prediction from blog data
aditya parameswaran

  

eldar sadikov

introduction

we have approximately one years worth of blog posts
from     with over    million web blogs tracked  on average
there are     thousand blog posts per day  in this project 
we are attempting to extract from the blog data the set of
features that are predictive of the movie gross sales  critics ratings  and viewers ratings  collected by sites like      
having gained this insight  we are applying machine learning techniques to make predictions on sales and ratings for
future movies 
this is useful for example  to see if the buzz surrounding
a movie is sufficient to obtain high sales  or whether additional marketing is required  in addition  we could automatically figure out ratings of movies based on their mentions in
blogs  this could be useful for movie rating sites like rotten
tomatoes     and imdb      either to verify the correctness
of ratings  or to seed ratings for a new movie or a movie
that did not exist in their database  additionally  in some
instances information like gross sales may not be publicly
available  so we would like to make a prediction instead  at
a high level  we would like to see if the online chatter is
useful for analysis and prediction of the quality and popularity of various items  be it movies  songs  books  restaurants
or other commercial products 
in our project  for the top movies of            of them
that have non negligible blog mentions  and top movies of
all time         we try to predict the following  the gross
sales  the critics rating and the average viewers rating  we
selected a long list of relevant features and populated them
after parsing the blog data  after performing training  crossvalidation  feature and model selection with a primitive set
of models  we have reasonable error rates for most output
variables  we find that naive bayes and svm are the best
prediction algorithms for our data  and pca generally works
best as a feature selection method  finally  we have observed
some interesting patterns that suggest that quite accurate
predictions can take place  given more sophisticated algorithms 

  

data and features

we have collected titles of the top     box office movies
of      from     and the top     u s  box office movies of
all time from      we have then hand filtered both lists for
the titles that were similar to the common english phrases 
this has effectively narrowed down our lists to the     top

 

petros venetis

movies of       which we are going to refer to as new movies 
and the     top movies of all time  which we are going to
refer to as old movies 
due to the sheer size of the original data set  approximately      tb   we had to do parsing in multiple stages 
at the first stage  we eliminated posts that were non english
and posts that contained more than    links  the former
was done because our focus was on the u s  movies  whereas
the latter was done for the purpose of filtering spam  after we performed this step  we constructed a list of regular
expressions corresponding to the titles of the new and old
movies and ran it against the data set to aggregate the posts
that mention movies  this has effectively become our working data set  which was of     gb size   from which we
have extracted our features 
the features that have been extracted can generally be
classified into four categories where each category is described in detail in the following subsections 
 basic features that quantify movie mentions without
regard for the quality  sentiment  or time of the blog
posts where they are made
 features that respect only mentions made within a
time window before or after a movie release date
 features that address the spam issue
 features that respect only positive sentiment mentions

   

basic features

we have hypothesized that the importance of a movie
mention in a post is proportional to whether it occurs in the
title or the text of the post as well as the rank and the indegree of the blog where the mention is made    accordingly 
we have devised our initial   features as follows 
   number of movie mentions in the title or text of blog
posts
   number of movie mentions in the title of blog posts
   number of movie mentions limited to only top ranked
blogs        blogs ranked 
   number of movie mentions weighted by blog rank where
weights are equal to    ln rank  or   for non ranked
blogs
   number of movie mentions weighted by blog in degree
where weights are equal to ln indegree  or   for
indegree    
although the weights used for feature   and   are quite
intuitive given our hypotheses  they may not be as effective
 
both blog rank  which measures blog popularity  and blog
indegree were calculated by http   spinn r com 

fias the weights determined automatically by a learning algorithm  hence  in addition to the features above  we have
discretized movie mentions by the ranking tier of a blog in
which they are made into    features as follows 
   number of movie mentions in the blogs ranked     
   number of movie mentions in the blogs ranked      
   
    number of movie mentions in the blogs ranked       
    number of movie mentions in the blogs ranked        
   
    number of movie mentions in the blogs ranked        
    number of movie mentions in the blogs ranked     
and above  but excluding non ranked blogs 
finally  in addition to the features that quantify movie
mentions  we have included among our features general characteristics of a movie as collected from     
 genre  discretized to be an integer             
 budget
 distributor  discretized to be an integer             

   

times series features

most of the box office sales are made within the first few
weeks after the movie release date and the success of the
movie is often highly dependent on the promotional campaign prior to the release date  hence  we have hypothesized
that the movie hype in online chatter just before and right
after the release date should in general be a good indicator
of the box office sales and public ratings  accordingly  we
have discretized movie mentions in a time series features as
follows 
   number of movie mentions  th week        days  before the release date
   number of movie mentions  th week        days  before the release date
   
   number of movie mentions  st week      days  after
the release date
   
    number of movie mentions  th week        days  after
the release date

   

features that address spam issue

although we filtered a large number of spam posts during parsing by discarding those that contained more than   
links  we have still ended up with many spam posts in our
working data set  we observed that the majority of spam
posts were either very short in length  usually a sentence
or two with a link  or quite lengthy with many html tags
and images embedded in their content  hence  we decided to
employ the following heuristic for filtering these spam posts 
if a post is either less than     characters long or contains
on average less than    characters of text in between the
html tags  then it is a spam post  to avoid the risk of
false positives  non spam posts classified as spam   instead
of employing this heuristic across all features  we have decided instead to add a set of additional features that relied
on this technique 
   number of mentions in the title or description of nonspam posts

   number of mentions in the title of non spam posts
      times series features that respect only non spam posts
since ranked blogs are unlikely to contain spam posts  we
have not included features that respected blog ranking among
the new features 

   

sentiment features

a sheer number of movie mentions in blog posts may
not always be indicative of high viewers ratings or high
box office sales and it seems intuitive to consider the sentiment of the posts when trying to predict ratings or sales 
since a movie mentioned in a post may not always be a central theme of the post  to measure the polarity of a movie
mention  we focus only on the   sentences surrounding the
movie title in the text of a blog post  to determine a movie
mentions sentiment  we employ the hierarchical classification approach described in     using lingpipe classifiers     
specifically  we use a subjectivity classifier to select from the
  sentences only those ones that meet a subjectivity threshold  and then classify those for sentiment using a polarity
classifier  both lingpipe subjectivity classifier and polarity classifier are   gram language model classifiers with the
former trained on the imdb     plot summaries and rotten
tomatoes customer reviews     and the latter trained on the
full text imdb movie reviews  described in more detain in
     
we have found that lingpipe polarity classifier is very
conservative when determining the sentiment and tends to
assign negative classification more frequently than the positive one  thus  we have decided to add two sets of features 
one associated with a conservative assessment of sentiment 
where we give credit to only those posts that lingpipe classifies as positive and  one associated with a more aggressive
assessment of sentiment  where we give credit not only to
the posts classified as positive but also to the posts classified as negative with a very low confidence    for each of
these sets we have added the time series features  e g   number of movie mentions with positive sentiment in the first
week after the release date  and the rank tiers features  e g  
number of movie mentions with positive sentiment in blogs
ranked        

   

output variables

for both new and old movies  we have collected the following output variables from     and     
 average rating of critics
 average rating by users  viewers 
 gross box office sales       only for new movies and
all time for old movies 

  

model

as described in the previous section  we have a set of input
features  a total of      and a set of output variables    
that we would like to predict  as a first step  we discretized
the output variables to    buckets  or deciles  we wish to
use classification to predict which decile the movie lies in
 
the probability of a sentence being subjective estimated
by the classifier needs to be at least     
 
we set the threshold level for aggressive sentiment to be the
     cross entropy between positive and negative sentiment
probabilities

fifor the given output variable  given the values of the input
features  we consider a classification successful if we are able
to predict the right region in which the movie lies  i e  we
say that the prediction is correct if we predict the correct
decile by       e g   if the actual value is    then a correct
classification would be any of the deciles               the
algorithms we used for prediction were the following 
   naive bayes  the input features are discretized into
   buckets  and the probability of the output variable
being in any given decile given the values of the input
variables are calculated  the best decile is picked 
   linear regression  the input features are fed into the
linear regression framework  and the value of the output variable is returned  we say that the prediction is
correct if the value of the output variable lies in      
deciles of the actual decile 
   locally weighted linear regression  similar to linear regression  except that we chose an appropriate
weighting function   
   multiclass svm  we trained our data to create hyperplane classification boundaries for each class   i e 
decile  this allowed us to say if a movie is in a particular decile or not  if a movie was classified into many
deciles  we picked the decile hyperplane such that the
distance to the hyperplane is the maximum among all
deciles for which the movie was classified into  if a
movie is not classified into any bucket  then we arbitrarily output the value    i e  that the movie is
average w r t  the output variable 
in addition to the forementioned machine learning techniques  we have also experimented with softmax regression 
however  the observed performance was quite poor and decided not to use it among our algorithms 
due to the small size of the training data       new
movies and      old movies   we couldnt use the original
set of features we had extracted      total   which prompted
us to look for a feature selection technique  on the initial set
of     features  we measured the training and test error and
found the test error to be much greater than the training error  which prompted us to reduce the dimensionality of the
data  given that we cannot generate more training examples
  our list of movies is the largest available list on the web     
in addition some of our features could be noisy  e g  sentiment analysis   which makes feature selection even more
crucial  we wish to only keep the most important features
for training  and remove the ones that are seemingly random  hence  we had three different ways to select features
for each output variable 
   kl divergence  we picked    features that the output
variable has the least kl divergence with  this indicates that the output variable has low entropy given
the input feature 
   correlation  we picked    features that are most correlated to the output variable 
   pca  we performed principal component analysis on
the data and picked the top    eigenvectors  we then
projected all the columns onto those eigenvectors  thus
reducing the dimensionality of the matrix 
 

we experimented with various functions  and chose
norm x y 
for both the old and the new
w x  y       max
z norm x z 
movie set

given the three feature selection methods and   prediction techniques  we ended up with           models  after
separating the training from the test data       for training   we proceeded to perform    fold cross validation with
the training data  for each output variable  we evaluated
the average error for each of the    models over the crossvalidation sets and then for each output variable picked the
model that performs best on average  i e  we picked the
least b
sj  hij    i e  the estimated generalization error  

  

results

the estimated generalization errors for each of the   
models is given in table   for the new movies and table
  for the old movies  table   shows the best model selected
for each of the output variables  where training error column shows the estimated generalization error obtained with
the best model  for each output variable  we then train a
selected model  which includes both the algorithm and the
feature selection method  on the entire training set  and test
it on the test set  the test error obtained as a result for each
output variable is shown in the last column of table   
naive bayes and svm have turned out to be the more
effective algorithms for most of the output variables and
pca has been consistently effective as a feature selection
method  on the other hand  linear regression has performed poorly for most of the variables  which may indicate
that the output variables as functions of features are not
linear  nonetheless  no selected model has performed extremely well on a test set for any of the output variables 
this can be explained by any of the following  low number
of training examples  inherently noisy data set  poor sentiment analysis  inter dependence between movies released in
the same time period 
as seen from table    for some output variables  e g  
critics rating for the new and old movies and gross for the
old movies   the training error is very close to the test error 
however  for some of the other variables  e g       gross
and user rating for the new movies  the difference between
the training error and the test error is still high  thus  we
hypothesize that the results could be improved by selecting
a better model  or by including more features  for example  by employing a better sentiment analysis approach   in
addition  note that the value of the test error for the last
two rows of table   is smaller than the training error  this
might be due to the fact that we have a limited number
of examples  and the initial split of data into training and
test examples may have given rise to a large number of the
highly predictable movies falling in the test set 
our work demonstrates that blogs could be a very good
source of information for analysis and prediction of movie
quality and popularity  in spite of the relatively poor performance of the selected models on the test set  we have
indeed observed interesting patterns that suggest predictive
power of blogs  specifically  graph   shows that the number of movie mentions is directly related to the movie gross 
graph   shows correlation of      gross to the times series
features  i e  mentions in the  th week before the release
date   th week before the release date           th week after
the release date  and demonstrates that the closer we are
to the release date  the more correlated number of mentions
are to the actual gross  the same applies to the other output variables   finally  graph   shows correlation of     
gross to the rank tier features  i e  mentions in blogs ranked

fitable    estimated generalization error for each of the    models and   output variables on the new movies
  st row  gross sales   nd row  critics rating   rd row  user ratings 
lr kl
      
      
      

lr cl
      
      
      

lr pc
      
      
      

wr kl
      
      
      

wr cl
      
      
      

wr pc
      
      
      

nb kl
      
      
      

nb cl
      
      
      

nb pc
      
      
      

sv kl
      
      
      

sv cl
      
      
      

sv pc
      
      
      

table    estimated generalization error for each of the    models and   output variables on the old movies
  st row  gross sales   nd row  critics rating   rd row  user ratings 
lr kl
      
      
      

lr cl
      
      
      

lr pc
      
      
      

wr kl
      
      
      

wr cl
      
      
      

wr pc
      
      
      

nb kl
      
      
      

nb cl
      
      
      

nb pc
      
      
      

sv kl
      
      
      

sv cl
      
      
      

sv pc
      
      
      

table    estimated generalization error and test error for each variables selected model
output variable best model training error test error
     gross
nbayes pca
      
      
critics rating
nbayes pca
      
      
new movies
user rating
wlr kl
      
      
gross
nbayes kl
      
      
old movies
critics rating
svm corr
      
      
user rating
svm pca
      
      
graph    rank tier feature correlation to      gross

graph    number of movie mentions in the title
vs       gross

graph    time series feature correlation to      gross

      blogs ranked                blogs ranked        from
the graph it can be seen that the higher the ranking of the
blogs where movies are mentioned is  the more correlated
the number of mentions are to the gross  same applies to
other output features  
given the relationship of times series features to the gross
demonstrated in graph    an interesting problem that could
be examined is predicting sales of the ith week after the
release date given blog posts until the i   th week  we
have not tackled this problem in our project but it would be
worthwhile to address in the future work 

acknowledgements
we would like to thank jure leskovec and spinn r for providing us the data 

  
   
   
   
   
   

references
http   spinn r com 
http   www the numbers com 
http   www rottentomatoes com 
http   www imdb com 
http   alias i com lingpipe 

fi    bo pang and lillian lee        a sentimental education  sentiment analysis using subjectivity summarization based on minimum cuts  acl proceedings 

fi