sentiment classification  judging attractiveness of people through
textual descriptions from online reviewers
natth bejraburnin  nathan howard  john le
december         
abstract
we aim to judge attractiveness of people given information provided by online reviewers  we were
given the data from facestat com and we developed and tested several machine learning algorithms to
meet these goals  the data is gathered from a variety of online reviewers  either anonymously or not 
among the information are single word textual descriptions  judgements on intelligence level  wealth 
weight  gender  ethnicity  we mainly thought of our feature set as a bag of words  to improve upon the
bag of words model we clustered the words based on several techniques  most notably mutual information 
and then created a concept mapping from words that were less informative to words with high mutual
information scores  this helped improve accuracy by about      percent with naive bayes and about     
percent on joachims svm light  we also tried logistic regression and locally weighted linear regression
with varied success 

  introduction
machine learning algorithms  such as naive bayes  have been used with great success for classifying text
documents  particularly for classifying spam emails  applying methods from the text classification problem 
we wanted to predict the attractiveness of a person given their textual descriptions  we tested a couple of
bag of words  bow  model of the textual descriptions on several different algorithms  particularly regression 
naive bayes and svms  the bow model we tested was  the entire vocabulary of the training set  the    
most common words  and the     words with highest mutual information score  mutual information is a
commonly used technique for feature selection which measures the amount of information that a value of
one variable gives about another variable  yang and pedersen        cover and thomas       as cited in
schneider         and we calculated it with 
m i xi   y   

x

x

xi  tokens  y     

p xi   y  log

p xi   y 
 
p xi  p y 

where xi denotes whether token i appearing in a face  y denotes attractiveness  p xi   y   p xi   and p y  can
all be estimated from their empirical distributions on the training set  we will also describe a method where
we used a given bow model to cluster words and enhance our features 

  data information
the textual descriptions came from www facestat com  particularly they are textual descriptions that
are submitted by mostly anonymous reviewers  the non anonymous reviewers judgments were extremely
sparse and hence we treated all reviewers as anonymous  though we had wanted to use algorithms  such
as em clustering  that analyzed biases within the reviewers  attractiveness ratings were determined by
averaging all of the reviewers judgments on a scale of   to    and we deemed that a person was attractive
 

fiif their average attractiveness rating was greater than      this number was chosen objectively as it is the
center of   and    the methods for gathering data justifies objectively choosing a standard for attractiveness
that is independent of the actual judgments 
the textual descriptions are single word descriptions for a variety of categories  such as describe in one
word  age  gender  and what is my worst feature   the person uploading the face gets to choose up
to five categories they especially want judged  accounting for playful categories like how intoxicated am i  
the only category which will always be judged by at least one reviewer is describe in one word  the age
and gender categories are inputted by the person uploading the face  although the user can also choose to
have reviewers judge these as well  we worked on a subset        faces  of the data  where all of the faces
have an attractiveness rating and some words in the describe category 
judgments for each category are gathered from a pool of reviewers providing textual descriptions conforming to the category  the reviewers are either randomly selected from this pool of reviewers or randomly
selected from people who anonymously view the site on the internet  for each reviewer that is reviewing
the categories they judge are independently randomly selected  furthermore  while reviewing  reviewers will
not be able to see the past judgments of a particular face unless by chance they had come across the face
while browsing  reviewers cannot choose to review a particular face  they can only decide that they want to
review faces and from then on the website randomly gives them a face to judge  because reviewers cannot
see how other reviewers have described a particular face  we decided to objectively define attractiveness as
having a rating greater than     

  pre processing
from the textual data described above  we generate numerical matrices for our learning algorithms by
using the following rules 
   each image is represented by a row matrix whose dimension is   x     
   the first entry is binary with   indicating that the person is attractive and    or    if needed for svm 
otherwise 
   the second entry is the average of all the numbers posted under category age 
   the next   entries correspond to the categories of ethnicity  each entry is the average of the counts
on each category 
   the   th is the average of the counts of responses with male     and responses with female     
   the   th is the average judgment of weight  where weight  like attractiveness  is judged on a   to  
scale 
   the   th is binary value describing whether the user wanted to be judged on wealth 
   the last     entries are generated with the multinomial event model i e  the ith entry represents the
count of the ith words occurences in the set of judges descriptions of this image 
   then only for regression and svms  we normalize the matrix  for naive bayes  we use only the last
    entries  for reasons which well explain later 

  methods
    clustering
we clustered words to the words we used in the bow model  our method was to cluster a non cluster
point to that point based on the metric p  cluster point appears on a face non cluster point on a face   
 

fi  of times cluster point appears on a face a non cluster point appears in
 
total   of words on faces in which the non cluster point appeared

then we treated a non cluster point  i e a token

that was not used in our bow model  as the token
argmaxclusterpoint p  cluster point appears on a face non cluster point i appears on a face  
this means any time we saw the non cluster point that we would treat it as
argmaxclusterpoint p  cluster point appears on a face   non cluster point i is on a face  
we applied this feature adjustment method for the bow models of the     most common words and the
    highest scoring mutual information words  this method did not need to be applied when we used all
of the tokens in the bow since in this case all words in the training sets were treated as cluster points 
the motivation for this clustering approach is twofold  first  the internet jargon used by judges has both
incorrect spelling and non standard words  furthermore the input doesnt allow reviewers to add spaces 
hence there are a lot of tokens which are concatenations of several words  sometimes delimited by nothing 
these factors make stemming lemmatization less effective and thus we decided not to apply stemming or
lemmatization to the words  an additional benefit of our mapping is that it maps semantically similar but
lexically different words together  for example  in our bow over made is mapped to fake  geezer is
mapped to old and off beat is mapped to artsy 

    naive bayes
with naive bayes we would just use the words from the bow model  we ignored the other categories 
we at first took the other categories into account but they seemed to be introducing more noise and our
naive bayes model was worse classifier  we tried looking at those objects as normally distributed averages
and used them in our naive bayes model but this turned out to be unfruitful  we also tested treating the
categories as tokens but from mutual information they did not turn out to be useful based on the mutual
information metric  and hence we ended up ignoring them in for our final discussion  the results of the
clustering applied to naive bayes appears in the charts below  naive bayes saw slight increases in test set
accuracy and decreases in train set accuracy  and increases in precision and recall  when using the clustering
model as opposed to not clustering  this appeared to tell us that clustering indeed helped improve our
generalization error although as our chart shows not greatly and possibly by not a significant amount 

    logistic and locally weighted linear regressions
with the regression methods we plugged in the models to regression models  it took forever to run and
the charts below describe our accuracy  in the chart for locally weighted linear regression  we ran it by
testing several bandwidths and the chart shows us results from choosing the bandwidth that gave us the
least test error 

    support vector machine
we use joachims svm light to implement the support vector machine algorithms  svm  on our
datasets  we try this implementation with both the linear kernel and the gaussian kernel  or radial basis
function  rbf   whose gamma parameter is determined by the cross validation method described below  for
cross validation  each candidate model is varied only by the gamma parameter  all else fixed  since most
feature values range between    and    we need to use small gamma in order to increase the gap between any
two non similar samples  some trials suggest gamma have the order of     and we define the candidate
models as shown in the table  we train each of these on a set of      samples and test it on a set of    
samples  the results  see table    recommend we use gamma          
then we run the selected model on two sets of data  the one with and without clustering  from the
results  both generalization accuracy and precision recall  displayed in the chart  we can see that clustering
does not do significant improvement for svm 
 

fitable   

accuracy rate

      
      

     
      

results from running cross validation
     
     
      
     
     
      
      
      
      
      

    
      

   
      

 
      

    comparison of the algorithms performances
algorithms

naive bayes

locally weighted linear regression

logistic regression

svm with linear kernel

svm with gaussian kernel

training
accuracy rate
size
w clustering
w o clustering
   
      
      
    
      
      
    
      
      
    
      
      
    
      
      
full
      
      
avg       improvement
   
n a
      
    
n a
      
    
n a
      
    
n a
      
    
n a
      
full
n a
      
   
n a
      
    
n a
      
    
n a
      
    
n a
      
    
n a
      
full
n a
      
   
      
      
    
      
      
    
      
      
    
      
      
    
      
      
full
      
      
avg         improvement
   
      
      
    
      
      
    
      
      
    
      
      
    
      
      
full
      
      
avg         drop

precision recall
w clustering
w o clustering
             
             
             
             
             
            
             
             
             
             
             
             
n a
n a
n a
n a
n a
n a
n a
n a
n a
n a
n a
n a
             
             
             
             
             
             

n a
n a
n a
n a
n a
n a
n a
n a
n a
n a
n a
n a
             
             
             
             
             
             

             
             
             
             
             
             

             
             
             
             
             
             

  discussion
the most interesting outcome of our project was the bag of words clustering  while clustering did not
decrease test set error significantly  its word associations proved interesting in their own right and worthy of
further study  since words exist in a discrete space and the spelling of two words usually gives little guidance
to how they are related  there is no obvious metric of the distance between to two words  however  while
simple  the results of our clustering introduces a topology on the words which  in many cases  correlate with
an english speakers notion of the relatedness between words  with regards to the actual text classification 
we found that a svm performed better than a naive bayes classifier which performed better than logistic
regression  these results are in accord with previous text classification trials  kim  sang bum et  al       
which found that svms performed better than naive bayes classifiers  one hypothesis for the reason our
naive bayes classifier performed relativly well against the svm is that  in our case  the naive bayess
assumption that the probability of each word appearing is independent of which other words are in the text
closely approximates reality since most the tags are only one word 

 

fi  future work
   adjust the concept mapping  we currently pick a single informative word to map uninformative words 
the word is chosen by picking the informative word that has the highest probability of showing up
with our given uninformative word  this might give too much weight to an uninformative word being
mapped to a word useful in determining attractiveness  instead of doing this we would consider the
following  if we see an uninformative word  then to the bow feature vector for each good word we
add the probabilities that the good word shows up with an uninformative word  calculated by  number
of times good word appears in faces with the uninformative word   total number of words that appear
in faces with the uninformative word   intuitively this should smooth out the weight of adding a full
instance of the informative word to the feature vector by distributing it across the clusters of words
given by the bow 
   facestat com allows you to mark out the face you want judged  if the site could be expanded so that
you can mark out features to be judged we maybe be able to use textual descriptions to find novel
features within images  this could help generate models for what an attractive face might look like 
   define the topology of the space given by the words being points  and letting the distance metric be
defined by probabilities that words show up together  we could use this to create a visualization for
the space and if we color sections of the space based on attractiveness it could look pretty  like if
on the scale of colors ultraviolet means more attractive and as we move towards words that describe
unattractive faces the color shifts towards the red end of the color spectrum 
   from the comparison of the results from each algorithm we implemented  we can observe that the
generalization accuracy does not exceed      it could be expected that our training datasets are not
linearly separable  as it contains around     outliers  one reason that accounts for this high number
of outliers must be that the quality of attractiveness is not universal objective  as a consequence  there
must be quite a number of images that possesses similar feature values to ones in the opposite category 
the training datasets could be improved so that they reflect more truly the performance effectiveness
of the algorithms implemented against them 

  acknowledgements
we are thankful to www facestat com and particularly lukas biewald for for providing all the data 

references
    a  mccallum  k nigam   aaai    workshop on learning for text categorization 
dns  icar cnr it   http   ds internic net rfc rfc     txt  accessed august          

      

    a  ng  cs     lecture notes autumn      
    sang bum kim  kyoung soo han  hae chang rim  and sung hyon myaeng  some effective techniques for naive bayes text classification  ieee transactions on knowledge and data
engineering  vol      no      november       
    t  joachims  making large scale svm learning practical  advance in kernel methods   support
vector learning  b  schalkopf and c  burges and a  smola  ed    mit press       
    s  karl michael  a new feature selection score for multinomial naive bayes text classification based
on kl divergence  the companion volume to the proceedings of   st annual meeting of the association
for computation linguistics  association for computational linguistics  july        page        

 

fi