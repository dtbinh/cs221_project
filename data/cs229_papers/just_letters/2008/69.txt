book recommendations on goodreads com
derrick isaacson and abraham sebastian

introduction
goodreads is a social networking website that allows users to share information about
books that they are reading  get book recommendations from other users and meet new
people online 
a goodreads user maintains bookshelves of books that he has read or is currently reading 
he can rate books that he has already read and can also write reviews for books  users can
find friends within goodreads and compare books with them  users can also recommend
books that they have liked to their friends 
we propose to create an automatic recommendation system that uses prior knowledge of a
user s rating for some books to suggest new titles to add to his collection  we would like to
make recommendations with high precision  i e  there must be a high probability that the
user would like the suggested books  we use user based approaches where we use
similarity measures among groups of users to make recommendations  for example  we use
k nearest neighbors clustering to group users together based on the books on their
bookshelves and their personal ratings for those books  we predict ratings for a book that a
user has not read from the rating given to that book by other users in his cluster  we also
use item based methods where we create networks of related items to make
recommendations  so in this case a recommendation model is not tailor made for a
particular user but is instead based on the particular items he selects 

data acquisition
to recommend books we needed data on users and the ratings they gave to books  we
acquired the data by querying goodreads  public web api 
goodreads organizes their data by users and  bookshelves   a user has multiple
bookshelves that each contain multiple books  there is a standard set of bookshelves which
every user has   read    currently reading   and  to read   most users stick to the standard
set  but goodreads provides the ability to create custom bookshelves  this ends up acting
like a form of tagging  for example  the play macbeth by william shakespeare has been put
on a  plays    shakespeare   or  classics  bookshelf by multiple users 
we acquired our data mainly through the  get the books on a shelf  method  given a user
and bookshelf name we queried for all of the books  this provided several fields of data for
each book on the shelf such as user rating  average rating  and catalog data such as title
and isbn 
goodreads does not expose a list of user ids so coming up with a list of users to get data
for was a challenge  we found that if we took the user ids for our own profiles and queried
for numbers nearby  that we were able to find a sufficient number of active users  because
we were interested in books that users have already completed and given a rating too we
used the standard  read  bookshelf for each user  this was still challenging because many

fipeople list their bookshelves as private  and many people do not have any books on their
 read  shelf  we ended up having to query for about    times the number of user ids as we
actually needed data for in order to find enough public bookshelves that have books on
them 

model evaluation
similar to facebook friend suggestion      we would like to predict a rating that a user
would give each book if they were to read it  goodreads allows you to rate books on a scale
of     stars with   being the best  however  we do not simply want to calculate how many
stars a user would give a book  but find the top x number of books that they would like  so
we would like to calculate these numbers on a continuous scale and pick the books with the
largest x values  rather than simply classify the books for the user 
there is also a challenge in testing our hypothesis once we calculate it  because it is not
possible to make the recommendations and then have the users read the books and get
back to us in a timely manner  we decided to use some form of hold out cross validation  as
we prototype our system and iterate we plan to experiment with different forms of crossvalidation to see what our needs are  although we cannot recommend books and then test it
out on the users  we can obtain data for a fairly large number of users so a simpler form of
hold out cross validation will likely be sufficient 

item based methods
similarity computation
item based collaborative filtering finds relationships between pairs of items while ignoring
similarity between users for simplicity  it performs regression that is simpler than linear
regression  rather than computing f x    ax   b  it calculates f x    x   b for each pair of
items 
the input we use for computing item similarity is a matrix of users and their ratings for
specific items  we compute a similarity measure between pairs of items as follows  we
derive vectors i and j for the the two items using the ratings of all users that have rated
both items  for example 
i

    

j

u 

 

 

u 

 

 

u 
u 

 
 

in the above table user u  has not rated item i and user u  has not rated item j  so we
have i         and j          we then compute the average vector from i to j as         
          we use this to measure the similarity between two items 
for a given item j that a user has not rated and some existing ratings for a user we can

fipredict how a user will rate j  the prediction is made by adding the average vector from i to
j to the user s rating for i  then taking the average over all i 
we also followed one common improvement to this algorithm by weighting the different i
items used to predict the new j item  we give a higher weight to i when more users have
rated both i and j 

learning performance
slope one is used because
   it is simple to implement and does not require much tuning 
   it avoids overfitting the training data because of its simplicity 
   it is relatively fast to compute 
we implemented slope one in c  and ran it on a machine with a      ghz amd athlon
processor    gb of ram  running windows xp and visual studio       the one major
 
performance bottleck that we ran into was the n amount of memory that the similarity
calculations require from calculating all pairs of items  because not every pair of items have
been rated by some user we represent the matrix as a dictionary of dictionaries where the
keys are isbns for the books  even then we could only compute the matrix for      users
before running out of memory on our machine 
future work could improve this a few ways  one would be to not store all of the data in
memory at a time  a second would be to cut the size of the matrix in half by only storing
vectors in one direction between a pair of products  the vector from item j to item i is
simply the negative of the vector from item i to j we could avoid the storage overhead and
do the reverse lookup in our table when necessary  however  we did not see much
improvement when increasing the number of users from      to      so we expect the
results to not change much 

recommendation performance
we tested our algorithm through cross validation  first we held out of our training set    
of our users  after training the algorithm we made predictions using hold out one cross
validation  we did this by repeatedly holding out a single book the user had rated and
making a prediction on that book looking only at the other ratings the user had given 
we tried a few methods of generalization error to find the best indication of how this would
perform as a recommendation system  first we calculated the average difference between
our prediction and the actual rating  this gave us an error of about     out of   stars 
as mentioned above  a recommendation system is only interested in books for which it
predicts maximum ratings  we improved our error measurement by only considering   star
predictions  after tuning some parameters of how the algorithm rounds its predictions we
were able to predict exactly the user s rating about     of the time and within   star    
of the time  as a comparison  only     of the ratings are   stars so our predictions are
actually meaningful 

fibelow is a graph of the generalization error  where the error is reported as percent of
predictions within an error range from   to   stars 

as referenced above  there was one rounding parameter we could tune in the system  we
discovered that adjusting it gave different results and after looking into it we discovered we
were trading off precision for recall of the   star ratings  below is a graph of the tradoff as a
function of the rounding parameter  we tuned the system for precision over recall  the
algorithm returns hundreds or more of   star predictions so we did not need high recall to
recommend a few good books to the user 

user based methods
user based collaborative filtering works by looking for users who share the same rating
patterns as the active user  the user whom the prediction is for   these methods work by
first clustering together users who are similar and then deriving the rating for a new item
from the ratings given by other users in the cluster  we used k nearest neighbors to cluster
users together  for a dataset with n users and m book titles  we implicitly represent each
user as a point in an m dimensional plane  where each coordinate is the rating for the book
corresponding to that coordinate axis  we then compute the similarity measure between a

fipair of users as the average of the squares of the difference between ratings for books that
they have both rated 
we predict the rating for a book that a user has not yet rated by computing the weighted
average of ratings given to the book by other users in the same cluster  where the weights
are the similarity measures between pairs of users  to determine the optimal value of k  we
ran our algorithm on the dataset using different values of k and tested our generalization
error with hold out cross validation  the graph below shows the average difference between
our predictions and the actual ratings given by users for progressively higher values of k 
we see that our predictions do not improve much beyond k   

references
    daniel lemire and anna maclachlan  slope one predictors for online rating based
collaborative filtering  in siam data mining  sdm     newport beach  california  april
            
    b  m  sarwar  g  karypis  j  a  konstan  and j  riedl  item based collaborative filtering
recommendation algorithms  in www         
    eytan daniyalzade and tim lipus  facebook friend suggestion  in cs     machine
learning final projects  http   www stanford edu class cs    projects     html  autumn
    

fi