grasping objects using high density  high accuracy point cloud data
alex krimkevich
alexkrim stanford edu
december         

abstract grasping is an important manipulator function
that forms the basis of a robots interaction with its environment  interesting algorithms cast the question as a learning
problem           however  these efforts have been somewhat
hamstrung by the lack of reliable and detailed depth data 
the new borg laser scanner for the stair platform remedies
this problem  providing dense  highly accurate depth data
by active triangluation  given this data  we seek to discover
whether local point cloud geometry suffices to determine the
optimal grasp position for a robotic gripper  where we assume
a priori knowledge of the actual grasping points  we present
algorithms trained using regression based methods on planar
and ellipsoid approximations of the data  we find that  given
some assumptions about our features  we can predict quite
successfully the best arm configuration when grasping an
object 

i  introduction
we present brief background information on the robotic
manipulator  training platform  and grasping point classifier 

fig    

grasp points  in green  in sample scene 

a  robot and training platform
the stair  platform is built around the katana arm  a
  degree of freedom robotic manipulator  motion planning
for the arm is accomplished using the motion planning
kit  or mpk  mpk combines adaptive sbl  a probabilistic
roadmap planner  and an open inventor based renderer to
compute and visualize collision free paths in configuration
space for arbitrary robots  as a preliminary step to the
research contained in this paper  we made several bug fixes
and modifications to mpk  most importantly  we gave the
visualization machinery the ability to extract relevant configuration information about the arm  we also added the ability
to overlay features and labels on a scene  together  these
allowed us to perform training completely in simulation 
finally  we created an improved model of the stair 
platform and obtained an accurate calibration to transform
borg laser scans into mpk scenes 

of a scene  features are extracted from each   x   patch  as
described above  each patch and its features are then passed
to the classifier  and several of the top patches are chosen as
candidate grasp points  see fig    
c  paper structure
we first discuss the intuition and basic approach to the
problem  next  we go into detail about the methods used 
finally  we discuss our results  conclusion  and future work 
ii  approach
given a grasp point  we define its neighborhood to be its k
nearest neighbors  this definition is rather limitedconsider 
for example  implications in a cluttered environment where
different objects are very near to each other  however  in
simple scenes  this serves as a good heuristic for identifying
regions of a surface containing our grasp point 

b  grasping point classifier

a  local plane approximation

the current grasping point classifier is a linear svm
that uses     exclusively depth based features  the training
algorithm first obtains a     x     pixel depth map from
the borg scanner  it divides the map into   x   pixel regions
and convolves each with laws texture masks  these allow
extraction of edge features  which are combined with similarly obtained features from neighboring patches to better
understand local shape information  this is paired with an
appropriate label for the patch in order to generate a training
example  in order to execute a grasp given a test depth map

once we have determined the neighborhood of a grasp
point  we can find a local plane approximation to the surface
in that neighborhood  to do this  we use principal component
analysis      for grasping point pi   denote its neighborhood
nbhd  pi    and let i be the centroid of nbhd  pi    then the
covariance matrix is given as follows 
cov nbhd  pi     

x
x nbhd pi  

 x  i   x  i  t

finote that because the points in nbhd  pi   already have an
appropriate scale  determined by their spatial layout   we do
not rescale the points to have unit variance 
the eigenvectors of cov nbhd  pi    sorted in order of
decreasing eigenvalue yield the principal components of the
points  in particular  the eigenvector associated with the
smallest eigenvalue is the normal to the least squares plane
approximation of nbhd  pi    the katana manipulator has a
parallel plate gripper that works best for grasping narrow
objects  therefore  it seems quite natural that for objects
with local planar geometry we would want our gripper to
be parallel to this normal vector  similarly  to enable this
parallel grasp we must approach the object perpendicular to
the normal vector  this suggests that the first and second
principal components influence the angle of approach to the
object 
b  local ellipsoid approximation
for block shaped or curved objects  the local plane approximation may not properly capture the true local geometry
of the neighborhood of our grasping point  an ellipsoid
might be a better fit in these kinds of situations  to find
this ellipsoid  we construct the covariance matrix as above
and find its eigenvectors  these eigenvectors serve as the
principal axes of the ellipsoid  the lengths of the axes are
given by the corresponding eigenvalues  we use a parametric
representation of the ellipsoid that is helpful in generating
features 
 i 

 i 

 i 

 i 

v      cos  cos  
v      cos  sin  
 i 

b  features
in our experiments  we used two sets of features  we now
describe both 
   planar features  when considering the planar approxiation of a surface  we used the three principal components
as features  the motivation for this is that the katana arm
performs best when grasping narrow objects  so we want
our prediction to be as near to parallel with the local plane
normal as possible  our desire for a parallel grip then dictates
that we approach perpendicular to the plane normal  so
ideally this approach angle is a linear combination of the
first and second principal components 
however  there are a several more issues to consider 
first  the workspace of the katana arm limits the reachable
configurations  thus  for example  it is not possible to
achieve a vertical grasp for objects near the boundary of
the workspace  or approximately     m from the origin 
therefore  we would like our predictions to somehow reflect
these sort of constraints  also  the labels are obtained in a
simulated environment where precision control of the gripper
is very difficult  as a result  the labels contain a fair amount
of noise  and we also want our predictions to filter human
error in the training examples  thus  there is a strong learning
component to making our predictions using local planar
features 
   ellipsoid features  for the ellipsoid approximation  we
obtained    normals to the local ellipse and used these as
features  using the cartesian representation of an ellipse 
we take the gradient to find an equation for the normal at
arbitrary x  y  z 
y 
z 
x 
          
 
a
b
c
 x  y  z
f  x  y  z    h           i
a b c
 cos  cos    cos  sin    sin  
 
 
i
 h
 
 
 
where the final equality used our parametrization shown
previously  we take normals for  on        at   intervals
and for  on           at   intervals as well  we include
f  x  y  z   

 i 

v      sin  
 i 

 i 

 i 

for                       here         
are our eigenvalues found above  worth noting is that the
 i   i   i 
resulting vector  v  v  v   t is in the basis defined by the
eigenvectors  so we perform a change of basis to standard
coordinates  also worth noting is that the parameterization is
not one to one at the poles  so these points should be treated
separately 
iii  supervised learning
a  labels
to perform supervised learning  the label y  i  for a single
training example consists of the vector in r  between the
fingertips when the arm is in the optimal grasping position
about a grasping point  the katana wrist is capable of full
rotation  so y  i  is equivalent to  y  i  for our purposes  this
label is often sufficient to fully describe the configuration
of the katana arm  specifically  let pi be the vertical plane
containing the origin and the grasp point pi   then provided
that the projection of y  i  onto pi is non zero  the label will
have a unique corresponding approach position  the normal
to the label lying in pi   knowing the wrist and approach
angles  we can easily perform inverse kinematics to find an
appropriate position for the arm 

fig     labels  in black  and features  red  green  and blue for strongest 
middle  and weakest components  respectively  in a sample scene 

fi         t and         t separately  these correspond to
      and       
our hope in using the ellipse features is that we can obtain
a finer  more granular representation of curved surfaces  like
mugs  we may also be able to better account for workspace
constraints and training noise as described in our discussion
of planar features 
c  training
we tried linear regression and locally weighted linear
regression for each set of features used  we trained our
algorithms on approximately    grasps on cups  plates  and
blocks at a variety of distances from the base of the robotic
arm  we discuss our methods in detail 
   linear regression  let x  i   r n be our ith
training example  where n is the number of features  and
  rn be our parameter vector  for linear regression  we
seek to minimize the following cost function 
m

j    

  x  i 
 x   y  i   t  x  i    y  i   
  i  

given a training set of local planar examples  we can write a
closed form expression for  similar to the normal equations 
m
m
x
x
      x  i   t x  i        x  i   t y  i   
i  

i  

for
set of local ellipsoid examples  the matrix
pm a training
 i  t
 i 
 x
 
x
is generally singular  so we cannot use
i  
the equation above  instead  we find the gradient of the cost
function and perform batch gradient descent 
j    

m
x
 x  i   t x  i     x  i   t y  i 
i  
m

x  i 

j    
 xj  t  x  i    y  i   
j
i  
j    j   

m
x

 i 

 xj  t  x  i    y  i   

i  

we found that            works fairly well for this
problem  empirically  the ellipsoids tend to have one very
large axis  and for larger values of  gradient descent actually
diverges 
   locally weighted linear regression  initially  we used
the following standard weights 
w i    exp 

kpi  pquery k 
 
   

with        
however  two considerations motivated us to try another
set of weights  first  we did not have a very large dataset
and were reluctant to throw large parts of it away  second 
we noted that we could take advantage of the workspace
constraints of the arm when setting the weights  beyond a
certain fundamental distance of about      m  it is impossible
for the arm to perform a vertical grasp  conversely  within
     m  the arm cannot perform horizontal grasps  therefore 

it seems that grasps on either side of that boundary should
be similar to each other  this leads us to try the following
weights 
w i   

 
    exp k  sign       kpquery k  kpi k        

these favor points on the same side of the      m boundary 
k is a parameter that controls how quickly training points on
the opposite side of the      m boundary decay  results for
both weights are shown below 
d  modified pca
in order to get good performance from the algorithm  it
was necessary to do slight post processing of the principal
components  the reason for this is that the principal component directions are somewhat arbitrary  from the point of
view of pca  there is no difference between the positive and
the negative directions  unfortunately  this also means that
there is no consistency to directions for points from different
surfaces  this means that training on one object may lead to
poor results when testing on another  therefore  we make the
assumption that the predictiction can always be represented
by a linear combination of the features having all nonnegative
coefficients  note that this only requires reversing principal
components that form an angle with their label exceeding
  o   this would give a consistent orientation to all of
our principal compoents  to implement this assumption  we
compared the raw principal components to their labels and
changed their directions as needed  this was also done for
training examples that were held out for testing  a decision
that will be discussed later 
iv  results
   fold cross validation was used to test our algorithm 
results follow for both standard and locally weighted linear
regression  as well as for both types of weights and for modified pca  see above   we use lr to denote linear regression
and lwr to denote locally weighted linear regression 
table i
r esults   error in degrees

lr
lr  modified pca 
lwr  modified pca  standard weights 
lwr  modified pca  special weights 

planar
    o
    o
    o
    o

ellipsoid
    o
    o
   o
   o

v  conclusion
results obtained without using modified pca are fairly
poor  the reason for this is the variability of principle
component directions  and training with the larger number
of ellipsoid features seems even more vulnerable to the
problem  the issue is discussed in more detail above  once
we take the step of modifying pca  though  results for the
planar case improve considerably  interestingly  though they
do improve for the ellipsoid case  they still remain quite
bad  this finding is difficult to interpret  it is possible that

fithe ellipsoid method is more sensitive to noise  which would
also explain the difference in results between the planar and
ellipsoid models when doing standard linear regression  more
work is required here 
in the planar case  the improvement due to locally
weighted linear regression was marginal  for the ellipsoid
approximation  on the other hand  it resulted in a nearly
three fold improvement in accuracy over the planar  this
suggests that the ellipsoid is very good at capturing geometric
information for similar groups of training examples  so given
a large  broad training set  it seems likely that it could be
successfully used to predict optimal grasp angles for novel
objects  we also note here that our special weights performed
no better than the standard ones  which means our intuition
for using them was not necessarily correct 
finally  recall that the principal component directions
are also modified for the test examples  this step seems
somewhat suspect  but the improved results indicate that the
assumption behind it is indeed valid  therefore  the principal
components  when correctly interpreted  do account for some
of the structure of the problem 
vi  future work
in the future  we would like to remove the need to orient
the principal components for training and test data     
presents a possible algorithm that could be adapted for this
purpose  essentially  one picks a normal vector as a reference

direction and sets nearby normal vectors to point to the same
direction  this approach does not require knowledge of the
labels  so it could solve our problem if we extend it to
the other two principal components  we would also like to
perform real grasping experiments using our algorithm  this
is a necessary step to make sure that our results hold outside
of simulation  finally  it would be interesting to try new sets
of features to see what kind of results they give  there may
be other geometric ideas that yield better predictions 
vii  acknowledgments
the author gratefully acknowledges the help of quoc v 
le in providing calibrations between the borg laser and
mpk  along with patient guidance   and hee tae jung in
explaining the mechanics of the grasping point classifier 
additionally  this project would not be possible without the
cs    professor and staff  so a great thank you to them as
well 
r eferences
    l  wong  learning to select a good grasp  cs    class project report 
     
    a  saxena  m  s  chung  a  ng  robotic grasping of novel objects
using vision  international journal of robotics research  vol      no   
pp           feb       
    h  hoppe  t  derose  t  duchamp  j  mcdonald  and w  stuetzle 
surface reconstruction from unorganized points  in proceedings of
the   th annual conference on computer graphics and interactive
techniques  pp              

fi