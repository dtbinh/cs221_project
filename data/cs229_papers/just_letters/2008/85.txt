absolute range detection system for stair
giancarlo garcia and david jackson  december         
introduction
absolute range detection has been a long time objective of studies focused on achieving stereo
computer vision  many researchers have attempted to emulate some part of the human stereo
system  most commonly motion parallax  these attempts  however  have concluded that motion
parallax is not a reliable source of input for systems attempting range measurements and  in fact 
often worsens object size and range prediction          a system with these qualities is needed
for applications such as the stanford ai robot  stair   which must be able to maneuver
through dynamic environments in order to carry out its tasks 
our approach to tackling the problem of range detection was two fold  our first system replaced
one of the two cameras in a traditional stereo vision system with a laser marker  by holding the
marker and camera fixed while varying the their distance to an object  a training set was
produced from which any new distance could be inferred  utilizing this method we found that we
could achieve reliable      range estimates at up to     feet 
in our second approach  our original objective was to expand upon our first approach to produce
a system that could provide absolute range for any pixel in a given camera image  not just one at
a time  through trial and error we eventually we settled on a fringe projection system put forth
by zhang and yau     that allowed us to produce phase maps from which very accurate range
information can be extracted 
part i  camera marker system
a single camera image does not provide
enough information on its own for a robot to
infer range information  although it is hard to
imagine  this is true as well in humans  while
humans utilize several methods of range
detection  motion parallax  the ability to see
how objects shift with respect to eye position 
requires multiple images  by introducing a laser
marker in place of a second image capture  we
essentially reduce the magnitude of the problem
of implementing a motion parallax in machines
for full images to one small subset equivalent to
a point in an image  while this is not ideal in
practice  it helps us to move in the right
direction if we find that this method gives
promising results 
a model for the experiment can be developed
by considering what happens when we shine a

figure  

filaser into the field of view  fov  of a camera  assuming the laser and camera are aligned  the
laser marker at some distance  depth  x enters the camera fov  assuming the fov grows
linearly with distance  then we can infer that the ratio of the distance between the marker and
center of the and the marker and the edge of the image will go as the inverse of this relationship 
since the image is discretized  the natural interpretation of this ratio is that of pixels per true
area  naturally  as a camera captures objects that are far away  less pixels are devoted to objects
in the distance than in the foreground  hence  the distance of the marker to the center of the
image can be expressed as 
 
xmar ker       
d
here d is the true distance from
the camera to the object the laser
shines on  and    and    are
learned parameters to be
determined by our learning
algorithm 
the experiment we carried out
was very simple  by bringing the
laser marker into the field of
view of the camera  image
subtraction can be used on two
images of the same scene  laser
on laser off  to determine the
approximate pixel position of
the laser in the image  our setup
for this experiment included one
camera  canon sub slr    mp 
  x physical zoom  and one
 green  laser pointer  both
camera and laser were fixed to a
wooden plank and placed on a
rolling cart  on each experiment
conducted  a fixed target was
chosen such that there was
ample range of motion away
from
this
target
while
maintaining equivalent lighting
conditions 

figure  

testing was conducted inside
for optimal lighting conditions
and  once this proved promising 
we moved outdoors to produce a
training set  in this outdoor
figure  

filocation  the laser pointer was projected onto an office chair placed between   and     ft away
from the camera laser setup at  ft intervals  the camera and laser were held fixed and the chair
was moved to ensure fixed alignment between the laser and camera   the camera was set at its
highest physical zoom level    x   figure   shows the training set produced using this procedure 
the data was fit using the above model utilizing the least squares method  least squares
guarantees the best fit in the sense that the error will be minimized  because we could infer the
model from our experimental setup  we are confident that this model gives accurate results for
regions not explored by the training set 
several distances were then chosen at random and utilized as a testing set  for the test set several
different types of materials were used as targets  with varying texture  color  and reflectivity  the
error produced by the test set  figure    is very reasonable for values up to    ft 
part ii  fringe projection system
our goal for the second part was to develop a system that could determine absolute range on all
points in an image at or near real time speeds  the work done by zhang provided just what we
were looking for  as he has demonstrated a system which maps  d into  d data in real time  this
system uses a fast camera with synced dlp projector to obtain three pictures of the same image
with three sinusoidal fringe patterns projected onto it by the dlp projector  we used three fringe
patterns  each offset by     degrees 
 
i     x  y       cos    x  y   
 
 
i     x  y       cos    x  y   

 
 
 
the parameters  and  are fixed coefficients that represent the average intensity and intensity
modulation  respectively  once the fringes projected images are captured  the effective phase
map can be retrieved as 
i   i  
   x  y    tan      
 
 i    i    i  
i     x  y       cos    x  y   

phase unwrapping is then used to obtain range measurements for each pixel in the image  we
were able to reproduce this simple system using a dlp projector and camera  we obtained three
fringe projected images and used these to obtain a phase map  figure     from here we knew that
phase unwrapping software is readily available to perform the phase map to range map
transformation 
one drawback that became evident during the testing process is that zhang et al only use their
system in optimal conditions  e g  a very dark room  so that the light from the dlp projector
alone provides a high enough snr for the fringe patterns to be easily captured on camera  as our
main project aim was to produce a range detection system for stair  we obviously needed
something that could work in sub optimal lighting conditions  e g  fluorescent lighting or  at
worst  sunlight   we tested the same system in sub optimal lighting conditions and  as expected 
received much worse results  see figure  a  

fiin order to raise the snr to an adequate level we
simply needed to produce more light in order to
overcome sources like fluorescent lighting and
sunlight  several methods were discussed 
including retrofitting a dlp projector with a
stronger light source or moving to the near infrared
spectrum  non overlapping with sunlight   the
latter idea received some attention  as light with at
         nm wavelength is absorbed by water
vapor  so there is almost no background sunlight at
this wavelength  likewise florescent  halogen  and
incandescent lights do not produce light in this area
of the spectrum  commercial infrared cameras
exist that are sensitive to these wavelengths of
light  conceptually  a system could operate and not
disturb surrounding people or have to compete
with background ambient lighting  while an
interesting vision  exploration and engineering of
this concept was not feasible in the time span
allotted by this class 

dlp projector in darkness
figure  

in short  several of these ideas were pursued  but with no engineering success  after running into
difficulty retrofitting a dlp projector with an alternate light source  halogen  hid  xenon  etc  
we decided to try the same idea on an overhead projector  which is much less sophisticated
technologically  in order to get the maximum light output we used a nikon sb     camera flash
synced with a nikon d   dslr  a custom opening was made for the flash so that it aligned
optimally with the mirror beneath the projection screen  a fringe patter was printed on a
transparency and moved manually for experiments 
results using this system were an all around success  figure  b   tests in fluorescent lighting
proved comparable to results for the dlp projector trials in absolute darkness  in addition  its
power costs are very low compared to the    w required for a dlp projector  and thus make it
suitable as an on board system for robots such as stair 

conclusions
dlp projector in fluorescent light
figure  a

flash dslr in fluorescent light
figure  b

ficonclusions
we have made some headway into the problem of reliable absolute range detection for
autonomous robots  as a first step  we developed a system that reliably predicts the distance of
one point in an image up to     ft away  next we worked on ways to extend this ability to
capture absolute range for all pixels in an image  fringe projection provided the basis for this
work and we successfully made headway into adapting zhang and yaus fringe projection
technique to situations with sub optimal lighting 
   david and giancarlo want to thank morgan and andrew for their constant support and
guidance
references
    luo  kenyon  kamper  et al  the effects of scene complexity  stereovision  and motion
parallax on sizeconstancy in a virtual environment  virtual reality conference        vr     
ieee 
    rauschecker  a  m   solomon  s  g     glennerster  a          stereo and motion parallax
cues in human  d vision  can they vanish without a trace  journal of vision                     
    zhang and yau  high resolution  real time  d absolute coordinate measurement based on a
phase shifting method  optics express  vol     issue    pp           

fi