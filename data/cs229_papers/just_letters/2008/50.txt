netflix movie rating prediction using enriched movie metadata
wei tu  chung wu  michael yu

   introduction
the netflix prize is a competition hosted by netflix  inc  to find a better algorithm for
predicting how a user would rate a new movie  netflix provides a test set consisting of over
    million ratings generated by over     thousand users on over    thousand movies to
use for training  because of its one million dollar prize  the netflix prize has drawn attention
from scientists and researchers across the world  bellkor in bigchaos  the team currently in
the lead  has published a series of papers documenting their approach  according to their
paper   improved neighborhood based collaborative filtering       recommender systems
use either of two strategies  content based approach and collaborative filtering  their team
has spent over two years perfecting their collaborative filtering algorithm  so we decided to
explore a content based approach 
since the netflix data set provides very little data for each movie    only its title  the ratings
from the users and the date of the ratings    we turned to the internet movie database    
for richer metadata  we also experimented with clustering sparser metadata like actors and
actresses  we then ran experiments on predicting ratings with and without the richer
metadata  we found that enriching that enriching our baseline collaborative filtering
approach with movie metadata only made a small improvement of      in the root mean
squared error  rmse  of our predictions 

   baseline setup
in order to predict user ratings  we viewed each user as a separate regression problem 
this allowed us to narrow down the data to a manageable size and to personalize our
predictions for each user  to learn the hypothesis for a single user u  we trained a support
vector regression machine  we created one training example for each movie m that u has
rated  the score   target value for a training example is u s rating of m  the features of the
training examples the ratings of movie m from each of the top        users  as ranked by
total number of ratings per user   this feature set  which does not include any movie
metadata  forms our baseline model 
    normalizing ratings

some users give higher or lower ratings on average than other users  the variance of a
user s ratings can also differ from user to user  to compensate for these differences  we
normalized every rating by first centering the mean of each user s ratings to   and then
dividing each rating by the standard deviation of that user s ratings  in other words  a
normalized rating is the number of standard deviations the rating is from user s mean 
after training a model and making predictions  we then transform the normalized rating
predictions back to a   to   scale  capping any ratings that fall outside this range 
using a radial basis function  rbf  kernel  we found that normalizing the ratings improved
the rmse of the baseline model by        using a linear kernel  normalization had almost
no effect  it increased the rmse of the baseline by       

fi   enriching netflix data with imdb metadata
we used a combination of tools           plus a lot of custom code to load the imdb data
into our mysql database  one challenge we faced was in mapping netflix dvd titles to
imdb entity names  the two databases use slightly different punctuations  abbreviations
and capitalizations  for foreign films  netflix also used translated english titles  while imdb
used original language titles transliterated into english  and since the basic unit of entity in
the netflix database is a dvd while the basic unit of entity in imdb is more abstract  e g  a
film or a tv episode   there are often no logical mapping for netflix entities like  friends 
season     we employed various heuristics to work around these issues  but the results are
still far from perfect 
    turning metadata into features

to turn the meta data into features  we took the  bag of words  approach  where our
vocabulary is a dictionary of all the genres  countries  languages  director writer actor
names that appeared at least   times among the movies the particular user has rated  each
word is a binary feature for a movie  for each movie that the user has rated  we a feature
to   if the corresponding word appears in the movie s metadata 

   clustering people in the imdb social graph
we were concerned about mapping each actor to a unique feature in the input vectors 
since the actor features are very sparsely populated  it can be rare for one actor to show
up more than once for a user s movie set  for example  if a user has seen and liked many
brad pitt movies  then the brad pitt feature is a good predictor of ratings  but if he has only
seen but also liked jackie chan and jet li only once each  we should still capture some
fondness for asian martial arts actors  even though there is no direct actor feature overlap 
similarly  we might predict that he will enjoy a movie with bruce lee  even though he has
never seen a bruce lee film  intuitively  then  if we could cluster jackie chan  jet li and
bruce lee together into the same feature  we can make better predictions for other films
with actors in the same cluster 
we found in the imdb data set a massive social graph of directors  writers  actors and
actresses working with each other over the span of more than a hundred years  if we build
a graph where the nodes are people  and draw an edge each time a pair of people worked
together on a movie  then this graph would have almost two million nodes with more than
    million edges  we decided to leverage this social graph to cluster people into groups 
whose members have all worked together with similar people  because there are so many
people  we first divided the people into four non exclusive groups    those who have
performed in the role of director  writer  actor or actress  note that even when we are
clustering only directors  we still leverage the entire graph and make use of their work
history with writers  actors and actresses 
    clustering people using k means

we used k means to cluster people  each entity to cluster is a person and his work history 
conceptually  it is a vector in n space  where n is the number of people in the dataset  the
i th element of the vector is the number of edges from this person to the i th person  we
normalize each vector to a norm of   
the  centroid  of a group of people is also a vector in n space  where the i th element

fistores the number of people in this group that have worked with the i th person 
intuitively  the i th element stores a  popularity  measure of the i th person in this
centroid  the centroid vector is also normalized to a norm of   
the difference function between a person and a centroid is simply the euclidean distance
between the two corresponding vectors  this distance measure awards those who have
worked with  popular  people in the centroid  and punishes those who have not  and those
who have worked with a lot with people that are not well represented in the centroid  it is
very effective at keeping the cluster sizes relatively even so that everyone does not simply
gravitate towards the same cluster 
there were about  k directors    k writers    k actresses and    k actors who have
worked on the netflix movies  for actors and actresses  we decided to only include people
who have worked on five movies or more  thus skipping one time actors who likely have no
predictive power in a user s rating  this reduced our number of actors and actresses down
to about   k and   k  respectively  we clustered each group into    clusters using   
iterations 
the cluster results tended to be intuitive  the director clusters were the most insightful 
for example  the pixar directors    john lasseter  brad bird and andrew stanton    fell into
one cluster  and popular entertainment machines like steven spielberg and george lucas
fell into another  clustering for actors and actresses  though  put most of the popular 
modern hollywood people into the same clusters  to more effectively separate that critical
group of people  we ran k means again on just the  famous  actors and actresses  and
found finer grained clusters  we used results from all six clusterings to build our feature
vectors 

   experiment setup
to measure the utility of movie metadata for predicting user ratings  we ran experiments
using three different models that differ only in their feature sets 
baseline model 
 the ratings of movie m from each of the top        users  as ranked by total
number of ratings per user  
unclustered metadata model 
 all features from the baseline model 
 the genre  language  countries  directors  actors  actresses  and writers for movie
m 
clustered metadata model 
 all features from the baseline model 
 the genre  language  and countries features from unclustered metadata model
 director clusters  actor clusters  actress clusters  hollywood actor clusters 
hollywood actress clusters  and writer clusters for movie m 
we used libsvm to train our svm      libsvm is a widely used svm library that provides
many useful features  such as support for common kernels  cross validation  and automatic
parameter selection  after some initial experimentation  we found the linear kernel yielded
the best performance  so  we used a linear kernel and a regularization parameter of c     
due to time and machine resource constraints  we trained hypotheses for      randomly

fiselected users out of     thousand users total  for each user  we split the data into two
equally sized sets  one for training and one for testing  we trained hypotheses using each
of the three models mentioned above and computed the average rmse of each model over
the      users  we also computed the rmse of a simplistic hypothesis function that always
outputs the average rating that all users have given to a movie 

   experimental results
the following table contains the observed rmse on our test sets for the      random users 
model
rmse

always avg  rating
       

baseline unclustered

clustered

               

       

our baseline model achieved an rmse that was within    of the rmse achieved by netflix s
cinematch system  despite using only half of the available training data  adding movie
metadata to the model yielded very little improvement in the rmse  however  the
unclustered metadata model decreased the rmse by less than       over our baseline 
clustering the metadata did appear to be somewhat effective  but the overall improvement
was only       over our baseline 
the following chart shows the absolute change in rmse from the baseline using the
clustered and unclustered metadata models vs  the size of the training set 

the clustered metadata model tends to have a significant effect on the rmse  both positive
and negative  for a larger number of users compared to the unclustered metadata model 
this makes sense  as the unclustered features are more sparse  both metadata models

fiappear to significantly increase the rmse for users with a very high number of ratings  for
these users  the test error was significantly higher than the training error  which suggests
overfitting 
   future work
there are several potential improvements we could make to our recommender system that
do not depend on how movie metadata is used  we found that the rmse was higher on
average for users that had very few movie ratings  under      for these users  we could
try to cluster them with more prolific users and use the movies these prolific users rated as
training examples  effectively increasing our training set  this will also help our algorithm
scale better  we would only need to train a model for each cluster of users that have similar
taste instead of a model for each individual user  making it more feasible to cover all    k
users in the test set using a reasonable amount of resources 
along the same lines  if we can calculate the distance between users based on taste  we
could use the ratings from the users that are most similar to the user we are training the
model for as features  the ratings from these users may be more predictive than the
ratings from the top   k most prolific users  which we are currently using 
we also feel there are many improvements possible for our clustering distance function  for
example  one goal would be to try to end up with small sized clusters of highly influential
people and large sized clusters of less significant people  the clusters could be leveraged to
fill in the gaps in similarity in less popular people while still allowing very popular people
that are in most users  data sets to have maximal influence 
finally  even though that our experiment showed that the metadata we ve collected does
not improve the quality of the recommendation engine significantly  we are still optimistic
that some metadata will  one interesting experiment to try is to build another vocabulary
of movie s plot keywords and add those as features 

   references
    r  m  bell and y  koren   improved neighborhood based collaborative filtering   proc 
kdd  cup and workshop at the   th acm sigkdd international conference on
knowledge discovery and data mining       
    internet movie database  at http   www imdb com
    internet movie database plain data files  retrieved on november   th       
at http   www imdb com interfaces plain
    col needham s command line search tool for the internet movie database  retrieved
on november   th        at http   www imdb com interfaces unix
    imdbpy      a python interface to imdb data  retrieved on november   th       
at http   imdbpy sourceforge net 
    chih chung chang and chih jen lin  libsvm   a library for support vector machines 
      software available at http   www csie ntu edu tw  cjlin libsvm

fi