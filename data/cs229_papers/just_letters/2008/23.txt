using mean shift for video image segmentation
joel darnauer
joeld stanford edu
            
abstract

produced in a causal manner  that is  only the information
in prior frames can be used to assign a label to a object 

the goal of this project was to develop a fast video image
segmentation routine which could be used as a preprocessing step for motion tracking  we chose mean shift
    as the primary algorithm  our implementation includes
several enhancements including dynamically adjusting the
kernel bandwidth based on the overall level of image noise 
and keeping a cache of past moves to avoid repeated
computations 
the frame rate of the resulting
implementation is still slow due to the quadratic
complextity and iterative nature of the underlying
algorithm  but provides a reasonable starting point for
refinements  we conclude with a discussion of several
limitations of the mean shift as a procedure for image
segmentation and present a couple options for
improvement 

once this basic labeling is produced it should be possible to
produce segmented video with diagnostic output showing
motions of segments  higher level algorithms could build
upon this system to find intersections between segements an
track multi segment objects 
an alternative formalation of the segmentation problem
presented in     is to consider image space as a  dimensional regular graph between neighboring pixels in
x y t 
the image segmentation problem consists of
selecting edges in the graph which connect segments  or
additionally of finding a spanning forest of the image graph 
this interpretation will be important for some of our later
optimizations 
having considered the format of the output  we must now
turn our attention to the properties of the labeling or
spanning forest produced 

general problem formulation

image segmentation is an important low level task in
computer vision  as we saw in the homework the k means
algorithm can be used to compress an image into a reduced
color space that approximately represents the original
image  a robust segmentation could be the first stage in a
object tracking pipeline  and in some ways represents a dual
approach to the more common approach of tracking corner
features 

intuitively we want pixels to be labeled in the same
segment if they correspond to the same shaded object from
frame to frame  while subjective pixels in the same
segment should have the following features 


they are spatially contiguous within the same
frame 



should be of similar color  with possible gradients
due to lighting  and optionally texture  



between frames there is a simple model of
perspective like transformations which explain the
trajectory of the  d surface for the segment  with
allowances for deformation  occlusion and camera
motion 

in the nomenclature of the class  the set of training
examples x is x i  pos x  pos y  t  r  g  b   additional
features could be computed  such as converting the color
space from rgb to hsv or other transformations  



a more complicated algorithm might include
terms to compensate for global lighting
fluctuations  flashing lights  camera exposure
changes  etc  

in our case we know that each frame covers pos x and
pos y  which may lead to some interesting optimizations 



a very sophisticated algorithm might include
processing to account for motion blur 

informally  we define the video image segmentation
problem as follows 

input 
a set of f input frames containing w x h rgb pixels 

due to time limitations in the project we were only able to
process frames individually  so the t dimension will be
ignored for now 

a number of these features are beyond the scope of this
class  for this class we will focus initially on the first
problem of segmenting a still image 

output 
a labeling of each pixel in each frame to a segment id  in
a real time algorithm the labeling of segments should be

 

fithe mean shift paradigm
comaniciu     use the mean shift algorithm for image
segmentation  unlike k means which might use a straight
distance metric to assign pixels to a pre defined number of
clusters  the mean shift associates each pixel or feature with
some local maximum in the feature density of feature space 
feature density is computed by convolving each feature
in x with a kernel function  typically multivariate gaussian 
the mean shift procedure performs gradient ascent in this
feature density space  so each feature is associated with the
point which is the attractor for the local basin of attraction
that the feature resides in 

figure    a discontinuity in the previous patch produces a
dip in the density function which pushes points away from
the edge  because the features are uniformly dense in x y 
the mean shift operator can be thought of as a edge
detector with a resolution determined by the spatial radius
of the kernel 

but why is this a good choice  consider an input image
which consists of a gray patch with a uniform gradient in
the x dimension from light to dark  a human viewer would
attribute this gradient to some natural lighting variation and
would associate all of the pixels in the patch with the same
object  however pixels on the far left and far right of the
patch have relatively large differences in color and spatial
feature dimensions  so a nave distance function might
classify these pixels to different features  we need a way to
unify these pixels based on the information between them 

so the basic mean shift operation is like edge detection and
importantly is stationary for patches with a uniform first
derivative 
the world view of mean shift in some ways is like mixture
of gaussians  in that the modes of the feature density
function are like the centers of the gaussian sources in
mog  the main difference is that the attractors in mog
can be very complex in shape  later we will see that there
are limitations to this view of the problem 

mean shift accomplishes this because in the gradient
example above  the features form a uniform patch in the  dimensional feature space  if the kernel function has a
sufficiently large aperature the maximum of the density will
be at the center of the patch   figure    

mean shift procedure and complexity
the general mean shift procedure for a feature x i procedes
as follows 

figure    blue dots are points in a simplified   d feature
space where the vertical axis represents color and the
horizontal axis represents space  in this case the points
form a uniform gradient like the gray patch in the example 
if the kernel function is wider than the patch  the center of
the patch will be attractor  if the kernel function has a
finite radius r then all the points which are further than r
from the edge will have the same local density  and will
therefore be stationary 

  

for each feature in x j in x  compute the distance
d j   x j  x i

  

apply the kernel function k   to each d j to
compute the weight for that feature 
w j   k d j 

  

compute a new x i  

  

repeat step   with the new x i until  x i x i  is
within some tolerance delta 

j w j x j   j w j

at each update the x i is a weighted sum of the x i  this
procedure is guaranteed to converge as long as the kernel
function k   is monotonically decreasing and convex 
typical kernels are guassian functions with some variance
assigned to each dimension 
two major difficulties with mean shift include the problem
that the basic computation of the kernel distances are o n  
in the size of features  and that the number of iterations
required is input dependent  the first advantage can be
addressed by choosing a kernel that decays rapidly in
certain dimensions  in practice the number of iterations for
images is roughly constant and depends on the tolerance
used  among other features 

 

fiif the kernel function used has a finite radius r  then the
complexity is more like o n r  i  where i is the mean
number of iterations needed for convergence 

post processing steps
once the mean shift procedure is performed we have
associated each pixel with an attractor  especially in the
case of small kernel width r  many points in flat patches
will be stationary and should be associated with each other 
a post processing step is done to merge all   connected
clusters of attractors and then points are labeled with the ids
of these superclusters  further postprocessing operations
like removing clusters below a certain size or minimum
with could be performed at this point  but we avoided this
to see the naked performance of the algorithm 
figure    same sequence of operations on a real webcam
image 

the pipeline
the steps in the processing pipeline in our implementation
can be seen in figure   and    this sequence uses a
guassian kernel truncated at r   with some of the
optimizations described below 

noise optimization
one very important feature of the work was building a
routine which could generate several abitrary test images 
we included a feature that allowed us to add noise to the
images and noticed that the vanilla gaussian kernel
produced rather poor results because it assigned too much
significance to these small fluctuations  especially in large
flat spots 

regular gaussian

flat spot ignores noise

figure    one improvement over the original mean shift
algorithm was to discount small difference in color as being
insignificant  the normal guassian kernel in color space is
replaced with one with a flat spot whose width depends on
the pixel to pixel variances thoughout the source image 
figure    processing pipeline for a test image sequence 
original test image  upper left   attractors labeled with
brightness in the color of the source image  upper right  
attractors labeled with the super cluster after merging
 lower left   final segmented image  lower right   some
artifacts are visible in this segmentation due to limitations
of the algorithm 
figure    result of the adaptive noise threshold  left image
is the standard guassian kernel  right image is with the
optimization 

 

fifuture directions

we experimented with several kernels including faster ones
such as   d      d and k d  all performed similarly  but we
used the guassian kernel for most of our evaluation because
it is more common and the performance difference were
slight 

there are several interesting directions the project could
take from here 


there are a number of parameters in the algorithm
which much be manually tweaked  which is quite
unsatisfying  it would be better pehaps to use the
test image procedure to create images with a
known ground truth and then use supervised
learning to create the images  if this is done  other
algorithms such as svn could be applied to the
problem directly  which might produce much
better results 



instead of trying label pixels or edges  the real
problem is perhaps better formulated as finding the
set of shaded polygons which are most likely to
have generated the source image  im not sure
what the parameter space of such an algorithm
might look like  but it could also use the
supervised learning approach  training on cg
images from video games and movies 

optimizing r
since the inner loop depends quadratically on the kernel
radius r  it is important to understand what value of r is
necessary  figure    last page  shows a sweep of some
images with different values of r  generally a value of
r   or r   produced reasonable results for our webcam
images 
optimizing i
since the mean shift computation moves features to a basin
of attraction  we reasoned that many of these moves are
likely to collect into streams and that it might be possible to
speed up the computation by creating a move cache for the
image  at each step of the mean shift  the cache is
consulted and if the current feature position is within some
distance d from one in the cache  we substitute the stored
move  the cache is efficient because we store only one
move for each xy position  reasoning that colors along a
trajectory are likely to be similar 

if you have any interest or advice  please contact me at
joeld stanford edu or call me at              

there is a slight speedup from this approach because we are
able to match about     of moves without noticable
changes in image quality  the amount of additional storing
and branching slows the algorithm down though  so the
overall performance gain is only about     
one interesting side effect of this is that the moves tend to
be from neighboring pixel to neighboring pixel  so the
result is to build up a graph of associations between pixels
much like that in     

references

   dorin comaniciu and peter meer  mean shift  a
robust approach toward feature space analysis 
ieee trans pattern analysis and machine intelligence 
     

overall performance
the frame rate of the overall performance is about
    msec     fps  on    x    pixel images for a kernel
radius of   and about   iterations per pixel  the actual rate
is image dependent  but corresponds to an inner loop time
 computing the distance and kernel weights for each pixel 
of about   nsec  since a call to exp   on my machine takes
about   nsec  this seems like reasonable performance 
more work is needed to improve the inner loop time 

   d  comaniciu  v  ramesh  and p  meer   kernel based
object tracking   ieee trans  pattern anal  machine
intell   vol      pp                 
   pedro f  felzenszwalb and daniel p  huttenlocher
international journal of computer vision  volume    
number    september     

 

fifigure    selection of kernel radius r  here labeled w  and its effect on segmentation in test and real images  if w is too
small  there is insufficient separation between clusters and bleedthrough defects are common 

 

fi