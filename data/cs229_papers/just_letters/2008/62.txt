detection and extraction of events from emails
shashank senapaty
department of computer science
stanford university  stanford ca
senapaty cs stanford edu
december         

abstract

dar quickly  in the example shown in figure    while
gmail does make a suggestion to add to calendar it
i build a system to detect emails that are inform  is unable to extract the date  time or venue in this
ing the reader of an event and automatically extract particular case  as shown later the system presented
structured information describing the event such as here does accurately extract this information for this
the title  date  time and venue of the event using example  the goal of this project is to explore how
various machine learning and natural language pro  well we can solve this problem and whether a robust
cessing techniques  such a system if run on an email reliable system can be built that in most cases will
client can be used to alert the user of events he she firstly detect that the email is about an event and secmay be interested in  and either automatically add ondly extract the correct information for the event 
the event to the users calendar or facilitate one click
add since the system would have automatically ex    problem definition
tracted attributes describing the event 

 
   

this problem comprises of two parts  the first part
is a classification problem where we decide whether
an email contains information about an event or not 
if the email is in fact an event email  the second part
of the problems can be characterized as an information extraction task where we determine structured
information of the event from unstructured text  in
this system  i attempt to extract the following attributes  title  venue  date  start time  and end time
if available 
there are some inherent amiguities in both parts 
for the classification task  it may not necessarily be
clear whether an email should get classified as an
event email  for example  an email that informs of
a deadline  such as for submitting an application  is
not strictly an event that can be attended but still
maybe something you want added to your calendar 
i have considered such a case not to be an event and
thus the system here attempts to classify this as a

introduction
motivation

many of us get a large volume of email hitting our inbox especially from a variety of mailing lists that one
may be subscribed to  we may be receiving emails on
certain mailing lists about events that may interest
us such as recruting events  talks  and other social
events and it would be convenient if we could add
the event with one click instead of opening up the
calendar and manually entering the title  date  time
and venue  indeed  gmail already has such a feature
where it suggests a one click add to a users calendar
in certain cases  figure     but it is observed that
in many cases gmail does not provide such a suggestion even when the email contains event information
and the user would like to add it to his her calen 

fifigure    gmail gives an option to add to calendar when it detects an event 
negative example  corresponding to non events   in
general  i have used my judgement in resolving such
ambiguities by using the general narrow definition of
an event as something that you would attend like a
talk or a social gathering 
for the information extraction task  it is obviously
upto a persons judgement what exactly qualifies as
the title of an event  therefore  in such cases i use an
evaluation metric that reasonably captures whether
the system is correct  for example  using exact string
comparison would be completely unreasonable  i instead use a metric that captures the similarity between the strings but is more accomodating  details
about the metrics used for evaluation are in section
     for the time attribute of an event  however  the
system must understand the semantics of the value
and identify an exact time point so that the event can
be added to the calendar appropriately  therefore  in
this case the system is evaluated on the actual time
value inferred  for example   pm      pm      
pm       and       hrs must all be inferred as
the time      pm 

   

ever  accurately predict which of the two dates is the
actual date of the event  similarly  an email can contain both start and end times and other irrrelevant
times  and the system must accurately predict which
is the start time and which is the end time of the
event  for this it is necessary to rely on contextual
clues and careful and thoughtful feature selection is
necessary  moreover  it can be quite hard to discern
the venue of an event because in many cases there
may not be contexual information aiding in detecting the venue  figure   illustrates this also where
the venue nec auditorium  gates computer science building b   is simply written alone and not
in the context of a sentence  in general  this line may
just say gates b   and the system has the task of
knowing that it is a venue 

   

approach

figure   shows the system design for the whole system  for the information extraction task  i used a
maximum entropy markov model  memm   which
combines a maximum entropy classifier       with a
viterbi decoder  this is a popular algorithm for performing information extraction in the field of natural
language processing  however  since training data
was not plentiful  this requires careful feature engi 

challenges

as seen in the example in figure    there are actually
two dates in the email body  the system must  how 

fineering to avoid the sparseness problem  the algorithm is described in more detail in section     
for the event email classification task  i tried
the naive bayes multinomial event model using
a specialized tokenization of the input  this tokenization used special tokens like month  time 
date to replace months  times and dates respectively in addition to basic tokens like httpaddr 
emailaddr  and number to replace urls  email
addresses  and numbers  while this algorithm has
certain shortcomings for the task at hand  particularly the fact that it doesnt capture the sequence
structure of the text  such as if we used bigrams or
trigrams   it still serves well as a baseline since it is an
algorithm known to perform well for a text classification task  i later provided some suggestions on how
performance on the event email classification task can
be improved even though i did not get to implementing it myself 

ing their role  i e   the relevant parts of the email
have to be tagged as corresponding to the title 
venue  date  start time  end time of the
email  this was done for each positive example in
the dataset using the stanford javanlp  document
annotation tool 

 

section     describes the memm model that is at
the core of the information extraction system  thereafter  section     discusses the overall system design
for the information extraction task  section     discusses the features used in the memm classifiers 
section     discusses the evaluation metric for the information extraction task and finally section     discusses the implications of certain choices regarding
system design and features 

   

the model

the memm classifier assigns to each token in an
email one of several labels classes corresponding to
the attributes of interest  the labels in this case
are  title  venue  date  start time  end
time  other  in this model  we therefore model
the conditional probability of a token having one of
these six labels given the features associated with the
token  for each token in the email  features are computed based on the token itself  the neighboring tokens  and the label of the previous token  the conditional probability of a class for a particular token
is modelled as a linear combination of the features
combined via a softmax function  there is a weight
associated with each feature class pair and these are
the parameters of the model  formally  the conditional probability of a class for a token d and a set of
features fj is modelled as 

figure    system design 

 

information extraction

dataset

the dataset was formed using emails sent to
mscs cs stanford edu mailing list      emails were
manually labelled as positive and negative examples
exp i t x 
p  y   i x      p
corresponding to event emails and non event emails 
t
j exp j x 
the dataset was divided into a training set of    
examples and a test set of    examples 
the objective function is the negative log likelimoreover  the memm approach used for informahood of the data and the weights are learned to
tion extraction  described in section    requires each
  http   nlp stanford edu software tagger shtml
token in the emails to be tagged with tags describ 

fi   

minimize this objective function using gradient descent  given a test email  instead of labelling each
token to maximize conditional likelihood individually 
a viterbi decoder is used to label the tokens in the
email so as to maximize the joint likelihood of the
email 

   

features

the current word  contexual features like the previous and next words  the label of the previous word 
and orthographic features were used as features  a
special feature that checked if the word represented
a month was used  specialized orthographic features
were also used to dectect dates and times 

system design
   

figure   shows the system design for the information extraction system  two memm classifiers are
used  one for the subject and one for the body of the
email  because the subject and body have very different structure  further motivation for this decision is
in section      the two classifiers are trained on the
subjects and bodies of the emails in the training set
respectively  given a new email  the two classifiers
label the subject and body of the email  for extracting the value of an attribute  all candidates labelled
with that particular label are considered  and one of
the values is chosen based on the probabilites associated with each of them  however  if a candidate for
an attribute is available from the subject this is always preferred over a candidate from the body since
we expect the subject to have more of this important
information 

evaluation metric

for date  start time  and end time exact symantic
value are inferred by the system and as such the extracted value is taken to be correct if it matches exactly the semantic value of the gold standard  for
example  all of  pm      pm       pm must be
inferred as the time       hrs  for the title and venue 
an exact string match is not reasonable because even
humans cannot agree on what should be the exact title in many cases  therefore  these values are marked
correct based on a recall type measure  r measure 
and precision type measure  p measure   the rmeasure is defined as the fraction of words in the gold
standard that are present in the extracted value and
the p measure is defined as the fraction of words in
the extracted value that are present in the gold standard  if both r measure and p measure thresholds
are met for a particular value  only then is it marked
correct  the used r and p thresholds for title were
           and for venue it was             it should
be noted that the final algorithm used is not very
sensitive to these thresholds  particularly for venue 
because the precision of the extracted values are very
high  this is discussed further in section   

   

design and feature analysis

the decision to use two different memm classifier 
one for subject and one for body  was made because
the subject and body have very different structure
and typically contain different attributes  the subject typically contains important information perfigure    system design for the information extractaining to the attributes we are interested in whereas
tion system 
the body contains a lot of irrelevant information and
noise  the difference is clear when we compare the
 

fi 

features learnt for the subject and body classifier  tables   and    
label
title

feature
initcaps

venue

word gates

date

prev label date

the naive bayes multinomial event model was implemented using the tokenization mentioned previously  this achieved a test set error of     percent 
the error is as high as it is because this is a simple bag
of words approach and does not capture the structure
of the data like contextual information  however  for
this application it is not necessary for this classification to be perfect  in particular  even if we are only
mildly confident that the email contains an event 
we can run the information extraction system on the
email and show the one click add option to the user 
if the email does not contain an event the user simply
ignores it but if it does indeed contain an event then
we have served the purpose of the system since the
user can enjoy one click add 
moreover  on exploring this issue more  it seems
like it might be prudent to run the memm classifier
on the email first  using inputs from the output of
the information extraction system  such as confidence
in predictions etc   we can make a much better judgement of whether the email is about an event  this is
likely to work much better since the memm classifier
captures the true structure of the data  we can use
the output of the memm classifiers as features for a
logistic regression algorithm for example 

description
starts
with
capital letter
word
is
gates
label of previous word is
date

table    highly weighted features after training for
subject classifier 

label
title

feature
prev label title

title

nextword ee

title

initcaps

venue

prev label venue

venue

prevword in

date

month

date

prev word  

start time

prev word from

event email classification

description
label of previous word is title 
next word is
ee
starts
with
capital letter
label of previous word is
venue 
previous word
is in
word
represents a month 
 e g  nov  
previous word
is  
previous word
is from 
next word is
p m

 

results

the final results obtained are shown in table    it
can be the seen that the precision is perfect for each
attribute and this is desirable since we certainly do
table    highly weighted features after training for not want to extract wrong information for any atbody classifier 
tribute  rather the system should leave this attribute
blank  therefore  it is desirable that failures in the
note that contextual features turn out to be useful  system hurt the recall numbers rather than the precifor example  one of the most highly weighted features sion numbers and this is the case here  two examples
for venue in the body classifier is that the previous of the results obtained are shown in figures   and   
word is in  the feature that detects months is a
valuable feature for date  also  using a viterbi decoder instead of a greedy decoder to label allows us  
conclusion
to take into account the previous label as a feature 
which turns out to be useful in many cases as can be the system here is a fairly good system to extract
seen from tables   and   
various attributes of events from emails  with minor
end time

nextword p m

 

fifigure    example result 

figure    example result 

 

filabel
title
venue
date
start time
end time

recall
   
    
    
    
    

precision
   
   
   
   
   

f 
   
    
   
    
    

table    recall  precision and f  using only body
classifier
refinements  such as better tokenization  word stemming and such basic nlp techniques the performance
on certain attributes can be increased  the recall for
the venue is a bit low at       this is partly because
in many cases there is not enough contextual information surrounding the venue as mentioned previously 
in this case we must rely on having seen the word
such as gates or packard before  this problem
can be fixed by increasing the training size to a more
representative set or by building a corpus of locations 

 

acknowledgement

some of the code for the implementation of the
memm classifiers was taken from partial code provided for stanfords cs    n course  the javanlp
annotation tool by the stanford nlp group was useful in annotating the dataset 

 

references

   jurafsky  d  and martin  j h        speech and
language processing  an introduction to natural language processing  computational linguistics and speech recognition  second edition  prentice hall 
   ion muslea        extraction patterns for information extraction tasks  a survey
   adwait ratnaparkhi  a simple introduction to
maximum entropy models for natural language
processing  technical report        institute
for research in cognitive science  university of
pennsylvania 

 

fi