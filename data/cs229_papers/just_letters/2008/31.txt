robot grasping with optical proximity sensors
min young kim  dookun park  and jaewon yang
stanford university
 minykim  dkpark  crucis  stanford edu

   introduction

grasping is a basic and important problem in
robotic manipulation  and sensing the object
geometry is important for reliable grasping
action  in this project  we implement an object
grasping system  basically  we use wam
robot arm and barrett robot hand for objects
grasping  there are optical proximity sensors
on each fingertips of the robot hand and we
use the optical sensors for pre touch pose
estimation  there is an existing algorithm  but
we use different learning methods to improve
the object geometry recognition and finally
enhance the performance of grasping action 
   data

we receive input data from    sensors
attached on the fingertips  the robot has  
fingers and each finger has   sensors  input
data consists of    sub values  the meaning
of these values will be described in the
following section  outputs which we should
estimate are the geometrical configuration of
the surface of the object from each finger 
distance and two angles which depict the tilt of
the surface  output consists of   values 
   regression models

we measure xr   from four optical sensors
mounted on the finger tips of stair   first
 

four readings are made without emission of
light and then sensors emit by turns  when a
sensor radiates  not only the emitting sensor
but all the others measure light  this is called
crosstalk 
given the sensor reading x  our job is to
estimate yr  that consists of the distance
from the object to the finger and two angles
specifying the orientation of the object  we use
a bayesian polynomial regression model  high
order polynomials is necessary in order to
address nonlinearity between x and y  and a
bayesian approach would keep our model
from over fitting 
   robot control
wamarm stair   and barretthand

the robot we use is wamarm  stair   in a i 
lab  we also have barrett hand for grasping
simulation and the hand is attached on the
end effecter of stair   controllers for
manipulating these robots are already
implemented by stanford a i  lab  however  a
force sensor has recently been added to
stair  and we needed to change
configuration by figuring out the mass  the
position of the center of mass and value of d
parameter for dh table using btdiag controller
which is the old version  the values we figured
out are as follows 

fibarretthand mass        kg 
barretthand centermass                    
dh param d          
 values are obtained by trial and error 

to get started with the project we needed
to download and install ros for manipulating
stair   there should be roughly  gb spaces
for installation both ros and stair project
and stair project consists of at least four
programs newcontroller  relay server hack 
xwam  and irstreamer 
after all installation  it is necessary to run
both of wamarm  stair   and barretthand 
and test the basic movement of them 
stair  manipulation

the operation system that we used is called
ros robot operating system      since the
existing controls and related programs run on
ros  we needed to make sure if ros and all
ros related packages had been accurately
configured  though  in the middle of the
project  ros did not work so we had to
completely re install ros 

figure    process of stair  manipulation

we manipulated barretthand with a
 

controller called newcontrol in wam 
machine  there is another program called
irstreamer  it takes serial input and sends
the data to the controller  we used the
irstreamer to collect sensors reading  apply
our model  and finally map the result data from
the regression into certain variable which
would be used for actual grasping  at last but
not least  we used grasping program to run
stair  
however  since newcontrol runs on
wam  machine and the others run on smartwing machine  theres a need to use socket
for communicating within machines  relayserverhack is used on wam  machine for
these communications  all programs need to
be executed in a right order 
because there was no document for
instructions to run these programs  we spent
quite a big amount of time to make things right 
wed finally succeeded to run all programs
and started to create a new version of
irstreamer for applying our regression model 
the new program is called irnewmodelmin
and we did not use calibration parameters
calculated by the previous researcher  after
getting distances from the model  we mapped
the distances to the desired value which would
then be used for grasping  the desired values
were ranged from   to      if the desired value
is    it means the finger is located far from the
object  on the other hand      means that
the finger is very close to the object  we used
a linear mapping which maps     centimeters
to value     and     centimeters to value   
desired values worked as a measurement
while deciding future movement of each finger 
we basically used grasping program to
simulate stair   and tuned the program to

fiproperly fit our model into stair  

figure    errors vs  order of polynomial

   results

    
cv error
training error

    

preliminary result with previous data

    

    
cv error
training error

    
    

  of the norm of y 

  
    
    
    
    
  
    

 

 

 

 

 
 
 
the order of polynomial

 

  

  

    
  of the norm of y 

during the first a few weeks  we performed
regression based on the dataset that hsiao
collected about a grey box during this summer 
we could not gather a new training set
because stair  has been under
reconfiguration 
we first verified the relevance of input
features because in hsia et al      the authors
argued that all but three attributes of x are
meaningless  as a quick measurement  we
calculated the correlation coefficient of each xi
and yj  and the probability that xi and yj have
no correlation  surprisingly  any x and y
showed a correlation coefficient about      and
the probability of no correlation was   in any
case  therefore  we decided to include all the
features  we found suitable model and
estimate a generalization error of our model by
a cross validation  cv  test 
furthermore  we concluded that the
previous datasets are not trustworthy  after we
enable stair  move again  we tested our
model on a real gray box to verify the integrity
of training data  however  this test showed
more than     errors  which was abnormally
higher than cv errors 

    
    
  
    
    
    

   

  

  

  

  
  
regularization coefficient

  

  

figure
figure    errors vs  regularization parameter

result with new training sets

figure    measurement tool for data collection

we collected training data with a black box
and a wooden box  we did not choose brighter
objects because the sensors are saturated too
often with bright objects  we varied the
distance from  mm to   mm  and the angles
from    to      later  we included in the
training set the case that the finger is normal
to the surface because we observed that this
case happens often in reality 
after gathering a training set  we performed
regression  choosing model parameters by a
cv test  we tested our model with various
object  our model estimates the distance
within     errors when the surface has similar
color and reflectivity compared to the objects
over which we trained 

fithe shortcoming of current configuration is
that it cannot detect the reflectivity of the
surface  which is crucial in accurate estimation 
indeed  our model estimated distance shorter
than the real value when we tested over bright
or reflective objects  it turned out  however 
that the relative  not absolute  distances
between each finger and the surface are used
in the control program of stair   therefore 
we could handle this shortcoming by choosing
 th polynomial model that showed monotone
decrease between sensor readings and the
estimates 
grasping test for several objects

 a  wood cube

 b  adapter

 c  paper box

 d  green bowl
figure 
figure   tested objects

all objects used for data collection and some
other objects are used in simulation  a black
box  laptop adapter  and wood cube are the
objects used for data and barretthand resulted
in grasping these objects with accurate
probing  a green bowl  blue stripped white
bowl  and brown paper box were the new
objects and barretthand grasped green bowl
and paper box with high accuracy but
barretthand failed to grasp blue stripped with
bowl  it is convincing that the reason would be
 

at reflection rate on the surface of the object 
when the reflection rate is too high  such as
white color  sensor values are too high to
result in feasible data  overall grasping rate of
our model for those different objects was
           succeeded out of    trials  
   discussion

having succeeded to grasp objects is
noticeable result  though theres some
shortcoming with barretthand itself and
objects to be grasped  one thing is that due to
limited freedom in finger movements  some
objects are very hard to grasp 
with the current configuration of sensors  a
regression model cannot estimate the distance
with high accuracy for different kinds of
surfaces  given sensor readings at one point 
it is impossible to determine the reflectivity of
the surface  we will be addressed this
shortcoming by combining sensor readings
from various points  for example  we can
watch how much sensor readings increase as
fingers approaches to the object  and
determine the reflectivity based on the
observations 
one of the alternative solutions is to use
different type of sensors whose signal
relatively independent from reflection rates of
the surface  then we can get much better
results when testing with unknown objects 
issues occurred during the project and
suggestions

network in gates building sometimes failed 
since the overall system is based on many
programs running on different computers 
network failure definitely had slowed down the
project 
i 

fifinger tip parts can be easily detached from
the hand with a small screw driver and it was
convenient to do that when collecting data 
when proximity sensor values seem to be
weird  it is highly recommended to reset the
sensor power 
the   th values of    inputs of the finer
two f   seems not reliable 
when the robot arm of stair  seems to be
weird and the joint movement is not smooth  it
is probably the problem of wam   not of the
arm  it is recommended to restart wam  and
try your job again 
since  btdiag  program was initially
designed for the basic diagnosis of the robot
arm  it is one of the most stable program for
the robot arm  running  btdiag  program can
be a good start point if the robot have stopped
urgently 
it is highly recommended not to assume
anything would be naturally working  what you
really assumed fine can be a key point of your
problem 
ii 
ii 

iii 
iii 

iv 
iv 

v 

vi 

vii 
vii 

   references

    k  hsiao  p  nangeroni  m  huber  a 
saxena  and a  y  ng  grasping using optical
proximity sensors 
    robot operating system wiki
http   pr willowgarage com wiki ros

 

fi