scalable object recognition using support vector machines
david chen  mina makar  shang hsuan tsai
 dmchen  mamakar  sstsai  stanford edu
abstract
automatic recognition of objects in images now typically relies on
robust local image features  for scalable search through a large
database  image features are quantized using a scalable vocabulary
tree  svt  which forms a large visual dictionary  in this project  we
design support vector machine  svm  classifiers for tree histograms
calculated from svt quantization  we explore several practical kernels that naturally capture the statistics of image features  a baseline
naive bayes classifier for tree histograms is also created for comparison  after naive bayes or svm classification  we further perform
a geometric verification step to avoid false positive matches  using
either affine or scale consistency check  the naive bayes and svm
classifiers and the geometric verification algorithms are tested on two
real image databases with challenging image distortions 
   introduction
automatic recognition of objects in images enables a wide variety
of computer assisted activities  such as building recognition for a
virtual outdoors guide      artwork recognition for a virtual museum guide      and cd cover recognition for comparison shopping
and music sampling      the accuracy of object recognition has
improved significantly with the invention of robust local features 
among the most popular feature types are the scale invariant feature transform  sift      and speeded up robust features  surf 
     in each case  local features are extracted from an image by    
searching for stable keypoints in a multi resolution scale space and
    calculating a distinctive descriptor  or a high dimensional vector 
from a histogram of gradients in a local patch around each keypoint 

 a 

 b 

 c 
fig      a  part of a cd cover with surf features   b  another view
of the cd cover   c  matching surf features between  a  and  b  

fig     cd cover recognition using a mobile phone 

fig    a   b  shows surf features overlaid on top of two images  which capture two different views of part of a cd cover  the
various features exist at different scales and orientations corresponding to the natural characteristics of this cd cover image  despite the
viewpoint change  many common features are found in both images
and can be reliably matched  as depicted in fig    c  
given a query image  pairwise image matching with every image
in the database is an accurate but extremely slow search process 
especially if the database size is large  in cd cover recognition on
a mobile phone  as depicted in fig     a mobile phone captures a
picture of a cd cover and transmits the query image or features to a
server  the server must quickly search through a large database with
thousands to millions of cd cover images and return the identity of
the query cd cover  since the user expects a response within a few
seconds  the slow pairwise matching would be unacceptable 
an effective solution for search through large image databases
is to quantize the feature descriptors using a scalable vocabulary tree
 svt       the svt is constructed by hierarchical k means clustering of feature descriptors  the nodes of the tree can be interpreted as
a visual dictionary  analogous to a dictionary used for text classification  after quantizing each feature descriptor to the nearest nodes in
the svt  a feature set is efficiently summarized by a tree histogram 
expressing how often each tree node is visited  the compactness
of the tree histogram is the reason why svts enable fast searches
through large databases 
treating the tree histogram itself as a high dimensional feature
vector  we can consider maximum margin classification of tree histograms  in      local features are quantized to a flat vocabulary 
as opposed to the hierarchical vocabulary contained in an svt  the
authors of     apply support vector machine  svm  classification
of histograms formed from the flat vocabulary  in our project  we
generalize their method to work for svm classification of tree histograms formed from a hierarchical vocabulary 
the tree histogram of     discards all geometrical relationships
between features  thus  it is possible for the configuration of keypoints in the top database images after the svt search to differ from

fithe configuration of keypoints in the query image  when this occurs 
it is better to declare no match than to report a likely false positive
match  thus  we further propose a geometric consistency check after the svt search  if no strong geometric correspondence is found 
we can avoid false positives by reporting no match  we evaluate two
different geometric verification algorithms      a very accurate affine
consistency check  and     a much faster but nearly as accurate scale
consistency check 
our report is organized as follows  sec    reviews how a tree
histogam is generated and presents a multi class extension of the
two class naive bayes multivariate model  then  sec    presents
several different kernels for svm classification of tree histograms 
after svm classification  the top database images are checked for
geometric consistency with the query image using one of two different algorithms  as discussed in sec     we present experimental
results in sec    for two image databases and evaluate the classification performance of the different kernels and geometric verification
algorithms 

 a 

   background on tree histograms
     tree histograms in a scalable vocabulary tree
a scalable vocabulary tree  svt  is generated by hierarchical kmeans clustering of training feature descriptors  hierarchical kmeans is a generalization of the flat k means algorithm presented
in lecture notes    fig    illustrates the process of hierarchical
k means clustering of feature descriptors  first  we extract a representative subset of descriptors  usually on the order of several
million  from the database images  second  we perform flat k means
clustering on all these descriptors  resulting in k different clusters 
third  we further perform flat k means clustering on each of the
k clusters  and we repeat this subdivision process recursively until
each cluster contains only a few descriptors  a tree structure naturally emerges  where the nodes in the tree are the cluster centroids
determined by hierarchical k means  an example of a small svt is
shown in fig     in practice  svts are grown to be very large  e g  
contain on the order of   million leaf nodes  to ensure that the visual
vocabulary provides good coverage of the high dimensional space
of feature descriptors 
for classification of feature descriptors  we interpret the tree
nodes as visual words  analogous to the multivariate event model
shown for text classification in lecture notes    we define the
tree histogram for an image as a vector of node visit counts 
x    x  x     xn    where xi is the number of feature descriptors in the image quantized by nearest neighbor search to the
ith node of the svt and n is the total number of nodes in the svt 
in the remainder of this report  we will create efficient classifiers for
the tree histogram 
     naive bayes classifier
as a simple baseline system  we can apply naive bayes classification to decide the class of each query image  we generalize the
multinomial event model presented in lecture notes   to the multiclass scenario  during training  we first calculate the prior probability of each class y c for c              c 
y c

 

m
o
  x n  i 
  y  c
m i  

 

   

we assume there are sufficient training samples in each class so that
laplace smoothing of the prior probabilities is unnecessary  then 

 b 

 c 
fig     steps in hierarchical k means clustering of feature descriptors   a  extract feature descriptors from training database images 
 b  perform first level of k means clustering   c  perform second
level of k means clustering 

we calculate the laplace smoothed probabilty of the occurence of
each tree node or visual word given the class of the image  using the
tree histogram x  for c              c and k              n  

p
 i 
m
 i 
  
  y
 
c x
k
i  

k y c    pm
 
   
 i 
  c ni   n
i      y

where n is the number of tree nodes or visual words  ni is the number of feature descriptors in the ith image  and c is the number of
 i 
classes  in the numerator of eq     xk is the number of times the ith
images feature descriptors visit the kth node of the svt 
during testing  for a new query images tree histogram x  we
look for c           c  that maximizes the following probability 
pr y   c  x 

 

pr y   c 

n
y

pr xi  y   c 

i  

 

y c

n
y

i  

i
xi y c

 

   

fifig     svt of depth d     and branch factor k      containing
n      nodes 
where n is the number of feature descriptors in the query image 
results for naive bayes classification of an actual image set will be
given in sec    
   support vector machine classification
of tree histograms
in this section  we create maximum margin classifiers for the tree
histogram defined in sec     our approach is inspired by the prior
work in      which proposed svm classifiers for flat visual vocabularies  we generalize their method to work for the hierarchical visual
vocabulary contained in an svt  taking into special account the informativeness of different nodes in the svt 
     weighted tree histogram
in a hierarchical visual vocabulary  it is important to consider the
varying degrees of informativeness provided by words at different
levels  intuitively  the nodes at higher levels of the svt are less
informative  because many feature descriptors from many image
classes visit them  the analogy in text classification is that a word
like mammal is less informative or specific than words like canine
and feline  to express this intuition mathematically  we apply a
weighting scheme from information retrieval     which assigns a
informativeness score to each word in a vocabulary 
wi   ln  m mi  

 

   

where m is the total number of training images and mi is the number of training images that visit the ith word in the visual vocabulary 
or the ith word in the svt  if mi      which occurs rarely for degenerate parts of the tree  we assign wi     to effectively prune
away that part of the tree  this weighting gives greater emphasis to
tree nodes visited by fewer images  which are more discriminative
in classification 
using the weights defined in eq     we can create a weighted
tree histogram x    x  w  x  w     xn wn    the weighted tree
histogram is the feature vector we will subsequently use for svm
classification 
     kernels for svm classification
we consider four kernels for svm classifcation of the weighted tree
histogram  the simplest is the linear kernel 
t

klin  x  z    x z

 

   

the linear kernel is not able to capture correlations between different
words in the vocabulary  for example  features associated with the

eyes of a person usually occur together in the same image with features of the nose  ears  mouth  and hair  to exploit such co occurence
relationships while still keeping the complexity of the svm classifier
low  we propose three computationally efficient nonlinear kernels  a
polynomial kernel  a gaussian kernel with l  norm distance  and a
sigmoid kernel are specified as follows 

d
kpoly  x  z   
xt z   c
 
   


 
  x  z   
 
   
kgauss  x  z    exp 
 


ksgm  x  z    tanh xt z   c
 
   
where the various parameters in the kernels are selected by ten fold
cross validation  all of these kernels are proven to be mercer kernels
in     
unlike the two class svm presented in lecture notes    we
need a more general c class svm to classify our image data  we
choose the one versus one method  where a different svm is trained
between every pair of classes  for c classes  there are c c      
pairs of classes  to classify an image  we perform c c      
comparisons  svm classifications  and pick the class that wins the
majority of comparisons  experimental results for all the kernels on
a real image set is presented in sec    
   geometric consistency check
to reduce the number of false positive image matches after svm
classification of the tree histogram  a geometric consistency check
between the top database images and the query image should be performed  if no good geometric correspondence is found  no match is
reported to reduce the false positive rate  in an application like cd
cover recognition  if the classification result is ambiguous  it is better
to report no match and prompt the user to try taking another query
photo than to report a false cd cover identity  here  we evaluate
two different geometry verification algorithms  an accurate affine
consistency check and a much faster but nearly as accurate scale
consistency check 
     affine consistency check
n

q
let the query image have feature keypoints pq     xq i   yq i   i  
nd
and a database image have keypoints pd     xd i   yd i   i     if the
two images contain similar objects and do not differ in viewpoint
significantly  a subset of the points in pq will be well mapped by an
affine transformation into a subset of the points in pd   these affinerelated points are called inliers of the affine model  as opposed to the
other points in pq and pd called outliers which do not conform to
the affine model  the key challenge is to find the best affine transformation when initially we do not know the separation between inliers
and outliers 
random sample consensus  ransac      is an iterative algorithm well suited to discovery of unknown models in the presence of
outliers  we apply ransac to find the best affine transformation
between pq and pd as follows  notationally  let  a  denote the size
of a set a 

   for each descriptor vq i in the query image  find the closest
descriptor vd i in terms of euclidean distance in the database
image  propose that keypoint  xq i   yq i    pq is matched to
keypoint  xd i   yd i    pd  
   initialize ransac by setting the following parameters 

fi a  max iteration    maximum number of iterations
 b  min error     
 c  min start       minimum number of inliers at start
 d  min end    minimum number of inliers for convergence
 e  max offset    a keypoints maximum offset from affine
model prediction to remain an inlier
   for  iteration      iteration  max iteration  iteration   
 a  set maybe inliers    min start random matches 
 b  set maybe model    least squares affine model amaybe
between keypoint matches in maybe inliers
 c  set consensus set    maybe inliers
 d  for every keypoint  xq i   yq i    pq not in maybeinliers  find  xd i   yd i     amaybe  xq i   yq i    if the
offset    xd i   yd i     xd i   yd i        max offset 
add this keypoint match to consensus set 

   experimental results
classification using naive bayes and svms is performed on two different image databases  the first database is the well known zurich
buildings database  zubud        which contains      database
images representing   views of     buildings in zurich  the query
image set contains     images depicting a subset of the     buildings  some examples are shown in fig    
the second database is our own cd cover database  cdcd  
which contains      database images representing   views of    
cd covers  the query image set consists of    images  representing    different cd covers drawn randomly from the     cd covers  cdcd is more challenging than zubud because of increased
background clutter  partial occlusions  and specular reflections from
camera flash  some examples are shown in fig    

 e  if  consensus set    min end  skip to the next iteration 
 f  set better model    least squares affine model abetter
between keypoint matches in consensus set 
 g  for every match in consensus set  find the offset
   xd i   yd i     xd i   yd i        set mean offset   
average of these offsets 

fig     zurich building database images 

 h  if mean offset   min error  set min error    meanoffset  best model    better model  and best consensusset    consensus set 
a correct image match will have a large number of elements in
best consensus set  whereas an incorrect match will yield very few
elements in best consensus set  thus  if  best consensus set  is below some minimum threshold  we judge the query and database image to be geometrically dissimilar  the main drawback of the algorithm is its need to repeatedly compute affine models  which makes
the algorithm slow and therefore unattractive for low latency object
recognition applications  thus  in the next section  we propose a
more computationally efficient geometric check 
     scale consistency check
assume a query image and a database image share common objects 
but the objects may be shown at different magnifications in the two
images  then  the scales  q          q nq   of features in the query
image should be nearly proportional to the scales  d          d nq  
of matching features in the database image  in other words  the ratio
of scales  q    d          q nq  d nq   should be nearly constant 
using this rationale  we propose a scale consistency check 
   perform step   of the affine consistency check 
   set r     q    d          q nq  d nq   
   set rmed    median  r  
   set consensus set    all ratios in r that are within  of rmed  
similar to before   consensus set  measures the strength of the
geometric correspondence between the query and database images 
the reason for choosing the median ratio rather than mean ratio is
that the median is less sensitive to outliers  unlike affine consistency check  scale consistency check is non iterative and requires
much simpler computation  in sec     we evaluate the two geometric verification algorithms and show scale consistency check
performs nearly as well as affine consistency check but runs considerably faster 

fig     cd cover database images 
first  we evaluate classification performance without any postsvt geometric verification  we choose surf over sift because
surf has lower dimensionality  enabling our learning algorithms to
run faster  our hierarchical k means algorithm uses vlfeat     
and our svm algorithm uses libsvm       after training naive
bayes and svm classifiers on the database images  the performance
is tested on the query images  table   compares the match rates for
different classifiers  where the match rate  mr  is defined to be
mr  

no  query images correctly identified
no  query images

   

the best performance is obtained for the svm with a polynomial
kernel of degree     the polynomial kernel slightly improves classification accuracy compared to the linear kernel for zubud  but
the two kernels give the same result for cdcd  because the tree
histograms are already very high dimensional vectors  there is already sufficient separability between most image classes in the original vector space  allowing the linear kernel to be effective  as expected  the match rates are lower for cdcd than for zubud because
cdcd contains more challenging image distortions  reasonably
high match rates are obtained for both databases using svms  naive
bayes performs poorly for cdcd because of the more challenging
image distortions  lower ratio of number of foreground features to
number of background features  and larger number of classes 

fi   conclusion

table    match rates for zubud and cdcd 
zubud
classifier
naive bayes
svm with linear kernel
svm with gaussian kernel
svm with sigmoid kernel
svm with degree    polynomial kernel

mr
      
      
      
      
      

cdcd
classifier
naive bayes
svm with linear kernel
svm with gaussian kernel
svm with sigmoid kernel
svm with degree    polynomial kernel

mr
      
      
      
      
      

this report has presented svm classification of tree histograms generated from an svt  we have demonstrated how to generalize svm
classification of flat visual vocabularies to svm classification of hierarchical vocabularies  several computationally efficient kernels
are suggested  a baseline naive bayes classifier was also investigated  our proposed classifiers are evaluated using two image data
sets  the zurich building database and our own more challenging
cd cover database  the svm classifiers achieve fairly high match
rates for both data sets  on top of the basic svm classifier  we also
proposed geometric verification  with either an affine consistency
check or a scale consistency check  to reduce the false positive rate 
   acknowledgments
the students would like to thank prof  andrew ng and the teaching
assistants for their help and advice  we enjoyed taking the class and
are thankful for the opportunity to apply our new machine learning
knowledge in this project 

second  we evaluate the performance of the two proposed geometric verification algorithms and measure the reduction in the false
positive rate  if a query image and one of the top post svt database
images pass the geometric check  we report the result as a match 
otherwise  the result is no match  then  the false positive rate  fpr 
is defined to be
fpr  

no  match query images incorrectly identified
no  match query images

    

because the polynomial kernel achieved the best result for both
databases  we apply geometric consistency check to the polynomial
kernels top five database images 
the comparison of match rates and false positive rates for with
and without geometric checks is given in table    we see that for
both databases  the false positive rate is reduced significantly by applying a geometric check  the match rate is only reduced slightly
for zubud and is unaffected for cdcd  meaning a geometric check
rarely discounts valid matches  also  when measuring the runtime
per query image  the scale check runs much faster than the affine
check while achieving about the same accuracy 

table    geometric check results for zubud and cdcd 
geometric check
none
affine
scale

zubud
mr
fpr
             
             
             

time  sec 

      
      

geometric check
none
affine
scale

cdcd
mr
      
      
      

time  sec 

      
      

fpr
      
      
      

   references
    g  fritz  c  seifert  and l  paletta  a mobile vision system for
urban detection with informative local descriptors  in ieee
international conference on computer vision systems       
    h  bay  b  fasel  and l  v  gool  interactive museum guide 
fast and robust recognition of museum objects  in international workshop on mobile vision       
    s  tsai  d  chen  j  singh  and b  girod  rate efficient  realtime cd cover recognition on a camera phone  in acm multimedia  october      
    d  lowe  distinctive image features from scale invariant keypoints  international journal of computer vision  vol      no 
   pp         november      
    h  bay  t  tuytelaars  and l  v  gool  surf  speeded up
robust features  in european conference on computer vision 
may      
    d  nister and h  stewenius  scalable recognition with a vocabulary tree  in ieee computer vision and pattern recognition or cvpr       
    j  zhang  m  marszalek  s  lazebnik  and c  schmid  local
features and kernels for classification of texture and object categories  in ieee computer vision and pattern recognition
workshop       
    j  shawe taylor and n  cristianini  kernel methods for pattern
analysis  cambridge university press       
    m  a  fischler and r  c  bolles  random sample consensus  a
paradigm for model fitting with applications to image analysis
and automated cartography  communications of acm  vol 
    no     pp          june      
     h  shao  t  svoboda  and l  v  gool  zubud   zurich buildings database for image based recognition  april      
     a  vedaldi and b  fulkerson  vlfeat   an open and portable
library of computer vision algorithms       
     c  c  chang and c  j  lin  libsvm   a library for support
vector machines       

fi