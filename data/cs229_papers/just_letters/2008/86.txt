textured object detection in stereo images using
visual features
michael levin            
december         

introduction
a robot can be easily modified to gather depth data alongside optical images  when combined with an effective object detection framework  this allows the robot to not only identify
potentially interesting objects but locate their position and orientation within the world 
this information is useful for obstacle avoidance and navigation  locating landmarks for positioning  and for locating a target object in the world  if the detection is accurate enough 
the robot can also use the information to locate a grasping point 
the goal of this project is to produce a trainable object detector suitable for this setting 
during training  visual features from highly textured areas of the image are extracted and
stored along with their world space position to form a stored view of the object  when
presented with a novel scene the detector will try to match highly textured points with the
database of stored object descriptions to find consistent formations of features that would
indicate the presence of a known object 
this project is supervised by dr  gary bradski at willow garage  willow garage
provided the necessary equipment to capture dense stereo images  upon completion of
the project  the resulting system is planned to be integrated into the robot operating
system and tested on the personal robotics platform currently under development at willow
garage 

stereo image dataset
for this project  stereo images were collected using a videre binocular camera  depth data
is determined from the image pair using block correspondence as described in      because
this method works by finding similar patches in left and right images  it does not work well
on poorly textured surfaces  in order to overcome this problem  a second set of images is
taken in addition to the initial images while a random noise pattern is projected onto the
scene  the second set of images is then used for depth calculations while the left image of
the first set of images is used to extract visual features  see figure    
the dataset  figure    consisted of               stereo color images of ten toy objects 
the background was known and kept fixed throughout training and testing and was used in
foreground segmentation  a scene could be composed of one or more known and unknown
objects and multiple instances of one object type  objects were placed in novel position and
orientations and allowed to occlude each other to present a challenging detection problem 

fifigure    on the first row is the camera used and the output     by     stereo images  in the
second row is the dense stereo setup and the disparity map without and with the projector 

training
the detector must first be trained on the set of objects that are to be detected  using one of
the images from the stereo pair  surf     feature points  or alternatively sift      are first
extracted along with the depth calculated from the dense stereo image pair  these points
build up a sparse point cloud description of the object  to robustly recognize an object 
enough views must be collected so that no area of the object has not been captured 
after all object descriptions have been stored  a point classifier is trained to classify
feature point vectors as belonging to one or more of the trained objects  the classifier does
not have to precisely partition the points but needs only to determine if a point could be
a plausible member of an object class  random forest  k nearest neighbors  and k means
clustering were investigated for the point classifier 
the random forest classifier was chosen for feature classification for its efficiency and
straightforward parallelism  random forests have been shown to have recognition performance matching multi way svm and superior computational speed in image classification
tasks        and will perform well even when built in a completely random fashion     
however  it was found that both the random forest classifier and the k nearest neighbors classifiers tended to overfit the data  better results were obtained by using k means
clustering  with k proportional to the data size  to build a model of where in feature space
the points were distributed for each object  to test against this  the distance between the
test point and the nearest cluster was compared to the clusters standard deviation  this
kind of per object classification was better suited for the purposes of object detection 

object detection
when scanning a novel scene  depth and visual features are extracted in the same fashion as
during training  the following algorithm is then run over each of the object views collected
during training 

fifigure    each of the ten classes of object used in the dataset with the corresponding dense
stereo disparity map shown below the left camera image 
   random sample consensus  ransac  is used to find a translation and rotation of the
view into the test space  only very good feature matches are used as potential inliers 
   after a potential position in test space is found  validation is performed  the volume
around the points composing the view after transformation into test space are used as
a hull and test points that are classified as belonging to the current views object class
that fall within this volume are collected  if enough points are collected  all collected
points are removed from the test scene and the process repeats again for the current
view  this allows the detector to match multiple instances of one object 
   if less than three points pairs were found for ransac  if ransac failed to find
three good inliers  or if validation did not collect enough points  the process moves on
to the next view 
the results for some of the test images are shown in figure    the detector worked well
on larger  well textured objects that produced large feature point clouds but worked poorly
on smaller objects  part of the reason for this was the low resolution of the camera  a large
portion of the feature points produced for small objects contained pieces of the background
and would not match if the object was moved in the scene or occluded 
one of the advantages of this detector against a purely feature based approach is the
ability to match non planar objects through limited rotations  if depth information were
not available the detector would have been forced to treat the object as a plane and would
not have found the correct orientation adjustment for the feature point cloud 

fi


figure    a visualization of the depth maps for two scenes and the extracted feature point
clouds 

conclusion
the object detector produced for this project would be ideally suited to detection tasks with
a limited vocabulary of objects such as landmark detection or finding a target object in
clutter  the relative computational efficiency of the detector also allow it to run in realtime  overall the approach has promising applications and would perform even better with
more accurate equipment 

references
    herbert bay  tinne tuytelaars  and luc van gool  surf  speeded up robust features 
in proceedings of the ninth european conference on computer vision  may      
    a  bosch  a  zisserman  and x  muoz  image classification using random forests and
ferns  computer vision        iccv       ieee   th international conference on 
pages     oct       
    gary bradski and adrian kaehler  learning opencv  pages         oreilly media 
inc    st edition  oct       
    pierre geurts  extremely randomized trees  in machine learning  page            
    vincent lepetit and pascal fua  keypoint recognition using randomized trees  ieee
transactions on pattern analysis and machine intelligence                
    d g  lowe  object recognition from local scale invariant features  computer vision 
      the proceedings of the seventh ieee international conference on            
vol         

fifigure    object detection results for test images  query images and their extracted feature
point clouds  the feature point clouds from the matched view are overlaid with colored
borders 

fi