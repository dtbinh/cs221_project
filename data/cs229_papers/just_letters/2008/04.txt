a model of perceptual decision making in lateral intraparietal
area
andrew saxe

josh herbach
advised by j  mcclelland

 

introduction

we model an oculomotor decision making experiment in which monkeys are shown a cloud of moving dots and must
decide which way the dots are moving on average  in each trial of the experiment a subset of the dots moves coherently
to the left or right  while the remaining dots move randomly  the monkey indicates its choice by saccading to the left or
right  and if correct it receives a juice reward  this standard paradigm has recently been extended to include differing
reward conditions      before the onset of the motion stimulus  a reward stimulus is presented that indicates how many
drops of juice the monkey will receive for a correct answer in each direction 
analysis of the behavioral data from this experiment shows that the monkeys achieve a near optimal reward rate on
this task      however  the neural circuits underlying this decision process remain unclear 
we attempt to explain the neural data using a computational neuroscience approach  we hypothesize the computation
that we believe lip performs  find the optimal solution to that computation  and see if the optimal solution predicts
the experimental data  in particular  we hypothesize that lip implements an optimal decision rule  it receives noisy
observations of the motion direction as input  and produces the decision that will maximize the monkeys expected
reward rate as output  in section   we formulate a probabilistic model of the task  in section   we find the optimal
decision rule  in section   we set the parameters of our model to closely approximate previous modeling efforts  in
section    we present a stochastic neural network representing lip that we train to implement this optimal decision
rule  finally  section   makes comparisons to experimental data 

 

modeling the computation

because we intend to train a recurrent neural network to implement the optimal decision rule  we first formulate the
computational problem solved by the monkey in a discrete time setting 
in a given trial of the experiment  a certain fraction of dots move coherently to the left or right and the rest move
randomly  define the signed coherence c         of a trial to be the fraction of dots moving coherently with the sign
indicating if the movement is to the left or right respectively  thus the correct answer y   sign c   correct responses
are rewarded with either one or two drops of juice  define r    r          where r  is the reward magnitude for a
correct response with y     and r is the reward magnitude for a correct response with y     
during a trial  lip receives input from lower level visual processing areas sensitive to motion direction  we describe
this input signal as a series of noisy inputs x    x t    t           t    where lip receives input x t  at time t  here
the time period during which the monkey views the moving dots has been discretized into t instants  in the simplest
model  let x t          represent the observed stimulus direction  we take the x t  to be mutually independent
given y  and will specify p x t    by defining a measurement model p x t   c  and a prior over coherences for a trial
p c   the experiment consists of blocks of trials with fixed coherence magnitude  c    cmag   for each trial the
leftward or rightward direction is chosen randomly  i e  p y      is known and set by the experimenter  thus
p c     c  cmag  p y         c   cmag  p y      
to find p x t   c    p x t   y  cmag    we will require that the probability of error under the optimal decision function
in the equal reward case r    r be identical to that of previous modeling approaches based on the continuous time

fidrift diffusion process        since previous approaches have treated the equal reward case  this requirement will make
our formulation match previous work  to do so we must know the optimal decision rule 

 

the optimal decision rule

we now derive the optimal decision rule as a function of p x t   c  and the other parameters  let p    p x t      y  
   cmag    we can now compute the expected reward r for a single trial given a response d x  r    r   cmag       
e r d x  r    r   cmag       

  r  p y     x  cmag  
 

r  p y     

t
y

p x t   y      cmag   

   
   

t  

 the formula for the expected reward is similar when d x  r    r   cmag         since we have defined d to
be a function maximizing the expected reward rate  d should choose   when e r d x  r    r   cmag         
e r d x  r    r   cmag        or alternatively  since e r d x  r    r   cmag     i       it chooses   when
 

 

e r d x  r    r   cmag       
 
e r d x  r    r   cmag       

   

 

p  t 
r  p y        p x t 
p t
    p    t x  
r p y     

   

manipulating this eventually yields
 

now we take the log of both sides to get the condition d  x  r    r   cmag       if

   x
 

p
r 
p y     
  log
    log
  log
x t   
r
p y     
   p 
t

   

and    otherwise 

 

a measurement model in agreement with the drift diffusion process

in the equal reward  p y            case     becomes
 


d  x  r    r   cmag      

 
x

x

 t 

  

      

t

pt
let n   t     x t        then n  binomial t  p     assuming y      the probability of error is the probability
that the sum of t bernoulli trials  each with probability of success p x t      y      r    r   cmag    is less than
t     to find p  we can require that as t    the error matches the error of the drift diffusion model  by applying
the de moivre laplace theorem and setting the result equal to the error of the drift diffusion model  we find that
p 

 

 
 
  q
 
    k  t    
a  tf

   

a is a drift rate parameter representing the strength of the motion signal  and k is a parameter controlling the amount of
noise  unsurprisingly  as the influence of noise  k  increases  the signal portion of p  decreases and as the meaningful
drift increases  a  the signal has a larger impact  in       the drift rate a is assumed to be proportional to coherence 
a   ac where a is a parameter  substituting this into     yields
p 

 

 
 
  q  
 
k t
   
a  c  tf    

   

from which p x t   y  cmag   can be recovered  thus our discrete time model and the continuous models in       will be
close approximations of each other for large t   figure  a shows the quality of approximation for t       the number
of samples used subsequently 

fiprobability of response    p d  x r  r cmag    

ddm vs  binomial psychometric functions  t   
 

 t 
output

   

wy

   

wx

   

 
 

wr

hidden

   

ddm
binomial
   

 
coherence c

   

input
 

r  t 

r  t 

x t 

 

figure     a  comparison of psychometric functions under a ddm and the discrete time optimal decision function     
with p x t  c  as given in     and t       tf      a      k       b  recurrent network architecture 

 

implementing the decision rule in a recurrent neural network

the optimal decision rule given in     can only predict behavioral data  to make the connection to neural data  we
train a recurrent neural network to implement the optimal decision rule and see if the firing rates of the network match
those recorded in lip  our network consists of three layers  figure  b   the input layer presents the vector u t  where

   t 

   t 
 t 
 t 
 t 
 t 
 t 
u      x t        u      x t        u    r    u    r   and u       the components u  and u 
split the input x t  into two processes so that neurons in the network can become responsive to only the leftward or
rightward directions  or to a mixture of both   it projects to a hidden layer with weights w u   each neuron in the
hidden layer receives input from all other hidden neurons through recurrent connections w r   and sends output to the
output layer through weights w y   the output layer consists of a single neuron which outputs the decision y  t   
in other contexts noise has been found to be crucial to reproducing observed properties of experimental data     and
so we have trained networks in both a noiseless  deterministic setting  and a noisy  stochastic one 
let o t  be the hidden neuron activation at time t  this activation is updated according to


x
x
 t   
 t 
 t 
 t 
 t 
oi
 f
wijr  oj   ij    
wju  uj   i   i    
j

where f  x   

 t 
 
  exp x   ij

j

 gaussian    

 t 
oj
 t 
  aoj

 


    i t   gaussian        i  gaussian        and all

random variables are mutually independent  the noise terms were proposed by todorov in      the random variable
 t 
ij models the poisson firing characteristics of neurons in vivo and synaptic depression effects  the random variables
 t 

 t 

i and i model input noise  with i representing fluctuating noise and i representing slowly varying noise that
remains constant over the course of a trial  we took        a       and              
the output of the network y  t  is calculated as
y  t 



x y  t 
   f 
wj oj     
j

to train the network we minimize the expected error of the network over a set of training data  we use the back
propagation through time algorithm     to calculate the gradient of the error with respect to the network parameters 
and make use of noise freezing tricks described in     to speed the computations 

 

comparison to data

the firing rates of hidden units in the trained network show two typical patterns  in the first  the unit begins each trial
with a low activation  and its activation increases as it receives information favoring one direction  we interpret this

fiintegrator neuron average response

average firing rates of neuron         coherence
  
      y r r 
     
     
     
     
     
     
     

  
  

   
   

activation    of maximum firing rate 

deviation from initial firing rate  hz 

  

  
 
 

   
   
   
   
   
   
   

 
  

      y r r 
     
     
     
     
     
     
     

 

 

  
  
  
  
  
  
ms  aligned to    ms after motion period onset 

   
  

  

  
  
  
  
  
time step  t    is beginning of motion period 

  

figure    firing rates   a  monkey data   b  model

signed coherence vs   of rightward responses

signed coherence vs   of rightward responses

 
   

   
  rightward responses

   
   
   
   
   

   
   
   
   
   

   

   

   

   

 
   

   
   
   
   

   

 
signed coherence

 
   

   

 
signed coherence

figure    psychometric functions   a  monkey data   b  model
input preference for trained neurons
   
   
   
   
u 

  rightward responses

   

 
    r r 
   
   
   

 
   
   
   
   
 

   

 
u 

figure  

   

   

fineuron as tracking the sum of x t    and hence call it an integrator neuron  the average activity of a typical integrating
neuron is shown in figure  b  in the second pattern  the unit begins near its maximum activation  and its activation
decreases as it receives information favoring one direction  we call this type of unit an reverse integrator neuron 
we examined neural data collected and provided to us by a  rorie  w t  newsome  and j  guan for neurons exhibiting
these patterns in monkeys performing the task  we found four neurons of fifty two that robustly showed this integrating
response pattern  one such neuron is shown in figure  a  compare to figure  b   a number of other neurons showed
robust integrating processes in some but not all of the reward conditions  however  no reverse integrators were found
in the monkey data  this observation is consistent with the general finding of sparse firing rates in the brain  although
we expected reverse integrators in our deterministic network  we had hoped that they would not be present in the
stochastic network since the variance of the noise added to each hidden neuron scales linearly with that neurons
activation  we reasoned that this would push the network toward lower firing rates to reduce the impact of this noise 
as reported by      however this was not observed  and our stochastic network was very close in character to the
deterministic one 
to compare the behavioral data to that of the model  we analyze the percentage of rightward responses as a function
of coherence and reward condition  the resulting curve is called a psychometric function  and is shown in figure
 a for the monkey data  the psychometric function shows intuitive behavior  the equal reward conditions yield
indistinguishable curves  and the asymmetric reward conditions shift the curves in the direction of higher reward 
figure  b shows the psychometric function calculated based on five trained networks  each one trained for a different
coherence level  the curves show the same general pattern  except that the asymmetric reward conditions for the
model go to zero or one at coherences near zero  this pattern is actually optimal
for ourfi discrete setting of the task 
fi
fip  t  fi
fi log r   r   fi
fi
fi
 t   so for fi log p     p     fi   t the optimal decision
since the sum of the inputs is bounded by t   i e 
tx
will be fixed regardless of the input sequence  since these bumps are clearly not observed in the monkey data  our
computational model of the task is too crude to properly capture monkey behavior near low coherences  to mitigate
log r   r  
these problems in the future  the parameters could be chosen so that log p
     p     is smaller than t  
finally  we examine the structure of the learned solution  models of the equal reward case often posit one group of
neurons sensitive to motion in one direction and another group sensitive to motion in the other direction  our model
had the freedom to become selective to any mixture of the two input components u  and u    to see if neurons in the
model become sensitive to one direction of motion or the other  we plot the unit vector in the direction of the weights
to these input components in figure    a weight vector aligned with one axis or the other would indicate a neuron
selective only to one direction of motion  instead  we see weight vectors aligned with the negative diagonal  indicating
opposed input weights of equal magnitude  that is  our neurons become selective to both directions of motion 

 

conclusion

the model presented in this paper exhibits a number of features of the neural and behavioral data for monkeys  yet the
discrepancies between the model and data remain large  we believe that the successes of the model argue for continued
investigation  if the basic hypothesis is correct  i e   the neural responses are indeed the result of optimizing the neural
system subject to constraints imposed by its architecture and biological substrate  then we can set conditions under
which we would expect the model to reproduce the experimental data  first  we can ask if we have the proper model of
the computation  the optimal solution to the proper model should match the behavioral data  next  we can ask if we
have successfully trained a neural network to implement the optimal decision rule  since we know the optimal rule 
it is easy to determine whether the problem lies in the training process  finally  we can ask if we have successfully
captured the constraints of the biological system 
references
    s  feng  p  holmes  a  rorie  and w t  newsome  can monkeys choose optimally when faced with noisy stimuli and unequal
rewards  submitted  plos computational biology  aug      
    r  bogacz  e  brown  j  moehlis  p  holmes  j d  cohen  the physics of optimal decision making  a formal analysis of
models of performance in two alternative forced choice tasks  psychological review  vol         oct               
    e  todorov  mixed muscle movement representations emerge from optimization of stochastic sensorimotor transformations 
submitted      
    p j  werbos  back propagation through time  what it does and how to do it  proceedings of the ieee  vol              
          

fi