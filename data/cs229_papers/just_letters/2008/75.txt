noise vs feature 
probabilistic denoising of time of flight range data
derek chan
cs    final project report
ddc stanford edu

abstract
advances in active  d range sensors have enabled the
recording of depth maps at video frame rates 
unfortunately  the captured depth data is often noticeably
contaminated with noise  we present a series of statistical
analyses and denoising techniques to improve the raw
output of depth sensors  unifying our investigations is the
concept that in the presence of high sensor noise  the ability
to distinguish effectively between noise corruption and real
depth features is needed to reconstruct the original true
geometry realistically 

  introduction
range sensors  such as time of flight  tof  cameras  have
enabled the reconstruction of  d geometry independent of
texture required for stereo vision methods  unfortunately 
range sensors which are able to produce a  d array of depth
values at real time speeds generally produce data heavily
corrupted by noise  in this paper we elect to focus on a
particular tof camera  the mesa swissranger sr      the
sr     is capable of capturing    x    resolution depth
maps at approximately    frames per second 
although depth sensors are increasingly being use for a
variety of commercial and academic applications  the high
level of noise makes the effective use of these sensors
challenging  thus  we propose a technique for estimating the
true original geometry of a scene based upon an input depth
map  following certain previous investigations  noted in
sect     in the area of denoising we have elected to use a
bayesian model for our approaches  in section   we present
a series of techniques which illustrate some of the issues that
depth reconstruction techniques should be aware of to enable
the better recovery of true geometry by denoising of range
data  in particular we endeavor to tackle raw data that is
noisier than previous works have used  the high noise to
distinguishable feature ratio in the raw data makes nave
denoising techniques problematic  we seek to sharpen edges
and blur noise  however  this requires being able to
distinguish the categories  in section     we argue how such
distinctions allow for data dependent denoising choices  in
section    we conclude with further suggestions as to further
applications of such a model 

  related works
there exist present techniques of obtaining less noisy depth
maps from these sensors  the simplest method is to integrate
over time by averaging many frames together  however  this
is obviously not a viable option in real time scenarios  we
seek to provide a method which could be applied to
individual depth frames since we believe such a method
would be general and allow for use in a greater set of
scenarios including dynamic scenes  most related to our
work is that by  diebel    where a bayesian model was also
used to perform probable surface reconstruction based upon
slightly noisy depth data  a primary difference in our work
is in the type of sensor used  the previous work focused on
synthetic data or used data obtain from a laser line scanner 
these sensors capture at much slower rates than tof
sensors  but they also provide much stabler measurements 
in comparison  our sensors have a much higher noise to size
of feature ratio  however like the aforementioned work  our
technique will ultimately be a bayesian method which will
estimate the true depths under statistically learned
assumptions  in addition the previous work primarily
focused on using simply the depth measurements from their
sensor while we hope to also use other data and statistics
such as the gray scale intensity image provided by our tof
camera 
also relevant to our work are investigations into upsampling
depth data  some of these techniques are robust for at least a
small amount of noise in the input depth maps  and in the
process of increasing resolution  also effectively do some
noise reduction  in particular upsampling does smooth out
some peppering noise   schuon    used the concept of
multiple slightly shifted captures of the same scene to
provide increased information on a scene to upsample it 
however this technique also relies upon multiple images just
as time averaging frames does  the use of a high resolution
color image as a guide to upsample low resolution depth
 diebel    kopf    chan     since the color image is
comparatively noise free  these techniques ultimately also
guide the result towards being comparatively noise free  this
technique relies upon a fairly accurate alignment between
the color and depth images  since no sensor presently exists
with a unified lens set  imperfect calibration procedures
generally results in some misalignment artifacts in these

fisetups when used on real world scenes 
finally the task of super resolution for standard color images
is also related to our goal  towards this endeavor  learning
techniques exist  sun       freeman       which ultimately
manufacture plausible high frequency details for a low
resolution image based upon training sets of low resolution
vs high resolution pairs  previous works use a number of
ideas on different statistical priors of real images which will
provide us with ideas for construction of potential priors for
our scenario where we train upon low noise vs and high
noise data pairs of the same scene  where as these previous
works sought to improve visual upsampling in a relatively
noise free rgb space  our analysis is in the realm of noisy
depth images  this poses the possibility for investigating
some of the characteristics unique to depth sensors  most
noticeably the data we have provided gives depth and
intensity values  this allows us derive further features such
as patch orientation for a given pixel 

    denoising investigations
    probabilistic denoising framework
our framework is admittedly similar to that denoted in
 diebel     in our scenario  we are provided with depth
measurements m  which are some noise corrupted
approximation of the true scene distance x  we wish to find
the probable value for x given the measurements based upon
some statistical assumptions  thus  we wish to optimize over
the following objective function 
p xm  p mx p x  p  m

   

where p m  is a constant with respect to our optimization
over the x s  the x  which minimizes this objective  will
provide our best guess for the true scene distances 
x  argminx log pmxlog p x

   

here  the first term  log p z x   will henceforth be denoted
the measurement potential  m  because it is a probability of
the noise in the measurements given the real data  the
second term  log p x    is our surface smoothness prior  s 
which is a prior probability of the smoothness of surfaces in
the world  these two terms counteract each other during the
optimization process 
as mentioned  one method for denoising depth maps is to
fuse the data with aligned unnoisy color data under the
general assumption that that areas of similar color are likely
to have similar similar depth  we start with a
reimplementation of the markov random field  mrf 
objective from  diebel    to demonstrate some of the
problems with existing approaches  with this heuristic  our
measurement potential simply checks the squared distance
between the estimated real depth x with the actual
measurement m 

figure    scene  top  with raw depth map  top middle  is
denoised using the single mode mrf method  bottom
middle  using both the depth map and color image as
inputs  note the texture embossing from the colour image
onto the depth map for the checkerboard  book cover and
shopping bag text  in comparison when a  noise vs feature 
decision is made  bottom  the texture copying is removed 

fifigure    the scene  left  of two separated books has a  d reconstruction  middle left  from raw data  note the depth
separation of the books is evident in the  d scene  however  when we use a simple heuristic  sect       for distinguishing
features from noise  this depth discontinuity can not be effectively determined  large thresholds  middle left  fail to mark
the separation between the books  small thresholds  left  cause the general depth map to be contaminated with noise 



m 

 

k x i mi 

i      n

   k is a weighting constant

s tries to maintain depths for neighboring pixels when their
visible colors  denoted i  are similar 
s  
i

 

 eci i   xi  x j  
i

j

ji

by taking the derivatives of this objective function  we can
set up this optimization to be solved using a conjugate
gradient optimizer  a result from this process is shown in
figure    although the output depths are cleaner  this nave
approach also noticeably suffer from texture embossing
since noise along color edges are enhanced to appear
incorrectly as depth discontinuity 
    dual mode denoising
alternatively  we design an augmented bilateral filter
 tomasi    kernel  within this closed formed solution  we
distinguish between noise and feature with a simple metric
removing texture copying as shown in figure    the filter is 
x p 

 
kp

 i q f  pq d   i p i q m pmq

in the nave mrf technique color features are erroneously
visible in the depth map  the objective function does not
differentiate between noise and features  thus  noise along
color edges is enhanced  the bilateral filter method
effectively has a dual mode measurement potential where
the function alpha makes a decision between feature or
noise and either chooses to edge enhance from the color
image or blur from the depth map respectively 
in the augmented bilateral filter technique  the decision
function  alpha  between noise vs feature is made using a
simple heuristic of comparing the maximum and minimum
values within a neighborhood of a blurred copy of the input 
however  this metric is not entirely robust  fig     when
small thresholds are shown foreground features  such as the
separation of the two books  are visible but much
background noise is marked as feature  when large
thresholds are chosen  foreground edges are not
appropriately marked  a thresholding problem exists with
the current metric  thus  it seems as if a distance dependent
threshold could be learned from data to combat this problem 
with a noise model  we could for example mark small
discontinuities in the foreground as feature while seeing the
same depth difference more likely as noise if the
measurement is faraway 

q 

here  q is an index for a nearby value from the set of
surrounding data points omega  f is a gaussian over spatial
differences  thus without function d  we would have a
gaussian blur 
d   g i p  i q  hm p mq
d provides a blend between two different gaussian
functions  g operates upon differences in visible color while
h operates upon differences in depth  when noise is present
without features  we need not consult the color image  and
the input depths can simply be blurred  this decision is
made by function alpha which takes in the neighborhood of
depths and appropriately samples from the sigmoid function 

figure    intensity images provided by the depth
sensor  to gather data for our noise model  we
collected data of a macbeth check at different distances
and of a board at different orientations and distances 

fi    noise statistics and model

    an application upon single perspective denoising

based upon the results from our dual mode design  we seek
to learn a noise model to better guide the noise vs feature
decision  for tof range sensors  the random error in
measurement lies primarily along the ray from the sensor 
from recorded tests we derive that the noise can be
approximated by a gaussian  the noise for measurements is
seemingly dependent on a number of parameters  in our
current investigation  we have focused on parameters based
upon the inherent measurement principle of the sr    
which relies on the reflection off surfaces of infrared rays
from the camera 

the denoising of a single depth frame can be done with the
following proposed objective  to evaluate the similarity
between the measured depths and range values obtained
during conjugate gradient optimization  we use the
mahalanobis distance between the recorded data and
optimized values as our measurement potential 

choosing parameters likely to change from this
measurement principle we decided upon the following 
    distance from the sensor
    incident angle between the infrared  ir  measurement
rays and the surface being measured
    infrared absorption of the material being measured
we collect data of a board at a variety of different
orientations and distances  fig      in addition recordings or
a macbeth check at different distances is taken to measure
noise due to intensity differences  some generalizations of
the results are shown in figure    as expected  the variance
over time of the measurement of a surface increases as
distance increases  incident angle increases  and ir
absorption increases  in addition  the greatest variance is
seen for low intensity values  ie high ir absorption  as
expected since in this case no measurement rays are
reflected back towards the sensor 
using this captured data we can run a gradient descent
algorithm over a parameter space specified over a
polynomial for each of the above variables  thus we learn a
polynomial regression for the variance values dependent on
our parameters  this model is used in the formulation of a
measurement potential  we next note an example objective
for denoising using just a single depth sensor by itself 

m 



t

 

mi  xi      i  mi  x i 

i       n

where sigma is the covariance matrix of our measured data 
it is specified as 



 



x    
t
  r     y   r
 
    z
in our case  sigma z is the variance in the ray direction where
we can use the results of our model  the other variances are
provided as small constants  r provides a rotation matrix
into the ray direction for a given pixel in our depth map  for
our smoothness prior we use the laplacian surface prior
below where omega is once again the surrounding
neighborhood  this metric is passed through function h
which is a huber function  the huber function returns an l 
norm for large inputs otherwise it returns an l  norm  the
l  norm for large distances makes this theoretically less
negatively influenced by sudden large peppering noise
spikes 
 
s    h xi 
 q

i      n
i q 
i

application of this optimization to a raw depth map results
in a noticeable cleaner range output  fig    

figure    from the collected data  example plots of variance compared with each of our feature statistics when the other
parameters are held to some constant  the calculated variance is based off of measurements made in meters  the units of
scene intensity are from the raw output of the depth sensor which provides a    bit gray scale intensity reading along
with the depth measurements 

fifigure    the scene  left  with raw  d reconstruction  middle  is passed through our single sensor optimization to
produce the result  right   note that the input has a fair amount of noise throughout the reconstruction  in the output 
details such as the folds in the green blanket and paper bag are more evident 

  conclusion and future work
we have presented a set of different techniques for
denoising range data  in particular we demonstrated the need
for a dual mode objective which differentiates between noise
and feature to perform separate actions as necessary  for this
goal we have designed a data model for the noise variance
based upon recorded measurements  further quantitative
analysis of our model should be performed  in addition  
present ground truth for our data model is obtained through
temporal averaging of frames from the sr      this
unfortunately does not take into account the slight
systematic bias of the sensor  comparisons with
measurements from a more accurate device such as a laser
range finder could increase accuracy 
insertion of a noise model into an objective with a dual
mode surface prior term which smooths or edge enhances as
is appropriate seems the next logical step  in particular the
gradient profile prior  sun    seems a good candidate for
enhancing known features  further testing with a variety of
surface priors should also be performed 

  acknowledgments
i would like to thank professor christian theobalt  professor
sebastian thrun  and james diebel for their advice through
my tof data investigations as well as providing me with
the sensor and computing equipment  the denoising
investigations presented in this work are part of a larger set
of investigations into tof camera data reconstruction and
data fusion with color cameras that started previous to this
quarter and will be continuing past this class  some of the
bilateral filter investigations discussed culminated in midoctober of this year  however  the work is still ongoing  i
am also grateful to sebastian schuon for the recent setup of
a motor mounted laser range finder that will allow me to
continue with these investigations using a more reliable
basis for ground truth measurements 

  references
d  anderson  h  herman  and a  kelly  experimental
characterization of commercial flash ladar devices  international
conference of sensing and technology      
d  chan  h  buisman  c  theobalt  and s  thrun  a noise aware
filter for depth upsampling  eccv workshop      
j  diebel  s  thrun  and m  breunig  a bayesian method for
probable surface reconstruction and decimation  acm
transactions on graphics      
j  diebel and s  thrun  an application of markov random fields
to range sensing  nips      
w  t  freeman  t  r  jones  and e  c  pasztor  example based
superresolution  ieee computer graphics       
j  kopf  m  cohen  d  lischinski  and m  uyttendaele  joint
bilateral upsampling  acm transactions on graphics      
a  levin  a  zomet  and y  weiss  learning to perceive
transparency from the statistics of natural scenes  nips pages
              
c  tomasi and r  manduchi  bilateral filtering for gray and color
images  in iccv  pages            
s  schuon  c  theobalt  j  davis  and s  thrun  high quality
scanning using time of flight depth superresolution  cvpr
workshops      
j  sun  z  xu  and h  shum  image super resolution using gradient
profile prior  cvpr      
j  sun  n  n  zheng  h  tao  and h  y  shum  image hallucination
with primal sketch priors  cvpr      
q  yang  r  yang  j  davis  d  nistr  spatial depth super
resolution for range images  cvpr      

fi