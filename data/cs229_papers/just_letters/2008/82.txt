cs    autumn     

a machine learning approach to
the frequency control of mems resonators
hyung kyu lee and shingo yoneoka
stanford university  california  usa
   introduction
silicon mems resonators have been considered as
replacements for quartz crystal resonators in electronic
systems  mems resonators have many advantages over
quartz references such as small size  low cost  less power
consumption  and cmos compatibility  therefore  mems
resonators are suitable for frequency references  clock  in
miniaturized handheld electronic devices 
silicon mems resonators consist of double ended
tuning forks  detf  that vibrate at a designed frequency
when actuation signal is applied  fig      the resonant
frequency is proven to be a function of temperature of the
device  dimension of a tuning fork  and the bias
voltage vbias  for actuation  here  the temperature is
environmental variable determined by ambient condition 
the geometrical dimensions of a tuning fork are design
variables fixed during fabrication  and the bias voltage is a
control variable  since the frequency of silicon mems
resonators is greatly affected by temperature variation 
much worse than that of quartz crystal resonators  frequency
stabilization is necessary for mems resonators 
the resonant frequency of mems resonators can be
tuned by changing the bias voltage  therefore  we can
stabilize the frequency by applying proper bias voltage
according to the measured device temperature  to achieve
this goal  we need a calibration table that shows
temperature bias voltage relation for a fixed target
frequency  to build this table  we     measure frequency at
array of measurement points  fig          fit the data using
polynomial equation      and obtain iso frequency line from
the equation 
conventional calibration method stated above does not
care about the efficiency in step     and      therefore  a
large amount of data is gathered and as many features are
used for fitting as possible  however  for the
commercialization of mems resonators  cost effective
calibration process is needed  for that  it is necessary to
minimize the number of measurement points to generate a
fitting curve without losing the fitting accuracy  here  a
machine learning approach to generate the calibration table
would be necessary 
if we figure out significant features and optimized
measurement points using machine learning  we can build
the same calibration table with shorter measurement time 
also  the device to device variation error caused by
uncertainties in fabrication process would be solved using
the gaussian process regression algorithm 
for this study  we measure the frequency of multiple
resonators as a function of temperature and bias voltage  we
will evaluate the performance of our study using this data 

figure    schematic of the double ended tuning fork  detf 
mems resonator 

figure    resonant frequency of mems resonator is plotted
as a function of temperature and the bias voltage 

   feature selection
first  we investigate that which polynomial is the best
to fit the data for an individual resonator  hence  we ignore
the variation of geometrical dimensions between each
device at this point  and assume that the frequency is only
the function of temperature and bias voltage  lets define
the temperature as x   and a bias voltage as x   we have m
training examples  x i   f i   i           m   where x i     x  i 
  x  i  t and f i  is measured frequency  the fitting curve for
the frequency of the resonator can be described as a
combination of polynomials in two variables 

f  i        a  j k    x  i    j  x  i    k
j

k

   

where     j     k i   j   n
if we treat all variables as high dimensional input
features such that z    x  n  x n  x  n  x   x x  n       x   x      t
then  we can linearized the equation as f  zt   can be
calculated with a normal equation 

fics    autumn     
 
      z  z    z  f  
t

  

t

  f      
   
 
f       
   f  m     

  z    t  
 
 
z         
   z  m  t   

since we have a large number of features    features
for n       we conduct feature selection to extract important
features using backward and forward search  we use
hold out cross validation      of the data  and
leave one out cross validation  loocv  to calculate the
generalization error for the feature selections  we use two
criteria in cross validation routine  maximum error method
 maxe  and average error method  avge   in each
iteration step  we obtain the array of error values correspond
to learning examples  here  maxe uses the maximum value
of errors and avge uses the averaged value to choose more
significant feature set  we start feature selection from the  th
order   variable polynomial 
fig    shows the result of feature selections for three
different devices  we compared the number of removed
features with the error for the backward search  fig     i 
ii    and the number of features with the error for the
forward search  fig     iii  iv    avge and maxe are
examined in each case 
from the calculation result  we can observe that the
average error is minimized when the number of removed
features is        when we apply backward search  for the
forward search  the average error is minimized when the
number of feature is         larger number of removed
features is preferred for backward search and smaller
number of features for forward search since we want to
reduce the measurement points to generate the fitting curve 
using the measurement data of those devices  we
summarize top    features to be removed or chosen by each
search algorithm  table    
from the analysis of the results from both search
methods  we found that we can obtain the best fitting error
when the number of feature is      we conducted feature
selection for the data from three different devices  and
obtain similar trend for the optimized number of features 
therefore  we conclude that the numbers of significant
features are common for different devices 

 ii 

 iii 

 iv 

 i 

figure    calculation result form feature selection
algorithm   i  and  ii  show the average and the maximum
error for backward search   iii  and  iv  show the average
and the maximum error for forward search    different types
of cross validation methods are used to evaluate errors 

fics    autumn     
table    top    feature list chosen by feature selection
algorithm 
backward
loocv
hold out

backward
loocv
hold out

forward
loocv
hold out
forward
loocv
hold out

avge
x    x  x    x    x  x    x  x   x  x   x   x  x   
x    x    x   x    x    x x  
x    x  x   x  x   x    x  x   x  x   
x    x  x    x  x    x x    x    x   x  x   x x 
maxe
x    x  x   x    x  x   x  x    x    x  x    x  x   
x x    x  x    x  x    const  x x    x 
x    x  x   x  x   x x    x    x    x  x    x  x  
x  x    x  x   x    x x    x x   x x  
avge
const  x    x    x  x    x x    x  x    x  x   
x    x  x    x  x    x    x   x    x  
const  x   x  x    x    x  x    x  x    x  x   
x    x  x    x    x x    x  x    x x     x  
maxe
const  x x    x    x    x    x    x   x    x  x   x  
x    x    x  x    x  x  
const  x x    x    x x   x   x  x   x   x  x   
x  x    x    x    x x    x  x   x 

random search for feature selection
from the previous section  we decided how many and
which features are needed for the fit with the smallest fitting
error  however  feature selection methods  forward search
and backward search  we used above are heuristic so that
they do not guarantee that the solution has the minimum
fitting error  it becomes more evident if we see solutions
presented on table    although there are some correlations
among solutions  no unique solution exists  therefore  we
can conclude that there is room for improvement with other
search method  this is the motivation to implement the
random search method for feature selection 
the random search method compares fitting error of a
large number of possible feature sets in a loop and returns
the feature set with the smallest error  at the first step 
randomized feature set is generated by the code  since we
start from  th order   variable polynomial equation  we have
total of    features in the feature pool  therefore  if we want
to select n features through random search algorithm  we
have    c n different features sets to compare  here  we will
use n    because we learned    is the minimum number of
features with which we can achieve sub ppm error  hence 
at least    c               iterations are needed to obtain the
solution in an ideal case  this is computationally heavy
process so that couple of weeks is required on a personal
computer  therefore  we decided to run a routine until top
   smallest errors are smaller than backward   forward
search result  and then analyze feature sets in a top    list 
this modification makes the result of random search
method not to be the guaranteed best solution  but pseudo

best solutions will be still meaningful if we can improve
fitting error 
in the implementation  device    and    are used with
loocv for cross validation and maxe for error criteria 
after   million iterations  results are compared to forward
search results  table     if we obtain the most frequently
appeared features from the top    feature set list  we can
build a feature set with small fitting error  the resultant
feature set is shown in table   
table    comparison of fitting errors between forward
search and random search 
device
  
  

forward search
       ppm
       ppm

random search  top   
       to        ppm
       to        ppm

comparison with analytical model
finally  we compare the result of feature selection from
random search with the analytical model based on the
physics of the resonant beam  the frequency of the resonant
beam is a function of the temperature and the bias voltage
and it can be described as following in a simple model 
f  t  vb    

 hsi  t        sio  vb 
 
      
b t    
 
  t sio   t        gbeam  t    sio    
    si  t  ac  t   l t  

   

where si is the mass density of silicon  ac is the
cross sectional area of the beam  l is the length  b is the
bending stiffness  hsi is the height  tsio  is the thickness of
sio  layer  and gbeam is the gap for electrostatic transduction 
these material and dimensional variables are known to be a
function of temperature    and si are permittivity constants 
we conduct taylor expansion of the eqn    to express
frequency as a polynomial function of temperature and bias
voltage to make eqn    comparable to eqn     after taylor
expansion  we compare which terms in the resultant
polynomials are important by checking variance of each
terms in the given temperature and bias voltage range 
table   shows the comparison of important features
from the analytical model approach and the random search
method  features in red color are common features from
those two different methods  from this result  we observe
that   out of    features are shared  this is slightly more
than      which implies that our feature selection methods
are reasonable in physical sense  however  there are still
mismatch of features  it suggests the current analytical
model is not sophisticated enough to describe the relation
between frequency  temperature  and the bias voltage
correctly  this is true because a known phenomenon such as
a f effect is not included in eqn    due to its complexity 
also  it is possible that unknown factors affect the
measurement result  causing eqn    not to predict frequency
precisely 
in conclusion  comparison between analytical model
and results from feature selection proved the reliability of
feature selection method we used  also  it gives us the need
to improve the analytical model for better prediction 

fics    autumn     
table    comparison of the combination of    best features
extracted by random feature selection algorithm and the
analytical mode 
random feature
selection
analytical
model

const   x  x    x    x    x    x x    x  x   
x x    x   x  x    x    x  x    x  
const   x    x    x    x   x  x    x    x  x   
x x    x    x  x    x x    x  

   optimized calibration point
in the previous chapter  we could specify the
combination of optimized features using feature selection 
as a next step  we minimize the number of measurement
points to generate calibration tables with similar accuracy 
since the optimized number of feature is     we only need
   measurement points to generate calibration table  we
reduce unimportant measurement points using backward
search algorithm  fig    show the fitting curve which is
generated by    measurement points chosen by backward
search algorithm  and the error between the fitting curve and
the measurement values  the maximum error of the fitting
curve is       ppm  since we originally need     points to
generate the calibration table with      ppm maximum
error  we could achieve    times reduction of measurement
points with maintaining sub ppm error 
optimized measurement points chosen by a certain
device should be applicable for other devices  hence  we
generate fitting curve for other device using the same
measurement point  comparison of maximum and mean
error of each device is shown in table    we can see that all
maximum error is sub ppm 
 i 

 ii 

figure     i  calibration table generated by the optimized   
measurements point using backward search   ii  the error
between the generated calibration table and measurement
result 
table    maximum and mean errors of calibration table
generated by    measurement points  measurement point is
specified by original device with backward search
algorithm  and those points are used for the calibration in
device         and   
device  
max  error
 ppm 
mean error
 ppm 

original

 

 

 

     

     

     

     

      

     

      

      

   device to device variation
in previous two parts  we figured out the way to obtain
a calibration curve for a device in efficient way  although
those are great accomplishment  we want to further reduce
the number of measurement points 
the idea starts from the fact that resonators with the
same design share general frequency temperature bias
voltage characteristics even if there is a small variation due
to uncertainties in manufacturing process  in other words 
although we cannot apply the characterization result of one
device to other devices directly  it is possible to estimate the
fitting curve of a test device if we combine full
characterization data of training devices with a few
measurement data of the test device 
since the variation is caused by latent  unobservable 
variables such as dimensional variables of the resonant
beam  we need additional variables on top of temperature
and bias voltage to learn general characteristics  the
frequency of at certain temperature and bias voltage points
are only option for this purpose because there are no more
observable variables 
unlike eqn     which is a good hypothesis for a single
resonator characteristic  we dont know which hypothesis
effective to treat device to device variation due to additional
input variables  therefore  we decide to use the gaussian
process regression since it free us from the difficulty to
choose right hypothesis 
lets define training input as xin  training output as f 
testing input as x in  and the testing output as f   as
additional input variables to identify each device and to
learn general characteristic  we include the frequency of
certain measurement points to input xin  if we define 
m    of on calibration data on each device
n    of devices for training
k    of measurement data on a test device

fics    autumn     
input for the gaussian process regression can be
described as 

 ii 

 
  f   
  x  y   
    
   
  f   
  
    r nm k    k   
f           r nm k       x in    
  xn yn  
    
 
 
  f n  
  xt yt  
 f  
  t 
 
f       ft       r m k       x  in     xt  yt      r m k    k   
where 
   
   
  xi  
 
xi  
  fi  x        
  fi     fi k  
 
 
 f
 
   
     
     
 
x
x
f
 x
 
i    
    x     i  
  i  
 
fi     i
 
y
 
i
      i    
   
   
   
   m  
 
 
 
 m    
 m    
   fi  x     
   xi   xi     
  fi     fi k  
  xt      xt       
  ft  x        
  ft      ft  k  
     
 
 
 f
     
   
 
ft  k  
x
xt     
f  x    
t   
 
ft     t
  xt     t   
  yt    
   
     
   
   
   
   k  
 
 
 
 k    
 k    
   ft  x     
   xt    xt      
  ft      ft  k  
  xt k   
 
xt k   
  ft  x  k       
  ft      ft  k  
  
  
 
 
 
 f
 k   
 k     
 k   
 
ft  k   
x
xt     
f  x
  
t   
ft      t
  xt      t   
  yt     
   
 
 
   
   
   
 
   m  
 
 
 
 m    
 m    
xt      
   ft  x     
   xt   
  ft      ft  k  
in the implementation  we prepare measurement data of
  devices with identical design  then  we use full
characterization data of   devices with data from a few
measurement point of the test device for training with the
squared exponential kernel  after optimizing parameters for
the regression  we generate the calibration table  fig     
less than    ppm error is achieved with   points
measurement  and less than    ppm error with   point
measurement  this is great result considering we use only
two devices for training  further improvement is expected in
the future when more training devices are prepared 
 i 

figure    calibration table generated by  i    point
measurements and  ii    point measurement based on the
training data of   devices 

conclusion
using tools in machine learning  we success to develop
effective calibration process for the frequency control of
mems resonators  we achieve    times reduction of
measurement points for the calibration with maintaining
sub ppm error between the fitting curve and measurement
values  also  we demonstrate the use of gaussian process
regression to solve device to device variation issues  since
the current calibration error in this part is not sufficient for
the commercialization  future work would be focused on the
improvement of this problem using large amount of training
data 

acknowledgement
we would like to thank prof  ng and cs    teaching
team for great learning experiences 

references
    cs    machine learning  lecture note
    s  chatterjee and a  s  hadi  regression analysis by
example  hoboken  john wiley   sons       
    c  e  rasmussen and c  k  i  williams  gaussian
process for machine learning  mit press       
    c  t  c  nguyen   mems technology for timing and
frequency control   ieee transactions on ultrasonics 
ferroelectrics  and frequency control  vol      pp 
              
    g  k  ho  k  sundaresan  s  pourkamali  and f  ayazi 
 temperature
compensated
ibar
reference
oscillators   in   th ieee international conference on
micro electro mechanical systems  mems     
istanbul  turkey         pp          
    r  melamud  b  kim  s  chandorkar   m  a  hopcroft 
m  agarwal  c  m  jha  and t  w  kenny 
 temperature compensated
high stability
silicon
resonators   applied physics letters  vol            
       
    http   www vectron com products tcxo tcxo index htm

fi