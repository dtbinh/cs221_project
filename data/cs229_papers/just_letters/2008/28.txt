m achine l earning for g ene b ehaviour c lassification
karan mangla arunanshu roy
december         

abstract

  

ccnb   g m  and ccne   g s  data

  
an interesting problem in biology is to determine the activation phase of genes  the human body contains nearly
 
       genes  many of these genes play a wide variety of
roles in the cell cycle  identifying the phase of activation
 
of the gene can help determine its function in the gene 
experimentally determining the phase of all these genes
 
can be expensive  our tool attempts to use machine learnccnb   g m  vs bub b  g m 
ing to determine the activation phase of a gene based on
 
ccne   g s  vs bub b  g s 
its expression profile  we first normalize the genes to be
able to capture activation and deactivation  next we apply
 
 
 
 
 
 
 
 
 
 
  
  
svm on this dataset using a small number of preclassibub b  g m  microarray data
fied genes as our training set  since genes can be active in
multiple phases  we created a separate classifier for each figure    plot of bub b  g m  data vs ccnb   g m 
activation phase 
and ccne   g s  data

 

introduction

 

errors in data

the cell cycle is one of the most important gene processes  one of the major issues in tackling this problem is the
involving a large number of genes in a wide variety of inaccuracy of the data  there are various reasons for errors
functions  gene transcription in the cell cycle occurs in in the data 
phases  with each phase having its own specific transcription factors  understanding the genes involved in each
 errors in expression profiles  while the expression
phase  would provide a better understanding of the cell cydata was carefully collected there are many sources
cle and also make it easier to identify the function of the
of errors in this data  firstly  the experiments were
gene  running experiments to find the phase for all       
not conducted on synchronized cultures  hence the
genes would be quite time consuming  our tool provides a
cultures would have contained a mixture of cells in
fast machine learning approach to classify genes to cell cydifferent phases at time of collection of expression
cle phases  based on their expression profiles in microardata  this will greatly reduce the strength of phase
ray experiments 
signal in the expression profiles
our data consist of       affymetrix u   plus     hufurther  microarray analysis suffers from errors due
man microarrays      the datasets were normalized using
to dead probes and other problems that corrupt the
the standard robust multi chip analysis rma       in toexpression profiles 
tal  we have        gene profiles  as genes are associated
to multiple probes  we have also obtained set of     genes
 errors in classified data  our collection of classified
classified into cell cycle activation phases  corresponding
genes are also expected to have errors due to the difto      probes in the microarray  genes were classified
ficulty in experimentally classifying genes  it is estiinto the g  s  g   g  m  m g  and s cell cycle phases 
mated that     of our classified genes are incorrectly
as can be observed in figure    genes in similar phases
placed into activation phases  this will also greatly
appear to be correlated while genes in different phases are
hamper the accuracy of the algorithm 
less so 
 

fi 

experimental procudure

precision recall curve for gda
    
   

we split our data randomly into     training data and
    test data  all algorithms were trained and tested only
on the training data  testing of algorithms was done by
creating a hold out data set which was used to evaluate the
model learned by the algorithm on the remaining training
set  our best algorithm was then verified on the     test
data 

    

precision

   
    
   
    
   
    

 

gda

we first applied gda to the problem  we used the simple
gda algorithm to the data  however  running the gda algorithm over the entire data gave a covariance matrix that
was nearly singular  making the calculation error prone 
using standard pca analysis we reduced dimensionality
of the input data  after running pca  the top k components were chosen as input for the learning algorithm 
in order to measure our results  we chose to compare
precision and recall rather than accuracy  since for each
phase the proportion of genes not active in that phase are
much larger than the proportion of genes active in that
phase  even classifying all the genes as not active in the
phase gives high accuracy  which is not actually desirable 
we observed that our system had high variance  to reduce the number of parameters in the system and prevent
overfitting  we applied the naive bayes assumption on
our data  p  x i   y      and p  x i   y      were modeled
as gaussian distribution which were independent for all
i  thus the number of parameters learned is reduced and
prevents overfitting 
this method was applied for a variety of number of input parameters  the results have been shown in figure
   we have plotted precision and recall values obtained in
the different runs  we observe that the overall f values are
very low for gda  this is expected since our features are
unlikely to be independent 

   
   

    

   

    

   

    
recall

   

    

   

    

figure    gda results for classification of g m genes
recall
    
    
    
    
    

precision
    
    
    
    
    

table    precision and recall tradeoff for logistic regression

we used pearsons correlation to try to select good features for this dataset  however  as can be seen from from
table   feature reduction did not improve our results  implying that most features are useful in evaluating the activation phase of the gene 

 

support vector machines

support vector machines were used to attempt classication of the genes due to their inherent advantage in dealing with large feature spaces and large training sets  svms
  bayesian logistic regression
also give us the option of trying out different kernels that
suit our data and has the advantage of handling outliers
since generative algorithms were performing quite poorly through the use of regularization  svm software written
on our problem we attempted to apply discriminative algorithms  we applied bayesian logistic regression using
k
recall precision
an online software     
   
    
    
we observed improved results suggesting that our data
   
    
    
cannot be represented as a gaussian distribution  note
   
    
    
that while the individual values of the precision and re          
    
call are not higher than those observed in the earlier algorithms  the f value of our results is much better  the
table   provides a tradeoff between precision and recall table    precision and recall for different number of features
using bayesian logistic regression for the g m phase 
 

fiphase
g s
mg 
g m

recall
  
  
  

precision
  
  
  

number of features used
   
   
   
    

recall
  
  
  
  

precision
  
  
  
  

table    svm based classification results on hold out set
table    svd based feature reduction results on hold out
set
in matlab     which is available online was used for
these simulations  the first classication of g s genes was
done using a linear kernel  the results from the svm were
superior to the other supervised learning techiniques that
we tried  we achieved a precision of     and a recall of
     we then used a modified kernel using the pearson
correlation between feature vectors  this improved our
precision to     and recall to     
all the      features were used in these computations 
however some feature reduction techniques have been
tried on this data as explained in the next section and we
observed that similar precision and recall can be achived
with fewer features but there is no significant improvement using feature reduction  the results were not affected by value of c lying between   and     and the value
of the regularization parameter is chosen to be      table
  shows the results for classication of three phases using
this scheme  we get the best results for g m and g s
phases for which we have the largest amount of classified
genes 

rank
   
   
   
   

g m since the largest amount of data is available for that
class 

   

precision and recall    

svd based feature selection

singular value decomposition was used to select a reduced set of features for classification  it was observed
that reducing the number of features did not help to improve the classification of genes in g m  the results are
summarised in table   

  
  

precision
  
  
  
  

table    low rank approximation denoising results

   

   

recall
  
  
  
  

low rank approximations to denoise
training data

using singular value decomposition on training data  low
rank aproximations were obtained  we expect this to help
reduce the noise that may be present in the training data 
the results however showed that this method of denoising
did not improve classification  the results are summarised
in table   

  
  
  
  
  
  

   

  
 
 

 

 

 
threshold value

 

 

 

removing low variance data to filter out
dead probes

the microarray data was filtered to remove genes for
which the data showed a low variance  we believe that
figure    precision and recall for g m classification usthis can be indicative of a dead probe and hence using a
ing svm
minimum threshold variance  the data was filtered to remove probes with a low variance in measurements  no
significant improvement could be obtained with this technique  the results are summarised in table   

 

feature selection

since the best results obtained could only achieve about   k nearest neighbors
    precision and recall on the data we tried feature selection and data cleaning techniques to improve classifi  given that linear classifiers such as svm and logistic recation   the results are for the classification of genes in gression were working very poorly on this data  we tried
 

ficorrelation threshold
   
   
   

recall
  
  
  

precision
  
  
  

  

discussion on data

since no improvment could be obtained through the above
feature selection and data denoising techniques we attempted to understand the data better through a study of
table    low variance filtering results
correlation among data belonging to different classes  it
appears that while genes belonging to the same activation
phase are often well correlated  there may be a good corphase f value
relation with genes belong to other activation phases too 
g s
    
the plots here show the correlation between the genes
g 
    
classified as g m and those classified as g s  the corremg 
    
lation between g m and g s genes is also shown  we see
s
    
that several genes in g s are well correlated with genes
g m
    
classified as g m  this illustrates why the classification
of genes based on the available microarray data is inhertable    precision and recall for each phase for   nn
ently a difficult problem  given that the data may contain
misclassified genes and other sources of noise we believe
that it is difficult to achieve better classification using this
non linear classifiers in an attempt to improve the accu  data 
racy of our classification  one classifier that we considered was   nn  this classifier would help reduce the inaccuracy caused by classification errors in our training set as
it uses more local characteristics to learn models  we ran
this algorithm using the weka software        nn however
performed quite purely on our problem  we have provided
the per phase f values in table   received for    fold cross
validation 
visualization of correlation matrix for g s

   

   

   

   

   

genes in g s

   

  

   

  

 

decision trees

 

  

   

  

   

  

another popular non linear classifier is decision trees  we
tested whether using simple decision trees would allow
our data to improve  again we observed quite poor results  we tried to apply the ada boost algorithm to improve our decision trees  however  their was very little
improvement in classification  both these algorithms were
run using weka implementations     

  

  

  
genes in g s

   

   

   

figure    correlation between g s genes

  

final results

results obtained for ada boost for various boost iterations are given in table    classification was only done having noted that the svm and the bayesian logistic refor the g m phase of the cell cycle 
greassion perform best in classifying our data  we ran the
classification on the initially described test set  the svm
achieved a precison of     and a recall of     while the
bayesoan logistic regression showed a precision of    
no  of iterations precision recall
and     recall 
  
    
    
  
  
    
  
    
  
   conclusion
table    precision and recall for different number of as we can observe the data is very noisy  hence  we
boosting iteration in ada boost
get better classification results from linear classifiers than
 

finon linear classifiers  the best results are obtained on using svms on this data  normalization of the data helps
give a small increase in accuracy of the classifier  however  feature selection techniques completely fails on this
dataset  suggesting that most features are important for
classification  finally  attempts to denoise the data were
also not successful 
we  however  noted that results improved as the number of training examples for a phase that we could provide
increased  this suggests that with a larger training set this
system would provide increased accuracy  another major
problem with this data is the fact that there are errors in the
classification of the training set  a more accurate training
set should also boost the usefulness of this system
while there are a lot of problems with misclassification 
we see that we do get good results which means that using
this algorithm to prefilter genes will help to classify genes
in to their correct phases  it is important to note that of
the        gene probes only      have been classified as
yet  thus we believe that inspite of the modest precison
and recall attained  the tool can be used to classify a large
number of genes and greatly increment the current information on the activation phases and roles of genes in the
cell cycle 

visualization of correlation matrix for g m

   
   
   
   

   

genes in g m

   

  
   

  
 

  

   

  

   

  

  

  

  
genes in g m

   

   

   

figure    correlation between g m genes

references
    s  canu  y  grandvalet  v  guigue  and a  rakotomamonjy  svm and kernel methods matlab toolbox 
perception systmes et information  insa de rouen 
rouen  france       
    alexander genkin  david d  lewis  and david madigan  bbr  bayesian logistic regression software 

visualization of correlation matrix
   
   

    r  a  irizarry  b  m  bolstad  f  collin  l  m  cope 
b  hobbs  and t  p  speed  summaries of affymetrix
genechip probe level data  nucleic acids res        
february      

   
   

   

genes in g m

   

   
  

    debashis sahoo  david l  dill  andrew j  gentles 
robert tibshirani  and sylvia k  plevritis  boolean
implication networks derived from large scale  whole
genome microarray datasets 
genome biology 
  r      october      

 
  

   

  

   

  

  

  

  

  
genes in g s

   

   

   

    ian h  witten  eibe frank  len trigg  mark hall 
geoffrey holmes  and sally jo cunningham  the
waikato environment for knowledge analysis 

   

figure    correlation between g s and g m genes

 

fi