 

cs    project report 
improving search engine for a digital library
farnaz ronaghi khameneh
farnaaz stanford edu

abstract this project introduces a novel approach for
using click through data to discover clusters of similar
queries and similar urls  one can simply observe that
users reformulate their queries to find a desirable result 
we define this sequence of queries as a query chain  our
data set consists of records containing user id  query term 
query date and time  clicked item url and clicked item
rank if there exists one  viewing this data set as a bipartite
graph we perform a graph based agglomerative clustering
to find similar queries and similar urls  we intend to use
human intelligence in expressing his information need as
a prior knowledge in agglomerative clustering which will
result in an earlier convergence and a noticeable improvement in whole system performance  we also describe how
to validate this model and how to use query url clusters
in a real world search engines 
index terms machine learning  information retrieval

i  i ntroduction
textual information in our digital library  library
of congress  forms a massive unstructured data set 
with the increasing size of data available in such
library  there is an acute need for automatic methods
to organize data  most text clustering algorithms
represent document as vectors in a high dimensional
space and they put them together in a cluster according to a distance measure      the algorithm
that we use for query url clustering is basically
content ignorant  similarity measures based on cooccurrence information from query logs lead the
clustering technique     
intuition behind using agglomerative clustering
is based on two observations  first  users express
their information need with different terms but they
may select the same url as the most relevant
result  this shows that these two different queries
are expressing the same information need  second 
users may search for same query but click on urls
which seem to be totally unrelated using measures
like cosine distance  using latent information in

query logs will assist in finding this set of related
urls 
as users search  it is well documented that they
try to reformulate their queries instead of switching
to a new search engine      we call sequence of
query reformulations  a query chain  to the best of
my knowledge researches have considered queries
independently for ranking judgments      uses query
chains to rerank search engine results by extracting
implicit preference judgment from clicked items in a
query chain  they assume to have the top ten results
returned by search engine which is not available in
our data set 
the key contribution of this work is recognizing
that we can successfully use evidence of query
chains that is present in search engine log files
to enhance graph based agglomerative clustering 
and improving it with a more reasonable similarity
measure  in section ii we will propose a method
to extract query chains automatically from a search
engine log file  section iii will talk about agglomerative clustering algorithm  section v and iv will
give experimental results and discuss various uses
of this technique 
ii  e xtracting q uery c hains
in order to make use of human intelligence to
express his information need  we should be able to
detect query chains  in this section we propose an
algorithm for automatically extracting query chains
and judge its effectiveness 
    uses the simple heuristic that any two queries
from the same user which follow each other in
less than    minutes are in a query chain  another
approach for detecting query chains is training an
svm which needs labeled data  in     researchers
have manually detected query chains in a log file
containing      queries  they have used these
chains as a basis for comparing different evaluation

fi 

methods  they have trained an svm using feature
vector parameters as described in table i 
table i
parameters to train an svm for detecting query
chains  

cosinedistance q   q  
cosinedistance doc ids of r   doc ids of r  
cosinedistance abstracts of r   abstracts of r  
trigrammatch q  q  
shareoneword q   q  
sharetwowords q   q  
sharephraseoftwowords q   q  
numberofdifferentwords q   q  
t   t                   
seconds t   t        seconds
normalizednumberofclicks r  

using five fold cross validation for comparing
their    minute heuristic and trained svm with
respect to query chains extracted manually  svm
training out performs the heuristic algorithm only
for   percent  computing this feature vector for
every pair of queries is so expensive  so using the
simple heuristic will be more reasonable 
using    minute heuristic will result in grouping
lots of unrelated queries in the same query chain 
users may search for another topic without any
noticeable time gap between the two  to avoid this
problem we add a new simple heuristic  we find
the common longest subsequence  lcs  of the two
query terms  if the result was larger than a preset
threshold we will add them to the same query chain 
to extract query chains we make a graph of query
terms  there will be a link between two terms if
they satisfy    minute heuristic and lcs conditions 
query chains are the connected components of this
graph 
iii  agglomerative graph   based
clustering

clustering queries submitted to a search engine
appears to be a very explored task  query clustering
has been used in personalizing search  query suggestion modules and spell correction tasks  researches
on user behavior show that most users try to reformulate their queries in a search engine instead
of switching to another search engine  moreover

study of search engine usage patterns shows that
have begun to rely more on one word queries and
expect search engines help them in finding their
actual information need 
clustering urls becomes useful in personalizing
search engines  researches have been investigating
the more general problem of document clustering  in
this group of algorithms documents are represented
as vectors in a high dimensional space hierarchical
and flat clustering algorithms place documents in
the same cluster based on a distance measure in this
space  in this project we are going to use a graphbased hierarchical clustering proposed in     with
a more reasonable similarity measure  according to
    content aware algorithms may fail in clustering 
 text free pages  distance functions based on
the vector representation of documents fail on
documents which only contain images
 pages with restricted access  pages may be
password protected and their content unavailable to a clustering algorithm 
 pages with dynamic content  a clustering algorithm based on content is more susceptible
to placing these urls in the same cluster
the most important advantage of agglomerative
clustering proposed in     is that it is content
ignorant  urls are placed in the same cluster based
on co occurance measures  it is not vulnerable to the
problems given above 
algorithm proposed in     starts by making a
bipartite graph of queries as white nodes and urls
as black node  there will be a link between a query
and a url if at least one user has clicked on that
url as the relevant result for the corresponding
query  intuitively if we define n  x  neighborhood
of x and n  y  neighborhood of y  similarity of
two nodes x and y should be proportional to n  x 
and n  y  overlap  the basic similarity measure
proposed in  reference  is as follows 
 n  x   n  y  
   
 n  x   n  y  
to use this graph to discover separate clusters of
queries that express the same information need or
url clusters that contain urls related to similar
information needs      propose the following algorithm 
 x  y   

agglomerative iterative clustering

   score all pairs of white vertices according to
equation  

fi 

   merge the two vertices with the largest similarity measure
   score all pairs of black vertices according to
equation  
   merge two black vertices with the largest
similarity measure
   exit if convergence criterion holds else go to
step  
at first glance it might not be clear that why
an iterative approach is necessary  in figure   after
merging vertices   and    vertices a and c will suddenly be similar refer to    this iterative approach
discovers hidden information faster 
a

 

b

c
fig    

 

necessity of iterative clustering

a
b

 

c
fig    

necessity of iterative clustering

similarity between vertices will lie between zero
and one  one of the major problems with this
similarity measure is that it does not distinguish
between two vertices having exactly the same neighborhood and vertices having exactly the same two
neighborhood  the second problem is that merging
two clusters will result in deleting repeated vertices
which destroys valuable information about vertex
worth in clusters  we can give weight to vertices
in a cluster according to the number of times they
appear in that cluster  vertex repetition in clusters
shows closer relation cluster and vertex  urls
many repetitions in a cluster representing a special information need  discloses a close relationship
between the url and regarding information need 

we use this information to make equation   as the
sum of intersection members weights over the sum
of union members weights  this information can
further be used for reranking search engine results 
exploring search engine log files  we found a
large number of queries with no selected item url 
these queries happen so often  they are either a miss
spelling or users inability to express his information
need  these will result in having isolated vertices
in our bipartite graph  agglomerative clustering
algorithm will be unable to place them in any of
the resulting clusters as long as there is no cooccurance information about them  here is the time
where query chains show their ability in using
human intelligence  using our prior knowledge on
user query reformulations  we will merge all query
vertices in the same query chain  this will eliminate
isolated vertices  further more it will result in earlier
convergence of agglomerative clustering algorithm 
iv  u sage
clusters resulting from agglomerative clustering
algorithm either represent queries expressing the
same information need or urls which are related to
the same information need  noticing to the fact that
query reformulations can result from misspellings 
query clusters can be used for spelling correction
purposes 
on the other hand queries in the same cluster
represent the same information need  we can use
this fact in making query reformulation suggestion
systems      used clusters for this purpose and compared their result with existing suggestion system by
using user implicit feedback 
we use the resulting query and url clusters for
reranking search engine results  the scenario is as
follows 
 user searches for a new term 
 assign users search item to one of existing
query clusters 
 retrieve basic search engine results 
 delete all urls in the associated url cluster
from basic results 
 rank urls according their weight in associated url cluster 
 add ranked urls on top of basic search engine results 
assigning users search term to one of existing
clusters has a great impact on final ranking  first

fi 

we compute lcs for query term and all terms in all
clusters  we choose the term having maximum lcs
as the cluster representative  we select the cluster
for which lcs of its representative and query term
is maximum  intuitively ranking urls in associated
cluster according to their weight and adding them
to the top of search engine basic results will end
in a better ranking  as long as we know queries
in the associated cluster are the best matches with
user information need  further more their weight
is a good clue of how close they are to users
information need  we expect this system result in
more user satisfaction 
v  e xperimental r esults
this report was supposed to introduce an algorithm to improve a digital library search engine 
the library under study is library of congress  a
governmental library  there exist specific law for
disclosure of its query log information  we have
used aol search engine published data  it is very
huge data set consisting of ten files  we use one
file for training and one file for testing  statistics
on training data can be found in table ii  these
query logs are unfiltered  we have filtered them to
eliminate objectionable data 
table ii
s tatistics on training data
number of queries

       

number of query chains

      

number of terms

       

number of urls

      

standard ways of testing user satisfaction from
ranking functions always involve running a public
search engine for some months  ask users for
explicit judgements or extract judgments implicitly
from deployed search engine log files          we
didnt have time to do so  we have a novel approach
for comparing our model to the basic agglomerative
clustering algorithm 
we use one of search engine log files as a virtual
online search engine for testing proposed ranking
approach  we have the following information about
each query in the log file  if user has clicked on any
item  we know that item and its rank  if user has reformulated his query we have his query chain so we

know which urls he has clicked on  according to
the fact that reformulating queries most of the time
is a means for expressing unsatisfied information
needs  it is reasonable to give more score to urls
clicked on at the end of a query chain     so our
testing approach will be as follows 
 retrieve a new query from log file 
 find its chain 
 assign it to one of query clusters according to
proposed mechanism 
 rank associated url cluster members according to proposed approach 
 give one score if clicked items have better
rank in proposed approach along with paying
attention to the rules given above
this method for testing can only determine number of times that one algorithm outperforms the
basic search engines approach based on given
assumptions on use behavior  without having an
online search engine and logging users implicit
feedback by methods proposed in      we can not
tell anything about actual user satisfaction in each of
two approaches  although our method can compare
user satisfaction in different methods  using this
approach our results are given in table iii  applying
our method of testing basic agglomerative clustering
improves user satisfaction    percent  adding query
chain information will improve our result to    percent and enhancing similarity measure for clustering
algorithm will improve result to    percent 
table iii
experimental results  

clustering proposed in  ref 

   

add query chain information

   

improve similarity measure

   

according to our unusual method of evaluation 
in some cases we can not say that we definitely have
improved search engine ranking  noticing that   
percent of users only view the first two result pages 
we can claim that as a whole we have improved
user satisfaction on these two pages  we view results
that are clicked urls mostly having a rank between
one to ten in basic search engine ranking  on the
other hand these results have been proved to be
related to users information need  as results show
it is reasonable to claim we are improving user
satisfaction in terms of ranking results  we believe

fi 

testing this approach with standard measures prove
it to be affective and will give more meaningful
results on its performance 
vi  c onclusion
in this project we used two heuristics to find
sequences of user query reformulations named as
query chains from search engine log files  we made
a bipartite graph from query terms on one side
and urls on the other side  we ran a graphbased agglomerative clustering along with a more
reasonable similarity measure to find clusters of
urls and clusters of query terms  clusters of query
terms depict various formulations of an information
need  on the other hand  clusters of urls consist
of urls related to the same information need 
using these facts along with historical studies of
user search behavior  we showed a way to improve
user satisfaction mostly in terms of ranking there
are lots of queries for which our basic search engine did not return any satisfactory result  whereas
by using this method we are returning are urls
which are expected to be the most related to user
information need and in some sense we can say we
are improving precision 
the key contribution of this project was understanding the fact that our prior knowledge on query
chains can make a major improvement in agglomerative clustering algorithm  this can be used in many
application for improving search engine results 
vii  acknowledgements
author would like to thank amin saberi for
his guidance throughout this project  and nathan
sakunkoo for his suggestions on data set 
r eferences
    doug beeferman and adam berger  agglomerative clustering
of a search engine query log  in proceedings of the sixth acm
sigkdd international conference on knowledge discovery and
data mining  pages         acm press       
    andrei broder  a taxonomy of web search  sigir forum 
                
    charles l a  clarke  maheedhar kolla  gordon v  cormack 
olga vechtomova  azin ashkan  stefan buttcher  and ian mackinnon  novelty and diversity in information retrieval evaluation 
in sigir     proceedings of the   st annual international acm
sigir conference on research and development in information
retrieval  pages         new york  ny  usa        acm 
    laura a  granka  thorsten joachims  and geri gay  eye tracking
analysis of user behavior in www search  in sigir     proceedings of the   th annual international acm sigir conference on
research and development in information retrieval  pages    
     new york  ny  usa        acm 

    thorsten joachims  evaluating retrieval performance using
clickthrough data  in in proceedings of the sigir workshop on
mathematical formal methods in information retrieval  pages
           
    christopher d  manning  prabhakar raghavan  and hinrich
schutze  introduction to information retrieval  cambridge
university press  july      
    f  radlinski and t  joachims  query chains  learning to rank
from implicit feedback       

fi