 

autonomous interpretation of elevator panels for robot navigation
mark baybutt  blake carpenter  and kristen lurie
abstract the objective of the work presented in this paper is to
develop a method to interpret interior elevator panels for robot
navigation  we outline a three level
level hierarchical approach
approach  which
applies principles from both supervised
ed and unsupervised
machine learning techniques  in particular  we will show the
development of an algorithm that accepts an elevator panel
image paired with a desired floor location and determines the
region in the image corresponding to the floors butto
button and
optimal location for a robotic arm to press 

i 

introduction

w

hile robots exist which can autonomously navigate
unknown buildings  one outstanding robotic navigation
problem is interaction
ion between robot and elevator  developing
a solution to this challenge would enable robots to traverse
previously unattainable floors of a building  for a robot to
successfully interact with and navigate an elevator  there are
many tasks that need to be performed  these include
identification and action upon the exterior
erior panel  entrance into
the elevator  detection and alignment with the interior elevator
panel  identification and action upon the interior panel button 
and exit from the elevator  klingbeil et al     touched upon the
first area   detecting and manipulating exterior elevator button
panels   as an extension of work related to detecting and
manipulating door handles  despite the similarities to exterior
elevator panel
nel detection  interior elevator panels are more
complex as they contain numerous floor options in various
configurations 
the discussion of work performed herein addresses the
challenge of interpreting and taking action upon interior
elevator panels  in particular  the goal of the project is to
develop
evelop an algorithm that will identify a location for a robot to
press based on the desired floor location with ultimate
implementation on the stair 
ii 

overview

our proposed approach divides the main task into three
simplified sequential steps consisting of 
  
  
  

identifying buttons and labels  figure
figure  a 
interpreting labels  figure  b 
assigning text to buttons  figure  c 
c 

this procedure is intended to be general as to bes
best interpret
any elevator panel 
the procedure starts by identifying an elevator panels
buttons  any object which performs a function when pressed
pressed 
submitted as a project final report for stanford university cs    autumn
     

red regions in figure  a 
and labels  any character or
picture which indicates a
buttons function  yellow
regions in figure  a  
figure    steps involved in
from these identifications 
interpreting an elevator
interpretation
interp
of
the
panel
characters and text on the
labels is performed  yellow regions in figure  b   then  based
on the position of the buttons and labels  the two can be
correlated such that each button has some descriptor of its
function  from these three steps  a depression point for each
button and a descriptor of these points can be determined 
with this information  the robot can ascertain where to press
based on the desired floor location 
iii 

approach

a  data collection and segmentation
elevator panels vary greatly in terms of button design 
orientation and labeling  thus it is extremely important to have
not only a sizable training set  but also a training set that
captures the many different variances in panel style  to create
a training set that reproduced elevator panel variance  we
collected approximately     images
mages of interior elevator
panels 
to aid in cropping positive
and negative training images  a
matlab application was
written which enables users to
select regions of the image and
associate with desired tags 
figure   shows a portion of an
image with the cropping and
figure    user controlled
tagging scheme implemented 
image tagging
four tags have been defined to
identify regions of images  labels  red boxes  
b
labeled buttons
 yellow boxes   unlabeled buttons  green boxes   and negative
 blue boxes  
   after the user crops and tags the image
appropriately  the application automatically selects varying
sized portions of the unselected regions of the image  i e 
 i nonbuttons or non labels 
labels  to include in the negative training set 
to provide added flexibility  the application also provides the
ability to specify regions of the image to explicitly include in
the negative training set  such as key holes which may look
similar to buttons  
user specified information is stored from tagging including 
type of tag  label  labeled button 
button  or unlabeled button  
unlabeled
description for labels and labeled buttons
buttons  e g  alarm  floor   
etc    coordinates and dimensions of each of the tagged
regions  and the button  which each label describes 
des
these

fi 
metrics are later used as ground truth  gt  evidence to
evaluate the performance of each stage of the algorithm in
addition to overall performance 
b  button and label identification
a sliding window object detector  swod      was utilized
to identify regions within test images  which contain buttons
and labels  we utilized     of the tagged images for swod
training to create two image models  a label model  using
both label and labeled button images in the positive training
set and unlabeled button and arbitrary background images in
the negative training set  and button model  using unlabeledbutton and labeled button images in the positive training set
and label and arbitrary background images in the negative
training set   the remaining     of tagged images were used
for testing 
to quantify detection results  the following metrics were
defined  a true positive  tp  detection indicates the detection
box centroid fell within the gt detection box  a false positive
 fp  detection either did not classify the item correctly or a tp
detection with higher probability already identified the gt
item in the image 
the two models were applied to approximately    test
images to gauge overall performance  the output of the
swod for each image was a listing of detections size  x  and
y coordinates  in pixels   and the probability in which it
matched the applied model  the resulting detections had     
recall  but incredibly low precision as compared to gt  the
intuition gained from these initial findings was the models
generated a considerable number of detections per image 
some of which correctly identified the item of interest 
contributing to high total recall  yet the vast majority either
did not accurately identify the item or was a repeat detection
of the item  contributing to low precision  refinement to the
training sets were made and new models generated and
retested  little improvement was seen and from these results 
we concluded that an intelligent method for downselecting
detections was required to increase precision at this stage of
the process and improve accuracy of the overall approach 
to accomplish the downselect of detections  a three phased
methodology was implemented  a static probability threshold
of     was initially implemented where detections above    
reported probability were kept while the rest were discarded 
this approach worked reasonably well in most test cases 
however  failed in instances where detections did not return
relatively high probability  to counteract this effect and
provide a means to generate a more natural threshold per
detection set  a dynamic probability thresholding technique
was implemented wherein the maximum and standard
deviation  std  in probabilities were calculated based upon
each set of detection  probabilities  pr  which fell within the
set of  maxpr  max      were retained 
while detections with probabilities outside of this range were
discarded  the coefficient a was a control parameter that

was experimentally determined through the use of precisionrecall  pr  curves to find an optimal solution  see figure  
and subsequent discussion   the reduction from raw to
thresholded detections can be seen by comparing figure  a
and figure  b 
the second step in the downselect of detections was a
pruning phase  this phase was motivated by the fact that in
many practical applications range finding capabilities could
assist in determining the distance from the camera to the
elevator panel  such is the case with stair   from this
distance  a calculation of expected button label detection size
in pixels can be determined as the physical size of
buttons labels adheres to guidelines set forth by the american
disabilities act  ada       in the absence of such distance
information  the ratio of gt box sizes  in pixels   to source
image size  in pixels   for all training images was calculated
as it was concluded every training and test image was taken
from the same range of distances      feet  from the elevator
panel  the values satisfying equation   and equation   were
used for prune and prune   respectfully 
prune   max 

prune

mean 

min 









 

     std 









equation  

gt


max 
 
image


  min 
mean  gt       std  gt 
image
image 


equation  

satisfying these equations ensured the pruning values will
not exceed the bounding limits of the data set  i e  maximum
and minimum values   for each test image  the pruning values
were multiplied by the image size to determine the expected
range of detection window size  detections which fall outside
of this range are discarded  this downselect step is most
evident in the upper third of figure  b and figure  c in the
removal of the relatively small button detections  seen in red 
and the relatively large label detections  seen in yellow  
the final step of downselecting detections is to remove
overlapping detections  a variety of methods were applied to
achieve this including  probability weighted k means 
probability weighted k median  and probability dominated
percent overlap removal  results from weighted k means
caused resulting centroid positions to be drawn away from
correctly identified button label regions when detections with
high probability were clustered together  a range of k values
were experimented with  however  the effect persisted in a
number of trials  to eliminate the detrimental averaging effect
of k means  a weighted k median approach was applied  this
approach worked reasonably well in assigning the k centroid
to the detection with highest probability in the assignment
cluster  however  it was found to be computationally
expensive and the results from probability dominated percent

fi 
overlap removal performed equally as well at less
computational expense  since the ultimate goal of this
algorithm is to be implemented in near real time  the percent
overlap removal method was deemed preferable  in this
method  detections are compared to one another and if an
overlap percentage above a control parameter overlap is
exceeded  the detection with higher probability is retained
while the remaining detections associated with the overlap
region are removed  the overlap parameter was
experimentally determined through the use of pr curves to
find an optimal solution  see figure    
test images button pr

precision

   
std    
std    
std    

   
   
   
    

    

    

   
recall
test images label pr

    

   

precision

   
    
 
    

    

    

   

    
    
recall

    

    

the pr curve associated with label detection behaves in a
more typical manner where including a greater number of
detections  i e  increasing std  increases recall while
reducing precision  an optimal combination of precision and
recall can be achieved with an std     and     overlap
which jointly maximizes precision and recall  the results from
applying this final step in detection downselect can be seen by
comparing figure  c and figure  d 

    

std    
std    
std    

    

maximum probability  nevertheless  increasing the percent
overlap threshold to an optimal point does improve recall
while not sacrificing precision  the optimal corner point
circled in dark blue represents     overlap  i e  detections
exceeding     shared overlap are trimmed to one detection  
increasing this overlap threshold causes precision to plummet
as a greater number of detections are retained that identify the
same gt location 

 

    

figure    button  top  and label  bottom  precision recall
curves
the pr curves seen in figure   assisted in determining
optimal values for the std coefficient a in the dynamic
thresholding step and
percentage overlap
in the percent overlap
removal step  each
curve in the plot
represents a variation
in std while each
data point represents a
variation in percent
overlap  a sweep of
std values from    
to     and overlap
values of     to    
were made on all test
images  a subset of
these results is shown
in figure   for clarity 
figure    visualization of button
the pr curve shows and label identification  labels in
interesting behavior
yellow  buttons  in red    a  raw
for
buttons
as
swod detections   b  postincreasing std from probability thresholding   c  post    to     does not
pruning  and  d  post overlap
detection and removal
increase precision or
recall  the intuition from this observation is that all button
detections are within     standard deviations from the

c  text and character recognition on buttons and labels
after labels have been identified by the swod  we use
character recognition to classify the segmented labels  three
approaches for label recognition were considered 
text character swod  support vector machines  svm   and
tesseract  googles ocr software   each approach was
tested and evaluated and based upon performance and success
rates  tesseract were selected to implement text and character
recognition on buttons and labels 
the text character swod approach aimed to detect
characters and image patterns in a label using the swod  we
created swod models for alpha numeric characters as well as
common elevator characters  such as      the door close
sign  from each label  we segmented individual characters as
positive training samples  for example  label    was
segmented into a   and a    the   was used as one
positive training sample for the   model with the   and
other parts of the label as negative training samples  each
model was run on a single label  the resulting classification
detections from each model were analyzed and based on these
detections a joint classification was created  a    label  for
example  ideally has many detection boxes from the   and
  models  while every other model has significantly fewer
detections  based on the position of the   model detections
relative to the   model detections  it can determined that the
label is a     this approach did not work well in practice as
both precision and recall values were low and no more data
was available 
the second approach attempted to use svm on a label to
determine its type  the feature vector was the intensity of each
pixel when reduced to a   x   pixel black and white image  a
model was created for numbers       and    while the training
set error for each of these models was     there was no
separation between positive and negative examples and thus
error was high  the models were clearly overfitting the data 
we decided not to pursue svm any further as improving as it
would require us to accurate segmentation each digit from a
label  which proved complicated 

fi 
the third approach uses tesseract to
classify a binary  processed version of a
label  tesseract recognizes black pixels on a
white background and tries
ries to classify the
pixels as characters in its own dictionary 
after experimenting with tesseract  we
learned that it would return text strings that
do not correspond to floor labels
labels  if given
large areas of black pixels that did not
resemble anything or a readable character
with noise surrounding it  also  in some
cases it would incorrectly classify an image
that clearly resembled a known characte
character 
thus  images
mages of labels must be converted
to noiseless binary images with only the
characters remaining to be prop
properly
classified  these images are created by
converting the image to binary using a dynamically selected
threshold based on image contrast and then removing regions
of noise  i e  long  thin lines  regions of a few pixels   due to
the fact  it is difficult to capture
ure a noiseless digit with our
image processing techniques  we try to isolate characters using
eight different images with small variation in threshold and
region detection  ideally  tesseract then classifies the unclear
images as non floor text strings and the clear images as the
true value  the results are then analyzed and the best
classification is returned as the final classi
classification for the
label  as seen in figure   
figure   
tesseract
process path

because tesseract can only
classify
digits
and
text
characters  it returns non floor
text strings for labels with
pictures or many characters 
such as the bell label or a
close door label  labels
that are classified as non floor
text strings are removed from
future steps  this result is
sufficient as the robot does not
need to push non floor buttons
for navigation  the output of the
label text identification step is
shown in figure   

figure     labe
labels classified
through tesseract

in practice  problems arose that ultimately led to poor
accuracy for this approach  figure   shows confusion
matrices for tesseract versus ground truth label
classifications  results show that there is a significant amount
of error in this process  error comes from both the image
processing step  as it is difficult to eliminate noise and retain
the characters  and the ocr step  which often misclassifies
images which seem clear to the observer 
d  classification of buttons and correlation with labels
after recognizing the label text  we then assign text to
buttons with a three step process  this means we will assign
valid floor text to the floor buttons and no text to non
non floor

figure   confusion matrix  a
 a is labels  b is labeled
buttons  with y axis is ground truth label type and x axis
is ocr classification  higher probabilities correspond to
more red shading  the
he diagonal portion of the matrix
contains number values  the last row and column contain
non floor text strings   and the other values are letters 
numbers are occasionally and letters are frequently
classified as gibberish  labeled buttons
buttons are classified less
accurately 
buttons and fp buttons   first  we used svm with a linear
kernel to train a model  which
h correlates labels to buttons     
five features are defined for each button and label pair 
distance and percent overlap between button and label  overlap
between button and other labels  and prediction on whether
label lies on the correct side of the button  which is determined
by the ratio of buttons to labels on the left and right of the
button  this model assumes that a button and its related
rela
label
have roughly the same y coordinate 
coordinate  but does not assume a
placement for the label  which allows us to capture labels that
are to the right  left  and on top of a button as well as multiple
labels for a button  the precision and recall are
             
       and               for the testing and
training sets  respectively   figure  a
a 
after buttons and labels are correlated  the label text is
assigned to the button in which it is paired  if there are
multiple labels for a single button  we choose the label text
over the label button
button text  because tesseract more accurately
classifies labels  precision and recall for this step are
              and               for testing
t
and training
sets  respectively  precision and recall both increase  because
many errors from correlation do not contribute to properly
identifying button text  i e  a button with three identical labels
are matched to only two of them    shown in figure  b  this
process eliminates some false positive buttons  since buttons
that are not assigned to labels are likely false positive
detections 
we applied the svm models in two ways  by including all
labels and by only including valid floor labels  although
accuracy of each method was approximately the same  we
chose the latter because as it is impossible to assign valid
button text from a floor from button text to valid floor label
that are not associated
ssociated with valid floor labels  however  by
eliminating invalid floor labels it is possible to incorrectly
correlate buttons with valid floor labels as the svm model
relies on the labels that are located in the same row as a

fi 
button  with higher accuracyy in the label identification step
and the same high recall and low precision for the label model 
applying the svm with only valid floor labels makes the most
sense as we would correctly eliminate false positive labels
before running the svm 
because there is poor
accuracy identifying label
text  we attempted adjust
some
of
the
misclassifications  such
that all floor buttons are
assigned to valid text and
all non floor buttons are
assigned to no text  the
buttons are fit to a grid by
using the detected center
point of each button 
 figure  c  then  the
pattern of numbers on the
panel is determined by
identifying the
most
common
difference
between floor numbers figure     assignment of text to
across a column and buttons   a  buttons  red  are
correlated with their labels
down a row  we use these
 yellow  as shown with blue
two numbers along with
lines   b  buttons absorb the
numeric label detections
text of the labels to which they
to generate the ideal
were matched  labels that
arrangement of numbers  represent floors are in red  the
this
process
rest are in white   c  button
oversimplifies the typical locations are placed in a grid 
elevator
panel
by  d  labels are adjusted based
assuming  for example 
on numeric labels  red and
that floor labels are only
white boxes represents no
numeric and always vary
change in text  green is
by the same number improvement in classification 
and blue is improper
across a row and a
adjustment 
column  however  this
model of the elevator panel does particularly well when only a
few floor buttons are improperly labeled   figure
figure  d  
iv 

step 
table    component wise
wise system test results

v 

the results from the proposed approach show promise for
an autonomous method for interpretation of elevator panels 
despite arguably low precision and recall for overall system
performance  the approach applied a variety of methodologies
and machine learning principles in search of an optimal and
robust solution  from these varied approaches for each stage 
the best option was selected based upon standard performance
metrics  a number of refinements were identified and are
currently underway  to improve the overall accuracy of button
and label identification  fine tuning
tuning of the label model would
more accurately classify true positives and improve initial
precision  the initial mentality of desirable high label recall
assumed the text and character recognition would accurately
identify tp labels while rejecting fp as unclassifiable  in
practice  this wass an improper assumption as the character
recognition step is often able to identify text from fp labels 
to improve character recognition  we seek to develop a
process to segment individual characters from the labels and
then use an svm to classify individual
individua characters and
ultimately label text strings  finally  button and label
correlation can be improved by identifying features that better
suit typical output from the label text recognition stage 
references
   

e  klingbeil  a  saxena  and a  y  ng  learning to open new doors 
aaai   th annual robot workshop and exhibition       

   

stephen
hen gould  andrew y  ng and daphne koller  the stair vision
library  http   ai stanford edu  sgould svl       

   

ada evaluation  thyssenkrupp elevator american business unit 
unit
http   www thyssenkruppelevator com images brochure images pdf   
   adaevaluation       pdf      

   

t  joachims  making large scale
scale svm learning practical  advances in
kernel methods   support vector learning  b  schlkopf and c  burges
and a  smola  ed    mit press       

results

in addition to the evaluation of individual systems  overall
system performance was evaluated  for each of the three main
steps in the process  we started with ground truth data and
carried the process to completion to evaluate
ate the effic
efficiency of
each step  the results of these tests are presented in table   
there is no significant difference between system
performance with and without adjustment of button text 
however  recall for for the last step decreases signficantly
        to         when we add the adjustment step
confirming that many of the assumptions in the adjustment
step are not valid  in general the majority of the error can be
attributed first two steps  by improving the accuracy of these
steps  we will likely eliminate the need for the adjustment

discussion and future work

fi