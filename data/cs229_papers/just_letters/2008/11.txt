incentives and machine learning
john hegeman
december         
in       us paid search ad spend was      billion   most of which used a
pay per click  ppc  billing model  in ppc  advertisers only pay the search
engine when their ad receives a click  hence  the ability to accurately estimate
an ads click through rate  ctr  is extremely valuable  the more likely that
an ad is clicked  the more likely that the search engine is paid 
an important but often ignored feature of this environment  is the adversarial nature of the estimation problem  the cost per click  cpc  that an
advertiser pays is often inversely proportional to the estimated ctr of the
ad  hence  an advertiser always prefers that the search engine assign a higher
ctr estimate rather than a lower estimate  this is true regardless of the ads
true ctr  the conicting objectives of the advertiser and the search engine
wouldnt necessarily be a problem except that the advertiser often has control
over the inputs to the learning algorithm and has some ability to distort them 
one might be tempted to think that this shouldnt matter at all  if the
machine learning algorithm is continually trained on new data as it comes in 
then it should automatically adjust to this behavior  the problem with this
argument is that the resulting  naive  equilibrium results in a distribution of
x that is less informative about y than the undistorted distribution is  the
following example illustrates this point 
example   ads are of two types  with probability pl an ad is of type   l
and has ctr yl   with probability ph an ad is of type   h and has ctr
equal to yh  we assume yh   yl    an ads type is not observable  instead  the
learning algorithm must estimate y based on the landing page type  x  ads of
type l normally have landing page x   h while ads of type h have landing page
x   h  however  advertisers are able to send tra c through a landing page
of the alternate type for a cost c   yh yl   advertisers maximize the utility
function u   
y     e  
y   c  fx   g and the search engine has an objective function
e  y y       ignoring incentives  the optimal estimation strategy is to choose
y  to approximate e yjx   however  in our setting  the equilibrium resulting
from this estimation strategy has all advertisers using landing page x   h and
consequently the search engine is no better o than if it hadnt used the landing
page data at all 
in contrast  the optimal learning algorithm for this example would choose
y  to approximate e yjx      
 e y  with
chosen so that the benet to
 

fiadvertisers of type l from distorting their landing page is slightly less than the
cost of distorting the landing page   e yjh  e yjl     c
 
in what follows  we generalize this example to allow for a distribution of distortion costs and show that the optimal learning algorithm in this environment
still seeks to approximate the weighted average e yjx      
 e y  rather
than the standard e yjx   unfortunately  the correct choice of will depend
on the distribution of the manipulation cost which is both unknown and impossible to estimate statically  however  this result can still provide some guidance
in practical applications since the principal  if given enough time  could make
small adjustments to and then observe whether the resulting equilibrium is
better or worse than the previous equilibrium 

 

the model

a principal  the search engine in the above example  must estimate an unobserved characteristic y as a function of a characteristic x reported by an agent 
the distribution of y is a function of the agents type    f    g which is unobserved by the principal  we assume y    yl   yh   and yl   e yj        e yj  
     yh   after the principal observes x  she makes an estimate of y which we
denote y  x   we will refer to y  x  as the estimation function  the principals
payo is a function of the expected accuracy of the estimate 
up  

e  y

y  x      

the agents payo is equal to the principals estimate  y   minus the distortion
cost if the agent reported misreported x 
ua  x  c      y  x 

c  fx   g  

the cost of distortion  c  is distributed according to the distribution function
f  x   we assume f  x  is continuous with density function f  x  such that
f  yl       and f  c      for c     
we will evaluate estimation functions in terms of their equilibrium performance  that is  we assume agents choose x  c    y     arg maxua  x  c    y   
x

the principals equilibrium payo  up is her expected utility when agents choose
x   x   up   
y     e  y y  x  c    y         we will use y m to denote an estimation function that maximizes up  

 

results

our initial concern in section     will be to analyze the optimal estimation function y  x  without regard for how y  x  might be approximated by a principal
without knowledge of the distribution of y given   section     will then turn
 

fito methods for approximating the optimal estimation function using a converging series of estimation functions  we refer to such a series as an estimation
strategy 

   

estimation functions

while we cannot solve for the optimal estimation function explicitly  the following proposition provides some insight into the form of y m which will prove
useful later 
proposition   there exists
x      
 e y  

         such that y m  x    e yjx  c    y m    

proof  first  observe that adding a constant to y  has no e ect on an agents
optimal report  x  c    y     x  c    y    a   this allows us to prove the following
lemma 
lemma   e  
ym  x  c    y m       e y  
proof  let y    x    y m  x    e y  e  
ym  x  c    y m      it follows that
 
 
 
y     e  y y   x  c    y      
up   
  e  y y m  x  c    y    e y    e  
ym  x  c    y m        
 
  e   y y m  x  c    y          e y  e  
ym  x  c    y m      
 
  up   
ym      e y  e  
ym  x  c    y m     
up   
y        e y  e  
ym  x  c    y m      
thus  we must have that  e y  e  
ym  x  c    y m           which implies
e  
ym  x  c    y m       e y  
since only at agents of at most one type will pay the distortion cost  we will
always have e  
ym  x  c    y m        e y   this ensures that we can select a value
of           such that y m       e yjx  c    y m            
 e y   for a
xed value of y m      there is a unique value of y m     that ensures lemma   is
satised  moreover  observe that e  e yjx  c    y m     x      e y     e y  
thus  if y m       e yjx  c    y m            
 e y  then lemma   requires
that y m       e yjx  c    y m            
 e y   it follows that there must
exist such that y m  x    e yjx  c    y m     x      
 e y   to complete
the proof of the proposition  it remains to show that          
we rst rule out the case of     
up   
ym     e  y
e yjx  c    y m      
 e y     
 
  e  y e y 
 e yjx  c    y m    e y    
  e  y e y          
 e  e yjx  c    y m    e y     
 
e  y e y    
thus  if were less than   then the optimal estimation strategy would perform worse than simply using y  x    e y  which is a contradiction 
we now rule out the possibility of      first  note that if     then
y m       e yjx  c    y m         consider the estimation strategy y   formed
 

fiby setting y         e yjx  c    y m        and y         y m      note that the
incentive for type     to report x     has been strictly decreased and thus fewer
agents will misreport  we can now group the agents into three categories     
those of type     who report x     in response to either estimation strategy 
    those of type     who report x     in response to y m but x     in
response to y     and     those who report x     in response to either estimation
strategy  observe that for agents in groups     and     y   is closer than y m
to the expected value of y given which of the above three groups the agent is
in  since estimation accuracy is una ected for agents in the third category this
implies that up   
y       up   
ym   which is a contradiction  it follows that         
for the optimal estimation strategy 

   

estimation strategies

proposition   tells us that the optimal estimation function always results in
an equilibrium in which the predicted value of y is a simple weighted average
of the unconditional expectation of y and the expectation of y conditional on
 
the agents reported x  let e yjx
  x    be the average value of y across all
observations prior to i with x   x   or yh if x  has not been observed  and let
  be the average value of y across all observations prior to i  this suggests
e y 
that the optimal estimation function can be approximated by the estimation
 i 
   i  jx i        
   i     due to
strategy fg  i   x g 
e y
 e y
i   where g  x   
space constraints we will not formally discuss convergence issues for estimation
strategies and will simply assume that an estimation strategy of this form will
converge to some estimation function g   note that by the denition of g  i   
g  must satisfy g  x    e yjx  c    g     x      
 e y   the following
proposition ensures that if is chosen correctly then this estimation strategy
will converge to the optimal equilibrium 
proposition   let y  and y   satisfy y  x    e yjx  c    y     x      
 e y 
and y    x    e yjx  c    y       x      
 e y   it follows that y  x    y    x  
proof  subtracting the expression for y     from the expression for y     yields
y     y        e yjx  c    y        e yjx  c    y        
   
and similarly
y       y          e yjx  c    y          e yjx  c    y           
   
observe that y     y       y       y       implies that more agents of type
    report x     in response to y  than in response to y   which implies that
e yjx  c    y          e yjx  c    y           however  e yjx  c    y         
e yjx  c    y          and thus subtracting equation     from     yields
  
y     y        
y       y          e yjx  c    y        e yjx  c    y         
let
be the value of such that y m  x    e yjx  c    y m     x      
 e y   proposition   guarantees that
exists  
 i 

corollary   the estimation strategy ga  x   
converges to the optimal estimation function 
 

e  i  jx i        
e y

e  i   
 e y

fiproof  ga converges to some g a such that g a  x   
e yjx  c    g a    
x    
 e y   by proposition    this su cient to ensure that the equilibrium
outcome of the estimation strategy ga is identical to that of y m  
the following proposition improves on the range of possible values of
ruling out     and     

by

 
proposition   the naive estimation strategy g    e yjx 
always outperforms
 
the trivial estimation strategy g    e y   however  it is never optimal  in
 
  outperforms
particular  there exists
    such that g   e yjx 
    
 e y 
g  for every          
proof  for brevity  we provide only a sketch of the proof  the rst claim  that
g  outperforms g    follows immediately from the observation that not all agents
choose to manipulate in the equilibrium resulting from g   
for the second claim  consider the equilibrium resulting from the naive estimation strategy         switching to the estimation strategy    
has a
cost of order   as y  moves away from e yjx   however  it also causes a mass
of order of type l advertisers from x   xh to x   xl which has a benet of
order   thus  for su ciently small the impact will be positive 

   

agent surplus

the previous analysis has been focused on the principals equilibrium payo 
however  in a richer model  the principal might also care to some extent about
the payo to the agent  in our example setting of a search engine and advertisers  this could arise in a model with entry costs since a higher payo to
advertisers will result in more advertisers entering the market which will in turn
could yield a higher payo to the principal  we briey touch on the agents
surplus with proposition   
e
proposition   for estimation functions of the form y  x    e yjx 
    
e
 e y   equilibrium advertiser surplus is strictly decreasing in for     
proof  e ua  x  c       e  
y  x  c  fx   g     e  
y  x   c pr x     
e
e
first  note that e  e yjx      
 e y     e y  is independent of   since
the equilibrium value of y     y     is increasing in   pr x      is also increasing
in and thus e ua  x  c     is decreasing in  

 

conclusion

in many practical machine learning applications  agents with objectives contrary
to the objectives of the principal may have the ability to manipulate some or
all of the input data  ignoring incentive issues in such environments will result
in a sub optimal estimation accuracy  our contribution is to demonstrate
that the optimal learning algorithm in such an environment under utilizes the
manipulable input by using an objective function that is a weighted average of
the conditional and unconditional expectations of the output variable 
 

fi