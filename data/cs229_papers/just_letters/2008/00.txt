accurate and cheap robot range finder



ivan papusha
december         

abstract
a novel high quality distance sensor for robotics applications is proposed  the sensor relies on
triangulation with the offset of a laser line as it is reflected off an object into a cheap webcam  an
ml approach to finding the error model showed that the sensor was very accurate when the laser
line was found  it is suggested that better line finding methods than simple color filtering would
make the sensor more viable 

 

introduction

any self respecting mobile robot requires some sort of distance measurement sensor or range finding
mechanism  among the most accessible are ultrasonic range finders  which time the propagation and
reflection of a sonic pulse  while cheap and ubiquitous  ultrasonic rangers  especially when placed in
ring configuration  are plagued with fundamental difficulties that make them unattractive for serious
localization 
at the other end of the spectrum are high end laser rangefinders  which use light instead of sound to
determine distance from time of flight  these are often bundled with precision optics and mechanisms
that allow one to infer  d point clouds over large and small human distances  their precision and
reliability makes them ideal for industrial and research applications  but their cost is prohibitive to the
hobbyist or researcher on a low budget 
to solve the problem of optimizing user cost vs  sensor precision and reliability  we consider a
different sensor design  here  the only materials needed are a laser line generator and a camera  e g  
a cheap webcam   the principle of operation is simple  one points the line generator and the camera
in the same direction  but offsets them some known distance dof f     cm  the camera sees the laser
line  filtered from the rest of the environment based on brightness and color  which is offset whenever
it strikes an object  by calculating the offset distance from the expected position of the laser line  the
distance to the object can be inferred 
this sensor  of course  is not perfect and is subject to its own errors  in particular  its error model
and corresponding error parameters are quite different from the error parameters of time of flight
based rangers such as the ones discussed above  this paper will formulate the error model and use an
automatic maximum likelihood  ml  method that will learn the fundamental parameters of the error
model from a proposed calibration scheme          results of the sensor and sensor model in action are
also discussed 


i thank morgan quigley for his direction  as well as the stair project for the materials 

 

fi 

range sensor design

   

geometry and raycasting

vie
w

the relations among the fundamental lengths and angles described in figure   are derived using a
simple ray casting scheme  the sensor is extremely sensitive to construction parameters  so to eliminate
systematic error  a sturdy construction is necessary  note that the camera must be appropriately
calibrated for radial distortion  using e g   a standard checkerboard algorithm       so that these figures
make sense 

top

fie
ld

of

object laser
intersection
on

iz
hor
era

laser line

cam

obstruction

dof f





yp

rot

horizon  bottom field of view 

dobj

camera

figure    single point simplified ranger geometry  side view  the camera is tilted such that the actual
horizon corresponds to the bottom field of view limit  the object is dobj away from the laser line
generator  which is separated from the camera by dof f   a known distance  the camera sees the point
of intersection yrc  yres of the way from the bottom of its viewing plane 
in order to triangulate the distance to given object  we use a standard line plane intersection
method  the camera is assumed to be at the origin of a   d spherical coordinate system  the plane
of intersection is the one generated by the laser line  offset a distance dof f below the camera  after
calibration     and laser line detection  see below   horizontal and vertical angles  horiz and vert
respectively are inferred from the location of the laser line for each column of the display  finally  the
distance dobj to the object is calculated by finding the intersection of a line and a plane 

   
     

detecting the laser line
color filtering

assume that the laser line has color represented by the rgb vector v    r  g  b t   where r  g  and b
are intensity values for the red  green  and blue components of the color respectively  experimentally 
typical values for the components of v are              t on a scale from   to      for every pixel with
color w  we can project w onto v to see how strongly w corresponds to v using the dot product 
y 

wv
v
kvk 

   

where y  r is the strength of the projection onto v and v is the unit vector in the direction of v 
colors strongly correlated with v will give large values of y and colors weakly correlated with v will
give small values 
 

fi     

fitting a gaussian

since each column of pixels corresponds to one offset  and hence one measurement  we can find where
the line is by a simple fit to a gaussian  to make this more concrete  suppose that in a given column 
the projections onto v are the scalars  y       y               y  r     where r is the cameras vertical resolution
in pixels  we can therefore treat the values y               y  r  as entries in a histogram with r bins of size
   the expected position of the laser line is simply the weighted mean
e y   

r
x

  
yi

r
x

i  yi  

   

i  

i  

notice that e y  can be a fraction  which effectively allows a little extra resolution beyond the cameras
pixel resolution  in practice  detection works better if the camera is taken slightly out of focus  which
blurs out some noise at the expense of a wider distribution over the y values 

 
   

sensor calibration
gathering data
      raw samples  object at      meters

histogram  object at      meters

   

    

 
    

   
 

    

frequency

raw distance

   
 
   

    

 
    
   
 

   

   
 

    

    

    

    

    
sample

    

    

    

    

 

     

 a  raw data

 

   

 

   

 

   
 
distance

   

 

   

 

   

 b  histogram

figure    raw data and histogram for        measurements of a box      meters from the sensor 
about     of the measurements are centered around the true distance  a small number of values are
scattered randomly through the entire measurement space  and the rest return zmax   when the laser
line was not found 
a box is placed a known distance dobj   m in the center third of the cameras field of view 
only those pixels which correspond to the object are considered  after the laser line is found and
raycasting is used to extract the distance to the object  one should expect all the measurements in
the point cloud to center around the actual distance dobj    to the box  label all the measurements
z       z               z  m    where in this case m           

   

error model

we use a modified decomposition of the measurement density discussed in      in particular  the
probability for each measurement z  i    the probability p z  i     of that measurement given that the
actual distance is   is split into three distributions

 

fi    centered around
 correct measurement  a single variable gaussian distribution phit  z  i     hit
 
the correct measurement  its variance  hit is a parameter of the model that measures noise  we
include in the model only those values corresponding to the measurement space that were not
failures  i e  
 
   
n    hit
if    z  i    zmax  
 
phit  z  i     hit
  
 
otherwise 
rz
    dz
where  is a normalization parameter equal to the cumulative density      max n    hit

 random measurement  a uniform distribution prand  z  i     corresponding to measurement
noise through the entire measurement space  i e  
 
  zmax if    z   zmax  
 i 
prand  z     
 
otherwise 
 failure  a point mass distribution pmax  z  i         z   zmax   equal to   only if the measurement is a failure   e g   the camera failed to detect a line 
the probabilities are mixed using the mixing parameters hit   rand   max   where we constrain hit  
rand   max    


t 
   
phit  z  i     hit
hit
 
   
  hit   rand   max      rand    prand  z  i     
p z  i     hit
 i 
max
pmax  z    

   

learning from data to infer error parameters

we formulate the learning problem of finding the probability density function by maximizing the total
t
     
likelihood of the parameter     hit
hit
rand   max     that is 
   arg max


m
y

 
  hit   rand   max  
p z  i     hit

   

i  

subject to hit   rand   max      where m is the number of training examples  in this case        

   

results

the expectation maximization  em  algorithm     was used to solve the constrained optimization
problem of equation    the results are summarized in figure    having run the algorithm for several
distances  the mixing parameters remain about the same for the same lighting conditions  while the
gaussian width hit increases with distance  this makes sense  because as the distance to the object
increases  the offsets approach the resolution of the camera 

 
   

conclusion
advantages over ultrasonic rangers

the horizontal resolution of the sensor is limited only by the horizontal resolution of the camera 
that is  the distances provided by the sensor are much more granular than a single or even several
sonar elements  in addition  the webcam sensor does not suffer from sonar cross talk  and can make
measurements as quickly as the camera can take pictures and hardware can process them  in ultrasonic
 

fifit probability density  object at      meters
 

probability density

   
   

           

   

         

   

zhit          

   

zmax         

   

zrand          

   
   
   
 

 

   

 

   

 

   
 
distance  meters 

   

 

   

 

   

figure    plot of the probability density function for measurements of distances to a box      m away 
notice the uniform density spread throughout the entire space and the gaussian centered around the
actual distance  the mixing parameters show that about     of the results come from the gaussian 
and     belong to the point mass failure function  the rest are random readings 
sensors  one needs to wait a long time in clock cycles after sending a ping before the ping returns  or
fails to return   during this time  no more measurements can be made  the slow measurement tomeasurement time can be detrimental in a dynamic environment  as the robot can fail to see objects
that move quickly in and out of view  because the webcam sensor relies on light  the camera sees the
laser and can calculate offsets almost instantaneously 

   

disadvantages

the main problem with the sensor is the sensitivity to the laser line detection  the measurement zmax
is returned whenever the laser line was not found  which happens quite often  because the scheme
used was based on simple color filtering  any environment containing colors similar to the lasers make
it hard to find the line  in particular  the sensor is currently unsuitable in use in bright environments 
e g   outside in daylight  it is possible to make the laser line detection more robust by using knowledge
about what it should look like in the camera  we know  for instance  that the line is horizontal or
almost horizontal  one can train a classification algorithm to look for horizontal lines in an image 
and then decide whether the horizontal line is part of the environment or the laser line  indeed  this
can be the subject of further research 

references
    andrew ng  em algorithm  cs    class notes       
    hai nguyen  ros wiki  camera calibration       
    sebastian thrun  wolfram burgard  and dieter fox  probabilistic robotics  chapter      pages
        mit press       

 

fi