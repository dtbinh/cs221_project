machine learning term project write up
creating models of performers of chopin mazurkas
marcello herreshoff
in collaboration with craig sapp  craig ccrma stanford edu 

 

motivation

we want to generative models of pianists based on input features extracted from musical scores  such as the number
of events in a beat  the position of a beat in a phrase  dynamics  harmony  form  etc   target features are tempo
values for each beat of a performance  we try to extract performer style from these models to generate synthetic
performances of different compositions  these models can also potentially be used to identify the performers of new
or old recordings with unknown performers 
training data consists of tempo curves extracted from audio recordings of     performances of five different
mazurkas composed by frederic chopin played by     different performers  craig has demonstrated that a performer
nearly always maintains a consistent performance rendering of the same piece over time  even after several decades 
and numerical methods based on correlation can be used to identify audio recordings of the same piece played by
the same pianist  
we are interested in being able to transfer the performance style of a particular performer between different
pieces for the purpose of synthetic performance in that performers style  or to identify a performer in a recording
of unknown or disputed origin   recent work has been done on attempting to address performer style in a machinelearning context  but state of the art is still rather speculative   automatically generated performance rendering
competitions have been held at several music related conferences in the past few years  

 

input and target features

target and input features for the project consist of data for five solo piano mazurkas composed by frederic chopin
             the mazurka is a folk dance from chopins native country of poland in triple meter which is generally
characterized by a weak  short first beat in each measure and an accented second or third beat  chopin converted and
popularized this folk dance into an abstract musical art form  performance conventions for playing these compositions
also show a general trend over time from a dance to more abstract personal musical interpretations  in addition 
performances of mazurkas tend to vary regionally  with polish and russian pianists influenced by the historical dance
interpretations  while pianists more geographically distant from this central tradition tend to use a more individual
and abstract playing style 

   

target features

the target data consists of tempo data for each beat in various performances by professional pianists  extracted
by craig as part of the mazurka project at royal holloway  university of london   performance data consists of
absolute timings for beats in recordings of the mazurka  as well as loudness levels at the locations of the beats  which
are not utilized in the current study   the tempo data used in this project is converted into beats per minute which
is inversely proportional to the duration between absolute beat timings locations 
tempo i   

  
 i   

beat

 beat i 

  hybrid numeric rank similarity metrics for musical performance analysis  craig sapp  ismir      
http   ismir     ismir net papers ismir          pdf
  fantasia for piano  mark singer  the new yorker     september      
http   www newyorker com reporting                  fa  fact  singer currentpage all
  in search of the horowitz factor  widmer  et al   ai magazine       sept         furlhttp   portal acm org citation cfm id       
  http   www renconmusic org icmpc     
  http   mazurka org uk info revcond  or in microsoft excel format  http   mazurka org uk info excel beat

 

fibeat timings are extracted manually with the assistance of audio analysis tools  using an audio editor called sonic
visualiser   automatic beat extraction is not possible with current state of the art methods since mazurka beattempos can vary by     between successive beats  a characteristic of the mazurka genre  and most beat extraction
methods assume a narrower variation between beats  each mazurka performance consists of a sequence about    
    beat tempos  figure   shows beat tempo curves for several performers all playing mazurka in b minor  op     
no    

figure    six example beat tempo curves for performances of mazurka       the light gray curve is the average for
   performances  plot   shows a performer who concatenates phrases  plot   shows a performer who plays slower
than average and does not do much phrase arching  plot   show a performer who exaggerates the metric cycle by
switching between fast and slow beats  plot   shows someone who plays very close to the average  plots    show the
same performer recorded on different dates 
each of the five mazurkas utilized for this study have performance data for    to    performances  all mazurkas
include data for three performances by arthur rubinstein  a well known and prolific performer of the   th century 
as well as occasional duplicate performers who record the same mazurka twice 

   

input features

several input features were extracted from text based musical scores for each mazurka   we chose features which we
thought would be likely to differ between different performers and might stay stable between the performances of an
individual performer  the current set of features going from general to more musically specific 
   the mean feature  this feature is always    we included it so that the linear regression algorithm can learn the
constant offset  the theta value for this feature describes roughly the average tempo at which the performer
plays 
   the global position  this feature increases linearly as the piece progresses  the theta value for this feature
describes roughly whether the performer accelerates or decelerates on average over the course of the entire
piece 
   the metrical position  this feature is the position of the beat in the measure  in this case  because all mazurkas
are in    time  the position is either      or    the theta value for this feature describes roughly whether the
performer accelerates or decelerates inside each measure  averaged across the whole piece  
   the number of left hand events  this feature is the number of notes played by the performers left hand in
each beat  the theta value of this feature describes roughly whether the performer speeds up or slows down
when playing beats with more ornate left hand parts 
  http   www sonicvisualiser org 

http   sv mazurka org uk

  http   kern ccarh org cgi bin ksbrowse type collection l  users craig classical chopin mazurka

 

fi   the number of right hand events  same as above  
   the harmonic charge  a measurement of the local harmonic activity  the calculation method is described
below  the theta value of this feature shows roughly whether the performer plays faster when the performance
modulates up a fifth 
to calculate the harmonic charge we measure the interval between the global key of the piece and the local key
of a analysis window around the current beat  the interval is described as a number of perfect fifths between the
key tonics  for example  if the global key is c major  and the local key is g major  then the harmonic charge is   
since g major is close to c major  if the local key is b major  then the harmonic charge compared to c major is
higher at    since it is a more distant key relation 
we calculate the local and global key measures using the krumhansl schmuckler key finding algorithm with
bellman budge key profiles   the algorithm measures a chromatic histogram of notes in a musical selection  and
then uses pearson correlation to compare to expected prototypes for major and minor keys  taking the test key with
the highest correlation as the answer 
p
 h k  t   h   p t   p  
key   arg max pp t
p
 
 
k
t  p t   p  
t  h k  t   h  
where h is a duration weighted histogram of pitches in the analysis window in the music score  p is a pitch class
histogram expected for a major or minor key 

 

linear regression model

because we are trying to build an application  we decided to start out with a simple model and improve it incrementally  our basic model states that the tempo with which a performer will play a beat is gaussianly distributed with
mean at an affine function of the absolute index of the measure containing the beat  the absolute index of the beat 
the index of the beat in the measure  in this case  a number between   and    because mazurkas have three beat
measures   the number of beats in the performers left hand  the number of beats in the performers right hand  and
the harmonic charge 
in frequentist terms  our prediction for the performer will be an affine function of the features listed above  and
our effort function will be the sum of squared errors between the prediction and the actual performance  in order to
make the error output more comprehensible  we calculated the root mean squared  rms  error  which is equivalent 

figure    three progressive reconstructions of rubinsteins      performance of mazurka       using linear regression
on the original features as well as quadratic features 
for each piece  the average of the rms error between each recording and the average of all recordings of each
piece was lower than the average of the rms error between each recording and its reconstruction under my linear
regression model  this means that the reconstructions are worse approximations to the recordings than the average
recording  for example  the average rms error for the reconstructions of mazurka      is         while the average
rms error for the average of all recordings of mazurka      was        
  visual

hierarchical key analysis  craig sapp  in acm cie      october       http   portal acm org citation cfm id                

 

finext  we did an ablative analysis  we started by stripping off all the features  except the constant  in order to
get a base line on the error  the error of this severely ablated model  which in effect approximated every recording
with a flat line  produced an error which was not much higher than the error of the linear regression model which
had all five features we listed as its input  for example  the average rms error for the flat line approximation of
mazurka      was          on only one of the mazurkas  mazurka      was did the average rms error for the
flat line approximation and the average rms error for the full linear regression differ by as much as      
this indicates not only that the algorithm is not extracting enough information from the data to be a better
approximation than the average recording  but that none of these five features are not strongly correlated with the
tempo data  because if they were  some values of theta would have significantly lowered the rms error      
we have also done experiments adding quadratic terms to our existing features  for each feature x i  we added
another feature xi n    x i       the idea being that many of the stuctures in music have shapes that look like
arches  see for example figure     to test whether this was effective we trained both models on rubinsteins     
performance of mazurka      and we tested them on rubinsteins      performance of the same mazurka  adding
these terms reduced the rms error from       to        this means that the error function  which is proportional to
a the square of the rms error  was reduced by an additional      
as a specific example consider figure    this shows a progressive reconstruction of the piece  first using only the
first three features  then using the first five features and then using all six features  the first reconstruction includes
the global and metric position features  here we see that it has roughly catured the tempo arch in which rubinstein
plays the piece 

figure    weights trained for all the performances by rubinstein and czerny stefanska on mazurkas      and      
each plot shows the six compoents of  with different colored bars indicating different performances   the values
for theta  have been scaled by a factor of    to fit in the chart   for brevity we did not include the squared features 
while the reconstriction is by no means a good fit  it does capture an interesting fact about rubinsteins performance  the second and third reconstructions feature sharp downward spikes  which do seem to align well with
downward spikes the target  inspecting the score of the piece  we found that these downward spikes occur whenever
there was a half note in the left hand  which would cause the left hand event count to drop   these spikes all align
well with spikes in the target recording  so rubinstein really does slow down when the left hand plays a half note 
as can be seen in figure    the weights assigned to the features vary from mazurka to mazurka even when the
performer is held constant  however  while the features have not characterized the style of a performer sufficiently to
identify the perfomer of an arbitrary piece  the values of  detected by the logistic regression usually seem relatively
stable within performances by the same performer of the same piece   the two recordings of czernys playing
mazurka      were fourty years apart   an improved version of this technique could be useful for identifying the
performer of a disputed recording 
  the

full data set and code is available here http   www stanford edu   marce    cs    linear regression tgz

 

fi 

future directions

   

pca filtering

another experiment we performed on the data was to do pca filtering on the several of the recordings  to test the
robustness of craigs similarity algorithm to degradation of its input   
by pca filtering  we mean that we did principle component analysis on the data  calculated the pc loadings for
each recording and each principle component and then reconstructed each recording using only the first n principle
components  we did this for n                                      
we found that by retaining the ten largest principle components of the data  the similarity algorithm was able to
detect the true performer of the original recording with high accuracy    
the similarity algorithm may not be taking advantage of all the information that may be available in the filtered
recordings  however  it is able to correctly identify the performers of recordings even when the recording has had all
but its first ten principle components filtered out  the fact that it is capable of correctly identifying the performer
of the recording indicates that  in some sense  the performers style can be distinguished from the styles of the other
performers using ten numbers 

   

linear regression with more features

it is clear that we need to extract more features from the scores  possible features that might be helpful include
   an average of many different performances of the piece  this would allow the linear regression algorithm to
look for patterns in the way that the current preformer differs from the average  
   phrasing information  the position of the beat in a musical phrase   these feature s  would either be the
locations of the measures in the phrase based
on hand generated phrase boundary  or a collection of sine and

 
n
and
cos
n
for
various values of k  here n is the index of the measure in the
cosine waves  i e  sin  
k
k
piece   for example  in figure   there are eight regularly spaced phrases that are each twenty four beats long 
   adding more detailed rhythmic information  for example  the number of half notes  quarter notes  eighthnotes  etc  in the left and right hands in the current measure as well as the current beat 
   music is an ordered squence of events which give rise to the interpretation  our current models dont take this
into account  we can include the features of neighboring beats in the feaature set of the current beat to gain
musical context 
   nearby dynamics markers in the music  e g  piano and forte markers  crescendos  etc  

   

kernelized linear regression

kernelized linear regression could allow us to detect more complex relationships between the features for example a
dissonant note at the end of a measure might warrant a different interpretation from a dissonant note at the start
of a measure  another way to use kernelized linear regression would be to construct a mapping from the musical
score of a measure to a tree structure and then use a tree similarity measure as the kernel    this could have the
advantage of automatically detecting which features of the score are relevant but the disadvantage that it could be
difficult to tell which features those are 

   

hidden markov models

another possibility is to model the pianists as entities with hidden state using a hidden markov model  hidden
markov models have enjoyed success in areas such as speech recognition  because musical interpretations may have
similar structures to vocalized speech  both are acoustic processes designed to be processed by the human brain  
this may be grounds for optimism that a hidden markov model could characterize the playing style of a performer 
another reason that hidden markov models might be useful models of performers is that pieces of music may contain
distinct sections meant to be interpreted with different moods 

   hybrid numeric rank similarity metrics for musical performance analysis  craig sapp  ismir      
http   ismir     ismir net papers ismir          pdf
   a graph can be found here http   www stanford edu  marce    cs    pcaandresidue          pdf
 
   a survey of kernels for structured data  thomas gartner  acm sigkdd explorations newsletter http   portal acm org 
citation cfm doid              

 

fi