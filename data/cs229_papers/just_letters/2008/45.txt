content based features in the composer identification problem
cs     final project
sean meador  smeador stanford edu 

karl uhlig  knuhlig stanford edu 

december         

 

overview

classification of digital music  also called music information retrieval  or mir   is a long standing problem
in machine learning  one with many potential real world applications  for example  providing accurate
recommendations is extremely important to online music websites  pandora  itunes genius  etc   as this
is the primary means by which users discover new music  many classification schemes have therefore been
proposed  with some attempting to group music according to characteristics like mood and genre  and others
attempting to identify the particular artist or composer who created the work 
due to the complex nature of audio waveforms  however  nearly all music classification algorithms begin
with a feature extraction step  raw digital audio is essentially unusable for direct training on a learning
algorithm  therefore  it is first necessary to process the data and distill key identifying features from the
audio clips 
until recently  researchers were getting very good results using only relatively low level signal features of
the audio      however  after the discovery of a design flaw now known as the album effect  the performance
of such classifiers has dropped dramatically      in this paper  we focus on classical composer identification 
and propose a content based feature set which addresses the limitations of current classifiers caused by the
album effect 

 

the problem

composer identification is a relatively well studied multi value classification problem  at the music information retrieval evaluation exchange  mirex   teams of researchers test their classification algorithms in
a number of different contests  composer identification is one such task  and many entries in this competition have yielded good results         a survey of these classifiers seems to suggest that feature selection is
not simply a necessary pre processing step in the overall algorithm  but is in fact the key component of a
good classifier  in general  standard machine learning algorithms have been applied successfully to extracted
features  mixtures of gaussians  dag svm  etc    teams achieve different results  then  primarily because
of the features they select 
j s  downie  a key contributor to the mirex competition  recently proposed the following prevalent
issues with current music classification schemes     
   album effect  prior to       data sets in the mirex competition were not filtered by album  that
is  audio clips from the same album appeared in both the training and testing sets  because of this 
timbral feature sets  mfccs  zero crossing rates  spectral centroid  etc   were picking up on trivial
production qualities of the albums rather than actual music theoretical content  when album filtering
was applied to the data  performance in the competition declined substantially 
   artist filtering  similar to the album effect  data sets were also not being filtered by artist  the results
of this effect were particularly pronounced  in the genre classification task  a timbral based classifier
 

fiachieved     accuracy without filtering  and     with filtering  this evidence further supports the
notion that spectral and timbral features are a nave representation of music 
together  these effects contribute to what downie calls the glass ceiling for spectral and timbral feature
sets  in other words  these features alone appear to have an upper performance limit because they are not
capturing real music information in a truly meaningful way  improvements in this field will thus come only
when classifiers account for more sophisticated  music theoretical features of the data they examine 

 

features

to address this limitation  we propose a feature set which is based on the broad chord changes which take
place during a piece of music 

   

spectral features

the standard feature sets are summarized below  and are described in detail in        
   mel frequency cepstral coefficients  mfccs   these features are borrowed from the field of speech
recognition  where they have been applied with great success 
the mfccs are the coefficients  typically the first     of the audio signal on the mel frequency cepstrum  after obtaining the frequency domain representation of the waveform via the discrete fourier
transform  the signal is converted to the mel scale  a perceptually motivated logarithmic scale which
more accurately models human perception of pitch  finally  the discrete cosine transform is applied 
the resulting cepstrum gives a fairly accurate representation of the timbre of the signal  and has the
benefit that most of the energy is located in the first few bands of the spectrum 
   zero crossing rate  this feature is simply computed as the number of times the signal crosses zero 
it gives an overall measure of the noisiness of the signal 
   spectral centroid  this feature indicates the center of mass of the audio signal and  perceptually  is
stronly correlated to the brightness of the sound 
   other features  other low level features commonly used in classification algorithms include spectral
roll off  root mean square energy  delta spectrum  kurtosis  skew  flatness  and entropy  we calculate
these features using      a comprehensive auditory toolbox for matlab  
based on the above feature sets  it should be clear that spectral feature sets do little to capture the actual
musical content of an audio file  they certainly capture relevant features like timbre and brightness  but do
not represent the overall music from which they are extracted 

   

content based features

in order to address the limitations outlined above  we propose a new feature set which is based on the beat
and chord patterns found in a music clip  we hypothesize that a composer can be modeled roughly by the
types of chord progressions they employ in their music  to that end  we extract a feature vector from each
clip which is based on the number and type of each chord transition we encounter 
   first  we use a standard beat detection algorithm to find the most likely positions of beats within the
song  in western music  it is the case that chord transitions rarely occur between beats  therefore  we
assume that the audio between beats is encompassed by a single chord  this allows us to slice the
audio into beat length frames  each of which represents a single chord 

 

fifigure    this diagram shows the four step transformation from waveform to chord transition vector 
   for each beat frame  we compute its harmonic pitch class profile  this is calculated by dividing the
frequency spectrum into logarithmic pitch bands  and then folding these bands into a single octave 
the result is a    dimensional vector representing the relative strengths of each chroma  pitch  in the
frame 
   the hpcp is translated into an actual chord by correlating its values against those of pre computed
chord templates  in our testing  we limited our scope to the major and minor triads for each pitch    
chords in all  
   finally  we compute the transition between each pair of chords in the sample  for example  the
transition from c to g major represents the transition up by a  th  this yields a final     dimensional
vector of pitch transitions  and has the benefit of being invariant to the key of the song 

 

classification

support vector machines  svms  are among the best classifiers for their speed and accuracy  surveying
recent mirex entries  we found that most teams used some form of svm for classification  however 
conventional svms are binary classifiers  in order to address the multi valued case of classical composers  we
instead use a decision directed acyclic graph svm  or ddag svm      these classifiers work by performing
a series of binary classifications  comparing only a single pair of classes at each step  thus  ddag svms
work by gradual exclusion 
training of a ddag svm
is the same as with conventional pairwise support vector machines  namely 

we need to determine k  decision functions for each pair of the k classes  however  testing is much faster
using a ddag svm because we only need to perform  k     classifications  one for each level in the decision
graph  in our case this means performing three classifications per sample  which is not a prohibitive cost 
finally  we used a gaussian kernel in our algorithm  this choice seemed to yield the best results 
 

fifigure     a  the ddag for finding the best of four classes  the equivalent list state for each node is shown
next to that node   b  a diagram of the input of a four class problem  a   v   svm can only exclude one
class from consideration 

figure    confusion matrices resulting from training on baseline and augmented feature sets  row labels
represent the correct class  and columns represent the labels applied during classification 

 

fi 

results

the mirex competitions classical composer category includes eleven composers and a total of around
        second audio files  due to time and resource constraints  we limited our scope to four of the most
representative composers from the baroque  classical  and romantic periods  bach  mozart  beethoven  and
brahms  we collected one hundred    second samples for each composer  taking clips from a wide range of
albums  furthermore  we applied filtering to our training and testing sets to avoid the album effect described
earlier 
to establish a baseline  we first train and test using only a standard spectral feature set  as described
in section       we then augment our feature vectors with our chord analysis vector  and train and test
using these features using   fold cross validation  using our augmented feature vector  we achieved a   
improvement over the baseline  our results are summarized in figure   

 

conclusion and future work

it is clear that the success of future classifiers will be dependent on their ability to capture music theoretical
aspects of the data they examine  we believe our feature set is a step in that direction  and we were able to
achieve modest performance gains over spectral feature sets 
however  there are a number of limitations in our implementation which could see substantial improvement in the future  for one  we limited our chord analysis to only the major and minor triads  we found
this limitation necessary because the techniques we used for chord detection did not provide the resolution
required to identify more sophisticated chords  beat and chord detection is an area of active research  and
emerging techniques show promise for improving our model 
furthermore  we limited our chord analysis to a simple transition counting scheme  clearly  this method
does not account for significant aspects of a musical work  in future refinements of our algorithm  we will
want to look at more sophisticated structural aspects of the work like key modulation with respect to the
base key  or longer chord patterns of chord changes  currently  transitions counts are patterns of length two  

references
    downie  j s          the music information retrieval evaluation exchange              a window into
music information retrieval research  acoustic science and technology      vol          
    lartillot  o     toivianen  p          mir in matlab  a toolbox for musical feature extraction  unpublished 
    li  d   sethi  i k   dimitrova  n     mcgee  t          classification of general audio data for contentbased retrieval  pattern recognition letters      pp          
    mandel  m   poliner  g     ellis  d          support vector machine active learning for music retrieval 
multimedia systems  special issue on machine learning approaches to multimedia information retrieval 
vol      no     pp        aug      
    mandel  m     ellis  d          labrosas audio classification submissions  mirex      
    mckinney  m f     breebaart  j          features for audio and music classification  proceedings of the
international symposium on music information retrieval       
    peeters  g          a generic training and classification system  audio music mood  audio genre 
audio artist  and audio tag  mirex      
    platt  c   cristianini  n     shawe taylor  j          large margin dags for multiclass classficiation 
mit press 

 

fi