chinese  restaurant  menu translation
ting liao
  description of the problem
when you goes to a chinese restaurant  especially when traveling in asia  you will have no idea what
the menu says even if there is an english translation on it  you will see names from burn the spring
chicken to cowboy meat  even the menu at olympic village during the      beijing olympics has
similar problems  the main reason is that a normal translator cannot generally handle the name of a
dish due to the lack of sentence structure  when you simply group a set of nouns together  as in most
of the cases in names of chinese dishes  it would be hard for the translator to decide what to do when
the words have multiple meanings 
if we want to build a general translator that can handle food translation  it would be very hard 
however  if we create a translator that is specifically for food translation  the problem becomes much
easier to tackle  first of all we do not have to worry about the context  we know it has to do with food 
and knowing that the numbers of useful vocabularies is easier to handle  this paper describes a
supervised learning algorithm that trains the computer to translate the name of a dish in chinese to
english 
  the idea
in the movie terminal  tom hanks learned the english language by comparing a booklet in english
and the same booklet in the fictional krakozhian  the same idea applies here  the training set contains
entries consisted of the chinese name of a dish and the corresponding english name of the dish  the
challenge to is break up to chinese name such that we can find the chinese word s  that corresponds to
a certain english word s  in the name  unlike the english language  chinese words are not made up by
letters  but instead they are made up with characters  a chinese word can be a single character or a
multi character one   however a word with   or more characters is extremely rare   another difference
between the languages is that chinese words are not separated by space  so when you see two chinese
characters together  it could be one word or it could be two  and we will have to account for that 
  model
we assume that there is a correct objective translation f c    e  which means whenever we see the
word c  we can translate it to multiple e s  the different e s should only happen when the word c is
used for different meanings  by objective i mean if two c s have the same meaning  they cannot return
a different e  consider a training set of size m  we have m pairs   the chinese word c i  is the chinese
translation of e i   c i    c  i  c  i     cn i  where cj i  is the j th character for the chinese word with length
n and ej i  is the j th word in the english word  the goal is to create a set of translation rules f such that
when we see a chinese word c  we can apply f c   e for the english translation e 
obviously  if we choose f that makes  f c i    e i   then we will get a      match for the training set 
but as you can imagine  if we get anything that is not in the set  we will fail to translate it  so this is not
very useful  if we know the word chicken  we should be able to use this knowledge in other context 
so if there is a word cj we see multiple times in different context  and their english translations contain
the same specific sequence e  the rule f cj   e will be a useful one because the more appearances of
this translation in the training set could mean that there is a higher probability we see this rule used in
words outside of this training set  we assign a score to each translation guess  the score should reflect

fitwo things  
   the more this guess appears  the higher the score should be
   a rule that translates an n length c is preferred to a translation rule for a shorter c  otherwise we
will always translate only the substring of c because if the translation for f c   e has x appearance 
the rule f substring of c   must have at least x appearance  but it would seem that f c   e should
be considered if the number of appearance does not differ by too much 
the model i used  which is a bit arbitrary  is for each rule f c   e  where the length of c is n  we
give it a  n score  but we will treat the set of rules f c i    e i  as the starting point  meaning it has  
points  now if we find a rule f c   e with a length n c that appears x times  then these n   x
characters can be represented by   rule  i thus treat this rule as scoring n    x    points  we can see that
this scoring system fits well with the   requirements i set if we use a greedy algorithm to try to
maximize the score   each cj i  can only be used to help find one rule  after it is used  we delete that
character  see below  
  training
the ideal case here would be maximizing the score  which is find a set of rules f such that
each f c   e for a c with length n that appears x times has score n    x   
find the set of non overlapping  we cannot use two different f for the same cj i  when keeping score  f s
that will maximize the score for this training set 
the problem is  the total number of possibility of f is enormous because of the multi character and
multi word translation  so it would be hard to find the real maximum  instead i used a greedy
algorithm to find f  we went through the whole set and find out the single rule f that creates the
highest scores   in my dataset  the highest score rule is for the word rice  which has score     
the way to do that is simply going through all the words with different lengths  then find out how
many times the word has appeared in the training set  then we find out the english translation for these
words and find out which english pattern has appeared most  and x   the number of times the english
pattern appears   once we have found the f c   e with the highest score at this point  we can remove
c and e from the training pairs if c is in the chinese name and e is in the english name of the training
pair  we replace c and e with    to make sure we won t check for the word ac after b is removed
from abc  we then repeat the process until we cannot find rule  from the left over words  f such that
it scores higher than    this is the first phase of the algorithm
the second phase is to train something i called the unbreakable  which represents a chinese word
that cannot be broken up into substring that makes sense  it happens when there is a special name of a
dish  therefore we simply add f c i    e i  as one of the translation rules  the third phase is to find
out all the useless words  sometimes on a menu  there are some useless words  in the sense of
translations  like wonderful and tasty  so after removing all our guesses  if the chinese part of the
left over pair is not empty but the english part is empty  we make a guess that these chinese words are
useless  that means f c       if at this point there are pairs that has only one consecutive sequence of
characters in the chinese part and only one sequence of words in the english part  we basically link
these sequence of chinese words to the sequence of english words  since we do not have a great basis
for these guesses  we simply give them a score of    there may be still some pairs that are still not
completely mapped  so we will have to give up and find out what the pair originally looked like  before
replacing words with    and make a direct mapping from the chinese name to the english name 

fi  testing
when given a chinese name c  we try to find out what combinations of f cj   e give the highest
scores  this method inherently has some problems  for a word that has multiple meaning  if one
meaning dominates by having a much higher score  the other meaning does not have much chance of
showing up  unless it can squeeze into the top    which means the rest of the words do not allow
multiple meanings   even though it may be the correct meaning  we tested these translations on the
original training set  trying to see what is the average hit rate  a word in the guess that is in the original
english word   and the result turned out to be      i tested it on different subsets of the training set and
the result varies between     to     
  problem
i  positions
the biggest problem i have is with the position of the words  we may get f c   e right for a
substring c  but where should e be put in our final guess  that is a major problem right now  i
have a method in mind but i am not sure whether it will work  given each f c   e  in addition
to giving it a score  we assign to it a position score  which is the average index of e   the length
of the whole word of all words where this rule f c   e applies  and when we are making the
final guess  we sort the substring by their position score  this part i have not implemented 
ii  word inconsistency
the other problem is the inconsistency in words  for example  when to use fried and deep
fried  they could mean the same thing most of the time  but using my algorithm  we will
always translate the chinese word to fried  that is not that big a problem by itself  the
translation is reasonable  but when we are in the later phases of the training  it depends on the
first phase removing the words accurately and in this case  deep is left over and may lead to
unexpected result  for example a useless word will now be translated to deep instead of the
empty string   that is not the only problem with inconsistency  we have different tenses and
we have plural and singular forms  so is it meat slice  or is it sliced meat  if c is the chinese
word for meat slice  f c   meat is the most likely result  although we give weights to the
length of the chinese words  we do not really give weight to the length of the english word 
inconsistencies simply confuse the algorithm 
perhaps what we can do here is do a reverse matching  meaning that we will use a similar
algorithm to find a set of rules g e   c  which is supposed to be f inverse  training g will put
weights on the length of the english word such that one mistake  e g  typo  is not going to
change f c   meat slice to f c   slice  if one of the set has meet slice instead   this is
actually a quite important fix  but the problem is that this is not a   to   mapping  if it were 
running this algorithm both ways would be a great way to remove inconsistencies  but since f
is a one to many mapping  g will have to be many to one if it is f inverse  that would be hard
to achieve  so the most likely g will end up to be a many to many mapping  we can then try
each of these rules in g e    c and create a corresponding f c   e and see how the rule scores
in the training set 
iii one to many mapping
i guess the worst thing about this algorithm is that if the f c   e is a one to many mapping 
they we get multiple results  as i have explained above  a less likely translation could be the
right translation  but my algorithm does not know when is that the case  if somehow the
translation got you a choice between beef rice and pork rice  you can t really decide even
with the help of the translator 
  application

fione of the main point of this algorithm is that we do not need to know much about the languages  we
do need some minimal knowledge however such as the chinese words are not separated by space but
the english language is etc  if we have a perfectly objectively consistently translated menu  between
languages   we can simply feed it to the machine  then the algorithm will learn whatever it can and be
used to translate other menu  provided we have proper character recognition software on cell phones 
we can take pictures of the menu and find out the guessed meaning of the name  which would be
interesting 
  conclusion
the algorithm itself is not an especially efficient one  for the training data i have     training pair
 which by the way made me really hungry when i worked on this  it took about    minutes  after quite
a bit of optimization    the slowness is due to the fact that i do not know how to break up the words 
which lead me to a lot of guessing and thus delaying the result  i got most of my data from restaurants
around the bay area  but the problem remains   these menus are badly translated and extremely
inconsistent  and creative   so unfortunately i have to put in my own translated names for the program
to work  it is unfortunate because my goal is to feed the algorithm with menus that i do not understand
and have the machine learn it for me  the algorithm can possibly be applied to other fields where the
context does not involve too many words and where the grammar is not too important in the translation
 i think pork rice black bean sauce is much better than bone rice  so even with bad grammar the
translation here i think is quite useful to some people   i think the translations are helpful to a certain
degree with a lot of room for improvement  but since it may be related to what you eat and thus maybe
your health  use with care  attached is a list with f s that has the highest score 

training data obtained from  
hong kong restaurant
washington bakery and restaurant
tam cafe

fi











xo









































rice
beef
chicken
fried
noodle
seafood
soup
vegetable
beef
clay pot
bean curd
wonton
xo sauce
sandwich
pepper
baked
pork chop
spaghetti
egg
curry
sauce
fish
macaroni
shrimp
spare rib
black bean
shredded
porridge
mein
instant
salt
pork
rice
ginger
satay
cod
fried
chow fun
prawn
corn
tomato
vermicelli
kung pao
toast
meat
pork
egg plant
scallop
mushroom
satay sauce
stew
black
oyster sauce

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
 
 
 
 
 
 
 
 

fig    translation rules with the highest scores
































xo






















ham
udon
braised
pea
diced
squid
chow
cream
mustard
duck
special
luncheon
rice
kidney
dumpling
lai fun
short rib
haslet
garlic
style
chinese
fillet
broccoli
yee
oyster
tender
soup
chinese melon
broth
clam
ox
xo sauce
cashew
ball
braised
country style
noodle
pork
ball
minced
taro
assorted meat
butter
steamed
sour
abalone
steak
snow
sauce
preserved
sauteed
sauce
salted

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

fi