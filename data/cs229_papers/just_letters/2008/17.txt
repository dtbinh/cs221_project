tagez  flickr tag recommendation
ashton anderson and karthik raghunathan and adam vogel

abstract
user tagging of multimedia has emerged as the premier organizational tool for large sets of rapidly growing information  we present a tag prediction system
for images on flickr which combines both linguistic
and vision features  we describe methods for building
language models of tags on flickr  similar in spirit to
traditional language modeling in the nlp community 
we evaluate our system against held out flickr data 
and achieve competitive performance 

introduction
freeform keyword annotations have become a hallmark
of web     style internet applications  allowing users to
organize large  rapidly changing datasets  multimedia
tagging in websites such as flickr and youtube is a key
component in image retrieval and search  these new
platforms present several opportunities and challenges 
we now have unparalleled access to images with keyword annotations  but there are no rules for how a tag
applies to a photo  resulting in a very organic dataset 
although the large size of these datasets is attractive
for machine learning  their scale presents challenges to
our algorithms  the ubiquity of this problem has attracted interest in the vision  barnard et al        
web  sigurbjornsson and van zwol        and database
 heymann  ramage  and garcia molina       communities 
in this paper we present tagez  a tag prediction system for flickr  given a flickr image  which has possibly
already been tagged  tagez outputs a ranked list of five
candidate tags which might also apply  previous work
typically focuses either on the vision  barnard et al 
      li and wang       or language  sigurbjornsson
and van zwol       portions of the tagging problem 
we combine both vision and language features into one
global model 
using the language model described in  sigurbjornsson and van zwol       and the vision system
from  li and wang        we utilize rank aggregation
methods from social choice theory  borda       to combine them into a final ranking 
c       association for the advancement of arcopyright 
tificial intelligence  www aaai org   all rights reserved 

secondly  we describe a greasemonkey script which a
user can download that seamlessly adds our tag prediction system to the normal flickr tag interface  using
ajax technology  this allows us to asynchronously run
our image analysis  which takes on average less than
  seconds per novel image   returning our list in near
real time to the user 
lastly  we present an empirical evaluation of the
tagez system using standard information retrieval
metrics  these results show that the language component outperforms the vision component  and that their
combination actually underperforms just the language
component  we discuss a method for using held out
data in a lower bound evaluation to avoid the labors of
manual annotation 

system architecture
tagez consists of a language  vision  and aggregation
component  figure   displays our architecture  with an
example taken from flickr  note that in this example
the user has already applied some tags to the image 
which the language component uses to find commonly
co occurring tags throughout the rest of flickr  alternatively  the vision component learns correlations between the contents of the image and tags  but ignores
any previously applied tags  this allows for a purely vision based approach when the user has not supplied any
tags  and a surprisingly accurate language component
when the user has input a few tags 
outside of the box in figure    we also have a flickr
crawler and our greasemonkey front end  which allows
users to actually apply our system to flickr 

front end
for actual usage of the tagez system  we wrote a
greasemonkey  boodman       script which adds our
functionality directly to the flickr website     greasemonkey is a mozilla firefox extension that allows onthe fly changes to web pages after a user downloads a
small javascript like script  then when a user clicks the
 
available from
acvogel tagez 

http   cs stanford edu people 

fifigure    recommendation system architecture
add tag link on a photo in flickr  this greasemonkey script adds a line which calls and displays the tagez
recommendations  critically  we use an asynchronous
javascript call  ajax   which does not require a new
pageload to display our results 
more specifically  this greasemonkey ajax called is
handled by a jython webserver  which in turn calls our
tagez java implementation  jython is an implementation of python on the jvm  which allows native calls of
java libraries directly from python  when the ajax
call returns  the javascript in our greasemonkey script
displays the relevant links  which a user can then click
to apply the tags  in the same manner that flickr common tags are usually applied 

flickr crawler
our flickr language model requires many successive
api calls to gather the relevant unigram and bigram
statistics for tags of interest  this is not a problem in
offline evaluation and usage  but real world users wont
wait four minutes  thus we cache all flickr information we gather  and wrote a simple crawler to gather
the relevant statistics for common tags 
we use the flickr hot tag list as our crawler seed
set  which is a list of     commonly used tags  for each
of these seeds  we query flickr for the photos with that
tag  we gather other tags that occur in this result list 
and add them to our tag list  furthermore  we also use
the flickr getrelatedtags function to expand our tag
list  we repeat this procedure for each of the tags in
our seed set and crawl a total of      tags 
given this set of tags and photos they occur in  it is
straightforward to compute our language model statistics  we count occurrences  unigrams  using a simple tag search on flickr  and count co occurrences  bi 

grams  with a conjunctive tag query  in the case of
cache misses  we simply revert to the relevant flickr
api calls 

language
the purpose of the language component of our system
is to compute a set of tags that are likely to be relevant
to a particular image  given the set of tags u already
defined by the user  for each user defined tag ui  u  
we compute a list of related tags ri   these lists ri are
then merged into a single output list o of recommendations  we discuss these two steps in turn 

from user defined tag to related tags
the complete freedom flickr offers its users in regards
to tagging leads to a huge but noisy and inconsistent tag
space  because of this immense size  tag co occurrence
is a natural metric to use  the co occurrence between
two tags is the number of images that contain both
tags  by themselves  raw co occurrence scores are not
very meaningful since they ignore the frequency of the
individual tags  to account for this we normalize these
scores by the frequency of the tags  in the literature
there exist two different classes of normalized metrics 
symmetric and asymmetric  sigurbjornsson and van
zwol        we consider one of each 
the symmetric metric we use is the jaccard coefficient  which is defined as follows 
p  tj  ti     

 ti  tj  
 ti  tj  

   

unlike raw co occurrence  the jaccard coefficient is a
meaningful measure  however  it tends to measure how
similar two tags are  if two tags have a high jaccard
score  then they almost always occur in the data set as

fia pair  and one will almost never occur in the absence
of the other  our goal is not to find similar tags  but
to find relevant ones  asymmetric metrics are one way
of doing this 
the asymmetric metric we use is given by 
p  tj  ti     

 ti  tj  
 ti  

   

as the notation suggests  we can interpret this measure
as the probability of a photo being annotated with tj
given that it is annotated with ti  sigurbjornsson and
van zwol       
by looking at pairs of words scored by both the jaccard coefficient and the above asymmetric metric  we
observed that the asymmetric metric was much more
suited to our task than its symmetric counterpart 
as mentioned above  the jaccard coefficient tends to
score similar or synonymous tags highest  which from
our perspective is less interesting  we chose to use
the asymmetric coefficient for measuring co occurrence 
and throughout the rest of this paper references to cooccurrence score will mean the asymmetric calculation 
as mentioned above  our decision to use a cooccurrence metric was partially motivated by flickrs
enormity  however  crawling all of flickr wasnt feasible  given a tag ti   finding the relevant tags ri corresponding to it would have required a number of searches
on the order of the number of tags in flickr  around
    million  sigurbjornsson and van zwol         doing this for any significant number of tags would require
an astronomical number of calls to the flickr api and
computer time  instead  we use a method in the flickr
api that returns some of the most relevant tags for any
given tag  this function is computed by deep in house
analysis of the full tag graph  for each user defined tag
ui   we only consider these tags as possible candidates
for inclusion in the corresponding list of related tags ri  
this allows us to cut down on the number of other tags
to consider from millions to dozens  while still using the
aforementioned co occurrence metrics to decide which
tags are most relevant 

merging the lists of related tags
after coming up with a list ri of relevant tags  each
with a score  for each user defined tag ui   the last step is
to aggregate them together to form the final recommendations o  in all of the following methods  we compute
a final score for each tag then sort the tags in descending order 
   vote the vote method is the simplest possible
method and we use it as a baseline  a user defined
tag ui votes for tag t if t appears in ri   the final score for a tag ti is the total number of votes it
receives 
   sum in the sum method  a tags final score is the
sum of its scores in all lists ri in which it appears 
so within a list ri   the related tags are given votes

weighted by their score instead of all related tags getting equal votes 
   promotion methods sigurbjornsson and zwol introduced a promotion score based on the overall
frequency of tags in flickr  tags are penalized for being either too frequent or too infrequent  and the rank
in which tags appear in the ri lists  this can then be
aggregated by vote or sum  as above  sigurbjornsson
and van zwol       
   aggregation of the above we aggregated all four
of the above methods using borda voting  see the
rank aggregation section  

vision
our vision system learns a predictive model of keyword
tags from an image feature representation  we use the
automatic linguistic indexing of pictures   real time
 alipr  system developed by li et al   li and wang
       this system has several desirable properties 
it uses a fairly shallow feature representation which is
not fitted specifically to any domain  and furthermore
alipr is fairly quick  taking an average of     seconds
to predict tags for a novel image 
we use the alipr system as a black box  where we
input an image from flickr and get back a list of    tags
and their corresponding confidence scores as output by
the model   
space considerations prevent us from describing this
component in great detail  but the feature representation is a mixture of luv color features and texture
features which are formed from wavelet coefficients in
high frequency bands from the original pixel data  this
results in a   dimensional feature vector for each pixel 
alipr next clusters these pixels into contiguous image
segments  using this feature representation  alipr
next learns a generative model of p image tag   and
chooses tags which maximize the posterior of the image
features 
however  alipr is only trained on     keywords
from the corel image dataset  a commonly used
gold standard image keyword corpus  blei and jordan
       although they evaluate their system against
flickr in  li and wang        its not clear why they do
not train on all of flickr  this severely limits the impact that the vision component can have on our overall
system  as there is oftentimes not much overlap between
the language and vision outputs 

rank aggregation
once the vision component and the language component have outputted their recommendations  the system
must aggregate these two ranked lists in some logical
way  this problem crops up in many natural settings
in information retrieval  for example aggregating search
engine results   we use a simple algorithm from the ir
 
thanks to james wang for giving us access to the
alipr api 

filiterature called borda voting  which originated in election theory  borda        in each list  of size n   the
tags are assigned a decreasing number of points  the
top ranked tag is given n    points  the second ranked
tag is given n    points and so on until the last tag
which is given no points  then the points for each tag
are summed and the tags are sorted in decreasing order 
if the lists have different numbers of elements  we set n
to be the size of the longest list 

evaluation
in this section we present our quantitative evaluation
of our tag prediction methods  we started with a set of
   seed tags  and for each seed tag we randomly chose
around    images with this tag which had at least  
tags  this yielded a test set of     images  for each
test image  we randomly held out one fifth of the tags 
treating them as the test tags  since flickr places
no restrictions on the tags users can annotate their pictures with  many tags are very infrequent and virtually
unpredictable  we filter these out by calling flickrs
getrelated function on the test tags and filtering tags
that have no related tags  this heuristic is based on
the observation that tags with no related tags in the
tag graph are typically obscure and infrequent tags 
we then ran each prediction method on the test images and compared the output to the held out test tags 
a predicted tag is judged as incorrect if it is not present
in the held out set  since the held out tags need not
be the only tags which could apply to an image  our
evaluation method actually gives a lower bound on our
systems performance 
to evaluate the results  we used standard information
retrieval metrics  the mean reciprocal rank  mrr  
the success at rank k  s k   and the precision at rank
k  p k   the mrr is defined as the reciprocal of the
rank of the first relevant  i e  held out  tag  averaged
over all test photos  success at rank k is   if a heldout tag was ranked in the top k results and   if not 
averaged over all test photos and precision at rank k is
the number of held out tags ranked in the top k results 
again averaged over all test photos 
figure   displays our results  surprisingly  the sum
method consistently outperformed the baseline vote
method  indicating that the asymmetric co occurrence
scores we used are appropriate and helpful in evaluating how relevant tags are  in contrast to the results
in  sigurbjornsson and van zwol        the promotion methods actually hurt performance  the vision
component did not perform well under our evaluation
metrics  probably because the vision components vocabulary is restricted to the corel image datasets    
tags  this restriction severely limited the vision components possible success under the ir metrics  only
    of the     test images contained held out tags in
the vision components vocabulary  if the vision component had been trained on flickr  or if we had used
human evaluation  the vision component would probably have received much higher scores  because of this 

the entire system  both vision and language components aggregated using borda voting  underperformed
the language component by itself  this suggests that
the aggregation method we used was too crude 

conclusion
in this paper we presented tagez  a system for tag
recommendation incorporating both language and vision components  in the language component  a natural asymmetric co occurrence metric is used for quantifying how related one tag is to another  we narrow
our attention of potentially related tags to only those
that are relatively close in the tag graph  which is
computed by an in house flickr function  then we aggregate these lists together using various methods and
output one final ranking  the vision component use
basic texture and image segmentation to recommend
potential tags  these two disparate recommendations
are then aggregated into one final list using a rank aggregation algorithm borrowed from election theory 
we evaluated our system using a test set of     images with some of the original tags for each image heldout  then we compared the systems output with the
held out tags only counted direct matches as successes
 thus our evaluation was a lower bound   we used standard information retrieval metrics to quantify the quality of our tag recommendation methods 
we found that the sum method of aggregating related
tag lists within the language component outperformed
all other tag recommendation methods  including the
combination of the language and vision components 
the main reason for the underperformance of the vision component is that it was not trained on flickr 
the aggregation method we used  borda voting  also
disregarded the scores that were given to it 
tagez leaves several areas open to improvement 
firstly we could train the vision component on all of
flickr so that it can handle all tags  tagez uses a
primitive method of aggregating the two components
recommendations  refined aggregation would improve
performance  another possible extension is to use the
output of the language component to narrow down candidate tags for the vision component 

references
barnard  k   duygulu  p   forsyth  d   freitas  n  d  
blei  d  m   k  j   hofmann  t   poggio  t   and
shawe taylor  j        matching words and pictures 
journal of machine learning research            
blei  d  m   and jordan  m  i        modeling annotated data  in sigir     proceedings of the   th
annual international acm sigir conference on research and development in informaion retrieval     
     new york  ny  usa  acm press 
boodman  a        greasemonkey  http   www 
greasespot net  
borda  j  c        memoire sur les elections au
scrutin  in histoire de lacademie royale des sciences 

fi a  mean reciprocal rank

 b  precision at rank  

 c  success at rank  

figure    experimental results
heymann  p   ramage  d   and garcia molina  h 
      social tag prediction  in proceedings of the   st
annual international acm sigir conference 
li  j   and wang  j  z        real time computerized
annotation of pictures  in multimedia     proceedings of the   th annual acm international conference on multimedia          new york  ny  usa 
acm 
sigurbjornsson  b   and van zwol  r        flickr
tag recommendation based on collective knowledge  in
www     proceeding of the   th international conference on world wide web          new york  ny 
usa  acm 

fi