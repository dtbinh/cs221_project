cs     the netflix project
jane huang  jack kamm  conal sathi
december         

abstract
this paper investigates the combination and application of a number of machine learning
applications to the netflix challenge  the algorithm uses extra data in addition to the
netflix training set  namely  it uses a mapping from netflix to features gleaned from imdb 
such as the director and genre  using k means clustering  the algorithm first clusters the
users together by the imdb features each movie has  we tried making predictions through
principally three methods  using naive bayes alone on the imdb features  the average rating
that a cluster gives to a movie  and through combining naive bayes with clustering 

introduction
the netflix challenge
given a user and a movie  we need to predict what rating the user gave me the movie  as
training data  we are given a list of vectors  u  m  r  t   where u is a user id  m is a movie
id  r is the rating u gave to m  and t is the date 
after training  we output predictions for a list of user movie pairs  we measure error by
using the root mean squared error  rmse  
the netflix challenge is to get an rmse of or below         the data set comprises
over     million movie ratings from over         customers 

general points on methodology
to make things faster  we ran our algorithms on a random set of      users  we used simple
cross validation to test our results  we removed one movie for each user from the training
data and placed it in our test set 
to augment the training set netflix provided  we used a mapping that maps each movie to
a list of features it contains  such as genre  director  and actors  the mapping only consisted
of those features that appeared in    movies or more  there are      such features  for
comparison  a mapping with features that appear in   movies or more has       features  we
chose to use the smaller feature mapping because it would be faster to use and also because
features that appear in very few movies wouldnt be very useful for making predictions 

 

fialgorithms
naive bayes
the first algorithm we tried was simple naive bayes  for a given user u  for a movie m with
features f    f    f            fn    we predicted the rating r that maximized p r  u p f  r  u  
using
the naive assumption that all features are independent  we get that p f  r  u   
qn
i   p fi  r  u   we used the maximum likelihood estimates with laplace smoothing to
estimate p fi  r  u  and p r  u  
we tried using naive bayes because it could take each users individual preferences for
specific features into account  however  the rmse we got was         which is not very
good  for comparison  if you simply predict the average rating of each user for each usermovie pair  we get an rmse of         one obvious problem with naive bayes is that it
assumes each feature is independent  which is not true  for example  a director may prefer
to work with particular actors  a bigger problem is that users have not seen each feature
enough times to make good predictions  a single user will not have watched all that many
movies  and each movie only has a handful of features 
to remedy the latter problem  we also tried using naive bayes with clusters  we clustered similar users together  see the following section   and then when making predictions
we treated each cluster as a single user  so  for example  if user u belongs to cluster c 
for a movie
q m with features f    f    f            fn    we predict the rating r that maximizes
p r  c  ni   p fi  r  c   where we estimate the probabilities using the maximum likelihood
estimate with laplace smoothing  so  for example we estimate p fi     r  c  to be the
number of times we have seen a movie with feature fi get rating r by any user in c  divided
by the number of times we have seen a movie get a rating r by any user in c  and then add
one to the numerator and two to the denominator 
after clustering we got better results  our best results were with    clusters  we got an
rmse of         if we have too many clusters  clusters are too small and we dont have
enough data per cluster to make accurate predictions  if clusters are too large  there are too
many dissimilar users in a single cluster 

k means clustering
a typical way to predict how a user will rate a movie is to see how similar users rated the
same movie  so we clustered similar users together  and then used information in the entire
cluster to make predictions for any individual user in the cluster 
we decided to cluster users together based on their tastes about imdb features  in
particular  for each user and each feature  we calculated the expected rating the user would
give a movie with that feature  we then placed the user in a high dimensional space  where
each dimension is a imdb feature  and the coordinate of the user along that dimension is
the expected rating the user gives that feature  we then used k means  with the euclidean
norm  to cluster users 
to make predictions with clusters  we use two methods  firstly  we use cluster averaging 
when we want to make a prediction for a movie  we look at the other members of the users
cluster to see how they rated the movie  and take the average  if were predicting a rating
for a movie that nobody else in the cluster has watched  then we use the users own average

 

fimovie rating  we ran the cluster averaging algorithm on varying cluster sizes  and discovered
that the best number of clusters to have was ten  which implies an average of about     users
per cluster  the following graph shows how the rmse varies with the number of clusters
used 

the shape of the graph is convex  which makes sense  the fewer clusters you have 
the more overfitting you do  because users within clusters becoming increasingly dissimilar 
however  the more clusters you have  the less information you have with each cluster to work
with  it appears that for a set of      users  ten clusters finds the right balance between
overfitting and a lack of information per cluster 
surprisingly  combining the algorithms is not very helpful  using cluster averaging yields
a better rmse than combining clustering with naive bayes 

it makes sense that naive bayes combined with clustering does better than naive bayes
alone  see naive bayes section  it is surprising that simply using cluster averaging works
better than naive bayes combined with clustering  however  since naive bayes uses more
information about users tastes  naive bayes may perform worse because it fails to take
into account the intrinsic value of a movie  for example  the matrix and the matrix  
probably have similar features  but the matrix is a far superior movie  by using cluster
averaging  however  we use the average rating given by the cluster  which is going to be a
lot higher for the matrix than for the matrix   
 

fiprincipal components analysis
since we had      data points that each had over a thousand features  it seemed wise to
prune back the number of features through principal components analysis before making
any clusters  we hoped that though applying pca would cause some information loss as it
compressed      dimensions into k dimensions  the information loss would be compensated
for by reducing a lot of noise at the same time  in addition  it might have helped the k means
clustering algorithm run faster  in our experiments  we ran pca on the optimal cluster sizes
we found  so for cluster averaging  where the optimal number of clusters was ten  we used
ten clusters  and for clustering combined with naive bayes  we used forty clusters  the
following graph shows the results we got while varying the number of components used 

running pca prior to running cluster averaging alone does not improve rmse  despite
tweaking the number of components for ten clusters  we are unable to achieve a lower rmse
than for ten clusters without pca  this may be because pca encourages overfitting and
user tastes are highly idiosyncratic  once we chose the best number of components however 
rmse was nearly the same as the best rmse for cluster averaging  so choosing an optimal
number of components might not hurt results 
however  running pca to form the clusters before running naive bayes combing with
clustering does seem to help the rmse a little bit  these results are unexpected  however 
since for using naive bayes we use all the features  not the set of compressed features created
by pca  it does not seem like pca should have an effect at all  the benefit seen from pca
could simply be random noise 

 

ficonclusion
the following graph displays the best rmses achieved with each algorithm 

we used a few different approaches to try and make predictions for the netflix challenge 
unfortunately  our algorithms had limited success  the least successful approach was naive
bayes  in large part because we did not have enough data for an individual user  when
we combined clustering with naive bayes  we got better results  however  simply taking
averages across each cluster does a better job than naive bayes  this may be because naive
bayes fails to take into account the intrinsic value of a movie  even though a movie has
features a user likes  the movie might still be poorly made  finally  we tried using pca to
help with clustering  pca made clustering faster but made the clusters less accurate when
we just took averages across clusters  the clusters were slightly more accurate for naive
bayes 
there are a couple of things we could do to improve our algorithms  for naive bayes  we
could try to take into account the intrinsic value of a movie by offsetting our prediction by
the average rating of the movie  for clustering  we could take into account more information
than just the expected rating that a user gives a feature  for example  the variance of a
rating that a user gives a feature shows how important a feature is to the user  a low variance
implies that the feature is more important to the user   to improve clustering  we could
turn each feature into   dimensions  one for each rating  and along each dimension plot the
probability that the user will give the feature that rating 

references
grigorik  ilya  correlating netflix and imdb datasets  january         
ng  andrew  lecture notes  december      

 

fi