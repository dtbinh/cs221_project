self lane assignment using smart mobile camera for intelligent
gps navigation and trac interpretation
tianshi gao
stanford university

tianshig stanford edu

   introduction
imagine that you are driving on the highway at   
mph and trying to gure out which lane should follow
to exit in front  the precision of the current gps cannot tell on which lane you are on  so the instruction
given by the gps is just as simple as keep right resulting in the drivers panic caused by searching from
multiple signs  however  if we have a smart camera
mounted inside the vehicle which is capable of inferring the current lane the vehicle is on and feeding this
information into gps  then more intelligent instructions like stay on the current lane or turn to your
next right lane can be achieved 
another potential application using smart mobile camera is to estimate the speed and density of the vehicles surrounding a prob vehicle with camera mounted
inside  as a result  real time trac status can be inferred from data collected by actively running vehicles
instead of limited static loop detectors beneath the
road  moreover  if the prob vehicle knows which lane
it is on  then lane by lane trac ow can be obtained
by reporting the self lane number of the prob vehicle 
in this report  i proposed a novel and very eective
algorithm consisting of both computer vision and machine learning techniques to solve the problem which is
dened as given an image taken by a camera mounted
inside a vehicle  infer on which lane the vehicle is 
i form this problem as a scene classication problem
where dierent classes correspond to dierent scenes
seen from dierent lanes as shown in figure    in the
proposed algorithm  horizon is detected  a set of features at dierent positions on the image is obtained
from a lter bank consisting of oriented steerable lters at two scales and nally three dierent learning
algorithms are applied to train the classiers and the
results are compared  for each class  both the precision and recall rates are around or above     

 a  lane  

 b  lane  

 c  lane  

 d  lane  

figure    sample images from four dierent classes

   approach
     problem formation
in this work i focused on the highway situation where
lanes exhibit low curvature and the number of lanes is
four which is given as prior information  in practice 
this is a reasonable assumption because we can get the
number of lanes from the gps digital map and four
lanes is a very common case 
since perfectly detecting tting all lanes is unreliable
or even impossible due to occlusion caused by other vehicles  i tried to nd a global representation of the image directly from low level features like oriented edges
and infer the self lane number by the overall appearance  therefore  we can think of this problem as a
scene classication problem in which given a test image we want to classify it into four categories corresponding to four scenes seen on lane         and  
respectively  lane   corresponds to the leftmost lane 
and others are indexed from the left to right  
the scene classication problem considered here is different from the traditional one which is about classifying images into very broad categories like oce  highway  forest  mountain  etc  therefore  the problem
here is more challenging in terms of understanding the
scenes in a ner granularity  it is also dierent from
object recognition which id like to bypass  since each
object detector for the lane marker  vehicle and road

fiself lane assignment using smart mobile camera

will have certain error rate and its very likely that errors from each detector will accumulate at later stage 
     feature
       feature design
based on the intuition of how people distinguish dierent lane situations  there are three desired properties
for a good feature design to capture 
 lane markers  lanes are separated and dened by
lane markers  so they are the most discriminative
information 
 vehicles  if there are multiple vehicles on your
right  then its less likely that you are on the rightmost lane 
 spatial distribution  besides the presence of lane
markers and vehicles  the more important information is how they are spatially distributed on
the image plane 
to capture the information above  as shown in figure   a  a lter bank consisting of oriented steerable
lters is used to implicitly capture the textures for
both lane markers and vehicles  due to perspective
projection  the scales of edges at dierent positions on
the image plane varies  so i used two sets of    lters
which are at two dierent scales  to keep the spatial information  i partitioned the image below horizon
into multiple cells which is shown in figure   b  

 a 

m                 corresponding to each lter turned
to dierent angles with even or odd phases  in the experiment  ive partitioned the images into m n cells 
where m     and n      let the grayscale image be
i and then the response of the image to each of the
lter is incorporated into 

  i  fk m   x  y  
   
xi j k m  
 x y ci j

where ci j corresponds to the cell at ith row
and jth column and i           m and j  
        n   in order to make the response less sensitive to the illumination and contrast of the image  i normalize the    dimensional vector xi j k   
 xi j k     xi j k          xi j k     t to have energy    i e  
xi j k         but if the energy of xi j k  is too small 
ill not normalize it in order to capture those uniform
road regions  furthermore  three statistics used in    
of the response for a set of    lters within one cell are
also incorporated into the feature vector  these three
statistics include mean  argmax and maxmedian of
the components of xi j k    so each cell has a        
dimensional descriptor  and all the    descriptors are
stacked into a single                   dimensional
feature vector for each image 
     horizon detection
as mentioned in the above subsection  the image is
partitioned into multiple cells below horizon  i detect
the horizon by detecting the vanishing point in two
steps as follows 
   lone line detection  i used the same method mentioned in     to detect lone lines in the image and
ltered out those nearly vertical or horizontal lines
to reduce outliers  denote the number of lone
lines after ltering as l and these lines are parameterized by i and ri as follows 
x sin i   y cos i   ri

 b 
figure     a  filter bank consisting of    oriented steerable
lters per    degree with even and odd phases  b  spatial
partition below horizon

       feature representation
denote the lters as fk m where k        corresponding to two sets of lters with dierent scales and

i              l

   

   robust fitting in hough domain  since the vanishing point is located at the intersection of the l
lines  we can get the estimation of the vanishing
point by minimize the norm of the residual 
minimize ax  r 

   

where 



a 


sin  
sin  
  
 

cos  
cos  
  
 

sin l

cos l












r 


r 
r 
  
 
rl







fiself lane assignment using smart mobile camera

the reason i used   norm instead of ordinary least
square is to make the estimation less sensitive to
outliers  this convex optimization problem     is
solved using cvx      figure   shows some detection results 

table    horizon detection error rate
mean of relative error std of relative error
     
     

   experiment and result
     data
i sampled frames from    short sequences and the
numbers of images collected for lane   to lane   are
              and     respectively  since the dataset
is unbalanced  i set the initial weights for adaboost
according to the proportion of the number of images
for each class  and also adjust the penalty parameters
of relaxation for dierent classes in svm according to
the ratio between the numbers of dierent classes 
     horizon detection

figure    sample horizon detection results  color lines are
the detected long lines and the cross is the detected vanishing point 

     learning algorithm
each dimension in the feature vector doesnt provide
equal information  for example  those features from
the cell that is in front of the vehicle contain little
information  to avoid overtting  i e   reducing the
model complexity  i have chosen three dierent learning algorithms 

i estimated the horizon position for all the      images  and table   and figure   show the detection
result  around     of the detected horizon lies in the
   relative error band  the mean of the relative error
is only       which is   pixels in this case 
   
estimated horizon position
   relative error band

   

   

   

   

   adaboost with decision trees  i used logistic regression version of adaboost        with weak
learners based on decision trees  decision trees
make good weak learners  since they provide explicit feature selection and limited modeling of the
joint statistics of features 
   bayesian logistic regression  by assuming a prior
on the coecients in logistic regression  bayesian
logistic regression is capable of shrinking the coefcients to avoid overtting  the parameters can
be learned by map and i used zero mean gaussian prior and implementation from     
   svm  although svm doesnt provide explicit feature selection or shrinkage  its still possible to
have relatively low error rate  i used the     implementation with linear kernel 

   

   

 

   

    

    

    

    

figure    estimated horizon positions 

     classification
the classier for each class is trained in one vs  all
fashion  at the test stage  the classication result is
chosen as the one with the highest probability  i used
  fold cross validation to evaluate the performances
of three learning algorithms  the fold number is  
instead of most common   or    is because i want to
reduce the correlation between the training and test
data 
the confusion table for each algorithm is shown in

fiself lane assignment using smart mobile camera
table    confusion table for adaboost with decision trees
lane  
lane  
lane  
lane  
precision

lane  
   
 

      

lane  
 
   
  
 
      

lane  

lane  

  
   
  
      

  
  
   
      

recall
      
      
      
      

hmm  making spatial partition more robust maybe by
drawing rays from vanishing point 

 a  lane  

table    confusion table for bayesian logistic regression
lane
lane
lane
lane

 
 
 
 

precision

lane  

lane  

   
 

 
   
  
 

      

      

lane  

lane  

recall

  
   
  

 
  
   

      
      
      
      

      

      

 b  lane  
table          all three methods give comparable
results  and bayesian logistic regression has slightly
better accuracy for lane   and lane    in general  the
precision and recall rate for each class is around or
above      in addition  the results are consistent with
the intuitions in terms of  i  lane   and lane   have
better accuracy than lane   and lane    ii  lane   and
lane   are more likely to be confused by each other 
iii  and lane   is more likely to be confused by lane  
than lane      and lane   is more likely to be confused
by lane   than lane     
moreover  top features selected by adaboost with decision trees are shown in figure    the oriented lters at
dierent cells correspond to the selected features  the
positions and orientations of these lters are more or
less consistent with the positions and orientations with
the lane markers or the vehicles like the vertical edge
response at the  nd row and  rd column for classier
lane   

 c  lane  

 d  lane  
figure    selected top features by adaboost with decision
trees for dierent classes 

acknowledgments
id like to thank honglak lee and zhi li for some
helpful discussions 

   conclusion and discussion

references

in this report  i have proposed a novel and eective
algorithm to infer the lane number from a single image  the results show that bypassing explicit object
recognition and achieving the inference goal directly
from low level representation with the spatial distribution works well in this scene classication problem requiring ner granularity  some further improvements
could include incorporating temporal dimension using

    d  hoiem  a  efros  and m  herbert  geometric context from a single image  international conference on
computer vision  iccv        

table    confusion table for svm
lane
lane
lane
lane

 
 
 
 

precision

lane  

lane  

   
 

 
   
  
 

      

      

lane  

    j  kosecka and w  zhang  video compass  proc 
eccv  springer verlag       
    m  grant and s  boyd  cvx  matlab software for
disciplined convex programming  web page and software  
http   stanford edu  boyd cvx  december      
    m  collins  r  schapire  and y  singer  logistic regression  adaboost and bregman distances  machine learning 
vol      no           

lane  

recall

  
   
  

 
  
   

      
      
      
      

      

      

    a  genkin  d  d lewis and d  madigan 
bbr 
bayesian
logistic
regression
software 
http   www stat rutgers edu  madigan bbr 
   
a

c 
chang
and
c 
library
for
support

lin 
libsvm

vector
machines 

fiself lane assignment using smart mobile camera
http   www csie ntu edu tw  cjlin libsvm

fi