recognizing people in video sequences
red daly

   abstract
we confront the problem of identifying people by name using video data  this paper
has two main contributions      a face recognition algorithm based on sift features that
is capable of high accuracy rates for some datasets      a simple algorithm to be used in
conjunction with a facial recognizer to smooth recognition in video sequences 

date  november          
 

fi 

red daly

   introduction
facial recognition systems have wide applicability in search  security  robotics  and other
areas  in many of these fields  video data is already highly available  however  most
facial detection and recognition technology exists to identify individuals using a single still
image  we leverage these existing technologies in the current system use some additional
information available  
there has been extensive work in facial recognition  commonly used facial recognition
algorithms to date include eigenfaces  turk        and fisherfaces  belhumeur         we
base our approach to facial recognition on sift features  sift  as described in  lowe 
      is the best known a family of local feature detection algorithms which also includes
surf and derivatives of sift 
   problem
we are provided n training pairs  x i    y  i     i           n where x i  denotes the ith training
image and y  i    l  l           n if the lth image is a picture of the lth persons face  given
a test movie x with m frames  we wish to label each frame yi l      i           m if the ith
frame contains the lth person and yi l     otherwise 
in order to constrain the problem  we assume the positive training examples show only
the face region of a single persons body  we do not  however  assume that the eyes  nose 
or other features of each face are aligned within a training set  ideally the algorithm we
use should be robust to changes in illumination and pose 
   method
we attempted to solve the above problem by first developing a facial recognizer that is
capable of working on still frames  we use sift features as the basic unit of recognition 
as opposed to approaches based directly on pixel values  thus  for each image we processed
the input image for sift features and were then able to discard the image data  a basic
assumption we made was that recognition is based on facial features and does not not use
other aspects of the image to train or label 
     facial recognition based on  lowe         as our first approach  we used the
technique for matching sift keypoints as described in  lowe         keypoints are ex i 
tracted from all training images and the test image  let rj denote the j th     point
sift feature descriptor vector corresponding to training pair  x i    y  i     for each keypoint
descriptor from the test image  r  we find its nearest neighbor in the set of feature de i 
 j 
scriptors  r   we also find the second nearest neighbor  r such that y  i     y  j    the
 i 
 j 
ratio of the
fifi euclidean
fifi distance between r and r and r and r must be less than   
fifi
 i  fifi
fifir  r fifi
fifi         and y  i  must be   in order for the match to count   this
 i e     fifififi
 i  fifi
fifir  r fifi
 

firecognizing people in video sequences

 

exclusion method uses the empirical result that     of p correctm atch   is distributed
where       while only     of p incorrectm atch   is distributed where        
these preliminary matches are further filtered by performing a hough transform using
the scale  orientation  and position components of the matched sift features  and maximizing in the hough space  we did not perform the final geometric step used in  lowe 
       and instead accepted the results of the hough transform to cluster matched keypoints  we also weighted bin entries in our hough transform by         using the insight
that       roughly corresponds to how good a match is  we used the largest cluster
of keypoints output from the hough transform as the final match  accepting the match if
there were more than   points in the cluster 
     svm based supplement  single frame based approaches to facial recognition on
video often suffer from sporadic incorrect recognitions due to bad frames or deficiencies
of the facial recognition algorithm  we therefore developed an algorithm based on svms
that predicts  based on information available about previous frames  whether the current
frame should be labelled as a match for a given person l 
the input to the svm is a measure of confidence that the person appeared in each
of c of the previous frames  we used a c of     corresponding to one second of video
in our test set  the measure of confidence was exactly the size of the largest cluster of
sift keypoints described the the basic facial recognition algorithm  the svm thus made
use of the trained sift based face recognizer to perform its on training  in addition to
the additional information used from video data  this algorithm also replaced the hand set
  point threshold with a value determined by the svm to improve performance 
     implementation  sift features were extracted using the sift   library  vedaldi 
      and a script written to analyze its output  for svms  libsvm  chang  lin       
was used in combination with a common lisp wrapper library  melis         image formats
were interchanges using imagemagick 
all other algorithms related to image processing and machine learning were written by
the author 
   testing
first we tested our facial recognition algorithm against the at t face database  which
is a database of frontal face images  there are    images each of    subjects  we only
tested with    subjects due to the o nm  complexity of our unoptimized implementation 
we then tested the same algorithm against a self made image database  our database 
unlike those commonly available  contains video data of subjects to accompany frontal
facial images  the database contains three subjects  each with ten frontal facial images
and two to   ten second videos  the individual video frames are labelled for whether they
contain the person in them or not 
     results  our sift based facial recognizer was able to achieve an accuracies of      
and       by training on only   images per subject on the at t and in house databases
respectively 

fi 

red daly

the       accuracy on our own database is based on using the facial recognizer on each
frame of video for each participant  when we used the svm supplemented facial recognizer
on the video frames  we were able to achieve a higher accuracy rate of        most of the
observed gains were due to smoothing of poor earlier results 
   references
belhumeur  hespanha  et al  eigenfaces vs  fisherfaces  recognition using class specific
linear projection      

chang  chih chung  lin  chih jen        http   www csie ntu edu tw  cjlin libsvm 
melis  gabor  cl libsvm        http   www cliki net cl libsvm
turk  m   pentland  a  eigenfaces for recognition      
turk 
vedaldi  andrea  sift          http   vision ucla edu  vedaldi code siftpp siftpp html
viola  paul  jones  michael j  robust real time face detection      

fi