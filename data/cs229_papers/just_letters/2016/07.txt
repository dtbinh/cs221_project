machine recognition of squiggles in seti signal data
travis chen  travis   stanford edu   kenny smith  smithken stanford edu 
jason wang  jasonkwang stanford edu 

i  introduction
the singular question  are we alone   has boggled
scientists for centuries  the seti institute operates the
allen telescope array  ata  to observe star systems for
radio signals which may provide evidence of extraterrestrial intelligence  signal events that maintain an intensity
above an empirically set threshold across all frequencies
are converted into spectrogram images through a slidingwindow fast fourier transform  fft  and set aside for
human analysis 
a key problem is being able to pinpoint significant
patterns in the signal stream that are not associated with
known interferences  such as aircraft rfi and narrowband zero drift signals  seti is currently constructing
a pipeline to stratify known interferences within signal
streams in real time  in the past few years  an unknown
subset of signals  inelegantly referred to as squiggles  has
become increasingly prevalent  squiggles are broadly
defined as modulating signals  hand curated by scientists
at nasa  their origin is unknown  in fact  the quest to
understand squiggles is an open problem posed by seti
     our project will be centered on this signal subset 
using spectrogram waterfall plots collected from the
ata seti dataset  we hope to make an open source
contribution in two ways     perform supervised learning
to classify squiggles against nonsquiggles and    conduct unsupervised learning to identify potential squiggle
subgroups and their characteristics 
ii  related work
in the specific domain space of squiggle analysis  little
work has been done  for the past decade  seti has
worked to optimize its real time processing algorithm
to identify notable signal events that warrant human
intervention  sonata is a open source software system
that currently includes a post processing package to
identify common pulsar and linear  carrier wave signals 
there has been a significant amount of academic literature dedicated to the domain of classifying unknown
signals streams and feature extraction from spectrogram
images  iversen et al      constructs a combined artificial
neural network classifier to classify various unknown
radio signal formats  due to our limited data set of only

fig     squiggle spectrograms

fig     non squiggle
spectrograms

    unlabelled squiggle examples  we believe training
a neural network to classify between squiggle and nonsquiggle signals would lead to gross overfitting  perovic
et al      provides a landscape overview of spectrogram analysis  spanning topological feature extraction to
kalman filtering to identify dynamic signals  we hope
to use an approach unique to squiggles  conversion of
squiggles into discrete time series data points 
iii  dataset
we used a dataset of      spectrogram images provided to us by the seti institute  this includes a library
of     hand identified squiggles and      nonsquiggles 
attributed to known human interferences and random
noise  each spectrogram is comprised of a signal event
that passed the sonata pre processing phase between
the dates of           and            the png format
is specified at    x    pixels  representing roughly
   mhz in bandwidth and    seconds  respectively  xaxis  frequency domain  y axis  time domain  
iv  methodology and preprocessing
a  conversion of spectrograms into discrete timepoints
in exploring the spectrogram dataset  we arrived at the
conclusion that each squiggle can be treated a discrete
time series  by selecting one frequency from each time
slice in a spectrogram  our initial approach relied solely

fion intensity  selecting the frequency with the maximum
intensity from each timeslice  however  this approach
failed to trace the squiggle accurately in the presence of
strong background noise  furthermore  many squiggles
had gaps  sets of time slices over which the signal disappears almost entirely  to solve this issue of interpolation
and to exclude outlying points  we sought the optimal
path to minimize the following loss 
l x    

t
x

 i t  xt     in  t  xt   

t  

 

t
x
        xt  xt    
t  

where i x  y  gives the intensity
at some discrete
p
point  x  y   and in  t  xt     o                  i t  
o    xt   o    represents the intensities of surrounding
points   and  are the parameters of our loss function 
we found that        and      produced the best
results  hence  our final loss function was 
t

l x    

t

 x
 x
i t  xt    
 xt  xt    
  t  
  t  

the code was optimized in c    with the ultimate goal
of integration into a real time analysis pipeline     
b  spectrogram analysis
we extracted two features from the data prior to
conducting any time series analysis 
   loss   we found that the final value of the loss
function resulting from our discretization algorithm over the resultant squiggle proved to be a
reliable measure of overall intensity and coherence
of the signals in our data set 
   width   letting i   the max intensity of a given
time slice  and i be the corresponding index  we
estimated signal width of all     time slices based
on the number of indices in  i      i       with
intensities     i  we then took the mean of
signal widths falling between the   th and   th
percentiles 
c  time series analysis
each spectrogram image has the same frequency
units but captures a different window of bandwidth 
unfortunately  the frequency ranges of each plot were
unavailable to us  so we conducted our analysis in a
manner agnostic to absolute frequencies  before any
time series analysis  we modified each time series to

have mean   by subtracting the original mean  after
this normalization  we extracted the following features 
   variance   we took the overall mean squared error
 mse  of the time series around the mean 
   modulation xt     t       wt   wt  n          i i d t
we first fit a linear model  above  to the data using
simple linear regression  we then estimated    by
taking the mse of the model 
   arima          parameters     b xt        b wt   
xt         xt   xt    wt   wt    
wt  n          i i d t
using the arima function in r  we first tried out
various models in the arima class of models
before settling on arima           which consistently provided the lowest akaike information
criterion  aic  when fitted to squiggle time series  we fitted arima          models to each
squiggle time series  and extracted estimates for
the parameters       and      and incorporated
these estimates into our analysis 
   hurst
i
h exponent
h
 
cn
e r n 
s n 
we estimated the hurst exponent  a measure of
the long term memory of the system  using the
numpy polyfit function on the lag vector we
obtained 
   fast fourier
pt transform
 ikt
xk   t   xt e       k                
we applied a fast fourier transform  fft  to
the squiggle time series to extract the component
frequencies in the signal  we sampled the fft
output at    uniformly spaced frequencies from
  to   we ignored the fft at k     which
corresponds roughly to the mean of the signal  our
resultant features were the absolute values of the
fft at these points 
v  classification
to ensure an unbiased classification  the full dataset
was split into     training and     test  using the
training set  we applied    fold cross validation to
tune model parameters  performance metrics were then
scored by applying the fitted classifier to the     heldout validation set  we used two performance metrics 
   acc  accuracy defined as     misclassification error and    auc  area under the receiver operating
characteristic  roc  curve  the roc curve measure
the true positive rate against the false positive rate at
various threshold settings  a steep slope in the beginning

fiindicates good predictive performance   increasing the
threshold increases the true positive rate while introducing few false positives  when the curve flattens 
we observe the introduction of false positives as the
threshold increases  note that an auc value of    
refers to a random classifier that stratifies positive and
negative samples arbitrarily  in our models  we denote a
positive and negative label as nonsquiggle and squiggle 
respectively 
a  baseline model
we first applied unregularized  l  regularized  lasso  
and l  regularized  ridge  logistic regression using the
normalized     time series points  we achieved a baseline accuracy of       on the test set  with all three
models classifying the full dataset as nonsquiggle  and
in fact  the true negative rate is      and the false
positive rate is       for all three models  we can note
the auc of      denoting a random classifier  since our
dataset is unbalanced  with       squiggle and      
nonsquiggle  our accuracy begins relatively high despite
using a model that deems all input as nonsquiggle 
improvements in acc and auc metrics are in relation
to this baseline 
baseline results
logistic model
unregularized
lasso  l  
ridge  l  

train acc
     
     
     

train auc
     
   
   

test acc
     
     
     

test auc
     
   
   

series  and signal width extracted from the spectrogram 
and loss from the dynamic programming algorithm  we
applied   families of classifiers     logistic regression
using l   l   and no regularization     support vector machines  svm  using linear  radial  polynomial 
and sigmoid kernels     tree based methods including
boosting  bagging  and random forests  and    k nearest
neighbors  knn   using    folds cross validation on
the training set  we performed hyperparameter optimization on each classifier  we identified the optimal
parameters  shrinkage parameter  in lasso and ridge
logistic regression  kernel parameters and soft margin
parameter c for svms  number of trees in tree based
methods  number of neighbors considered k in knn 
we chose the parameter s  based on cross validation
misclassification rate using the one standard error rule 
favoring simpler models to reduce the potential for overfitting  for multi parameter classifiers  we performed a
grid search 
in aggregate  we achieved our highest acc of      
using the boosting tree based method  however  nearly
all tree based methods resulted in relatively low auc
metrics  thus  accounting for our unbalanced dataset  we
believe unregularized logistic regression is the optimal
classifier  boasting a test auc of        in fact  one
of the key properties of auc is that is it invariant to
class skew  meaning that an unbalanced dataset of    
positive labels will result in the same roc curve as a
dataset of     positive      negative labels 
final results

b  intermediate model
we improved our baseline model by transforming our
features space from the     time series points to the
   fft frequency samples  we then applied unregularized  l  regularized  lasso   and l  regularized  ridge 
logistic regression once more  achieving a significant
improvement in both acc and auc  unregularized
logistic regression produced the greatest auc while
ridge regression produced the greatest acc 

logistic model
unregularized logistic
lasso logistic  l  
ridge logistic  l  
svm linear
svm radial
svm polynomial
svm sigmoid
boosting     iterations 
bagging     trees 
random forests     trees 
  nn

train acc
     
     
     
     
     
     
     
    
    
    
     

train auc
     
     
     
     
     
     
     
    
     
     
n a

test acc
     
     
     
     
     
     
     
     
     
     
     

test auc
     
     
     
     
     
     
     
     
     
     
n a

intermediate results
d  feature significance
logistic model
unregularized
lasso  l  
ridge  l  

train acc
     
     
     

train auc
     
     
     

test acc
     
     
     

test auc
     
     
     

c  final model
in our final model  we incorporated all    features 
comprised of the    fft frequency samples  the  
parameters from the arima        model  the variance 
modulation  and hurst exponent of the     slice time

we identified the features that had notable predictive power in the logistic family of classifiers  for
unregularized logistic regression  we noted   variables
with a p value less than        loss  hurst exponent 
signal width  modulation  and the        parameters from the arima        model  for l  regularized
logistic regression  we noted that   variables boasted
nonzero coefficients  loss  signal width  modulation  and
arima             the p values are representative of

fifor each method  we plotted the average silhouette
score over all clusters while varying k from   to     we
observed that   clusters produced favorable silhouette
scores for the methods which utilized the euclidean
distance metric 

fig     the roc curve of the logistic family smooths
out at the top bend  resulting in a higher auc metric 
the roc curve of tree based methods is less smooth 

each features significance as a predictor for the response 
it should be noted  however  that correlated features
tend to reduce each others significance  as verified by
an analysis of variance  anova  test  we claim that
arima           and modulation are the two most
significant features  reducing the residual variance of
our logistic model the most  we can further verify
these results using forward or backward stepwise regression  choosing features iteratively based on adjusted
r squared or akaike information criterion  aic  

fig     significance features from the different models

fig     silhouette scores from different methods
the question naturally arises whether the four clusters
uncovered by each of the algorithms are in fact the same
four clusters  to determine this  we mapped the four
clusters to each other so as to maximize the proportion
of points that are in the same cluster across all three
methods  we have graphed the corresponding clusterings
below 

vi  clustering

fig     principal components visualizations for different clustering schemes

before clustering  we normalized all features to have
mean   and variance    then performed dimensionality
reduction using principal component analysis  pca  
projecting our    features into   principal component
vectors  capturing       of the variance  we hypothesized that the squiggles likely followed a continuous spectrum rather than occupying distinct subgroups 
thus  we sampled a variety of distance metrics including
euclidean  manhattan  and canberra distance  as well
as various clustering algorithms  namely k means and
several hierarchical algorithms including single  average 
complete  mcquitty  centroid  median  and ward linkage
clustering  we also applied divisive clustering  which
yielded unfavorable results and tended to place outlier
points in their own clusters 

with the mapping given above  the proportion of
points that appear in the same cluster in all three
instances is calculated to be          or           
we performed the same set of tests         times
on randomized gaussian n     i  noise  the average
value of the above proportion was        and only
           test runs produced a proportion higher than
       signifying a p value of around       with the null
hypothesis that the data was generated from gaussian
random noise  the high level of concordance between
the clusters generated signifies that the results we found
are robust to the exact method of clustering  below
are examples of squiggles sampled randomly from each
of the four clusters  of the points that were assigned
unanimously to a cluster  

a  methodology

fichi squared test significant results
characteristic
august
  am     am
  am      pm
   pm     pm
l polarization
r polarization

fig     the presence of   clusters may imply the
existence of   distinct sources  which may be further
investigated by the seti team 

fig     the results of k    ward hierarchical clustering
using euclidean distance on the pca squiggle set  we
then projected the clusters onto the first two linear
discriminant functions 

b  chi squared test insights
with potential subgroups identified  we assessed the
characteristics of each cluster using known temporal and
polarization characteristics  the analysis of k    ward
d  hierarchical clustering under euclidean distance
proved most promising  we ran a series of independent
chi squared tests to assess the dependency of temporal
 month    hour timeframe  and polarization variables
against membership in the clusters above  the table
lists characteristics that were shown to exhibit the most
significant dependency on cluster membership  in particular  we can note that nearly all members of the red
cluster  corresponding to squiggles with large variance
in frequency  were produced detected between   pm and
 pm  this dependency on the    hour earth cycle could
imply that the source is terrestrial  rather than external 
once denser clusters of squiggles are identified  we hope
to replicate similar chi squared analyses 

p value
    e   
    e   
    e   
    e   
    e   
    e   

vii  conclusions   future work
as discussed  our model is agnostic to absolute frequencies  we consider this to be a severe drawback 
especially in clustering  as unique signals from the same
source are likely to have similar frequencies 
although we were able to capture a wide range of
modulation speeds  our ability to do so was hampered
by our discretization algorithm  which assigned a single
value per time point  at higher modulation speeds 
the signal simply appears to be a jagged wideband
signal  simulation and image processing could be used
to turn modulation speed into a more tangible parameter 
instead of relying on the fast fourier transform  prior to
pushing our code to the setiquest repository  we will
also perform model selection to trim our predictors to
only the most indicative to decrease both computation
time and overfitting for real time classification 
if squiggles do in fact come from a wide array of
sources  the logical next step would be to continue
uncovering dense clusters of squiggles that come from
the same source on a predictable basis  seti recently
opened access to         unknown spectrogram signals 
we can apply our existing classifier to curate more
squiggles  thus providing a larger dataset to conduct
unsupervised learning 
viii  acknowledgments
our work on this project was also counted toward cs
     project in mining massive datasets  our advisor
was professor jeffrey ullman and our additional team
member for cs     was frank fan 
r eferences
    http   setiquest org wiki index php 
enhancement of algorithm to detect pulse 
signals       
    classification of communication signals and detection of unknown formats using artificial neural networks  alexander
iversen  nicholas k  taylor and keith e  brown       
    automatic recognition of features in spectrograms based on
some image analysis methods  aleksandar perovi   zoran orevi 
mira paskota   aleksandar takai   aleksandar jovanovi       
    https   github com jwang    seti timeseries 

fi