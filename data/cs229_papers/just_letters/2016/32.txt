humanities research recommendations via collaborative topic modeling
nitya mani and andy chen

abstract we present two novel applications of collaborative topic
modeling to the broad datasets of humanities research article recommendations  in the first  we present an adaptation of the semisupervised collaborative topic regression model to a situation in which
no user feedback by simulating users to develop a much better contentbased recommendation model  over     precision and relevant recall 
than several implemented in the status quo  including the recommendations platform implemented by escholarship  host to the international
journal of comparative psychology  in the second  we demonstrate how
differential weightings on algorithm parameters can be used to provide
relevant recommendations for humanities researchers based on sparse 
noisy  varied information and a small dataset 

tend to come with lower readership and citation count  and thus
any recommendation platform needs to be robust with respect to
relatively small amounts of implicit feedback  thus  the different
environments of humanities research are not necessarily optimally
modeled by either a purely content or filtering based model or the
same parameters and combinations effective for high volume article
sites or technical stem papers  finally  we will examine if a similar
model can be used to effectively simulate users to iteratively update
purely content based recommendation platforms 
ii  theoretical background

i  introduction
currently  academically motivated parties  whether for research 
industry purposes  or casual interest  have access to a wealth of
scholarly information to meet their information needs  in fact  in
the current age with thousands of articles and papers constantly
being published in hundreds of journals  most conducting research
have the opposite problem of having to sift through too much  often
not incredibly relevant information to find what they are looking for 
thus  automated recommendation platforms are becoming increasingly more relevant to uncovering helpful resources and potentially
interesting articles that cannot simply be found by following a trail
of citations or an unfocused keyword search 
current article recommendation platforms generally fall under
one of two umbrella categories  content based models     seek to
understand the content of an article and compare that to the content
of articles a user is interested when making recommendations 
filtering based models     seek to identify users similar to the
current user and thus make article predictions without ever modeling
the content of the article 
collaborative topic modeling is a class of recommendation
algorithms that combine topic modeling of articles with implicit
feedback from users  i e  information about users article preferences that is not based on an explicit ranking system  or explicit
evaluations of articles  however  the majority of such algorithms
currently in place tend to be heavily skewed in favor of one
model over another  collaborative topic modeling has been most
prominently used in news article recommendations that focus on
filtering and user similarity matrices  only modeling content for
broad keywords and for articles released within the hour  on the
other hand  scientific article recommendations tend to heavily rely
on topic modeling based on the content of the title and abstract 
given that these snippets tend to be filled with keywords that give
fairly accurate insight into the content of the article                
in this paper we seek to apply an adaptation of the collaborative
topic regression model to make recommendations for humanities
research and nonfiction writing based on a combination of implicit
network and user feedback and topic modeling  non scientific
academic publications and nonfiction writing have topics that can
be modeled somewhat effectively  but abstracts and titles tend to be
metaphorical in nature and less clustered around a small number
of technical terms and clear cut ideas  further  articles tend to
be concentrated around specific niches with respect to readership
and reader interest  on the other hand  such publications also

a  topic modeling via latent dirichlet allocation
latent dirichlet allocation  lda      is a generative probabilistic
model for text corpora and other collections of discrete data  unlike
other information retrieval schemes such as tf idf  the lda model
reveals aspects of interdocument statistical structure in the corpus 
each document is modeled as a mixture of topics  where each word
is assigned to one of those topics  here  each document represents
a bag of words i e  sentence structure does not play a role in the
model  more precisely  given m documents  suppose we have k
topics             k   each of which represents a distribution over a
fixed vocabulary v   this vocabulary should be free of non topicspecific stop words  such as pronouns or common verbs  given fixed
hyperparameters       the generative model is then as follows 
for each document wi in the corpus 
   choose the word length ni  poisson  
   assign a topic distribution i  dirichlet   over the k
topics 
   for each word wij  wi  
a  choose a topic zij  multinomial i   
b  choose the word wij  p wij  zij    which is the
multinomial probability conditioned on the topic zij  
the goal of this lda algorithm  given the value of the hyperparameter   is to maximize the likelihood of the corpus data with
respect to  and the i   to do so  we use the em algorithm to
learn the k topics             k and topic distributions             m  
note that our unsupervised technique is not a clustering technique
on topics  as each document can contain words in different topics 
note also that the probability of generating each
document is p  ni  p  wi  ni    so argmax  log p  wi    
argmax i  log p  ni  
 
log p  wi  ni   
 
argmax i log p  wi  ni    as ni is drawn from a poisson
distribution independent of  and i  
b  collaborative filtering via matrix factorization
collaborative filtering     to find recommendations for a certain
user involves looking at the preferences of other similar users 
suppose there are i users and j articles  if users i  and i  have
similar interests  then for each article j  collaborative filtering
can look at whether user i  recommends article j and use that
information to determine whether user i  should read article j 
matrix factorization for recommendations is a latent factor model 
in which manifest variables relate to latent  or nonobservable 

fivariables  in this scenario  we only observe the set of all rij   which
represents the rating that user i gives article j  notice that while a
high rating is unambiguous  a low value can symbolize one of two
situations 
 user i has read the article and does not recommend the article
to others 
 user i has never seen the article and thus cannot recommend
it 
therefore  the goal of the ctr method is to change zero entries
of the second type into predictions about whether user i would
recommend article j  this distinction is especially critical in light
of the fact that the majority of user document pairs would fall under
the latter  rather than former category 
we represent both users and items as latent k dimensional
vectors ui and vj   where k is significantly smaller than the number
of users or articles  we predict new ratings by computing 
rij   uti vj

   

the goal of the algorithm is to minimize the least squared error
over all user article pairs  if u    ui  ii   is the set of all user
vectors and v    vj  jj   is the set of all article vectors  then the
algorithm finds 

x
 rij  uti vj      u   ui       v   vj    
   
argmin
u v

i j

where u and v are regularization parameters 
we use probabilistic matrix factorization  pmf  to model the
generation of user and article vectors  as it scales linearly with the
number of observations and performs well with large  sparse data 
    the generative process for producing the user and article data
is as follows 
   for each user i              i  choose a latent user vector ui 
n      
u ik   
   for each article j              j  choose a latent article vector
vj  n      
v ik   
   for each user pair  i  j   assign a rating rij  n  uti vj   c 
ij   
where cij is the precision parameter 
the precision parameters cij measure the confidence of the rating
rij   as mentioned previously  a high rating rij unambiguously
represents a positive rating that user i gives to article j  therefore 
cij should be high in magnitude  however  a lower rating rij can
symbolize multiple scenarios  so cij should be lower in magnitude 
specifically  in our algorithm  the input data rij consists of only
binary values  so we assign  for hyperparameters    a   b 
 
a if rij    
cij  
b if rij    
 note  however  that each uti vj can be a decimal value   to find
the optimal values of u and v given a set of binary rij   we use
gradient coordinate ascent on each ui and vj to find u and v in
equation    we may then generate a set of rij   uti vj to use as
the prediction ratings 
ctr on its own  however  cannot make accurate recommendations for articles that few or no users have seen  therefore  we
must complement the ctr method with lda topic modeling in
our model 
iii  the regression model
collaborative topic regression      models users as having interests based on implicit article recommendations and models
documents with topic proportions j naively learned from latent

dirichlet allocation  thus ctr is as a regression model is able to
differentiate document topics that characterize content from those
that might characterize readership interest of a body of academics 
ctr uses an algorithm in the vein of expectation maximization to
indirectly learn the map estimates of the log likelihood function
of all the parameters being estimated u  v   given the initial
conditions on the lda and matrix factorization models 
matrix factorizations learns short feature vectors to represent
each user and document  and predicts the recommendation status of
the pair user i and document j as rij   uti vj   when incorporating
content modeling of the documents  we continue to predict uti vj  
but here vj   j   j   where j is the topic proportion learned
via lda and j is a latent error variable to offset j   the purely
content based proportion that enables the documents latent vector
to diverge from j   thus as more users rate an article  the prediction
becomes increasingly dependent on the recommendations of users
and less so on the lda model of the document proportions  the
ctr model has very strong similarities to collaborative filtering
as can be seen in the generative process that characterizes the
model and its assumptions about how these articles and feedback
are generated  assume that we begin with k topics derived from
an lda analysis of the documents       k  
   for each user i              i  choose a latent user vector ui 
n      
u ik   
   for each article j              j choose a latent article vector
vj  n     
v ik   
 j 
   for each document j  select word wn  mult  j    where
n

 j 

n  mult j  
   for the user document pair  i  j   assume the rating can be
modeled as rij  n  uti vj   c 
ij  
given this generative model  the expectation of rij is  similar to
collaborative filtering  e rij     uti vj   with the primary difference
in how we model the latent document vector  incorporating the
content based proportion  vj   j   j where j  n      
v ik   
thus  learning each of these parameters can be done by finding
a maximum a posteriori estimate of ui   vj   j   and rij   where he
can find the map estimates of u  v  r using coordinate ascent 
we compute the map estimates by maximizing the log likelihood
of the data  in particular the overall log likelihood of each of
u  v  r       j    minimizing the least squared error of our eventual
prediction with regularization 
ll u  v    j   r    u   v  
u
 
 
 

i
x

 

i  

j x
x
j  

  ui     

n

log

j
x

 
  vj 

j     

j  
k
x

 
 j 
k k w j 
n

k  

j
j
  xx

cij  rij  uti vj   
  i   j  

then  we can iteratively maximize this function using coordinate
ascent by setting the gradient of the log likelihood to   and
determining the the new optimal values for each user and document
latent vector ui and vj as 
ui     v diag cij    j  v t   u ik    v diag cij    j  ri
vj     u diag cij    i  u t   v ik     u diag cij    i  rj   v j  
here ri    rij   jj   and rj    rij   ii     for the moment  we
will fix j as the original lda proportions and treat the proportion

fivectors as constants 
iv  making recommendations
for the moment  we predict the expected rating rij   uti vj
where vj   j if there is no user information about document j 
we will eventually employ an algorithm in the style of     to rank
our recommendations 
v  empirical study  simulating
recommendations with escholarship
collaborative topic regression and similar models have been
studied in a wide variety of largely scientific contexts            
     as a mechanism by which to incorporate implicit and explicit
user feedback about documents into a recommendation system 
however  even in situations in which little or no user data has been
collected  collaborative topic regression and similar models can be
applied to iteratively update existing recommendations  here  we
reimagine the model in a novel context  one in which no real userfeedback is present  but where we can simulate users to improve
traditional content based recommendations  we consider by way
of example the international journal of comparative psychology 
hosted on the site escholarship with the journal issues  for each
journal article  the website provides a listing of approximately   
similar articles generated by a content modeling process that
selects other journal articles most similar in content keywords to
the one being viewed 
however  many of these recommendations are largely if not
completely irrelevant to the content of the article  thus  we sought
to improve these recommendations  by using ctr on a set of
simulated recommendations to iteratively update these similar
article recommendations  we simulated users by considering each
list of    similar articles corresponding to a particular article to
be recommendations of a user and then applying ctr on this
set of articles and user  note that we discard the article from
which we generated the simulated user  to arrive at a new list of
recommendations for this user  which hopefully present a better
set ranking of similar articles to the original article 
in order to test this  we gathered data from     users and     
articles from the international journal of comparative psychology 
each user had a total of    similar articles  from which we
isolated the odd numbered ones as user recommendations  this
gave a total of      user item observed pairs  experimentally  we
considered a variety of values for the model hyperparameters to
optimize precision and recall using a restricted grid search  settling
on k        u         v        a      b         some
example topics yielded have top words species patterns california
populations habitat  public policy states issues economic  and expression gene genetic function levels  some of the hyperparameter
search statistics for k are pictured below 
some sample data for hyperparameter configurations illustrates
more completely the relative performance and confidence of our
model in predicting training  witheld testing  and new articles in its
top recommendations 
as desired  the learning model predicted all of the userrecommended articles with high ratings  and      of the time
recommended the original article from which the user was created
with a rating at least      or in the top    recommendations
 note that we withheld these articles for testing purposes from
the training data set   additionally       of the time  the top
  withheld recommendations were recommended by the ctr
algorithm  overall  the recall on the relevant withheld and provided
recommendations was      as the data suggest  not all of withheld

fig     this graph shows the accuracy of model on the withheld testing
data for a variety of choices for the number of topics size of latent feature
vectors k  given the irrelevance of many of the articles recommmended by
the journal  selecting k       optimized the recall of relevant articles with
respect to the precision of the overall model  and was high enough to ensure
user provided recommendations were maintained with high confidence 

fig     this graph shows the model accuracy on the training data with
respect to the number of topics size of feature vectors k when conducting
the hyperparameter search  note that for the purposes of low computation
costs  parameters were treated as independent when conducting this search
and were sequentially optimized although a grid search would have likely
been more optimal 

articles were predicted  in part because the content based model
used by the international journal of comparative psychology often
made predictions irrelevant to the bulk of the other recommended
articles that were thus discarded  in this sense  our model performed
far better in recommending relevant articles 
to compute the precision quantitatively  we took a random
sample of    of the     users and classified each of the original
recommendations from the international journal of comparative
pyschology as    relevant  or   irrelevant  by hand  where only
articles clearly about a different subject entirely were marked as  
then  we saw that in aggregate  our model correctly recommended
 with a rating at least      or in the top    recommendations  over
    of the   articles  and less than    of the  articles  as a

fifig    
this graph shows the proportion of documents that received
predicted rating rij in the intervals depicted on the x axis for k      
where a higher rating corresponds to a prediction that user i is more likely
to like document j  the blue bars represent training data and the green bars
represent withheld user information  as the data suggest  the provided
recommendations received high scores  as they should given that a user has
expressed interest already  and many of the withheld documents  around
     occurred as a top    prediction for the article 

fig     this table shows the rankings of the provided article recommendations  where as illustrated irrelevant articles received lower rankings than
more relevant articles

fig     this table shows the rankings of the withheld articles  with np
indicating that the withheld article in question was not predicted as a similar
article of interest by our ctr algorithm  note that all of these withheld
articles with the possible exception of   that were not recommended were
classified as  or irrelevant to the user 

fig    
this graph shows the proportion of documents that received
predicted rating rij in the intervals depicted on the x axis for k  
    including new predictions of articles not originally predicted by the
comparative psychology journal model with the yellow bars  given the
sparseness of the training matrix and also the high confidence in predicting
original user recommendations  there are a large number of new articles
predicted  especially as the confidence decreases 

case study  consider user     created from the recommendations
generated for the article the development of juvenile typical
patterns of play fighting in juvenile rats does not depend on
peer peer play experience in the peri weaning period  below is
a table summarizing the results we obtained as far as the journal
recommendations  our model predicted   new articles not included
in this set  the highest rank of which  rank    was the original
article from which we drew the simulated user data  and which
included all   other articles scored as a    like altruism in animal
play and human ritual and how studies of wild and captive
dolphins contribute to our understanding of individual differences
and personality 
thus our final model was able to achieve around     precision
and relevant recall on the dataset  making it a far better article
recommendation platform than the existing content based platform

fig    
this table shows the rankings of the new recommendations
 within the top     provided by our recommendation platform that were
not present in the list of similar items generated by the ijcp content based
recommendation 

employed by the international journal of comparative psychology 
that recommended at least     irrelevant    articles for each of the
randomly sampled papers 
vi  empirical study  humanities research
with citeulike
after simulating user data  we implemented our algorithm on
user given ratings data  for this scenario  the user article interactions are much sparser and noisier than in the first scenario 
while the simulated users for escholarship each had at least ten
recommendations  the average number of recommendations in our

ficiteulike dataset is roughly      with most users recommending
fewer than   articles  in addition  users rarely recommended articles
that were all in the same topic 
we also expanded the diversity of our article corpus by not
limiting our articles to one journal  while the escholarship articles
primarily originated from international journal of comparative
psychology  our citeulike articles were found in journals ranging
from latin american research review to asian theatre journal 
some were even written in foreign languages  see more details
in the discussion section   these articles  compared to scientific
articles  collectively had fewer abstracts  these humanities abstracts
also tended to be less summary focused 
we collected all      of the user profiles whose declared research
areas lay in european  eastern  asian  african  american  or
australasian language or literature studies  of these      had at
least one article in her personal library  collectively  the set of users
had      articles  like in the previous empirical study  we withheld
half of our collected user article interactions  ratings  to reserve for
the test set  therefore  the training set of user article interactions
consisted of     instances of a user recommending an article 
as before  we used grid search to find the hyperparameter
values that maximized our precision and recall  for each set
of hyperparameters  we ran lda ctr on the training data and
produced recommendations for our set of users  for this study  the
hyperparameter values that optimized our precision and recall were
k       u         v        and cij            where cij    
when user ui recommended vj and cij        otherwise 
as previously mentioned  we hide half of the users ratings and
use them to evaluate our algorithms recall performance  to calculate
recall  for each user ui   we compute how many articles in the entire
dataset that user ui rated positively  both in the hidden and training
halves of the recommendation data  we then take an average of our
results  our algorithm then has a     recall rate  which means that
our algorithm predicts at least     of the hidden articles  note that
it is possible for our algorithm to choose to not recommend articles
associated with ui supplied in the training set   though the nominal
value is low  our algorithm performs relatively well compared to
other recommendation systems 
to consider our algorithms performance in the context of citeulikes current recommendations  we analyze our algorithms
accuracy only for users who have rated at least    articles  users
with accounts can only receive recommendations after adding at
least    articles to their libraries  we calculated precision in a
similar manner as in the previous empirical study  for each user
in a random sample  we classified the recommendations for which
the algorithm provided rating were above      for that user  we
then manually classified the recommendations as relevant     or
irrelevant     in a similar manner as in the previous experiment 
with this metric      of the algorithms recommendations fell into
the     category  giving us an     precision value 
vii  discussion
based on our analysis  we conclude that composing lda topic
modeling with collaborative filtering significantly improves the
existing recommendations from escholarships international journal of comparative psychology  for each psychology article  our
algorithm not only adds relevant similar articles  but also removes
irrelevant articles from the original set of given recommendations 
this means that our lda ctr algorithm can augment escholarships existing recommendation system  when we apply our ldactr model to the citeulike humanities articles database  given the

sparse and noisy user data  we achieve precision and recall results
that compare to those of previous recommendation algorithms 
an interesting observation was that the lda algorithm on the
citeulike data categorized words from foreign languages  besides
english  into their own topic  this phenomenon has a theoretical explanation  articles written in spanish  french  and italian
comprised a significant portion of the articles retrieved from the
citeulike database  and within these documents  foreign word
tokens appear together  therefore  to effectively assign topics to
foreign documents  we must employ a machine translation model
in the future 
for our other future progress  we are looking to implement our
algorithm in practice  we are in the process of communicating with
both escholarship and citeulike to inform them of our suggest
improvements to their recommendation algorithms  in terms of
improving our current model  we plan to employ the following
changes to our algorithm 
 accounting for documents with the same author as previous
recommendations  given a user ui and document vj   we set a
different document vk with the same author as vj to have cik  
     implementing this change would allow the algorithm to
have less sparse data concerning users who do not rate many
articles 
 extending the lda to run on introductions rather than only
abstracts  as many humanities articles lack legitimate abstracts 
introductions would expand the dataset to include more articles 
 incorporating citation sources into the learning model  given a
user ui and document vj   we set a different document vk that
cites or is cited by vj to have cik       
acknowledgment
thank you to professor duchi for advice on the project and to
chong wang and david blei for sample data 
r eferences
    agarwal   d   and c hen   b  c  flda  matrix factorization through
latent dirichlet allocation  in proceedings of the third acm international conference on web search and data mining         acm 
pp        
    b lei   d  m   and l afferty  j  d  a correlated topic model of
science  the annals of applied statistics              
    b lei   d  m   n g   a   and j ordan   m  i  latent dirichlet allocation 
vol     acm  pp          
    b lei   d  m   n g   a  y   and j ordan   m  i  latent dirichlet
allocation  the journal of machine learning research              
     
    b ogers   t   and van den b osch   a  recommending scientific
articles using citeulike  in proceedings of the      acm conference
on recommender systems         acm  pp         
    h u   y   koren   y   and volinsky  c  collaborative filtering for
implicit feedback datasets  in data mining        icdm    eighth
ieee international conference on         ieee  pp         
    k eener   j  p  the perron frobenius theorem and the ranking of
football teams  siam review                    
    koren   y   b ell   r   and volinsky  c  matrix factorization
techniques for recommender systems  computer                 
    parra  s antander   d   and b rusilovsky  p  improving collaborative filtering in social tagging systems for the recommendation of
scientific articles  in web intelligence and intelligent agent technology
 wi iat        ieee wic acm international conference on        
vol     ieee  pp         
     wang   c   and b lei   d  m  collaborative topic modeling for
recommending scientific articles  in proceedings of the   th acm
sigkdd international conference on knowledge discovery and data
mining         acm  pp         

fi