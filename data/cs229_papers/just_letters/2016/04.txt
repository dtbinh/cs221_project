supervised learning to predict human driver merging
behavior
derek phillips  alexander lin
 djp    alin     stanford edu

june        

abstract

 

this paper uses the supervised learning techniques of linear regression and support vector
machines in an attempt to predict the merging
behavior of drivers on u s  highway     based
on current traffic patterns  using highway data
from the federal highway administration  the
paper approaches the problem from numerous
angles  eventually concluding that using a twostep approach achieves the best result  the first
step is to cluster the drivers based on driver history  and train separate models for each of the
clusters  this results in the best results in every
case 

our data is from the ngsim database and includes positional data for vehicles over a stretch
of highway     and i    we transformed the
data from the ngsim database to include directional velocity  and ultimately arranged it in grid
format to allow for a constant feature size to be
input into our models  for each grid entry  we
keep an average of the features of the vehicles
in that grid area  the grid has low resolution
to maintain a small feature set size  and we further cut down the feature set size by limiting the
window of interest to a subset of the highway
from when the merge begins to when it ends 
for each frame the vehicle is in  the input is the
current grid of traffic  with the merging vehicle
removed  and the time elapsed since the vehicle
first entered the area  the output will be either
the x or the y position of the merging vehicle 
in its raw form  we only have position and
x velocity and x acceleration  we decided to
augment our data to include velocity and acceleration on the y axis  since we are studying the
merging and positional behavior of vehicles  this
data is extremely valuable 
to streamline the runtime of our prediction algorithms  we precompute each of the data representations that we plan on using  we have created several models as described below  and plan

 

introduction

understanding human driver behavior is a critical component in the development of autonomous vehicles  in previous research  laneshifting and regular highway driving has been
well studied  but the analysis of merging behavior is sparse  we are developing a model for predicting merging behavior on highways given positional and trajectory information of the traffic 
the model predicts vertical position of a merging vehicle given the current traffic and time
elapsed 
 

data and processing

figrid square  we ran both svm and linear regression on this dataset  and the results are shown
below  although the overall scores   losses for
these baselines were relatively similar  the distribution of what contributed to the losses were
different 
generally  it appears that the performance of
the predictor based off of just the mean roadway
velocity is better at earlier timesteps  whereas
the predictor based off of vehicle location is able
to better fit the data at later timesteps  as we enhanced our data  our results would more closely
match the grid baseline 

figure    visualization of highway vehicles

 
   

linear regression vs  svm

as we developed our model  it quickly became
clear that svm regression was the superior of
the two techniques for our application 

figure    linreg baseline losses
on testing more to identify one with which we
can get successful results 
additionally  we built several visualization
tools to help us gain intuition about our dataset
as well as sanity check our work  a frame from
our visualization tool is shown   you can clearly
see congestion building up  as well as cars merging on and off of the roadway 

 

methods and techniques

   

tuning svm

one of the main characteristics of an svm is
the ability to tune the hyper parameters  the
penalty weight and the epsilon value  these alter the bias and variance of the model  so choosing the best parameters is crucial to producing
accurate results  using a subset of the data  various values were tested  including penalties centered at the default value of    maxing out at
        and bottoming out at       the epsilons
were tested between values of  e   and      all
pairs of possible combinations performed worse
than the default  penalties    epsilon       except for the pair with a penalty of     and epsilon of     which performed better in our scoring metrics  however  these results were too invariant to the different possible car trajectories 
thus  the default parameters were chosen for the
rest of the project  as they provided the best bal 

preliminary results and
baseline

we generated our baseline results using two
naive feature implementations  the first consisted simply of the mean velocity of vehicles on
the road at the time  our second baseline consisted of a simple grid  with no other information besides the number of vehicles within each
 

fiance of average accuracy and producing trajec        y velocity  y acceleration
tories that matched the shape of the test vehicles 
similar results arose from including the average
instantaneous velocity and acceleration in the y
direction  the hypothesized cause for these fail    mean centering data
ures is that adding more features made it harder
for the svm to find the correct weights 
seeing as how absolute data is not always as
useful as relative data  one attempted strategy       frame history
was to mean center the grids before creating the
model  this did not have any significant change another examined variation on the feature set
to accuracy of the models  linear regression and was giving the models   frame grids per trainsvm   and it took a fair amount of time longer  ing example  the frame from    time steps ago
so the rest of the project uses non mean centered as well as the current frame  the goal of this
approach was to give the model more infordata 
mation about the history of the traffic as supposed to only the current snapshot  doubling
the feature size unsurprisingly resulted in a sig    tuning features
nificantly longer runtime  with limited to no improvements to show for it 
the next logical step to examine variation in the
model such that the best possible model can be
produced is variation of the features  initially        vehicle initial position
the features were the grid of current traffic  the one feature that increased the accuracy of both
time elapsed since the merging vehicle entered models was including the initial position of the
the area  the grid itself is what was first exam  merging vehicle along with the current traffic
ined for improvement  the grid first contained and time elapsed  this helped because  not only
the number of vehicles in the grid  and the av  did it only add   feature to the training examerage instantaneous velocity and acceleration of ples  but it gave perspective to the model  as it is
those vehicles in the x direction  but there were possible for different merging vehicles to begin
many other features that could have been cho  in very different locations of the merge ramp 
sen 
table    results of feature tweaking
     

time and space headway

characteristics
svm      
svm          
svm     e   
mean centered
headway
vyay
frame history
inital position

the first of these features to be tested was headway  the motivation behind headway was that
not all of the vehicles are the same size  so it
might be more useful for the model to know how
much space is between cars than other features 
the results were disappointing  with the svm
model doing worse than without headway  and
linear regression doing marginally better 
 

svm score
    
   
    
    
      
      
    
    

linreg score
    
    
    
    
    
     
    
    

fitable    here  the default grid features in a particular are  vehicles  instantaneous velocity and
acceleration in x direction  the characteristics
are additional features as explained in the previous sections   score    and using sklearn score
for each model 

   

before the clustering began  the data was adjusted to be relative to the current traffic  what
this means is that there will be no bias of the data
where cars that travel in heavy congestion will
are more inclined to be aggressive because there
is less headway in front of them  all vehicles
were classified to give a broader data set than
just using the merging vehicles  after this meancentering was performed  we ran   clustering
on the data to output different classifications of
drivers  we separated our models based on these
clusters  and tested performance 
the results from this were fairly interesting 
the clusters were not evenly distributed  with
the vast majority of vehicles belonging to one
cluster  however  the performance on that cluster was much better than any other models  and
the performance on the other clusters was only
slightly worse than normal  however  linear regression performed terribly 

k means clustering to classifying driver behavior

up until this point the models have been predicting the trajectory given only information about
the current situation  additionally  the models tend to perform well on merging vehicles
that only merge one lane  but poorly on vehicles that move multiple lanes over immediately after merging  so the problem becomes 
how can the model better between cars that are
likely to merge numerous lanes and cars that
are not  without cheating it and telling it the future   the answer is with behavioral data for
the driver  based on the drivers historical information  for example  a historically aggressive
driver is more likely to merge into a small gap 
or to speed up to overtake a car in the lane that
it is trying to get to  along with being more inclined to traverse multiple lanes immediately after merging  however  ngsim does not historical data for the drivers  and how can the behavior be calculated in such a way as to be helpful
for the learning models 
the approach taken was to create clusters
based on the headway  acceleration  and velocity of the cars  the motivation behind this was
that an aggressive driver would keep less headway between them and the car in front of them 
and would have shaper acceleration and a higher
speed  to ensure that no unfair advantages were
used  the clustering data was taken from the portion of the highway after the merge  which still
provided about a quarter miles worth of data 
and positional data was not used  additionally 

table    clustering scores
model cluster   cluster  
cluster  
svm     
no examples     
linreg      
no examples      

   

reducing grid size

another method in which we attempted to improve our results was through varying the size of
our feature grid  we recognized that it was likely
that some grid positions  i e  the leftmost lanes
furthest from the merging vehicle  would have
little effect on predicting the merging vehicles
behavior  additionally  these increased features
could have led to overfitting of our model  reducing the size of our grid from   x   indices
to   x    and ignoring the top lanes decreased
our loss across all examples 
 

fithe entire dataset  however  this resulted in
worse performance over vehicles that merged
across several lanes right away 
we hypothesize that the result described
above can be attributed to several factors  the
first  simple explanation is that we could be
overfitting our data  however  we believe there
may be a deeper issue  in our training data  we
have approximately     vehicles per    minute
time period that merge onto the road  although
we break these down into hundreds of training
examples each  we were unable to get around
the fact that out of these approximately     vehicles  very few of them changed into multiple lanes  with the dataset used  we found it
difficult to identify features that directly correllated to whether or not a driver would merge
across multiple lanes consistently  even with kclustering of driver behavior 

figure    a well behaved  single lane merge

figure    example of multi lane merge

 
 

final results and analysis

future work

we have identified several viable methods which
we hope can produce better results in the future  running more tests on feature selection
and identifying the features that most strongly
correllate to multiple lane merges would likely
greatly improve results  much of the observed
losses were a result of our model being unable to
accurately predict the trajectory of a car merging
multiple lanes  so a good first step would be to
classify based on historical driving data  of the
specific driver  if the driver will merge multiple
lanes  and if so use a different model than for
merging only one lane 

our most successful models came from using
clustered models trained on the smaller grid size
    x      with each grid position having features for number of vehicles  x velocity and xacceleration  it is important to note that our predictions were trained and scored over the entire
time that a vehicle was present in the grid frame 
however  the grid frame for some merging vehicles extended over     time frames  so we are
tracking in total one minute of vehicle position
data  as one would expect  the losses at earlier
points
additionally  it seemed that throughout our
experiments with feature modification  the overall shape of our predictions were relatively similar between runs  for the vehicles that remained
within the first lane  this allowed us to achieve
incredibly high accuracy  with some examples
having average losses of below     feet across
 

fi