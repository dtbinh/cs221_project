cs     stats     spring      project report
sunet ids 
names 

jcingel stanford edu  puzon stanford edu
jarrod cingel  liezl puzon

predicting expedia hotel cluster groupings with user search
queries
abstract
in this paper  we aim to create the optimal hotel recommendations for expedia com customers that are searching for a hotel to
book  we will model this problem as a multiclass classification problem and build variations of classic support vector machines
 svms  and decision tree classifiers to predict the   most likely hotel groupings from which a user will book a hotel  we use
feature selection techniques to select optimal feature subsets  then build a unique combined svm and decision tree model that
achieves a higher precision and recall than either individual model alone  the combined model is derived using a scoring technique
that is based on the supplied evaluation criteria  mean average precision      

 

introduction

our project is based on the expedia hotel recommendations challenge on kaggle com  https   www kaggle com c 
expedia hotel recommendations   the goal of this project is to predict which of the     hotel clusters that a random
expedia visitor will book a hotel from  the high level application of this project is to allow expedia to provide the
optimal personalized hotel recommendations for the user based on a user search event  which will increase the number of
hotels booked through expedia and simultaneously increase user satisfaction in the product  however  since the problem
involves presenting optimal recommendations which the user is presented to choose from  this problem is not simply another
multiclass classification problem  we must instead predict five hotel clusters that the user is most likely to book  the
evaluation metric  mean average precision      evaluates each list of five predictions for each testing example  the map  
scoring formula is as follows 
 u   min   n 
  x x
m ap     
p  k 
 u   u  
k  

where u is the test set  n is the number of hotel clusters predicted by the algorithm  and p  k  is the precision in the
list of clusters at cutoff k  with this scoring system  we are awarded a higher score for the correct cluster being as close
to the front of the list of predictions as possible 

 

data

the given dataset includes a training dataset with about    million examples and an evaluation dataset of about     million
examples with hidden output hotel cluster  the    features shared by both the training set and evaluation set are listed
in the table on the following page  between each of the    individual features  we discovered no strong correlations  we
then used principal component analysis  pca  on the whole dataset  before appending the   principal components  and
discovered that     of the variance was accounted for by   principal components  as pictured below 

 

fifeature name
site name
posa continent
user location country
user location region
user location city
orig destination distance

is mobile
is package
channel
srch adults cnt
srch children cnt
srch rm cnt
srch destination id
srch destination type id
hotel continent
hotel country
hotel market

description
id of the expedia point of sale  i e  expedia com 
expedia co uk  expedia co jp      
id of continent associated with site name
the id of the country the customer is located
the id of the region the customer is located
the id of the city the customer is located
physical distance between a hotel and a customer at
the time of search  a null means the distance could
not be calculated
int
  when a user connected from a mobile device   
otherwise
  if the click booking was generated as a part of a
package  i e  combined with a flight     otherwise
id of a marketing channel
the number of adults specified in the hotel room
the number of  extra occupancy  children specified
in the hotel room
the number of hotel rooms specified in the search
id of the destination where the hotel search was performed
type of destination
hotel continent
hotel country
hotel market

   

data type
int
int
int
int
int
double

int
int
int
int
int
int
int
int
int
int
int

latent features

the destinations file contains     numerically encoded features  labeled        which describe each possible destination 
this makes intuitive explanation challenging because it is not given how these numbers were computed  or what the    
latent features mean  thus  we normalized the features then used principal component analysis  pca  and discovered
that     of the variance was accounted for by   principal components  the first three of these principal components were
appended to the whole dataset via a join operation on destination id to bring the total number of features to    

   

downsampling

we filter out all training examples where the user did not actually book the hotel cluster that they clicked on  we do this
because the actual evaluation dataset on kaggle contains only booking events 
we begin by selecting        different user ids out of about         unique user ids randomly from the training dataset 
we take all training instances from those user ids and discard the others  this is because in the evaluation dataset  user
events are preserved  and it would be irresponsible to arbitrarily discard certain events from the same user while keeping
others 

   

feature selection

to select the optimal subset of features for our models  we chose to use a wrapper method with forward search using
the average k fold cross validation score  this allows us to maximize our models prediction accuracy  we arrived at the
same optimal subset of features for svm and decision trees  these consisted of the last   elements in the table above 
srch destination id  srch destination type id  hotel continent  hotel country  and hotel market 
the fact that these   features were selected as the optimal subset is quite surprising  since these are all related to the
destination  though the removed user specific features   like number of rooms and length of stay   appear at first glance
to be the defining characteristics of any user recommendation platform  they are actually far less indicative of booking
outcome than destination specific features  it is likely that introducing these extra features produced lower k fold cross
validation scores because of the resulting increase in model complexity  furthermore  the principal components extracted
from the latent destination features provided no performance gain and also added to model complexity 

 

fi 

constructing a benchmark

the expected value of the map   evaluation score for an output list of five hotel clusters produced by random guessing is
one benchmark for evaluating our work  we calculate this benchmark as follows  suppose we were randomly selecting  
clusters for each testing example  at each position in our final   guesses  we get more points the closer to the front of our
guesses the correct cluster is  and   if it is not present  this means that our map   score for random guessing would be 
n

map  random  

 

  x x    p 
scorej
n i   j      p 

in the above  n represents the number testing examples  and scorej represents the score awarded for successfully guessing
the correct cluster in the jth position  note that the     comes from the fact that there are     possible hotel cluster
assignments  we get   points if the correct value is in the first position        if it is in the last position  and   otherwise 
so we can define scorej as follows 
scorej      j          j
substituting this into the above equation  we have 
n

map  random

 

 

x    p 
  x x    p 
  

j 
 
    j 
 
   p
n i   j      p 
 
j  

we solve the above for and we get map  random          

 

supervised learning

in order to generate improvement over map  random   we looked primarily to several different supervised learning techniques 
these include multinomial naive bayes  multiclass logistic regression  multiclass svm  and multiclass decision trees 
we were able to discard the first two models based strictly on their poor training set accuracies compared to the last two 
finally  a novel convolution of the last two models allowed us to achieve a fairly high score 

   

baseline model approaches

we first attempted to train a multinomial naive bayes classifier with laplace smoothing  with the feature subset we
selected  we achieve around    k fold cross validation accuracy  with multinomial logistic regression  we achieve a     
accuracy  multiclass adaboosted decision trees  multiclass gradient boosting  random forests all achieved a k fold cross
validation accuracy of around       although better than     the random guessing benchmark of selecting predictions
randomly of     possible hotel clusters  these models fall short of svm and decision trees  we omitted extending these
models to the case of   predictions per training example based on the fact that svm and decision trees increased our k fold
cross validation accuracy by threefold and fivefold  respectively 

   

multiclass svm

the multiclass svm is very time consuming  yet we hypothesized that given enough data  it can be a very accurate model 
to test our hypothesis  we trained an svm on a subset of the training data consisting of only one feature  the destination
ids  we use the downsampling method described in the downsampling section above  this initial baseline was able to
achieve an average of       training accuracy and an average k fold cross validation accuracy of about        which is
very good considering that many training instances contain the same destination id with different hotel cluster values 
the average k fold cross validation accuracy increased to       after using a subset consisting of the   optimal features
as described in the feature selection section 

   

decision trees

the decision tree classifier has the advantage of being extremely efficient  although one downside is that decision trees
are subject to overfitting  our precautions of selecting an optimal subset of features counterbalanced the negative aspects
of this model by reducing model complexity  furthermore  most other models we tried required downsampling before
performing k fold cross validation  however  this model can use the partitions of the entire dataset for cross validation
and still runs significantly faster than the others  using just the destination id feature  we achieved a training accuracy
of about       and an average cross validation score of        the average k fold cross validation accuracy increased to
      after using a subset consisting of the   optimal features as described in the feature selection section 

 

fi 

model modification and combination

once we decided which supervised learning methods to use  we needed to develop ways to    instead of classifying each
training example with a single output label  produce a list of   predictions ordered by certainty to match the required
submission format    combine their predictions to maximize the map  evaluation metric by using a novel convolution of
both classifiers 

   

classifier modification

first  we needed to modify both supervised learning tools to make   predictions  rather than    for the svm classifier  this
required a bit of intuition regarding the way the classifier works  the multiclass svm we used needed to classify among
    different possible cluster assignments  rather than using     traditional one vs rest classifiers  we elected to use     
one vs one classifiers  our intuition is as follows 
classifiers such that there exists a single
in order to make decide among n distinct classes  we need a total of n n  
 
classifier comparing each distinct i  j for every i  j  c  where c is the set of possible classes  once each classifier is
trained  every classifier is used to make a prediction for a given test example  we initialize a dictionary containing a key
for each possible class  every time one of the n n  
  binary classifiers decides in favor of a single class  the value for the key
corresponding to that class in the dictionary is incremented by    after all n n  
  classifiers have been tested  the dictionary
is sorted in non increasing order by value  and we retain the first   results in this list to use as predictions  the decision
tree classifier is inherently multiclass  so only slight modifications were required to return   predictions 
once this modification was done for each of the two supervised learning classifiers  we combined their outputs as follows 
first  assign normalized weights to each classifier  the idea here is to give higher weight to the classifier with the smallest
generalization error  assuming that its results are more likely to be correct than the results from the other classifier  we
can calculate this constant for classifier i as follows 
   erri
ci   p 
j       errj  
once we have the constant for each classifier  we need to find the highest scoring   clusters out of the possible    we
are given  we need to account for the fact that a cluster could be used twice  so we create a dictionary with    keys   
for each cluster  whose values are initialized to    we iterate through each item in the list returned by each classifier  and
update the clusters dictionary value with a score calculated as follows 
scorei    scorei   ci     ni  
in the above equation  ci is the weighting constant for the list from the respective classifier  and ni is the index of the
element in the list  from   to    inclusive 

once we have done this for each element  we sort the dictionary by value in non increasing order  and then take the  
elements with the highest values  thus  our list is complete 
     

accuracy on validation set

before submitting to the competition by running on the entire testing set  we generated statistics to evaluate our models
success  since the testing set does not provide the cluster values  we needed to do this using a validation subset we
generated earlier from the training data  we ran trials for all three of our methods  including svm  decision trees  and the
convolution of the two described above  for each trial  we plot two normalized confusion matrices below  the first defines
a classification as correct classification only when the true cluster value is the first value in the list  the second is more
lenient  and considers a classification correct if it appears in the list at all  here are the respective confusion matrices 
we can see that the optimal model convolution has higher average precision and recall than its two components  the
svm and the decision tree classifier  do alone  verifying this  the next step was to run our algorithm on the test dataset
and submit to kaggle 
     

submission results

after running our algorithm on the entire test dataset and then submitting  we achieved a highest score of         for
the map   evaluation  with the highest score on the leaderboard being slightly over      our results are quite good in
comparison to other submissions considering that those submissions took advantage of a data leak  whereby some of the
examples in the evaluation set were leaked into the training data without removing key identifying information about the
example  orig destination distance and user location city could be used to exactly identify duplicates in the evaluation and
training data  
 

fi 

next steps

in the future  with more time and computing power  we would like to apply other machine learning techniques  such as
neural networks  and compare them against our current combined model  we plan to remove the filtering and test this
method on the entire set of    million training examples  with such a large dataset  techniques like neural networks can
be very powerful 

 

works consulted

   https   www dataquest io blog kaggle tutorial 
   http   scikit learn org stable modules multiclass html
   https   web stanford edu  hastie papers samme pdf
   http   rob schapire net papers multiboost journal pdf
   https   www csie ntu edu tw  cjlin papers multisvm pdf
   http   dml cs byu edu  cgc docs atdm readings mlm overview pdf
   http   astro temple edu  tud      pdfs ijcai   pdf

 

fi