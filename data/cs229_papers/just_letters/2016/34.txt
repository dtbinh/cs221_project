predicting international restaurant success with yelp
angela kong    vivian nguyen    and catherina xu 

abstract in this project  we aim to identify the key features
people in different countries look for in their dining experience 
using the yelp dataset      we performed feature selection to
identify the business attributes that correspond to high star
ratings for each country  then  we classified the data using
models such as naive bayes  support vector machines  svm  
decision trees  logistic regression  and gaussian discriminant
analysis  gda  to evaluate the strength of the feature sets we
selected  we used univariate feature selection with a chi square
scoring function to choose the most important features  gda
was the best performing model  with test accuracies of around
    for binary classification  lastly  we used natural language
processing methods to identify the most informative features
from restaurant review texts  using these features  an accuracy
of around     was achieved for review classification 

seminal paper  yun  wu  and wang have explored using
part of speech  pos  analysis to predict a business rating
based off of user generated text alone  while they claim
that this representation cancels out subjectivity      users
reviews tend to be reactive instead of constructive  therefore 
while the accuracy of these sentiment based predictions are
high  they may not necessarily provide restaurant owners
with specific improvements to increase their chances of
success  in our project  we focus on not only modeling a
restaurants success through textual analysis of user reviews 
but analyzing which features are better predictors of success
among restaurants in different countries to provide datadriven predictions of international trends 

i  introduction

iii  data
we obtained our dataset from the yelp dataset challenge
webpage  which contains a total of        businesses     
million reviews by         users  and         business
attributes  because our project focuses only on predicting restaurant success  we filtered out all non restaurant
businesses  this left us with        restaurants from four
different countries  the united states  the united kingdom 
canada  and germany  the datasets for the businesses and
reviews are stored in two separate json files  with one object
per line 

yelp is one of the largest and most popular platforms for
crowd sourced reviews about local businesses  with over    
million monthly unique visitors and     million reviews to
date      a restaurants yelp page has become its first impression to customers  and strongly influences an individuals
dining decisions  consequently  success on the platform  in
the form of positive reviews and high star ratings  is coveted
by businesses worldwide 
the ability to identify business features that are most
indicative of success on yelp can help restaurants devise
sensible strategies to improve their own ratings  specifically 
we will explore how features gain and lose importance as
we vary geographical location by country  for example  are
americans more inclined toward a late night snack than
their german counterparts  do canadians value a take out
option more than those who live in the united kingdom 
through our work  we aim to bring to attention the various 
and sometimes non obvious  cultural nuances that impact the
dining experience  in the future  these methods can also be
utilized to determine how varying other attributes  restaurant
size  price range  etc instead of location  affect the critical
features chosen and overall classification performance 
ii  related work
as a modern  information rich dataset  the yelp dataset
has been a valuable resource for predicting a restaurants star
ratings and success  for example  gingerich and bochkov
have previously conducted similarity analysis on restaurants
based off of text analysis and word vectors      in another
  angela

kong 

computer

science 

stanford

university

science 

stanford

university

science 

stanford

university

akong  stanford edu
  vivian

nguyen 

computer

vnguyen  stanford edu
  catherina

xu 

computer

yuex stanford edu

a  format of business data
 
type  business 
   
name   business name  
neighborhoods    hood names   
city   city  
state   state  
latitude  latitude 
longitude  longitude 
stars   star rating  rounded to half stars  
categories    localized category names  
open  true   false  corresponds to closed  not
business hours  
hours   
   
  
attributes   
   
 
b  format of reviews
 
type  review 

fi   
stars   star rating  rounded to half stars  
text   review text  
date   date  formatted like             
votes    vote type    count   
 
iv  preprocessing   feature selection
we ran a python script to convert the json data into
a csv file  to prune the yelp dataset  which contains
   feature categories  we performed the following procedure  first  we removed features that are not relevant to
predicting restaurant success  such as business id and
business name  and features that pertain only to nonrestaurant businesses  such as type of hair specialization  additionally  we removed all features for which approximately
fewer than     of the restaurants did not have a value  for
example  while the majority of restaurants had information
about restaurant ambience  very few had information about
whether or not it accommodates halal dietary restrictions  we
narrowed down the feature categories to     some of which
include  attire  good for kids  noise level  outdoor seating 
price range  review count  has take out  and has wi fi 
a  preprocessing
we converted all categorical features  such as restaurant
attire  to numerical values  for instance  we represented
casual  dressy  and formal as       and    respectively 
for feature values that are true and false  we converted
the boolean values into their respective integer values  in
addition to the aforementioned     threshold we placed on
feature selection  we considered several different approaches 
including case deletion  regression imputation  and mean
imputation  to account for missing data      we decided
against case deletion because it discards any incomplete
data example  which significantly reduces the size of our
dataset  we also decided against regression imputation since
it requires the implementation of a model to predict missing
values and assumes a correlation among features  which we
cannot assume in the first step of our analysis 
therefore  we chose mean imputation  a widely accepted
method in the statistical community  to fill in our missing
data values      for each missing feature value  we averaged
the existing values for that feature and replaced the missing
value with the average  we use a variety of machine learning
models  including both generative and deterministic  therefore  to ensure consistency  we conducted mean imputation
for all of our classifiers  in addition  since we chose only
features for which at least     of the restaurants had values 
we avoided averaging over a small number of values  instead 
we averaged over the majority of the values for each feature
and filled in missing blanks with the overall trend for that
feature 
b  feature selection
we used univariate feature selection to identify which
twenty features were most important in predicting success 

for all the countries combined and for each country separately  we considered two different scoring functions that
return univariate p values in order to select the most important features  chi square and anova  because both our
features and classes  star ratings  are represented as discrete
values  we decided to use a chi square test  anova tests
are mainly used when the feature variables are discrete and
the classification variable is continuous 
v  models
we considered two different modes of restaurant classification based on star ratings  binary and multiclass  in the binary
case  restaurants with a star rating below     are classified
as    and restaurants with a star rating of     and above
are classified as    the machine learning models we used to
train and predict the data are naive bayes  logistic regression 
support vector machine  svm   decision tree  random forest 
and gaussian discriminant analysis  gda   in the multi class
case  restaurants are classified from   to   based on the
integer value their star rating  rounded   the models used are
multinomial logistic regression  decision tree  and random
forest 
for every prediction model  we trained and tested on the
data from all countries combined  and then on each countrys
data separately  in total  there are        restaurants  of
which we used        to train on and        to test on  we
only considered six cities in the u s  for which yelp had the
most data  instead of all of the cities  for each country  we
trained on approximately     of the restaurants and tested
on the remaining           training and      testing for
u s       training and     testing for the u k       training
and    testing for canada  and     training and     testing
for germany  furthermore  we conducted multiple iterations
of training and testing for each model with randomized
testing and training data each time  therefore  our results
are averaged using monte carlo cross validation    
a  naive bayes
we implemented the multinomial naive bayes classifier
with a laplace smoothing value of         using all of the
countries data  the test accuracy was          the results
for each separate country are included in the results section
of our paper  the test accuracy ranges from         for
the u k  to         for canada  the equations used are
included below 

fib  logistic regression
for logistic regression  our test accuracies varied depending on the strength of regularization  we implemented
logistic regression using scikit  where the inverse of regularization strength is represented by parameter c  increasing
or decreasing c by factors of    does not yield significant
differences in test accuracy  but we noticed that a higher
c value  less regularization   results in higher test accuracy 
conversely  in the multi class model  a higher c typically
results in lower test accuracy  overall  our multi class model
performed worse  as shown in the table below 
c

    
   
   
    
     

binary
test
accuracy
       
       
       
       
       

multiclass test
accuracy
       
       
       
       
       

c  support vector machine
to compare the results of different linear svm classifiers
graphically  we display the following  d projection of the
yelp data set  since we can only graph two features of
the data set  we select two features that are among the
most informative for a restaurants success across all four
countries  noise level and alcohol 
since noise level and alcohol are both discretized variables  with alcohol having three possible values  none  beer
and wine  and full bar  and noise level being quiet  average 
loud  or very loud  there are only    possible combinations
for a training example to possess  as seen below 

we see that both linear models have linear decision
boundaries  while the nonlinear kernel models have irregular
decision boundaries that are representative of the corresponding kernels and parameter values  however  there are slight
differences in the decision boundaries produced by svc with
linear kernel and linearsvc  which may be due to the fact
that svc minimizes the regular hinge loss  while linearsvc
minimizes the squared hinge loss 
svm classifiers
svc
linear svc
rbf kernel
polynomial
 degree    kernel

accuracy
     
     
     
     

we see that the rbf kernel produces the best results 
then  we experimented with tweaking the c and gamma
parameter values to see if we can achieve even better
accuracy 
c
    
   
   
   
     
     

gamma
   
   
   
     
   
   

accuracy
       
       
       
       
       
       

we conclude that the best svm classifier uses a rbf kernel
with parameters as gamma         and c       
d  decision tree and random forest

to consider how our svm model would perform on
variables that are not categorical  we chose to consider the
review count feature  which has a mean value of    and a
standard deviation of     

we implemented decision trees for both binary and multiclass classification  the decision tree is more complex and
is a generally more accurate model than decision stumps 
which are the simplest version of a decision tree      benefits
of decision trees include logarithmic growth in the cost of
predicting data as the number of data points increase  and
statistical validation of its reliability  however  decision trees
are very susceptible to minor changes in the data and tend to
overfit      therefore  we also implemented a random forest
that averages ten trees in order to better model and predict
the data  for binary classification and for all of the countries
combined  the decision tree test accuracy is          and the

firandom forest test accuracy is          for the multi class
classification for all the countries combined  the decision tree
test accuracy is          and the random forest test accuracy
is         
e  gaussian discriminant analysis
for binary classification  we implemented gda using
scikit  the test accuracy for the full dataset with all of the
countries is          the test accuracies for each of the countries is enumerated in the results section  the test accuracies
range from         for the u s  to     for canada  thus 
gda is generally the best performing model  explained in
more detail in the sections below   the formulas used for
this generative model are the following 

vi  analysis of text based reviews
apart from our core analysis of business features  we also
investigated the top review text features that were indicators
of restaurant success  the purpose of this section is to
identify important features that were not part of yelps official
set of business features  for example  slow is not in yelps
feature set  but may be mentioned many times in negative
reviews   we can then infer that customers place high value
on speed of service 
to preprocess the review data  we gathered all of the
reviews available for each of the four countries  a review
was labeled positive if the reviewer gave the restaurant  
or more stars  negative otherwise  the data was tokenized
using the the natural language toolkits  nltk  word
tokenizer  which split off white space and punctuation other
than periods  we chose not to convert all letters to lower case
because upper case often indicates strong emotion 
naive bayes is a generative supervised learning model that
is commonly used for text processing and sentiment analysis
tasks  and assumes independence between pairs of features 
we used the nltk naive bayes classifier to train and test
our data  and to identify the most informative features  this
classifier uses the same model as the multinomial naive
bayes classification discussed above 
we performed    fold cross validation to acquire the test
accuracies below 
country
canada
uk
us
germany

  train
    
     
      
   

  test
   
    
     
  

accuracy
          
          
          
         

this approach seemed to work best with medium to large
datasets  if there is too little data  the classification was made
based on random words that happened to appear more in
one type of review  thus  we decided to drop germany from
our analysis of informative features because its accuracy was
worse than random guessing       
the informativeness of a word is 
maxlabels p  word label 
minlabels p  word label 

the top    most informative features of us  uk  and
canadian reviews are outlined in the table below 

sentiment heavy words such as disgusting  unhappy 
worst  dominated all three lists  uk customers did not like
food that tasted like it was microwaved or lukewarm  though
reviewers often added a redeeming quality to a negative
review  softening the overall harshness of the review 

the strongest words for us customers were overwhelmingly more negative  with use of capitalization to emphasize
intense negative emotion  us customers seemed to crave
personal attention and focused strongly on a servers attitude 

we also tested three other models  a unigram model
with stemming  stop word removal  and a bigram model 
however  stemming lowered the    fold classification accuracy by around      for each country  removing stopwords  mysql stop word list  caused the accuracy to remain
about the same for each country   for example  canadas
accuracy was at         instead of          this is likely
because the stop word probabilities for each category are
very similar and did not have high impact on the class
decision  bigrams also had similar accuracies  though the

fimajority of the most informative bigrams were extensions of
the words on our unigram list  and less indicative of specific
business features   some examples include  tasteless  and  
 horrible  service  
vii  discussion and results
after running univariate feature selection with the chisquare scoring function  we selected the    most important
features for the us  uk  canada  and germany  ultimately 
our goal was to identify features  if any  that are considered
globally important indicators to a restaurants success  as
well as possible features specific to a particular countrys
idiosyncratic cultural values 
we found that there are   features that are highly weighted
in all four countries  availability of street parking  ability
to make reservations  review count  casual ambience  noise
level  and attire  other features corresponding to high star
rating include  outdoor seating  classy ambience  touristy
ambience  waiter service  hipster ambience  garage parking 
trendy ambience  wi fi  intimate ambience  good for kids 
good for groups  allows smoking  and has tv 
next  we examined features that are indicative of success
for restaurants situated in a specific country  we found that
the divey ambience was solely important for restaurants in
the united states  thereby demonstrating an american appreciation for lower end dining establishments  in addition  in
the north america region  customer satisfaction is positively
influenced by the existence of parking lots and parking valet
services  we speculated that parking is more important in
the u s  and canada due to a higher percentage of drivers 
whereas in europe  public transportation is more popular 
in europe  restaurant success is also positively correlated
with availability of alcohol  this is perhaps due to the lower
drinking age in europe than in the us  furthermore  by
analyzing the review text  we were able to infer  from the
most informative features  the tendency of americans to be
more vocal  negative  and service oriented in their reviews 
using the    most important features  we applied various
models to the data  the resulting test accuracies are summarized in the table below  for most countries  the gda model
outperforms the others  and the multi class decision tree
performs the worst  this is because gda assumes p xy  is
distributed according to a multivariate normal distribution  if
this assumption is correct  gda is asymptotically efficient 
which means that with large training sets  we dont expect
many models to be strictly better than gda      in general 
the binary models do better than the multi class models  as it
is more difficult to accurately classify with multiple possible
outcomes 

viii  future work
in the future  we plan to implement multiple imputation 
in general  this method better identifies data variability than
single imputation  but due to the time constraint  we reserve
these models  such as mixture of gaussians  for the future 
another way to make up for the missing values is to gather
more data  perhaps from a future yelp dataset challenge 
furthermore  we would like to improve our textual analysis accuracy through leveraging human annotated multilingual sentiment datasets online and exploring languageindependent textual analysis  especially for datasets where
the primary language is not english 
ix  references
    yelp dataset challenge  yelp  n p   n d  web    
june      https   www yelp com dataset challenge 
    an introduction to yelp metrics as of march
          yelp  n p   n d  web     may      
http   www yelp com factsheet 
    gingerich  travis  and yevhen bochkov  predicting
business ratings on yelp  stanford university       
    xu  yun  xinhui wu  and qinxia wang  sentiment
analysis of yelps ratings based on text reviews  stanford
university       
    missing problems in machine learning  marlin 
m  benjamin  graduate department of computer science
university of toronto       
    xu  qing song and yi zeng liang  monte carlo
cross validation  chemometrics and intelligent laboratory 
  july      
    burges  chris  from stumps to trees to forests 
cortana intelligence and ml blog team     sept       
web     june      
          decision trees        decision trees scikitlearn        documentation  n p   n d  web     june      
    ng  andrew  cs      generative learning algorithms  stanford university 

fi