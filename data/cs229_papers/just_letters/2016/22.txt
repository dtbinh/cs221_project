finding your way  courtesy of machine learning

chaitanya asawa
department of computer science
stanford university
palo alto  ca      
casawa stanford edu

marcus gomez
department of computer science
stanford university
palo alto  ca      
mvgomez stanford edu

viraj mehta
department of mathematics
stanford university
palo alto  ca      
virajm stanford edu

abstract
in this paper  we consider the multi label  multi class prediction problem in the context of classifying undergraduate education requirements at stanford university  namely  given a courses description  determining
what general education requirements it satisfies  given the extremely tough challenge of using a small dataset 
we opt to consider models and make modifications that are able to handle multiple classes and produce multiple labels with very limited training examples  we present a slightly modified version of naive bayes  an
application of boostexter  and several iterations of linear classification techniques  then  we explore the
performance of techniques from deep learning including rnn  lstm  and gru 

 

motivation

 

related work

to our knowledge  no group has worked on this problem
with this dataset  additionally  to date  multi label multiclass problems have not been extremely well researched due
to complexity  there are a few modern standards for said
problem class  schapire and singer developed boostexter
     an extension of adaboost  well studied boosting algorithm   elisseeff and weston developed a generalized version
of svms that minimizes a rank based loss instead of pair  background
wise binary losses      zhang and zhou developed a multifor undergraduates  stanford requires completion of a series label generalization of knn  dubbed ml knn  that identifies
of requirements known as ways of thinking ways of doing neighbors and chooses a label set using maximum a posteriori
 ways   undergraduates must take    courses across   dif   map  estimation     
ferent ways  these    courses are not fixed  and multiple
courses can fulfill a given way  a course can also fulfill mul    data
tiple ways 
our data will come from stanfords explorecourses  which
for a given course  provides both a full course description and
a list of way s  that it satisfies  we were granted access to
  problem
the problem we would like to explore is as follows  given this dataset 
we believe that there is a flaw in the undergraduate graduation requirements  if a student makes the interesting choice of
fulfilling his her formal reasoning ways requirement with
lie algebra  as of now  he she will not be able to graduate 
clearly  the ways requirements are currently not assigned
completely and or sufficiently 

a courses description  if we know that the course satisfies
at least one way  can we predict the way s  that it satis    generalizability
fies  this is a multi label  multi class problem as the multiple part of the motivation for studying the multi class  multi label
ways represent multiple classes  and the multiple ways a classification problem in this setting  using only a course decourse could satisfy represent multiple labels 
scription and not necessarily all other tags  was that we would
as the ways system has only been recently introduced  not be able to explore the problem in a generalizable manner that
all courses have been approved to or marked as satisfying a we could then use for other problems  in order to create a
way  we believe that this could be of interest as a tool for the more general multi class  multi label text classification modregistrar and may take steps to make it available to them as ule  we restrict our analysis to descriptions  using word frequency features only  later  we describe some potential impart of a maturing ways program 
provements from using dataset specific features as mentioned
in our particular case  this problem is extremely challenging in section     since we were interested in studying the multiin that we have very little data  our motivation is to help more class  multi label problem in general  adding hand engineered
data of this form be possible   and yet  we need to be able to features would decrease the portability of the models and espredict multiple classes and labels with limited training knowl  pecially the neural models attempt to gather that information
edge 
as a part of the process 
 

fi 

preliminary results

classification test  in addition  the two metric system allows us
to dig deeper into the methods that are inherently multi label
as opposed to those that use a combination of binary classifiers 
    baseline models
in our baseline  we decided to construct models which involve developing a binary classifier for every single way  this
would mean we have   classifiers  each indicating whether
or not a course satisfies a particular way  we would train
the classifiers individually  then  at test time  we would run
each classifier over a course description  and determine which
ways the course satisfies  we have constructed three such
sets of models 
      linear classifier
we constructed a standard linear model  using word frequency
counts from descriptions as features 

    data processing
we have collected the course descriptions and ways of      
courses from explorecourses 
out of these       courses  only      unique courses had
ways   when we say unique courses  we only took one
course from a set of courses with the same description  to avoid
biasing the data with duplicates  
these courses collectively satisfy      ways  meaning for
courses that do satisfy ways  they satisfy on average     
ways 
as the unlabeled courses could qualify for satisfying some
way  but are currently not marked as such  we have not included them in our data  and focused only on courses that do
have ways 

we were able to achieve        false negative metric on a
training set and        error on a dev test set  additionally  using the aforementioned hamming distance we achieved      
as our error 

then  we removed stop words  frequent words  as they typically do not provide any insight into the text due to their high
frequency and presence in every class  we also converted all
words to lowercase and removed all punctuation  to assure
that all words with the same stem but different suffix were
treated similarly  as they have the same intention for the most
part   we also stemmed our data  the data was not stemmed
for the deep learning models  in which we do not stem the
words since we are using word vectors as inputs  finally  we
tokenized the data  because our models work on the word level
at the moment 

to better understand our performance  we performed a finegrained analysis over how each way classifier was doing 
we found that some of the more stem oriented ways  such
as formal reasoning  fr   applied quantitative reasoning
 aqr   and scientific method analysis  sma   had better
performance than other ways 

we then performed a random       split of the formatted data
to constructed a training set and dev test set 
    error metrics
there are two error metrics that we have been using to gauge
our performance in a loss function independent manner between classifiers  we use the first metric only for baseline
methods  when we have multiple classifiers  the second metric  the hamming distance  is the metric we will use to ultimately evaluate all classifiers 
the first  the false negative metric  is a naive approach that
is useful for independent classifier methods but is too simple
for the multi label concept  we train an independent classifier
for each way  for each training example  there are   or more
way labels  for each given test label  we run the relevant classifier  if the classifier misclassifies the example  we increment
the error count  the metric is then given by
dn  

      naive bayes
      i word vec style subsampling
we constructed a naive bayes model from scratch  to account
for the small amount of training data and the skewed proportions of the positive and negative examples  we constructed an
analog of the negative subsampling method used by mikolov
et  al in their loss function for word vec      in particular  we
randomly sampled the negative training examples so that there
was an equal number of positive and negative examples in each
class when training  we performed this subsampling for a few
iterations  and then we averaged the parameters determined by
the naive bayes algorithm  though this is not a standard part
of the naive bayes procedure  and we could not find any literature examples of this being done to improve performance 
this gave us a significant improvement in both error categories
 on the order of      

number of misclassified labels
number of labels

the second metric is hamming distance  calculated as follows  take a training example x i    let a i  be the set of
true ways of the example and let b  i  be the set of labeled
 i 
ways by our classifier s   then the hamming distance dh is
computed as
 a i   b  i   
 i 
dh       i 
 
 a  b  i   

 i 
      ii results
the average of these dh over all training examples is our
we were able to achieve        false negative error on a trainoverall metric 
ing set  and        false negative error on a dev test set  usby using two metrics  we have a complete picture of the per  ing the hamming distance metric of error  we achieved an erformance of our classifiers on a single label and multi label ror of        this  in addition to the proceeding figure  seems

 

fito indicate we have a series of reasonably good single way help reduce model variance and improve overall performance 
classifiers  but their combined performance is not as well 
especially in the context of high vocabulary feature size  in
our case  v             thus  we used principal components
to better understand our performance  we performed a fine  analysis  pca  to reduce the number of features  as shown
grained analysis over how each way classifier was doing  we below  we explain most of the variance with around      feasee that way er and way ed perform exceptionally poorly  tures  or    th of the dataset
whereas all the other ways perform reasonably the same 

running feature reduction  however  did not yield significant
improvements in overall model efficacy  after the first    prin      support vector machines
cipal
components  for both hamming error and average perin addition to the baseline models  we leveraged the previous
baseline approach using support vector machines  svms       class testing error error plateaus and no additional components
yield large decreases in error 
in particular  we used a linear kernel of the form 
k xi   xj     xti xj
and a radial basis function kernel of the form
  xi  xj     
 
k xi   xj     exp 
   
for the linear kernel  we achieved a training error of       
and a test error of        error here is average hinge loss   for
the rbf kernel  we achieved a training error of       and a
test error of        the models we implemented here seem to
indicate that svms are a poor model for the multi class multilabel problem  as further  evidence  we show the roc curves
below  left is linear  right is rbf   the macro average roc
curve is generated by considering the average of the roc over
each class  the micro average curve is generated by considering all positives and negatives as a collective single set  note
importantly that for both the macro  and micro average roc
curves  the area under said curves is less than     and in the
micro average case  the curve is effectively linear  this is a
strong indicator that in general  the svms are not expected to
rank a randomly chosen positive and randomly chosen negative sample any differently  i e  the svm test is effectively
random worthless  

 

 

class independence assumption

in the onevsrest style models  we make the assumption that
the classes are all independent  however  this assumption may
not be true  and inter class dependence may yield important
interactions not accounted for by just the descriptions  in
particular  consider the correlation matrix of ways frequencies shown below  obtained using graphical lasso since the
dataset is fairly small 

dimensional reduction via principal
components analysis

work by robles et  al  indicates that both for general
text classification tasks and for specifically multi label textclassification tasks  dimensionality reduction techniques may
 

fia ii
aqr
ce
ed
er
fr
si
sma

a ii
   
      
      
     
     
      
      
      

aqr
     
   
      
      
      
     
      
     

ce
     
      
   
      
      
      
      
      

ed
     
      
      
   
      
      
     
      

er
     
      
      
      
   
      
      
      

fr
     
     
      
      
      
   
      
     

si
     
      
      
     
      
      
   
      

sma
     
     
      
      
      
     
      
   

note that there are clearly non trivial inter class correlations
 e g  si  social inquiry  and a ii  artistic and aesthetic inquiry  are anti correlated  sma  scientific method and analysis  and a ii are anti correlated  that simply do not get accounted for in the onevsrest models 

another feature we could have added was the old db  ec 
or ihum requirement labels  but we considered that this was
not a useful feature for future data  it also would make our
classifiers highly nonportable to other problems 

by using only descriptions for multi label  multi class classification  we focused on experimentation with models that
   boostexter
could hopefully apply generally  rather than hand engineering
we noticed the clear interclass correlations and nonlinearity of features 
features  suggesting we try something that can easily capture
these nonlinearities  boostexter is an extension of adaboost    neural sequential models
that is well suited to multi class multi label learning and text as our other models were working on the token level  they
classification      at a high level  boostexter swaps the de  were not able to necessarily capture the non linear interactions
cision stumps which return a binary value for a series of real  between words  to handle this  we experimented with neural
valued weak learners that allow for a ranked list of label like  sequential models  these models generally take a sequence
lihoods  in particular  we used a modified version of the icsi  of inputs and try to somehow capture properties about the seboost framework    
quential nature of the data 

a general recurrent neural network  where the bottom layer of
nodes are inputs  the middle layer are hidden states  and the
we found that boosting methods exhibit the standard behavior top layer are output states 
of overfitting on our dataset  it seems that we need more data
so that we can have better test performance  at the point where we experimented with   sequential models with keras     
the training and test errors diverge  we have a hamming loss of  rnn  recurrent neural network
      we believe that the other reason boosting doesnt per   lstm  long short term memory network
form well is that there isnt a way to encode prior knowledge  gru  gated recurrent network
of the terms in the text   as an example  kant is a term that
would immediately lead one to an ethical reasoning label  but
in all of these models we applied a relu layer followed by a
our software is unlikely to have learned such an association  
softmax layer on the last output of the sequential model  the
output vector of the softmax layer served as a probability distribution for each of the   possible ways  and we tuned a parameter that would determine some probability threshold for
   improvement with domain specific
whether or not a course deserved a particular way label  we
features
used binary cross entropy loss for our loss function 
although we restricted ourselves to word frequencies to create we used word vectors released by stanford that were created
a general use tool  for this particular dataset  there were some
using the glove method as inputs to our sequential models
features independent of raw text that could have some predic     
tive power  as an example  below we show result of adding the
course department as a feature in addition to the first    princi  for the   models experimented with  we plot their loss over
pal components in a linear classifier  similar results were seen time 
for other methods as well 
 

fi  

forward steps

we believe that our most limiting factor was the lack of data
available to us  we believe that with more examples available
 as they will be over time as the ways program matures   our
various methods will be able to increase their effectiveness 
beyond research  we also reached out to the registrar for their
potential interest in such a tool  as the ways program matures 
acknowledgments
it seems that a simple rnn did not change the loss over time  thank you explorecourses for giving access to course data 
one hypothesis for this is a vanishing gradient problem  as
described by bengio et  al       in particular  since the num  references
ber of inputs to the rnn is the number of words in a course
description  and in our data descriptions consist of    words     r  e  schapire and y  singer  boostexter  a boostingbased system for text categorization  in machine learnon average  the rnn consist of    hidden states 
ing  pp               
after seeing the superior performance of the gru  we focused
    a  elisseeff and j  weston  a kernel method for multion tuning the gru  one hyperparameter we tuned was the outlabelled classification  in in advances in neural inforput size of the gru  before applying the softmax layer 
mation processing systems     pp          mit press 
     
    m  l  zhang and z  h  zhou  ml knn  a lazy learning approach to multi label learning  pattern recogn  
vol      pp            july      
    t  mikolov  i  sutskever  k  chen  g  s  corrado 
and j  dean  distributed representations of words and
phrases and their compositionality  in advances in
neural information processing systems  pp           
     
we found that changing the output size  at small sizes  had
little effect on accuracy  we hypothesize that despite there being many inputs  the gru does not utilize too much information and hence does not have a much different accuracy with
higher dimensional embeddings  a high dimensional output 
however  seems to harm performance  potentially due to more
unnecessary parameters 

    f  pedregosa  g  varoquaux  a  gramfort  v  michel 
b  thirion  o  grisel  m  blondel  p  prettenhofer 
r  weiss  v  dubourg  j  vanderplas  a  passos  d  cournapeau  m  brucher  m  perrot  and e  duchesnay 
scikit learn  machine learning in python  journal of
machine learning research  vol      pp           
     

  

    p  j  m  zhang  min ling and v  robles  feature selection for multi label naive bayes classification  vol      
pp                 

conclusion

we compare the performance of all of our models 

    r  e  schapire and y  singer  boostexter  a boostingbased system for text categorization  machine learning 
vol      no     pp               
    b  favre  d  hakkani tur  and s  cuendet  icsiboost 
http   code google come p icsiboost 
     
    f  chollet  keras  https   github com 
fchollet keras       
     j  pennington  r  socher  and c  d  manning  glove 
global vectors for word representation   in emnlp 
we see that of all our classfiers  the best two were the linvol      pp                 
ear classifier and the gated recurrent network  the gru
performed slightly better than our linear classifier  while in      y  bengio  p  simard  and p  frasconi  learning longterm dependencies with gradient descent is difficult 
practice grus tend to typically have superior performance to
neural networks  ieee transactions on  vol     no    
linear classifiers  we believe the dearth of data prevented the
pp               
gru from learning its plethora of parameters well 

 

fi