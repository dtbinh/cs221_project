predicting perfume rate and popularity
yao li  yaoliphy stanford edu 

   introduction
the fragrance and perfume industry is experiencing a growth of approximately    to    annually
during      and        and the size of the global fragrance and perfume market is as large as
      billion in        the continuous growth and huge size of this market is due to the
worldwide popularity of perfume use  for example         u s  households use or buy perfume 
cologne  and toilet water in        in this work  we apply different machine learning  ml 
techniques to analyzing this huge market and explore the possibility of predicting the rate and
popularity of a perfume based on its various properties and features 
the ultimate goal of this work is to provide advice for both perfume buyers and manufactures  for
perfume buyers  this work is supposed to help them choose perfumes that will help them smell ontrend  high rate  high popularity  or unique  high rate  low popularity   for perfume manufactures 
we would like to provide advice regarding how to produce perfumes that will become next best
sellers 

figure    an example of input data

   dataset and features
get raw data and select features  datasets are obtained through web scraping of
www fragrantica com using python library beautifulsoup   www fragrantica com is a perfume
encyclopedia website  containing information of over        perfumes  figure   shows an
example of various information that can be found on this website for each perfume  the rate score
and the number of ratings and user reviews represent the rate and popularity of the perfume  the
website also displays user votes for longevity  sillage  the degree to which a perfumes scent
lingers in the air   day night  and seasons  besides  we can also find main accords and main notes
of a perfume  notes are descriptors of scents that can be sensed upon the application of a perfume 
and are very important and fundamental features of a perfume  in table    we list all input and
 
  

fitarget features selected in this work  the target features are rate and popularity  the input features
include season  day night  longevity  sillage  notes  and accords 

table    selected input and target features
filter data and preprocess non standard data  there is no meaning including extremely
unpopular perfumes in our dataset  therefore  we have removed these extremely unpopular
perfumes from our dataset by applying filtering criteria  the filtering criteria include that the rate
score cannot be none  user votes for season  day night  longevity  and sillage cannot be zero  and
main accords and notes cannot be none  after filtering         perfumes are left  to apply ml
techniques  we have also preprocessed non standard data  as shown in the last column of table   
first  the user votes for season  day night  longevity  and sillage have been converted to percentage
of the total votes  second  the notes and accords have been converted to indictor vectors  in the
dataset  a complete list of all perfume notes includes approximately     notes  and only the    
most common notes are selected to form a set of note tokens  the indicator vector of a perfumes
notes describes whether each token note appears in this perfume  this is similar to the spam
classification problem  in which we first choose a set of tokens and then find the indicator vector
for each message or email  the indicator vector of accords is computed similarly after choosing
the    most common accords among all    accords to form a token list  third  before applying
classification models  we have discretized the continuous valued target features  for example  the
perfumes with the     most ratings and user reviews are labeled as popular      the perfumes
with the     least ratings and user reviews are labeled as unpopular      the rest perfumes are
labeled as median     

   method
we first apply six different classification models to predicting both rate and popularity of a
perfume  because classifications models do not work very well for the rate prediction  we then
apply three different regression models to the prediction of rate  we have used the implementation
of these models in scikit learn  in python 
classification models  the first classifier we have tried is support vector machines  svm   we
choose the kernel to be gaussian radial basis function with parameter  
         exp      
 

 
 

 

  
  

fia small  means two vectors far away from each other will still influence each other  leading to
under fitting  a large  means that the support vector does not have widespread influence  leading
to high bias and low variance  namely over fitting  the second classifier we have applied is
boosting  gradient tree boosting has been chosen with decision stumps as weak learner  using
boosting  we have also compute the relative importance of different input features  the relative
importance of input features is computed based on the number of times a feature is selected for
splitting  weighted by squared improvement to the model  the third classifier we have tried is k
nearest neighbors  k nn   k nn works by finding k training samples closest in distance to the
new data point and then predicting the output from its k nearest neighbors  a very large value of k
would lead to slow simulation  and we stop at using k equivalent     we have also applied
decision tree  dts  classifier  a large value of maximum depth of the tree leads to high bias and
low variance  and vice versa  in addition to these four classifiers  we have also tried logistic
regression and nave bayes  nb  classification 
regression models  decision tree  dts  regression  linear regression  and boosting regression
have been applied to predicting rate  similar to dts classifier  the performance of dts regression
also depends on the maximum depth of the tree  for boosting regression  we use least squares loss
function and     boosting stages to perform 

figure    performance of different classifiers

   results and analysis
in figure    we plot the performance of different classifiers for both popularity  blue curves  and
rate  red curves   the solid curves are test errors and dashed curves are training errors  in figure
 a  we plot the error by svm as a function of the parameter   as shown in figure  a  a small
 

  

fivalue of  leads to under fitting and a large value leads to over fitting  after choosing an
optimized value of   svm predicts popularity with a test error of       and rate with an error of
       figure  b shows that boosting model leads to a smaller test error for popularity prediction
        and a test error of       for rate prediction  as shown in figure  c  when the number of
nearest neighbors is chosen to be     the test error is       for popularity prediction and      
for rate prediction  figure  d shows that dts classifier is easy to be over fitted if the maximum
depth of the tree is large  and it predicts popularity with a test error of       and rate with an error
of        comparison of these different classifiers has been plotted in figure    figure   also
includes the test errors of logistic regression and nave bayes  as shown in figure    the error of
popularity prediction is the smallest using boosting model  svm  knn  and dts can also predict
popularity with a small error of approximately      however  the error generated by logistic
regression and nave bayes is much larger  approximately      the error of nave bayes is large
because our features are not independent of each other given the class  therefore they do not
satisfy the nave bayes assumption 

figure    comparison of performance
of different classifiers

figure    performance of dts regression
for rate prediction

as shown in figure    for the prediction of rate  all these classifiers generate an error of
approximately      to achieve a smaller error  we have applied different regression models to
rate prediction  figure   shows the performance of dts regression  similar to dts classifier  a
large value of maximum depth of the tree will result in over fitting  as shown in figure    for rate
prediction  dts regression generates an error of approximately        we have also tried linear
regression and boosting regression  after parameter optimization  linear regression gives a test
error of       and boosting regression gives an error of       
through the comparison of different classification and regression models  we have shown that
classification models such as boosting work the best for the prediction of perfume popularity and
can give a test error as small as     and regression models work better for the prediction of
perfume rate and can lead to a test error of     

 

  

fifigure    relative importance of different input featuers
figure   shows the relative importance of different input features we have selected in our models 
the relative importance is computed using boosting algorithm  as shown in figure    season is the
most important input feature for both popularity and rate prediction  longevity and sillage are also
important for both  day night is less important  perfume notes are very important for the
prediction of rate  and less important when predicting popularity  main accords are the least
important feature for both 

   conclusions and future work
in summary  we have applied different ml techniques to predicting the rate and popularity of a
perfume using its various features  we have shown that some classification models such as
boosting can predict perfume popularity with a test error as small as    and regression models
can be applied to predicting perfume rate with a test error of      furthermore  we show that
some features such as season are more important than other features such as accords 
to continue this work  we would like to include the perfume ingredients as another input feature 
this will help our work provide guidance for perfume manufactures regarding how to produce a
popular perfume  finally  we want to interpreter our ml results and try to provide customized
advice  for example  we would like to predict the most popular perfumes for different seasons 
also  we would like to show what combination of perfume notes would have the highest rate 

references
   http   www futuremarketinsights com reports global fragrances market
   http   www statista com statistics       
   http   www statista com statistics       
   https   www crummy com software beautifulsoup bs  doc 
   scikit learn  machine learning in python  pedregosa et al   jmlr     pp                  
 

  

fi