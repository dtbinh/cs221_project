
 

recognizingemotionfromstaticimages
jasonchen cheson theodorachu theodora priyankasekhar psekhar 


i abstract

theeffectofsvmsandcnnsonemotiondetectioninstaticimagesareanalyzedinthispaper the
investigationintothesvmsincludedtestingvariousparametersandkernelsaswellasmakingmultiple
hypothesesconcerningproperfeaturevectors thatemotionsdependsimplyonthelocationsoffacial
landmarksandthatemotionsaredependentontherelationshipbetweenlandmarks theinvestigationinto
cnnsincludedparameterfinetuningandextractingthefinallayerasafeaturevectorforthesvm the
cnnfaroutperformedthesvmwitha     accuracy 


ii problemoverview

emotionsinformperceptionandaction humansaresocializedtolearnhowtoactandreactbasedon
theirunderstandingoftheemotionsofthosearoundthem becauseemotionrecognitionissoimportantto
everydaylife wewanttotrainanalgorithmforthistask highlyaccurateemotionrecognitionsystems
couldleadtoadvancesinpsychologyandsociology whichwouldleadtoanincreasedunderstandingof
decisionmakingandconsumerpreferences amongotherthings duringthecourseofourproject we
comparedtheperformanceofsvmsandcnnsonemotionclassification 


iii modelselection

weconsideredbothgenerativeanddeterministicmodelsforourwork whilesomerealworldscenarios
maybeaccuratelymodeledwithcertainemotionalprobabilitydistributions i e peoplearemorelikelyto
behappythanangryatsocialevents  datasetstendtocontainamoreequaldistributionofemotion 
becausewedeterminedthattherewasnoclearlydiscernableorevidentlymeaningfulaprioriprobability
distributionforgeneralemotiondetectioninacuratedsetofstaticimages wedecidedtofocusonmore
robustdiscriminativemodelsforthisproject 

wechosetouseansvmbecauseithastheabilitytocapturecomplexrelationshipsinbothregression
andclassificationproblems thesvmaccountsfornonlinearityinfeaturesandcanbetunedtobalance
biasandvarianceeffectively inpreviousresearchconductedonthistopic svmswerealsoshownto
provideabaselineforunderstandingwhatkindsoffeaturesarerelevanttothisproblem giventhewide
numberoffeaturepossibilitiesonagivenface thesvmwasbestsuitedtoourtask 

additionally wedecidedtoinvestigateconvolutionalneuralnetworks cnnshavebeenshowntodo
wellonimagerecognitiontasksandprovideversatilityinfeaturelearning andtheyareoftenconsidered
stateoftheartforimagelearningtasks 


fi
 

iii relatedwork

inimagebasedstaticfacialexpressionrecognitionwithmultipledeepnetworklearning yuand
zhangusedeepcnnstodeterminefacialemotions theirbaselinewasaround   accuracy andthey
wereabletooptimizethistohitabout   accuracy    however theircnnwasalsofinetunedtothe
datasettheywereworkingwith duetotheprocessingcomplexityofcnns trainingonthetrainingset
ratherthanusingapretrainedcnnwouldtakeontheorderofweekstorun otherattemptshavefocused
ontheescalationofemotionthroughvideoframes    findingthelocationsoffacialfeaturestoinform
changesinemotion    andusinghiddenmarkovmodelstocombinevideoandaudioinemotion
detection    theonethingmissingfromthisresearchisconsensusoverwhatfeaturesaremostrelevant
tothisproblem previousattemptsshowthatthereisalotofpotentialforusingcnnsonpureimage
emotiondetection however wewerecurioushowthiswouldcompareifweusedapretrainedcnn 
specifically wewantedtocomparecnnsandsvmsinordertogainabetterunderstandingofwhat
featuresareextractedandwhatfeaturesarerelevanttothisproblem 


iv methodology

weareusingtheextendedcohnkanadedataset adatasetspecificallyreleasedforthepurposeof
encouragingemotiondetectionresearch thefacesshowarangeof emotions       toextractrelevant
datafromtheseimages weusegooglescloudvisionapi whichhastheabilitytopinpointfacesand
facialfeatures includingtheirlocations italsohastheabilitytomakeemotionlabelprobability
estimateshowever forthesakeofselfdiscovery wehavechosennottousethisfunction 

figure  samplefromck dataset



foroursvm webeganbycroppingthepicturessothatallthefaceswereofthesamescaleandsize 
then wetookthegoogleapiandextractedthelocationsoffacialfeaturesandfaciallandmarks i e 
cornerofeye centerofmouth  usingthesefeatures wefoundthegeometricanglesbetweenthe
variousfacialfeatures theseanglesmadeupourfeaturevector wethentunedthecandgammavalues 
inadditiontotestingvarioustypesofkernels toensurerandomsamplingofdataandtomakesure
overfittingdidnotoccur weapplied foldcrossvalidationtoourdatasetintrainingandtesting 


fi
 

additionally imageswereclassifiedusingapretrainedcnn thefirstandsecondfullyconnectedlayers
ofthecaffeimagenetcnnwereextractedandusedasinputforthesvm 


v svm

toimplementthesvm weusedthepythonsklearntoolkitfortraining fitting andtesting sincewe
chosetoclassifyarangeof emotions weneededamulticlasssvm whichisprovidedbysklearnin
boththeonevsoneandonevsallvariations 

duringthetraining fitting andtestingprocesswefoundthattheonevsoneimplementationoften
performedbetterthanonevsrest whichisexpectedgivenauniqueclassifierisconstructedforeachpair
ofclasses normally theconcernforonevsonesvmsisexpensivecomputation butsinceourdatasets
ofimageswererelativelysmall onevsonetrainingwasabletorunquicklyenough tolocatethesvm
withthebestresults wereplicatedtheexperimentswithvariouskernels suchasthelinear rbf and
sigmoidkernels foreachofthesekernels wealsoperformedparametertuningbytryingtheexperiments
withcombinationsofcandgammavaluesacrosstheranges                   and             
     respectively 

forfeatureselection ournaiveimplementationforsvmusedthedirectnormalizedlandmarkcoordinates
receivedfromthegoogleapi whichmeantforeachimagethefeaturevectorconsistedof  tuplesof x 
y z coordinates eachrepresentedasafloat however wehypothesizedthatwhenhumansinterpret
facialfeatures theylookathowthefeaturesinteractwitheachothertodrawaconclusion wethenadded
moresophisticatedfeaturesbycalculatinganglesbetweeneachofthelandmarks whichwasdoneby
choosingthreecoordinates settingoneasthevertex andusingtheothertwotoformtheleftandright
legsoftheangle sincethisresultedinacomputationallyexpensiveprocessgivenallthepermutations
possible wehandpickedcertainfaciallandmarksthathadthepotentialtochangethemosttoincludein
ourfeaturevectors forexample theanglefrombottomliptoleftandrightmouthcornerswere
experimentallydeterminedsignificantwhilethetipofnoselandmarkwasremovedcompletely 


vi cnn

severalconvolutionalneuralnetworkshavebeentrainedonthegenericimagenetdataset thesemodels
areoptimizedforcoarselabels i e windoworcat  butthefinalconnectedlayersofthesenetsare
oftenfinetunedformorespecifictasksonnewdatasetswithdifferentlabels twodifferentcnnswere
usedinthisproject 

thecnnusedfordirectcomparisoninthisprojectwasthetransferlearningmodelsubmittedto    
emotionrecognitioninthewildcontestbyh winetal    thecascadingfinetuningresultedin     
intheemotiwvalidationsetand     intheemotiwtestset whilethisarchitecturedidnotwinthe
challenge itwaschosenduetoitsaccessibility easeofimplementation andrelevancetooursmall
dataset itwasusedoutoftheboxwithnofinetuning 


fi
 

thecnnusedforsvmfeatureextractionwasthecaffearchitecture pretrainedonimagenet   fc 
andfc ofthisnetworkwereusedasfeaturesinthesvmforourdataset incombinationswithour
manuallycraftedfeatures thiscnnwasalsofinetunedonourdatasetandusedtogeneratepredictions 
thesummaryoftheseresultsisreportedbelow  

figure  resultssummary


classificationaccuraciesseveralofthemodelsweresimilarandlowerthanexpected simplemodels
somewhatoutperformedmoresophisticatedonesonthisdataset thecombinationoffc featuresandour
manuallyselectedfeatureshadthehighestperformanceofthefeaturecombinations however the
finetunedcnnfaroutperformedothermethodsofemotionclassification correctlyclassifying     of
thetestset thesuperiorperformanceofthecnnalignswiththeresultsofpreviouswork 


vii interpretationofresults

oursvmdidnotperformaswellaswehoped muchofourdifficultywithobtainingperformancegains
stemmedfromthesmallsizeofourdataset therbfkerneltendedtodisproportionatelychoosethemost
commoncategory class  theemotionsurprise evenwithparametertuning limitingitsusefulnessin
practicalapplications thisbiasislikelybecausetherewasnotenoughdatatoallowformeaningful
separabilitygiventhecomplexityofourfeatureset becausesvmperformanceishighlydependenton
featuresets webelievethatthesvmcanbeoptimizedwithmoredirectedfeatures giventhatthesvm
runsolelyonfeaturesofanglesbetweenfaciallandmarksperformedbetterthanthepurelandmarks we
canhypothesizethatfeaturesthathelpanalgorithmbetterunderstandtheinteractionsbetweenfacial
landmarksarebetterhowever therearestillimprovementsthatcanbemade 

presently ourfeaturesfallonacontinuousrangeofvaluesyet thisleavesmuchofthediscretizationof
thedatatothealgorithm webelievethatusingafeaturesetofindicatorfunctions e g anindicatorfora
smileorforfurrowedeyebrows wouldboostsvmperformance astheplaneofseparabilitywould
theoreticallybecomemoreapparent 

whatisinterestingtonoteisthethefeaturesextractedfromthecnnseemedtocontributetosvm
performancegains despitethepretrainedcnnsrelativelypoorperformance themoregeneralized

fi
 

fullyconnectedlayersservedasusefulrepresentations thecombinationslightlyoutperformedboththe
pretrainedcnnandthesvm indicatingthattransferlearningwouldbeworthfurtherinvestigation 

therestrictionsofoursmalldatasetalsopreventedusfromattemptingtofullytrainacnnbecauseofthe
largesamplesizesthesemodelsrequire thelowperformanceoftheemotionrecognitioncnnfromthe
emotiwchallengeislikelyduetonuanceddifferencesbetweenourdataandthatdatausedfortraining 
futurestudieswouldseparatecolorpicturesfromblackandwhitepictures aswellasensureimagesize
andproportioncompatibilitytotheemotiwtrainingdatabeforeretestingthismodel theextremelyhigh
accuracyofthetunedcaffecnn pretrainedonimagenet islikelyduetosomelevelofoverfitting 
becausethedatasetissosmall theneuralnetislikelylearningfeaturesspecifictothisdatasetratherthan
featuresrelevanttoemotionrecognitionasawhole 


viii futurework

weplantoinvestigatehowfinetuningotheremotionspecificcnnsonourdatasetaffectsperformance 
alargerdatasetisessentialforthistask andthusfutureworkcantrainandtestonthisdatasetin
combinationwithdatasetssuchasjaffe furthermore finetuningacnnwithhigheraccuracyonthe
emotiwchallengesetscouldproducemoreusefulintermediatelayersforinputintothesvm 
additionally finetuningonlargerdatasetscouldalsodecreasetheeffectofoverfitting futurestudies
couldinvestigatecombinationsofdatasetstoaddtovariationintrainingandtestingdata 

lastly tofurtheroptimizethesvm wewouldimplementindicatorfunctionfeaturesaspreviously
mentioned relatedworkalsosuggeststhathistogramoforientedgradients hog featuresinsteadof
geometriconescouldleadtosignificantperformancegains    


references

   z yuandc zhang  imagebasedstaticfacialexpressionrecognitionwithmultipledeepnetworklearning        online  available 
http   research microsoft com pubs        icmi     chazhang pdf  accessed   jun      
   g littlewort m bartlett i fasel j susskindandj movellan  dynamicsoffacialexpressionextractedautomaticallyfromvideo  
computervisionandpatternrecognitionworkshop      cvprw        conferenceon pp           
   l luoh c huangandh liu  imageprocessingbasedemotionrecognition      internationalconferenceonsystemscienceand
engineering      
   p ngandl desilva  bimodalemotionrecognition        online  available 
https   www researchgate net profile liyanage de silva publication         bimodal emotion recognition links  deec  a e   f  f        
pdf  accessed   jun      
   kanade t  cohn j f   tian y        comprehensivedatabaseforfacialexpressionanalysis proceedingsofthefourthieee
internationalconferenceonautomaticfaceandgesturerecognition fg     grenoble france      
   lucey p  cohn j f  kanade t  saragih j  ambadar z   matthews i        theextendedcohnkanadedataset ck   acomplete
expressiondatasetforactionunitandemotionspecifiedexpression proceedingsofthethirdinternationalworkshoponcvprforhuman
communicativebehavioranalysis cvpr hb      sanfrancisco usa       
   
dee
ple
arningforemotionrecognitiononsmalldatasetsusingtransferlearning
 
proc   thacminternationalconferenceonmultimodalinteraction icmi  emotionrecognitioninthewildchallenge seattle wa nov 
         
   jia yangqing etal  caffe convolutionalarchitectureforfastfeatureembedding  proceedingsoftheacminternationalconferenceon
multimedia acm      
   
dahmane mohamed andjeanmeunier  emotionrecognitionusingdynamicgridbasedhogfeatures  
automaticface gesture
recognitionandworkshops fg          ieeeinternationalconferenceon
 ieee      

fi