demystifying the workings of lending club
bhatnagar pujun
    serra mall
stanford  ca      
pujun cs stanford edu

chow nick
    serra mall
stanford  ca      
nickchow stanford edu

abstract

 

lai max
    serra mall
stanford  ca      
maxlai stanford edu

introduction

lending club  as an online banking platform  is becoming increasingly popular ever since it started in
      by applying machine learning techniques  we
intend to investigate following questions 

lending club is the worlds largest peer topeer marketplace connecting borrowers and
investors  they claim to transform the banking system by operating at a lower cost than
a traditional bank and thereby making credit
more affordable and investing more rewarding 
over the last   years  the number of loans in
the marketplace has increased exponentially 
yet little is known about the algorithms that
determine if a loan is approved  and if it is  the
interest rate a loan is offered at  in this paper
we attempt to demystify the inner workings of
this marketplace by applying machine learning
techniques to lending clubs publicly available dataset 

 using supervised methods  can one predict if a
loan application would be approved 
 given that an application is approved  can we correctly predict the offered interest rate 
 has the standard of lending club approvals
changed over the years of            especially
after their initial public offering 
 can we extract a trend of how the significance of
various features has changed over the years  can
this information be used to game their online system to increase applications chance of approval 

using a basket of supervised learning techniques  we find that we can build highly accurate models  with an f measure of up to     
that predict if an application will be approved 
we also find that if a loan is approved  we can
determine the interest rate at which the loan
will be offered at  we provide an analysis of
the performance of different machine learning
models applied to our dataset 

 can we find some structure among this rich
dataset which can be used to generate artificial
data for our models  especially for the earlier years
of lending club 

 

data pre processing

the dataset  available at lending club website  is a
comprehensive dataset of all applications for peer topeer loans on the lending club platform between     
and       the data files are csv files which are split by
whether the loan is approved or denied  the following
is a plot of the lending club application statistics each
year 
note that the number of training examples grows
exponentially over the years as lending club has expanded rapidly  the amount of loan applications grew
from       in      to over   million in      
denied applications contain far fewer features than
approved applications  for the approval classification
problem  we maximize the available data by combining the features available in both the approved and denied applications  for the interest rate regression problem  we do not have to analyze the denied applications
and hence we can use all the features available in the
approved applications  hence  we decide to separate
pre processing for classification and regression 

with the models generated  we discover that
lending club has gradually relaxed its application loan approval criteria  we hypothesize
that this was due to the company preparing
for its initial public offering  which eventually
happened in       in addition  we find that
certain features  such as if the loan is a credit
card refinancing loan  are constantly predictive
of whether a loan is approved or denied  using this newly discovered insight  we suggest
some ways to game lending clubs system to
increase an applicants chances of approval 
finally  using effective clustering and visualization techniques  we uncover and exhibit
structure in this rich dataset  which can be exploited to artificially generate more examples 
specially for the years which only a limited
number of training examples are available 
 

fiest rate and loan quality are among some of the selected features  we continue processing the data as
highlighted in the previous sub section for each year 
we notice that many of the features  such as income 
have a right skew  therefore we log normalize the data
with mean   and variance   to ensure our algorithm
treats each feature equally  we run linear regression on
this data 

figure    number of applications received by lending
club per year
   

classification task  loan approval

to determine if the criteria for approval has changed
over the years  we first split up the datasets according
to the year the loan was issued  we use r and python
to pre process the data  all pre processing scripts used
can be found on our github repository 
before we start our analysis  we extract the common
subset of features from the approved and denied files
and combine the two datasets together for each year 
we also notice that in the approved dataset there are
only    unique values for the purpose of loan column  while in some years of the denied dataset there
are over        unique values  however  we observe
that the top     unique values for each year in the denied dataset represents over     of that years denied
loan applications  with the      data as an exception  
therefore  in hope of cleaning the data  for each year
we create a function that maps the top     unique values into the    unique values in the approved dataset 
we delete the last    of denied loan applications 

figure    regression task  processed lending club
data for     

 
   

   

regression task  interest rate

using our general intuition  we carefully select    out
of     features from the approved data  where about
half of the features are empty  loan amount  inter 

classification task

in order to find the model that works best  we apply
several machine learning algorithms onto our dataset
and compare their performances  for each year of data 
we independently run support vector machines     
logistic regression  boosting      random forest    
and artificial neural network      for a total of   
iterations  for fast training  we use java  python  and
weka      scikitlearn      we split the data into    
training set and     testing set 
   

figure    classification task  processed lending club
data for     

models

regression task

after successfully training a classifier that can predict if
a loan will be approved  next step is to predict the interest rate for the approved loans  for accomplishing this
task  we apply regression techniques after normalizing
data  in order to measure the accuracy of our model 
we decide to measure performance by using root mean
squared  rms  error because we want to heavily penalize the model for incorrectly predicting the interest
rate 
   

clustering task

hoping to find latent structure within the data  we use
unsupervised techniques to cluster the data  to investigate this  we remove the state and purpose of loan

fifeatures and cluster the normalized data using k means
     in order to visualize this data  we implement t sne
    using python  t distributed stochastic neighbor
embedding  t sne  is a  prize winning  technique for
dimensionality reduction that is particularly well suited
for the visualization of high dimensional datasets  we
use this approach to find if our resulting clusters indicate some latent trend within the data 

 

fiers 

figure    confusion matrices for year     

analysis

   

classification results

for each year of our data  we calculate the f measure
associated with the dataset using the confusion matrices  we use this as our primary measure of performance for each of the models because we notice that
evaluating model performance based on classification
error is potentially misleading  as only a small fraction of the applications         are successful in any
year  classifiers  such as ada boost for the      data 
can get a low classification error just by classifying every loan as denied  therefore  we use the f measure 
which is a combination of precision and recall  to evaluate our models performance 

figure    f measure values by algorithm and year
figure   is a visualization of how the machine learning models compare to each other over the years  overall  we find the random forest algorithm generally
produces the best predictions  with a f measure of
    in       but artificial neural network performs
equally well as the number of training examples increases over the years 
as we run the models on datasets with more examples  we expect the accuracy to trend upwards  we
believe the models accuracy for      in figure  
is higher than expected because of a variety of reasons  first  since this was the first year that lending club open sourced their data  their data isnt consistent  during the pre processing stage  we end up
dropping most of the examples  which we suspect ultimately leads to over simplification and enables us to
learn a simpler model that works quite well with the remaining      data  we also hypothesize that in      
lending club was using a simpler algorithm with limited features  which is easily estimated by our classi 

figure   shows confusion matrices for the classification results  during the analysis  we see that different
algorithms classify examples differently and therefore
we decide to look at the confusion matrices  in some
cases  like adaboost  the model classifies all examples are positive and doesnt do anything intelligent 
we identify these models and make sure to not use this
for future testing 
   

has loan quality changed 

we see convincing evidence that lending club has
gradually relaxed its loan approval standards  figure   shows a plot of debt to income  dti  for all approved loans in each year between            the
graph shows that lending club increased the maximum dti that it will accept on applications gradually
from     in      to     in       lending club also
relaxed the maximum loan amount that it will accept
from         in      to         in       as seen in
figure   
a possible explanation for a relaxation over the
years is that the management team wanted to generate
greater revenue growth and higher profits to prepare for
an eventual initial public offering  which happened in
       since a relaxation would result in the approval
of more loans  and since lending club charges a percentage fee on every loan that is funded on its platform 
increasing the maximum loan amount and dti would
result in higher profits and higher valuation of the company 

figure    debt to income of approved applications
         

fifigure    most significant features by year
figure    loan amounts of approved applications
         
   

has feature significance changed 

we notice that there are certain features that are constantly predictive of whether a loan is approved or denied  in figure    we plot some of the features that are
most indicative of approval and denial  this plot shows
the ranking of the resulting coefficients of the logistic
regression  the higher the value  the more predictive
the feature is of approval for that year  while the lower
the value  the more predictive the feature is of denial
for the year 
we notice that educational loans are likely to be denied  whilst credit card consolidation loans are likely
to be approved  this can be explained through economic intuition  education loans are likely to be denied
because seekers of these loans  students  are unlikely to
have a stable source of income and hence are likely to
have a higher chance of defaulting  on the other hand 
credit card refinancing applications are likely to be approved because people who want to refinance credit
card debt must already have a credit card  which itself
requires a stringent credit approval process 
renewable energy loans tell a particularly interesting story  in      and       renewable energy loans
were highly predictive of loan approval  however  this
predictiveness disappeared soon after and by      renewable energy loans were actually predictive of loan
denial  an explanation for this effect is that in      the
energy improvement and extension act was passed 
which provided tax credits to renewable energy initiatives  therefore the borrowers had  in effect  higher
disposable income and hence a higher probability of
paying back the loan compared to before  by      
many of these tax credits had been phased out  and
therefore lending club has reversed their algorithm to
account for this change 
an immediate takeaway from this analysis is that applicants should state that the purpose of the loan is for
credit card consolidation to maximize their chances of
approval 

   

regression results

we use regression to predict the interest rate for approved applications  after running linear regression 
we find that the rms errors are very low  less than
      in       because loan grade is included as a
feature  as loan grade is determined by an algorithm
within lending club  we decide to not use it and implement different data processing techniques on the remaining data 
we perform pca and run regression on the transformed data  we hope that by reducing the number of
dimensions  we would be able to counter noise present
in the data and account for less data  especially for the
earlier years  and consequently decrease the generalization error of our interest rate predictions  to determine
the number of principle components to include  we run
pca on the normalized data for each year  the results
are shown in figure    we notice that there is a noticeable kink in the data after   principal components 
which indicates that most of the variance is captured
by the first three eigenvectors  hence we decide to use
k     for pca 

figure    degree of variance captured by pca
figure    shows the rms error of our interest rate
predictions using different data processing techniques 
analyzing the results  we note the following insights 

fiare localized to different parts in the high dimensional
space  this proves that our hypothesis about some inherent structure in the data  also  using the found clusters  we can potentially generate even more examples 
which can in turn be used to improve our models performance  especially for the starting years where we
have limited data 

 

acknowledgments

we would like to thank dr  duchi and all     tas for
guiding us and consistently assisting us throughout the
project 
figure     regression results for interest rate 
 loan grade feature is a near perfect predictor of
the interest rate  this is not surprising  as lending club states that they determine the interest
rate based on the loan grade calculated for that
loan  we notice that we generally do not have perfect predictions on interest rates for different loan
grade  this is likely because loan rates for different loan grade will change over time  but the low
rms error shows that interest rates for a specified
loan grade do not vary drastically over a year  
 increased complexity of lending clubs system
over the years  even though there are more data
samples each passing year  our rms error has
steadily increased  in       our simple linear regression algorithm did a good job of predicting the
interest rate of a loan  with a rms error of      
using the same type of model  our      rms error is over       it also seems that their model
now uses more features  some of which may not
publicly available 
 low dimensionality of the approved data  taking the first    of over     principal components
generates decent predictions  we realize a rms
error that is about     greater than that of taking
all principal components  this shows most of the
important determinants of interest rate can be represented by the first three principal components 
   

references
   

   

   

   

   

clustering results

while trying to build models to predict the interest rate
and if a loan will be approved  we notice some structure in the data and hypothesize that we may be able
to find clusters that are highly indicative of interesting
trends  we decide to apply techniques from our unsupervised toolbox to find structures but quickly discover
that there isnt any intuitive way of visualizing the results of our experiments  after doing some research 
we find t sne as one of the ways to visualize our results  we discover the following interesting trends  as
seen in figure     we generate clear clusters when we
remove the purpose attribute and try clustering the examples  we observe that the results are sparse and

   

   

   

leo breiman  random forests  in  mach 
learn        oct         pp       issn            doi              a                 
url   http   dx doi org         a 
              
christopher j  c  burges  a tutorial on support vector machines for pattern recognition 
in  data min  knowl  discov       june       
pp          issn             doi          
a                  url  http       dx  
doi org         a               
mark hall et al  the weka data mining software  an update  in  sigkdd explor  newsl 
      nov         pp        issn            
doi                                  url 
http       doi   acm   org              
                
tapas kanungo et al  an efficient k means
clustering algorithm  analysis and implementation  in  ieee trans  pattern anal  mach  intell 
      july        pp          issn            
doi               tpami                  
url   http       dx   doi   org              
tpami              
xuchun li  lei wang  and eric sung  adaboost with svm based component classifiers 
in  eng  appl  artif  intell        aug        
pp          issn             doi          
j engappai              url  http 
  dx doi org         j engappai 
            
laurens van der maaten and geoffrey hinton 
visualizing data using t sne  in  the journal of machine learning research            
        p     
f  pedregosa et al  scikit learn  machine learning in python  in  journal of machine learning
research            pp           
o  postolache et al  the multisensor ann fusion method for accurate displacement measurement  in  buletinul institutului politehnic
din iasi xlv il  fasc  a  nov         pp     
    

fifigure     t sne visualization of found clusters

fi