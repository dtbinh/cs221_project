cs    project  building on existing bayesian learning for safe high
speed planning in partially observable environments
toby john buckley
i  i ntroduction
with improvements in sensing technology and computational power  robots capable of moving through an environment in real time are becoming more and more feasible 
one such example is an autonomous four wheeled vehicle
which obeys differential constraints  fig      the general
methodology for a robot  given a movement task  is to
sense its surroundings  compute a trajectory which will bring
it closer to the goal location  and begin to move  while
moving  the robot may re sense the environment and update
its algorithm to utilize this new information  an example
of this is shown in fig      where a car is traversing a
maze like environment  this is useful in multiple scenarios 
if there are moving objects  uncertainties in the sensors 
or an unknown map to traverse  the task would be near
impossible to complete without feedback  each of these cases
are exacerbated by high speeds and energetic dynamics  as
the planner may not have time to react properly to dangerous
behavior  as a result  safety constraints are maintained in
calculations for the planner to ensure collisions do not occur 
a typical constraint is to simulate actions into the future 
and confirm that at least one possible action does not result in
collision  if no such actions exist  the current state is called
an inevitable collision state  ics       further constraints
can be derived by considering the dynamics of objects in the
environment  as well as forcing the horizon to be arbitrarily
large     
in any case  in order to perform the simulation  assumptobyb stanford edu

fig     a car like vehicle  no slip is assumed  so differential
constraints must be obeyed which limit the vehicles movement abilities in the lateral direction 

 a 

 b 

 c 

 d 

 e 

 f 

fig     the path of a car as it moves through time in an
unknown environment  its knowledge of the environment
improves as it progresses  green is the executed path  magenta is the planned path given its current knowledge  pink
is the boundary into the unknown  and blue are the inferred
walls 

tions must be made about the unexplored state space  in
the most conservative approach  the robot treats any part
of the environment not already explored as an obstacle 
this approach maintains zero percent probability of collision
but has multiple drawbacks as well  for instance  a robot
rounding a hallway corner will slow down so that it can sense
the unexplored path as its turning  resulting in more time
taken  in the same scenario  a human knows from experience
that it is very unlikely a hallway dead ends and subsequently
will turn the corner sharply  if a path contains many sharp

fiturns the lost time can add up  resulting in much slower
completion time 
there are multiple methods to speed up the robot  the
first is to relax the safety constraints and approximate the
probability of collision in some manner  this  combined
with a penalty for collisions allows the robot to naturally
gauge whether an actions risk vs reward is worthwhile 
this method often requires hard coded behavior which can
be detrimental in scenarios differing from the algorithms
original intent 
another method is to maintain safety constraints but
encourage behavior that reduces the likelihood a robot finds
itself in an unfavorable scenario  with the same example as
previously  when taking a sharp corner at high speed a robot
can swing out wide in order to increase its vision around the
corner and give itself room to take evasive action if necessary 
if the hallway is clear  it will continue its turn without having
to accelerate back to full speed 
this paper uses the latter method as a baseline planner  and
compares it to the probability based planner which utilizes
bayesian inference 
ii  l iterature
there are many methods to tackling the problem of high
speed planning in partially observable environments  each
with their own strengths and weaknesses 
first off  it can be advantageous to recast this problem as
a pomdp  as many people have  and use this framework to
work in the belief space instead of the state space          
     with such a formulation  its possible to manipulate the
beliefs directly and take them into account when choosing
a next action  a large branch of the pomdp formulation
research is focused on relaxing the safety constraints outlined
previously and using methods such as machine learning or

fig     computing ics  the blue line depicts a candidate
action  with green and red showing valid and invalid emergency stopping maneuvers respectively  even though the grey
un seen space is obstacle free  the vehicle doesnt know that
from its initial position  so to be conservative  it assumes
such space is an obstacle 

fig     all possible quarter second actions for a car with a
max speed of    m s 

sampling of the belief space to estimate the probability of
collision     
one such method was recently proposed by charles
richter et  al  their planning algorithm utilizes machine
learning to estimate the probability of collision for a given
state      the collision probability depends on calculating
pre defined features of an observation  such as minimum
distance to nearest known obstacle or the final speed of an
action  and comparing it against the machine learned data 
while such algorithms obtain impressive results  it ultimately
only works in environments similar to those trained on  furthermore  there is an argument to be made that environments
are too high in dimensionality to be boiled down to a handful
of features 
while richters algorithm does reduce completion time 
there are areas to improve on  first  richter et  al  assume a
data set can be built by training in any environment and that
any differences in output are due to their features lacking the
subtlety to capture the difference  this may lead to irrational
behavior in the robot if two training environments happen
to share features but differ greatly in collision probability 
this method is also open to incorrectly identifying a novel
environment as one that has been trained in  for example 
results from richters simulation in a hallway forest hybrid
map using a prior and training data shows that even in
environments not trained in  forest   there are peaks in
the data density  implying in those time steps the planner
mistook the forest for a hallway environment  this problem
may be reduced by introducing more features such as largest
arc length of an obstacle projected on the horizon  or longest
straight edge of an obstacle
second  richters algorithm does not take into account
potential information gained from executing actions that
brings the robot close to the edge of unexplored territory  in
situations where data density is low  it would be beneficial to
return to areas of high data density  if the planner was choosing between two similar actions  one of which continued in

fid init k 
for k    to k do
randomly sample feasible configuration 
map  and action
calculate stopping maneuvers
if collision free then
y  i    
else
y  i    
end
  calcf eatures action 
d k    y  i     
end
algorithm    probability modeling

low data density region and the other with the potential to
observe a region of high data density  the latter action should
be chosen 
iii  p roposed s olution
charles richter uses four features to predict the probability
of crashing  they are as follows     minimum distance to
the nearest obstacle along the path     average distance to an
obstacle or horizon in a    angle in front of the robot along
the action     average free straight path directly in front of
the robot along the action  and    total speed at the end of
the action 
in order to test additional features and see how the results
change  i chose four additional features to test     ratio of
sensed new cells to total cells     ratio of walls to free space 
   total turn angle     number of obstacle cluster  calculated
using k means clustering  
training data  d  is generated by randomly sampling
a feasible configuration and action within a training map 
an observation is made from the configuration and the
features are calculated with respect to the chosen action 
next  emergency braking maneuvers are executed from the
end of the action for a variety of steering angles to see
if the vehicle is in an inevitable collision state  fig     
if any maneuvers successfully bring the vehicle to a stop
without collision  then yi is set to    otherwise yi     
the features and ics check results are placed in d and the
process repeats  algorithm   outlines this process 
in order to choose the next action  the cost of each feasible
action is calculated     and the minimum is chosen  fig     
shows an example of each action possible for a car  sans
obstacles   ja  at   denotes the time to execute action at  
h bt   at   denotes the heuristic cost to the goal for at given
the current belief bt   jc denotes the cost of collision  and fc
denotes the posterior probability of collision 

 
at  bt     argminat ja  at     h bt   at     jc  fc   bt   at   
   
posterior probability of collision is calculated according to
a non parametric bayesian inference model      this model
was developed by vega brown et al     

y  t rain  d
while not at goal do
cost init actions 
for a  actions do
  calcf eatures a 
k  calckernel   t rain  
    calcp suedop riors a 
fc  eq    f  y      k 
cost a   eq     a  fc  
end
a  argmin cost 
execute a
end
algorithm    bayesian learning

fc      p  y   collision   d   
pn
     i   k   i  yi
pn
          i   k   i  

   

where k   i   is the radial basis function  gaussian
kernel   the prior pseudo counts  and  act as a form a
laplace smoothing  where the counts are a function of the
features present for the given action  if action at results in
an inevitable collision state when assuming that all unknown
space is an obstacle  then  is set to a positive value 
otherwise it is zero  this ensures that when the vehicle enters

 a  maze

 b  forest

 c  hybrid

fig     maps used to train the machine learning planner 

fi a  baseline

to the goal  but once a corner is approached the baseline
planner must swing overly wide in order to maintain high
speed and meet the ics constraint  fig    shows how this
behavior truly reduces total time  as seen  the difference in
velocity between the ml planner and the baseline is almost
always positive  and in upwards of   m s in magnitude  by
maintaining higher speed for longer  the time to the goal is
significantly reduced 
in contrast  observe how the probabilistic planner cuts
the majority of the corners very closely  this is because
the machine learning data tells it that each corner has high
likelihood of continuing past the unknown boundary  so
it associates low risk with maintaining high speed while
moving through the region  presented in table i are the time

 b  machine learning

fig     simulation results for the maze map from the two
algorithms  color denotes speed of the vehicle where dark
blue is zero and red is high speed 

a region with little to no training data  the prior distribution
dominates and a similar safety constraint compared to the
baseline is used to guide the vehicle through the region 
algorithm   outlines this process 
the result of the action cost function is that when the
algorithm is very confident a collision will not occur due to
high training data density and a small number of recorded
collisions  then the robot will maintain high speed while
steering towards unknown regions of the map  the planner
assumes the space past the boundary will be open and that
no collision will occur  conversely  if the data shows that
actions with similar features crashed a majority of the time 
then the cost will drastically increase  making it unlikely the
planner will choose such an action  and will choose a safer
alternative 
iv  s imulation  e xperiments
in our simulation  the full dynamics of a car are used 
complete with applied force at the front axle to act as the
electric motor or braking system  the available controls
are steering angle and applied force  the original planner
was trained on a maze like environment  while the extended
planner was trained on all three types of maps  fig      a
total of      training points were generated  and a value of
jc       was used for the cost of collision  if an action is
an ics according to a conservative map estimate  then  is
set to    and   otherwise  and the same as richters paper 
    is set to   
now that the specifics of how the simulation was run are
taken care of  we can examine the results  fig      shows an
example of paths taken by the two algorithms for a mazelike map  note that the baseline is unnecessarily curvy  this is
from the cost function depending heavily on speed at the end
of the action  as a result  when traversing an open hallway
the planner goes close to the wall as this reduces distance

fig     difference in velocity between the ml planner and
baseline 
taken to complete three different maps  simulations were
ran with randomized starting locations within a bounding
start box  the original machine learning planner experiences
speedups in maps where it has some familiarity  maze  
hybrid  and is slower in the unknown environment  forest  
table ii show the percent reduction of the ml planners
compared to the baseline  the new machine learning planner
is also faster in the maze  but far slower on the other two
maps  overall the original ml planner beats the new ml
planner in each category  this is interesting since the new
planner has been trained on the new environments whereas
the original has not  i attribute the lack of speed up due to
the fact that the feature space has increased from four to
eight  but the number of training points stayed the same 
table i  time for completion of multiple maps  all results
in seconds 
maze

forest

hybrid

baseline

     

   

   

m l 

    

   

   

m l  new

    

    

    

fitable ii  percent reduction compared to baseline
maze

forest

hybrid

m l 

     

      

     

m l  new

     

      

     

this shows the limitations of selecting too many features
without generating enough training data 
it is also clear that machine learning is not right for all
environment types  in some cases  the baseline planner is
satisfactory 
v  c onclusions
i have shown two variations on a greedy path planning
algorithm which reduce time to the goal by up to      
compared to a baseline planner  this is because the baseline
is very conservative  maintaing hard coded safety constraints 
and naive  it simply tries to maximize velocity throughout the
course 
this speedup comes with considerable risk involved  of
the    trials ran with a collision cost of      only   
completed  if collision cost was increased or more training
data generated  the number of failed runs should decrease 
finally  i have also shown that selecting too many features
without properly generating enough training points can lead
to worst behavior than a naive baseline 
r eferences
    inevitable collision states  a step towards safer robots  
    a short paper about motion safety 
    high speed autonomous navigation of unknown environments using
learned probabilities of collision 
    intention aware online pomdp planning for autonomous driving in a
crowd 
    motion planning under uncertainty using iterative local optimization in
belief space 
    motion planning under uncertainty for robotic tasks with long time
horizons 
    c  richter et al  bayesian learning for safe high speed navigation in
unknown environments  in proc  isrr       
    vega brown et al  nonparametric bayesian inference on multivariate
exponential families 

fi