assigning style grade and providing style
feedback by k means clustering and softmax
regression
roman roman  homero
stanford university
homero stanford edu
          

 

abstract

cation model to assign a program
style grade 

while identifying functionality mistakes in a program can be done
introduction
with near certainty for a finite num   
ber of final requirements  identifying style mistakes is subject to developing good programming style is
subtle conventions and an infinite a vital part of the cs   a class and
number of possible programs  this to enforce this practice all assignments
poses a problem for students try  are graded not only on functionality
ing to get feedback on their pro  but also on style  but what exactly
gram style while they are still work  constitutes good style is not very clear 
ing on the assignment  also it as such  students who are just learnmakes it harder for teacher assis  ing about programming struggle to detants  tas  to agree on a cer  velop this good style  unlike functain style grade  therefore  the tionality which they can test themselves
goal of this research is to figure by running their program on their comout how to automatically assign a puter  style is not given feedback until
style grade to a program and pro  the program has been graded by the
vide style feedback  more specifi  ta by which time it is too late to fix 
cally  the procedures employed are  during the developing stage of the profirst  k means clustering of the data gram writing  the students program is
according to one of three different not necessarily functionally complete
strategies  then  from each clus  but we still wish to provide feedback
ter fitting a logistic regression or on the style and format of the parts alnaive bayes model for classifying ready written so that the student may
functions into those well decom  back trace if necessary and rethink his
posed and another for well for  current implementation  by providing
matted functions  and  finally  fit  both style and functionality feedback
ting a softmax multi class classifi  at every stage  the aim is to have the
 

fistudent improve both at the same time
rather than pushing style as an afterthought for the end and as a result
make bugs harder to debug 

 

hypothesis

since we want to classify into more than
one grade bucket a multi class classification model seems appropriate for the
situation  intuitively  the three most
important factors when considering
whether a program has good style are
whether it is well decomposed  well formatted and whether it works  but since
a single program may have several possible correct solutions it may be the
case that different combination of these
characteristics produce different style
grades for each solution  therefore  it
is of interest to explore whether running softmax only on those programs
that have an implementation similar to
the test program has more accuracy
than simply fitting softmax to all the
training data  and since we also want
to provide feedback for non working programs we explore the possibility of determining the features of the softmax
model by running logistic regression or
naive bayes on the functions alone to
decide whether each function is well
decomposed and well formatted and finally take an average for an entire program to determine whether the program is well decomposed and well formatted 

 
   

implementation
pre processing

first      programs were collected from
the karel midpoint finding assignment
from the cs   a class     of them
 

working programs     non working and
  from each grading bucket category
 plus  check plus  check  check minus 
minus   initially  the plan was to obtain hundreds of programs from professor chris piech but due to student privacy issues  he was only able to provide
a couple  as such  most of the programs were personally written making
sure to include all major possible solutions and collected from friends  then 
after obtaining the programs  the training programs were pre processed to obtain feature vectors describing each program and each function in each program  for the training data  the function vectors also contained a label on
whether it is well decomposed and well
formatted and the program vectors contained the actual grade of a program 
as for the testing data  no program
vectors were given 
then  for clustering    different
strategies were explored 

   
     

clustering
strategy    cluster by command counts

for this strategy  i parsed the     train
set programs into the basic command
primitives karel could understand   move   
putbeeper    pickbeeper    turnleft   
turnright    turnaround     and counted
how many of each were in the program 
then i ran k means to cluster them
in   dimensional space  below is a  d
cross section of the two dominant features move   and turnleft   

fifigure    move   vs turnleft    d
cross section for k    

figure    k means clustering for k    
     

strategy    cluster by running k means twice 

then for the third strategy  i tried something more clever  namely  to run kmeans twice  once to find the the average of the coordinates within a single
program and the second time to cluster
these averages into k clusters 
     

clustering results

clustering by counts of primitives is
very susceptible to unnecessary command calls  also it does not distinguish between call times  clustering
      strategy    cluster by pour  by pouring all coordinates may be susing all coordinates
ceptible to outlying programs that tend
for the second strategy  i kept track to spend too much time at a certain
of the coordinates karel was in dur  place  double k means overall seems to
ing each time step in a program  this address the issues above and can even
produced a set of  time  x coordinate  be implemented for variable times  howy coordinate  vectors for each program ever  it breaks down with infinite loops 
figure    coordinate clustering for
k  

and a set of vector sets for all     train
programs  then i proceeded to run kmeans by pouring all coordinates together 

   

logistic regression or naive
bayes for function classification

with the training programs clustered 
we proceed to fit a logistic regression or
a naive bayes model for all the function is each program cluster  for this
 

fi   

once we have decided whether each function is well decomposed and well formatted we take an average over all functions in the test program and test whether
the program is functionally correct to
come up with the program description
vector  program decomposed  program
well formatted  program works   then
we fit a softmax regression model for
each program cluster in the training
data where y   i               k   more
specifically  we do gradient descent on
the following cost function    including
a weight decay term to ensure the cost
function j   is convex for any     

figure    logistic function regression
we use collected properties of each function  for decomposition we use the following feature vector   is the function
between      lines   does it have appropriate line length  is there no repeating code    and for function format we use the following   does it have
correct indentation   is there no blank
lines   is it commented    shown above
is an example of logistic regression for
the functions in the train set 

   

softmax regression

t  i 
m k
k
n
e j x
 xx  
  xx
 i 
  y   j log pk

  
j       
lt x i 
m i   j  
  i   j   ij
l   e

and taking the gradient gives 
m

j j     

then plugging into the stochastic gradient descent rule we get 

feedback

j    j  j j  

after fitting the cluster functions from
our training data we can use them to
provide feedback to a student on his
functions as he is still working on the
program  all we need to do is take his
program and for each function decide
whether it is decomposed or not and
point to whether we found it to have
appropriate length and non repeating
code as for format we can report whether
we believe each function to be well formatted and point to whether it has correct indentation  no blank lines  and
comments 

 

for each value j           k
 
m   
where we set               m
number of train programs and k     
finally we use this model to assign a
bucket style grade to a test program 

 

t

 i 

e j x
  x  i 
 x    y  i    j  pk
   j
lt x i 
m i  
l   e

softmax results

the following table presents the accuracies obtained for each test set in each
bucket category  consisting of   programs each as noted earlier  

fiplain this polarizing behavior by realizing that when we ran logistic regression
on each function we only identified between well decomposed formatted or
not at all 

 

future work

a future possible fix would be to run
softmax on each function and take that
average  however  that approach would
be very susceptible to mal formed functions and would likely require to increase the size of the feature function
vector  also we worked strictly within
a karel world setting and as such it
figure    softmax regression with lo  would be interesting to see whether these
gistic and clustering for training data  results also hold for purely java programs 
bucket

softmax
with
logistic
and
clustering

softmax
with
logistic
without
clustering

softmax
with
naive
bayes
and
clustering
   
   

softmax
with
naive
bayes
without
clustering
   
   

plus
   
   
check
   
   
plus
check
   
   
   
   
check
   
   
   
   
minus
minus
   
   
   
   
as we can see from the table  clusterreferences
ing before hand seems to perform bet   
ter  also running logistic regression on
each function seems to have higher ac  references
curacy than logistic regression  this
can be easily explained if we consider     unsupervised
feature
learnthat the characteristics in the function
ing
and
deep
learning 
vector are not necessarily independent 
softmax regression http
 
however  while our softmax model per  uf ldl stanf ord edu wiki index php 
formed at     with logistic and clussof tmaxr egression
tering for the plus bucket  it performed
poorly for the check plus and check minus buckets  on retrospect  we can ex 

 

fi