characterizing united states presidential candidates speech patterns
kyana van houten and brendan corcoran
department of computer science  stanford university
 dated  june         
we seek to quantitatively characterize the speech patterns of leading candidates of the     
united states presidential election  we compiled full text transcripts of stump speeches  debates 
and interviews from the      election cycle  then  we determined appropriate features from the
raw text that meaningfully reflect both what a candidate speaks about and how a candidate speaks 
from these features  we created a model for the speech style of each candidate  comparing these
models gives insight into the differences between the candidates  it also allows us  given a new
speech transcript  to make a prediction of the most likely speaker among the candidates 

introduction

rhetoric is a crucial factor that citizens use to decide
which candidate they vote for  it affects how citizens
perceive candidates on both the conscious and subconscious level  therefore it is an important topic to research
and characterize  this is especially the case in the     
united states presidential election  as the candidates are
perceived to have particularly different styles of speaking  from trumps brash style to sanderss exasperated
tone  rather than relying on stereotypes and preconceptions  we hope to rigorously define these differences
by objectively characterizing the candidates speech patterns  furthermore  we can use these quantitative characterizations to actually predict  given a new speech transcript  which of the candidates is the most likely speaker 

literature review

for the reasons just described  politicians rhetoric has
been an active topic of research for several decades  one
study in sweden was able to classify politicians by gender 
political affiliation  and gender      using support vector
machines  svms  and a bag of words vector representation  the algorithm was able to achieve an accuracy rate
of       for age        for political affiliation  and      
for gender  this suggested that speech patterns varied
significantly between different groups 
another group was interested in studying the speech
patterns of japanese prime ministers      since svms do
not work as well in japanese  the group used a different
method  random forest classifiers  the method successfully identified speaker specific expressions and allowed
for objective investigation of political styles 
a third group at northwestern university examined
speeches given in united states senate      using svms 
the algorithm achieve prediction accuracy of     and determine that cultural rather than economic vocabulary
was more effective at differentiating liberals and conservatives 
meanwhile  a group from the american enterprise
institute utilized a bag of words technique to examine

the differences between the most frequently used words
by conservative and liberal      presidential candidates
during debates      they were able to use this technique
to measure how liberal or conservative a candidate and
see how this measure varied among the         debates 

dataset and features
gathering raw data

first  we needed to gather text data of candidates
speeches  from a number of online sources including  various news publications  the candidates respective campaign websites  and project vote smart  a nonpartisan database of information on candidates for public office               we collected       speeches for each
candidate  mostly stump speeches but also long form responses from debates and interviews 

feature selection

essentially  we want to reduce a whole speech into a
feature vector  one way to do this is with a bag of
words  that is  represent the speech with a vector the
length of the dictionary whose ith element is   if the
ith word in the dictionary appears in the speech and  
otherwise  this is a perfectly valid feature vector that
would likely make good predictions about which candidate gave a given speech  however  this representation
does not reveal anything meaningful about how it made
the prediction  that is  we would not be able to examine
the parameters and say something significant about the
candidates  the best we could do is to say that  for example  clinton is more likely to say this particular word
than trump  which in general is not very interesting 
instead  we want our features to be significant on their
own  for example  how much a candidate talks about the
economy or the average word length in a speech  if we
can reduce a speech to a small number of meaningful
features  and we still have a lot of predictive power  this
tells us much more than the bag of words approach 

fi 

what a candidate speaks about
how a candidate speaks
economy
ratio of first name last name
health care
ratio of female male pronouns
foreign threats
ratio of first person singular plural
trade
mean word length
manufacturing
mean sentence length
womens health
mean number of conjunctions per sentence
immigration
number of unique words
religion
constitution
table i  feature set

to that end  we divide our features into what a candidate talks about and how a candidate talks  in the
former category  we chose   policy topics that we believe
represent important issues as well as issues that differentiate the candidates  for each topic  we generated a
list of buzzwords relating to that topic  for example  the
list of words corresponding to economy includes economy economics middle class wall street banks mortgage
income financial  then  we go through each word in a
speech and if that word is a buzzword of a policy  that
policy is incremented  in the end  for each topic  we find
the frequency  per     words  with which a candidate
mentions a buzzword from that topics list 
for the other category  we seek to characterize how the
candidate speaks  regardless of what he or she is speaking about  this includes features such as mean sentence
length and frequency of using conjunctions  the complete set of features is listed in table i 

data representation

we treat a speech and its speaker as a single example  then  the x i   rk vector contains the real values
for each of the k features in table i for the ith training
example  ith speech  and y  i                   represents
which of the   candidates gave the speech  for example 
    
x  is the frequency of trade related terms in the   th
speech  essentially  we take a full text transcript and
boil it down to a vector in rk  

methods
algorithm selection

there are a few options when choosing an algorithm
for a multinomial classification problem  one is logistic
regression  or softmax regression   this method is robust in that it does not make very strong assumptions
about the data  however  since it is a discriminative algorithm  its parameters do not tell us what a clinton or
trump speech looks like on its own  but only a relative
probability between the two 
another option is gaussian discriminant analysis
 gda   this makes stronger assumptions about the data 
namely that the data is indeed gaussian  our feature set
contains features with distributions that are distinctly
gaussian  mean word length  number of unique words 
and some features whose distributions are more poisson
 frequency of policy buzzwords   however  we feel comfortable approximating every feature as a gaussian and
trusting that gda is robust enough to make good predictions  this proved to be true in practice  
another advantage of gda is that it tends to require
fewer training examples to learn well  one of our major
limitations is sheer number of speeches a candidate gives
as well as the availability of transcripts  as a result  we
managed to collect       speeches per candidate which is
not a very large training set  despite this  gda should
be able to generate good results 

generating parameters

following the gda strategy  we fit a k dimensional
gaussian to each of the candidates training data  to
do this  we must determine the mean vector    for each
candidate as well as one covariance matrix    that will

fi 
be used for all candidates  the parameters are determined by the following intuitive equations  where m is
the size of the training set 
pm
 i 
  j x i 
i     y
j   p
m
 i    j 
i     y

speeches into sets of     training and     test sets  we
shuffled and split our speeches    times to train and test
our models  averaging across these trials  we achieved
a training error of     and a test error of     both of
which are well below the expected error from random
guessing       

m
x
 
 x i   y i    x i   y i   t
i  

making a prediction

given a new speech  we want to predict which candidate is most likely to have given that speech  that is 
ypred   arg max p y x 
y

however  we only know p x y   namely the gaussian 
 
p x y   exp   x  y  t    x  y   
 
we can relate the two through bayes rule to get 

figure    comparison of the distributions of frequency with
which hillary clinton and bernie sanders speak about immigration and the economy  we see that sanders speaks more
about the economy and immigration than does clinton 

 
ypred   arg max exp   x  y  t    x  y   p y 
y
 
this is how the algorithm makes a prediction  intuitively  we find which candidates gaussian the new point
is most likely to lie on 
results and analysis

there are several results we wanted to obtain from
this study  the ability to predict which candidate was
most likely to have given a speech  the ability to compare meaningful statistics about the candidates speech 
and the ability to classify historical speeches to current
candidates 
predictive power

to make a prediction  we pre process the new speech
example as we do the training data to create a feature
vector  using this feature vector  we determine which
candidates gaussian the new example is most likely to
lie on then compare the result to the identity of the
known orator  figures   and   show examples of the
models constructed for the candidates in two different
feature spaces  in determining the accuracy with which
our method can predict which candidate was the orator
of a speech  we randomly shuffled and split our collected

figure    comparison of the distributions of mean word
length and mean sentence length in the speeches from hillary
clinton and donald trump we see that trump generally uses
slightly shorter words than clinton on average while trumps
sentences are significantly shorter than clintons on average 

comparing candidates

we also measured several interesting results about
each candidates speech patterns  for example  bernie

fi 
sanders spoke the most about the economy  ted cruz
spoke the most about religion  the constitution  and foreign threats  donald trump spoke the most about immigration and had the shortest mean sentence length 
trump tends to use first person singular tense significantly more than cruz  the two democrat candidates
tend to speak more about manufacturing than the republican candidates 
figure   allows us to compare all of the candidates
in terms of all of the features we chose  we can also
generate figures similar to figures   and   for any pair
of candidates with respect to any features of interest for
a more in depth comparison of the candidates 

figure    relative mean values for each candidate for each
feature

historical speeches

once we have tested our algorithm on speeches we
know to have come from the candidates  we thought
it would be interesting to feed the algorithm famous
speeches from historical figures to determine which of
the present day candidates would be most likely to give
the speech 
from this testing  we found that some of the speeches
our model attributed to ted cruz were barry goldwaters acceptance speech at the      republican national
convention as well as president reagans speech on the
evil empire 
among those predicted to be hillary clinton speeches
were john f  kennedys moon speech at rice and
obamas victory speech on the night of the      general
election 
however  interestingly enough  bill clintons speech at
the      democratic national convention was predicted
to be from bernie sanders 

conclusion

our project demonstrated the effectiveness of an alternative method to the commonly used bag of words for
characterizing speech patterns by representing speeches
only as a vector of feature values instead of much larger
word vectors  our method also provides us with much
richer characterization as opposed to just prediction capabilities 
in the future  we can add additional features that will
allow us to analyze speeches in more depth  we were
limited to features that were fairly simple to extract  but
with more background in natural language processing we
could expand our features to include measures of the sophistication of language used by candidates  i e  candidate   speaks at a  th grade comprehension level whereas
candidate   speaks at a university comprehension level 
which tells us how accessible a candidate may be to different demographics  we could also add features that
extract a candidates position on different issues rather
than just how often a candidate speaks about an issue 
this method has potential to substantially contribute
to the data driven aspect of politics and allow voters to
compare candidates in a quantitative manner 

    mats dahllof  automatic prediction of gender  political
affiliation  and age in swedish politicians from the wording
of their speechesa comparative study of classifiability 
literary and linguistic computing       
    takafumi suzuki  extracting speaker specific functional
expressions from political speeches using random forests
in order to investigate speakers political styles  journal
of the american society for information science and technology       
    bei yu daniel diermeier  jean francois godbout and stefan kaufmann  language and ideology in congress       
    weifeng zhong  the candidates in their own words  a
textual analysis of      presidential primary debates  aei
economic perspectives 
    the new york times 
    project vote smart 
    hillary clinton campaign website 

fi