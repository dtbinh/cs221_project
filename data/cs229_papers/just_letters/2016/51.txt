cs     final project  structure prediction of optical
functional devices with deep learning
kai zhang  shiyu liu  and qing wang

nomenclature
x
y
hl
m
n
p
r

the output electrical field  which is the input to the neural networks
the si structure  which is the output of the neural networks
number of neurons in in layer l
size of data sets
size of the si structure
number of layers in the neural networks
size of the discretized electrical field signal
   introduction

improving the efficiency of optical device is important in a variety of applications 
however  this process is typically done empirically  in this project  we formulate a systematically way to improve the efficiency of optical device design with machine learning 
the optical device we focus on is a silicon  si  nano structure  this device is constructed by a series of si nano cells  which is represented as the        binary series in
fig     in fig       and   indicate the existence and void of si at a particular location 
a beam of light perpendicular to the si structure is incident onto the si structure and
excites the surrounding electric field  in this project  we use the output electric field to
predict its corresponding si structure 
output electric field
 

 

 

 

 

 

 

 

 

 

si structure
incident light

figure    schematic of  d si structure with simulation procedure 
note that the projection from the input si structure to the output electrical field
follows the underlying physical law governed by the maxwells equations  which is a full
rank operation  the inversion of this problem is well defined  therefore  with appropriate
machine learning technique  we can predict the si structure based on the output electrical
field 
to address the non linear relation between the si structure and the output electrical
field  we use deep learning as our training algorithm  in the meanwhile  this approach
also allows us to reduce the dimensionality of the underlying physics  one the other hand 
although the si structure that is represented by an r n vector can take  n combinations 
a functional optical device almost always follows specific patterns and the number of
output labels in the neural networks is confined  therefore  by limiting our scope to
 

fi 

kai zhang  shiyu liu  and qing wang
input

hidden

hidden

output

layer

layer  

layer  

layer









f    w    b 
x 

r

z

   

f    w    b 
 

h 

z

   

fo   wo   bo
 

h 

y           n

figure    neural networks with   hidden layers 
si structures with physical functionalities  we can get a converged solution using finite
number of data sets 
the structure of this report is given as follows  a detailed interpretation of the neural
networks we use in this project is provided in section    section   describes the procedure
of the simulation and the preprocessing of the training data  the training results are
discussed in section   
   neural networks
in deep learning  the input data is processed through a neural networks that is constructed by a multiple layers of computational units  an example of a four layer neural
networks is shown in fig     this neural networks consists of one input layer  one output
layer and two hidden layers  data propagates from the input layer to the output layer by
going through transformation functions between each layer  the dimensions of hidden
layers determine the complexity of parameterization of the neural networks 
the propagation of data in the neural networks is characterized by a forward feeding
process  specifically  each layer takes a linear transformation of the data from previous
layer and process it using an activation function  at layer l  we can express the forwardfeeding process as 

   
z  l    fl wl z  l     bl   l           p  

where z l is the transformed data  wl and bl are the weights and bias respectively  and fl is
the activation function at layer l  in the first hidden layer  the input data z       x  which
is the input to the neural networks  for layers with size of hl   we have wl  rhl hl  and
bl  r hl   in addition  in this project  we use a rectified linear unit  relu  function as
the activation function at all layers  which is defined as 
   

fl  z    max    z   l           p  

where p is the total number of layers in the neural networks 
the network between the last hidden layer and the output layer gives the prediction to
the output data  because the output data is a vector of size n  we represent the prediction
function by a linear transformation  which is 
   

y   wo z  p    bo  

because the output vector in this project is binary  we obtain our predictions as 
 
    yj    
   
y j  
   yj    

fics     final project

 

the cost function of this neural networks is defined by a mean square error  mse 
function  which is 
m

   

  x  i 
j w  b  x  y   
ky  y  i  k    
m i  

because j w  b  x  y  is convex  the parameters can be trained by solving the following
problem 
   

min
wl  bl  l        p 

j w  b  x  y  

we solve this problem using stochastic gradient descent in a set of back propagation
steps 
the training and testing errors are defined by the following equation 
sp
m
ky  i   y  i  k  
i  
pm
 
   
train test  
 i   
i   ky k 
this error definition is used to characterize the convergence of the learning process at
each iteration  in addition  to quantify the accuracy in si structure prediction  we define
the prediction error as 
m pn
  x j     y j    yj  
   
prediction  
 
m i  
n
we use this error definition as a metric to the performance of the learning algorithm 
   problem setup and data acquisition
we obtain the data for learning from simulations of the optic electric interaction using
the rigorous coupled wave analysis  rcwa  software  in the simulations  the refraction
index of si is nsi       and the refraction index of vacuum is nvacuum      light with
wavelength      m is illuminated perpendicular to the si structure from the top  for
each si structure randomly generated by the rcwa software  the corresponding electric
field is recorded  figures   a  and   b  show an example of the si structure and the
magnitude of its output electric field  the si structure is represented by the dark red and
vacuum is represented by dark blue in fig    a   in fig    b   the electric field above the
si structure is activated by the reflected light and the electric field below the si structure
is activated by the transmitted light 
for the learning purpose  we collected        data sets from the simulations  we use
    of the data sets as the training set and the rest of the     as the test set  the
inputs of learning are the electric fields retrieved at two specific vertical locations  which
are represented by x   i   c      in the first case  the inputs are taken at the near field
that is     below the si structure  in the second case  the inputs are taken at the far
field that is    below the si struture  note that x  is complex because the electric field
signal contains both magnitude and phase information  to avoid the computations with
complex numbers  we treat the magnitude and phase of the inputs separately  therefore 
the inputs used in the learning process are represented by x i   r       the outputs of
learning are the binary vector of si structure  which is y  i          n   where n      is
used 

fi 

kai zhang  shiyu liu  and qing wang

 a 

 b 

figure     a   d si structure aligned along x direction at height z        
and  b  the corresponding output electric field given light normal incident
on si structures 
   training outcome and discussion
the training curve for the near field and far field learning are shown in figs    a 
and   b   in both cases  the results converges in about     iterations  the test error is
slightly greater than the training error  however  the errors for the near field learning 
which are       for training and       for testing  are more than two folds lower than
the errors for the far field training  which are       for training and       for testing 
the corresponding prediction error for the near field learning are      for training and
     for testing  and the prediction error for far field learning are       for training
and       for testing  the degradation in performance as the data collection location
moves away from the si structure is a consequence of the decay in optical intensity of
the transmitted light  information carried by the transmitted light dissipates as the light
travels  this indicates that the electric field in the near field provides a better metric
than in the far field to characterize the si structure 
  

  
training
testing

  
  

  
  

  
  

training
testing

  

error    

error    

  

 

   

   
iterations

 a 

   

   

  

 

   

   
iterations

   

   

 b 

figure    learning curve with two layer neural networks for   a  nearfield electric field training   b  far field electric field training 
to quantify the far field efficiency of the prediction  we pre define an output electric
field and apply the parameters obtained from the far field learning to predict its corresponding si structure  the comparison of the far field efficiency of the    transmitted
light between the predicted si structure and the optimal structure are shown in fig    
mispredictions in magnitude and phase of the electric field are observed in fig     the

fics     final project

 

efficiency associated with the predicted si structure is        to correct for potentially
misrepresented si cell in the predicted structure  we perform a local found method that
alters each element in the predicted si structure one at a time  with this approach  the
efficiency improves to        note that the maximum efficiency for all possible    cell si
structures is        this shows that the deep learning procedure provides us a reliable
method to predict the si structure for prescribed electric field 

figure    comparison of    deflected transmitted light electric field of
the predicted si structure and the ideal      efficiency electric field 
   conclusion
in this project  we implemented a two layer neural networks algorithm to study the
relation between optical si structures and the output electric fields  we trained two neural
networks using the near field and far field electric field data obtained from the rcwa
software  the size of the data sets used for learning is         in both setups  the results
converges in     iterations  the accuracy of prediction using the near field data reached
      and the accuracy using far field data is        with local found method  an
efficiency of       is achieved by the predicted si structure against the       maximum
possible efficiency for the    transmitted light  compared to the traditional opticaldevice design process  the deep learning approach significantly improves the effectiveness
of this process without considering the convoluted underlying physics 
to further improve the method  in our future research  we will test different cost
functions for training such that the binary nature of the si structure is better represented 
the depth of the neural networks and the dimension of parameters will also be adjusted
to optimize the results 

fi