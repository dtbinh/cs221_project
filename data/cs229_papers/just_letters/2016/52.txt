aspect based sentiment analysis on hotel reviews
yangyang yu
stanford university
yyu   stanford edu

abstract
in this project we explored varieties of supervised machine learning methods for the purpose of sentiment analysis on tripadvisor hotel reviews  we experimented and
explored with the factors that affect accuracy of the predictions to develop a satisfying review analyzer  we focus on
not only the overall opinions but also aspect based opinions
including service  rooms  location  value  cleanliness  sleep
quality and business service  as a result  we implemented
an analyzer that is able to predict rating and polarity of reviews on individual aspects  the accuracy of our predictors
reached     to     for star rating and about     to    
for polarity 

   introduction
nowadays  people frequently use reviews on online communities to learn about others opinions and to express their
own opinions on business  while a rating can be a good indicator for the opinion  text reviews are usually more elaborative  at the same time  reading text reviews is also timeconsuming  for this project  we propose using machine
learning algorithms to help extract opinions from text reviews  more specifically  we would like to build an algorithm that is able to differentiate individual aspects of the
review  being able to analysis the individual aspects is especially valuable since a business can vary in different aspects
and that users might have different preferences and priorities  the results of aspect based semantic analysis can be
used in a wide variety of applications  including building
better customized recommendation systems and generating
more informative summaries  we can also use the results as
features of the reviews for the purpose of further analysis 

groups of hotels  we use the star ratings as the ground truth
of the users sentiment for both learning guidelines and accuracy analysis guidelines  the review title and texts are
combined as the object of analysis 

   approaches
     feature extraction
we selected the bag of words model to represent our review texts  we experimented with several feature extraction
configurations 
we first experimented with the classic text analysis
pipeline  where after eliminating the stop words  the occurrence of each word in the review text is counted 
then the tf idf  term frequency times inverse documentfrequency  is calculated to put more emphasis on the less
common  thus more interesting words 
during our analysis of some preliminary results  we realized that due to the limited topic of reviews  the words
that express sentiments are actually very common across all
documents  as a result  the tf idf transform might not
be suitable for our application  so we experimented with
pipelines without the tf idf transformation 
we also explore the effect of using n grams  we experimented with both character based n gram and word based
n gram  character based n gram is supposed to help us reduce the effect of mis spelling while word based n gram
would provide us more information through phrases  the
extra information that is only carried by multi word phrases
includes the extend of an opinion  e g  very good  negations  e g  not good  and the aspect  e g  good service 
since using n gram drastically increased our feature size 
we also applied explicit max and mean document frequency
constraints to limit the number of features 

     model

   dataset collection
for this project  we will use the tripadvisor data set collected by wang et al     the data set consists of        
text reviews along with star ratings for the overall service
and seven individual aspects  the reviews are organized in

we experimented with two models for the problem  we
modeled it as a multi class classification problem and a regression problem  to model the problem as a multi class
classification problem  we consider the one to five star ratings as the five classes  to model the problem as a re 

figression problem  we consider the rating as a continuous
variable that can take the value from one to five  with
both methods  we treat each aspect as a separate problem 
one challenge is that aspect based classification inputs and
guidelines are quite noisy in some sense  since it is possible
for a user to leave a star rating for a certain aspect without
mentioning the aspect in the text  and even if they did  it
could be only a small portion of the text  one measurement
is to compare the accuracy of a predictor trained on the aspect star ratings with the accuracy of a predictor trained on
the overall star ratings  in this way  we will be able to see if
training on specific aspect guidelines is actually helpful for
the predictor to understand better 

     algorithms
we applied the multinomial naive bayes algorithm  the
linear svm algorithm and the linear regression algorithm
respectively 
preliminary results and observations discovered one issue with our training data  since people give a higher star
rating a lot more often than a lower star rating  our dataset is
very skewed  with about    one star ratings and about    
five star ratings  as a result  it is very important to balance
the input training data  we experimented with three popular methods to deal with unbalanced inputs  class weight 
sub sample and over sample 
the class weight method applies a weight to each class
based on the sample distribution  the class weight is calculated by the inverse of the number of class samples in the
dataset  the penalty of each sample is then weighted by the
class weight  as a result  a class with fewer samples in our
dataset will be emphasized more to compensate the fewer
number of samples 
the over sample method repeatedly sample the classes
with lower distribution in the dataset until the same sample
number is reached as the classes with higher distribution 
the sub sample method sub sample the classes with
higher distribution  so that the number of samples used
training match the number of samples in the classes with
lower distribution 

   results
     evaluation methods
to explore the effect of different data set sizes  we sampled the available data set into four sub sets of sizes        
               and         for validation purpose  we randomly sample one third of each subset as the test set and the
rest two thirds of each subset as training set  we train our
predictor using the training set and make predictions using
the predictor on the test set 
we used two accuracy measurements  star rating accuracy and polarity accuracy  for each test sample  a star rat 

ing of a certain aspect is generated  the prediction is then
compared with the ground truth to determine the accuracy
of the predictor  the accuracy is calculated by the number of
mismatched predictions divided by the size of the set 
for the star rating accuracy  under the multi class classification model  a prediction is considered mismatched when
the predicted rating is different than the user given rating 
under the regression model  a prediction is considered mismatched when the predicted rating and the user given rating
has more than a     star difference 
for the polarity accuracy  under both models  the results
are defined into three groups  positive  neutral  and negative  all ratings above   are considered positive  all ratings
below   are considered negative  while all ratings at   are
considered neutral 
in the following sections  we analyze the various factors we experimented with by examining the accuracy of
the trained predictors 

     class balance method comparison
the results in table   are generated based on the same
test and training set grouping  using the svm algorithm
with the same parameter  the overall ratings are set as the
prediction goals 

table    accuracy of the predictors trained with different class balance techniques 

no balance
class weight
over sample
sub sample

training set accuracy
     
     
     
     

test set accuracy
     
     
     
     

as we can see  the class weight method works the best
in our application 

     model and algorithm comparison
as discussed in section    we decided to experiment with
two different models  multi class classification and regression  and three different algorithms  naive bayse  svm and
linear regression  
the results are shown in the figures below  figure  
shows the star rating accuracy and figure   shows the polarity rating accuracy 
as we can see  as the dataset size becomes larger  the
svm algorithm tends to generate better results  thus  we
chose svm as the learning algorithm for our application 
at this point  the star rating accuracy is about     to     
while the polarity accuracy is about     to     

fitd idf transformation  due to the limited computation resources  we only ran the experiments on the sub dataset of
size        as we found in section      the accuracy results
generated on the sub dataset of size       and the accuracy
results generated on the sub dataset of       are very close 
the exact n gram configuration setups we used are given
in table    min df and max df indicate the constraints
for the features document frequency  any feature that appears too rare  lower than the min df constraint  or too
often  higher than the max df constraint  is removed  for
the     gram configuration  the min df is set to   occurrences 
table    detailed n gram configurations 

figure    star rating accuracy generated with various algorithms
under various dataset sizes 

n gram

base

 
 
  or  

word
char
word

stop word
removal 
yes
no
no

min df

max df

none
  
 

none
   
   

the results are shown in figure    both the star rating
accuracy and the polarity accuracy are given in the same
graph 

figure    polarity accuracy generated with various algorithms under various dataset sizes 

     feature selection comparison
as discussed in section    we ran experiments with various n gram configuration and pipelines with and without the

figure    star rating accuracy and polarity accuracy generated
with various feature configurations 

fias we can see from the graph  feature selection plays
a very important role in prediction accuracy  in general 
word based configurations work better than character based
configurations  by selecting     gram with no tf idf
transformation  we are able to improve the prediction accuracy significantly  the star rating accuracy is now around
    quite consistently while the polarity accuracy is between     and     
among all the aspects  the business service accuracy
is lower than the others  it is most likely caused by the insufficient training set size  even though all the aspects are
trained using the same reviews  a large portion of the reviews do not have a rating on the business service aspect 
thus the training set for business service aspect is much
smaller than the other aspects  we believe the prediction
accuracy will improve with a larger training set 

     overall vs  aspect specific predictor
lastly  we would like to examine the effectiveness of
our aspect specific predictors  for this purpose  we compared the accuracy of predictions generated by a predictor
trained with only overall ratings and the accuracy of predictions generated by a predictor trained with aspect ratings 
if our machine learning algorithm is indeed learning unique
features for each aspect  we expect the aspect based predictor to generate better results than an overall predictor  the
results are shown in figure   

as we can see  the aspect training results are indeed better than the overall training results in all aspects  which
means training the predictor using aspect based objectives
was able to learn the aspect specific features 

   conclusion and future work
in this project  we examined various class balance techniques and data models  we achieved promising prediction
accuracy on text review sentiments  our prediction accuracy reached     to     for star rating  and     to    
for polarity  we abstracted the problem into a multi class
classification problem  selected the bag of words feature
model using     word long phrases  and executed the machine learning process with the svm algorithm 
among the design decisions  feature selection played a
very important role in our design process  we were able
to improve the prediction accuracy by about     selecting the appropriate features  therefore  more optimization
in feature selection will likely further improve the prediction accuracy  the bag of words model used in this project
included full review text even when training for specific aspects  therefore  the input data are effectively very noisy 
wang et al     presented an aspect analysis method that
could help separate the aspects and reduce the noise  it
would very interesting to incorporate such aspect analysis
into this project 

references
    h  wang  y  lu  and c  zhai  latent aspect rating analysis
on review text data  a rating regression approach  in proceedings of the   th acm sigkdd international conference
on knowledge discovery and data mining  kdd     pages
        new york  ny  usa        acm 
    h  wang  y  lu  and c  zhai  latent aspect rating analysis
without aspect keyword supervision  in proceedings of the
  th acm sigkdd international conference on knowledge
discovery and data mining  kdd     pages         new
york  ny  usa        acm 

figure    aspect accuracy generated using an overall predictor and
an aspect specific predictor 

fi