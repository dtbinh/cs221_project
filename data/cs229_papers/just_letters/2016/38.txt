   
   
   
   
   
   
   
   

twitter us airline recommendation prediction
xiaotong duan  tianshu ji  wanyi qian

   
   
   
   
   
   

abstract
the goals of this project are    build a model for six major u s  airlines that
performs sentiment analysis on customer reviews so that the airlines can have fast
and concise feedback     make recommendations on the most important aspect
of services they could improve given customers complains  in this project  we
performed multi class classification using naive bayes  svm and neural network
on the twitter us airline data set from kaggle  significant accuracy has achieved 
which shows that our models are reliable for future prediction 

   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

 

introduction

in recent years  twitter has become the de facto online customer service platform  thus  a companys
image on twitter is of central importance and this is especially true for airlines given that many
tweets are travel related in nature  in fact  research has shown that responding to tweets has revenue
generating potential  drives higher satisfaction than other customer service channels  and perhaps
most importantly  satisfied twitter users spread the word  in this project  we use tweets gathered
from twitter to learn about peoples flight experiences and give airline companies suggestions on
how to make their trip more enjoyable 
the data set contains about        tweets  collected from february      on various airline reviews 
every review is labeled as either positive  negative or neutral  first  we want to build a model to
perform sentiment analysis on the data set  second  more interestingly  we want to assign a reason
to each negative response  such as late flight  lost luggage  etc  in our data set  about     of the
negative reviews has a negative reason label  yet the rests are labeled as cant tell  our goal is to
assign a label to this unspecified group  by knowing every reviews negative reason  we can give
specific suggestions to different airline companies on how to improve their service 

 

background and related work

nowadays  developing and testing different models for a natural language processing problem is
an interesting and challenging task  however  due to the nature of the problem  the accuracy of
sentiment analysis on single sentence like movie reviews never reaches above     for the past
  years      looking at last years project on twitter      their accuracy was        to        
depending on different models  in our project  we achieved near     more than their result  which
is a significant improvement 
since tweets texts are usually short and verbal  the same problem presents in our data set as well 
however  even though the tweets are short  there are strong indicative words  specific words can be
used as indicators for spam ham emails and achieve good test accuracy  therefore  we believe that
tweets review  without many negating negatives  can be predicted well using the frequency vector
representation  to prove this  we will use recurrent neural network model and the glove word
vector     to compare the result 
 

fi   
   

 

   
   
   
   
   
   

   

   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

approach
dataset

the sentiment analysis labels are positive       negative       and neutral       the negative
reason labels are bad flight         canceled flight         customer services issues          damaged luggage         flight attendant complaints         flight booking problems         late
flights         long lines          and lost luggage        
     

preprocess of dataset

in the preprocessing step  non english word  symbols and website links are eliminated  then the
whole data set is randomly separated into training set        samples       and test set      
samples       
     

dictionary

the dictionary is made based on the training data and all sentences are broken down into list of
words      delete common words such as a  an  to  of  on etc  with high frequency but little semantic
usage      stem words  such as thanks and thank as one word      delete low frequency words
that appear once to reduce the size of dictionary for calculation efficiency 
     

frequencies matrix

a feature matrix is built to convert the textual information into numerical information  in the feature
matrix  the number of rows indicates the number of samples  the number of columns is the length
of the dictionary  and each element indicates whether the specific word has appeared in the current
review    for existence and   for absence 
to get a sense of correlation presented in our feature matrix  i e  bad and suck may have a
higher chance to present together  we perform pca to capture the variance  the result shows that
for the first component  variance explained is       and for the next nine components  the variance
explained is all around       this shows that there isnt significant correlation between words and
to achieve better accuracy  we include all the words in the dictionary  we propose that the lack
of correlation comes from the nature of the text data  most of them are very short sentences and
extremely verbal 
   

models
   naive bayes with multinomial event model from sklearn is used  input is the frequency
vector and laplace smoothing is used 
nyi   
   
yi  
ny   n
   support vector machines with linear kernel and rbf kernel are used in this project  svm
uses the same input and implementation package as naive bayes 
k u  v    ut v

   
 

k u  v    exp 

ku  vk
 
   

   

   neural network
tensorflow is used in implementation  input is the frequency vector that represents a review  the output is a vector with probabilities for different classes and the highest is selected as prediction  label is a one hot vector that represents the class  loss function is
cross entropy plus a regularization term  the vanilla neural network that we use 
h   wx   b

   

y   sof tmax w h   b 

   

 

fi   
   

   recurrent neural network
a bi directional gated recurrent unit network  gru  can capture the structure features
of a sentence  also  it solves the vanishing gradient problem which many recurrent neural
network models have  bi directional gru is commonly used in text analysis  which we
want to compare with our models  package scikit is used for implementation  in gru  word
vectors  instead of frequency vector  will be used and we choose glove twitter   b zip    
these are pre trained word vectors that are trained on twitter data set  the math for gru
is shown as follows 

  i 
for right direction h t

   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   


 i 
similarly for h t
output

 

   


 r   i 

  r   i 
 i 


r t    w i xt   u i ht   

   





 i 
e
ht   tanh w i xt   rt  u i ht   

   


  i 
 i 
 i 
 i 
 i 
h t   zt  ht        zt    e
ht

   

 top 

  top  
yt   sof tmax u   h t   h t     c 

    

experiments   results

   
     

sentiment analysis
naive bayes classification with laplace smoothing

  smoothing parameter  is tuned  the lowest test error         is achieved when  is     or   
     is used in further experiments 
     

support vector machine with linear kernel

before tuning the regularization  svm with linear kernel  rbf kernel results in            test error 
respectively  therefore  svm with rbf kernel is excluded from future tuning due to the higher
initial test error  l  regularization is used to avoid overfitting  according to the graph shown below 
the lowest test error         is achieved when l  regularization is      

   
   
   
   
   
   
   
   
   
   
   
   


 z   i 

  z   i 
 i 


z t    w i xt   u i ht   

 a  svm tuning result

 b  nb tuning result

figure    sentiment analysis test error

     

one layer neural network

in each stochastic gradient descent step  only a batch of     samples is used in sgd to increase the
training speed  tuning parameters are learning step and regularization term  which are      and  
respectively  the best test error for this one layer neural network is         
 

fi   
   

     

   
   
   
   
   
   

word vectors from glove with a dimension of    will be used in gru  a   layer gru has a test
error of        a   layer gru has a test error of        learning step is       l  is   

   
   
   
   
   
   

     

bi directional gated recurrent unit network

sentiment analysis result

in sentiment analysis task  svm with linear kernel achieves the best test accuracy  therefore  svm
is recommended in this section  according to the result from linear svm  virgin american performs
the best according to its lowest negative review composition in its total reviews 

   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

   

negative reason prediction

in this section  the goal is to determine the most negative reason on flight services  all the negative
reviews have been collected for this task  and separated into labeled set and unlabeled set  we will
make predictions on the unlabeled set 
     

naive bayes classification

using naive bayes classification  the test error is average to        after ten fold cross validation 
with a laplace smooth factor of     
     

support vector machine

l  regularization is tuned  the best test error for svm is         when l  regularization        

   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

 a  svm tuning result

 b  nb tuning result

figure    negative reason test error

     

one layer neural network

input is same as before  labels dimension changes to    learning step and regularization term are
     and   respectively  the test error is       
     

negative reasons classification

given by the lowest test error  naive bayes is used for the prediction of unclassified data  result is
shown below that most complaints are on customer service  one postulate might be due to the high
 

fi   
   

volume of contact  since various reasons can lead to calling customer service  thus correlations
between classes may play a factor in determining this result 

   
   
   
   
   
   
   
   
   
   
   
   

 a  major negative reasons for each airlines

   
   
   
   
   

figure    negative reason classification
airline
virgin america
united airlines
southwest
delta
us airways
american airline

   
   
   
   
   
   
   
   
   
   
   
   

 

 st negative reason
customer service issue
customer service issue
customer service issue
late flight
customer service issue
customer service issue

 nd negative reason
flight booking problems
late flight
late flight
customer service issue
late flight
late flight

conclusion
 it is pleased that our vectors work  it is surprising that svm and naive bayes perform
better than deep learning methods  and the accuracy is very high       we think the
reason behind this is that while movie reviews have a lot of sarcasm     which is very
difficult for any model to grasp  twitter reviews are much more straight forward  and thus
most of the sentiments are expressed directly at the word level  that is to say  with specific
word appearance  sentiment is indicated clearly  which justifies our feature representation
using frequency vector  it is possible to judge a twitter airline reviews sentiment only by
identifying positive words in a review  therefore  given the nature of our data set  the task
can be solved at bag of word level well 
 however  it is too early to say that neural network can not perform better than bag of word
models  the frequency vector used in vanilla neural network is so large that takes enormous
time to train  roughly   hours for        iterations now  therefore  clever ways of reducing
frequency vector size are needed  meanwhile  better tuning parameters can be figured out
once training time is significantly decreased 
 another possible reason is that for recurrent neural network  gru in our project  labeling
every node is very important  while this model can achieve as high as above     accuracy
using stanford sentiment tree bank dataset     our results show that without sufficient
labeling  this model is not able to achieve an accuracy above      which means rnn
family needs strong supervision  however  most of the online reviews and other documents
only have limited labels  better labeling algorithm on new data set should be thought about
in future work 

   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   

 b  airlines performance on service issues

 

reference
  
  
  
  

pang  lee        cs   d slides 
yuan  zhou  twitter sentiment analysis with recursive neural networks 
pennington  socher  manning  glove  global vectors for word representation
stanford sentiment tree bank http   nlp stanford edu sentiment treebank

 

fi