machine learning for controlled slides of a rc car
cs    term project
morgan quigley and michael vitus
december         

 

hardware

the hardware platform for this project was basically
unstoppable 

   

drivetrain

for the drivetrain and mechanical platform of our
car  we started with an xray m   kit and added
a     watt brushless motor  its matching   phase
power converter  and a   cell lithium polymer battery  we found that this drivetrain produces enormous amounts of power  far beyond what we truly
needed  but power is addictive and you can never
have enough of it  to allow continous drifting of the
car  we covered the tires with small pieces of     
pvc pipe  the completed drivetrain is shown in figure   

figure    final assembly with vision markers installed
board which accepts r c stick positions via rs    and outputs a standard r c pwm pulse train
which is fed into the trainer port of an r c transmitter  the transmitters trainer switch is then used
to choose between autonomous and manual control
of the car  a standard r c radio receiver was used
on the car to control the steering servo and provide
throttle input to the motors speed control 

   

as shown in figure    we attached squares of red and
blue fabric to the front and rear of the car so that
we would be able to derive the position and heading
of the car from an overhead camera  the overhead
camera is able to pan and tilt to see a wide area
of floor space  but we found that when the camera
was in motion  latency from its pan and tilt encoders
threw the position estimates far out of whack  to
reduce this effect  we discretized the cameras motion
into   settings of pan and tilt  for a total of   possible
camera attitudes  
in addition  we added a green dot to the middle of
the playing field  and differenced the cars computed
position from the computed position of the green dot 
we found that this dramatically reduced the errors
from the moving camera  as the encoding errors will

figure    brushless    phase  drivetrain with lipo
battery and    mhz radio receiver

   

localization

control

using hardware designed by mark woodward  our
software was able to generate standard    mhz radio control signals  mark fabricated an atmel based
 

fiequally skew the positions of the green dot and the
car  leaving their relative positions intact  we chose
the camera pan and tilt discretizations so as to ensure that the green dot at the origin never left the
camera frame  two typical camera frames are shown
in figure   

figure    interface board stacked on     mhz
transceiver at left  imu at center  and rabbit microcontroller at right
the imu  pick out the z gyro readings  and transmit
them    times per second over the     mhz link 
we fabricated a board which regulated the cars lipo
battery to    v   v  and  v as needed by the various
parts of the system  and performed level conversion
between rs      used by the imu  and    v ttl
 used by the microcontroller   these modules were
attached to the roof of the car  as shown in figure   

 a  camera centered

a     mhz transceiver was connected to the controller pc to receive the gyro data  to calibrate
and unbias the gyroscope measurements  we drove
the car for several minutes  and performed linear regression of the vision yawrate estimate against the
z gyro yawrate measurements  a typical plot of this
data is shown in figure    running the gyroscope
readings through this linear map resulted in the desired scaling of radians sec and zeroed the sensors
dc bias 

 b  camera panned to a corner

figure    two typical camera frames  the green
dot on the floor marks the center of the coordinate
system  the cars red and blue squares give both
position and heading   the white tape on the floor
is not related to our project  
after some experimentation  we were able to tweak
marks vision code into running at    frames sec 
which is the full frame rate of the camera 

   

onboard inertial sensing

we soon found that the yaw rate estimates from the
vision system were noisier than we wanted  this was
unsurprising  as the yaw estimate itself is computed
as the arctangent of the coordinate distances between
the front and rear markers on the car  taking the
numerical derivative of this already differenced yaw
estimate introduced significant noise into the system 
to overcome this  we added a black box imu  an
xsens mt   to the car  among the many sensors in
the imu is a z axis mems rate gyro  which provided
a direct measurement of yaw rate  we attached a    
mhz radio transceiver to the car  and used a rabbit
microcontroller to parse the data streaming out of

figure    calibration of the yaw rate gyro measurements to radians sec  sensor saturation can be seen
at extreme right and left  but this was outside the
normal operating range of the experiment 

 

fi 

model

numerous feature mappings were explored in determining the optimal trade off between variance
and bias of the training data  the final feature
mappings that were used in determining the model

t
were x   x  t     u v r ur vr u  v   r  u  v   r 

t
and u   u  t                       
to evaluate the validity of the model  the data that
was parsed from the driving logs was integrated forward in time to estimate the position of the car  the
average of the error for each time step was plotted
versus time for two different feature mappings in figure   where x   x  t     x  t  and u   u  t     u  t  

after the hardware was assembled  the next step of
the project was to develop a model of the car during
controlled slides  a body frame was used in modeling
of the car to take advantage of the symmetries of
the system which is shown in figure    in normal
operation of a car  the angle between the velocity
vector and the heading of the car    is in the range
of  o   and therefore it was used to distinguish when
the car was sliding 

figure    coordinate frame of the car 
figure    mean errors versus time of sequence 

the states of the car that are the most important
to model at each time step are the forward velocity
of the car  u  the cross track velocity  v  and the rate
of rotation around the vertical axis  r 
a discrete time model instead of a continuous time
model was used to model the cars dynamics because
the data collected of the car was limited by the frame
rate of the camera which is    hz  the model of the
cars dynamics is shown in equation     in which a
higher dimensional mapping    is used for the current state and current input to predict the state at
the next timestep 

the higher dimensional feature mapping      provides slight better integration error than using just
the current state and input to predict the next state 
to obtain a feel for the coefficients  for the sake of
space  the following a and b matrices are the coefficients for the lower dimensional feature space     


    
     
    
    
    
a             
 
 
     
    


          
x  t        ax  x  t     bu  u  t  
   
b              
t
t
         
where x  t     u v r    u  t            is the steering
input  and  is the throttle input  to determine the
with a valid model of the sliding dynamics  the
model parameters  a and b  least squares was used to next step was to learn how to control the coordinated
minimize the error between the estimate of the state slides 
and the actual state observed  which is shown in eqn 
    
  controller
x
min
kx  t        ax  x  t     bu  u  t    k 
we experimented initially with an lqr controller 
t
    but decided to implement a q learning controller 
 

fiunstable and enter into donuts  therefore  for the
reward function  we penalize the controller for changing the control action  at each timestep  the reward
structure was as follows 

using the model      produced in the previous section  the q learner drove the simulation thousands
of times  the desired trajectory of the car is a coordinated slide of radius  m which is shown in figure
  

r   ro      new  old      new  old   

   

where
ro

ro
ro

if    cm  r       cm 
cm
   cm
s  r      s 
rad
rad
  s       s
    if r      cm  r       cm
 
  otherwise

 

  

whenever ro was     the simulation was restarted 
just as in the pendulum problem in the problem set 
the update step for the q function is 
q  s  a          q  s  a      r    max q  s    a    
   
an example of the simulation run after the conthe states that were used to discretize the state troller has trained the q function is shown in figure
space are  r  r       the reasoning behind the choice   
of these states is that for the desired trajectory they
should remain constant  and therefore  it is linearizing the system around an operating point 
the ranges of the discretization are 
figure    desired trajectory of controlled slide and
car states 

r      cm
   cm  r      cm
   cm  r      cm
   cm  r       cm
    cm  r       cm     cm  r       cm
r      cm
r       cm
s
   cm
s  r     
r      cm
s

cm
s

     rad
     rad         rad
       rad
     rad
s
rad
  s       rad
s
rad
  rad
s      
s

cm
    cm
s  r      s
cm
cm
   s  r       s

  rad          rad
    rad          rad

 
 

figure    simulation of the model and controller 

rad
s
rad
s

      rad
s
      rad
s
    rad
s

 

real world validation

to drive the real system  we simply exported the qtable from matlab  copied it to the pc hooked up
to the vision and control systems  and executed the
policy encoded in the q table in realtime  generating
the controllers state  r  r      in realtime from the
output of vision system and the imu took significant
debugging efforts  however  eventually we were able

the steering actions that the controller was able
to choose between are  steer straight  left and hard
left  and the throttle actions are  slow  medium and
fast  since the dynamics of the car during sliding are
unstable  erratic manuevers  such as constant switching of steering angle  will cause the system to become
 

fiduring the trial shown in figure     the cars
to compute this information  discretize it  perform
the q table lookup  and send out the steering and sideslip angle ranged from   and    degrees  the
q learned policy was able to control this sideslip anthrottle commands in realtime 
it would be an overstatement to say that we were gle to maintain some semblance of an orbit  a plot
entirely pleased with the results  we found that the of the sideslip angle experienced during the trial is
handoff of control from the human driver to the shown in figure    
computer was tricky to get right  because our model
only learned how to drive the car when it was sliding  the human driver needed to initiate a slide and
then give control to the computer  in addition  the
q learner only learned how to control the car within
a certain range of initial conditions of  r  r       although we randomized these initial conditions during
training  it still took some practice and patience to
execute the control handoff when the car was in a
feasible state 
camera motion was also a difficulty  although the
green dot at the origin of the coordinate system
helped dampen spurious measurements during camera motion  there was still some residual error in the
system during camera slew  and this often caused the
state estimates to be incorrect  we also suspect that
figure     sideslip angle during the trial 
the overall system latency  including vision processing  action selection  control waveform synthesis  and
actuator response  lead to the imprecise results  however  even with all of these issues  on a good run  the  
acknowledgments
q learner ended up controlling the car better than we
were able to do manually  figure    shows the best we must acknowledge the help and advice of mark
orbit the computer was able to perform  along with woodward  who designed and built the r c transthe ideal   meter orbit 
mitter interface hardware and software  and constructed the vision system  without his help  this
project would have never happened in a single quarter  we also acknowledge pieter abbeel and adam
coates in their advice for the q learner  in addition 
kurt miller helped us understand the imu and    
mhz radios 

figure     best performance from the controller with
the real world system  the car entered the orbit at
upper left  and did     circles before sliding out of
control in the center of the orbit 
 

fi