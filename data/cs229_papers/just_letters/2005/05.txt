distributed compression of stereoscopic images
with unsupervised learning of disparity
david varodayan and aditya mavlankar
information systems laboratory  department of electrical engineering
stanford university  stanford  ca      
email   varodayan  maditya  stanford edu

abstract distributed compression is particularly attractive
for stereoscopic images since it avoids communication between
cameras  since compression performance depends on exploiting the redundancy between images  knowing the disparity is
important at the decoder  unfortunately  distributed encoders
cannot calculate this disparity and communicate it  in this
paper  we propose an expectation maximization algorithm to
perform unsupervised learning of disparity during the decoding
procedure  experimental results show that this performs nearly
as well as a system which knows the disparity through an oracle 

i  i ntroduction
colocated pixels from pairs of stereoscopic images are very
statistically dependent after compensation for disparity induced by the geometry of the scene  much of the disparity between these images can be characterized as shifts
of foreground objects relative to the background  assuming
that the disparity information and occlusions can be coded
compactly  joint lossless compression is much more efficient
than separate lossless encoding and decoding  surprisingly 
distributed lossless encoding combined with joint decoding
can be just as efficient as the wholly joint system  according
to the slepian wolf theorem      distributed compression
is preferred because it avoids communication between the
stereo cameras  the difficulty  however  lies in discovering and
exploiting the scene dependent disparity at the decoder  while
keeping the transmission rate low 
a similar problem arises in the area of low complexity
encoding of video captured by a single camera          these
systems encode frames of video separately and decode them
jointly  so discovering the motion between successive frames at
the decoder is helpful  one very computationally burdensome
way to learn the motion is to run the decoding algorithm
with every motion realization      another approach requires
the encoder to transmit additional hashed information  so the
decoder can select a good motion configuration before running
the decoding algorithm      since the encoder transmits the
hashes at a constant rate  it wastes bits when there is little
motion  on the other hand  if there is too much change
between frames  the fixed rate hash may be insufficient for
reliable motion search  due to the drawbacks of excessive
computation and difficulty of rate allocation for the hash 
we use neither of these approaches for the compression of
stereoscopic images 

 a 

 b 

 c 

 d 

fig      a  source image x  b  source image y  c  sum of x and y modulo
   d  sum of x and y modulo    shifted to realign the shifted rectangle 

in section ii  we consider a toy version of the problem and
propose a novel decoding algorithm  which learns disparity
unsupervised  we describe the algorithm formally within the
framework of expectation maximization  em  in section iii 
section iv reports our simulation results 
ii  r andom d ot s tereogram c ompression
we model stereoscopic images x and y as binary random dot
stereograms      the disparity information d governs the relationship between x and y   we generate y by copying x and
shifting an arbitrary rectangular region of it horizontally  the
newly revealed area is filled randomly  finally  independent
identically distributed  i i d   binary noise is added  modulo
   to y to mimic camera noise  thus  d consists of the
boundaries of the shifted rectangle as well as the magnitude
and direction of the shift  fig    shows sample realizations of
x and y and their sums under different shifts  the interesting
observation of     is that stereoscopic viewing of x and y as a

fislepian wolf rate
encoder
separate
encoding

side information

conventional
encoder

fig    

ldpc
encoder

slepian wolf
decoder

ldpc
decoder

joint
decoding

conventional
decoder

 a 

ldpc
encoder

ldpc
decoder

disparity
oracle

distributed compression  separate encoding and joint decoding

single image creates an illusion of depth  the shifted rectangle
appears on a different plane compared to the rest of the image 
our compression setup is shown in fig     images x and
y are encoded separately and decoded jointly  for simplicity 
we assume that y is conventionally coded and is available
at the decoder  the challenge is to encode x efficiently in
the absence of y so that it can be reliably decoded in the
presence of y   the slepian wolf theorem states that x can
be communicated losslessly to the decoder using r bits on
average as long as r   h x y       
fig    depicts three compression systems that can be applied
to this problem  the system in fig    a  performs compression
of x with respect to the colocated pixels of y under the
assumption of no disparity      the encoder computes the
syndrome s  of length r bits  of x with respect to a lowdensity parity check  ldpc  code      the decoder initially
estimates x statistically using the colocated pixels of y and
refines these estimates using s via an iterative belief propagation algorithm  when disparity is introduced between x and
y   this scheme performs badly because the estimates of x are
poor in the shifted region  for comparison  fig    b  shows an
impractical scheme in which the decoder is endowed with a
disparity oracle  the oracle informs the decoder which pixels
of y should be used to inform the estimates of the pixels of x
during ldpc decoding  finally  fig    c  depicts our proposed
practical decoder that learns disparity d via em  the disparity
oracle of fig    b  is replaced by a disparity estimator  which
maintains an a posteriori probability distribution on d  every
iteration of ldpc decoding sends the disparity estimator a soft
estimate of x  denoted by   in order to refine the distribution
on d  in return  the disparity estimator updates the side
information  for the ldpc decoder by blending information
from the pixels of y according to the refined distribution on
d  the following section formalizes the process in terms of
em 

 b 

ldpc
decoder
 m step 

ldpc
encoder

disparity
estimator
 e step 

 c 

fig      a  distributed compression assuming no disparity  b  distributed
compression with a disparity oracle  c  distributed compression with unsupervised learning of disparity d via em

tuple  l  m    m    n    n     let r and z be  m  m      by n   n       and m by n binary images  respectively  where
r i  j  and z i  j  form i i d  bernoulli random processes with
p  r i  j             and p  z i  j               
generate the image y as follows using r to fill in the newly
revealed area and z as noise  notice that the pixels y  i  j 
form an i i d  equiprobable bernoulli random process 
y    x
y  m    m    n    n       r
y  m    m    n    l   n    l     x m    m    n    n   
y    y  z
we denote the a posteriori probability distribution of d as
papp  d  and that of x as
papp  x 



iii  e xpectation m aximization a lgorithm
let x be a binary image of size m by n  in which pixels
x i  j  form an i i d  equiprobable bernoulli random process 
define l to be a random integer representing the disparity
shift and constrain  l   l  n  define also random indices
m   m  and n   n  to be the vertical and horizontal
boundaries of the disparity region  respectively  thus  d is the

y

p  x i  j  

i j

 

y

 i  j x i j       i  j   x i j   

i j

where the  i  j    papp  x i  j       are parameters  thus 
 can be interpreted as a soft estimate of x 
the disparity estimator in fig    c  performs the e step of

fidisparity
pmf
   

weights

   
   
 

estimate
pmf
per block

fig    

the e step  disparity estimation and side information blending

em  namely  the following refinement of papp  d  
papp  d     p  d y  s   
 p  d p  y  s d   
 papp  d p  y  d   
the approximation in the last step is reasonable since  is
iteratively reconciled with s during the m step  but the estep  as written above  is expensive due to the vast number
of possible values of d  to reduce computation  the disparity
estimator first learns only the shift l block by block as shown
in the left hand side of fig     for a specified blocksize k 
every k by k block of  is compared to the colocated block
of y as well as all those shifted between l and l pixels
horizontally  for a block u v with top left pixel located at
 u  v   the distribution on the shift lu v is updated by
papp  lu v     papp  lu v  p  yu v lu v  lu v   u v   
where yu v lu v is the k by k block of y with top left pixel
at  u  v   lu v   

finally  the disparity estimator creates estimates u v of the
block xu v by blending estimates from each of the blocks
yu v lu v according to the distribution papp  lu v    as shown
in the right hand side of fig     more generally  this can be
described as
x
 i  j   
papp  d   d p  x i  j  d   d  y   
d

the ldpc decoder performs the m step  namely  the following maximization of the likelihood of y and the syndrome
s 


  
 


arg max p  y  s   

x
arg max
p  d   d p  y  s d   d   


arg max


d
x

papp  d   d p  y  s d   d   

d

true maximization is intractable  so we approximate it with
an iteration of ldpc decoding 

fi   

   

   
   

unsupervised learning  
compensation

   

oracle assisted
compensation

   

rate r

   

rate r

   

unsupervised learning  
compensation

   
no compensation
   

   
   

oracle assisted
compensation
no compensation
slepian wolf bound

slepian wolf bound
   

   

   

   

 
 

   

   

   

   

   

 
 

   

   

   

h x y 

   

   

   

   

h x y 

fig     rate  in bit pixel  required to communicate x for the different
systems shown in fig     when there is no disparity  the codes used are
regular of degree   

fig     rate  in bit pixel  required to communicate x for the different
systems shown in fig     when there is no disparity  the codes used are
irregular of degree ranging from   to    

   
   
   

   
no compensation

   
   

rate r

rate r

   
    unsupervised learning  
compensation
     best worst case 

 
 

    oracle assisted
compensation
 
 
   

oracle assisted
compensation
   

slepian wolf bound

   

slepian wolf bound

   

unsupervised learning  
compensation
     best worst case 
   

   

   

no compensation

   

   

   

   

   

   

   

   

   

   

h x y 

h x y 
fig     rate  in bit pixel  required to communicate x for the different
systems shown in fig     when there is disparity of size    by    and shift
   the codes used are regular of degree   

fig     rate  in bit pixel  required to communicate x for the different
systems shown in fig     when there is disparity of size    by    and shift
   the codes used are irregular of degree ranging from   to    

iv  s imulation r esults
iterating between the e step and the m step in this way provides a coarse profile of the disparity  limited by the granularity of k by k blocks  we refine the estimate of d by estimating
the disparity region boundary variables  m    m    n    n    
once several contiguous blocks agree upon a value for l 
for simplicity  instead of maintaining probability distributions
on the values of  m    m    n    n     we estimate a single
value for each boundary variable and refine it during every
iteration  this improves the fineness of compensation of the
side information beyond the granularity of k by k blocks 
the decoding algorithm terminates successfully when the
thresholded estimate x             yields syndrome equal
to s 

for our simulations  we select the following constants  image
height m       image width n       maximum horizontal
shift l      blocksize k      the camera noise parameter
   p  z i  j       ranges between      and       the
distributions of lu v are initialized to

      if lu v     
papp  lu v     
       if lu v      
rate control is implemented as follows  after     decoding
iterations  if x still does not satisfy the syndrome condition 
the decoder requests additional transmission rate from the
encoder  we employ rate adaptive codes as described in     
figs    and   show the performance of the systems in
fig    using regular codes of degree    when there is no
disparity and when there is disparity  respectively  in fig    

fiiteration  

iteration  

iteration  

iteration  

 

 

 

 

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

 

 

 

                      

fig    

                      

                      

 

                      

evolution of a disparity probability distribution for a sample   by   block

the disparity region is    by    pixels in size and the shift is
l      for the proposed scheme of fig    c   we show results
when the disparity region is aligned with the   by   block
grid  best case  and when it is offset from the grid by   pixels
horizontally and vertically  worst case   figs    and   show the
corresponding performance using irregular codes with degree
distribution ranging from   to     when there is no disparity
and when there is disparity  respectively 
figs    and   indicate that with no disparity  the compression
performance is identical for all three systems shown in fig    
this is because they all generate the same side information
for the ldpc decoder  when disparity exists  figs    and  
demonstrate that only the oracle assisted system performs as
close to the slepian wolf bound as before  the system that
assumes no disparity performs up to   times worse than
before because the side information is very unreliable in the
disparity region  the proposed unsupervised learning system
does significantly better than this  and comes close to the
performance of the impractical oracle assisted scheme 
to illustrate the progress of the unsupervised learning
decoding algorithm  we show how the disparity probability
distribution evolves for a sample   by   block in fig    
v  c onclusions
for the simplified problem of distributed compression of
random dot stereograms  unsupervised learning of disparity
is superior to ignoring disparity and is also practical  to our
knowledge  there is no literature on applying unsupervised
learning of disparity to either realistic distributed stereoscopic
image compression or realistic low complexity video compression  this suggests an interesting research direction 
vi  acknowledgments
we thank prof  bernd girod and markus flierl for useful
discussions 

r eferences
    d  slepian and j  k  wolf  noiseless coding of correlated information
sources  ieee trans  inform  theory  vol      no     pp          july
     
    a  aaron  r  zhang  and b  girod  wyner ziv coding of motion video 
in proc  asilomar conf  on signals  syst   comput   pacific grove  ca 
     
    r  puri and k  ramchandran  prism  a new robust video coding
architecture based on distributed compression principles  in proc 
allerton conf  commun   contr  and comput   allerton  il       
    a  aaron  s  rane  and b  girod  wyner ziv video coding with hashbased motion compensation at the receiver  in proc  ieee international
conf  on image processing  singapore       
    b  julesz  binocular depth perception of computer generated patterns 
bell sys  tech  j  vol      pp                 
    a  liveris  z  xiong  and c  georghiades  compression of binary
sources with side information at the decoder using ldpc codes  ieee
commun  lett   vol     no      pp          oct       
    r  g  gallager  low density parity check codes  cambridge ma  mit
press       
    d  varodayan  a  aaron  and b  girod  rate adaptive distributed source
coding using low density parity check codes  in proc  asilomar conf 
on signals  syst   comput   pacific grove  ca       

fi