cs    report  december     

 

statistical clustering and mineral spectral unmixing
in aviris hyperspectral image of cuprite  nv
mario parente  argyris zymnis

i  i ntroduction
hyperspectral imaging is a technique for obtaining a spectrum in each position of a large array of spatial positions
so that a recognizable image is obtained at each of a set of
discrete wavelengths  the images might be of a rock in the
laboratory  a field study site from an aircraft or a rover camera 
or a whole planet from a spacecraft or earth based telescope 
by analyzing the spectral features  generally neighborhoods
of local minima in the spectra  one can map materials  a
simplistic explanation for this being is that specific chemical
bonds in different materials manifest themselves as absorption
features at different wavelengths and by mapping where those
bonds occur in the spectra one can uniquely identify what
is called the unique spectral signature of the material   the
factors affecting spectra of natural materials and the causes
of absorption features are several and combine in complex
ways  they are not the focus of this paper but a comprehensive
tutorial can be found in      spectral unmixing is the procedure
by which the measured spectrum of a pixel is decomposed
into a collection of constituent spectra  or endmembers  and a
set of corresponding fractions  or abundances  that indicate the
proportion of each endmember present in the pixel  in the case
of rocks or soils the endmembers can be consistent with the
minerals present in the geologic surface observed  in this work
we present a novel technique of endmember selection from
a database of minerals based on simple convex optimization
techniques 
spectral unmixing can assume linear or nonlinear combination of the endmembers depending on the nature of the
surface observed      unfortunately nonlinear schemes can be
impractical for hyperspectral imaging because multiple views
from different angles of the same scene are required      
linear spectral unmixing is based on the assumption
that the spectrum of each pixel of the scene is a convex
combination of the spectra of its component minerals      
deterministic modeling of the mixture lacks the ability to
explain the statistical variability of the spectra within a class
due for example to illumination differences  altimetry  grain
size of the material and other causes  several attempts have
been made to correct this problem  these approaches allow the
endmembers of the mixture to be random variables  mostly
gaussians            
the present work assumes a mixture of multidimensional
pdfs for the statistical distribution of the spectra of the
single pixels composing the scene  each pdf  a multinomial
gaussian  represents the likelihood of a certain mineral mixture in the scene  we make use of the gauss mixture vector

quantization algorithm          as an alternative to the em
algorithm    to learn the mixture parameters  we also explore
cluster analysis with correlation distance     
the clustering stage is useful to select only a few centroids
each to be representative of the image and to perform only
on them the unmixing as opposed to the whole image  this
decreases the computational cost of the processing  especially
when a large number of images is acquired 
each gaussian mean produced by the clustering stage 
thought to be representative of a specific mineral mixture  is
unmixed in this work by a constrained least square algorithm
which can be cast as a quadratic program 
ii  aviris c uprite dataset
spectral data collected over cuprite  nevada  usa  have
been widely used to evaluate remote sensing technology and
for spectral unmixing           and references therein 
for the purpose of our study    out of the aviris bands     
       or      to      m  have been selected because of the
better discrimination of mineral signatures in that range 
in figure   b  there is a plot of the spectra that represent
the spectral variability in the image  those were obtained by
considering the image as a    dimensional data cloud and
capturing its corners 
iii  c lustering
our goal in clustering is to pick up as much as possible of
the spectral variability in the image  we tried some statistical
measures of cluster validation such as the gap statistics  by
polling several experts in mineral identification we assessed
that the statistical optimal number of clusters is too low to
capture the variability in the data that those experts would
consider if they scanned the pixel spectra 
since this is a completely unsupervised classification and
for the reasons just mentioned we consider capturing the most
spectra of figure   b  as a reasonable goal for the clustering
stage and to select the number of clusters 
we experimented with   different setups  k means  gmvq
and cluster analysis with the correlation measure 
we try for each k  number of clusters    runs with random
initial point and choose the run with minimum value for
objective function  distortion or distance  
a  lloyd clustering algorithm for gauss mixture design
the gauss mixture vector quantization algorithm can be
seen as an alternative to the em algorithm for fitting a finite

fics    report  december     

 

 a  rgb composite of bands          and    
fig    

 b  spectral variability

aviris hyperspectral image of cuprite  nv

gauss mixture  pm   gm   to a training set  x    x            xn  
 see     section   and      
the design of a gauss mixture implemented by gmvq is
as follows     
minimum distortion  nearest neighbor  step  for i  
           n encode each training vector xi into the index
c    xi   corresponding to the minimum distortion gaussian
c
model fm  xi  m
   that is     


 
c
c    xi     arg min  ln fm  xi  m
     ln c
   
m
pm
 
c
  
   
  arg min  ln  km
m  
 
c  
   x  cm  t  km
   x  cm     ln pcm   
 
c
are the current estimates of the mean and
where cm and km
covariance of the distribution of the samples 
centroid step  given all the vectors  x    x            xnm  
belonging to the m th partition determine a gaussian density
c
c
  so as to minimize
  fm  xi m
 i e  its parameters cm and km

nm 
x
 
 
c
c  
ln  km
     xi  cm  t  km
   xi  cm  
   
 
 
i  
the minimization can be performed by alternatively fixing cm
c
or km
and minimizing over the other one      the solutions
are the sample mean in the m th partition
c  
m  

nm
  x
xi
nm i  

   

and the sample covariance in the m th partition
c  
km
 

nm
  x
 xi  cm   xi  cm  t
nm i  

   

the algorithm includes one more step to calculate the
optimal length function ln p c  given the partition and the
m
centroids     
we proposed a variation on the gmvq algorithm that
discards the penalty term  ln p c in the distortion measure  
m

by considering        because we observed from simulations
that algorithms that use measures of membership probability
of each cluster   like the prior for each cluster in em and
optimal length function for gmvq  penalize too much the
clusters with fewer assigned sample 
   euclidean distance  if we set the covariance term
km   m equal to the identity  the distortion measure becomes
the euclidean distance and the gmvq algorithm reduces to
the well known k means  or vanilla vector quantization  
the euclidean distance is invariant under orthogonal transformation of the data but it does not take the correlation of
the variables into account 
the results in figure    left  show that the euclidean distortion is able to pick up the relatively very big  in norm  and very
small clusters in figure   b  which stand out as solitary but
only a few of the spectra in the central range are distinguished 
the reason being that those spectra differ mostly in shape 
we also found that the segmentation map was a little bit too
fragmented 
   mahalanobis distance  if the only constraint is   
  then the distance measure is similar to the mahalanobis
distance  with an additional term that considers the volume
of the gaussian cluster  
the classifier becomes quadratic  the increased flexibility
of the boundary is traded off by the decreasing of the betweencluster variance within cluster variance ratio 
from figure    left  we see results similar to the previous
case  the reason might rely on the fact that the covariances
of the clusters are very similar and we know that in case
the classification boundary is linear  we also notice that the
gmvq estimation for the mean is a simple average like
in k means  the fragmentation of the segmentation map is
somewhat improved by the use of the second order statistics 
b  correlation based cluster analysis
the correlation based distance between a pixel xi and a
centroid  is 
dc  xi           xi         

 xi  xi   t      
 
kxi  xi  k  k   k 

fics    report  december     

 

    

   

reflectance

    

   

    

   

    

 

    

   

    

   

    

   

    

   

    

wavelength

fig    

cluster centroids  left  and cluster map  right  for euclidean distance 

    

   

reflectance

    

   

    

   

    

 

    

   

    

   

    

   

    

   

    

wavelength

fig    

cluster centroids  left  and cluster map  right  for mahalanobis distance 

where xi    are the vector means of xi and  respectively 
this is a measure that is invariant to scaling and shifting
 vertically  of the expression values  we tried this setup to take
into account the shape of the spectra considered as signals 
the drawback is that the actual magnitudes of the spectra are
ignored 
if the inputs are standardized  then the above distance is
equivalent to the euclidean distance  another drawback of the
distance is that dc  xi         only implies linear relationship
between xi and  furthermore the centroids are not obvious
to interpret 
we actually obtained the best results with the correlationbased distance  as we can see from figure    left   the obvoius
limitation of the measure is that the high norm cluster in figure
  b  is misplaced because the measure is normalized  we on
the other hand get almost the full variability in the data  in
a development of this project we will explore a clustering
algorithm based on shape and gain vector quantization
that takes into account correlation  shape  and norm  gain 

simultaneously  the segmentation map seems less fragmented 
iv  m ineral i dentification and u nmixing
we assume that a dictionary of mineral spectra is available
to us  for this particular dataset  we extracted the dictionary
from     and       suppose that the mineral dictionary is given
in d


d   v  v        vn  
where vi for i              n are the individual mineral spectra 
we want to find the abundances a j    such that  for each cluster
centroid  mean  j   we have 
j 

n
x

 j 

ai vi   da j 

   

i  

in a least squares sense 
since it is unreasonable to assume that a given spectrum
is the linear combination of a large number of dictionary

fics    report  december     

 

    

reflectance

   

    

   

    

 

    

   

    

   

    

   

    

   

    

wavelength

fig    

cluster means  left  and cluster map  right  for correlation distance 

spectra  we want to impose a limit on the number of nonzero abundance coefficients  we can view this problem as
selecting a small number of regressors out of a given set  in
order to approximate  in a least squares sense  a given vector 
specifically we would like to solve the following problem  for
each cluster centroid 
minimize kda j   j k 
subject to card a j     r
a j    

   

here card a j    denotes the cardinality of a j    i e  the
number of nonzero elements in a j    or in other words the
sparsity structure of the abundance vector 
for our particular problem  the dictionary contains n      
minerals  we would like to express each centroid as a linear
combination of approximately r     of those minerals 
problem   reduces to a quadratic program  qp  if the
cardinality constraint is removed  however  with this constraint
present  it turns out that this problem is combinatorial and is
thus very hard to solve  specifically  if we wanted to find the
global optimum of   we would have to solve n  r  n  r  
quadratic programs  each of these qps would correspond to a
different sparsity structure in the abundance vector  obviously
solving such a number of problems is intractable  even for a
modest value of r 
there exist  however  efficient heuristics for finding approximate solutions to this problem  as explained in     section
       one method that works satisfactorily is to first solve the
following problem  for a range of values of  
 j 

minimize kda

 j 

 j k    ka

k 

   

by increasing the value of   we are in essence putting more
weight on minimizing the l   norm of the abundance vector
a j    this causes the solution of   to be sparser  we can then
use the sparsity pattern given by this problem to solve the
original problem 

it turns out that problem   is equivalent to the following
problem  for an appropriate choice of  
minimize kda j   j k 
subject to ka j  k   

   

this problem can be expressed as a qp with a simple
transformation in the variables 
the parameter  puts a limit on the maximum allowable l  
norm of a j    in particular  if we choose  to be large  then
the problem essentially becomes unconstrained  on the other
hand  if  is less than the l   norm of the optimal solution of
the unconstrained least squares problem  then the constraint
in   will be tight  in other words if we choose a small  
 j 
then we can be certain that the solution a of   will have
 j 
ka k      thus  since an l   norm constraint on a j  will
change its sparsity structure  we can change  until we get the
 j 
desired cardinality on the solution a  
 j 
now suppose we obtain an acceptable solution a to
   we then construct the matrix d  which consists of the
 j 
columns of d which correspond to non zero entries in a   we
then proceed to solve the following problem for each cluster
centroid 
minimize kda j   j k 
    
subject to a j    
thus  the solution to     for a centroid j will give us the
abundances  weights  for that given cluster corresponding to
equation    in order to express these in terms of percentages 
we then have to normalize the vector a j   
v  u nmixing r esults
the results of figure   show the estimated abundance
maps for three minerals  whose presence in this region is
unanimously agreed on by experts  i e        the maximum
in the scale is      dark red   we found reference for quantitative data for mineral abundances for this dataset  namely
      for the most common minerals our results our method
produced abundance maps which are qualitatively similar to

fics    report  december     

 

those obtained used there  the values of the abundances are
in broad accordance but we dont have a definitive answer of
what are the most accurate for the lack of ground truth data
on mineral abundances 
  

vi  c onclusion and f uture w ork
in this work we explored clustering techniques on a wellknown hyperspectral image  we assessed that cluster analysis
with use of the correlation distortion measure is a technique
that picks up most of the variability in the dataset  despite the
lack of quantitative reference data for mineral abundances for
this dataset  our results were qualitatively in accordance with
other studies 
in future studies we will devise reliable performance measures for cluster validation and mineral unmixing  we will also
explore the clustering performance of an algorithm that takes
into account both shape and norm as an improvement of our
clustering stage 

  

  

  

  

  

r eferences
  

    a  aiyer  k  pyun  y  huang  d  obrien and r m  gray  lloyd clustering
of gauss mixture models for image compression and classification  in
image communication  vol     pp                 
    s  boyd and l  vandenberghe  convex optimization  cambridge university press         
    r n  clark  spectroscopy of rocks and minerals  and principles of
spectroscopy  in manual of remote sensing  john wiley and sons  a 
rencz editor  new york         
    r  n  clark  g  a  swayze  k  e  livo  r  f  kokaly  s  j  sutley  j  b 
dalton  r  r mcdougal  and c  a  gent  imaging spectroscopy  earth
and planetary remote sensing with the usgs tetracorder and expert
systems  journal of geophysical research  vol       no  e      p          december       
    a p  dempster  n m  laird and d b  rubin  maximum likelihood from
incomplete data via the em algorithm  journal of the royal statistical
society  ser  b             
    m t  eissmann and r c  hardle  stochastic spectral unmixing with
enhanced endmember class separation  applied optics  vol     no     
 december       
    r m  gray  gauss mixture vector quantization  proceedings of ieee
international cnference on acoustics  speech and signal processing 
 may       
    t  hastie  r  tibshirani and j  friedman  the elements of statistical
learning  springer       
    n  keshava and j f  mustard  spectral unmixing  ieee signal processing
magazine   january       
     m  parente  an investigation of the properties of expectationmaximization and gauss mixture vector quantization in density estimation and clustering  ee    report  stanford university   september
      
     m  petrou  mixed pixel classification  an overview  submitted to world
scientific         
     r  redner and h  walker  mixture densities  maximum likelihood and
the em algorithm  siam review         pages           april       
     j j settle and n a  drake  linear mixing and the estimation of ground
cover proportions  international journal of remote sensing      pp                  
     d  stein  application of the normal compositional model to the analysis
of hyperspectral imagery  ieee         
     d w  stein  the normal compositional model with applications to
hyperspectral image analysis  mit lincoln laboratory  project report
nga      march       

  

  

  

  

  

  

  

  

  

  

  

fig     alunite hs     b  left   kaolinite cm   middle  and muscovite
gds     right  abundance maps 

fi