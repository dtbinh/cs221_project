 

decoding cognitive states from fmri timeseries
catie chang
catie stanford edu
cs    final project report
i  introduction
conventional analysis of functional magnetic resonance
imaging  fmri  data follows a regression based approach 
in which one identifies the neural correlates of a particular cognitive function by correlating individual voxel timecourses with a known pattern of stimulus presentations 
however  one can reverse the direction of analysis  rather
than using knowledge of the stimulus pattern to infer brain
activity  one can ask whether brain signals can be used to
predict perceptual or cognitive states  this problem falls
naturally into the domain of machine learning  and can be
viewed as an instance of learning classifiers from extremely
high dimensional  sparse  and noisy data     
recently  mitchell et al      demonstrated the feasibility
of training gaussian naive bayes  gnb   k nearest neighbors  knn   and support vector machine  svm  classifiers to discriminate between a finite set of cognitive states 
for instance  given fmri data from a single time interval
 t   t    the classifier could determine whether the subject
was viewing a picture or reading a sentence during that interval  cox and savoy     used linear discriminant analysis  lda  and svm to investigate the neural representation
of various object categories  and davatzikos et al     applied
svms and lda to the problem of lie detection  the ability
to automatically classify fmri data has found applications
in clinical diagnosis as well  zhang et al     use knn  gnb 
svm  and adaboost classifiers to discriminate between the
brains of healthy versus drug addicted subjects 
besides demonstrating the power of machine learning algorithms  classifying fmri data can provide valuable insight into mechanisms of brain functioning  that is  activation patterns which play a critical role in discriminating
between perceptual or cognitive conditions may likely have
strong neurobiological relevance  in this way  classification may be regarded as a hypothesis generating method 
furthermore  the approach of characterizing entire spatiotemporal activation patterns represents one important departure from massively univariate analyses  e g  spm     
commonly found in functional neuroimaging literature 
in this project  we first apply well known machine learning algorithms  e g  lda  svm  to the problem of discriminating between cognitive states both a mental arithmetic
task  block design  and a working memory task  eventrelated design   in each task  classifiers are trained using
short time intervals of fmri data known to correspond to
either of two conditions      an experimental condition 
or     a control condition  after training  the classifier
must determine whether an unseen segment of fmri data
corresponds to an experimental or control condition  for
both single subject and multiple subject classification  we

are able to achieve accuracies comparable to those reported
in               
next  we characterize the most discriminating regions of
the brain for both cognitive tasks by examining the weight
vectors  w  returned by the svm classifiers  we demonstrate that these discriminating volumes overlap to some
extent with the t maps resulting from the univariate general linear model  glm  analysis  this work is similar to
that described in     
finally  we explore the use of dynamic bayesian networks  dbns  in modeling functional interactions between
brain regions in the working memory task  unlike the lda
and svm classifiers  which use only spatial patterns of
voxels to characterize differences between cognitive states 
dbns can capture the statistical relationships between
brain regions over time  hence  modeling fmri data using
dbns can be used for both classifying new data and generating hypotheses about functional interactions between
brain regions throughout different stages of cognitive processing 
ii  classification
training classifiers
in both the arithmetic and working memory tasks  the
classification function assumes the following form 
f   fmri sequence t    t      state   state  
fmri sequence t    t    refers to the set of fmri images
collected during the time interval  t    t     our method for
encoding fmri sequence t    t    is based on      each training example x i  is formed by concatenating the signal values from p selected voxels over  t    t     thus  x i  is an
 mp     vector  where m is the number of fmri images
acquired during the interval  t    t     each x i  has an associated binary valued label y  i    where y  i      if  t    t   
corresponds to a trial of classstate  and y  i      if  t    t   
corresponds to trial of class state  
in the mental arithmetic task  state  corresponds to a
trial in which the subject views a valid  though possibly
incorrect  equation  e g         or         and must
determine whether or not the equation is correct  state 
corresponds to a trial in which the subject views a nonequation string of numbers and symbols  e g         
and must determine whether or not the equation contains
the number    in the working memory task  the subject
is prompted to remember a string of   numbers that are
either all the same  low load  state    or all different
 high load  state    
dimensionality reduction because the number of voxels
in the brain is large  over         for our data   feature

fi 

table i
loocv errors obtained across multiple subjects  for the arithmetic task 

method
lda
svm
svm

kernel
n a
rbf
linear

errors
                                                      
                                                      
                                                      

mean error
      
      
      

table ii
loocv errors obtained across multiple subjects  for the working memory task 

method
lda
svm
svm

kernel
n a
rbf
linear

errors
                                                                                 
                                                                                   
                                                                                  

table iii
loocv errors obtained across multiple subjects using the
svm classifier on a pca basis

subject
 
 
 
 
 
 
 
 
 
  
  
  
  
  
mean error

wm
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      

ma
      
      
      
      
      
      
      
n a
n a
n a
n a
n a
n a
n a
      

selection dimensionality reduction is desirable  we implemented the following two feature selection methods 
 i  intersection of functional and anatomical rois here 
we begin with a set of     anatomical rois  e g  hippocampus  cerebellum  these rois comprise all available
templates supplied by the marsbar matlab toolbox      
we then determine which voxels in each region are significantly  p        active in the experimental condition versus
the control condition by separately correlating each voxels
timecourse with the stimulus waveform for each condition
 a boxcar signal which is high when the stimulus is on and
low when the stimulus is off   and applying a t test  the
significant voxels in a particular roi are grouped into a single supervoxel  and the timecourses of each constituent
voxel are averaged to obtain the supervoxels timecourse 
note that some rois may contain no significant voxels 
when classifying across multiple subjects  we only consider
rois that contain at least one significant voxel from each
subject 

mean error
      
     
      

 ii  pca using voxels from the entire brain here  no feature  voxel  selection is performed  instead  pca is applied
to reduce the dimensionality of the full  n  p  training
matrix  where n is the total number of training examples
and p is equal to the number of voxels in the brain  this
method allows us to construct discriminating volumes 
i e  spatial maps that display voxels playing the most critical role in the classification      in addition  unlike  i  
this method makes no a priori assumptions about voxel
activation  thereby opening the possibility of discovering
previously unsuspected brain regions that might prove critical to the cognitive process of interest  here  we did not
choose to discard any of the principal components  pcs 
corresponding to nonzero eigenvectors  hence  there is no
information loss in the pca transformation 
we choose these feature selection methods because they
easily extend to the problem of training classifiers across
multiple subjects  for instance  the roi abstraction directly allows for the mapping of corresponding features
across subjects      other feature selection methods proposed in the current literature  e g  selecting the p most
active voxels in the brain      do not generalize well to the
multiple subjects case 
in the mental arithmetic task  each block consisted of   
timepoints  because there tends to be higher variability in
brain activation at the beginning and end of each experimental block  our training and test sets drew data from the
  timepoints centered in the middle of each block  for the
working memory task  we drew   data point from each trial
   seconds after the stimulus onset  to use in the training
and test sets 
other preprocessing steps prior to forming the feature
vectors  we low pass filter the voxel timeseries  subtract the
mean  and remove linear drifts  fmri data contains highfrequency  task unrelated noise as well as linear scanner
drift which can introduce high degrees of variation between training examples of the same class  after low pass
filtering and detrending  training examples belonging to a
single class appear more uniform  for the second feature
selection method  we downsampled all brain volumes by a
factor of   before applying pca  due to memory limita 

fi 

tions  
classifiers we applied the following classifiers      lda
 from the discrim toolbox for matlab by michael kiefte 
dalhousie univ        svm  svm toolbox for matlab by
anton schwaighofer  http   ida first fraunhofer de   anton software html 
testing classifiers
we quantify the loocv error obtained when training
both on  a  single subjects and  b  across multiple subjects 
for single subjects  we quantify the performance of the
classifiers and feature selection methods using leave oneout cross validation  since fmri data is strongly correlated
in time  the point that is left out  say  at time t   will be
related to the training points at  t  k  t   k   thereby
producing biased error estimates  thus  when testing on
point t  we exclude points t    from the training set     
for multiple subjects  the loocv error is the prediction
error obtained from testing on one subject  after having
trained on the remainder of subjects  
tables   and   display prediction errors when feature selection method  i  was applied  table   shows the prediction errors on each of   subjects for the mental arithmetic
task  and table   shows the prediction errors on each of
   subjects for the working memory task  results indicate that svm  compared with lda  is more capable of
generalizing across subjects  the across subject errors in
both tasks are comparable to those reported by      when
using svms to detect whether subjects were reading a sentence or viewing a picture  they achieved across subject
errors of         on the syntactic ambiguity study  determining whether subjects were reading an ambiguous or
unambiguous sentence   svm errors were around        
in a face matching task  miranda et al      achieved error
rates of         faces versus locations   and         faces
versus control  
table   displays the across subject prediction errors
when feature selection method ii  was applied  the mean
error on the mental arithmentic class was         and the
mean error on the working memory task was        
in general  the error for the arithmetic task is much lower
than that of the working memory task  this result may reflect the fact that the arithmetic task has a block design
structure  while the working memory task has an eventrelated structure  in a block design  several trials of the
same condition  experimental or control  are presented in
close succession  thus  the characteristic activity pattern
for each condition is sustained over several seconds  on the
other hand  the experimental and control trials of an eventrelated design are randomly interleaved  which often means
that  a  two trials of the same type are separated in time 
and  b  two trials of different conditions may sometimes
occur in quick temporal succession  thereby allowing the
the slowly varying brain reponse  hemodynamic response
function  or hrf  to the first trial to obscure that of the
second trial type  the signal to noise ratio is also higher in
a block design compared to an event related design  since
hrfs are known to sum in a rougly linear fashion  thus 

event related designs pose a more difficult challenge to classifiers 
it is also worth noting that the error for the svm acrosssubjects classification using feature selection method  ii  in
the working memory task was highly sensitive to the set of
data points used for training testing  for instance  while
using the first and or second timepoints following the onset
of each trial  the across subject classification error rarely
dropped below      however  using the fourth timepoint
yielded errors in the        range 
iii  mapping discriminating volumes
the svm classifier finds a hyperplane that maximizes
the the margin of separation between the two classes  the
normal vector w defining the optimal hyperplane  and  consequently  the optimal linear transformation of the data
points  can be interpreted as the direction along which the
two classes differ the most  thus  mapping the w vector
into a brain volume yields a spatial map indicating the
relative discriminating importance of each voxel  while
the lda classifier also yields a separating hyperplane  we
chose to generate the discriminating volumes based on the
svm because of svms superiority in generalizing to unseen data 
because svm was performed in principal components
space  we first project the resulting normal vector  wp  
back into voxel space with the transformation w   v wp  
where v is the matrix of eigenvectors  pcs  
the discriminating volume and corresponding glm map
for the working memory task is shown in figures  a and
 b  respectively  note the presence of clusters in the parietal  motor  and left basal ganglia regions in both maps 
these areas are known to play a role in working memoryrelated processing  the majority of the differences occur
in the top and bottom rows of the montages  which do not
contain brain structures relevant to working memory processing  the discriminating volume and glm map for the
mental arithmetic task is shown in figures  c and  d  note
that a few of the regions with high weights in the discriminating volume are overlap with regions with high t values
resulting from the glm analysis  e g  l r putamen  l r
insula   however  many salient clusters in the glm map
are missing from the discriminating volume  e g  cerebellar
regions  sma  cingulum  
in figure    the glm maps are thresholded to show
voxels with significance p         while the discriminating
volumes are thresholded to show voxels whose w values are
above     of the maximum absolute value in w  though
it is not exactly correct to compare w values with p values 
    observed that after converting w values to p values using nonparametric permuations tests  voxels whose values
exceeded     of the max matched very closely the voxels
which turned up as significant at p       
in the working memory task      of the thresholded
      of the max  discriminating volume intersected with
the glm map  however  only     of the glm map intersected with the thresholded discriminating volume   for
the mental arithmetic      of the thresholded discriminat 

fi 

 a 

   

   

   

   

   

   

   

   

   

   

   

   

   

  

  

  

 

 

  

  

  

  

  

 c 

   

   

   

   

   

   

   

   

   

   

   

   

   

  

  

  

 

 

  

  

  

  

  

 b 

   

   

   

   

   

   

   

   

   

   

   

   

   

  

  

  

 

 

  

  

  

  

  

 d 

   

   

   

   

   

   

   

   

   

   

   

   

   

  

  

  

 

 

  

  

  

  

  

fig      a  discriminating volume for the working memory task   coronal slices   b  glm t map for the working memory taks   coronal
slices   c  discriminating volume for the mental arithmetic task   axial slices   d  glm t map for the mental arithmetic task   axial
slices  for display purposes  elements in the discriminating volume maps  i e  w  which is a unit vector  are scaled by a factor of      

ing volume intersected with the glm map  and again     
of the glm map intersected with the thresholded discriminating volume  
how might we interpret differences between the glm
maps and the discriminating volumes  the glm is a univariate approach which tries to fit a linear model to the
timeseries  whereas the svm considers only the spatial
pattern at each moment in time  while the two methods of analysis provide different perspectives on the data 
it is unclear which is more correct  the svm and other
methods of multi voxel analysis do  however  provide valuable alternatives to linear modeling  and indeed  there are
many cases in which simple linear timeseries models are inappropriate  e g  experimental designs in which timeseries
regressors are highly collinear  or when the actual shape
of the hemodynamic response differs significantly from the
canonical  modeled response   it is notable that both here
and in      svm classification using no prior model of the
hemodynamic response  as well as completely unbiased feature selection  identifies regions similar to those identified
by a glm analysis 
iv  dynamic bayesian nets
a bayesian network is a graphical representation of joint
probability distributions over sets of random variables 
nodes in the graph represent variables in a system  and
arcs represent conditional dependences  dynamic bayesian
networks  dbns  explicitly model temporal processes  in
a dbn  nodes are arranged into columns  where each column represents a particular time frame in the process  arcs
connecting nodes between columns represent causal relationships 
dbns have recently been applied to the problem of mod 

eling relationships between brain regions in fmri data  unlike the glm  dbns do not assume linearity of the bold
response or voxel wise independence  burge et al      used
dbns to model differences in brain networks between a
group of dementia patients and a group of healthy subjects  they constructed a dbn with     nodes in each
column  where node i in column t represented the mean
signal of the ith roi at timeframe t  timecourses were
quantized to   or   levels  so that each node had a discrete
conditional probability table  cpt   a structure learning
algorithm was applied to search for the network topology
that best explains the data  the markov assumption is invoked to reduce the search space  only two columns  t and
t      are needed   after the networks were learned  classification accuracy on test data from each group was obtained as a means of validating the resulting structures 
their classification accuracy comparable to that of svms
and gaussian naive bayes  gnb  classifiers 
very recently  zhang et al       used dbns to model
the interactions between   rois in groups of drug addicted
and healthy subjects  a dynamically multi linked hidden
markov model  dml hmm       was used  and a structural expectation maximization  sem  algorithm was performed to learn both the structure and parameters that
maximize p  data model   figure    
in this project  i constructed dbns to explore possible differences in functional interaction between the highload and low load conditions in the working memory task
described above  section ii   i chose to model the relationships between   rois that are hypothesized to be important in working memory  as in      observations were
taken as the mean signal values in each roi  and were
quantized to   levels  i experimented with several dif 

fi 

setting up different priors in the cpds based on existing
neural connectivity models  and letting each observation
take continuous  rather than quantized  values whose densities are modeled  say  as mixtures of gaussians 

 a 

acknowledgements

fig      a  example of a dml hmm  zhang       nips    b  sem
algorithm for parameter and structure learning 

many thanks to professor vinod menon  dept  of psychiatry   behavioral sciences  dept  of neuroscience  for
the datasets  fast computers  and helpful discussions about
fmri 
references

ferent models topologies  the first model was similar to
    in that each node represented the fully observed mean
roi signal value  structure learning was performed using
the reveal algorithm      with both the bic and ml
scoring criteria  as implemented in the bayes net toolbox
 http   bnt sourceforge net   the ml criterion constructs
arcs that maximize the mutual information between the
parents and child of each familiy  which tended to always result in fully connected graphs  the bic criterion
has a penalty term which lessens the tendency to overfit 
bic     log l     k log n
here  l   is the maximum likelihood of the data under
the current structure  k is the number of parameters of the
model  and n is the size of the training set  however  under
the bic criterion  my structural searches only produced
diagonal  identity  adjacency matrices for both the highload and low load data sets  i then tried using the ml
criterion  while restricting the maximum number of parents
of each child to    the structures learned for the high load
and low load condition were different  however  classifying
new test data via argmax p  data structureclass    could not
class

be performed significantly better than chance  this is likely
a consequence of having too few datapoints in the test set 
however  it is also possible that the chosen rois do not
exhibit strong causal relationships  or relationships that
differ between the high  and low load conditions 
i also constructed dml hmm models and implemented
the sem algorithm for structure and parameter learning 
as in       hidden nodes were assumed to be discrete and
binary valued  arcs could exist between hidden states only 
as shown in figure    the resulting structures for both the
low load and high load conditions differ only in one column 
and again  classification accuracy did not exceed chance 

 a 

 

 

 

 

 

 

 

 

 

 

 

 
 

 

 

 

 

 

 

 

 

 

 

 

fig      a  dml hmm sem adjacency matrix for the high load
condition   b  dml hmm sem adjacency matrix for the lowload condition  low classification accuracy implies that these
structures are not reflective of differences in neural connectivity
between conditions 

future work could involve selecting different sets of rois 

   

tom m  mitchell  rebecca hutchinson  radu stefan niculescu 
francisco pereira  xuerui wang  marcel just  and sharlene newman  learning to decode cognitive states from brain images  
machine learning  vol      no       pp               
    david d  cox and robert l  savoy  functional magnetic resonance imaging  fmri  brain reading  detecting and classifying
distributed patterns of fmri activity in human visual cortex  
neuroimage  vol      no     pp               
    c  davatzikos  k  ruparel  y  fan  and d g  shen  classifying
spatial patterns of brain activity with machine learning methods 
application to lie detection  neuroimage  vol      no     pp 
             
         ieee computer society conference on computer vision
and pattern recognition  cvpr              june       san
diego  ca  usa  ieee computer society       
    k  friston  a p  holmes  j b poline  p j  grasby  s c r
williams  r s j  frackowiak  and r  turner  analysis of fmri
time series revisited  neuroimage  vol     no     pp             
    j  mourao miranda  a l w  bokde  c  born  h  hampel  and
m  stetter  classifying brain states and determining the discriminating activation patterns  support vector machine on
functional mri data  neuroimage       
    m  brett  j l anton  r  valabregue  and j b poline  region
of interest analysis using an spm toolbox  international conferance on functional mapping of the human brain       
    x  wang  r  hutchinson  and t m  mitchell  training fmri
classifiers to detect cognitive states across multiple human subjects  nips       
    j  burge  v p  clark  t  lane  h  link  and s  qiu  evidence for
altered neural networks in dementia  tech report  university
of new mexico  vol  tr cs               
     lei zhang  dimitris samaras  nelly alia klein  nora volkow 
and rita goldstein  modeling neuronal interactivity using dynamic bayesian networks  in advances in neural information
processing systems     y  weiss  b  scholkopf  and j  platt 
eds  mit press  cambridge  ma       
     s  gong and t  xiang  recognition of group activities using
dynamic probabilistic networks  iccv   ninth ieee international conference on computer vision  vol     pp            
     s  liang s  furhrman and r  somogyi  reveal  a general reverse
engineering algorithm for inference of genetic network architectures  pac symp biocomput   pp             

fi