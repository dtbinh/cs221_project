florin ratiu
cs    final project

reordering attachment candidates in the csli dialogue systems dmt

   abstract
this paper describes an approach for selecting the best candidate dialogue move in multidevice dialogue systems based on multiple sources of information  including parsing
hypotheses  contextual information  information from topic classifiers and semantic
features  at the basis of this approach stands the ability to re order n best lists of inputs
using the features mentioned above  thus potential errors from speech recognition and
parsers can be corrected  machine learning techniques are compared to the baseline
system  which is based on hand crafted heuristics 
   the csli dialogue system
the csli dialogue manager  cdm  implements the information state update  isu 
paradigm to dialogue management  this approach provides a powerful representation of
the dialogue by collecting information relevant to the dialogue context in a central data
structure  this context is used to interpret incoming utterances  do resolution of noun
phrases  nps   construct responses  maintain state  etc  in cdm the isu approach has
been designed to support multi threaded and multi topic conversations  the central data
structures used to support these are the dialogue move tree  dmt  and the activity tree
 at   an overview of the system architecture is presented in figure  below 

the dmt has a tree structure that represents the entire dialogue history  each subtree
represents a thread in the conversation and incoming utterances  interpreted as dialogue
moves  are transformed into nodes  multi threading and multi device dialogue is
supported by allowing nodes created from utterances corresponding to different topics of
conversation or addressing different devices to attach in different subtrees  the root of
the tree is a node responsible for managing all the devices the user can address  and the

 

finext level corresponds to the managers of these different devices  all other nodes
correspond to user or system utterances 
the active node list  anl  is a list of all the nodes in the dmt that accept attachment
of other nodes  they correspond to open topics of conversation  to which new utterances
can be added 
the nodes in the dmt express how users utterances and systems responses are
incorporated in the dialogue context  a description of these nodes can be found in     
there is a scripting language that defines the conversion from utterances and actions to
the dmt nodes  which allows easy customizations of these conversions to new domains
and applications  the script can support hierarchies of dialogue moves and provides
semantic templates that define valid attachment of new nodes  examples of the script are
also presented in     
during the process of interpreting and responding to users utterances and creating new
activities the system is trying to resolve nps extracted from utterances  this might
involve interaction with the knowledge manager and querying of the knowledge base  at
the dialogue level  system responses correspond to user nodes in the dmt and some
might be grounding points or clarification questions in the dialogue 
   the attachment algorithm
in the general case  multiple possible candidate dialogue moves will be produced for a
given user utterance  for a number of reasons 
  multiple hypotheses from asr statistical parser output 
  multiple interpretation methods  deep parsing vs  shallow classification  
  multiple possible move types for a candidate interpretation 
  multiple antecedent nodes  active dialogue threads   including multiple devices 
for a particular move type 
they are not independent  it is important to consider all factors simultaneously  to allow
an integrated scoring function for each candidate and thus consider the best overall  the
skeleton algorithm for instantiating and selecting a dialogue move is therefore as follows 
foreach open node o
foreach n  best list entry n
foreach matching script entry m
create candidate move
score all candidates
if   score  top      score   second   
then
select top candidate
else
generate question to disambiguate
if   score   selected   node     threshold  
generate question to confirm

 

fithe interesting aspect of the above process is the scoring function  dialogue move
candidates are scored using a number of weighted features  ranging from speechrecognizer confidence  through to pragmatic features such as the device in focus and
recency of the dmt node the candidate would attach to  the full list of features currently
considered is shown in the table above  note the inclusion of features at many levels 
from acoustic recognition confidences through syntactic parse confidence to semantic and
pragmatic features 
recognition features 

 

semantic features 

 

contextual features 

 

parse probabilities and ranks 
note  unfortunately there is only one speech hypothesis
available  the project is joint work with bosch rtc and
they only provide a single sr result 
topic classification for the parse 
number of slots filled  ambiguously  resolved unresolved
by input pattern  that tries to match the parse  
set of constraints  in a frame object  that is sent to the
knowledge base 
number of kb results for such a frame 
number of kb results for such a frame 
position and recency of the parent node in the dmt 
frequency of dmt attachments   pairs of child and parent
node types 
pairs of chronologically consecutive nodes 

this integrated scoring mechanism therefore allows n best list input to be re ordered 
dialogue move candidates are potentially instantiated for each n best list entry and the
highest scoring candidate chosen  while the n best list rank and confidence are factors in
the overall score  other features may outweigh them  resulting in an initially lower ranked
n best entry becoming the highest scoring dialogue move 
the default attaching algorithm used only a small subset of these features to score
attachments and then selects the best one  instantiation of a dialogue move is
conditioned on the parse of the user utterance matching a specified pattern  this is just a
parse tree  and or a topic classifier  once this first step is completed the attaching
algorithm uses the statistical parse and topic scores  probabilities and likelihoods  and a
should attach score  defined arbitrary by developer to indicate how likely is a child user
node type to attach to a parent node type  to compare the candidate possible attachments 
experience with this system showed that incorporating a larger set of features is hard 
many heuristics are not very intuitive and complexity increases very fast 
all these suggest an alternative approach  apply machine learning for selecting the best
dialogue move candidate  for each user utterance in the training set we create a set of
candidate dialog moves  pairs of parent  child node  where the child always corresponds
to the user utterance   based on the state of dmt and matchings of n best list of parses
with patterns and topics  for each such possible attachment we can compute a vector of
the features presented above and manually label it as correct incorrect attachment 

 

fi   data collection
data used for these experiments was collected during several user sessions in which the
performance of this dialogue system was evaluated  the subject utterances were
recorded as  khz and   khz waveform files and the entire information state and
candidate attachements were logged  there were two domains tested  an mp  application
and a restaurant database selection  for a total of almost     user utterances 
for each user utterance only a single speech recognition is available  but this produces an
n best list of parses  and for each one of them multiple dialog move candidates are
considered  the objective of the attachment algorithm is to select the best possible dialog
move among all the candidates produced by all the parses in the n best list 
   results
the baseline system  b  simply takes the first  most likely  parse and selects the
attachment with the most recent parent node in the dmt  the default attachment
algorithm  d  is based on hand crafted techniques  described in section    
the machine learning approach  ml reorder  uses classification obtained from the
memory based learner timbl  for each potential candidate we associated a vector of
features  the ones from above  and also the supervised classification class
 correct incorrect   so for each user utterance  u  well have many candidate moves  m  
m     mk   all of which are incorrect except for the one we labeled as the correct one  we
always have one correct example  the best move based on the list of parses  we allow
attachment of error nodes if there is nothing else better   so this is done regardless of
correctness of the speech recognition 
baseline  b 
default  d 
ml reorder
ml reorder
correct incorrect correct incorrect correct incorrect correct incorrect
   
  
   
  
   
   
   
  
mp 
      
      
      
      
   
  
   
  
   
  
   
  
restaurant
      
      
      
      
the performance of ml reorder was on average worse than that of the baseline system 
this might be explained by the fact that only one candidate move in  m   m     mk  is
selected  while there might be several almost optimal ones  with feature vectors very
similar to the features of the one that should be selected  but which have incorrect labels 
this problem suggested a different representation of the training data  for each training
example  user utterance  we only consider the   best candidates produced by the default
d system  a vector of features consists of the set of features of the   five candidates
 simply concatenated  and the labeling class is the number of the instance  among these
   that is the correct one  in all cases the correct dialog move was among these   best
candidates and in cases in which we had less than   candidates we simply filled the
features vector with zeros  we call this system ml reorder and the performance  best
among all the systems  is reported in the last column of the table above  since we have
limited data  a leave one out crossvaliadation setup was used here 

 

fiperformance gain over the baseline comes from the fact that both d and ml reorder
manage to solve some parsing problems and re order the n best list of parses  most
frequent ones were pp attachments  a difficult challenge for statistical parses  and
nominal modifiers 
pp  attachment 
   how about  a restaurant  in grant      on mayfield  
   how about  a restaurant  in grant     on mayfield   

nominal modifier 
   how about  a    cheap   chinese   restaurant  
   how about  a   cheap     chinese   restaurant  

   conclusion and future work
the results so far seem quite encouraging  both d and ml reorder perform
significantly better than the baseline  while ml reorder obtains increases of       and
      over d in the two domains  performance in the restaurant domain is better because
topic classification is only available here and this tends to be an important feature 
the data sets used in these examples were rather small and other learners might be tested 
a difficult task so far  both for d and ml reorder  was disambiguating between
revision dialog moves  nodes that should attach to other previous user nodes  and nodes
that should create a new dialog thread  so far this problem was solved in the broader
context of generally selecting the best dialog move from the entire set of candidates  if
we restrict to training examples relevant to this task we should be able to apply an mlreorder algorithm efficiently  without having to increase the features vector size 
references 
   chotimongkol and a  rudnicky        nbest speech hypotheses reordering using
linear regression  in proceedings of the  th european conference on speech
communication and technology  eurospeech  
   m  gabsdil and o  lemon        combining acoustic and pragmatic features to
predict recognition performance in spoken dialogue systems  in proc    nd
annual meeting of the acl 
   c  manning  h  schutze        foundations of statistical natural language
processing 
   d  mirkovic and l  cavedon        practical plug and play dialogue
management  in proceedings of the annual meeting of the pacific association of
computational linguistics  pacling  
   l  cavedon  m  purver  f  ratiu        combining confidence scores with
contextual features for robust multi device dialogue 

 

fi