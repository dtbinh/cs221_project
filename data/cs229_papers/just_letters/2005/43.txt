simultaneous learning of a robot s gait and its body
dimensions and compliances
by alan asbeck and nick choo
overview
the goal of this project was to have a simulation simultaneously learn a robot s gait as well as
body dimensions and compliancesin essence  create a design through machine learning  can
we generate an optimal gait and body design instead of spending much time hand tuning these
parameters 
as a practical motivation  the robot used in the simulation was loosely modeled after an
actual robot  isprawl  created by sangbae kim in prof  mark cutkosky s lab in the mechanical
engineering department here at stanford  though some details of the simulation differed from the
actual robot  figure   shows pictures of the simulated and isprawl robots  originally  we
simulated a quadruped robot with three degrees of freedom per leg  including a knee joint  for a
total of    parameters  however  this was much too complicated for the simulation to learn good
parameters effectively  so we switched to this simpler robot 
the simulation was done using the arachi dynamics engine  arachi  inc   and rise
modeling environment used by the robotics in scansorial environments darpa project 

figure    pictures of the robot used in the simulation  on the left   and isprawl  on the right   the blue
block on the left of the simulated robot denotes the front and was massless 

simulation
the simulated robot consisted of an actuated piston joint and a passive hip joint in each leg
 see figure     it moves using an alternating tripod gait  the pistons in each tripod were driven in
a fixed sinusoidal pattern  with the two tripods     degrees out of phase  when each piston
extends  the leg rotates backwards about the hip joint  so the robot is driven upwards and
forwards  then  when the piston lifts the leg off the ground  the passive spring in the hip returns
the leg to its initial position 
in the simulation  the robot was constructed to be laterally symmetric  as isprawl is in real
life  this enabled the robot to go nearly straight for long distances  the robot had    parameters
that could be adjusted  the bias angle  position gain kp  and velocity gain kv for each of the three
pairs of hip joints  the position and velocity gains for each of the pistons  and the body length and
width  these are denoted in figure    the kp  kv terms control the spring constant and damping
for the hip angle and piston suspension 
t   kp   xdesired   x    kv  vdesired  v 

fiwhere t is the torque applied to the joint  x is the position of the joint  and v is the velocity of the
joint 

figure    parameters varied in the simulation 

the robots gait is controlled by these parameters because the mechanics of the actual gait are
tightly coupled to them  in the case of isprawl  the legs move very quickly and are all angled so
as to push backwards  leading the robot to move in a smooth motion  in these simulation results
 discussed below   the robot learned to move in more of a bounding motion  due to its low piston
frequency  in one gait  the rear and middle hip joints were angled so as to push the robot
backwards  functioning quite differently than the legs of isprawl 

algorithms
our learning algorithms are based on the idea that distance traveled is an  unknown  function f  
of a parameter vector  plus some stochastic noise  our reward function was chosen to be the
distance traveled in the forward direction  along the y axis   minus the lateral deviation from the
straight ahead path  the magnitude of the x coordinate   and we try to maximize this reward by
finding the maxima of f   over our parameter space  in both our methods of looking for the
optimal gait  we essentially iterate over the following operation on  

 i      arg max  f     
   i   i   

subject to  min     max

the first algorithm is a hill climbing algorithm  in which we try to have our parameter take a
step in a random direction  and evaluate its performance at that point 
the coordinate ascent algorithm instead considers each parameter  taking steps until the reward
function achieves close to a maximum in the particular parameter  and iterating through the
parameters until convergence  we also took smaller and smaller steps when the parameters
were close to a  possibly local  optimum 
each algorithm was run several times for random initial parameters  until convergence within a
specified tolerance  although several runs were stopped before convergence due to time
constraints 

figradient  hill climbing  method
begin with a random parameter vector
record the reward
repeat 

add a random  to    record the
reward 

if the reward of a step taken in the
new direction  is less than the old
reward  take a step in the other
direction 

update  only if reward increases  if
maxiter iterations have passed without
improvement  decrease step size 
report as convergent solution if step
size   minsize 

coordinate ascent method
begin with a random parameter vector
record the reward
repeat 

add a fixed step length j to j  
record the reward 

if the reward of a step taken in the
new direction j is less than the old
reward  take a step in the other
direction 

continue stepping until average
reward does not improve 

if all parameters have taken one
forward and one backward step
without improvement  decrease step
size  report as convergent solution if
step size   minsize 

issues
noisy reward
the first issue that we encountered in the simulation phase of the project was that there was a
high degree of noise in the reward obtained per trial  examining the variance of the reward over
different reward magnitudes suggested that the noise level is highly correlated with magnitude of
reward  this makes it difficult to determine whether a step actually improved the reward
especially in the latter part of runs 
to counter the effects of the noisy reward  we ran each trial between   to    usually   times  and
averaged the rewards  we also specified a tolerance based on the magnitude of the reward  and if
a reward gain was within this tolerance we would still step in this direction  but consider it a
no improvement step 
finally  we averaged the rewards over longer simulation trials  and let the robot run longer    
seconds  to reduce variances from initialization  robot legs are moving freely before we drop
the robot to the ground for each trial  
computational bottlenecks
the main problem that we faced in running the simulations was that simulations the simulations
took very long to run  in general     seconds of simulation time took      minutes of real time to
run  even with graphics turned off  with averaging  taking only    steps takes almost   hours 

results
simulations greatly increased the reward over a nave implementation with random
parametersthey were able to find a good parameter set even if the initial gait was moving in the
wrong direction  a plot of the rewards versus time for several runs is shown in figure    both the
hill climbing and coordinate ascent approaches worked well 

fifigure    rewards achieved by the robot as a function of time  this includes two simulations that had not
yet converged 

the final joint compliances and gaits found by the simulation varied  indicating that our
simulation frequently got stuck in local optima  however  several of the gaits converged to
nearly the same final reward  suggesting that this may be close to a global maximum 
furthermore  some joint compliances converged to very similar results across different
simulations  see figure     the piston compliances for the front hip converged to very similar
results  a very strong spring and low damping  this combination of parameters enables the leg to
push against the ground as strongly as possible  providing the greatest upwards forwards motion 
several other joint compliances also converged to reasonably similar results across simulations 
particularly the middle hip compliances and rear piston compliances  it is interesting to note that
the simulation that performed the best  the  in the plot  actually had parameters that deviated
significantly from the others in many cases 

figure    the plot above shows the final kp and kv values for various different simulations 

the hip angles found by the simulation varied widely  as shown in figure    this was a
surprising result since the hip angle was found to control the speed of the robot significantly in
laboratory experiments with isprawl  in the gait the simulated robot is executing  the hip angles
may not make much of a difference 

fithe body dimensions varied  but in almost all cases the body length was larger by a
factor of two than the body width  see figure     this result is similar to what intuition suggests 
that a long narrow body is optimal for facilitating the body to go in the straightest possible
direction  e g   the long narrow car bodies of drag racers  

figure    the left plot shows the final hip angles  and the bottom right plot shows the final body
dimensions 

conclusions
performance assessment
we found that hill climbing and coordinate ascent both do well  converging to similar rewards 
final gaits performed significantly better than with the initial parameters  one added benefit of
these algorithms  and partially the problem setup  is robustness  all our trials tended to converge
to high rewards even with very bad initial parameters  a qualitative analysis of the robot gaits
revealed that they tended to exhibit the tendency of bounding motions  most parameter values
seemed to converge to within a range  although there were several parameters in the obtained
gaits that varied greatly between gaits 
there are several caveats to the results obtained  the main issue is that we currently have no
theoretical upper bound on speed  and thus we cannot gauge how close the gaits are to the true
optimal gait for the specific contact model  although we suspect that the algorithms converged to
a close approximation of the true optimal gait  also we have not yet tested the parameters on the
real robot to determine whether our parameters really translate to a good gait in real life 
future work
one area for further work ahead is obtaining theoretical results on an upper bound for robot
speed  to get an idea of how close our solutions are to optimal  a useful experiment would be to
match simulation parameters to the actual isprawl robot  to compare the simulation performance
to actual performance on isprawl  finally  we plan to expand on this work by exploring other

possible algorithms for gait body dimensions and compliance optimization 

acknowledgements
we thank prof  mark cutkosky and the biomimetics lab for use of the lab resources in
performing these simulations  we also thank daniel santos and jonathan karpick for help with
the arachi simulator 

fi