    algorithm

fault tolerant distributed
random forests

current implementations of random forests
are sequential in nature  a forest of decision
trees independently train on a training set  all
running on a single processing element 
because each tree in the forest trains
independently from all other trees  random
forests is a strong candidate for
parallelization 

    background

random forests  is a classifier based on
classification trees constructed using an
algorithm developed by leo breiman and
adele cutler  this classifier trains a forest
of decision trees and performs classification
predictions by presenting an input vector to
each of the trained trees in the forest  and
taking the majority vote as determined by
the individual trees 

a large cluster collectively has enough
resources to accommodate most problems  but
resources are distributed amongst many
independent nodes  the data sets targeted for
classification by algorithms such as random
forests tend to be extremely large  and must
be distributed amongst all the working nodes
of the cluster 

    motivation
as the cost of commodity pc hardware and
network equipment drops  cluster computing
becomes ever more popular  if previously
sequential algorithms can be rewritten for
distributed implementation  one can benefit
from both reduced processing time  and the
ability to accommodate extremely large
working sets available today 

in the distributed implementation of random
forests  each cluster node is transferred an
equal subset of the whole training data set
from a source cluster node  each computing
node then trains a random forest cluster subforest on its training subset  after training 
the distributed random forest can accept
vectors for classification  an input vector is
presented to each nodes cluster sub forest 
and each sub forest returns with a vote  all
votes are communicated to a result node that
is responsible for tallying all incoming votes 
the majority vote is the classification result 

however  there are limitations to cluster
computing  network communication
becomes a severe bottleneck  and there always
exists the possibility of node failures within
the cluster 
the distributed random forests algorithm
presented here specifically targets
implementation in cluster environments and
attempts to accommodate the inherent
limitations and concerns of using cluster
hardware by presenting an algorithm with
sparse communication and fault tolerance 

while the training subset size can vary  each
computing node only trains on the subset
provided to it by the source cluster node 
computing nodes communicate only with the
source node and the result node  within this
framework  the majority of communication
occurs when transferring the training data
subsets to the computing nodes  and thereafter
all computing node communication is sparse 
either receiving input vectors from a source
node on the network  or sending its computed
vote to the result node which then computes
the final classification result 

 

random forests
 http   www stat berkeley edu users breiman randomf
orests  

 

fiand result nodes to partition and distribute
datasets  train sub forests  vote  and classify 

there are several advantages to the distributed
framework presented 

all experimental results presented are
obtained using a ten fold cross validation
scheme

fault tolerance is a large concern when using
commodity hardware in a cluster environment 
because computing nodes do not
communicate amongst each other  no single
computing node can become a source of
catastrophic failure for the cluster in the case
when a computing node either fails or
becomes unable to communicate 

parameters including training subset size 
number of classifiers  and number of trees per
classifier were varied to investigate their
effects on classification performance 
before dealing with subset size  we introduce
the concept of sample gain  given a
training set of size x  and a cluster with c
computing nodes  a training subset of size
x c  i e   the data set is equally distributed
amongst all the computing nodes   refers to a
sample gain of one  sample gain of g refers to
a training subset of size g x c  note that if
sample gain is greater than one  training
subsets will contain overlapping data 

in the typical case  the result node will await
responses from all computing nodes  but being
built for fault tolerance  the result node has a
built in time out device  this time out
counter  reset by an input vector arrival  will 
after a time out period  abandon waiting for
any nodes that have not yet returned their
votes  and compute the majority vote with the
tallied votes that have successfully arrived 
this feature can be tuned such that it will
abandon waiting for votes from nodes that
have either likely failed  or may be subject to
high latency network connections  in either
case  the behavior of the result node can be
tuned to suit the needs of the application 

data partitioning is performed as follows 
   the training dataset is first randomized 
and
   training subsets are then picked out
from the original training set in
contiguous blocks 

classification accuracy results presented will
show that the loss of some fraction of
computing node results will not critically
impact prediction accuracy as long as
sufficient nodes are in the cluster  adjusting
the subset size sent to each computing node is
a possibility to accommodate for node failure
within small cluster 

the training subset for the nth classifier  of c
classifiers  is a contiguous block of size g c
 where g sample gain  beginning  n   c  th
way down from the top of the source training
set  while treating the source training set as a
circular buffer  figure   shows an example of
data partitioning for   classifiers with sample
gain   

    methodology

note that with this partitioning scheme  those
training subsets with sample gain less or equal
to one are effectively picked without
replacement  and those with sample gain
greater than one  are effectively picked with
replacement because of the overlap of training
subsets 

a simulation of the distributed random
forests algorithm was implemented  along
with a cross validation framework  the
simulation implemented sequentially performs
the tasks of the source node  computing nodes 

 

fi 
a
randomized

we can draw two conclusions from this graph 
a  increasing the number of classifiers
while maintaining the same sample
gain is accompanied by a drop in
classification accuracy  basically 
reducing the classifier training subset
size is amenable to improving
execution speedup time  but is
accompanied by a drop in
classification accuracy 
b  however  increasing the sample gain
 possibly causing training subsets to be
drawn with replacement  increases
accuracy performance 

 
b

   
b a
   
b a

source training set

training subsets
with   classifiers
and sample gain  

figure    data partitioning example

specifically  we can see that while drawing
without replacement at sample gain equal to
one  there is some loss in classification
accuracy compared to the baseline  the single
classifier drawing with replacement from the
entire dataset   accuracy performance for the
    classifier case with sample gain of  
drops by      relative to the baseline  at
sample gain equal to      the accuracy
performance drops by       however  by
increasing the sample gain  accuracy
performance can be recovered by increasing
the sample gain  note  however  that once
sample gain exceeds    our data partitioning
scheme moves from sampling without
replacement  to sampling with replacement 

    results
data sets from the university of california
irvine machine learning repository were
used to validate our results  data sets
presented here relate to diabetes data     
data points    features  and forest cover type
data         data points     features  

    increasing training subset
size and speedup vs accuracy
figure   deals with uci training data relating
to forest cover  the results presented show
the sensitivity of accuracy performance as
sample gain and number of classifiers are
varied 

 

fiaccuracy

covtype          samples     features
    trees for each classifier
     
   

single
classifier

     
    
     

  
classifiers

    
     
    
     

  
classifiers
   
classifiers

    
     
 

   

 

   

 

   

 

   

 

   

 

sample gain

figure    accuracy vs  num of classifiers and sample gain  covtype data set

covtype         samples     features

single
classifier

   

accuracy

    
  trees per
classifier    
data

   

    
   tree per
classifier    
data

   
    

    trees per
classifier    
data

   
 

  

number of classifiers

   

    

figure    accuracy vs  num of classifiers  covtype data set
    trees per
classifier with
   data

diabetes       samples    feature
   

acc urac y

    

    trees per
classifier with
    data

   
    

    trees per
classifier with
    data

   
    
   
 

  

   
number of classifiers

figure    accuracy vs  num of classifiers  diabetes data set

 

    

    trees per
classifier with
    data

fi    conclusion

     accuracy plateau and
fault tolerance

the first major conclusion that can be made
from this study is that some loss in accuracy is
inevitable from parallelization  this loss in
accuracy is directly attributable to the data
partitioning  which causes each tree to be
exposed to only a subset of the data  this is
especially true when sampling without
replacement  we must qualify this result 
however  with the note that the loss in
accuracy is dependent on the actual data set 

figure   and   results show the effect of
varying the number of classifiers on accuracy
performance  we can draw two conclusions
from these graphs 
a  accuracy performance rises quickly
when raising the number of classifiers
while the number of classifiers is small 
and
b  as the number of classifiers increases
provided other variables are held
constant  accuracy performance
plateaus and stays approximately
constant

as a means to counteract the potential dropoff in accuracy  we showed that increasing
sample gain beyond could help in recovering
lost accuracy performance  we also note 
however  that this is a tradeoff  since
increasing sample gain results in increased
execution time 

it is the second observation stated that makes
this distributed implementation of the random
forests algorithm a good candidate for the
cluster environment where fault tolerance is
necessary  the algorithm is capable of
handling lost sub forest votes and maintains
prediction accuracy given a sufficient number
of initial classifiers 

accuracy performance rises quickly when
raising the number of classifiers while the
number of classifiers is small  and as the
number of classifiers increases  accuracy
performance plateaus and stays approximately
constant  making distributed random forests
a good candidate for cluster environments 
where fault tolerance is an asset  due to its
accuracy performances insensitivity to lost
sub forest votes when sufficient classifiers are
present 

beyond ten classifiers  accuracy performance
on the forest cover data set in figure   has
plateaued and stays approximately constant as
the number of classifiers increases into the
hundreds  suppose a cluster of hundreds of
classifiers are operating on the forest cover
data  and some computing nodes may have
either failed or do not return their votes within
a time out period  the result node responsible
for computing the majority vote may choose
not to include the votes of those computing
nodes in the final tally  however  given the
observation that accuracy performance
remains approximately constant for most
cluster configurations containing at least   
classifiers  one can expect that the effect of
losing a small number of sub forest votes on
accuracy performance will be negligible 

    acknowledgements
the authors would like to thank gary bradski
for his comments  suggestions  and continual
support throughout the quarter  without
garys mentorship  this project would not
have been possible 

 

fi