fraud detection for online retail using random forests
eric altendorf  peter brende  josh daniel  laurent lessard
abstract
as online commerce becomes more common 
fraud is an increasingly important concern  current anti fraud techniques include blacklists 
hand crafted rules  and review of individual
transactions by human experts  these methods
have achieved good results  but a significant
number of costly fraudulent transactions still
occur  and the fraud detection process is expensive due to its heavy reliance on human experts 
our goal is to improve the quality of fraud detection and decrease the need for costly human
analysis of individual transactions  we propose
two modifications to the approval process for an
online retailer based on a random forests classifier 

   introduction
we have obtained data from two sources  an
online retailer of computer equipment and peripherals  and quova  a provider of geolocation
data  the retail data consists of about        
records of orders placed online over a   month
span  currently  when the retailer receives an
order request  they decide whether to approve
the order and ship the goods using the decision
process illustrated in figure    the flow consists of a series of decision nodes 
   pre filter  rejects blacklist of bad customers 
bank rejections  avs  card address mismatch  
rejects        
   send to human  uses simple rules like contains ipod to decide whether to send order to
human analyst for review         to analyst 
        to accept 
   analyst  expert reviewer manually analyzes
orders and rejects based on likelihood of committing fraud  defaulting on credit  or returninproduct  reject       
all orders that are not rejected by the pre filter
or human expert are approved  of these     

were later reported as fraudulent by the credit
card holder 
the current process contains two sources of expense for the retailer that could be decreased
with the use of intelligent classifiers  first  at
the analyst node  human labor is used to review
individual orders  this labor is both slow and
expensive relative to automated systems 
second  of the orders that are passed to the accept node  a certain fraction are fraudulent  potentially  an intelligent classifier at this stage
could significantly reduce the number of fraudulent orders approved while only slightly increasing the number of valid orders that are rejected 
in section    we discuss the tradeoffs between a
high rate of fraud detection and mislabeling nonfraud instances 
therefore  we propose a new order review process for the retailer as illustrated in figure    essentially  we augment the existing system with
two additional decision nodes powered by intelligent classifiers 
   analyst simulator  either rejects  or sends to a
real human for review  as explained in section
   the analyst simulator does not accept orders
outright  to build a prototype for this classifier 
we train on the        items that were reviewed
by a human 
   fraud classifier  as a final step before approval  each order passes through our custom
fraud classifier  we build our model by training
on a set of approximately         orders  containing     fraudulent transactions  that were
approved by the current system   in section   
we deal with the issue of balancing fp and tp  

fiorders

orders

        

pre filter

       

pre filter

send to human 

        

send to human 

human simulator
dsimsimimulator
human
psimulator

       
       
     

human

      
     

fraud predictor

        

accept
            

fraud

reject

fraud

not fraud

figure    current infrastructure

   data sources
engineering

and

reject

accept

                

not fraud

figure    proposed infrastructure

feature

we obtained data from two primary sources 
first  a major online retailer of computer equipment and peripherals supplied us with        
records of orders placed over a   month span in
      which identify the customer  time date of
the order  items ordered  and credit card and
shipping information  these records also include the ip address from which the order was
placed  allowing us to supplement the orders
data with geolocation and network information
data obtained from quova  inc  this allows
us to determine  for each order  the continent 
country  state province  city  postal code of the
computer from which the order was placed  it
also provides information about the local network connection  modem  cable  isdn  dsl 
mobile wireless  etc   and the ip routing method
 anonymizers  proxies  mobile gateways  satellites   finally  it lets us determine information
about the network to which the user is attached
 the carriers name  such as stanford or comcast  whether or not the user is on the aol network  which geolocates all users to specific
aol office locations  and the domain name of
the users ip  

much of our time investment was on data preparation and intelligent feature engineering  a
process guided by our collaborators in the finance department at the retail company  they
helped us identify characteristics typical of users
placing fraudulent orders  who 





tend to be transient geographically
use non standard internet connections
exhibit unique patterns in purchase timing
purchase items that are easily resellable and
small in size

based on these ideas  we extracted a total of   
features  including









billing shipping address match
distances between location of network connection and billing and shipping addresses
indicator variables for specific products
indicator variables for both hot  e g   ipod 
ipaq  handheld computer  and cold  e g 
printers  cables  keywords occuring in item
descriptions
item cost per weight
indicator variables for time of day and dayof week
credit card history  number of recent orders 
cumulative recent charges

in addition  we have some international orders 
but probably too few to learn probabilities of
fraud from each of over     countries  therefore  we omit country identity and instead sub 

fistitute demographic and socioeconomic statistics
obtained from the cia world factbook  such as
number of internet connections and telephones 
average income  and unemployment rate 

for both analyst and fraud problems  we trained
the random forest classifier on the first     of
our dataset and used the remaining     for
validation 

   random forests

for each validation sample  the regression model
returns a response y between    indicating the
positive class  and    negative class  

random forests is an algorithm for classification and regression  breiman        briefly  it
is an ensemble of decision tree classifiers  the
output of the random forest classifier is the majority vote amongst the set of tree classifiers  to
train each tree  a subset of the full training set is
sampled randomly  then  a decision tree is built
in the normal way  except that no pruning is
done and each node splits on a feature selected
from a random subset of the full feature set 
training is fast  even for large data sets with
many features and data instances  because each
tree is trained independently of the others  the
random forest algorithm has been found to be
resistant to overfitting and provides a good estimate of the generalization error  without having
to do cross validation  through the out of bag
error rate that it returns 
our data sets are quite imbalanced  which in
general  can lead to problems during the learning
process  several approaches have been proposed to deal with imbalance in the context of
random forests including resampling techniques  and cost based optimization  chen  et 
al        
we take a different approach  using regression
forests and classifying based on an adjustable
threshold  by changing the threshold level  we
create a set of classifiers  h  each of which has a
different false positive  fp  and true positive
 tp  rate  the tradeoff between the fp and tp
rates is captured in the standard roc curve  see 
for example  figures   and    

in figure    we show a histogram of these responses for the analyst problem  note that about
half of the rejected samples are easy to classify 

easy to classify

figure    response distribution for analyst

almost all nonfraud cases are
easily separated

   experiments and results
for our experiments we worked with the
openml  machine learning  library developed
by intel  corp 
we specified the maximum number of features
to be considered at each tree node to be   and
the out of bag sampling rate as     

figure    response distribution for fraud
for the fraud problem  the response histogram
 figure    looks quite different  non fraud
cases appear to be highly distinguishable 

fisince fraud cases are very rare  only     cases
out of           we have to be careful about
picking operating points on the roc curve  figure     if we zoom in near fp      we see that
the probability isnt actually zero  and this has
consequences 

   optimizing the decision threshold
to select an appropriate threshold value and  in
turn  a classifier  we must specify some objective in the problem  in this problem  our success
can be measured by the net change in expected
profit 

if we knew the cost of human analysis  per order
reviewed  and the cost of a false positives  the
profit we would make from the transaction   it
would be straightforward to tradeoff the threshold parameter and find the policy that maximizes
profit as described in section   
notice  however  see figure     that a moderate
tp rate can be achieved while maintaining a fp
close to zero  this means that we can easily
choose a decision boundary which will reliably
pre reject a sizeable portion of the samples
without needing the intervention of a human
analyst 

in general  if we can assign some cost to each
false positive and to each true positive  it is possible to choose amongst the set  h  of classifiers
 described above   letting p  and p  be the prior
probabilities for classes   and    and c  and c 
the respective misclassification costs  our objective is defined as 

f   p  fpc    p       tp  c 
  p  fpc    p       g   fp   c   
where g    specifies the roc curve

safe threshold

 f
  p  c    p c  g    fp  
 fp
setting this to zero  we get 

g  fp   

c   p 
c  p 

the optimal classifier corresponds to the point
on the roc curve where the slope is equal to a
ratio involving the prior probabilities for the two
 
classes and the two costs 

the analyst simulator problem
for the analyst simulator problem  the difficulty lies in assigning costs to the two types of
classification errors  since this  classification 
problem occurs far upstream in the retailers
approval process  the costs and benefits of each
type of error can only be accurately determined
by doing a controlled experiment  that is  by approving certain orders that would normally be
rejected  and observing the outcome 

figure    roc for analyst problem
we propose  as a conservative policy  to only
pre reject cases for which we are virtually certain there will be no false positives  from the
roc plot  this corresponds to     on the tp
axis  if we take the prior probability of rejection
into account  we can expect to pre filter     
           of the samples sent to the analyst 

the fraud prediction problem
suppose we wanted to detect     of the fraudulent cases  this would cause a      fp rate 
taking prior probability into account  we can
expect to reject     fraudulent transactions at
the expense of also rejecting     legitimate ones
 over the entire data set  

fi    say  we would obtain very good tp and fp
rates 

            

figure    roc for fraud
generally  allowing a fraudulent purchase costs
the retailer the full price of the item  while denying a legitimate purchase only results in a loss
equal to the profit margin  so in the example
above  our classifier will save the retailer money
under the reasonable assumption that the profit
margin on items is less than     
as in the analyst case  knowing our exact profit
margin will allow us to design a more aggressive
policy  the retailer simply needs to pinpoint the
average cost of a fraudulent order and the average profit margin on items sold  then  using the
procedure described above  we pick the point on
the roc curve that optimizes expected misclassification cost 

   discussion
cascades of classifiers are a popular method of
dealing with rare event detection  see  for instance  viola and jones        wu  et al         
the main assumption is that we can train n independent classifiers all with a very high  say 
       tp rate and medium  say       fp rate 
then  by requiring all n classifiers to agree on a
positive detection  we can reduce the fp rate to
   n  while retaining a tp rate of      n  for n  

one popular application of cascades is the face
detection image processing problem  in face detection  non face images are quite diverse  this
makes it easy to enforce independence of the
cascade nodes  all we have to do is design a
long chain of classifiers where each one specializes in rejecting a particular type of non face
object with a near perfect tp rate  the question
is  can we always enforce the independence of
the classifiers  
for the fraud problem  we suspect not  although
it is a rare event detection problem  it is fundamentally different from the face detection problem  as we have seen from the roc  most nonfraud cases look similar and are easily identified 
therefore  training on subsets of the non fraud
data would not generate independent classifiers
and we would not reap the benefit of exponentially decreasing errors 
a standard cascade will not work with the analyst problem either  the roc plot shows it is not
possible to obtain the needed high tp and moderate fp  we do  however  have points on the
roc with very low fp rates  we believe it
should be possible to build an inverted cascade which exploits this roc shape by requiring all classifiers in the cascade to agree on a
negative detection 
we would like to thank dr  gary bradski at intel
research for his valuable help and advice 

   references
breiman  leo          random forests   machine learning              
chao chen  andy liaw and leo breiman
        using random forest to learn imbalanced data 
paul a viola  michael j  jones        rapid
object detection using a boosted cascade of
simple features  cvpr            
jianxin wu  matthew d  mullin  james m 
rehg         linear asymmetric classifier for
cascade detectors  icml pages          

fi