cs    

stay alert  the ford challenge
louis fourrier
fabien gaie
thomas rolf

   problem description
a  goal
our final project is a recent kaggle
competition submitted by ford whose goal is
to design a binary classifier to detect whether
a driver is alert or not  driving while being
distracted  fatigued or drowsy may lead to
accidents  solving this problem may
eventually save lives and is thus a great
application of machine learning 
b  dataset overview
ford provided a combination of vehicular 
environmental and driver physiological data
acquired in real time while driving  these
different features do not have any name
indicating what they represent  which adds to
the complexity of the problem since we
cannot rely on physical intuition 

louis fourrier
fabien gaie
thomas rolf

impact and the different correlations  we
completed this first analysis with some useful
metrics 
 mean and variance of each feature
distribution
 raw estimation of how far from a
gaussian the distribution is  based on
kurtosis and skewness 
 mutual information between each feature
and the output labels
in order to run our algorithms we split our
data into a training        and a test set
        it is worth noticing that the data
provided are unbalanced since there are more
positive labels than negative labels  this is an
important point to note since it often affects
the learning algorithm behavior 
b  generation of new features

the dataset consists of a number of  trials  
each one representing about   minutes of
sequential data that are recorded every     ms
during a driving session  the trials are
samples from some     drivers and   
different features are recorded  the overall
dataset is a        x   matrix with the
associated labels 

need for new features 
the first attempts we made relied on the   
features provided by the original dataset and
our algorithms performed very poorly  thus
we decided to generate new features for
algorithms such as naive bayes and logistic
regression  which do not handle a kernel
trick easily 

   methodology

method to generate new features 
we generated some additional features by
combining existing features into new ones
and making some mathematical operations on
existing features 
 added the inverse  the square and the
cube of every features    xi  xi   xi  

a  data analysis
we started by plotting the probability density
functions of the features in both alert and
non alert cases to quickly get a grasp of the

fall     

cs      machine learning  final report

 

fi added all the combination of   columns
 
 
 generated time intervals variable  mainly
and
  
 suppressed   original features that
proved to be useless since they remain
constant for every row 
this resulted in a total of approximately    
features from an initial    feature dataset  it
enabled us to capture more patterns when we
implemented our algorithms on this enhanced
set of features 
shuffling our data or not 
we considered randomly shuffling our dataset
at first  however this proved to be dangerous
for our model because it resulted in splitting
data from the same user in both the training
and test sets  thus artificially improving the
accuracy and auc results  the time
sequencing of the data was also lost by this
shuffling 
we finally decided to split our users into a
test and a training set first  then compute the
time varying features and finally shuffle data
before running our algorithms 
c  evaluation criteria
in order to assess our algorithms we mainly
used two types of evaluation criteria 
 the accuracy of our algorithm
 equivalently the training and testing
errors  
 the area under the curve  auc  
computed as the area under the roc
 receiver operating characteristic  curve 
this criterion is insensitive to unbalanced
dataset and it does not require defining a
specific threshold for the decision
boundary  this metric is closely related
to the true positive rate  tpr  and false
positive rate  fpr  

figure    roc curve obtained by logistic regression 
the area under the curve is       

throughout our project  we ran algorithms
using both evaluation criteria  we mainly
present results using the accuracy since it gave
us satisfying overall results and it allowed us
to compare the performances of all our
algorithms  we kept track of the auc as a
control metric and both the accuracy and the
auc improved as our algorithms got better 

   feature selection 
seeing the initial results and after generating
new features  we had to filter the best features
out to reduce the noise and implement more
efficient algorithms 
a  mutual information
our first method to select features was to use
mutual information on the initial features 
the five best features were      
and
 
we were surprised by the fact that none of
the physiological features was selected so we
decided to implement forward searches on
different algorithms 
b  forward search
we performed two different forward search
procedures maximizing our two different
evaluation criteria   the accuracy and the

fall     

cs      machine learning  final report

 

fiauc  the selected features varied with the
algorithm and the evaluation criteria 

naive
bayes
logistic
regression
svm

allowed
features
       
 

allowed features
   
 
 

 

 

 
 
 

 
 
 

 

 

 

 

 
 

 

 

 

 

 
figure    five best features obtained from forward
search in naive bayes  logistic regression and svm
algorithms 

the selected best features by the forward
search procedures varied with the algorithm
so that there is no ultimate feature set  note
that some features that we already captured
with the mutual information like
and
appear several times in the table  when
checking against the distribution of such
features  we can see that they are indeed
helpful separating the data into both labels 

multinomial nave bayes with laplace
smoothing 
we discretized all the input data by dividing
each feature into a predetermined number of
buckets before computing the multinomial
probabilities with laplace smoothing  the
number of buckets had a big impact on the
performance of the algorithm with a
maximum around     buckets  too many
buckets proved to be inefficient since it could
not capture the distribution properly and led
to random probabilities 
naive bayes with gaussian distribution
fitting 
we modeled each distribution as a gaussian
distribution which is a strong assumption for
some features but gave surprisingly good
results thanks to the forward search
procedure 
these good results can be explained by the
fact that some of the feature distributions are
close to gaussian distributions 
b  logistic regression
to begin with  we implemented logistic
regression algorithms with both batch and
stochastic gradient descent  while the batch
gradient descent always converged  the
stochastic one sometimes did not  we then
leveraged matlab optimized version of the
logistic regression to have faster algorithms 
after insuring that the results were consistent
with our own algorithms results 

figure    plot of the distribution of feature
alert and non alert cases 

in both

   learning algorithms
a  nave bayes

the logistic regression model enabled us to
easily compute the auc since we could
output the probability of the label being   or
  and sample the roc curve by varying the
decision threshold  we used this method to
optimize on the auc for one of our forward
search experiment 

we implemented naive bayes algorithms
with two different underlying models
assuming that features were conditionally
independent given the alertness of the driver 

fall     

cs      machine learning  final report

 

fic  svm

accuracy

we implemented a svm algorithm with both
linear and nonlinear kernels using liblinear
and libsvm libraries for matlab 
first  the svm with linear kernel applied to
the    initial features gave a coherent
accuracy of      in order to work in a higher
dimensional space  we implemented a svm
with gaussian kernel but it did not converge
in a reasonable time  we then tried to
implement the linear kernel on the enhanced
dataset with our additional features but faced
the same issue  therefore  we decided to
implement a forward search to limit the
number of features and prevent the algorithm
to diverge  it turned out that choosing more
than    features did not provide significant
improvements 
we maximized the accuracy while varying the
svm parameter c between     and      we
noticed that c had little impact on the svm
accuracy and finally let c be   

tpr

fpr

auc

multinomial
nave bayes
gaussian
nave bayes
logistic
regression
svm
figure    performances of algorithm on initial dataset 

these insufficient results were the reason for
both the generation of additional features to
capture better correlations and the selection
of best features among this enhanced dataset 
results with mutual information features 
selected
accuracy
auc
features
     
depending
 
on the algorithm
figure    performances of algorithms applied to the
five best features from the mutual information 

the performances displayed above were a
good start given the small number of features
but encouraged us to implement forward
search algorithms 
results with best selected features from
forward search 
the forward search procedures we used with
each algorithm gave us the best results with
the features described in the previous section 
accuracy  in   
figure    influence of the parameter c of the svm on
the error 

d  results
results with basic    features 
our first step was to run our three algorithms
on the initial dataset of    features 
number of features in the forward search

fall     

cs      machine learning  final report

 

fiaccuracy
nave bayes
logistic
regression
svm  linear
kernel 

tpr

fpr

auc

 

figure    accuracy evolution during the forward search
 plot  and final performances of the algorithms  table  

out of the algorithm we implemented  the
nave bayes with gaussian distribution
fitting is clearly the most accurate one  the
nave bayes and the svm have lower
performances  the unsatisfying result of the
svm is due to the only linear kernel 
from an initial dataset of    features  we
created around     features before selecting
only ten of them while significantly increasing
the accuracy  a few features only therefore
provided a good predictive power 

   conclusion
the best features strongly depend on the
algorithm used to predict the alertness of the
driver  the set of selected features is always a
combination of vehicular  physiological and
environmental features  which seems
reasonable to capture the maximum
information about the driving situation 
our best results were obtained with a nave
bayes algorithm and such a set of features  to
further improve these results  we are
considering a random tree forest algorithm 

fall     

cs      machine learning  final report

 

fi