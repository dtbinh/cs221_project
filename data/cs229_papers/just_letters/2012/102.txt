elmer  le
quentin  moy
jerry  zhou
fall        cs     final  project
  
predicting  music  tags  from  lyrics
  
    abstract
  
currently   many  music  applications  allow  users  to  associate  each  song  with  a  set  of  arbitrary  words   
colloquially  called  tags   tags  often  describe  the  songs  genre   but  can  also  be  any  other  attribute  the  
user  desires   one  common  application  with  genre  tags  is  to  find  other  songs  with  similar  tags  to  
generate  a  list  of  user specific  recommendations   however   we  noticed  a  potential  shortcoming  of  
the  current  tag  system   since  all  tags  are  user defined   they  are  prone  to  user  error  and  subjectivity   
this  raises  the  question   is  there  a  better  way  to  generate  tags   this  project  explores  ways  to  work  
around  user  error   is  it  possible  to  predict  a  songs  appropriate  tags  given  the  features  of  the  song  
itself   in  particular   we  try  to  utilize  a  songs  lyrics  to  predict  its  tags 
  
    introduction
  
for  this  project   we  first  picked  out  a  small  list  of  frequently  applied  song  tags   rock   love   pop   
alternative   to  examine   then   for  each  selected  tag   we  built  a  classifier  by  retrieving  training  
examples   each  composed  of  a  songs  word  counts  and  its  associated  tags   to  test  the  classifier   we  
reserved  another  set  of  word  counts   and  used  our  classifier  to  predict  whether  or  not  an  example  
should  belong  to  each  tag  in  our  list   finally   we  determined  accuracies  by  comparing  the  
predictions  to  their  known  tags  in  the  database   previously   some  other  studies          have  also  tried  
to  predict  music  tags  using  other  features   like  actual  audio  clips   they  achieve  roughly           
accuracy 
  
    data
  
for  data  sets   we  used  the  publicly  available   and  legally  produced   million  song  dataset      msd    a  
large  conglomeration  of  music  data  of             modern  songs   it  contains  several  large  datasets  of  
song  lyrics   tags   artists   and  several  other  attributes  that  are  unrelated  to  our  investigation   the  
lyrical  information  is  already  tabulated   so  we  were  only  given  word  counts  for  the        most  
common  words  that  appear  in  the  songs   as  a  result   we  were  unable  to  examine  fluency   sequences  
of  words   in  this  exploration   the  raw  data  is  downloadable  in  sqlite  databases   from  which  we  
extracted  data  with  python  and  matlab  libraries 
    analysis
  
in  order  to  predict  tags   we  trained  four  binary  classifiers  that  would  distinguish  between  having  
and  not  having  a  given  tag   given  a  list  of  word  counts  and  their  associated  tags   we  used  nave  

fibayes   logistic  regression   random  forest   and  svm  algorithms  to  construct  the  classifiers   in  all  
cases   one  training  examples  was  the  list  of  word  counts  for  one  song   so  the  set  of  training  
examples  would  be  a  large  set  of  word  counts  for  many  songs   the  output  was  whether  or  not  the  
song  had  the  given  tag   note  that   as  mentioned  above   the  data  set  only  has  word  counts  for  the  
      most  common  words   which  in  most  cases  is  enough  to  cover  the  entire  song   but  not  always 
  
 a   svm
  
we  first  elected  to  use  an  svm  two class  classifier   compared  to  other  methods   support  vector  
machines  make  few  assumptions  about  our  data  and  provide  theoretical  performance  guarantees   
as  a  tradeoff   the  computation  speed  is  highly  degraded  for  large  feature  sets   thus   we  chose  to  
only  use       of  the  most  common  lyrics  as  our  features   and        training  samples   three  classes  of  
kernels   linear   quadratic  and  rbf   were  tested  using  the  smo  algorithm  and  all  provided  similar  
results   below  is  a  table  of  accuracies  for  several  sample  tags 
  
tag

rock

pop

alternative

love

linear  svm  accuracy

   

   

   

   

poly  svm  accuracy

   

   

   

   

rbf  svm  accuracy

   

   

   

   

  
  for  our  data   a  linear  kernel  performed  the  best  and  also  avoided  the  problems  of  overfitting  and  
overly  long  computation  times   this  likely  suggests  that  the  relationship  between  our  set  of  lyrics  to  
tags    is  closer  to  linear   
 b   nave  bayes
for  our  naive  bayes  classifier   we  experimented  with  using  different  sets  of  words  as  our  features   
as  well  as  different  size  training  sets  to  find  what  would  be  most  effective  in  determining  tags   the  
original  data  set  contains  word  counts  for  the        most  common  words  across  all  songs   but  many  
of  these  words  actually  had  very  few  occurrences  in  our  database   so  we  experimented  with  using  
only  the  more  common  words  in  our  classifier   as  can  be  seen  from  the  left  graph  below   which  
used  a  constant  of        training  examples    our  accuracy  was  generally  constant  until  we  got  down  
to  a  very  low  number  of  words   meaning  that  the  less  common  words  did  not  increase  our  accuracy  
significantly   we  also  experimented  with  the  number  of  training  examples  that  we  used  going  from  
    songs  all  the  way  up  to         with        words  as  features    as  can  be  seen  by  the  graph   
increasing  our  training  size  generally  increased  our  accuracy  up  to  around        training  examples   
following  the  parameter  selection  graphs  is  a  table  of  average  accuracies  for  our  tags   calculated  
with        words  and        training 
    
  

fitag

rock

pop

alternative

love

accuracy

   

   

   

   

  
 c   logistic  regression
  
for  a  given  weight  vector  w  and  feature  vector   x    logistic  regression  uses  the  logistic  function  

 
   e w  x  
to  predict  a  binary  label   in  our  implementation  of  logistic  regression   due  to  large  training  set  and  
feature  vector  sizes   we  used  stochastic  gradient  descent  to  optimize  our  weights  iteratively 



w w 

s
 loss x      
t

where  w  is  the  feature  vector   t  is  the  iteration  of  the  current  step  of  stochastic  descent     is  the  
reduction   to  help  it  converge  faster    s  is  the  initial  step  size   and   loss x  is  the  gradient  of  the  

logistic  loss  function   the  first  step  was  to  select  values  for  these  parameters   as  well  as  the  number  
of  training  examples   given  that  we  had  enough  data  to  have  large  training  sets  
 and  still  have  test  
data   we  optimized  parameters  by  varying  one  parameter  while  holding  others  constant   running  

the  algorithm  using  the  different  values   and  selecting  the  one  with  the  best  test  accuracy    granted   
the  general  tactic  for  this  is  to  use  cross validation  to  avoid  overfitting  to  training  data  and  
mistakenly  choosing  the  most  overfit  model   however   since  we  chose  parameters  based  on  test  
accuracy   this  should  not  be  a  problem    for  the  sake  of  space   we  omit  graphs  of  tuning  parameters 
we  tried  to  reduce  the  number  of  features  in  the  feature  vector  by  selecting  the  most  significant  
features  using  forward  search   however   due  to  technical  limitations   it  took  impractically  long  to  
run        iterations  of  gradient  descent  per  feature    we  opted  to  stick  to  our  overall  feature  vector   
another  technique  we  used  to  improve  our  feature  vector  was  to  exclude  all  words  with     or  fewer  
letters   this  proved  effective   increasing  accuracy  by  several  percentage  points 

fiwe  also  experimented  with  regularizing  our  weights  to  prevent  overfitting   but  given  that  training  
and  test  accuracies  were  fairly  close  and  regularization  slows  the  algorithm  down  by  several  times   
we  chose  not  to  use  it   in  the  end   we  ran  with        training  examples   an  initial  step  size  of      with  
a  reduction  of       and      iterations  of  descent   again   to  prevent  the  algorithm  from  running  
impractically  long    
  
tag

rock

pop

alternative

love

accuracy

   

     

     

   

  
 d   random  forest
the  random  forest  algorithm  is  based  on  a  majority vote  among  many  decision  trees   for  t  decision  
trees   each  one  has  n  nodes   and  we  randomly  choose  s  training  examples   which  we  use  to  train  
that  tree   for  each  node   we  randomly  choose  a  set  of  f  features  to  use  to  construct  the  decision  at  
that  node   all  trees  are  constructed  in  this  way   to  test   we  take  the  test  data   evaluate  the  result  of  
each  decision  tree   and  in  the  case  of  a  binary  classifier   take  the  majority  vote  among  all  trees   in  
the  case  of  multi class  problem   the  output  is  the  mode  of  all  trees    
we  experimented  with  different  numbers  of  trees  and  different  numbers  of  features  per  tree  in  
addition  to  the  number  of  words  when  tuning  our  parameters  for  random  forest     testing  across  
different  sets  of  features  gave  similar  results  to  changing  the  set  of  features  when  using  naive  bayes  
in  that  having  too  few  words  resulted  in  a  less  accurate  algorithm   but  past  around       words  the  
accuracies  were  generally  pretty  constant   increasing  our  number  of  trees  increased  our  accuracy  
up  to  around      trees   while  increasing  our  number  of  features  didnt  have  a  very  large  effect  on  
our  accuracy  except  for  in  the  case  of     feature  per  tree   below  is  a  table  of  our  average  accuracies  
for  random  forest  with        words        trees  and      features  per  tree 

fitag

rock

pop

alternative

love

accuracy

   

   

   

   

    results  and  discussion
  
of  our  four  implementations   logistic  regression  performed  the  best   achieving  over       accuracy   
previous  studies        get  around       to       accuracy  by  analyzing  other  features  like  the  sound  
file  itself   so  our  regression  seems  like  a  significant  improvement   our  other  three  algorithms  
scored  in  the  same  ballpark  as  the  previous  studies   the  inaccuracy  can  partially  be  explained  by  
the  nature  of  the  data  itself   tags  are   by  definition   all  user generated   there  is  no  notion  of  an  
objectively  correct  tag   thus   there  is  potential  for  noise  to  be  present  in  all  of  our  test  and  
training  data   increasing  training  size  can  mitigate  this  problem  slightly   but  cannot  solve  it  entirely   
in  addition   due  to  the  creative  nature  of  music  itself   lyrics  themselves  are  also  extremely  variable 
  
further  developing  tag  prediction  would  probably  need  a  more  holistic  view  of  songs  that  takes  
more  complex  factors  into  account   such  as  the  songs  tempo  or  volume   while  it  would  also  be  ideal  
to  have  a  data  set  with  objectively  correct  tags   such  a  dataset  likely  does  not  exist  due  to  the  
nature  of  the  tagging  feature   another  approach  could  be  using  unsupervised  techniques  such  as  k 
means  clustering  on  song  lyrics  and  generating  our  own  tags  from  the  top  terms  of  each  cluster 
  
    references
  
                       michael  mandel  and  daniel  ellis   multiple instance  learning  for  music  information  
retrieval   in  content based  retrieval   categorization   and  similarity   ismir                   
http   www ee columbia edu  dpwe pubs mandele   mimusic pdf
  
                       douglas  eck   paul  lamere   thierry  bertin mahieux   and  stephen  green   automatic  
generation  of  social  tags  for  music  recommendation          
http   www iro umontreal ca  eckdoug papers      nips pdf
  
                       thierry  bertin mahieux   daniel  p w   ellis   brian  whitman   and  paul  lamere     the  million  
song  dataset   in  proceedings  of  the    th  international  society  for  music  information  
retrieval  conference   ismir                 http   labrosa ee columbia edu millionsong 
  
  

fi