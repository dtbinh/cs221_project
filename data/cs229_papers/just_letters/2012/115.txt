detection of myers  briggs type indicator via text
based computer mediated communication
dan brinks  hugh white
department of electrical engineering
stanford university
palo alto  ca
 dbrinks  hwhite  stanford edu

abstract in this paper various algorithms for detecting
myers briggs type indicator based on brief samples of an
individuals text communication from the web site twitter are
explored  these algorithms are trained using almost sevenhundred thousand tweets from four thousand six hundred
unique users who have indicated their mbti results 
keywords mbti  myers briggs  twitter  nlp  nave bayes

introduction
the myers briggs type indicator  mbti  is a
psychometric assessment that describes preferences for
recharging 
understanding
information 
making
decisions  and resolving issues  it is widely used to help
people understand themselves  co operate effectively
with others  and present information persuasively 
personality assessment is also increasingly being used in
marketing campaigns  having been used even in the     
elections      the mbti assessment uses a    question
multiple choice test to determine personality type 
results of this assessment are confidential between the
individual and the administrator  however  as mbti
makes predictions about how an individual
communicates  it is possible for a trained analyst to
examine samples of a subjects written communications
and determine the subjects mbti with a certain degree
of accuracy  the aim of this project is to develop a
computer system that can perform the function of the
trained human analyst by predicting mbti based on text
communication 
i 

data set
while mbti results are confidential  many
individuals who have taken the assessment openly reveal
their myers briggs type in a variety of ways including
twitter  for instance  a twitter search of  infp finds
tweets such as this  i just reread the meyers briggs
description of my  infp personality type  its scaryaccurate  while not all tweets tagged with a myersbriggs four letter personality type are authored by an
individual of that personality type  it is a reasonable
assumption that the majority of them are  a python script
ii 

utilizing the twitter api was used to search for tweets
including a myers briggs type  mbt  abbreviation  the
username and mbt were recorded  resulting in a list of
      users labeled with an mbt  then  another python
script retrieved the last two hundred tweets for each of
the labeled users  because twitter throttles the number of
requests per hour  these scripts were run automatically
for five weeks  this produced a set of         tweets 
each labeled by mbt 

data set breakdown
users by type

users aggregated by spectrum

type count percentage

enfj
esfp
infj
isfp
entj
estj
intj
istp
entp
estp
intp
esfj

   
   
   
   
   
   
   
   
   
  
   
   

    
    
     
    
    
    
     
    
    
    
    
    

isfj
enfp
istj
infp
total

   
   
   
   
    

    
    
    
    
      

table i 

spectrum

count

e vs i
n vs s
t vs f
p vs j

         
           
           
           

percentage

   
   
   
   

     
     
     
     

tweets aggregated by spectrum
spectrum

count

e vs i
n vs s
t vs f
p vs j

               
               
               
               

percentage

   
   
   
   

     
     
     
     

data set breakdown by label and
sprectrum

iii 

preprocessing

initial inspection of the data revealed one potential
issue  many of the users labeled intp were not
referencing their mbt  instead  they had simply
misspelled into  by retaining only users who
hashtagged an mbt or capitalized the entire mbt     

cla

fiof intps and     of all users were eliminated 
inspection of the data confirmed this filtering functioned
as intended  in addition  any user whose labeling tweet
contained two or more different mbts was rejected 
next  all numbers  links    user   and mbts   were
replaced with number  url  at user  and
mbt  in addition  all contractions were replaced by
their expanded form  and all words were converted to
lowercase  each tweet was tokenized using the natural
language toolkit  nltk 
python library
wordpuncttokenizer  finally  all of a users tweets were
aggregated into a single text block 
processing parameterization
several further processing steps were implemented
and selectively applied  this enabled the optimum
processing parameters to be determined by running every
combination and measuring the results  the optional
processing steps were as follows 
iv 

   porter stemming 
   emoticon substitution  emoticons were reduced
to one of four categories  smiley 
frown  wink  or laugh 
   minimum token frequency  any token
occurring with a frequency less than the
specified value was rejected 
   minimum user frequency  any token used by
less than the specified fraction of user was
rejected 
  

term frequency transform  only relevant for
mnemnb   the frequency of terms by each
user was transformed by a log     f  factor  to
decrease the effects of heavy tail which occurs

in text  as per     
   inverse document frequency transform  only
relevant for mnemnb   the weight of terms
was discounted by their document frequency as
per     
algorithm development
the initial algorithm employed the nave bayes
classifier provided by the nltk  which uses the multivariate bernoulli event model  it was discovered that this
classifier yielded poor test results as classification
accuracy was worse than the prior distribution  even the
training results were only on par with the prior
expectation  analysis showed that the classifier was
almost universally making its decisions based on the
number of words retained for each user  for instance 
one test showed that the average number of tokens for a
user chosen to be an extrovert was forty three  while the
average number of tokens for chosen introverts was over
three hundred  this shortcoming is a result of the
calculations performed by the multi variate bernoulli
event model  that providing more features for a label to
the algorithm increases the probability of that label
being selected 
to combat the issues inherent in the multi variate
event model  a multinomial event model classifier was
written since nltk provides no such functionality  this
classifier avoided the selection dichotomy based on
number of tokens and therefore improved performance
to a level roughly on par with the prior distributions 
however  the training accuracy had improved to a level
well above the priors which indicates that the classifier
was functioning nominally  in order to improve
performance  the variance between training and testing
was addressed 
v 

training accuracy by classifier
classifier
multinomial event model naive bayes
l  regularized logistic regression  primal 
l  regularized l  loss sv classification  dual 
l  regularized l  loss sv classification  primal 
l  regularized l  loss sv classification  dual 
sv classification by crammer and singer
l  regularized l  loss sv classification
l  regularized logistic regression
l  regularized logistic regression  dual 
 

leaving the mbts unmodified caused the classifiers to
perform significantly better  but the authors felt this enabled
the classifiers to cheat  and thus should be disallowed 

e vs i
     
     
     
     
     
      
      
     
      
table ii 

n vs s
     
     
     
     
     
      
      
     
      

t vs f
     
      
     
     
     
      
      
     
      

p vs j
     
     
     
     
     
      
      
     
      

training accuracy by classifer

fithe first solution to a high variance problem is more
data  unfortunately  twitter places a cap on data
retrieval requests  and only a limited number of users
tweet their mbti information  this meant that the only
way to acquire more data was to give the twitter
scraping scripts more time to do their work  however 
even after tripling the number of collected tweets 
performance remained constant 
another solution to high variance is decreasing the
feature set size  by modifying the preprocessing steps  a
parameterized number of features could be fed to the
classifier in order to determine the optimal number of
features  additionally  several transforms detailed in    
were added to the classifier in hopes of improving the
performance  furthermore  the algorithm was modified
to use confidence metrics in its classification and
instructed to only make a determination for users about
which it had a strong degree of certainty  this yielded
significant improvements to training accuracy
 sometimes above        ultimately  however  none of
these options improved testing behavior to any
significant degree 
to verify the accuracy of the multinomial event
model classifier  svm and logistic regression classifiers
provided by liblinear    were employed  these
classifiers suffered similar issues to nave bayes
relatively high training accuracy but low test accuracy
across a broad range of tokenizing and feature set size
parameterization 
results
once processed  the data was fed into multiple
classifiers  the performance of each classifier was
measured using       hold out cross validation  a full
list of classifiers and performance metrics are shown in
table iii 
vi 

vii  analysis

there are several possible reasons why the machine
classifier did not achieve better performance  one
explanation is that a large portion of tweets are noise
with respect to mbti  this is the result of several
factors  perhaps the most difficult to overcome is the
inherent breviloquence of tweets  because twitter
imposes an     character limit on each tweet  users are
forced to express themselves succinctly  which causes
stylistic elements common in prose to be suppressed as
each thought is compressed down to its raw elements 
this means that the number of indicator words were few
and infrequent  in addition  a large percentage of tokens
in tweets are not english words  but twitter handles
being retweeted or urls  thus  while a users tweet set
may contain a thousand tokens  a significant subset is
unique to that individual user  and cannot be used for
correlation  further  due to retweeting  a users tweet
may not be expressing his or her own thoughts  but those
of a different individual 
a second explanation is that while tweets may have
mbti relevant information buried in them  this
information is not accessible through simple word
frequency  as an example  consider the following tweet 
everyone is like  i hate obama  or  i hate romney 
and i m over here like  i love pizza   the user  as a
perceiver  is contrasting the strong judgments of others
with her own preference for food  however  word
frequency analysis shows hate hate love  strong words
signaling towards a judger  thus  a decision based on
word frequency alone would mislabel this tweet  it is
possible that advanced natural language processing
 nlp  techniques that isolate clauses  identify sentence
structure  and recognize negators could result in useful
features  but such techniques were outside the scope of
this project 

performance by classifier
classifier
multinomial event model naive bayes
l  regularized logistic regression  primal 
l  regularized l  loss sv classification  dual 
l  regularized l  loss sv classification  primal 
l  regularized l  loss sv classification  dual 
sv classification by crammer and singer
l  regularized l  loss sv classification
l  regularized logistic regression
l  regularized logistic regression  dual 
table iii 

training accuracy by classifer

e vs i
     
     
     
     
     
     
     
     
     

n vs s
     
     
     
     
     
     
     
     
     

t vs f
     
     
     
     
     
     
     
     
     

p vs j
     
     
     
     
     
     
     
     
     

fiviii  comparison with human experts

twenty users were randomly selected from our
dataset  for each of these users  thirty of their tweets
were randomly chosen and presented to two human
experts trained in mbti administration and analysis 
these same tweets were also supplied to the
multinomial event model nave bayes classifier  the
results of both the human and machine selections are
shown in table iv 
human    averaged      human    averaged
        and the mnemnb classifier averaged        
while the machine classifier did outperform the humans 
the performance difference is small enough that this
result is probably not significant  especially considering
the small sample size  the human experts found some
users in the test set to be unclassifiable and were forced
to make a random guess  on other tweets  the experts
indicated they had a low confidence in their predictions
for a certain spectrum  while in general  the experts
confidence in their predictions corresponded with their
results  there were users that the experts were shocked to
learn they had mislabeled  this supports the idea that
while some users have tweets that contain personality
indicators  others do not  or worse  contain
misinformation 

comparison of human
experts vs machine
spectrum human   human   mnemnb
e vs i
     
     
     
n vs s
     
     
     
t vs f
     
     
     
p vs j
     
     
     
table iv 

comparison of human experts vs
machine

when successful  the human experts tended to draw
upon context information in the tweets  for example  in
the tweet got to rush and crowd on public transport   
life sucks  the expert concluded the user was an
introvert since they were referencing crowd and
public in the context of life sucks  this indicates
that by using only word frequencies  the mnemnb
classifier is rejecting potentially useful information 

ix 

conclusion

in this project nearly one million tweets from sixthousand users were retrieved for the purpose of myersbriggs type detection  a multinomial event model
naive bayes classifier was developed  trained  and
tested on this data  the performance of this classifier on
training data was quite good  but the classifier failed to
achieve excellent results for test data  a variety of
preprocessing techniques were parameterized and
attempted in all combinations without noticeable effect 
while this appears to be a high variance problem 
adding more data and limiting the number of features did
not improve performance  fixes for known weaknesses
in nave bayes classifiers were also attempted  but again
performance remained roughly constant  to ensure that
the performance of the nave bayes classifier was not
due to implementation error  the training and test data
was fed into several classifiers provided by liblinear
with similar results  further analysis of these results
lead the authors to conclude that while there may be
mbti information in tweets  it is not prevalent and may
require advanced natural language processing techniques
to uncover 
acknowlegdements
special thanks to david patterson for providing insight
regarding mbti and tweet data and providing
suggestions for improving the preprocessing  thanks to
both david patterson and lloyd patterson for serving as
the human experts and analyzing    pages of raw tweets 
x 

   

   

   

   
   

xi  references
j  rennie  l shih  j  teevan  and d  karger  tackling
the poor assumptions of nave bayes text classifiers 
proceedings of the twentieth international conference on
machine learning  icml        washington dc       
j  perkins  python text processing with nltk   
cookbook  olton  birmingham  uk  packt publishing 
    
r  e  fan  k  w  chang  c  j  hsieh  x  r  wang  and
c  j  lin  liblinear  a library for large linear
classification  journal of machine learning research
        
          
software
available
at
http   www csie ntu edu tw  cjlin liblinear
m  russel  mining the social web  sebastopol  ca 
oreilly media      
c  parsons and m  memoli  president obama tailors
outreach for select group  the los angeles times   
august
     
web 
  
december
     
http   articles latimes com      aug    nation la naobama narrowcasting          

fi