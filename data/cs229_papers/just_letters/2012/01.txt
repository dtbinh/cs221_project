creating a nl texas holdem bot
introduction
poker is an easy game to learn by very tough to master  one of the things that is hard to
do is controlling emotions  due to frustration  many have made the wrong decision 
moreover  one can make a lot of money by playing multiple tables at once online  this is
where an idea of a poker bot that makes quick decisions without the interference of
emotions can be a very profitable one  though it isnt strictly legal to use bots to play
online poker in multi tables for you  the idea that one can create a bot is very exhilarating 
just like it has been for many with the game of chess  poker is a very complicated game
and the machine learning techniques used to solve such a problem can be used in other
useful areas that require reacting to different situations
problem definition
the goal of this project is to create a bot that plays poker in a profitable manner  the
training data is my hand history that a software has saved from my games in online poker 
the goal is to use this data to create a poker bot  to simplify the problem  some
limitations to the game are made  firstly  though this is nl holdem  the bots bets will
be fixed  a common raise made by many players is   times the bet made in front of them 
if the bot is leading out  the bet will be     of the pot  lastly  there will be no concept of
bankroll  however  the winnings and the losses of the bot will be tracked 
model formation
to make computers play like humans  it has to estimate the hand of opponents based on
its betting patterns  imparting this wisdom to the bot is not a trivial task at all because
there are so many situations of the game to consider  this is where machine learning
becomes useful as it acts as a heuristic  the models goal will be to determine based on a
few features whether it will call  raise  check or fold in each street 
the training data available gives insight on the properties of the hands for which i called 
checked  raised or folded  hence  the training data lends itself to nave bayes  nb   this
nave bayes models job is to tell the bot which action is the most optimal  hence  this
model will be multinomial and not bernoulli  by getting the probability that a certain
action is the most optimal one  a preliminary approach may be to pick the action with the
highest probability  a better approach would be to pick the action according to the
distribution given  which adds randomness and is a crucial part of the game 
one of the added complexities of this model is the changing of the features for the
decisions  one of the classical uses of this model is spam classification  the features to
determine whether the email is spam or not are the same  in this case  the features used to
determine whether the bot should fold in a later street  turn or river  will include features
of the flop but not vice versa 

fianother alternative to nb is support vector machines  svm   this is an alternative
because the classical applications that use nb uses many features  like the occurrence of
a words in the dictionary  they are not that many features for this problem so a nonbinary svm could be a better model  however  getting the data to a format for svm
would be very difficult because there are copious training examples  one would have to
decipher each one of them to summarize what actions were taken  hence  for this project 
with the available time  this model isnt as practical 
features
the preliminary features selected for the study are listed below  for my training data  i
filtered my hands based on these features and calculated the number of hands i called 
raised  checked or folded 
   starting hand  or in other words  the hole cards  the two cards given at the starting 
   the opponents action in the current street  this is not applicable if the bot acts first 
   current hand  the bot could have a pair  two pair  three of a kind  a straight  a flush
or a certain of type of draw  which should affect its play
   position  in poker  the player who acts second has the upper hand 
   the actions of the previous streets  in other words  what the bot should do in the turn
may depend on what happened in the flop and pre flop 
   card texture  many times what the flop  turn and river are should affect the bots play 
development process and testing procedure
developing most software is an iterative process  this is crucial with machine learning so
that the model is robust and can be implemented efficiently  with the proposed nb
model  the pre flop was first implemented and the performance was evaluated  after
necessary changes  the same is done for the flop and then for the turn and the river  for
the intermediate testing  the interface was made in matlab  a table of   players was
made  one of them being the bot  i manually played for the others and instruct the bot to
respond  poker players are a mix of certain styles  which include being tight  aggressive 
loose and passive  hence  i made the competitors play an extreme version of these styles 
it wasnt a trivial task to set up the game and the interface and sample hands were shown
in the poster session 
changes to the nb model
the three main features of pre flop for the model are starting hand  position and bet state 
bet state corresponds to whether players before the bot had called or raised  laplacian
smoothing was implemented  however  it may not have had a significant impact as the
training data had a wide variety of hands  after running the given properties of the model 
the bots pre flop performance was studied and concluded to be unsatisfactory  firstly  if
there were a bet in front of the bot  the bot would almost always fold  lastly  many
profitable players would open even with mediocre hands if they were sitting in late
position to steal blinds  though this is shown in the statistics  the bot wasnt doing this 

fiit was concluded that this model wasnt working well because nb assumption didnt hold
for this problem  the features are conditionally dependent and now the conditional joint
probability cant be expressed as a product of conditional probabilities  for example 
given that a player raised and was in late position  the chance that he has a mediocre hand
is high  similarly  if a player bet from early position  the chance that he has a mediocre
hand is low  if there is no raise in front of the bot and it is in late position  the bot should
be raising almost always  regardless of starting hand  hence  the solution to this was to
model the conditional joint probability 
n

p   x   x    xn   as   k     p   xi   as   k  
i  

where x is the feature and a is the action  this states the invalidity of the assumption 
there are     possible starting hands for a player  it would take a lot of time for one to
count the number of times a player performed a certain action from each position and for
each hand  hence  the conditional joint probability was modeled  this modeling also took
two iterations  first  given that the bot performed a certain action and had a certain hand 
the probability that the bot is in a certain position was modeled discretely using   bins of
position  big blind  small blind  early  middle  late and dealer as shown below  to make
the problem more manageable  the starting hands were given an integer from   to    with
  denoting a premium hand 
p   xi   as   k  h   l      kli
this distribution was solved using a method like least squares  the linear equation set up
is shown below  what it denotes is that the distribution should be selected such that the
global probability of an action is equal to the one measured  if n is total hands 

  a   k 
 
 kli h  

n h
a
the base constraint is that for each starting hand strength and action  the values that
denote position should add up to   because this is a probability density function  there
were other inequality constraints to capture the effect of position  more specifically  if the
bot had a premium hand  the probability it should raise with it is evenly distributed
among the positions because the position shouldnt have an effect  in contrast  if the bot
has a mediocre hand  the bot should raise with that hand mostly from late position  the
training data took into account the fact that one should be getting more mediocre hands
than premium ones   one cant always get aces   this problem is an example of quadratic
programming  the techniques to solve such a problem  which include lagrange
multipliers and formulating a primal dual problem is similar to the one used to solve
svms  matlabs routines were used to solve this problem 


min b  a

 

 
s t  kli      b  c

the bet state wasnt included in this system  this was for two reasons  first  it was
unclear what constraints would model the effect of the bet state as was done for position 
secondly  the matrices were kept to a manageable size for ease of computation  hence 
for the next iteration  it was assumed that bet state was conditionally independent from

fithe other two features  from studying the performance of the bot  it was concluded that
the bot handles position well  however  it doesnt handle bet states well  for example 
with a drawing hand  like suited connectors  even if there is a raise before the bot  it is
profitable for the bot to call and see the flop  to fix this issue  it was assumed that the bet
state was the third and final feature the bots play should depend on  with the previous
method  the probability the bot performs a certain action with a certain hand in a certain
position is known  with the probability the bot should perform a certain action given a
certain bet state calculated from the training data  one can find out which hands the bot
can have to perform that action in that position given that bet state  this was done by
aligning the probabilities in a greedy way  with the maximum first  the cumulative
distribution function was calculated and checked whether the cdf of that hand was
lower or equal to the probability specified for that given bet state  this model works
extremely well  however  it is less random than the previous model because many times 
the model decides on one final action  for on another implementation  the bot can act
outside the decision of this model with a given parameter to introduce more randomness 
post flop
the base nb algorithm was applied for the streets after pre flop with the features being
starting hand  action of previous streets and current made hand  though there were
correct moves  there were also a few blatantly wrong moves  skewed towards folding 
after analyzing a few training hands that met the criterion and went as expected  it was
concluded that the error was a high variance error and the number of features were
reduced  namely  instead of using the information of all the streets before the current
street  the features were reduced to two  defense and offense  if the bot had bet in the
previous street and got called  the bot was in offense and vice versa  the starting hand
feature was also not used anymore  this got rid of lot of the noise and the bot performed
much better  a lot of tuning as done for the pre flop was not done because now only the
important features were used and the conditional dependence wasnt magnified 
markov decision process  mdp 
with a table of players with different styles made  it was an interesting aspect to study
whether the bot could adapt to the different players  which is a crucial part of poker 
instead of focus on making methods to test the model on other pre made data  this
garnered more focus  this algorithm was used only in post flop given the robust method
already implemented for pre flop  to use this model  i made the bot follow the nb model
till the markov decision process is trained after enough iterations  a mixture of
unsupervised and supervised may be a good blueprint for other problems as well 
the states used for this problem are winning in the flop turn river  by making the
opponents fold   losing in the flop turn river  by folding   seeing the next street and being
in the defense offense and winning at showdown for each specific hand and for each size
of pot  though the pot size is a continuous variable  it was discretized into   bins  this
came up to     states  the rewards is the amount won or lost at the terminal states  which
are the states at showdown and the losing and winning states at each of the streets  with

fimore hands  the average is stored  the actions are the four possible actions  call  raise 
check and fold  for each of the street  flop  turn and river   which is a total of    actions 
the transition probability is now a function of player and this should help the bot finding
the best action  for example  the probability of going to the next street being on the
offense is low for an aggressive player even if the bot bets because it is likely that the bot
will be re raised and is now forced to call  as the game goes on  hopefully the bot
recognizes that being on the defensive is bad because if the opponent makes another bet 
as given by the nb model  the bot should fold most of the time  hence  against an
aggressive player  it should check and then call  the bot is now not so much in a
defensive state  another example is the probability that a tight opponent folds to a bluff
or a bet is high  so to increase the expected reward  it should raise against tight players 
and with more iterations  it should know that the reward at showdown for bad hands is
negative  which will induce the bot to bluff with bad hands and to bet with good hands to
increase the pot and win more at showdown  in value iteration  to handle the different
players  the update was normalized  where   is the number of players 
v  s    r s   

 
 max a   psa  s  v  s  
  p
s

results
using matlab  a poker session is simulated  at first  the nb model was used  the
mdp was put into effect after the markov model has a hand with each of the players 
this took    hands  with more data on the aggressive players because they play more
hands  by that number  fortunately  the rewards values were fairly accurate as this wasnt
a function of player  i played as others with the bot for    more hands after that  in poker 
many times there isnt a clear cut answer to what the right play is as there are many
factors to be considered  hence  to test the models  from all the bots actions  i looked at
the percentage of the bots good  fair and wrong moves  since most of those errors came
post flop i looked at pre and post flop separately  pf   pre flop  f   post flop 
the bots winnings are also reported  with its original stack starting at       except for
the winnings  the rest are percentages  some key statistics of the bot are also reported and
compared to my play  i am looser pre flop because i didnt give the bot knowledge of pot
odds  which encourages players to call with mediocre hands just because there is money
in the middle  having won huge pots before mdp  one with aces  mdp assigned a high
value for going to showdown and so the bot became more loose and aggressive than nb 
which  at times  was a good thing as the bot made some good moves  however  more
iterations were needed for the bot to distinguish between the different players  at the end 
it kept calling the aggressive players  for the next step  it would be good to devise a way
to autonomously test so that the mdp can get trained in time 
play
pf
pf
pf
f
f
f
saw bet
winnings
good
fair wrong good
fair poor flop frequency
nb
  
 
 
  
  
  
  
  
   
mdp
  
 
 
  
  
  
  
  
   
me
  
  

fi