author identification on twitter
antonio castro
antonio alfredo castro gmail com

i  i ntroduction
as of june       twitter had    m users     m of
whom are in the united states  these users  especially those
outside of the united states  may assume that they have a
certain level of anonymity among this sea of tweets  our
project investigates whether the identity of an anonymous
twitter user can  in fact  be uncovered using only linguistic
stylometry  authorship recognition is a very well studied
domain  but the scale is almost always limited to no more
than a few hundred authors  narayanan  et al      study
authorship recognition at internet scale  by looking at the
characteristics of different classifiers when applied to a
corpus of approximately    k blogs  we set out to answer
the question of whether similar results could be achieved
on tweets rather than blogs  despite their much shorter
length  starting with the set of features  classifiers  and
normalization methods that yielded the best results over blog
data in      we adapt them to twitter data and measure the
results 

brian lindauer
brian shendauer com

source

desired usage

actual usage

klout

top thousand klout
users as a source of a
variety of users with
rich content 

not viable for use 
only small lists of
top klout rankings
are published 

twitter firehose

obtain tons of tweets
across a massive
number of users 

not viable for use 
while the data is
broad  it does not
provide us with a
long enough history
of any individual
user to populate our
sparse set of features 

twitaholic

provides a top     
most followed list of
twitter users 

provides the basis of
our twitter users to
gather data from 

dell solicitation

obtain a
employees
maintain
separate
accounts 

of
who
two
twitter

provides a set of
known twitter accounts that are authored by the same
person 

web search

search for phrases
such as also follow
me at on twitter profile pages 

provides a set of
known twitter accounts that are authored by the same
person 

google plus profile
scrape

discover users that
report having multiple twitter feeds to
be followed 

adds to set of twitter
accounts with known
authors 

ii  data c ollection
our set of training data spans more than     users  most
having at least      tweets per user  this provides enough
data to our classifiers despite the sparsity of the derived
features and the limitations imposed on the length of a tweet 
our data set also includes a number of twitter accounts
where we have prior knowledge that they are authored by
the same user as at least one other account in the set 
table i describes the various sources we reviewed and
how we ended up using the data  we initially utilized a web
site called discovertext com to follow the desired accounts
and begin collecting data  however  the service is insufficient
for our needs because it fails to capture information about
retweets and is unable to provide historical tweet data  as
a result  we utilize the twitter api directly to gather the
last      tweets of each of the users identified in table i 
primarily because of twitter rate limit limitations  the data
gathering requires several days to complete 
our experimental methodology requires that we identify
a collection of twitter account pairs where one author is responsible for both accounts  our primary methods for identifying those accounts where issuing a request to employees
of dell with official dell twitter accounts  and using google
to search for phrases indicating multiple twitter accounts 

list

table i
data s ources

we also obtained some meta information about google plus
profiles from the authors of how unique and traceable are
usernames       and used that to target a crawl of google
plus profile data  this produced an additional set of account
pairs  after eliminating non english feeds  feeds containing
only links  etc   we are left with    labeled accounts from
   different authors 
due to the small number of valid account pairs in which
we have prior knowledge of the account being authored by
the same user  we simulate dual authorship by splitting each
feed       and performing cross validation and measuring
the error  since this measures error against the same feed 
rather than another feed by the same author  it is not ideal 

fibut in most cases  it should approximate a lower bound 
and as such it gives us a good indication of the algorithms
general performance in de anonymizing tweets 
additionally  some accounts exhibit issues that might
introduce confounds into the experiment  examples of these
include foreign languages and tweets automatically generated by applications  such as foursquare  we do not incorporate any cleansing of these issues in our experiments other
than the final test we performed using the known accounts
with duplicate authors  for those accounts  we manually
review their feeds to remove any feeds that contained any
obvious issues 
the results in this paper are based on a collection of    
twitter streams containing approximately    k total tweets 
these include the    sets of accounts that are known to be
maintained by the same author 
iii  f eatures
our selection of features is inspired by narayanan     
writeprints      and ireland      it is  in fact  mostly a
subset of the narayanan features  these features aim to
focus on the style of the tweet rather than its topic  so  for
example  we specifically look at function stop words rather
than ignoring them and focusing on words with large tf idf
scores  in adapting narayanans previous work to twitter  we
add several twitter specific features  described in table ii 

adoped the definition of information gain used in narayanan 
that is 
ig fi     h t    h t  fi     h t     h fi    h t  fi  
where h is the shannon entropy  t is the random variable
for the twitter account number  and fi is the random
variable for feature i      by using the same information
gain metric as narayanan  we are also able to compare the
effective features in detecting blog authorship to those in
detecting twitter authorship  the most influential features
for our classifier are listed in table iii 
feature

information gain  bits 

freq  of non ascii characters

       

number of words per tweet

       

freq  of all lowercase words

      

freq  of o

       

number of characters per tweet

      

freq  of a

       

freq  of t

       

freq  of e

       

freq  of  

       

freq  of words with only the first letter capitalized

       

freq  of h

       
       

category

description

count

freq  of n

length

words characters per post

 

freq  of i

    

frequency of words in uppercase 
lowercase  capitalized  camelcase 
and other capitalization schemes

 

freq  of r

      

freq  of  

       

word length

histogram of word lengths from    

  

character frequencies

frequency of letters a z  ignoring
case   digits  and many ascii symbols

  

unicode

frequency of non ascii characters

 

function stop words

frequency of words like the  of 
and then

   

twitter conventions

existence of rt or mt

 

retweets

whether the post is an exact retweet 
or a modified retweet

 

word shape

table ii
f eatures used   adapted from    

we extract all     of these features using a ruby script 
and store them in csv for ingestion by the classifier
programs  which are implemented in matlab  extracting
these features presents no notable challenges in scalability
or algorithmic complexity 
we were curious to know which of these features has the
most impact on our classification accuracy  to find out  we

table iii
f eatures with highest information gain

comparing this list with narayanans top    features for
blogs  we see that both find the length of the post and the
capitalization style to be highly discriminative  however  the
most discriminative individual characters are different for
blog posts and tweets  narayanan found that apostrophes 
periods  and commas were the most important characters
for blogs  while we found that o  a  t  e  and period were
the most important for tweets  this result was initially
puzzling  but we soon realized that all of the characters
comprising http    are near the top of our list  it may be
that vowels are highly ranked becuase they help distinguish
tweets consisting primarily of english words from those
containing mostly urls 
far and away  our most influential feature is the frequency
of non ascii characters  some twitter users routinely include unicode in their tweets  while others never do  since
we are nominally filtering out non english accounts  these
unicode characters are mostly special characters  such as

fihearts and smilies  rather than characters in non english
words 
finally  we note that the frequency of   is highly
ranked  but not in our top ten  this character is used on
twitter to denote a reference to another twitter feed  it far
outperforms our more twitter specific features  such as the
presence of rt      bits   or whether a retweet includes
an exact inexact copy of the original tweet       and     
bits  respectively  
iv  c lassifiers
because narayanan  et al  reported their best results with
a combination of nearest neighbors  nn  and regularized
least squares classification  rlsc   we implement these
classifiers and run them against the data 
initially focusing on nn  we implement the variation
described by narayanan along with the normalization procedure from that same paper  rather than keeping all data
points in memory  which would be very expensive considering the number of twitter users  we compute one centroid
for each twitter account  to do this  we read in all extracted
tweet features from all users  then normalize by both column
and row  first  each column value is normalized by the mean
of the non zero values in that column  then  each row value
is divided by the norm of that row 
at prediction time  we read the extracted features of
each tweet in the test stream  for each of those tweets 
we measure the euclidean distance to each of the centroids
computed in training  then we take the sum of the distances
of all the tweets to each of the centroids and rank the centroids by their average nearness to a tweet in the test stream 
we ask whether the account by the same author appears in
the top n  of the ranking  including whether it is ranked
first  we also measure generalization error using       cross
validation on tweets from the same account  in computing
both training error and cross validation generalization error 
we count a prediction as correct only if the correct account
appeared first in the ranked list  with our training and cross
validations set  nn yields a       training error and a
     generalization error  this generalization accuracy is
surprising considering the relative simplicity and lack of
domain specificity in our featureset  in fact  the feature set
is composed largely of one grams and function words 
though our sample size is small  we are able to use our
   labeled accounts to get a measure of accuracy when the
algorithm is applied to our intended use case  given one of
the accounts in the pair  the nn classifier ranks the other
account first     of the time  an error rate of      but
the correct author is ranked at least  nd     of the time 
and they appear in the top     of the ranking over    
of the time  figure   shows the cumulative distribution over
these rankings 
this nn algorithm is relatively fast  since it only needs
to compare each test point to one centroid for each training

figure   

cumulative distribution of percentile rank over test examples

class  because these tests are independent and lightweight 
we are able to utilize matlabs parallel computing capabilities and process the entire dataset in minutes 
we implement the regularized least square classifier
algorithm starting with the original closed form solution as
described in rifkins paper     
w    x t x   i   x t  y
given the size of the training set of approximately        
tweets in our design matrix x  and the multiclass     
    convention y matrix with     classifier vectors the
algorithm requires approximately    hours to complete for
each classifier vector  however  we found that the training
error performance is not affected by converting to a      
convention and we are able to complete the entire classifier
calculation using sparse matrices in matlab in a single
step
w    x t x   i   x t y
within a few minutes 
as a matter of convention  we classify each tweet as either
a positive or negative by determining the maximum value
of each linear classifier method for a single tweet  setting
that classifer to one and the others to zero  we used the
frequency of a classifier being chosen across the sample set
as an aggregate to determine confidence accross a sampling
of tweets  however  this result does not vary notably from
using the sum of the raw values produced by each tweet 
similar to the results in the narayanan paper  the resulting
training error of this one vs  all  ova  method  ranges
between     and     which is more than an order of
magnitude worse than our nn classifier  this is a known
problem for ova classifiers with heavily skewed data  for
each label in our data set  the rlsc generally has a thousand
positive examples compared to nearly half a million negative
examples  we explored a handful of methods to level the

fidata as the algorithm  rescaling the alone is not an option
as the algorithm is invariant to rescaling of the input data 
we try a few methods     to reduce this error by including
pruning     negative examples for each ova being trained
and artifically creating like samples for training  however 
we find that these methods only improved the classification
error by only       
inspired by the penalization concept in the narayanan
paper  we set out to modify the cost function so that it
penalizes false negatives proportionally more heavliy than
false positives  the closed form solution for appropriatley
balancing the ratio of positive and negative examples is as
follows  we let j be an m  m diagonal matrix where jii
is equal to the ratio of negative to positive examples in rows
corresponding to a positive example in classifier j  and  s
for all other diagonal values 
more formally 
p
  yji     
wj   pi
i   yji     
jii   wj yi       yi  
using these classifier specific j and y j values  we can
derive j for each classifier j in closed form as follows 
 
 xj  y j  t j  xj  y j       j    
 
j j j     x t j xj  x t j y j    j    

j j    

j    x t j x    i   x t j y j
using this closed form requires the generation of  
    kx   k for each of the     classifiers and requires
iterating through each classifier independently  due to the
memory requirements of this algorithm in matlab  even
using sparse matrices  this closed form algorithm is difficult
to parallelize beyond a handful of threads and thus still
required several hours to complete  however  with these
results we are able to reduce our training error to     
and our generalization error to       most importantly  the
algorithm performs significantly better than nn on the set
of known twitter dual accounts  classifying     of them
correctly  comparing rlsc to nn in figure    we see that
rlsc outperforms nn at every threshold 
in accomplishing the above results  we do not experiment
much with the regularization paramater   our choice of
lambda is the minimum order of magnitude that did not result in the classifiers calculation resulting in nearly singular
matrices for the algorithm  which  in this case was      
we minimally explore methods to improve the performance
and memory requirements of the algorithm without notable
impact  but do not explore methods that do not require large
matrix operations such as conjugate descent and dynamic
programming as referenced by naranayan and rifkin    
which may be necessary to scale significantly beyond the
number of users we are working with in this experiment 

v  r ecommendations
given the prominant use of twitter by political dissidents 
its alarming to learn that the author of an anonymous feed
might be identified with     accuracy based only publicly
viewable information  by using other information  such as
the time of posts and ip access logs  the identification rate is
likely to be much higher  however  having examined many
of the failed matches  we note that evasion is simple  as long
as the author is aware of these risks  in several of the failed
matches  one of the accounts is written in a deliberately
different voice  in one case  the author tweets in the voice
of his dog  in other cases  the author of limits the amount
of commentary in the second feed and mostly posts urls 
by following these examples and either deliberately altering
their writing voice  or limiting the amount of text posted 
twitter users can help maintain their anonymity 
vi  f uture w ork
given the initial promising results  there is opportunity
for continued work in testing classifier accuracy and performance at larger scales  as well as in several other areas 
including 
 expanding the exploration of stylometry features in
previous work to further impact generalzation error 
 collecting a broader set of known account pairs and or
identifying a list of potential pairs to be confirmed 
 exploring conjugate descent  dynamic programming  or
stochastic methods to improve the speed and memory
usage of the rlsc algorithm 
 exploring ensemble learning to combine rlsc and nn
algorithms and its impact on generalization error 
 applying these methods on a much larger number of
accounts  e g            twitter accounts  
 removing language and application data that may be
introducing confounds 
vii  c onclusion
we are encouraged by our results  the classifiers both
exhibit excellent accuracy in cross validation  and do fairly
well in the general use case where the test stream comes
from a different twitter account by the same author  we
expected less accuracy from twitter than from the blog
or email data used in previous work because the size of
the tweets are significantly smaller in comparison  with the
small number of labeled examples in our data set  we cannot
make a judgement about whether performance was better or
worse on twitter vs  blog data  but we can conclude that
stylometric analysis does  in fact  perform well on tweets 
r eferences
    abbasi  ahmed  and hsinchun chen  writeprints  a stylometric approach to identity level identification and similarity
detection in cyberspace  acm transactions on information
systems                

fi    narayanan  arvind  et al  on the feasibility of internet scale
author identification  security and privacy  sp        ieee
symposium on  ieee       
    ireland  m e     pennebaker  j w          language style
matching in writing  synchrony in essays  correspondence  and
poetry  journal of personality and social psychology     
    perito  daniele  et al  how unique and traceable are
usernames   privacy enhancing technologies  springer
berlin heidelberg       
    rifkin  ryan  gene yeo  and tomaso poggio  regularized
least squares classification  nato science series sub series
iii computer and systems sciences                     
    ofer dekel ohad shamir  multiclass multilabel classification
with more classes than examples  proceedings of the   th international conference on artificial intelligence and statistics
 aistats        chia laguna resort  sardinia  italy  volume
  of jmlr  w cp   
    schapire  robert e   and yoram singer  boostexter  a
boosting based system for text categorization  machine learning                      

fi