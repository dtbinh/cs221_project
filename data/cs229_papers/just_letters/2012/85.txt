wafer spatial signature analysis
abhishek singh and wojtek poppe

abstract
semiconductor manufacturing is a complex multi step process that can be prone to processing issues that lead to
nonfunctional chips  a significant proportion of systematic defects can manifest as spatial patterns  signatures  of
failing chips on the silicon wafers  these systematic spatial patterns are indicative of process defects that need to
be identified and tracked  the primary challenges of classifying failure signatures across wafers are   a  presence
of more than one systematic failure patterns  or mechanisms  on a single wafer   b  presence of random defects
that make chips fail randomly adding noise to the patterns  and  c  small amounts of labeled data  in this paper 
we apply machine learning algorithms to automatically track these spatial systematic failure patterns in midst of
abovementioned challenges and assess their performance 

introduction
during the manufacturing process  semiconductor wafers go through numerous chemical and mechanical
processing steps  a finished wafer is cut up into chips before they are packaged  figure     each processing step is
susceptible to process variations as well as tool recipe issues that may render affected chips useless  in a majority
of cases  especially during the early days of a process generation  process defects are systematic in nature and
result in a systematic wafer signature of failing dies  figure   shows an example of wafer with systematic pattern
where more chips fail at the outer right edge of the wafer  since each processed wafer consists of over a hundred
process steps  it is common for multiple signatures to exist on one wafer  it is important to quickly identify which
signature affects the most wafers  so that resources can be focused on addressing the biggest yield detractors  in
this paper we compare various learning algorithms in tracking these spatial signatures across thousands of wafers 
we also present a signature quality metric to identify the presence of a systematic which serves as a diagnostic
tool in assessing the performance of any algorithm 

figure    manufactured semiconductor wafer consisting of
several chips

figure    yellow squares indicate nonfunctional chips  note the
high failure right on the right edge

experimental data and dimensionality reduction
data set
for this project we used    months  jan nov  of data consisting        wafers  this data set is known to capture
several process issues that emerged at various points and were eventually addressed and fixed  therefore  the
systematic signatures that we aimed to track using various learning algorithms were prevalent in the early portion
of the data set and faded away as the process matured  we focused our efforts on three known signatures  figure
   and in particular the checker ring pattern  which was the most common and well understood  note the single

fiwafer shown in figure   constitutes one training example  the checker ring pattern is actually present  but it is
mixed up with other less frequently observed issues such as high failure rate on the right edge 

figure    real signatures  yellow indicates region of higher failure rates 

feature encoding
we chose the  x  y  location of each chip on the wafer as a feature and the pass    or fail    status of the
corresponding chip as the feature value  each wafer or training example was represented by a     bit long feature
vector          etc   this feature encoding is referred to as full wafer training set  to reduce dimensionality in
an effort to decrease minimum training size requirements we tried three different feature encodings  these
include 
 adaptive features  we crop chips that form the spatial signature  also referred to as hot spots  on the
wafer along with their immediate neighbors  the neighboring chips are included in order to retain the
contrast information between the frequently failing chips compared to other chips  similar to the fullwafer case  the pass fail status of each chip is used as the feature value  the length of adaptive features
would change between signatures  but we train separate svms for each signature anyways 
    reticle zones  instead of having a feature for each die  we calculate the yield or average intensity in
multiple chips that are within one of    zones  the zone definitions are pretty commonly used in industry
and in our case are very well suited to the checker ring pattern
    radial zones  similar to    reticle zone except with    radial zones  also common zonal map  

signature quality metric
one of the main challenges we face is a dearth of accurately labeled training examples  so we implemented a
signature quality metric  sqm  which turned out to be a very useful diagnostic for evaluating classification
results  as seen in figure    in a lot of cases a single wafer may not exhibit a clear signature  thus we resort to
analyzing a stack of wafers  the sqm for a stack of wafers is defined as 
  fffi      


    fi     fi

        fi     fi

in order to compute the sqm we need to first identify the hot spots locations on the wafer  this can be
accomplished by maintaining a baseline set of wafers that represent the majority of the wafer population
unaffected by the signature being analyzed  next  the target wafer stack is normalized with respect to the
baseline wafer stack in order to fix the global process bias  the difference of normalized wafer stack and the
baseline is computed for each chip location  the chip locations high delta values     sigma  correspond to the
hotspot locations  the baseline population is used to compute the expected failure rates at the hotspot locations 
the ratio of total failure rates at the hotspot locations in the target wafer stack with respect to the total expected
failure rates at the corresponding locations is used as sqm score  this metric can then be used to quantify how
pure a particular group of wafers is relative to some target signature 

firesults
comparison of various algorithms
in order to gain better insight into what types of learning algorithms will work best for spatial wafer signatures we
decided to look at logistic regression  lr   svm  and nearest neighbor  knn   logistic regression is simple to
understand  svm has shown very positive results for character recognition   and nearest neighbor could give us
insights into distance metrics  which would be useful for other algorithms  such as unsupervised clustering  figure
  demonstrates performance for the various algorithms 

figure    comparison of various learning algorithms  plotting precision given recall      if recall is never      then we say precision   
error bars indicate a   sigma bound based on     random bagging runs 

we looked at a variety of metrics ranging from prc area to average accuracy for quantifying algorithm
performance and found precision given a fixed recall to serve our purposes best  we had the following takeaways
from each algorithm 
logistic regression  lr   it worked  but only for large training sets  training error was always    which indicated
logistic regression suffers from high variance  we looked at the theta vector as seen in figure  a  and noticed that
it took logistic regression a lot of samples to accurately identify the hotspot locations  which eventually
garnered a high corresponding theta value 

figure    example of how logistic regression converges on a  vector that weighs hotspot chip locations much more than
surrounding die  also note immediately surrounding chips are negative to indicate the need for only the hotspot being a fail 

svm  svm had excellent performance and still classified with some precision down to   training examples  this is
likely due to the fact that svm classifier not only iterates until it correctly classifies the two classes but also

fimaximizes the margin between them  its worth noting that the margin for error is small for smaller training sets
and minimal changes in threshold could lead to drastic changes in precision  this is reflected in the significantly
higher variance with training set sizes       we ran     random training sets for each training set size  
knn  nearest neighbor showed the poorest results  which is likely due to the distance metric we used  as seen in
in figure    lr  and most likely svm  weigh specific chips more than others  however  knn tends to weigh all the
features equally which may wash out the signal  higher failure rate at specific locations   we do think that this can
be addressed  but would require a custom distance metric for each signature 
k means and mixture of gaussians  none of the clustering algorithms we tried effectively clustered large sample
sets  small sample sets with well chosen examples split into predictable clusters  but running a full month lead to
uninteresting clusters  we feel this is largely due to the unweighted distance metric that also affected knn  we
observed slightly improved performance using radial and    zone encoding  but not enough to justify a deeper
analysis in the time provided 
comparison of feature encoding schemes
using svm with a gaussian kernel on the four different feature encodings lead to performance seen in figure   
surprisingly the adaptive encoding with     features always outperformed the    zone encoding  even with the
smallest training set  adaptive encoding with the reduced binary feature set worked best for all signatures in all
cases      precision was achievable at     recall  but only for a highly tuned threshold setting  in other words 
the algorithm would pick the correct class  but with very low confidence  and classification results would vary
between training sets of the same size  fortunately the sqm score could be used to help alleviate this issue  we
found that we could sub sample even a small training set  predict groups with high sqm  and then re train on
previously unlabeled data to get more stable and predictable svms  as another vote of confidence for binary
encoding  the full wafer svm  with     features  outperformed the    zone svm when we had at least    training
examples 

figure    performance of the four different feature encoding schemes  error bars were not drawn to keep the graph clean  but are
similar to the svm gaussian error bars seen in figure  

to demonstrate the robustness of our algorithm we ran the adaptive svm one month at a time on the full
training set and were able to produce a chart of impacted wafers over time  we were able to accurately detect
    of the wafers in january when this issue was prevalent and also in august when     of wafers were affected 
note the quality score in figure  b is flat for the other class  which is a diagnostic we use when looking at
unlabeled data  the signature quality or signal from this particular process defect also decreased over time as the
issue was addressed and fixed  there was an interesting bump in august when a couple lots of wafers were

fireleased from quarantine that were actually processed earlier in the year  hence had a stronger signature   the
chart in figure  a is the essence of what we wanted to achieve with this project 

checker pattern signature vs time

quality score vs time
 

     
    
    
    
    
 

  wafers

total wafers

signature class
other class

   
sqm

signature wafers

 

nov

oct

sep

aug

jul

jun

apr

may

mar

feb

jan

   
 

 a 

 b 

figure    a  signature wafers identified vs time      wafers identified in jan and only    in november   b  quality score for signature
and other class  note how flat the other class signature quality is  this is a strong indicator of a good classifier 

discussion
support vector machines have demonstrated high performance in character recognition  and we feel have
performed even better in spatial wafer pattern recognition  one potential reason why is that spatial wafer
patterns will generally have the same exact chips  or pixels  failing  image recognition techniques tend to do well
with good centering of target objects  so ours is somewhat the extreme case of that  this may be related to why
binary features perform so much better as specific chip  or pixel  location is an important factor  adaptive
features also show a dramatic improvement as a lot of the noise from other parts of the wafer that may have
other systematics is filtered out  in order to push training set requirements even further  we are developing a
semi supervised type strategy where we can iteratively evolve a training set using unlabeled data and sqm
scores from multiple runs with slightly different training sets   this is an area of active development we plan to
pursue more rigorously in the future 

conclusion
we have demonstrated in this paper that support vector machines can be very effectively trained to identify
spatial wafer patterns of failing chips  the most effective feature encoding is a binary one  for pass   and fail   
with an adaptive feature vector that filters out uninteresting chips on the wafer  we are hence able to take a
relatively small training set and calculate yield impact with very high precision  we still need to automate most of
the flow in a robust manner before users can just throw in a handful of wafer and get good results  but the steps
necessary are much clearer after completing this project 

acknowledgements
we would like to thank andrew maas for all his guidance and advice during all his project office hours and
beyond  we also want to thank prof  andrew ng for such an insightful course on machine learning 

references
   
   
   
   

fast and accurate digit classification  eecs berkeley edu pubs techrpts      eecs          pdf 
libsvm  a library for support vector machines  http   www csie ntu edu tw  cjlin libsvm 
weka    data mining software in java  http   www cs waikato ac nz ml weka 
a framework for learning predictive structures from multiple tasks and unlabeled data
 jmlr csail mit edu papers volume  ando  a ando  a pdf 

fi