 

film classification by trailer features
edmund helmer and qinghui ji
december         

  

introduction

the matrix  a sci fi film released in       was famous for telling viewers in its trailer that 
unfortunately  no one can be told what the matrix is  you have to see it for yourself  and
film goers did  resulting in over      million worldwide box office gross  four academy award
wins  and an     critic approval rate  according to rotten tomatoes   the decision to see any
film is based on many factors  cast  critical opinion  recommendations of our friends  but often
its simply because we like the trailer  so we ask the question  what information can a machine
extract from trailers 
for this paper  we have collected a set of trailers      with video      with subtitles  
extracted features from the video feeds and the subtitle texts  and attempted to classify the genre
and mpaa rating of each film 

  

data

 a 
video features
the potential feature space from a trailer is massive  including an rgb tuple for every pixel for
every frame of every trailer  as well as potential object detection  in order to prune the space into
a more manageable set  we used three main categories of video features      mean frames     
scene variation      face recognition  to obtain the trailers  we used python to scrape thenumbers com  film site  to download all trailers that the site hosts        and the python module
opencv provided the tools to complete the video analysis 
    to create what we call mean frames  for each pixel location  we averaged all
values of that pixel over the frames of the trailers  and in effect created a single blurred image
for each trailer  fig    shows two example mean frames  finding nemo and the recent release 
lincoln  while image blurring is a standard technique used for background detection   as far as
we know  the creation of mean frames is an original concept in visual analysis  though similar to
key frame detection  described in more detail later  

fig     mean frames of finding nemo  lincoln

  

   

fi 

from the mean frames  we extracted the rgb histograms  which represent the
distribution of red  green  and blue used in the trailer  as shown in fig     each colors vector of
intensities were then recorded as features 

fig     mean histograms finding nemo  lincoln

    key frame generation is a standard task in video processing  which splits any video
file into its separate scenes  and key frames are the splitting points  one method used to create
key frames is to measure the change in each pixels rgb values between each consecutive
frames  and returns the frames following the highest changes   we used this idea to measure the
number of scene changes by keeping an average of the frame changes over each trailer  with the
idea that some genres or mpaa ratings may be described by faster or slower cutting of scenes 
    finally  we hypothesized that some genres and mpaa ratings would feature more or
fewer people in their trailers  and that face recognition algorithms would provide a reasonable
proxy for this  fig    demonstrates face recognition from one trailer of harry potter and the
deathly hallows  part    one example of the algorithm in process 

fig     face recognition from harry potter and the deathly hallows  part  

 b 
text features
words spoken in a trailer are text files downloaded from the youtube closed caption database
and was read into a matrix  similar to the spam dataset  each row is one sample and each
column is a word  due to the scarcity of english subtitle resource online  we downloaded
spanish versions  first we deleted all the words that are less than two characters  then using
treetagger packages from university of stuttgart  we scrubbed all the words  words like articles
 el   preposition  y  and proper noun michael  were removed  noun and verbs were then
adjusted to their standard forms  acercara  acercarnos and acercarte to acercar   at the end 
we reduced the number of words from      to      

  

models and evaluation

  a

video features

  

   

fi 

the features extracted from the video provided some separation without any complex analysis 
as shown in fig     a mapping of genre and mpaa rating by percent of time in the trailer faces
appeared  facetime   and the average brightness of the trailer  brightness  

fig     mpaa rating and genre mapped to facetime and brightness 

the most easily seen results are that  g rated films tend to skew left  which turns out to
be because they heavily involve animated features with non human characters  drama and
comedy feature the most human content  horror films use the least amount of brightness in the
trailers 
to attempt classification  we applied   different main classification algorithms  nave
bayes  multi class support vector machine  and random forest  although the original feature
space included the entire histogram of rgb values stemming from each films mean frame  we
found that results were improved  even over tuning  by only using the mean values of each color
as features  and that using the entire vector of information for each color led to overfitting  the
support vector machine was tested over linear  radial basis  sigmoid  and polynomial kernels  as
well as tuned by  and cost  the random forest was only tuned to include enough trees to reach
convergence  and nave bayes was run without tuning 
shown below  the multi class support vector machine has the highest accuracy in
predicting genre  and random forest has the highest accuracy in predicting mpaa rating 

fig     classification accuracy histograms of test accuracy       iterations      training  on mpaa and genre

  

   

fi 
table    mean accuracy rate across classifiers predicting mpaa rating by video features

naive bayes

svm

random forest

mle

multinomial

      

       

       

     

      

    p value     

   

comparing difference in mean accuracy to the mle classification 

table    mean accuracy rate across classifiers predicting mpaa rating by video features

naive bayes

svm

random forest

mle

multinomial

      

       

       

     

      

    p value         comparing difference in mean accuracy to the mle classification 

the classification techniques were compared to sampling randomly from a multinomial
distribution  as parameterized by the training set distributions   and compared to an mle
estimate  which is selecting the mode of the training tags   the algorithms were run selecting an
        training testing split over      iterations  and all classification algorithms showed
statistical significance  except nave bayes in predicting mpaa 
table    mean accuracy rate across classifiers predicting genre by text features

naive bayes

svm

random forest

mle

multinomial

       

       

       

      

      

    p value     

   

comparing difference in mean accuracy to the mle classification 

  b
text features
for subtitle features  we cleaned the data set as described above  then  as in video data  we ran
the same three classifiers on subtitle dataset  and compared over     iterations with an        
training testing split on the data  the random forest accuracy rate on testing was         using
a linear kernel svm  we gained a testing accuracy rate of      a mean improvement over mle 
but without statistical significance  and using nave bayes  we did not beat the mle estimate 
we also compared results to using the bag of words approach  without cleaning the data first  but
found that the cleaned data set had more accuracy  and was computationally far more efficient 

fig     classification accuracy histograms

  

   

fi 
of test accuracy       iterations      training 

naive bayes

svm

random forest

mle

multinomial

      

      

       

    

     

    p value     

   

comparing difference in means to the mle classification 

we also generated the top   gram that was most indicative of the each class  for

each word w  given a certain class  c 
     
action
bien

  

adventure
solo

animation
vida

 
   

comedy
solo

  
                 
 
               

drama
nuevo

horror
sexo

  

musical
hacer

sci fi
bien

thriller
pronto

further work

  a
larger dataset
the selection of trailers from the numbers only presented     observations  and the number of
trailers found with spanish subtitles only numbered      a more complex scraping tool would
allow us to download more trailers for video processing  and as closed captioning becomes a
higher priority  it may become easier to find trailers with subtitles  in spanish or in english  
  b
more features and ensemble learning
other features from the trailer such as audio  including volume  length and key tune of the
background music could be included into the model for better results 
another feature we considered was mapping trailer cuts to the time sample from the
original movie  the core idea is that some trailers spoil more of a movie than others  which
when quantified may divide films in a meaningful way  either by genre or mpaa rating  or by
other potential taggings such as critical reception 
finally  an ensemble of the subtitle and video classification could be achieved if the
datasets were generated with more or complete overlap 

  

references

    zang  qi  and reinhard klette   robust background subtraction and maintenance   pattern
recognition        icpr       proceedings of the   th international conference on  vol    
ieee       
    liu  lijie  and guoliang fan   combined key frame extraction and object based video
segmentation   circuits and systems for video technology  ieee transactions on             
        

  

   

fi