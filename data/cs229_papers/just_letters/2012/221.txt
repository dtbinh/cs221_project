distinguishing opinion from news
katherine busch
abstract
newspapers have separate sections for opinion articles and news articles  the goal of this
project is to classify articles as opinion versus news and also to do analysis of the results to
figure out the factors that distinguish the two  preliminary results show that classification is
possible with unigram features in an svm with f  of     
introduction
this project focuses on subjectivity classification for news articles  much prior work on
subjectivity has focused on distinguishing positive and negative sentiment  for instance  in
product reviews  or classifying phrases or clauses as subjective  liu         here we attempt to
distinguish entire articles as reporting news or expressing opinion  the task is related but has
some key differences  for instance  review type sentiment analysis often relies on pre made
lexicons or focuses on classifying words as positive or negative  toprak and gurevych       
turney and littman        potts   words associated with positivity and negativity are not
necessarily those associated with editorials and opinion pieces in which authors pose
sophisticated arguments about current events  policies  etc  one goal of the project was to gain a
lexical understanding of words that can distinguish the two categories  and thus be able to
generate a lexicon similar those already existing for sentiment analysis of reviews that would
work for articles 
prior work
there has been thorough research into document classification  machine learning in automated
text categorization   sebastiani        provides an overview of work up to       within the
area of subjectivity sentiment analysis there is also a wide variety of work  pang and lee give an
overview of the field of subjectivity  pang and lee         liu defines many different problems
within the field including sentiment and subjectivity classification 
    classifying an opinionated document as expressing a positive or negative
opinion  and     classifying a sentence or a clause of the sentence as subjective
or objective
 liu       
liu also gives an overview of the field thus far from a teaching perspective  turney and littman
provide a method for sentiment for particular words based on their context  turney and littman 
       yu and hatzivassiloglou specifically address distinguishing opinion from news using a
naive bayes classifier and are able to achieve very high results  yu and hatzivassiloglou        
however  their method did not generalize to my dataset 
data
i use two datasets  both consisting of articles from the new york times  the primary dataset
consists of     articles over the course of the   years up to and including       for comparison 
i also test on a dataset of articles from october and november      in which news events are
covered repeatedly  the data was collected by scraping the new york times website  the first
 

fiset includes    news articles and   opinion articles year arbitrarily selected  the second includes
the entire world and united states news sections and entire opinion sections for several days in
the past months  the discussion below concerns the long term set unless otherwise specified 
results
dataset  new york times articles          
learning algorithm
multinomial nb with laplace smoothing
svm  unigram counts
svm  unigram counts with stemming
svm  tfidf
svm with pos tags counts     features 
svm with pos and stemmed unigram
svm with top      features
table    f  for large time period dataset

f 
   
   
   
   
   
   
   

analysis
i focus on the results for the mixed years dataset and only use the small time period dataset for
comparison in the language results section  overall  our classifier achieved high precision and
recall for the test set with the best f  score of     using a linear svm with unigram counts as
features  well above the multinomial naive bayes baseline of      below we detail the
techniques we tried and where we succeeded 
feature and classifier selection

f  by number of features

    
    
    
    
f 

    
   
    
    
    
    
 

    

    
    
top features used by mi

    

    

figure    searching top features  by mutual information score  for optimal number of features
for classifier selection  we tried binomial and multinomial naive bayes and svm with a linear
kernel  other kernels discussed below   with initial features  svm outperformed naive bayes
 

fiwith an f  of     compared to     for naive bayes  while the difference is slight  it widened as
we sought to improve the performance as discussed below  other results suggest than in general
svm outperforms naive bayes in text classification  so this difference is expected and we will
focus on svm for the rest of the paper due to its superior performance  rennie        
for feature selection  we began with unigram counts using stop words  with just unigram counts
alone  an svm achieved     f   adding bigrams and trigams did not improve the classifier at all 
and this is likely due to sparsity of data  sparsity is a common problem with unigram models in
which the number of features is much less than the number of training examples  ng   with
unigrams alone  our feature space had      features  yet only    training examples  adding ngrams only increases that space 
instead we tried several successful techniques for reducing the feature space  with porter
stemming  which reduces the feature space by merging words with the same roots  the score
increased to      using a mutual information measure of binarized features vectors  we searched
the space of number of features in increments of      peaking at      features and an f  of     
this indicates that the top      words are better for distinguishing opinion from news than the
space of all of the features  however  it is interesting to note that just the top     features were
able to achieve an f  of     which is still very high  after that  the gain in score per feature
diminishes greatly  so a classifier interested in efficiency and willing to compromise slightly on
correctly could do extremely well in this     dimensional feature space 
we also tried using tf idf instead of counts  previous research has suggested that tf idf
improves scores for text classification  rennie et al        toprak and gurevych          we
were unable to replicate these results and instead saw f  decreased to      while we do not have
a good explanation for why this should be different  usage of stop words and stemming might
have helped eliminate words like  the  that would be overcounted  the goal of tf idf is to
give higher weight to words that occur a lot in a document but little over the corpus  another
theory is that if a news and opinion piece are about the same event  they will have high tf idf
for words related to that event but that word will not help to distinguish the class  however  the
phenomenon is also likely to be a peculiarity of the dataset 
finally  some work showed that part of speech counts might be effective at subjectivity
classification  toprak and gurevych         to test this  we used the counts of part of speech
tags from the penn treebank tagger  the results were unsuccessful with f  falling to      with
articles mostly getting classified as news  nor did these improve score when used in
conjunction with unigram features  the theory behind this is that more adjectives would be used
in opinion pieces  that this phenomenon was not observed is probably another difference
between newspaper pieces and the traditional reviews that subjectivity research focuses on 
to further improve our results  we tried using both polynomial and gaussian kernels  while we
achieved similar results with these kernels  we were not able to exceed the results from a linear
kernel  we believe this is because the initial data was already linearly separable with the
exception of a few outliers that the algorithm will not be able to detect 

 

fiindeed  upon looking at the misclassified examples  half were actually reviews of movies  travel
destinations  etc  that are not technically classified by the new york times as opinion because
they do not appear with the other opinion and editorial pieces  one could argue that the data is
mislabeled 
language related results
top rated by mutual information for short term dataset 
   quot
    tax
   year
    officials
   party
    city
   years
    medicaid
   israel
    court
   federal
    women
   bbc
    campaign
   united
    cuts
   ms
    country
    time
    american
top rated by mutual information for long term dataset 
   dr
    studi
   report
    kill
   work
    told
   product
    republican
   percent
    street
   iraq
    research
   includ
    plan
   world
    polic
   project
    program
    secur
    rais
the world that mutual information measurement found to be most informative of category
corroborated the hypothesis that traditional sentiment lexicons such as tud subjective verb
lexicon used in toprak and gurevych to some would not be as effective for news articles
 toprak and gurevych        tud  
the short term data set as expected includes more words related to specific news events of the
last few months  especially politics related ones that were prevalent during the united states
election season  such as campaign  country  party  and the word israel due to the israeli attach on
gaza  in the short term  particular news pieces are more successful than opinion or news related
words in general at distinguishing the categories 
the long term data set  by contrast  included only one word that appeared to be related to a
particular event  iraq  since the iraq war lasted over the entire period that the dataset was
collected from  the presence of the word makes sense  the rest of the words  such as report 
work  percent  kill  or polic seem to be clearly connected reporting or opining 

 

fithe long term top     features are available at http   katherinebusch com op news features txt
as a ready made lexicon for newspaper subjectivity analysis 
conclusions
the task of distinguishing opinion and news appears to be ones that can be solved with relatively
simple tools  much to the credit of the new york times  prior work in document classification
appears to have been effective at this specific classification task  in the future  it would be
interesting to explore generalizing the task to different dataset to test whether the lexicon of
news opinion words generated by the model succeeds in classifying articles from other
newspapers  news sources  blogs  etc  one could also try using features related to sentence
structure  these would be unlikely to improve score but might provide interesting linguistic
insights 
references
liu   sentiment analysis and subjectivity   handbook of natural language processing   nd
edition       
ng  cs    class notes  cs    stanford edu 
pang and lee  opinion mining and sentiment analysis  foundations and trends in information
retrieval         pp             
potts   sentiment analysis tutorial   http   sentiment christopherpotts net 
rennie et al   tackling the poor assumptions of naive bayes text classifiers        
sebastiani   machine learning in automated text categorization   acm computing surveys 
     
toprak and gurevych   document level subjectivity classication experiments in deft  
challenge   deft          
tud subject verb lexicon  http   www ukp tu darmstadt de data sentiment analysis subjectiveverbs lexicons
turney and littman   measuring praise and criticism  inference of semantic orientation from
association   acm transactions on information systems  vol      no     october      
yu and hatzivassiloglou  towards answering opinion questions  separating facts from opinions
and identifying the polarity of opinion sentences  in proceedings of the      conference on
empirical methods in natural language processing  pages         sapporo  japan       
libraries used
sklearn  nltk

 

fi