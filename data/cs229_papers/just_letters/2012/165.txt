cs    titanic  machine learning from disaster

eric lam
stanford university

abstract
in this project  we see how we can use machine learning
techniques to predict survivors of the titanic  with a
dataset of     individuals containing features like sex  age 
and class  we attempt to predict the survivors of a small
test group of      in particular  compare different machine
learning techniques like nave bayes  svm  and decision
tree analysis 

   introduction
using data provided by www kaggle com  our goal is to
apply machine learning techniques to successfully predict
which passengers survived the sinking of the titanic 
features like ticket price  age  sex  and class will be used
to make the predictions 
we take several approaches to this problem in order to
compare and contrast the different machine learning
techniques  by looking at the results of each technique we
can make some insights about the problem  the methods
used in the project include nave bayes  svm  and
decision tree  using these methods  we try to predict the
survival of passengers using different combinations of
features 
the challenge boils down to a classification problem
given a set of features  one way to make predictions
would be to use nave bayes      another would be to use
svm to map our features to a higher dimensional space 
our approach will be to first use nave bayes as a baseline
measure of what is achievable  once this is complete  we
use svm     on our data to see if we can achieve better
results  lastly we use decision tree analysis     and find
the optimal decision boundaries 

chongxuan tang
stanford university

   data set
the data we used for our project was provided on the
kaggle website  we were given     passenger samples for
our training set and their associated labels of whether or
not the passenger survived  for each passenger  we were
given his her passenger class  name  sex  age  number of
siblings spouses aboard  number of parents children
aboard  ticket number  fare  cabin embarked  and port of
embarkation  for the test data  we had     samples in the
same format 
the dataset is not complete  meaning that for several
samples  one or many of fields were not available and
marked empty  especially in the latter fields  age  fare 
cabin  and port   however  all sample points contained at
least information about gender and passenger class  to
normalize the data  we replace missing values with the
mean of the remaining data set or other values 

   data analysis
in order to prepare our data for training in our nave
bayes classifier  we remove or replace blank values and
determine bin sizes for each feature  for instance  fare can
range a large number of values  so we group fares
together  the same is done for cabin data since the data is
divided into cabin sections  a b c d   a similar grouping
is done to the ticket data 
for our svm  we do not need to bin values together 
instead we simply turn all the values into numerical
values  in order to do this  well interpret the bit
representation of strings and characters as float
represented numbers 

figure    data breakdown by sex  class and age  percentages are percent that survived  red boxes
indicate mostly died  green boxes indicate mostly survived  and grey indicates     survival

fiin figure    of the previous page  we see the breakdown
of the data to get a better sense of what features might be
good indicators of our classification problem  first  we
notice that out of all the passengers in the test data 
       survived  if we breakdown the group into sex  we
see that a significant difference in survival between
females          and males           this is a strong
indicator that sex would probably be a good feature to use 
continuing our analysis  we see that of the females in first
class and second class  first class can be thought of as
upper class  second class as middle class  and third class as
lower class   more than     survived  third class fared
much worse with a     survival rate  of the males  first
class had a much higher survival rate          than
second          or third           interestingly  there
was not significant variation in survival given a persons
age in any subgroup except for youths in second class 

   approach method
basic nave bayes classification in     is used as a
baseline to see what is achievable  more sophisticated
techniques like svm in     and decision tree analysis is
used     to see if improvements can be made in the
classification test  we experimented with using different
feature sets of each method and found the optimal feature
combination on the test group 

   nave bayes
as a benchmark  we first implemented nave bayes     
for the nave bayes model  we considered the following
features     sex     passenger class     age  and    fare  we
chose to use the multinomial event model and laplace
smoothing  first we had to find p died  and p survived 
by tallying up the number of passengers that survived and
dividing by the total number of samples  both gender and
passenger class took on discrete values  gender has two
values  male and female  and passenger class has three
values   st   nd  and  rd class  next  we had to estimate the
conditional probabilities of these features given whether a
passenger
survived 
for
example 
to
find
    we had to count the number of male
survivors and divide that by the total number of survivors 
the same can be done for other features and values 
before computing the parameter estimates for the
features age and fare  they first need to be discretized  for
age  we grouped the ages into buckets of size    we used a
default value of    for samples for which age information
was not provided  similarly  for fare  we grouped the fare
prices into buckets of size    and used    for samples with
no fare information  after discretizing age and fare  we
found the estimate for conditional probabilities of those
features given whether a passenger died or survived the
same way as before 

the conditional probability computed from the training set
is given by
 
              
     

where  is a particular feature and  is survival  we
iterate through all the training examples   this gives us a
conditional probability distribution based on survival 
using this conditional probability distribution  we can
compute the probability that a test point survives given the
feature set  we use the maximum a posteriori or map
decision rule as shown below 
             arg max                   
 

where   are our features   is true if survived and false if
not survived  we multiply the probability of each feature
given a negative outcome and compare that with the
probability of each feature given a positive outcome  we
make a prediction based on which probability is greater 
table    nave bayes accuracy  using different
features
pclass
sex
age
fare
accuracy
yes
yes
yes
yes
      
yes
yes
no
yes
      
no
yes
yes
yes
      
yes
no
yes
yes
      
no
yes
no
no
      
we tried several different combinations of features to
use  shown in the table above  and the gender of the
passenger seemed to be the strongest indicator of whether
a he she survived  adding the other three features to our
nave bayes model did not improve the prediction
accuracy  this is probably because gender has the most
correlation to survival and dominates the nave bayes
classifier  however  without considering the gender
feature  the addition of other features did improve the
performance of the classifier  which shows that although
the other features are not as strong an indicator of survival 
they still do have a small correlation to a passengers
chance of survival 

   svm
to improve our classification  we used support vector
machines      we considered the following features    
passenger class     sex     age     number of siblings    
patriarchal status     fare  and    place of embarkation  we
used a gaussian radial basis function as our kernel and set
the tolerance to         

fipclass
yes
no
no
no
no
no
no

table    svm accuracy  using different features
age
sibsp
parch
fare
embarked
no
no
no
no
yes
yes
yes
yes
no
no
no
yes
no
yes
no
no
no
yes
yes
yes
yes
no
yes
no
yes
yes
yes
no
yes
yes
yes
no
no
yes
yes

sex
yes
yes
yes
no
no
yes
no

unlike nave bayes  no extra data cleaning was
needed  iterating through all possible feature
combinations  we were able to achieve an accuracy rate of
       on the test data set using only three features  the
three features that achieve this rate were class  sex and
place of embarkation  using age  fare  and place of
embarkation resulted in the worst accuracy of         it
is interesting to note that this accuracy would be less if we
had just guessed that all test points died  accuracy of
         this suggests that perhaps class and sex are
strong indicators of survival whereas age and fare are
weaker indicators of survival  in figure    we see the svm
learning curve using the features class  sex and place of
embarkation  at around     samples  the training curve
has reached its asymptotic value of        and any
additional sample does not improve the accuracy 

svm learning curve
    

    

accuracy

    

    

    

    

    

 

   

   

   

   
   
training size

   

   

   

   

figure    svm learning curve using class  sex  and place
of embarkation

   decision tree
we built our decision using the following features  gender  passenger class  age  and fare  we first split the
data into males and females because it was most correlated
with the chance of survival  from just using a single
feature  we achieved an accuracy of         which is the

accuracy
      
      
      
      
      
      
      

same percentage as nave bayes with just the gender
feature  this is expected since with just the gender feature 
both classifiers are labeling test samples the same way
 which is marking all females as survived and all males as
died  
then we split both males and females into passenger
classes  even after splitting the data into passenger class 
males in each class are more likely to die  and passengers
in each class  other than class    are more likely to survive 
if we choose the hard decision that female passengers in
class   all survive  it will still produce an accuracy of
       because the classifier hasnt changed from the
earlier process of labeling all males as died and females as
survived  however  if we choose the hard decision that all
females in class   will die  our accuracy improves to
       on the test data 
next  we look at the feature age  since the domain of
age is continuous  we have to find a good decision
boundary to split our data  after plotting the age and
survival of passengers in each gender and passenger class 
we decided to use a binary decision because in most cases 
older passengers were more likely to die than younger
ones  instead of using the same age boundary for each
gender and passenger class  we considered each gender
and passenger class  case by case and found different
boundary thresholds for each  to find our boundary
threshold  we tried to minimize the classification error on
our training set  this means that we chose the age
boundary for each gender and passenger class such that if
we classify all samples below the age boundary as
survived and all above as died  we minimize the
classification error on the training set  after including age
in the decision tree  we achieve a classification error of
       

fifemale  class  

male  class  
   

   
survived
dead

   

   

fare

fare

   
   

   
   

   

   

   
 

 

 

  

  
age

  

  

figure    optimal decision boundaries for the subgroup
male  class  

 

  

  
age

  

  

figure    fare vs  age and survival in the subgroup
female  class  
female  class  

male  class  

  

  
survived
dead

  

survived
dead

  

  

  

  

  

fare

fare

survived
dead

   

  
  

  
  

  

  

  

 
 

 

  

  
age

  

 

  

  

  

figure    optimal decision boundaries for the subgroup
male  class  

  
age

  

  

  

figure    optimal decision boundaries for the subgroup
female  class  

male  class  

female  class  

  

  

survived
dead

  

survived
dead
  

  
fare

fare

  

  

  

  

  

  
 

 

  

  
age

  

  

figure    optimal decision boundaries for the subgroup
male  class  

 

 

  

  
age

  

  

figure    optimal decision boundaries for the subgroup
female  class  

fithe fare feature itself is not well correlated with
survival rate so we decided to consider fare together with
age  for males in class    the training data suggests that
young passengers and passengers who pay a high fare are
most likely to survive  for both males and females in class
   the training data suggests that passengers who are both
young and paid low fare are most likely to survive  for
passengers in class   and females in class    fare didnt
seem to be a factor in determining survival rate  so after
finding the boundary thresholds to use for male in class  
and passengers in class    that minimizes the error in the
training set  we achieved a prediction accuracy of       
on the test data 
we also tried separating the data based on other based
such as the number of siblings spouses and the number of
parents children aboard  however  these features did not
provide good insight into survival rate 

   results
of the three methods  nave bayes performed the worst
and decision tree performed the best  however  the best
and worst performance only differs by       so all the
methods have roughly the same performance on our data
set  this is probably because there was one feature that
was strongly correlated with whether a passenger survives 
the nave bayes model assumes that all features are
independent but the decision tree does not make this
assumption  even though the decision tree considers
correlation between features  it only performs marginally
better than nave bayes  so this shows that assuming that
features are independent is not necessarily a bad
assumption for our problem  table   offers a summary of
the achievable accuracy using nave bayes  svm  and
decision tree analysis 
even though we were given many features of
passengers in our data  we found that most of the features
were not useful in classification  for example  the number
of sibling spouses and the number of parents children did
not help with classification in any of the three models 
knowing the number of relatives aboard did not help with
classification  but perhaps  if we were given the links
between passengers then wed be able to infer more about
the survival rate  since family units tend to all die or all
survive  knowing the family links would have been useful 
table    comparison of performance
nave bayes
       accuracy
svm
       accuracy
decision tree
       accuracy

   conclusion future work
there were not significant differences in accuracy
between the three methods we experimented with  even
using every combination of features  we were still not able
to produce an accuracy rate that was much different than
simple nave bayes classifier using only sex as a feature 
it appears that the other features were only weakly
indicative of survival  as sex seemed to dominate the
others in terms of being able to accurately predict survival 
even with more sophisticated algorithms  we were not
able to achieve much improvement  this shows the
importance of choosing important features and obtaining
good data 
it would be interesting to continue this analysis with
other possible features or with other machine learning
algorithms like random forests or other variants of nave
bayes 

    references
    a  ng  cs    notes  stanford university      
    cortes  corinna  and vapnik  vladimir n    support vector
networks   machine learning           
    stuart j  russell   peter norvig  artificial intelligence  a
modern approach  pearson education       pg        

future distribution permission
the author s  of this report give permission for this
document to be distributed to stanford affiliated students
taking future courses 

fi