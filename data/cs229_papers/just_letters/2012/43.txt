structural learning for web design

maxine lim
arvind satyanarayan
cesar torres
stanford university  stanford  ca       usa

abstract
recursive neural networks  rnns  have been
successful for structured prediction in domains such as language and image processing 
these techniques imposed structure onto sentences or images for more effective learning 
however  in domains such as web design 
structure is explicitly embedded in the document object model  so structured prediction can be done using the natural hierarchy
of web pages  this characteristic also allows
for features to be inserted at each node of the
rnn rather than only using features at the
leaves  we show that for structural label prediction  this technique outperforms the baseline by     though it performs poorly for
style labels for reasons that are likely a result of suboptimal data 

   introduction
design is difficult to quantify  but in domains such as
web design  it can be represented digitally in the form
of html  css  and its external resources  as a result  we can leverage this data and enable machines to
interpret design elements  for example  given a web
page  can we automatically decide if this page looks
minimal or modern  how can we best encode these
qualitative characteristics in data representations 
in this paper we investigate using structural prediction techniques to learn design descriptors for web
pages  based on previous work in web design and
machine learning  we adapt a method using recursive
neural networks  rnns  to more accurately represent
web design by embeding page structure into the feature representations of web elements  we use these

maxinel stanford edu
arvindsatya cs stanford edu
ctorres  stanford edu

structure embedded feature representations to train
classifiers for two classes of design descriptors  our results show that structure is indeed an important factor
to consider when applying machine learning to web
design  and our technique is able to outperform the
baseline 

   background
     motivation
automatic prediction of design descriptors can enable
a new class of tools for web design  structural semantic labels  e g   sidebar or comment can enable tools
that automatically manipulate web content such as
page to page or page to mobile retargeting  leveraging style and content based keywords in design search
can help inspire and direct design work by helping
designers find relevant inspiration  currently  finding
this inspiration is limited to manually curated galleries
or template libraries  these search techniques do not
provide flexible or scalable navigation of the full web 
     previous work
from previous work we point out three important insights  first  training off the shelf binary svm classifiers for structural semantics using crowdsourced labels with a set of       visual features is feasible
and achieves a     average accuracy  lim et al  
       second  when applying machine learning to
web design  page structure is important  kumar et al  
       and third  structured prediction using rnns
has proven successful in domains such as natural language and image processing  whose entities do not possess an explicit structure  socher et al          combining these insights  we adapt an existing structured
prediction technique for a domain where structure is
explicit  structure has been shown to be important
in applying machine learning  and learning has been
shown to be feasible 

fistructural learning for web design

   method

wstyle

where m is the number of raw features assigned   and
wsem   n m       the bias term has been combined into all the parameter matrices   we select f to
be the tanh function rather than the sigmoid function
because our normalized data values range from       
rather than       

wdomain

div

body
                 
w

ws
body

we then incorporate the result into computing the activation 


c 
 c  

p   f  w 
cparent   
 

                     

wstruct

img

div
                 
w

img
                 
ws

ws
h 

h 

img

                     

img

                     

as in previous work  we then add to each rnn parent
node a softmax layer to predict class labels 

p

h 
                 

p

                 

ws

ws
h 

                     

p

                     

   data preparation
     feature set

figure    our adapted rnn model that incorporates raw
feature vectors at every node 

     our model
previous work used rnns for structured prediction
in domains such as language and image processing  socher et al          using the underlying dom
tree of web pages  we eliminate the need to develop
the structural extraction techniques used in other domains  furthermore  this explicit structure allows us
to incorporate an additional set of features corresponding to the parent node at every neuron in the rnn 
an overview of our model is shown in figure   

each of our examples is a web element with its corresponding feature vector  these elements are derived
from the bento segmentation of the dom tree  which
segments visually salient blocks from web pages  kumar et al          the       dimensional feature vectors for each element include dom related properties
 e g  tree level  number of children   css attributes
 e g  font  color  size   and computer vision features
 e g  gist descriptors   these web elements along
with their feature vectors are provided by the webzeitgeist repository  kumar et al         
     tree binarization

     adaptation for web design
our adaptation of rnns for structured prediction involves modifying the feed forward step of the algorithm  typically  the activations for each node of the
rnn is computed by 

a
b

c

a
d

e

a
b

d

a
a

e
a

c
b

 
c 
p   f  w c    
 
where f is the sigmoid function  c    c    p   n    and 
w   n  n     
in our technique  we apply the semantic transformation to the parent node 


fparent
cparent   f  wsem
  
 

e
d

c

figure    the tree binarization process  which adheres to
chomsky normal form 

training rnns required binarizing the dom trees for
each web page  to maintain the parent child relationships among the nodes  we constructed post order
trees from their bento segmentations and binarized
them using chomsky normal form as shown in figure   
this method requires that all product rules follow the

fistructural learning for web design

form 
a  bc
a
s
thus  if a node has more than two children  a new
product rule would be derived of the form 
a  bcd  a  be and e  cd
where e is a new intermediary dummy node which
inherits its feature representation from its parent a 
the resulting trees were assigned a post order identifier and stored within a nosql database along with
information describing how to map the original node
back to its parent identifier  this mapping is needed
to reconstruct the tree for training and evaluation 
     label collection

fr
equenc
y

we collected two classes of labels with which to train
rnns  style and structural semantic  style labels describe the design of the web page  e g   minimal or
elegant  and structural semantic labels describe the
purpose of each element on the page  e g   sidebar or
comment  while style labels are page level descriptors  structural semantic labels describe an individual
page node  we ran one study for gathering the pagelevel labels and another for gathering node level labels 
overall we recruited over       us based participants
from amazons mechanical turk and odesk to apply
over        domain  style  and structural semantic labels to over       web pages  these pages were drawn
from the webzeitgeist design repository  which provides visual segmentations and page features for more
than         web pages  kumar et al         

st
y
l
ela
bel
s

st
r
uc
t
ur
a
l
sema
nt
i
cla
bel
s

figure    heavy tailed distributions of collected label sets 

     cleaning data
allowing users to enter labels in a free form text field
encouraged a wide variety of labels  but it also resulted
in a heavily tailed frequency distribution  as shown in
   among the thousands of distinct labels  many only

table    number of total and distinct raw labels for all
three label classes 
label type

total raw

distinct raw

site type
style
structural

      
      
      

     
     
     

table    number of total and distinct used labels for all
three label classes 
label type

total used

distinct used

site type
style
structural

      
      
      

  
  
  

occurred one time or had effectively the same meaning
as another label  these labels differed only by choice
of delimiter  e g   eye  catching and eye catching  or
word form  e g   religious and religion  we applied a
series of transformations to clean the raw data 
to clean the site type and style labels  we first trimmed
each entry of extra punctuation at the ends  i e  
simple became simple  we proceeded to split long
compound labels by the underscore character only if
each of the resulting terms had already occurred in
our label set  for examine simple clean minimal
would be split into simple  clean  and minimal
since each had occurred in the set individually  but
black and white would not  because and did not appear in our original label set  next we merged labels
with common stems derived from the porter  stemming algorithm  then manually merged labels such as
cartoonish and cartoon  finally  we removed labels
that had only been applied once or only by one person  for the structural semantic labels  we only removed labels that had only been applied once or by a
single individual 
     label results
the number of total and distinct labels from our study
for the two label classes is shown in table    even after
cleaning the data  there were still hundreds of distinct
labels for each class  many of which would be difficult
to for a person  much less a learning algorithm  to distinguish between  furthermore  many labels only occurred a handful of times  producing too few examples
to expect our rnn to learn  therefore we selected the
most frequent set of labels to learn  maintaining only

fistructural learning for web design

the labels that occurred fifty or more times  this final
filter reduced each set of labels to less than a hundred
distinct elements  as shown in table   

   learning
     unit tests
given the changes we introduced to the rnn framework  we constructed a set of simple unit tests to
verify that gradient descent would converge correctly 
these test cases involved simple tree structures of     
nodes    raw features and     label classes which were
fed through the rnn with gradient check enabled 
with this flag  the gradient descent library would calculate an expected gradient and compare it to the output of the rnn  once our unit tests passed the gradient check  we had some level of confidence on the
validity of our code 
     experimental setup
to train and evaluate the rnn  we constructed a holdout set with     of the data used for training and    
for testing  for a baseline comparison  we developed
a softmax only classifier which was trained only on
labeled nodes  i e   ignored the structural hierarchy of
a web page tree   after several rounds of training and
testing  we determined two suitable metrics for judging the accuracy of label classifiers  cross entropy and
whether ground truth labels were in the top n predicted labels  where n is the number of ground truth
labels  the latter is a more human understandable
measure of accuracy that remains robust against multiple co occurring labels without penalizing predicted
ordering 
     parameter tweaking
adjusting the parameters of the rnn significantly affected its performance  in particular  we tweaked two
parameters  n  the number of hidden nodes in the
rnn  beginning at    and in increments of     and
  the regularization constant  by orders of magnitude
starting at         we found the optimal parameters 
determined by the highest average test accuracy of labels  to be n                 on average  the rnn
would take       hours to train  thus due to time
constraints  we were only able to adjust parameters
for a limited set of permutations 

   results and discussion
at the optimal parameters of n                 the
average test accuracy of structural rnn classifiers is

    with search being the most accurately classified
label at     and user control at     in comparison  the baseline average test accuracy is      on the
other hand  style labels perform significantly worse 
the average test accuracy is    for rnns compared
to a baseline average of     many of the style labels were not accurately predicted whatsoever     
by either  however  clean and modern performed well
under both conditions      and     respectively for
rnn      and     for the baseline  these accuracies
are listed in figure   

training accuracies
n      lambda     
type
  labels
structural semantic
   
style
   

softmax     rnn   
  
  
 
 

testing accuracies
n      lambda  
type
structural semantic
style

  labels softmax     rnn   
  
  
  
  
 
 

figure    average training and test accuracies for structural semantic and style labels  for structural labels  rnn
outperforms the baseline 

although the rnn classified labels do perform  on average  better than the baseline  we expected the addition of structural information to make a larger impact 
moreover  while previous work obtained an average accuracy of     for structural labels using binary svms 
our results are much lower  granted  given that the
data  the label set  and the metric are different  these
numbers are perhaps unfairly compared 
however  one reason for this result can a sparse data
set  we had many distinct labels  and the frequency
was not evenly distributed among them  labels that
performed well tended to have more examples  collapsing this set of labels even further  or collecting
more data would help to reduce the skew in the data
set 
another problem with our data was the miscalculation
of negative examples  due to the manner in which we
conducted our crowdsourced label collection  we did
not have any true negative examples  if a node or
page does not have a specific label  it does not imply
that it is not in that class  counting a lack of a label
as a negative label is likely having a detrimental effect
on the learning 

fistructural learning for web design

figure    heat map of raw features grouped by label for structural and style labels  note the density difference between
style and structural semantic feature vectors 

our data set does not entirely account for why style label classifiers performed so poorly  especially compared
to their structural counterparts  we hypothesize that
our choice of softmax classifier is also negatively affecting style label accuracy  typically  a node can only be
labeled with any one of the structural labels  thus 
softmax is a good classifier to use here as all probabilities must sum to    but in the case of style labels 
a page can be described with multiple labels  making
softmax cause a smearing of predicted probabilities 
training multiple binary classifiers might be a better
choice for non disjoint labels 
although we do not have optimal results  we have evidence that these descriptors can be learned and that
structure is important in this learning  as shown in
figure    the heatmap visualizations of raw features
grouped by label show clear banding  which implies
that there are patterns to be learned for both structural and style labels  additionally  rnns do better
than the baseline for structural labels by     indicating that structure can further inform the learning 

   conclusion
we have implemented an adapted rnn algorithm for
embedding structure into the feature representations
for web elements to predict design descriptors for web
design  weve shown that for the optimal parameter
combination  our method is able to outperform the
baseline by    for structural labels  unfortunately
overall our accuracies are low  and for style labels our
classifiers consistently performed poorly  we point to
parameter adjustment  a richer  better data set  and
different classifers types for the different label classes
as ways to improve our accuracies 
     future work
looking ahead we are re running our experiments with
a collapsed label set of approximately twenty labels
per label class  by merging similar labels together
 e g  header and heading  and removing ones that
were difficult for even humans to understand  e g 
user control   we believe that a more accurate set of

softmax classifiers will be learnt on a smaller label set 
we have also launched a new round of crowdsourced label collection to increase the density of our label set  in
this study  participants are given the newly collapsed
set of labels and are taken through our corpus page bypage  for each page  participants are asked to select all
style labels that apply  they are then taken through
each structural label individually and asked to select
all visual blocks that fit the label  with this design  we
can be more confident that our dataset is complete  in
particular  as participants see the whole set of labels 
if a node or page does not have a particular label  this
does indeed count as a negative example 
with style labels  we are investigating the effects of
training multiple  independent logistic classifiers  one
per label  the obvious caveat is that different style
labels may not necessarily be independent  a page being labeled clean may also imply that it is minimal 
nonetheless  we believe this may be a first step towards addressing the issue of probability smearing
discussed previously 

acknowledgments
this work was done in collaboration with ranjitha
kumar  richard socher  jerry o  talton  and scott
r  klemmer 

references
kumar  r   talton  j  o   ahmad  s   and klemmer  s  r 
bricolage  example based retargeting for web design  in
chi  acm conference on human factors in computing
systems       
kumar  r   satyanarayan  a   torres  c   lim  m   ahmad 
s   klemmer  s  r   and talton  j  o  webzeitgeist 
design mining the web  in chi  acm conference on
human factors in computing systems       
lim  m   kumar  r   satyanarayan  a   torres  c   talton 
j  o   and klemmer  s  r  learning structural semantics
for the web  technical report  stanford university       
socher  r   lin  c  chiung yu  ng  a  y   and manning 
c  d  parsing natural scenes and natural language with
recursive neural networks  in proceedings of the   th
international conference on machine learning       

fi