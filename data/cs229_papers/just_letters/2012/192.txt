using twitter data to predict box office revenues
p  thomas barthelemy  bartho stanford edu 
department of computer science      serra mall
stanford  ca      

devin guillory  deving   stanford edu 
department of computer science      serra mall
stanford  ca      

chip mandal  cmandal stanford edu 
department of computer science      serra mall
stanford  ca      
abstract
we summarize an effort to predict box office revenues using
twitter data  it is hypothesized that an increased number of
tweets about a movie before its release will result in increased
box office revenue  our task can be decomposed into two subtasks  the estimation of the frequency of tweets about particular movies and revenue prediction given this frequency 
keywords  tweet classification  nave bayes 

overview and motivation
the strategy was to first identify the number of tweets about
the movie prior to movie opening  and then to use regression
to create a model for predicting box office revenue  the former was the more challenging task  and we approached it in
three different ways  the most basic way was to count the occurrence of the title in tweets  although there are clear cases
in which this is not expected to perform well  next  we attempted a variant of nave bayes  finally  we utilized a bag
of words model to estimate the frequency of tweets which are
about the movie 
we did not use hashtags during classification  as our twitter dataset is from       before hashtags were commonly
used 

data and processing
we used two separate data sources  twitter data and movie
reviews from imdb 

transformers as an indicator for transformers  revenge of
the fallen and inglourious for inglorious basterds  such
a classification method was expected to bias our probabilities
of movie specific wordsthat is  we would expect an overestimated probability of the movie titleand thus was not used
for such purpose  rather  the approximately labeled tweets
were used for identifying movie general words  e g  movie 
watch  tonight  or for validating classification 
initial word counts were performed using grep  the performance of grep was slow  especially since some of our algorithms required searching multiple keywords in a given file 
for better performance  we indexed the tweets using apache
lucene  direct frequency calculation was performed using
this index  inference was implemented using tweet by tweet
classification 

imdb review data
we used imdb for two goals  to identify general attributes
for each movie  e g  opening day  box office revenue  and to
observe the probability of generating a particular word in reference to a movie  concerning this latter point  we assumed
that the probability of generating a word in an imdb review
about a given movie was the same as the probability of generating the same word in a tweet about the same movie    
reviews per movie were taken from imdb  each set including
about        words in total 

models

twitter data
the twitter data included a sampling of approximately half
a billion tweets over the last   months of       because we
wanted to predict revenue for    movies and tweets about
movies occurred at a rate of       at best  and usually far less
than that  it was not feasible to label tweets for each movie 
we manually examined   k tweets to label those that were
about movies in generalthat is  about any movie  this was
used to identify the prior probability of a tweet being about
any movie  a value used in the nave bayes analysis 
on occasion  we used a search labeled set of tweets by
searching for movies for which it was unlikely to mistake the
title or keyword for a non movie reference  and we assumed
that this correctly labeled the tweets  for instance  we used

we used multiple methods to estimate the frequency of tweets
as input to our regression model  the two initial strategies attempt to classify these tweets individually  and the remaining
strategies consider instead a particular day as simply a mix
of a non movie specific bag of words and a movie specific
tweets bag of words 

title search
to provide baseline performance  we fit linear regression
model using a keyword search  as shown in figure    that
is  we simply searched the occurrence of the title  case insensitive  in all of the tweets in the week before their respective
opening days 

fifigure    the graphical model representing the probability
of a tweet containing a particular word conditional upon it
being about any movie and conditional upon it being about a
particular movie 
figure    count of tweets having title words versus movie
revenue 
searching for the movie title is not always a good indicator that the tweet is about a movie  there are two common
cases in which this posed a problem  first is the case in which
the movie title is long and infrequently mentioned in its entirety  for instance  the lord of the rings  the fellowship of
the ring is often referred to as lord of the rings or even
lotr  second is the case in which the title is very short
and likely to be contained in tweets that do not refer to the
movie  one example of this is shorts  a movie released in
august      

nave bayes
we could not use conventional nave bayes for tweet classification because we did not know the prior probability of a
tweet being about a specific movie   if we did  this part of
our project would be trivial   we considered circumventing
this problem by decomposing the causal model into one for
which the probabilities could be estimated 
let ma be the variable representing the tweet being about
any movie  ma   or not about any movie  ma    let ms be the
variable representing a tweet being about a movie  ms   or not
about a movie  ms    and let w represent the generation of
a particular word  given the graphical model in figure   
and using the simplifying assumption that p w  ma   ms    
p w  ma  p w  ms   and the fact that p ms  ma        we can
represent the probability of a tweet being about a specific
movie given a word 
p ms  w  
p w  
ma p w  ms   ma  p ms  ma  p ma  
 
ma ms p w  ms   ma  p ms  ma  p ma  
p w  ms  p w  ma  p ms  ma  p ma  
 
ma ms p w  ms  p w  ma  p ms  ma  p ma  

p ms  w    

there is a similar derivation for p ms  w    though the
summand in the numerator remains  this gives us many more
probabilities that we have to estimate  however  there are
ways to approximate them 
 p ma   was calculated using the   k hand labeled tweets  it
was observed that the prior probability of the tweet being
about a movie is roughly       
 p w  ma   was calculated using search labeled data  because the search labeled data was selected on the basis of
the movie title  the sampling method was not expected to
adversely effect the probabilities of movie general words 
words with high p w  ma   included movie  watch  and
tonight 
 p w  ms   was approximated using imdb data  that is  we
assumed that the distribution of words in imdb movie reviews matched the distribution of words in tweets about the
same movie  for the movie transformers  revenge of the
fallen  words with high p w  ms   included transformers 
bumblebee  and optimus 
 p ms  ma   could not be measured  our strategy was to assume that it would be fixed and calculate it by optimizing
the f  score using a few movies 
frequent itemset analysis as an optimization  we limited the set of movie general words using frequent itemset
analysis  that is  we identified a set of movie general words
having the highest interest before calculating the probability
p w  ma   for each  interest is defined as 
interest w     p ms  w    p w  
here  we estimate p ms  w   by identifying the frequency of
word w as it appears in the result of an exact title search  the
other probability p w   is simply the frequency of word w in
all tweets 

filetting sn be the n highest interest words for a particular
movie  we calculate how common the word w is using 
cw  

  n
   w  sn  
n n  

for words common to many movie specific tweets  e g 
movie   this value is larger than      for words specific
to only one movie  it is close to   n 
estimating p ms  ma   we selected a p ms  ma   to optimizing the f  score for particular test movies  it was expected
that optimizing over various movies would allow us to select
an average value which we could use for nave bayes 
we computed the f  score by measuring both precision
and recall  we used our search labeled dataset to measure
both values  though this allows one to obtain a recall value
greater than one  for instance  when comparing classification of tweets about transformers  revenge of the fallen for
which the label is defined based on the presence of the word
transformers  our classification algorithm identified some
tweets that were about the movie but did not contain the word
transformers  for instance  the algorithm identified tweets
referring to the character bumblebee  nevertheless  the goal
of this exercise was to optimize the f  score  which could be
performed regardless of the denominator used in recall 
the ultimate concern with the nave bayes model is apparent in table    which shows the optimal conditional probability for a set of movies  note that the optimal value of
p ms  ma   varies greatly from movie to movie  it varies from
      to       correspondingly  the precision and recall was
greatly reduced when using p ms  ma   far away from the optimal value for that movie  thus  the probability of a tweet
being about a specific movie given that that tweet is about any
movie cannot be well approximated by a fixed value  thus 
our nave bayes model would not be useful by itself to predict the number of tweets about a movie  it is for this reason
that we did not use it to predict movie revenue 
table    optimal p ms  ma   values 
movie title
law abiding citizen
district  
transformers    

p ms  ma  
     
    
   

performance in table    we compare performance of
nave bayes to the direct title search  to do so  we searched
over a subset of tweets on opening day of the particular
movie  determining precision is straight forward  we can
simply hand classify the positively labeled tweets  recall is
more challenging  because it is not feasible to label enough
tweets for a usable sample  we must presume a number of true
positives  however  in our case  we provide the f  values primarily to compare two classification strategies  and thus the

number of true positives is arbitrary as long as we keep it consistent  for each movie  we use as the number of true positives the maximum value of correctly identified tweets over
the two classification techniques 

table    comparison of title search and nave bayes performance using f  score 
movie title
law abiding citizen
fame
zombieland
transformers    

title search
    
    
    
    

nave bayes
    
    
    
    

notably  there is a large performance improvement when
searching for movies with long names like transformers  revenge of the fallen  which was expected  however  there is
not a significant gain in the identification of tweets relavent to
a movie titled with a short  commonly used word like fame 
further  the title search performs much better when looking
for movies titled with short  uncommonly used words like
zombieland  in general  the nave bayes model provides
more consistent f  score  which suggests that it would result in better revenue prediction were it not for the fact that
we cannot hold fixed p ms  ma   
there were observable differences in the word frequencies
of imdb data and twitter data  the primary difference is
that reviews about a particular movie infrequently reference
the movie title  as this context is understood by the audience 
conversely  such a context is not understood in the twittersphere  the audience would not know that a tweet is about a
movie unless it contained a movie title or an obvious reference  thus  we augmented our imdb data by adding the title
to the imdb reviews at a frequency of one out of every   
words  which corresponds to the assumption that each tweet
about a movie contains roughly one mention of the title  this
ensured that the most indicative word for the movie was generally a word in the movie title itself  however  there were
cases in which other words were still more indicative  as in
mj  for michael jackson  for the movie this is it 
additionally  there was noticeable difference between
imdb vernacular and twitter vernacular  for instance  it
was observed that the imdb reviews about this is it used the
word mj less frequently than tweets about the same movie 
this keyword appeared with a frequency of approximately
one mention every thousand words in imdb reviews  however  when simply searching for tweets with the phrase this
is it  the incidence of mj was approximately one order of
magnitude higher           we consider this to be a conservative estimate because this set of tweets included some
tweets that were not about the movie  that is  searching for the
movie title was not completely precise   thus  the incidence
of mj in tweets about this is it is certainly over       

fifrequency estimation
if we divide the tweets on opening day into two groups 
tweets about the specific movie and all remaining tweets  we
can consider both separately as bags of words  next  if we assume that on some arbitrary day far from the movie opening 
the bag is entirely not about the movie  then we can estimate
the mix of the bag on opening day  we estimate the following values 
 p w  ms   can be approximated as the frequency of word
w on an arbitrary day far away from opening day 
 p w  ms   can be approximated as the frequency of word
w in imdb reviews in the same manner as defined in the
nave bayes analysis 
 p w   is essentially a mixed bag observed near or on opening day  so  this probability is equal to the proportionate
contribution of each bag 

figure    estimated frequency of movie specific tweet versus
movie revenue  uncorrected 

p w     p w  ms  p ms     p w  ms      p ms   
ultimately  we can solve for the prior probability of the
movie  which provides the equation below  assuming that
the length of each tweet is constant  then p ms   gives us the
fraction of tweets about our movie 
p ms    

p w    p w  ms  
p w  ms    p w  ms  

theoretically  this equation should hold for any word 
however  this equation is sensitive to errors when the denominator is close to zero  our strategy for avoiding this circumstance is to use the word with the highest ratio of p w  ms  
to p w  ms    which tended to prefer words in the movie title
like pelham from the taking of pelham       
performance results of this process are shown in figure   
some outliers are noticeable  it is impossible for a frequency
to be negative  and it is unlikely that nearly all tweets on one
day were about one movie  the data point having frequency
     represents this is it  for which the frequency is grossly
overestimated because we underestimated the frequency of
mj in tweets about the movie  ignoring movies with predicted frequencies less than zero and greater than      we have
figure   
table   shows a few comparisons between observed and
predicted frequencies  where the observed tweets were identified using a keyword search  assuming that a majority of
the tweets about the test movies contain the keyword specified in the table  then the observed frequency should be within
a factor of two of the actual frequency  notice  however  that
the predicted frequency is one to two orders of magnitude too
large 
this is could be caused by an underestimation of p w  ms   
the scope of discussion on imdb movie reviews is much
more rich than what is generally included in movie tweets and
is likely to contain a much more varied set of movie specific

table    observed and predicted frequencies of tweets about
a movie 
movie title
ice age  
sherlock holmes
transformers    

keyword
ice age
sherlock
transformers

obs 
      
      
     

pred 
     
    
    

words  that is  since a tweet about a movie must make obvious to its audience that it is about a particular movie within
only a few dozen words  it is unlikely that the tweet will mention an obscure  or  improbable  word related to the movie 
imdb reviews  on the other hand  are free to discuss more
nuanced topics at length and in detail  in short  the distribution of words for tweets is skewed towards a smaller set
of words  thus  when selecting the word with the maximum
frequency  we underestimate p w  ms    which would in turn
make our predicted p ms   too high 
nevertheless  the source of this error affects the data in a
sufficiently regular fashion that the model offers slightly improved prediction over the title search model  which is discussed in the model comparison section 
frequency estimate variant as a slight tweak  if we take
the words with the highest p w  ms   p w  ms   and scale the
numerator of the p w   equation above  we are left with an
equation that biases movies for which the indicative words
have large changes from the control day and for which the
word strongly indicates the movie  roughly  our score is as
follows 
keyword score    p w    p w  ms   

p w  ms  
p w  ms  

this score further improves our ability to predict box office
movie revenue 

fifigure    estimated frequency of movie specific tweet versus
movie revenue  with outliers removed 

figure    performance of the various models  average rms
error from loocv decreases with each subsequent model 
though there remains room for improvement 
we demonstrated the potential to use labeled data from an
alternative source when labeled data from the target source
is absent  however  the result is strictly an approximation
and ignores the differing contexts and colloquialisms idiosyncratic to a particular medium 
the revenue of a movie may also be determined by other
factors  like revenue of the lead actor  budget of the movie 
etc  adding additional features like this to suppliment tweet
frequency could provide a better model for revenue prediction 
future work could also combine the frequency estimation
with classification  that is  if one can estimate the prior probability of tweets about a movie  then one could apply our variant of nave bayes  this could allow one to apply more sophisticated text analysis  like sentiment analysis 

figure    keyword score and movie revenue 

model comparison
for each model  we predict movie revenue using linear
regression  next  we use leave one out cross validation
 loocv  to compare the performance of our models 
as shown in figure    the average rms error is improved
from    m to    m  which one could compare to the average revenue of movies in our set     m  further  we tried
fitting to higher order polynomials  but we observed marginal
improvement at second order and overfitting at higher order
polynomials  in short  the accuracy of our models predictions leaves room for future work 

conclusion and future work
we demonstrated various techniques for estimating tweet frequencies and attempted to use this to predict movie revenue 
prediction accuracy was improved over a simple title search 

fi