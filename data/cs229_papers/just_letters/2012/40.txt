identifying important communications

aaron jaffey
ajaffey stanford edu

akifumi kobashi
akobashi stanford edu

abstract
as we move towards a society increasingly dependent on electronic communication  our inbox sizes have become so large that many of us cannot keep up with the
deluge of information  to that end  we wanted to know if it would be possible to
reduce some aspect of this social noise by using machine learning to filter out what
users consider to be unimportant  although this sounds similar to a spam filtering problem  we wanted to consider all major forms of electronic communication 
phone  email  and facebook  furthermore  this type of classification is highly individual  compared to spam filtering  so ones own communications provide the
best source for training data  using naive bayes and svm classifiers trained on
a sizeable set of communication metadata  cross validation showed that the algorithms performed decently on these different sources  achieving a best accuracy
around     for facebook data      for cellular data  and       for email data 
these data sources appear to be weakly correlated  and so it is difficult to improve
classification accuracy by linking various communications using an address book 

 

methodology and data

in order to train classification algorithms  it was first necessary to collect personal communications
data  for each of the three means of communication we utilized  we wrote python scripts to scrape
the data  we obtained email data using imap  facebook data using the facebook developer api 
and cell phone data through an export process from our cell phone carriers 
for this problem  we chose a simple binary classification scheme to divide communications into important and unimportant  while this is a rather granular classification scheme  it makes automated
and manual classification of training data easier  for example  for email  we are able to classify training data using different methods based on ones usage patterns  in one case  we can consider read
messages in the the users inbox as important  and unread ones as unimportant  alternatively  we can
consider messages in ones inbox as important  and archived messages as unimportant  similarly 
we can assume that emails one replied to were important  facebook message data is rather difficult
to classify automatically by examining metadata  while the facebook message center is constantly
changing  users do not typically receive sufficient unimportant mail that is discarded to use this as
training data  furthermore  almost all personal messages appear in the users inbox  determining
if a facebook message was replied to is problematic  because messages can be divided into short
snippets from chat sessions  and clustering them to identify conversations is an undertaking in itself 
due to these difficulties  we chose to classify facebook messages manually  classifying phone call
data posed a similar problem  so we also chose to classify calls manually 
with this project  we hoped not only to attempt to classify important communications within each
platform  but also to link our classification results together in a logical and useful way  a natural
way to do this is to connect data based on the other party in the communication  we began by
exporting our personal address book data into a form that could be integrated with machine learning
algorithms  and queried to derive a unique identifier for a person based on their name  email address 
or phone number  if the third party was not in the address book  we generated a new unique identifier
for them  by including features that link a communication to its sender recipient  we attempted to
 

fiderive an importance measure for individuals one communicates with  this data can be plugged
back into the algorithms and be used to classify new test data with better theoretical accuracy  for
example  if users were to make a number of phone calls to their friend  we hoped the algorithm
might increase the predicted importance of emails received from their friend 
since we chose to make this a binary classification problem  natural choices of algorithms are supervised learning algorithms such as naive bayes  and support vector machines  we wrote an
implementation of naive bayes in matlab  and used libsvm     

 

choice of features

we chose to include as many features as possible from metadata that had non zero data  and data
that was easily convertible to a numeric value  in cases where there was redundant or irrelevant
data  i e  cell phone call records contain a rate code responding to time of day  in addition to a
timestamp  as well as a billing category that depends on the other partys carrier   we left out the
redundant features to avoid adding extra noise into our classification problems  for cell phone data 
we have seven per call featuresday of week  time of day  duration  frequency of calle r ee   time
since last call with this person  whether or not a call was incoming  and if the calle r ee  is in the
address book  facebook metadata provides six features  whether the message is read  the fraction
of unread messages in a thread  number of messages in a thread  frequency of messages from the
sender recipient  length of the message  and number of words in the message  email included these
six  in addition to whether the users email was located on the to  the cc  or neither 
in order to integrate the different forms of electronic communication  we added an identifier for
the other party in the communication to each data vector  we experimented with different ways
of integrating this information  including using one binary feature for each person the user has
communicated with  using a single identifier for the other party involved  and directly including
features detailing the frequency of communication with the party  we settled on the first method
since it was simplest way to handle communications with multiple recipients 

 

combining data sources

since we classified three different types of communications data separately  we hoped to combine
the results of training on these data sets in a useful way  that is  we hoped to increase our accuracy of
classification by associating communication across different modes  we tried two different ways of
integrating data from the different sets  first  we tried direct insertion of features  in other words  for
each of the three modes we explored  we injected features associated with the sender initiator  some
derived from other modes  for example  features used in email classification included the frequency
of phone calls sent and received with the sender of the email  in addition to the frequency of email
communication  in total  four features were added to each of the three mode of communication 
corresponding to the frequency of sent received messages from the other two modes 
we also tried using the decision values from training each data set to produce an importance metric
for each sample  this approach made sense  particularly for naive bayes and linear svm  since
in the first case  the decision value was a probability the message was important  and in the second
case  the value was the distance from the margin  using the address book  we mapped these decision
values into a matrix by individual and communication type  we repeated the following algorithm
until cross validation accuracy stopped changing 
   for each communication type j  train the algorithm and then classify the training data using
the model 
   compute the following
 i 

 i 

 i 

 a  for each sample xj   extract the contacts vector cj   where each element in cj is a
binary value corresponding to whether or not a particular contact was involved in the
 i 
message  all together  the cj values produce a matrix c 
 b  find the matrix d   v t c  where v is a vector containing the decision values for each
sample 
 

fi c  to compute a per contact value  we averaged all of the non zero columns in d to get
the vector c j  
   stack the c j vectors vertically to create a new matrix c     and generate a new vector c  
by taking the geometric means column by column  the choice of geometric mean was
motivated by the fact that the margins  or probability values  from different data sets are not
comparable in absolute values  but make more sense when compared relatively  in doing
so  we chose to weight each of the three forms of communication equally  but introducing
weighting coefficients for each of the communication methods may be useful if there is
sufficient overlap in the data for this technique to be effective 
 i 

   for each communication type  multiply the vectors c   and cj element by element to modify the original data  producing new training data xj  

 
   

results
comparison of different algorithms and kernels

we compared three algorithms for
classification  a support vector machine with linear and gaussian kernels  in addition to a naive bayes
classification  using    fold cross
validation  we generated statistics for
the accuracy of different data set
sizes  for data sets smaller than the
full data set  we performed the crossvalidation test    times and averaged
the results to better represent the true
accuracy of these smaller data sets 
svm  figure    with both kernels
performed extremely well for email
data with accuracies close to      
much better than the naive bayes
which still achieved a respectable
    accuracy  naive bayes accuracy
 figure    was slightly better than
svm accuracy for a very small data
set  as expected  due to smaller sample complexity  accuracy using a linear kernel was very close to accuracy
using a gaussian kernel 

figure    cross validation accuracy of svm using linear
kernel 

    combining
modes of communication
our attempt to combine the data from
different sources was not very beneficial for large sample sizes when applied to our data sets in either of our
strategies  with our first tactic of feature injection  the cross validation accuracy increased slightly when combined with phone data  but with the
full email data set  this benefit shrank
to less than      across the board 
the learning curve in figure   illustrates the improvements seen  in our

figure    cross validation accuracy of naive bayes 

 

fisecond strategy  we saw a limited improvement in cross validation accuracy for naive bayes of
        and an improvement for svm kernels of        
   

feature selection

by running a feature selection algorithm based on f scores      we found
that in most cases the frequency of
contact with the sender of the message was the most heavily weighted
feature  this is in line with our hypothesis that it is the person that matters  and not so much the content of
the message  interestingly  the accuracy of classification dropped  then
plateaued after just five features  indicating that high accuracy can be attained with very few features  the
five  in order of weighting are    the
number of emails sent to the sender
   number of emails received from
the sender    number of emails in the
thread    whether the email was directed to us on to or cc and    the
number of words in the subject 
figure    cross validation accuracy of email data  when usfor cellular data  the most heavily ing features inserted from data obtained through other comweighted features were whether the munication types 
calle r ee  was in the address book 
followed by the call duration  this is
logical  since most important phone calls are from somebody one knows  this data depended much
more on the presence of the contact identifiers than email in order to obtain high accuracy 
for fb data  message length was the most indicative feature  followed by the fraction of unread
messages in a thread  this makes sense as well  as short chat messages are likely less important than
longer ones 
   

error analysis

our initial efforts were focused on breaking past this     accuracy barrier  but a manual examination of all of the miscategorized emails indicated that all of these were emails that were read
by mistake  or read based on the words of the subject  by manually classifying the misclassified
emails into these two categories  we found that     of the miscategorized emails were read based
on the words in the subject  but would have otherwise not been read  e g  interesting job postings
on a noisy mailing list   thus  even introducing a textual feature recognition algorithm would have
only reduced the incorrectly classified emails by about      with the remaining     a systematic
unavoidable error inherent in our metric of importance being measured by message read unread
status 
we also generated statistics on the precision and recall of our classifiers  table    to see if they were
more biased toward choosing messages as important or unimportant  additionally  we obtained
information on how well the data was balanced between the two classes  for phone  facebook  and
email data respectively            and     of the messages in the training data set were considered
important  fortunately  for email and phone data  the precision statistic  which represents the fraction
true unimportant
true unimportant
true unimportant false unimportant   was larger than the recall statistic  true unimportant false important   this means
those classifiers were less likely to miss an important message than they were to mark an unimportant
message as important  for this problem  this was the preferred bias since misclassified unimportant
messages can easily be discarded or looked at later  for the email data  the only unbalanced data
set  the recall statistic was not too low  indicating that the classifier was good at not classifying too
many unimportant messages as important 
 

fitable    linear svm classifier precision and recall using full data set 
email
phone
fb
precision
recall

 

      
      

      
      

      
      

conclusion

for many people  email  phone  and facebook communication data sets seem to be used for distinct
and mutually exclusive purposes  in other words  communication with a particular person was primarily restricted to one mode  for example  grandparents are always contacted by phone  parents by
email  and friends by facebook  in fact  our data showed that only       of contacts were common
among more than one of the communication schemes  this corroborates our examination of why
email classification accuracy barely improves with the addition of both facebook and phone data 
because the strongest features were the number of emails sent and received  a boost in accuracy was
only seen where an oft contacted friend on one mode switched over to another mode temporarily 
continuing the example above  this would be an email from grandparents 
accuracy obtained using the svm classifier was decent enough to be used as an aid  but insufficient
to use as a screening mechanism as is often used with spam filters  since unimportant communications are still likely to be attended to by the recipient  having perfect accuracy is not crucial  one
possible implementation for email or facebook would be a filter based on importance  where the
user would choose to read important messages immediately  and the others at a regular  but less
frequent interval  a configurable threshold could allow the user to set a bias based on their level of
concern about the chance of missing an important message until later 

 

future plans

for this project  we chose to utilize large data sets from recent communications  we realized that our
approach could also be applied to live data using an online learning approach  this would be a more
practical implementation that would enable the algorithm to adapt to new contacts and importance
preferences  online learning could be particularly interesting for cellular communicationsyour
phone might predict whether an incoming call is important  and then be trained based on whether or
not you answered it 
also  addition of textual features from both the subject and the body of messages would likely
improve the accuracy of classifying facebook data  since facebook metadata is sparse and it is
difficult to distinguish between different messages in a thread and their importance using exclusively
metadata 
another potential interesting extension would be the application of hierarchical machine learning
principles  where many child classifiers could be trained for each different contact the user has 
and a parent classifier could be used where the child classifiers are not accurate enough or have no
information about a user 

references
    chang  c     lin  c          libsvm  a library for support vector machines  acm transactions on intelligent systems and technology  tist            
    chen  y     lin  c          combining svms with various feature selection strategies  feature
extraction          
    hsu  c   chang  c     lin  c          a practical guide to support vector classification  retrieved from http   www csie ntu edu tw  cjlin papers guide guide pdf 

 

fi