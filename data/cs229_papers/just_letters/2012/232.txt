phishing detection using neural network
ningxia zhang  yongqing yuan
department of computer science  department of statistics  stanford university

abstract
the goal of this project is to apply multilayer feedforward neural networks to phishing email detection and evaluate the effectiveness of
this approach  we design the feature set  process the phishing dataset  and implement the neural network  nn  systems  we then use
cross validation to evaluate the performance of nns with different numbers of hidden units and activation functions  we also compare
the performance of nns with other major machine learning algorithms  from the statistical analysis  we conclude that nns with an
appropriate number of hidden units can achieve satisfactory accuracy even when the training examples are scarce  moreover  our feature
selection is effective in capturing the characteristics of phishing emails  as most machine learning algorithms can yield reasonable results
with it 

 

introduction

incorporating some basic features pertaining to the email
structure and external links 

recently  a phishing email has been circulating in the
stanford community  aiming to collect sunetids and passwords  as the majority of phishing emails are formatted
to appear from a legitimate source  a large percentage
of email users are unable to recognize phishing attacks 
moreover  traditional spam email filters are inclined to fail
to identify phishing emails since most phishing attacks use
more sophisticated techniques and tend to be directed to a
more targeted audience  with the increasing severity of this
issue  many efforts have been devoted to apply machine
learning methods to phishing detection 

 
   

methods
features

after referring to available literature  we have selected and
defined a set of features that capture the characteristics of
phishing emails           

one of the most common machine learning techniques
for phishing classification is to use a list of key features
to represent an email and apply a learning algorithm to
classify an email to phishing or ham based on the selected
features  chandrasekaran et al      proposed a novel
technique to classify phishing emails based on distinct
structural characteristics  such as the structure of the email
subject line and some functional words  they used svm to
test their features on     emails and obtained a     accuracy rate  however  they did not perform different splits
between training and test data due to the small sample size 
fette et al      used ten different features specific to the
deceptive methods for phishing classification and obtained
an f   measure of more than     using a support vector machine classifier  however they used significantly more ham
emails        than phishing emails       in their simulation 

     

structural features

   total number of body parts
according to mime standard   content type  attribute of
one email could be multipart  meaning that this email has
multiple body parts  phishers are likely to utilize this fact to
construct phishing emails with sophisticated structures  by
counting the number of boundary variables  we obtain the
number of body parts in a multipart email  if the  contenttype  of the email is not multipart  this feature is set to
   for the purpose of differentiating from multipart emails
with only one body part  if one part can be further divided
into multiple parts  the number of sub parts is added to
the number of parts of the entire email  for example  if an
email has   body parts  one of which has   sub parts  the
number of body parts is set to    however  only   parts of
the content are scanned in the feature extraction process 
   total number of alternative parts
the multipart alternative subtype indicates that each part
is an  alternative  version of the same or similar content 
each in a different format denoted by its  content type 
header      as it is not strictly enforced that each part
of the message is the same or similar  phishers often take
advantage of this fact to create fraudulent emails 

in this project  we use approximately      emails out
of which      are phishing emails and the rest are ham 
we notice that few studies have been done on applications of neural networks  nns  to phishing email filtering 
although nns normally require considerable time for parameter training  they usually yield more accurate results
than other classifiers      in our project  we try to detect
phishing attacks through a feedforward neural network by
 

fi     

appear as phishers fabricate stories luring readers to enter
their personal information 

link features

   total number of links
phishing emails usually contain multiple links to fake websites for readers to sign in 
   number of ip based links
a legitimate website usually has a domain name for identification while phishers typically use multiple zombie systems to host phishing sites  besides  the use of ip address
makes it difficult for readers to know exactly which site
they are being directed to when they click on the link 
therefore  the presence of ip based links can be a good
indicator of phishing emails 
   number of deceptive links
deceptive links are the ones with visible urls different
from the urls to which they are pointing  some phishers
use this technique to fool email readers into clicking on the
links 
   number of links behind an image
in order to make the emails look authentic  phishers often
place in the emails images or banners linking to a legitimate
website  thus  if url based images appear in an email  it
is likely to be an phishing email 
   maximum number of dots in a link
using sub domains is another technique phishers often
exploit to make links appear legitimate  resulting in a inordinately large number of dots in the url     
   a boolean indicator of whether there is a link that contains
one of the following words  click  here  login  update
to realize the goal of acquiring usernames  passwords  or
credit card information from the readers  phishing emails
often invite readers to login to the fake websites for reasons
such as updating personal information  therefore  those
words appearing in the link text would be a good indicator 
     

   

an artificial neural network  or neural network  is a mathematical model inspired by biological neural networks  in
most cases it is an adaptive system that changes its structure during learning       there are many different types
of nns  for the purpose of phishing detection  which is
basically a classification problem  we choose multilayer
feedforward nn  in a feedforward nn  the connections
between neurons do not form a directed cycle  contrasted
with recurrent nns  which are often used for pattern recognition  feedforward nns are better at modeling relationships between inputs and outputs  in our experiments  we
use the most common structure of multilayer feedforward
nn  which consists of one input layer  one hidden layer
and one output layer  the number of computational units
in the input and output layers corresponds to the number
of inputs and outputs  different numbers of units in the
hidden layer are attempted in the following experiments 
to fit our dataset  hyperbolic tangent and sigmoid are used
as activation functions  a comparison of the two is also
conducted  with regard to the training method  we choose
resilient propagation training  rprop   as it is usually the
most efficient training algorithm for supervised feedforward nns     

   

other machine learning techniques

to further evaluate the performance of nns in phishing
detection  we compare its performance against that of other
major machine learning classifiers  decision tree  dt  
k nearest neighbors  naive bayes  nb   support vector machine  svm  and unsupervised k means clustering  the
same dataset and feature set are used in the comparison 

element features

   a boolean indicator of whether it is in html format
phishing emails are mostly in html format as plain text
does not provide the opportunity to play the tricks of phishing 
   a boolean indicator of whether it contains javascript
javascript enables phishers to perform many actions behind
the scene  such as creating popup windows and changing
the status bar of a web browser      if the email contains
strings   javascript  or  onclick   this feature is set to one 
   a boolean indicator of whether it contains  form  tag
html forms are one of the techniques used to gather
information from readers     
     

neural networks

   

cross validation

given a training dataset and a proposed classifer  we assess the performance of the classifier by using hold out
cross validation  also known as simple cross validation     
the dataset is randomly divided into strain and scv   the
proposed classifier is trained on strain to get parameter estimates and tested on scv   we then obtain the output which
indicates whether each email in scv is ham or phishing 
this procedure is repeated    times for different sizes of
strain and scv   the proportions of the dataset used as strain
are as follows                                         
         and     

word list features

   boolean indicators of whether the words or stems listed below
appear in the email body  account  update  confirm  verify  secur 
notif  log  click  inconvenien
in typical phishing email examples  these words frequently

   

evaluation metrics

by comparing the classification predictions with the actual
categories of the emails  we are able to compute the num 

fibers of true negatives  tn  correctly classified ham email  
false negatives  fn  phishing email mistakenly classified as
ham   true positives  tp  correctly classified phishing email 
and false positives  fp  ham email mistakenly classified
as phishing   to evaluate the classifier performance  we
compute the accuracy accu  and the weighted accuracy
 wacc   by the following formula 
accu  
wacc     

tn   tp
tn   fp  tp  fn

   

 tn   tp
  tn   fp   fn   tp

   

     

in order to ensure that each feature has an equal impact in
the classification process  the vectors should be normalized
before applying machine learning algorithms  for each
feature  we find the maximum and minimum values  and
for each value of this feature  we compute 
normalized value  

tp
tp  fp

f   

 

recall  

tp
tp  fn

  precisionrecall
precision recall

     

   

   

   

   

     

feature extraction

data analysis

once we obtain the classification predictions  we compute
tn  fn  tp  fp  accu  waccu   precision  recall and f   score
as described in the method section  we compare different
neural networks by varying the units in the hidden layer
as well as the activation function  we also compare the
performance of neural networks with that of other machine
learning techniques 

implementation and experiments
preprocessing

machine learning implementation

the multilayer feedforward nn is implemented in java
with the encog java core package  which provides a powerful framework to conveniently construct nns and perform
training and testing  when implementing other machine
learning algorithms  we exploit the corresponding off theshelf matlab packages 

dataset

   

training and test sets preparation

to conduct the cross validations described above  we divide the dataset into training and test sets with different
proportions  for each proportion  we generate    different
training and test sets  this is done by matlab 

the dataset comprises of a large number of real world examples of ham and phishing emails  all in standard mime
format  there are a total number of      ham emails and
     phishing emails  separated in   folders    of which
hold ham emails and   hold phishing emails  each text file
contains a single mime email 

 

 current valueminimum 
 maximumminimum 

after normalization  the values of all features fall into the
range of   to   and each feature contributes the same in determining the classification output  the normalized vectors
of the whole dataset are stored in another text file 

in phishing email filtering  errors are not of equal importance  a false positive is much more costly than a false
negative in the real world      it is thus desirable to have
a classfier with a low false positive rate  the  weighted
accuracy  measure is proposed by androutsopoulos et al 
    to address this issue  different values of  can be applied to the formula      notice that when  is one  the fp
and fn are weighed equally  in our simulations  we pick
     so that fp are penalized nine times more than fn 
in addition  we compute the precision  recall and f   score
of each classifer as follows 
precision  

normalization

we write a perl script to extract features from one email
example  it reads in the email file  does structural analysis
with the help of mime  entity and mime  parser modules 
it summarises link features using html  simplelinkextor
and html  linkextractor modules  other features are
obtained by taking advantage of the powerful regular expression manipulation of perl  ultimately  it outputs a
feature vector together with the ideal value    for phishing
email and   for ham   to process the entire dataset  another
perl script is written to call the feature extracting script and
write the obtained feature vectors line by line into one text
file 

 

results

as mentioned in the previous section  to evaluate each
neural network classifier  we calculate the average accu
and waccu        in    cross validation procedures for
each training size  as shown in figure   and figure   
when the training size is small  more hidden units tend to
overfit the data while fewer hidden units tend to underfit 
however  when the training set is large enough  the number of hidden units does not greatly affect performance 
 

fifigure    waccu for nn with      training size
we compare the nn performance using two activation functions  hyperbolic tangent  ht  function and sigmoid function  the results are shown in figure   and
figure    it is noticeable that the sigmoid function performs slightly better than the hyperbolic tangent function 

figure    each curve shows the average accu for an nn classifier
with a specific hidden layer size 

figure    each curve shows the average waccu for an nn classifier with a specific hidden layer size 

figure    accu of two nn    hidden units  activation functions

to further demonstrate the overfitting of the dataset
with a small training size  we examine the accu and
waccu for the      training set in figure   and figure    we observe that the two curves both peak
at   hidden units and start to decline as more hidden units are used  it is also worth noting that the
waccu generally drops after penalizing fp more than fn 

figure    waccu of two nn    hidden units  activation functions
we also compare the nn performance with other machine learning techniques  the results are shown in figure
  and figure    decision tree has the best overall performance  while it falls short on small training sets compared
to nn and k nearest  generally  most algorithms can reach
an accuracy of      which suggests that the selected feature
set has captured the essential characteristics of phishing
emails  when we perform unsupervised   means clustering
on the entire dataset  we are able to achieve     accuracy 
which further supports the validity of our feature set 

figure    accu for nn with      training size
 

fithe highest recall while still mainitaining a      precision 
suggesting that nns are excellent at detecting phishing
emails while misclassifying only a small portion of ham
emails 

references
    saeed abu nimeh  dario nappa  xinlei wang  and
suku nair  a comparison of machine learning techniques for phishing detection  in proceedings of the
anti phishing working group ecrime researchers summit  pages              

figure    accu of nn    hidden units  and other machine learning techniques

    ion androutsopoulos  john koutsias  konstantinos v 
chandrinos  george paliouras  and constantine d 
spyropoulos  an evaluation of naive bayesian antispam filtering  in proceedings of the workshop on machine learning in the new information age    th european conference on machine learning  barcelona 
spain       
    ram basnet  srinivas mukkamala  and andrew h 
sung  detection of phishing attacks  a machine learning approach  studies in fuzziness and soft computing 
                 
    madhusudhanan
chandrasekaran 
krishnan
narayanan  and shambhu upadhyaya 
phishing e mail detection based on structural properties  in
proceedings of the nys cyber security conference       

figure    waccu of of nn    hidden units  and other machine
learning techniques
table    evaluations of nns with two activation functions
activation accu
waccu
precision recall f 
ht
                    
             
sigmoid
                    
             
table    evaluations of
niques
method
accu
dt
      
svm 
      
svm 
      
nb
      
k nearest       
nn
      

    james clark  irena koprinsk  and josiah poon  a neural network based approach to automated e mail classification  in proc  ieee wic international conference on
web intelligence  wi   pages              

nns and other machine learning techwaccu
      
      
      
      
      
      

precision
      
      
      
      
      
      

recall
      
      
      
      
      
      

    ian fette  norman sadeh  and anthony tomasic 
learning to detect phishing emails  in proceedings
of the international world wide web conference www  
     

f 
      
      
      
      
      
      

    network working group  multipurpose internet
mail extensions  mime  part two media types  http 
  tools ietf org html rfc     section       
     
    andrew ng  cs    lecture notes  http   cs    
stanford edu notes cs    notes  pdf       

table   summarizes performance measures for nns
with two activation functions in detail  as seen in the table 
ht function performs slightly better in terms of all measures except recall  notice that the largest difference out
of all the measures comes from waccu   which suggests that
the ht function is better at avoiding misclassifying ham
emails to phishing emails 
table   summarizes the performace measures for nns
and other machine learning techniques  as shown in the
table  dt gives the best overall performance  nns give

    martin riedmiller and heinrich braun  a direct adaptive method for fast backpropagation learning  the
rprop algorithm  in proceedings of the ieee international conference on neural networks  volume    pages
             
     wikipedia  artificial neural network  wikipedia  the
free encyclopedia 

 

fi