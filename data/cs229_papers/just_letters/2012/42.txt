reinforcement learning of taxi driver passenger seeking
strategies  
  
haochen  tang  
  
introduction  
  
a   decision making   system    such   as   a   robot    takes   input   information   from   sensors  
 location   velocity   environments  and  etc    and  select  certain  action  among  multiple  
alternatives  based  on  its  own  policy  and  its  current  states   after  a  taxi  driver  drops  

figure      decision  making  system  

  

  
the   previous   passenger    he she   needs   to   decide   how   to   find   the   next   passenger   in  
the  most  efficient  way   take  a  taxi  driver  in  beijing  as  an  example   given  the  drop off  
location   of   the   last   passenger   which   is   at   beijing   university    and   all   available  
information  such  as  location   time   traffic   weather  and  etc    the  driver  may  drive  to  
location  a  which  is  another  university   or  to  location  b  which  is  a  popular  tourism  
place the   summer   palace     or   to   location   c   which   is   a   shopping   center   in   downtown    

figure      taxi  driver  decision  making  illustration  

    

  
beijing    therefore   in   this   project    i   consider   the   taxi   driver   as   a   special   and  
sophisticated   decision making   system   when   he she   is   looking   for   the   next  
passenger    and   i   am   going   to   discover   the   optimal   policy   when   the   taxi   driver   is  
searching  for  the  next  passenger   this  is  defined  as  the  optimal  passenger seeking  
strategy    the   result   will   be   very   helpful   to   guide   taxi   drivers   to   achieve   better  

fi                                

earnings   as   well   as   reduce   fuel   cost   and   hazardous   emissions    moreover    since   the  
self driving   cars   have   become   available    we   could   expect   self driving   taxis   in   the  
near  future   this  result  can  be  used  to  efficiently  manage  self driving  taxis  systems     
  
the  data  used  in  this  project  are  gps  trajectories  from         struct  trajectory   
taxis  in  the  city  of  beijing   china  from  may   st           may     
int  id 
  
double  time 
  st          the  data  structure  is  shown  in  the  right     
  
double  x 
  
  
double  y 
  
  
bool  isheavy 
  
  
  
related  works  and  my  method            
  
                                                  figure      data  structure  
a   few   works   have   already   been   conducted   to   analyze   the   taxi   gps   trajectories    j   
yuan  finds  all  the  taxi  waiting  areas  from  the  historical  gps  data  and  provides  the  
statistics  for  the  waiting  areas          y   ge  discovers  the  preferred  pick up  locations  of  
those   high   profitable   taxi   drivers   and   uses   a   sequence   of   the   preferred   pick up  
locations   as   the   recommending   driving   route          x    zheng   uses   an   non 
homogeneous   poisson   process   to   model   the   characteristics   of   vacant   taxis   and  
estimate  passenger  waiting  time          
  
my  method  focuses  on  applying  reinforcement  learning  algorithm  on  taxi  gps  data  
to   reveal   the   optimal   passenger seeking   strategy   at   different   states    shown   in   the  
figure  below   when  the  driver  starts  a  cruise  trip   trip  that  the  taxi  is  vacant   from  

figure      mdp  model  

  

  
a  starting  state   he  chooses  certain  action   and  with  some  probability   he  will  end  up  
in  certain  state   
  
the  work  has  two  major  part   the  first  part  is  processing  the  gps  trajectory  data  and  
generate  all  the  parameters  needed  for  the  reinforcement  learning   the  second  part  
is  applying  the  reinforcement  learning  algorithm  to  find  out  the  optimal  strategy  for  
the  taxi  drivers   

fidata  processing  
  
first   i   divide   the   entire   beijing   city   into   a          grid    so   that   each   grid   roughly  
covers  a   km km  area   which  takes  a  normal  taxi  about     min  travels  from  one  
side  to  the  other  side   this  is  my  state  space   
  
given   the   gps   trajectory   of   one   taxi   in   the   one   month   time   period    i   will   find   the  
pick up  and  drop off  locations  using  the  isheavy  information   then  i  will  break  the  

figure      gps  trajectory  for  one  taxi  driver  

  

  
gps   trajectory   into   occupied   trips   and   cruise   trips   using   the   pick up   and   drop off  
locations   i  came  up  with           occupied  trips  and           cruise  trips  for        
taxis   in   one   month    for   each   of   the   occupied   trips    i   calculate   the   fare   generated  
based  on  the  fare  policy  of  beijing  taxi   

figure      occupied  and  cruise  trips  

  

  

figiven   the   trips   and   the   grid    i   calculate   the   number   of   pick up   events   within   each   of  
the  grid  in  the  one month  period   the  average  fare  income  and  fuel  cost  generated  
from  these  pick ups   i  also  calculate  the  total  cruise  time  in  minutes  within  each  of  
the  grid   now  i  would  like  to  build  a  grid  data  structure  containing  all  the  values  i  
need   for   the   reinforcement   learning    the   data   type   for   each   of   the          grids   is  
shown   in   figure        the   dropstate   data  
contains   the   number   of   drop off   to   all   struct  stategrid   
int  numpickup 
      states  from  pick up  in  this  grid   as     
  
double  totalcruisetime   
well   as   the   corresponding   expected   fare     
double  meanfare   
and  fuel  cost   
  
double  meanfuel   
  
  
grid vector double    dropstate   
  
some  parameter  values  are  visualized  in  
figure      
  
  
  
                                                                              figure      grid  data  type  
  
  

  

  

  

figure      data  visualization  

  

fimdp  and  reinforcement  learning  
  
now   we   will   use   the   values   we   obtained   from   the   data   processing   to   implement   the  
mdp  model  for  reinforcement  learning   in  my  mdp  model   the  time  step  is  set  as     
minutes   the  actions  can  be  made  at  each  grid  are  driving  north   east   south   west  to  
the  adjacent  grid  or  stay  in  the  same  grid   every  time  the  driver  makes  any  decision   
for  the  first  half  time  step   he she  will  be  traveling  in  that  grid   if  failed  to  pick  up  
any  passenger   the  driver  will  travel  in  the  adjacent  grid  or  the  same  grid   depending  
on   the   action   he she   chooses    therefore    the   pick   up   probability   at   grid i j    within      
minute  cruise  will  be   
ppu   min  i  j   

  pickup i  j 
totalcruisetime i  j    

                                                                                                            
and  the  pick up  probability  of  every  half  time  step        minutes   will  be   assuming  
iid    
  
  
  
                               ppu  i  j         ppu   min  i  j        
the  probability  that  after  a  taxi  picks  up  passengers  in  grid i j    it  goes  to  grid m n   
is   
pij  m  n   

  drop grid   m  n   fromgrid   i  j  
  totalpickup grid   i  j  
  

                                                                          
  
then  my  mdp  model  is   
  

states         locations  

actions    at   each   grid    driver   can   go   to   the   adjacent   grids   in   north    east    south   
west  directions  or  stay  in  the  same  grid  

state  transition  probability  from  grid i j   to  grid m n      

go  north     ppu i j   pij m n         ppu i j    ppu i   j   pi  j m n   

go  east           ppu i j   pij m n         ppu i j    ppu i j     pij   m n   

go  south     ppu i j   pij m n         ppu i j    ppu i   j   pi  j m n   

go  west       ppu i j   pij m n         ppu i j    ppu i j     pij   m n   

stay                     ppu i j   pij m n         ppu i j    ppu i j   pij m n   

reward  function   
r i  j    ppu  i  j   e fare i  j    e fuel   cost i  j   
                                              
  

           
  
and  i  use  the  value  iteration  to  get  the  optimal  policy   

for  each  state  s   initialize  v s          

repeat  until  converge     
  
  
for  every  state  s   update  
v  s     r s    max aa  psa  s   v  s   
                                                                                                                                                      
  
   
  
  
  

firesult  
  
the  value  convergence  is  shown  in  figure      it  takes  about      time  steps  to  converge               
and  the  optimal  policy  at  each  state  is  shown  in  figure       

                                                                                                    

figure      value  convergence  

    

fifigure       optimal  strategy  at  each  grid  

  

future  works  
  
i  havent  find  a  way  to  validate  my  result   one  method  i  am  considering  is  to  find  the  
high   profitable   driver   from   the   data   and   compare   their   actions   at   each   grid   with   the  
optimal  policy  discovered  by  the  reinforcement  learning   
  
another   interesting   question   is    if   this   optimal   policy   is   available   to   every   taxi  
driver    optimal   actions   may   not   be   optimal   any   more   since   a   lot   of   taxi   drivers  
choose  them   i  am  thinking  about  applying  game  theory  to  solve  this  problem     
  
machine   learning   is   a   really   amazing   technology    thank   you   so   much   for   introducing  
it   to   me    professor   ng    i   enjoyed   learning   this   new   knowledge    please   have   a   nice  
holiday  season   
  
references  
  

  

fi     j   yuan  and  et  al    where  to  find  my  next  passenger   ubicomp     september        
                          beijing   china   
  
     y   ge  and  et  al    a  taxi  business  intelligence  system   kdd     august               
                     san  diego   california   usa   
  
     x   zheng  and  et  al    where  to  wait  for  a  taxi   urbcomp       august                
              beijing   china   
  
  

fi