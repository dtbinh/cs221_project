music classification by composer
janice lan
janlan stanford edu

armon saied
armons stanford edu

cs      andrew ng
december         

abstract
music classification by a computer has been an interesting subject of machine learning research  we
implemented a variety of different classification algorithms with the goal of identifying   classical
composers from various time periods  to improve the performance of our learning models and optimize
our feature selection we executed some diagnostic tests  including the leave one out cross validation
method  finally we analyzed and assessed the performance of our learning algorithms and remarked on
some possible areas for further improvement 

  introduction
the ability to classify musical compositions by composer is useful for several applications  such as
organizing musical databases  learning preferences and patterns of music listeners  and building music
recommendation systems  many musicians can usually differentiate compositions of different composers
even if they have never heard those particular pieces before  because of the way humans perceive music 
people focus on the tone and color of the song  the emotional responses generated from listening to the
music  general characteristics such as the level of dissonance  recurrent features such as trills or arpeggios 
and other overarching qualities to distinguish the style of a composer  when listening to music  humans
care much less about theoretical rules and numeric patterns of the notes  however  many of the
overarching qualities are difficult to quantify  and thus unlikely to be used by computers  in this project 
we attempt to differentiate various styles of music  in this case  composers  by applying machine learning
to numeric data extracted from patterns in music 
previously  lebar  chang  and yu worked on a similar project where they attempted to classify music by
composers  however  they used scores instead of audio files as their source of data      they used nave
bayes  svm  lda  and k nn  there have also been numerous projects of classifying music from audio
files  though most classify by genre and not by composer  for instance  haggblade  hong  and kao used
kl divergence  k nn  k means  svm  and neural networks to classify songs into classical  jazz  metal 
and pop     
building off of previous ideas  we hoped to explore different techniques for successfully classifying music
by composer  therefore  our primary challenges were to choose effective machine learning algorithms to
implement and to ascertain the most appropriate quantifiable musical features 

  data
to limit the scope of this project to a domain less broad than music  we restricted our music data to solo
piano compositions  we also limited the file format to midi files  in order to keep consistent our methods
of parsing music for numeric data  midi files were obtained from
several websites  mostly from www piano midi de and
composer
lived
  files
www classicalmidiconnection com 
bach  j s 
         
   
scarlatti
mozart
beethoven
schubert
chopin
liszt
debussy
prokofiev

to select the musicians to classify  we decided to choose famous
composers from different eras of classical music who composed
large collections of piano compositions  we settled with nine

  

         
         
         
         
         
         
         
         

   
  
  
  
   
  
  
  

ficomposers to analyze  ranging from the baroque era to the modern era 
we noted the relatively large amount of data for scarlatti  especially because in a previous music
classification study  a cross validated nave bayes model biased the classification towards composers with
more data      however  we later tested our learning algorithms with reduced scarlatti data and found that
there were no significant problems with the disparate amounts of data between composers 

  methodologies
    feature extraction
we used music    a python package  and miditoolbox  a matlab package  to extract quantifiable features
from the midi files  initially  we started classifying solely using the mean and standard deviation of
pitches  note durations  and inter onset interval  time between attack points of consecutive notes   later
on  we added pitch intervals  song tempo  pitch range  and the divergence from original key  the fraction
of notes that do not belong in the major or minor scale of the original key   for most of these features we
observed the mean  standard deviation  and the range  in addition we also analyzed the note sequence 
transposed to c major minor  this was used in the bayesian network classifier in an attempt to analyze
the melodies  and to determine which composers they are the most characteristic of 

    preliminary algorithms
we started out with classifying between   composers  chopin and bach  as a simplified test between a
relatively distinct pair of composers  we used the original set of features as described above in three main
learning algorithms  nave bayes  perceptron learning algorithm  stochastic gradient descent   and logistic
regression  stochastic gradient descent  

    support vector machine
we implemented the support vector machine model as a binary classifier using sequential minimal
optimization  later  implementing a   vs  all scheme for classification  we extended the classifier to
have multi class capabilities in order to classify all   composers 

    k nearest neighbors
we implemented a simple k nearest neighbors algorithm using a euclidean definition of the distance
function  to improve the algorithms performance  we tested it for numerous k values  tried several
different distance functions  and finally tried weighting the features in a manner that agreed with our
feature analysis tests 

    bayesian network
the bayesian network classifier is based off of the probability distribution of the next note given the
current note and  optionally  previous note s   classification of a song was based on how likely it is to
have its sequence of notes  i e  the product of p note i     note i  for all notes in the composition 

  results
the following are two graphs of our results for svm  k nn  and bayesian network  the first figure shows
the percentage of songs that were correctly classified by the multi class svm and k nn  the second
figure similarly shows the percent accuracy for bayesian network  where a k fold cross validation was
also used 

    preliminary algorithms
our three preliminary algorithms were tested with the original training data  the nave bayes reported a
training error of     the perceptron a training error of      and the logistic regression a training error of
    

fi    support vector machine
the first implementation was very successful for most composers  using binary classification  all of the
composers  except for  prokofiev and scarlatti were identified with less than     testing error  using a  
vs  all multi class implementation  we achieved the level of classification accuracy shown in the graph
above  the following is a brief description of   vs  all  for each composer  mark its train data as class
label positive  run the svm algorithm where the remaining composers are all marked class label negative 
then as long as the algorithm returns negative for the current training data  cycle the current composer into
the subset of negative composers  classify  and then repeat the process 

    k nearest neighbors
the final results of this algorithm are shown in the graph above  for k     again we used the   vs  all
scheme for multi class classification  our initial implementation of k nn performed at a     total
classifying accuracy for all of the composers  adjusting the value of k yielded at most a     change in

fitesting error  furthermore  using different distance functions did not show a consistent improvement in
classification  so we settled on euclidean distance  d q  p   

n

  q

i

 pi      

i  

    bayesian network
the first attempt at a bayesian network classifier used p next note   current note   this did not work well 
as the training error was over     for all 
composers except for bach  mozart  and schubert  it appears that
the probability distribution of two consecutive notes was very characteristic of different composers  to
improve on this  we adjusted the number of notes used in the conditional probability  using two notes
instead of one decreased the train error to      using k fold cross validation  with k     to run this
learning algorithm on test data we got the values shown in the graph above 
to see if using more notes would generate better models  we also tried using   notes as the conditional
probability  the result of the k fold cross validation was significantly worse  except for scarlatti  which
had a     accuracy  this shows that the faults in the learning algorithm are probably due to lack of data 
there are      combinations of   notes  and we do not have enough notes and songs to give a reasonable
probability distribution for all the triplets 

  analysis
    algorithm evaluation
we evaluated our algorithms with k fold cross validation  using k      because we did not have much data
and did not want to leave much out of the training set  we experimented with adjustments of k  for the
bayesian network classifier  k    gave the same results  except debussy was    worse  with k     the
results were the same except that beethoven improved by    and liszt improved by     moreover  we
also conducted the same tests with reduced scarlatti data to address concerns with the imbalance in data 
when using only a randomly selected     compositions  there was almost no difference  except that bach
was a few percent less accurate  we can conclude that the exceptional amount of data for scarlatti does not
bias the classifications  and in fact  is beneficial for training the difference between scarlatti and bach 
for k nn we achieved the highest classification accuracies for each composer by weighting the features 
the weights were constants proportional to the values we determined for each features measured
relevance discovered in the analysis described below 

    feature evaluation
we performed two distinct diagnostics in order to evaluate our features  feature relevance analysis and
variance bias analysis using learning curves  in order to assess the relevance of our chosen features  we
wrote a program that executed our multi class svm for each possible n sized subset chosen from the total
features available  given our time and computational limitations we only ran this program for n values of
           out of our total of    possible features  below is a graph  showing the frequencies with which
each feature appeared in a feature subset that yielded a testing error less than    

fi    composer similarity
an interesting analysis of the classifiers results is the similarity between each combination of composers 
this can be seen in the confusion matrix of the results of k fold cross validation with k     each bar
represents the percentage of wrong classifications  for instance      of beethoven compositions were
classified as mozart  but only    was mistakenly classified as bach 

higher bars represent a greater similarity between two composers  from this we can see that  as expected 
composers of similar time periods are more easily mistaken for each other  similar results can be seen
when we remove one composer from the classification and see which composers improve in accuracy  and
by how much  for instance  removing bach increases the accuracy of scarlatti by      and removing
mozart increases the accuracy of beethoven by     

  further work
given more time  there are several other music features we would have liked to try  we would use chord
progressions and note progressions  which are commonly used in musical analysis  one machine learning
paper on musical style examined silence durations      furthermore  if we extracted features from songs in
the wav file format we could look at song dynamics and tempo changes  due to time constraints  we were
unable to successfully implement the softmax regression  however  we believe that softmax is very
appropriate for our project  and should be the next algorithm to test  in addition  we would attempt using
principal component analysis  pca   neural networks  and discriminant analysis  future extensions
worthy of consideration are looking at songs with multiple instruments and trying additional genres of
music 

  references
    http   cs    stanford edu proj     lebarchangyu classifyingmusicalscoresbycomposer pdf
    http   cs    stanford edu proj     haggbladehongkao musicgenreclassification pdf  
     http   ieeexplore ieee org xpls abs all jsp arnumber        

fi