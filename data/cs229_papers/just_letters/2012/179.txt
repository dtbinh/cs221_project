using discriminative component analysis to learn descriptors for improved shape
mapping
andy nguyen  charlie camp
shape matching is an important problem in computational geometry with applications in many
areas ranging from animation to medical imaging  the objective of the shape matching problem
is to nd a correspondence between all points on two given shapes  one general approach to this
problem is to compute geometric descriptors on every point on both shapes  and then match the
points based on the descriptors  subject to additional continuity constraints  unfortunately  there
are many dierent descriptors that have been proposed  and all of them work well in some cases but
poorly in others  in this project we will obtain training data of shapes with known correspondences 
and then compute the descriptors on these sets  we then use metric learning to determine the
appropriate weight given to each descriptor  based on how well they match up with the known
correspondences  once the weights have been learned  we can feed them into an existing general
framework for shape matching and evaluate our results there  for this last step  we compare the
shapes using the eigenbasis of the laplace beltrami operator by requiring that the map be functionpreserving for each descriptor function fed in  while the laplace beltrami basis is not a particularly
good choice for excessively dierent shapes  it is a popular choice due to its performance on nearisometric shapes  as well as its ability to be truncated with limited signal loss  much like the fourier
basis 

i 

general procedure for shape matching

for this problem  we have many similar   dimensional shapes that are essentially the same object in dierent
positions  the goal of shape mapping is to nd which points on one mesh correspond to which points on another
mesh  the shapes are described by   d triangle meshes  which consist of a set of points in   dimensions  as well as
a set of edges that connect the points  where necessary  a direction around each triangle can be determined by the
order in which the edges are listed   these meshes tend to contain about        points 
for each point in the mesh  we wish to create a vector containing all descriptors for that point  the most important
descriptors we use are intrinsic descriptors such as the wave kernel signature  wks     heat kernel signature  hks    
gaussian curvature  and mean curvature  the wave kernel signature and heat kernel signature are measured by
initializing a delta function signal at the point  then measuring the value at that point while the signal propagates
along the mesh surface according to the wave equation and heat equation  respectively  wks and hks tend to
make up the majority of our descriptors  since we use the values at many dierent time steps  where each time step
is treated as a distinct descriptor 
to match two meshes  we create a m x n descriptor matrix  where m is the number of points in the mesh and n
is the number of descriptors  the next step would be to match the rows of two such matrices using a least  squares
method  however  since the meshes in use tend to contain on the order of        points  we rst change to a much
smaller laplace   beltrami basis and perform least squares matching with respect to the new basis functions 
ii 

using discriminative component analysis  dca  to improve mapping

the main contribution of our project is to apply discriminative component analysis to the above matching process 
when the meshes are matched using their descriptor vectors  each descriptor is given an equal weight regardless of
its eectiveness  we can achieve a much better matching by applying metric learning through the use of dca  the
point of dca is to create optimal descriptor vectors by weighting and mixing the existing descriptors  we are also
able to decrease the number of resulting descriptor dimensionality when using dca  below we describe the process
used 
we begin by choosing a small subset of points called salient points  which mark the same landmark features in each
mesh  for example we might choose the salient point    for each mesh to be the tip of the nose  while point   might
be chosen to be the left knee  in our project we choose    such points  our set of training data will then be the
descriptor vectors of all of these points from all meshes  where we refer to all such vectors from a particular salient
point as a chunklet 
some chunklets are said to be discriminated from each other by negative constraints  we will aim to transform
descriptor vectors such that those from discriminated chunklets are as distinct as possible and those from the same
chunklet are as similar as possible  note that not all chunklets are negatively constrained  in particular features that

fi 

a 

 
 

 

 

 

 

 

 

 

 
 
 
 

 

     x    
descriptor matrix

    x   
dca
descriptor weigting

     

   

     

   

     

   

     

   

 

      x   
descriptor matrix
 weighted 
     
     

 

 

 

        

               

   

b 

     
     
 

 

 

 

 

 

 

 

 

              

           

 
 

 

 

 

 

 

 

 

 

 

 

 

 

laplacebeltrami
basis change

      x   
descriptor matrix
 weighted 

 

    x   
descriptor matrix
 lb basis 

   

     

   

   

     

   

   

     

   

     

   

 

   
 

 

 

 

 

              

   

 

 

 

 

 

              

     

fig     a  begin with a m x n descriptor matrix  with m points in the mesh and n descriptors per point  the teal columns
correspond to wks descriptors at dierent time steps  the green columns correspond to similar hks descriptors  and the
last two columns correspond to the two curvature descriptors  by multiplying by the calculated dca matrix  we reduce the
descriptor space to    optimized descriptors  b  to nd correspondence mapping  we rst change basis to the eigenstates of
the laplace beltrami operator  once in this basis we can match the descriptor matrix to that of another mesh  then transform
back to the point basis to get a correspondence mapping 

occur symmetrically in right   left pairs 
the dca algorithm works by creating two matrices  cb and cw   which represent the variance between discriminated
chunklets and the variance among descriptors of the same chunklet respectively  
n
   
cb  
 mj  mi   mj  mi  t
nb j  

   

jdj

cw  

nj
n
    
 xij  mj   xij  mj  t
n j   nj j  

   

the matrix in equation     measures the average variance between negatively constrained chunklets  mj and mi
are the mean descriptor vectors of chunklets i and j  where j sums over all chunklets and i sums over all chunklets
negatively constrained to j  the matrix in equation     measures the average variance among points within a chunklet 
in the dca algorithm  we rst diagonalize     to end up with a new basis that consists of the largest valued
eigenvectors of      this represents the basis that best discriminates the chunklets  we transform     to this basis 
then diagonalize the resulting matrix  by taking the lowest value eigenvectors we obtain a transformation that
maximizes variance across discriminated chunklets  and minimizes variance within a given chunklet  in this process
it is common to choose only a subset of the eigenvectors at each step  resulting in a descriptor space with much lower
dimensionality  in our project  we are able to reduce the dimensionality of the descriptor space from roughly     to
about    

fi 

a 

b 

c 

fig     visual comparison of mapping between two meshes  a  reference mesh  b  mapping calculated using raw descriptor
vectors  c  mapping calculated using dca weighting  the case with dca weighting has noticeably better correspondence 
with particular attention to the pelvic region and elbows 

the end result from dca we acquire the matrix a that transforms our raw descriptor vectors to the optimal learned
descriptor vectors  this can then be used for comparing two unknown test meshes by transforming the descriptor
vectors for the entire set of points  see fig    
iii 

functional maps

once we have two meshes with weighted descriptor matrices  in the laplace beltrami basis   we can nd the
best correspondence through the use of functional maps  from the above methods we should know the descriptor
functions best preserved by a good map  we can use these probe functions as constraints to nd a map between
basis functions on the two shapes    this then becomse a least squares problem 
minm   f  m g  

   

here f is a probe function written in the chosen basis  laplace beltrami  on one mesh  and each corresponding
column of g is the same probe function written in the chosen basis on the other mesh 
iv 

results

mappings between test meshes were calculated both with and without dca descriptor weighting  the average
error for each mapping was calculated as the average euclidean distance of each calculated point mapping to the
correct corresponding point  the error was consistently lower across the board when using dca vs  using the raw
descriptors 
average error with and without dca with dierent descriptor choices 
using only wks and hks as descriptors  training sets  error         without dca        with dca
testing sets  error         without dca         with dca
using curvature with wks and hks  training sets  error          without dca        with dca
testing sets  error          without dca        with dca

to get an idea of the scale of the above error  the gures were approximately   units tall  note that when curvature
values  both gaussian and mean curvature  were used as descriptors  the error increased noticeably  this is not
unexpected  since adding certain descriptors has the possibility of increasing minimum variance within chunklets 

fi 
a 

   

   

 

b 

   

   

 

   
  

   
  

   
  

 

   

  

   
  

 

   

  

   
  

   
  

   
  
 

  

  

  

  

  

   

   
  
 

  

  

  

  

  

   

fig     matrices containing relative error for all shape mappings amongst    test cases  ij th entry corresponds to  errweighted
  errraw   value resulting from mapping mesh i to mesh j  negative entries correspond to mappings where use dca descriptor
weighting resulted in a better mapping  a  error comparison where curvature is not included  b  error comparison where
curvature is included  note that each pixel corresponds to a comparison like in fig   

curvature in particular is known for producing this result  since the curvature of certain salient points can change
drastically with dierent poses 
the important observation here is that the dca learning algorithm deals with the curvature appropriately  the
curvature descriptors are properly incorporated into the learned descriptors in such a way to further decrease the
error  as compared even to the dca adjusted case without curvature  another observation is that adding the extra
  curvature descriptors results in   additional learned descriptors  this is not surprising  since curvature should
contain very dierent information from the wks and hks descriptors  while many of the individual wks and hks
descriptors are similar and will be combined with each other in the dca learning step 
acknowledgments

we would like to thank justin solomon for providing us with his implementation of the functional maps framework 

    m  ovsjanikov  m  ben chen  j  solomon  a  butscher  l  guibas  functional maps  a flexible representation of maps
between shapes acm transactions on graphics              
    jian sun  maks ovsjanikov  leonidas guibas  a concise and provably informative multi scale signature based on heat
diusion  eurographics symposium on geometry processing  sgp  
    d  anguelov  p  srinivasan  d  koller  s  thrun  j  rodgers  j  davis  scape  shape completion and animation of people
acm transactions on graphics                    
    m  aubry  u  schlickewey  d  cremers  the wave kernel signature  a quantum mechanical approach to shape analysis 
computer vision workshops  iccv workshops        ieee international conference on                  
    steven c  h  hoi  wei liu  michael r  lyu  wei ying ma  learning distance metrics with contextual constraints for image
retrieva  proc  computer vision and pattern recognition                  

fi