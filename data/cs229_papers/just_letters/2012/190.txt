musical genre tag classification with curated and crowdsourced
datasets
omar diab  anthony mainero  reid watson
stanford university  computer science
 odiab  amainero  rawatson  stanford edu
abstract
analyzing music audio files based on genres and other qualitative tags is an
active field of research in machine learning  when paired with particular classification
algorithms  most notably support vector machines  svms  and k nearest neighbor
classifiers  knns   certain features  including mel frequency cepstral coefficients
 mfccs   chroma attributes and other spectral properties  have been shown to be
effective features for classifying music by genre  in this paper we apply these methods
and features across two datasets  gtzan and the million song dataset  with four
different tag sources  gtzan  the echo nest  musicbrainz  and last fm  
two of these tag sources are professionally curated  gtzan and musicbrainz 
while the other two are crowdsourcedthat is  unmonitored users create the tags for
each track  two of the datasets had features on a track by track basis  gtzan and
last fm  while the other two are classified by artist  by exploring the cross validation
balanced accuracy across these different datasets  we find that classifications are made
significantly more accurately on curated tags in comparison to crowdsourced tags  but
that tagging by artist as opposed to by song creates a considerably smaller difference in
effect  we found  however  that crowdsourced tags can be effective when done in large
enough quantites  as seen in the last fm dataset 
in that effort  several papers have explored
the efficacy of learning algorithms to predict genres 
in his paper george tzanetakis effectively classified
genres on live radio broadcasts using a gaussian
classifier      mandel et  al  used svms on artistand album level features to make similar
classifications as well      another study explored
mixtures of gaussians and k nearest neighbors for
the same task      each of these studies used similar
featuresmel frequency cepstral coefficients and
chroma properties of the audio waveform  for
instanceto make these classifications 
with prior work in mind we decided to
focus on knns  svms  and other classifiers and
explore their relative performance  in particular  we

   introduction
musical genre classification is an active field
of machine learning research  some argue that
machine learning for genre classification is
intractable for normal use because genres are not
clearly defined  on the other hand  people using
online music services are very likely to search for
music by genre  so understanding how to
automatically classify music by genre would be
useful  at a minimum  overarching genres like rock
or disco likely exhibit enough distinction for
computers to effectively distinguish between them 
hence many scientists have attemptedand largely
succeededin producing quality classifiers for
determining genres 

 

fiare interested in determining how the nature of
each dataset affects each classifiers accuracy 

of the audio tracks from the million song subset
 scraped from the  digital com public api  and the
gtzan dataset  we used marsyas     to extract
a number of relevant features from the raw audio
files  the features we extracted were 

   datasets
tag by artist
tag by song

curated
musicbrainz
gtzan

crowdsourced
the echo nest
last fm

   mel frequency cepstral coefficients  short
term spectral based features which model
amplitude across the spectrum 
   zero crossings  the number of times the
waveform crosses   
   spectral centroids  where the spectral
center of mass of a sound is 
   chroma properties  discretizes the
spectrum into chromatic keys  and
represents the presence of each key 
   spectral rolloff  the frequency at which
high frequencies decline to    typically
computed when the waveform hits    
energy 

table    properties of the datasets used

we gathered songs from two sources  the
million song subset and gtzan  the million
song subset is a selection of the metadata
pertaining to        songs  in particular  it contains
tags aggregated from the echo nest  musicbrainz 
and last fm      thus  we have four tag databases
in total  musicbrainz  the echo nest  last fm  and
gtzan 
two of these databases  musicbrainz and
gtzan  are curated  that is  humans assign their
tags selectively with accuracy in mind
for academic purpose  the other two
databases  echonest and last fm  are
crowdsourced  users apply tags with no
moderator oversight  thus  curated tag
datasets are expected to be more
accurate overall than crowdsources ones 
additionally 
two
of
these
sources 
the
echo
nest
and
musicbrainz  assign tags by artist 
last fm and gtzan tags  on the other
figure    proposed method of collecting data
hand  apply to individual tracks 
gtzan is a database of music
when taken together  these features denote
created by george tzanetakis specifically for
a wide range of sonic characteristics of the music 
machine learning analysis of genre classification
including instrumentation  tonal variation  timbre
problems  the selected music is classified into ten
texture  and production attributes  together  they
genres  blues  classical  country  disco  hip hop 
constitute the musical surface of the song     
jazz  metal  pop  reggae  and rock  because the
to sanity test our tag data  we made note
million song subset did not contain enough
of the relation between the frequency of songs of a
classical and disco songs  those genres were ignored
certain genre appearing in online music datasets
in our analysis 
and the number records sold in that genre in     
we created an intersection of       songs
     through this data  we found that blues  metal
that were present and tagged in each of our tag
and reggae are overrepresented in online music
datasets  for each  we acquired    second previews

 

fiof a misclassification  so higher values of 
encourage fewer misclassifications  and 
represents the relative importance of a
single data point 
grid py trains several
music sales and genre tag frequency
svms with multiple choices of 
and  and compares them  by
   
    
default  the comparator is cross   
validation accuracy  however  our
    
data sets are unbalancedfor
genre tags
   
instance  there are far more non    
music sales
blues
examples
than
blues
   
    
examples  allowing the blues
 
classifier to achieve a high crossvalidation accuracy by just
classifying everything negatively 
therefore  we selected balanced
accuracy  bac  as our metric 
figure    music sales versus aggregated genre tag frequency in our
which is defined as follows 

datasets 
while
country
and
pop
are
underrepresented 
this
information 
while
tangential  is a potential avenue for future research 

datasets

   methodology
for each genre  we train our dataset on a
classifier and use cross validation with   folds to
assess its overall accuracy  logistic regression and
nave bayes require no specific model selection
beforehand  with k nearest neighbors we used
      where  is the number of training
examples 
for svms  we use a modified version of
libsvms grid py module to produce an optimal
choice of parameters for the svm  in a svm with a
radial basis kernel  the objective function is to
minimize 

bac  

sensitivity   specificity
 

where
sensistivity  

specificity  

tp
tp   fn

tn
tn   fp

tp   true positives 
fn   false negatives  etc 
by using this metric to measure the efficacy of the
svm  we mitigate the aforementioned issues 
additionally  the classifier was run with
weights on positive and negative datapoints  the
weights denote how much a training example of
each class affects the objective function  for
instance  if there is a weight of  on positive test
examples  then misclassifications of positive test
examples are  times as costly  to further offset
unbalanced data sets  positive test examples were
weighted by the number of negative test examples 
and vice versa 



 
          
 


and the kernel is 
 
ff   ff fi   exp ff  ff  


by varying our choices of  and   we can
change the way the svm decides on a
dividing hyperplane   represents the cost

 

fifalse negative rate for country music by
classification algorithm by dataset

false positive rate for country music by
classification algorithm by dataset

   
   

gtzan

   

echo nest

   

   
   
   
   
   
 

musicbrainz

 
naive logistic
bayes

knn

svm

last fm

gtzan
echo nest
musicbrainz
naive logistic knn
bayes

   results
a  logistic regression and nave bayes
logistic regression and nave bayes were
relatively ineffective  nave bayes exhibited large
false positive rates and low false negative rates for
across genres in all the datasets  while logistic
regression produced high false negative and low
false positive rates  hence  both of them produced
relatively low cross validation accuracies and are
not particularly useful classifiers for this task 

svm

last fm

b  k nearest neighbors and svms
both knns and svms produced strong
results  they exhibited both low false positive and
false negative rates  and generally high crossvalidation accuracy  across all datasets and genres 
knns and svms produced     and     crossvalidation accuracies  respectively 

k nearest neighbors cross validation classification accuracy by dataset by genre
   

blues

  

country

  

hiphop

  

jazz
metal

  

pop
 
gtzan

echo nest

musicbrainz

last fm

reggae

svm cross validation classification accuracy by dataset by genre
   

blues

  

country

  

hiphop

  

jazz
metal

  

pop
 
gtzan

echo nest

music brainz

 

last fm

reggae

fieffects are less significant for genre classification
than the nature of the tagging source 
overall  we find that a large number of
examples and curated tags  gtzan  give us the
most machine predictable dataset 

   discussion
we dismiss logistic regression and nave
bayes as being comparatively ineffective genre
classifiers with a spectral feature set  qualitatively 
spectral features are likely not independent  on the
other hand  svms and knns do not rest on
independence assumptions  explaining why they
performed relatively well  these results corroborate
past studies in machine learning genre classifiers 
comparing cross validation accuracy across
datasets  we find that each algorithm performs
better on the gtzan  musicbrainz  and last fm
datasets than on the echo nest dataset  using
knns and svms on the gtzan dataset produces
    and     average cross validation accuracies
across all genres  respectively  on the other hand 
with the same algorithms on the echo nest dataset 
we get     and      respectively 
we
attribute
the
improvement
in
classification accuracy between the echo nest and
the other datasets to the fact that the latter are
either curated or filtered  while our last fm data is
crowdsourced  we narrow down our tags by
frequency  so that only tags that are at least     as
popular as the most popular tags for a song are
chosen  coupled with the fact that genre tags like
rock and country are more common than other
tags  we achieve decent accuracy with crowdsourced
data so long as genre tags are applied to a song
with high frequency  the last fm dataset actually
performs about equally well as musicbrainz  though
this is likely attributed to our far larger set of tags
on last fm songs than on musicbrainz songs  giving
us more training examples for last fm 
additionally  we found that the effect of
curated versus crowdsourced datasets is far more
significant than the difference between artist level
and track level tagging  this is likely due to the
fact that while many artists exhibit wide variation
in the types of music they make  they are less likely
to stray between overarching genres like rock and
disco  hence  while studies suggest that music from
specific artists or albums tend to have similar
spectral qualities  creating an album effect  these

   citations
    tzanetakis  george  georg essl  and perry
cook   automatic musical genre classification
of audio signals   the international society
for music information retrieval       
http   ismir     ismir net  pdf tzanetakis pdf
    mandel  michael i  and daniel p w  ellis 
song level features and support vector
machines for music classification  the
international society for music information
retrieval 
columbia
university 
     
http   www ee columbia edu  dpwe pubs ismir
   svm pdf
    li  tao  mitsunori ogihara  and qi li  a
comparative study on content based music
genre classification  special interest group on
information
retrieval 
     
p 
    
http   users cis fiu edu  taoli pub sigir  p    li pdf
    thierry bertin mahieux  daniel p w  ellis 
brian whitman  and paul lamere  the million
song dataset  in proceedings of the   th
international society for music information
retrieval conference  ismir             
   

tzanetakis  george and perry cook 
marsyas  a framework for audio analysis 
organised
sound
     
    
http   www marsyas info

    the nielsen company   billboards      music
industry report  business wire       
http   www businesswire com news home     
           en nielsen companybillboard e       s      music industryreport

 

fi