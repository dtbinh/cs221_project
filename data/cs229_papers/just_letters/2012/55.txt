predicting arm movements in virtual
environments
howon lee  jimmy lee  erik brockbank

i 

introduction

tudies conducted at the stanford virtual human interaction lab  vhil  place subjects in
virtual environments where they must converse and interact with other subjects as well as
avatars and embodied agents  to do this  we place subjects in head mounted displays  which
block out other visual stimuli and allow the user to  enter  a virtual world  we also put infrared
trackers on subjects  which allows the system to track the subjects movements  the goal of this
project was to use this data to reduce the number of trackers which participants need to wear  by
building a predictive model that would enable us to predict the location of a subjects elbows using
head  ankle  and wrist trackers as input  this increase the immersiveness of our simulation  since
fewer positioning trackers are needed  and allows us to more easily do experiments where the
participants can see themselves in virtual reality  many researchers have worked on the problem
of creating a  d model from motion tracking           but we believe that this is the first time
anybody tried to infer the placement of motion tracking points from other motion tracking points 

s

ii 

data collection

in order to gather an appropriate sample of labelled data  we had lab members do three tasks  sit
down for five minutes while being recorded  stand for five minutes while being recorded  and
move around the lab and tag virtual boxes placed at random locations by reaching out as if to
touch them  again for five minutes  this is to get participants to walk around the lab and extend
their arms at various heights and angles in order to gather a varied sample of typical  natural arm
movements 
the participants wore infrared trackers on the wrists and elbows  as well as the ankles and one
on the head for all of these tasks  the input features then were the position of each wrist and the
ankles with respect to the head  as well as head location and orientation coordinates  pitch  yaw 
and roll  of the head  the output features were the position of the elbows  each of   participants
performed the box task  the labelled data was collected    times per second and written to an
external file  which we then used as our training and testing data  this gave us a total of around
        data points 
during data collection  we identified many sources of possible error or misleading data 
including the risk of technical failure  e g  problems with infrared tracker operation or tracking
and rendering during the box task   in order to accommodate this possibility  beyond collecting
additional data  we wrote a script to  play back  each participants session  see figure     for any
given data file of input features  the script animates a basic stick figure to recreate the position
and orientation values at each time t  this allowed us to review each session and see that the data
had been properly collected and stored  due to problems with the infrared trackers  we did in fact
have to throw out   of the participants data before beginning our training  these errors were only
easily noticeable by running our replay script on the data we had collected 
 

fifigure    playing back the data for each participants session

iii 

learning algorithms and results

after collecting data from participants in the virtual box task and verifying their validity using
our playback script  we used the data to train predictive algorithms on the input features  this is
a supervised regression task  we started out with the typical linear regression and then took a
number of the algorithms for supervised learning  modified to suit the task  we began by setting
a basic linear regression to the data  for single participants  we were able to reach a coefficient of
determination r    value of      with     hold out on elbow location prediction  however  on the
aggregate of the data for all participants  r  was only       unsatisfied with these numbers  we
decided to try additional algorithms in the hopes that we might raise our quantitative accuracy
measures before exploring subjective accuracy  described below   for a summary of all the results 
see the table in the next page 
we followed linear regression with a ridge regression algorithm to see if added regularization
might improve our results  this produced only a modest improvement  perhaps due to more
systemic problems that were visible in the subjective testing phase  after the initial regressions 
we implemented a random forest algorithm  which added a great deal of expressive power to our
predictions  this was confirmed by the much higher coefficient of determination  we followed this
with an artificial neural network  which regressed the datapoints closely  as reflected in the r 
value of        this increased responsiveness with the more high level algorithms was exciting
because it is perhaps reflective of a greater degree of complexity than we had initially anticipated
in this problem  at least involving the features and training data that we chose to start with 
one possible reason for the need for more expressive algorithms is that our inputs have fairly
complicated interactions with respect to how they produce the output  we can imagine various
ways in which the other input features might be nonlinear  when standing in a neutral position 
ankle position and separation may be highly indicative of elbow position and when bending
down  e g  to touch a box low to the ground   head position and orientation might strongly reflect
this  in any case  the ability to achieve high values for coefficient of determination or r  with
increasingly complex algorithms shows that these produce good regressions 
 

fiwe used scikit learn for training     except for the neural networks  for which we used
pybrain    
algorithm
r  with     holdout
linear regression
     
ridge regression
     
random forest
     
artificial neural networks    hidden layer of    neurons 
     

   

subjective results

an interesting property of our particular learning problem is that we can talk not only about
objective accuracy in the quantitative means described above  but also subjective accuracy  related
to whether the algorithm provides a realistic experience for participants  if we were to use an
algorithm to render elbow location in real time based only on wrist location  it is imperative that
subjects not find their elbows to be in a different location in the virtual world from where they
would expect them to be  this reduces  presence    the feeling for a participant that she is actually
in the virtual world   an important feature in obtaining accurate results from experiments at vhil 
figure    real time virtual environment with elbow prediction

in order to confirm whether or not our quantitative accuracy corresponds to this more subjective
accuracy  we wrote a script that is able to run our learning algorithms and render their predictions
in real time  we place a subject in a simple virtual environment that includes a virtual mirror 
allowing the subject to see all of their movements  we then feed the subjects wrist  ankle  and
head location  as well as head orientation to the algorithm in real time and render the algorithms
projected elbow location for the participant to see in the mirror  see figure     this is vital because
it allows us to test the true accuracy of our algorithms  whether or not they are able to render
elbow location in a way that feels realistic to the participant  further  it enables us to ask questions
that would be very difficult without this feature  such as how our algorithms are able to handle
novel or very fast movements and difficult arm positions in addition to the standard movements
provided in our training data  additionally  the real time validation provides an early answer to
a speed accuracy tradeoff in how we render predicted arm movements  while our quantitative
results above focused on accuracy  speed is a significant factor for the learning task  since presence
is reduced when a virtual reality environment renders at less than    frames per second  without
some way of testing the performance of our algorithms on the spot  we have no way of knowing
where the most optimal region lies between speed and accuracy  or whether there is one at all 
 

fiafter obtaining the quantitative accuracy results described above  we ran each of our predictive
algorithms in the real time validation script to examine whether good machine learning could be
aligned with the goals of the project which have to do with the subjects experience in the virtual
world  our results surprised us and were very informative in thinking about future directions 
the first observation was that the linear and ridge regression  despite their relatively low accuracy
rates  offer great advantages in terms of speed  they allowed for very natural renderings of elbow
location that felt accurate for basic motions such as walking and generic arm movements  however 
the consequences of their low coefficients of determination became apparent when we attempted
novel or even slightly unique body movements  for example  we found that raising either ankle
off the ground typically lifts the corresponding elbow up towards the head  which is of course
not representative of normal ankle movements  while this was the most egregious failure of the
algorithm  similar patterns emerged for other movements that were not explicitly included in the
training data set  as described in section iv below  this problem  a sort of over fitting  may be
remedied by broadening our training data to include a more diverse set of body and arm motions 
another pattern that emerged  though less conclusively  was the possibility of a handedness
bias  certain positions and movements of either hand similar to those involved in the cube task
produced differential responses in the left and right elbows  since the majority of our subjects
were  evidentially based on what we saw during the data collection and what would be expected
of a normal sample set  right handed  we suspect that there may be a scarcity in the data of
left arm movements  which could be causing higher error rates and some of the asymmetrical
results witnessed during real time validation  alongside these patterns  there were no observable
differences between the linear and ridge regression 
when we initially ran our random forest algorithm  we found that its predictions were typically
fairly accurate as measured by r    much more so than the linear and ridge regressions for more
unusual arm movements  which might have been expected from the increased robustness and
higher coefficient of determination for the random forest model  however  we observed that
these gains were offset by a problem of jittery rendering  in which the predicted elbow locations 
even while fairly accurate  seemed to jump around and were somewhat delayed behind actual
movements  when we ran the artificial neural network  its predicted arm positions seemed to be
excessively dominated by the rotation of the subjects body  and was also jittery as well  although
we used these classification algorithms in a regression mode  they didnt seem to behave as
smoothly as we might have hoped they would 
in summary  we were thrilled to discover that our learning algorithms could be translated
to what often amounted to very accurate real time elbow location predictions  although there is
certainly room for improvement in the regression models  the below table lists links to videos of
the virtual mirrors for each of the regressions which we ran 
algorithm
link
linear regression
http   youtu be tsdj x cpji
ridge regression
http   youtu be rx u   bj  
random forest
http   youtu be alf tubb ag
artificial neural networks    hidden layer of    neurons  http   youtu be hlk rgxadle

iv 

future research and directions

this project offers opportunities for further work in several directions  there are of course several
steps we might take with respect of improving our machine learning on the project 
the first is to incorporate a more diverse set of training data  what we discovered from the
subjective evaluation of our algorithms was that the ones that have the most optimal prediction
 

fispeed  and consequently the most fluid rendering   namely the linear regression and ridge
regression  are highly susceptible to overfitting in a way that might be improved through a more
diverse set of training data  for example  one problem we saw with both algorithms was that
raising one ankle or the other often causes the corresponding elbow to raise as well  presumably
due to a lack of training data in which the ankles are raised but not the elbows  imagine touching
a virtual box hanging in the air  your ankle moves along with your arm  because your whole body
reaches out to touch it  improving our training set in order to diversify body movements might
help avoid such problems with the linear and ridge regression models 
one additional pattern we observed in the data is that there is evidence  described above in
results  of a handedness bias where people completing the box task were more likely to use
their right hands and therefore  right elbow location prediction is sometimes asymmetric to left
elbow prediction  future expansions of our training data set might look at further examining and
correcting for this feature 
finally  assuming high degrees of accuracy are attainable with the improvements above and
looking beyond the immediate future  we hope this research contributes to the growing field of
human motion reconstruction  it is worth acknowledging that in our particular case it may not in
fact be of high practical value to render elbow location based on our given input features  as long
as it remains fairly easy to simply track and render elbow movements of our participants without
causing excessive discomfort or inaccuracy using the same trackers already placed on the wrists
and ankles  however  as a matter of academic inquiry in the field of motion reconstruction  it
may be an open question whether elbow location is highly predictable using wrist location  if  as
our research seems to suggest  that is indeed the case  this leads to a number of questions about
which joints have primacy in the sense of predictive power over the rest of the bodys movements 
in the field of social sciences  we may well ask how much about non verbal cues can be inferred
from predictive models that are able to map whole arm or body movements using only a few key
tracking locations 

   

acknowledgements

we would like to thank prof  jeremy bailenson of the communications department and our
labmates at the virtual human interaction lab  we would also like to thank the course staff of
cs     especially richard chen and mahdi soltanolkotabi  for advice with regards to the project 

iv references
    lenarcic  j   and philippe wenger   human motion reconstruction by direct control of marker
trajectories   advances in robot kinematics  analysis and design  new york  springer       
    khatib  o   e  demircan  v  de sapio  l  sentis  t  besier  and s  delp   robotics based synthesis
of human motion   journal of physiology paris                        
    lai  ying xun et al    d adaptive reconstruction of human motion from multi sensors   the
third international workshop on wireless sensor  actuator and robot networks       
    tom schaul  justin bayer  daan wierstra  sun yi  martin felder  frank sehnke  thomas
ruckstiess  jurgen schmidhuber  pybrain 
    pedregosa et al   scikit learn  machine learning in python  jmlr     pp                  

 

fi