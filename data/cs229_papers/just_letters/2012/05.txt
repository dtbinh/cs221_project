 

malicious url detection
christophe chong  stanford   daniel liu  stanford   and wonhong lee  neustar 
abstractweb vulnerabilities are on the rise with the use of smartphones and mobile devices for both personal and
professional use  this paper focuses on a machine learning solution that identifies malicious urls using a combination
of url lexical features  javascript source features  and payload size  we use an svm with a polynomial kernel to
achieve an accuracy of      and an f  score of      
index termsinternet  security  machine learning  malware  javascript

f

 
   

r esearch goal
mobile trends in security

in this paper  we discuss our experience training and testing a malicious url detection system  several trends in technology and security
motivate our research efforts 
first  the web has grown to be an increasingly dangerous place  in       symantec reported a year over year increase in web attacks
by          this translates into roughly      
new attacks every day  the speed at which
new attacks are deployed has considerably outpaced boxed anti malware software 
second  there has been significant growth
in both personal and enterprise use of mobile
web technology  in their      state of mobility survey  symantec noted that  once mostly
forbidden by it  smartphones are now being
used by hundreds of millions of employees
throughout the world      thus  the attackable
population for attackers has not only grown 
but comprises  all else equal  a potentially more
attractive group from a commercial or political
standpoint 
finally  although smartphone usage has
grown to be a major endpoint in internet connectivity  it still lacks the level of protection
found in pc based anti malware technology 
part of this is due to the novelty of the devices 
but it is also directly driven by strict controls
some mobile device makers place on thirdparty software developers 

    research goal
our ultimate goal is to contribute to the creation of a realtime malware classifier to block
out malicious urls  we focus our efforts on
three subcategories of web attacks  drive bydownloads  where users unwittingly download an executable malware payload  phishing 
where attackers pose as legitimate websites
to steal user information  and exploits from
javascript code found in website source code 

 

p rior work

    lexical and url features
we build upon the work of several malware
detection research efforts  younghan choi et al 
use n gram  entropy  and word size as metrics
for malicious code detection in javascript code
     they note that attackers commonly use obfuscation techniques to hide javascript attacks 
fortunately  the resulting code can often look
heavily obfuscated in comparison to legitimate
code  making it possible to use certain obfuscation patterns as a proxy for malicious intent 
justin ma et al  have demonstrated the potential of a classifier based on suspicious urls
     they train their dataset on properties such
as host name length  overall url length  and
the count of the subdomain separating character      combining these lexical features with
host information  e g  dns registry info   the
researchers report an accuracy rate of over     
finally  several researchers            have
used passive dns query data to detect malware domains  particular those used to run

fi 

command and control centers for infected ma  where we define tf and idf
chines 
f  t  d 
tf  t  d   
max f  w  d    w  d 
 d 
  data
idf  t  d    log
  d  d   t  d  
to find benign urls  we seeded a crawler we also exploit the hierarchical nature of the
with the top      websites on the alexa subdomains by splitting along each separator
ranking website and started collecting and saving a bigram consisting of any subdourls  we then searched a malware main plus the top level domain  we hope to run
database  http   support clean mx de clean  across phishing patterns or other suspicious
mx viruses  to find recently discovered urls in the process 
malware sites 
the problem with gathering data from
fig     attackers may systematically choose urls
malicious urls is that  once known  the urls
dont stay up for very long  to save the state
of the website  we downloaded the source or
payload object at the url location and saved
it on a separate machine 
after beginning our analysis  we realized
that lexical features were getting an incredible
boost from duplicates  we thus removed urls     source code features
if their first three subdomains matched up 
javascript exploits are typically obfuscated to
we ended up finding     duplicate urls 
prevent detection by automated or manual
at the end of the web crawls  we had   k
analysis  heres an example of one exploitative
benign urls and   k malware urls  we then
script we found in our malicious sample 
randomly sampled  k malware urls to get
approximately      benign urls and     
 k i s  string  fro  
malware urls for our final training testing
 mch   arcode   n k  
set 
 i h math f  i h         
if      xf     eval s   

 

f eatures

we develop three different categories of features to detect malicious urls 

   

url lexical features

fortunately  we are able to use the salience of
obfuscation as a proxy for exploitative behavior  attackers typically use special characters to
encode script  either as direct ascii or transformed by some simple character to character
function 
document write unescape 
  c        d  c   
  c     e     d   
     e           

we approach the url as an nlp problem 
we use term frequency inverse document frequency  tf  idf   to weigh the importance of
a token in the url as a way to associate url
tokens with labels  tokens include anything in
thus  we can use the ratio of special charthe url  including both the domain and the
acter subsequences  non english for en webpath  tf  idf can be defined as
sites  to script length 
in addition  attackers who choose to retf  idf   tf  t  d   idf  t  d 
construct functions before calling them require the use of special functions  such

fi 

fig     comparing special character subsequences in
malicious  red  to benign  blue  urls  the files are
evenly distributed across the y axis for clarity  the xaxis is a normalized score 

summarizes our results for all cases 
case
       
lexical features
x x x x
keyword count
x
x
special char ratio
x x
script length
x
file size

 
x
x
x
x
x

 
x
x
x
x

fig     malicious url detection feature selection

as fromcharcode  eval  document write 
escape  etc  they can also include the malicious code in an iframe  we count these
keywords and use them as one feature 
    network features
although we have explored a variety of network features  including latency  dns query
data  domain registry data  and payload size 
we have only captured payload size for our
tests  executable can be arbitrarily long  and
obfuscated script may add to payload size as
well 

 

e xperiment

we chose to use an svm with a polynomial
kernel of degree two  with an       split on
training and testing over   k urls 
we tried various combinations of the
features      lexical features      lexical features
and counts of keywords      lexical features
and the special character subsequence ratio 
    lexical features  counts of keywords  special
character ratio  and script length      the
previous case and file size      the previous
case without lexical features 
our best results came from case      where
all features are used  we had an accuracy
rate of      and an f  score of       figure  

 
   

d iscussion
results

one of our assumptions was that machinegenerated malicious urls could be detected
by extracting lexical features from the url  we
have evidence to support that telling features
can be extracted by using url bigrams and
tf idf word association 
although javascript features boosted
our svm performance  more sophisticated
javascript features may be worth pursuing 
one alternative includes extracting features
by dynamically running and analyzing
javascript code  which may end up having
complementary performance with static
javascript analysis  as we have observed
already  legitimate urls commonly engage
in javascript obfuscation  making static code
analysis a less attractive option 
   

attacker strategy

the growing threat to mobile web users could
be mitigated by automatic url detection  by
using a trained svm  one could check urls

fi 

fast enough to deploy in a realtime service 
this means users can use a preemptive service
without impacting their mobile experience  as
the old saying goes  an ounce of prevention is
worth a pound of cure  but only if the solution
is palatable 
attackers may certainly make tradeoffs to
outwit the features we have selected  however 
such elusion isnt free  for example  using more
legitimate sounding urls in phishing attempts
may bypass suspicious bigram detection  but
may result in fewer click throughs by scrupulous users  or  reducing special char code sequences in obfuscation may work  but only by
increasing script size or by using less obfuscation and risking detection by malicious code
pattern detectors  our hope is that by adding
the appropriate features  a machine learning
based system would be able to force attackers
to make tradeoffs in web based attacks 

 

c onclusion

we have shown that it is possible to construct
an svm to classify malicious urls with some
degree of accuracy  future work would involve
testing on a much wider array of malicious
urls  while incorporating a more sophisticated javascript feature extractor and utilizing
more network features  more importantly  by
using a trained svm  it is possible to provide
a realtime service to check malware urls 
regardless of the browsing device used 
in general  using a machine learning approach to discover malicious urls and web
attackers is a potentially significant approach 
especially when considering the scale at which
machines themselves have been used to automatically generate  obfuscate  or permute attacks  we hope to see more research put forward in this endeavor to further reduce the
space of feasible attacks 

r eferences
    antonakakis  manos  kopis  detecting malware domains
at the upper dns hierarchy  http   static usenix org 
events sec   tech slides antonakakis pdf 
    bilge  leyla  engin kirda  christopher kruegel  marco
balduzzi  exposure  finding malicious domains using passive dns analysis  http   www syssec project 
eu media page media   bilge ndss   pdf 
    choi  younghan  taeghyoon kim  seokjin choi   automatic detection for javascript obfuscation attacks in web
pages through string pattern analysis  http   www sersc 
org journals ijsia vol  no         pdf 
    ma  justin  lawrence k  saul  stefan savage  geoffrey
m  voelker  beyond blacklists  learning to detect malicious web sites from suspicious urls  http   www cs 
berkeley edu jtma papers beyondbl kdd     pdf 
    symantec  internet security threat report  volume    
http   www symantec com threatreport  
    symantec 
    
state
of
mobility
survey 
http   www symantec com about news resources 
press kits detail jsp pkid state of mobility survey 

fi