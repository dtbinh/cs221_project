recognizing chatting style
rohan puttagunta  nick wu  renjie you
december         

 

introduction

there has been significant work in text classification and stylometry  which is the study of
linguistic style  much of this work has been focused on more formal bodies of text  for example  one might classify emails as spam or not spam  or attempt to identify the true author
of a literary work  our project  however  is concerned with classifying who the writer is in
an online one on one chat  online chats use significantly more informal diction and syntax
than previously studied texts  this fact allows us to attempt to use unique features and
idiosyncrasies of peoples informal online writing styles  in addition to traditional techniques
and characteristics  to distinguish between writers 
being able to identify between writers in online chat has a number of significant uses  court
cases may often include a review of online chat communications  and this would be useful
in potentially detecting fraudulent or tampered evidence  furthermore  especially in a live
chat conversation  this may also be used to identify social engineering attempts 

 

data collection and formatting

our data sets use the authors personal google chat logs  as downloaded via the mozilla
thunderbird mail client  we have three data sets  with the primary one being the largest
data set containing        chats            lines of chat  and           words  excluding
words lines by the authors   the chats span roughly   years and feature over     unique
writers  although over     of the words are concentrated in just    writers      of the words
in   writers  and     of the words in the top writer  the other data sets are used as well
for diagnostics and additional verification of results  although smaller  they have similar
distributions and concentrations 
for the considerations of this project  we will only consider chats by writers with more than
   of the total number of words  for the main data set  this is    people  i e  we have   
classification labels  furthermore  we will only train and test on chats containing at least   
words by the other writer  because if the chat contains not enough words  it becomes nearly
 

fiimpossible to make accurate predictions 

figure    distribution of total words among the various writers  notice that the largest
portion of the chart  the      actually belongs to everyone else  i e  everyone not in the
top    
we formatted the text by tokenizing across whitespace to create our feature vectors  one additional formatting technique we used was punctuation splitting  which selectively separated
punctuation from words and used punctuation as its own feature 
 

fi 

models used

we implemented four main models 
   naive bayes multinomial event model with laplace smoothing 
   svms with one versus one implementation
   svms with one versus rest implementation
   softmax regression
in each of the first three models  our feature vector represented absolute word frequencies  the svms were implemented with linear kernels  in the softmax regression model 
the feature vector was a boolean array which represented the appearance of a word in a chat 
to determine which features were used  we tried the following   filters 
   no filter  if any string appeared after tokenizing across whitespace  it was used as a
feature 
   top     most common english words  we removed all features that were in a dictionary
of the     most frequently used english words  this is because we believed that
common english words would not be a signal for distinguishing between classifications 
   all english words  we removed all features that were in a relatively comprehensive
dictionary of        english words  this was done to isolate chat specific words and
idiosyncrasies such as acronyms like lol or emoticons 
the filtering was case sensitive in that we did not filter out any word with a capital letter
because we believe capitalization is a fairly distinguishing feature  for each of the three
feature vectors  we used both punctuation splitting  as mentioned in the previous section 
and no punctuation splitting  this brought the total number of unique feature vectors up
to    each of the feature vectors had over         features  though the filtering made the
feature vectors a bit smaller  the primary difference was that most of the more prevalent
features were removed 
furthermore  we also attempted the following models and ideas  but ultimately they were
not used for various reasons 
   naive bayes multi variate bernoulli event model  this had a low success rate  less than
     and was hampered by the fact that line and chat lengths  measured in terms of
the number of words  vary wildly from person to person  which significantly influences
the training of the parameters and skews the results 
 

same as cs     lecture notes  generative learning algorithms  page   

 

fi   adding non word frequency features to svms  such as number of words per line  we
found that this did not contribute much to the results  i e  there was no noticeable
change from the existing svms  this is largely because the existing number of features
is overwhelmingly large  on the order of          compared to a small number of
handpicked features 
   using word frequencies as the feature vector for softmax instead of a binary vector  we
could not train the model because the computation either overflowed or underflowed
 if we normalized the frequencies  during the exponentiation process 

 

results

the table below features the four aforementioned models and their success rates under the
three types of feature filtering  each table entry contains two elements  the first element is
the accuracy rate without punctuation splitting and the second element is the accuracy rate
with punctuation splitting  in each case  we split off     of the data set for training and
used the remaining     for testing to obtain these values  the highest value for each model
is italicized and the global maximum of the entire table is bolded 

naive bayes
svms  one versus one 
svms  one versus rest 
softmax

 

exclude all
english words
            
            
            
            

exclude     most
common english words
            
            
            
            

exclude nothing
            
            
            
            

discussion and further work

our results were overall very satisfactory  the accuracy was as high as     under certain
settings  which is a significant amount considering there were    classification labels and the
largest only made up about     of the total samples  generally  our models made classification mistakes on relatively short chats  which is to be expected given that shorter chats
contain less information  furthermore  we found that if we were to give our models a second
or third classification choice  our total accuracy may be higher than     
the results suggest that the feature vector after we exclude all english words captures the
bulk of the models predictive powers  although in some cases adding back in the regular
english words improved the testing accuracy  the overall increase was marginal compared to
the original base  the left column  
however  there is potentially some latent unexplored structure  for example  in our naive
bayes model  whenever our model erred  it tended to systematically over guess classifications
 

fiwith higher priors  in particular  it tended to guess the writer with the highest prior about
    to     of the time  but the writer with the highest prior only encompassed     of the
total number of words in chats 
furthermore  our svms might improve with more innovative features or even possibly fewer
features  due to the fact that they are currently overfitting   instead of excluding features
 e g  english words  entirely  we could also investigate weighting schemes to keep them in 
but lower their influence on the models guesses 
finally  the softmax classification was hindered at various instances by precision limitations
in matlab  which was our primary language for implementing it  in particular  the gradient
ascent was very sensitive  even small changes to the learning rate caused potential overflow 
additionally  we mightve been able to improve softmax by using a feature vector that
includes actual word frequencies  instead of a binary vector  and other interesting features 
to implement these changes  one can use python and its mathematical computing packages
that can support higher precision 

 

acknowledgments

we would like to thank professor andrew ng and the rest of the cs     teaching staff for
teaching us the techniques that made this project possible  we would also like to thank
catherine chen for helping with the initial project idea 

 

fi