          

predicting future energy consumption
cs    project report
adrien boiron  stephane lo  antoine marot
abstract
load forecasting for electric utilities is a crucial step in planning and operations  especially with
the increasingly stressed utilization of equipment  the objective of this project was to accurately
backcast are forecast hourly energy loads  in kw  for a us utility for    zones using more than  
years of historical loads and temperature data from    weather stations  several multivariate
linear regression models were developed and reliably predicted energy loads with down to   
mean training and testing errors using a leave one week out cross validation  lowocv 
algorithm over the     years of data available  along the way  the data was notably treated to
remove problematic events for training such as outages  and to fit sudden jumps in load 
indicator model
as part of the kaggle competition gefcom          historical hourly energy loads data were
provided for    zones  without specific information  along with temperature data for    weather
stations  our first approach consisted in training a multiple linear regression model on the entire
dataset available  with different combination of the following features  temperature  month  day
of the week  hour  and trend  this model  called the indicator model  could be written as 
                                             
note that in the cases of the month  day  and hour features  the predictor variables are qualitative
instead of quantitative  for example  the   could be seen as a vector having a different value for
each month  and  as an indicator retrieving the right constant as follows 
                     
regarding the temperature law  a  rd degree polynomial was found to provide the best fit  as it is
also in the literature      relationship between weather stations and zones was not available  it
was therefore necessary to correlate weather stations and zones in order to use the appropriate
features  the selection of the most correlated stations for each zone was done using data during
early morning hours in winter  since we found out through analysis that was the time of highest
correlation between temperature and load  logical since no human activity  except heating relied
to temperature  
let us note that zone   will mostly be left out in our discussion  it is because the load history in
zone   is very different in nature to what is found in all other zones  such that a specific and
different model would be needed for zone    since time was lacking to investigate this zone
properly  it is left aside in this analysis 
additional features such as the interaction between month temperature  hour temperature  and
day hour were progressively and similarly added to improve this model  a leave one week out
cross validation  lowocv  algorithm was written to test the indicator model  and the mean
training  and testing  error of the most complex one was found to be of more than       see
results    which was not satisfying  that is why we went on to a more elaborated model that also
optimizes the temperature polynomial and trend coefficient for each season  day and hour  that is
the full model we will now describe 

   

fi          
full model
another approach to capture human activity within a model is actually to divide the training set in
independent smaller data sets for which this activity should be identical  and to fit a model to each
of those reduced training sets  in practice  the full data set was divided in              data sets 
one for each different season  day and hour  those small data sets had around    training
examples each  and would comprise all the available data points corresponding for example to a
 am on a monday in winter 
 
 
                                              
       

the model  used to fit each of the reduced sets and described above  used as features the trend of
the overall data  and a degree   polynomial of the temperature at time t as well as at time t   
taking the temperature from the most correlated weather station for each zone  this correlation
can be realized during winter mornings and kept as argument as before  or the weather station
with the highest correlation can be determined for each season  day and hour  both give quite
similar results  multivariate linear regression  through the normal equations  is used to fit the   s 
also  holidays were manually modified in the data to be treated as weekend days 
to test this model  a lowocv algorithm was also written  in practice  it would for each hour of
the test week  extract the season  day and hour  in order to pick and use the appropriate model
among all those we trained on the other weeks  satisfying training and testing error of the order of
   were obtained with that model   some results are shown on figure   

figure    example  zone    forecast in late     

bias vs  variance
the next step was to construct learning curves to diagnose if we had rather bias or variance
issues  despite the small size of each of the training sets  the learning curve plotted here for this
model firstly showed that enough data is available to make the testing error converge to the
training error  and thus that we did not need to train the model upon every week  a limited
number was necessary  which lead a substantial acceleration of the algorithm  it also taught us
that in order to further improve our model the bias should be reduced by adding more features 
potential other features were then envisioned  such as the temperature   hours and   hours before 
or also the temperature given by the second and third best correlated weather stations 
those features were added to the model  still keeping the division for each season  hour and day 
in doing so  the training error substantially dropped from       to as low as        but
concerning the testing error  there were no major improvements and it appeared that the best
results were often obtained with fewer features  for some zones  it was better to use the two best
correlated stations than only one  meaning that the zone could be in between two weather stations

   

fi          
for instance  and for others only one was more effective with this data set  notably  adding the
previous temperature was beneficial for quite a few of them 

figure    learning curve

this significant increase in variance was due to overfitting  there was not enough data for each
season  day and hour to fit appropriately more features and to lower effectively the testing error
 if we use them all  we have more than    parameters for    points    one idea was then to group
weekdays and weekends  increasing the training sets size but risking to loose the intrinsic
difference in human activity between each of those days  when doing so  continuous
improvement was noticed when adding more correlated stations  for some zones  grouping
weekdays and weekends to then fit more correlated stations performed better than treating each
day separately with only one station 
we do believe those supplementary features are promising and carry information  but in order to
include them ideally into the model  without overfitting and without having to deal with
complicated trade offs  more data would be necessary 
on forecasting
another possibility to improve the accuracy of this model could be also to use the load history 
for example  for very short term forecasting  adding as feature the load of the previous hour
drops the testing error to around       we could also imagine  depending on how far in the future
the forecast is needed  using the load at the same hour the day or the week before  etc 
an attempt to forecast iteratively a whole week showed interesting results  using the load of the
previous hour proved to be more accurate on the first days of the week but more and more
inaccurate after several iterations  hour after hour  to then reach a point where it could be less
accurate than a method not using this feature  those results also varied depending on the zone
and the week  being the sign of underlying complexity and instability 
in our study  forecasting was realized within the data  using the real temperature as input for the
forecasting algorithm  this was used to decouple load prediction and temperature prediction  and
build the most accurate possible load model  a next step would be to create also a model for the
temperature  in that case  data sets going back     years are available  that should permit to
create a satisfying temperature model with machine learning techniques  then  both load and
temperature model could be used to realize complete forecasting 

   

fi          
data adaptation    energy outages

figure    outage detection using lowocv

some data adaptations were needed to improve the performance  for example  load data may
have sudden drops corresponding to energy outages in the zone  these outages were detected
through the lowocv algorithm and systematically isolated to not affect the model training 
removing outages from data using a criterion on the maximum lowocv testing error reduced
training error from        to       in zone   while using the same training algorithm 
data adaptation    load jump

figure    load history in zone   

in certain zones  load jumps can occur  created by sudden and permanent load transfers or the use
of a supplementary power plant  a linear shift prediction method was applied to capture such a
jump occurring in      in zone     in practice  it meant that more features were added to the
design vector so that the normal equations also fit the jump  this lead to such a model 
 
 
                                              
       
            

here   was for example   for      and     for the years before  while the jump fitters   and  
would only be non null and calculated through the normal equations for zone    where the jump
occurs  the results for the jump fitting are shown below on figure    without the alpha shift
correction  the mean training error in zone    was         with it  only       

figure    zone    forecast with alpha shift off  left  and on  right 

   

fi          
results
the performance of the early indicator model and full model are listed below along with different
simpler models for which one feature or adaptation was removed independently from the full
model  or using only temperature  no hour dependency  etc  the full model  apart from zone   
provides a very good prediction of energy consumption  the errors listed below are training
errors  which are equal to the testing error found in doing lowocv since learning convergence
is achieved in all those configurations 

conclusion
an efficient learning algorithm was developed to accurately predict load consumption in    zones
using a division of the data  a limited amount of features and some data adaptations  this model
is able  when knowing the temperature  to predict the load with    mean error over more than    
years of hourly data  two of those data adaptation techniques  that substantially improved the
training in specific zones  were described  also  additional features were proposed  that could
provide a higher accuracy over bigger sets of data  at last  further work could be to create a
model to predict temperature in order to realize and test complete forecasting 
references
    www kaggle com  global energy forecasting competition       load forecasting
    tao hong  short term electric load forecasting  phd dissertation  north carolina state
university  sept   th     

   

fi