haptic classification and faulty sensor compensation
for a robotic hand
hannah stuart  paul karplus  habiya beg
department of mechanical engineering  stanford university
abstract
currently  robots operating in unstructured environments
rely heavily on visual feedback from cameras to perform
tasks  however  in many situations visual feedback is not
available  for example if the robot must work in the dark
or grab an object from a bag  in these environments 
haptic feedback in the robots hands can augment visual
feedback to help the robot identify object size  weight 
and pull force 
we implemented machine learning algorithms
on data taken from a robotic hand to predict the size of
the object grasped  pull force on the object  and direction
of the pull force  in addition  the robotic hand we tested
had several faulty sensor samples  such as noisy
electrical connections   we used linear regression 
multivariate nave bayes  multiclass logistic
regression  multiclass svm regression  gradient
ascent algorithm  and k means clustering to determine
which sensors were faulty and compensate if possible or
chose an algorithm robust to noise and error 
  introduction
currently  robotic control in unstructured environments
relies heavily on visual perception because it is
unobtrusive and reliable in many circumstances     
however  haptic exploration and manipulation allows
robots to interact successfully with dynamic and
complex environments when visual feedback fails  for
example extracting a specific object from inside a duffle
bag or manipulating a tool while vision is obstructed  
however  tactile and position sensors can become noisy
or erroneous due to physical damage in these potentially
treacherous contact situations  we seek to identify and
compensate for faulty haptic and position sensory data 
also  the process of estimating what we expect the hand

to feel could become a part of the automatic feedback
control of the hand  changing actuation to achieve a
specific type of grasp  given unreliable sensor feedback 
robust error compensation algorithms may be
particularly important  for example  in human robot
interaction safety 
research has been conducted on replicating
human haptic learning in humanoid robots to improve
the cohesion and performance of robots in real world
situations      machine learning algorithms have been
employed to classify objects  solely from haptic sensor
data without explicitly modeling the object shape     
  experimental setup
we tested the arm h sri hand  which has four cabledriven fingers  one motor per finger  and one tendon per
finger  this hand is under actuated because it has more
degrees of freedom than actuators  during testing  two
opposing fingers gripped a     or     diameter pvc 
    long tube  then  the tube was slowly pulled out by
its center of mass  by using a low friction slider on the
inside edge of the tube  at angles varying from   to   
degrees    to pi   radians  in    degree increments as
show in figure  and    grasp force  same as tendon
force  was also varied from    to    newtons in steps of

distal phalanx

intermediate
phalanx

proximal
phalanx

figure    experimental setup 

figure    examples of  left  one pull trial with a    
tube size and  right  different pull angles with    
tube size 

fi n  but was kept constant during each trial 
knuckle angle  finger pad pressure  video 
gauge pull force  and tendon tension were recorded as a
function of time using the robot operating system
 ros   there is one capacitive encoder per knuckle and
   pressure sensors distributed through the finger pads of
each finger     total   the hand was mounted on a   axis
jr      n load cell for gauge force redundancy  a
webcam recorded images of the scene to collect
displacement information and was calibrated using the
image toolbox included in ros 
frictional effects between the object and finger
pads are pose dependent  so it was desirable to place the
object in roughly the same initial position every test 
therefore  the object was shaken in the grasp to allow
the hand to settle to a more optimal starting condition
 which also happens to indicate local stability in the
initial grasp   the objects pull cable was routed through
a pulley placed at approximately the desired pulling
angle  and connected at the other end to a force gauge
 see figure     this provided easy force measurement
along the direction of the pull cable  so will be easier to
analyze  video images and jr  readings were not
utilized for this experiment  but future work could
incorporate them 
  machine learning experiments
machine learning methods have been employed to
classify pull angle  object force  and object size in the
hands grasp  finger pad sensors were calibrated using
linear regression and used to train nave bayes 
support vector  and logistic regression models for
predicting pull angle and object force  encoders were
calibrated using k means clustering and used to train an
svm model for object size classification 
the pull experiments were conducted     times 
with a sampling rate that provided      samples total 
because of the large data sets  all accuracies are
calculated using a hold out cross validation method
where the model is trained on     of the data  randomly
selected  and tested on the remaining     
    finger pad force sensor characterization
the raw data was calibrated such that  given a reading
from the    sensors you could estimate the normal force
location and amplitude on each phalanx    per finger   
total   calibration data for the finger sensors was
collected by placing a printed strip of dots over the
surface of each finger with a repeatable locating jig and
equidistant test locations   mm apart   slowly pressing
the force gauge  by hand up to   n  directly on a known
location of the pad surface  we recorded raw force values
from the tactile sensors on each phalanx  during this
preliminary test        pressure samples and      gauge
force samples were collected over the same time period 
but with different sample rates  therefore  finger pad

readings were linearly interpolated to match the time
stamps of the gauge 
linear regression was used to formulate a
hypothesis for applied force  f   length along the finger
 y   and location along the width of the finger  x  using
the array of sensors on each phalange of one finger  the
normal equation design matrix was dimensioned     xn 
where n was the number of sensors on that specific
phalange  testing error was calculated for each phalange
model 
phalanx
proximal intermediate distal
  of sensors  n  
 
 
f error
     
     
     
y error
    
    
    
x error
    
    
    
these errors are largely due to the mechanical
shortcomings of the fingers  there are locations on the
finger pads that do not have sensing material underneath 
for example  large errors occur primarily in sample
locations which are not located directly above sensors 
locations where the sensors are only detecting strain
propagations through the polyurethane skin  there is
also mechanical play where finger pad connections do
not have locating features  no load output from each
individual sensor may also change due to flexing of the
plastic base  considering these factors  this model error
is reasonable  however linear regression is susceptible
to noise 
figure   illustrates the hysteresis of the one
working sensor on the intermediate phalanx  in this case 
slow force application gives the more linear region of
skin readings while faster force release decreases nonlinearly  most likely due to the dynamic characteristics
of the materials encasing the sensors  however  this

figure     a typical outputs from one working sensor    
locations are tested on this phalax  resulting in    hysteresis loops 
one highlighted test location  b  appears to be centered on the
sensor   c  individual samples  note change of force rate  

finonlinearity could be due to human error also  on the
other finger  the sensors were more erratic and unreliable
due to a faulty electrical connection  therefore 
symmetry is used to assumed that this calibration process
can represent both fingers when they work properly  this
is an important source of error during later model
development   this highlights a main challenge for
roboticists  unreliable sensors 
    pull angle classification using pad sensors
pull angle was classified using multivariate nave bayes
 nb   support vector machine  svm   and logistic
regression  logreg   these algorithms were run using
all raw data     input variables  and the y and f outputs
from the calculated linear regression hypothesis    
input variables   the variance of the data is high at low
object pull forces  so each algorithm was retrained a
second time excluding pull forces below  n  nb was run
using kernelized multivariate nave bayes capabilities 
multivariate logreg and svm were conducted using
the liblinear      library provided by the machine
learning group at national taiwan university 
figure   summarizes and compares the
resulting test error for each training method  logreg
and svm show similar trends  and performed best when
trained on all raw data  resulting in        and       
accuracy respectively 
of the misclassified cases  when using nb on
all raw data  most were within one class value of the
correct angle  only    degrees off   only      of
predictions were significantly wrong  off by    degrees
or more   figure   shows the nb distribution of
predictions  given each actual pull angle class  this
trend is demonstrative of all training method trends 

figure    percent accuracy for pull angle 
    nave bayes      logistic regression      svm 

figure    angle classification distribution for nb  all raw data  

in this classification circumstance it is
advantageous to keep low force data in training  not
only does logreg and svm work better when no data is
excluded  but it gives the robot designer more
information about small force object interactions  also 
it appears that the error of the linear regression
hypothesis only hurts the accuracy of all three models 
    pull force classification using pad sensors
pull force was also classified using multivariate nb 
svm  and logreg  initial tests were run on all raw data
with classes created from the gauge force reading
rounded to the nearest integer for a total of    classes 

figure    nave bayes errors in prediction for    classes  the
blue is within a  n range around the correct hypothesis  note 
error seems to diminish at very high applied object forces 
high forces usually correspond to a moving object  therefore 
it seems static frictional forces  or unchanging hand pose  may
affect the reliability of pressure sensor readings 

fithen seeking to improve tolerance  the force classes
were binned into  n ranges for a total of    classes from
  n to   n  both schemes were also trained using the
linear regression  see figure   for a summary of test
results  nave bayes gave the best result         testing
error  using all raw data with the  n range binning
scheme  figure   shows the benefits of increasing class
range  figure   shows the nb distribution of predictions 
given each actual pull force class 
    faulty knuckle angle sensor compensation
the knuckle angle sensors in the robotic hand were
custom research prototypes  they were an entirely new
design that worked by measuring a variable capacitance 
they were designed to be absolute encoders but due to
symmetry in the design they could be off by multiples of
pi   radians 
before we could use the knuckle angle sensor
data to predict object size  we had to remove this
sporadic offset  we could not simply subtract the initial
value from all our trial runs because then we would lose
information about the relationship between the different
knuckle sensors 
in the end  we used a k means algorithm to
match a set of means that were offset by pi   radians to
the raw data  then we normalized by these means to
remove the offset 
the green dots in figure   show the knuckle
data for knuckles one  two  and three from one finger
grasping the    in tube  the green line shows the density
of points  it can be seen that the data is clustered around
multiples of pi   radians 
the blue dots in figure   indicate the means that
were fit to the raw data  a gradient ascent algorithm was
used to find the best fit of the means to the data 
the original data was then normalized by the
matched means  the red dots and line in figure   show
the normalized data and the density of points
respectively 
figure    shows the knuckle angle data versus
time for all trials before and after compensation of all
three knuckles of the two fingers  green lines show the
angle of the first knuckle  the red lines show the second
knuckle  and the blue lines show the third knuckle  as
you can see  the measurements are much more consistent
after compensation 

figure    percent accuracy for pull force 
    nave bayes      logistic regression      svm 

figure    force classification distribution for nb   n bins  

    object size prediction
after we compensated for the knuckle angle sensor
offsets  we used an svm algorithm to try to differentiate
between when the hand is grasping the     versus the
    diameter tube  we split the knuckle angle data into
two bins      for training      for testing  since the
poses of the two fingers are roughly symmetric and the
distal knuckle does not bend very much  we chose to
figure    k means and gradient descent to compensate for
fixed knuckle angle sensor offsets

fiit would also be interesting to test and classify more
object sizes and shapes  it is important to note that these
machine learning methods have been trained for a
specific test setup  for robots to function in unstructured
environments  ongoing experimentation is vital 
    learning algorithms
more leaning algorithms could be employed to improve
fit  for example  the em algorithm could take into
account pad sensor reliability 
also  finding an adequate method to condition
incoming finger pad data to make an accurate hypothesis
of applied force and location on each phalanx may prove
to cancel out specified noise to create a superior learning
algorithm  for example using locally weighted
regression over time may reduce the effects of erratic
electrical connections 
figure     original knuckle angle data  top  and
compensated knuckle angle data  bottom 

only use the knuckle angle data from the proximal and
middle knuckle of the first finger to train our svm 
the svm results are shown in figure     the
prediction accuracy was     for the test data  this is an
exciting result because it suggests that a robotic hand
could be trained to identify objects of different sizes with
knuckle angle feedback alone 

  summary and conclusion
the models developed in this project can be used to
allow a robot to haptically explore its environment
without visual feedback  for example  identifying an
object in a bag by touch or estimating the weight of a
object in the dark  object size  pull force  and pull angle
from knuckle angle sensor and finger pad pressure
sensor data can be successfully predicted using machine
learning algorithms  even in situation where a faulty
sensor might disrupt accuracy  the robustness of the
algorithms still allows for reasonably reliable results 
exciting future work could build on these
techniques to help increase the capabilities of robots to
perform in unstructured environments 
  acknowledgements
we would like to thank bdml members mark cutkosky 
dan aukes  john ulmen  and barrett heyneman for
helping with the experimental setup and making this
project possible  thank you to sri  darpa  and nsf
for past and present support  finally  thank you to all the
cs    staff for all their hard work this quarter 
  works cited
    dipert  b   shoham  a      eye  robot  embedded

figure     vm of joint angle for     and     diameter tubes

  future work
    data collection
during data collect  human factors affected the pad
sensors and should be more controlled  improving data
collection could lead classifying when pressure sensor
data becomes faulty to adjust the hypothesis locally 

vision  the next big thing in digital signal
processing   solid state circuits magazine  ieee   vol   
no    pp        june     
    jefferson coelho  justus piater  roderic grupen 
developing haptic and visual perceptual categories for
reaching and grasping with a humanoid robot  robotics and
autonomous systems  volume     issues       
november       pages         
    gorges  n   navarro     
ger  d 
rn  h    
 haptic object recognition using passive joints and haptic
key features   robotics and automation  icra       
ieee international conference on   vol   no   pp               may     

fi