predicting patients with diabetes type ii
from ehr data
cs    final project

xiaoran zhang

ruoyu ding

scpd
nuance communications  inc 
burlington  ma
xiaoranz     gmail com

stanford university
ruoyud stanford edu

abstractin this paper  we are interested in developing
classification methods for predicting patients with diabetes type
ii from ehr data  we first compare several common binary
classification methods for this task  svm  gradient boosted
trees and neural nets  we optimize the parameters for the best
three individual systems  then implement weighted voting
technique between these systems to perform system combination
prediction 
keywordsbinary classification  diagnosis prediction

i 

introduction

due to recent attentions and efforts in healthcare initiatives 
ehr  electronic health records  is quickly becoming a
requirement per patient encounter and is increasingly being
adopted by both physicians and hospitals  one of the possible
uses for this increase of structured data in the form of ehr is
to predict prevalent diseases such as diabetes  type ii diabetes
in particular  is present in      of the population in the us 
being able to predict diabetes diagnosis from past hospital
visits is a step forward to early detection of diabetes type ii as
well as understanding its relations with other diagnosis and risk
factors 
in this paper  we use the de identified ehr data provided
by ehr vendor practice fusion in their kaggle challenge  we
will first discuss feature selection and normalization  then
proceed to compare individual binary classification methods
we employed  such as support vector machines  svm  
neural nets  and gradient boosted trees  we optimize the
parameters for each individual method then discuss the
performance of voting combination between the three systems 
ii 

methodology

the data for this binary classification task is provided by
practice fusion in their kaggle challenge  the ehr data is
organized into database tables with patient specific
information  visit specific physical examination information 
lab panel results and diagnosis  the data is also comprised of
both numerical and categorical data  both of which require
treatment before being used in our classifiers 

a  feature processing and selection
   numerical features  numeric data for this task is
comprised of mainly patient per visit physical examination
data  namely  height  weight  bmi  temperature  respiratory
rate  systolic and diastolic blood pressure  per patient data 
namely  age  we combine numeric data across visits on a perpatient basis by taking the median value of all visits  median
is used instead of mean because there are frequent outliers for
one or two of a patients visits  after combining the data on a
per patient basis  we discard temperature and respiratory rate
because the lack of data  values are missing for most patients 
and we also discard height and bmi data since height has
many outliers which leads to noisy data for bmi  we keep
weight to represent obesity  systolic and diastolic blood
pressure to represent hypotension  both of which are
important risk factors for diagnosing diabetes type ii 
a  missing values  for missing numeric values  we
substitute the missing value with the median of all of the
patients in the training set 
   categorical features  we have two important sources
of categorical data  list of medications prescribed to the
patient per visit and list of diagnosis associated with the
patient per visit  since we do not have temporal information
on the visits and since all of the visits are recent  within the
past   years   we combine medication and diagnosis data
across all visits per patient 
a  data representation  since we have a wide range of
diagnosis and mediation and majority of them have low
frequency of occurence  if we represented every diagnosis and
medication as a feature  we would have a large feature space
with sparse data  thus  we pick the top n most discriminative
diagnosis and medication to produce binary feature vectors for
each of these diagnosis medication   i e    indicates absence
and   indicates presence   the discriminativeness of the
categorical feature is determined by the difference in the
prevalence of the diagnosis medication in patients with
diabetes type ii and patients without diabetes type ii  the
prevalence in any one class is measured by the percentage of

fipatients with the diagnosis medication in that class  this
works quite well  for example  the top two most discrimitive
conditions includes hypertension and lipoprotein deficiencies 
both of which associates closely with diabetic patients 
b  data normalization the names of the diagnosis are
based on icd   coding standard and the names of the
medications are usually brand information with routes  both
of these are more fine grained than what we would like for this
task and therefore we normalize both as follows  for
diagnosis  the icd   code provides the ontological structure
from which the disease is derived  for example  vascular
dementia with depressed mood has an icd   code of      
and senile dementia with delusional or depressive features
has an icd   code of        both of which are child nodes of
snile dementia  uncomplicated with an icd   code of    
in the disease ontology  for our purposes  we collapse these
diagnosis to their parent node  i e  icd   code of      and
consider them to be the same diagnosis  we normalize the
medication features by taking out the route information  e g 
topical vs  oral tablet  and mapping the brand name
medication to its active ingredient   e g  plavix oral tablet
maps to clopidogrel   we also normalize the casing on these
before converting data to the representation described above 
   additional features  we also compute two additional
features  length of the medication list per patient and length of
the diagnosis list per patient 
b  classification model formulations
for our binary classification task  we choose to examine
three machine learning methods with the ability to deal with
higher dimensional features and combinations of features 
since our initial results with linear and low order machine
learning methods gave poor results due to simplicity  for
support vector machine and gradient boosted tree  we use
the implementation provided by the libsvm and gbm r
packages  implement our own neural network algorithm in r 
   svm  we use svm with a polynomial kernel and norm soft margin classification  corresponds to cclassification in libsvm   this gives us control over tuning the
regularization parameter  i e  cost  as well as the degree of the
polynomial  i e  degree  
   gradient boosted trees for binary classification  we
use the bernoulli lost function  we tune the shrinkage
parameter as well as the interaction parameter  i e 
interaction depth  to prevent between overfitting and to
represent non linearity 
   neural network  our implementation of the neural
network uses the back propagation technique to update the
weights  since this is a binary classifier  we train the model
by minimizing the cross entropy error function  where
represents the target  truth  value of the
feature vector and
represents the output from the model  we use the logistic
function as the activation function  we also scale numeric
input data with the scale   function in r 

 

 

       

   

  

we tune the number of hidden layers in our neural
network   note  in our attempt to tune the regularization
parameter  we found the results are highly inconsistent
between runs  
   weighted voting system combination  for each test
sample  we obtain the prediction results from each of the
optimized classifiers and employ a voting scheme to achieve a
system combination 
iii 

experimental setup

a  data preparation
we have a total of      patient data feature vectors  with a
total of    features each  we divide this data into disjoint
datasets by random sampling  train  dev and test sets 
   training set  train   the training set is comprised of
     labeled patient feature vectors  with label  
corresponding to a non diabetic patient and label  
corresponding to a diabetic patient 
   development set  dev   the dev set is comprised of    
patient feature vectors and is used as the test set for parameter
tuning and algorithm development 
   test set  test   the test set is comprised of     patient
feature vectors and is used as the blind set only for final
evaluation of the systems 
b  evaluation metrics
we use three metrics to evaluate each of the classifier and
the overall system  precision      recall     and f measure     
precision represents the accuracy of our prediction for the
samples where we predicted class    patient has diabetes type
ii   recall represents the percent of correctly classified patients
with diabetes type ii out of all the patients with diabetes type
ii  f measure is the harmonic mean between precision and
recall  we aim to maximize the f measure for both
optimization and final result 

c  model optimization
for each of the three models  we optimize the model by
tuning the associated model parameters  this is accomplished
by training the model on the training set with a range of values
 usually      for the parameter of interest while holding the rest
constant  we choose the parameter that gives us the best fmeasure on the     patient data development set as the
optimized parameter  we also measure the performance
multiple times  for gbt and nn  to ensure that the optimal
parameter results are consistent between runs 

fiiv 

results and discussion

a  model optimization results
   svm parameter optimization  for the l  norm soft
margin implementation of svm  we tune the regularization
parameter as all as the degree of the polynomial kernel  we
found that a polynomial of degree   and cost of    produces
the best results without underfitting or orderfitting the data 
the results are shown in the table below 
table i 
cost     
train
dev
cost     
train
dev

svm parameter optimization results
regularization parameter  cost 
precision

recall

f measure

     
     

     
     

     

     
     

     
     

cost     
train
dev

     
     

     
     

     
     

degree    

precision

recall

f measure

train
dev
degree    
train
dev

     
     

     
     

     
     

     
     

     
     

     
     

     
     

     
     

     
      

     
     

     
     

     
     

degree of polynomial

table iii 

table ii 
shrinkage      
train
dev
shrinkage      
train
dev
shrinkage      
train
dev

gbt parameter optimization results
shrinkage parameter
precision

recall

f measure

     
     

     
     

     
     

     
     

     
     

     
      

     
     

     
     

     
     

interaction depth
degree    

precision

recall

f measure

train
dev
degree    

     
     

     
     

     
     

     
     

      

     

     
     

     
     

     
     

nn parameter optimization results
number of hidden layers

n hidden    

precision

recall

f measure

train
dev
n hidden    
train
dev

     
     

     
     

     
     

     
     

     
     

      

     
     

     
     

     
     

n hidden    
train
dev

     

b  results of optimized classifiers on test set
we evaluate each of the three models on our test set with
the optimized parameters  the test set is unseen data to both
the training and parameter tuning 
table iv 
classifier

   gbt parameter optimization  we optimize the
shrinkage parameters  i e  regularization  and interaction depth
of the trees  i e  represents degree of non linearity   we default
the number of classifiers to      we find that at shrinkage of
    and interaction depth of    we achieve the best results for
the development set 

     
     

   nn parameter optimization  we optimize our neural
network by experimenting with both the regularization term 
and the number of hidden layers for model complexity  we
find that at   hidden layers we achieve the best performance
on the development set  the results for  is too inconsistent
between runs  thus by default  we set     

      

     
     

degree    
train
dev
degree    
train
dev

train
dev
degree    
train
dev

svm
gbt
nn

results on test set for optimized classifiers
performance on test set
precision
     
     
     

recall

     
     
     

f measure
     
     
     

one thing to note from this result is that all of the models
have consistently poor recall  this is largely because we have
highly unbalanced class data  that is  the number of patients in
the training set without diabetes  i e  negative class  is roughly
  times the number of patients in the training set with diabetes
 i e  positive class   at a clinical setting in particular  we may
choose to favor a higher recall over a higher precision because
for early diagnosis of critical conditions and diseases  we
would rather have a false alarm than non detection 
we can improve recall and f measure by up weighing the
samples for patients with diabetes  note that in general there is
a trade off between the precision and recall depending on the
weights we choose for the positive and negative class samples 
we plot the f measure performance for the development
set for each classifier at different levels of positive class upweighing   i e  positive vs  negative class weight ratio      
                                   

fi    
    
    

svm
gbt
nn
 

 

 

 

 

amount of upweighing of positive class data

fig     the figure shows the f measure with various upweighing ratio for the
different classifiers 

from figure i  we can see that up weighing the less
representative positive class samples does increase the fmeasure in both gbt and nn classifiers on the development
set  this is because we are gaining more recall in proportion to
losing precision  svm performance remained constant because
we did not gain any support vectors by up weighing the data 
we then retrain the models based on the optimal up weighing
for each model and test on the test set  for nn  the optimal upweighing is at       and for gbt  the optimal up weighing is at
    
table v 

results on test set for after upweighting
performance on test set

classifier
svm
gbt      
nn        

precision

recall

f measure

     
     
     

     
     
     

     
     
     

we were able to improve the f measure and recall for both
gbt and nn  gbt is the best performing classifier out of the

med  diag  med  diag  dbp diag 

relative influence of features in gbm

 

individual classifier  we can visualize the significance of
contribution of each feature as modeled by the gbt 
as expected  diag   hypotension   diag   lipoprotein
deficiencies   age  d s blood pressure and weight are among
the most influential features for predicting diabetes type ii in
patients 

    

f measure

    

    

f measures on dev set with upweighing

 

  

  

  

relative influence

fig     the figure shows the relative influence  in percent  for each of the features 

we also combine the systems by weighing the output of
each classifier with ratio between its f measurement and total
measurement  we use this as a proxy for determining the
goodness of the system  this is not the same as the
conventional majority voting system which needs per sample
confidence scores from each of the classifiers  we do not have
such information available 
table vi 
classifier
combined system

results on test set for combined system
performance on test set
precision
     

recall

     

f measure
     

the combined system performs worse than the best
systems  this means that we do not gain information from this
type of system combination  this means weighing per classifier
is uneffective since the systems do not complement each other 

future work
for future work  we can build classifiers to output
confidence for each of the test samples and weigh the classifier
result per sample  also  we could add more features to try to
improve both precision and recall 

fi