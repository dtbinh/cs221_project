predicting imdb movie ratings using google trends
deniz demir  olga kapralova  hongze lai
december         

movie ratings are influenced by many factors  so accurate prediction of new movie ratings can be challenging 
in recent years  various semantic analysis techniques were successfully applied to analyzing user reviews  which
in turn were applied to predict imdb movie ratings  based on imdb reviews  youtube movie trailer reviews etc  
to the best of our knowledge there has been no research done on predicting imdb movie ratings using google
search frequencies for movie related information  however  several authors have suggested to use search volume
to predict consumer behavior        
our main idea in this project is to characterize each movie by the set of features  and then use google search
frequencies of these features to predict movie popularity  the intuition behind this approach is that for popular
movies one should see the higher search volume of queries associated with the movie 
we view this problem as a supervised learning problem  and we used logistic regression  svm and multi layer
perceptron algorithms for our project  we also used dimensionality reduction techniques to select the optimum set
of features for one of the experiments that we performed 
in what follows we first describe the dataset that we used for our experiments  after that we give details of the
experiments that we performed and discuss their results 

 

dataset

data that we use for our project comes from two sources      imdb dataset and     google search frequencies 
imdb dataset imdb provides rich data about movies  and user ratings for those movies  for our project we
selected     movies      bad with imdb rating     and     good movies with imdb rating      using the
pre processed dataset  as well as lists of american movies released in a particular year posted on wikipedia
 we used lists of movies released in                    such combination was needed since the above referred
preprocessed dataset mostly contains information about the movies released before       and does not cover more
recent movies  for each movie in the combined dataset we used the api http   www omdbapi com to
obtain its imdb data  which allowed us to collect imdb data for     movies released in the interval from     
and       we were not interested in movies released before      as google search statistics is not available for
them  for each movie we recorded the following fields      movie title      movie director      movie actor        
movie actor     in the order in which actors are listed on the imdb website       release date 
google search frequencies we tried two different approaches for movie prediction popularity      combining
google trends and google adwords statistics and     using only google trends statistics  we now describe our
data collection process for both of these experiments 
 

the dataset is released in the framework of the  nd international workshop on information heterogeneity and fusion in recommender
systems  hetrec       http   ir ii uam es hetrec     at the  th acm conference on recommender systems  recsys
      http   recsys acm org     

 

figoogle trends provides a search popularity index  spi  of any particular google query in a specified time period
and geographical region  this index is based on the query share  i e  the total number of searches for a particular
query divided by the total search volume seen in the specified geographical region and within the given time period 
before displaying final trends graph  google performs the second round of normalization  where it divides each
query share value by the highest value of query share within the specified time period  the output is obtained by
multiplying this value by      thus google shows the normalized search statistics  and the normalization constant
varies from query to query  note that this fact does not allow us to compare the popularity of two different queries
using the trends data only  we fix this problem using adwords data as specified below  see section    google
adwords  
usage of trends data in our experiments  in both experiments for each movie we collected the trends data for
the above specified fields  i e  movies title  director  actor   and actor    the trends query interval was set in the
following way  we used the movie release date field recorded  
   from one month before the movie release date to current moment for first experiment 
   from   months before the movie release date to   months after the movie release date for the second experiment 
such query interval choice for the first experiment is motivated in section     and is dictated by the way the google
adwords data is collected  such interval length for the second experiment was chosen because we believe that
data outside of this range is unlikely to contain any meaningful signal 
google adwords is the tool aimed at businesses to deliver ads to potential customers  it has a rich functionality
for this  but we have used only the keyword tool provided by google adwords  the keyword tool returns the search
volume for a particular keyword  or keyphrase  in a specified geographical region in the last    months  thus 
adwords data allows us to recover the normalization constant lost in trends data  and compare query popularity 
in particular  that is why we set the trends interval end moment to be the current moment for the first experiment
 see section   for details of this calculation   note that we are not guaranteed that statistics calculated for trends
and adwords uses the same search database  however  we believe that such approach correctly estimates the order
of magnitude of the trends normalization constant 
let us note that the major problem with using google adwords keyword tool is that we were not granted the
developer key  since our intended usage was not in compliance with adwords apis terms and conditions  thus  we
were not able to automatically collect the adwords data  however  to try this approach we collected the adwords
data for movie title  movie director  actor  and actor  for the set of     movies     good and    bad movies in our
    movies dataset  

 

methodology

first experiment in this section we describe the way of defining features for experiment    first  due to the
manual data collection process  we were able to collect data for     movies  thus  to keep the ratio m    n
 where as usual  m denotes the number of points in the training set  and n is the number of features  we limit the
set of features to be the   dimensional vector that contains the total number of search volume of the movie title 
director  actor  and actor  around the movie release date  we estimate this search volume in the time interval
starting   month before the release date ending   months after the release date  in particular  we calculate the
values of the features in the following way 
 let a be the search volume provided by adwords for a given keyword in the last    months in the us
 

fi let t    one month before the release date
 let t    current moment  note that the length of the interval  t    t    is always more than   year  as we work
with movies released before      
 let xt   where t    t   t    be the trends data for the same keyword in the us
p
 calculate g   t xt   where t ranges over the subintervals in the last    month
p
 set n   a g  calculate f   n t xt   where t ranges over the subintervals around the release date  i e 
in the interval     month     month  
note  that due to the very small dimension of the feature space we did not apply any feature selection or dimensionality reduction techniques in this experiment 
results we approach the problem of predicting movie rating as a two class classification supervised learning
problem  i e  is the problem of determining if movie rating is high or low  in particular  we assign all the movies
with imdb rating less than   to class    and all movies with rating    to class    in this experiment we compared
the performance of the logistic classifier     regularized svm  with gaussian kernel  i e  exp  u  v      and
multilayer perceptron  note that due to the small size of the dataset we used   fold cross validation to estimate the
empirical error  where the dataset was divided randomly into   parts  table   shows the algorithms performance 
correctly classified
logistic
    svm
multilayer perceptron

overall 
      
      
      

high rated movies 
   
      
   

low rated movies 
   
   
   

table    distribution of movie ratings in the first experiment

 a 

 b 

figure     a   distribution of movie ratings in the dataset  experiment     b   distribution for experiment   
fig    a  shows the distribution of movie ratings in the generated dataset  note that in our dataset     of the
movies have high rank  and     have low rank  so the movie database is balanced 
discussion first  as the above table shows all three classifiers perform very badly  in fact logistic regression
classifier performs similarly to a fair coin toss  around     of high and low rated movies are classified correctly 
on the other hand     svm appears to always classify the movies as a low rated  finally  the multi layer perceptron
 

fiperforms to a coin toss with one appearing with probability       thus  surprisingly we essentially obtain no signal
using this setup  we next describe our second experiment which gives nontrivial performance 

 

second experiment

defining features in our second experiment we did not use the google adwords data  and relied only on the
trends data  we briefly described the data collection process in section    see google search frequencies   let us
now describe it in more detail  fig    a  shows an example of time series data returned by google trends 
usually  the data had a sharp peak around the movie release date  and it was decaying around it  we would
also like to note that the fast increase in popularity usually occurred one week before the release date  and that  
months after the release the number of searches was very small  so  we concentrate on the data contained in the
interval starting   month before the release and ending   months after the release  as we assume that this   month
interval contains most information  we then further split these   month interval into the following segments     
one month before the release and     after the release  we first create   intervals   weeks each  see fig    a    and
we define the remaining part to be the  th interval  
we define a feature as the area under the curve in each of these time segments  note that since the search activity
before the release is small  we do not split the the area under the curve before the release into smaller sub segments
and treat it as a single feature  thus  we generate   feature vector from each trends query 
for each movie we request trends data for the following four fields      title of the movie      directory of the
movie      actor         actor     thus  we have           features total 
experiment description the following fig    b  shows the distribution of the movie ratings in     movie
dataset  note  that our dataset is balanced again  since it contains same number of high and low rated movies 

  

  

prediction accuracy  percentage 

  

  

  

  

  

  

  

  

pre

 a 

post 

post 

post 
post 
features  increasing time order 

post 

post 

post 

 b 

figure     a   feature definition for the second experiment  b   marginal prediction value
student version of matlab

results table below shows the classification performance of the same set of algorithms as we used in our first
experiment  in this case  we chose   fold cross validation  
discussion as the above figure shows the same algorithms perform much better in this experiment  in particular 
    svm correctly predicts in     of cases  and is consistent within both classes  however  logistic classifier and
 

ficorrectly classified
logistic
    svm
mlp    hidden layers 

overall 
      
      
      

high rated movies 
      
      
      

low rated movies 
      
      
      

table    distribution of movie ratings in the second experiment
mlp perform a bit worse  we think that such behavior is explained by the presence of outliers in the dataset  in
particular  we saw several movies that have very low rank  but that are very popular  e g  the movie justin bieber 
never say never which imdb rank is       i e  these movies behave in terms of popularity closer to good movies 
and thus trends data decays slowly 

 

feature selection

next  we consider how    svm performance changes when we use different set of features  fig    b  shows the
prediction accuracy if we add features in the increasing time order  using more and more area under the curve in
each run of the experiment  thus  this figure shows the marginal discriminative value of using search activity in
additional time period 
note that adding first two post release features in fact decreases the performance of the classifiers  when we
run the experiment with only pre feature  using only the area before the release   we get better result         
than when we use pre  post   and post   features           note that using pre  post   and post   features
corresponds to analyzing search frequencies from one month before the release to   weeks after the release  when
we use only post   and post   features  only   weeks of search activity after the release   we achieve       
accuracy  therefore  short term post release search activities have less predictive power than those of pre release
and longer term post release 
we also analyzed which movies characteristic  i e  title  director  actor  and actor   has the highest impact on
prediction accuracy  the results show that the search activities for the title  director  and the first actor of the
movies have very close discriminative values  while those of the second actor have significantly less discriminative
value  this is consistent with the results of the feature selection algorithms we have run 
we ran cfs subset evaluation with forward  backward and bi directional search  and all have eliminated the
features related to search activity for the second actor  the selected features give close prediction performance
 svm           compared with the result that we have seen with using full feature set 

references
    h  choi and h  varian  predicting the present with google trends       
    s  goel  j  m  hofman  s  lahaie  d  m  pennock  and d  j  watts  predicting consumer behavior with web
search  pnas       

 

fi