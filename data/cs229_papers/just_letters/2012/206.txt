 

kinect gesture recognition for interactive system
hao zhang  wenxiao du  and haoran li

abstract gaming systems like kinect and xbox always
have to tackle the problem of extracting features from
video data sets and classifying the body movement  in
this study  reasonable features like human joints positions 
joints velocities  joint angles and joint angular velocities are extracted  we used several machine learning
methods including naive bayes  support vector machine
and random forest to learn and classify the human
gestures  simulation results and the final confusion matrix
show that by combining delicately preprocessed data sets
and random forest methods  the f scores of the correct
predictions can be maximized  such methods can also be
applied in real time scenarios 
index terms kinect gesture recognition  svm  random
forest  naive bayes

i  i ntroduction
the last few years witnessed a great increase of the
prevalence of body movement based interface  among
all the modes  touchless body movement interface has
obviously caught more attentions since it can offer
more friendly user experience  in the application area 
traditional video cameras can be used to caption the
body movements to enable interactive system  however 
due to the limitation of the usage on applications 
such technology did not own a large user set  on the
other hand  some gaming systems like microsoft kinect 
nitendo wii and sony playstation  have made such
touchless body movement based interface more popular
and convenient to use by introducing a depth sensor to
capture video data in  d 
in the paper  we focus on gesture recognition of
such interactive system  in this sense  by analyzing
and training the video data from microsoft kinect  we
would design a machine learning method to classify the
actual movement captured from the kinect video with
high accuracy  when a movement is finished  it would
automatically classify the movement into one of the
  gestures asshowninf ig   to further implement the
built in functions in kinect 
the remainder of the paper is organized as follows 
section ii describes the collection of data sets  the
the authors are with the department of electronic engineering at
stanford university  ca         united states  email   hzhang   
wxdu  aimeeli  stanford edu 

fig    

input gestures 

method of extracting features from the data sets is
detailed in section iii  section iv describes the learning
process by svm  and in section v  the learning process
of random forest is explained  section vi provides
simulation performance to compare different learning
methods and analysis the learning results  finally  we
conclude the paper in section vii 

ii  t he k inect  d

data sets

the data sets we are using in this paper are provided by microsoft research cambridge     msrc     microsoft has also provided a programming toolkit
of kinect for windows software development kit beta 
the sdk offers the capability to track the skeleton  d
model and obtain the data of joints positions      the
data sets are collected from    people performing  
different gestures  f ig     with approximately   hour
   minutes  more specifically  with a sample rate of
  hz  it is composed of    sequences         frames 
with a total of      gesture instances  mathematically
speaking  there are   gestures with about    sequences
each  and each sequence is composed of about    
frames constituting approximately    gesture instances 
labeling of the data is automatically done by the related
tagstream files 
there are two kinds of gesture types in the data sets 
iconic gestures   those imbue a correspondence between
the gesture and the reference  and metaphor gestures those represent an abstract concept  a table of the gesture
is given on the top of the next page 

fi 

table i
g esture c lassification

iconic gestures

number of instance

metaphoric gestures

number of instance

crouch or hide
throw an object
kick

   
   
   

start music raise volume
navigate to next menu
take a bow to end music

   
   
   

iii  f eature e xtraction
in the original data set  each frame of gestures is
recorded as the absolute position of    joints of human body in xyz coordinates     data total per frame 
meanwhile  in each sequence  a single gesture has been
repeated for several times  therefore  some preprocess
should be applied to the raw data sets in order to form
the proper training examples and informative feature
vectors  for time t  we derive a feature vector of
t    xt tl  from the last l observations xt to xtl  
indicated by the paper     that when l       the realtime performance can be achieved  therefore we define
every    frames as a training example  even though we
cannot precisely subsume a gesture instance into every
   frames  the relative displacement of adjacent frames
within a training example can also provide enough
information to make the classification  for each pair of
adjacent frames    kinds of factors can be considered as
the possible components of a feature vector  which are 
   xyz  coordinates per joint     total
   xyz  velocities per joint     total
    joint angles
    joint angular velocities
the skeletal structure of human body is shown in fig    

   
   
   
 
   
   
   
   
 

 
   
 

fig    

   

   

   

 

   

skeletal structure of human body 

here are some details about each components  the
xyz  velocities are straightforwardly defined as the difference between xyz coordinates of corresponding joints

between each pair of adjacent frames  the joint angle is
simply the angle between the two segments on either
side of the joint  for the joint like shoulder center 
which has multiple segments around it  we compute the
angles pairwise  besides only extracting angles between
adjacent segments  we put an imaginary joint in          
in world coordinates  which is the location of camera 
this is helpful because all other angles are rotation
invariant  but this one allows you to distinguish changes
with respect to the camera  for example  when we want
to recognize whether a person throws an object to the left
or to the right of the camera  the joint angular velocity
is the rate of change of joint angle  which is computed
by the difference of the corresponding joint angle in each
pair of adjacent frames 
iv  svm c lassification
after preprocessing the feature vectors  we first use
a svm tool     to train our data  the link to the svm
package is from      we randomly divided the given data
into     for training and     for testing  the following
five steps are gone through in the process of training and
testing 
a  define feature vector
in this step  we would determine the composition of
feature vector  as described in the previous section  four
classes of features are considered  we run the forward
search on these feature classes and obtain the following
results  the feature selection is run on the data sets with
   sequences for training and    sequences for test 
the result of feature selection is shown in the table
on the next page 
we choose xyz velocity  joint angle and joint angular
velocity as the feature vector for each frame  and the
dimension is                     as described in the
previous section     frames are included in each training
example  thus the dimension of a feature vector of a
training example is      
b  data scaling
scaling before applying svm is of great significance 
by scaling we can avoid the scenario that attributes in

fi 

table ii
f eature c lass s election

feature in use

feature fixed

accuracy

 
 
 
 
   
   
   
     
     
       





 
 
 
   
   
     

        
        
        
        
        
        
        
        
        
        

dimensional space and it has fewer hyperparameters
than polynomial kernel which influences the complexity
of model selection  from the result  we can see that
real proportion
the polynomial kernel is overfitting  linear kernel also
       
provides us with a comparable accuracy due to the large
      
number of features  but since rbf kernel gives us a
       
higher accuracy  we determined to use rbf kernel 
      
       
       
       
       
       
       

    is xyz position    is xyz velocity    is joint angle   is joint anglular
velocity

larger numeric range dominate the ones in small numeric
range  and it can alleviate the mathematical calculation
workload 
in this paper  the features are linearly scaled into a
range of          by libsvm  the improvement on the
accuracy can be seen 
table iii
data s caling

mode

accuracy

real proportion

before scaling
after scaling

       
        

         
         

from the table  it can be observed that by preprocessing
of scaling on the data  the accuracy can improved by
about     therefore  in the afterwards experiment  we
will use the scaled data in order to achieve a better
prediction 
c  kernel selection
we tried three kernels in our process of kernel
selection  linear kernel  polynomial kernel and radial
basis function  rbf  kernel  the accuracy of prediction
using the three kernels after scaling is in the table below 
table iv
k ernel s election

kernel

accuracy

real proportion

linear
polynomial
rbf

        
        
        

         
         
         

note that rbf kernel achieves the highest accuracy 
this kernel nonlinearly maps samples into a higher

d  parameter selection
there are two parameters for rbf kernel  c and   
which is not known beforehand  thus some kinds of
parameter search must be done  the goal is to identify
good  c     so that the classifier can accurately classify
unknown data  a common strategy is to use n fold crossvalidation  which divides the training set into n subsets of
equal size and sequentially one subset is tested using the
classifier trained on the remaining n   subsets  we use
a grid search on c and  by cross validation  various
pairs of  c    values are tried and the one with best
cross validation accuracy is picked  after running the
parameter selection script  we got the parameter c     
and              with an accuracy of           we
used this parameter in later training 
e  final result
after defining the feature vectors  scaling the data 
choosing the most accurate kernel and got the parameters  we used svm train and svm predict again with
the chosen kernel and parameters  we finally got an
accuracy of prediction of                       which
is acceptable 
v  r andom f orest l earning m ethod
as in      random forest works as described below 
after given a set of training examples  a random forest
is created with h random decision trees  and for the
k  th tree in the random forest  a random vector k
is generated independently of the past random vectors
         k    this vector k is then used to grow the
trees resulting in a classifier hk  x  k   where x is the
feature vector  for each tree  a decision function splits
the training data that reach a node at a given level in
the tree     then each tree gives a classification  and we
say the tree votes for that class  the forest chooses the
classification having the most votes  over all the trees in
the forest  
the resulting forest classifier h is used to classify
a given feature vector by taking the mode of all the
classifications made by the tree classification h  h
for all the forest 

fi 

fscores of three method

a  growing trees
the following approach is similar to that of      at
test time t  we derive a vector t    xt  tl       rd
from the last l observations xt to xtl     according to
what we have described in the svm method  the training
examples are set to l      frames  which obtains d  
     features  the feature vector t is evaluated by a set
of m decision trees in the random forest  where simple
test
f   rd   left right 
   
are performed recursively at each node until a leaf node
is reached  in our experiment  the number of random
decision trees is set to be m        the parameters
   of each tests are determined separately during
the training phase  and the determination process is
described below 
for each tree m           m   it produces one class
decision ytm and the posterior class distribution
p yt   a xtl   t     

m
  x
i ytm   a 
m

   

m  

over gesture class a  at the same time  we have to add
an extra class none to indicates whether a gesture has
been recognized  if for a gesture class a  a we have
p yt   a xtl   t       we can then determined the
gesture being detected at current time t  we used a fixed
value             for all the random forest experiments 

naive bayesian
svm
random forest

 

   

   

   

   

 

fig    

hide

throw

kick

startmusic nextmenu

endmusic

fscore of three method 

vi  s imulation r esults and p erformance
a ssessment
the accuracy of the three algorithms are summarized
in table below 
table v
accuracy c omparison

algorithm

accuracy

naive bayes
svm
random forest

      
      
      

b  random forest training and predicting
for the training  we use approximately     of all the
observations together with the action point annotations
for a set of n sequences  where the n  th sequence is
an ordered list  xnt   ytn  t      tn   our goas is to learn a
set of m decision trees that classify the action points in
these sequences correctly by means of      then for the
decision parts  we use simple decision stump tests    
with     i  h      i  d  h  r 
 
left
if t  i  h
f i h   t    
   
right otherwise
standard information gain criterion and training procedure are used in the method  we greedily select a split
function f i j  for each node in the decision tree from a
set of randomly generated proposal split functions  the
tree is then grown until the node is pure  in a sense  all
training examples assigned to that node have the same
label 
after all the decision trees are finally formed  the
random forest is well set  and we can use the random
forest model to make classifications by simply putting
the test examples into the random forest 

in the final performance assessment  the whole data
set is randomly split into two parts      sequences for
training and    sequences for testing  we use f score
and confusion matrix to evaluate the performance of each
algorithm  the f score of the three methods is fig    and
the confusion matrix of the three methods is fig    
the accuracy of the prediction by svm is        
from the confusion matrix  we can see that the performance on recognizing gesture         is relatively better
than on other gestures  however  since other gestures can
also easily be misclassified into gesture    the recall of
gesture   is low  which makes its fscore great lower than
its accuracy 
we can see that svm preforms worse than random
forest algorithm  probably because there are too many
features in each training example  although the feature
class selection has been conducted on the data set  the
over fitting still slightly exists  such guess can also be
confirmed by the fact that the final accuracy on the whole
data set is poorer than the accuracy when the algorithm
is conducted on the small data set in the feature selection
step 

fi 

fig    

confusion matrix 

we also implemented naive bayes as a benchmark
to compare with the results got by svm and random
forest  at first we used normal distribution to model
the data and created class variable for training taking
     distinct levels  then we have a train category
vector that defines which class the corresponding row
of training belongs to  we used naive bayes classifier
with the multinomial event model and laplace transform
to classify each gesture  then we compared with the
actual category and got the confusion matrix and fscore  the accuracy of the prediction by naive bayes
is         from the confusion matrix  we can see
that the performance of predicting gesture         is
better compared to the other gestures  but overall  the
performance is worse than that of svm and random
forest  since naive bayes discretizes the feature values
and instead uses a class variable  it loses some accuracy
in the process of discretization  which is reasonable 
the performance of the random forest is the best
among three algorithms  the accuracy by random forest
can reaches as high as         meanwhile the f scores
of all six gestures are higher than other methods 
vii  c onclusion
in this report  we have studied the methods to preprocessing the given data sets to find the best features 
and then  in svm process  after feature class is selected 
scaling  kernel selection  rbf kernel parameter selection  we have decided the final svm model  and the
f scores of every classs in the svm model can be seen
on fig     then  we have tried random forest method 
after growing a forest with     decision trees  the fscore of every class in the model has increased a lot  as
a benchmark  a naive bayesian model was also simulated 
by comparing all three models  it can be found that by
combining delicately preprocessed data sets and random
forest methods  the f scores of the correct predictions
can be maximized  in a sense  the kinect system can thus

differentiate one human gesture from the other trained
gestures with high accuracy 
in the future work  a more accurate feature selection
on the data sets can be conducted  if we are given
more powerful computation resources  we would like
to experiment with a larger data sets  and are capable
of conducting the large computation required delicate
feature selection  meanwhile  another improvement in
the future can be focused on the vision part  which is
the method to extract joints data sets from the kinect
video  it is indeed a challenging task 
r eferences
    gabriele fanelli angela yao  juergen gall and luc van gool 
does human action recognition benefit from pose estimation  
      http   dx doi org         c       
    simon fothergill  helena mentis  pushmeet kohli  and sebastian
nowozin  instructing people for training gestural interactive
systems  in proceedings of the sigchi conference on human
factors in computing systems  chi     pages           new
york  ny  usa        acm 
    simon fothergill  helena m  mentis  pushmeet kohli  and sebastian nowozin  instructing people for training gestural interactive
systems  in joseph a  konstan  ed h  chi  and kristina hook 
editors  chi  pages           acm       
    g  rogez  j  rihan  s  ramalingam  c  orrite  and p h s  torr 
randomized trees for human pose detection  in computer vision
and pattern recognition        cvpr       ieee conference
on  pages      june      
    jamie shotton  andrew fitzgibbon  mat cook  toby sharp  mark
finocchio  richard moore  alex kipman  and andrew blake 
real time human pose recognition in parts from single depth
images  in in in cvpr          
    leo breiman statistics and leo breiman  random forests  in
machine learning  pages           
    www csie ntu edu tw cjlin libsvm  

fi