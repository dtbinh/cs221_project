sentimentanalysisofusersreviewsandcomments
abhijitchakankarsanjuktapalmathurkrishnavenuturimilli

 overview
the goalofourprojectis toapply machinelearningforsentimentanalysis oropinionmining onusergenerated
text on the web  such as  movie or product reviews  or comments  on social networks  and forums  given the
content of this  usergenerated text  we are looking to classify  the reviews comments  as  being positive or
negative  an opinion is  defined as  a positive or negative sentiment  view  attitude  emotion  or appraisal about
an entity  or an aspect of the entity  from an opinion holder  this  is  a relevant problem in todays  world as  the
amount of usergenerated textonthewebis increasingandsentimentanalysis canbeusedtodetectthemood
ofusers onaforumortodetectspamifthetextis toonegative by buildingfeatures tocategorizethecontentof
agiventext weusesupervisedlearningtechniquestodetectpositivevsnegativesentimentinthetext 
 datasets
we analyzed three separate datasets  two of which comprised of movie reviews  and the third involved
detectinginsultsinuserscomments 
    large movie review dataset  this  dataset contains  movie reviews  from imdb  consisting of   k  highly
polar movie reviews  for training  and   k  set for testing  in each set  there is  a      breakdown between
positive and negative reviews  no more than    reviews  areallowedforany givenmoviesincereviews forthe
same movie could have correlated ratings  the train and test sets  contain a disjoint set of movies  so no
significant performance is  obtained by  memorizing movieunique terms  the learning word vectors  for
sentimentanalysispaperbymaasetal thatalsousesthisdatasetachievesahighestaccuracyof       
    polarity movie review dataset  this  dataset consists  of      processed movie reviews  drawn from
imdb archive  classified into positive and negative sets  each set comprising      movie reviews  weran  
foldcrossvalidationtomeasureaccuracyofclassifiers 
    detecting insults in social commentary  this  competition was  to build the best model to detectwhena
commentfromaconversationwouldbeconsideredinsultingtoanotherparticipantintheconversation samples
could be drawn from conversation streams  like news  commenting sites  magazine comments  message
boards  blogs  text messages  etc  the training data set has       examples  out of which              are
insults  the test data set has       examples  out of which             areinsults sincethis was arelatively
skeweddataset wealsomadeuseofprecisionandrecalltoevaluateourmodels 
 features
for each of the datasets  some preprocessing had to be done before applying the belowmentioned features 
examples  include parsing relevant text body  from the original data set  removing html tags  from the text 
handling quotes  and other punctuation appropriately  and removing redundant repetition of letters   e g 
stuuuuupidtostuupid soastodeferfromtheoriginalstupid  
    ngrams  using the bag of words  approach  we tried uni  bi and trigrams  forthekaggledataset wealso
tried using up to  grams  upon observation of common phrases  we also tried stemming to only usestems of
the words  in the ngrams  in particular  we made use of the porter stemmer from the nltk libraries  we
experimented with using a variety  ofvalues as thefeaturevalues suchas thetermfrequency count just     
forwhetherthetermwasabsentorpresent andthetfidfweight 
    partofspeech  pos  tagging  we fed each piece of text from the dataset to nltk pos tagger  we
appended the pos tag to the end of the ngram stems  to distinguish betweendifferentuses withinasentence
ofeachword sincesentiments areoftenexpressedwiththeuseofadjectives andadverbs wealsotriedusing
justtheadjectivesandadverbsasfeatures 

fi   customfeatures
      large movie review dataset  with movie reviews  often comprising of a paragraph of text  users
typically  make their main expression of sentiment at the very  start or end of the review  the middlehalfofthe
paragraph typically  contains  other details  about the movie  which the user may  end up summarizing as  a
positive or negative sentiment at the end  thus  we tried incorporating the position of where the ngram
appeared with respect totheparticularexampletext weaddedasuffix tothewordforwhichquarterofthetext
the word appeared in  like the pang and lee paper describes  another option could have been to specifically
targetwordsthatappearedinthefirstorlastsentenceasfeatures 
      polarity movie review dataset  with pos tagging  wetriedvariants ofbigrams andtrigrams wherethe
adjective adverb includingsuperlatives is
a thesecondwordofbigrams notfunny nothinggreat doeslittle nothingnewetc 
b thefirstwordofbigrams extremelywell reallygood compellingstoryetc 
c themiddlewordoftrigrams
      kaggle detecting insults  competition dataset  we downloaded a subjectivity  clues  file and a
badwords  file containing     badwords thatwas usedtoidentify really bad oftencurse words wetriedusing
words  that express  strong positive or negative subjectivity  this  file contains       entries  one per line  as
follows type strongsubjlen  word  abhorspos  adjstemmed  npriorpolarity negative 
otherfeaturesusedinclude 
   you acommentisusuallyaninsultonlyiftheinsultisdirectedtothesecondperson 
a  usingthegooglebadwordsfilefromtheweb asdescribedabove 
b  usingthesubjectivitycluesfilefromtheweb asdescribedabove 
c  detectingbadwordwithinafewwordsaroundvariationsof you  suchasu youre your 
d  generate contextwords  i e thewordsbetween you andbadword 
e  detectingastrongnegativesubjectivitywordwithinafewwordsaround you  
   badwords  we tried raw counts  as  well as  fraction of badwords  this  feature did not work  as  the
noninsultshadahigherproportionofbadwordsthaninsultsintrainingset 
   badword pairs    we used ordered pairs  of badwords   not necessarily  bigrams  in the same sentence
that had a high chisquared score as  features  e g  it found that dumb   ass  is  not nearly  as  bad as
dumb f    
   exclamations uppercasewords weusefractionoftheseinthecommenttogetasmallimprovement 
   partofspeechtagging usingnltkspartofspeechtaggingwetriedfollowingfeatures 
a  fractionofeachtagtype nouns verbs adjectivesetc 
b  fractionofonlyadjectives adverbsorboth
    feature selection  one mode of feature selection that was  attempted across  all the datasets  was  to use
the top nmost frequentlyoccurring ngrams  as  the only  features  additionally  when using the nltk naive
bayes  classifier  we picked out the n most informative features  used for training the data to rebuild themodel
for application against the test set  for the kaggle dataset  we also tried chisquared based feature selection 
we sortedthefeatures  e g badword pairs ontheirchisquaredscores andusedonly theones thatexceeded
athreshold typically      thishelpedreduceoverfittingandmadesomeofthefeaturesuseful 
 models
naive bayes  and support vector machines   svm  were mainly  used to classify thedualclassedsentimentof
thedata 
    naive bayes classifier  we used the naive bayes  classifier model from the python nltk libraries  we
used the absence or presence of a term as  the feature values  after experimenting with the other measures
discussed in      we also ran kfold cross  validation across  the various  data sets toassess whetherthedata
wasbeingoverfittedtothetrainingdataset typicallyusingk    
    svm  we ran the svm model from the python libsvm libraries  we experimented withthetypes ofkernels

fiand penalty  values  and ended up mostly  usingthedefaultparameters e g forthelargemoviereviewdataset 
theonlydifferencewasthatweusedahigherpenaltyc  whentrainingthesvmmodel 
    logistic regression  we used a custom implementation of logistic  regression inpythonusinggradient
descent  the optimization steptypically ranforabout  to   iterations andusedthesamefeaturesetas for
nb and svm  we also used k  fold cv withvarious values ofk            andtheresults arebeingreported
fork  
 results
listedbelowaretheaccuracyresultswegotwitheachoftheconstructedmodelsagainsteachdataset 
   largemoviereviewdataset allthemodelsmadeuseoftheporterstemmeronthetokens 
model 
 
 
 
 
 
 
 

feature
unigram
unigramwithadjectivesonly
unigram quartile position
unigram pos
model  bigram
model  bigram quartile position
model  bigram pos

naivebayes
       
       
       
       
       
      
       

svm
       
       

       
       

       

   polaritymoviereviewdataset partofspeechtagswereusedtoselecttheparticularngrams 
model 
 
 
 
 
 
 
 
 

feature
unigrams absence presence 
unigramswithfrequencycount
unigrams onlyadj adv 
bigrams absence presence 
bigrams firstwordadj adv 
bigrams secondwordadj adv 
trigrams absence presence 
trigrams middlewordadj adv 

naivebayes
    
   
    
   
    
    
    
    

svm
    

    
    
    
    
    
    

   kaggledetectinginsultscompetitiondataset usedthebad subjectivewordfileswithngrams 
model 
 
 
 
 
 
 
 
 
 

feature
unigramsonly
you  bad word only
model  model 
model  bigrams
model  upto grams
model  badwordpairs
model  exclamations
model  nostemming
model  negsubjectivewords

naivebayes
     
     
     
     
     
     
     
     
     

logisticregression
     
     
     
     
     
     
     
     
     

svm


     





      

fifurthermore wedidananalysisofprecisionandrecallaswellforthisdatasetsinceitwasknowntobe
skewedwithrespecttohavingmorenoninsultsthaninsultsinbothtrainingandtestsets 

 analysis
    large movie review dataset  the combination of unigrams  and bigrams  with the partofspeech tag
appended as  a suffix  to each word performed best on naive bayes whileusingtheadjectives by themselves
did not perform well  appending the partofspeech tag to each token helped distinguish between the different
uses  of words  especially  in the construction of bigrams  to express  sentiment  examples  of the most
informativefeaturesusedwiththissetupincluded 
 negative worst jjs film nn thi dt crap nn worst jjs movi nn wast vb your prp just rb aw jj 
 positive highli rb recommend vbd wonder jj movi nn perfectli rb cast vbn well rb worth in
on the other hand  the standard unigrams  and bigrams  worked best on svm  without any  use of the
partofspeech tags  the quartile position of each ngram within the text did not provide any  further
improvements 
    polarity movie review dataset  unigrams  absence presenceofadj adv performedbestonnaivebayes
and bigrams   absence presence  performed best on svm  in unigrams   using the top n most frequently used
words  among all documents   adjectives  such as  outstanding     astounding     atrocious    ludicrous   
thematic     insulting   etc   came up as  the most informative features  trigrams  degraded the performance
and using frequency  counts  did not show any  improvement  to push the accuracy  further experimentingwith
the feature selection techniques  here is  not enough  advanced nlp techniques  are necessary  to extract the
subject of the sentences  in the reviews  and their meanings  for instance  the authormightdescribewhatwas
expected out of the movie in positive terms  but in the last sentence indicate thathewas disappointed orvice
versa 
    kaggle detecting insults competitiondataset many features werededicatedtodetectingthesecond
person subject you  since a comment was  usually  labeled as  an insult only  if it can be established that the
insult is  directed to the second person  trying to learn the contexts  in which  you   bad word   is  not an
insult did not work  out well due to the sparsity  of the kaggle data set  with a bigger corpus  that strategy  may
succeed 
the use of the bad words  and subjective words  files  proved useful to seek  out the bad words  in detecting an

fiinsult  detecting a bad word within some words  around variations  of you  suchas  youareanidiot beingan
insult  worked more often than not  but fell short on several occasions  such as   you are not an idiot  or you
thinkheisidiot notbeinglabeledasinsults 
using the additional features  such as  partofspeech tags  did not provide any  gains  and some combinations
actually  saw a minor loss  in performance  additionally  we think  there are several mislabeled examples  that
end up confusing the training model  here are a few of examples  we think  that are incorrectly  labeled as   not
insults   f    all u p     asz  crackers is  an obvious  insult  while you are as  naive as ateenagegirlis more
subtle 
 conclusion
we were able to achieve comparable results  as  the corresponding papers  for both the movie reviewdatasets
using our described feature sets  for the kaggle dataset  while we didnt have a baseline performance to
compare to  in comparing against the     skewed data set itself  we wereabletobuildamodelthatimproved
upon that  the bag of words  approach using the ngrams  worked well for sentiment analysis  where the
inclusion of both unigrams  and bigrams  made the most improvements  incorporating the partofspeech tag of
the ngrams  also boosted our models  all the algorithms  we tried  nb  lr and svm  worked reasonably  well 
withsvmperformingbestonthemoviereviewdatasets 
overall  gaining further improvements  through these models  for the purposes  of sentiment analysis  falls  more
into the domain of natural language processing  we should do some sentence structure analysis  and
associate positivity negativity  to the subject ofthesentimente g thesecondpersonyouinthekaggledata
set  or the actual movie in the case of the movie review data sets  if we build features  using moreinformation
about the semantic  structureofthesentence thesesupervisedmodels willprobably performbetter itis alsoto
benotedthatsentences involvingsarcasm negations andothers suchas this movieis worthwatchingseveral
timescannotbeclassifiedbyourabovedescribedfeatureset 
lastly  we dabbled a little into trying to detect a specific  type of sentiment  namely  insults  via thekaggledata
set  going beyond the more general positive vs  negative sentimentanalysis ofthemoviereviewdatasets we
applied more custom features  specific  to detecting bad words  and detecting the second person you  this
work  can be extended to further detect specific  types  of sentiment  as  well as  experiment with different
domains   e g  politics  sports  otherthanmoviereviews todeterminewhethertherearesomecommontypes of
features  that can beusedforsentimentanalysis oriftherearesentimentspecific  e g badwords forinsults or
domainspecificfeatures e g politicalpartyjargon thatultimatelyprovidefurtherimprovements 
 references
bopang lillianlee andshivakumarvaithyanathan      thumbsup sentimentclassificationusing
machinelearningtechniques proceedingsofemnlp pp      
andrewl maas raymonde daly petert pham danhuang andrewy ng andchristopherpotts      
learningwordvectorsforsentimentanalysis the  thannualmeetingoftheassociationforcomputational
linguistics acl      
bopangandlillianlee      asentimentaleducation sentimentanalysisusingsubjectivitysummarization
basedonminimumcuts proceedingsoftheacl pages       
   datasources
 largemoviereviewdataset http   ai stanford edu  amaas data sentiment 
 polaritymoviereviewdataset http   www cs cornell edu people pabo moviereviewdata 
 kaggledetectinginsultscompetitiondataset 
http   www kaggle com c detectinginsultsinsocialcommentary

fi