stay alert  the ford challenge
tayyab bin tariq  allen chen
cs     fall     
problem description
driving while drowsy  intoxicated  or otherwise distracted can have life changing consequences 
activities that divert the driver s attention from the road ahead  such as engaging in a conversation with
other passengers in the car  making or receiving phone calls  sending or receiving text messages  eating
while driving or events outside the car may cause driver distraction  fatigue and drowsiness can result
from driving long hours or from lack of sleep  given a set of physiological  environmental and vehicular
features taken from real world testing  the goal of our project was to predict whether or not the driver of a
car is alert  the units and source of these features have been removed  therefore preventing us from
using any domain and or feature specific methods to the problem  and presenting a binary classification
problem  setting the top leaderboard scores on kaggle as our benchmark  we sought to create a
competitive classifier using the techniques we have learned in cs     
for this competition  kaggle scored test results based on receiver operating characteristic area
 

under curve  roc auc    this rewards a high

ratio  which is important for driving

situations  since a system that triggers many false positives will likely be very intrusive to the driver  or
simply turned off altogether  for classifier development  we used f  score and assumed that it was a
 
good proxy of the auc score on the training set  
data description
 
we obtained the data for this problem from the kaggle challenge website   the website provides
two data files   one for training and one for testing  the training data file  hereafter called s train  consists of
        data points  each data point belongs to a one of     separate trials  the test file  hereafter
called stest  contains         data points belonging to     trials  while each data point in strain comes with
a labels in        stest has no labels  the intention is that we test our classifier on the test data and submit
our predictions via kaggles online submission process  each sample contains   physiological    
environmental and    vehicular features  as previously mentioned  the actual identity and units of the
features has been stripped away from the data  making it more difficult to intuit which features might be
most relevant to classification 
for classifier development  we held back     of strain  hereby referred to as sdev  in order to
evaluate our models before submission to kaggle for scoring on stest  however  we soon found that when
we tried to train neural networks  svms and random forests on this data  the turnaround time required to
perform substantial testing  i e  for parameter search  was too long given the project timeline  or we just
ran out of available memory  as a workaround  we selected the first         measurements from s train
and divided them into strain and sdev  again using an       split  once we had tuned our final model  we
trained it stest  in the following sections all the results are from training on s train and testing on sdev unless
otherwise stated 

baseline methods
for the milestone  we explored three methods to establish baseline performance upon which to
build during the rest of the project 
note that the kaggle score is calculated based on the area under the receiver operating curve  roc  
referred to from here on as auc 

fimethod

description

f  on
strain

kaggle score  auc 

linear decision
boundary on single
feature

see plotting data section below

     

      

logistic regression

used glm in matlab to run logistic regression
on strain

     

     

svm

liblinear package  linear kernel

     

      

naive bayes

discretized each feature across all training
samples  using     bins

     

     

plotting data
we plotted the data to look for interesting patterns  we plotted each of the    variables as a
scatter plot against the labels and also plotted combinations of variables  we noted a couple of interesting
patterns  we noted that whenever the e   environmental feature    was greater than     the labels were
mostly negative  we used this intuition to come with the simplest possible classifier and that was just
  e          this extremely simple classifier gave us an f  p r of                   on the s and auc
of       on the test set  as evaluated by kaggles online evaluation system   this is a very reasonable
result for a classifier as simple as a comparison operator  we also noted interesting shapes behavior in
other variables  for instance p  was strongly correlated with an alert label whenever it was an even
multiple of      the same behavior was noted by other kaggle participants  nt    we also noted that p 
looked largely bimodal  later on we use these intuitions to transform the data to get better results 

feature    vs feature   

feature    vs feature  

naive bayes
for naive bayes  we discretized each column into a number of bins  defined globally  we then
carried out a multinomial model for binary classification similar to the one used on problem set   for spam
email classification  with laplace smoothing applied  we saw optimal performance around     bins 
logistic regression

fiwe then moved on to use a logistic regression as a means of predicting the drivers alertness 
we trained the model on strain and used sdev as the validation set  this gave us an f  p r of
               on the validation set and an auc of        on stest 
svms
we also tried using svms to build a classifier for driver alertness  as a first attempt  we used the
raw data and trained a simple svm using a linear kernel with l  regularization to make predictions  we
trained it on strain and tested it on sdev to get a f  p r of                   and an auc of       on stest
as evaluated by the kaggle online evaluation system 
neural networks
the first more advanced method we applied was neural networks  using a feedforward neural
network with two hidden layers of size    and     nodes  we obtained an f  score of       and a kaggle
auc of        while training on stest  these results caused us to focus our efforts on trying to improve
neural network performance through tweaking parameters and various other methods 
we made several observations regarding the data that led us to apply various transforms on the
training set  first  we noted that the individual observations were on widely varying scales  which led us to
believe that scaling the data to a standard range       would both improve performance and reduce
possibilities of computational error  i e  failure of iterative methods to converge consistently   while this
was not the case  when we attempted to scale data on a trial by trial basis  we saw improved results
compared to scaling based on all trials combined  this suggests that the trials are not drawn from the
same distribution  we address this fact later in the paper 
we also tried running neural network on a binned version of strain  using        and     bins  a
larger number of bins decreased performance  with    bins seeing performance slightly below our initial
runs  however  discretization caused our training error to fall dramatically  producing f  scores of over   
percent  indicating overfitting to the training set  we also attempted less complicated neural networks 
using a single hidden layer with    to    nodes  again  we witnessed that training error decreased  while
test error increased compared to the initial settings 
due to the dynamic nature of the problem  one approach that we tried while working with neural
networks was using a measure of change in the features as a feature  for example  we created a feature
that represented the difference between the current value of each feature and the mean of the previous
    values  however  this did not seem to increase performance above the baseline 
random forests
another type of classifier we attempted to use was random forest  we used the randomforest
package in r to see if it would offer improved auc performance on the test data  similar to neural
networks  random forests are quite computationally intensive to train  so we used strain and sdev  again 
we saw scores on sdev of above    percent  but the kaggle auc results were around    to      percent 
very similar to the neural network  experimenting with both the node size and number of trees in the forest
did not yield significant improvements  and attempting to train on a larger subset of the training data
required too much memory 
further data analysis
as we proceeded with more advanced techniques beyond our baseline analyses  we saw a
pattern of our algorithms returning a much higher auc when run on the held back subset of the training
data compared with the auc we were receiving on stest  this implies that stest and sdev are drawn from
different distributions  and therefore we should extrapolate using a simpler model  we decided to step

fiback from the more advanced black box techniques and try a simpler approach  using logistic
regression and selecting a smaller subset of features to avoid overfitting 
an analysis of the mean isalert value across trials reveals that there is a bimodal distribution  i e 
in each trial  the driver is mostly alert or mostly not alert  
histogram of mean driver alertness per trial

this observation suggests that we should use aggregate data from each trial as an additional
feature  we chose to add the mean and standard deviation across all observations of a trial as additional
features  expanding our feature space from    dimensions to     furthermore  we tossed out correlated
variables  such as p   correlated with p   and p   correlated with p    transformed p  into a     indicator
variable  and discretized e  and e  into   bins  following suggestions from competitors on the kaggle
 
forums    note  p   physiological feature  e   environmental  v   vehicular 
we then carried out both forward and backward search  using logistic regression f  score and
kaggle score to optimize the number of features 

firesults and discussion
method

sdev f  score

stest auc  via kaggle 

logistic regression

     

     

svm

     

      

nave bayes

     

      

neural network    layers

     

      

neural network     bins 

     

      

random forest      trees

     

      

logistic regression with feature
selection

      

      

over the course of the project  we found that black box methods came with several
disadvantages   parameter tuning took a long time  especially since training on large data sets with neural
networks and random forests is computationally intensive  random forest also has the disadvantage of
not converging to a certain result with each run  which means we saw variation in auc results of around
  percent between runs on the same training and test sets  furthermore  increasing the complexity of
neural networks and random forest consistently overfit the test set 
feature selection showed that maximum auc on stest appeared to occur at just   or   features
using logistic regression  which provided the best results   this is likely due to the fact that s train and stest
differ in some way  as seemed to be the consensus among other kaggle competitors  also note that
logistic regression with feature selection results in f  and auc scores that are very close  suggesting that
we are not overfitting the data 
in the end  our simple logistic regression using   or   features selected via forward search
presented the best results  with auc around    percent and putting us in the top    on the kaggle
leaderboard 
one issue that we did not address was that our mean and standard deviation features were taken
from all data across a trial  meaning it could not run in real time as a true driver alertness application
would  however  implementation of an online learning version would be simple  and results from other
 
kaggle competitors suggest a very small difference in resulting auc  
furthermore  because of the way auc is calculated  we found that the kaggle scoring system
consistently gave higher scores when we submitted a continuous range of values from classifiers that
supported it  e g  logistic regression 

    http   en wikipedia org wiki receiver operating characteristic
    http   en wikipedia org wiki f  score
    http   www kaggle com c stayalert data
    http   www kaggle com c stayalert forums t     methods tips from non top  participants      post    
    http   blog kaggle com wp content uploads         ford pdf

fi