forecasting trade direction and size of future contracts using deep
belief network
anthony lai  aslai   mk li  lilemon   foon wang pong  ppong 

abstract
algorithmic trading  high frequency trading  hft  in particular  has drawn a lot of interests within the computer
science community  market making is one of the most common type of high frequency trading strategies 
market making strategies provide liquidity to financial markets  and in return  profit by capturing the bid ask
spread  the profitability of a market making strategy is dependent on its ability to adapt to demand fluctuations
of the underlying asset  in this paper  we attempt to use deep belief network to forecast trade direction and size
of future contracts  the ability to predict trade direction and size enables automated market maker to manage
inventories more intelligently 

introduction
market making in a nutshell
according to garman         buyers and sellers arrive randomly according to a poisson process      assume that
alice wants to buy     shares of google  there might not be someone who wants to sell     shares of google
right now  market maker plays the role of an intermediary  quoting at the bid and ask price simultaneously 
when a buyer or seller wants to make a trade  the market maker act as a counterparty  taking the other side of
the trade  in return  the market maker profit from the bid ask spread for providing liquidity to the market 

figure    illustration of center limit order book

figure    bid ask price and arrival rates of buyers
and sellers 

automated market making strategy
an automated market maker is connected to an exchange  usually via the fix protocol  the algorithm
strategically places limit orders in the order book and constantly readjust the open orders based on market
conditions and its inventory  as we have mentioned earlier  the market maker profits from the bid ask spread 
let us formalize the average profit of a market maker over time  let buy ask  and sell bid  be the arrival rate of
the buyer and seller at the ask and bid price respectively  in the ideal world  buy ask  is equal to sell bid  and the
average profit is given as 

however  in practice  this is rarely the case  buyers and sellers arrive randomly  figure   illustrates how buy ask 
and sell bid  is related to the bid and ask prices  in theory  assuming that there is only one market maker  he could
control buy ask  and sell bid  by adjusting the bid and ask prices  in practice  market maker could also adapt by
strategically adjust their open orders in the order book  the ability to accurately predict the future directions and

fiquantities of trades allow market maker to properly gauge the supply and demand in the marketplace and
thereby to modify their open orders 
deep belief network  dbn 

figure    structure of our deep belief network 
consists of an input layer    hidden layers of rbm and
an output layer of rbm 

figure    diagram of a restricted boltzmann machine 

deep belief network is a probabilistic generative model proposed by hinton      it consists of an input layer  an
output layer  and is composed of multiple layers of hidden variables stacked on top of each other  using
multiple hidden layers allows the network to learn higher order features  hinton has developed an efficient 
greedy layer by layer approach for learning the network weights  each layer consists of a restricted boltzmann
machine  rbm   the deep belief network is trained in two steps  namely  the unsupervised pre training and the
supervised fine tuning 
unsupervised pre training
traditionally  deep architectures is difficult to train because of their non convex objective function  as a result 
the parameters tend to converge at local optima  performing unsupervised pre training helps initialize the
weights to better values and helps us find better local optima      unsupervised pre training is performed by
having each hidden layer greedily learns the identity function one at a time  using the output of the previous layer
as the input 
supervised fine tuning
supervised fine tuning is performed after the unsupervised pre training  the network is initialized using the
weights from the pre training  by performing unsupervised pre training  we are able to find better local optima
in the fine tuning phase than using randomly initialized weights 
restricted boltzmann machine
restricted boltzmann machines  rbms  consist of visible and hidden units that form a bipartite graph  figure    
the visible and hidden units are conditionally independent given the other layer  the rbms are then trained by
maximizing the likelihood given by the following equation  figure     rbm is trained using a method called
contrastive divergence that is developed by hinton  further information can be found in hintons paper     

figure    log likelihood of the restricted boltzmann machine  in this case  x i  refers to the visible units 

dataset
to ensure the relevancy of our results  we acquired tick by tick data of s p equity index futures  es  from the

fichicago mercantile exchange  cme   tick by tick data includes all trade and order book events occurred at the
exchange  it contains significantly more information than the typical information obtained from google or
yahoo finance   which are summary of the tick by tick data  the data we obtained from cme is encoded in fix
format  figure     we implemented a parser to reconstruct trade messages and order book data 
                x    cme                                                                                      es
z                                                                                                  esz            
                                                                                    esz                           
                                         

figure    a single fix message encoding an incremental market data update message 
normalization and data embedding
our input vector is detailed in figure    prices and time values are first converted to relative values by
subtracting the values of the trade price and trade time at t   respectively  for instance  if the trade price at
t   and t    are        and        respectively  then trade price      and trade price        
the neural network requires input to be in the range         we have therefore created an embedding by
converting numerical values into binary form  for example  the final result for trade size would look as follows 
trade size      round log                                             after these datatrans formations  our input
features becomes a    x  feature vector 

figure    illustration of an input vector 

results
baseline approaches
for the purpose of this project  we evaluated several machine learning algorithms  in particular  logistic
regression and support vector machines  logistic regression was a natural choice because we wanted to make
binary predictions about the directions of future trades  we also attempted to use svm for both the trade
direction and quantity prediction tasks  we did some field trials comparing the various learning algorithms  dbn
was the most accurate out of the three  and therefore we decided to focus on dbn for the purpose of this
project 
dbn
the structure of our deep belief network is shown in figure    there are a total of   hidden layers  each with    
nodes  this is the best configuration out of various other configurations of network topologies we explored 
trade direction prediction
we want to predict the next    trades given the previous    trades  for this task  we trained    dbns  the ith
dbn is trained to predict the direction of the trade at ti  the results are shown in figure    for comparison  we
used   different sets of input  one using only information from the past    trades and another using both trade
and order book information 

fifigure    accuracies of predicting trade direction  the predictions in the first row only uses trade information 
the predictions in the second row uses both trade and top of the book information  namely the bid price  bid
size  ask price  ask size  
trade quantity prediction
similar to the previous prediction task  we trained    dbns to predict the sizes of the next    trades  our earlier
attempt uses a logistic regression in the output layer to predict a normalized value between         the prediction
range is very narrow  between     and      we attribute this to the steepness of the sigmoid function  posing this
as a classification problem would perhaps be more appropriate  we therefore transformed the trade quantity
into    discrete bins  the distribution of the trade quantity is extremely skewed as shown in figure    as a
preprocessing step  we log normalized the trade quantity  reducing the kurtosis from       to      doing so
created    discrete bins  each corresponded to a power of    results are shown in figure    

figure    histogram of trade quantities 

figure    histogram of log normalized trade
quantities 

figure     rmse of predicting trade quantities  the predictions in the first row only uses trade information  the
predictions in the second row uses both trade and top of the book information  namely the bid price  bid size 
ask price  ask size  

error analysis
trade direction error analysis
given the past    trades  our model yields an accuracy of over      it appears that additional information  such
as the order book data  did not improve the result  although the unprocessed order book data does not seems
very predictive  it could potentially be useful if we manually engineer features that is not currently captured by
the dbn 
we are interested to understand why trade direction can be predicted  the graph of trade directions are shown

fiin figure     by inspection  we discovered that the trades tend to be of consecutive buys and sells  which explains
it far from random and allow our algorithm to perform some predictions 

figure     time series of trade directions  buy and sell orders are shown at the top and bottom
respectively 
trade quantity error analysis
from the result above  we can see that the prediction for the trade quantities are fairly inconsistent  it is unclear
if there exists any correlations between our input data and the trade quantities  perhaps  we may need
additional information  other than the last    trades  to improve the prediction  we also tried to gain additional
insights about the dbn by visualizing its weights  but it turned out not to be too informative either 
the rmse of the results are on average over   bins different from the actual labels  when we look at the output
of the dbn  it predicts the majority class most of the time   in this case it is bin    we attribute this to the
skewness of the class labels  one way to deal with skewed class distribution is to resample from the underlying
dataset to obtain a more evenly distributed set of training examples 
there are potentially multiple factors contributing to such unpredictability  first  when trading large quantities 
hedge funds and institutional traders use several ways to minimize market impact  the simplest way is to divide
large trades into smaller trades  more complex approaches involve further obscuring the trading patterns by
introducing noise using multiple buying and selling transactions      moreover  other market makers may use
similar algorithms to predict the demand and supply  as a result  any arbitrage opportunities would disappear
quickly  leading to mixed signals mingled with each other 
perhaps  the more interesting problem is the prediction of outliers    trades with large quantities  the ability to
predict these outliers is more important as these outliers would cause the market maker to over buy or over sell
the asset  leading to increased risks and unbalance inventories 
future work
we would like to investigate further using other complementary tools and information and see if we can see
improveme our current results  one possibility is to include data from highly correlated financial product such as
nasdaq futures market nq  as additional features  the rationale behind this is similar to pairs trading  if a large
quantity is traded in nasdaq  it might inform us about trades related to es  s p  futures  another possibility is to
include other handcrafted statistical information such as moving averages as input features  there could be
information not captured by the fundamental trade information that can help achieve better predictions  it may
also be useful to create an automated process to experiment more comprehensively with our dbns using
different hyper parameters  such as the number of hidden layers  the dimension of different hidden layers 
number of training iterations  learning rate and etc  although we have done various tests and decide to settle on
our current configurations  it would be beneficial if we could further fine tune our hyper parameters 
   joel hasbrouck  empirical market microstructure  the institutions  economics  and econometrics of securities
trading 
   g  e  hinton  s  osindero  and y  w  teh  a fast learning algorithm for deep belief nets  neural computation 
vol      no     pp                
    geoffrey hinton         training products of experts by minimizing contrastive divergence  neural
computation             
    http   ufldl stanford edu wiki index php deep networks  overview
    http   en wikipedia org wiki algorithmic trading

fi