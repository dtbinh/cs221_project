real time reinforcement learning in traffic signal system
tianshu chu
abstract real time optimization of a traffic signal system is a
difficult decision making problem with no considerable model
given  to achieve this optimization  a perfect tradeoff should be
made between the distributed learning in each individual
intersection  and the integrated cooperation in the whole traffic
grid  this paper explores such a tradeoff and designs an efficient
traffic signal system by applying a hybrid ontology based model 
first  a model based reinforcement learning  rl  algorithm is
induced  second  a model of smart traffic signal system is
designed with importing the rl algorithm into the background
knowledge space of each signal agent  finally  a simulation of the
model is conducted and the results are discussed 
index termsmas  rl  smart infrastructure  ontology 

i  introduction
to mitigate the increasing traffic congestions during rapid
urbanization  an optimal distribution of transportation resource
is necessary  the real time optimization of signal system is
one fundamental approach  the research interests in this area
have moved from modeling centralized control system to
modeling hierarchically distributed control system due to more
efficient and adaptive performance  to design high quality
distributed signal system  two issues should be reviewed
carefully 
 how to make each agent smarter to achieve the local
optimum 
 how to make the whole multi agent system  mas 
smarter to balance each local optimum and the global
optimum 
typical approaches to the first issue are rls  such as qlearning      td method      or model based rl  which has
more advantages for global optimum      an rl example was
given by b  abdulhai et al      then an online learning can be
implemented to achieve real time optimization based on rl 
for the second issue  usually evolutionarily stable strategy
learning can be used in cooperative mas      however  this
algorithm is practically difficult 
there are several examples considering both issues  s 
mikami and y  kakazu combined the individual rl with
genetic searching algorithm to achieve global cooperation     
m  choy  r  cheu  and d  srinivasan developed a more
sophisticated model by implementing online learning with rl 
learning rate and local weight adjustment  and evolutionary
algorithm      later they added neural network as well     
however  to achieve the second issue  these models inevitably
make the original rl much more complicated  leading to
limited performances and low efficiencies  actually  the
simulations of these models were conducted only in small scale
traffic grid  and no real time data was provided 
to design more efficient learning model  this paper uses an
alternative approach to achieve the second issue  applying the

ontology based model      and introducing extra information
sharing and communication processes in the dynamic ontology
to make cooperative rl  first  an efficient model based rl is
developed using q function defined by m  wiering      
second  static and dynamic ontologies are designed
considering the necessary information for rl and cooperation 
third  a netlog simulation is conducted for large scale traffic
grid and different car agents  finally  the comparisons to other
models of signal systems are given  and results are discussed 
ii  model based reinforcement learning
a  model objectives
the traffic grid is a square initialized by the road number
 n  and block size  m   m is also the capacity of the queue
before each intersection  because each road has   directions 
the total size will be a square of    m   n       each
intersection c  c has four signals  and signal ci controls traffic
flow with diri  where dir    n w s e   the decision space of
each signal is u    r  red   g  green    there are two basic
traffic rules in this model which are shown in fig   
 when the signal is red  the car can only turn right
under yielding 
 when the signal is green  the car can go straight  turn
right  or turn left under yielding
three different car agent types are designed to make the
traffic system more realistic  drunken car agents do a random
walk with legal actions and will arrive at the destination by
change  nave car agents are attempted to move closer to the
destination  smart car agents are improved nave car agents 
which can choose the optimal action to minimize expected
waiting time in the next intersection 
b  definition of q  and v function
the general goal of the whole signal system is minimizing
the average cumulative waiting time of all car agent on the way 
so the q function can be defined as negative that value given
their current state and the decision of each intersection  for
example  if we have ut c     r  then we can simultaneously
determine ut    r g r g   also  each state can be identified
player
 

player
 

player
 
player
 

player
 

fig   traffic flows in the local system
with decision profile  r r r r r  
black arrow shows the right turn
flow  green arrow shows the straight
flow  blue arrow shows the left turn
flow  and red arrow shows the
stopped cars  note the incoming flow
after the red flow also accounts for
the congestion possibility 

fiwith the current signal  cars position in the queue  and its
destination  then the q  and v functions are given as

destinations can only be located on the road  and a car is also
regarded as reaching destination if it reaches the neighbor patch
on the road with opposite direction 

qt st  ut   where st    ct i qt   s  st     dest  qt       m      
vt   s    maxuqt s  u  

   

both q  and v values are stored at each car agent 
c  definition of transition and reward functions
we can approximately define the transition function pt s  ut 
v   v  s  by treating all car agents as drunken cars 
specifically  the transition functions for v  s are listed below 
 when ut   r  qt      qt   is occupied  pt  ct i qt   ut   ct i
qt           
 when ut   r  qt      qt   is empty  pt  ct i qt   ut   ct i qt        
 when ut   r  qt      pt  ct i qt   ut   f ct  r i   r i  m    
    
 when ut   g  qt      pt  ct i qt   ut   ct i   qt       
 when ut   g  qt      pt  ct i qt   ut   f ct  r i   r i  m    
pt  ct i qt   ut   f ct  l i   l i  m     pt  ct i qt   ut   f ct  i  i
m         
where  r i   l i   is used to find next direction by turning right
 left  with r i    i     i     and f ct  r i   is used to find the
next intersection  note pt dest  u  dest  is always    the reward
function is given as
rt s  ut     e  v   s     pt s  ut  s   

fig   q value estimation in small scale traffic grid

   

d  definition of updating rules
the original updating rule for q value is
qt   st  ut        qt st  ut     rt st  ut  vt st     

   

to simplify the problem  making       then in this model  the
v value can be alternatively expressed as
vt s    maxue  tau  t t  tau trtau stau  utau  t   t rt   st        
where rt   st        if st     dest  otherwise rt   st        
so we can update the optimal decision per intersection with
value iteration 
vt   c  i  q   rt   c  i  q 
for t   t    until convergence
ut  c         argmaxu i q rt s  u  vpt s  u  v  vt   v  
vt s   rt s  ut  s   vpt s  ut  s   v  vt   v 
in an agent based model  this process can be approximately
done with estimating the expected q value all the way before
destination with          to check the performance 
experiments are conducted in a small scale traffic grid with n  
   m      and smart car number       the estimated cumulative
waiting time  absolute q value  of one car and corresponding
average waiting time are shown in fig    and fig    note all

fig   average waiting time in small scale traffic grid

e  implementation of cooperative features
since rl is time consuming and data reliable  it is only
applied to coordinator agent  during the rl process of
coordinator agent  intersection agent can make nave localoptimal decision to reduce its queue size  also  coordinatoragent will send information to make balance between each
child agent  therefore the whole decision making process is
guaranteed to be real time cooperative 
iii  design of the static ontology
the similar static ontology is used here  which is shown in

fig   static ontology

fifig    the only difference is that rl is used instead of greedy
learning in the background knowledge space of coordinatoragents  specifically  the goals for agents at each layer are listed
in table   below 
table i  goals for agent layers in static ontology
agent layer
signal
intersection
coordinator
global

goals
conduct the decision from intersection agent
greedily minimize the total queue size of child signalagents  consider the decision from coordinator agent
maximize the estimated total v values of all car agents
inside this region    neighboring intersection agents  
balance performances of child intersection agents
present average and cumulative waiting time of caragents inside this traffic grid for human involved decision

coordinator agents paly main roles in this smart signal
system  they seek for global optimal decisions to minimize the
waiting time of cars on the way  they perform real time
communication with child agents to make integrated local
optimum  on the contrast  intersection agents make simple and
quick decisions to guarantee the adaption of the system  the
global agent in this model does not take responsibility for
further global optimum because computing all car based vvalues in a combined state space of a large traffic grid is timeconsuming  instead  it just collects global data for result
estimation 
the models in the background knowledge are listed in
table    fictitious learning and markov process are used in
both intersection agents and coordinator agents  however 
different decision making models are applied for these two
agents  intersection agents perform greedy algorithm to
minimize the estimated queue size at the next moment 
coordinator agents perform reinforcement learning to minimize
the estimated total waiting time of all cars in the region  due to
different computing complication  intersection agents can
make real time decision  while coordinator agents can only
update their decision within a period    seconds in this model  
furthermore  these two kinds of agents communicate with each
other so intersection can also achieve balanced performance
with its neighbors 

region  details of these two decision making process are
described below 
a  decision making process for intersection agent
if we define c    intersection  i    signal  q    queue size 
     estimated value  h    relevant historical data  then the
decision making process can be described as 
for each c   intersection agents 
for each u   g r 
for each i   child signal agents 
qt    c i u   mp qt c i  u 
rt c u   rt c u  qt    c i 
for each cj   adjacent intersection agents 
pt    cj u   fl h cj  
qt    cj   upt    cj u  mp qt cj  u 
rt c g   rt c g          qt    cj          qt    cj  
rt c r   rt c r          qt    cj          qt    cj  
ut  c   argmaxurt c u 
b  decision making process for coordinator agent
to simplify this process  i assume all the cars are nave car
agents so the transition space can be reduced significantly  also 
the expected waiting time at each intersection can be calculated
using geometric distribution  in fact  there are only two
situations we need to consider  fig   
 when the destination is on the right side ahead  caragent can only choose the  turn right    path if the
light is red  it can also choose the  go straight   
path if the light is green 
 when the destination is ahead or on the left side ahead 
car agent always has longer waiting time if the light is
red 
dest 

dest 

dest 

dest 

table ii  background knowledge in static ontology
model
fictitious
learning  fl 
markov
process  mp 
greedy
reinforcement
learning

description

fig   action space of nave cars before green light  left  and red light  right 

estimate the decision of intersection agents

if we define path    a set of possible paths presented as a
sequence of intersections  v    negative cumulative waiting
time to the destination        then this process can be
described as

estimate the queue size
make the decision to minimize the estimated queue size
in the region
make the decision to maximize the estimated v values
of all cars in the region

in short  intersection agents make decision every second 
based on the estimated queue size of itself and its neighbors
 which is the partial information from coordinator agents  
coordinator agents make decision every two seconds  based on
the estimated cumulative waiting time of car agents inside the

for each a   car agents in the region 
for each c   adjacent intersection agents  path 
u  c   pt    c u 
v a c u   cp a c u c      g  c  e v a c u  c    
u  c   argmaxuav a c u 

fiiv  design of the dynamic ontology
the framework of the corresponding dynamic ontology is
shown in fig    also  the carrying information is shown in
table   

beginning  and drops fast when time elapses  the cumulative
waiting time  area  also decreases because car agents achieve
their destinations in a short period 

fig   dynamic ontology
table iii  information flows in dynamic ontology
information

fig   average waiting time in a regular signal system

classifications

 period  sec  

environmental info 

experience info 

i     

u  c  from c  children c 
  dir c      

i     

qc  c qc    from c 
children c 
qc c qc    from c 
children b 

u  c  from c  children b 

i     

qc from c  children a 

u  from c  children a 

i     

n a

u  from c  parent c 
u  c  from c  adjacent c 

i     

n a

u  from c  parent d 

v  results and analysis
in this section  the performance of this model will be
estimated  first  a general comparison with regular signal
system is conducted to confirm the efficiency  second  the
appropriate weight of local optimum is selected from plots 
third  it is compared with a nave model built with greedy
algorithm to ensure the difference between local optimum and
global optimum in this signal system  forth  the robustness in
large scale traffic grid is tested  also  the overall performance
with changing critical variables is visualized 
the default settings of the simulations are  run times       
n      m      car number       car kind   nave car  time
horizon       seconds  estimation standard   average waiting
time of all cars  all the plots are actually the average values of
    runs  some settings may be changed later for the particular
purpose of the experiment 
a  comparison with regular signal system
to confirm the efficiency of this model for all car agents 
three car kinds are tested in this experiment  the performance
of a regular signal system with fixed cycle time    seconds is
provided for comparison  the results are shown in fig   and
fig    for regular signal system and smart signal system
designed with this model respectively  we can see in this
model  the average waiting time is reduced significantly at the

fig   average waiting time in a smart signal system designed with this model

b  balance with local optimum
in this model  each intersection should balance its
performance with its neighbors  however  how an appropriate
tradeoff can be made between this cooperation and its local
optimum  if we change the weight of local optimum part in the
reward function of an intersection agent  the result will be like
fig    although heavy weighted local optimum can achieve
relatively low average waiting time at beginning  it extends
cumulative waiting time of cars  specifically  with weight     
all cars can achieve destinations after    seconds  while with
weight      the traveling time increases significantly to    
seconds  so weight is chosen as   for this model 
c  comparison with nave local optimum
although this model just considers neighboring optimum 
in small scale traffic grid given in default settings  it can be
approximately regarded as global optimum  so we can compare

fiit with a nave local optimum model  which only considers
real time minimizing of its queue length  to estimate how much
a global optimum can improve the performance of this model 
from the result shown in fig     we can see when the traffic
density is high  the performance of local optimum is very
unstable and may occur irreversible congestion  note the traffic
density is calculated as initial car number   grid capacity  where
the capacity is   m n  n    

fig    performances in large scale traffic grid

vi  summary

fig   performances with different weights of local optimum

this paper designs a smart signal system by introducing a
sophisticated reinforcement learning model and a neighborcooperation feature to the original ontology based smart
infrastructure design model  the efficient and stable
performance of this model is demonstrated with a series of
experiments  however  there is still improving space  such as
combining cheap nave local optimum with this model based
on the current traffic density 
references
   

fig    local and global optimums with different traffic densities

d  performance in large scale traffic grid
as the scale of traffic grid increases  this neighborcooperation becomes trivial  leading to a decrease global
optimum  the performances of this model are also estimated in
large scale traffic grid with n           fig      when n      
the curve does not change very much  when n       average
waiting time increases at beginning  so cumulative waiting time
increases significantly 

c j c h  watkins  learning from delayed rewards  doctoral
dissertation  kings college  cambridge       
    r s  sutton  learning to predict by the methods of temporal
differences  machine learning                
    m a  wiering  explorations in efficient reinforcement learning 
doctoral dissertation  university of amsterdam       
    baher abdulhai  rob pringle  and grigoris j  karakoulas 
 reinforcement learning for true adaptive traffic signal control   journal
of transportation engineering                      
    ana lc bazzan   a distributed approach for coordination of traffic
signal agents   autonomous agents and multi agent systems                    
    sadayoshi mikami  and yukinori kakazu   genetic reinforcement
learning for cooperative traffic signal control   ieee world congress on
computational intelligence  evolutionary computation       
    min chee choy  dipti srinivasan  and ruey long cheu   cooperative 
hybrid agent architecture for real time traffic signal control   ieee
transactions on systems  man and cybernetics  part a  systems and
humans                      
    srini dipti srinivasan  min chee choy  and ruey long cheu   neural
networks for real time traffic signal control   ieee transactions on
intelligent transportation systems                     
    tianshu chu  jie wang  and james o  leckie  an ontology based
service model for smart infrastructure design  proceedings of ieee
conference on cloud and service computing       
     m  a  wiering   multi agent reinforcement learning for traffic light
control                   

fi