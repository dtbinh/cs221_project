finding meaning in new york city public school data
cs     machine learning  fall     
sophia westwood

daniel jackoway

computer science department
stanford university

computer science department
stanford university

sophia cs stanford edu

jackoway cs stanford edu

abstract
in this paper  we apply machine learning techniques on data
from over five hundred new york city schools and examine
the factors behind individual school performance in     
and      based on the demographic  test performance  and
survey data collected in       we uncover major factors
shaping school improvement and decline  provide a predictive model for schools future trajectories  and rigorously
evaluate common assumptions about school performance 
we measure school performance with the new york state
english language arts student test results  we find that a
schools starting position in      is extremely powerful in an
unexpected inverse direction  schools above the mean tend
to get worse  and schools below the mean get better  yet 
initial state test score is only one window into the data  we
explore key features beyond score in predicting both current performance and future improvement  and relate the
two learning objectives  while demographic data allows us
to accurately classify schools as above  or below average 
we make strong predictions of future improvement based on
just two questions on parent involvement  finally  we provide machine learning evidence of the strong and nuanced
web of interrelated factors that characterize schools 

  

introduction

dents  for example  lloyd predicted student failure from
third grade data based on a regression model that labels
students as graduating or failing through current grades 
family characteristics  and test scores      in addition  a
     study on the california high school exit exam investigated factors in fourth grade  including student behavior
as well as student performance  that predict later student
success and failure on the test  the study pinpointed classroom behavior  student absences  ethnicity  test scores  and
english learner status      
additional studies consider the effects of particular intervention techniques on school performance  an analysis of
no child left behinds school accountability requirements
found that school poverty and district size were the best predictors of whether underperforming schools would be able
to achieve the necessary improvement  where high poverty
schools in large districts were the least likely to succeed 
adopting strategies such as dedicating resources to align
the curriculum with standards were also predictors of success       other studies investigate the success of particular
intervention programs such as success for all in inner city
elementary schools     
our project differs from these approaches in that it does
not look at the performance of individual students  nor at
the success of particular intervention programs  rather  we
analyze the factors that affect general school improvement or
decline across a broad range of schools in the new york city
school district  we examine factors including both quantitative achievement results and demographic information  as
well as extensive official surveys of parents and teachers  the
surveys include  for example  ratings of perceived teacher
quality  parent teacher student interaction  perceived school
environment  and perceived gang influence 

the new york city department of education is the largest
system of public schools in america  covering approximately
     schools and     million students     in addition  new
york city serves a large population of low income and minority students  the school system collects and publishes
extensive data on their schools  including detailed parent
and teacher surveys ranging back to       yet  there exists
little machine learning analysis based on this data 
this combination  a large and diverse student body  an
extensive and detailed dataset on schools  and the dearth
of existing rigorous analyses  motivates our analysis of the
new york city school system to identify key factors in school
improvement and decline and predict future school performance  we aim to apply machine learning techniques to
better understand what shapes primary school success and
failure  provide a predictive model for schools future trajectories  and rigorously evaluate common assumptions about
school performance 

  

  

we now present our methodology and results  sections    
and     develop a model based on the strong inverse rela 

background

previous work in the area of education and data has often emphasized performance predictions for individual stu 

  

data

we obtain our data set by merging publicly available spreadsheets from the new york city department of education 
focusing on third grade  we combine surveys of         parents      surveys of        teachers      school demographics
     and new york state english language arts test scores
         in all  we have     features for     schools 

methodology   results

 
see     for further information on survey methodology and
questions 

fitable    classifying improvement  columns  train accuracy 
test accuracy  precision for did not improve  recall for those did
not improve  precision for improved  recall improved 
train test   pr   rec   pr   rec
logistic reg 
    
    
   
   
   
   
   
   
   
   
linear svm
    
    
gaussian svm
    
    
   
   
   
   
random forest
    
    
   
   
   
   

tionship between current score and future improvement  section     looks at predicting this models misclassifications 
section     analyzes key features for future improvement
beyond current score  section     analyzes key features for
predicting current score  and section     teases apart the relationship between the problem of predicting current score
and predicting future improvement with regard to the key
features for each  finally  section     presents additional
mathematical insight into the structure of the featurespace
through principal components analysis 
we normalize all features to have a mean of   and variance
of    in addition  we evaluate binary classification results
with hold out cross validation  randomly placing     of our
    examples in the training set  and the remaining     in
the testing set 

   

initial  predict school improvement

as an initial approach  we pose the following binary classification problem  based on      data  predict whether
individual schools third grade new york state english language test results were better in       or not  the    
features consist of the      english state test score      
demographic data  and      parent and teacher survey responses  the labels we predict are the      new york state
english test results  the data points are individual public
schools in the new york city school district 
we train logistic regression  linear and gaussian svms 
and a random forest classifier and achieve high precision 
recall  and accuracy  see table   for results  logistic regression and the random forest classifier perform the best
on the test set  achieving       and       test accuracy
respectively  with reasonable precision and recall on both
classes 
we next explore naive classifiers to estimate how well one
can predict this problem without complex machine learning 
one might assume the model good schools get better  bad
schools get worse  good schools generally have involved
parents  engaged students  and strong teachers  thus  one
might expect to see a continued upward trend  on the other
side  bad schools often have less involved parents  more disconnected students  and weaker teachers  which might make
them continue to get worse barring intervention  our first
naive classifier  then  labels schools as improving if their
     english score is above the mean      english score
across all schools  and as not improving otherwise  our
second naive classifier inverts these labelings  the results
in table   show that  contrary to intuition  a naive classifier that outputs good schools get worse  bad schools get
better produces even higher performance than complicated
machine learning classifiers  the strong performance of this
naive classifier suggests a dominating trend  regression to
the mean 

   

multiclass classification

we proceed to explore this naive result in more depth 

table    naive classifier  columns  train accuracy  test accuracy  precision for did not improve  recall for those did not
improve  precision for improved  recall improved 
train test   pr   rec   pr   rec
good improve
    
    
   
   
   
   
   
   
   
  
bad improve
    
    
table    multiclass classification  columns  train accuracy 
test accuracy  precision for decline  recall for decline  precision
for neutral  recall for neutral  precision for improved  recall improved 
train test   pr   rec   pr   rec   pr
logistic
    
    
   
   
   
   
   
linear
    
    
   
   
   
   
   
   
   
   
   
   
gaussian
    
    
rand forest
    
    
   
   
   
   
   
naive
    
    
   
   
   
   
   

the average      score for all schools is     points  within
a rough range of     to       the change in english score
between      and      follows a normal distribution with
mean      points and standard deviation      points  based
on this distribution  we expand our binary classification problem to a multiclass problem with three classes  significant
improve  neutral  significant decline  neutral consists of
     points from the mean          significant improve consists of        points from the mean          
and significant decline consists of        points from the
mean          
table   presents the performance results of the algorithms 
note that logistic regression and the linear svm involve
one vs all multiclass classification  the gaussian svm involve one vs one multiclass classification  and the random
forest classifier is inherently multiclass  the three class
naive classifier labels decline if the schools      english
score is below  mean      neutral if the      score is between  mean     and  mean     and better if the     
score is above  mean      inspecting the test accuracy 
precision  and recall of the different algorithms supports the
same conclusion as the binary classification  a naive prediction of bad schools get better  good schools get worse
outperforms more advanced machine learning classifiers 

   

insight into misclassifications

now that multiclass classification has verified the validity
of the naive model  we return to the binary classification
problem and investigate the reasons for success of the bad
schools get better  good schools get worse model  then  we
delve into its points of failure by modeling naive misclassifications as a prediction problem 
figure   presents the linear relationship between the base
     english score  and the      to      change in english
score  the pearson correlation coefficient is       demonstrating a powerful inverse correlation  this strong linear
correlation between      score and score improvement explains the success of the naive classification model  as the
regression line roughly maps a net change of   to a     
score of      the mean starting score 
we now examine the schools that the naive model misclassifies  these schools are either above the mean schools
that are getting better  or below the mean schools that are
getting worse  as judged by third grade english state test
scores  just      of above mean schools improved and just
      of below mean schools got worse  because the dataset
for good schools that improve is so small  we focus here on

  rec
   
   
   
   
   

fibinary classification problem described in section      with
the      english score feature removed 
we present lists of chosen features when the svms penalty
is such that it chooses first two and then five features  together with each features weight  positive weights mean
the algorithm is more likely to select improved when this
features value is high  while negative weights mean the algorithm is more likely to select did not improve when this
features value is high 
top two features for predicting improvement

change in english score vs  baseline score
  

score change from      to     

  
  
  
  
  
 
  
  
  
  
   

   

   

   

   

   

   

   

     english score

figure    there is a strong negative correlation between a
schools      score and its score increase from      to      
table    classifying improvement of below mean schools 
columns  train accuracy  test accuracy  precision for did not improve  recall for those did not improve  precision for improved 
recall improved 
train test   pr   rec   pr   rec
logistic reg 
    
    
   
   
   
   
linear svm
    
    
   
   
   
   
gaussian svm
    
    
   
   
   
   
random forest
    
    
   
   
   
   

the bad schools classification problem 
we train logistic regression  svms  and random forest
classifiers  where the features and labels are the same as
the prediction problem in section      but the data points
are limited to schools with      test scores below the mean 
note that the binary naive classification would predict improve for every data point in this set  similarly  the svm
and random forest predictions initially output improve
for all the data points  reflecting the skewed training data 
we thus resample the data to formulate a training set with
even representation from both classes  concretely  there are
   training examples from each class  table   shows the
results of training learning algorithms to predict whether a
bad school will improve or not 
even with resampling  the learning algorithms struggle on
this second classification problem  while each achieves high
training accuracy  test accuracy is low  in addition precision
is extremely low for the did not improve class  we attempt to address the high variance by trimming down the
featurespace  by running an svm with l  norm penalty 
see section     for details on feature pruning   but to little success  the high variance suggests that we may need
more training examples  particularly bad schools that got
worse  in order to make better predictions for below average
schools 

   

key features for predicting improvement

so far  we have included the      english score as a feature  and the success of the naive model proves it is a strong
predictor  we now remove the starting score feature and investigate other key features for making predictions of future
performance  we focus on feature pruning via an svm with
l  norm penalty     to determine feature importance in the

   percentage of parents who reported talking to a teacher
about how to help their children learn better once or
twice this school year           
   percentage of parents who reported talking to a teacher
about their childrens academic progress at least once
a week          e    
top five features for predicting improvement
   percentage of parents who reported talking to a teacher
about how to help their children learn better once or
twice this school year           
   percentage of parents who reported talking to a teacher
about their childrens academic progress at least once
a week          
   percentage of teachers who reported that         of
their students had a parent attend a conference          
   percentage of teachers who strongly disagree that
adults at their school are often disrespectful to students          
   percent of students who are asian           
many of the presumed strong performance features  such
as parent improvement  have negative weights  meaning that
the algorithm is likely to select did not improve when
these good features are high  this apparent paradox stems
from the strong inverse relationship between      english
score and improvement  strangely  having a high percentage of parents who talk to a teacher about their childrens
academic progress at least once a week has a positive weight
 this suggests that high values will predict an improve label  implying a bad school  we propose that a high percentage of parents and teachers talking extremely often about
childrens progress perhaps suggests that children are struggling  it is also notable that the best few features for prediction on the data are primarily survey responses  not demographic data  we posit that the many complex factors
affecting school performance and improvement  and the variance within demographic categories  might mean that a survey answer may capture more information   see sections
    and     for more analysis of predictions based on demographic data  
while we saw above how      english scores predict improvement well  we can also make strong predictions with
the top survey question features  training on just the top
two features for predicting improvement  we achieve the results in table    a performance close to the initial machinelearning results from when training on all the data in section      training on just the top five features for predicting
improvement  we achieve even stronger results  see table    
we do not attempt to draw causality from these results  or
even a root cause  but  it is notable how much information
about a schools future trajectory can be gleaned from so

fitable    classifying improvement using only two features 
columns  train accuracy  test accuracy  precision for did not improve  recall for those did not improve  precision for improved 
recall improved 
train test   pr   rec   pr   rec
   
   
   
   
logistic regression
    
    
linear svm
    
    
   
   
   
   
gaussian svm
    
    
   
   
   
   
   
   
   
   
random forest
    
    

table    classifying      score  above mean note above  using
only five features  columns  train accuracy  test accuracy  precision for not above  recall for those not above  precision for
above  recall for above 
train test   pr   rec   pr   rec
   
   
   
   
logistic reg 
    
    
linear svm
    
    
   
   
   
   
gaussian svm
    
    
   
   
   
   
   
   
   
   
random forest
    
    

table    classifying improvement using only five features 
columns  train accuracy  test accuracy  precision for did not improve  recall for those did not improve  precision for improved 
recall improved 
train test   pr   rec   pr   rec
logistic regression
    
    
   
   
   
   
linear svm
    
    
   
   
   
   
gaussian svm
    
    
   
   
   
   
random forest
    
    
   
   
   
   

table    classifying improvement using five features most predictive of current score  columns  train accuracy  test accuracy 
precision for not improved  recall for did not improve  precision
for improved  recall for improved 
train test   pr   rec   pr   rec
logistic reg 
    
    
   
   
   
   
linear svm
    
    
   
   
   
   
gaussian svm
    
    
   
   
   
   
   
   
   
   
random forest
    
    

little information on the school  centering mostly around
parent teacher interactions 

the high test accuracy  precision  and recall of these algorithms demonstrates an unfortunate degree of success in
predicting current score based primarily on current demographic data 

   

key features for predicting current performance

to follow up our analysis of key features for predicting
improvement  we now investigate the key features for predicting current performance  we model the classification
problem as follows  the feature space consists of all survey
and demographic data  the labels are above if the     
score is above the mean and not above otherwise  and
the data points are the schools  we prune features as in
section     and present lists of the top features with their
scores 
top two features for predicting current performance
   number of black students           
   number of white students          
top five features for predicting current performance
  
  
  
  
  

number of asian students          
number of white students          
number of black students           
number of hispanic students            
teachers report that foreign language is not offered in
any form at the school            

depressingly  these feature lists demonstrate the strength
of school demographic features  likely also reflective of socioeconomic status and school resources  in predicting the
current performance on state tests  tables   and   show
the performance of learning algorithms trained using just the
top two features and just the top five features  respectively 
table    classifying      score  above mean not above  using
only two features  columns  train accuracy  test accuracy  precision for not above  recall for those not above  precision for
above  recall for above 
train test   pr   rec   pr   rec
logistic reg 
    
    
   
   
   
   
linear svm
    
    
   
   
   
   
gaussian svm
    
    
   
   
   
   
random forest
    
    
   
   
   
   

   

relationship between improvement and current score

we now connect the key features for improvement identified in section     and the key features for performance
identified in section     to the strong inverse relationship
between current score and future improvement analyzed in
sections     and      we investigate how closely tied the
key features for predicting improvement  from section     
are to the key features for predicting current score  from
section      by examining how each set of five key features
performs on the opposite classification problem  table  
presents results for classifying school improvement using just
the five features most predictive of current score  table   
presents results for classifying current performance using
just the five features most predictive of school improvement 
the relatively strong performance in both tables confirm
that current score and improvement are closely linked  as
seen in sections     and      yet  the slightly weaker performance of the score key features on classifying future improvement as compared to the improvement key features
 see section      suggests that the machine learning approach
to improvement does more than simply approximate current score and use the score improvement inverse correlation  other features lend additional insight  finally  such
strong performance on limited sets of features also suggest
the interrelatedness of the featurespace 

   

analysis of feature space with pca

we now use principal components analysis on the normalized data to gain additional mathematical insight into
table     classifying      score  above mean not above  using
five features most predictive of improvement  columns  train
accuracy  test accuracy  precision for not above  recall for those
not above  precision for above  recall for above 
train test   pr   rec   pr   rec
logistic reg 
    
    
   
   
   
   
linear svm
    
    
   
   
   
   
gaussian svm
    
    
   
   
   
   
random forest
    
    
   
   
   
   

fivariance captured by pca
   

  original variance captured

  
  
  
  
  
  
  
  
  
 

 

  

  

  

  

  

  

  

  

  

   

number of principal components

figure    the first principal component captures     of the
datas variance  and a long tail of further principal components
slowly approach capturing the rest 

the structure of the featurespace  while two principal components together account for     of the variability in the
data  one hundred principal components account for just
    of the variability  figure   presents how the total
original variability accounted for changes with the number
of principal components  while there is moderate frontloading in the first ten features  there exists an extremely
long tail  one interpretation suggests that there are a few
powerful underlying factors  perhaps all related to the idea
of socioeconomic status or parent involvement  that affect
a substantial amount of the variance  the long tail  however  suggests that much of the variance in the data cannot
be accounted for by only a few dimensions  speaking to the
richness of the dataset and the nuances of measuring schools
with statistical data  these pca results also suggest that
there likely exists much variance within each binary label 
as just a few features  accounting for just a fraction of the
variance in the data  enabled us to make strong distinctions
between the classes  see sections           and       this
hypothesis makes intuitive sense  above average or belowaverage schools still have wide variability  it is also possible
that pcas inability to represent the variability of the data
with a small number of principal components suggests that
features in the data  parent involvement and well trained
teachers  or gang violence and jaded teachers  for example
 might have nonlinear interactions that pca struggles to
fully capture 

  

conclusions and future work

we have analyzed the strong inverse correlation between
current score and future improvement  sections     and     
and attempted to predict which schools would buck this
trend  section       deriving real world insight from the
data  we have determined the top features that predict future improvement  section       as well as the key features
for predicting current score  section       we have related
the two classification problems to better understand both
 section       and have applied principal components analysis to provide further mathematical insight into the structure of the featureset  section      
we find that bad schools get better  good schools get

worse describes the strong inverse correlation between current score and future improvement  lack of sufficient counterexamples inhibits further analysis of why some good schools
do get better and some bad schools do not get better  after
removing current score as a feature  key features centering
around parent involvement best predict future improvement
or decline  for classification of schools current scores as
above  or below average  demographic features appear the
most predictive  with a set of five or even just two key
features  we can classify future improvement or decline with
an accuracy of    to      and current performance with an
accuracy of    to      the trimmed featureset for improvement performs admirably in predicting score  and vice versa 
despite our ability to make strong classifications from few
features  analysis of the featurespace suggests a nuanced 
deep web of interrelated factors that characterize schools 
opening up space for future work with larger datasets to
better understand the differences within each of our classes
 improve and did not improve  and above average
and below average  
preliminary analysis of math scores within the same framework produces the similar results  future work in this domain might generalize results to other grades and other
school districts  with particular focus on differences within
below average or above average schools 

  

references

    d  n  lloyd  prediction of school failure from
third grade data  educational and psychologocial
measurement                    
    n  a  madden  r  e  slavin  n  l  karweit  l  j 
dolan  and b  a  wasik  success for all  longitudinal
effects of a restructuring program for inner city
elementary schools  american educational research
journal                    
    h  t  nguyen  k  franke    and s  petrovic  on
general definition of l  norm support vector machines
for feature selection  international journal of machine
learning and computing              august      
    n  d  of education       learning environment survey 
     
    n  d  of education  a new view of new york city
school performance                  
    n  d  of education  about us       
    n  d  of education  demographic snapshot            
    n  d  of education  learning environment survey
report               
    n  d  of education  new york city results on the new
york state english language arts  ela    mathematics
tests grades             
     c  padilla  k  woodworth  and k  laguarda 
evaluation of title i accountability systems  school
improvement efforts and assistance to identified
schools  technical report  american educational
research association       
     a  c  zau and j  r  betts  predicting success 
preventing failure  an investigation of the california
high school exit exam  technical report  public policy
institute of california       

fi