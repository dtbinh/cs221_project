emi music data science
metehan dizioglu  rolando vicaria
introduction
the question this project attempts to answer is can we predict if a listener will like a
new song  this problem was presented on kaggle by emi  one of the worlds largest
music production companies  we attempt to answer the question by looking at
listener demographic data collected by emi as well as answers to questionnaires
about music preferences  this data was collected by emi and its affiliates
throughout the uk  it includes men and women ranging from    to    years of age 
all records were anonymized  users  artists  and tracks were all given unique
identifiers 

data
the data set was initially split up across several csv files  the first of these was
users csv which contained the following information for         individuals 


user id   anonymized user identifier



gender   in text format



age   integer  not age groups  there were missing data 



employment status   in text format  there were missing data 



geographical region   different regions in uk 



importance of music in users life   in text format  there were missing data 



hours spent in a day listening to music they own   in text format  there were
missing data 



hours spent in a day listening to background music   in text format  there
were missing data 



   questions asking user to rate on scale of       whether they agree with
the statement
   i enjoy actively searching for and discovering music that ive never
heard before

fi   i find it easy to find new music
   i am constantly interested in and looking for more music
   i would like to buy new music but i dont know what to buy
   i use to know where to find music
   im not willing to pay for music
   i enjoy music primarily from going out to dance
   music for me is all about nightlife and going out
   im out of touch with new music
   my music collection is a source of pride
   pop music is fun
   pop music helps me to escape
   i want a multimedia experience at my fingertips wherever i go
   i love technology
   people often ask my advice on music what to listen to
   i would be willing to pay for the opportunity to buy new music prerelease
   i find seeing a new artist band on a tv a useful way of discovering new
music
   i like to be at the cutting edge of new music
   i like to know about music before other people
the second csv file  words csv  contained information about what words users
used to describe artists  it did this for over         combinations of users and
artists 


user id   integer



artist id   integer



heard of   in text format  there were missing data 



own artists music   in text format  there were missing data 

fi

like artist  integer between        there were missing data 



   words that a user could choose from to describe the artist  e g  cheesy 
soulful  aggressive  etc 

the third file  train csv  contained several rows  each with a user id  artist id  track
id  and a rating  the rating was on a scale of        where     indicated strongly
liked the song  this is the target variable that we wish to predict  the rating a
listener will give to a new track they have never heard before 
the last file  test data  contained the same data as the train csv but rating
missing  which is our target in this project 

initial attempts
we began by branching out and trying two different approaches in parallel  one
approach was a linear svm and the other was k means 
our first attempt at running k means was for the users gender  age  and region  we
did this for    clusters  for each cluster  we aggregated the artists that the users in
that cluster had stated that they like  instead of predicting a rating from        we
tried to predict a yes or no for each track based on whether or not the artist was
contained in the list of artists for that users cluster  we measured accuracy by
assuming that an actual rating      was a yes and      was a no  we then
compared our predictions to the transformed actual ratings  we achieved    
accuracy in this way 
we attributed this low percentage to the fact that the artist list for each cluster was
pretty large  therefore we had an overwhelming number of yes predictions 
we initially attempted to run an svm using only the users gender  age  and region
together with the artist id and track id 
we measured accuracy by counting the number of predicted ratings that were
within         and   percent of the actual ratings  this initial svm gave the following
results 
  difference of prediction from actual
rating

  of test data correctly predicted

within    of the actual rating

  

within     of the actual rating

   

within     of the actual rating

   

fifactorization machines
we decided to use factorization machines    factorization machines  fm  are a new
model class that combines the advantages of polynomial regression models with
factorization models  inference in factorized polynomial regression models can be
understood as an intertwined combination of a principal component analysis like
feature selection step and a linear regression step on the resulting latent feature
space representations  like polynomial regression models  fms are a general model
class working with any real valued feature vector as input for the prediction of real
valued dependent variables as output  however  in contrast to polynomial
regression models  fms replace two way and all other higher order interaction
effects by their factorized analogues  the factorization of higher order interactions
enables efficient parameter estimation 
we chose to use libfm  library for our project  libfm is a software implementation for
factorization machines that features stochastic gradient descent  sgd  and
alternating least squares  als  optimization as well as bayesian inference using
markov chain monte carlo  mcmc   in our analysis we applied all three of sgd  als 
and mcmc algorithms as learning methods 
each row contains a training case  x  y  for the real valued feature vector x with the
target y  the row states first the value y and then the non zero values of x  the
libfm tool trains a factorization machine  fm  model from training data  train and
predicts the test data  test 

processing data
we had to process the data and handle missing fields and then shape it such that
we can run our learning algorithms on it  we started from users csv  this file
contained user information and answers to questions directed by the surveyor as
described above 
we calculated the mean age and populated the missing age information with the
mean  then we created age groups                 etc   this gave us    new
columns  we marked the column with   if the user was in that age group    if not 
by looking at all the rows for work status we found out all the unique work
statuses and again created a column for each unique work status  iterated through
all the users  rows  and mark the column with   if that user was in that work status 
  if not  we applied the same logic also to both region and music  essentially we
ended up with unique columns for each unique response that user gave 
this approach got a little harder when we start processing the hours the user
spends listening to the music they own and the hours the user listens to background
music  the answers were not clearly indicated and used words like      hour   
hours  one hour  one which all meaning the same thing  this data had to be

fitranslated into integers  we used some python and some r scripting to process
these entries 
the next data file we processed was words csv  we first calculated the means of
each column and filled in the missing data in the columns with respective means 
there is a column associated with each of    words but we applied the same
techniques we used for users csv for columns heard of  own artist  which
generated several columns since answers were like  own none  own a little  own
bunch  etc 
at the final steps we aligned the both the newusers csv and newwords csv with
train csv and test csv individually  the final format of the train new csv is  user 
artist  track  userdata  worddata   our features totaled     in our combined
train csv and test csv files 
finally  the data needed to be reformatted into a structure that could be fed into
libfm  this format is the same one used by other machine learning libraries 
namely  libsvm and svmlite 
first we fitted several latent factor models to the target  for each artist  track and
user  we have a separated column indicating whether this rating is from this user  of
this track or of this artist   thus  each row in the data matrix contains exactly    s 
representing artist  track and user respectively  the main idea of latent factor model
is to capture the interaction between users and tracks  tracks can be categorized
into several groups and so are users  users in the same group tend to have similar
taste of different kinds of music  the latent factors are used to model users
different preferences of music from different categories  we used libfm to train this
part of model 
we used a cross validation technique where we split the training data into    equal
parts  the final prediction was the averaged result of the    cross validation runs 
the error reported here is the result returned from submitting the predictions
generated from the models on kaggle 
learning method

root mean squared
error  rmse 

iterations

initial std dev

sgd

        

    

   

mcmc

        

   

 

als

        

   

   

fihad these predictions been submitted while the competition was active  these
would have qualified for   th    rd  and   st place respectively 

gradient boosting machine
as a final optimization  we experimented with the gradient boosting machine    gbm 
package in r  we took the output of the factorization machine predictions and ran it
through a linear regression  the output of that was then fed into the gbm library 
there was immediate improvement on the rmse results  at    iterations  n trees on
gbm   the rmse of the sgd predictions improved to           a hypothetical   st
place had it been submitted while the competion was active   at     iterations  this
improved to           hypothetical   th place   at      iterations  this improved
to           hypothetical   th place   we did not attempt more      iterations
because of the long running time of this algorithm 

references
   http   www ismll unihildesheim de pub pdfs freudenthalerrendle factorizedpolynomialregression
 pdf
   http   www libfm org 
   friedman  j  h    stochastic gradient boosting  http   wwwstat stanford edu  jhf ftp stobst pdf

fi