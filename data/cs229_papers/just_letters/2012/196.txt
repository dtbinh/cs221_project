applying feature selection to gene expression data  cell type
classification   gene signature identification 
gustavo empinotti

susan tu

raf mertens

cs   
gustavoe   susanctu   rafm  stanford edu

december         
abstract
dna microarrays allow biologists to capture the expression of tens of thousands of genes in a single tissue sample 
in this paper  we explore the possibility of using this gene expression data to identify gene signatures that allow
for accurate classification of cells  we describe our work on two datasets  one derived from cancerous and normal
breast tissue  and one derived from blood cells  for the first dataset  we attempted to use feature selection to find
the genes that indicate cancerous breast tissue  this problem turned out to be easy in the sense that many sets of
genes result in high classifier performance  so we concluded that we needed a more difficult classification problem in
order to find a gene signature of biological significance  in the second dataset  cells were labeled by flow cytometry
according to their stage in hematopoietic differentiation  for this multiclass classification problem  we identified
gene signatures that give reasonably good classification results  we also report our classifiers results when run on
test datasets with early progenitors and aml  acute myeloid leukemia  cells  where the classification of cancerous
cells is of particular interest because accurate classification would allow us to determine which types of normal cells
cancerous cells developed from 

 

introduction

for this project we used scikit learn  a collection of
python implementations of common machine learning
algorithms available at http   scikit learn org 

the wealth of gene expression data obtained from microarray technology has triggered research on the application of
computational methods in particular those from statis  binary classification  breast
tics and machine learning  to biology problems  on the
topic of cancer  for example  work has been done on precancer
dicting survival         determining which genes expression
correlate with certain diseases  and classifying cancers by     dataset   preprocessing
subtype            popular approaches include entropy
theory    and t statistics for feature selection  k nearest in this section  we describe our attempts to use feature
neighbors  naive bayes  and support vector machines for selection to identify a gene signature that distinguishes
classification     
between cancerous and normal breast tissue  the dataset
was originally obtained from the national cancer instiwe attempt to identify gene signatures for two prob  tutes cancer genome atlas and includes expression data
lems  in the first dataset we try to predict whether or of       genes for     people  of whom     have breast
not the sample comes from a cancer patient  in the sec  cancer and    do not  data was obtained from agilent
ond  we attempt to classify a cell according to its stage of g     microarrays 
hematopoietic differentiation  a highly regulated process
by which the body generates blood cells  the process is we normalized the data so that the expression of each
also a widely studied model for multilineage differentiation gene had mean   and standard deviation    at least one
in humans      this second problem involved multiclass gene expression value was missing for each of     people 
classification  a field in which no dominant method has these values collectively pertained to     distinct genes
emerged 
and added up to a total of      missing values  we set
these values to be equal to the mean     
 

fi   

results   discussion

variety of combinations of feature selection and classification methods by using multiple methods on   different
method
precision
recall
  features
datasets  their findings consistently pointed towards betnaive bayes
   
   
all
ter performance of svm when compared to j    decision
logistic regression with l 
   
    
  
 
tree  naive bayes and k nearest neighbor  however  there
svm with 
   
    
  
backwards selection
   
    
  
was no clear decision as to what usage of svm led to betsvm with random
   
    
  
ter results  the question remains of what generalization
method  from binary to multiclass  should be used  for
table    average precision and recall on breast cancer
that reason  we only used svm classification  and varied
dataset from   fold cross validation  number of features for
logistic regression is average over   runs  for backwards selec  its parameters in search for the optimal choice  in addition we removed    features on each iteration due to limitations tion to generalization method  we varied feature selection
method and parameters for svm  coefficient c of regularin computational resources 
ization term  type of kernel  class weights  
as demonstrated by the high percentages in table    this
problem is very easy to solve  the high precision and re        feature selection and regularization
call resulting from picking random features suggests that
any set of genes gives good predictions  which is consistent as is usually the case with microarray data  the number
with recent literature that claims that random subsets of of features in our dataset drastically exceeded the number
genes are good at predicting breast cancer survival  and of training examples  therefore we added feature selecsometimes even better than some published gene signa  tion and regularization to prevent overfitting  we used
tures      although we did not find the latter to be the two straightforward methods  a univariate feature selec 
case in our classification problem   the feature selection tion method based on   a measure of dependence between
random
variables  
and an l  regularization method
methods in table    although they all resulted in excellent
that
results
in
sparse
solutions
 by driving many coefficlassification accuracy  resulted in gene signatures that had
cients
to
   
little to no overlap  these results suggest that there are
many distinct reasonably small gene signature that indicate whether breast tissue is cancerous or not 
      handling multiclass classification

 
   

multiclass classifiers fall into roughly two types  generalizations of binary classifiers versus repeated application of
binary classifiers as they are  our multiclass classifier consists of repeated application of binary classifiers  we tried
three ways of building a multiclass classifier out of binary
ones  one vs all  one vs one and error correcting output
coding  ecoc   in one vs all  a binary classifier is built
for each category  each one having the positive class as that
category and the negative class as the union of the rest 
in one vs one  a binary classifier is built for each pair of
classes  ignoring all the remaining categories  in ecoc 
a sequence of binary classifiers are built  for each one of
them  a randomly chosen subset of the categories is the
positive class  and the union of the remaining categories
is the negative class  in all of them  the predicted category for a new example is  briefly  the category that more
closely agrees with the multiple classifications  for more
precise descriptions of these generalization methods  see li
et al      

multiclass classification  blood
cells
dataset   preprocessing

this section regards our attempt to develop a classifier that categorizes cells according to their stage of
hematopoietic differentiation 
labels were obtained
through flow cytometry and cdna amplification  as further described by novershtern et al       the dataset
contained data from     arrays  each array had gene expression levels for       genes  and each cell was classified
in one of    categories  shown in figure     novershtern
et al  grouped the    classes into   more general ones and
found gene signatures for these   classes  our goal was to
refine this grouping  i e   find signatures that distinguish
among a broader set of classes 

extensive preprocessing of this dataset had already been
done by professor david dill  as in the breast cancer     results   discussion
dataset  we normalized the data to have mean   and stan        cross validation
dard deviation    there were no missing values 
initially we repeatedly ran svm with all    classes and
we varied the kernel  c  and the feature selection and gen    methods
eralization methods  when trying ecoc  we also varied
the code length  we found that the optimal choice was
    choice of classification method
using svms with a linear kernel  c        equal weightli et al      did research on multiclass classification meth  ing of the classes  l  regularization  which automatically
ods when applied to microarray data  they compared a determines the number of features  in a one vs all scheme
 

fifigure    hematopoietic cell differentiation  black indicates early progenitors that were in our     array training set  pink
indicates early progenitors that were present only in a test set  blue indicates all other cells present in our training set  hsc 
hematopoietic stem cell  mpp  late multipotent progenitor  cmp  common myeloid progenitor  mep  megakaryocyte erythroid
progenitor  ery  erythrocyte  mega  megakaryocytes  gmp  granulocyte monocyte progenitor  gran  granulocyte  mono 
monocyte  eos   eosinophil  baso  basophil  dend  dendritic  pre bcell  early or pro b cell  bcell  naive  mature  able
to switch  or switched b cell  nk  natural killer  tcell  t cells 

 see figure   for comparison with other methods   this
led to       accuracy with leave one out cross validation 
here we observed that the most common misclassifications
were ery   ery  and ery  mapping to each other  this
reflects their biological similarity  so we turned these   categories into a single one  we assume that the information
in our dataset is not enough to distinguish them   we
did the same with mega  and mega   this results in
   classes  doing so raised the accuracy to        see
figure   for the confusion matrix   li et al      reported
an accuracy no higher than     for their dataset with   
classes  the highest number of classes they worked with 

     

fier did very well on the prevalent classes  we found that
adjusting class weights decreased our leave one out crossvalidation performance by     
     

test set

we then tried to use our classifier on a test set  on
two   array test sets  we were able to identify granulocytes correctly with our best performing  as determined
through cross validation on the     array data set  onevs one svm  we also attempted to classify a    array test
set of early progenitors by using a two stage classification 
we classified all the cells using our best one vs all svm 
then  we selected out all the cells classified as any one
of the five early progenitors  hsc   hsc   mep  cmp 
gmp   we used a one vs all svm trained on only the early
progenitor cells to reclassify these cells classified as early
progenitors  we opted for a two layer approach because
our initial classifier was particularly deficient in classifying
early progenitors  eight of those    cells were mpps  a
cell type not present in the     array test set  and thus
not part of our    classes   we classified those   as either hsc  or cmp  which are respectively   position and
  positions away in the tree  of the remaining    cells    
were classified within   position from its real location in

adjusting class weights

in the standard svm framework each class is weighted
equally  since we are worse at classifying cells that are infrequent in our training set  we tried adjusting weights on
the penalty term of the svm to be inversely proportional
to class frequencies  this would cause our classifier to
trade off confidence on most classes with improved classification of the rare classes  we thought that such a trade off
could result in overall better performance since our classi 

fithe tree  one cell was classified   positions away  and   genes give an average     accuracy on leave one out crosswere more than   positions away 
validation  against       for our selected genes   which
gives credibility to these signatures  the following classes
are predicted with no false negatives  and hence provide
reasonable gene signatures   baso  bcella   bcella  
bcella   bcella   denda   denda   ery     a single cluster   gran   gran   hsc   mega     a single
cluster   nka   nka   nka   tcel   tcel   tcel  
tcel   tcel   tcel   tcel   see table   for an example of a gene signature 
coefficient
    
    
    
    
    
    
    
    

figure    loocv accuracy of various classification methods  using c      selecting     features with   for   vs  
and   vs all  selecting     features with   for ecoc 

gene
c  orf 
slc  a 
mfsd 
adra a
phgdh
parg
zbtb 
traj  

expression
    
    
    
    
      
     
    
    

table    gene signature for bcella 

the following have a particularly high number of false negatives  cmp  ery   gmp  tcel  

   

future work

one of the most important problems to be addressed in
future work is that of classifying cancerous cells into their
stage of differentiation  this is very difficult because some
genes have a distorted expression in cancerous cells 
our work also shows the importance of collecting more
microarray data  because our classifier does very well with
the classes for which we have more training examples  this
gives hope that obtaining more microarray data  which is
currently expensive  will allow for increasingly accurate
classifiers and gene signatures 
figure    confusion matrix for    classes    vs all svm
with l  regularization and c      the       on the color scale
is the fraction of samples of the actual class that are classified
as each of the predicted classes 

on a related note  our    class classifier is ineffective
at distinguishing mep  cmp  gmp and ery  from one
another  future work could restrict its attention to these
cells 

novershtern et al      group the    classes into   larger
classes in order to get gene signatures  since our classifier
consistently classifies    classes with no false negatives 
we were able to retrieve gene signatures for all of these by
looking at the genes picked by feature selection by the respective classifier  one for each cell  as in one vs all   some
of the gene expressions in our gene signatures were as far as
  standard deviations away from the mean  standard deviation and mean computed over all classes   the size of the
gene signatures  determined by l  regularization  ranges
from   to    genes and averages to     random sets of   

microarray data is susceptible to errors  in purifying 
for example   one indication of this is that one of the
cells labeled as gmp consistently gets mapped to t cells
and these   classes are very far from each other in the differentiation process  this seems not to be just a problem
with the classifier since this mistake persisted even when
our classifier correctly classified all the remaining gmps 
therefore  it might be useful to apply statistical methods
to identify outliers in this dataset  and make this process
standard for microarray data  since they are error prone 
and ignore them 
 

fi 

acknowledgements

and ready to use gene expression data  thank you to professor ravi majeti  stanford cancer center  for the aml
test sets  to professor stephen boyd  stanford ee  for a
thank you to professor david dill  stanford cs  for his discussion on regularization  and to yifei meng  compuvaluable guidance and for providing us with preprocessed tational biology     for help in evaluating test set results 

references
    haibe kains  b   desmedt  c   piette  f   buyse  m   cardoso  f   vant veer  l     sotiriou  c  comparison of
prognostic gene expression signatures for breast cancer  bmc genomics               doi                        
    buyse  m   loi  s   vant veer  l   viale  g   delorenzi  m   glas  a  m         piccart  m  j  validation and clinical
utility of a    gene prognostic signature for women with node negative breast cancer  jnci  journal of the
national cancer institute                          doi         jnci djj   
    sotiriou  c     pusztai  l  gene expression signatures in breast cancer  new england journal of medicine 
                       doi         nejmra       
    abraham  g   kowalczyk  a   loi  s   haviv  i     zobel  j  prediction of breast cancer prognosis using
geneset statistics provides signature stability and biological context  bmc bioinformatics                  
doi                         
    liu  h   li  j     wong  l  a comparative study on feature selection and classification methods using gene
expression profiles and proteomic patterns  genome informatics  international conference on genome informatics 
               
    venet  d   dumont  j  e     detours  v  most random gene expression signatures are significantly associated
with breast cancer outcome  plos computational biology                   doi         journal pcbi        
    li  t   zhang  c    ogihata  m  a comparative study of feature selection and multiclass classification methods for tissue classification based on gene expression  bioinformatics                        
doi         bioinformatics bth   
    novershtern  n   subramanian  a   lawton  l  n   mak  r  h   haining  w n   mcconkey  m e   habib  n  
yosef  n   chang  c y   shay  t   frampton  g m   drake  a c   leskov  i   nilsson  b   preffer  f   dombkowski 
d   evans  j w   liefeld  t   smutko  j s   chen  j   friedman  n   young  r a   golub  t r   regev  a    
ebert  b l  densely interconnected transcriptional circuits control cell states in human hematopoiesis  cell
                    doi         j cell            

 

fi