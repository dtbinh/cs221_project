detecting vandalism in wikipedia edits
mudit jain

murugan ayyappan

nikhil agarwal

muditjai stanford edu

murugan stanford edu

nikhilag stanford edu

   introduction
    vandalism in wikipedia
wikipedia is an online encyclopaedia that is
developed and maintained by the public  anyone can make
changes to its articles  and create new ones  official
wikipedia sites have been created for     languages  with
more than   million articles in wikipedia english alone 
making it is the largest encyclopaedia ever created 
everyday more than         edits are made to
articles across all of the wikimedia websites by people
from all over the world      although this open source
approach has been vital to wikipedia s success  it has
inherent problems  one of the most widespread being rogue
edits  vandalisms  
vandalism is defined as  any addition  removal or
change of content made in a deliberate attempt to
compromise the integrity of wikipedia        the most
common types of vandalisms according to wikipedia are
addition of irrelevant obscenities and crude humour to a
page  illegitimately blanking pages and inserting obvious
nonsense into a page       it is estimated that the
vandalism rate is around    of all edits  these bad faith
edits cause a lot of problems in wikipedia by reducing
article quality  reliability and damages the website s
reputation 
given the inherent problem of vandalisms in the open
source model of wikipedia  mechanisms to automatically
detect vandalisms have been around for almost as long as
wikipedia itself  and many approaches and techniques have
been used to solve this problem  in this paper  we discuss
some ways to improve existing automatic vandalism
detection mechanisms  in particular  we focus on machine
learning based approaches given their adeptness in solving
such problems 

    evolution of wikipedia vandalism
detection
early days of automated vandalism detection consisted
of rule based bots that involve blacklisting of ips and users 
grammar rules and static lists of vulgar words and
obscenities  examples of such bots are antivandalbot 
cluebot  martinbot  later on  potthast     proposed to treat
the vandalism detection problem as a classification
problem  and suggested amongst the first machine learning
and statistical based approaches to tackle this problem 
they used nave bayes that was improved by statistical

compression models  since then  many different feature
approaches have been tried out with machine learning
techniques  with good results 
other researches such as those in     use the wikitrust
system to predict labels based on user reputation features 
user reputation increases or decreases depending on the
quality of their article revisions  edits   it assumes that
quality is directly proportional to the amount of the change
that was retained in subsequent revisions  the algorithm
also considers reviewer reputation scores  and if the author
was anonymous as features  amongst others   in
conjunction with these features  they used
another example is stiki metadata     which was
used in wikipedias stiki vandalism detection tool  they
used alternating decision trees with metadata features to
come up with vandalism label predictions  metadata
features examined fields of edit such as timestamp  editor
information  article and revision comment  these were then
used to calculate features pertaining to editors registration
status  edit time of day  day of week  geographical origin 
revision comment length  etc 
in      si chi chin et al used semantic features and
statistical language models to predict vandalisms  building
on statistical language model concepts  they constructed
distributions of words from revision history of wikipedia 
since vandalisms involves use of unexpected words  they
used the variances in distributions to predict if an edit was a
vandal or not  they also use an active learning model to
solve noisy and incomplete labelling of vandalisms 
cluebotng     improves upon cluebot to replace its
rule based model to a machine learning based one  it uses
bayesian classifiers  with a multinomial event model along
with word whitelisting blacklisting  and ann  where
inputs are various statistics calculated from the edit  
bayesian classifier  to classify an edit as vandal or
regular 
in the recent pan      and pan      competitions to
detect vandalisms in wikipedia  feature extraction and
machine learning techniques have been the most successful 
velasco et al     used a combination of the features
discussed above  they built upon the text features proposed
by      as well as the language and metadata features
obtained from            these features were then learnt by
logitboost  random forest and svm models and were
tested against the pan wvc    corpus 
in the following sections we will talk about the
following  we will look at a summary of features we
selected for implementation based on manual observation

fiof vandalisms in conjunction with features suggested in     
its class distribution and some insights into the nature of the
problem  we will look at an outline of our overall
algorithm followed by the results of our experiments that
show how our addition of extra features improved the
models learning  we conclude by exploring some future
directions 

   data
in the wikipedia research community  two major
corpuses have been released for vandalism detection model
learning   the pan wvc     pan       and pan wvc    pan       corpuses  for our project  we chose the
pan wvc    corpus for learning our model since its
sample size is much bigger than pan wvc    data
        regular and       vandals in      as opposed to
     regular and      vandal edits   the pan      data
corpus was the first such corpus collected in an attempt to
create a standard dataset that researchers could compare
their algorithms against  this contains edits got from edit
logs in wikipedia which have been annotated by
mechanical turks  for our project  we chose to include old
and new revision texts  editor  if no username is present  ip
address was stored instead   edit time and edit comment in
our base data  we built our features from this data 

   preprocessing
wikipedia edit logs are stored in text form and
contain special formatting to denote links  image urls 
tables  section headers  references  alignment information 
etc  there are existing parsers available that remove
wikipedia formatting and output plain text  we tried
several parsers  however each had its own limitations  they
either removed all special characters including those which
were not part of wikipedia formatting or they
concatenated original edit text words  which in turn misled
our features  see section   on features below   thus we
created our own pre processing steps that would help us
with feature extraction later  it does the following 
   replace all urls with  url url 
   replace all alphanumeric characters with
 alphanumeric alphanumeric 
   replace all numbers with  number number 
   separate all non alpha numeric characters from
alpha characters by inserting spaces around them 
   replace newline character with  newline  
steps         allow easier feature extraction for urls 
alphanumerics and numbers respectively  step   helps us in
preserving the wikipedia formatting symbols  including
this in our feature set will help classify cases of template
vandalisms  image url vandalisms  etc 
we ran our pre processor on the pan      data 
performed feature extraction on this processed data and fed
these features to the classifier 

   features extracted
there are many classes of vandalism  the most
common types of vandalism are addition and deletion of
random text  promotion and propagation of spam  selfpromotion  silly vandalism by adding nonsense characters 
creating hoaxes by propagating plausible misinformation 
vandalisms to wikipedia page objects such as templates 
page name  images  links  etc   personal attacks and
defamation attacks on people  countries and communities
     
from the pre processed data  we extracted three main
classes of features  metadata features  text features and
language features that will help in classifying many of the
above vandalism types  these are listed in table   
text features capture characteristics of the inserted
text  it gets information on character casings  special
characters  word length  diversity of characters  etc  these
help in catching vandalisms involving random word inserts 
silly vandalisms and also changes to wikipedia formatting 
since we preserve wikipedia formatting symbols in our
pre processed data  any changes to these will show up in
the features 
language features help the classifier in understanding
the semantics of the edit text  vulgar term features help in
detecting abusive language and personal attacks  colloquial
and slang word related features help detect unrelated casual
language in an edit text  which usually indicates vandalism 
using a pronoun list  the algorithm gets features that help
in detecting self promotions 
metadata features capture extra information about edit
text  currently we have   features  is editor anonymous 
and edit comment length 

   experiments and results
we tried out different well known machine learning
classifiers on the features discussed above for vandalism
detection  we picked the best one from this evaluation and
varied its parameters to observe the change in performance 
we also analysed the different subsets of feature classes to
understand their contribution to the entire system 
in each case  we used    fold cross validation on our
training data and report the precision  p   recall  r   fscore  area under precision recall curve  auc pr  and area
under receiver operating characteristic curve  auc roc  
we used weka for our experiments 

fitable    list of features
metadata features

feature description

iseditanonymous

boolean to indicate whether edit was done by a registered wikipedia user or an anonymous
user 
length of editors comment 

editcommentlength

text features  unless mentioned otherwise  each of the following feature is computed on inserted text only 
uppertoallratio

ratio of uppercase characters to all characters

uppertolowerratio

ratio of uppercase characters to lower case characters 

digittoallratio

ratio of digits to all characters 

nonalnumtoallratio

ratio of non alpha numeric characters to all characters 

characterdiversity

a function to measure number of unique character 

avgtermfrequency

average frequency of each inserted word in the original article 

maxinversecharacterdiversity

maximum of  total characters unique characters  over each inserted word

vandalizedoneword

boolean to indicate whether a single word was converted from correctly spelt to misspelt 

longestnonurlword

length of the longest inserted word

longestrepeatedcharsequence

length of longest contiguous character sequence

longestrepeatedwordsequence

maximum number of repeats of a word 

revisionlengthratio

ratio of new revision length to old revision length 

revisionlengthincrement

difference between new revision length and old revision length 

language features  unless mentioned otherwise  each of the following feature is computed on inserted text only 
colloquialfrequency

frequency of words belonging to colloquial lexicon

colloquialimpact

ratio of  added words   deleted words   total words in original  belonging to colloquial
lexicon
frequency of words belonging to dictionary lexicon

dictionaryfrequency
dictionaryimpact
nonvulgaradulttermsfrequency
nonvulgaradulttermsimpact
pronounsfrequency
pronounsimpact
slangwordsfrequency
slangwordsimpact

ratio of  added words deleted words   total words in original  belonging to dictionary
lexicon
frequency of words belonging to non vulgar adult lexicon
ratio of  added words deleted words   total words in original  belonging to non vulgar
adult lexicon
frequency of words belonging to pronoun lexicon
ratio of  added words deleted words   total words in original  belonging to pronoun
lexicon
frequency of words belonging to insults and slangs lexicon

vulgarwordsfrequency

ratio of  added words deleted words   total words in original  belonging to insults and
slangs lexicon
frequency of words belonging to vulgar lexicon

vulgarwordsimpact

ratio of  added words deleted words   total words in original  belonging to vulgar lexicon

colloquialdeletedfrequency

frequency of deleted words belonging to colloquial lexicon

dictionarydeletedfrequency

frequency of deleted words belonging to dictionary lexicon

pronounsdeletedfrequency

frequency of deleted words belonging to pronoun lexicon

slangwordsdeletedfrequency

frequency of deleted words belonging to insults and slangs lexicon

vulgarwordsdeletedfrequency

frequency of deleted words belonging to vulgar words lexicon

nonvulgarsextermsdeleted
frequency

ratio of  added words deleted words   total words in original  belonging to non vulgar
adult terms lexicon

fifigure    evaluation of different classifiers

in table    we analyse contributions of the different
feature categories  individually  text features are the most
informative followed by language and metadata features 
effectiveness of text features indicates that random text
 gibberish  insertion is the most common form of
vandalism 
language features  which target lexically well formed but
abusive malicious edits  are less important than text
features which indicate relatively lower frequency of such
vandalisms  metadata features are least informative since
we have only two such features currently   namely
comment length and whether editor was anonymous 
introducing additional metadata features such as reputation
of author  local day and time of edit can improve them
further  however these were not part of the pan     
dataset and hence not considered for this project 
table    evaluating different classifiers
f score

auc
pr

auc
roc

     

     

     

     

     

     

     

     

     

     

     

     

     

     

     

     

     

     

     

classifier

p

r

nave bayes

     

c   
logit boost
random
forest

figure    evaluation of different feature classes

table     evaluation of feature classes using
random forest      trees 
auc
auc
features
p
r
f score
pr
roc
metadata            
     
     
     
language

     

     

     

     

     

text

     

     

     

     

     

m l

     

     

     

     

   

m t

     

     

     

     

     

t l

     

     

     

     

   

m t l

     

     

     

     

     

table    evaluating different no  of trees for random forest
trees

p

r

f score

auc
pr

auc
roc

  

     

     

     

     

     

  

     

     

     

     

     

  

     

     

     

     

     

   

     

     

     

     

     

   

     

     

     

     

     

    

     

     

     

     

     

combining feature categories always shows an
improvement over either of the individual categories and
the best feature group is obtained by adding all the three
feature categories 
in table    we analyse results of different types of
classifiers  random forest performed better than other
classifiers like logitboost  c    decision trees and nave
bayes in terms of precision  recall and area under
precision recall curve  hence we selected random forest
as the algorithm for further analysis 

fifigure    evaluation of random forest with different no  of trees

in table    we analyse the effect of increasing the
complexity of our learning algorithm  increasing the
number of trees in random forest from    to     quickly
increases the pr numbers until they gradually asymptote
after      we observe that forest size of     trees achieves
a good trade off between complexity and performance 
the figures     show the p r curve for tables      we can
choose the operating point of our algorithm to be either
high precision or high recall depending on the specific
requirements of the vandalism detection application 

   conclusions and future work
in this project we evaluated features with different
classifiers for the task of wikipedia vandalism detection 
we found out that random forest worked best with a
combination of all the three classes of features  metadata 
language and text  
there is further scope for improvement by adding
additional features such as author and edit reputations 
better semantic features using nlp frameworks and using
better lexicons for language features 

   references
   

velasco et al  wikipedia vandalism detection
through machine learning  feature review and
new proposals       

   

g  potthast  automatic vandalism detection in
wikipedia  in advances in information retreival lecture notes in computer science  vol        craig
macdonald  ed   berlin  springer        pp          

   

stiki         online   available 
http   en wikipedia org wiki wikipedia stiki metada
ta scoring and origins   accessed            

   

wikitrust         online   available 
http   en wikipedia org wiki wikitrust   accessed
      

   

b adler et al  detecting wikipedia vandalism using
wikitrust  padua       

   

si chi chin et al  detecting wikipedia vandalism
with active learning and statistical language
models  in wicow     raleigh  nc  usa       

   

cluebot  ng  wikipedia user cluebot ng       
 online   available 
http   en wikipedia org wiki user cluebot ng 

   

w  vandalism  wikipedia         online  
available 
http   en wikipedia org wiki wikipedia vandalism t
ypes of vandalism 

   

wikimedia  wikimedia         online   available 
http   toolserver org  emijrp wikimediacounter  

     wikipedia  wikipedia vandalism         online  
available 
http   en wikipedia org wiki wikipedia vandalism 
 accessed       
     w  vandalismtypes  wikipedia         online  
available 
http   en wikipedia org wiki wikipedia vandalism ty
pes 
     university of waikato  weka 

   acknowledgements
we would like to acknowledge professor andrew ng and
the tas for their assistance throughout the course  we
would also like to thank santiago moises mola velasco
 winner of pan      competition  for his guidance 

fi