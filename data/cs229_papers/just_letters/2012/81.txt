broadcast news story boundary detection using visual  audio and text
features
maryam daneshi  matt yu

abstract
news video story segmentation is vital for video summarization  story linking  and curation  we present a multimodal segmentation algorithm which fuses video  audio and
text cues for story boundary detection  we show that broadcast news closed captioning is a rich and readily available
source that improves story boundary detection  furthermore 
we propose an empirical distribution based feature representation for various binary video and text features  we investigate different multimodal fusion methods for learning algorithms based on discriminative models and evaluate the performance of each set of features on more than    hours of
three major news programs  we compare the effect of each
feature and fusion method on the segmentation accuracy of
each news program 
index terms story segmentation  multimodal fusion 
supervised learning

 

introduction

news video story segmentation  a process which breaks news
streams into individual stories  is an important tool for next
generation news systems  however  the wide variation of production rules across channels and diversity of stories in each
program make segmentation a difficult task 
to overcome this difficulty  it is essential to take advantage of the different modalities in news streams  video  audio  and closed captioning  however  many useful cues are
inherently binary  e g  the existence of an anchor in a shot 
furthermore  gathering training data can be problematic because shots which do not contain story boundaries severely
outnumber shots that do contain story boundaries 
in this paper  we describe a novel story segmentation
algorithm which extracts and fuses features from multiple
cues and trains a story boundary classifier  given training
data for a news program  we generate a separate classifier
which learns the story boundary characteristics of that program  to adapt our binary features  we propose an empirical distribution based feature generation model which builds
a conditional distribution for the distance of each feature from
a story boundary  while these cues  individually  are insufficient to reliably indicate a story boundary  an intelligent combination of these cues can produce a strong indicator  to that
end  we also study different fusion methods in our discriminative classification approach and analyze the performance of

each technique  finally  to deal with the imbalance between
non story and story sample points in the training data  we use
a bootstrapping approach 
the rest of the paper is organized as follows  sec    reviews existing work on story boundary detection  in section  
we introduce all visual  audio and text cues as well as the
classification framework  finally in sec    we present our
experimental results and compare the performance of various
features and fusion methods 

  related work
in previous work  researchers detected story boundaries by
combining multiple cues  however  the majority of these efforts focused on just video and audio features  hsu et al     
considered the appearance of an anchor person  audio pitch
jump and significant audio pauses as the main set of features 
zhai et al      obtained text from automatic speech recognition  asr  to detect potential segmentation points 
multimodal feature fusion has been of great interest to
the research community  hsu et al      used a maximum entropy objective to select the most informative mid level audio
and video features and demonstrated an optimal feature fusion method  in later works  hsu et al         investigated alternative discriminative models  i e  support vector machine
 svm   and showed a performance improvement when combining maximum entropy with svm  while jianping et al     
presented a naive bayes approach for story boundary detection  gao et al      combined syntactic and semantic methods
for segmentation using an unsupervised learning method 

  news story segmentation
figure   shows an overview of the features we use for segmentation  in sec      we describe the video and audio features followed by a detailed description of the text features in
sec       later  in sec       we describe our multimodal story
segmentation algorithm 
    video and audio features
     

anchor frames

usually  story transitions occur while an anchor is visible or
has recently appeared  furthermore  anchors appear more often than any other person in the news and move very little 
thus  to detect anchor shots  the following method is used 
news video is sampled every     ms and both face detec 

fi      a b              

the average volume of the news stream     mathematically 
p t   

            

              

                     
                 

                     
                 

andrea mitchell  thank you     and the supreme
court today
     
 

   
 

     
 

   
 

    

fig     segmentation features overview   for any time in the news
program various video  audio and text features are collected

tion and tracking are used to find all face appearances  in
the detection phase  a viola jones frontal face detector     is
applied to find all faces in a frame  then a color histogram
based tracker  camshift      is applied to track all detected
faces in the following frames  in the last stage  we cluster all
the color histograms using l  distance  the cluster with the
shots that are closest to the dominant cluster centroids are the
anchor shots 
furthermore  most news programs tend to follow the same
pattern during a story transition  i e the anchor appears on the
left with an image of the next story over his shoulder  thus 
the geometric location of the bounding box for the detected
face is also used as a visual cue 
     

black frames

it has been shown in      that commercials are usually followed by one or two frames that are entirely black  for broadcast news  we observe that a new story starts after a commercial  however  a black frame may also appear in other parts of
the news       therefore  like the other cues  black frames are
not  by themselves  a reliable indicator of a segment boundary  instead  they provide added information to improve the
segmentaiton 
     

 t   t   

    text features
            

   
 

max
t   tw t  
t   t   
v  tk     tk  t   t   

            

significant pause detection

long pauses were shown in     to be good indicators of story
boundaries  this audio cue captures the tendency of an anchorperson to pause momentarily before introducing a new
story  at every time point of interest  t  the longest period of
silence  p t   is calculated in the interval  t  w  t   where w
is the sampling period  a period of silence is defined as a time
duration where the audio volume  v  t   is always below half

by u s  law  closed captioning  cc  must be provided with all
news videos  often      and    markers are inserted to denote story changes or speaker changes  respectively  since cc
text is transcribed by a human  it is always delayed relative to
the video  to obtain accurate timestamps for the cc words 
asr is performed on the audio track using the cmu sphinx
toolkit       words in cc and asr are matched and aligned
using a dynamic time warping algorithm           yielding
timestamps which have an average error of less than a second  asr recognized words are then matched with cc words
to align the entire cc text 
     

bag of words histogram distance

consecutive stories tend to contain many different words  at
any time point  we calculate two bag of words histograms
with tf idf normalization  one for the words before the time
point and one for the words after the sampled time  then 
we generate a continuous feature by calculating the distance
between the two histograms 
f  t      h t  w  t   h t  t   w     
where f  t  is the distance between histograms of length w
words at time t and h t    t    is the bag of words histogram
between times t  and t    to pick a meaningful window size
w   the normalized histogram distance of the story boundaries
are analysed on three news programs  from our analysis  a w
value of     was the best window size 
     

transition phrase

broadcast news writers use transitions to carry the audience
from one story to another  we collected and built a database
of over     reliable transition phrases from several months of
news programs  at any time point  we collect a binary feature
indicating the presence of any of these transitions phrases 
     

reporter change marker

    and    markers are inserted to denote changes in stories
or changes in speakers  respectively  however  some news
broadcasters use    for both speaker and topic changes and
not the story change marker at all  e  g  pbs news hour  we
define a binary feature that indicates the presence of    
    segmentation framework
many of our features are binary  moreover  the presence of
each of these features  does not directly imply a story boundary  for example  a story boundary may appear a few seconds
after the appearance of a black frame  we define          a

fi                 
         
          
       
  
          

        
         
              

                    

fi   t 
t      seg  fi   t    fi  t  t    

 

t

        
         
          

                    

        
         
 

fig     feature extraction binary features are enhanced using a prior
empirical based probability distribution
               
                
              

sentations using both early and late fusion schemes       in
early fusion  the normalized feature vectors are concatenated
and a support vector machine  svm  is used to classify time
points as boundaries or non boundaries  we use the radial
basis function  rbf  as the kernel function for the svm 

       
 
       

             
         

            
  
          
  
 

             
  

k xi   xj     e  xi xj   

 

where          is the kernel parameter  the  parameter is set to be the inverse of the median of all the pairwise
training instance distances       five fold cross validation is
applied by varying c  the soft margin parameter of the svm 
on the training set to find the parameter which achieves the
highest accuracy 
in late fusion  the same svm is applied to the concatenation of video audio features and the text features separately 
the decision values  dv av and dv t   of the classifiers are
normalized and a weighted sum is calculated as 
dvlf     dv av          dv t
  

              
               

             
         

     
 
       
              

           
  
  
  
          

             
  
 

            
 
         

            

fig     classification framework  early  top  and late  bottom  fusion techniques are used in the evaluation framework followed by
smoothing and filtering

random variable indicating a story boundary  and then calculate an empirical prior probability distribution of  seg fi   t   
for all binary features as 
seg fi   t  

 

p      fi   t  

 


p
t g t   fi  t  t  
p
p
t g t  
t fi  t 

where fi   t         is the binary feature value at a given
time and i is the feature index  t  in seconds  denotes the
time difference between the feature indicator and the actual
story boundary  g   t         represents the ground truth
story segmentation data 
as shown in fig     first  the features described in sec     
and sec      are extracted from the news video stream  then 
binary features are enhanced by the previously calculated empirical prior probabilities  seg  as 
x
seg fi   t    fi  t  t  
fi  t    
t

figure   shows the evaluation approaches in our classification framework  we combine features into multimodal repre 

where  is found by exhaustive search to maximize the area
under the precision recall curve  average precision value  
p
in this work  precision and recall are defined as t pt f
p and
tp
respectively 
in
our
training
and
testing
data 
news
t p  f n
videos are sampled at one second intervals  which leads to a
highly imbalanced dataset  for example  in a    minute program with   stories  there are   positive samples and     
negative samples  therefore  less than    of the labeled
points are positive in this program  to overcome this imbalance  hard negative examples in the training set are isolated
by selecting     of the negative and all the positive training
samples to train a classifier  then we test the classifier on the
remaining     of the negative samples  decision values of
each of the tested samples are stored  after five iterations of
the method above  the top     of the hard negative examples
 samples with high false positive decision values  and all positive examples are picked as training samples  this method
reduces the ratio of the positive to negative training samples
to         for our discriminative model we use manually
annotated reference story boundaries  however  features are
usually asynchronous across modalities and human annotated
ground truth data is not very precise  thus  in our data  sample points within a     second fuzzy window of the human
annotations are also labeled as positive points 
also  as a post classification step  we apply smoothing and
filtering on the classifiers decision values  the smoothing is
done using a lowpass filtered with a window size of   and the
filtering uses a one dimensional laplacian filter with a kernel
of 
                  
the length of the smoothing and filtering kernels are chosen
to be the same as the length of the ground truth fuzzy window size we added to our sample point  the filtering and

fismoothing steps highlight the regions of decision values with
rapid change in a smoothed window around the potential story
boundary points  this approach can improve the accuracy
of the detection algorithm up to     finally  video sample
points are classified to story and non story by thresholding
the decision values 

 

experimental results

we built a database of news streams from three major u s 
broadcast news programs  the database consists of    hours
of nbc nightly news     hours of abc world news and   
hours of pbs news hour collected from september to mid
november of       we used human annotators to create story
boundary ground truths  on average there are seven to eight
stories in every news program  we use     of the videos of
each channel for training and the rest for testing  we sampled
each news stream at one second intervals and extracted the
video  audio and text features mentioned in sec   
table    story boundary detection performance of each feature for
  different news programs

nbc news
feature

abc news

pbs news

p

r

f 

p

r

f 

p

r

f 

anchor s 
presence

    

    

    

    

    

    

    

    

    

black
frame

    

    

    

    

    

    

    

    

    

significant
pause

    

    

    

    

    

    

    

    

    

transition
phrase

    

    

    

    

    

    

    

    

    

bow
histogram

    

    

    

    

    

    

    

    

    

reporter
marker

    

    

    

    

    

    

    

    

    

   

importance of features

before presenting the story boundary detection results using
multimodal fusion  we compare the performance of individual
features  table   shows precision and recall values for the
maximum f  score of each feature  where f  score is defined
r
as f      p
p  r   we observe a high f  score for the anchor
feature across all programs  from our observations  nbc and
abc news have more similar production rules  in these two
programs  significant pause is an important feature where the
reporter change marker is not a strong feature  these two
programs tend to use     markers for story changes so the
majority of the reporter change markers are not indicators of
story change 
for pbs news hour  reporter change and presence of
transition phrase have high f  scores where presence of black

frame doesnt seem to be a strong feature  this is due to the
fact that pbs news hour does not have commercials  however  as we mentioned before  black frames may occasionally
be inserted before story boundaries  also  most of these stories start after transition music  which causes the pause feature
to perform poorly 
from these results  we observe that the presence of each
features is valuable  however  feature performance varies
across news programs  therefore  each channel requires a
separate classifier and a different fusion method to achieve
the best performance 
    multimodal fusion
we evaluated story boundary detection over our database of
three news programs  nbc nightly news and abc world
news have     markers in their closed captioning text which
indicate story changes  in these two programs  we do not
use these error prone story change markers as a feature for
segmentation but we analyze their performance and consider
them as a baseline for our segmentation performance analysis 
figure   shows the precision recall curves for nbc
nightly news and abc world news  in nbc news  we observe that text features  t f  alone are as good as the story
change markers performance  furthermore  both fusion techniques boost performance with late fusion  va t lf  improving the baseline performance by more than     
for abc world news  video aduio or text features alone
perform better than the baseline  the best boundary detection
performance for this program was an f  score of      when
using early fusion of video audio and text features  va tef  
in fig    we show the precision recall curve of pbs
news hour  this news program seems to benefit more from
the text features  improving the video audio feature based
classification by more than     percent  the best f  score is
     for early fusion of features  va ef  
from these results  we observe the importance of text
features in improving segmentation accuracy across all programs  furthermore  we believe there are many more useful text features we can extract from cc  also  these results
highlight the importance finding the proper fusion strategy for
each channel for an optimal segmentation result 

  conclusion and future work
in this paper  we investigated different multimodal fusion
methods for learning algorithms based on discriminative
models  along with video and audio cues  we utilized text
cues from closed captioning which is readily available in
all news streams  furthermore  we proposed an empirical
distribution based feature representation for such features 
in addition  we investigated the importance of various
modalities across three major u s  news programs by analyzing the segmentation performance based on each modality 
for each news program  we studied the importance of each

finbc nightly news

abc worlds news

 

   
vaf
tf
va tef
va tlf

   
   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

 
 

   

   

   

   

   
recall

   

   

   

   

   
vaf
tf
va tef
va tlf

   

precision

precision

 

 
 

 

   

   

   

   

   
recall

   

   

   

   

fig     precision recall curve for nbc nightly news  left   abc world news  right  comparing the performance of story change markers
      text features  t f   video audio features  va f   early fusion of all features  va t ef  and late fusion of all features  va t lf 
pbs news hour
 

vaf
tf
va tef
va tlf

   
   

   

   

precision

   
   

   

   

   

   
   

   
   
   
 
 

   
   

   

   

   

   

   

   

   

   

 

   

recall

fig     precision recall curve for pbs news hour comparing the
performance of text features  t f   video audio features  va f  
early fusion of all features  va t ef  and late fusion of all features
 va t lf 

    

    

    

feature and showed the need for per channel fusion strategy 
in the future  it is important to explore the temporal dynamics of news stories  the expected length of each story is
a parameter than can be learned for each news program  finally  major news programs produce hours of news per week
following same production rules  it will be interesting to incorporate new sample data collected weekly without completely redesigning the classifier 

 

references

    w  hsu  an information theoretic framework towards large scale video structuring  threading  and retrieval  ph d  thesis  graduate school of arts and sciences 
columbia university       
    y  zhai  a  yilmaz  and m  shah  story segmentation in news videos using

    
    

    
    

visual and textual cues  in acm international conference on multimedia       
pp        
w  hsu and s  f  chang  a statistical framework for fusing mid level perceptual
features in news story segmentation  in international conference on multimedia
and expo        pp         
w  h  m  hsu and s  f  chang  generative  discriminative and ensemble learning
on multi modal perceptual fusion toward news video story segmentation  in ieee
international conference on multimedia and expo       
w  hsu  s  f  chang  c  w  huang  l  kennedy  c  y  lin  and g  iyengar  discovery and fusion of salient multi modal features towards news story segmentation  in spie electronic imaging        pp         
w  jianping  p  tianqiang  and l  bicheng  news video story segmentation based
on naive bayes model  in international conference on natural computation 
      pp       
x  gao and x  tang  unsupervised and model free news video segmentation 
in ieee workshop on content based access of image and video libraries       
pp       
p  viola and m  j  jones  robust real time face detection  international journal
of computer vision  vol      no     pp               
r  y  d  xu j  g  allen and j  s  jin  object tracking using camshift algorithm
and multiple quantized feature spaces  in proceedings of the pan sydney area
workshop on visual information processing        pp     
a  g  haupmann and m  j  witbrock  story segmentation and detection of commercials in broadcast news video  in proceedings of the advances in digital
libraries conference        pp         
pnar duygulu  ming yu chen  and er hauptmann  comparison and combination
of two novel commercial detection methods  in proceedings of the international
conference on multimedia and expo        pp           
w  walker  p  lamere  p  p  kwok  b  raj  r  singh  e  gouvea  p  wolf  and
j  woelfel  sphinx    a flexible open source framework for speech recognition 
tech  rep        
c w  huang  w  hsu  and s  f  chang  automatic closed caption alignment
based on speech recognition transcripts  tech  rep   columbia university       
a  g  hauptmann and m  j  witbrock  story segmentation and detection of commercials in broadcast news vvideo  in advances in digital libraries conference 
      pp         
m  worring c g  m  snoek and a  w  m  smeulders  early versus late fusion in
semantic video analysis  in acm multimedia        pp         
g  peter and n  sebastian  on feature combination for multiclass object classification  in international conference on computer vision        pp         

 

fi