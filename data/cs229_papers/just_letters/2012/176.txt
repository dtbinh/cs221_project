content aware email multiclass classification
categorize emails according to senders
liwei wang  li du
s
abstract
people nowadays are overwhelmed by tons of coming emails everyday at work or in their daily life  the large
quantities of emails keep causing confusions  not only spam emails are considered to be junk  but also unwanted
emails  e g  advertisements  cause people to waste time on reading them  therefore  it becomes urgent to develop
reliable automatic categorization of emails to save the trouble  this project aims at researching on ways doing
supervised and unsupervised classification of emails according to email content  in particular  putting emails into
folders in terms of role of email senders 

   introduction
email classification falls into the text categorization reign of machine learning  example like spam email
filtering has been the one of the most popular topics in text categorization over the years  there are several problems
to be recognized and tackled in the process of coming up the solution 
 signature of emails
for text categorization  the most common signature  or representation  of emails can be words  dumais et al  
       sequences of words  caropreso et al          part of speech tags  finn et al          word clusters
 bekkerman et al             


feature selection
by choosing words  possibly counts of words on the token list in the emails  i e  bag of words  as feature vector 
its readily seen that dimension of feature vector and what features to choose affect classification in one way or
another  an
unacceptably high dimension of feature vector may make classifier  e g  svm less reliable when
there are not enough training examples  on the other hand  features play little role on distinguishing emails
from one class to another should be discarded 


classifier selection
there are several existing supervised and unsupervised classifiers out there to be selected  the problem is to
choose the one fits our problem best and the one gives
the best performance 

   design methodology
    dataset
we use a large corpus of real world email messages from enron employees      the enron corpus was made
public during the legal investigation concerning the enron corporation  this dataset  along with a thorough
explanation of its origin  is available at http   www  cs cmu edu  enron   in the raw enron corpus  there are a
total of         messages belonging to     users  since email classification is highly dependent on identity of
individuals  different people from different backgrounds may have different folders for emails  therefore  we choose
emails from employees in the same company  so composition of their emails is similar  among all the messages in
this dataset  we randomly picked over      emails as our own dataset 
    workflow overview
the following is a general workflow for the implementation of classifiers from raw data to final results  we
only show the supervised classification aspect  unsupervised part can be viewed as an extension  which will be
discussed in the following sections 
   labeling 
we put all the messages into   categories 
 friends and families      
 business  e g  announcements  information from own company      
 colleagues  e g  coworkers at same company or alliance partners      
 advertisements publishers     

fi

organizations  e g  organizations other than own company  this may include other organizations the subject
participates or activities they are involved in       
   stemming 
we used an open source python code to do the stemming  the stemmer stemmed the words in the email
documents so that words with the same meaning will have the same form as our data 
   get words statistics and token list 
the data examples are then feed into a program extracting statistics of the dataset  the result of this step gives
a sorted list of all tokens appeared in the dataset and along with their count  i e  number of times of presence in all
the email documents   in summary  there are      emails in all  and        tokens 
   modify token list 
based on the preliminary token list we get from the last step  we can have a general knowledge of the
construction of the list  there is a whole large number of tokens having only a small number of count  so that we can
discard them as they rarely appear in other email documents  on the other hand  there are also some tokens having
too many counts  which are not informative in terms of the classification task  eventually  the range of count we
define is from     to       we also added   other special token  number  dollar  http and email  as a
result the token list is reduced to             long 
   convert examples into matrix 
the main task of this step is to turn each example into a feature vector and then put them together to form an
entire matrix  the following is the list of things done in order 
 in a large loop  read the email one by one  for each email 
 first  store its label  then for each other word in this email  take down the number of its appearance  and
store the result accordingly in its feature vector  the feature vector is a vector of all tokens  the value of
each entry of the vector is the count of the token corresponding to that entry 
 special words are replaced by tokens number  dollar  http and email 
 put all the vectors into one matrix and rearrange them into sparsed form 
 shuffle the examples  put them into random order 
 divide the examples into    groups  every time  put   of them into training examples  and the remaining
one as testing examples  as a result  we have    trainingtesting pairs 
 write the training and testing examples into files
   classification 
e did the classification usin na ve ayes and
  to compare the result of the two methods  o train and
test one class as positive examples  labeled as     we treat all other classes as negative examples  labeled as   for
nb or   for svm  and do this for every class 
    supervised classification using na
ve bayes and svm
na
ve bayes and support vector machine are applied to this project implementation  on the one hand  na
ve
bayes are quite common for email classification  which can be considered as baseline  support vector machine  on
the other hand  proves to have good performance on text categorization 
 na
ve bayes
given m examples  and each example is represented by a vector    
  to simplify just denote it as x 
assuming elements in the feature vector are independent  we can build our model by solving ml function to get
parameters 

here we can use bayes rule to decompose the right hand side of the equation  the parameters allow us to make
predictions on new data  we also used laplacian smoothing to make sure that we do not encounter   occurrence of
counts 
 support vector machine
support vector machine is achieved by building a hyper plane dividing positive and negative classes  the
optimization problem is 

fiwhere w and and b are the parameters for the model  a revised version of the optimization problem takes into
account data points that are allowed to be misclassified  non separable cases  by adding another parameter c
controlling the weightin of such error allowed  he kernel we chose for this project is a linear kernel  because it
makes no sense using higher dimension feature vector when the dimension is already very large for svm and a
linear kernel serves right for this project 
    unsupervised classification using hierarchical clustering
after getting the result from supervised classification  we found that there is an inevitable problem  labeling
can be misleading  since we do not know the ground truth of label of the emails data we have  the label are done
manually  which gives rise to a highly unreliable label of the examples because on the one hand  its difficult to stick
to some criteria in the judgment on what the label of every document is  especially there is vague or subtle
difference between one class from another for some cases   on the other hand  its hard to see the intrinsic
characteristic of some documents by just reading the email  therefore  it will be helpful to come up with some way
that allows the emails to automatically cluster themselves first and then  by assigning each cluster a label  we can do
supervised learning on them  in particular  for application we do not know the label  this is true for most cases   we
can use unsupervised learning to categorize the documents  and hopefully the result of clustering can give some
insights on the characteristic of the documents and the label for it 
the algorithms for unsupervised classification available includes k means  em algorithm  which is softer
then k means because it depends on some probability model in making estimation   factor analysis and etc  to
implement this algorithm  a high dimension feature vector makes it extremely inefficient or unreliable  therefore  to
solve this problem  we either need to decrease the dimension of feature vector  or choose some algorithm that fits
well for high dimension feature vector and text categorization  we first tried pca to decrease the dimension and
implement mixture of gaussian  only to find that mixture of gaussian fails to fit our problem because the number of
parameter scales quadratic with length of feature vector  think about the covariance matrix  
another approach to take is to use hierarchical clustering  and specifically  agglomerative clustering  this is a
 bottom up  approach  each observation starts in its own cluster  and pairs of clusters are merged as one moves up
the hierarchy      the metric can be used as closeness measurement between pair of examples includes euclidean
distance  l   and squared ed  manhattan distance  cosine similarity and etc  on the other hand  the linkage criterion
specifying dissimilarity of sets includes maximum or complete linkage clustering  minimum or single linkage
clustering  minimum energy clustering  we can try each of these metric and criteria and select the one resulting in
best performance   a review of cluster analysis in health psychology research found that the most common distance
measure in published studies in that research area is the euclidean distance or the squared euclidean distance      
the implementation is quite straightforward  we only need to construct a matrix keeping distance of each pair
in the examples and do the merging stage by stage and finally get a hierarchy of the clustering 

   results and evaluation
here were ivin the final results of our implementation of the proposed al orithm  y comparin different
methods and different feature selection  hopefully one can have a general view on how to choose appropriate
method and feature vector 
    svm vs  na
ve bayes
as we are using    fold cross validation  the evaluation metric shows the average of    sets  we give the
evaluation results for svm and na
ve bayes approaches respectively  for each approach  we give accuracy table
and precision recall curve  table   and figure    
method
label
 
 
 

svm accuracy

nb accuracy

     
     
     

     
     
     

fi 
 

     
     
    
     
table    accuracy of svm and nb

figure   precision recall curve for class     and  
the accuracy table shows that svm performs better than nb in terms of accuracy  but generally speaking  the
accuracy is not high as expected  by reading precision recall curve  svm actually has smaller area under curve than
na
ve bayes  particularly  the curve of svm is somehow parallel to diagonal of the graph which makes it far from a
good classifier 
    hierarchical clustering
among the hierarchy of clusters we generate  we are giving the fraction of examples with same label in each
cluster  table     we also tried svm on the clustered data  examples in the same cluster have the same label  
hopefully the results  figure    may give us some insight on the strange behavior of the svm precision recall curve
shown above 
for best performance  several methods and metrics are tried 
method
unweighted
centroid
furthest
shortest
inner squared
 dissimilarity
average
distance
distance
distance
distance
criteria 
distance
 upgmc 
 upgma 
metric
euclidean  l   cosine
correlation
hamming
spearman
 distance 
results show that furthest distance     cosine correlation spearman combination gives best performance 
label
cluster
examples   
   
   
   
   
   
   

 

 

 

 

 

max rate

 
 
   
 
      
  
  
  
   
  
      
 
   
 
  
  
      
   
   
 
   
   
      
   
   
 
  
   
      
 
  
 
  
   
      
table    fraction of same label examples in each cluster
its readily seen that label   is almost clustered into one cluster with percentage of over      other label
documents are clustered into more than one cluster  label   documents are the majority in two clusters  this makes
sense since we have more label   documents in the datasets 

fifigure    svm on clustered data
this precision recall curve looks better  it is highly probable that labeling the documents by hand is not reliable 
unsupervised learning can capture the nature of the documents and therefore gives clearer division between documents
cluster  another reason may be the representation method is not proper  bag of words representation may not be the
best fit for our project problem 

   future work
as the evaluation results show  there is still large margin for us to improve performance of the algorithms  this
can be done in the following aspect 
 choose different document representation  other than bag of words representation  there are other ways
representing our examples  one of the drawbacks of bag of words is that it ignores the semantic
relationship between words in the sentence  using sequences of words allows one to explore the underneath
semantic relationship  this may require some natural language analysis  on the other hand  we can always
weight different part of the document  e g  gives higher weight to subject or attachment 

ry other classification approaches  eve only tried
and na ve ayes while therere many other
algorithms proved to be feasible for document categorization  for example  maximum entropy  which
models the class conditional distribution with the most uniform one that satisfies constraints given by the
training set        wide margin winnow which is an on line learning algorithm and random forest which is a
decision tree approach 
 build more balanced datasets  the number of each class in the datasets is not balanced resulting in less
reliable training model as well as evaluation results  if the testing set examples are not balanced  just by
looking at accuracy may be misleading  to tackle this problem  we can either weight each class according
to the documents number in each class  and its not necessarily linear   or make copies of documents which
belong to the minority class 
   conclusion
in summary  by comparing different supervised and unsupervised learning methods in text classification
problems  we find that svm performs better than na
ve bayes in terms of accuracy but actually has smaller areaunder curve  possible reasons include  bad document representation choice  unreliable label by hand and improper
classification approaches  to find the reason for that  unsupervised learning methods are taken and hierarchical
clustering is selected  as is shown by the results  using hierarchical clustering to do the labeling automatically
according to the interior correlation properties of the feature vectors tells that our subjective labeling is one of the
factors that area under curve is small using svm  and the classifications by using these new labels are better  the
accuracy also could be improved by developing new feature vectors  classifiers and more balanced dataset 
reference
    bryan klimt  yiming yang  introducing the enron corpus 
    ron bekkerman  automatic categorization of email into folders  benchmark experiments on enron and sri
corpora       
    wikipedia  hierarchical clustering  http   en wikipedia org wiki hierarchical clustering

fi