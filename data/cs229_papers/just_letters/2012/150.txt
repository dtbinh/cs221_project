predicting the odds of getting retweeted
arun mahendra
stanford university

arunmahe stanford edu

   introduction
millions of people tweet every day about almost
any topic imaginable  but only a small percent of
these get retweeted  people retweet for several
reasons and psychology of why people retweet
can be complex  in general  it is safe to assume
that essentially people retweet when they find
something interesting and they want to share it
with others  the more a tweet gets retweeted the
more people know about it  a tweet is more
beneficial if it gets retweeted  knowing the odds
of getting retweeted based on the content has
useful applications  for example  including the
right words  rephrasing or including a relevant
hyperlink in the tweet can get the attention of
more people and thereby  increase the chances of
getting the message passed on further  the goal
of my project is to develop a machine learning
algorithm to predict the likelihood of a tweet
getting retweeted based on the content of the
tweet  in this paper i evaluate the performance of
supervised classifiers trained on topics derived
using latent dirichlet allocation  lda     
model from tweets 

once the data is downloaded  the tweet json
objects are processed to remove fragmented data
and extract desired attributes  the processed data
is then moved in to a hadoop hive data
warehouse  using hive simplifies many file
manipulation and organization tasks  large text
files can be easily manipulated and transformed
simply by running sql queries and this avoids
the need to write custom scripts to traverse large
text files to accomplish trivial tasks 
preprocessing tweet text
   only tweets where the user language is
set to english is used 
   common stop words are removed 
   non printable characters are removed 
   tweets are lemmatized 
   punctuations are used loosely in tweets
when compared to other  more organized
written texts  like in following example
tweet  i am soo cooooool     please
retweet       in the preprocessing all
punctuations are removed 

   acquiring and processing twitter
data

   hyperlinks
are
token url

for this project  i downloaded data using curl
and the twitter streaming api  the data is
continuously downloaded on to an amazon ec 
machine  one of the criteria for using the twitter
streaming api is that at least one keyword must
be tracked and capture tweets containing those
words only  in order to get a large set of diverse
tweets  i began by tracking most commonly used
words like the  a  at  then  what 
when rt etc  for a targeted study  i also
downloaded tweets made by a single user and
his her followers over the course of few weeks 

   all text is converted to lower case

replaced

with

   method
unlike large structured texts  twitter data poses
unique challenges for developing machine
learning algorithms  tweets in general are very
casual form of writing  spelling errors are
abundant in tweets  words are often arbitrarily
stretched to emphasize a point of speech or
abbreviated to fit into short sentences  as humans
we can read and understand the tweets easily but
for machine learning it makes the problem more
challenging  tweets make a lot of sense when put

fiinto a context  some of these are global contexts
which most people understand  while others
make sense only to a select group of people 
in this project  i use lda to generate topics from
retweeted tweets  to illustrate discovering topics
from tweets  consider the following set of tweets
that was acquired from random users using the
twitter streaming api on the night of the     
vice presidential debate  lda algorithm was run
with each tweet as a document and the
vocabulary used was created from the same set of
documents  the following is the average inferred
topic proportion for the retweet dataset 

figure    interconnection of twitter users to their
followers and friends
to predict the odds of a tweet getting retweeted
by the followers  the learning algorithm should
model the retweeting behavior of the followers 
this can be accomplished using a supervised
learning algorithm 
in order to train a supervised learning algorithm 
the tweets must be labeled  i use the following
simple metric to assign positive and negative
classes to tweets in my dataset 

figure   shows the topic distribution on arbitrary
set of retweets from random set of users  for a
single twitter user  a tweet must be first retweeted
by the users immediate followers before it can
be retweeted by anyone else  by discovering and
then learning topics that a users followers often
retweet  the algorithm can attempt to predict
chances of a new tweet getting retweeted  using
twitter streaming api  only tweets  and retweets 
sent out during that time can be captured  tweets
sent out by a user previously cannot be acquired 
twitter users are interconnected to their followers
and friends  a users tweets are received only by
their immediate followers  the followers can
further retweet them to their followers  a users
followers also receive tweets from other people
they are following 

let set of tweets                     be the
complete set of training examples 
let
the
followers
                 

of

user



be

let the number of times tweet  is retweeted by
the followers  be   
let the life span of a tweet be
   max time   origin time 

then  retweet rate   





the retweet rate gives a simple metric to gauge
the importance of a tweet to a set of followers 
the labels are assigned to each tweet by using the
distribution of this rate among a set of followers 
a positive label is given to tweets with high
retweet rate  a negative label is given for tweets
with a low retweet rate  this means that it has
been retweeted only a few times in a long period
of time 

fiposterior dirichlet parameters  are computed for
the training data set  i for each document di is
used as input features for training linear support
vector machine and logistic regression model 
the following figures       show the
performance of the svm and logistic regression
trained on the topics generated by the lda on
the labeled tweets respectively 
figure  
lda svm test   train percent
   

positive label clearly indicates popularity
whereas  in contrast  tweets labeled negative
could mean either the users in set u did not want
to retweet i or simply fewer users in set u
actually received tweet i and thus resulting in
low rate of retweet 

  
percent

figure    tweets with retweet rate      are
labeled as negative and tweets with rate      are
labeled as positive

  
  
  
 
                              
number of topics

figure  

   feature extraction and classification

lda logistic regression test   train percent
   

test
percent

  
percent

there are several supervised text classification
methods available in the literature such as     
             in this paper i evaluate two layered
classification methods  lda logistic regression

and lda svm   i also propose a variation to
lda svm method to factor in the labels 
in lda svm method  lda model is used to
generate topics from a text corpus and these
topics are provided as input features to train svm
for classification 
to empirically evaluate these models  i use the
test dataset containing       tweets  acquired and
processed as described in the previous section  a
balanced set  consisting of equal number of
positive and negative examples  of m labeled
tweets are randomly selected  out of this      of
the data is used for training and     for testing 
for a k topic lda model  consider a tweet as
document di in corpus c    d    d    d       dm    
the size of the total dataset is m  vocabulary v is
derived from the corpus c  the lda model is
trained on the corpus c and then the variational

test
percent
train
percent
true
positive
false
positive
false
negative
true
negative

train
percent

  

true
positive

  

false
positive

  

false
negative

 
                              
number of topics

true
negative

number of training examples used      
one of the drawbacks of this method  as noted in
the literature     is that lda is a generative
model and the topics inferred using this
unsupervised process may not be the ones that
best represent the labels  this means that labels
are not factored into the topic generation process 

fii propose a variation to this two layered method
in order to factor in the labels  for the case of
binary classification  the idea is to train two lda
models  one on each corpus  negative corpus and
positive corpus separately  compute two sets of
variational posterior dirichlet parameters
          for positive and negative documents
respectively  also  cross compute  for positive
training examples using lda trained on negative
set and vice versa  let the resulting parameters be
called   n      p    combining the topics from
            the following is defined 
topic set t  
       
   
       
 t    t     t n   t n     t k  
topics generated by lda model using positive
and negative datasets are represented by
superscript     and      respectively  m is the total
number of training examples
   

   

   

percent

   

   

   

    

    

    

    

    

  

cross inferred topics lda svm test  
train percent

test
percent

   discussion and conclusion
lda logistic
regression
and
lda svm
performed roughly about the same  their
performance peaked at     topics with    
accuracy  the cross inferred topic lda svm
performed worse than both these methods on all
topic counts on the test sets  on the training set it
fit the data almost as good and in some cases
better than lda logistic and lda svm  the
better fitting of training data suggests that cross
inferred topic lda svm is over fitting the data
and therefore  has high variance  it should be
noted that in this study only a small number of
tweets were used  cross inferred topic lda svm
could possibly perform better on a large training
set  this can be explored in future work 
given the nature of tweeting  a set of randomly
acquired tweets can have high density of topics 
accuracy of labeling can have significant effect
on the performance of supervised classifiers  the
simple labeling metric used in this study can be
improved  twitter data comes with a variety of
auxiliary data that includes various user specific
information such as friends  follower count 
profile
description 
personalized
settings
information  geo location etc  some of these can
be used to create labels or even used as input
features for classification 
in order to predict the odds of getting retweeted
with greater accuracy  the next phase is to
explore non linear supervised classifiers  this
work has laid foundation for future work 

  

train
percent

 in this project  svm and logistic regression

  

true
positive

was implemented in python using scikit learn    
and lda algorithm using gensim    

  

false
positive

  

false
negative

 
                              
number of topics

true
negative

   references
    perotte 

adler  et al   hierarchically
supervised latent dirichlet allocation  neural
information
processing
systems
 to
appear         

fi    blei  david m   and jon d  mcauliffe 

 supervised topic models   arxiv preprint
arxiv                  
    blei  david m   andrew y  ng  and michael
i  jordan   latent dirichlet allocation   the
journal of machine learning research  
                 
    quercia  daniele  harry askham  and jon
crowcroft   tweetlda  supervised topic
classification and link prediction in
twitter   proceedings of the  th acm
international conference on web science
 websci        
    ramage  daniel  christopher d  manning 
and susan dumais   partially labeled topic

models for interpretable text mining  
proceedings of the   th acm sigkdd
international conference on knowledge
discovery and data mining  acm       
    pedregosa  fabian  et al   scikit learn 
machine learning in python   the journal of
machine learning research           
    ehek  radim  and petr sojka   petr 
software framework for topic modelling
with large corpora   proceedings of lrec
     workshop new challenges for nlp
frameworks       

fi