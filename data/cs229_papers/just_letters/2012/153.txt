stanford cs     project

 

handwritten character recognition in ancient
manuscripts
peter kajenski
abstractthe eigenface method is a technique that has been
widely used for facial recognition algorithms  the method relies
on the use of a one dimensional singular value decomposition
 svd   but recently it has been argued that a two dimensional
svd would be more effective  in this study  both methods were
applied to a handwritten character recognition problem  the two
methods yielded similar accuracy rates  but in some applications
the two dimensional svd may offer some computational advantages 
index termssingular value decomposition  handwritten
character recognition  support vector machines

i  i ntroduction
facial recognition is currently an active area of research 
and one technique that has frequently been used for this
application is the eigenface method      eigenfaces are created
from a set of two dimensional training images that have been
vectorized  and then a singular value decomposition  svd 
is applied to the data set  the eigenvectors associated with
the most significant principal components are retained  and
thus comprise the eigenfaces  a two dimensional singular
value decomposition   d svd  algorithm has recently been
described in the literature  which is a generalization of the
well known svd      in     the properties of the  d svd
were defined  and it was demonstrated that it can be used
to improve the accuracy of a facial recognition algorithm 
as well as offer better compression of image data sets than
would be the case with the conventional svd  given that
written texts are two dimensional in nature  it is only natural
to ask whether a  d svd would offer any benefits for the
handwritten character recognition problem 
the problem of handwriting recognition have been studied
for many years         and several such algorithms have been
incorporated in commercialized products       handwriting
recognition can be broadly classified as either an online
problem  whereby the writers pen strokes can be used to
assist in the classification process  or an offline problem 
where only the written characters themselves are used  of
particular interest in this study are ancient manuscripts which 
of course  were written by hand  the first step to analyzing
such documents is to implement an algorithm that can record
the individual characters  and put them into a digital form that
a machine can manipulate 
during the period from about     bce until about     ce 
many western documents were written in a style known as
scriptura continua       which roughly translates to continuous writing  this style of writing is typically characterized
by the use of uncial letters  all upper case   with no spacing
between the words  and with little or no punctuation indicating
the beginning or end of a given sentences 
p  kajenski is with the raytheon company      lowell street  andover 
ma        usa e mail  kajenski raytheon org
manuscript received december         

for this particular effort the codex sinaiticus manuscript
was chosen  as it has a number of features that make it
convenient for study  it is believed that codex sinaiticus was
written somewhere between the years     and     ce  and it
is perhaps a little unusual in that while it was written in the
continua scriptura writing style  the characters are organized
in distinctive columns and rows       codex sinaiticus is
currently held in four separate libraries  which are in entirely
different countries  in      the components of the document
were reunited in a virtual manner  and it is now available on
the internet             the website provides photographs of
the actual manuscript itself  as well as a transcription of the
greek text  thus providing an experts opinion on the identity
of each individual character 
character recognition algorithms can provide scholars with
a new set of very powerful techniques for studying ancient
documents  for example  it may offer the ability to ascertain
something about the scribes who drafted the manuscript  it
is believed that at least three scribes participated in writing
codex sinaiticus  although some contend that a fourth was
also present  and there were also numerous corrections to
the manuscript made by later editors       most character
recognition algorithms are designed to be able to recognize
a given letter  independent of who the author may have been 
in this kind of application it would actually be more helpful
to have an author dependent character recognition algorithm 
one that could distinguish between the letter  written by
two different scribes  such a tool could help estimate how
many writers helped produce the document  who wrote what
sections  and perhaps even suggest how many different editors
may subsequently altered it  further  handwriting analysis
tools might even permit scholars to determine what other
extant manuscripts a given scribe might have worked on 
in section ii a brief overview of the svd algoirhtms are
given  in section iii the application of the two svd algorithms
to obtaining the principal components from the character data
will be described  and experimental results using a support
vector machine  svm  will be presented  finally  in section
iv conclusions will be given 
ii  s ingular value d ecompositions
a  the  d svd
we begin by describing the application of a one dimensional
svd for character recognition  this generally entails converting a given image into a single vector  starting with n images
of size h  w  one creates a vector of size  d   hw  and each
is placed into a set                  n    a zero mean vector is
computed as i   i    where 

 

n
  x
i
n i  

   

the one dimensional covariance matrix  c   is defined as 
c 

n
  x
i ti   b b t
n i  

   

fistanford cs     project

 

where b                n    then c can be decomposed using
a svd as 
c  u v

   

where u and v  are unitary matrices  and  is a diagonal
eigenvalue matrix 


      
 
    

  


   
   
 
   
 
  
  
   
  
 



 

n

b  the  d svd
the description of the  d svd presented here largely
follows that in      we start by defining averaged row row
and column column covariance matrices 
n
x

t
a a i  a
a
f  
a i  a
i  
n
x

g 

a
a i  a

t

a
a i  a



   

i  

p
a   n  i a i   we perform a  d svd on both f and
where a
g   to create a matrix u r which contains the r eigenvectors of
f   and a matrix v s corresponds to the c eigenvectors of g  
accordingly  we have 

f  

r
x

 u  u t   

   
c
x

g 

 v  v t   

   

   

where   and   are the  th eigenvalues associated with f and
g   respectively  we define an eigenmatrix for a given image 
a i as 
mi   urt ai vc  

i              n 

b for the letter  
the computed vector 

the classification was performed with the libsvm support
vector machine routine       which was configured in a oneversus all  ova  manner       each character image was
made up of       pixels  and the  d svd and  d svd
algorithms were used to reduce the images to their principal
components  for the  d svd  the approach used to preprocess the images was similar to the method used for facial
b g    u
u            ug   
recognition  a subset of eigenvectors  u
associated with the largest g eigenvalues were used to convert
the vectorized character image into the test data space as 
b t n
bn   u

g

u            u r   
u r   u
v c   vv             v c   

fig    

   

where m i forms a matrix of eigenvalues  note that unlike
in the  d svd case where  is a diagonal matrix  m i is
not constrained to be diagonal  the a i matrix can then be
recovered by 
a i   ur mivct
   
iii  e xperiments
pages from the book   timothy chapter   in the codex
sinaiticus manuscript were downloaded from the internet  and
the color images were submitted to a threshold to convert them
into binary data sets  a bounding box routine was used to
identify potential characters  characters that overlapped each
other were excluded from the set  but any fragments from
other characters that may have leaked into the bounding
box were allowed  and noisy and faded images were also
included  the frame size for each character was      pixels 
and each character was centered in the frame  a data set of
approximately       character images were collected and used
in these experiments 

   

similarly  transforming the character images into the testdata spaces with the  d svd involved using a subset of the
u p    u
u            up    v
vq  
eigenvectors computed in      u
 vv            vq    with p  k  q  s  for the nth character
image  a n   this is given as 
m   upt anvq

    

figures   and   show representative examples of the magnib and m for the letter  
tudes of 
b n   and the matrix
the elements in the transformed vector 
terms from m were used as inputs into the svm  the
problem at hand now is how to make a fair comparison of the
performance of the  d svd and  d svd  it was reasoned
that if these algorithms were to be used in a practical system 
the end user wouldnt be at all concerned with how long to
takes to train the system  rather  what would matter would
be the time needed to classify all of characters in the test
data  accordingly  it decided to compare the classification
accuracy of each  for a given average execution time  this
approach immediately gave rise to an observation regarding
the computational speed of the two pre processing algorithms 
which was found experimentally to be proportional to the
number of multiplication steps  as noted above  the images
were        pixels  and so if we used the eigenvectors
associated with the g highest eigenvalues  then the number
of multiplication steps needed for the application of     to the

fistanford cs     project

 

fig     the number of multiplies for the  d svd  solid line  and the number
of multiplies fo the  d svd  dashed line   as a function of the number of
input points 
fig    

the magnitude of the matrix m computed for the letter  
table i
c lassification u sing a l inear k ernel svm

size
  
  
  
  

 d svd
time  s  accuracy    
      
     
      
     
      
     
     
     

size
  
  
  
  

 d svd
time  s  accuracy    
      
     
      
     
      
     
     
    

table ii
c lassification u sing a s econd o rder p olynomial k ernel svm

size
  
  
  
  

 d svd
time  s  accuracy    
      
     
      
     
     
     
     
     

size
  
  
  
  

 d svd
time  s  accuracy    
      
     
      
     
      
     
      
    

fig     the execution times for the  d svd  solid line  and the number of
multiplies fo the  d svd  dashed line   as a function of the number of input
points 

vectorized image would require 
n    g      

    

in contrast  if we use p eigenvectors for the construction of
up   and q for v q   the number of multiplications  n    needed
to construct mi would be 
n    p           p      q

    

figure   shows plots of the number of multiplication steps
for n   solid line  and n   dashed line   as function of the
number of input parameters  note that these trends depend on
the dimensions of the image  and the difference between n 
and n  would be even more pronounced for larger images 
approximately     of the characters were randomly selected to be used in the training set  and the remaining
     were used for testing  first  a forward search was
conducted to determine the classification accuracy for different
combinations and numbers of input parameters  this step was
repeated for a linear kernel  a radial basis kernel  as well as
higher order polynomial kernels  it quickly became apparent
that the best classification accuracy was obtained for the linear

fig     the execution times for the  d svd  solid line  and the number
of multiplies for the  d svd  dashed line   as a function of the number of
input points 

fistanford cs     project

 

table iii
c onfusion m atrix for  d svd  p olynomial k ernel

a
c
t
u
a
l

a


h
k

m
n
o


a
   
 
 
 
 
 
 
 
 
 


 
  
 
 
 
 
 
 
 
 


 
 
  
 
 
 
 
 
 
 

predicted
h
k
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 


 
 
 
 
 
  
 
 
 
 

m
 
 
 
 
 
 
  
 
 
 

n
 
 
 
 
 
 
 
  
 
 

o
 
 
 
 
 
 
 
 
  
 


 
 
 
 
 
 
 
 
 
  

table iv
c onfusion m atrix for   d   svd   p olynomial k ernel

fig     the total number of support vectors for the one versus all classification scheme     svm classifiers   the upper plot shows the cases for the
 d svd  with a linear kernel  solid line  and the second order polynomial
kernel  dashed line   the lower plot shows the same result for the  d svd 

and second order polynomial kernels  once the accuracy rates
were established  a timing study was conducted in which the
classification task was repeated     times  and the execution
times for all of the runs were averaged  the results from the
 d svd and  d svd were then paired according to execution
time  the results for the case where a linear kernel was
used are shown in table i  and those for the second order
polynomial kernel are shown in table ii  the size parameter
indicated for the  d svd represents the first g eigenvectors
used in      and the size indicated for the  d svd represents
the first p  q eigenvectors from       overall  both methods
yield comparable accuracies for the given execution times 
the execution times for the linear kernel svm were plotted
in figure    and it was noted that the trends generally followed
the pattern in figure    the execution times for the second
order polynomial kernel svm were plotted in figure    which
quite strikingly  did not at all follow the expected trends 
suggesting that complexity of the classification algorithm
dominates for the higher order kernel  it was noted in     
that the computational
complexity of the svm is of the order

o n   m   where n is the number of input points and m is
the number of support vectors  this suggests that while some
speed advantage may be afforded by the fewer multiplication
steps needed for the  d svd  the advantage could be entirely
lost if it comes at the expense of an increase in the number of
required support vectors  figure   show plots of the total sum
of the number of support vectors  for all    of the character
classifiers in the ova code  as a function of the number of
input points  the upper plot shows the results for the  dsvd  with a linear kernel  solid line  and with a second order
polynomial kernel  dashed line   the lower plot shows the
same result for the  d svd  the number of support vectors
evidently increases considerably when going from a linear
to a second order polynomial kernel  and generally seems to
increase with the number of input points 
to gain a better insight as to the differences in performance
of the classifiers  confusion matrices      were created for the

a
c
t
u
a
l

a


h
k

m
n
o


a
   
 
 
 
 
 
 
 
 
 


 
  
 
 
 
 
 
 
 
 


 
 
  
 
 
 
 
 
 
 

predicted
h
k
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 


 
 
 
 
 
  
 
 
 
 

m
 
 
 
 
 
 
  
 
 
 

n
 
 
 
 
 
 
 
  
 
 

o
 
 
 
 
 
 
 
 
  
 


 
 
 
 
 
 
 
 
 
  

second order kernel case where g      for the  d svd  and
for the case where p   q     for the  d svd  as indicated
in table iv  note that these tables are abbreviated due to
space limitations  and only show half of the characters used
in the study  characters that were entirely error free were not
included in these matrices  but were included in the accuracy
computations  from these tables it is clear that there was
some difficulty with sorting the letters      and a 
to investigate the nature of these errors  an experiment was
run in which the character images were reconstructed using
the eigenvectors and eigenmatrices  as shown in figure    the
image on the top left is the original image  the top center
image is the reconstruction of the image using the first   
eigenvectors of the  d svd  and the top right image is the
reconstruction using     with p   q      the bottom row
shows the case where    eigenvectors were used for the  dsvd  and a      eigenmatrix was used for the  d svd  in
this latter case it appears that the  d svd does a somewhat
better job of reconstructing the original image  though both
methods yield similar classification accuracies in the svm 
iv  c onclusion
the  d svd has been used for solving recognition problems for many years  and has proven to be quite effective
in many applications  the  d svd has been found to also be
effective for handwritten character recognition  and in fact may
potentially offer some computational advantages over the  dsvd  however  the advantages for the  d svd can be lost if 
as a consequence of using it  it imposes a higher computational
burden on whatever classification algorithm is used  in the
experiments described here the performance of both the  dsvd and  d svd were comparable 

fistanford cs     project

 

machines  ieee transactions on neural networks  vol      pp      
          
     l  kaufman  advances in kernel methodssupport vector learning  c  b 
b  schlkopf and a  smola  eds  mit press       
     s  stehman  selecting and interpreting measures of thematic classification accuracy  remote sensing of environment  vol      p             

fig     the figure on the top left is the original image the top center image
is the reconstruction of the image using the first    eigenvectors with the
 d svd  and the top right image is the reconstruction using     with p  
q     the figure on the bottom left is again the original image the bottom
center image is the reconstruction of the image using the first    eigenvectors
with the  d svd  and the bottom right image is the reconstruction using    
with p   q     

r eferences
    m  turk and a  pentland  face recognition using eigenfaces  in
computer vision and pattern recognition        proceedings cvpr
     ieee computer society conference on  jun       pp          
    c  ding and j  ye  two dimensional singular value decomposition
  dsvd  for  d maps and images  in proc  siam intl conf  data
mining  vol  sdm          p       
    r  alhajj and a  elnagar  multiagents to separating handwritten connected digits  systems  man and cybernetics  part a  systems and
humans  ieee transactions on  vol      no     pp            sept 
     
    t  artieres  s  marukatat  and p  gallinari  online handwritten shape
recognition using segmental hidden markov models  pattern analysis
and machine intelligence  ieee transactions on  vol      no     pp     
     feb       
    d  ghosh  t  dube  and a  shivaprasad  script recognition  a review 
pattern analysis and machine intelligence  ieee transactions on 
vol      no      pp             dec       
    a  graves  m  liwicki  s  fernandez  r  bertolami  h  bunke  and
j  schmidhuber  a novel connectionist system for unconstrained handwriting recognition  pattern analysis and machine intelligence  ieee
transactions on  vol      no     pp           may      
    r  jayadevan  s  kolhe  p  patil  and u  pal  offline recognition of
devanagari script  a survey  systems  man  and cybernetics  part c 
applications and reviews  ieee transactions on  vol      no     pp     
     nov       
    j  park  an adaptive approach to offline handwritten word recognition 
pattern analysis and machine intelligence  ieee transactions on 
vol      no     pp           jul      
    j  zeng and z  q  liu  markov random field based statistical character
structure modeling for handwritten chinese character recognition  pattern analysis and machine intelligence  ieee transactions on  vol     
no     pp           may      
     r  plamondon and s  srihari  online and off line handwriting recognition  a comprehensive survey  pattern analysis and machine intelligence  ieee transactions on  vol      no     pp         jan      
     b  metzger and b  d  ehrman  the text of the new testament  an
introduction to the critical editions and to the theory and practice of
modern textual criticism  oxford university press       
     e  henschke  digitizing the hand written bible  the codex sinaiticus 
its history and modern presentation  libri  vol      p             
     z  m  dogan and a  scharsky  virtual unification of the earliest
christian bible  digitisation  transcription  translation and physical
description of the codex sinaiticus  european conference on digital
libraries       
     c  chang and c  lin  libsvm  a library for support vector machines  acm transactions on intelligent systems and
technology  vol     pp                   software available at
http   www csie ntu edu tw  cjlin libsvm 
     c  l  c  hsu  a comparison of methods for multiclass support vector

fi