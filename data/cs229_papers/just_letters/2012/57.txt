negative news no more 
classifying news article headlines
karianne bergen and leilani gilpin
kbergen stanford edu lgilpin stanford edu
december         

 

introduction

the goal of this project is to develop an algorithm that will classify a news article headline
according to how positive or uplifting that news story is  the algorithm should be able to
distinguish between positive story baby elephant rescued in kenya with rope and a land
rover  and negative headline firms on alert for letter bombs  the algorithm will also
identify as neutral those stories that are neither strongly positive or negative  e g  ipad
changing how college textbooks are used    the focus is on classifying the content topics of
the articles as positive negative rather than the attitude of the author toward the subject 
since news articles are typically written in an objective style 
   

data collection and data set

for this task we collected two data sets  the first is a set of      news article headlines 
the second is a set of      news article headlines with short text excerpts from the article
 typically the first     sentences of article text   most of the data samples were extracted from
rss feeds over several weeks during fall quarter       we did not include stories collected on
election day  as these stories were repetitive and overwhelmingly neutral  strongly polarizing
headlines are classified as neutral   the sources of the news feeds include google news  cnn 
bcc  fox news  and the new york times  we included headlines from a pre existing data
set consisting of headlines from news websites in           in order to avoid a skewed data
set  we obtained many positive headlines from     and      our final data sets are roughly
evenly divided between the three classes  with each class representing        of the samples
in each data set  the positive neutral negative split is                 for headline plustext data  and                 for headline only data 
each data sample  corresponding to a single news article  was assigned to one of three
classes  positive  negative  or neutral  the data samples were classified by the two
project team members  articles were classified as positive if they featured a happy  inspiring  funny  or uplifting topic  articles classified as negative typically include themes of
violence  crime  natural disasters  and loss of life or property  articles that did not strongly
fall into either category  including polarizing articles  e g  on controversial or political subjects   were classified as neutral  see table   for examples  

 
   

method
feature extraction

we use a bag of words model for headline classification  one set of features was generated for
each of the two data sets  each feature set was based on a dictionary of words extracted from
the headline  and text excerpt  data  features represent individual word fragments  tokens  
with an additional feature indicating whether a numeric value appears in the headlines  the
feature set excludes stop words  e g  about  over  with   suffixes were removed  both

fiautomatically and manually  from dictionary words to create the list of tokens appearing in
each data set  the feature set for the headline only data includes      features       tokens 
  numeric  and the feature set for the headline plus text data includes       features       
tokens    numeric  
   

news article classification

for news article classification  we used both naive bayes and support vector machine  svm 
classifiers      of the data was used for training and cross validation and     for testing 
the training test sets included           samples for headline only data and         
samples for headline with text data      of the training data      of the total data set 
was used for cross validation 
   

naive bayes

we used two different naive bayes models  one models the thee classes  positive  negative  and neutral  while the other models two classes  positive and negative  and uses
a threshold parameter to define the neutral class from this model  both the two class and
three class naive bayes classifiers use a multinomial event model with laplace smoothing 
our initial attempts using a two class naive bayes classifier involved mapping multiple
results to a single class prediction  we trained separate classifiers for positive vs  nonpositive  negative vs  non negative and neutral vs  non neutral  however  this method had
limited success  as discrepancies among the three predictions for a single sample degraded
performance of the method 
our successful use of the two class naive bayes classifier attempts to exploit the fact
that the neutral class represents an intermediate class between positive and negative  in
our two class model  the data set was trained on positive and negative samples only 
disregarding the neutral examples  the prediction for the neutral class is based on a
thresholding scheme  if the difference in posterior probabilities for the positive or negative
classes is below a specific threshold for a given test sample  it will be classified as neutral 
the best thresholding method  absolute difference of log probabilities  and the threshold
value      and     for headline and text and headline only  respectively  were selected using
hold out cross validation 
the three class naive bayes classifier was the most successful classifier for our classification problem  one of the model parameters we experimented with was a weighting scheme
for words that appeared in the headline as opposed to those in the text excerpt  since the
headline generally contains the most pertinent keywords relating to the articles content  we
wanted to take advantage of the distinction between the headline and text excerpt data  in
this model  the frequencies of words appearing in the headline are multiplied by a weight
    and frequencies of words in the text excerpt are weighted       we used hold out
cross validation to select the optimal value of   however we found that varying the weighting
factor  did not have a statistically significant impact on the accuracy of the classification 
therefore  the unweighed frequencies        were used in our model 
   

support vector machine

we also used a support vector machine classifier with a linear kernel  implemented using the
spider for matlab library      initially  the svm did not include regularization  as a result
the classifier tended to over fit the training set and have an accuracy roughly     lower than

 

fithat of the three class naive bayes  therefore  we introduced regularization via soft margin
parameter  c  we used hold out cross validation to select the parameter value  c       and
c        for headline only and headline with text data respectively 
   

feature selection

we also tried using feature selection to improve algorithm performance  we used a filter
feature selection method  using the mutual information measure to score the features  we
then applied hold out cross validation to select the optimal number of features  the result
was that for both the naive bayes and svm classifiers for each data set  the best performance was obtained if the full features set was used  we did find however  that the marginal
improvement of features was relatively small after roughly     of the features with largest
mutual information scores were included in the features set  thus we found that the number of features can be reduced by     with a    loss in accuracy and      increase in
positive negative errors 
   

performance metric

one of the difficulties of categorizing news stories as positive  negative or neutral  is that
these class distinctions are relatively subjective  especially for the neutral label  for this
application  we are most concerned with our algorithm correctly differentiating between
positive and negative stories 
in assessing the performance of the algorithm  we divide the results into three cases  exact match  neutral error  and positive negative error  exact matches represent
test samples for which the predicted class is identical to the ground truth class  neutral
errors represent test examples that are either incorrectly predicted to be in the neutral
class  or are neutral samples that have been incorrectly predicted as positive or negative 
positive negative errors represents test samples for which the ground truth class is either positive or negative and the algorithm predicts the sample belongs to the opposite
class  to measure algorithm performance  we use the percentage of exact matches and
positive negative errors in the test set 

 

results

in our milestone  diagnostics showed that our algorithm performance may be improved
with more data  either more headline samples or more text per article   figures   and  
show that the accuracy of the three class naive bayes levels out and no longer improves
significantly for larger training sets  therefore  while we observe that the results still show
moderate bias  we do not believe that the current performance is limited by the size of our
data set 
a comparison of the performance for different classifiers is shown in tables     and
figures   and    figures   and   indicate that three class naive bayes has the best performance on both data sets  three class naive bayes has            accuracy          
positive negative error on headline and text headline only data  the second best performing method for headline only data is two class naive bayes with       accuracy and     
positive negative error  the regularized svm was the second best performing method on
headline and text data with       accuracy and      positive negative error  generally 
the classification of headline and text news data has greater accuracy than the classification
of headline only text  when text data is included  accuracy improves by      for a given
classification algorithm 
 

fifigure    accuracy vs training set size
for headline only news articles       test
samples

figure    accuracy vs training set size for
headline and text news articles      test
samples

figure   
classification of
headline only
news
articles 
     test samples

figure   
classification of
headline and text news articles 
    test samples

tables     show the results of three different classification schemes on the headline withtext data  each entry in the table corresponds to the number of test samples  out of a total
of          positive      neutral      negative   that fell into each category  green denotes
an accurate prediction  yellow denotes errors in the classification of neutral articles  and
orange denotes the more significant positive negative errors  tables   and   indicate similar
performance trends for three class naive bayes and regularized svm classifiers 
the best accuracy achieved by our classifiers is around     for headline and text data 
and     for headline only data  while this still leaves a substantial number of misclassifications  the positive error rate is roughly    and thus the majority of the incorrect predictions
involve the neutral class  however  as discussed above  such errors are likely related to the
subjective class definitions  as a baseline  an experiment in which     articles  headlineswith text  were independently classified by two different individuals indicated that human
classifications match for roughly     of news articles  including a      disagreement on
positive and negative classes   therefore  the algorithm performance is roughly on par with

 

fitrue    
true  o 
true    

   
   
  
  

output
 o     
  
  
      
      

table    svm with regularization

true    
true  o 
true    
table   
bayes

   
   
  
  

output
 o     
  
  
      
      

  class naive

true    
true  o 
true    

   
   
  
  

output
 o     
  
  
  
  
      

table      class naive
bayes with thresholding

human performance in this task 
table   includes examples of classification results for the three class naive bayes on
headline with text data  this gives a sense of the types of headlines for which the algorithm
performs well and the types of class ambiguities that exist due to the subjective nature of
the classification 
true    
true o 
true    

output    
aviators give puppies a
second chance
afghan opium harvest
down sharply
with a friendly face 
china tightens security

output  o 
breeze through tsa security
during the holidays
californias housing market
sees mixed recovery
zombies attack vip
in california

output    
doc helps others
after losing son
congress looks at ways
to raise taxes
french citizen kidnapped
in mali

table    headline classification output

 

conclusion and future work

given the subjective nature of our classes  future work may involve creating more personalized recommendations of positive and negative stories based on the users preferences 
we also hope to use our algorithm to create a web application that filters article feeds to
bring the users only happy and uplifting new stories for when theyre having a bad day  we
plan to make our data set publicly available for the machine learning community 

references
    sriram  bharath  fuhry  david  et al  short text classification in twitter to improve
information filtering sigir     proceedings of the   rd international acm sigir
conference on research and development in information retrieval  pp               
    strapparava  carlo and mihalcea  rada  dataset for emotions and or polarity orientation  semeval        th international workshop on semantic evaluations       
    great news  http   www greatnewsnetwork org 
    huffpost good news  http   www huffingtonpost com good news 
    spider for matlab  library   http   people kyb tuebingen mpg de spider 

 

fi