final report   smart and fast email sorting
antonin bas   clement mennesson

 

projects description

some people receive hundreds of emails a week and sorting all of them into different categories
 e g  stanford  studies  holidays  next week  internship  friends  graduate activities  can be timeconsuming  most email clients provide a sorting mechanism based on rules specified by the user  
senders email address  key words for the subject    the aim of this project is to develop a machine
learning algorithm which would learn from the manual sorting of emails by the user in order to
quickly be able to handle itself the processing of new emails 
we do not want to have to wait for the user to label a sufficiently high number of emails in
each category before being able to make a prediction  we are therefore looking to implement an
online learning algorithm  which will make a prediction for each incoming email as soon as it arrives
 even for the first ones  even though the tentative labelling is likely to be erroneous   however  the
algorithm will not display its prediction to the user and move the email to a specific folder unless
it is confident in its prediction  indeed  an application which frequently mislabels email or worse 
loses important emails by mistakenly placing them in a garbage folder rarely consulted by the
customer  is just not worth using  an interesting part of the project is therefore to evaluate the
degree of confidence of the algorithm in its prediction 
it is interesting to note that at least one open source solution  popfile  already exits which
fullfils this task  popfile is an email proxy running naive bayes  which inserts itself between the
email server and the email client  however  it is our opinion that popfile is not well adapted to
webmail clients   the user has to run popfile as a daemon on a machine which remains on  if
the machine is turned off  then the email does not get sorted anymore  which prevents mobile only
internet users to sort their email with popfile  therefore  one of our goals will be to develop an
email sorter which uses as few computing ressources as possible  such a product may be able to run
directly on web servers  and could be used directly by webmail providers 

 
   

email processing
tokenization

an important part of our work was to obtain well formated data on which to test our algorithms 
we have developped an email retriever   tokenizer   labelling tool  with a user interface  ui  
email retriever we connect to a given imap email server  in our case gmail  using oracles
javamail api  and retrieve the inbox content 
labelling the downloaded emails are displayed one by one via the ui to the user  which can choose
to give them a label or to leave them unlabelled
tokenizer an email can have different content types   text plain  text html or multipart alternative 
when for example it combines a text plain and a text html representation of the same message  our tool only supports emails with at least one text plain part  which is the part we
use for the tokenization  and is sufficient for our tests  furthermore  most email clients tend
to include a copy of the original email when you choose the reply option  we have choosen to
discard this copy from our input   for now  we consider that having the same subject is a good
enough indication that two emails are related  and that the extra information is not needed 
for the tokenization  we use the stanford log linear part of speech tagger  which includes a
stemming algorithm  we discard ponctuation tokens  web addresses and email addresses are
 

firespectively replaced by tokens ht t p addr domain and em ailaddr domain  where
domain is the domain name for the web   email address  the mails subject  as well as the
recipient and senders addresses are also tokenized  the final output is a one line text file  per
mail  containing the label  and the number of occurences of each known token  since we want
to design an online learning algorithm  the representation of an email does not have a fixed
length   each incoming email is likely to increase the number of known tokens and thus the
length of an email representaion 

   

other features

there are several features one could select instead to lower the dimension of the problem  such
features include for instance   the size of the email  the number of receivers  the time period when
it was sent    using these features as regressors  one could expect to obtain results using supervised
learning techniques  however  the loss of information is huge since the actual content of the email is
never taken into account  email tokenization seems a better approach  besides  it is always possible
to identify the most relevant tokens for a particular category  and only feed those to the algorithm 

 

description of the data sets

the algorithms presented are tested with two different data sets obtained from one of our gmail
boxes 
the table below shows the distribution of the data sets   number of categories  total number of
emails  proportion of unlabelled emails  no label given by the user   average number of emails per
category  lower   higher number of emails in one category 
data set
 
 

nb of categories
  
 

nb of emails
   
   

unlabelled
           
         

average number
    
     

lower
 
  

higher
   
   

table    distribution of the data sets
the first data set specifies    very specific categories  with sometimes very few emails per category 
for the second data set  we have tried to simplify the task of the classifier   there are fewer categories 
and more emails per category  for both data sets  it would be impossible to define objective criteria to
sort the emails  i e  gmail current sorting model using user defined categories could not be applied 
given the gmail box we consider  these data sets are both reasonable email allocations  we do
not try to fool the algorithm by wrongly labelling some emails  this way  we make sure there is
no bias in data selection and that we are able to analyze the different behaviours of our algorithm
accurately  we want to insist on the fact that there are unlabelled emails each time  which means we
do not want to sort the inbox completely  as we assume most users do not 

 

error and hesitation

each data set contains emails the user does not want to classify  consequently  we distinguish
between error and hesitation and introduce some criterion to measure the degree of confidence of the
algorithm in his prediction 
error   the algorithm makes a prediction for the email category or box  which it is confident about 
but the prediction is wrong   the email ends up in the wrong category or receives a label whereas
the user did not want it labelled  the algorithm should try to minimize the number of errors 
as an important email could end up in a box of little interest to the user 
hesitation   the algorithm makes a prediction for the email category or box  which it is not confident about  the email receives no label and is left in the main inbox  therefore  the user has
to sort the email himself  but there is no risk of losing an important email  an hesitation is
considered preferable to an error 

 

fi 

first approach   multinomial naive bayes framework

   

first implementation

we present here a first implementation of email sorting using the multinomial naive bayes
framework with laplace smoothing  it is a natural extension of the spam non spam naive bayes
algorithm used in many spam classifiers  except that we now have several categories  each with its
own naive bayes classifier  at each step of the algorithm  i e  for each new incoming email  the
training set is increased by one  and the dictionnary   tokens list is extended  as in the spam non
spam approach  we calculate the probability for the new email to belong to each category  we can
note that the probabilities found do not necessarily sum up to    the most obvious example is when
an email does not belong to any category  we describe below the different steps of the algorithm for
each incoming email  we implemented it in matlab 
   train the algorithm with the n sorted emails 
   assign the n     email to a category based on the words contained in current dictionnary and
qualify the confidence of the prediction  the category predicted is the maximum classification
probability among the categories  the prediction is confident when this probability is higher
than some value   and all the other classification probabilities are lower than some value  
in the final tests  we choose         and         given the results observed  the choice for 
has more impact as classification probabilites often end up being   or    a high beta means a
high level of confidence in your training 
   check the correctness of the labelling  in case of mislabelling  add an error and reassign the
new email to its correct category 
   expand the token list and update the representation of the trainig set  n     emails  in this
new dictionnary  
this algorithm demands much computing   one naive bayes classifier is maintained for each
category  and has to be updated for each incoming email 

   

adding relevance

the assignment of an email generally relies on keywords  consequently  we select the most relevant
tokens for each category to compute a relevance filter  excluding high frequency tokens  which appear
in all categories   and tokens which only appear sporadically in a category  suppose we know j i  
p token   j y   i  for all  i  j   the relevance ri j of a token j for category i is  
ri j   log p

j i
l  i j i

the number of relevant tokens is a key parameter  a low number sharpens the classification but is
sensitive to the variabilty of content in a category whereas a large number gives too much credit
to each classification thus increasing the hesitation rate  the number of relevant tokens  as well as
how they are computed  impacts the algorithms performance time  recomputing the list for each
new incoming email is very time consuming  however  when the categories are more stable  it is
not necessary to recompute the list at every step  and classifying incoming emails becomes faster  a
reduced corpus means fewer operations  

   

results

data set          error and     hesitation  considering the    most relevant tokens for each
category                  
data set        error and       hesitation  considering the     most relevant tokens for each
category                  
the error rate seems to be less sensitive to the number of relevant tokens than the hesitation rate 
actually  after a short training period  the algorithm becomes very accurate and stops mislabelling
 

fiemails  which explains the low error rate passed a few hundred emails  what happens when we add
more tokens  especially with the first data set     boxes   is that the probability of belonging to a
category becomes higher than     for several categories  this result ends up with more hesitation 
there is no clear rule for choosing the number of relevant tokens  but we suggest keeping it to a
small fraction of the total dictionary      

 

k means clustering

while naive bayes produces good results  we are also considering another approach  inspired
by unsupervised learning  which may lead to a reduced performing time  each mail category is
represented by a a vector  centroid  in a m dimensional space  where m is the size of the dictionnary 
m grows for each incoming email we add to the training set  we represent incoming emails by binary
vectors  tokens presence   absence   we use two different metrics to calculate the distance between
a new mail and a centroid  the first one is the traditional l  norm  the second one is the scalar
product of the new email vector and the centroid 

   

algorithm

   label the incoming email by finding the closest centroid  based on the tokens currently
contained in the dictionnary  the prediction is confident when the mail is really closer to a
centroid than to the others  we use the ratio of the distances and some threshold value  to
decide whether the mail will actually be classified or not 
   check the correctness of the labelling  in case of mislabelling  add an error and reassign correctly
the new email 
   expand the token list and update the centroids  new tokens  new dimension    the space
dimension is increased by one for each new token 
this algorithm is a little faster than our naive bayes approach since for each new incoming email 
we only have to update one centroid  and this update requires few operations 

   

adding relevance

as for naive bayes  we can only use the most significant tokens in our predictions to reduce the
dimension across which we make a prediction    is the centroids matrix  given a category i and a
token j  we define  
 i  j 
ri j   p
l  i  i  j 

   
     

results
choice of distance

the l  norm is the first natural choice for a distance but it gives poor results  the scalar product
of the new email vector and a centroid is a projection rather than a distance because the closest
you are to a centroid  the higher is the norm of the projection  however  the second approach gives
better results both in terms of error and hesitation  and this is the measure used for plotting the
curves presented below  we can note that using the scalar product makes the algorithm look a lot
like naive bayes 
     

analysis

the two curves show the error hesitation curves for the two data sets when we vary the parameter
  a low error rate comes at the cost of a high hesitation rate and vice versa  the algorithm produces
satisfying results  especially for the second data set      error for     hesitation when  is set
correctly  however we do not see how to provide an heuristic for the choice of  

 

fifigure    error hesitation curve for first data set

figure    error hesitation curve for second data set

   

additional remark   giving more weight to recent emails

in some cases  especially for the second data set   for a given category  the lexical field of the
emails can change with a new topic of discussion for instance    we thought this might impact the
precision of the algorithm  therefore  we modified the algorithm to give more weight  in the centroids 
to the most recent emails in the category  this slightly lowered the hesitation rate  but we did not
judge this improvement enough to justify the additional computing time 

 

conclusion

we obtained very good performances with naive bayes  however  we could not complete our
secondary objective  which was to devise an alternate algorithm  with similar  or slightly inferior 
results than naive bayes  but with a lower running time  our k means adaptation does take less time
to execute than our naive bayes implementation  but is not as accurate and requires a finer tuning
of parameters  actually  we realize now that an online machine learning algorithm will always require
some heavy computation at each step  since the model needs to be updated for each new example 
in the absence of a fast algorithm  one can always try to reduce the frequency of the updates  and
see if the accuracy is significantly reduced 

 

fi