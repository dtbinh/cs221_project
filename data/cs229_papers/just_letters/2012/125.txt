composer identification of digital audio modeling
content specific features through markov models
aric bartle  abartle stanford edu 
december         

 

background

the field of composer recognition has been relatively well studied  and there
are generally two ways to view this field  the first is to extract individual
pitches along with their rhythm and dynamics from an exact source  such a
source can be a midi  this view has extensively been analysed through numerous models  simpler models consist of training an svm on the features of
the composition that are the chords  the rhythms  the dynamics  etc  lcy  
however  compositions are really much closer to actual language  and this
implies that a nlp approach may be better  much research takes this approach and uses such nlp models like markov models successfully jb  
the secondary view to composer classification is taken from the standpoint of the digital audio  waveform  of compositions  in a sense there is far
less that has been explored from this standpoint  the music information
retrieval evaluation exchange  mirex  is an annual evaluation campaign
for composer identification and other tasks based on audio clips  fairly impressive results are demonstrated each year  yet the classifications are done
almost solely upon spectral analysis of the audio signal  spectral features  
content specific features like actual harmonies are not considered in any
depth  the paper  mu  analysed content specific features and obtained approximately a    accuracy increase over standard spectral analysis methods 
this is not surprising since composers are mainly distinguished by musical
content 

 

overview

the system described here can be viewed as a linear svm classifier with its
features consisting of spectral and content specific ones  several different
 

fitypes of content specific features are tried including the ones described in
 mu  and a novel set of features generated through a markov chain with the
aim to see if these features produce better results than the ones in  mu  
the test and training sets for the svm are drawn from a custom database
consisting of     distinct audio samples of    seconds in length  the database
is organized into   classes for the   different composers with each class being broken down into   albums of    samples  here  the composers bach 
beethoven  chopin  and liszt were chosen  all samples were distinct musical pieces and each album was a different performer  it should also be
noted that these samples were restricted to the piano to avoid possibly biasing towards an instrument  in drawing the training and test samples  it
is necessary that no sample from a particular album in the test set appear
in the training and vice versa  this is to avoid the so called album effect
where spectral features pick up on qualities relating to the recording and
artist rather than the piece of music jd  

 

spectral features

the spectral features are computed like in  gt   however  only what are
termed the timbral features are used in this implementation  briefly they
are spectral centroid  rolloff  flux and mel frequency cepstral coefficients
of an audio sample  in total  they form a    dimensional vector  this vector
is computed throughout the audio sample and a running mean and running
standard deviation are found as well  this creates for  when the two are
combined  a    dimensional vector which can be extended to    by again
computing a running mean and running standard deviation  finally  these
   dimensional vectors throughout the sample are averaged  giving a   
dimensional spectral feature vector 

 

content specific features

there are three different types of content feature vectors that are extracted 
the first two involve initially estimating a sequence of harmonies  chords 
throughout a sample  and then using those extracted harmonies to generate
features  the harmonies consist of the    major and minor chords  initially 
an approach like in  mu  was used to extract these harmonies  however 
it was found that there was quite a bit of noise in the predictions  instead
the software package  nmrb  was used to give fairly accurate predictions 

 

filastly  these harmonies are transformed to the key of c major in order to
be key invariant 
the first type of feature vector is computed like in  mu   transitions
from one harmony to the next are used to form a    dimensional vector 
the second type of feature is found through a markov chain  a markov
chain is generated for each composer of the training set with the states being
the harmonies  then the log likelihood of each audio sample in the training
set and test set are computed using these   markov chains  yielding a  
dimensional feature vector  the final type of feature vector is formed based
upon the dynamics of a sample  the sample is first normalized with respect
to the rms of its corresponding album  this make the assumption that
each album displays the full variation in dynamic range of that composer 
after normalization  beat detection is performed in order to determine the
likely locations where dynamics will change  in western music  dynamics
usually change on the beat  finally  a max is taken around the beat and the
resulting amplitude discretized  resulting in   of   levels of loudness  like
the second type of feature vector a markov chain is employed to generate
a   dimensional vector where this time the states are given by the levels of
loudness 

 

results

the database is split        albums           albums  for the test set
and training set  respectively  there are      possible combinations for this
splitting making it a bit impractical to compute all and form an average of
the classification results  instead     random sets are computed and classified to form an average  this classification was run several times producing
results  figure    all within     of each other  a baseline of     accuracy
was achieved through the spectral features alone  bar     when enhanced
with the markov specific features  classification increased to      bar    
however  if instead the    dimensional content specific feature vector was
appended to just the spectral features      accuracy was achieved  bar    
furthermore  another configuration was tested with one album in the testing set and the rest in the training set  there are    possible sets and the
average of these classifications is summarized in figure   
it can be seen that in figure   the markov features  bar    do better than
the    dimensional vector  bar     this discrepancy can likely be explained
by the nature of the training and test sets  in the first configuration  there
can be only one album for a composer in the training set  hence  the markov

 

fimodel will be based off of just this album  it had been observed that the
markov model seemed to over fit by running tests on just the markov features  it is reasonable to see that the markov model produce worse results in
this case and other similar ones  another possible issue is that not all training test set combinations were tried for the first classifier or enough trials
performed  it was inherently prohibitive in terms of time to try all the     
combinations  even performing the    trials took a considerable amount of
time because of the relatively large regularization coefficient required 

figure      to    split

figure      to    split

 

fi 

conclusion

the results are certainly promising  the second configuration shows the
markov features outperforming the one described in  mu  by     the first
configuration  although showing a decrease for the markov features  cannot
be taken that definitively because of the relative lack of testing  and even if
in the end the markov features do not perform as well  it is likely that the
accuracy is not that less and above that of the spectral features alone 
it is certainly worthwhile to extend the markov chain to more complex
models  furthermore  the content specific feature vectors can be extended
as well to include information relating to the rhythm and such  nonetheless 
the underlying problem present is that for these more complex models the
amount of data required grows quickly  and the time for constructing high
quality audio clip databases grows quickly as well due mainly to the album
effect  fortunately  content specific features are indifferent to many of the
problems that plague spectral features  particularly the album effect  it is
because of this that future research should be capable of training and testing
more complex models for content specific features 

references
 jb  jan buys  generative models of music for style imitation and composer recognition 
 jd  j s  downie  the music information retrieval evaluation exchange
             a window into music information retrieval research 
acoustic science and technology      vol          
 gt  george tzanetakis  marsyas submissions to mirex      
http   www music  ir org mirex abstracts      gt  pdf 
 lcy  justin lebar  gary chang  david yu  classifying musical scores by
composer a machine learning approach
 mu  sean meador  karl uhlig  content based features in the composer
identification problem cs     final project 
 nmrb  yizhao ni  matt mcvicar  raul santos rodriguez  tijl de
bie  harmony progression analyser for harmonic analysis of music 
https   patterns enm bris ac uk hpa software package 

 

fi