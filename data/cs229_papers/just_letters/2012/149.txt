cs    course project  a new rival to predator and alien
martin raison
stanford university

botao hu
stanford university

mraison stanford edu

botaohu stanford edu

abstract

   

this report documents how we improved the tld
framework for real time object tracking     by using a
new set of features and modifying the learning algorithm 

the main focus of this work is the detection component
of the framework  and the associated learning process 
the detector used in the tld framework uses the following workflow 

 

tld detector operation

   each frame is scanned using a sliding window  at
multiple scales  about a hundred thousand windows are considered  depending on the size of the
image and the size of the original object bounding
box  the part of the image contained in a window
is called a patch 

introduction

the problem of real time object tracking in a sequence
of frames has gained much recognition in the computer
vision community in recent years  the tld framework  kalal et al        marketed as predator  and the
alien tracker  pernici et al       are recent successful
attempts to solve the problem  the tld framework    
improves the tracking performance by combining a detector and an optical flow tracker  the purpose of the
detector is to prevent the tracker from drifting away
from the object  and recover tracking after an occlusion  since the only prior knowledge about the object
is a bounding box in the initial frame  the detector is
trained online via semi supervised learning  in order to
build such a system  two challenges must be addressed 

   each patch is flagged as positive or negative using
a   step detection cascade 
 variance filter  if the variance of the patch is less
than half the variance of the object in its initial
bounding box  the window is rejected
 ensemble classifier  a confidence measure is obtained
for the patch using random ferns  several groups of
features are extracted from the patch  and for each
group  a probability is computed  based on the number of times the same combination of features appeared in previous frames as positive or negative examples  the final confidence measure is the average
of the probabilities of each group of features 

   finding a good set of features to be used by the
detector for classifying image patches
   using an efficient learning algorithm to train the
detector with examples from previous frames

 nearest neighbor classifier  the normalized correlation coefficient is used to evaluate the distance between the considered patch and two sets of patches 
one set of positive patches  one set of negative
patches  built from previous frames   these two sets
of patches represent the object template  and are
maintained by a p n learning algorithm  introduced
in     

the solutions to these two problems are dependent on
each other  and as such  they must be designed so as
to fit into a single system 
our goal was to investigate new approaches for   
and    and try to find improvements in terms of robustness of tracking  good performance with a wide
range of objects  tolerance to fast movements  camera
blur  clutter  low resolution  etc  and efficiency  time
and space complexity  

background substraction can also be used as a preliminary step to filter out windows 

 

   

motivation   background work

this section details the mode of operation of the tld
detector      and motivates our use of features based on
compressive sensing for improving the system 

compressive sensing for image patch
descriptors

the ensemble classifier is a critical part of the detection
cascade  with the dataset used for the experiments  we
 

finoticed that on average  it selects about    patches out
of        patches on each frame  one of the main difficulties of training the ensemble classifier is that the size
of the training set is small  the tld framework tackles this issue by using random ferns  but in reality the
independence assumption between groups of features is
not verified  during the project  we tried to improve
this part of the detection cascade by using alternative
descriptors  i e  sets of features  for the patches and
modifying the classification algorithm accordingly 
many descriptor extraction algorithms have been developed in the last few years  such as freak  brisk 
brief or orb  the recent compressive tracking
 ct  method     introduces a way of computing descriptors based on compressive sensing  given an image patch x of size w  h  the patches xi j      i  w 
   j  h  are obtained by filtering x with a rectangle
filter of size i  j whose elements are all equal to   
each pixel of a patch xi j represents a rectangle feature  sum of all the elements in a rectangle   all the
xi j are then considered as column vectors  and concatenated to form a big column vector x of size  wh    
the many features contained in x are meant to account for a variety of scales and horizontal vertical deformations of the object  the descriptor x of the patch
is then obtained from x with a random projection  a
very sparse random matrix r of size l   wh   is used
for the projection  where l is the size chosen for the
descriptor  the matrix r is randomly defined by 

 

  with probability  s
 
ri j    
with probability  s


 
with probability     s

terest and the camera varies 

 

methodology

we focused on transposing the ct method to the tld
framework  to improve the tld detector while overcoming the limitations of the original ct approach 

   

descriptor computation

the main challenge for the descriptor computation was
to scale up the algorithm  ct considers only windows
near the current object location  whereas tld scans
the whole frame  so we needed to build descriptors that
were easier to compute  fortunately  another characteristic of ct descriptors is that they were intended to
work for all scales of the object  this is not necessary
in the case of the tld framework  since each frame
is scanned at multiple scales  based on these observations  we slightly modified the descriptors  and designed an algorithm to compute them efficiently  this
procedure was the object of the cs   a part of the
project 

   

online nave bayes

given the sparsity of the training data  and the necessity to train the classifier online  the nave bayes
algorithm was a natural choice  in addition  object
tracking is specifically challenging because of appearance changes of the object of interest over the course
of the video  in order to introduce decay in the model 
we used a learning rate  to do the relative weighting
between past and present examples  during tracking 
one model update is performed for each frame 
the input features are image patch descriptors  each
 i   i 
 i 
descriptor is denoted by x i     x    x         xn    with
 i 
a label y     if the patch corresponds to the object
 i 
of interest  y  i      otherwise  the xj s for j          n
are supposed to be independent given y  i    with

where s is a constant  li et al  showed in     that for
s up to wh  log  wh   the matrix r is asymptotically
normal  up to a constant   a consequence is that with
high probability  x can be reconstructed from x with
minimal error  achlioptas      
this algorithm was used in     for the purpose of
building a real time object tracker   the compressive
tracker  ct   this approach led to successful results 
but we observed that the system itself has limitations 
the ct method considers much fewer windows on each
frame than tld  as a consequence  while the computation time is significantly reduced  the ct tracker is
not very robust to fast movements and occlusion  in
addition  although the rectangle filters are intended to
account for scales of the object  the scale itself is
never explicitly determined  the size of the current
bounding box always remains equal to the size of the
initial bounding box  which is a significant drawback
in scenes where the distance between the object of in 

 i 

   

   

 i 

   

   

xj   y  i       n  j   j  
xj   y  i       n  j   j  
also  for k          we denote by  k      k  the
mean and variance of the positive  k      and negative  k      training examples drawn from the current
frame  if we give a weight  to the training examples
from the previous frames  and a weight     to the
training examples from the current frame  we can derive the mean and variance of the resulting descriptor
 

fidistribution  and obtain the following update formulas 
 k      k          k 
v
u
u    k               k    
 k 
    t
         k    k    
similar updates are used in     

 

figure    early experiments  keypoints are detected on each
frame  and then classified  the red points are negative  the blue
points are positive  the green box is the ground truth bounding
box for the object 

experiments

this section details how we tested the performance of
our approach 

   

this method allowed us to perform detection without using a sliding window mechanism  however  there
were limitations  first  keypoint detectors do not uniformly detect keypoints on the frame  and sometimes
do not even detect any keypoint on the object of interest  making further detection impossible  then  using
available implementation of descriptors  we could not
easily tune parameters such as the number of features 
finally  these descriptors are more appropriate for detecting characteristic points on an object  rather than
full objects  for these reasons  we moved on to the previously described method  keeping the sliding window
mechanism but using ct like descriptors for classification 

dataset and evaluation

for evaluating our system  we used the videos from the
tld dataset     and other videos commonly used for
evaluating trackers  zhong et al       
a typical measure for the performance of a tracking system is the pascal overlap measure      a prediction is considered valid if the overlap ratio of the
bounding box with the ground truth is greater than a
threshold   
 bprediction  bground truth  
 
 bprediction  bground truth  

   

the value of  chosen in     for comparing the tld
framework with other trackers is       we used this
same threshold for our experiments 
we measured the performance of our system at two
levels  we evaluated the performance of our new classifier alone  section       and we evaluated the performance impact for the entire pipeline  section       in
both cases  we measured the performance in terms of
precision  recall and f score 
finally  since the goal was to build a real time system  we evaluated the speed of our algorithm in terms
of frames per second 

   

classifier performance

to compare our new classifier with the original ensemble classifier  we modified the tld pipeline  on each
frame  before the learning step  we replaced the predicted bounding box with the ground truth  this ensured that the training examples selected afterwards
were similar  otherwise the training sets for different
classifiers would diverge  and the comparison would become irrelevant 
on each frame  we assigned a label to all the image
patch descriptors using the pascal measure  section
      and compared it with the output of the classifier 
figure   shows an example of precision  recall and fscore as a function of time  using a descriptor length
n       and a learning rate          with these settings  we achieved an f score of       on average on the
whole dataset  precision        recall         while
the tld framework achieved        precision       
recall         our system significantly improves the
classification recall  for an almost equivalent precision 
the introduction of decay  through the parameter  
makes the classification performance much more stable over time  the example on figure   shows that
the original ensemble classifier fails to adapt quickly
when the appearance of the object changes  because

preliminary experiments

before adopting the approach detailed in section    we
did some early experiments with popular keypoint detectors and descriptor extraction algorithms  freak 
brisk  surf  orb etc   the pipeline was 
   on each frame  run the keypoint detector
   compute a descriptor for each keypoint
   classify the descriptors with a nave bayes algorithm
 

fitld

finally  we observed how the performance varied
with the number of features  figure     if n is too
low  the model is highly biased  and the descriptors
dont capture enough information about the patches 
we couldnt observe any clear sign of overfitting when
increasing the number of features  however  high values of n require more computation  which is critical for
a real time system  we found n       to be a good
compromise between accuracy and speed 

 
precision
recall
fscore

   

   

   

   

 

 

  

   

   

   

   

   

 a  original tld
cttld
 
precision
recall
fscore

   

   

   

for evaluating the complete pipeline  we measured the
precision  recall and f score of the bounding box prediction for each video  this is different from the classifier
evaluation  where we measured the precision  recall and
f score of the image patch classification for each frame 
the precision p is the rate of valid bounding boxes
among all the predictions  the recall r is the rate of
predicted bounding boxes among all those that should
have been predicted  and as usual  the f score is defined
r
as f   p p r
  we obtained one value of p   r  and f for
each video  a comparison of the two trackers is shown
on figure   
our system did slightly better overall than the original tld framework  but since the average numbers
are very close  tests on a more extensive dataset would
be required for confirming the progress  in addition 
both systems have their strengths and weaknesses  to
understand the results  we did a qualitative analysis of
the performance for each video  we observed that our
system is more resistant to image blur  clutter and occlusion  whereas the original tld framework is better
for discriminating between objects with small variation
of intensity  and more robust to illumination changes 
examples are given on figure    a general observation

   

   

 

 

  

   

   

   

   

overall system performance

   

 b  improved tld
figure    precision  blue   recall  green  and f score  red  as a
function of time for the panda video from the tld dataset  the
frame number is shown on the x axis   our classifier produces a
more stable f score 

the weight of the first training examples remains too
high  on the other hand  the f score of our system is
almost always above      this is important because
the detector is most useful when the object is difficult
to track  i e  when the optical flow tracker trajectory is
most likely to drift from the object 
we tested several values of   figure     increasing
 reduces the vulnerability to temporary appearance
changes of the object  blur  occlusion  etc   but the
system adapts more slowly to long term appearance
changes  orientation change  shape change  etc   we
obtained the best performance with         
    
   

sequence
david
jumping
pedestrian 
pedestrian 
pedestrian 
car
panda
animal
board
car  
caviar
faceocc 
girl
panda 
shaking
stone
singer 
mean

    
   

precision
recall
fscore

    
   
   

   

   

   
learning rate

   

   

 

   
   
   
   

precision
recall
fscore

   
 
 

  

   
number of features

   

   

figure    top  average precision recall f score on the dataset as
a function of the learning rate   number of features n        
bottom  average precision recall f score as a function of n    
      

tld  measured 
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  

ct tld
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  
                  

figure    comparison of our system  ct tld  with the original
tld  the numbers in each column are the precision  recall and
f score 

 

fi 

is that our system can deal with a wider range of appearance changes and movements  whereas the original
tld framework tends to be more precise  higher overlap when the tracking is successful   this can probably
be explained by the nature of the descriptors  our descriptor corresponds to a summation of intensities over
rectangles  whereas tld uses more localized features
 intensity difference between pairs of pixels  

conclusion

our classifier improves the tracking performance of the
tld framework in a large range of common situations 
in some cases  such as when the intensity variance over
the object is low  the original tld system still remains
better  our learning algorithm does not seem to be
the bottleneck  the introduction of a decay parameter
makes the classification performance significantly more
stable over time  on the other hand  our features do
not capture the same kind of information as the small
scale features used in the original tld system  in the
future  we intend to improve our descriptors by using
a retinal topology inspired from freak keypoint descriptors      in order to capture both local and larger
scale information about the object 

finally  we measured the speed of our system  initially  the frame rate was low  but writing c code instead of matlab code increased the average frame
rate to    fps on a     ghz intel i  processor on a
   x    video  with an initial bounding box of size
   x    the initial tld framework is faster  during
our tests  we achieved    fps on average  our systems
performance still has the right order of magnitude for
real time operation  and we plan on optimizing it to
get smoother tracking 

 

acknowledgements

we would like to express our gratitude to alexandre
alahi  post doc at the stanford computer vision lab  
who accepted to mentor our project 

 

appendix

this project is done jointly with the cs   a class
project for all members of the team 

 a  animal

references
   

z  kalal  k  mikolajczyk  and j  matas  tracking learningdetection  in  pattern analysis and machine intelligence 
ieee transactions on              pp           

   

f  pernici  facehugger  the alien tracker applied
to faces  in  european conference on computer vision
 eccv         

   

k  zhang  l  zhang  and m h  yang  real time compressive tracking  in  eccv        

   

p  li  t j  hastie  and k w  church  very sparse random
projections  in  proceedings of the   th acm sigkdd
international conference on knowledge discovery and data
mining  acm        pp         

   

d  achlioptas  database friendly random projections 
johnson lindenstrauss with binary coins  in  journal of
computer and system sciences              pp         

   

w  zhong  h  lu  and m h  yang  robust object tracking via sparsity based collaborative model  in  computer
vision and pattern recognition  cvpr        ieee conference on  ieee        pp           

   

m  everingham et al  the pascal visual object classes  voc 
challenge  in  international journal of computer vision     
        pp         

   

p  vandergheynst  r  ortiz  and a  alahi  freak  fast
retina keypoint  in       ieee conference on computer
vision and pattern recognition  ieee        pp         

 b  pedestrian 

 c  pedestrian 

 d  stone
ground truth

lk

ct

tld

cttld

figure    superposition of the bounding boxes output by the
optical flow tracker alone  lk   the original ct system  the original tld system  and our system  cttld   on  a   blur example  and  b   clutter example   our system recovers faster  on
 c   tld never recovers after the occlusion  on  d   our tracker
jumps to another similar object 

 

fi