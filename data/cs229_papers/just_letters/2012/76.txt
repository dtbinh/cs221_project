learning to recognize objects in images
huimin li and matthew zahr
december         

 

introduction

the goal of our project is to quickly and reliably classify objects in an image  the envisioned application is an aid
for the visually impaired in a real time situation  i e  an algorithm that can be run on a mobile device  with real time
environmental data being collected via the devices camera  ideally  the camera would capture an image of the users
path and the proposed method would determine if any obstructions pose a threat  due to time limitations of the
quarter  we did not carry this project through the envisioned application  instead we laid the foundational steps 
primarily algorithm development and training 
our application to assisting the visually impaired in real time has a very natural separation of the training and
testing phase  in the training phase  it is assumed that computational time and resources are essentially unlimited 
this phase can be thought of as product development where a large amount of computational effort is devoted to
learning an algorithm  once the algorithm has been sufficiently trained  it is deployed on a mobile device and must
be able to rapidly detect obstructions  in practical situations  training time is an important consideration since
development cost is proportional to development time  this issue is addressed in our approach 
the approach used incorporates four computer vision and machine learning concepts  sliding windows to extract
sub images from the image  feature extraction to get meaningful data from the sub images  support vector machines
 svms  to classify the objects in sub image  and principle component analysis  pca  to improve efficiency  as
a model problem for the motivating application  we focused on the problem of recognizing objects in images  in
particular  soccer balls and sunflowers  for this algorithm to be useful as a real time aid to the visually impaired  it
would have to be enhanced to distinguish between close and far objects  as well as provide information about
relative distance between the user and the object  etc  we do not consider these complications in this project  we
focus on the core machine learning issues of object recognition  the training and testing of the proposed algorithm
was done using data sets        

 

algorithm

in this section  we present the proposed algorithm for object recognition and clearly distinguish between the training
and testing phases  let us first introduce some notation  define the set of training images as itrain    xi  pi    
at this point  we have not chosen a mathematical representation of the image  and therefore the notation used is
abstract  we are taking a supervised approach to machine learning so we break this set into the positive training
 

set itrain
   x  itrain   x contains object of interest  and the negative training set itrain
   x  itrain  
q
x does not contain the object of interest   similarly  the set of testing images itest    yi  i   is decomposed as the
 

positive itest
and negative itest
examples  as mentioned in section    many sub images will be extracted from each
test image and we denote sub image j of test image i as yij  

   

training

at a conceptual level  the training phase of our approach is broken into four stages      filter the background out of
the image  or equivalently  locate the objects in the image       extract pertinent features from the image  usually
high dimensional       construct a subspace on which to approximate the feature vector  optional   and     train the
model based on the reduced representation of the feature vector 
 graduate
 graduate

student  department of computer science
student  institute for computational and mathematical engineering

 

fithe background filtering or object extraction step is achieved manually by centering the object in the image and
cropping to          pixels  for the proposed algorithm  it is important that all training images are the same size
because the software package we are using to extract features will generate feature vectors of different dimensions for
images of different sizes  without additional information  data vectors of different dimensions cannot be compared
properly using standard classification algorithms 
the feature extraction phase uses the standard computer vision software vlfeat     to extract a histogram of
object gradients  hog  from a given image  this software takes our images xi as input  and returns a vector of
hog feature data xi  rn   the images in our data set  after cropping  were          pixels  which resulted in
hog vectors of dimension n        
the optional step of dimension reduction is achieved using principle component analysis  pca   the procedure
to apply pca to this problem
is to collect the hog feature
vectors into a matrix


ppand compute its singular value
decomposition  svd   x    x       xp     uvt   where    p  i   xi   a low dimensional representation for the feature vectors can be obtained by approximating them as a linear combination of the first k columns
of u  xi    xi   where   rnk is the matrix formed from the first k columns of u and xi  rk   for this to be
useful  we require k  n  since  is an orthogonal matrix  we can recover the reduced vector by simply projecting
the feature vector onto the basis  xi   t  xi     the svd is generally considered an expensive operation  but
there exist efficient algorithms for computing only a few dominant left singular vectors      the purpose of using
pca is to gain efficiency in the training phase  as we show later  the online  testing  cost is independent of whether
pca is used  if there are many training images  which will be the case in practical situations  the cost of training
the svm will be high because there are terms in the optimization formulation that involve sums over all training
data  where each data point is a hog vector   therefore  the incorporation of pca will reduce the training cost
if  there are many training images  only a few dominant singular vectors are required  and these dominant singular
vectors can be computed quickly  as mentioned in the introduction  the motivation for reducing offline cost is to
minimize product development cost while maintaining accuracy 
the next step of the proposed approach consists of training a support vector machine  svm  using the hog
feature vectors  xi   or their reduced representation  xi   along with their known classification as training data  our
implementation leverages the svm library liblinear     to perform this step  the output of the svm is a vector
defining the normal to the linear classifying hyperplane and a scalar defining the offset  these quantities are denoted
w  rn and b  respectively if the full hog vectors are passed to the svm or w  rk and b  if the reduced hog
vector representation is passed to the svm  at this point  we also define the vector w   w  which will be used in
the testing phase  if pca used  

   

testing

the time critical testing phase involves four steps      extract sub images from the original image      extract hog
feature vector from each sub image      determine the reduced representation of the feature vectors  optional   and
    classify the image by using the trained svm on the sub images 
the first step is achieved by considering a fixed size bounding box  window  that slides over the entire image 
every time the bounding box moves  the portion of the image within its domain is extracted as a sub image  to
generate a sufficiently large number of sub images for appropriate identification of an object  the bounding box begins
in the upper left position of the image and moves   pixels horizontally at each step  once the edge of the image is
reached  the window is moved down   pixels and begins sliding to the left in   pixel increments  the sliding window
approach allows the svm built in the training phase to be robust with respect to the position of the object in an
image and background noise  by using bounding boxes of several different sizes  the algorithm becomes more robust
with respect to scaling of the object  every time a sub image  yij is extracted  its hog vector yij is determined
using     
if pca is not used  the third step is skipped and classification is performed on the full hog vectors yij using
w and b  we classify an image yi as a positive example  i e  contains object of interest  if wt yij   b     for at
least   values of j  otherwise  it is classified as a negative example  this is interpreted as claiming that image yi
contains the object of interest if at least three of its sub images contain it  if pca is used to generate low dimensional
representations of the hog vectors  the hog feature yij must be projected onto the subspace   yij   t  yij    
then  an image yi is classified as positive if wt yij   b     for at least three values of j 
at first glance  it appears that pca actually has a more expensive testing phase than does the algorithm without
pca  this can be seen from the fact that the non pca algorithm requires a single inner product of n dimensional
vectors  wt yij   for each j to classify yi   but the algorithm with pca first requires k inner products of n dimensional
vectors  t  yij    and a single inner product of k dimensional vectors  wt yij   for each j  however  our introduction
of w   w in the previous section  reduces the testing cost of the pca algorithm to a single inner product of n 

fidimensional vectors for each j  wt yij   wt t  yij       w t  yij      wt  yij     therefore  the online
cost is the same regardless of whether pca is used  also notice that pre computing w  eliminates the need to store
reduced basis   rnk during the testing phase  this is a significant observation if the training phase of our
algorithm is performed on mobile devices  with limited memory 
figure    soccer ball image and visualization of its feature vector

 

results

in this section  we present the results of applying the algorithm in section   to determining if an image contains a
soccer ball or sunflower  our investigation of the study is performed by progressively improving the robustness of
the algorithm by adding complexity to the algorithm  initially  instead of using the sliding window approach  we
manually pre process each test image  this initial approach is tested with and without the incorporation of pca 
the next step incorporates the sliding window approach 

   

study    test images manually pre processed  no sliding window 

in this section  the algorithm in section   is applied to recognizing a soccer ball in an image without the added
complexity of the sliding window  all test images are manually pre processed by centering the object and cropping
the image to the appropriate size  we trained our algorithm with    positive examples and    negative examples 
the algorithm was tested on a set containing    positive examples and    negative examples  the quality of our
algorithm is assessed by the number of mis classified test examples  which we present in terms of false positive rate 
false negative rate  and total error rate in table    it can be seen that the error rate is quite low and incorporating
pca with dimension    introduces no additional error  this initial version of the algorithm will fail if the object is
not manually centered or the background is not removed  it relies on the image pre processing  this algorithm has
relatively low errors because we are explicitly telling the algorithm the location of the object by manually cropping 
therefore  the errors in table   essentially serve as a lower bound for the errors we expect from the sliding window
implementation  if using sliding windows  we lose a bit of accuracy  but we gain robustness with respect to object
position and scaling  and the online algorithm is entirely automatic 
table    soccer ball example with manual test image pre processing and pca
no pca pca dim   pca dim    pca dim    pca dim   
false positive rate
  
      
  
  
  
false negative rate
     
      
      
     
     
total error rate
     
      
      
     
     

   

study    sliding window

in this section  we repeat the experiment from section     with the incorporation of the sliding window  we consider
four different sliding windows                            and          pixels  which will be denoted swi  swii 
swiii  and swiv  respectively  table   shows the results of varying the number of sliding windows used  as expected 
incorporating different sliding window sizes improves the accuracy of the algorithm by improving robustness with
respect to object scale  table   also shows that incorporating the smallest sliding window  sw   actual increases
the error  this is an artifact of the circular shape of soccer balls  once you zoom in on an image  with background
noise  enough  it is likely that there will be some objects with circular shape and the algorithm will generate a false
positive 
 

fitable    soccer ball example with sliding window
swiii swii   sw iii swii   swiv
false positive rate
     
     
     
false negative rate      
     
     
total error rate
     
     
     

swi   swiv
     
     
     

table    soccer ball example with sliding window  swi swiv  and pca
dim    dim    dim    
false positive rate
     
     
     
false negative rate
     
  
     
total error rate
     
     
     

   

study    additional object   sunflower

we observed the soccer ball example generated a large number of false positives  this is attributed to the commonality
of circular objects in a natural image  i e  human head or fist  tennis ball  plates  etc  can all be considered roughly
circular in a  d image   to test this hypothesis  we performed an abridged version of study   except we tried to
classify images based on whether they contain a sunflower  sunflowers were chosen because their unique shape will
reduce the likelihood of finding similar shaped objects in an image 
experimentation with this algorithm along with a literature search emphasized the importance of the negative
training set size and quality  figure   illustrates the importance of training set size by plotting the three error rates
versus negative training set size  an important feature of this plot is the original negative training set is generated
from random  non sunflower images  however  when the negative training set is enlarged  the additional examples
are chosen based on a heuristic relevance criterion  for the smallest negative training set sizes     and      there is
a false negative rate of   because the algorithm classified every test image as positive  i e  there were no predicted
negative images  
figure    sunflower example  error versus negative training set size
false positive rate
false negative rate

   

total error rate
   

   

   

   

 
  

 

  

  

  
  
   
number of negative training examples

   

   

   

conclusion

in this project  we used computer vision and machine learning techniques such as sliding windows  hog  pca  and
svm to determine whether images contain objects of interest  particular attention was given to keep training costs
low by incorporating pca  the proposed algorithm had a high success rate on object centered test images  but had
no robustness with regard to object scaling and position  incorporation of sliding windows increased the error rate
but improved robustness 
future work will focus on improving the robustness of the proposed algorithm to false positives by using an
enriched set of negative training examples  another direction is to improve the performance of pca with sliding
windows by using a local basis for each object in addition to the global basis      a necessary enhancement for our

 

fifigure    soccer ball example

properly labeled positive and negative examples

mislabeled positive and negative examples

figure    sunflower example

properly labeled positive and negative examples

mislabeled positive and negative examples

eventual application will be to generalize to multinomial classification for distinguishing multiple objects in a given
image 

references
    y  chahlaoui  k  gallivan  and p  van dooren  recursive calculation of dominant singular subspaces  siam
journal on matrix analysis and applications                     
    r  e  fan  k  w  chang  c  j  hsieh  x  r  wang  and c  j  lin  liblinear  a library for large linear
classification  journal of machine learning research                   
    l  fei fei  r  fergus  and p  perona  learning generative visual models from few training examples  an incremental bayesian approach tested on     object categories  ieee  cvpr       workshop on generative model
ieee  cvpr       workshop on generative model based vision       
    g  griffin  a  holub  and p  perona  caltech     object category dataset  technical report       california
institute of technology       
    h  murase and s  k  nayar  visual learning and recognition of   d objects from appearance  internal journal of
computer vision               
    a  vedaldi and b  fulkerson 
http   www vlfeat org        

vlfeat 

an open and portable library of computer vision algorithms 

 

fi