good cell  bad cell  classification of segmented
images for suitable quantification and analysis
derek macklin  haisam islam  jonathan lu
december         

abstractwhile open source tools exist to automatically
segment and track cells in time lapse microscopy experiments  the resulting output must be inspected to detect and
remove spurious artifacts  in addition  data not exhibiting
proper experimental controls must be discarded before
performing downstream analysis  currently  the data set
is manually examined to accomplish these tasks  here we
present machine learning approaches for classifying the
suitability of data traces for downstream processing and
analysis  we integrate the most successful approaches into
the experimental workflow 

i  i ntroduction
time lapse live cell microscopy is a powerful technique to study the temporal dynamics of signaling pathways in single cells  using fluorescently labeled proteins  researchers can perform experiments to observe
the interactions of signaling components to understand
the underlying mechanisms of action  analyzing data
from these experiments requires image processing to
quantify the spatio temporal dynamics of labeled proteins      recently  sophisticated open source software
packages have been released to help automate biological
image processing tasks such as cell segmentation     and
tracking      while these packages can be combined to
create an image processing pipeline  the data traces that
are produced must be inspected to determine if they
are appropriate for inclusion in downstream analysis 
figure   shows an overview of the workflow 
data traces produced by the image processing pipeline
are excluded from further scientific analysis for two
reasons  one reason is that the segmentation algorithm
occasionally fails to uniquely identify and separate adjacent cells  thereby introducing large artifacts in some
of the generated traces  another reason is that some
traces may not exhibit features associated with proper
experimental controls  for example  some cells may
not contain any fluorescently labeled protein when the
labeling process is not      efficient  presently  cells
and their corresponding traces are visually inspected to

determine if they should be analyzed further  in this
paper we present our efforts to apply supervised learning
techniques to automate this classification of good and
bad cells 
ii  m ethods
a  data
three researchers from the covert lab at stanford
university have provided data sets containing time
courses of multiple features per cell and the associated
good or bad labeling  each of the three data sets
reports features and labelings for approximately          cells  the features for each cell are produced by
cellprofiler     which reports approximately    properties  including  meanintensity  stdintensity  meanintensityedge  area  perimeter  and eccentricity  these
features are reported for each cell in the frame  for
all frames  thus generating two dimensional time series
traces representing each cell  when a cell is not in the
field of view  its features are all recorded as nan for
that frame 
we have chosen not to aggregate the data from the
three researchers because each researcher uses different
experimental conditions and thus has different criteria for
classifying cells as good or bad  we seek to develop
and demonstrate an algorithm which works for each
researcher when trained on the properties produced by
cellprofiler in conjunction with the manually determined
labels 
b  features  part i
the provided data sets are not immediately amenable
to machine learning algorithms  each cell is represented
by two dimensions of data      the properties reported by
cellprofiler  and     time  in addition  cells remain in the
field of view for differing amounts of time  thus  many
commonly used techniques which require input vectors
to be in the same n dimensional space are not well suited

fifig     a schematized  and satirized  overview of the experimental workflow  from data collection to publication 
this project seeks to minimize the manual classification of data that must occur prior to the scientific analysis
required for publication 

unless missing values are carefully imputed for frames
in which a cell is outside the field of view 
our initial approach is to choose features that are
summary statistics of the temporal dynamics of each
property reported by cellprofilerthis circumvents the
need to impute missing values  we take the minimum 
maximum  mean  and standard deviation of each property over all frames in which a cell is in the field of
view  thereby representing each cell with one dimension
of data  we recognize that this transformation discards
many of the temporal features that may be critical for
this particular classification problem  initially  though 
we have decided to investigate different classification
algorithms with this overview feature set 
prior to training different algorithms  we examine the
pairwise correlations of all the features to remove highlycorrelated features  we also remove features which have
very low correlation with the observed labeling 

baseline  thus we normalize the meanintensity timeseries property to its starting and maximum value and
append features describing the derivative of this normalized trace in the first    frames  for data set  
we also append a feature indicating how long a cell
remains within the field of view  for data set   we
append features describing the temporal dynamics of
area since researchers look at the dynamics of cell area
when performing manual classification for this data set 
e  logistic regression
we perform logistic regression on each data set using
the glmfit and glmval functions in matlab  the
mathworks  natick  ma  usa   we have made a slight
modification to the glmfit function to allow it to iterate
for more than the default     iterations 
f  naive bayes

c  features  part ii
we augment our initial feature vector  described
above  with more nuanced temporal information to improve classifier performance  for cells that remain within
the field of view for at least    frames we compute the
fast fourier transform  fft  on a sliding window of   
time points and average the successive windows  thereby
generating a vector in r   that represents the frequency
content of differing length traces  we append this to our
initial feature vector  for cells that are recorded for less
than    frames  we append a zero vector 

we implement a naive bayes classifier with a multinomial event model  since our features are reported as
continuous values  we discretize these values into a finite
number of bins so that we can model p xi  y  for each
feature xi as a multinomial distribution  to perform the
discretization  we take the maximum value of each feature  the minimum value of each feature  and divide that
range into a number of bins  to select the number of bins 
we perform cross validation varying the number of bins
from   to      and select the number which maximizes
area under the  receiver operator characteristic  curve 

d  features  part iii
to further improve performance  we add custom features that incorporate characteristics that each researcher
takes into consideration when classifying his or her data
set  for example  in data sets   and    researchers look
for mean intensity changes in the first       frames 
these intensity changes need not be large in absolute
magnitude but must be noticeable compared to an initial

g  support vector machine
we train a support vector machine  svm  using the
libsvm library      we select a radial basis kernel
and select appropriate parameters by performing a grid
search in log space to maximize area under the  receiver operator characteristic  curve obtained by crossvalidation 

fiu 

u 

 

 
bad
good

 

bad
good

 

u 

  

bad
good

 

 
 
 

 
u 

  

 a  data set  

 
 

 

u 

 

 
 

 

 b  data set  

 
u 

  

 c  data set  

fig     initial features  c f  section ii b  of each data set projected onto the first two principal components 

h  evaluation of learning algorithms
for each learning algorithm we perform hold out cross
validation  training on     of the data and testing
on the other      because the labelings are skewed
with        of cells marked good depending on the
researcher  we report area under the curve  auc  rather
than accuracy  in general we display and report auc for
precision recall curves  aucpr    we also report auc
for receiver operator characteristic curves  aucroc  
which compare true positive and false positive rates  the
relationship between precision recall  pr  and receiver
operator characteristic  roc  curves is discussed in    
and the authors suggest that pr curves can be more
informative for skewed data sets 
to generate pr and roc curves and compute
their respective aucs  we generally use matlabs
perfcurve function  for svms we use slight modifications of libsvms plotroc function  which calls
perfcurve  
i  principal component analysis
in order to visualize our data in two dimensions  we
use the svd function in matlab after standard preprocessing to normalize the mean and variance 
j  pipeline integration
we integrate the most successful classifiers into the
image processing pipeline to augment the manual classification process  the motivation for this project   to
achieve this  we save the models and any associated
normalization constants so that new data can be appropriately transformed prior to classification 
iii  r esults
a  classification results  part i
aucroc and aucpr values for three different classification algorithms  trained and tested on our first set

table i  classifier performance using initial feature set 
data set  

data set  

data set  

aucroc aucpr aucroc aucpr aucroc aucpr
logistic
regression

    

    

    

    

    

    

naive
bayes

    

    

    

    

    

    

support
vector
machine

    

    

    

    

    

    

of selected features  c f  section ii b   are reported in
table i 
we see that logistic regression does not perform well
for data sets   and    while its performance is much
more comparable to the naive bayes and svm classifiers
for data set    to investigate this  we observe figure   
which shows the initial features for all three data sets
projected onto the first two principal components  we see
that the data is not linearly separable in low dimension
for any of the data sets  but for data set    there
is a cluster of good cells somewhat removed from
bad cells  this may enable logistic regression to
better separate data in data set    however  the bestperforming classifier for data set   is the svm 
to our surprise  naive bayes  when appropriately
discretized for each data set  performs better than the
svm for data sets   and   
b  classification results  part ii
after characterizing the performance of the classification algorithms on the initial feature set  we attempt
to make improvements by adding more discriminative
features  discussed in sections ii c and ii d   first by
incorporating information describing the temporal dynamics  in particular  we focused on data set   since the

fi   

 
 

auc       
   
recall

   

 
 

 

 a  initial features
 c f  section ii b 

 
precision

 
precision

precision

 

auc       
   
recall

   

 
 

 

 b  with ffts
 c f  section ii c 

auc       
   
recall

 

 c  data specific
 c f  section ii d 

fig     precision recall curves for the svm classifiers trained on data set    performance  as measured by the area
under the curve  increases as the feature set is improved and refined 
 
precision

precision

 

   

 
 

auc       
   
recall

 

   

 
 

auc       
   
recall

 

fig     precision recall curve for the svm classifier
trained on data set   using the full feature set  c f 
section ii d  

fig     precision recall curve for the naive bayes classifier trained on data set   using the initial feature set
 c f  section ii b  

researcher who provided it is currently the most invested
in the automation of the classification task 
figure  b shows the precision recall  pr  curve of the
svm trained on the feature set described in section ii c 
as a reference  figure  a shows the pr curve when
the svm is trained on the initial feature set described
in section ii b  we see that the new feature set which
includes a representation of the temporal dynamics improves svm performance 
we note that that the new feature set improves the
svm performance for data sets   and    but the performance is still less than that of the naive bayes classifier
trained on the initial feature set  data not shown  

have once again improved performance in classifying
data set   
in addition  the full feature set improves svm performance for data set   over that of naive bayes  trained
on any of the feature sets   figure   shows the associated
pr curve 
new features did not improve svm performance on
data set   over that of a naive bayes classifier trained
on the initial feature set  c f  section ii b   the pr curve
for the naive bayes classifier trained on this data set is
shown in figure   

c  classification results  part iii
we again attempt to further improve classifier performance by incorporating features that reflect the criteria
used by researchers when manually labeling their data
sets  as described in section ii d 
figure  c shows the pr curve of the svm trained
on the full feature set  we see that the new features

d  pipeline integration
the best performing classifiers are integrated into the
experimental workflow at the end of the image processing pipeline  the classifiers make an initial attempt at
classifying cells and allow the researchers to decide the
final labelings  the researchers use the initial labelings as
they rapidly search through their data sets to identify and
prioritize which results are worth manually classifying 
this was not possible when the overwhelming number of

fibad time series traces were not differentiated from
and therefore maskedthe good time series traces 
iv  c onclusion
in this work we present our effort to augment and partially automate some of the manual classification tasks
involved in processing data from time lapse microscopy
experiments  we have integrated the best performing
classifiers into the experimental workflow  enabling researchers to quickly observe trends in the data so that
they can prioritize their analysis tasks  we hope to make
further improvements in the future 
acknowledgements
we thank jake hughey  keara lane  and sergi regot
from the covert lab for providing their labeled data sets
and for offering their feedback as we iterated designs 
we thank professor andrew ng and the teaching staff
for their guidance this quarter 
r eferences
    t  k  lee and m  w  covert  high throughput  single cell nfkb dynamics  current opinion in genetics and development 
vol      no     pp                  genetics of system biology 
    l  kamentsky  t  r  jones  a  fraser  m  a  bray  d  j  logan 
k  l  madden  v  ljosa  c  rueden  k  w  eliceiri  and a  e 
carpenter  improved structure  function  and compatibility for
cellprofiler  modular high throughput image analysis software 
bioinformatics       
    d 
blair
and
e 
dufresne 
the
matlab
particle tracking code repository   online   available 
http   physics georgetown edu matlab 
    c  c  chang and c  j  lin  libsvm  a library for support
vector machines  acm transactions on intelligent systems and
technology  vol     pp                   software available at
http   www csie ntu edu tw  cjlin libsvm 
    j  davis and m  goadrich  the relationship between precisionrecall and roc curves  in proceedings of the   rd international
conference on machine learning  ser  icml     new york 
ny  usa  acm        pp           online   available 
http   doi acm org                        

fi