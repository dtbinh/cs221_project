fast and low power ocr for the blind

frank liu
cs      machine learning
stanford university

   introduction

the voice project is that its ocr algorithm can take a
couple of seconds to process text  and the accuracy is
somewhat questionable given the low resolution camera input 
despite the potential for ocr as seen in the
voice project  the vast majority of recent ocr research is focused towards improving classification accuracy  batuwita and bandara  for example  present a
constrained ocr algorithm for fuzzy  low resolution
scanned letters and numbers  while their work
presents a high classification accuracy         it takes
over half a second to classify each character     
similarly  si et al      and namane et al      both
achieve a high accuracy  approximately      classification method for scanned text  but explicitly mentions
the immense computational complexity of their algorithms  for many recent ocr related algorithms  runtime will often double or triple for a just few percent
increase in accuracy  although there are certain advantages to having extremely accurate algorithms  ocrs
usefulness to the blind only manifests itself when letters and characters can be quickly recognized and output to the user through audio or some other form of
sensory communication 
this paper will detail the design and implement a
novel method for fast  low power word recognition 
creating an algorithm designed to use small amounts
of computing power while still maintaining a reasonably high level of accuracy on everyday recognizable
characters  section   explores several feature extraction and classification algorithm combinations  some
of these algorithms are tweaked some portions of the
algorithms to obtain better classification accuracy or
a lower runtime  section   also presents a qualita 

optical character recognition  or ocr  is the process of extracting text from scanned documents  although ocr is a well studied topic  text embedded in
natural scenes also carries extremely useful information  as such  it is often necessary for computers or
mobile devices to automatically recognize them 
among the various subtopics of scene text classification  character classification  i e  the process of
recognizing various letters and digits  is perhaps the
most important  however  this task is rather difficult 
since recognizable characters often appear in a variety
of different scenes with a variety of different designs 
additionally  they are difficult to accurately classify
due to the variant properties of scene text 
a common way to learn images of characters is to
apply a scale and viewpoint invariant feature extraction algorithm with a classification algorithm  for the
english alphabet  this classification algorithm would
categorize feature sets from each image into    categories     letters and    numbers  excluding symbols such as   and     many classification algorithms are viable  but each produce different results
when paired with a different set of features 
while ocr has many applications  blind men and
women have perhaps the greatest use for letter and
word recognition  the voice project      is an excellent example of this  voice kits attempt to help the
blind recognize everyday objects  such as a pedestrian
walkway or a parking lot  the package also comes
with an ocr algorithm  which allows users to listen
to  for example  the time displayed on a clock or text
written in a book  however  one of the downsides of
 

fitive formula that determines the quality of a particular combination of feature extraction   classification
algorithms  finally  section   presents optimized results compiled using the best selected combination of
feature extraction   classification algorithms  testing
will occur on the ocr dataset collected by rob kassel
at the mit spoken language systems group  found
here  www seas upenn edu  taskar ocr letter data gz  

by     the total number of lowercase and uppercase
alphanumeric characters in the english alphabet  
to allow the ocr method to learn the characters 
each learning algorithm was paired with a feature extraction algorithm  designed to take keypoint vectors
at each pixel in the image  these features consisted
of some variable number f of feature vectors  each of
which was    bits wide  feature vectors which had
less than    bits were simply zero padded until the
vector had length of     the following image shows a
selected set of sift interest keypoints extracted from
an image of huang engineering center 

   methodology
a power efficient ocr algorithm attempts to minimize the computational steps used in the ocr process
while still achieving a high classification accuracy  for
mobile and low power applications  an extremely accurate but computationally expensive algorithm is undesirable  on the other hand  a fast and power efficient
algorithm with a relatively low classification accuracy
is also inadequate 
to better quantitatively measure this balance  the
ocr method employs a weighted sum over the runtime and test set classification accuracy to determine
which combination is the best  this equation is based
on user preferences generated by the voice project 

figure    selected sift features taken from an image of
huang engineering center 

r
 a
   
n
where r is the overall runtime over the test set  a
is the classification accuracy  and n is the number of
points in the character dataset  this formula reflects
the desire to have an algorithm as close to      as
possible  while still maintaining a strong relative runtime 
to achieve maximum balance between computing
efficiency and recognition accuracy  several potential
algorithms learning algorithms were analyzed to see
which produced the best results 
b r  a   

below is a list of all of the feature extraction algorithms tested for this project 
    harris corners    
    histogram of gradients
    scale invariant feature transform  sift     
    speeded up robust features  surf     
to keep runtime calculations consistent  only matlab libraries and scripts were used to code the feature
recognition and classification algorithms 
as per equation    each combination of algorithms
was analyzed for both runtime and test set accuracy 
the table below shows a summary of the results  the
maximum output value from equation   was normalized to     
in the experiments  the gaussian kernel was used
to train the svm classifier  surprisingly  sift performed considerably better than hog  while surf

    k nearest neighbor  k    
    k nearest neighbor  k     
    naive bayes  n        

n
  

    support vector machines  svm 
for knn  k refers to the number of closest neighbors analyzed  for naive bayes  the parameter n
refers to the laplace smoothing factor  conveniently
defined as    of the test sets element count divided
 

fiusing libraries provided by rob hess from oregon
state university      this provided an almost threefold improvement in runtime  with no change to the
classification accuracy 

     image downsampling and smoothing
in order to improve the efficiency of the algorithm 
the original image is downsampled to a        square
image via bicubic interpolation  furthermore  to compensate for spurious high frequency information in the
downsampled image  the method employs a gaussian
lowpass filter to smooth out any potential sharp corners  this increases the reliability of the surf descriptor 
using libsvm     to fine tune the classification
parameters  two distinct patters were created for feature extraction and training  both designed to compensate  in one way or another  for the systems lack of
computing power 
           window size      descriptor elements per
feature  although the descriptor for each pixel
contains quite a bit of information  the number of
pixels we consider is rather small 

figure    flow chart for the algorithm 

hc
hog
surf
sift

knn 
     
     
     
     

knn  
     
     
     
     

nb
     
     
     
     

svm
     
     
   
     

         window size     descriptor elements per
feature  this pattern reduces the number of elements per descriptor  but increases the number of
pixels in the interest region 

table    normalized values        best  for b r  a  for
different algorithm combinations 

for pattern    see figure     a search range
of log   c                        and log      
                     a region was then identified
around  c                   which has a high crossvalidation accuracy of        immediately following this  the grid search was rerun using log   c   
                and log                       
this produced a cross validation accuracy of      
and an optimized pair of parameters    c     
                 using these parameters  a test set accuracy of                      was achieved 
for pattern    see figure     a search
range of log   c 
 
                    and
log    
 
                    was used
before determining the ranges for fine grid
search to be log   c 
 
              and
log                      the best parameter

outperformed sift by a relatively small amount despite the reported  x speedup over sift 

   optimizations
as shown in section    surf with svm has shown
better results than all of other algorithm combinations 
to further improve the ocr method  several techniques were used to improve both the classification accuracy and runtime of the algorithm 

     code conversion to c
to improve runtime performance and decrease
library and platform related overhead  the original
surf   svm code was ported from matlab to c
 

fi   results
preliminary field tests were generated using an
field programmable gate array  fpga  running a
mips like processor at a clock frequency of    mhz 
due to time constraints  the updated x   based ocr
method was not ported directly to the mips assembly  instead  valgrind     was used to determine the
number of instances of each assembly instruction that
occurred when running the ocr method over the test
set  these instructions and their corresponding number of occupancies n in the code were then copied to
the fpga  which then ran each instruction n times 
over the entire test set  the fpga based system observed a     ms classification runtime per character 
this means that the system can correctly classify approximately    out of     characters every half second
on a    mhz clock speed 

figure    grid search for pattern    top graph corresponds
to a coarse search  whereas the bottom graph corresponds
to a fine search 

   further work
low power ocr has huge potential as a blindness
aid  especially as processing power becomes cheaper
and cheaper  although the ocr system shown here
has shown a good set of preliminary results  there is
still plenty of room for future work 
    comprehensive field tests  in this project  no real
field tests  with an actual live webcam feed and
user  were performed  doing so would be a huge
step forward in the project  and could allow for
more optimizations tailored towards actual userreported problems 
    addition of text to speech capabilities  at the
moment  there is no way for a blind user to assess
the output of the ocr method  adding text tospeech software and recompiling runtime results
would allow for a better understanding of the viability of the system in a real world setting 

figure    grid search for pattern    top graph corresponds
to a coarse search  whereas the bottom graph corresponds
to a fine search 

    improved accuracy for ocr algorithm  while a
low runtime is critical for the application to perform well  a reasonably high accuracy just as important      classification accuracy may be a bit
too inaccurate for a user to perform tasks on a
daily basis  to increase classifications accuracy
or decrease runtime  more learning and feature
extraction algorithms could be analyzed  image

pair  c    turned out to be                   turning
in a test set accuracy of                      
given the different possible current ocr algorithms      likely is very close to the maximum possible accuracy achievable while still maintaining a low
runtime  both patterns were able to achieve approximately    ms classification runtime per character 
 

fimodification for more robust feature extraction
is also another possibility to improve the ocr
method 

references
    e  h  soubari p  meyrueis a  namane 
m  maamoun 
csm based feature extraction for degraded machine printed character
recognition  in proceedings of icmlc         
 
    k  batuwita and g  bandara  fuzzy recognition
of offline handwritten numeric characters  in proceedings of cis           
    c 
chang
and
http   www csie ntu edu tw 
 

c 
lin 
cjlin libsvm  

    t  tuytelaars h  bay and l  v  gool  surf 
speeded up robust features  in proceedings of
eccv           
    c  harris and m  stephens  a combined corner
and edge detector  in proceedings of avc   
       
    rob hess  http   eecs oregonstate edu  hess   
    x  tian j  si  f  yang  a new algorithm of mixed
chinese english character segmentation based on
irregularty degree  in proceedings of icmlc   
       
    d  g  lowe  distinctive image features from
scale invariant keypoints  in ijcv           
    valgrind  http   valgrind org    
     the
voice
project 
http   www seeingwithsound com ocr htm 
 

 

fi