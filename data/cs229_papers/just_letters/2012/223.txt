movie rating estimation and recommendation
zhouxiao bao  haiying xia
abstract
in this paper  we build a movie rating prediction system
based on selected training sets provided by movielens 
several machine learning related algorithms  baseline
predictor  knn  stochastic gradient descent  svd  svd   
asymmetric svd  integrated model and nmtf are used to
predict the rating from particular users for unrated movies 
rmse  root mean square error  is applied as the main
criteria to evaluate their performance  the simulation result
shows distinct performance due to selected algorithms as
well as the corresponding learning rates 
index terms movie rating predictor  svd  rmse 
matrix factorization
   introduction
recommender systems provide users with personalized
suggestions for products or services  they are becoming
more and more important in the success of electronic
commerce  and being utilized in various applications such as
amazon  youtube and google news  generally speaking  a
recommendation system builds up items profiles  and users
profiles based on their previous behavior recorded  then it
makes a prediction on the rating given by certain user on
certain item which he she has not yet evaluated  based on
the prediction  the system makes recommendations  various
techniques for recommendation generation have been
proposed and successfully deployed in commercial
environments  among which collaborative filtering  cf  and
content based methods are most commonly used        
movie is now an indispensable entertainment in human life 
most video websites such as youtube and hulu and a
number of social networks allow users rate on
videos movies  in this project  we build a movie rating
prediction system based on several selected training sets 
which estimates the movie ratings from each user 
according to this result  we are able to make personalized
movie recommendations for every user  which would more
likely satisfy users expectation and improve user
experience 

from     users on      movies  in which each user has
rated at least    movies  among movielens    k data set 
we choose ua base test and ub base test for result
comparison between different training sets and testing sets 
and ua base test for model comparison between different
algorithms  the whole set u data is split into a training set
and a test set with exactly    ratings per user in the test set 
the sets ua test and ub test are disjoint  also  in order to
apply cross validation to select from different models  we
again split the data set ua base into    small disjoint sets 
this allows us to perform    fold cross validation on
ua  base   ua   base and evaluate the finally selected model
on test set ua test 
the training and testing data are pre processed as follows 
we apply the database to build a u by i matrix a  where u is
the number of users  and i is the number of rated movies 
each element
denotes the rating scored by the u th user
for the i th movie  it is easy to find that the majority of
movies dont obtain a sufficient number of ratings  and also 
there only exist common ratings for general user  so a is a
very sparse matrix 
   problem description
after pre processing  we obtain a large user item matrix
a
  where n is the number of users and n is the
total number of items  movies   so we have 
a

r  
  

 

existent rating
no such rating

thus our work is to fill in all the zero entries in the matrix
based on the training set of existing ratings  assume the
   
prediction rating of user u on item i is t r
in this project the widely used rmse  root mean square
error  criteria is applied to evaluate the performance of each
algorithm  it could be calculated as 
rmse

 

 
 s

 

  

as is mentioned above  u  i  s
user u has rated item i before 

r

actually means that

   dataset and pre processing
   algorithms
considering about the simulation efficiency  we choose
movielens    k data set  as our training and testing set 
such set consists of         ratings  rating score from     

    baseline predictors

t

firmse curve for different k values based on two datasets
    
    
   
    
    
rmse

we use a simple baseline predictor to estimate the movie
ratings from each particular user  the predictor algorithm is
described in      in this approach  the unknown rating score
 b
b   where  is the overall
is estimated as b
average score  b and b is the training deviations of user u
and item i  respectively  the parameters  b and b are
estimated using a decoupling method  which requires less
    
   
complexity but less accurate  we choose 
which are parameters applied to estimate b and b  
respectively 

    
    
 
    
    

by applying ua base  ub base as two training sets  and
ua test  ub test as two test sets for them  respectively 

    

 

   

   

   

   
    
k value

    

    

    

    

 a 

running the baseline predictor  we get the result listed in
table   

timing curve for different k values based on two datasets
   

table    performance of baseline
   

ub data

       

       

it shows that by choosing proper parameters       we can
obtain reasonable results on rating prediction  note that
different   s will result in distinct rmse  our goal here
is just to provide some values to compare with following
results  so only one pair of reasonable parameters is used
here 

in the problem that we apply knn to estimate the movie
rates  we use a similarity matrix to measure the distance
between each item  so  this method should be more
precisely named as item based knn algorithm  the
approach is described in detail in      to measure the
similarity between items  we choose pearson correlation 
the similarity between item i and item i can be calculated
as follows 







   

   

   

   

   

 

   

   

   

   
    
k value

    

    

    

    

 b 
fig    the  a  rmse curve and  b  timing curve based on
different k values 

    knn  k nearest neighbor 

from the above curves  we are able to choose a proper kvalue to achieve reasonable estimation performance  for the
particular training set in our project  an appropriate k value
is suggested ranging from     to      
rmse based on different k values for various training subsets
   

    





r

 

r
r

 

r


r


 


r
r

leave out
leave out
leave out
leave out
leave out
leave out
leave out
leave out
leave out
leave out

rmse

similarity i   i


   
elapsed time

rmse

ua data

 

r
 

here  u i is the set of all users who has rated on i before 
u i is the set of all users who has rated on i   u i 
u i is a set of users who has rated both items  r is the
average rating of all ratings given by user u 
since the performance depends on k  number of nearest
neighbors  we try different ks in the same training set  and
evaluate the corresponding performance by measuring the
rmse  using two database ua and ub  the rmse curve
based on different k values is shown in fig   a   while the
corresponding timing curve is illustrated in fig   b  

    

 

   

   

   

   

    

    

    

    

training set 
training set 
training set 
training set 
training set 
training set 
training set 
training set 
training set 
training set 

    

k value

fig    rmse curve based on different k values for leaving out
different training subsets 

the above model is then further improved by using    fold
cross validation  we split the data set ua base into    sets
and perform    fold cross validation on ua  base ua   base  the rmse curve in terms of different k values
on the    training subsets is illustrated in fig    the

 
 
 
 
 
 
 
 
 
  

fisuggested k value according to the curves is ranging from
    to       which is similar to the result without cross
validation  the smallest rmse value in the overall
simulation result is         

with        
defined in section     and      in our
project    are initialized using decoupling method  and
  s initial values remain to random vectors  their
updating rules are 





    stochastic gradient descent
the rating estimation equation for stochastic gradient
descent method could be written as 


 

describes the overall interests of the users to
where 

illustrates the interests one
particular items  and
particular user has for the items  denote the prediction error
   then  
are updated using gradient
descent following the equations 
























 

 
 
 

in our project  we choose the learning rate 
     for svd method 
 
 
      svd  

     

 

based on svd method  svd   improves the accuracy by
adding an item related factor vector    as described
in      the prediction model becomes 
 


 

 

 


where   are learning rates  and the initial values for   
are set as random vectors with entries uniformly distributed
in        after several experiments for different choice of
    we select
     
      the rmse curve with
different k values is shown in fig    
rmse vs  k value curve using stochastic gradient descent

where
is defined as the set in which the corresponding
items are rated by user   the updating equation is also
improved as provided in      in our project  the learning rate
      
      
      
is chosen as 
     for a relatively good performance 

     

      asymmetric svd
the asymmetric svd method improves the base svd as
described in      in our project  we revise the estimation
equation as in order to reduce computing complexity 

                
     

rmse

    

 


     

 




a relatively better learning rate set is chosen as  
     
        

     

 

     

     

 

  

   

   

   
   
   
k value  dimension 

   

   

   

   

the rmse curves based on different k values  dimension 
for svd and its variants are in fig    
rmse vs  k value  dimension  curve using svd and its variants

fig    rmse curve based on different k values dimension 
using stochastic gradient descent method

    

the rmse curve shows a better performance than both
baseline predictor and knn 

the svd method could be considered as combination of
baseline predictor and stochastic gradient descent  the
overall prediction equation is written as in     


    

rmse

    svd and its variants 
 
      svd

svd
svd  
asymmetric svd

    

    

    

    

    

 

  

   

   

   
   
   
k value  dimension 

   

   

   

   

fig    rmse curve based on different k values dimension 
using svd and its variants

fico clutering using bvd
     

    global neighborhood model
     

r



b

b

 r u  

    
     

rmse

this model allows an efficient global optimization scheme 
it is able to integrate implicit user feedback  we abandon
the user specific weights in favor of global weights which
are independent of a specific user  the estimation is 

     
     
     

 


r

b

w

c

    
     

the updating rule for w and c is 
w w

  r u   e

r

  r u   e

c c

     
  

b

w

c

apply this algorithm on ua and set the parameters as 
                we can get for uatest is 
rmse           
this is much better than the baseline and knn predictor 
but is worse than those matrix factorization methods 
    co clustering by bvd  block value decomposition 
recently  traditional data clustering methods such as kmeans has been applied in the transformed space  different
from svd  it introduces a block value matrix  the algorithm
is given by the minimization of 


 
is user cluster matrix 

is
where

is block value matrix  k
movie cluster matrix and 
is the number of clusters we select  
   

apparently  the objective function is convex in u  r and m 
so we can derive an em style algorithm that converges to a
local minimum by iteratively updating the decomposition
using a set of multiplicative updating rules 



  

  

  

  
k

  

  

  

  

fig    rmse vs  k values dimension  for co clustering using
bvd

this algorithm successfully captures the clustering feature
of both users and movies and the relationship between their
clusters  from the result  we can see that this algorithm can
generate better performance than previous methods  it can
reach a smallest rmse at certain k  and this value  we
found  depends highly on the characteristic of the dataset 
   conclusion
in our project  various rating prediction algorithms are
applied using the movielens dataset  the methods based
matrix factorization outperform the other ones  which only
use the stochastic information of the training database 
adding the block value matrix can further improve the
performance 
   references
    j  breese  d  heckerman and c  kadie  empirical analysis of
predictive algorithms for collaborative filtering  technical
report of microsoft research       
    f  ricci  l  rokach  b  shapira  p  kantor  recommender
systems handbook 
    b  sarwar  g  karypis  j  konstan and john riedl  item based
collaborative filtering recommendation algorithms  proceedings
of the   th international conference on world wide web      
        
    b  long  z  zhang and p  yu  co clustering by block value
decomposition  sigkdd    august             
    t  huynh and d  vu  using co clustering for predicting movie
rating in netflix 


    y  koren  factorization meets the neighborhood  a
multifaceted collaborative filtering model  kdd   

running this algorithm for different values of k until
converge  we can get the following curve of rmse on
dataset ua 

fi