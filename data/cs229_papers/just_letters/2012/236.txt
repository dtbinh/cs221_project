nikhil bhargava  andy fang  peter tseng
cs     paper

machine learning an american pastime
i  introduction
baseball has been a popular american sport that has steadily gained worldwide
appreciation in the past few decades  over the years  sports statisticians have become very
interested in analyzing data from baseball games  coming up with various metrics ranging from
the simple  rbis  runs batted in   to the more complex  ops  on base plus slugging percentage  
to get a numerical sense of player performance  more recently  the application of statistics to
baseball has reached pop culture fame in the movie  moneyball  we wanted to predict the
outcome of an upcoming baseball game based on prior information on the teams respective
performances as well as general trends in baseball using a predictive machine learning model 

ii  analyzing the problem  our initial hypotheses
baseball as a sport has many interesting characteristics that we tried to account for in our
attempts at building an effective predictive model  one issue that consistently arises with
baseball is that the sport itself is highly variable  if the best and worst team play each other backto back  it would not be unreasonable to predict that they split their games  as a result  we
predicted that it is of key importance to include factors that measure a teams recent success  for
example  if we looked at a players batting average over the past     games  it is likely that the
batting average over this time interval would not change much from one game to another 
however  if we were to also examine that players performance over the last five games  the
result would change much more dramatically from game to game  furthermore  we originally
hypothesized that short term metrics could help with factors like momentum and streakiness 
which are highly imprecise yet still considered important to assessing the strength of a team 
this streakiness also means that a short term view should not be the only data we
include about a player  thus  we hypothesized that it is also important to account for players
performances over the course of previous games  spanning months and even years past 

 

fiiii  obtaining data
while there exist several databases loaded with baseball statistics  we were only able to
find ones that aggregated player statistics for an entire season  for the purposes of our project  it
was imperative that at any given moment in time  we had the most up to date player statistics and
metrics of their recent performances  consequently we collected game data in the mlb dating
back to      but excluding the      season via retrosheet org  this data provided us with more
than        games and was arranged in the following fashion  for each year  there were plain
text files delineating the roster of each team  and there were csvs for each game scrupulously
detailing the play by play events  we then converted this unstructured data into relational
data  after obtaining our data  we decided to hold out the entire      season from our data
and to reserve it for a final run where we better estimate the true accuracy of our classifier  we
hold these data points out to prevent any sort of fitting to the data  for our normal development
cycles  we elected to test on games in      and to train on only the      and      seasons to
increase the throughput of our learning algorithms  this decision was justified as even in two
seasons we had      training examples  which was roughly ten times larger than our largest
feature set 

iv  machine learning strategy
we looked at many different aspects of the machine learning process to determine what
algorithm would produce the best output for us  the two elements we varied from run to run
were     the feature set and     the learning model 
initially  we decided that a support vector machine  svm  would provide a sufficient
model for predicting baseball game outcomes and that it would be a good model for us to test
our feature set on  since we assumed that the learning model was sufficient  for a given matchup between two teams  our initial feature set simply looked at team related aspects such as the
head to head performance of the two teams  the overall win loss record of a team over the last
n games  the overall run differential  of a team over the last n games  etc  we called this initial
feature set the team features  we then decided to append features related to individual players
career statistics for each of the starting nine batters in each teams lineup  these stats included but
were not limited to each players career batting average and on base plus slugging percentage 
 

run differentials differ from win loss record because run differentials factor in how much a team won by 

 

fiwe called this new feature set the team data and career players data features feature set  lastly 
we decided to add on information about individual player momentum  examining features like
a players batting average over the past n games and so on  this feature set contained all the
features we looked at 
optimizing the svm itself proved to be a nontrivial task  we first chose to look at
different kinds of kernels we could apply to the model  and in the end  we decided that a radialbasis function  rbf  was the most appropriate kernel to use for our problem since we found that
other kernels  such as linear  polynomial  and sigmoid functions  performed consistently worse
than the rbf kernel  we used grid search over the two rbf variables c and  to fine tune our
svm  we found for many values that the svm ended up predicting that the home team would
win for every game  and we noticed that there was a boundary between value combinations of
c and  that caused the svm to always guess the home team winning and combinations that
caused the svm to perform worse than guessing that the home team would win  however  along
this boundary  we found that the svm actually out performed the model that always predicted
the home team winning  a heatmap of a part of the grid search results below illustrates this
boundary phenomenon  where white space represents the area where the svm always roots for
the home team  red space is where the svm performs worse than rooting for the home team  and
green space is where the svm outperforms always rooting for the home team 

after testing the performance of the three feature sets on the support vector machine 
we decided to experiment with different learning models to see whether or not they could
outperform the svm  we looked at naive bayes  perceptron  multi layer perceptron models and
compared their performances to that of the rbf svm and came up with the following results 
which validated our prediction that the svm was a good model to start out with for predicting
the baseball game outcomes 

 

fiv  analyzing results
analyzing our results  we see that to a large extent  our guesses are affected by the high
variability of the problem  and in fact the strategy of always picking the home team seems to
outperform many of our classifiers  notably the perceptron and multi layer perceptron  in terms
of our results generally  we saw a large drop off between our training results and our testing
results  we hypothesize that this could be due to overfitting of our data  in a few select cases 
certain feature sets outperform the always pick the home team strategy  but we feel like they do
not exceed the strategy by a large enough margin for us to consider it to a superior classifier 
one noteworthy point was that our naive bayes classifier did roughly as well on the
testing set as it did on the training set  and additionally it seemed to outperform the strategy of
always guessing that the home team wins  future steps could involve expanding on our naive
bayes classifier to see whether additional features would help in its prediction  at least initially 
we decided not to include individual player features in our naive bayes classifier as we had
no good standard for discretizing a continuous valued range  such as batting average  into
individual buckets 
since winning and losing a baseball game  the two possible classifications for the svm 
happen at the same rate  using the accuracy of the models predictions as a measuring stick is
reasonable  however  we also tried using the f  scoring mechanism to see if they tell us
anything more meaningful about our features than simple accuracy 

 

fiit is interesting to observe that though measuring by accuracy seems to indicate that having
a learning model that accounts for features about the team  individual career statistics  and
individual momentum statistics is better than one that does not  but measuring by f  score
actually gives the opposite result  with the research we conducted  we believe it is inconclusive
which measurement system gives us a clearer picture of what the right feature set is for
predicting baseball game outcomes 

vi  conclusion
in conclusion  the feature set and classifier combinations that we explored performed
only marginally better than using the simple heuristic of always selecting the home team to win
even after optimizations like grid search  we highly doubt that performing a more extensive grid
search or trying another classifier will yield better results  however  we suspect that the feature
sets that we chose hindered our performance  the natural follow up question is  what does this
mean in the context of baseball  with moderate confidence  we assert that 
 head to head team statistics
 recent win loss and run differentials versus other teams
 metrics  of individual players batting performances in recent games 
 metrics of individual players batting performance for their entire careers
do not have a large impact on the result of an individual game  we conjecture that adding
features to capture more information about pitchers will increase performance of the various
classifiers  we recommend that future baseball statisticians pursue models which account
heavily for pitcher data  ultimately  we will not be taking our machine learning project to
vegas 

 
 

metrics include ops  batting average  strikeout rate  and walks per game
recent games include the last              and    games

 

fi