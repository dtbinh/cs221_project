thankbeer  a beer recommendation engine
final report
robert wilson
department of electrical engineering
stanford university
email  rwilson  stanford edu

abstractwe discuss a beer recommendation engine that
predicts whether a user has had a given beer as well as the rating
the user will assign that beer based on the beers the user has
had and the assigned ratings  k means clustering is used to group
similar users for both prediction problems  this framework may
be valuable to bars or breweries trying to learn the preferences of
their demographic  to consumers wondering what beer to order
next  or to beer judges trying to objectively assess quality despite
subjective preferences 

i  i ntroduction
the beer drinkers of today face an unprecedented variety
of options  this variety poses its own problem for novices
and experts alike  what should i drink next  few things in
this world surpass the disappointment of drinking bad beer 
yet given the subjectivity of taste  to whom should an unsure
patron turn for advice on what to order  knowing the preferences of the customer can aid a bartender in recommending a
drink  but a properly trained machine learning algorithm has
the potential to outperform even the beer connoisseur in this
task 
before making a recommendation  a human or machine
must first learn the preferences of the patron  this learning process inevitably follows some combination of two approaches  focusing on beers or qualities  in the former  we ask
the patron their favorite beers  in the latter  we ask what kinds
of beers  hoppy  sour  etc   the patron likes  these questions
address what a patron likes and why  both approaches provide
insight into consumer behavior and the qualities of a great
product  and may be used in conjunction to make better
recommendations 
an obvious starting point is to ask the user of a machine
learning based system to provide a list of their favorite beers 
a search functionality included in our system permits the user
to do just this  casual users  however  may have trouble freely
recalling their favorite beers  so a prompt based approach may
help users remember beers they had forgotten aboutprovided
we can predict which beers someone has had better than they
can remember  there is an additional benefit to being able to
predict whether a user has had a beer  or at the very least has
access to it  if we recommend  e g  a beer only available in
germany to a person in california  the recommendation is not
valuable regardless of its validity  for someone to have had
a beer  it necessarily must have been available to them  so
predicting availability is correlated with predicting whether a

user has actually tried a beer  even if a person has access to
a beer  they may have chosen not to order it due to personal
preferences  so predicting whether a user has had a beer has
some overlap with predicting their opinion of it 
the rating assigned to a beer depends on the objective
quality of the beer  colored by the preferences of the drinker 
averaging the ratings of many may converge to a measure
of the objective quality of the beer but does not account for
individual taste  thus any impersonal measure of the quality
of a beer is of limited utility  ideally we should ask only those
individuals who like the same beers we do to recommend
beers  clustering users based on preferences permits just this 
gathering data is often a non trivial task in designing a
machine learning algorithm  we set up www thankbeer com
to solicit ratings and test predictions  as of this report  we
have roughly thirty users and nearly two thousand data points
on which to test the algorithms discussed here  users are
presented with a series of beers to rate so their preferences
may be identified  they may search for specific beers or
breweries  from a database of roughly five thousand beers
mostly from the united states     they may also search for
a bar  leading to a beer menu which is sorted according to the
personalized preferences of the viewer  sorting beer menus
based on personal preferences is one of the major goals of
this project 
ii  p redicting past p urchases
for the purposes of predicting past purchases  we define
the experience matrix r having elements rij            
where rij     means user i has told us they have never
had beer j  rij      means user i has told us they have had
beer j  and rij     means we do not know whether the user
has had this beer  of course rij really is either   or    
the goal of this section is to estimate it  let us first discuss
how we initially predicted this  which will form a convenient
benchmark against which we may measure the success of more
advanced algorithms 
in order to begin gathering data as quickly as possible  we
initially implemented a correlation based approach to predicting whether a user i has had a beer  for appropriate weights
 ik         measuring the correlation of users i and k  we
  courtesy 

www beerme com

fipredict
p
rij   sign

k  i  ik rkj

p

k  i

 

 rkj  

in determining the correlation coefficient  ik   we wanted to
capture the idea that two users having the same beer says
more than two users not having had a beer  given the typical
user has had relatively few beers   thus we defined
 
   rij     
 
rij
 
rij otherwise
and using the pearson correlation for  ik  
p
 
 
 
 
jb  rij  ri   rkj  rk  
qp
 ik   qp
   
 
 
   
jb  rij  ri  
jb  rkj  rk  
with bar denoting average over the absent index  sums  including in computing the unshown averages  are over only those
beers for which rij and rkj are actually known  in the case
these two users have no beers in common  their correlation is
undefined 
by considering all data gathered to date  we can apply the
leave one out cross validation process to measure the success of this benchmark algorithm  we remove a single datum 
predict the label for that datum based on the residual data  and
count the errors  because we would like to recommend beers
the user can easily access without flying around the world  we
are concerned primarily with the rate of false positives  cases
where we thought a user had had a beer  but in fact had not  
this is most important when requesting ratings from the user
for the purposes of learning preferences  the user can only rate
beers they have had  it is frustrating only to be presented beers
the user has never heard of  thus when learning preferences  a
natural strategy is to present the beer we are most confident the
user has had  but not yet rated  the error of the algorithm  then 
is the number of false positives divided by the total number
of positives  our benchmark algorithm has an error of   
this seemingly large error is partially because only   of
our data points are positive  which in turn reflects the failure
of our algorithm to present the user with beers they have had 
lets try a different approach  we model the event that
user i has had beer j as a bernoulli random variable with
parameter j   that is  all users are considered the same  and
rij is simply drawn from this distribution  taking on value   
with probability j and   with probability     j    we can
estimate j as
p
  rij      
j   pi
i   rij      
and predict rij     if j       and   otherwise  simple
enough  but the resulting error is    lets adopt a clustering
approach  modeling rij  bern c i j with user i in cluster
c i               k   the updated estimate
p
  c      c i    r j      
c i j   p 
    c      c i    r j      

fig    

error with increasing number of clusters

considers only those users in the same cluster as user i 
while user ratings are restricted to be    cluster centroids
are allowed to take on any value  being the average of the
user ratings in that cluster  so c  rk b   where  b  is the
number of beers  has entries
p
  r j   c      i 
cij   p
    c      i 
we use the l  norm in determining the cluster for a user   
x
 r j  cij  
c      arg min
i

j

summing over only those beers for which we know r j   we
use the standard approach  initializing centroids randomly 
and iteratively assigning users to clusters and redetermining
centroids until convergence  fig    shows the mean error
as the number of clusters increased  because of the random
initialization  the error varied from run to run  so twenty trials
were considered for each data point shown in the figure  with
the associated standard deviation shown as dashed lines about
the mean  this type of graph is displayed throughout this
paper  dashed lines always represent one standard deviation
above and below the mean  shown as a solid line 
we found something interesting  the error actually diminished if we ignored one of the users  fig    shows in red the
loocv error when ignoring said user  this user was unusually
experienced  we hypothesize because we have relatively few
users  he unduly influenced the clustering  since he has had
more beers than anyone else in this study only one other
person was in his cluster  the author  actually  except when
the number of clusters was low  thus any beer he has had the
author hasnt led to a false positive  this shows the importance
of having numerous persons in each cluster 
we must decide the number of clusters to use  for the
purposes of this report  and in light of the number of users  we
simply looped over all the options  capping at half the users 
in light of the aforementioned finding  fewer clusters having

fifig    

brewery and state based clustering error

many users are preferable for robustness  however  our data
shows the error continued to decrease as the number of clusters
was increased  intuition sheds some light on the situation  we
conjecture based on personal experience there are two types
of beer drinkers  aficionados who have tried many of the beers
available in their area  and novices  who do not actively seek
out good beers and only drink what is available at the typical
bar or party  we conjecture further that novices throughout
the united states will have had mostly the same beers  while
aficionados will exhibit geographical diversity owing to the
small distribution region of most craft breweries  thus the
number of clusters  intuitively  should be one  for the novices 
plus the number of major brewing centers represented in the
database  at this point there is insufficient data to confirm or
reject this hypothesis 
one method to make better use of a small data set is to
project the features to a smaller space  the problems we
encountered are partially due to few people having had a particular beer  yet in predicting availability  it seems reasonable
to conjecture that if a person has access to one beer from a
brewery  they likely have access to others  while the flagship
beer of a brewery tends to have a wider distribution region than
smaller batches such as seasonal beers  it seems reasonable to
base our clustering algorithm on breweries instead of beers 
if two users have had beers from the same brewery  they are
similar  fig    shows the resulting loocv error  this brewerybased strategy did not perform as well as the original k means
approach  clustering based on the city or state of the brewery
did still worse  new ideas are needed to make further progress 
iii  p redicting r ating
a user may rate a beer out of five stars  the prediction strategy initially implemented  again in the interest of
getting something working as quickly as possible  mirrors
the correlation based approach that formed our benchmark
strategy for predicting whether a user had had a beer  for
this section  rij                    represents the rating assigned

fig    

prediction error

by user i to beer j  with   denoting the user has not rated this
beer  perhaps because they have not had it   we would like to
predict how a user would rate a beer if they had it 
the correlation based strategy predicts a weighted average
of the ratings other users have assigned the beer under consideration  the rating profile for a user i is normalized according
to 
rij  ri
 
rij
  qp
   
 
 r

r
 
ij
i
j
the normalized predicted rating for user i is
p
 
k  i ik rkj   rkj     
 
p
rij  
k  i   rkj     
where ik is the pearson correlation for the ratings of users i
and k  the unnormalized predicted rating is found by inverting
equation   and then rounding to the nearest integer   rounding
was not initially used  but is useful to compare against the
multinomial distribution based methods discussed below   via
the same leave one out cross validation procedure discussed
above  we may predict the rating for a single datum using
the remaining data and compare against the actual value  the
errors  defined as the difference between prediction and reality 
were distributed as shown in the histogram of fig     the
approximate symmetry of the histogram shows the strategy
overrates as often as it underrates  the average of the absolute
value of the errors was   
we can model the rating as being drawn from a multinomial
distribution
where rij   k with probability jk   k               
p 
  k   jk     for all beers j   which ignores the individual
preferences of the users  we estimate
p
  r    k 
jk   p  
    r j     
the predicted rating is arg maxk jk   alternatively we could
simply predict the average over all ratings and round at the
end 

fifig    

beer and style based clustering prediction error

we can cluster users similar to before  but we anticipate 
because the factors influencing taste are significantly more
complicated than those involving access to a beer  the number
of clusters needed will be much higher than before  resulting
in fewer data points per cluster and a larger resulting error  we
can apply a similar strategy as when clustering via breweries
to reduce the state space  we clustered by style  users who like
similar styles are similar  styles  e g  stout or ipa  were taken
from the beer judge certification program handbook  fig   
compares the performance of beer and style based clustering 
here  the error actually increases with increasing number of
clusters  perhaps due to insufficient data 
normalizing the ratings improves the error rate  but not the
trend  as shown in fig     clearly these clustering strategies
do not succeed in predicting the available data  projecting
onto still smaller spaces may help  the style based clustering
strategy neglected the relative similarities between styles  for
example  a pale ale and an ipa are similar  the styles could be
combined  some styles are sufficiently uncommon they could
be neglected altogether for the purposes of clustering  it must
be remembered  however  that style popularity differs from
region to region  styles common in germany may be unusual
in the united states 
at this point we must consider not only what the user
likes  but also why  users of www thankbeer com can apply
keywords like hoppy or sweet to beers and in the very
near future they will be able to assign a degree  letting the
community decide that one beer is hoppier than another  we
can then project each beer onto this lower dimension feature
space  the number of relevant features is likely much less
than the number of beers or styles  and perform the clustering
there  this will hopefully result in far fewer clusters  giving
more training examples per cluster and lower error  more
importantly  it permits the users to tell us directly why they
like or dislike the beers they do 

fig     beer and style based clustering prediction error based on normalized
ratings

iv  f uture w ork
the plan laid out for predicting rating based on clustering
in feature space is in progress  the best method for predicting
user rating is still the correlation coefficient based approach
implemented initially  although clustering reduced the error
associated with predicting whether a user has had a beer 
more work is needed since the error rate is still unacceptably
high  combining the two prediction problems may help since
personal preferences influence whether a user has had a beer 
modeling user ratings as a mixture of gaussians instead of a
multinomial distribution provides may provide more flexibility 
we would remove the requirement that predicted rating be an
integer  the rating would be normally distributed with mean
and variance depending on the cluster  due to the complexity
of tastes  a neural network seems like a promising possibility 
eliminating the clustering approach and modeling preferences
as a continuous spectrum based on some combination of 
e g  sweetness and hoppiness as reported by the users 
one potentially valuable excursion would be to apply these
methods to beer judging  which is sometimes criticized for emphasizing adherence to arbitrary style guidelines  this policy is
intended to place beers of a common style on an equal footing
and reduce the impact of the judges personal preferences  in
practice  beers that do not fit neatly into a particular category
are punished  regardless of how enjoyable they are  the effect
is to discourage creativity and the evolution of styles that led to
the fairly recent explosion of craft brewing in the first place  a
system that learns the personal preferences of judges permits
them to rate beers as they see fit  knowing their biases can be
corrected for and ratings combined to provide an assessment
less sensitive to style guidelines 
acknowledgment
the author would like to thank the early adopters of
www thankbeer com who donated ratings and put up with
an admittedly klunky interface 

fi