automated hand recognition as a human computer interface
sergii shelpuk
softserve  inc 
sergii shelpuk gmail com

the key factor of success in hci is making the
experience of software product as close as
possible to the experience of the real world
interaction  considering the examples above 
visual interface and mouse are much more alike
to the real world than the console  however 
interacting with the software using our own
fingers is even better since almost every
interaction of a human being with the real
world is of tactile  kinesthetic  nature 

abstract
this paper investigates applying machine
learning to the problem of turning a regular
webcam into the input device and humancomputer interface by the hand recognition 
the purpose of the project is to create an
application for drawing and making notes on
the presentation by moving the hand in front of
the laptop camera  for the purpose of this task 
there were created two separate datasets 
applied color filtering and trained two neural
network based classifiers  for the purpose of
accuracy improvement  also there was
introduced an algorithmic threshold based filer
for the drawing 

this concept can be extended to the other types
of interfaces as well 
today  webcam is an integral part of almost any
computing
device 
laptops 
tablets 
smartphones  tv theaters  great number of ip
phones  telepresence devices  atm and even
some cars have integrated webcam often with
the purpose of capturing and transmitting
someones face during the conversation 
however  from the hci point of view  their
potential seems to be greatly underestimated 

   introduction
human computer interaction  hci  focus is one
of the most popular and promising ideas in
software and hardware design of the last
decade  computer evolution and success stories
 as well as reasons of failure  of numerous
products were based on new types of interface
and user experience that make the product
convenient and easy to use for as many
potential customers as possible  in the early
days of personal computers  windows based
interface and mouse made a revolution in pc
world through making interaction with the
programs more intuitive than the console 
today  we are witnessing another hci enabled
revolution  smartphones and tablets  removal
of the mouse and keyboard and ability to
access the software directly with the fingers
make these devices such user friendly that even
children who do not have the access to the
education who and have never seen any
computer before can use tablets to learn how
to read and write by themselves   the
importance of this cannot be overestimated 

this project is devoted to the development of a
new type of hci allowing the presenter to make
notes and draw on the presentation using just
his her fingers with no additional device by
hand recognition with a webcam 

   data set
two separate datasets were created for the
purpose of this project  hand image dataset and
finger figure dataset 
hand image dataset was obtained by capturing
the picture from the camera and breaking it
down into    x    pixel squares  after that  the
pictures with the hand were separated
manually  filtered and reduced to the   x  
pixels size 
finger figure dataset was obtained by breaking
down    x    pictures with the hand into

 

mit technology review  given tablets but no
teachers  ethiopian children teach themselves

   

fic pixel  r   is a vector of rgb values of the

  x   squares  after that  the pictures with
finger figures were separated manually 

original pixel 

    hand image dataset

c ref  r   is a vector of reference color  the

this dataset consists of      images of   x  
pixel size  the pictures are divided into two
types       pictures with human hand  positive
examples  and      pictures without human
hand  negative examples  

color of the fingertips in the current light
condition  

filtering

    r is a variance constant 

c filtered  r is a grayscale value of the pixel
after transformation 

regular rgb color image contains information
about pixel colors that is redundant for the
purpose of this project  higher number of
features requires more data to train the
accurate classifier  converting the image into
grayscale does not fully address the problem 
grey intensity of every pixel varies with the light
condition  additionally  the grayscale image still
contains the background that also affects the
classifier performance 

intuition behind this filtering is the following 
after the transformation  grayscale picture has
only the figures that are similar in color to the
fingertips  everything else is white 

 a 

to address this problem the training set
pictures were processed with the skin detection
filtering 

 c 

figure    original image  a   greyscale image  b 
without filtering  still contain a lot of redundant
information  and filtered image  c   positive
example from the hand image dataset

the goal is to transform an rgb color image in
the form that contains only evidences of the
hand but not the background or any other
redundant information  the transformation also
should provide this result independent of light
condition and white balance of the original
picture 

 a 

the filter uses the fact that in standard
grayscale image the pixel with intensity  
corresponds to the black color  the pixel with
intensity     corresponds to the white color
and all the values between them corresponds to
the shades  for the filtering  rgb value of the
fingertips is used as a reference color  each
pixel of the image is transformed according to
the formula  

c filtered

 b 

 b 

 c 

figure    original image  a   greyscale image  b 
without filtering and filtered image  c  
negative example from the hand image dataset
this allows to use the product with the different
light conditions by changing value of the c ref  

c pixel  c ref t c pixel  c ref  



 
       e





    finger figure dataset
this dataset consists of      images of   x  
pixel size  the pictures are divided into two
types       pictures with finger figure  positive
examples  and      pictures without finger
figure  negative example  

 

according to the class restrictions  the filtering was written from
scratch

   

fino filtering was applied for this data set
because grayscale image gives the easily
recognized pattern 

 a 

performance  performs filtering and breaks it
into   x   squares and tests using two
classifiers  first one is looking for a hand on the
picture  hand image classifier  
if it returns true  the image contains hand 
then the program transforms the coordinates of
the positive square to the coordinates of the
original    x    image  takes    x    square
with the hand  transforms it to the greyscale
and breaks into   x   squares 

 b 

figure    positive  a  and negative  b  examples
from the finger figure dataset

   system design

each of the   x   square is tested with the
second classifier  if it returns true  the image
contains finger figure  then the program
transforms the coordinate of the square to the
original coordinates and considers them as a
drawing point 

the system overall consists of two architectural
components octave scripts and python
program 
octave scripts functionality 

for the purpose of this application  both
classifiers should perform on two classes that
are non linearly separable  two possible
algorithms performing well on non linear
classification were considered for the purpose
of this project  svm with polynomial kernel and
neural networks  nn  

   importing pictures and transforming them
into training set  cross validation set and
test set
   training classifiers
   exporting weights in csv format
python program functionality 
loading weights from csv files
capturing video from camera
performing skin detection filtering
detecting hand on the screen
detecting finger figure
transforming coordinates of the finger
figure to the screen coordinates for the
mouse position
   performing threshold based filtering
   drawing a figure based on the coordinates
of the finger figure

the table below represents best achieved
performance of two algorithms on the datasets 

opencv     library was used for the purpose of
video capturing  resizing and transforming into
grayscale    numpy       library was used for
linear algebra calculations in python 

also  regularization was used to avoid
overfitting  regularization parameter was
selected based on the cross validation set
performance 

    classifiers

    hand image classifier

the system needs to find the finger figure on
the image taken from the webcam  for this
purpose  python program captures the image
from the webcam  reduces its size from
   x    to    x    for the reason of

architecture of the hand image classifier and
regularization parameter was selected based on
the classifier performance on the hand image
dataset 

 

parameter    nn architecture is represented
as following  input layer size hidden layer

  
  
  
  
  
  

svm
nn

hand image
dataset
      
      

finger figure
dataset
     
      

so  nn classifiers were selected for the
application  backpropagation was used as a
training method 

the table below represents the accuracy of the
three layer nn architecture given regularization

according to the class restrictions  both neural network  nn 
classifiers were written from scratch  opencv internal nn
functionality was not used for the purpose of this project

   

fisize output layer size  some combinations of
architecture regularization parameter was not
tested because they are clearly supposed to
give the performance lower than already found
maximum 


 
    
    
   
 
 
 
  
  
  
  
  

     
  
 
     
     
     
    
     
     
     
     
 

     
   
 
    
     
     
     
     
     
     
    
     

     
    
 
     
     
     
     
     
 

     
    
 
    
      
     
     
     

for the finger figure classifier  the same analysis
was performed to define the better architecture
and the better regularization parameter  the
results of the analysis are presented in the table
below 

     
    
 
    
     
     
     
    


 
   
 
 
 
 

     
    
 
     
     
     

           
    
    
 
 
     
     
            
    
     
     
     
     
    

so three layer neural network with architecture
           and regularization parameter

     

was chosen for the finger figure
image classifier 
the performance of the classifier is specified in
the table below 

four layer nn architectures were also tested
but they did not show any significant
improvement of the performance  so three
layer neural network with architecture
           and regularization parameter
    was chosen for the hand image
classifier 

test set size
accuracy
true positive
false positive
true negative
false negative
precision
recall
f  score

the performance of the classifier is specified in
the table below 
test set size
accuracy
true positive
false positive
true negative
false negative
precision
recall
f  score

     
   
 
    
     
    
 

    
      
   
  
    
  
      
      
     

as well as for hand image classifier  precision is
a key performance indicator so this classifier is
acceptable as well 

    
     
   
  
    
  
     
     
    

    threshold based filtering
the main problem with the application is false
positives  every false positive not only
consumes cpu resources to evaluate the
picture in details looking for finger figure  but
also in case of false positive of the finger figure
classifier  it produces a false drawing point 
despite pretty high level of accuracy  this
happens and still makes the method
inapplicable 

for the purpose of this project we really care
about precision since false positives affects
performance of the system overall  from this
point of view  the performance of the classifier
is acceptable 

to address this issue  additional filtering
method was introduced  each drawing point is
represented by two coordinates x and y  we

    finger figure classifier

   

fi

make assumption that since the user moves the
hand smoothly  so two sequential drawing
points cannot be far away from each other  if
the distance of the next drawing point found
and previous drawing point exceeds some
threshold d tr then the new drawing point is
likely to be a false positive and should be
excluded from the drawing point lists for the
current line 



after the filtering  the drawing point is
connected with the previous drawing point by
emulating mouse movement with the left
button pressed 



the figure below represents the example of
using the application to make some note on the
powerpoint presentation 

using the fact that if a    x    square
contains a hand  then the shifted for       
pixels square should also contain the hand 
the additional classification can be
introduces to improve the accuracy of
classification
currently  the application uses straight
lines to connect drawing points  this
results in quite ugly lines  drawing points
can be divided into groups of three and
each group can be approximated by the
second order polynomial  this will make
the drawing smooth 
additional algorithm could be introduced
to predict where the finger figure most
likely will be in the next timeframe  next
screen capture  based on the previous
movements  this can reduce the cpu work
and the amount of pictures to classify thus
reducing the false positive chance 

references
robert l  harvey  paul n  dicaprio  and karl g 
heinemann a neural network architecture for
general image recognition  the lincoln
laboratory journal volume    number        
         
c  c  yang  s o  prasher  j  a  landry  h s 
ramaswamy and a  ditommaso  application of
artificial neural networks in image recognition
and classification of crop and weeds  canadian
agricultural engineering vol      no   
july august september               

figure    drawing on the presentation with the
developed application

christopher m  bishop  neural networks for
pattern recognition oxford university press 
nov         

   conclusion and future work
clearly  the quality of the drawing on the
current stage is not enough to call the
application a completed product  however  it
shows that machine learning can turn regular
webcam into interface for human computer
interaction 
the project has a lot of opportunities for
improvement and future work 


deep learning techniques and dropout
method can be applied to improve the
performance of the classifiers 
   

fi