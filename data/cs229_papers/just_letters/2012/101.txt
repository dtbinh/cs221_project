a  supervised  learning  method  for  seismic  data  quality  control  
travis  addair  
lawrence  livermore  national  laboratory  
  
  
  
background  
at  lawrence  livermore  national  laboratory   llnl   the  nuclear  explosion  monitoring  group  maintains  a  database  
of   over                waveforms   for               distinct   events   and           distinct   stations    we   had   recently   cross 
correlated   all   possible   pairs   of   waveforms   for   events   within        km   of   one   another   and   wanted   to   mine   this  
dataset   for   statistics    however    an   unknown   number   of   the   waveform   segments   contained   non seismic   signal  
artifacts   dominating   the   correlation    thus   rendering   the   correlation   value   meaningless      these   needed   to   be  
identified  and  removed  before  the  project  could  proceed   
  
manual  classification    labeling  
the  initial  cross  correlation  effort  resulted  in              correlations  stored  as  rows  in  a  database  table     each  of  
these   rows   contained   pointers   to   the   waveform   segments   that   were   correlated    the   band   into   which   each  
waveform  was  filtered   and  a  series  of  relevant  features  for  each  of  the  two  segments     table     describes  these  
features  in  greater  detail   
  
table     features  used  to  classify  segments  

abbreviation  
description  
avg delta  
average  of  the  distance   in  degrees   of  the  catalog  location  of  each  event  to  the  station  
varf  
time  variance  
vart  
frequency  variance  
t   
time  center  
window length    common   length  of  the  correlation  windows  in  seconds    
low corner  
low  corner  frequency  of  a  bandpass  filter   if  applied   
high corner  
high  corner  frequency  of  a  bandpass  filter   if  applied     
shift  
absolute  shift  in  seconds  of  the  second  trace  at  the  maximum    
sig rms  
rms  computed  in  signal  window  
sw snr  
short window  signal to noise  ratio  
lw snr  
long window  signal to noise  ratio  
tbp  
time  bandwidth  product  
pos kurtosis  
the  sample  kurtosis  if  positive      otherwise   http   en wikipedia org wiki kurtosis   
neg kurtosis  
the  sample  kurtosis  if  negative   as  a  positive  real  number      otherwise  
extr raw  
abs   median signal     mean signal         range signal   
  
in  order  to  determine  if  this  quality  control  problem  would  be  well  suited  to  machine  learning  techniques   we  
needed   examples   of   both   good   and   bad   data   from   our   correlation   table       by   visually   examining   the   raw   and  
filtered  seismograms  of  a  segment   a  domain  expert  could  discriminate  between  valid  seismic  data  and  invalid  
artifact dominated   data    to   facilitate   rapid   classification   of   segments    a   program   was   written   to   randomly  
sample  from  the  over      million  correlations  in  the  table   and  display  the  raw  and  filtered  seismograms   screens  
    and        for   all   the   unlabeled   waveform   segments       when   viewing   each   sample    the   operator   was   given   the  
choice   to   mark   the   segment   as   good   or   bad    after   which   the   result   was   saved   to   a   segment   quality   table   for  
future  use  in  automated  classification     
  
  

  

   

fiscreen     manual  classifier  showing  a  good   valid   segment   screen     manual  classifier  showing  a  bad   invalid   segment  

  
preprocessing  
unable  to  apply  if else  rules  to  a  satisfactory  degree  of  accuracy   a  supervised  learning  solution  was  explored     
we   selected   the   support   vector   machine    svm    as   our   classification   model   of   choice   due   its   popularity   as   a  
binary   classifier   capable   of   efficiently   operating   in   high   dimensional   feature   spaces       in   looking   for   third party  
svm  implementations   our  goals  were  to  find  an  api  that  was  open  source  and  could  easily  integrate  with  our  
existing  java  codebase   thereby  facilitating  interaction  with  the  database  and  visualization  of  waveforms     the  
libsvm    package   by   chih chung   chang   and   chih jen   lin   was   selected   for   being   the   most   prominent   open  
source   off the shelf  svm  with  a  java  implementation     
  
from  the  manual  classification  process           unique  waveform  segment  classifications  of  good   g   or  bad   b   
were  stored  in  the  segment  quality  table     after  exporting  the  data  and  associated  feature  values  to  a  flatfile   
python  utility  scripts  provided  by  libsvm  were  used  to  validate  the  data   scale  the  features  to  a            range   
and  run  a  grid  search  to  determine  the  optimal  parameterization  of  the  support  vector  machine  using  a  radial  
basis   function    rbf    kernel       literature   provided   by   the   authors   of   libsvm   suggests   using   the   rbf   kernel   in  
most   cases    particularly   when   the   number   of   features   is   significantly   smaller   than   the   number   of   training  
examples     having  over          examples  and  only      features   this  disparity  clearly  characterized  our  data  set   
continued  refinement  of  the  grid  search  ultimately  resulted  in    fold  cross  validation  accuracy  of           
  
automatic  classification    global  dataset  
using  the  parameters  obtained  from  the  grid  search   an  automatic  classifier  tailored  specifically  to  our  seismic  
data  processing  api  was  written  as  a  wrapper  for  and  extension  to  the  libsvm  java  library     in  contrast  to  the  
original   libsvm   framework    this   extension   was   able   to   process   data   by   querying   and   updating   the   database  
directly       by   fitting   into   our   existing   seismic   processing   api    the   svm   was   further   able   to   integrate   into   other  
applications  with  minimal  overhead   
  
to   verify   the   correctness   of   our   java   svm   implementation    holdout   cross   validation   was   performed   on   the  
labeled  dataset   reserving       for  training  and       for  testing     the  accuracy  for  this  test  was  similar  to  results  
from   the   cross validation   performed   on   the   flatfile    around             given   that   the   training   data   was   skewed  
towards  invalid  examples        precision  and  recall  were  also  calculated  and  determined  to  be  approximately       
and          respectively    for   segments   classified   as   good   using   the   same           split       from   the   standpoint   of  
improving   final   correlation   results    there   were   pros   and   cons   to   throwing   more   or   less   data   out       because   of   this  
ambiguity   accuracy  was  retained  as  the  primary  performance  metric     

                                                                                                                
 
 

  

  http   www csie ntu edu tw  cjlin libsvm     
  http   www csie ntu edu tw  cjlin papers guide guide pdf    

   

fias   a   means   of   determining   whether   it   would   increase   accuracy   to   gather   more   training   data    we   iteratively  
subtracted       samples  from  our       training  data  and  measured  our  training  and  test  accuracies  on  each  of  
these   subsets       as   figure       shows    we   were   clearly   seeing   diminishing   returns   as   our   training   set   increased   
indicating   convergence   to   a   local   maximum       indeed    even   after   growing   our   labeled   data   set   from           
examples   to             as   mentioned   above    we   were   unable   to   noticeably   increase   overall   accuracy       we  
concluded  that  our  misclassifications  were  the  result  of  minor  underfitting   and  that  additional  features  could  be  
explored  to  improve  performance   
  

accuracy  vs  training  set  size  for  global  
dataset  
     

accuracy  

     
    
    

test  accuracy  

    

training  accuracy  

    
    
   

      

      

      

      

       

       

training  set  size  

  

figure     adding  training  data  reveals  minor  underfitting   bias   suggesting  more  features  could  improve  accuracy  

for   the   purpose   of   eliminating   artifacts   from   the   correlation   results    we   decided   that         accuracy   provided  
sufficient   confidence   for   deploying   the   system   in   a   production   environment       to   demonstrate   that   our   results  
were   meaningful    i e     that   our   accuracy   was   truly   accurate     a   new   capability   was   added   to   the   manual  
classification  program  that   for  a  given  sample   used  the  trained  svm  to  predict  the  quality  and  display  the  result  
to  the  operator     this  prediction  tool  proved  to  be  a  valuable   informal  metric  for  evaluating  the  classifier   
  
classification  of  the  global  correlated  dataset  resulted  in  the  removal  of              correlation  pairs  from  the  
table    i e     over         of   the   correlations   were   determined   to   have   at   least   one   bad   segment        eliminating   so  
much   invalid   data   would   certainly   increase   productivity   for   analysts   attempting   to   sift   through   the   correlation  
results   but  ideally  the  automated  classifier  could  be  used  earlier  in  the  processing  pipeline  to  flag  non seismic  
events   before   ever   attempting   correlation       in   order   to   be   effective   as   part   of   this   detection   process    the  
automated   classifier   would   need   to   generalize   well   to   previously   unseen   arrays   of   seismic   sensors    or   at   least  
require  minimal  modification  beyond  gathering  a  few  thousand  manual  classifications  and  retraining   
  
forward  selection  was  applied  to  the  feature  set  as  a  means  of  informally  assessing  how  much  each  feature  was  
contributing   to   the   classifiers   performance    and   to   see   if   any   features   captured   redundant   qualities   of   the   data   
using  avg delta  alone   the  classifier  was  able  to  achieve  about       accuracy   but  given  that  the  dataset  was  
skewed         towards   bad   examples    this   wasnt   particularly   remarkable       the   selection   of   avg delta    a  
measure   of   the   distance   between   the   event   and   the   sensor    as   the   most   informative   feature   raised   questions  
about   this   approachs   ability   to   generalize   to   processing   unseen   seismic   arrays   in   real   time       due   to   being   a   non 

  

   

fiseismic   feature   of   the   station   and   event    avg delta   would   have   little   meaning   for   seismic   arrays   processed  
individually     
  
automatic  classification    local  dataset  
to  test  the  viability  of  applying  the  svm  approach  as  part  of  a  detection  pipeline   over  ten  thousand  segments  
from  an  entirely  new  dataset  were  manually  labeled     unlike  the  global  dataset  used  in  correlation   these  data  
were   all   local   to   a   single   seismic   array       directly   applying   the   svm   trained   on   the   global   dataset   to   the   local  
resulted  in  dismally  poor  accuracy  of  around          reparameterizing  the  svm  and  retraining  on  the  local  labeled  
dataset  increased  the  accuracy  substantially  to  around          however   inspection  of  the  newly  labeled  training  
data  revealed  that  they  were  skewed       towards  bad  examples     precision  was  determined  to  be  upwards  of  
       while   recall   of   good   examples   was   shown   to   be   around             clearly    the   local   svm   was   achieving   high  
accuracy  by  blindly  throwing  out  much  of  the  data   
  
in   an   attempt   to   correct   this   behavior    the   local   dataset   was   deskewed   for   training       more   specifically    we  
selected  the  largest  subset  of  the  manually  labeled  dataset  such  that  the  number  of  good  examples  equaled  the  
number   of   bad   examples       this   resulted   in   a   training   set   of   approximately          examples       following  
reparameterization   and   retraining   of   the   svm    the   system   achieved   tenfold   cross   validation   results   of           
accuracy           precision   and          recall       
  
inspection   of   how   the   even   subsets   of   good   and   bad   data   were   distributed   in   both   the   global   and   local   datasets  
revealed  many  values  differing  by  orders  of  magnitude     in  an  attempt  to  better  capture  the  similarity  between  
extreme  values  in  different  datasets   we  logarithmically  scaled  the  feature  values     by  constraining  the  data  in  
this   way    the   parameterization   process   for   both   the   global   and   local   datasets   converged   to   the   same  
parameters     consequently   we  were  able  to  overcome  the  limitation  of  needing  to  parameterize  the  svm  for  
every   new   dataset    i e     our   selection   of   the   penalty   parameter   c   and   kernel   parameter      could   remain   constant  
for  new  seismic  arrays   only  the  training  set  needed  to  change    
  
conclusions  
the  same  deskewing  technique  was  applied  to  the  global  dataset   resulting  in  an  almost      increase  in  tenfold  
cross   validation   accuracy   to                precision   and   recall   also   improved   significantly   to            and            
respectively     the  addition  of  logarithmic  scaling  and  deskewed  training  data  also  improved  performance  when  
training   on   the   global   dataset   and   testing   on   the   local   dataset    accuracy   improved   by   almost        percentage  
points  to           and  precision  and  recall  improved  to          and           respectively     still   the  significant  hit  
to   performance   incurred   by   not   using   seismic   array specific   training   data   meant   that   this   approach   was   not  
sufficiently  accurate  for  production   
  
table     performance  metrics  with  different  training  and  test  sets  

test  
  f  cv  global           
  f  cv  local          
train  global     test  local  

accuracy  
precision  
recall  
conclusion  
       
       
       errs  on  acceptance  
       
       
        errs  on  rejection  
       
       
        errs  on  acceptance  

  
  
the  difference  in  tenfold  cross validation  accuracy  between  the  deskewed  global  and  local  datasets  was  roughly  
         reapplying   feature   selection   to   both   datasets    we   found   that   our   intuition   regarding   avg delta   was  
correct       in   the   deskewed   global   dataset    avg delta   became   a   less   informative   feature    but   still   contributed  
significantly   to   total   accuracy    see   figure            in   the   local   dataset    however    adding   avg delta   to   the   svm  

  

   

fiactually  resulted  in  a  decrease  in  overall  accuracy               we  attribute  this  decline  to  minor  changes  in  how  
the  svm  fit  the  training  set  with  avg delta   resulting  in  slightly  worse  generalization  to  the  test  set     in  both  
datasets    variance    in   the   time   and   frequency   domains    proved   to   be   the   most   valuable   discriminator       the  
window   length    signal to noise   ratio    and   positive   kurtosis   were   also   consistently   valuable   features   between  
datasets       
  
that  the  majority  of  features  provided  little  to  no  gains  in  feature  selection  strongly  suggests  that  they  captured  
redundant  qualities  of  the  data     in  looking  to  improve  performance  on  seismic  array specific  classifiers   we  will  
need  to  explore  additional  features   
  

test  set  accuracy  

global  test  set  accuracy  vs  k best  
features  
     
    
    
    
    
    
    
accuracy  

k best  features  
figure     most  accuracy  from  few  features  implies  several  captured  redundant  qualities  of  the  data  

  

future  plans  
in   adopting   this   automated   classification   system   to   an   active   seismic   detection   framework    each   seismic   array  
will   require   its   own   training   set   and   svm       as   new   seismic   arrays   are   introduced    a   human   operator   will   need   to  
label  at  least  one  thousand  good  and  bad  examples     after  this  initial  labeling  is  completed   it  is  hoped  that  the  
automated   classifier   will   be   able   to   run   without   retraining   for   months    if   not   years    at   a   time       because   the   svm  
parameterization   has   been   shown   to   generalize   to   new   datasets    however    the   training   data   will   be   the   only  
component  of  the  system  that  will  likely  need  to  change  between  seismic  arrays   
  
there   are   plans   to   continue   improving   upon   the   capabilities   and   robustness   of   the   automated   classifier     
expanding   its   use   beyond   the   correlation   and   detection   problems    the   classifier   could   be   modified   to   classify  
non seismic  data  into  various  artifact  subtypes     additionally   new  features  could  be  derived  from  similar   non 
machine  learning  quality  control  tools  such  as  iriss  quality  analysis  control  kit   quack       more  ambitiously   it  
is   hoped   that   the   work   here   could   be   developed   further   to   create   a   new   industry   standard   in   seismic   quality  
control  and  event  classification   
  
acknowledgements  
douglas   dodge   with   lawrence   livermore   national   laboratory   for   providing   domain   expertise    labeling   the  
training  set   generating  the  unlabeled  correlation  table   and  presenting  the  original  problem   

                                                                                                                
   http   www iris edu dms newsletter vol  no  exploring iris data and data quality with quack     
  

   

fi