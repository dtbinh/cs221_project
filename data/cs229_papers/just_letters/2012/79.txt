predicting user ratings using status models on
amazon com

  

borui wang

guan  bell  wang

stanford university

stanford university

stanford university

borui stanford edu

guanw stanford edu

yunlou stanford edu

abstract

amazon is the worlds largest online retailers where millions
of customers purchase and review products on its website 
however  many amazon customers do not review and rate
products after the purchase  and tons of research projects
work on producing better prediction strategies for customer
ratings  in this research project  we show a new approach
to enhance the accuracy of the rating prediction by using
machine learning methods that learn from a graph based on
user status  defined by features such as the helpfulness votes
and total votes received by the users  we discussed how the
training performance of our model changes as we change
the training method  the dataset used for training and the
features used in the model  we compared this graphical
model with another non graphic model that is also based on
customerss review and status with different settings  and we
achieved over     prediction accuracy using our graphical
status model 

  

related work

predicting user ratings is one of the core issues in recommendation systems  the relevant works in recommendation systems mostly focus on enhancing the quality of the
algorithms to increase the prediction accuracy  the most
popular system for rating prediction is collaborative filtering  which seeks to predict the expected rating a user may
give to an item he she hasnt rated yet  memory based and
model based  e g  matrix factorization      are the two most
popular methods for collaborative filtering  however  both
systems take a sparse user product rating matrix as an input
and may fail to capture the quality of the users and their reviews  in a similar project using properties of the amazon
graph to better understand reviews     proposed by leon 
vasant  sheldon         the predicted feedback score was
represented with a linear combination of the following features  original rating  review helpfulness count  review
unhelpfulness count  review helpfulness ratio  reviewer
helpfulness ratio  reviewer bias  reviewer expertise  reviewer clustering  reviewer betweenness  and reviewer de 

yun  vincent  lou

gree  however  the goal of their project is to predict the
rating of a customer who reviews the same product more
than once  while our project is to predict the users firsttime rating score  also  they use stochastic gradient descent
to minimize the mean square error to capture the weights of
such features  while we tried more than five different learning methods and analyzed their results in our project 

  

data collection process

we used the amazon product co purchasing network metadata from project snap    for our research  the dataset
includes over   million review scores and helpfulness votes
by     million customers for     million products  to convert the amazon meta data into the format we need  we
developed a ruby preprocessing program for data parsing 
for the non graphical model  we parse the data into matrix
files readable by matlab and csv files for networkx libraries
in python  concretely  the output uses row entries to describe which products are reviewed by which customer and
their rating scores  for the graphical model  we parse the
data into hash structures representing customer to product
and product to customer relationships based on the chosen
dataset size to build the graph 

  

initial finding and statistics

because using the entire dataset to build the graph for our
status model turned out to be slow on networkx  we can
only use a subset of all the data for training  we started
with using a graph built from      customers who reviewed
        products to reduce the path searching complexity
in our graphical status model  such range of review counts
also happened to give the constructed customer graph a high
average cluster coefficient of       we discussed our training result using such dataset in section      in later sections
       we show that selecting customers of different ranges
                                     of review counts affects the graph cluster coefficient and ultimately affect our
learning accuracy 

   graphical status model
    overview of the graphical status model
here we describe the details of the graphical status model 
the model assumes that the rating which user u gives to a
product is related to the status of him herself and the statuses of the other users who also happen to review the same
products as u  the status of an user in our model is defined
as the total helpfulness votes divided by the total amount

fifigure   

of votes he she received on amazon  under such definition 
the status of an user has the inclusive range         to see
how a users status can be related to other users statuses 
consider figure    the solid circles a  b  c  d  e  f represent
  different users and their statuses in decimal format  and
the shapes p    p    p    p    p  with dotted border represent  
distinct products  the circle representing a user u is placed
within the shape representing the product p if u reviewed
p  for example  user a   d reviewed product p   customer
c  d  e  f reviewed p    we create edges between customers
who both reviewed the same product  and the direction of
the edge depends on the difference between the users statuses  as shown in the figure    the edge always points to
user of higher status  we try to observe if there is any relationship between the statuses of related customers and their
reviews  we utilize the user statuses and co review relationships in the graph to relate the users  assume we want to
predict the rating of p  given by customer d with all the
edge and user information in the graph  we first find out if
there is any outgoing path from d to another customer in
p  in the graph  where the path itself does not pass through
an edge in p    if such path exists  we find the shortest path
and record the attributes of the customers along the path to
construct the machine learning objectives  introduced later 
to predict the rating d given to p   in the figure   above 
the shortest path d  b  c was chosen  note that edge
d  c is not valid as it is in p    the length of the path
we could find depends on the co review patterns  we expect
the path to be short if two customers who reviewed different
products can be connected by co review relationships with
the same customers  we show later that over     of the
customers in our selected dataset could find such path of
length two  which forms triangles of product co review pairs
such as triangle abd and bcd 

   

triangle types and learning features in the
graphical status model

in order to build confidence of using the graphical model 
we explored the abundance of co review triangles as defined
previously in the graph  we used networkx for python to
generate the customer relationship graph using customers
who reviewed         products  and found that there are

     nodes and         edges in the graph  the graph
is highly connected  and the largest connected component
is the graph itself and the average clustering coefficient is
      as a result  when we use bfs to search the paths as
defined previously for the customers  we find that        of
all paths have length two  thus the graph contains a large
number of triangles co review relationships  this property
supports our model and gives sufficient amount of instances
to form a dataset for training and testing our model  in order to apply the concept of status  we assign each customer
with a status score  we tested several means of computing a customers status based on statistics such as the total
number of reviews  total helpfulness  total number of votes 
and total rating scores from the customers  one simple definition of status is the percentage of helpful votes  which is
total helpfulness divided by total number of votes  after
assigning the status score to each customer  we can build
the graph with signed edges  for example  if as status is
higher than bs  then edge ab is positive  otherwise ab is
negative  thus we can have eight different triangle types 
where the triangle type will be used as one feature in our
machine learning process  later  we found that there is usually more than one triangle for most customers in our graph
and we discussed how the training result changes as we add
more triangles in our training features in     

   

other learning features

besides the triangle type  we found some other features for
machine learning  take the previous example  we have customer d  b  c and product p    noted that we are going to
predict customer ds rating on p    and customer c has also
rated p    the other features we could possibly include in our
learning model are therefore ds average rating  cs rating
on p  and p  s average rating  the inspiration of choosing
these features is that when a customer rates a product  he
usually considers the products average rating which reflects
the general public opinion  and his own average rating which
reflects his own personal opinion  we also think a customers
rating can be influenced by his neighbors in the graph  so
we added the neighbors rating on the same product in our
learning model as well 

   

initial learning results

each three customers and one product that meet the definition of a triangle as defined previously is a training example in our machine learning model  we used weka    to
train and test the dataset  after testing several different
machine learning methods  such as linear regression  neural
network  knn  decision table  we found that knn gave the
best performance  we tested our model on a dataset using
       instances with two test options  cross validation with
   folds  and percentage split with     training instances
and     testing instances  below are the results  where we
measured mean absolute error  mean squared error and test
accuracy for each case 
from results in table   and table    we can conclude that
knn gives the best prediction  with cross validation  knn
correctly predicted        of testing instances  with percentage split  knn correctly predicted        of testing
instances  the results indicate that our model is reasonable
and effective for predicting customers ratings on amazon
products 

fiknn
linear regression
neurak network
decision table

mae
      
      
      
      

mse
      
      
      
     

accuracy
      
      
      
      

table    cross validation with    folds
knn
linear regression
neurak network
decision table

mae
      
      
      
      

mse
      
      
      
      

accuracy
      
      
      
      

table    percentage split with     training data

   

improved graphical model

the training methods and training model from the previous
section gave good results that verify our intuition of the
graphical model  in this section  we improve our training
model by adding more triangle paths from our graph  we
also have done several experiments with different datasets
that represent customers who review different amount of
products  the results supported our model well and gave us
a good guideline on how to select features for the learning
process 
specifically  our first experiment is designed to check if the
model works for different datasets that represent users who
review different amount of reviews  the second experiment
is to apply the model on one dataset but with different number of triangles representing co review paths  the third experiment is to measure the performance of the model when
the input graph of the dataset is not fully unveiled  for example  by randomly removing customers from the graph 
we adopted knn approach in weka to perform all the experiments as it is proved to give the best training method
from the previous section 

     

experiment  

in this experiment  we applied our training model on five
datasets with two triangle modes  where we use   and  
triangle paths from the graphical model as training features 
the datasets vary in the range of the amount of the reviews
given by the customers  for example  the column        
in the tables below represents the training set of customers
who reviewed         products 
table   contains the datasets properties  which include the
number of instances in each dataset and the average cluster coefficient of the graph generated from the datasets  we
found that as the customers in our dataset review more products  the average cluster coefficient of the graph increases
indicating that the graph becomes denser 
dataset
       
       
       
       
       

number of instances
      
     
      
     
    

average cluster coefficient
      
      
      
     
      

table    dataset properties table

figure   
for each dataset  we tested our model with cross validation
with    folds  below are the results trained for different
datasets with   and   triangles as training features  we
measured the mean absolute error  mean squared error and
test accuracy for each case similar to the previous section 
dataset
       
       
       
       
       

mae
     
      
      
      
      

mse
      
      
     
      
      

accurary
      
      
      
      
      

table    cross validation with    folds    triangle
mode 
dataset
mae
mse
accurary
       
       
       
       
       

      
        
        
        
      

      
      
      
      
      

      
      
      
     
      

table    cross validation with    folds    triangle
mode 
from the table   and    we can find an improvement of
the training accuracy as we use more triangles for training  and the accuracy for datasets with   triangle path as
learning feature is around      and the accuracy with  triangle paths is around      this prediction accuracy is
very high  in addition  the training results indicate that our
model also works for datasets of different ranges  we will
show how many triangles gives the optimal results in the
second experiment 

     

experiment  

in this experiment  we applied the model on the same dataset
using different amount of triangles derived from our graphi
as features for training  the dataset we used is the one
where the customers number of reviews ranges from    
to      again  similar to the first experiment  we adopted
cross validation with    folds method  the results is in table
  
from table    we can find that using   triangles for our
training features gives the best performance  which achieved
the highest accuracy of         moreover  adding the second triangle improved the performance the most  because
the accuracy was improved by       after changing from  tiangle mode to   triangle mode  besides these two points 
we can also conclude that after having   triangles as training
features  adding more triangles does not improve the performance  therefore  the optimal number of triangles for our
model is   

fi  of remaining instances
 
 
 
 
 

mae
      
      
      
      
      

mse
      
     
      
      
      

accuracy
      
      
      
      
      

table    cross validation with    folds           triangle mode 
  of remaining instances
  k
  k
  k
  k
   k
   k
   k

mae
      
      
      
      
      
      
      

mse
      
      
      
      
      
      
      

accuracy
      
      
      
      
      
      
      

table    cross validation with    folds    triangle
mode          dataset 

     

experiment  

in this experiment  we tested our model with incomplete
data sets to find the relationship between prediction accuracy and the completeness of the data  we randomly removed certain amount of nodes  customers  and edges  coreview relationship  connecting them from the graphs generated from the datasets            the results are in table
  
from table   and figure    we can find that our model highly
depends on the completeness of the graph  the model performs badly when a large amount of nodes are removed  this
can be explained by the fact that our model uses knn to
produce prediction  this can be explained by the fact that
if customers with similar features are removed  the target
customer whom we want to predict will not be able to find
co reviewers in the training dataset  therefore hurting the
training quality and decreasing the prediction accuracy 

   review based status model
    overview of the review based status model
in this part of the project  we explore the relationship between the reviews and their influence on customers future
ratings  our training samples are based on the reviews of
each product 

   

baseline

in the baseline model  we only considered the impact of the
selected reviews for prediction 
p our assumptions for the
baseline model is rp ridict       hi      pi      vi   
rj   j            k  where the subscript j is the j th customer 
pi is the number of product reviews  hi is number of helpfulness votes  vi is the total number of votes 

   

improved model

we have two different assumptions with the review data    
assuming that the quality of the review is the key influencer
to the users     assuming the reputation of the reviewer is
the key influencer to the users  the first assumption
p goes
like  rp ridict     rproavg          ruseravg      
hi      vi      hi  vi     ri  rproavg    j            k 
where hi is the number of helpfulness and vi is the number
of votes for the review j  hi and vi are the data to measure the quality of the review  to find a better model  we
tried square and cubic of hi and vi   but the testing error
increased slightly  moreover  when we tried hi  vi   the mse
decreased by       indicating a valuable feature for the quality of the review  in the next section  we will discuss more
about the ratio hi  vi   such as including its square and cubic forms  subtracting by its average to distinguish between
high quality reviews  with positive numbers  and low quality
reviews  with negative numbers   the second assumption
is 
p
rp ridict     rproavg          ruseravg       hi u  
   vi u      ri u     ri  rproavg    j            k  where
u is the user of the ith review hi u is the total number of
helpfulness of u  and vi u is the total number of votes ri u is
the total number of ratings from the user u  vi  u  ri  u and
hi u are the data to measure the status of the user  to find
the best model  we tried the square and cubic forms of hi u
 ri u and vi u   but reaching a higher testing error  when
we triedthe feature hi  u  vi  u  there is no improvement in
training error 

   

combination  review based status model
and graphical status model

based on the improved model    we incorporate it with the
features used in the graphical status model 
define w   
p
w  and w  as  wd    ri  rproavg     d  hi u    d  
         j            k  we appended w    w  and w  to the
extracted feature vectors in improved model    we would
like to provide the learning algorithm with more information
by adding graphical status data to review based data  the
learning algorithms should be capable of figuring out the
best combination of the features by adjusting the coefficient
of each feature 

   

learning methods and evaluations

we adopted the cross validation method in this experiment 
the mean value for the target value in the training data
is        and its standard deviation is        the distribution of the ratings in our training data is shown in figure   
indicating that rating   and   appear most frequently 

figure   

since the hypothesis is a combination of weights and scales
for three models abvove  we first tried multilayer neural networks as our learning method  we used the mean square
error  mse  between the actual and predicted rating for
performance evaluation  the result is shown in table   

ficombined model
decision tree
knn k   
knn k   
knn k   
linear regression
least median square linear regression
locally weighted linear regression
multilayer perceptron   hidden layers
multilayer perceptron   hidden layers
multilayer perceptron   hidden layers

mean square error
      
      
      
      
      
      
      
      
      
      

absolute mean error
      
      
      
      
      
      
      
      
      
      

root mean square error
      
      
      
      
      
      
      
      
      
      

accuracy
      
      
      
      
      
      
      
      
      
      

table    eveluation result for combined model

figure    distribution of ratings in training data
improved model  
mean square error
absolute mean error
root mean square error
accuracy

k  
      
      
    
   

k  
      
      
    
   

table    performance laerned through knn

from the evaluation result  we find that the baseline model
has a very high bias for both the training and testing data 
but the mse for both of them differ little  indicating a low
variance in the learning model  also  improved model   has
a better performance than the other two models  we also
tried other learning methods for improved model    and find
that knn has a decent performance  which is shown in table
   
for the combined model  we tried four different learning
methods  decision tree  k nearest n  knn   linear regression and multilayer perceptron  the results for these
learning methods are shown in table    knn gave the best
prediction in terms of mean square error  mse   while decision tree  knn and multilayer perceptron gives similar
prediction accuracy around      when comparing the results of the combined model with improved model    neithor
the accuracy nor the mse was improved  when comparing
the results of of the combined model with graphical structure model  combined model performed worse  this was
caused by different interpretations of review based model
and graphical model  concretely  the graphical model is
neural networks
baseline
improved model  
improved model  

trainingmse
    
    
    

testing mse
    
    
    

table     comparision of three models using neural
networks

designed to explore the network path structure of the data 
while the review based model relies highly on the linear combination of common user features  simply combining data
from the two models does not give a better result because
there is no direct relation between the underlying meanings
of the feature vectors from the two models  as a result  the
performance with combined model is worse than graphical
model 

  

conclusion and future work

we have explored two models to solve the problem  the
first model relies more on analyzing the network structure
and using status theory  the second one focus more on
review based status information  from the results  we find
the first model gives better performance  which achieved a
mean square error around        and prediction accuracy
around         the second model gives the prediction accuracy around     and mean square error around         in
conclusion  applying network and status concepts in a graphical model is very useful to improve prediction accuracy for
amazon data  other customers ratings in a product might
produce bias to the target users rating      which is not
considered as a parameter in the graphical status learning
model  to extend our work  it might be helpful to include
parameters reflecting the bias caused by other reviews in
the same product to improve our model and reduce learning errors  furthermore  the definition of user status in the
graphical model can be overly simple and naive  other definitions of user status would change the triangle type and
drastically affect the learning result  which is left to be explored  during our experimentation of feature selection  the
features selected in the graphical model are not proved to
be the best choice of features  and it requires more analysis
to come up with a better set of features 

  

references

    snap  http   snap stanford edu  
    f  ricci  l  rokach  b  shapira  and p  b  kantor 
recommender systems handboo springer       
    weka is a collection of machine learning algorithms for
data mining tasks 
http   www cs waikato ac nz ml weka  
    c  danescu niculescu mizil  g  kossinets  j  kleinberg 
l  lee  how opinions are received by online
communities  a case study on amazon com helpfulness
votes   in proc  acm www       
    leon  vasant  sheldon  using properties of the amazon
graph to better understand reviews

fi