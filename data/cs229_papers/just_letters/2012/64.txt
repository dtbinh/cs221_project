recommendation of tv shows and movies based on facebook data
mathangi venkatesan

andy mai

mathangi stanford edu

andymai stanford edu

abstract
we seek to use facebook data to solve the cold start problem in recommending movies and
tv shows  we use a person s  likes  on facebook to predict what tv shows and movies he 
she may like  to simulate the cold start situation for our test users  we don t use any data about
what movies or tv show pages that they ve  like  d on facebook  this information is used only
to find the accuracy of our recommendation engine 
weve implemented two major approaches in our recommendation engine  the two methods
approach the same problem with different perspectives  our first approach uses unsupervised
learning to cluster together similar facebook profiles  after getting clusters of profiles  we
recommend movies and tv shows to each cluster  our second approach is a two step
approach  in the first step  we use supervised learning to recommend top genres for each test
user  in the second step  we recommend most popular movies and tv shows within those top
genres 
   introduction
when a user first signs up for a movie tv recommendation service  the recommendation
system has no information about what movies or tv shows the person has already watched
and liked disliked  this is called the cold start situation  despite not knowing anything about
the user  the recommendation engine has to give good recommendations in order to retain
the users interest  the common solution to this problem is to recommend to new users tv
shows and movies that are most popular among all users  here  popularity could be measured
by highest rating  most views  box office revenue or any other reasonable metric based on
available data  however  this solution is not personalized at all 
our goal is to give personalized cold start movie and tv show recommendations  the data we
use for making recommendations is the pages a person likes on facebook  the premise here
is that theres a correlation between a persons taste in books  activities  music etc  and his her
taste in movies tv shows 
   data
through a facebook data scraper  we acquired close to    thousand unique facebook profiles 
most of the profiles had very less no information  so  we discarded profiles of people who listed
less than three likes  in the end  we had      profiles to work with  we randomly chose    
of these to be our test users 
we were given a list of     tv shows along with their genres and description  we found this
dataset missing some of the most popular shows  like f r i e n d s   so  we manually added
     shows and their genre information from imdb  in the end  we had shows from     unique
genres 

 

fi   data processing common to both methods
for each user  we aggregated all their likes  except for movies and tv shows  into a long
string  which served as the document for that user  we stripped away tag information for the
likes because most users had only very few likes in each category and sometimes the same
like was in different categories for different users  this was most common for the activities and
interests categories  for eg  some people listed swimming under interests while others listed it
under activities  
we tokenized the documents and used a reverse stemmer written in matlab to get the rootform of each token  then  we created our vocabulary consisting of stemmed form of words that
appeared in at least one document 
we created a document term matrix where each document corresponds to a user and each
term corresponds to a word in our vocabulary  the  i j th element of the matrix is   if the jth term
is present in the ith document  otherwise its    we applied idf  inverse document frequency 
weighting to this matrix so that more frequently occurring terms have lesser importance than
less frequently occurring terms 
   features
we use the stemmed form of words that appear in any of the facebook profiles as our features 
for our dataset we had       features 
   methodology and results
          method    clustering facebook profiles using k means
we implemented k means algorithm with cosine similarity to cluster similar facebook profiles 
by clustering similar profiles  we wanted to simulate real life friend circles  profiles in the same
clusters are grouped together because they have the most similar profile data  and therefore
can be treated as  friends   since people tend to be friends with others who are share the same
interests  after clustering  the    most popular movies and tv shows from each cluster are
compiled and served as recommendations to test users who map to that cluster 
because of the very large feature set  we couldnt get a visual representation to see how well
our clustering algorithm was doing  so  we varied the number of clusters from   to    to see for
what cluster size we got the best accuracy 
in our first implementation of this algorithm  we naively used the document term matrix
without idf weighting and a non stemmed vocabulary  after seeing very poor accuracy of
recommendations  we investigated on a bunch of     profiles and observed that a lot of the
same similar words were being considered as different  so  we started reading about natural
language processing  we learnt about stemmers and used a matlab implementation of
reverse stemmer on our vocabulary  during this phase  we also hit upon idf weighting concept
on the internet  the final version of our algorithm uses the idf weighted document term matrix
and stemmed vocabulary that we created described in     data processing  section  
lastly  we implemented latent semantic analysis lsa  to reduce the dimension of the
document term matrix from       to approximately        and then  tested our accuracy 
       

results for method  
 

fiwe define

where

and 
we chose recommending the    most frequently liked movies and tv shows in the training set
as the baseline to compare our algorithm against  this baseline has an accuracy of       
when we implemented k means without stemming and idf weighting  we saw an overall
accuracy of        for k     
after stemming and idf weighting  our overall accuracy rose to        for k       as  we varied
the number of clusters from   to     we saw an variation in accuracy between        and
        we chose k     because that had the best overall accuracy  the following figure
shows the accuracies for some values of k  note  all accuracies in the figure were measured
after implementing the algorithm with stemming and idf weighting 

after reducing dimensions using lsa  our overall accuracy rose from        to        for k
   
a summary of our results 
metric

baseline recom
mending top   
movies shows in
training set 

k means without
stemming  idf
weighting

k means with
stemming  idf
weighting

k means with
stemming  idf
weighting   lsa

overall
accuracy

     

    

      

     

 

fi         method    using naive bayes to get top genres for users
our second approach to the problem centers around genres  rather than recommending
movies right away  we develop a model to determine users  favorite genres of movies and tv
shows and recommend them popular movies and tv shows from those genres 
we label each user or the document of each user  in our training set with the genre of shows
theyve liked  we also associate a weight for each genre theyve liked  for eg  if theyve liked  
shows and the  st show has genres comedy  satire  the  nd show has genres comedy drama 
then  for this user comedy has a weight of   and satire  drama have a weight of   each  we
create a person or document  genre matrix with each entry having weights as described above 
we use the document term matrix as described in     data processing  section  and the
document genre matrix to get the probability that a term in our vocabulary is associated with a
specific genre 
for each test user  we use the words in their document and apply the naive bayes algorithm
to compute the probability that they like each of the     genres  essentially  it is like a binary
classifier for each genre except we store the actual probability that they like a genre instead of
just storing   or    based on these probabilities  we recommend the top five genres for each test
user  then  for each of the top five genres recommended  we recommend the two most popular
tv shows or movies for that genre in our training dataset 
lastly  as in our previous method  we used latent semantic analysis lsa  to reduce the
dimension of the document term matrix from       to approximately        and then  tested
our accuracy 
        results for method  
after implementing method    we learnt our lesson and used the stemmed vocabulary and idf
weighted document term matrix from the beginning for method   
we have two accuracies to report for this algorithm  one is the accuracy with which we
recommend genres for users and the other is the accuracy with which we recommend movies
and tv shows for the users from those genres   we define accuracy for each of these cases
similar to how we defined it for method   
we chose recommending the   most frequently like d genres in our training dataset as the
baseline to compare our algorithm against  this baseline has an accuracy of        
in comparison  our algorithm for recommending the top   five genres for each test user has an
overall accuracy of         and  recommending the most frequently like d two movies tv
shows from each of the five recommended genres has an overall accuracy of        
after using lsa  our genre recommendation accuracy rose to       and our movie tv
recommendation accuracy rose to        
   analysis
both our methods suffered from the problem that our data was far too sparse  another general
problem is that people do not tend to list all the movies and tv shows they like on their
facebook profile 

 

fithe low accuracy of method   could be because there are no well defined clusters in our
dataset or there were clusters that got broken when we weeded out profiles that listed very
less information  another reason could be that perhaps facebook profiles cannot be clustered
by simply using a term document sparse matrix  the data that we have has only likes and
interests  but it does not have any information on the social dynamic of the person on facebook 
since our original goal was to cluster profiles to simulate friend circles  having information about
who is whos friend would have helped us a lot 
the accuracy of method   could have been higher if the list of popular shows and their genres
that we started out with had been more exhaustive  the main advantage of our method  
over method   is that in method   we dont assume that there is any underlying pattern in the
data like clusters  
   challenges faced during implementation
the biggest hurdle during implementation was processing text in users profiles  a surprisingly
large number of people misspelled the simplest of words  multiple facebook pages some with
misspellings  for the same like only made things worse 
very sparse data led to very large matrices and because of that the execution times of the
algorithms were very long 
   future work
the immediate next step in our work is to reduce the number of features thereby reducing the
sparsity of the matrix  
if we are able to collect friends information for each of our users  we can use that in our
recommendations 
a more philosophical view of the project is that we are trying to summarize people by looking
at what pages theyve liked on facebook  to this end  we need more data than just the title
of the pages theyve like d  a future direction is to work on an algorithm that takes in the
content of the pages theyve liked  pages they visit often  their status updates comments and
information about closest friends to give a summary for a person which can then be used as
the document for the person 
   acknowledegments
we would like to thank andrew maas for suggesting this project topic and giving valuable advice
throughout the duration of the project  we would also like to thank graham darcey and wayne
yurtin of screaming velocity for their help in collecting facebook data and providing tv movie
genres and descriptions 
   references
turney  peter d  and patrick pantel  from frequency to meaning  vector space model of
semantics  journal of artificial intelligence research                   

 

fi