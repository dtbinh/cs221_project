predicting u s  president election result based on google insights
yunzhu chen  fan zhang  yuanxi yue
december         
abstract
in this report  we used google insights data to predict the u s  president election results by states 
to be specific  we selected keywords closely related to the president candidates policies  and used the
searching frequencies in each states during the past    months as our data 
we applied supervised learning algorithm including gaussian discriminant analysis  support vector machine and naive bayes method  and unsupervised learning algorithm principal component
analysis  we also explained the results and discussed some interested findings which are useful for
future study 

 

introduction

it is commonly known that when people are interested and concerned about something  they are likely to
search on the internet  and there are already some studies using web search volume to make predictions 
google insights  also known as google trends  is an application in google to collect search history data
and related location information 
we are interested in researching on the web searching data and exploring the features that could
predict the us presidential election results by states 
this study could be useful because it provides a reliable tool to make prediction on the vote result 
besides survey the voters  it can potentially facilitate the electoral team and the media to understand
different concerns from different states  and the potential votes result  also  this study could even help
electoral team to strategize further campaign to their potential voters 

 

data and preprocessing

the data of keywords searching results are all collected from google insights  and the data are the
normalized searching volume on google by states with in    months  between nov      to nov       
and we researched on the      us presidential election result 
specifically  we chose the keywords by selecting some most controversial topics between the two president candidates  the keywords cover area including environment  military  foreign policies and etc 
   
 j 
 m 
we denote for the i th states  their search vector is xi    xi      xi        xi    i           n  the j th
element is the searching volume for the j th keyword in this state  m is the number of keywords we use  it
also means that the dimension of the data is m  n is the number of cases  and in this particular problem 
 j 
we have n      as the number of states  because the data are normalized by states  so xi           
 j 
where xi       means the i th states searched the j th keyword most frequently among other states 
and the labels for the states are the final voting result  we denote it as y    y         yn    because
conventionally there are two president candidates  yi only takes two values         or        depends on
particular method  
in order to select the features  keywords  that are most relevant to the election result  we calculate the
mutual information between the keywords and voting result  from all the keywords  we finally decided to
use m      of them into our model 

 

fi 

methodologies

our goal is to find good algorithm that could reliably predict the election voting results  to achieve this 
we try four different models  including gaussian discriminant analysis  logistic regression  naive bayes
and support vector machine 
this problem is a supervised classification problem with all the keywords as features and states as
cases 

 
   

model evaluation
   fold cross validation error rate

we randomly divide the states into    samples and conducted the    fold cross validation  the error rate
for the   classification models resulted from the    fold cross validation is shown below 
model
error rate

gda
    

logistic
    

naive bayes
    

svm
    

table       fold cross validation error rates
among the   models  svm generated significantly smaller error rate comparing to the other   models 
logistic regression had the largest error rate among the models but the error rate is similar to that of
gda and naive bayes 

   

roc curve

we plotted the roc curve with     of the samples as the training set and     of the samples as the test
set  we choose     for training and     for test because our sample size is relatively small and we would
like to get smoother curves  thus we decided to include more data into the test set  the plot is shown
below 

figure    roc curve for the four model
logistic regression showed little prediction power as its roc curve lies almost on the    degree line 
svm and gda showed relatively strong prediction power  while naive bayes had moderate performance 

   

plots of training errors and test errors

since the logistic regression has been recognized as the worst performed among the   models from the
previous   comparisons  we further compare the   other models  we used    to    samples for the training
set with the remaining as the test set  in this process  we got the training error and test error for different

 

fitraining and test sample size  for gda  naive bayes and svm respectively  the plots of training errors
and test errors are shown below 

figure    training errors and test errors for the four models
naive bayes showed both high training error and test error with the tendency to converge  this
indicates the naive bayes model has high bias or is under fitting the data 
gda showed low training error and high test error  the large gap between training error and test error
indicates the gda model has high variance or is over fitting the data  in the plot  gda even displays a
slightly increasing trend  indicating gda doesnt fit this case very well  possibly because the cases dont
conform to a normal assumption 
svm showed both low training error and test error  although it shows high variance  but since our
case number is limited  it could not be fixed for now  the error is acceptable  and it is the best among
the   models  therefore  we will choose it as a final model as the election voting prediction model 

 

results with keywords

we then conducted principal component analysis to the data  to explore how the web searched keywords
related to the result of voting 
in order to apply pca  we need to reduce the number of keywords to less than    first  to satisfy the
condition of using pca  once again  we calculate the mutual information between each of the keywords
and voting result  and selected    most relevant keywords 
with the screeplot for pca  figure     we can tell that the first two components could explain most
of the difference between voting  therefore  we research on these two components  and the corresponding
first two pca scores for each state 

variances

 

    

    

    

    

screeplot

comp  

comp  

comp  

comp  

comp  

figure    screeplot for pca
from the plot of first pca scores  figure   left   we can see that there are two obvious clusters of
states  and we could find the left cluster are more likely to vote for obama  if without knowing the
voting results  we simply classify the states to be obamas and romneys with the two cluster  the error
 

firate is around     we can also a rule for the left cluster  that with similar second score  a less first score
for a state means that the state is more in favor for obama  and with similar first score  a higher second
score means favor for romney  for the right cluster  there is not a very obvious structure 
in order to get a better understanding  we look at biplot  figure   right   it shows large negative
contribution for each words in the first score  this well explained the cluster in scores  that the states in
the left cluster are those web search activate states  also it shows some bias in our initial data selection 

   

   

 

   

  

   

   

  




  

  

  

  



   

  
   




   



   

   




   

pca scores

comp  

score  



  
green cards
turnaround
  international trade
palestine
  green jobs
  
winner
nato
   great lakes
  
  
energy research
national park
deportation
alternative minimum tax
cap and trade
carbon emissions
     
    
  
   
  
corporate taxes
nuclear weapon
  
 
  
  






 
























   









   

    
  
 
  
  
  
    

 

   



  

   

government spending
no child left behind
    
  
tax breaks
federal student loan
international students
  





   








   

 



  
 


mitt romney





barack obama
   

   

  
 
  
  
  
  

   



   

  






  

 

  

   

   

   

score  

   

   

   

   

comp  

figure    left  first two pca scores for each state  right  biplot   how does each keyword form the
first two components and effects the first two pca scores
the table of loadings  table    shows how the pca scores is calculated from the keywords  it listed
the loadings of the top   keywords that contributed  with the plot and the ranks  we can tell a lot stories 
people from different states have different concerns  those who concerns a lot on the keywords with
large negative loadings on component   are more likely to vote for obama  those who concerned about
keywords with positive loading of component   are more likely to be the supporter of romney 
component  
tax breaks
alternative minimum tax
carbon emissions
cap and trade
nuclear weapon

loadings
      
      
      
      
      

component  
government spending
no child left behind
nuclear weapon
corporate taxes
tax breaks

loadings
     
     
      
      
     

table    top keywords with largest absolute loadings for the first two components

 

discussions

in this project  we tried to use different classification models to learn about the relationship between
internet searching volume for political keywords and the      u s  president election voting result in
different states  we conclude that  among all the models  support vector machine with radical kernel is
most effective 
however  we still have an error rate larger than      it may on one hand due to the limited number of
observations  i e  the number of states   on the other hand due to the limited intrinsic explanation power
of searching volume to election results  however  it is still possible that the prediction power could be
enhanced if we select a more comprehensive set of keywords 
even though the prediction is not extremely precise  it could serve as a complement approach for
polling  at the same time  it also provides useful information for understanding some of the heterogeneity
across states 

 

fifurthermore  the results with keywords can be instructive for further campaigns  for example  the
political strategists in the campaign operation teams can apply the results generated by pca to see what
are the major concern of the voters 
one shortcoming is that the problem is an unsupervised problem when none of the states have released
their election results  to tackle this shortcoming  the pca part could serve as an unsupervised method
to classification  which also has a well controlled error rate  moreover  the supervised algorithms could
also be applied  without relying on released election results  by taking the safe states as the training set 
since we could at most times safely assume the supported candidate in those states would win the states
vote on the election day  then  we could use the trained model to make prediction on the swing states 
which are what people most likely to concern about 

references
    google trends  http   www google com trends  

 

fi