interpolating images between video frames
using non linear dimensionality reduction

sebastien robaszkiewicz
sammy el ghazzal

abstract
we present a new method for interpolating
images between frames of a video  by applying isomap  we map each frame of the video
to a low dimension feature space  which extracts meaningful features from the sequence
of images  to insert new images between  
frames  we select images from the original
dataset that are mapped in the same area
as those   frames  we assess the performance of our algorithm by confronting it to
  other interpolation algorithms on   different datasets  we delete every other frame
from the original datasets  and reinterpolate
the deleted images with   different methods 
by comparing the similarity of the interpolated image and the deleted image with measures based on sift and the hough transform  we determine which algorithm leads to
the lowest error  our results suggests that
the method based on isomap performs better than the two other algorithms when the
video contains repetitive motion 

robinio stanford edu
selghazz stanford edu

   method
     insuffisance of a linear approach
in this project  we intend to take advantage of the
underlying pattern in a video sequence to interpolate images between two consecutive frames  in order to find the dimension of the underlying structure in a sequence of images  we confronted two algorithms  principal component analysis  pca  and
isomap  tenenbaum et al          a nonlinear dimensionality reduction algorithm  the main difference in
principle between these two algorithms is that while
pca uses euclidean distances  isomap computes a
good approximation of pairwise geodesic distances
uses them in a spectral method to compute a lowdimensional embedding 
we found out that pca needed    principal components to capture      of the variance in the dataset
 which consisted in a teapot revolving around the zaxis   whereas isomap reaches a minimal residual variance of     for a two dimensional embedding  therefore
suggesting that the data lies in the neighborhood of a
two dimensional manifold  cf  figure    
     using isomap

   introduction
video compression has always been an important challenge  and it is now more crucial than ever due to
the wide use of streaming services  a way of achieving compression is to delete images  and interpolate
them back during the decompression process  in other
words  the compression reduces the frame rate of the
video and the decompression is aimed at bringing the
frame rate back to its original value  as suggested
by  pless         we investigate whether or not dimensionality reduction can be used to solve this problem 
proceedings of the    th international conference on machine learning  atlanta  georgia  usa        jmlr 
w cp volume     copyright      by the author s  

given a point in rd   we are not able a priori to find
its pre image s     there is no guarantee either that
the pre image will be unique  injectivity of   or that
such a pre image even exists  surjectivity of   
knowing the mapping function  would allow us to
find an approximation of the pre image by using a regression technique  we would compute x such that 
x   arg min k x   yk
xx

where y is the point for which we are trying to find
a pre image  initializing x to some value  we would
 
we define the pre image of a point y  rd in the feature space to be a point x such that y    x  where 
denotes the mapping function between the input space and
the low dimensional space 

fifinal project cs   
result of an embedding in a two dimensional space using pca
  

two dimensional isomap embedding  with neighborhood graph  
   

  
   
 
   
 

 

  

    

   

    

    
    

    

    

 

   

   

   

   
   

   

  

 

 

  

  

  

 b  pca

 a  isomap

figure    comparison between the two dimensional embeddings of pca and isomap on the teapot data set 

apply gradient descent  for instance  to minimize the
objective  the point x reached at convergence would
be considered to be a good approximation of a preimage of y 

solved by a regression  dam et al         
       location of the interpolated images in
the feature space

however  in practice  the map  between the input
space and the feature space is a priori not known 
consequently  given a new training point x  it is impossible to compute either its embedding  x  or the
gradient of a function involving  x   these remarks
motivate the need for an interpolation method not relying on the mapping function   which we detail in
the next section 

 i 
 i   
given   images
  we want to insert n
 x and x
 i k 
images p
between
them 
let us denote by
kj  nk

 i k 
the n points in the feature space evenly
d
kj  nk
spaced on the curve linking the two consecutive images
 x i    and  x i       more formally  if  i  is the truncation of  between  x i    and  x i      such that
 i   
 i         x i    and  i     
   we have  for
    x

     the method

 d i k   kj  nk to be the embedding of the interpolated
images  as we discussed in section      it is not possible to find preimage of those points  as a result  we
next detail an alternative method to find a reasonable
interpolation in the input space 

for an illustrated explanation of the method  please
refer to figure   
       mapping the dataset to a
low dimensional space
we use isomap to project each image from the original video to the low dimensional space  which is also
called feature
space  in that space  the data points

 x i    kj  nk are represented by their coordinates
and by their timestamp in the video  which corresponds to the index i  
       interpolating a curve between the
data points in the feature space
we interpolate a smooth curve between the points
in the low dimensional space  the curve equation is
given by t    t  and is constrained to go through
the m data points  i e   t            tm    rm s t  i 
j   mk   ti      x i     while minimizing the curvature of the curve  this optimization problem can be

any k  j   nk   i 

k
n  

  d i k    we consider the

       inserting new images
to address the problem of the preimage approximation  we choose the image corresponding to d i k 
to be its nearest neighbor in the low dimensional
space  specifically  for each d i k    we seek for the
data point  x j    that minimizes the euclidean distance between the two of them  and we then set
 i k 
p i k    x j     in other words 
 if we have u  i k    
 i k 
 j  

arg min jm d
  x       then we set p
  
 i k 

x u

 

 

       final result
each pair of consecutive original images  x i    x i     
is now augmented with other images from the dataset
 i   
 i n 
 
as follows   x i    x u             x u
  x i      

fifinal project cs   
a

b

c

 x i    

 x i    
 x i    

 x i  

d

 x i    

 x i  

 x i    

 x i  

 x i  

 x i    
d i    

 x i    

 x i    

 x i    

 x i    

d i    
d i    
d i    

d i    

 x i    

d i    
d i    

d i    

 x i    

figure    our interpolation method   a  we project the images from the video on the low dimensional space  lds  with
isomap   b  in the lds  we interpolate a smooth curve between the embedded data points   c  in the lds  we estimate
the location of the n images we want to insert  d i k            d i n    by placing them evenly on the curve between  x i    and
 x i        d  we set each of the interpolated images to be equal to the closest point from the original data 

figure    comparison between two interpolation methods   a   the method we discussed in section         b   weighted
average interpolation between the two images  the red circles  two extremal images  are the images between which we
want to insert new images  the blue triangles are the inserted images 

   experiment
     protocol
to test the validity of our method  we used the following protocol 
   from an original video  create a compressed version of the video by removing every other image 
   interpolate frames between each pair of consecutive images in the compressed video 
   compare our interpolated frames with the frames
deleted in step   
     measuring the performance of our method
       two other interpolation methods
in order to measure the performance of our method 
we confronted it with   other interpolation methods 
 averaging the pixel values of the adjacent images
 motion estimation   motion compensation
 memc   a common interpolation method used
for instance in the mpeg  h     standard  more
specifically  we used the toolbox discussed in
 barjatya         which consists in two steps 

   motion estimation  this task is performed by
a block matching algorithm  we mainly used
extensive search   the latter produces one
motion vector for each block in the image  a
block being a square of pixels  
   motion compensation  using the motion vectors found in the previous step  the algorithm
interpolates an intermediary image by translating blocks of pixels according to the motion vector
       assessing the performance of each
interpolation method
to compare the similarity between the image that was
deleted during compression and the interpolated image  we implemented two comparison procedures 
procedure    based on hough transform
we first derived a comparison method from the hough
transform  duda   hart         specifically  given
a discretization  k   l   k l    of the hough space 
we computed the simple hough transform of both the
original ht  d  and the interpolated images ht  i    we
then defined the hough error  to be 
 
x 
ht  d   k   l    ht  i   k   l    
 
 k l 

fifinal project cs   

overall  this method consists in comparing the set of
edges of the two images 
procedure    based on scale invariant feature
transform
scale invariant feature transform  sift   lowe 
      is usually used to detect the presence of objects in images  it computes keypoints which are represented by descriptors and is able to match key points
from an image to those of another image  see figure    
to come with a measure of similarity using this algorithm  we combined two criteria 
 the number of matches between the descriptors
of the two images    this measures how similar
the two objects are 
 the difference in position between the matching
descriptors of either image  this allows us to
know if the object is in the right position  location and orientation  and gives an idea of how the
interpolated image respects the flow of the video 

 for the second one  we used a cipr sequence representing a toy train going from right to left  a
board with an upwards movement  and   spinning
atoms  this video is therefore much more complex that the previous one  in particular there is
no repetitive movement 

   results
     shell dataset  video with repetitive
motion 
 the hough error estimation indicates that our
method using isomap performs significantly better than the two others on the shell dataset  figure    a   
 the sift error estimation was not exploitable
due to the number of outliers and too small differences in descriptors positions  probably because
some images do not have enough key points 
 for each of the     interpolated images  we found
that the minimum error was given by isomap 
     caltrain dataset  video without repetitive
motion 
 the hough error estimation indicates that the average interpolation performs significantly better
than the two others  the method using isomap
has no significant difference with the memc interpolation method 

figure    matching keypoints between the interpolated image and the deleted image using sift 

     the datasets
finally  we decided to compare the performance of the
  interpolation methods on   different datasets 
 for the first one  we built a video by rotating a
 d shell  the frame rate and the revolving speed
are slightly desynchronized so that each rotation
is different from the previous one  this video is
an example of a repetitive footage where similar
actions are seen at different points in the video 
 
descriptors are usually represented as a    dimensional features  which ensures that two matching keypoints are actually referring to the same element with good
probability 

 the sift error estimation indicates that the
method with isomap has significantly more descriptor matches than the two other methods  see
figure    b    this shows that the isomap interpolation method is better at preserving the original shape of the object  isomap and memc also
perform significantly better than the average interpolation in the position change of the matching
descriptors  see figure    c    however  there is no
significant difference between isomap and memc
on that aspect 
     videos
you can see the videos at the following url 
http   stanford edu  robinio cs   project  
on the shell dataset  see how the interpolation with
isomap yields a video which is very close to the
original video 

fifinal project cs   

sharper video

hough l  error
 
   

 in the worst case scenario  the effective frame rate
of the decoded video is the same as the compressed video  the interpolated frames between
x i  and x i    will be equal to x i  or x i      

   
   
   
   
   
   
   

   limitations   further work

   
 
average

isomap

memc

 a  hough error   shell dataset
sift   descriptor matches
    

  descriptor matches

    
    
    
   
   
   
   
average

isomap

the main limitation of our method is that we only
use images from the data set  as a consequence  the
method works only for videos that contain a repetitive
motion  an interesting improvement of the method
would be either to find a way of computing preimages with isomap or to use a nonlinear dimensionality
reduction algorithm that is invertible  or pseudo invertible   indeed  we would then be able to create
images from scratch  which would probably result in
a systematic increase the effective frame rate of the
video 

memc

 b  sift number of matches   caltrain
dataset
sift change of position of matching descriptors
 

another direction of research would be to find a way
to combine our method with another interpolation
method such as multi reference memc  the principal challenge would then be to find a systematic way
of deciding which algorithm generates which images 

   
   

references

   
   

barjatya  aroh  block matching algorithms for motion
estimation  ieee       

   
   
   
   
   
average

isomap

memc

 c  sift change in position of key
points   caltrain dataset
figure    comparison of the results of   interpolation
methods using the procedures described in section       
on each box  the central mark is the median  the edges
of the box are the   th and   th percentiles  the whiskers
extend to the most extreme data points not considered
outliers  and outliers are plotted individually 

   conclusion
our results suggest that our method is particularly efficient on footages with repetitive motion  for instance 
chen the camera is rotating around an object  or when
a person is waving his hand at someone  or if the camera is shooting a closeup of a flying bird   it has several
advantages 
 the interpolated images have the same quality as
the rest of the video  which often results in a much

dam  erik b   koch  martin  and lillholm  martin 
quaternions  interpolation and animation  technical report       
duda  richard o  and hart  peter e  use of the hough
transformation to detect lines and curves in pictures 
commun  acm              january       issn
           doi                        
lowe  david g  distinctive image features from scaleinvariant keypoints  int  j  comput  vision        
       november       issn            doi     
     b visi                     
pless  robert  image spaces and video trajectories 
using isomap to explore video sequences  in proceedings of the ninth ieee international conference on
computer vision   volume    iccv     pp       
washington  dc  usa        ieee computer society  isbn               
tenenbaum  joshua b   de silva  vin  and langford 
john c  a global geometric framework for nonlinear dimensionality reduction  science            
          december      

fi