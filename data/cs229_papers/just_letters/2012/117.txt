predicting the popularity of social news posts
joe maguire

scott michelson

department of electrical engineering
stanford university
stanford  california
jmaguire stanford edu

department of electrical engineering
stanford university
stanford  california
smich stanford edu

abstract  this project demonstrates that machine learning
can be used to accurately predict a posts popularity  after
collecting several thousand posts from hackernews over several
weeks  basic machine learning techniques were applied to a
generic set of features  after analyzing trends in the data and
refining the learning processes  our model predicted a posts
popularity with     accuracy  these results demonstrate that
basic machine learning models can be used to predict the
popularity of social media posts
keywordssocial news  machine learning

i 

introduction

over the past several years  social media has gained a wide
and influential presence online  the emergence of social media
news sites is reflective of this trend  sites like hackernews and
reddit drive enormous amounts of traffic and draw on
impressive user bases  as these sites become more and more
popular  the capability they provide to influence or connect to
large segments of the population will become increasingly
desirable  determining if there are well defined features in
posts that accurately predict a posts popularity is both an
interesting and a useful endeavor 
for the purposes of this paper  we define a popular post to
be one that has received over      upvotes   and an unpopular
one to be one that has received less than    
ii 



the words in the post



the domain the post links to



the time of day the post was created  in units of half
hours

before creating test and training data  we used posts to
populate dictionaries with words in the posts and domain
names from post links  unknown fields were added to each
field to account for keys found in the testing data but not the
sample data 
time of day was recorded by discretizing time into half
hour periods  and marking a bit for whichever period the post
fell into 
some features are currently left out  for example  poster
karma  a reflection of how popular the poster is  is naturally a
useful indicator of a popular post  however  we thought it
would be useful to initially avoid features intrinsic to the
poster  since this project is about what makes a popular post 
an answer such as a popular poster is not useful for someone
hoping to penetrate the social news community 
iii 

machine learning approaches

we used multiple machine learning techniques to gauge the
feasibility of our problems  our experiences with them are
cataloged in this section 

training data

a  data collection
we chose to collect training data from hacker news
 http   news ycombinator com    hacker news provides a
slightly more restricted set of post options when compared to
social news sites like reddit  such as restricting the use of
pictures  this makes for a more focused analysis 
we collected the training data by utilizing a hacker news
api called rewind hacker news     this resource samples the
top several hundred posts at different times of day and stores
them in a json format  using this api  we acquired around
     posts from about a two month period  the time of these
posts range across all hours of the day 
b  features
the feature set we used included the following features

a  nave bayes
our initial approach used an extremely simple multivariate
naive bayes model  run with our full feature set  since the
contents of the posts are relatively short  representing the
words as binary flags is not necessarily a huge detriment  the
binary nature of the model still failed to take into account all of
the information present in posts  and this approach gave us
about     accuracy  with a multinomial event model we saw
the chance to leverage more context than simply the presence
or absence of a word  the simple move to a multinomial model
with no other changes caused an increase of    to our initial
accuracy 
our initial feature set contained roughly        distinct
features  and many of the features fell into two not particularly
useful camps  many words were domain specific or otherwise
extremely rare  and showed up in very few posts  another set
consisted mainly of articles and prepositions  and showed up in

fian extremely large number of posts  we surmised that the
presence of large numbers of features of this sort contributed to
a significant amount of noise in the data  we decided to group
each of these sets into single categories  either uncommon
word or stopword  to cut down on the influence  without
completely discarding the information  after this trimming  we
were able to improve our accuracy by another    to     
our final optimization was to use a more involved method
to determine the most useful features to the learning process 
we decided to use the kullback leibler  k l  measure to
assess the usefulness of our various features  our approach to
this is discussed in detail in section iv  sweeping the number
of features used  we found that around     features gave us the
best accuracy while still retaining as many features as possible 
with this optimization  nave bayes achieved     accuracy 
b  perceptron
our data was collected over a period of about   weeks 
while a model we generate now may be able to accurately
predict popularity for a short time  internet trends tend to be
very short lived  and an unadaptive algorithm may quickly
become obsolete  this makes highly adaptive algorithms like
the perceptron appealing for their built in ability to learn
continuously  despite their simplicity
the perceptron achieved     accuracy on our test set after
running through our entire training set  the error on the second
half of our training set was about      suggesting its unlikely
more training examples would significantly improve accuracy 
we surmise that while it doesnt do anything too complicated 
the perceptron does well to capture easy patterns that lead to
popular posts  such as very popular buzzwords  websites  and
times  and manages to catch the low hanging fruit 
as a continuation to the experiment  we did some
investigation into a kernelized perceptron  the kernelized
version could measure cross correlation between various
features  which is important in text analysis since words in a
post are not independent  in addition  a kernelized perceptron
stores all of the examples where it mispredicted  this can be a
downside  as the storage requirements may not be trivial with a
high error rate  however by also storing the dates we can
gradually lower the influence of older examples when
calculating a new prediction 
we implemented a simple quadratic kernel perceptron  and
found that it improved accuracy to      this is an interesting
result  but given that it didnt even perform as well as naive
bayes  we decided not to pursue the avenue any further 
c  least squares
with previous approaches we treated popularity as binary 
a post is either popular  or it is not popular  however  this is
not a limitation of our data  rather  we have non binary metrics
for popularity in the form of comments and upvotes  as such  it
seemed useful to try and perform a regression on the data in
order to try to predict the precise value of those quantities  to
this end  we briefly investigated linear regression models 

our initial attempt tried to create a simple least squares fit
model  this had the effect of projecting essentially every test
input to about the same popularity  which was undesirable  to
curb this  we attempted a locally weighted least squares model 
however  regardless of bandwidth parameter we saw results
virtually indistinguishable from random 
our initial guess as to our poor success was that the large
feature set was introducing too much noise into our fit  in
attempt to address this  we decided to try projecting the
features into a lower dimensional feature space in an attempt to
digest the data and reduce noise  we retried our fit using
principal component analysis to project into spaces ranging
from   to    dimensions  the results were poor  our best
prediction occurred with    dimensions  where we got    
accuracy  even this result may simply be the result of noise 
given how poorly this approach performed  we did not
investigate it further  or otherwise examine how to reduce the
rms error of predictions 
d  support vector machine
after investigation into more unconventional methods  we
decided to return to the more standard models  as a follow up
to naive bayes  we ran a linear svm on the data  with the
features optimized in the same way  we had previously seen
that when run on a large amount of text data  svms tended to
have better asymptotic performance than naive bayes  this
was corroborated by the results  the svm achieved    
accuracy on the data 
encouraged by these results  we ran kernelized versions of
the svm over the data using the libsvm library     we tried
a sigmoid kernel  a radial basis function kernel  and a variety of
polynomial kernels  unfortunately  none of these performed as
well as the linear kernel  this was somewhat surprising  given
the improvement kernelization provided to the perceptron  our
current theory is that while kernelized svms can fit relatively
complex functions to the data  they overfit the training set in
our high dimensional feature space  making the resulting
models inextensible to other data  because the kernelized
perceptron is continuously learning as it classifies data  it was
not susceptible to this overfitting problem 
iv 

k l divergence scoring

the kullback leibler measure is commonly a used
technique for feature analysis  providing a measure of how
much information a specific feature provides to the learning
process  we hoped that scoring would allow us to reduce the
size of the feature set while maintaining or improving
classification accuracy  furthermore  the kl measure is
useful to elucidate underlying trends in the data  these trends
can be used to better understand the data set 
we implemented k l divergence as outlined in      the
endeavor was successful  in addition to actually improving our
accuracy for nave bayes  scoring provided additional insight
into our data  discussed in part b of the next section 

fiv 

results

a  machine learning classifications
below is a summary of our achieved accuracy with each
technique
table i 

classification accuracies

algorithm

multinomial
nave
bayes 
narrowed by k l divergence

features

website is at peak traffic is more likely to be in a better position
to be driven up or down in popularity by greater number of
users  we theorize that this may be related to how we
discretize time  a post that occurs at   am is more closely
related to a post that occurs at   pm then a post that occurs at
 am  however we do not model this relationship  and instead
treat time periods as orthogonal 

accuracy

domains

   

the table below shows the best scoring websites  divided
into news sites and all sites  these are not particularly
surprising  as they are all well known and respected websites 
note  however  that having a good k l score does not
necessarily imply how indicative that feature is of a popular
post  rather  it simply means the feature is useful for
distinguishing between popular and unpopular  for example 
google tends to have relatively generic links associated with it 
and may in fact be an indicator of unpopular posts 

quadratic kernelized perceptron

   

locally weighted least squares  features
projected to    dimensions

   

linear support vector machine

   

b  feature analysis
besides using our resulting scores to improve our model 
we also used our scores to better understand the dataset  our
scoring revealed several interesting if not surprising trends 

table ii 
rank

influential domains

news sites

all sites

time

 

tech crunch

github

the scores for the time related features showed that the
time of posting was highly influential  a graph of the influence
at a given time is shown below  it should be noted that the
lower the score  the higher the influence on the learning
algorithm 

 

the new york times

google

 

ars technica

tech crunch

 

wired

the new york times

 

bbc

ars technica

words
the leading words
in our analysis tended
to be common techoriented words  in
addition  the names of
three major technology
companies appeared as
highly influential  it
should be noted as
before
that
high
influence does not
mean high popularity 
a highly influential
feature may be a great
indicator
of
unpopularity 
we see a clear sinusoidal trend in this data  interestingly 
the periods of highest influence map well to a previous study of
the best times to post on hackernews     while the match
between our influence scores and the previously determined
best time windows is good  it is not perfect  we are slightly
concerned that the period of highest influence for our data
occurs directly inside the window of highest traffic  one would
assume that the period of highest influence would precede the
window of highest traffic  a post posted right before the

table iii 
rank

influential words

word

rank

word

 

show

 

web

 

startup

 

windows

 

apple

 

data

 

google

 

free

fivi 

future work

as of now  we only store the domain of the link  but  this is
insufficient to truly understand what hackernews readers find
interesting about a link  just because techcrunch is highly
influential doesnt mean that any link to techcrunch will lead
to a popular post  for example  a post linking to techcrunchs
contact information will not become popular  therefore  it
would be interesting to store features relating to the specific
article on that domain  for example  we could use the title of
the linked article as well as words from that article  an analysis
of those new features would give a more complete understand
of why certain urls are more influential than others 
because titles are relatively short  bigrams should be
analyzed in a future study  this will make the feature analysis
of words more powerful by providing the learning algorithm
with some context  for example  it may be that all popular
google related posts contain the words google news while
all unpopular google posts contain the words google wave 
without bigrams  consecutive words like google and
news are treated as independent  which is likely not the case 
an ultimate extension of the research would be to use it to
craft a popular post from scratch  creating a bot to do this
would be an interesting exercise 

as corporation to rethink how they communicate with their
audience  this study has shown that machine learning can
provide valuable insights into how to connect with users of
social news sites by revealing links between post content and
post popularity  this success should motivate a more in depth
study of this domain  ultimately the aim should be to
demonstrate that the knowledge gained through these
techniques can actually be applied to create popular posts 
acknowledgment
we would like to thank andrew ng and the entirety of the
cs    course staff for providing us with the tools and
necessary machine learning background to conduct this
research 
references
   

   

   

vii 

conclusion

the rise of social news will not only continue to change
how media is disseminated  but also force individuals as well

   

g  chang hwan lee  gutierrez  f   dejing dou   calculating feature
weights in naive bayes with kullback leibler measure   data mining
 icdm        ieee   th international conference on   vol   no  
pp                  dec       
the best time to post on hacker news  a comprehensive answer 
retrieved december       from  http   nathanael hevenet com the besttime to post on hacker news a comprehensive answer 
dabrowski  dominik  rewind hackernews  retrieved november     
from http   rewindhn com 
chang  chih chung  lin  chih jen  libsvm  a library for support
vector
machines 
retrieved
november
    
from
http   www csie ntu edu tw  cjlin libsvm 

fi