future distribution permission  the author s  of this report give permission for this document to be distributed to stanford affiliated students taking future courses 

a comparison of keypoint descriptors in the context of pedestrian detection 
freak vs  surf vs  brisk
cameron schaeffer
stanford university cs department
camerons stanford edu

abstract
the subject of keypoint detectors has been  for the
past    years  a popular topic of research in the
computer vision community  in the last five years 
though  the domain has shifted  the advent of
mobile devices such as the smart phone and tablet
computer has brought with it a demand for computer
vision on new platforms with restricted computing
cycles and limited memory  this shift to mobile
devices has resulted in a growing need for faster and
more memory efficient keypoint descriptors  for
applications such as panorama stitching  tracking 
and object recognition 
i present a comparison of two novel keypoint
descriptors with the well known surf descriptor in
the context of my pedestrian detector  i achieve over
    accuracy using freak descriptors with a
radial basis function svm classifier using a bag of
words model  i give charts comparing the speed and
accuracy of brisk and freak with surf in the
context of a pedestrian detection  and give valuable
statistics related to the training of such a detector 
which in turn will shed some led on the descriptors
themselves 

   introduction
the focus of the project is to perform interesting
evaluations to help programmers decide which keypoint
descriptor is most suitable for the pedestrian detector
application  and to produce code for a programmer to test
such descriptors on his own windows environment  to my
knowledge  at the time of this writing  a bag of words
pedestrian classifier for windows for these binary feature
descriptors has not been openly sourced  although several
similar classifiers exist for the linux environment   my
classifier is designed for pedestrian detection on still
images  but can be trivially extended to run in real time on
video  the classifier can also label where in the scene
pedestrians are located by taking images marked
positive  doing a bounding box sweep over the image 
and re running the classifier on each of these sub images 
although this feature is not analyzed in the report 

the pedestrian detector is written in c   using
msvc on windows  it relies on a standard bag of visual
words model  using surf  brisk  or freak features
as the possible word types  the detector provides
benchmarks on two state of the art binary descriptors 
freak     and brisk      comparing them to the widely
known surf keypoint descriptor      the pedestrian
detector is run with each descriptor in turn on the nicta
database         and compares performance tradeoffs such
as speed and accuracy in different situations 

     motivation
freak and brisk are novel binary descriptors that
far surpass the industry standards  it is very rare that a new
keypoint descriptor performs so much better than the
predecessors in this field  sift was left unchallenged for
almost a decade before surf was developed  now that
this new descriptor has been developed  analysis is
required so it can be immediately used by android
developers and security camera companies for applications
such as panorama stitching  object detection  tracking 
navigation  etc  although the bag of words object detector
has been around for   years      it is novel to use apply it
using these new descriptors and gauge performance in
detecting pedestrians  we can learn more about the
accuracy of freak and brisk by applying them to a
pedestrian detection problem on a real dataset 

   background related work
     overview of surf descriptor
the feature vector of surf is almost
identical to that of sift  it creates a
grid around the keypoint and divides
each grid cell into sub grids  at each
sub grid cell  the gradient is calculated
and is binned by angle into a
histogram whose counts are increased
figure    surf
hog descriptor by the magnitude of the gradient  all
weighted by a gaussian  these grid
histograms of gradients are concatenated into a   dimensional vector  the high dimensionality makes it
difficult to use this in real time  so surf can also use a

fifuture distribution permission  the author s  of this report give permission for this document to be distributed to stanford affiliated students taking future courses 

   vector of principle components of the    vector  pca
analysis is performed on a large set of training images  for
a speedup  surf also improves on sift by using a box
filter approximation to the convolution kernel of the
gaussian derivative operator  this convolution is sped up
further using integral images to reduce the time spent on
this step 

using a bag of words framework  much of the analysis
already done concerns accuracy of correspondences  and
while this is a valuable metric  it does not capture the
behavior of an ensemble of keypoints as i do 

   approach
this section describes our algorithm step by step 

     overview of brisk descriptor
brisk is a     bit binary descriptor
that computes the weighted gaussian
average over a select pattern of points
near the keypoint  see figure     it
compares the values of specific pairs
of gaussian windows  leading to
either a   or a    depending on which
figure    brisk
sampling pattern window in the pair was greater  the
pairs to use are preselected in brisk 
this creates binary descriptors that work with hamming
distance instead of euclidean  and can be made to run
extremely quickly using special ssse hardware
instructions for up to a  x speedup     

     overview of freak descriptor
freak is also a binary descriptor that
improves upon the sampling pattern and
method of pair selection that brisk
uses  freak evaluates    weighted
gaussians at locations around the
keypoint  but the pattern formed by
these gaussians is biologically
figure    freak
sampling pattern inspired by the retinal pattern in the
eye  the pixels being averaged
overlap  see figure     and are much more concentrated
near the keypoint  this leads to a more accurate
description of the keypoint as analysis will show 
the actual freak algorithm also uses a cascade
for comparing these pairs  and puts the    most important
bits in front to speed up the matching process 
unfortunately  this is not yet implemented in opencv so
it does not affect our analysis  but we expect that when
this is implemented  freaks matching step will speed
up by an order of magnitude 

     related work
there have been several benchmark studies similar
to mine  evaluating keypoint descriptors in the past
submitted to ieee and others      my work is novel
though because freak  surf  and brisk are brand
new descriptors that are not well analyzed yet  while some
benchmarks actually compare all three of these descriptors
     they have not given metrics a  in the context of
pedestrian detection  b  on the windows platform  or c 

figure    building the dictionary

     building the dictionary
i begin by loading all positive images  with mirroring 
and negative images  with sampling   and converting them
to   bit grayscale for a total of        images  half in
  x   resolution  half in cropped from     x    
resolution  i apply a dog band pass filter to avoid
aliasing  and then normalize image resolution to a fixed
value to ensure that the features learned are uniform
throughout training and testing  next  i run the surf
keypoint detector to produce the keypoints  fast      or
multi scale agast      keypoint detectors would also
work fine instead if a speedup is desired  these keypoint
vectors are fed into the descriptor  freak  brisk  or
surf  to receive the keypoint vectors as described earlier 
in negative images  if there are no keypoints  i just
resample the image  i then take all the keypoints from
every image ever seen  called the bag of features   and
cluster them into a fixed number of clusters using k
means with euclidean distance for surf and hamming
distance for the other two  the keypoint clusters from k 

fifuture distribution permission  the author s  of this report give permission for this document to be distributed to stanford affiliated students taking future courses 

means become our codewords that we will use to describe
images  we also store this vocabulary to a yaml file to

     nicta dataset
i use the widely cited nicta pedestrian dataset     to
learn the dictionary train and evaluate on  the dataset has
        x   positive images and      high resolution
negative images  i mirror positives left right for a total of
      positive training images  the negatives provided in
nicta are high resolution so i crop    sub images to get
      negatives  if there are no keypoints in the image 
we reject the crop and try again   the dataset is explicitly
divided into training and validation sets  with about    
of the images being used in validation  all tests are
performed on an intel     qm       ghz with  gb
ram  we do not multi thread for our benchmarks so only
one core is used 

figure    training and prediction process
save multiple hours on every subsequent test run 

     training and prediction
the next step is to train on our pedestrian dataset  we
load the appropriate labeled positive and negative image
files with bounding box information to begin training our
pedestrian detector  from the positives  we crop to the
region with the human  perform the same preprocessing as
before  invoke the descriptor  and match each keypoint in
the image to the closest feature in the dictionary  this is
done with either a brute force matcher opencv provides 
or a flann based matcher  flann uses the hierarchical
k means tree for generic feature matching and this gives
surf an inherent advantage because binary features are
not easily extended to hierarchical k means      
we make a histogram of the number of each visual
word found in the image and this histogram  a vector of
length size of dictionary  becomes our feature vector  for
negative images  we do the same thing  but instead of
cropping the human  we do    separate random crops 
these feature vectors go into the built in cvsvm library
 which takes in cvmats for training   and out comes a
trained svm  we save this svm for later use using the
opencv yaml save load functions because the training
step can take a very long time  hours on the full dataset  
the prediction is performed in the same way  take the
validation image  detect and extract the keypoints  match
the visual words to dictionary words and histogram  then
use the svm to predict the class of this histogram feature
vector 

figure    matching time vs  size of dictionary

     scalability of keypoint descriptors
we run tests to gauge the time it takes to match a
keypoint to the entire dictionary of      codewords  we
do this for each descriptor on the same training set of all
images  and we see from the graphs that surf is roughly
 x slower than brief  and brief is about    x slower
than freak  there appears to be a roughly quadratic
relationship between matching time and size of the
dictionary for all three algorithms as we would expect for
brute force matching  we see a similar quadratic effect
with the flann based matcher as well  as seen in figure
  

   evaluation
figure    choosing the optimal dictionary size
figure    samples from nicta dataset

fifuture distribution permission  the author s  of this report give permission for this document to be distributed to stanford affiliated students taking future courses 

     choosing vocab size to avoid over fitting
we determine the optimal dictionary size to achieve the
maximum accuracy of the pedestrian detector  if we have
too many words in the dictionary  we will overfit the
training data and see quantization effects when we build
our histogram  as seen by the rapid drop in accuracy as we
get close to       words   if we have too few words in the
dictionary  we underfit the data and are not descriptive
enough to distinguish between person and not person with
only a few visual words  notice that the number of
vocabulary words needed to describe all the images can be
partly dependent on the resolution of images  average
number of keypoints   during testing  it was noticed that
running on the inria dataset which has on average  x as
many keypoints as nicta  that having roughly     
words in the vocabulary was optimal  this can be
attributed to the fact that in higher resolution images  we
get more keypoints per image so we should have a few
more bins in the histogram without having to worry yet
about quantization effects  the ratio of average number of
keypoints to number of bins is important in the histogram
process it would seem in order to avoid overfitting  the
optimal number of bins for the nicta dataset was about
     keywords for my rough sweep of vocabulary sizes
using an exponential kernel svm  for each vocabulary
value in the plot  i did a log sweep of the svm c value 
and i display the optimal accuracy over all c values for
each number of codewords in the plot to remove svm
calibration as a source of error  because the accuracy is
variable  i run the test on   sets of      images that
nicta provides and plot average the accuracy over the  
image test sets  accuracy here is defined as percentage of
correct classifications over the number of validation
images 

figure    accuracy     as a function of number of
training images 

     a comparison of accuracy vs  training size
we note that freak generally performs better than the
other two algorithms     better on average than surf 
using a non linear nu rbf  nu parameter tuned  radial
basis function  svm  we see that all the algorithms
require about         training images to see a large spike
in accuracy in the non linear svm and then accuracy
begins to degrade after around      training images  also
from this plot  we can see that the histogram of words for
freak and brisk are clearly not linearly separable
because the linear svm does not really improve much
from random  achieving a peak of roughly     accuracy
on the binary descriptors   the linear svm seems to do
well on surf in comparison  around    better   but
surf in general is not as accurate as the other two with
the svm that performs best  the nonlinear exponential
kernel svm  the one class svm is an svm built into
opencv that takes in only positive training examples and
attempts to wrap a decision boundary tightly around these
examples  this svm does not work as well as the rbf
nonlinear one  but it still performs better than the linear
version  supporting the theory that the data is not linearly
separable  this could also occur because there are outliers
in the positive data which affect the one class svm much
more because it has less training data to begin with  on the
most trained non linear svm  freak performs at around
    accuracy  while brisk comes in second at     and
surf is close behind at     accuracy on the nicta
dataset with this bag of words pedestrian detector 

figure     accuracy     as a function of svm cost
parameter c  x axis  

fifuture distribution permission  the author s  of this report give permission for this document to be distributed to stanford affiliated students taking future courses 

     detector weaknesses
surf tends to underperform compared to freak and
brisk in accuracy  the binary freak provides a higher
accuracy description of pedestrian related keypoints  but
according to literature  this should be expected because it
has a higher rate of matching correspondences  which i
verified in testing        surf scored higher recall and
lower precision than brisk and freak  implying that it
is less conservative than the other two algorithms 
freak and brisk generally did not perform well on
pictures that had few keypoints and misclassified those 
these tended to include people who were not facing the
camera or who blended in well with the background  even
though these cases were covered in training  however  the
fault is more on the keypoint detector than the descriptor
because it is the detectors job to provide enough keypoints
for the descriptor in order to maintain accuracy  one
problem with the descriptor though is that it tended to do
rather poorly when the human pose was slightly off of
upright  shoulders were not aligned   the training data
seems to cover these cases so that is the fault of the
keypoint descriptor to capture this pose accurately  i
believe given more keypoints though  this could be made
up for by stronger hits on other parts of the body than the
shoulder  see figure    examples 

such as freak and brisk are the first step towards
widespread computer vision applications for the mobile
device industry  and before they become ubiquitous in this
market  further performance analysis is required 

   references
   a  alahi  r  ortiz  and p  vandergheynst  freak  fast retina
keypoint  in ieee conference on computer vision and pattern
recognition       
   leutenegger  chli  siegwart  brisk  binary robust invariant
scalable keypoints  iccv      
   h  bay  t  tuytelaars  and l  van gool  surf  speeded up robust
features  computer visioneccv       pages              
   k  mikolajzyk and c  schmid  a performance evaluation of local
descriptors  ieee trans  pattern analysis and machine intelligence 
vol     no     pp            october      
   g  overett  l  petersson  n  brewer  l  andersson and n 
pettersson  a new pedestrian dataset for supervised learning  in
ieee intelligent vehicles symposium       
   d  lowe  distinctive image features from scale invariant
keypoints  ijcv                    
   l  fei fei and p  perona          a bayesian hierarchical model for
learning natural scene categories   proc  of ieee computer vision and
pattern recognition  pp         
   brehar  r  a comparative study of pedestrian detection methods
using classical haar and hog features versus bow model computed
from haar and hog features ieee       p        
   a battle of three descriptors  surf  freak  and brisk
http   computer vision talks com         a battle of three descriptorssurf freak and brisk 

figure     left   wheres waldo  surf labeled these
images as human   right   low keypoint images are
often misclassified by freak and brisk 

   conclusion
in conclusion  i have created a pedestrian detector using
opencv for the windows platform  i determined that
surf is both a more robust and quick keypoint descriptor
than brisk and surf  its forbearers  the detector works
with     accuracy on the nicta pedestrian dataset and
most of the false positives can be attributed to lack of
keypoints which are the fault of the surf detector  or
extremely difficult images  the framework i provide is a
good start for someone trying to decide on a keypoint
descriptor for their own applications  the work also shows
that bag of words is a fine classifier to use with freak
and gives the optimal dictionary sizes  hopefully  over the
next few years  we will witness a rise in computer vision
applications on the mobile phone platform which is
becoming more and more the most lucrative field in
computer science  the invention of keypoint detectors

    edward rosten and tom drummond  fusing points and lines for
high performance tracking  iccv oct      
    elmar mair  gregory d  hager  darius burschka  michael suppa 
and gerhard hirzinger  adaptive and generic corner detection based on
the accelerated segment test  agast   in proceedings of the european
conference on computer vision  eccv      september      
    marius muja  flann  fast library for approximate nearest
neighbors        http   mloss org software view      

important note to cs    staff  this class was a joint
project for both cs    and cs     i worked alone on it all
quarter and hope to count the machine learning aspect of it for
this class and the computer vision aspect for cs     the part
for cs    includes  the training process for the svm such as
c value tuning  procedure for tuning with respect to both c
value and vocab size as variables  save and loading svm test
harnesses  etc  the entire process of bag of words and
general info is relevant to both classes  i have intentionally left
out many sections related to computer vision work because
they i feel they should not be double counted to keep this
paper relevant to what should be said about machine learning 
and i have done the same for the computer vision class with
respect to the learning aspects 

fi