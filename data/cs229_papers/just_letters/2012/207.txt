song genre classification via training on segment chromas and mfccs
caleb jordan

alex cope

stanford university
grnstnrd stanford edu

stanford university
alexcope stanford edu

abstract
automatic song classification has been an open challenge for
a number of years as it has many useful applications including dataset labelling and hit song prediction  there exists
research into many different approaches  including all of the
standard feature based classifiers  in this paper  we experiment with classification by multiple hidden markov models trained on chroma segment data from each song  these
models are theoretically much better suited to capture characteristics of songs for two reasons  first  they capture the
notion that consequetive segments of music are not independent  second  we derive the chroma and timbal data from
the song pitches and aggregate them intelligently over bars of
songs  producing time data that better aligns with chords and
real musical features  ultimately  our model performed much
worse than previous models  however  we hope think the results of this model will at least inform our understanding of
how machine learning can be applied to musical data 

chroma vectors encode pitch information  and when presented in sequence represent melodic and harmonic patterns
over time  different genres of music use different harmonic
frameworks as their basis  classical music employs a strict
set of contrapuntal and chord progression rules that have
largely been deemed irrelevant in modern music  chord sequences in pop music are very simple and center around
three or four chords  and jazz music features more color
 dissonant  tones and a different standard of chord progressions  mel frequency cepstral coefficients  mfccs   unlike chroma vectors  are non perceptual features and have
been used in many audio analysis tasks including speech
recognition  they can be thought to encode timbral information  i e  information about the instrumentation of a song 
different genres of music utilize different instruments  consider a folk song and a heavy metal song  so mfccs are
often used in genre classification  rump et al        

introduction

dataset description

understanding music is perhaps one of the most open ended
challenges in machine learning  while there are many specific tools to analyze features of music  including pitches 
beats  tempo  etc  there are more general problems like song
classification and playlist generation that are still being developed  these more general problems are challenging both
because of the large number of factors involved  as well as
the subjectivity of the results  classifying songs as hit
songs  for example  is an immensely practical and lucrative
application  but so far  this classification depends on features
completely unrelated to the music 
in this paper  we approach the problem of song classification by genre  related works have attempted to classify
songs by genre using support vector machines and similar
models to various degrees of success  tzanetakis  essl  and
cook       anan et al         to differentiate from previous models  we exploited the time series nature of pitch
and timbre information by using hidden markov models to
model our data  instead of using features like tempo and
mode to classify music  we used short time features  features derived from short time intervals in the music  meng
and shawe taylor       

all of the musical data came from the million song dataset
 bertin mahieux et al         a dataset of information of
one million popular songs which is freely available online
via amazon web services  the msd includes meta data
for songs including the estimated key of the song  mode
of the song  artist  title  and tempo  in particular  each
song includes arrays representing beats  pitches  and timbre
throughout the song  these songs are not labelled by genre 
however 
to acquire songs labelled by genre  we downloaded song
titles from sharemyplaylists com  labelled by the genre of
the playlists with which they were associated  of the     
title and artist pairs obtained  about one third were present
in the msd 
for the final dataset  we collected      songs from   
different genres  with labels and metadata  as a preprocessing step  we sampled the pitch and timbral data  about      
   dimensional elements originally  into    buckets  these
buckets were aligned with the onset of measured with the
hope that when combined in sequence  they would hold useful chord progression data  furthermore  we normalized the
pitch data by key  using the key information from the msd  
transposing the data so that each song is effectively in the
key of c 

c       association for the advancement of artificial
copyright 
intelligence  www aaai org   all rights reserved 

fiapproach
in order to capture the internal structure of each song and the
time dependent nature of the pitch data  we used a hidden
markov model to model the data  the observed variables
were the normalized     dimensional vectors of pitch data 
we assumed that the value of the discrete  latent variable at
each timestep determines a normal distribution from which
the corresponding pitch data was drawn 
that is  with observed variables x  t  and unobserved
variables y  t  for each segment t  we assume that x  t  
n  k   k   given y  t    k  the parameters of one hmm
models are as follows 
 k   the probability that y       k for a sequence 
 t   the transition matrix where tij is
p  y  t      j y  t    i  
 k   the mean corresponding to label k 
 k   the covariance matrix corresponding to label k 
to build a classifier  we trained a different model for each
genre  using the appropriate labelled sequences  the prediction for a test song is the genre corresponding to the model
for which the test song has the highest likelihood 
h x    argmaxk l x k  

   
figure    measure aligned key normalized chroma  top 
and mfcc  bottom  features for the first    bars of fleet
foxes white winter hymnal

is 
l x  m    

x

 p  y      p  x       x     y      

y

y

p  x  t    x t   y  t   p  y  t   y  t      

   

t

which is calculated efficiently using clique tree inference
 mengshool       

experiments
to analyze and preprocess the pitch data  we used a custom
python script to connect to amazons ec  service to access
the million song dataset from the cloud and the python
numpy library to normalize and cull the pitch and timbral
data vectors  modeling and learning the hmm was written in matlab  using the expectation maximization algorithm
with clique tree inference  we ran inference on the hmms
within em to calculate the log probability 
we tested both chroma and mfcc features  fig     
chroma features are represented as a    dimensional vector  encoding the octave invariant intensity of each pitch on
the chromatic scale  a c major chord  for example  would
be represented by a chroma vector with high intensities on
the features representing c  e  and g  we transposed each
song into the key of c by appropriately shifting the chroma
vectors so we could classify songs more accurately by chord
patterns  mfcc features are spectral features which encode
the timbre of a segment 
tuning the models involved experimenting with a few
different hyperparameters  the most interesting of these
was the cardinality k of the latent variables for the hmms 

which we swept from   to     fig      the choice of k had
little effect on the results  however  larger k values  starting with   to   depending on the amount of data  caused fitting gaussian parameters to be an underconstrained problem 
this lead to singular covariance matrices  necessitating early
termination of the em algorithm  however  even with early
termination  our results demonstrated impressive overfitting
on the medium dataset  with about    training error  unless
labelled otherwise  all accompanying plots were made using
a k value of   
our results show that the hmm is quite simply a poor
model with which to solve this problem  the plots presented
represent tests on just over     songs  with    genres having
enough data  the learning curve  fig     suggests a biased
model as training error increases with more training data 
which was slightly unexpected given the sheer number of
parameters the model uses  while the testing error  around
     is slightly better than chance        for    genres   it
is certainly unacceptable as a real genre classifier 
upon close inspection  some interesting results appear 
first is the observation that  when limiting the covariance
matrix to be diagonal  the models performed incredibly
poorly with around     training and testing error  i e  the
assumption that pitches are independent increases the error
to chance  this suggests that these models do somewhat
capture the dependencies between the different notes in segments  second  studying differences between predicted labels and real labels of test data revealed interesting rela 

fiis entirely impervious  it is possible that these models would
perform quite well separating songs with different musical
structures or common chord progressions  in a different domain  these models may be better suited to automatically
detect chord progressions and other musical patterns within
songs  for now  the hypothesis that time series models can
automatically classify songs is successfully disproven 

references

figure    learning curves over k values of the hmm

figure    learning curves over both chroma and mfcc segment types for     songs 
tionships  in particular  the largest number of misclassified songs were all blues songs mistakenly identified as pop
songs  ultimately  we believe these models may be capturing important characteristics of the music that have nothing
whatsoever to do with the genre  but further investigation
would be required 

conclusion
we have explored a previously untried method of automatic
song classification  using hidden markov models to model
time segment pitch data within songs  these models were
entirely unsuccessful at classifying songs by genre  however  there are several things to be learned from the expedition and its poor performance compared to previous attempts  first  the genre of the songs seems more or less
independent of the per segment data within a song  second 
by comparison of different distributions within the models  it
is clear that ours does capture relationships between pitches
within chords  finally  while these models do not classify
genre well  they may yet have success with other problems 
as commonly occurring misclassifications suggest that the
models learn similarities between certain genres  further
experiments with hidden markov models and song data
should focus on other problems  while genre classification

anan  y   hatano  k   bannai  h   and takeda  m       
music genre classification using similarity functions  in proceedings of the   th international society for music information retrieval conference  ismir    
bertin mahieux  t   ellies  d  p   whitman  b   and lamere 
p        the million song dataset  in proceedings of the   th
international society for music information retrieval conference  ismir    
meng  a   and shawe taylor  j        an investigation of
feature models for music genre classification using the support vector classifier  in proceedings of the  th international
society for music information retrieval conference  ismir
   
mengshool  o        understanding the scalability of
bayesian network inference using clique tree growth curves 
artificial intelligence             
rump  h   miyabe  s   tsunoo  e   ono  n   and sagama  s 
      autoregressive mfcc models for genre classification
improved by harmonic percussion separation  in proceedings of the   th international society for music information
retrieval conference  ismir    
tzanetakis  g   essl  g   and cook  p        automatic musical genre classification of audio signals  in proceedings of
the  nd international society for music information retrieval
conference  ismir    

fi