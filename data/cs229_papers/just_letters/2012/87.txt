cs     project  report  
using  newspaper  sentiments  to  predict  stock  movements  
hao  yee  chan            anthony  chow  
haoyeec stanford edu      ac     stanford edu  
  
problem  statement  
it  is  often  said  that  stock  prices  are  determined  by  market  sentiments   also   these  stock  prices  are  an  
instant  reflection  of  the  current  market  sentiments   despite  this   investors  often  use  current  news  to  
inform  their  next  investment  decision   the  problem  is  then  that  it  is  almost  impossible  to  read  through  all  
the  news  available  online   even  with  a  wealth  of  readings   market  sentiments  are  difficult  to  be  quantified  
and  understood     
  
this  project  looks  at  news  from  reuters  technology  to  be  used  as  sources  of  data  to  generate  a  model  to  
capture  market  sentiments   this  model  will  be  used  to  try  to  predict  the  movements  of  the  nasdaq  
composite  in  the  immediate  future   
  
dataset  
we  scrapped  data  reuters  to  create  a  model  for  market  sentiments   we  will  be  using  yahoo  share  prices  
to  construct  our  classifiers   which  will  be  the  nasdaq  composite   which  is  highly  followed  in  the  us  as  an  
indicator  of  the  performance  of  stocks  of  technology  companies  and  growth  companies    see  appendix  for  
screenshot  of  reuters  technology   we  created     separate  datasets   one  with     year  of  data        days  of  
trading   and  the  second  one  with     years  of  data        days  of  trading    note  that  there  are  less  days  of  
trading  than  there  are  in  a  year  due  to  market  closing  during  weekends  as  well  as  during  public  holidays   
  
problem  formulation  
we  split  the  news  data  from  reuters  technology  into  headline  and  body  feature  sets   we  aim  to  predict   
given  todays  set  of  headline  and  body  features   if  the  closing  price  of  tomorrows  stock  will  be  higher  or  
lower  than  todays   using  data  from  yahoo  finance   
  
     
    
  
                                
  
we  did  some  preprocessing  to  build  our  dataset   from  the  news   we  first  split  them  into     sets   headline  
and  body   for  each  set   we  had  stop  words  removed   the  words  lemmatized  and  selected       words  using  
the  following  heuristics   
  
bag of words  
chi squared  
mutual  information  
most  frequent  words  

   
                                         
    
    
    
  
                                              
    
     
where      number  of  news  
articles  with  word     and  class     
table      feature  selection  techniques  used  
our  methodology    
we  used  a  mixture  of  supervised  and  unsupervised  machine  learning  techniques  to  figure  out  our  data   
under  the  unsupervised  techniques   we  used  factor  analysis  with  em  to  look  at  some  of  the  key  
dimensions  that  described  the  data   we  also  compared  the  performance  of  the  various  supervised  
learning  algorithms  on  the  dataset   a  summary  of  the  supervised  learning  algorithms  implemented  in  this  
paper  is  summarized  in  the  table  below   

  

   

fi  
multinomial  nave  bayes  
gaussian  discriminant  analysis  
support  vector  machines  
headline  features      year   
   
headline  features      year   
body  features      year   
body  features      year   
body  features      year   
headline  features      years   
   
headline  features      years   
body  features      years   
body  features      years   
body  features      years   
table      table  of  summary  of  supervised  learning  algorithms  implemented  
  
our  results    
factor  analysis  of  data  
we  implemented  factor  analysis  on  the  body  feature  sets   we  present  the  results  obtained  from  the  body  
feature  sets      year  and     years   generated  from  frequent  words   we  find  that  there  seem  to  exist     main  
dimensions  in  the  data    finance   facebook  and  apple  that  characterized  the  news  from  last  year   for  the  
   years  data   it  seemed  to  be    finance   apple  and  everyone  else   perhaps  the  facebook  ipo  in  this  past  
year  generated  enough  coverage  to  create  this  unique  dimension  in  the  data   armed  with  the  idea  that  
there  were  special  dimensions  in  the  data   that  it  was  not  as  random  as  we  thought   we  went  to  perform  
supervised  learning  with  more  confidence   

  

  
table      dimensions  obtained  using  factor  analysis  on  body  feature  set  of    year   left   and    years   right   
of  data  respectively  

  

   

fisupervised  learning       multinomial  nave  bayes  
  
we  started  the  supervised  learning  with  multinomial  nave  bayes   the  datasets  were  split  into       training  
and       testing  sets   observing  that  there  exist  imperfections  in  the  market   we  created  a  cumulative  
feature  set  that  takes  into  account  information  from  past  news  in  the  following  fashion   
  
 
 
 
                         
 
 
 
                        
                    
                  
              

          

  
figure      an  example  of  test  statistics  trained  using  chi squared  feature  selection   
  
remarks       best  performance  comes  from  feature  sets  that  contain  information  only  from  current  day  or  
with  one  extra  day  behind         higher  dimension  feature  set  needed  for  better  performance  for  more  
number  of  days  incorporated    see  figure        features  for     days        features  for     day        features  for  
   days   
  
it  is  interested  that  the  chi squared  and  mutual  information  feature  selection  did  not  perform  as  well  as  
feature  selection  using  frequent  words   from  our  experiments   we  find  that  the  best  performance  came  
from  feature  set  generated  from     year  of  data  with  frequent  word  feature  selection   the  test  results  are  
summarized  in  the  two  tables  below   
  

  

  

   

fitable      summary  of  statistics  of  mnb  using     year  of  data  

  

table      summary  of  statistics  of  mnb  using     years  of  data  
  
supervised  learning       gaussian  discriminant  analysis  
we  then  tried  using  gda  to  compare  performance     

  
figure      an  example  of  test  statistics  trained  using  mutual  information  feature  selection   
  
remarks       the  covariance  matrix  rapidly  becomes  singular  at  higher  feature  spaces  due  to  insufficient  
training  data   this  occurs  when  the  number  of  features  is  approximately  equal  to  the  number  of  training  
data       also   we  observe  that  the  training  data  gets  fitted  very  well  with  increasing  number  of  features   
perhaps  leading  to  over fitting       we  are  able  to  obtain  good  accuracy         on  the  test  data  set  with  low  
number  of  features   thus  when  it  is  expensive  to  collect  features   the  gda  presents  itself  as  a  good  
alternative  to  mnb     
  
the  tables  below  summarize  our  findings  with  gda   we  see  that  in  general  the  best  performance  comes  
from  number  of  features  that  are  significantly  lower  than  that  required  by  the  mnb   

table      summary  of  statistics  of  gda  using     year  of  data  

  

  

   

fitable      summary  of  statistics  of  gda  using     years  of  data  

  

  
supervised  learning       support  vector  machines  
unlike  the  mnb   there  does  not  seem  to  be  a  clear  trend  in  the  results  of  the  svm   from  the  tables  below   
we  observe  that  we  get  the  best  results  from  the  svm  using  the  mutual  information  feature  selection   all  
the  results  below  were  calculated  using  linear  kernel     

table      summary  of  statistics  of  svm  using     year  of  data  

table      summary  of  statistics  of  svm  using     years  of  data  

  

  

  
summary  and  future  work  
we  compared  the  performance  of     supervised  classifiers  on  the  reuters  technology  news  sections  ability  
to  predict  the  stock  movements  of  the  nasdaq  composite   all     were  able  to  perform  better  than  
random   with  svm  and  nmb  being  able  to  perform  better  than       accuracy  under  certain  conditions  of  
feature  selections   number  of  features  and  number  of  days  of  information  included   also   with  the  
dimensions  learnt  from  the  factor  analysis   we  can  show  convincingly  that  our  learning  algorithms  did  pick  
up  hidden  trends  in  the  data  to  aid  in  prediction   this  showed  that  there  is  ability  of  news  sentiments  to  
predict  stock  market  movements  in  the  imperfect  market  conditions  we  live  in  today   
  
the  next  step  would  be  to  build  a  stronger  classifier  based  on  the     weak  classifiers  we  presented  in  this  
paper   also   other  classification  techniques  like  random  forests  could  be  attempted  as  well   more  
interestingly   we  could  incorporate  news  from  other  sections   to  see  which  sections  provide  best  
prediction  capabilities  for  tomorrows  stock  price  movements   
  
bibliography  
    andrew  ng   cs       machine  learning   stanford  university        
  
  
  
  
  
  

  

   

fiappendix  
screenshots  of  reuters  technology  
data  scrapped  from  http   www reuters com   

  
  

example  of  headline  and  story  from  reuters  technology  news  
  
screenshots  of  yahoo  finance  
  

example  of  screen  shot  from  yahoo  
finance   this  shows  the  ticker  for  the  
nasdaq  composite   we  also  
experimented  with  others  such  as  the  
dow  jones  industrial  average  and  the  
nikkei  index   however   it  appears  that  
the  news  we  were  scraping   ie   
technology  news   were  better  
predictors  of  the  nasdaq  composite  
due  to  the  large  number  of  technology  
companies  in  this  stock  market  index   

  

  

  

   

fi