learning static parameters in stochastic processes
bharath ramsundar
december         

 

introduction

consider a markovian stochastic process xt evolving  perhaps nonlinearly  over time variable t  
we may observe this process only through observations yt   this process is parameterized by vector
of parameters   which is typically unknown and must be learned from the sequence  yt    learning
the parameter  is critical to gaining understanding of this class of stochastic processes 
nonlinear stochastic processes arise in a variety of situations  for example  understanding the
time evolution of stock value through a standard stochastic volatility model requires the ability to
track the nonlinear evolution of price xt   such problems are typically solved by sequential monte
carlo  smc  methods  such as particle filtering  but only when parameter vector  is provided
to the monte carlo algorithm  standard algorithms such as particle filtering encounter difficulties
when  is unknown 
consequently  a large literature has developed focusing on algorithms to learn  in this setting 
for example  researchers from statistics and econometrics have introduced the particle mcmc
algorithm     which mixes markov chain monte carlo  mcmc  methods with sequential monte
carlo algorithms in order to learn parameters   unfortunately  such algorithms tend to be slow 
and often require at least quadratic time complexity     
in this project  we introduce a new algorithm that learns parameter  while performing inference 
namely  we modify the decayed mcmc filtering algorithm     to learn static parameters  we then
perform empirical analysis showing the robustness of this algorithm in handling static parameters
and also prove preliminary correctness results 
direction and guidance for this research were provided by professor stuart russell of uc berkeley 

 

nonlinear state space model

the following toy nonlinear stochastic problem     is routinely used to evaluate algorithms for their
ability to handle nonlinear time evolution 
xn 
xn 
    
    cos    n    vn
 
 
    xn 
xn 
yn  
  wn
  

xn  

x   n         the vn are iid drawn from n     v     and the wn are iid drawn from n     w   
 n  m       denotes the gaussian distribution of mean m and variance    and iid means independent
 

fiand identically distributed   we set parameter vecter     v   w    henceforth  we maintain the
convention in figures that blue lines are observations  green lines are true states  and red lines are
the products of inference 

figure    nonlinear state space model  w   v    

 

prior literature on static parameter learning

in this section we review various algorithms created for static parameter learning problems 

   

particle filtering

the particle filter does not learn static parameters  but effectively draws samples from nonlinear
processes given such parameters  we implemented a simple particle filter to draw samples from the
nonlinear state space model  figure   shows that the particle filter can almost infer the true state 

   

particle markov chain monte carlo

the pmcmc algorithm     is an extension of the markov chain monte carlo  mcmc  framework
to handle nonlinearities  the pmcmc extends the reach of this framework by using a particle
filter to sample from nonlinear distributions  we implemented pmcmc and used it to calculate
distributions for parameters v   w   see figure   for details 

figure    nonlinear state space model particle filtering     particles      time steps

figure    pmcmc parameter estimation
histogram

 

fialgorithm    dmcmc  decayed mcmc filtering
input  g t   decay function  s  total number of time steps 
k  gibbs moves per time step 
es
output  approximate filtering distributions d
  for s     to s do
 
for i     to k do
 
choose t from g s  
 
sample xt from p  xt   xt    xt     yt   
e s 
 
increment count for xs in d
 

e            d
et 
return d

 

sdmcmc  decayed mcmc with static parameters

in this section we define a variant of the decayed mcmc filtering algorithm  introduced in     
for the static parameter estimation problem 

   

decayed mcmc algorithm

we start by giving a brief overview of decayed mcmc filtering  assume as before hidden state
variables x            xt and evidence variables y            yt   decayed mcmc creates a markov chain to
target the distribution xt   y          yt through gibbs updates  to save time  the algorithm spends
progressively less time updating past elements and focuses on recent history  the rate of this decay
is given by function g t  on window     t   which controls sampling  for example g t     t  gives
the standard gibbs sampling methodology  the result achieved in     is that for
g   t     t  t         
algorithm   converges to the true filtering distribution for xt in time not dependent on t  

   

decayed mcmc for static parameters

mcmc techniques have long been used in the statistical literature to estimate static parameters 
we consequently propose algorithm     as a method to dynamically learn static parameters while
filtering 
     

empirical results

empirical results on the nonlinear state space model shows that algorithm   works well in practice 
however  the effectiveness of algorithm   becomes most clear when we emphasize the fact that
this inference is performed without prior knowledge of     v   w    for comparison  we perform
inference in the particle filter with  initialized according to p   from figures   and    we see
that the particle filter noticeably diverges from the true state  while sdmcmc achieves near perfect
accuracy 
in fact  with growing sequence size s  algorithm   does not lose accuracy  while the particle
filter does  figure   compares the l  distances of the inferred and true solutions for sdmcmc and

 

fialgorithm    sdmcmc  decayed mcmc filtering for static parameters
input  g t   decay function  s  total number of time steps 
k  gibbs moves per time step 
e s   parameter 
output  approximate filtering distributions d
  sample  from prior p  
  for s     to s do
 
for i     to k do
 
choose t from g s  
 
sample u from u          
 
if u   s  then
 
resample  from p     x            xs   
else
sample xt from p  xt   xt    xt     yt     
es  
increment count for xs in d

 
 
  
  
  

sample xs   from p  xs     xs   ys       
e            d
e t    
return d

figure    decayed mcmc  k    

figure    particle filter     particles

smc  particle filter  methods for s       timesteps  this figure indicates that the l  distance is
divergent for growing t with smc methods but is convergent for sdmcmc 
finally  we consider the parameter learning capabilities of sdmcmc  figures   and   show the
histograms of v   w considered in a run of algorithm    although the distribution does not center
around the true parameters v   w      it is close  the diagrams suggest that there might be
some bias  further analysis is required to clarify this point 
     

preliminary mathematical correctness analysis

we present some preliminary mathematical analysis of algorithm   
theorem      for all s   s in the outer for loop of algorithm    the inner for loop defines a
markov process with stationary distribution x            xs      y            ys  
proof  it suffices to show that the distribution x            xs      y            ys is invariant under an
action of the inner for loop  to do so  we will consider the two cases of the if condition separately 
suppose u     s  note that the marginal distribution  summing out   on x          xs is exactly
 

fifigure    log log comparison of l  distance for sdm  figure    v histogram  true
v    
cmc and smc

figure    w histogram  true
w    

the conditional x            xs   y            ys   algorithm   samples   p     x            xs    it follows
that the joint distribution after the sample is
p     x            xs  p  x            xs   y            ys     p     x            xs   y            ys  p  x            xs   y            ys  
  p    x            xs   y            ys  
now suppose that u    s  suppose that i is sampled according to decay g s   then the
marginal distribution  summing out xi   is
  x            xi           xs  p    x            xi           xs   y            ys  
the hat signifies exclusion  conditional independence shows that the joint distribution after
the gibbs sample is then
p  xi     xi    xi     yi  p    x            xi         xs   y            ys  
  p  xi     x            xi           xs   y            ys  p    x            xi           xs   y            ys  
  p    x            xs   y            ys  

references
    c  andrieu  a  doucet  and r  holenstein  particle markov chain monte carlo methods  journal
of the royal statistical society       
    n j  gordon  d j  salmond  and a f m  smith  novel approach to nonlinear non gaussian
bayesian state estimation  in radar and signal processing  iee proceedings f  volume     
pages         iet       
    n  kantas  an overview of sequential monte carlo methods for parameter estimation in general
state space models  in proc  ifac symposium on system identification  sysid        
    b  marthi  h  pasula  s  russell  and y  peres  decayed mcmc filtering  in proceedings of the
eighteenth conference on uncertainty in artificial intelligence  pages         morgan kaufmann publishers inc        
 

fi