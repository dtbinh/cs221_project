the learning keyboard
using the xbox kinect to learn user typing behavior

jonathan ellithorpe

pearl tan

jdellit stanford edu

pearltan stanford edu

abstractthe learning keyboard is a machine learning
system designed to guess what a user is typing solely by observing
their hand movements on a keyboard  the system trains on a
per user basis using supervised learning  and generates feature
vectors on a per word basis  we show that on datasets consisting
of more than     unique words the learning keyboard is able
to guess words with over     accuracy 

i 

i ntroduction

since the invention of the typewriter in the     s  keyboards have been and remain to be the primary method of
character input for computers and various other devices  at
an abstract level  the keyboard is only a method to translate
actuation of the hands into a sequence of characters to be
input to the computer device  in light of this  and with modern
computer vision technology  we asked ourselves if the presence
of a physical keyboard was even necessary to achieve this very
basic goal  as a first step towards answering this question
we designed the learning keyboard system  whereby the
computer actually learns what the user is typing by observing
only the movement of the users hands  while the presence of
a physical keyboard is required for training  once trained the
keyboard is no longer needed for typing 
in this paper we describe our first efforts towards this goal 
including the setup of a data collection station for recording
a users typing and hand motions  the extraction of different
feature vectors from the data  and our performance results
using a multi class classification support vector machine 
ii 

data c ollection

for collecting the needed data for training we setup a monitoring station pictured in figure    suspended directly above
the laptop keyboard at a distance of roughly    centimeters
is a kinect sensor equipped with an infrared camera  infrared
projector  and rgb camera  the desk space below is marked
off for consistent placement of the laptop with respect to the
camera above 
to pull the image data from the kinect sensor we used
the open source openkinect driver for mac      the software
comes with a program record which dumps all video data
from the device to disk with a unix time of day timestamp 
in the recorded depthmap images  each pixel value denotes
the distance of the object at that point in the image from the
camera  figure   shows what the camera captures from its
viewpoint 
to capture key press information we wrote a small keylogger using the tkinter library      we log every keypress

fig     data capture station

made by the user and tag it along with a unix time of day
timestamp  which allows us to later sync up with the kinect
video data 
finally to simplify data processing and feature vector
extraction  for each data capture session we author a dictionary
file pre defining the words to look for and extract out of
the data  in the future it would of course be possible to
automatically generate this dictionary file from the keylogging
data itself  but for now we use this method to manually control
which words are observed and learned on in the datasets 
iii 

f eature v ector e xtraction

a  learning on words  not letters
for our first implementation of the system we decided to
extract feature vectors on a per word basis and not on a per
key basis  as might seem at first obvious to try  this decision
was the result of two simple observations  the first was that
single key presses along the homerow of the keyboard  asdfjkl 
were indistinguishable from each other given the resolution of

fiiv 

f eature v ectors

in this section we describe the types of feature vectors that
we developed and tested 
a  edge detector type

fig     raw depth map capture from camera

depthmap data collected by the kinect sensor  indeed  a single
keypress is a mere     millimeters of movement   therefore 
learning would need to be done based on the whole position
of the hands  the second observation was that the position
of the hands during the press of a key is totally dependent
on the word being typed anyway  resulting in any given key
having as many feature vector signatures as there are words
that include that key  while learning on a per key basis may
nontheless still be worth a try  it is left as future work 

for this type of feature vector we used the canny     edge
detector as implemented in the opencv library to turn the
depth map data for a given frame of a given word into an edge
map  the edge maps for all frames are then added together to
produce a single frame for that word  see figure   for an
example  our reasoning for using such a feature vector was
that the superimposition of edge maps results in an image that
seems to capture the motion of the hands during the typing of
a word 

 a  no downsampling

 b  downsampled

fig     edge detector type feature vector

b  image data preprocessing
before extracting feature vectors for words from the collected image data  we first run the images through a proprocessor  the preprocessor removes the background from the image
apart from the hands themselves  using a simple threshold
filter   and crops the image to include only the area covered by
the keyboard  figure   shows an example of a preprocessed
image 

 a  no downsampling

 b  downsampled

fig     sum type feature vector

 a  no downsampling

 b  downsampled

fig     average type feature vector
fig     preprocessed depth map

c  extraction mechanism
to build a feature vector for the occurence of a typed word 
we first find the start and end times for the typing of that word
in the keylogging data  and then use those times to splice out
the recording of that word in the preprocessed depth map video
stream  the result is a set of frames for the word that are then
processed to generate a set of features describing the hand
motions captured in the frames  in the next section we describe
the three different types of feature vectors that we designed 
and explore their performance in a support vector machine in
the results section 

the downside of this approach  however  was that since the
resulting image in our implementation of the system was too
large     x    to use in an svm  to allow the computation to
run fast enough   downsampling was required  figure  b shows
the result of downsampling  and we can see that the image
no longer seems to capture the movement of the hands  in
the section on results we see how downsampling affects the
performance of an svm on this type of feature vector 
b  sum type
this feature vector is much simpler than the edge detector
type and just adds up the images from the frames captured for a
given word  since the background of all the depthmap images
is black after preprocessing  and since the image is   bit
greyscale  adding the images together results in an image that

fiis bright white wherever the hands had moved to  producing
a type of snow angel effect  our logic in using this style of
feature vector was therefore that the svm may be able to use
such area coverage of the hands during the typing of a word
as a clear signature of what word was typed  see figure   for
an example 
c  average type
this feature vector is the same as the sum type feature
vector except that we take an average at the last step  taking
an average has the effect of revealing the amount of time the
fingers have spent on various parts of the keyboard  which is
lost in the sum type feature vector due to greyscale images
having a     pixel value cap  see figure   for an example of
this type of feature vector 
v 

l earning m odel

since the problem at hand was fundamentally a supervised
learning problem with multi class classifcation on words  we
decided to use an off the shelf support vector machine called
libsvm      we chose default parameter settings  with the
exception of using a linear kernel instead of the default radial
kernel  all data in the results section was generated using
libsvm version      with these settings 
vi 

r esults

a  datasets
to evaluate the performance of our feature vector types we
captured four datasets described below  in order of increasing
complexity  on which to test them 
   plumpy databases dataset  our first dataset consisted only of the words plumpy and databases  these
words are typed solely by the right and left hands respectively
 and so are easily distinguishable in the feature space  
   charlie samson dataset  our second dataset also
consisted of only two words  charlie and samson  but this
time each requires both hands to type  making them harder to
tell apart in the feature space  
   jumping fox dataset  our third dataset consisted of
the   unique word sentence the quick brown fox jumps over
the lazy dog  and covers every letter of the alphabet 
   night before christmas dataset  twas was the
largest dataset that we collected  and consists of typing the
first   stanzas of the night before christmas poem by
clement clark moore  these stanzas contain a total of    
unique words      words in all  
b  comparing performance
to compare the performance of our different feature vector
types  for each type and for each dataset above we generated a
training set consisting of    samples for every unique word in
the dataset  we then fed these training examples to the svm
for leave one out cross validation and recorded the results 
shown in figure    note that for computational tractability
we used a downsampling factor of   on our images to reduce
the length of the resulting feature vectors from        to     

the plumpy databases two word dataset turned out to
pose no challenge to any of the three feature vector types  the
single handed typing of the two words came through clearly for
each  all of which scored a perfect accuracy  when increasing
the degree of complexity with multi hand typed words in
the charlie samson dataset  however  we see performance
begin to drop  surprisingly  though  this reduced accuracy is
held at     even when we increase the number of unique
words to   in the jumping fox dataset  despite the fact that
we are maintaining our    samples   word restriction for all
datasets  we notice that the edge detector type feature vector
begins to suffer in performance  however  and takes an even
bigger hit when increasing the unique word count to     in the
night before christmas dataset  its here that the different
feature vector types strength as a signal for a given word
starts to become apparent  the sum type shows itself to be
an even better signature than the edge detector type  while
the average type leads the ranks  validating its preservation
of time information as a useful quality and strong indicator of
which word was typed 
the floundering edge detector feature vector was a curiousity to us since we had assumed from the start that it would
be the best feature set  our first suspicion was that downsampling may have been taking a greater toll on its performance
compared to the other feature vector types  but this question
was put to rest when we observed the performance of each
type with zero downsampling  shown in figure     though
we still dont know the reason for its lagging performance 
perhaps variability in the resulting superimposed edge map is
a factor here  further analysis on this is left for future work 
figure   also helped to answer our questions about the
effects of downsampling in general on the performance of our
feature vectors  surprisingly  little performance was lost with
our chosen default downsampling factor of    beyond this 
however  we see accuracy begins to fall off as more and more
information is lost  it is interesting to note  however  that even
with a downsampling factor of     that is  a   x         factor
reduction in the number of pixels  down to a tiny  x  image  
we can still do roughly   x better than random guessing on
the night before christmas dataset  random guessing gives
us an accuracy of        while using the average type feature
vector we achieve          in other words  theres still a lot
of information about the original        pixels packed into
the downsampled     this observation leads us to believe
that other feature set reduction methods  such as pca  may
yield even better results than those we achieved having chosen
downsampling rather arbitrarily 
even so  with simple downsampling  our roughly    
accruacy on a     word dataset with a downsampling factor of
  and only    samples per word was very surprising  on our
datasets  however  we noted something a little bit simplistic
about them  which was that despite having so many unique
words  these words were always typed in the same order 
for instance in the night before christmas dataset  the
poem was typed    times  and always from start to finish 
hence a word like night is always preceeded by the and
succeeded by christmas  therefore if there were to be any
effect of neighboring words on the typing of the word night 
our dataset would not be capturing that at all  to explore
the question of neighbor effects on word typing  we typed

fifig     feature vector performance comparison across datasets

fig     effects of downsampling on the night before christmas dataset

the night before christmas poem backwards      christmas
before night the twas  and used it as a testing set against the
original forward typed dataset  treated as a training set  the
results are shown in figure   and reveal clearly that indeed the
hands type words differently depending on what word comes
before and what word comes after  still  though  in the best

case we measured with the averaging type feature vector  we
were able to achieve roughly     accuracy  giving us hope that
there is some significant amount of information still contained
in the feature vectors that is independent of neighboring words 
exploring this  too  is left for future study 

fifig     the neighboring words effect

vii 

f uture w ork

there are many avenues to explore for future work with
the learning keyboard  first  the neighboring words effect
needs to be investigated with the hope of developing feature
vectors that are able to extract out the neighbor independent
aspects of word typing  one idea with respect to this might be
to throw away a few video frames at the beginning and end
of the typing of a word  leaving only the motion of the hands
that occurred in the middle of the word  this may work well
for long words  but short words like a and i may require
other techniques 
secondly  the present implementation of the system does
not support the delete key  in the sense that if a word is
mistyped  partially deleted  and then finished correctly  the
system treats that as an unknown word and throws it out of
the collected data  to make the learning keyboard a useable
system for real data entry  a method for handling corrected
words would be required 
lastly  and also towards making the system practically
usable  a method for parsing out words from the depth map
stream without any a priorio knowledge of keypresses would
be required  presently the system parses out words from the
datastream  and hands these segments one word at a time to the
svm prediction system to guess which word was typed    but
in reality such a learning keyboard would need to first guess
where words are being typed in the video stream  perhaps by
detecting presses to the spacebar   and then guessing which
word was typed based on the spliced video 
beyond these  there are many exciting avenues of future
exploration including tuning various aspects of the system 
using pca instead of downsampling  making the system
independent of camera placement  and even seeing if it would
be possible for a machine to learn what a user is typing without
ever seeing keylog data  that is  use unsupervised learning
algorithms along with marchov models of typed words to
make accurate estimates of what the user is typing   for spy
applications it may not be critical to know precisely word for
word what the user typed  but rather to understand the general
meaning of their typed message 
viii 

c onclusion

with an xbox kinect  an open source image processing
library  and an off the shelf support vector machine we were

able to successfully make a first attempt at building the
learning keyboard and show some interesting first results 
including over     accuracy on a     unique word dataset
with    samples per word  though the simplification was made
that words were typed in the same order each time  we were
able to show with some initial findings that our chosen feature
vectors still maintained an information component that was
indepdent of neighboring words  and gives us hope that there
may be other feature vector generating schemes that better
minimize the neighboring words effect  we believe that with
larger datasets  better tuned feature vectors  and perhaps an
attempt at tuning the default svm parameters for libsvm 
we should be able to achieve even better results than these 
perhaps one day the learning keyboard or machine learning
techniques like the ones used here will indeed be able to make
the presence of a physical keyboard a mere memory of the past 
but a story told to grandchildren 
twas the night before christmas and all through the house 
not a keyboard was clacking  not even a mouse 
acknowledgments
we would like to thank chris lengerich for providing
useful advice for this project 
r eferences

    openkinect driver for mac  http   openkinect org wiki main page
    tkinter library http   wiki python org moin tkinter
    canny http   docs opencv org doc tutorials imgproc imgtrans canny detector canny de
    chang  chih chung and lin  chih jen  libsvm  a library for
support vector machines acm transactions on intelligent systems and technology                    software available at
http   www csie ntu edu tw  cjlin libsvm 

fi