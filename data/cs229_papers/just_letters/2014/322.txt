cs    project

final report

prediction of yelp review star rating
using sentiment analysis
chen li  stanford ee 

 

 

jin zhang  stanford cee 

introduction

yelp aims to help people find great local businesses  e g  restaurants  automated software is
currently used to recommend the most helpful and reliable reviews for the yelp community 
based on various measures of quality  reliability  and activity 
however  this is not tailored to each customer  our goal in this project is to apply machine
learning to predict a customers star rating of a restaurant based on his her reviews  as well
as other customers reviews ratings  to recommend other restaurants to the customer  as
shown in figure   

figure    user   business connections

the project has two tiers  first  using a customers review on a business to predict the
star rating given by the customer  second  using many customers reviews on a business and
on different to predict this customers likely ratings of different businesses 

 

data source

for our experiments  we used a deep dataset of yelp dataset challenge which is available online  http   www yelp com dataset challenge   which includes the data of        businesses 
        users and           reviews  these data provide useful information such as business
profile  review text  user profile  friends and votes  all the data are in json format  for
reviews  the data looks like
 
type  review 
 

fics    project

final report

business id   encrypted business id  
user id   encrypted user id  
stars   star rating  rounded to half stars  
text   review text  
date   date  formatted like             
votes    vote type    count   
 

 

features and preprocessing

at first  we need to train our model based on review texts and star rankings from the same
user  so  we selected a user who has written       reviews for experimental purposes  a file
containing all the reviews and ratings given by this user was generated 
then  review texts were cleaned  by removing format  punctuation and extra whitespace 
all characters from the dataset are lowercase  so there is no need to preprocess uppercase
letters  word stemming was achieved using porter stemming algorithm  which erased word
suffixes to retrieve the root or stem  stopwords  that is  words with no information value but
appear too common in a language  were also removed according to a list from nltk corpus 
for feature extraction  we need to count the frequency of every word that appears in the
users review pool  remove the ones with frequency lower than a certain bound  we chose
 e     so as to reduce the sparsity of our training matrix  and also the frequencies of the rest
      words compose our list of training features  the whole process is show in figure   

figure    data preprocess flow

 

fics    project

final report

finally  we extracted a sparse training matrix  where the i th row represents the i th review  and the j th column represents the j th token  the  i  j  entry of this matrix represents
the number of occurrences of the j th token in the i th review  the entire data preprocessing
is implemented in python 
for the second tier  we extracted and concatenated all the other users review texts for
every business this user has written a review for  the resulted       long reviews for these
businesses are considered as what this user might write down for these businesses before
visit  and the actual review this user has written as what this user actually write down after
visit  then  we used the users actual reviews to train the predicting model  while used the
concatenated reviews of other users to generate sparse testing matrix 

 

models

our first tier of work is a sentiment analysis and classification problem  there has been a
lot of existing work on similar topics of various scopes  some previous work focused on the
binary distinction of positive vs  negative     later work generalized to finer grained scales
such as numerical ratings       
first we categorize the star rating with positive and negative  greater smaller than  
stars   so the problem is a sentiment polarity analysis  we used logistic regression  lr  
naive bayes  nb  and support vector machine  svm   the previous two were implemented
in python  and svm is implemented in matlab leveraging the liblinear package 
then we generalized to   star rating scale classification using multinomial logistic regression  mnlr   naive bayes  nb  and support vector regression  svr      naive bayes
was still implemented in python  and svr was also implemented in matlab leveraging
the liblinear package 
for the second tier  we decided to choose the svr approach to train the predicting model 
since the results from the first tier show that svr approach performs the best 

 
   

results and discussion
rating prediction

for the first tier  we start with cross validation method  training set includes     samples 
which is about     of the data  and the test set has     remaining samples  the learning
results are shown in tables       
model
lr
nb
svm

training mse
      
      
      

test mse
      
      
      

table    polarity classification

 

iters
 
 
  

fics    project

final report
model
mnlr
nb
svr

training mse
      
      
      

test mse
      
      
      

iters
  
 
  

table      star classification

from the above two tables  we can conclude that nb doesnt predict very well for both
polarity and   star classification  which indicates that the assumption of nb method might
not be valid in this case 
both lr and mnlr has very low training error  but their test error is also very high 
this means that the regression tends to overfitting the data 
the svm and svr predict the best for polarity and   star classification respectively  so
we decided to use svm for our recommendation model
in conclusion  all the methods could give very good results on polarity analysis  however 
the   star classification error is still very large  so we decided to vary the training set size
and plot the learning curves  as shown in figure   

figure    learning curve for   star classification 

as we can see  test error and train error approach each other at first  but start to increase
or remain unchanged as the training set size gets larger than      this indicates a high bias
problem  and larger dataset will not help  a possible solution is to add more features 
in order to get more insight into the problem  we also carried out an ablative analysis 
we first run the model with no text pretreatment at all  and then add the next treatment
step in the following table  and repeat running and adding the next step until the last step
remove rare words  as shown in figure   

 

fics    project

final report

figure    ablative analysis for   star classification 

as we can see  removing features may lead to higher mean square error  which supported
our hypothesis that the resulted model has high bias and needs more features 

   

recommendation model

for the second tier  we used all the data samples for tier   to train the svr model  while
used concatenated reviews of other users to test the svr model  the training set includes
      samples  and the test set includes     samples  the results are shown in table   
model
training mse
remove features    star
      
remove stop word    star
      
remove stop word  polarity       

test mse iters
      
  
      
  
      
  

table      star recommendation model

the first row in the table corresponds to a   star prediction model with full text pretreatment  both training and test mse are really high  according to the ablative analysis  we
decided to try a   star prediction model with text pretreatment up to removing stop words 
the test mean square error          does become much more acceptable 
by using a polarity prediction model with text pretreatment up to removing stop words 
the results turn out to be highly accurate  indicating that the general recommendation approach  which predicts star rating using other users reviews  is acceptable  the reason why
  star prediction has much higher error is that its very difficult to distinguish between ratings
varying by only   star 
 

fics    project

 

final report

conclusions

we have implemented multiple layers of feature extractors and experimented with several
classification algorithms to predict star rating from review text  which gives a good result 
we carried out learning curve and ablative analysis  and experimented with difference feature
extractors  we have also predicted the customers star ratings for restaurants using all the
past reviews given by other customers and this customers predicting model 

 

future

there is also further work that can be done in experimenting with the recommendation
system  one option is to try more feature extraction approach such as bigram  trigram or
word chunks  this could effectively increase the information that can be obtained from one
review text  and add more features to overcome the high bias problem 
another option is to improve the recommendation mechanism  if we want to get the
rating of a user u on a business b  i e  x ub    we consider both business side rating  objective
rating  and user side rating  subjective rating  
x ub    y  ub    z  ub     ub 
where y  ub  is the business side rating   z  ub  is the user side rating and  ub  is gaussian noise 
assume both ratings as linear combinations of review text features  and get estimated
rating with training data of only review text and not the actual rating 
t

 ub 

y  ub    v  b   r ub      b
t

 ub 

z  ub    w u   r ub      u

where r ub  is the review text of user u on business b   r  is a feature extraction function 
and v  b  and w u  is weight vector for business side rating and user side rating respectively 
therefore 
x ub   r ub    v  b    w u   n   v  b    w u   t  r ub      
and the log likelihood is

l v  b    w u 
x

 
log p x ub   r ub    v  b    w u 
u b

 

x
u b

 
x ub    v  b    w u   t  r ub   
 
log 

   
 

hence  we can use gradient ascent to obtain the weight vectors of each business  v  b    and
each user  w u    with all the reviews 
in this way  it is likely that we could get a better prediction of an review  since the user
side part and business side part are evaluated separately  also  this could help with a better
recommendation system by considering more the user side part 
 

fics    project

final report

reference
    bo pang and lillian lee  a sentimental education  sentiment analysis using subjectivity summarization based on minimum cuts        proceedings of the acl 
    alexj smola andbernhardscho lkopf  a tutorial on support vector regression       
    bo pang and lillian lee  seeing stars  exploiting class relationships for sentiment
categorization with respect to rating scales        proceedings of the acl 
    daisuke okanohara and junichi tsujii  assigning polarity scores to reviews using
machine learning techniques        in ijcnlp 

 

fi