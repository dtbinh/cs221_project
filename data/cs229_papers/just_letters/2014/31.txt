detecting heart abnormality using ecg with
cart
paurakh rajbhandary

benjamin zhou

department of electrical engineering
paurakh stanford edu

department of mathematics
bzhou  stanford edu

gaspar garcia jr
department of computer science
gaspar   stanford edu

abstract
cardiovascular disease  cvd  is the leading cause
of global deaths  electrocardiogram  ecg or ekg 
is the most widely used first line clinical tool for
checking electrical activity in the heart  hence using
ecg
recordings
to
automatically
identify
arrhythmias accurately and efficiently can be an
important tool for cardiologists  we use the uc
irvine  uci  machine learning repository
containing an arrhythmia data set to implement a
multinomial classification for different types of heart
abnormalities  we show that a decision tree learning
algorithm  already widely used in many medical
diagnostics  is well suited for this application  we
achieved     classification accuracy with our
decision tree  which is relatively high compared to
other studies 
i  introduction

in the us alone  more than half a million people die
of heart disease  accounting for   in every   deaths 
about         americans have a heart attack  of which
        are a first heart attack  and         are
recurrent  coronary heart disease alone costs the us
       billion each year  the impact of heart disease on
lives and the cost of healthcare is a growing concern 
electrocardiogram  ecg  is one of the first line tests
cardiologists use to check for problems with electrical
activity of the cardiac muscles of patients  ecg is also
sometimes performed as part of a physical examination 
and is portable  making its use for pre diagnosis of heart
abnormalities favorable  hence  it is of great interest to
be able to accurately predict arrhythmia using patient
ecg data 

there has been much previous research on arrhythmia
classification  given the large dimensional size of
arrhythmia data features  one approach involved
transforming the features to a lower dimension using
principle component analysis  and then applying
support vector machines      another approach
involved analyzing the performance of a naive bayes
learning algorithm given varied learning times      the
motivation behind previous work has been centered on
developing a model that can perform non invasive risk
assessment of arrhythmia in a patient  using machine
learning principles  patient information can be analyzed
to determine the features most indicative of arrhythmia 
however  to our knowledge  there has not been any
published result in arrhythmia classification using cart
 classification and regression tree  analysis  our goal is
to accurately predict different types of arrhythmia in
patients  intuitively speaking  since doctors infer some
medical condition  children nodes  based on symptoms
 parent nodes   we decided to design a classifier based on
a tree structure  which graphically makes biological
sense  thus  we present an arrhythmia classifier based on
cart and decision tree analysis 
ii  methods

   data set
we used the uc irvine machine learning repository
    which has a data set containing arrhythmia
information for     patients  rows   each of these
patients has     features  columns   and was classified
into one of    categories     abnormal and   normal
heart conditions   our feature space comprised of    
dimensions  including patient information such as age 
sex  height  the pqrst wave signal  and channel
information 

fi   imputation
in the data set  there were many missing or na values 
when we observe the numbers of missing data for each
feature  we find the following 

feature    missing  we notice that the frequency for
each classification is less for  a  than  b   if we examine
more closely  we see that class    has positive frequency
after imputation  but zero frequency after removal of
patients  therefore  training on data after removal of the
    patients would give us less leverage in predicting
category     thus  we instead imputed the data for the
missing features using the r package rpart     
   cart model

table    frequency of na values in features         nd
row   percentage of patients with missing values for
each feature         rd row 

we saw that     patients        of all     patients  had
a missing value for feature     since this is a significant
proportion of the data  we chose to omit feature     since
it was mostly na values and offered no real training
benefit  for the remaining na values  which were in
features             and     we had to choose to either
 a  remove all patients      of them  with these missing
values  or  b  impute the missing data  since    
patients     of total patients  had missing values 
removing these patients could lead to significant
information degeneration 

a decision or classification tree represents a multistage decision process  where a decision is made at each
node  when it is at some node d in the building process 
it asks  which feature at d would give an optimal split to
the children of d  mathematically  the cart solves the
following optimization problem for each node as follows
      given a predetermined value xjr  called the scalar
splitting value for xj  the problem is to find a feature xj 
where xj exists in the feature space  that optimally
maximizes the separation of the data at node d  here  pl
refers to the fraction of points that will be partitioned to
the left child of d  and similarly pr is the fraction
partitioned to the right child  tp is the parent node  tl is
the left child and tr is the right child  i denotes the
impurity function used to calculate impurity at the given
node  we want to choose our features in the tree that
minimize the impurity at each node  the objective
function below maximizes the decrease in impurity from
the parent node and its children 

figure    optimization objective function for cart
    building the tree
table    histogram of classification frequencies

this histogram compares the frequencies of each
classification after removal of patients with na values
 a  and imputation  b   the majority of the patients were
classified as   or having normal heart conditions  there
were no classifications from        the blue columns
represent the frequencies of each classification with
imputed data  the red columns represent the frequencies
of each classification after removing     patients with
na values  the green columns represent the frequencies
of each classification after removing all patients with

when building the classification tree  decisions that
led to a compact tree with few nodes were preferred 
using the r package rpart      we built the decision tree
using an initial complexity parameter of         the
complexity parameter controls the size of the tree  and is
a way for the cart algorithm to know when to stop
partitioning into subset trees  this parameter allowed us
to prune the tree to prevent overfitting 

fi   evaluation metric
to evaluate our tree accuracy  we randomly split our
data set into training data and test data in three ways 
    training data and     test data      training data
and     test data       training data and      test
data  in each case  we trained our tree on the training
data and tested on the test data  we also performed   
fold cross validation 
   grid of evaluation
with the imputed data  and using r packages such as
e          we implemented support vector machine
with different kernels including linear  radial etc   and
naive bayes to compare and contrast accuracies obtained
by those metrics with our decision tree accuracies  we
also compared with the airs algorithm done by polat
     we also implemented feature selection on our
arrhythmia data to obtain a subset of important features 
and consequently created a decision tree  and ran svm 
naive bayes  etc  on those features  thus  in our grid of
evaluation  we compared the accuracies obtained from
each metric on imputed data  with the accuracies
obtained from each metric from feature selection 
iii  results

   cart

figure    decision tree from uci arrhythmia data
figure   is the decision tree for the arrhythmia data 
there are classifications      represented  and the tree is
about    levels deep  the root of the tree was feature   
or the heart rate in number of heart beats per minute 

graph    complexity parameter vs  error
the above graph shows the optimal complexity
parameter  the complexity parameter that minimized the
relative error of the tree was        
   accuracy measure

fitable   compares accuracies of all the different
metrics  in each box  we divide the box into a quadrant of
values  the top left cell of the quadrant refers to the
accuracy of splitting the data     training data and    
test data  the top right cell is     training data and    
test data  the bottom left cell is      training data and
     test data  the bottom right is the result of    fold
cross validation  we see that the cart algorithm has
     accuracy  which is relatively high compared to
other algorithms  comparing the accuracies of cart on
imputed data and feature selection  they are
approximately the same  while the accuracies for svm
on imputed data and feature selection are significantly
different  this suggests that the cart algorithm already
does well in finding the most important features in the
arrhythmia data  which is represented by the pruning of
the tree and the complexity parameter 
   confusion matrix
graph    importance measures of the arrhythmia
features
the above two graphs give two types of importance
measures of the features  the left graph shows how
worse the decision tree would perform without each
feature  i e  the measured decrease in overall accuracy of
the tree  hence  a high decrease in accuracy would be
expected for very predictive features  the right graph
measures the gini decrease  which is another way of
measuring the importance of features  we see that in both
graphs  feature    has the highest scores  this makes
sense  since feature    is the root of the decision tree 

table    confusion matrix of classifications by cart

table    overall accuracies from all metrics 

the additional information provided by the confusion
matrix indicates the weaknesses and strengths of our
model  for instance  we can infer with relatively high
confidence that a prediction indicating class    normal
heart conditions  is correct since we have       true
positive rate for normal heart conditions  however  we
can see that we only had a       true positive rate for
class    sinus tachycardy  the confusion matrix allows
us to understand which specific classification

fiinaccuracies are occurring so that we can fine tune our
model against such errors in the future  more
specifically we can observe our data with attention to
attributes that might sway the model towards the errors
made apparent by the confusion matrix  something we
could not do with the overall accuracy 

references
   

iv  conclusion

our cart analysis performed with      accuracy 
which did relatively well compared to other classifiers
such as svm or airs      from our cart graphical
model  we found that the root of the tree was feature    
or the heart rate in number of beats per minute  as the
root of the tree is suggested to be a determining feature of
the data  this makes sense because we would expect
normal or abnormal heart rates to be strongly correlated
with arrhythmia  looking at the top nodes of the tree  we
saw that these nodes were related to a multiple of
different features  but mainly features in the     range
i e  channel values 
v  discussion and future work

future work could involve further investigating top
features suggested by cart using pca  features
selection  etc  we could try fitting more models  and see
if those models also suggest that features in the     range
are important  we could use this new information to dig
deeper into the data to understand what relationship these
features have with other features  also  as the data set
had a lot of missing values  one could also work on
gathering more robust training data  or using another
method of imputation such as fuzzy k means clustering 
since we can expect training examples with the same
classification to have similar characteristics or features
      ideally  in the future  we want to validate or decide
which features are important for doctors to decide
between normal or abnormal heart conditions 
acknowledgment
we would like to thank dave deriso who advised this
work  we also want to acknowledge andrew ng 
without whom this wouldnt be possible 

   

   

   

   

   

   

   

   

polat  kemal  and salih gne   detection of ecg
arrhythmia using a differential expert system
approach based on principal component analysis and
least square support vector machine   applied
mathematics and computation                     
soman  thara  and patrick o  bobbie 
 classification of arrhythmia using machine learning
techniques   wseas transactions on computers    
                
therneau  terry m   beth atkinson  and brian
ripley   rpart  recursive partitioning   r package
version               
 the caret package   the caret package     aug 
      web     nov       
 package e       r software package  avaliable
at
http   cran rproject org web packages e     index html
polat  kemal  seral ahan  and salih gne   a new
method to medical diagnosis  artificial immune
recognition system  airs  with fuzzy weighted preprocessing
and
application
to
ecg
arrhythmia   expert systems with applications     
                
arrhythmia data set can be downloaded from
webpage
at
https   archive ics uci edu ml datasets arrhythmia
li  dan  et al   towards missing data imputation  a
study of fuzzy k means clustering method   rough
sets and current trends in computing  springer
berlin heidelberg       
robertson  b  l   c  j  price  and m  reale 
 nonsmooth optimization using classification and
regression trees   proceedings of the   th imacs
world congress and modsim   international
congress on modelling and simulation  cairns 
australia       

fi