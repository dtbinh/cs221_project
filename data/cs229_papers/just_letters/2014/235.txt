implementation of deep convolutional neural net on
a digital signal processor

elaina chai
december         

   abstract
in this paper i will discuss the feasibility of an implementation of an algorithm containing a
deep convolutional neural network for feature extraction  and softmax regression for feature
classification  for the purpose of real time lane detection on an embedded platform containing
a multi core digital signal processor  dsp   i will explore the merits of using fixed point and
floating point arithmetic in the implementation  and provide calculations estimating whether
the dsp is capable of real time operation  while initial calculations suggest that the dsp is
capable of real time operation using floating point and fixed point arithmetic    hz and   
hz respectively   problems were encountered using    bit fixed point in q format  resulting in
a failure of the algorithm to properly classify lanes  future work for this project include
exploring the challenges associated with the fixed point implementation  as well completing the
migration of the algorithm to multi core dsp using blas libraries 

   introduction
in recent years  deep convolutional neural networks  have gained large amounts of interest in
the machine learning community due to their high performance in object recognition
challenges such as mnist and imagenet        applications for deep cnn are constantly
growing  from object recognition  to speech recognition and more recently lane detection 
although there are many applications which can benefit from machine learning  or other
statistical learning algorithms   current machine learning implementations are typically run on
expensive high powered gpus  these implementations are infeasible for applications that
require relatively inexpensive hardware  or more importantly  are severely energy constrained 
dsps  where performance watt benchmarks are of particular interest  are well suited for any
application requiring large amounts of computation under strict energy constraints  however 
many of these energy gains are achieved by doing    bit fixed point calculations  as opposed to
single precision floating point typical of cpu and gpu architectures  while a move to    bit
fixed point would result in precision loss in the calculations  this may not be a problem in
machine learning applications  in the inference stage of machine learning algorithms  such as
softmax regression  final classification is usually done by comparing calculated probabilities  as
opposed to making decisions on based on absolute values  as a result  machine learning

 

fialgorithms  which already have some amount of tolerance to noise  also have some amount of
tolerance to precision loss  some questions that i will explore are the following 
 what levels of precision loss  due to truncation from the migration from floating point to
fixed point  with a limited word and fractional length  can be tolerated before noticeable
decreases in accuracy are observed 
 what is the theoretical frame rate that can be achieved using embedded hardware  using
floating or fixed point arithmetic 
to explore these questions  i implemented a lane detector algorithm using a deep
convolutional neural network for feature extraction  and a softmax regression algorithm for
feature classification using c    with end goal being a real time implementation on an
embedded digital signal processor  dsp  platform  i created fixed and floating point versions
to better understand effect of precision loss on the algorithm accuracy  i also performed initial
calculations to better understand the theoretical limits of the hardware platform 

   lane detector algorithm

local contrast normalization  lcn 
deep cnn

sliding window w  weights  
non linearity
pooling

sliding window w  weights  
non linearity
pooling

sliding window w  weights  

fully connected layer

softmax regression

 

fi   description of project development platform
the hardware used in this project is the   ak h evaluation model  evm  by texas
instruments  ti   the evm is a development platform containing a single   ak h keystone
multicore dsp arm system on chip  soc  by ti  the platform contains   gb ethernet
interfaces as well jtag emulation and rs     serial com interfaces to facilitate
communication to the on board soc  the soc contains   arm a   cores  and   c  x dsp
cores  with the following key features 
      gmacs dsp core for fixed point      ghz
      gflops for floating point      ghz
initial code development for this project is xcode     using c    code was initially tested on
an intel i  cpu  and cross compiled to run on the arm dsp core using the linaro linux
gcc     cross compiler  the final implementation will use blas libraries and compilers
provided in the ti mcsdk hpc development tools 

   theoretical limits of dsp hardware with respect to
algorithm
in this section i discuss the theoretical limits of the hardware platform  i explore whether the
evm has the capability to store and compute the lane detector algorithm in real time

  a  memory capacity requirements
to realize    hz  real time  operation  ideally  the on board  i e  evm memory must have the
capacity to hold the following 
 all coefficient parameter data    mb
 image data   mb image
 program data       mb
to maximize computation throughput  the evm must have the capacity to hold all the
coefficients  as well as at least   image   this means that we need
   m b    m b       m b     m b of memory on the evm 

   calculating computation time of a  d convolution
a calculation of the total amount of operations required by the algorithm shows that the
computation is entirely dominated by the sliding window convolutions  but at least two orders
of magnitude  each sliding window convolution requires         flops per image  vs     
flops for other parts of the algorithm  the c     dsp used in the hardware platform are
capable of   multiply accumulate  mac  operations per cycle for single precision floating
point  assuming a   ghz clock  this roughly corresponds to a  hz frame rate for a single
core  or a   hz frame rate using all   dsp cores 
despite a theoretical maximum of    macs cycle for a    bit fixed point implementation  the
frame rate for a    bit fixed point implementation may not be much higher than the floating
point frame rate  this is due to data movement restrictions  for efficient movement of data
through the memory  the data has to be properly aligned in memory  additionally  highly
optimized matrix matrix functions available for the dsp have restrictions on the dimensions of
the dot product computations  the result is that the frame rate for a fixed point
implementation may only be    hz if using all   dsp cores 

 

fi   current results and difficulties
the lane detector algorithm was implemented in c   in two forms  single precision floating
point and fixed point  the fixed point implementation uses a very coarse but flexible fixed
point implementation 
 all parameters are converted from single precision floating point to an q format fixed
point
 all computation carried out in q format
 final values converted back to floating point for comparisons against reference data
the final values of the softmax regression step were compared to a reference file generated by
the original cuda   caffe gpu implementation of the lane detector algorithm  additionally 
the single precision implementation was cross compiled and run on an a single arm a   core
as an initial test of the hardware platform setup  the final values of these implementation
were also compared to the reference output 

  a  summary of results
single precision floating point  c   cpu 
single precision floating point  c   arm 
   bit fixed point  matlab 
   bit fixed point  c   cpu   q format 
   bit fixed point  c   cpu   q format 

max difference
      e   
      
      
     
      

normalized mse
      e   
      e   
      e   
      
      

  b  fixed point
the current    bit fixed point implementation fails to classify the lanes  more work will need
to be done to pinpoint where the algorithm fails 

figure         bit fixed point output

figure         bit fixed point output

  c  precision errors between cross platform implementations
as an initial test of the ti embedded platform  the c   floating point implementation was
cross compiled and run on a single arm core  while there was a much higher difference
between the final values and the reference output  for the floating point implementations were
able to correctly classify the lanes in the input image 

 

fifigure      reference output

figure      arm floating point output

   future work
high speed multi core dsps have the theoretical capability for real time low power
implementation of a feed forward deep convolutional neural network at an order of magnitude
less power than a conventional cpu or gpu  there are current difficulties at this time with
the    bit fixed point implementation  additionally  initial calculations seems to suggest that
the fixed point implementation may not achieve a frame rate that much greater than the
floating point implementation for current filter window sizes  as a result  while i will work to
further to understand where the algorithm breaks down in the fixed point implementation  i
will also focus the migrating the the floating point implementation to the   dsp cores 
i will focus on achieving an implementation optimized for efficient data movement through the
memory  to achieve this  i will focus on a careful migration using blas libraries designed for
parallel computation across all   ti dsp cores  i am currently in talks with the high
performance computing  hpc  lab from ti on how to best do this 

   acknowledgements
this project could not have been done without the efforts of the following people  charles qi 
who provided the original matlab implementation i am basing this work on  boris murmann
and andrew ng for their support of this project  sameep tandon and tao wang for their
advice and for providing the image and parameter data for the algorithm  and fernando
mujica for his advice and support as well as for providing the hardware platform 

references
    alex krizhevsky  ilya sutskever  and geoffrey e hinton  imagenet classification with deep
convolutional neural networks  advances in neural information processing systems  pages
         

 

fi