 

seizure prediction from
intracranial eeg recordings
alex fu  spencer gibbs  and yuqi liu

f

 

i ntroduction

s

eizure forecasting systems hold promise
for improving the quality of life for patients with epilepsy  one proposed forecasting
method relies on continuous intracranial electroencephalography  ieeg  recording to look
for telltale feature sets in eeg data that suggest
imminent seizure threats  in order for eeg
based seizure forecasting systems to work
effectively  computational algorithms must reliably identify periods of increased probability
of seizure occurrence  if a reasonably wellperforming algorithm could be implemented
to identify those periods  then it is possible
to warn patients only before seizures  enabling
them to live a close to normal life 
recent research has shown that eeg signals
can be classified in four unique categories 
interictal  between seizures   preictal  immediately prior to seizure   ictal  during seizure 
and postictal  after seizure   in this project  we
applied machine learning algorithms to identify potential seizure occurrence using training
datasets collected from both dog and human
subjects  specifically  we aimed to differentiate
between data collected during preictal and interictal states  and thereby classify periods of
increased probability of seizure occurrence in
both dog and human subjects with naturally
occurring epilepsy 

ternational epilepsy electrophysiology portal
 www ieeg org  and hosted by kaggle com 
the competition provides ieeg datasets for
five dogs and two human subjects  each divided into preictal training examples  interictal
training examples  and test examples  each example contains data collected by    electrodes
over a span of    minutes  with a sampling
frequency of    hz  therefore  each example
has a    x         matrix with voltage recordings of the    electrodes  essentially  we have
    million predictor variables for each data
set  with     data sets available for just one
of the subjects  the total amount of available
data  when uncompressed  is      gb  with
such high dimensional data  our challenge is to
choose reasonable features to make as accurate
as possible predictions of periods with higher
seizure probability 

 

m ethods

w

first applied feature selection techniques and chose   summary statistics
as features  then applied logistic regression and
svm for sample classification 
based on the results of the initial learning
algorithms used  we decided to run aditional
algorithms on the most promising features  including dimension reduction using pca analysis and support vector machines on the preprocessed data 
e

    feature extraction
we start with visually analyzing the raw data
he data used in this project is provided to gain insights of the eeg signal characterisby the american epilepsy seizure predic  tics  a few initial features we looked at includtion contest  which is sponsored by the in  ing mean  variance  extreme values  period 

 

t

data overview

fi 

let the sequence x n  be a preprocessed
and fused input signal  then the instantaneous
energy is given by x n     considering that a
sliding window is used  the energy of the signal
becomes the average power over the window
mathematically defined as
e n   

 
n

nn
x

x i  

i  n  n   

where n is the size of the sliding window
expressed in number of points  range from  
to     n is the discrete time index  range from
  to        in our data samples 
fig     extreme value related feature  shows
   positive  i e  preictal   blue  and    negative
 red  training examples  the x axis denotes the
number of examples  for every example  we
compute the number of eeg values that fall
within the   th to   th percentile range of all
   electrodes  from the diagram we can see
the blue labeled positive training examples in
general have lower deviations of extreme values
from the mean 
and spectral energy distribution derived from
fourier transformations  for example  figure  
shows an extreme value related feature and
how value of that feature differs among positive and negative training examples 
based on these first observations and previous research in literature  we decided to
use a two step approach for feature extraction 
we first extracted first level features from the
raw data  then extracted second level features
from first level features  and finally trained the
model and based predictions using the secondlevel features 
     

first level features

     

second level features

to generate prediction indicators we extracted
   different second level features from the firstlevel features for each sample  these included
sample minimum  maximum  median  mean 
variance  standard deviation  skewness  kurtosis  slope  geometric mean  trapez  sum and
derivative  some of these features did not necessarily give good results initially  but we keep
them in the list for developing the objective
feature vector 
   

feature selection

we started with the filters and wrappers
method for feature selection  and finalized with
the minimum redundancy maximum relevance  mrmr  algorithm  ding and peng 
       the algorithm ranks a set of features
minimizing the redundancy among the subset
of features while maximizing the relevance of
the features  it first runs an f test as a relevance
measure  and then a computation of the pearsons correlation as a redundancy measure  after selecting the first feature  it iterates through
the rest of the features and ranks them based
on mrmr score 

we implemented several first level features  including curve length  energy  spectral entropy 
and energy of wavelet packets  the result is mrm rscore   max f  i  s       x  c i  j    
is
 s  js
that the signal energy best differentiates be   
tween positive and negative samples while
maintaining the information of the original raw
using this method  we select   features  norm
data  a detailed implementation is as follow  of variance  variance of variance  kurtosis  and
ing 
skewness 

fi 

   

pca variance analysis

because of the success with features based on
variance  we decided to do additional analysis on related features  specifically  we ran
a dimension reduction pca analysis on each
traning example available from one of the dog
subjects  dog    
for each of the     interictal and    preictal
   minute segments available  we first normalized the data and calculated its covariance
matrix to get its eigenvector basis  the data was
then projected onto each basis element  and the
variance across the vector was calculated  the
resulting feature vector contains the variance
along each of the    principle components 
next we ran various svm algorithms using
different kernels over differenct combinations
of the feature set  including comparing the
top two principle component variances  top
three  and all     the kernels used included the
standard linear kernel  and the gaussian  radial
basis function  kernel  the benefit of using the
rbf kernel is that it projects the data into an
infinite dimensional space without requiring
much additional computation cost  generally
it is easier to get better separation of data in
higher dimensions 
k x  z    e

kxzk 
   

r esults

t

he

table  
training and testing error rates of
second level features
model
log  reg 
lin  svm
rbf svm
rbf
svm ca 

false neg
 train 
     
     
     

false pos
 train 
     
     
     

false neg
 test 
     
     
     

false pos
 test 
     
     
     

    

     

    

     

    pca variance results
please see table   and the following figures for
pca results  the data is taken from dog subject
   using     interictal and    preictal samples
for training and     interictal and   preictal
samples for testing 
table  
training and testing error rates of pca
variance

   

because of the large quantity of negative
 interictal  data and relatively small amount of
preictal data  we added l  regularization and
weighted the preictal data regulatization terms
heavily compared to the interictal values  then
we adjusted the decision boundary so that the
error rate of predicting  rare  preictal events
was within ten percent of the error rate of
predicting  common  interictal events 
in order to test training error vs testing error 
we cross validated using a         training
data to test data ratio  leaving     interictal
and    preictal data sets for training  and    
interictal and   preictal data sets for testing 

 

parameters are then used to predict labels of
   additional samples for the same   dogs 
it appears that a rbf  gaussian  kernel svm
with cost adjustment towards avoiding false
negatives gives the best results 

model
lin  svm
kernel  d
rbf svm
kernel  d
  
rbf svm
kernel  d
     
rbf svm
kernel  d
      
rbf svm
kernel   d
  

 

false neg
 train 

false pos
 train 

false neg
 test 

false pos
 test 

     

     

    

     

     

     

    

     

     

     

    

     

     

     

    

     

     

    

    

     

d iscussion

results shown in table   are obtained one interesting observation is how good varifrom learning on     labeled training sam  ance is in differentiating preictal and intericples     positive  on   dog subjects  the learned tal samples  and contrary to our initial guess

fi 

fig     normalized variance on first two prin  fig     normalized variance on first two princiciple components
ple components  with gaussian kernel support
boundaries      

fig     normalized variance on first three principle components with gaussian kernel support boundaries        
fig     normalized variance on first two principle components  with linear kernel support      false negative and       false positive
after cost adjustment  but in practical use  those
boundaries
error rates are still way too high  this is partly
due to the limitation on computing power that ieeg recordings should fluctuate more given the massive size of each sample      milright before seizures strike  variance actually lion recordings   it takes a significant amount of
tends to actually attenuate  in the implemen  time to process more than    data samples at a
tation process  we also found that simpler fea  time  another limitation is our somewhat supertures  like nth moments of the data  actually ficial understanding of the ieeg data structure
served as better features than those obtained   with better understanding of the data  we
through more complex transformations like could probably develop features better reflectfourier transform 
ing the deep structure of the recordings  such as
the learning results are promising  with only ones on potential shape changes when entering

fi 

preictal states 
   

pca variance

the results of the pca variance analysis support the theory of reduced magnitudes of variance during preictal periods  figure   shows
the normalized variance along the first two
principle components  there does appear to
be some significant structure to the data but
too much mixing to provide good preditability 
noticibly most of the preictal data is in a
small low magnitude clump  confirming the
previous results of comparitively low variance
in preictal data  figure   shows the same data
with a linear svm applied  figure   shows the
same data with a gaussian  rbf  kernel on a
reduced data set      interictal     preictal   by
applying the gaussian kernel we see that the
support boundaries can flow around the data
more easily  however this may make it more
suseptable to overfitting 
figure    shows the data comparing the first
three principle component variances on    
interictal and    preictal data sets  figure  
shows the same results with a gaussian kernel
applied  again as in the  d case the separation
is not very good  but also not without information 
table   shows the results of training and
testing error rates  clearly the rates are far too
high for practical use since high positive error
rates would mean a patient would simply ignore warnings after a while  and high negative
error rates mean we are missing dangerous
seizure events  it is interesting to note that the
covariance does show some degree of structure
suggesting the electrode signals are not independent 

 

c onclusion

w

e have shown a statistically significant
corollation between ieeg signal variance and whether the subject is in an interictal
or preictal state  as a seizure approches it
seems that ieeg signals begin to die down
slightly into a muted state  before erupting
during the seizure  we found that variance 
variance of variance  skewedness and kertosis

were the best features based on a mrmr selection algithm  and using a gaussian kernel
with a support vector machine generated the
best prediction error rates  further analysis of
variance with pca and gaussian kernel svms
confirmed the reduced preictal variance result
and showed some structure in the signal covariance but did not generate any significantly
better prediction error rates 

 

f uture w ork

i

n addition to trying a wider range of features  some other directions include additional dimensionality reduction to select only
relevant electrodes  and analysis of the    min
preitcal states as an integral period  another
interesting direction would be to preprocess
the data after running ica analysis on each
sample set  suppose there were some dominant source generators in the brain such as
some lobes or neural bundles whose activation
might signal seizure imminence  additionally
suppose electrical signals add linearly so that
the signal received by each electrode is a linear
mapping from the signal generating neurons 
then in running ica we could extract the
source signal itself which then might be processed further with fourier analysis or other
techniques to look for something source signal
specific  another area we started to explore but
did not get results yet from is analyzing the
spectral composition of the signals  we would
like to look at the fourier transform of the
data and see how energy is distributed across
the power spectral density in interictal versus
preictal signals 

r eferences
    american epilepsy society seizure prediction challenge   online   available  http   www kaggle com 
    bruno direito et al   feature selection in high dimensional eeg
features spaces for epileptic seizure prediction  presented at the
  th ifac world congress  milano  italy       
    maryann dalessandro et al  epileptic seizure prediction
using hybrid feature selection over multiple intracranial
eeg electrode contacts  a report of four patients  in ieee
transactions on biomedical engineering  vol      no    
      pp          
    hanchuan peng  fuhui long  and chris ding  feature selection based on mutual information  criteria of max dependency 
max relevance  and min redundancy  in ieee transactions on
pattern analysis and machine intelligence  vol      no    
pp                 

fi