classifying forest cover type using cartographic
features
kevin crain  craink cs stanford edu

graham davis  gbdavis stanford edu

stanford university   cs      machine learning   december     

 

introduction

given elevation  hydrologic  soil  and sunlight data can we predict what type of tree would be in a small
patch of forest  our project attempts to predict the predominant type of tree in sections of wooded area 
understanding forest composition is a valuable aspect of managing the health and vitality of our wilderness
areas  classifying cover type can help further research regarding forest fire susceptibility  the spread of the
mountain pine beetle infestion     and de reforestation concerns  forest cover type data is often collected
by hand or computed using remote sensing techniques  e g  satellite imagery  such processes are both time
and resource intensive      in this report  we aim to predict forest cover type using cartographic data and a
variety of classification algorithms 

   

data and features

the data used in this report was taken from the uci machine learning repository      the data set
consisted of        samples of   m x   m patches of forest located in northern colorados roosevelt national
forest  certain attributes lend themselves well to human interpretation  for example  the correlation
between aspect  compass direction of slope face  and sunlight intensity makes intuitive sense  seeing as some
trees may thrive with heavy morning sun  each data sample includes    attributes  elevation  in meters  
slope  aspect  compass direction of slope face   vertical distance from water  horizontal distance from water 
sunlight intensity at  am    pm  and  pm    binary wilderness area designators  and    binary soil type
designators  in some tests  the    binary attributes were ommitted  each sample was classified into one of
seven forest cover types  spruce fir  lodgepole pine  ponderosa pine  cottonwood willow  aspen  douglas
fir  or krummholz  there are       samples classified as each of the seven cover types 

 

models   methods

to take measures against overfitting our models we employed    fold cross validation  our entire data
set of        samples was split into    evenly sized groups k         k     for each group ki   we would train our
models by conglomerating the other   groups before testing on ki   we then average the percent error on
each testing set ki to determine the perecent error for the model 
additionally  for some of our testing we removed the    binary features  labeled boolean on some
figures  in an effort to see if shrinking our feature spaces dimensionality would reduce overfitting and
increase testing performance  moreover  we knew that the models would run more quickly with only   
features 

   

principle component analysis

principle component analysis  pca  is a method of reducing the dimensionality of data while  usually 
maintaining most of the datas variance  all dimensions of the reduced data are linearly uncorrelated 
meaning the original data is projected into a space where each component is orthogonal to the others 
before computing the principal components  we zeroed out the mean of the data and set each coordinate of
 

fithe data to have unit varaince so as to treat each attribute evenly  computing the first principal component
of the data can be formulated as 
pm  i   i t
 
 u
argmax ut   m
i   x x
kuk  

pm
 
 i 
equivalently  this is the top eigenvector of the covariance matrix    of the data     m

i    x
 i 
t
  x      where  is the mean   now  reducing the data to k dimensions requires finding the top k
eigenvectors of   denoted u         uk    transforming a data sample into the k dimensional space now can be
done by easily  set the j th element of the k dimensional tranformed sample to be utj x i   
we used pca to visualize our data in
three dimensions  see fig 
   
clearly  the
data is stratified and looks reasonably seperable 
additionally  we decided to run our
multi class svm on the pca transformed data
in various dimensions 
reducing the dimensionality of our data enabled our multi class
svm to run more quickly 
however  since
variance is lost in reducing the data  we expected our results to suffer  see fig    in results  
figure    three dimensional representation of      
samples via pca

   

multi class support vector machine

the multi class support vector machine implemented in this report was imported from the sklearn
library  this svm uses the one vs  one approach to multi class classification  with   cover types to
classify  our svm implements and trains                   seperate binary classifiers  each binary
classifier is trained using strictly examples of two cover types  meaning it always predicts one of two cover
types  during testing  a test sample t is applied to each of the    classifiers  each binary classifier votes
for the cover type it predicts  test sample t receives the label c  where c is the cover type receiving the
highest number of votes 
the binary classifiers within our mutli class svm run as normal svm classifiers  solving the    regularization dual problem provides an optimal value for   which is used in the following equation  where the
classifier predicts y     if 
m
x

i y  i  hx i    xi   b     

i  

our multi class svm made use of the following gaussian or radial basis function  rbf  kernel 
exp kx i   xk   
to improve the accuracy of the multi class svm with respect to our data set  we sought to optimize two
hyperparameters of our model  c  the penalty parameter present in the    regularization dual problem  and
  our rbf kernel coefficient   to do so  we used both grid search over the hyperparameters and    fold
cross validation  using    fold cross validation and multiple iterations  we settled on c         and   
     as the optimized values of our svms hyperparameters 

   

k means clustering

as demonstrated in fig     the data obviously groups into cohesive clusters  so  we also decided to run
an unsupervised clustering algorithm on the data  since k means is unsupervised  it runs without observing
the labels of the data  upon convergence of the algorithm we observed each of the k clusters  labeling the
cluster based on the most common cover type among the samples assigned to it  to increase the accuracy of

 

fiour approach  for each value of k we run the algorithm    times  in each run we keep track of the cumulative
sum of geometric distance from each sample to its respective cluster  i e  inertia   finally  we choose the
cluster centers from the run which minimized this cumulative distance over the training dataset 

 
   

results   discussion
principal component analysis

we knew reducing the dimensionality of the data
would reduce the run time of our multi class svm 
however  the loss of variance would simultaenesouly
decrease performance  indeed  fig    confirms
our expectations and graphically demonstrates the
amount of variance captured by each principal component  see table     when only using the first
principal component the svm performs better than
our naive baseline  which always guesses the most
common label from the training set  within the
first three principal components        of the datas
variance is captured  the graphs curve shows the
diminising returns of running the svm with more
principal components  as expected  running the figure    training and generalization error of our
svm with    dimensional pca transformed data svm run on variable dimensions of pca data
 capturing         of the variance  performed only minimally worse than using the entire data set with all
   dimensions  also  the training error and generalization error were nearly identical for all runs 
 
 
 
 
 
 
 
 
 
  
                                                           
table    maintained percent variance for each of the ten principle components

   

multi class svm

as shown in fig     we ran diagnostics for the
multi class svm on both the data with boolean information and without  the blue and red curves
 with booleans  clearly demonstrate that as the
number of training samples increases we see convergence between the training error and generalization
error  both the shapes and the relatively small gap
between the curves indicate that high variance is
not an issue  similar findings occured when not using the booleans  in fact the difference between the
purple and orange curves is always smaller than that
between the blue and red  therefore  we conclude
that not using the booleans indeed lowers variance
and reduces overfitting  comparatively 
for each sample exactly two of the    figure    training and generalization error of our
soil wilderness indicators are turned on  earlier  we svm run with variable amounts of training data
hypothesized that the small amount of information
contained in the    booleans could possibly hurt our model since    dimensions would be more prone to
overfitting than     the results show that while reducing overfitting  the removal of the booleans also decreases performance on both testing and training  essentially  the    boolean indicators provide valuable
information at the cost of increasing the dimensionality of the data by more than a factor of   

 

fiwhen performing    fold cross validation on the entire data set with hyperparameters c          and
        the generlization error was         meaning our accuracy was         when training this model
on a random       split of the entire data set we obtained        training accuracy and        testing
accuracy  when removing the boolean features these accuracies dropped to        and         respectively 

   

k means cluster

initially  we ran k means with k     clusters
for each of the   covertypes  the results were poor 
so we increased the number of clusters to allow for
noise  that is  we knew from pcas   d visualization that samples often drifted away from their
cover types average  we hypothesized that adding
clusters would allow for each covertype to have multiple clusters  essentially making allowance for the
drifting  as seen in fig     additional clusters
provided benefit up to a point  the curve indicates
the diminishing returns of continuing this strategy 
which also greatly increased the algorithms runtime 

 

figure    test error of k means clustering when run
with varying numbers of clusters

conclusions

our multi class svm classifier and k means clustering algorithms performed quite well on both training
and test data  in particular  our svm classifier outperformed models used in studies involving a similar data
set  for instance  one      study by blackard and dean     reported        accuracy when classifying forest
cover type using an artificial neural network  furthermore  the same study reported        classification
accuracy using discriminant analysis  these results demonstrate that an optimized  one vs  one multiclass svm is a very accurate model with regards to forest type classification  similarly  our svm performed
similarly well on both training and test data  fig      thus  we were pleased to see that our model was not
struggling with overfitting and was demonstrating lower than anticipated generalization error        

 

future work

our main goal for future research is to approach our data set with other classification algorithms  first 
we want to implement a one vs  all multi class svm  because it seems to remain a relatively open question
in machine learning research      we hope to gain insights into the relative performance of one vs  one and
one vs  all svm algorithms  similarly  we would like to implement multinomial logistic regression and a
neural network  similar to those implemented in blackard            

references
    d a 
leatherman 
colorado
state
forest
service
entomologist
http   www ext colostate edu pubs insect       html revised      

 retired  

     

    blackard  jock a   dean  denis j  comparative accuracies of artifical neural networks and discriminant
analysis in predicting foorest cover types from cartogrpahic variables  computers and electronics in
agriculture        
    bache  k  lichman  m  uci machine learning repository  irvine  ca  university of california  school
of information and computer science        
    milgram  jonathan  et al  one against one or one against all  which one is better for handwriting
recognition with svms hal       
 

fi