cs     machine learning  fall     

mood detection with tweets
wen zhang    geng zhao  and chenye  charlie  zhu 
  stanford

university  zhangwen stanford edu
university  gengz stanford edu
  stanford university  chenye stanford edu
  stanford

december         
abstract
in our project  we applied naive bayes and svm models to classify an arbitrary tweet message into positive and negative
mood category  a properly optimized svm model with linear kernel yields satisfactory results  though the learning curve
suggested that it suffered from substantial overfitting  additionally  we have shown that all features are important for
classification and thus shall be neglected in the problem 

i 

introduction

twitter is an immensely popular social network with more than two hundred million users worldwide with
hundreds of millions of tweets posted every day  a great fraction of them are highly personal  and are expressive
of the users emotions  in this project  we use machine learning algorithms to predict the mood of a tweet 
happy or sad  the ability of mood detection has numerous real life applications  for example  advertisers may
personalize ads based on the sentiment of a user towards certain products 

ii 

dataset

the training and test data used in this project were obtained from sentiment       containing         tweets  evenly
divied between positive and negative sentiments  the tweets were scraped from the twitter website  and were
properly labelled according to the emoticons contained  tweets that include emoticons such as    were perceived
as positive examples  whereas those with symbols like    were interpreted as negative examples  ambiguous ones
were removed from the dataset  furthermore  the emoticons  strong indicators themselves  were stripped off after
the labelling  as not doing so would introduce a strong bias into the model     
for the purpose of this project  we randomly selected         tweets from the database      of the which
        tweets  were used for training and cross validation for paremeters  while the remaining            
tweets  were reserved for testing 

iii 

features and preprocessing

a natural way to approach text classification problems is to use tokens as features  during preprocessing  we
removed certain irrelevant tokens  urls  mentions   username  and retweets  rt  username   then we counted
the total number of occurrences for each token in the training examples  we obtained a total number of       
tokens for single words 
to take into account phrases and expressions such as not bad  we also added in two grams and three grams
 i e  two three adjacent tokens in the text  as features  this enabled us to extract more information from the text 
and also helped mitigate underfitting by increasing feature dimension  the total count of tokens is         for
  grams  and           for   grams 
we then transformed the count matrix into a normalized tf  term frequency  or tf idf  term frequency times
inverse document frequency  representation to account for varying contribution for classification of each token 
the tf of a token t in a document d  i e  a tweet  is the total occurrences of t in d 
tf t  d   

   t     t   

 

t d
  http   www sentiment    com 

 

fics     machine learning  fall     

the idf of a token t in a collection of documents d is inversely related with the number of documents in which
token t appears 
n
idf t  d     log
 
  d  d   t  d  
for a token that appears in most tweets  such as  the   it is less likely to contribute much to the classification  and
it will also have a low idf value  therefore  idf measures how informative the token is in the whole collection of
documents  tf idf is product of tf and idf 
tfidf t  d  d     tf t  d   idf t  d   
tf idf values weigh the occurrences of a token by how meaningful it is in the classification 
thus  for a tweet d in the collection of tweets d  its corresponding training example would be
x  d     tfidf t    d  d  

tfidf t    d  d  

        

where t    t          are the tokens  we may replace tfidf t  d  d   with tf t  d  if we decide not to use idf 

iv 
i 

learning models

naive bayes

first  we used a naive bayes classifier from the scikit learn package     as a baseline  simple and fast to train  this
model tends to yield acceptable results for text classification problems  it classifies a new input x with features
  xe            xen   into class y   where
n

y   arg max p y   p  xei  y  
c

ii 

i   

support vector machine

we futher experimented with soft margin support vector machines  svm  with linear kernels  using the implementation from scikit learn      the svm algorithm finds a separating hyperplane with maximal margin 
min
 w b

m
 
  w      c   i
 
i   

s t  y i   w t x  i    b       i
 i     i              m 
svms are a desirable model for text classification as the built in regularization mechanism mitigates the
potential overfitting  a prevelant phenomenon in text classification problems with very high dimentional input
feature space      furthermore  data points in these problems are typically linearly separable      and hence
training an svm with a linear kernel is remarkably fast using the smo algorithm 

v 
i 

experimental results and analysis

parameter selection

there are multiple decisions involved in parameter settings  for instance the choice whether to use plain tf or tf idf 
and what value is appropriate for c for the objective function in the svm model  we used cross validation to
determine the values of parameters  hold back     of the traning data into a cross validation set  train the learning
models using different parameters on the remaining      and choose the value that yields lowest cross validation
error 
 

fics     machine learning  fall     

tf idf
tf

naive bayes
      
      

svm
      
      

figure    cross validation errors when we use   do not use idf in
feature selection with    and   grams

figure    cross validation errors on different choices of parameter c
in an svm

the figures above represent two sample cross validation processes we run to attain the suitable parameters  for
instance  the graph on the left reports cross validation errors of svms with unigram features  and regularization
parameter c ranging from     to       we see that setting c          yields the most satisfactory result 
the table on the right shows cross validation errors when we choose to use tf or tf idf with   gram features the
svm model gives slightly better predictions when tf idf is used  while the performance of naive bayes model is
essentially unresponsive to the change 

ii 

error rates

after various experiments and trials with different combinations of learning models  parameter values and feature
selections  here we report the best results 

features
  grams
   and   grams
        and   grams

naive bayes with tf features
training error
test error
      
      
      
      
      
      

svm with tf idf features
training error test error
      
      
       
      
      
      

table    training errors of naive bayes and svm with different feature dimensions

from the data we obtained  a linear svm with   gram features yields the best testing accuracy          
furthermore  when we trained our best model on a larger data set with         training examples  the largest we
experimented with  it reported an even higher accuracy of        
additionally  svm models perform slightly better than their naive bayes counterparts  and increasing feature
size  while adjusting parameters accordingly  helps reduce error rates 

iii 

algorithm performance

we have plotted learning curves for all six models  here we present two examples 
 

fics     machine learning  fall     

figure    learning curve for naive bayes    grams 

figure    learning curve for svm    grams 

figure   on the left represents the learning curve for the naive bayes model with    and   gram tf features 
there is no clear indication whether overfitting or underfitting results in the generalization error   
figure   on the right shows the learning curve for the svm model with         and   gram tf idf features 
clearly the learning algorithm suffers from substantial overfitting  with notable discrepancy between training
errors and test errors  we further noticed that the training errors had not stablized yet  suggesting that adding
more training examples might raise the training error 

vi 

diagnostics

to alleviate overfitting problems in the svm model  we attempted to reduce the feature dimensions by selecting
the most relevant features  specifically  the relevance of a token mainly depends on 
 frequency in training set  tokens that appear more frequently in the training set are more likely to appear in
new tweets  and thus are more relevant for the classification problem 
 ratio of frequencies in the two categories  tokens that appear frequently in tweets of one category but rarely
in those of the other are more indicative of the class the tweet belongs to 
we formalized our reasoning by building the following heuristic and determining the relevance of each token 
h  x    

max  a x   bx      
a x   bx
 
 
min  a x   bx      
y   ay   by  

where a x and bx denote the frequency of token x in the positive and negative category respectively  the parameter
 represents the weights of two factors 
we selected the k features with the highest heuristic scores for different values of k and adjusted the values of
 accordingly  we then trained the model on the selected features 
to prove that our heuristic is reasonable  we set           and compared the behavior of an svm trained on
k features selected according to the heuristic and k random features from    and   gram tokens  the reported
cross validation errors are as follows 
k         
k          
k          

heuristically selected features
      
      
      

random features
      
      
      

figure    comparison of errors obtained by choosing k features according to the heuristic vs  randomly
  for

computational reasons  we reduce the feature dimention to         based on their occurances in all training examples 

 

fics     machine learning  fall     

choosing features according to the heuristic yields much better results than choosing randomly  this verifies
that our heuristic is valid 
below is a table of testing errors of an svm on the selected features from    and   gram tokens  out of       
features in total  

     
      
       

     
      
      
      

      
      
      
      

      
      
      
      

       
      
      
      

figure    test errors obtained by adjusting the values of k  columns  and   rows 

firstly  notice that the greater the value of  is  the better results we obtain  when  dominates  h  x   is
approximately equal to term frequency divided by the length of the corpus  thus  the ratio between the number
of occurences of each token in the two classes is not particularly indicative of the relevance of each token 
more importantly  we found that reducing the number of features only increases test error  and that the
more features we kept  the lower test error we got  this implies that most tokens are informative in this text
classification problem  and selecting features may lead to a loss of information  validating the findings by joachims
    

vii 

conclusion and future work

we applied naive bayes and svm models to classify tweets into positive and negative sentiment category  after
setting the proper parameters for each model through cross validation  we found that the svm model with linear
kernel yielded the best test result  and yet suffered from significant overfitting  in our attemp to reduce feature
dimension and select most  relavent  tokens  we found that most features are important for the classification and
should not be omitted 
in the future  we will consider more sophisticated feature representations and dataset preprocess to improve
the performance of our method  moreover  resorting to more advanced learning algorithms  such as neural
networks for automatic feature extraction  and npl models  such as lda  for better approaches to solve the
problem 

references
   

go  a   bhayani  r     huang l          twitter sentiment classification using distant supervision  retrieved december          from http   cs stanford edu people alecmgo papers twitterdistantsupervision   
pdf

   

joachims  t          text categorization with support vector machines  learning with many relevant features 
european conference on machine learning  ecml       

   

manning  c  d   raghavan  p     schijtze  h          support vector machines and machine learning on
documents introduction to information retrieval   pp            cambridge university press 

   

scikit learn developers  working with text data  retrieved december          from http   scikit learn 
org stable tutorial text analytics working with text data html

 

fi