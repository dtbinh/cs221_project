machine learning methods for biological data curation
kelley paskov  kpaskov stanford edu 
background
biological publications are being produced more rapidly than any human could
possibly read them  so modern biologists rely heavily on the manually curated data in
biological databases  this data is collected by expert biocurators who read literature
focused on a particular organism  disease  or process and extract key information in a
structured format using ontologies and controlled vocabularies  we would like to
automate parts of this process and focus on two prediction tasks 
      triage  task   based  on  its  abstract   can  we  determine  if  a  new  paper  contains    
relevant  information   this  is  a  binary  classification  task  where  a  label  of     
indicates  that  a  paper  contains  relevant  information  and  a  label  of      indicates  
that  a  paper  does  not  contain  relevant  information   
      multi label  classification  task   assuming  a  paper  has  relevant  content   
based  on  its  fulltext   can  we  determine  which  biological  category   or  categories   
can  be  associated  with  it   since  each  paper  can  be  associated  with  multiple  
biological  categories   this  is  not  a  multi class  classification  task   but  rather  a  
multi label  classification  task   given  k  categories   for  each  paper  we  would  like  
to  predict  a  binary  vector  of  length  k  indicating  which  biological  categories  the  
paper  is  associated  with   
some promising work has been done on automated paper triage and gene detection
within text  particularly related to the biocreative and bionlp competitions aimed at
evaluating the state of the art in biomedical text mining  but tools produced from these
competitions often have too narrow a focus or are unable to handle datasets on the scale
of well established model organism databases 
data
we have collected the full text of        articles curated by the saccharomyces
genome database  sgd  over the past    years  and the multi category label for each
article along   biological categories  ie we have a multi label classification task with k  
categories   we have also collected the abstracts from         articles  including the
       above and an additional        articles that do not contain annotatable
information 
millions  of  words  

   
   
   

dictionary  size  
abstract  
fulltext  

   
   

features
we chose to represent each paper as a bag of ngrams  capturing the number of occurrences of each ngram in the text of the paper  this representation is
effective and is easy to compute over the large amounts of
text in our two datasets   currently over   gigabytes  for
our abstract corpus  we experimented with unigram 
bigram and trigram  representations  for our fulltext
corpus  we used only the unigram representation due to

figure      feature  set  size   

                                                                                                                

   the  bigram  feature  set  contains  both  unigrams  and  bigrams   while  the  trigram  feature  set  contains  

fi  improvement in
validation accuracy

   

effect of preprocessing on
prediction accuracy
aliased and stemmed
stemmed

   

aliased

   
 

nave
bayes

    

svm

logistic
regression

computational constraints  figure   shows
the distribution of dictionary sizes for each
of our feature sets 
we experimented with two data
preprocessing steps  stemming and alias
replacement  we used the porter   stemming
algorithm to stem all of the words in the
corpus  we also wrote code to replace any
biological terms or aliases with standardized
names  including gene names and gene

ontology   yeast phenotype ontology   and
chebi  chemical terms  to determine
whether these preprocessing steps increase
the accuracy of our learning algorithms  we compared performance on three baseline
unigram models to  performance  with  no  preprocessing  see figure    and found that
both aliasing and stemming words has a positive effect on performance 
figure      effect  of  preprocessing  on  validation  set  
accuracy  relative  to  no  preprocessing     

models
we started by training four types of classifiers  on the triage task  logistic
regression  svm  nave bayes  and knn   logistic  regression  and  svm  outperform  the  
other  two  models   and  in  fact  perform  nearly  identically   we  chose  to  continue  our  
analysis  of  the  multi label  classification  task  with  logistic  regression  because  logistic  
regression  models  the  probability  that  a  datapoint  has  a  label  of      this  can  be  used  
as  a  confidence  score   allowing  us  determine  how  confident  we  are  in  a  given  
prediction   because  an  svm  only  takes  into  account  the  support  vectors   a  small  
subset  of  the  training  data   it  is  difficult  to  generate  a  meaningful  confidence  score  
for  points  that  arent  support  vectors     furthermore   the  logistic  regression  model  
allows  us  to  easily  tune  the  false  positive false  negative  tradeoff   an  important  
factor  for  this  task 
for our triage task  its extremely important for our classifier to generate very few
false negatives  false negatives correspond to missed information  which we would like
to avoid  in order to drive the number of false negatives down  we made a modification to
the logistic regression model  according to the logistic regression model  the probability  
that       has  label          is  modelled  as
 
                        
  
    exp        
all  features  are  normalized  by  their      norm   i e   we  scale  each  feature  so  that  
 
   

   

 

     for              we  did  not  normalize  individual  documents  because  

                                                                                                                
   https   pypi python org pypi stemming      
   http   geneontology org   
   http   www yeastgenome org ontology phenotype ypo overview  
   http   www ebi ac uk chebi  
   scikit learn   machine  learning  in  python   pedregosa  et  al    jmlr       pp                      

  

fithey  are  all  abstracts  and  have  approximately  the  same  length   we  used      
regularization   so  the  classical     regularized  logistic  regression  negative  log 
likelihood  is  
 

      



 

log           

 

log        

 

   



 

 
    

however   we  are  interested  in  a  slightly  different  problem  where  we  minimize  the  
error  on  negative  examples                    subject  to  the  error  on  
positive  examples                    being  below  an  acceptable  threshold   
this  is  given  by  the  problem  
  

min    



   

  
  
subject to  

log        
 



 



 

 
    

log         
 

it  can  be  shown   through  the  lagrangian   that   for  an  appropriately  chosen        
the  above  is  equivalent  to  minimizing  


log      
 

log        
 

 



 

 
    

therefore  we experimented with weighting our positive and negative classes in order to
tune the number of false negatives on our validation set 
triage task
for the triage task  we separated our corpus of abstracts into training  validation 
and testing sets  we used the validation set to select a model and tune parameters and the
testing set to report on the predicted performance of our optimal classifier 
we experimented with four different classifiers  nave bayes  knn  logistic
regression  and svm  our results are given in table    both logistic regression and svm
produced extremely similar models  this likely occurred because they both produce a
linear decision boundary that takes into account each training example according to how
well it is classified and can handle many correlated features because of   regularization 
both knn and nave bayes seemed to suffer from spurious and correlated features  this
trend is most clear for knn  as more features were added with the bigram and trigram
datasets  performance steeply dropped off 
table    triage task results
         training samples         validation samples         testing samples  
training validation validation validation
model
corpus
features
baseline
accuracy accuracy sensitivity specificity
nb
abstract
unigrams
   
      
      
    
    
nb
abstract
bigrams
   
      
      
    
    
nb
abstract
trigrams
   
      
      
    
    
knn
abstract
unigrams
   
      
knn
abstract
bigrams
   
      
knn
abstract
trigrams
   
      
svm
abstract
unigrams
   
      
      
    
    
svm
abstract
bigrams
   
      
      
    
    
svm
abstract
trigrams
   
      
      
    
    
logreg
abstract
unigrams
   
      
      
    
    

filogreg
abstract
bigrams
   
      
      
    
    
logreg
abstract
trigrams
   
      
      
    
    
  baseline shows the accuracy of classifying each sample to belong to the most common training class 

since curators must read all positively triaged papers  any false positives can
easily be corrected during the annotation process  this means we are primarily interested
in our classifiers negative predictions  false negatives correspond to papers whose
information is missed  which we want to avoid  furthermore  since curators no longer
need to read papers that are triaged as negative  the rate of negative predictions measures
the time savings of our classifier  by changing the class weight parameter  given in the
equations above  we were able to tune the number of false negative samples on our
validation set  table   shows validation statistics using trigram features on the abstract
corpus for the triage task  although validation accuracy may decrease  tuning alpha
allows us to decrease the expected number of false negative predictions  which results in
a better classifier for the task 
alpha
 
   
     

validation
accuracy
      
      
      

tp
    
    
    

table    alpha tuning results
false negative 
fn
fp
tn
predicted negative
             
     
             
     
             
    

predicted negative 
all
      
      
      

based on these results  we chose a logistic regression classifier using trigrams and an
alpha parameter of     as our optimal classifier  table   shows the predicted performance
of this classifier based on the testing set 
testing
accuracy
     

tp
    

table    testing results on triage task
false negative 
fn
fp
tn
predicted negative
             
     

predicted negative 
all
     

multi label classification task
we split the fulltext corpus in a similar manner as the abstract corpus  creating
training  validation  and testing sets  we chose to approach the multi label classification
problem by training   classifiers  one for each biological category  results are shown in
table    overall  this task seemed to be much more difficult than the triage task  this
may have been due to the fact that our dataset had relatively few positive examples for
each label  performance for one of the five categories was fairly poor  with our logistic
regression classifier performing less accurately than a simple baseline classifier that
assigns every sample to the most common training class  performance on the remaining
three categories was adequate  but low  this task requires further work 
table    multi label classification task results
        training samples        validation samples        testing samples 
training
validation validation validation
model
category corpus features baseline accuracy
accuracy sensitivity specificity
logreg
go
abstract unigrams    
      
           
    
logreg
go
abstract trigrams    
       
           
    
logreg
go
fulltext unigrams    
      
           
    
logreg
phen  abstract unigrams    
      
           
    
logreg
phen  abstract trigrams    
       
           
    
logreg
phen fulltext unigrams    
       
           
    
logreg
phys abstract unigrams    
      
           
    

filogreg
phys abstract trigrams    
       
           
    
logreg
phys fulltext unigrams    
      
           
    
logreg
gen  abstract unigrams    
      
           
    
logreg
gen  abstract trigrams    
       
           
    
logreg
gen  fulltext unigrams    
      
           
    
logreg
lit 
abstract unigram    
      
           
    
logreg
lit 
abstract trigrams    
       
           
    
logreg
lit 
fulltext unigrams    
      
           
    
  baseline shows the accuracy of classifying each sample to belong to the most common training class 

in table    when comparing the
performance of the abstract unigrams to the
abstract trigrams  it appears that sensitivity
   
increases while specificity decreases  however 
     
this is because we are sampling different points
unigrams  
     
along the roc curve  when we plot the roc
bigrams  
     
curves for unigrams  bigrams  and trigrams  see
     
trigrams  
figure     we see that as we move to more
   
complicated feature sets  the roc curve
   
                       
   
improves  this is most likely because bigrams
  speci icity  
and trigrams have the power to capture
informative phrases and multi word biological
figure      sensitivity  as  a  function  of  
specificity  for  unigram   bigram   a nd  trigram  
terms that cant be captured by unigrams alone 
features  for  the  go  multi label  category   
based on these results  we chose to use
the abstract trigrams dataset with a logistic
regression model as our optimal classifier for this task  table   shows predicted
performance for the classifier for each category based on the testing set 
sensitivity  

roc  curve  for  go  category  

category
go
phen 
phys 
gen 
lit 

table    testing results on multi label classification task
baseline
testing accuracy
testing sensitivity testing specificity
   
      
    
    
      
    
    
   
   
      
    
    
   
      
    
    
   
      
    
    

future work
there are several areas of this project that would benefit from future work  due to
the size of our datasets  we were only able to do parameter tuning at an order of
magnitude scale  by tuning parameters at a more fine grained level  we believe we could
increase performance on both tasks  our results on the multi label classification task
show that working with trigrams from the abstract corpus offers significant gains over
working with unigrams  we believe that working with bigrams or trigrams from the
fulltext corpus has the potential to dramatically increase performance by capturing
information found in phrases and multi word biological terms  however  this would
require custom software because it would increase our feature size by at least an order of
magnitude  finally  the ultimate goal is to integrate our classifier into an active curation
pipeline  we plan to present our results to the saccharomyces genome database  and
hope to eventually use these techniques to automate part of the biological data curation
process 

fi