multiple sensor indoor mapping using a mobile robot
timothy e  lee   leete stanford edu   cs    final project
introduction
mapping  the ability for a robot to observe and build a representation of its environment  is a critical task for mobile
robots  indeed  mapping is a necessary component of autonomous navigation  in addition to perception and localization 
mapping is achieved by measuring the environment with sensors  such as laser  sonar  or visual based techniques  and
using probabilistic models to estimate the state of the environment  for indoor mobile robots  mapping can be used to
build the indoor environment boundary  e g   building walls   this study will investigate how multiple sensors can be used in
concert to generate a map of the indoor environment using a mobile robot  understanding the improvement of multiple
sensor mapping over single sensor mapping may prove valuable in the design of mobile robots and autonomy routines  as
tradeoffs may exist between any improvement in mapping accuracy and the decrease in weight  useful payload capability 
and increase in computational resources for installing and utilizing the additional sensors 

goal and scope
the goal and scope of this study is to generate a map that estimates an indoor environment given robot sensor data  and
determine whether a fusion of sensor data can improve the accuracy of the map over using one sensor 

data
the selected dataset to investigate multiple sensor indoor mapping is the dataset collected from a pioneer   dx mobile
research robot exploring the first floor of gates computer science building at stanford university for approximately   
minutes  the data are available online in the robotics data set repository  radish   courtesy of b  gerkey      the robot was
equipped with a variety of sensors to record laser  sonar  and odometry data 
 laser range data were collected using a sick laser measurement sensor  lms     that was attached to the robot 
laser readings were collected at approximately    hz  each laser reading contains     measurements 
corresponding to   degree intervals sweeping from one side of the robot to the other  in total          laser
readings are available in the dataset 
 sonar range data were collected from the sonar array installed on the robot  the sonar array is composed of   
individual sensors spaced entirely around the robot         sonar readings were collected at a sampling frequency
of approximately    hz 
 odometry  or position  data were collected from the robot at approximately    hz         odometry readings are
available in the dataset  each reading provides the robot pose  x position  y position  and heading   translational
velocity  and rotational velocity 
it should be noted that the dataset lacks a quantitative ground truth map  which precludes certain analyses  a map of the
indoor environment is provided  but it has no resolution  distances  landmarks  or color scale  thus  extracting position and
probability estimates from the ground truth map is not feasible  therefore  mapping the indoor environment will be
considered to be a supervised learning problem only in the sense that a qualitative assessment of the generated maps
accuracy is possible  i e   how similar does it appear to the ground truth map  

models
learning the map of an indoor environment can be accomplished by generating an occupancy grid map
     the
occupancy grid is a discretized representation of the indoor environment  where each cell of the grid carries the probability
of that grid cell being free  not occupied   probabilistically  each cell of the occupancy grid is modeled as a binary random
variable  with value of   for free and value of   for occupied  the likelihood that a particular cell
of the occupancy grid is
free based on the robot pose
and evidence  i e   sensor data 
acquired until the present time is
   

fit  e  lee

multiple sensor indoor mapping using a mobile robot

cs    final project

the construction for the entire occupancy grid can thus be expressed as a product of marginals given pose and evidence 

the real time algorithm to construct the occupancy grid map is accomplished by processing the data chronologically  and
the cells within the perceptual field of the robot are updated whenever a sensor reading occurs      the robot pose is
updated in parallel using the odometry data  the perceptual field provides evidence that a certain grid cell is occupied
based on the range measurement  i e   distance   and provides non occupied evidence for cells located in between the
occupied cell and the robot  a separate map for each sensor is maintained  at the conclusion of the algorithm  the maps
generated from each sensor are combined to form one map  completing the multiple sensor indoor mapping routine  for
this study  all algorithms were implemented using matlab 
regarding the parameters of the model  the prior of occupancy is assumed to be      meaning equal probability initially that
the cell is either occupied or free  the weight of the sensor evidence also plays a key role in the model  without available
quantitative ground truth  the probability of receiving a sensor pulse from a particular cell given the cell is occupied is
assumed to be       and the probability of no sensor pulse from a particular cell  within the perceptual field  given the cell
is free also assumed to be       these probabilities are low to account for pedestrians and other dynamic considerations of
the indoor environment that would cause spurious data  however  there is sufficient volume of sensor data to estimate the
occupancy map for either sensor 

results and discussions
single sensor mapping
the first attempt at generating the indoor map for the entire dataset using the laser sensor revealed uncorrected odometry
errors in the dataset  as shown in figure    the source of these errors is caused by how the robot determines its position 
the pioneer   dx robot integrates the measured wheel velocities into position estimates  using bearing data provided by a
compass  in a process known as dead reckoning      however  errors within the measurement of wheel state and bearing
also become integrated and therefore grow without bound  hence  the use of position in the occupancy grid algorithm
must be adjusted in some way to account for these odometry errors  while a variety of techniques have been proposed to
estimate and remove this error  they require information beyond what is available in the dataset  e g   using accelerometer
data from a gyroscope      or by calibrating the robot by moving in a pre defined square pattern      
because the odometry errors manifest through integration  these integrated errors will remain small for small time
segments  thus  to provide an indoor map in the presence of odometry errors  the occupancy map for a limited portion of
the overall dataset is instead examined  this limited portion is the first   minutes of the indoor tour  and the qualitative
ground truth for this portion is shown in figure    the number of binary random variables representing the occupancy of
the map for this reduced portion of the discretized indoor environment is approximately        
figure   shows the single sensor occupancy grids generated for the cases of using the laser in isolation and the sonar in
isolation  unsurprisingly  the laser sensor provides well defined boundaries and open floors  which is expected due to the
high sampling rate and excellent resolution of the laser range measurements  some odometry error is present  but
otherwise  the map is similar to the qualitative ground truth map  for the occupancy grid generated from sonar data  the
overall probabilities are lower in open hallways  however  the sonar occupancy grid sufficiently predicts the boundaries of
this environment  so this occupancy grid generally agrees with the qualitative ground truth  disregarding odometry errors  

   

fit  e  lee

multiple sensor indoor mapping using a mobile robot

cs    final project

figure    occupancy grid map for the entire dataset as determined from laser measurements  the overlap is caused by
latent odometry errors in the dataset  the robot trajectory is superimposed 
multiple sensor mapping
having generated separate maps for both the laser and the sonar sensors 
the next step for fusing the sensor information is the selection of fusion
algorithm  one particular algorithm is provided that  for each grid cell 
keeps the minimum value over the maps generated by sensors     

this algorithm is described as pessimistic because  for each grid cell  the
sensor with the lower probability of that cell being free  higher probability
of being occupied  is selected  in other words  the fusion algorithm trades
less mapping of potential areas of further exportation  such as open doors figure    the qualitative ground truth for the
and corridors that are better captured by the laser  for higher probabilities
occupancy grid mapping problem  the
approximate robot trajectory is
of detecting boundaries  this is evident in figure   when comparing the
superimposed 
multiple sensor occupancy grid to the map generated by the laser sensor
in figure    figure   also indicates the sensor source for each grid cell  it suggests that the laser is providing better
probability estimate for walls and a higher probability estimate of free grid cells in hallways 
the results from the pessimistic sensor fusion suggest that the laser is superior to the sonar for classifying grid cells into
either free or occupied states  and therefore  for mapping this environment  this is likely due to the higher sampling rate of
the laser sensor as compared to the sonar sensor  however  because their underlying measurement mechanisms are
different  some object types in the indoor environment may be better suited for detection by one sensor  rather than the
other  for example  the sonar sensor has readings entirely around the robot  and thus can perceive objects behind the
robot   whereas the laser can only perceive objects in the direction of the robot heading 

   

fit  e  lee

multiple sensor indoor mapping using a mobile robot

cs    final project

figure    occupancy grid maps for using the laser alone  left  and the sonar alone  right  

figure    occupancy grid map generated from multiple sensors using a pessimistic fusion algorithm  left  
the sensor source for each cell is also shown  right  
therefore  it is desirable to choose the sensor with the highest confidence in the classification of grid cells  as either
occupied or free   to this end  a fusion algorithm is proposed that uses the sensor with the most confident classification 

the calculation of average probability over sensors is necessary to understand if the sensors are generally indicating a
free cell  and thus use the sensor with highest probability  or an occupied cell  and thus use the sensor with lowest
probability of being free  i e   highest probability of being occupied   the occupancy grid for the minmax sensor fusion is
shown in figure    it is evident that this fusion permits the use of laser readings in states where it outperforms the sonar
 e g   through long hallways and open doors   but also relies on the sonar for better occupied cell detection of boundaries in
the room at location           the difference between the laser occupancy grid and minmax fusion occupancy grid is subtle 
but the minmax fusion grid appears to offer a better estimate of the indoor environment than the single sensor grid  this is
achievable because sonar measurements are used when the sonar grid estimates are superior to the laser grid estimates 
   

fit  e  lee

multiple sensor indoor mapping using a mobile robot

cs    final project

figure    occupancy grid map generated from multiple sensors using the minmax fusion algorithm 
it should be noted that the model parameters  such as sensor evidence weights and sampling rates  likely affect how well
each sensor  and therefore the fusion of sensors  can predict the binary state of the occupancy grid cells  therefore  the
presentation of the minmax fusion algorithm is not meant to be stated as superior in general  rather  it is presented for
future study in multiple sensor indoor mapping as one of several algorithm options for sensor fusion 

conclusions
this study demonstrated that the indoor environment was successfully mapped using an occupancy grid  where each cell in
the grid was modeled as a binary random variable representing whether the cell was free or occupied  the probability
estimates  grid cells  were updated as the algorithm processed robot evidence  odometry  laser  and sonar  in real time 
the predicted map of the indoor environment was shown to be similar to the qualitative ground truth map  if odometry
errors are neglected  the minmax fusion algorithm was shown to slightly improve the probability estimates of the sensor
fusion map as compared to the map generated by the laser data alone  however  this algorithm may be sensitive to the
object types within the indoor environment and the model and sensor parameters  so further study is recommended 

future work
the current study explores the nature of mapping an indoor environment using multiple sensors  and there are several
paths forward of future work  to extend the work to the entirety of the indoor environment  it is necessary to correct for
odometry errors  it may be possible to join small submaps together in a technique such as linear slam that avoids issues
with odometry errors      the generality of the minmax sensor fusion algorithm is also intriguing  and it would be beneficial
to understand how sensitive this fusion algorithm is to sensor evidence weights  indoor obstacles  and other parameters of
the map and sensor models  lastly  it would be intriguing to cross reference the mapping method implemented in this
study with open source methods  such as those provided by the carmen toolbox  as a means of cross validation     

references
    a  howard  n  roy  the robotics data set repository  radish         http   radish sourceforge net  
    s  thrun  w  burgard  and d  fox  probabilistic robotics  mit press       
    pioneer   mobile robot  operation manual  january      
    c  tarin sauer  h  brugger  e  p  hofer  b  tibken  odometry error correction by sensor fusion for autonomous mobile robot navigation  ieee
instrumentation and measurement technology conference  may             
    j  borenstein  l  feng  umbmark  a benchmark test for measuring odometry errors in mobile robots  spie conference on mobile robots       
    l  zhao  s  huang  g  dissanayake  linear slam  a linear solution to the feature based and pose graph slam based on submap joining  proceedings
of the      ieee rsj international conference on intelligent robots and systems  november           
    m  montemerlo  n  roy  s  thrun  perspectives on standardization in mobile robot programming  the carnegie mellon navigation  carmen  toolkit 
proceedings of the      ieee rsj international conference on intelligent robots and systems  october             

   

fi