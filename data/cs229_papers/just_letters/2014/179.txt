 

seizure forecasting
xiaoying pang
 xypang stanford edu

abstract
the focus of this project is to predict impending seizure occurrence for epilepsy patients using intracranial
eeg recordings  reliable prediction of seizures can provide the patients with not only warnings but also
new therapeutic possibilities  the goal is to correctly differentiate the pre seizure brain state  the preictal
state  from the baseline state  the interictal state  using just the ieeg signals  both frequency domain
and time domain features have been extracted and explored and ml algorithms such as logistic regression 
lasso logistic regression  svm and knn have been applied  a kaggle score of         was achieved using
the logistic regression and frequency domain features 

introduction
seizure afflicts nearly    of the worlds population  when it strikes  it can disable a person temporarily
and cause serious injuries  its unforeseeable nature makes a patients daily life even harder  many patients
take preventive drugs daily  however  only a fraction of them can actually benefit from the medication 
some of them can even suffer from physical and cognitive side effects from these drugs  the ability
to forecast seizures will provide the patients with some certainties in their lives and enable on demand
treatments so that patients only need to take medicines when seizures are about to happen 
clinical studies have suggested that a patients brain activities can be classified into four states 
interictal  between seizures  or baseline   preictal  prior to seizure   ictal  seizure   and postictal  after
seizures   in this kaggle challenge  we were ask to correctly identify the pre seizure brain states  i e  the
preictal states from the baseline states i e  the interictal states using the intracranial eeg data 
due to the fact that ieeg patterns varies greatly across patients  in fact  one patients preictal
signals can look very similar to another patients interictal signals  it is almost impossible to construct
a single generic algorithm model that will work for all patients  a more realistic approach is to find a
patient specific classification method based on features extracted from each individual patients ieeg
data 
in this study  i have explored both time and frequency domain features extracted from the ieeg
signals and tested with a few ml algorithms  details about the features extracted and the machine
learning algorithms applied will be discussed in the following sections  matlab was adopted as the
scripting language for this project 

data and features
data
training and testing data for five animal and two human patients are provided by kaggle  each data
file contains a    min long ieeg recording collected using various numbers of electrodes  each row in
the data file is the signal picked up by one of the electrode  the sampling frequency of the electrodes or
channels was     hz for the animals and      hz for humans  the training data are very unbalanced 
e g  for the first animal patient      interictal training clips are provided  whereas only    preictal clips
are provided  the total data size is about    gb 

fi 

features
inspired by      and the kaggle discussion forum  the following features have been extracted from the
ieeg data 
   shannon entropy for different frequency bands using windowed data
   pca transformed feature  
   correlation between channels for windowed data
   correlation between channels for the whole    min data
to calculate feature    each    min data clip is first divided into        second long epochs with    
overlapping  then the hamming window is applied to each epoch to reduce the fft power leakage  the
fft power spectral density  psd  of one of the epochs is shown in fig     one can see that most of the
    

     

     

     

psd

     

     

     

     

     

     

 

 

  

  

  

  

   
   
frequency  hz 

   

   

   

   

figure    power spectral density of a    second epoch 
spectral powers are concentrated in the low frequency region  once the fft psd is calculated  it is then
normalized by its summation over all frequencies  and used for the calculation of the shannon entropy
for different frequency bands  shannon entropy     is a measure of the uncertainty in a signal  it can
be calculated according to eq    
p
pk log pk
entropy   k
   
log n
where pk is the psd of the kth frequency  and n is the total number of frequencies in a frequency band 
finer frequency band widths have been chosen for lower frequencies due to the fact that most of the
spectral powers are concentrated in these regions  different frequency band settings have been tested
and the most effective one is the   hz bands from      hz up to    hz and    hz bands from    to    
hz  to construct the final training matrix the band entropy for all the channels are concatenated  for
example  there are     interictal and    preictal training clips for the first dog patient  by using a   
second window  each    min clip can be divided into    epochs with     overlapping  the total number
of epochs is                        then for each epoch  there are number of channels  number of
frequency bands                features  so the final training matrix would be      by      the
same procedures have also been applied to the testing data  since each testing clip has been divided into

fi 

several epochs  the final prediction of one clip is simply the average prediction across all epochs within
the clip 
one of the advantages of the windowing technique is that it can help enlarge the training samples 
which can be especially useful for this highly unbalanced data  another advantage is that it helps to
preserve more detailed structures of the signals rather than averaging them out in feature calculations 
in order to further decouple the features  pca has been applied to get the demixing matrix and then
used to rotate the features in order to obtain the decoupled final forms 
besides the frequency domain  features like the variances and the correlations between different channels electrodes are computed in the time domain  they are calculated for both the windowed data and
the original    min clip data 
so far  feature   with    second window turns out to be the most effective kind 

ml algorithms and results
to formulate the classification problem  the preictal state is labeled as   and the interictal state is labeled
p
tp
t p  t n
as    the metrics precision   t pt f
p   recall   t p  f n and accuracy   t p  t n  f p  f n have been
calculated during the cross validations  the kaggle leader board score is quoted as the testing accuracy 
although it is not very clear how the score is calculated  it may be obtained using the area under the
roc curve for all the patients  ml algorithms such as logistic regression  logistic regression with lasso
regularization  svm and knn have been tested  the results shown in this section are all calculated using
feature   mentioned in the previous section 

logistic regression
logistic regression works surprisingly well for this problem  table   listed the training accuracies for all
the subjects using    fold cross validation  although the training metric values of the logistic regression
are lower than those obtained by other methods  a kaggle score of         have been achieved  the highest
among all the algorithms i have tried  part of the reason might be that during the training  posterior
probabilities have been mapped to   or   by comparing the probability to      which is probably not
what kaggle did when it calculated the scores 
table       fold cv results for logistic regression 
kaggle score          
subject
dog  
dog  
dog  
dog  
dog  
human  
human  

precision   
    
    
    
  
    
    
    

recall   
  
    
  
  
  
    
    

accuracy   
    
    
    
    
    
    
    

logistic regression with lasso regularization
the matlab function lassoglm with lambda           alpha       is used  parameter lambda
controls the magnitude of the l   norm  while the alpha parameter controls the weight of lasso  l  

fi 

norm  vs  ridge  l   norm  optimization  the cross validation accuracies are presented in table    a
kaggle score of        has been achieved by using this algorithm 
table       fold cv results for lasso lr 
kaggle score         
subject
dog  
dog  
dog  
dog  
dog  
human  
human  

precision   
    
    
    
    
    
    
    

recall   
    
    
    
    
    
    
    

accuracy   
    
    
    
    
    
    
    

svm
the matlab command fitcsvm with a gaussian kernel was applied to the training matrix  it yields the
best results when boxconstraint is set to     and cost is set to            where the boxconstraint
controls the magnitude of the regularization term  and the cost matrix indicates how different classification
scenarios will be penalized  a larger boxconstraint value can force the svm to generate fewer support
vectors  therefore reduce overfitting  a cost matrix of            means that there will be no penalty if
the prediction is correct  however  the penalty will be   if the prediction is an false alarm  prediction
is preictal and the data is actually interictal  and   if the prediction is false negative  prediction is
interictal  however  the data is actually preictal   since for seizure prediction  a false negative is much
more detrimental than a false alarm  more cost has been assigned to it  the cross validation accuracies of
the svm listed in table   are the best among all the algorithms i have tried  however  it didnt achieve
a better kaggle learderboard score           than that of the logistic regression           
table       fold cv results for svm 
kaggle score          
subject
dog  
dog  
dog  
dog  
dog  
human  
human  

precision   
    
    
    
    
  
    
    

recall   
    
    
    
    
    
    
    

accuracy   
    
    
    
    
    
    
    

knn
when training the knn  twice weight have been assigned to the preictal data than to the interictal data
since much less preictal data has been provided and we are more interested in the preictal state  this
seems to be able to improve the prediction accuracy slightly  table   lists the cv metric values of the
knn algorithm  the highest kaggle score i was able to get by using knn was         

fi 
table       fold cv results for knn 
kaggle score          
subject
dog  
dog  
dog  
dog  
dog  
human  
human  

precision   
    
    
    
    
    
    
    

recall   
    
    
    
    
    
    
    

accuracy   
    
    
    
    
    
    
    

discussion and future work
for this project  feature selection is the key  when i first started  i was using the variances and correlations
between channels  feature   and   mentioned in the previous section  as my primary features  the best
kaggle score i was able to achieve using these time domain features never exceeds       which was
obtained by using logistic regression  the frequency domain fft features  feature    i tried later on
turned out to be much better  in order to further decouple the features  i applied pca to the extracted
feature    however  that didnt help in terms of getting better cv accuracies and a higher kaggle score 
besides  i also tried to concatenate all the frequency and time domain features for training  but the cv
metric values and kaggle scores i was able to get are all worse than just using the frequency domain
features  genetic algorithm has been applied to feature selection too  but no substantial gain has been
achieved 
logistic regression  lasso logistic regression and svm all work very well for this problem  svm
produces the best cv accuracies  however  the logistic regression produces the best kaggle score  this
indicates a difference between the approach kaggle used to calculate error metrics and mine 
in the future  more features can be included  e g  the hjorth fractal dimension  mobility  complexity 
and eigenvalues of the covariance matrix between channels  etc  and ml algorithms such as the neural
network and random forest will be applied to this problem  a scheme combining predictions from an
ensemble of models will be tested to see if better and more consistent performance can be achieved 

references
   howbert jj  patterson ee  stead sm  brinkmann b  vasoli v  crepeau d  vite ch  sturges b 
ruedebusch v  mavoori j  leyde k  sheffield wd  litt b  worrell ga        forecasting seizures
in dogs with naturally occurring epilepsy  plos one      e      
   ark y  luo l  parhi kk  netoff t        seizure prediction with spectral power of eeg using
cost sensitive support vector machines  epilepsia              
   mormann f  andrzejak rg  elger ce  lehnertz k        seizure prediction  the long and winding
road  brain             
   c  shannon  a mathematical theory of communication  bell system technical journal  vol      pp 
                     

fi