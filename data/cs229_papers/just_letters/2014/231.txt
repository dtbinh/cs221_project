landmark recognition using machine learning
andrew crudge  will thomas and kaiyuan zhu

introduction
as smartphones and mobile data become more prevalent in modern society  the
possibilities for them to interact with the physical world also grow exponentially  technologies
such as oculus rift and google glass are attempting to bridge the gap between the virtual and
the physical  and as enhancements in computer speed and image processing are made  the
concept of augmented reality  ar  becomes more tangible 
however  one difficulty with ar is the sheer complexity of image processing and feature
recognition  a successful ar system must be able to distinguish among a large number of
landmarks and should be able to adapt to the existence of new landmarks  because of the
adaptability requirement  ar algorithms naturally lend themselves to using machine learning  as
such  the focus of this project is to develop  refine and document a machine learning algorithm
that can distinguish landmarks from images using a database of known landmarks 

data and preprocessing
the input data consists of     images of various buildings collected from google
images  the training data to be put into the svm consists of a vector that contains all the labels 
and a matrix whose rows are the examples and whose columns are the features  to make each
example the same feature dimension  the image is cropped to an aspect ratio of      this
specific aspect ratio is chosen for all images because most landmarks are skyscrapers that
requires more height than width to capture the main features  then  the images are converted
into grayscale because the hog descriptor looks for differences in gradient intensity  regardless
of which colors are used  lastly  the images are shrunk to    x    pixels  preserving the original
aspect ratio  so that each image will generate an identical feature size 

feature extraction
to extract features from the images  histogram of oriented gradients  hog  was used 
hog descriptors are useful for object detection because they analyze gradient orientation in
localized regions of an image  the image is divided into small regions called cells  within each
cell  the gradient directions of the pixels are analyzed and formed into a   d histogram      these
histograms are then combined to generate the features of the algorithm 
hog descriptors were chosen to extract the features from the input images because
they are well suited for object detection  by analyzing the gradient directions of the pixels in the
image  the descriptor is able to differentiate the edge of a building from the background 
the hog descriptor also possesses several other useful properties for object detection 
in particular  it is invariant to shadows or changes in illumination  this is achieved by combining
neighboring cells into a larger region called a block and computing a measure of the intensity of
the block  this intensity is then used to normalize the cells within the block      one drawback of
the hog tool is that it is not invariant to changes in orientation  this will not be a big issue in the
preliminary application as long as the buildings in the image are roughly upright 
the effectiveness of the hog depends on the cell size chosen for the algorithm  indeed 
varying the cell size changes the number of features generated for each example  a smaller cell
 

fimore information about the image  however  smaller cell size also increases the running time of
the algorithm since the larger feature vectors take more time to process  the effects of the cell
size of hog on the accuracy of the algorithm can be seen in figure   

figure    accuracy of the svm classifier as a function of the cell size of the hog descriptor

as cell size increases  the test accuracy of the algorithm decreases  the algorithm
achieves the highest accuracy of     with a cell size of  x   however  the accuracy drops
below     once the cell size grows to   x    after balancing the algorithms runtime and
performance  a cell size of   x   was selected  another feature extraction algorithm 
segmentation based fractal analysis  sfta   was considered  however  this method generates
feature vectors much slower and with a maximum accuracy of       much poorer than hog 

models
a support vector machine  svm  was selected as the primary machine learning classifier
for this application  this model was chosen because the algorithm is very efficient when dealing
with high dimensional feature spaces  additionally  svm usually has the best performance
among the other off the shelf supervised learning algorithm  and is very popular in many
industrial applications  in the application  feature vectors are produced through hog descriptor
with   x   cell size  and the resulting feature dimension is above      

results and discussions
the four classifiers were compared by being run on a dataset of     images  the
dataset was split into a training set consisting of    images and a test set consisting of the
remaining    images  to obtain an accurate evaluation of the performance  each classifier was
run    times  each time  the dataset was randomly permuted to vary the training and test sets 
the average performance of each classifier was then computed over the    runs  the results of
the experiment can be found in table   

 

ficlassifier

training accuracy

test accuracy

support vector machine

 

      

discriminant analysis

 

      

nave bayes classifier

      

      

linear regression

 

      

table    relative performance of various classifiers

the performance of the classifiers on the test set ranges from         among the four
classifiers  the support vector machine attains the highest average test accuracy  in addition  it
runs much faster than the other classifiers  as a result  it was selected for the application 
in addition  the effect of the training size on the performance of the classifiers was
analyzed  the size of the training set was varied between    and    images while maintaining a
test set of    images  the results of this experiment can be seen in figure   

figure    accuracy of three classifiers as a function of the size of the training set

in general  the test accuracy increases as the size of the training set grows  for a given
training set size  svm and discriminant analysis performed better than nave bayes  once
again  the svm has the highest accuracy for most training set sizes  slightly outperforming
discriminant analysis  in particular  as the training set grows to    images  the accuracy of the
svm classifier approaches      the svm and discriminant analysis maintain a training
accuracy of      for all sample sizes because they are given the correct labels as input  for
nave bayes however  the training accuracy decreases slightly as the training size grows 
additionally  functionality was developed to detect a target building from an image of any
size  for example  figures   a  b  show the successful recognition of the empire state building
in new york city  and figure   c  d  show similar recognition of the willis tower in chicago  the

 

fibox in the images shows the algorithms guess as to the location of the target building  in both
cases  the algorithm is able to correctly identify the target building 

 a 

 b 

 c 

 d 

 e 

 f 

figure    algorithm identifies target buildings from image of new york city and chicago skylines

 

fito detect a target building hidden within a larger image  the image is cropped into
multiple overlapping cells with identical aspect ratios  features are then extracted from the cells
using the hog descriptor and classified using the svm algorithm outlined above  for each cell 
the classifier outputs a labeling and a confidence  the cell with the largest confidence of being
classified as a positive labeling is then deemed the most likely cell to contain the target building 
finally  the algorithm was adapted to analyze images containing multiple target buildings  to
handle multiple target buildings in a single image  the problem was divided into multiple 
independent binary classification tasks  as before  the image was divided into cells and a
labeling and confidence was assigned to each cell using the svm  if an example has multiple
cells that are assigned the same label  the cell with the higher confidence score is assigned the
label  using this method  two target buildings could be detected from one image with an
accuracy of      combining the algorithm of multi class classification and algorithm of
recognizing target building in a large image  the result in figure   e  f  was produced  in which
the algorithm successfully identifies the empire state building and the chrysler building from an
image of the new york city skyline 

conclusions and future work
overall  the results are very encouraging  and they demonstrate that landmarks can be
accurately identified from an image using a basic classification algorithm  an accuracy as high
as     is attainable using a relatively small sample size 
furthermore  the time required to process and analyze an image is reasonable  these
results suggest that this algorithm could be incorporated into an app to provide real time
feedback as images are taken 
in the future  other feature extraction methods can be looked at that may give better
accuracy but require fewer dimensions  an algorithm will also need to be developed that can
automatically search and obtain data from a database  the project can ultimately become part of
the back end code for a feature recognition smartphone app 

references
    n  dalal and b  triggs   histograms of oriented gradients for human detection   
cvpr      

 

fi