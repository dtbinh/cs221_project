ruck those stats  machine learning as the new coach
alejandro sanchez  nicolas sanchez
stanford university
cs     machine learning  autumn     

in this project we aim to identify which quantifiable aspects of the game of rugby
union are most critical to carry a team to victory  to do this  we collect data from
thousands of past games and use this to train several learning algorithms  using a
cross validation algorithm we pick the most relevant features using the best available model  we then run the models again using these reduced features  finally  we
shift from looking directly at the features to analyzing a teams deviation from their
past k performances in order to understand what aspects of the game usually require most focus and improvement 

  introduction 
 

with the rugby world cup being the  th largest
sporting event in the world  rugby is a passion for many 
it is one of the most popular sports today  with established fans around the world 
by its construction  rugby puts into motion a
wide variety of skills  testing the members of a team both
mentally and physically  though much importance is
usually attributed to technical skills  strength and athleticism  no experienced follower of rugby can deny the
vital strategic and team component of the game  as a result teams typically develop a strategy that prioritizes
certain factors of the game over others  some teams may
focus more on ball possession while others focus on clear
line breaks  or kicks from hand for territory  understanding to what extent each of these factors contributes to a
victory therefore becomes one of the main goals for a
team  its coaches and the millions of fans around the
world  hence  it seems relevant to investigate what machine learning can offer in this respect 
more precisely  our aim is not to predict which
team will win in a given match or given tournament  rather by learning from which strategies have been successful in the past  we want to gain insight on the sport of
rugby as a whole  rather than focusing on a single game
outcome 

  data collection

we did manage to get access to readily available and
easily manageable datasets to perform machine learning
algorithms  but given the popularity of rugby union 
large collections of both team and player performance
statistics are available in various websites to deliver a
match pack that describes a game in detail to devoted
fans 
for our project  we decided to focus on team performance statistics  the first practical reason was the high
variability of the individual statistics  since players
change teams from year to year  an analysis of the individual players would probably inform us on that particular team without giving us a general insight into the sport
of rugby  moreover  rugby is at times referred to as the
ultimate team sport  and is without a doubt fundamentally driven by the performance of a team more than by
the performance of any individual player 
we decided that the espnscrum com website
contained the most abundant relevant team data  our first
objective was therefore to get the data of all the games
 each being on a separate webpage  into one same document  this proved particularly challenging as different
statistics were recorded for different matches  depending
on the year  and the importance of the match  effectively
scraping useful data off of the website therefore required
an elaborate python script 
once we found a way to scrape the data  we
chose to use games from super rugby and the english
premiership from the past   seasons  both are professional league competitions for top clubs in their respective
regions  super rugby brings together top teams from
australia  new zealand and south africa  while english
premiership gathers top teams from around england 
both are popular leagues  in turn meaning that
espnscrum kept track of most of the statistics for the

fimajority of the games in the last   seasons  they are both
larger than most other tournaments  meaning that each
season had more games  leading to more training points
our algorithm could learn from  we collected a total     
data point with ground truth 

  feature selection preprocessing
from the website we obtained    different statistics
of each game  most of these were in fact multiple performance metrics in one  rucks won  rucks lost was
just listed as one on the website   we preprocessed this
data so as to write all out statistics and eliminated redundant statistics  as well as performance metrics that were
too sparse  we therefore ended up with a staggering   team performance measures per game  we chose these
performance metrics  as they are what both fans and
coaches analyze to understand if they had a good performance or a poor performance  indeed we obtained game
stats sheets from a former professional rugby player  and
the stats they analyzed to evaluate their game performance were similar to the list of performance metrics we
included in our metrics 
in line with our objective  rather than comparing the performances of opposing teams  we only considered the
performances of one team as the input  and classified it
depending on whether the given team won the given
match  initially we used all of these features for our first
algorithm  seen as the ranges of the performance metrics
varied greatly  a team typically runs hundreds of meters
while they only get three or four tries per game  we decided to standardize the features  mean removal and variance scaling  to receive aid our models 
we began our project by having three distinct classes
for wins  losses and draws  as soon as we started to look
at the data and the result of the first machine learning
algorithm we realized that there were only a small number of draws  a little less    of the games were draws 
and their presences significantly dropped the accuracy of
our models  we therefore decided to rid both our training
set and test set of all draws  again we do not believe this
goes against our objective since our mission is to gain
insight on the game of rugby and we consider gaining
insight on     of the game will probably generalize to
that last    

  two approaches
we took two different approaches to creating the features we would input to a machine learning algorithm 
our first approach was to use the list of performance
metrics for a given game for a given team as the features
for a training input and classifying that training point as

won if the given team won the given game and as a loss if
the given team lost the given game  we train the different
models described below to this training data  intuitively 
this first approach takes games on an individual basis 
looks at the teams performance  and tries to model how
each team has to perform with respect to each feature in
order to win or lose a game  if we have a strong model
that accurately predicts if a team won game given its performance  analyzing which features are most important
for the model should give us an idea of which performance metrics are most important for a team to win 
our second approach is a little more elaborate and
comes from another strong professional belief in rugby
that to do well in a game you simply have to have certain
performances metrics better than your usual performance 
for each performance metric we look at the performance
of the team in the game that we are analyzing  and subtract it from the same teams previous k games  the vector
containing these values for all of the features will be our
input vector for the game  we still classify this input as
we did in the first input  win if the given team wins the
given game   intuitively this approach should have more
information on how the team is performing with respect
to its own standard in recent games  and might therefore
give a better idea if a team played well or not 

  model selection and results
before looking at reducing our features to an optimal set  we needed to select a model that could best
predict the outputs of a game using the given team statistics  the models we chose to explore were  nave bayes 
svm  random forest and nearest centroid  we ran a
first iteration of each of these algorithms using the raw
form of the data  where we only made necessary adjustments to be able to run the algorithms  we then made a
series of transformations to our data in order to increase
the success rate of our algorithms  including eliminating
draws  normalizing the data and using k past season performances for each team 

    initial run  setting the baseline 
as we explored the possibilities of proceeding
with this project it was necessary that we have a model
that would give us basic results and more importantly a
realistic baseline  with this in mind we used the nave
bayes algorithm  with no prior knowledge on the distribution of the features  we guessed a gaussian distribution
and ran the corresponding nave bayes algorithm    with 

fiwe inputted the raw feature matrix with the corresponding label vector and received a score on both the
training and test set  the gaussian model reported a success rate of       on the training set and       on the
test set  these low results were largely due to the fact that
we were considering wins  draws and losses  but when
we realized that only    of games were draws  we took
these out of the modeling  running the new data through
the gaussian nave bayes  we got a success rate of
      on training data and      on test data 

    feature ranking and feature selection 
the next step is to understand how relevant are
the features we used  for this did an individual feature
ranking using an extra trees classifier     from figure  
we notice that the most important features were tries and
conversions made while red cards and mauls won are not
all that relevant 

    first approach 
given the above results  we decided to proceed using the data without draws and preprocessing
such that it was standardized to a gaussian distribution of
mean   
no draws standardized 

reduced features

train

test

train

test

nave bayes gaussian

     

     

     

    

svm linear 

     

     

     

     

svc polynomial

    

     

     

     

svc rbf

     

     

    

    

nearest centroid

     

     

     

     

random forest

     

    

     

     

table    percentage of successful predictions for all algorithms using initial features and reduced features on both
training and testing sets 

however  one of the characteristics of the nave
bayes is that it naively assumes independence on the features  which is not something we necessarily want to assume which is why we wanted to use another approach
that would not make this assumption 
the next model we looked at  was the svm  for
this we used a support vector classifier    with linear 
polynomial  and rbf kernels and the results can be seen
in table    the results barely surpassed those from the
nave bayes with a maximum success rate form the linear kernel at       on the train set and       on the test
set  although this is much better than a       guess  it is
still not much better than our baseline 
we also used a nearest centroid     where the
prediction was based on how similar a teams performance was to another game that had already been played 
this gave us a success rate of       on the training set
and a       on the test set 
finally  although not something that was covered
in class  we decided to use a random forest     using the
same data that we inputted for the svms  we received
success rates of       on the training set and     on the
test set 

figure    ranking of initial    features using an extra trees
classifier  tries and conversions made rank at the top while
percentage of mauls won and red cards lag at the bottom 

given this information we looked to reduce our
feature set in order to get a better sense on what are the
core features that define a successful rugby game  hence
we carried out a recursive feature selection    using a
linear svm  and figure   shows that the optimal number
of features was     we note that with the first   features
there was a rapid increase in success rate but then the rate
stagnates with only an overall slight increase 
with these most relevant features  we trimmed
our data to reflect this change and plugged in the new
data into the algorithms we previously mentioned  figure
  contains the results for this reduced data  it can be noted that there was an overall increase but it was not considerable  nave bayes had the highest increase with    
an interesting point is that this feature selection had an
increase on all models even if the selection was done using a linear svm 

figure    graph of cross validation score given the number of
features selected  the maximum is at    features with a score
of        note that this is a cross validation score and not a
score on training or testing sets 

fi    second approach 
as mentioned earlier  this approach seeks to 
take into account the momentum of a season  and 
model what aspects of the game  or in this case fea 
tures  that need to be improved from game to game in 
order to increase the chances of winning the next 
game  
we modified the data as described in part   
and inputted it once more to all of our algorithms and 
created   new data sets  in each we respectively took 
the averages of the past                  and    perfor 
mances  we saw a slight but clear increase in success 
rate from   to    past performances but it then de 
clined as we considered    and     in table   reports 
the results for the past   and    performances  and 
table   reports the results for the past    perfor 
mances  
 
  past performances

figure    ranking of    features using an extra trees classifier  tries and conversions made rank at the top while percentage of mauls won and red cards lag at the bottom  due to an
issue of scaling not all features are labeled above  

 
finally we want to see which features were the most 
relevant and if we could settle for a set of core fea 
tures to get just as accurate or more accurate predic 
tions than we did with all    features  figure   shows 
the result of the rfs ran on the data with past    per 
formances  

   past performances

train

test

train

test

nave bayes gaussian

     

     

     

     

svm linear 

     

     

     

     

svc polynomial

    

     

    

    

svc rbf

     

    

     

     

nearest centroid

     

     

    

     

random forest

    

     

     

     

 
table    models run using data with averages of past   
and past    performances  
 

 

figure    graph of cross validation score given the number of
features selected  the maximum is at    features with a score
of        note that this is a cross validation score and not a
score on training or testing sets  

 
table   reflects the change when we run the trimmed 
data on the models once more  we observe that the 
linear svm yields the best results with       accura 
cy on the test set  
 
 
table   models run using past    performances  this 
was the model yielding best results   
 
as we did in the first approach we now want to know 
what the ranking of the individual features is in order 
to get a grasp of what were the most relevant factors 
in deciding whether a team wins or loses the game  
figure   shows the ranking  

  discussion
    first approach
for the first approach we see that our individual
rankings graph strongly indicates that there are a few
rankings that are significantly more important than the
rest  upon inspection  we see that this corresponds to the
point scoring performance metrics such as tries scored 
conversions made and penalty kicks made  since the
winner of a game is ultimately determined by the team
that has scored the most points  it make sense that these
features are most important in evaluating whether a team
has most likely won the game or not 

 

fiwe notice however that the other factors are in no
way useless  indeed  the model that best predicts the outcome of the game based on the performance metrics of
the team in question takes into account    features  so
although point scoring metrics are the most important  a
number of other metrics still bring valuable information
about the teams likelihood of winning that goes beyond
the information given by the point scoring metrics  this
goes in line with the general idea that to win a game  one
should focus on some important factors of the game apart
from scoring tries 
in order to better understand these other non scoring
metric features  we reduced the original data with    features  this time  we eliminated the   scoring metric features  which were  tries  conversions made  percentage
of conversions made  penalty kicks attempted  penalty
kicks made  we ranked the features individually one
more time  and the results can be seen in figure   

  conclusion
with    past games  the model is more accurate than
with the first approach  both with all of the features and
the reduced features 
by construction of our two methods this suggests that it
is more accurate to evaluate how well a team played by
considering their recent past performances than thinking
there is some absolute performance formula for a wellplayed game of rugby  nevertheless  they both confirm
that to be successful  a team must excel in a variety of
performance metrics  which most likely lead to success
only when they are combined  this optimal combination
of features seems to be somewhat stable as the    chosen
optimal features using    past games mostly overlaps
with the    features chosen for the first approach  furthermore these performance metrics are in accordance
with the performance metrics professionals used to analyze their games 

  future

figure    ranking of non scoring metric features using an
extra trees classifier  we see a different ranking than what we
saw in the figure   

our next step would be to see if our results still 
hold when we test them on games from other tour 
naments  and see how that impacts the accuracy the 
models and hence the importance of our chosen fea 
tures  
even though we deliberately took a different ap 
proach  it would also be interesting to see what the 
results would be like if we combined the performanc 
es of opposing teams  obviously leaving point scoring 
metrics  we could evaluate at which metric should a 
team outperform the opposing team   

    second approach
with the second approach  we see that the model is
most accurate when trained with    past performances 
however this may also have to do with the fact that a
team has no more than    games in a season and hence
higher values of k lead to much less data points both for
training and testing 
an initial feature ranking shows that once again in
general a team should always try to score more points
than it has been doing so far  whether it is by making
penalty kicks or scoring tries  this remains significantly
more important than all the other performance metrics 
however  finding the optimal combination of metrics
yields an optimal number of    performance metrics 
which is again much higher than the   or   highest individually ranked performance metrics  this time requiring
more features is even more important since the cross validation scores drop notably for less than optimal performance metrics 

  references
   

scikit learn  machine learning in python  pedregosa et al  
jmlr     pp                 
   

p  geurts  d  ernst   and l  wehenkel  extremely randomized trees  machine learning                    
patel  s  parity and predictability in the national football
league
url http   cs    stanford edu proj     patelparityandpredictabilityinthenationalfootballleague pdf

fi