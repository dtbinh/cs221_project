cs     project

 

object recognition in images
wenqing yang wenqing stanford edu   harvey han hanhs stanford edu 

abstractthe purpose of this project is to build an object
recognition system that can accurately classify images using
cifar     a benchmark dataset in image recognition  we applied
knowledge of machine learning to this computer vision system 
particularly  we investigated softmax regression  svm and
convolutional neural networks to build this model  among which
cnn generated the best result 

both the training and test set are labeled for training and
testing 

i  i ntroduction

notably  the dataset from kaggle is different from the online
offical dataset in     in that the organizers mixed some junk
data in the test set in order to guarantee the justice of the
competition  since we will not submit the result on kaggle  we
use the original test set without junk data directly to provide
an estimation of our prediction accuracy 

object recognition is an important subfield in computer
vision  it is easy for humans to recognize and classify
objects in images  but usually not for machines  there
are various obstacles in object recognition  for example 
a picture only shows an object in  d dimension but the
angle of viewpoint can vary  there are also scale  color
and illumination differences in a picture  moreover  the
intersection  deformation and intra class variation in the
objects themselves also make the problem difficult to
handle    

b  data preprocessing
cifar    gives us natural color images  the color
information may not be very essential in some algorithms 
however  if we apply the simplest way to process the
data  averaging rgb to grayscale   we will definitely lose
information  moreover  in natural images  color may be
related to different objects  for example  flowers tend to have
bright warm colors while trucks have relatively cold colors 
hence  we determined not to convert the pixels to grayscale    

however  object recognition has made great progress out
of machine learning techniques  over the past few decades  a
bunch of algorithms and methods have been created to solve
the problem  among which deep learning theory especially
neural network generates the best performance  thanks to
the advancement in machine learning area  recently object
recognition has thrived in a variety of commercial areas such
as automatic focus  mobileye and google goggles  it will
further provide more applications in industrial and medical
fields including manufacturing quality control and medical
imaging    
our project is from kaggle competition and the dataset is
publicly available  we focus object recognition particularly in
color images 

ii  dataset
a  raw data
cifar    is publicly available online     the dataset
consists of          x   color images used for object
recognition  we keep the split of train and test set in the
official data  there are        images in the training set and
       in the test set 
in addition  there are    object classes in total and one
image belongs to a certain class  there are no intersections
among the    classes  the label classes are namely airplane 
automobile  bird  cat  deer  dog  frog  horse  ship and truck 

in addition  the raw data can be redundant  because adjacent
pixels have highly correlated rgb values  we want to remove
this kind of redundancies while not losing useful information 
zca whitening    provides a great method to preprocess the
raw data  this is also a rough model of how biological eyes
process the images  we obtained the zca whitened data by
following ufldl tutorial implementation 
iii  e xperimental m ethods
a  softmax regression
we chose logistic regression as our first attempt  since
there are    different classes in our dataset  we in turn applied
softmax regression     which is multi class version logistic
regression  to classify and predict object labels  in order to
gain a clear understanding of the algorithm  we wrote some
codes with the assistance of ufldl rather than call functions
directly from matlab  we maintained the color information
and didnt convert the pixels to grayscale  expecting obtaining
higher accuracy 
b  svm
from the results of softmax regression  it turned out not to
be satisfactory  we gained more insight of the data and then
we turned to svm  we used liblinear    package in matlab
to train and test our dataset  just as what we did in problem
set    the only difference lied in the fact that we had   
instead of   labels classes 

fics     project

c  naive bayes
we tended to form a classification method with naive
bayes  considering each pixel of the image has   integers
to represent three colors and an integer containes   bits of
information  we could not simply inspect the existence of
each integer  instead  we should consider each bit as a word
in a dictionary since each pixel has    bits of information 
the dictionary size would be as huge as   x  x   that equals
to        moreover  there are ten classes in total  which
means we need to calculate a series of probabilities  thus 
this method turns out to be cumbersome and is not suitable
for object detection  taken all these into consideration  we
abandoned this idea of naive bayes 

d  convolutional neural network
the field of image recognition has made great progress
since the application of the convolutional neural network 
lenet  alexnet and googlenet are examples of milestones
in the development of cnn  there are various platforms to
build and train cnns conveniently such as caffe  theano 
cuda convnet   we applied matconvnet for self defined
cnn and c   for spatially sparse cnn 
   self defined cnn  we built up a    layer convolutional
neural network inspired by the examples in matconvnet   
and caffe     it is composed of layers of convolution 
rectified linear units  max and average pooling  there
are also two fully connected layers at the bottom  the
architecture is shown in fig    

 

   spatially sparse cnn  although the cnn above
dramatically improved the accuracy  we could still modify the
architecture to further improve our neural network  motivated
by recent spatially sparse cnn      we decided to implement
the sparse network to lower the test error  taking advantage
of sparsity of input  we were able to train and test deep
cnns more efficiently  this method turned out to be the best
algorithm for our project so far 
a  sparsity of cifar    images  imagine we feed
all zero arrays into the input layer  as it goes through the
hidden layers of cnn  it generates non zero outputs  we
consider receiving no meaningful information as a ground
state and then will be able to utilize this sparsity  handwriting
characters with thin pen can be considered sparse  however 
naturual images like cifar    images cannot be regarded as
sparse  to make it spatially sparse  we need to add paddings to
the surroundings of the images  this has a second advantage 
data augmentation on training data can be carried out more
easily by adding translations  rotations  or elastic distortions
to the input images     
b  architecture  sparse cnn takes the advantage of the
good performance of sparse dataset on deep neural network 
and the combination of multi column cnn and network
in network architecture  multi column deep neural network
has alternating convolutional and max pooling layers      in
addition to this  we add network in network structure     after
each maxpooling  the network architecture is shown in fig    

fig     architecture of spatially sparse cnn 

iv  r esults

fig     architecture of self defined cnn 

we made learning curves for softmax regression and svm 
see fig    and fig     the results of different experimental
methods are listed in tab  i showing both training and test
accuracies of different models 

fics     project

 

table i  accuracy rate for different models
experimental methods
softmax regression
svm
cnn
cnn  matconvnet 
spatially sparse cnn

training set accuracy
      
      
     
      
      

test set accuracy
      
      
     
      
      

fig     learning curve for softmax regression

fig     learning curve for svm

about   hours  so few tests could be made due to time limit 
we further conducted literature review in the field and trained
two well designed cnns  one is designed in matconvnet 
which emulates the layer structures from caffe  the other is
more complex and advanced state of art spatially sparse cnn 
which is developed recently by benjamin graham  both of
the two networks improved the accuracy rate greatly and the
latter one had the accuracy rate of over      this is a very
high accuracy in the field of multiclass object recognition  it
demonstrates the great potential of cnns in image recognition 
vi  f uture w ork
there are several benchmark datasets in image recognition
including mnist  nist  cifar     cifar      imagenet
etc  we will further explore more larger datasets with more
categories  also  we will turn to gpu to train our models 
which is promising to greatly shorten the training time 
furthermore  there are a large pool of convolutional neural
networks as well as other neural networks and involved
features can be added to both increase the accuracy and
efficiency  we are to learn more varieties in designing neural
networks 

vii  c onclusion
we first tried out softmax regression and svm and
gained a general view of the image recognition problem 
it was non linearly separable and suffered overfitting  then
we designed our own convolutional neural networks and
improved the performance greatly  we further implemented
two well designed cnns and obtained the high accuracy
rate of      we are fascinated by the great potential of
convolutional neural networks and we will dig more into the
great variety of neural networks and train and test networks
using gpu 

v  c omparison and a nalysis
for the data preprocessing  we successfully implemented
the zca whitening and mapped the raw data to whitened
data  the dimensions remained the same and the redundancy
was removed 

acknowledgement
thanks for professor andrew teaching this excellent course 
thanks for tas suggestions on our project  thanks for all
those who gave a comment on our project at poster session 

softmax regression and svm with linear kernel both led
to low accuracy  from the learning curve we can see the two
models have high bias and overfitting  with the whole training
set being        images  the accuracy will not exceed    
in        test images  this means only with linear classifiers
will not generate good performance in the object recognition 
the results aroused our reflection and drove us to investigate
neural networks especially convolutional neural networks 

r eferences

with a    layers cnn designed by ourselves  we see
the dramatic improvement in accuracy  it is stable and the
accurarcy rate is about     both in training and test dataset 
it proves that cnn is well suited for image recognition 
but further refinement can still be made to enhance the
performance  there is one difficulty with our selection of cnn
structures and layers that the model needs a long training time

    wiki  outline of object recognition  http   en wikipedia org wiki 
outline of object recognition 
    http   people csail mit edu klbouman pw papers and presentations 
objectrecognitiondetection          pdf 
    http   www cs toronto edu kriz cifar html
    https   www kaggle com c cifar    forums t      
converting the images to grayscale 
    http   ufldl stanford edu wiki index php whitening
    http   ufldl stanford edu wiki index php softmax regression
    http   www csie ntu edu tw cjlin liblinear 
    http   www vlfeat org matconvnet 
    http   caffe berkeleyvision org gathered examples cifar   html
     b  graham  spatially sparse convolutional neural networks  http   arxiv 
org pdf           pdf
     d  ciresan  u  meier  and j  schmidhuber  multi column deep neural
net works for image classication  in computer vision and pattern recognition cv p r       ieee conference on  pages                  
     min lin  qiang chen  and shuicheng yan  network in network  corr 
abs                 

fi