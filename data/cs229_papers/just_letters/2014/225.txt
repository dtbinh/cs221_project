player behavior and optimal team composition in
online multiplayer games
hao yi ong    sunil deolalikar  and mark v  peng 
given the said teams composition of players  all of whom
may have different play styles  specifically  we consider kmeans and dp meansan expectation maximization algorithm    for clustering play styles and logistic regression
 lr   gaussian discriminant analysis  gda   and support
vector machines  svms  for determining win loss outcomes 
the rest of the paper is structured as follows  section ii
describes the target game of our numerical experiments and
our data collection method  sections iii and iv demonstrate
several methods and their effectiveness for learning play style
clusters and outcome predictors  some concluding remarks
are drawn and future works mentioned in section v 

abstract we consider clustering player behavior and learning the optimal team composition for multiplayer online games 
the goal is to determine a set of descriptive play style groupings
and learn a predictor for win loss outcomes  the predictor takes
in as input the play styles of the participants in each team  i e  
the various team compositions in a game  our framework uses
unsupervised learning to find behavior clusters  which are  in
turn  used with classification algorithms to learn the outcome
predictor  for our numerical experiments  we consider league
of legends  a popular team based role playing game developed
by riot games  we observe the learned clusters to not only
corroborate well with game knowledge  but also provide insights
surprising to expert players  we also demonstrate that game
outcomes can be predicted with fairly high accuracy given team
composition based features 
index terms team performance  team composition  player
behavior  video games  multiplayer games  game prediction

ii  target g ame d escription
we begin with a description of the mmorpg used for
our numerical experiments and the data acquisition method 

i  i ntroduction

a  league of legends

online virtual worlds are an increasingly significant venue
for human interaction  by far the most active virtual worlds
belong to a genre of video games called massively multiplayer online role playing games  mmorpgs   where players interact with each other in a virtual world      in an
mmorpg  players assume the role of in game characters
and take control over most of their characters actions  often
working in teams to accomplish a common objective  such
as defeating opposing teams  due to the shared  persistent
nature of these virtual worlds  user behaviors and experiences
are shaped by various social factors 
besides profit making  an understanding of these social
dynamics would provide insight to human interactions in the
real world and the potential of virtual worlds for education 
training  and scientific research           numerous prior
studies in social sciences and management have investigated
how team compositions can affect team performance     
     however  little is understood about player behavior and
team performance and factors contributing to it in competitive mmorpgs  to address this  we develop a machine
learning framework that uses game histories to learn player
behavior clusters and predict the outcome of games given
prior knowledge about the game and its players 
the contributions of this paper are twofold  first  we
present several approaches that group player behaviors in
online games  second  we develop predictors that determine
how likely it is that a team of players can emerge victorious

for this project we consider a popular mmorpgthe
league of legends  lol   lol is a multiplayer online battle
arena video game developed and published by riot games
with    million daily players      furthermore  lol is a
representative mmorpg of its genre  with many similar
counterparts such as world of warcrafts dota      giving
us a measure of generalizability to other games in its genre 
in this mmorpg  a standard game consists of two opposing
teams of five players  each player assumes the role of
one of over     different characters battling each other to
destroy the opposing teams towersstructures that fall
after suffering enough attacks from characters  a game is
won when all of either teams towers are destroyed 
b  data set acquisition
the developer of lol has made the games player statistics and match histories freely available through a web based
application programming interface  api       we randomly
gathered over         instances of player statistics and over
       instances of match histories from the          
season  we then parsed and cleaned the raw game data
to construct our training and testing sets  depending on
the features we chose  player statistics include performance
indicators such as average damage dealt and number of wins 
match histories contain information such as participant id
numbers and character choices 

  mechanical

iii  b ehavioral c lustering

engineering department  stanford university
and astronautics department  stanford university
  computer science department  stanford university
email  fhaoyi sunild   mvpengg stanford edu
  aeronautics

the target games developers have grouped the     different in game characters into six classes  such as assassin
 

fior support  which indicates the characters gameplay style 
while these classes reflect the developers design intent for
the characters  they do not necessarily reveal the behavior of
actual players in games  using statistics from various players 
we present our feature selection method and the gameplay
styles learned by applying various clustering algorithms to
our data set  we validate our results and the insights derived
from it with expert analysis from ranked players 

the derivation of dp means is inspired by the connection
between k means em with a finite mixture of gaussians
model  namely  the k means algorithm may be viewed as
a limit of the em algorithm if all of the covariance matrices
corresponding to the clusters in a gaussian mixture model
are equal to i   as       the negative log likelihood of the
mixture of gaussians model approaches the k means clustering objective      correspondingly  the em steps approach
the k means steps in lloyds algorithm 
in the case of dp means      shows how to perform
a similar limiting argument  specifically  suppose that the
generative model for the em algorithm was a dp mixture
of gaussians model with covariances equal to i   letting
     for the dp mixture model yields the objective function

a  feature selection
for our clustering algorithms  the features were    normalized player statistics  such as average damage dealt and
money earned  the statistics were normalized over their
range of values  preventing clusters from being formed due
to order of magnitude differences between statistics  for
instance  damage dealt values are often   orders of magnitude
greater than kill streaks  which means small variations in
damage dealt are erroneously considered as much more
important than kill streaks if taken directly as feature values 

k x
x

i k    

      

   

where s d fs            sk g is the set of clusters  x is an
observation  and i is the i t h cluster centroid  note that 
unlike in k means  k is now a variable to be optimized over 
this leads to an algorithm with clustering assignments
similar to the classical k means algorithm and the same
monotonic local convergence guarantees   see algorithm    
the difference is that a new cluster is formed whenever
an observation is sufficiently far away from all existing
cluster centroids  with some user defined threshold distance
  intuitively   is a penalty on the number of clusters  on
top of the original k means distortion function 

   k means  given a set of observations  k means clustering aims to partition them into k sets s d fs            sk g so
as to minimize the within cluster sum of squares  i e   find
the minimizer s   of the distortion function 
kx

i k   c  k

id  x si

b  clustering models

k x
x

kx

   

i d  x si

where x is an observation and i is the i t h cluster centroid 
in general  this problem is computationally difficult  nphard   for our clustering  we employ lloyds algorithm 
which is a heuristic that consists of randomly choosing
observations as cluster centroids and iteratively assigning
observations to their closest centroids and updating the
centroids with the mean of their respective clusters      
to select the number of clusters k  we run    fold cross
validation over k to find a local optimizer  the scoring function for the cross validation is simply the average distortion
given by     over the held out sets 
   dp means  dp means is a nonparametric expectationmaximization  em  algorithm derived using a dirichlet process  dp  mixture of gaussians model  which in other words 
the user does not choose the number of clusters beforehand 
the technique being the topic of a series of papers  we will
only provide a brief description of the algorithm  the reader
is referred to           for a thorough review of dp means 
recall that the standard mixture of gaussians assumes that
one chooses a cluster with probability c and then generates
an observation from the k gaussians corresponding to that
chosen cluster  in contrast  the dp mixture of gaussians
is a bayesian extension to this model that arises by first
placing a dirichlet prior dir k      on the k mixing gaussian
coefficients  i e   the probability of choosing a cluster  for
some initial set of coefficients    e g   uniform prior   as
observations are made  the prior is updated and the mixture
coefficients change to reflect these new knowledge 

algorithm    dp means
input   x   input data    threshold distance
output  clustering s            sk   number of clusters k
k
 

 
s 
random observation x rand   x
 
x rand
repeat
x perm
random ordered permutation of x
   cluster assignments
for x   x perm in order do
c
argmini  f      kg kx i k  
if kx c k       then
k
k c 
k
x
else
sc
sc   fxg
   centroid updates
for i d          p
  k do
 
i
x si x
jsi j
until s            sk converge
we ran dp means with    fold cross validation over a
range of  values  setting our scoring function as the average
of the objective values from     over the held out sets 
 

fi players in each cluster differ in risk attitudes  such
as whether they attack deeper in enemy territory
 ambusher clusters           and   
 players who move stealthily around the battlefield
and engage in quick  close ranged combat
 some players prefer a team oriented style  whereas
others prefer a more lone wolf approach
 includes hybrid roles with other behavior clusters
 team support cluster  
 players who typically assist ranged physical attackers  healing  cooperative attacks  etc  
 magic attacker clusters   and   
 players who rely on magic based attacks  as opposed to physical damage in the above clusters
 differ in preference for close  or ranged combat
 miscellaneous clusters   and  
 no clear style preference
 differs in skill  either a novice player or prefers an
all around gameplay style
interestingly  we notice from expert analysis that there
appears to be a hierarchy of clusters  for instance  clusters
  and    fall under the broader magic attacker category 
this suggests that we might consider other clustering models
than k means or dp means  as these methods assign each
observation to only one cluster  we address this further in
section v 

c  numerical results
due to the random initializations  we ran    trials for
each clustering algorithm in order to obtain the best locally
optimal centroids  these optima correspond to    and  
clusters for k means and dp means  respectively  all code
were implemented in matlab and computations executed
on a     ghz intel core i  with   gb ram  figure   shows
an example of the log of distortion values attained over the
range of k values for the k means algorithm ran with   fold cross validation  table i summarizes the results for the
clustering algorithms  the recorded computation times were
averaged over the    trials  and do not include preprocessing
and transforming data into features  etc 
   

log distortion value

   

   

 

   

   

   

 

 

 

  

  

  

  

  

  

  

e  cluster visualization with pca

  

k

fig    shows the result of applying principal component
analysis  pca  to reduce our feature dimension and visualize
it in three dimensions  notice that the data is clearly clustered
into   distinct groups  suggesting that in higher dimensions
there are probably more clusters  overlaying our    groups
clustering from the k means technique in color  we observe
that they are consistent with the pca results  almost all
points in any k means cluster are in the same pca cluster 

fig     best trial out of     the log distortion values show a local optimum
at k      over the range of   to    clusters  magenta asterisk  

table i
p lay style clustering summary results

k means
dp means

cross val 

param  range

clusters

cpu time

   fold
   fold

k d              
 d                      

  
 

      s
     s

d  cluster interpretation
surprisingly  our consultations with expert  highly ranked
 top      worldwide  lol players corroborated the correctness of the behavior clusters learned by our algorithms 
by checking the centroid values corresponding to each
feature and using information about the frequency of in game
characters used for each cluster  these expert players were
able map each cluster to a specific gameplay type that they
had experienced in game  this suggests that our clustering
were intuitively correct  the mappings determined for the
   clusters k means result are as follows 
 ranged physical attacker clusters       and  
 players who maintain distance from fights while
dealing high damage with long range attacks

fig     visualizing our data with   principal components reveals at least
  distinct clusters  the    clusters k means results are overlaid in color 

 

fiiv  g ame o utcome p rediction
we illustrate the accuracy of game outcome predictors
that use team composition features based on our gameplay
style clusters learned in the previous section  we present our
feature selection  the classification models used to learn our
predictors  and the accuracies for our predictors 

where         and  are the means and covariance of the
gaussian distributions  here  we maximize the log likelihood
of the m samples data
m


y
                d log
p x  i     y  i   i                 

a  feature selection
for our classification algorithms  the features are the two
teams player compositions  associated with each team is a
vector of counts of players that fall into a certain play style
category  which were  say  derived from one of the clustering
algorithms  the feature vector is the concatenation of the
count vectors of teams   and    the labels for each sample
are the win loss indicator for the game  with   corresponding
to a victory and   a loss by team   to team    for instance 
there are   clusters  teams   and   have the count vectors
x    r  and x    r    and team   beats team    the feature
vector label pair would then be

 
x 
 x  y  d
    
x 

the result of maximizing   with respect to the model
parameters is a set of exact analytic equations       which
we compute directly  the derivation of these equations are
simple  and we omit them for brevity 
   support vector machine  assuming that our data are
separable with a large gap  a support vector machine model
posits that the size of the geometric margin between some
observation point and the decision boundary is proportional
to confidence level that the observation is classified correctly  the result of this model is an optimization problem
that seeks the maximum margin separating hyperplane for
our samples 
for our problem  we use    regularization since we are
uncertain about whether our data is linearly separable  e g  
outliers  erroneous data   the resulting problem is solved
using the sequential minimal optimization algorithm     

id 

where x is the feature vector and y is the sample binary
label 

c  evaluation criteria

b  classification models
to obtain the best win loss outcome predictor  we consider
different classification models  to determine the accuracy of
our predictors learned using the various models  we held
out     of our total sample set  over         in total  for
training  and used the held out samples for testing 
   logistic regression  for this model  we use the
bernoulli family of distributions to model the conditional
distribution of winning or losing given the team composition
features  that is  adhering to our notation introduced above 
y j xi   bernoulli     where  is our model parameter and
 d h  x  d      c exp   t x  is our hypothesis  which
is derived from formulating the bernoulli distribution as an
exponential family distribution  to learn our model  we find
a parameter  that maximizes the log likelihood function
m


y
     d log
p y  i   j x  i   i 
   

to evaluate the usefulness of game outcome predictor
models with features based on our learned behavior clusters 
we compare them against a baseline predictor with features
based on the game developers official gameplay classes  as
introduced in section iii  the game developers have grouped
the in game characters into six broad categories  such as
assassin or support  which supposedly reflects the characters
gameplay style  we learn a logistic regression model with
features constructed using these categories and use the    
hold out method for cross validation 
d  results and discussion

to ensure fairness of results  we ran    trials for each
model to determine the predictor accuracies  which are based
on different randomized train and test sets  as with our clustering algorithms  all code were implemented in matlab 
the computations were executed on a     ghz intel core i 
id 
with   gb ram  and the computation times were averaged
m

 



 over the    random trials  again  these times do not include
x
d
y  i  log h x  i   c   y  i   log   h x  i     preprocessing and transforming data into features  etc 
id 
as we observe in table ii  the best predictor learned
   
using our behavior clusters based features uses an svm
where m is the sample set size  we used stochastic gradient model with features derived from our k means clustering 
ascent to efficiently find the optimizer     
this predictor did significantly better      better  than the
   gaussian discriminant analysis  in this model  we as  baseline algorithm on the test sets  and the other predictors
sume that the input features x are continuous valued random were also competitiveall were only less accurate by a tiny
variables and model p  x j y  using a multivariate normal percentage 
distribution  in other words  we use a generative learning
other than illustrating the relatively high accuracy of our
model  in our case 
team composition based outcome prediction approach  this
y  bernoulli   
    result also implies that our behavior clusters learned had
more descriptive power than the official game developers
x j y d    n        
   
version  this indirectly concurs with what we have shown
x j y d    n          
    from our clustering models  the official gameplay style
 

fitable ii
o utcome prediction summary results

lr
gda
svm

train acc 

k means
test acc 

cpu time

train acc 

      
      
      

      
      
      

    s
    s
     s

      
      
      

    h  e  spotts  evaluating the effects of team composition and performance environment on team performance  journal of behavioral and
applied management       
    k  hellerstedt and h  e  aldrich  the impact of initial team composition and performance on team dynamics and survival  academy of
management  p          
    b  kulis and m  i  jordan  revisiting k means  new algorithms via
bayesian nonparametrics  in proceedings of the   th international
conference on machine learning  j  langford and j  pineau  eds 
omnipress  jun       
    p  tassi  riots league of legends reveals astonishing    million
daily players     million monthly  forbes       
    s 
ford 
league
of
legends 
marc
merrill
q a 
warcry
network 
     
 online  
available  http   www warcry com articles view interviews      league oflegends marc merrill q a
    riot games  inc   riot games api         online   available 
https   developer riotgames com 
     a  ng  cs      machine learning course notes         online  
available  http   cs    stanford edu materials html
     t  broderick  b  kulis  and m  i  jordan  mad bayes  mapbased asymptotic derivations from bayes  in proceedings of the
  th international conference on machine learning  s  dasgupta and
d  mcallester  eds  omnipress  jun       

dp means
test acc  cpu time
      
      
      

    s
    s
     s

categories that were used for the baseline algorithm do not
necessarily correspond to the behaviors of actual players in
games 
overall  our results validate our framework of first clustering players by their gameplay style and then using team
composition features based on these learned styles to predict
team performance  and since our target game is a representative title for games of the same type  i e   team based
role playing games   we expect this framework to also be
effective and generalizable to other multiplayer games 
v  c onclusion and e xtensions
in this brief  we have presented an algorithmic framework
for outcome prediction  by learning in game player behavior
categories through clustering and using them in features for
game outcome predictors based on classification models 
we are able to determine wins and losses with over    
accuracy for our target game  this approach could be used
to evaluate how team compositions can affect performance
in games other than the one we have considered 
future work will include adding time dependent player
statistics features  unlike the overall game statistics we
used  these timed statistics might give an additional layer
of descriptive power  allowing the model to differentiate
between clusters based on how players behave early and
later in the game  this might lead to a better features for a
more accurate team composition based win loss predictor  as
another extension  we could also consider different clustering
models  such as one that captures the ostensibly hierarchical
clustering seen in the expert analysis of the k means results 
for instance  the bp means model described in      is
designed to capture such hierarchical clustering relationships 
acknowledgments
we thank professor andrew ng and the course staff for
motivating and giving feedback for our work  we are also
grateful to the lol expert players who helped with our
cluster analysis 
r eferences
    e  tomai  r  salazar  and r  flores  simulating aggregate player
behavior with learning behavior trees  in proceedings of the   nd
annual conference on behavior representation in modeling and
simulation  w  g  kennedy  d  reitter  and r  s  amant  eds  brims
society  jul       
    w  s  bainbridge  the scientific research potential of virtual worlds 
science  vol       pp               
    m  d  dickey  three dimensional virtual worlds and distance learning  two case studies of active worlds as a medium for distance
education  british journal of educational technology  vol      pp 
             

 

fi