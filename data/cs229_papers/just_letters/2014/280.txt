arrhythmia classification for heart attack prediction
michelle jin
introduction
proper classification of heart abnormalities
can lead to significant improvements in
predictions of heart failures  the variety of
patient attributes that factor into arrhythmia
classification and the number of resulting
arrhythmia classes make this a complex
problem to solve  here  i use ucis arrhythmia
database    and apply a supervised learning
algorithm  implemented in matlab  to train and
classify test data into    separate classes of
heart conditions 
the dataset is contains     patients and    
features per patient  the features include patient
attributes such as age  height  weight  and
gender as well as quantized ecg data such as
the amplitude and width of the r  q  and s
waves  the patients are separated into   
different classes  including one class of normal 
   classes of various heart conditions  coronary
heart disease  av block  etc    and one class of
other  a small fraction of features are missing in
the original dataset as well 
i implemented a random forests training
algorithm combined with feature selection and
data sampling techniques for maximum
classification accuracy across all    classes  in
general  the work presented here used     of
the samples for training and     of the samples
for testing 
data preprocessing
there are     missing attributes in the
dataset as denoted by    this corresponds to
      of the overall dataset 
i tried several different methods to fill in this
missing data  these methods included replacing
missing features with  s as well as the mean of
each particular missing feature across all
patients  the difference between each method
was not observably significant in the final
classification results  as the missing attributes
did not represent a large portion of the data 

finally  the method i went with was to fill in
each missing attribute with the corresponding
feature of the patients nearest neighbor by
euclidean distance  this seemed the most
reasonable  although its results on accuracy
were not significant 
feature selection
i implemented forward search feature
selection based strictly on the correlation
between each feature and the overall
classification accuracy using a random forests
approach  my feature selection algorithm used
   fold cross validation to select the best    
features out of the     presented  for feature
selection purposes  accuracy was described as
the number of misclassified patients across all
classes the total number of patients 
as shown in figure    overall classification
error rate decreased significantly up to the   th
feature added  after which there was no
significant improvement with additional
features 

fig     number of features used versus test error rate 
error rate no longer decreases with additional features
after about the   th feature added 

in this project  i did not find it to be the case
that as the number of features added increased 
the training error increased while test error
decreased  rather  training and test error
plateaued after around the   th feature  both the

fitesting and training error rate hovered around
    overall misclassifications  signifying that
this was not a variance bias issue 
here  reducing the number of features used
through feature selection is beneficial not
because of increased accuracy  but because of
decreased processing time  which would have
greater implications if similar prediction
techniques was applied in real time  as long as
we have the    best features  we can be assured
that accuracy results will not significantly
improve with additional features 
test and training data sampling
several traits of the original dataset heavily
limit classification accuracy  out of the    
patients in the dataset  over half of them are in
class    normal   and several classes have five
or fewer samples in them  the unbalanced
nature of the dataset makes it much more likely
that underrepresented classes are misclassified 
in order to counter this effect  i preprocess the
data through both sampling and skewing before
any training and testing is done 
sampling is done by taking the original
distribution and resampling at random with
replacement until i draw the same number of
samples as the original dataset  random
sampling with replacement has the effect of
redistributing the skew of the data to create
more balanced classes  although better than the
original dataset  the sampled data still has
underrepresented classes  next  i skew the data
by replicating each class that contains less than
   samples  thus  all classes that contain less
than    patients have each of those patients
presented twice in the dataset after skewing 
the class distribution of the dataset  from the
original distribution  through sampling  and
finally through skewing  is presented in table   
table    distribution of data  original  after sampling 
and after skewing 

class labels
  
  

normal
ischemic changes
 coronary artery
disease 

origi
nal
   
  

sam
pled
   
  

ske
wed
   
  

  
  
  
  
  
  
  
  
  
  
  
  
  
  

old anterior
myocardial
infraction
old inferior
myocardial
infraction
sinus tachycardy
sinus bradycardy
ventricular
premature
contraction  pvc 
supraventricular
premature
contraction
left bundle branch
block
right bundle
branch block
   degree av block
   degree av block
   degree av block
left ventricule
hypertrophy
atrial fibrillation or
flutter
others

  

 

  

  

  

  

  
  
 

  
  
 

  
  
  

 

 

 

 

 

  

  

  

  

 
 
 
 

 
 
 
 

 
 
 
  

 

 

  

  

  

  

the result on overall accuracy of this data
manipulation is a decrease in the number of
misclassifications by      
next  i separate the training data from testing
data  following sampling and skewing  i
randomly sample     of the skewed data
without replacement for training purposes     
training is high enough that classification error
rate remains low and low enough that there is
enough test data left to represent all the classes 
then  every sample in the original dataset that is
not part of the training class is selected for
testing 
note that after sampling and skewing  the
data will have repeats  this only affects the
training  and the data selected for training will
include repeats so that underrepresented classes
in the original dataset get enough representation
in training  every sample used for testing is
unique 

fitesting error decreases as i increase the
percentage of data points used for training  the
result is shown in figure    elsewhere in this
report  percentage used for training remains
constant at     

fig     overall classification error rate on test samples
vs  percentage of data used for training  this runs on a
random forests algorithm using the top    features 

training model
the multi class nature of this dataset calls
for classification using a random forests
algorithm  this algorithm contains multiple
decision trees and selects the average of the all
the trees classification results as the final
classifier output  the overall classification error
versus the number of decision trees used is
produced in figure    this report uses the
results from    trees 

the dataset is multi class  and it contains
more
features
than
patient
samples 
furthermore  many of these    classes contain
small numbers of patients  and patient attributes
are often highly correlated  with these features 
classification through other algorithms  such as
svm  nave bayes  and logistic regression did
not produce as great results as the random
forests classifier did  i explored both an svm
approach as well as a logistic regression
approach  for differentiating between normal
and all the other unhealthy classes   but overall
misclassification error rate for those models
hovered around           compared to the
    error rate of random forests 
the ensemble of decision trees created from
the training data is then used to classify the test
data 
results
defining overall classification accuracy as
simply 
    
   
i found that overall accuracy hovers around
    using    features and     training data
across multiple runs  however  because the
classes are uneven  overall classification
accuracy as defined above may not be the best
indicator of classification results 
in order to get a better understanding of
accuracy  i also find the number of true
positives  tp   true negatives  tn   false
positives  fp   and false negatives  fn  per
class  using these  i calculated the per class
precision  recall  f score  and acc  redefined  
they are described as follows 
  

fig     number of trees versus overall classification
error

       
     

 where p and n are the total number of positives
and negatives per class 
precision  recall  and fscore are by the
traditional definitions 

fi  

  

  

 
     

are classified as class   rather than class      
vs     a large portion of misclassifications also
all have the similarity that they are classified as
  when the actual target class is something else 

 
     

        
     

the results are summarized in table    the
average of each is the per class result multiplied
by the number of test samples for that class over
the total number of test samples 
table    accuracy results by class

class
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
avg

acc
      
      
      
      
      
      
      
      
      
      
nan
nan
nan
      
      
      
      

precision recall
             
             
             
             
             
             
             
             
             
             
nan
nan
nan
nan
nan
nan
             
             
             
             

f score
      
      
      
      
      
      
      
      
      
      
nan
nan
nan
      
      
      
      

figure   shows the confusion matrix of how the
classes are being misclassified 
discussion
while the majority of classes have high
accuracy scores  the lowest accuracy scores
occur in classes       and     these three classes
all have low recall scores  meaning that out of
all the patients who actually have the disease as
marked by       and     this algorithm has
trouble classifying them as their respective
classes  in fact  out of the   test cases that are in
class    for the confusion matrix above  more

fig     confusion matrix  for each class  this shows
what the test sample actually is  target class  versus
what it is being classified as  output class   proper
classifications are shown in the diagonal  and the
overall accuracy rate is shown on the bottom right hand
corner 

conclusions
for this particular dataset  a random forests
training
algorithm
provides
the
best
classification results across all    classes  due
to the skewed nature of the original dataset 
resampling and re skewing the data to give
more weight to underrepresented classes during
training significantly increased all overall
accuracy metrics 
the accuracy scores presented here are
comparable to other learning algorithms on the
same dataset as presented in literature  typical
accuracy metrics range between            as
summarized in ozcifts paper     
future work
there are several things that could be done as
future work 

fifirst  out of the     features presented  many
are correlated  therefore  it is possible to
explore dimensionality reduction algorithms 
although in this case  the number of training
samples exceeded the number of features
present  however  there are other things that
could be done because much of the data is
correlated  for example  rather than viewing
features like height and weight as separate
attributes  it might be reasonable to combine
them and present the pair as a weight height
ratio  similar things could also be done with the
ecg data 
second  although not explored in this project 
a cost matrix is also something that could be
very useful to a problem like arrhythmia
classification  the cost of misclassifying a sick
patient as healthy  or misclassifying a sick
patient as having an incorrect type of sickness 
might be greater than the cost of misclassifying
a healthy individual as sick  the medical
implications
of
various
types
of
misclassifications should be taken into account
when designing such learning algorithms 
furthermore  implementing a cost matrix might
also prove to be beneficial in improving
accuracy  as placing a greater cost on often
misclassified classes could improve accuracy
results for those classes 
references
    bache  k    lichman  m          uci
machine learning repository
 http   archive ics uci edu ml   irvine  ca 
university of california  school of information
and computer science 
    akin ozcift   random forests ensemble
classifier trained with data resampling strategy
to improve cardiac arrhythmia diagnosis  
computers in biology and medicine          
note
this work was done partly in collaboration with
lee tanenbaum  we submitted the project
proposal and mid project report together 
however  because we each largely worked on
our own standalone pieces of code and found it

too hard to integrate in the end  we decided to
write separate final reports  i have previously
emailed the cs    staff about this 

fi