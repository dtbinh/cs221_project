vector based sentiment analysis of movie reviews
ian roberts and lisa yan
 iroberts  yanlisa  stanford edu

   most positive 
   positive 
   neutral 
   negative 
   most negative 

abstract
sentiment analysis is an important step towards comprehension in natural language processing  movie reviews are a
convenient source of highly polarized sentences for use in
sentiment analysis 
achieving a high level of accuracy in the sign of nonneutral sentiment is a challenge  when the problem is expanded to choosing one of   sentiment levels the problem
becomes significantly harder  among the models that we
tested  softmax regression with a bag of phrases feature set
provided the best   bin error rate  while svm with the same
bag of phrases features and a simple word sentiment sum
model provided the best error rate on sign prediction 

  

figure    rating sentence sentiment on a   point scale 

sentences

elements

training set
test set
    
    
dictionary
phrases
unique words
      
     

table    stanford sentiment analysis dataset 

introduction

sis website which split the sentences into a training set and
test set and provided a dictionary of sub phrases and unique
words  table     all phrases  and words  have a sentiment
label as well  which was determined in the original dataset
via amazon mechanical turk  sentiment is labeled on a  
point scale of    most negative  to    most positive   with  
being neutral  a distribution of the sentence sentiment labels
is in figure   
the dataset also includes a sentiment labeled partitioning
of each sentence on a parse tree  recursive node recombination can therefore be trained at all levels rather than just with
the root sentiment 

we investigate sentence sentiment using the pang and lee
dataset as annotated by socher  et al       sentiment analysis
research focuses on understanding the positive or negative
tone of a sentence based on sentence syntax  structure  and
content  previous research used a tree based model to label
sentence sentiment on a scale of   points  our project takes a
different approach of abstracting the sentence as a vector and
apply vector classification schemes  we explore two components  first  we would like to analyze the use of different sentence representations  such as bag of words  word sentiment
location  negation  etc   and abstract them into a set of features  second  we would like to classify sentence sentiment
using this set of features and compare the effectiveness of
different models  while sentiment polarity was analyzed in
a previous years project  we would like to explore   degrees
of sentiment labeling  figure    
we chose to investigate sentiment of movie reviews which
could be compared to numeric movie ratings  we looked
at a variety of models and feature types to attempt to capture the context important for accurate sentiment decoding
of the phrases of a sentence  while a tree based feature set
by socher et al      exists  we also wanted to explore how
linear feature vectors would fare for sentence sentiment classification  

  

it was a breathtaking movie 
it was a good movie 
it was a movie 
it was a bad movie 
it was a terrible movie 

  
   

approach
features

in figure   we examine the distribution of individual word
sentiments within sentences with each level of overall sentiment  the distributions are nearly identical with highly positive words showing up in highly negative sentences just as
often as in highly positive ones  this provides a clear indication that phrases and syntax are key to sentence sentiment analysis  while the sentiments of individual words and
phrases were labeled in our dataset the lack of correlation
between word sentiment and sentence sentiment led us to
ignore this labeling for some of our features 
we now overview our vector based features  where we
represent the ith sentence in our dataset as a vector x i  over

dataset
we used the datasets from stanfords sentiment analy 

fifeature name
bag of words
bag of phrases
word sentiment counts  wsc 

domain of x i 
       vw  
       v 
z 

word features  wf 

z ni

x j  i 
   jth word in ith sentence 
   jth phrase in ith sentence 
  words with sentiment j in ith sentence
word index in dictionary v of jth word in ith sentence
tf idf of jth word in ith sentence
sentiment of jth word in ith sentence

 a  summary table of vector based features 

model name
sentiment sum
naive bayes
k nearest neighbors
softmax regression
svm
tree prediction

bag of
words
x
x
x
x

bag of
phrases

wsc
x
x
x
x
x

x
x
x
x

wf

dictionary
indices

negation

tree

x
x
x
x
x
x

x

 b  summary table of models 
table    summary of features and models 

figure    histogram of sentiment labels for each sentiment label 

figure   

distribution of sentence sentiment labels across

tence  the distribution of word sentiments remaining nearly
constant with varying sentence sentiment as observed in figure   indicates that this is likely to be a poor assumption 
words with features  wf  this feature vector aggregates three different vector sentence representations  the
first is the dictionary index of each word in the sentence 
with the dictionary of words this allows complete reconstruction of the sentence  this means that sentence structure
and context are incorporated  although a linear predictor is
unlikely to be able to predict more than a small portion of the
structure in this representation  the second component is the
term frequency inverse document frequency for each word
in the sentence  this metric provides an indication of the
level of significance of the word within the corpus  the last
component is the sentiment label of each constituent word
of the sentence 

dataset 

some domain  where the length of the sentence is ni words 
th
 i 
and x i 
j is the j element in the feature vector x   our dictionary of words and phrases are vw and v  respectively  a
summary of these features is in table  a 
bag of words  bag of phrases in the bag of words representation a vector of length equal to the dictionary size
is populated with indicators for the presence of each word
within a sentence  this approach takes into account neither
individual word sentiment nor positioning of words  but it is
very simple to implement  the expansion to a bag of phrases
model adds sentence fragments to the model  the sentence
fragments incorporate context and phrasing that were ignored
by the bag of words model  the bag of phrases model is
limited by the level of overlap between phrases used in the
training and test sets 
word sentiment counts  wsc  this model represents a
sentence as a   element vector where each element indicates
the number of sentence words with the corresponding sentiment label  this model assumes that individual word sentiments are correlated with the sentiment of the overall sen 

   

models

the most basic estimation of sentence sentiment comes
from a vector sum of the sentiments of the words in the sentence  shifting the result such that a vector of neutral words
remains neutral the majority vote of non neutral terms determines the estimated sentence sentiment  the conclusion of
 

fifigure   is that this should be a poor estimate of the sentence
sentiment as sentences of all sentiments contain non neutral
words with nearly constant distributions  positive words are
generally not used to buoy the sentiment of sentences with
overall negative sentiment  instead they are generally altered
with control words or used as a contrast to emphasize the
negative sentiment of the sentence  movie reviews in particular make use of flamboyant and sarcastic phrasing to express negative sentiments  the most straightforward set of
control words are inversion of which  not  and the contraction suffix  nt  are typical examples  incorporating negation
in a model building sentence sentiments from word sentiments should improve performance  negation in a sentence
generally alters a sub section of a sentence rather than applying to all words within the sentence  localized negation
is not compatible with linear models and must either be used
with simple models such as vector sum of sentiments or be
introduced as a derived modification to the feature vector before modeling 
most negation has the position of the negating word as a
well defined initial boundary for the extent of the negation 
determining the final extent of the negation is much a difficult problem      we have used the approximation that negation runs until the end of the sentence but also allow multiple
negations to accumulate and continue to flip the sentiment
interpretation 
we used naive bayes  k nearest neighbors  and softmax regression to test both our dictionary feature set and
our word sentiment feature set  for k nearest neighbors 
we set k to be     of the training samples  for each test vector  the model selects the k nearest training vectors  selected
by hamming distance  and outputs the mode  most frequent 
of the training sentiments  we ran softmax regression to converge within a change of       which was      iterations  alpha        on the full phrase dictionary bag of phrases and
    iterations  alpha         on the word sentiment vector 
we implemented these models in matlab 
in the below equations  m is the size of our training set 
and g x i      s describes a hypothesis function g that gives
the ith sentence a sentiment label s  as a function of the feature vector x i   
sentiment sum we used a vector sum of word sentiments
as our baseline model  using the wsc model 

sentiment labels and the most probable label was selected 
qm

 i 
 i 
 i 
j   p x j  g x     s  p g x     s 
 i 
 i 
p g x     s x     p qm

 i 
 i 
 i 
s
j   p x j  g x     s  g x     s 
k nearest neighbors  knn  we used euclidean distance
to find the k closest training samples and returned the most
common sentence sentiment label  and tested trained on all
features 
d x  x i        x  x i      
  i 
 p y
 p y i 

 i 
h  x      p y i 
 p y i 

p y i 


    x i     

    x i     
 

    x i        p 

 j t x i 

j   e
    x i     
    x i     

 t x i  
e   
e t x i  
 t  i  
e  x 
 t  i  
e  x 
 t  i  
e  x

g x i      mode x p   y p     x p    k nearest samples 
softmax regression with l  regularization we tested and
trained softmax regression on all features 
max


m x
 
x

 

  y i    j  log p y i    j x i      

i   j  

x
   p     
  p  

the gradient ascent update equation is as follows 
m
x



x i    y i    j   p y i    j x i        j

i  

svm we used liblinear      to train svm models for our
feature vectors 
tree prediction elements of node recombination matrix
are defined by the average sentiments of nodes in the training
set with child labels corresponding to the indices of the matrix element  negation was included in this model by adding
a negation label to the set of sentiment labels  negation is
primarily right combining and not all trees separate phrases
such that negations occur as the left child of a node so the
negation persists in instances where the negation occurs on
a right child 
pm p
k   nnodes x k    s n   s nle f t     i   s nright     j 
pm p
mi  j  
k   n   s nle f t     i   s nright     j 

  
 
x
g x i     
  jx j  i         

results

the simple baseline model of vector sum of sentiments
provided better results than many of our more expressive
models  this is particularly true for polarity error as shown
in table    test error and train error are determined by correct labeling from the   sentiment labels  polarity error is
determined by the polarity of the predicted sentiment being
correct for non neutral sentences  the expected gain in performance of the vector sum of sentiments method from negation tracking did not show up  there are     sentences that
include negations in our test set of      sentences so the improvement from negation tracking should be small but not

j  

negation tracking detects a negating word and inverts the
sentiment of all subsequent words 
nave bayes  nb  we used bag of words  bag of phrases 
and a modified version of our feature vectors which ignored
the frequency products and word sentiments and instead focused only on dictionary indices of the sentence  our nave
bayes model used a bernoulli event model for each of the  
 

fimodel

features

sentiment sum

wsc
negation
bag of words
bag of phrases
wsc
dictionary indices
bag of words
bag of phrases
wsc
wf
bag of words
bag of phrases
wsc
wf
bag of words
bag of phrases
wsc
wf
tree

nave bayes

knn

softmax

svm

tree prediction

test
error
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

train
error
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

polarity
error
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

figure    test and training error vs  training set size for softmax

regression on bag of phrases 

feature types other than bag of words and the bag of phrases
features provide the best   level test error of all our models 
the training set error for bag of words and bag of phrases is
dramatically lower than the test error rate  the features in
these two scenarios are derived from the words and phrases
present in the training set and many of these are unique in the
dataset  this causes significant overfitting to the training set
but only the portion of these overfit features that also appear
in the test set are realized as overfitting errors 
svm provides similar   level error rates for the different
feature types as softmax regression  the bag of phrases feature set once again provides the best performance although it
is slightly inferior to softmax  the advantage to svm comes
from the significantly lower polarity error  the overfitting of
the bag of phrases feature set is most apparent in svm where
a    training set error rate is attained 
the relatively high polarity error for the best nave bayes
and softmax regression models indicate that these are relatively poor models for general application  when they do
make a mistake on the   level sentiment for a non neutral
word they make a large number of big mistakes as reflected
by their roughly     polarity error rates 
knn provides very poor results for all of the features
tested  the polarity error rate is higher than the   label error rate as the polarity error rate is evaluated on non neutral
sentences only  the high error rate of knn is likely due to
the euclidean distance metric chosen  for high dimension binary vectors such as produced by the bag of words and bag
of phrases models  the distance between sentence vectors is
large and close to randomly distributed 
the bag of phrases feature set provides the best performance for the svm and softmax regression models but it is
not consistent as the error rate with both knn and nave
bayes is near      the reduced feature set of bag of words
provides uniformly inferior performance to bag of phrases 
for svm and softmax regression this difference due to the
context and phrasing that is incorporated by the bag of phrases
model provides a dramatic improvement in test error rate of
at least      wf is much less variable with the training

table    table of results 

insignificant  there are several possible explanations for the
lack of improvement  the first is that our choice to negate
until the end of the sentence is a poor estimate of the proper
negation extent  the other good estimate of the extent of
negation is to negate until the next punctuation mark  but
the benefit of this form of negation tracking is also reported
to be insignificant      another explanation for the poor performance is that negation in sentences from movie reviews is
used in hyperbolic phrases and combined with other rhetorical devices such that the effect of negation tracking alone
is insignificant  the conclusion from either of these explanations is that simple negation tracking does not improve
sentiment labeling 
the nave bayes method provides relatively poor performance for most of our feature vectors that is only slightly
better than a random guess for   bin sentiment accuracy 
evaluating the model on the training set provides dramatically improved results  potentially indicating an overfitting
problem  reducing the training set of phrases to only a set
of words reduces the discrepancy between the training and
test error rates  but also results in overall worse performance 
the doubling of training set error for bag of words compared
to bag of phrases makes it clear that it is longer phrases that
are key to the prediction strength of this naive bayes model 
but training the longer features requires a training set that
shares these longer features with the test set  with a much
larger dataset this method may be able to overcome its lack
of structural awareness  but for this dataset it does not seem
practical beyond use as a baseline for comparing other methods  nave bayes with a feature vector of dictionary indices
provides noticably better   level accuracy than vector sum of
sentiments model but provides a significantly higher polarity
error 
softmax regression provides good performance with all
 

fi  

model used as it never has great performance but it also never
has the worst performance 
we attempted to use principal component analysis  pca 
in order to select the most relevant features from our models that exhibited overfitting  we did not get any benefit from
this which is likely due to the unusual features being unlikely
to appear in the test set 
the learning curve for softmax regression show in figure   shows a large separation between test and training error  the bag of phrases feature set depends heavily on those
phrases that are represented in the training set and the overlap of those phrases with the test set  with a dramatically
larger training set the training and test errors would converge
to some intermediate value  no matter how large the training
set is  however  such a model will be unable to properly decompose a test sentence with new and original phrasing  a
model that groups similar words and then trains their phrasing patterns has a much lower error rate limit and requires
much less training data 
the best literature result provides a       error rate for
sentences for   sentiment labels      our best result of    
is close but also notably below this level 
our initial intention was to compare sentiment analysis
models that used a vector sentence representation to recursive tree recombination models  we were able to conclude
that vector sentence representations are noticeably less expressive in terms of sentence structure and word context 
we thus started looking at applying models to tree reconstruction  the general reconstruction problem is expressed
by training an w w matrix where w is the number of words
in the training set dictionary  w is       in our dataset
which leads to a matrix that is much too large to be well estimated with our set of training sentences  the neural network
based approach introduced by socher et al  appears to be a
very promising way to reduce the recombination problem to
a manageable form      we took an alternate approach by
reducing the feature set of the recombination matrix  the
reduction of the matrix to a set of   sentiment labels plus
a negation label makes the model very similar to the vector
sum of sentiments model and the resulting performance is
also similar 

  

future

if we were to expound on this project  we would try implementing the following list 
 develop additional features for use in tree reconstruction
 explore deep learning for tree reconstruction of sentences as pioneered by socher et al 
 apply classification algorithms to phrases
 add negation tracking to linear models
 find a better distance metric for knn
 build up from a model of word compositions and build
towards sentences rather than decomposing sentences

references
    socher  r   perelygin  a   wu  j  y   chuang  j   manning 
c  d   ng  a  y   and potts  c  recursive deep models for semantic compositionality  empirical methods in natural language processing        
    wiegand  m   balahur  a   roth  b   klakow  d   and montoyo  a  a survey on the role of negation in sentiment analysis 
in proceedings of the workshop on negation and speculation
in natural language processing  july       

conclusion

we found that a bag of phrases feature set with an svm
model provided the best results among vector based sentence
models  while negation tracking did not provide any benefits in our experiments  negation is fundamental to the interpreted sentiment of many of our test sentences  a better
method of handling negation that potentially also accounts
for contrastive sentence structures will certainly improve performance  the additional flexibility of tree based representations appears to be the best future path for sentiment analysis 

 

fi