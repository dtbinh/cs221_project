equation to latex
abhinav rastogi  sevy harris
 arastogi sharris   stanford edu

i 

introduction

copying equations from a pdf file to a latex
document can be time consuming because
there is no easy way to convert the equations in
pdf form back to latex code  this automatic
conversion requires segmentation of characters
from the image  identification of these characters and conversion to latex code  this project
deals with the first two steps of this problem 
we have proposed a novel character segmentation algorithm for printed text and have experimented with some features and classifiers
which classify the segmented characters 

ii 

segmentation

we have made two assumptions for printed
text a  all characters in the image are axis aligned
 b  pixels corresponding to a single character
are connected
the first assumption is good because printed
text is well structured  if the image is not axisaligned  it can be corrected using convex hull
detection if the rotation is less than     but
we have assumed that this rotation is absent
from our input images  the second assumption holds true for the most of the characters in
printed text  few characters like i  j    etc 
violate this assumption but they can be dealt
with separately 
our segmentation algorithm is based on
the intuition that if we sum along the rows
of an axis aligned image  the rows containing
characters will give a lower sum than the rows
containing blank pixels  let us illustrate our
algorithm  let i be an m  n image  m rows 
n columns  containing multiple equations 

figure    the steps involved in segmentation of characters from an image of equation  order  top to
bottom 

our segmentation algorithm proceeds in
the following steps    threshold the image apply a threshold
of     to i to obtain a binary image b
containing   in blank pixels and   in character pixels  remove or add blank pixels
on the border such that the minimum
distance of any character pixel from the
image border is    pixels 
   perform binary erosion we use a      
horizontal mask to perform binary erosion on i   this spreads the character
pixels along the rows so that when we
 

fi  

  

  

  

  

sum up the rows of the image  we get a
substantial difference between the sums
corresponding to blank rows and rows
containing characters  these images are
solely generated for the purpose of obtaining row split points 
obtain blank rows sum the horizontally
eroded image along rows to get a list
of m numbers  r    r          rm   where ri  
nj   i i  j   the set  i  ri        max ri   
corresponds to the set of blank rows 
split text lines as expected  many blank
rows occur next to each other  we take
the mid point of each contiguous stretch
and split the image into many images 
each containing one row of text  let
m    m          m p be the mid points of contiguous stretches of blank columns  the
images i  mi   mi        are the images containing a row of text for i     to p    
split text vertically we perform steps    
for the image of each line using a vertical mask instead of horizontal and column sums instead of row sums to obtain
column splits and divide each text row
image further 
obtain segmented characters most of
the characters are segmented after step
  but if the text contains characters like
i or subscripts in   we might not have
segmented each character  so  if the image obtained after step   has more than  
connected component  steps     are again
repeated 
scale and center each obtained image is
then centered by addition or removal of
blank pixels on the border such that the
minimum distance of any character pixel
from the image border is   pixels 

iii 

characters and labels each image according to
the its character name obtained from the txt
file  the above procedure can be used to obtain
as much data as we need with very little effort 
for the purpose of this project  we have focused on the identification of upper and lower
case roman alphabets and digits  our dataset
consists of   images of each of these characters
and contains     images in total 

iv 

features

feature selection becomes a critical part of
this problem since it involves a large number
of classes and the size of each class is much
smaller than the number of classes  the following feature mappings map the image of
a character to a vector in a multidimensional
euclidean space  the learning algorithms are
then trained and tested on those vectors  we
tested different models on these three sets of
features i  average pixel intensity features  a  the
whole image is divided into a   x   grid
and the average pixel intensity in each
grid is calculated  the feature vector is of
size    x  and is obtained by concatenating the columns of the   x   image 
 ii  neighborhood pattern features  b  the
pattern formed by the adjacent pixels
seems to be an important cue in the identification of a digit  however  average
pixel intensity features do not take the
pattern formed by neighboring pixels into
account  if we consider a      neighborhood of a pixel  there are          possible patterns that can be formed by the
pixels in this neighborhood  we assign
a number to each such pattern  under
this feature mapping  we first convert the
image into a        image as described
above  then each non border pixel  which
are              in number are assigned
the number corresponding to the pattern
formed by its      neighborhood  the
feature vector of size        is obtained
by concatenating the numbers assigned
to each of the non border pixels in the

dataset

we wrote a python script which takes a txt file
as input and and substitutes its contents in a
tex file  a bash script then compiles the tex file
to generate the pdf document  converts the pdf
to an image  runs our segmentation algorithm
on the obtained image to segment the different
 

fi       image 
 iii  discrete fourier transform features  c 
the fourier transform captures the trends
in relative patterns and is not as susceptible to noise as the neighborhood pattern
features  the feature vector is obtained by
taking the dft of the   x   average pixel
intensity image  the real and imaginary
parts of the dft coefficients are then concatenated to form a        feature vector 

we classify the input using all of these
classifiers and the class which gets the majority vote is picked to be our predicted
class 
 iii  support vector machine svm is a fairly
good choice if we assume that the feature
space is linearly separable  this is not
intuitively clear as our feature space has
a high dimension  nevertheless  as previously mentioned  our classes do not have
a large variability and hence we expect
classes to be linearly separable pairwise 
however  another issue is that our feature space has far more dimensions than
the number of data points and our data
points are close to each other  svm  or
any linear classifier  may pose the danger
of overfitting  for this reason  we did not
use polynomial or rbf kernels for svm
because it further increases the effective
dimensionality for the feature space  the
objective function of or algorithm is

figure     i  original image extracted from text  ii 
       image with average pixel intensities
 iii  absolute value of real part dft coefficients and  iv  absolute value of imaginary
part dft coefficients  order  left to right 

v 

models

n
 
min w t w   c   i
w b   
i   

we employed the multiclass version of the following models to classify the characters  the
training and test error results for these models
are shown in the results section 
 i  naive bayes we chose naive bayes as a
baseline model so that we could get a
rough idea of the difficulty of the task 
we trained a naive bayes model using
the average pixel intensity features and
neighborhood pattern features 
 ii  linear discriminant analysis this
model assumes that the conditional distribution of the features given the class is
gaussian  this assumption is not explicitly true for our dataset and all classes
having the same covariance matrix does
not seem to be a good assumption  nevertheless  we expected a fairly good result
because much variability is not present in
our class  for the multiclass formulation
of lda  we used a one vs one approach 
this involves training a classifier for each
pairwise combination of classes  so  if
the number of classes is k then we train
k  k       classifiers  during prediction 

subject to yi  w t   xi     b       i
where  i    for i            n
our model uses a one vs one approach
for the multiclass formulation of svm as
described previously 
 iv  random forest this model can perform
well given large feature sets because it
combines the predictions of various decision trees to build a more robust classifier  while constructing new decision
trees  this method uses a random subset
of features  this helps us to get rid of
spurious features and might improve the
robustness of our estimate  our random
forest model makes use of id  algorithm
for training decision trees and uses the
gini measure for calculating the goodness
of a split criteria  the gini impurity measure is defined as
gini  xm    

 pmk     pmk  
k

 

fiwhere pmk is the fraction of times an element of class k occurs in a split xm of set
x  gini approximates the entropy function and hence our decision tree approximates a sequence of split criteria that
decrease the entropy of the final partition  after trainig numerous decision
trees  our model combines them using
the adaboost algorithm 

vi 

they perform worse  on further deliberation 
we feel that these features fail due to a similar reason  a slight shift in the image might
severely affect the feature vector  moreover 
the effect of noise is more pronounced in this
feature because a noisy pixel will considerably
change up to   components of the feature vector  these components correspond to the noisy
pixel and its neighbors 
it is tough to visualize the exact correspondence between a dft feature and the image 
hence  we had a neutral expectation from this
feature mapping before we began working on
it  as can be seen  these features give a considerably better result than other features  our
explanation for this observation is that dft
features capture the spatial periodicities of various pixels  dft can be thought of as averaging
after multiplication by sinusoids of different angular frequencies which are integral fractions
of    due to the averaging operation  the dft
features are robust to noise  further  a shift in
the image corresponds to the change in phase
of the dft coefficients and hence the feature
vectors are not affected much 
as far as models are concerned  we didnt
expect a good result from our baseline model 
which was a multiclass naive bayes classifier 
this is because nb assumes that the pixel intensities are independent  which doesnt seem
to be a good assumption  the lda classifier
works for our data because we have very little variability within each class and hence the
assumption that all classes share the same covariance matrix doesnt have much effect on
the accuracy of our algorithm if the classes are
far apart in the feature space  which is true for
most of the classes 
the random forest model is more robust
and helps in decreasing the variance of the classifier because it uses a set of decision trees to
make its decision  since we pick up a random
subset of features in the process of training
the decision trees  we automatically filter out
good features which affect our decision  our
intuition is validated by the fact that rf does
better than svm when we use an inferior set
of features  features a and b  because of its

results

we experimented with various combinations
of features and models described above  the
training and test results are as follows  the abbreviations for feature names have been given
in the section on features  the errors are reported as the percentage of data misclassified 
the training data consists for     images and
the test data consists of     images 
feature
a
b
             
             
             
             

model
nb
lda
svm
rf

c
   
   
   

table    training error of feature model combination

model
nb
lda
svm
rf

feature
a
b
             
             
             
             

c
      
      
      

table    test error of feature model combination

vii 

discussion

as expected  the average pixel intensities fail to
give a good result because a slight shift in the
image might lead to a different feature vector
altogether  we expected neighborhood pixel
pattern features to work better than average
pixel features but it was surprising to find that
 

fiability to discard irrelevant features  however 
when we have a better set of features  feature
c   its performance is close to that of svm 
svm and dft features was the best modelfeature combination we found  on test data 
our model misclassifies   out of     images 
the errors involve misclassification of     
and   as o  t and a respectively  the confused characters are structurally similar and
hence the confusion is plausible 

viii 

lots of different classes are present 
another interesting but non machine learning aspect of this problem which we have not
considered in this project is the generation of
latex commands after segmentation and classification of text 

references

future work

classification of printed characters is a tough
task  close to perfect accuracy is desirable in
order to build a system for converting equations to latex commands  we have only
worked on a subset of characters in this project 
if one were to include greek alphabets too  the
error would increase because of presence of
similar characters like a and   b and 
etc 
while doing a literature survey  we found
that neural networks give a good result for
handwritten digits  it would be interesting to
explore how they work on printed text when

 

   

t  mitchell  machine learning  a guide to
current research  springer        pp     

   

a  ng   cs     lecture notes  support
vector
machines  
 online 
cs    stanford edu notes

   

e  brown   character recognition by
feature point extraction    online  
www ccs neu edu home feneric

   

mahmoud  s a   mahmoud  a s    arabic character recognition using modified
fourier spectrum  mfs    geometric modeling and imaging   new trends        
vol   no   pp                aug      

   

scikit learn  a machine learning library
for python  online  scikitlearn org

fi