what are people saying about net neutrality 
adisonwongkar
 adison stanford edu 

christophwertz
 cwertz stanford edu 

introduction
the issue of net neutrality has recently made it into the headlines  the fcc has established an open
inbox where people can submit their comments on net neutrality and has made the dataset publicly
available  given the          individual comments in thedataset itbecomesanimmensechallengeto
understand the major topics addressed by what people are saying and to be able to quickly group
comments with similar main ideas together  this project aims to do unsupervised clustering and topic
modeling to effectively learn the main ideas of what people are saying in their comments  the main
challenge in performing such analysis is that the textual comments are often redundant and may use
variation of terminologies to describe the same concept  our goal is to partition these unlabeled
examples into clusters and discover natural categories in an unsupervised manner using lda  topic
alignment  f  measure  and perplexity evaluation are used to diagnose and optimize our choice of
parameters 

dataset  features  and preprocessing
we use the fcc published dataset fcc ecfs  which includes comments entered in ecfs  electronic
comment filing system  before    july       the datasetcontains       documents eachofwhich
contains id  unique id of the filing  and text  main body of the comments   along with other metadata 
weperformedbasicdatacleaningtoremovenonreadableartifactsthatcomefromocrornoiseintext
extractions from attachments  like  ppt   data cleaning is done by      normalizing accented terms     
dropping illegible artifacts described above  data preprocessing and tokenizing is done by     
normalizing all terms to lowercase      using english tokenization rule      filtering out terms w     
characters      removing common english stop words  and     normalizing spelling variations on some
important terms such as isp  paytoplay  commissioner chairman tom wheeler  common
carriers etc 

topic modeling
lda  latent dirichlet allocation  blei       is a generative probabilistic model forcollectionsofdiscretedata
such as text corpora  it modelsdocumentsasarandommixoflatenttopics whichischaracterizedbya
distribution over terms  and infers latent topic structure that is most likely to generate the observed
corpora  we use smoothed lda that assumesthefollowinggenerativeprocessforeachdocumentwin
corpus d      choose n   poisson          choose     dir         choose   dir        foreachof
thenwordswn    a chooseatopiczn multinomial        b chooseawordwnfromp wn zn     

we usestanfordtopicmodelingtoolboxv     tmt toperformldatrainingandinferringonourdataset 
unless mentioned specifically  we use the defaulttopic termsmoothing     andfilteringoutx   
most common terms  and for inference  we usegibbssamplermethodwith    maxiterations atthe
endofwhichweobservedconvergenceasevidencedbystabilizedlogprobabilityestimates  

result diagnostics
choosing the parameter k  number of latent topics  is extremely critical  as is x  number of most
commontermsfilteredout  weusevariousdiagnosticstofindtheoptimalchoicesofkandx 
 

fitopical alignment
to evaluate the fitness of our parameters  weapplytopicalalignmenttechniquesimilartochuangetal 
 chuang      
 which calculates matching likelihoods for topicconcept pairs  where the concepts are
identified by human expert asreference  butduetoourlownumberofreferenceconceptscomparedto
k  number of latent topics  wecalculatethematchinglikelihoodofconcepttermstotopicsandcompute
resolved  missed  repeated as the probability that a concept term appears  in one or more topic   is
missing  in all topics   and is repeated  in two or more topics   and similarly  we compute fusedasthe
probability of two terms from separate concepts appearing in the same topic  the repeated   fused
value is a proxy of how misaligned are the reference concepts with the discovered topics  we used
expert reference concepts published by sunlight foundation sunlight  below  for a total of   concepts and
  conceptterms whichweexpressasregex  asshownbelow 

concept 
slowlane s  
fastlane s  
paytoplay
wealthy
divide
netflix

concept 
common
commoncarrier s  
classif y ying ied 
reclassif y ying ied 
authority

concept 
important ly  
vital ly  
economy
essential
resource s  
cornerstone

concept 
work
competition
startup s  
kill s  
barrier s 
entry

concept 
access
choice
entertainment
fee s  
content
extort
extract

concept 
monopoly
competition
comcast
verizon
warner


we performed both line search with k         and grid search with x                 andk        
and plot the topical  mis alignment graphs  from line search  we see the rise of repeated topics with
larger k  especially k     and the resolved retrieval rate is about     at k     from grid search  we
observebetterperformance relativelylowermisalignment forx       fork    




 

fi

concept terms retrieval  f  
f  score  the weightedharmonicmeanofprecisionandrecall isoftenusedinirtomeasuredocument
classification performance  we evaluated how well the terms in our topics perform to retrieve the
reference concept terms  in particular we observe the f scoreforvariouschoicesofk        withour
default parameters x    and term concept smoothing       in computing precision and recall at i  we
considered the retrieved set at i to be the union of top i terms in all discovered topics  we found that
k           performs better compared to larger choices of k  even though we are considering
proportionallylargerretrievedtermswithlargerk 



perplexity evaluation
perplexity is a way of evaluating topic model in nlp  we perform perplexity analysis by      randomly
splitting the dataset into      training docs  for training lda model   and     holdout docs  for
evaluating perplexity on unseen data      finding parameters that minimize the models perplexity on
heldout data  lower perplexity is seen as a measure of goodness of fit for lda parameters based on
the heldouttestdata perplexityscoreoneachdocumentisdeterminedby    splittingthedocumentin
half      estimating perdocument topicdistributiononthewordsinthefirsthalfofthedocument and   
computing the surprise factor  i e  the number of equiprobable word choices  on average  of
 

fiencountering words in the second half of the document  more formally perplexity is defined below 
assuming the test documents dtestcontainsmdocuments eachofwhichcontainswordswdforatotalof
ndwords thep wd isestimatedfromdirichletdistributionlearnedfromdtrain 

below is the perplexity score grid search with x                 and k          we see that x  
consistently produced lowest perplexity  followed by x     the lowest perplexity seems to be around
k    



discussion
from all the diagnostics above  we see that the optimal parameters would be around k        and
x        and after applying our human judgment to the results  we settled on k     x     and default
topic term smoothing       as our chosen parameters  this agrees with results we see in perplexity
evaluation where perplexity is at minimum around k     choosing x    also made the most sense
because if we remove no terms  the most frequent terms that virtually exist in all documents such as
net neutrality  fcc  and internet would be repeated in most of the topics as one of the top terms 
on the other hand  if we remove too many terms  we would lose the most important terms that define
the topics  below is the summary of the discovered topics  we name our topic titles  and list of its top
keywords collapsingsimilartopicsanddiscardingtermswethinkarejunk 

reclassifyispsas
commoncarriers

economicimpact

objectingtoideaof objectingtoideaof internetasan
fast slowlane
paytoplay
essentialfreedom

commoncarriers
servicebroadband
telecommunications
reclassifypayfaster
actcommunications
rulescontentopen
freenew


usechoice
businessspeed
servicesslow
destroyable
economic
experiencelevel
playingfield
importantstrong

utilitypublictom
wheelerservice
commissionerstime
lanesprivatedeclare
economylifelive
modernwantfast
allowslowlanes
telecommunications
streetfree
broadband

 

importantservices
newbetter
paytoplay
innovativeprinciple
succeedlivetreat
equallytravels
worriesdatadear
subscribers
protectopenrule
principlescancer

companiespeople
freeaccessservice
likeopenpaycable
justdongovernment
contentinformation
freedom


ficommission
communications
federalopenrules

commissioners
telecommunications
proposedauthority
urgeservice

conclusions
discovering latent topics in a large text corpora  especially in an unsupervised manner  without label  
requires significant subjective manual analysis  lda is useful in uncovering the most likely latent topic
structure  but its usefulness is largely dependent on choosing the right parameters  in this project we
performed automated diagnostics with line and grid search on k and x  we compared the diagnostics
from the perspectives of topical alignment  concept retrieval f  score  a popular ir method   and
perplexity  the probabilistic surprise factor  apopularnlpmethod  usingallthreediagnosticshelpus
to give a more complete evaluation on how the parameters impact the lda performance  while there
are minor variationsintheresults wefoundthattheparameteroptimizationisgenerallyeffectiveandall
three diagnostics pointed to the same range of k             and x         being optimal  it would be
interesting to perform a comparative analysis with datasets with different topic structures or within a
supervised labelleddataset 

future
thereareafewtasksthatcouldbelogicalnextstepstothisproject 
   diagnosing topic termsmoothingparameters throughgridsearchandtopicalalignment chuang
et al  chuang       observed that small changes in smoothing parameters can significantly alter the
ratioofresolvedandfused 
   exploring and extending current approaches to a more principled and automated unsupervised
way to discern junk topics from legitimate ones  and to rank topic significance using topic
significance ranking  tsr  alsumait        in many cases an increase in junk topics is an indication
ofexcesslatenttopics sothisisveryusefulinformationtohave 
   applying hierarchical lda  hlda   a nonparametric topic model that can select the number of
latent topics as part of the model training procedure  and comparingitwithourchoiceofk note
howeverthathldastillrequirestuningofitssmoothingparameters 

acknowledgment
the authors would like to thank dr  andrew ng and cs    teaching staff for the great lectures on
machine learning  as well as dr  dan jurafsky for the project idea  thediscussions andthefeedbacks
hegaveatvarioustimesduringtheproject 


references
 blei     
bleietal  latentdirichletallocation journalofmachinelearningresearch      vol   
 alsumait      alsumaitetal  topicsignificancerankingofldagenerativemodels machinelearningand
knowledgediscoveryindatabases lecturenotesincomputersciencevolume          
 chuang      chuangetal  topicmodeldiagnostics assessingdomainrelevanceviatopicalalignment icml 
     
 fccecfs 
fccelectroniccommentfilingsystemhttp   www fcc gov files ecfs      ecfsfiles htm
 tmt 
stanfordtopicmodelingtoolbox http   wwwnlp stanford edu software tmt tmt     
 sunlight 
whatcanwelearnfrom       publiccommentsonthefccsnetneutralityplan          
http   sunlightfoundation com blog            whatcanwelearnfrom      publiccommentsonthefccsnetneutral
ityplan  data


 

fi