collaborative neighborhoods
diego represas  david dindi
diegorep ddindi stanford edu
december         
abstract
finding relevant research publications is a growing problem for researchers across all
fields  online platforms such as mendeley and citeulike have attempted to address
this need by providing researchers the ability to share relevant articles with one another 
these platforms have further sought to extend their capabilities by recommending articles
to users based on the users past interactions and preferences  the models that underlie
these methods  however  are unable to provide recommendations on an item for which
no prior interactions have been observed  to solve this issue  we propose collaborative
neighborhoods  cn   cn combines elements of collaborative topic regression     and
nearest neighbor models     to provide meaningful recommendations in both the presence and absence of past user interactions with items  we assess the performance of cn
on dataset of         articles sourced from pubmed  and demonstrate that our models
provides more accurate recommendations that extant recommendation frameworks 

 

introduction

most promising model thus far  ctr applies
topic modeling to augment the item feature
vector used in traditional collaborative filtering  the limitation of ctr  however  is its representation of users by latent features alone 
in the absence of information on past userarticle associations  these user latent features
cannot be accurately predicted  consequently 
ctr performs poorly on users that have fewer
article associations 
we address ctrs shortcomings with cn 
cn not only applies topic modeling to augment
the latent feature representation of items  but
does so as well for the latent feature representation of users  we begin by representing users
and items by their associated topic distributions  we then proceed by learning latent variables that offset these distributions using past

researchers today are inundated with information    million peer reviewed articles are
published every year      the difficulty in finding relevant articles amidst this abundance of
information has prompted citation management platforms like mendeley and citeulike
to implement recommendation systems to aid
researchers in the search       these systems
recommend articles based on implicit user preferences learned from a users past article associations   likes  shares or additions to ones
personal archive  
several collaborative filtering recommendation models have been proposed to aide in the
implicit learning of user preferences  collaborative topic regression  ctr      has been the
 

fiobservations of user article interactions  these
offsets capture hidden interests that an author
may have in fields that are outside their main
area of research  given that cn attributes
both explicit and implicit content features to
every user  it is capable both of understanding
hidden preferences   and providing recommendations to users for whom there is insufficient
information to learn implicit preferences 

 

mendation systems  including the one used by
mendeley  are based on collaborative filtering  cf  methods using latent factor models
                  in these models  the rating
that a user j attributes to item i can be predicted through the rating function ri j   uti vj  
where ui  rk is the latent factor vector for
user i and vj  rk   an effective approach for
implicit feedback datasets is to translate the
continuous value rating into the implicit space
by setting the preference variable as follows    
    

  ri j    
pi j  
   
  ri j    

background

a basic approach to recommending text
items has been to do so based on content
similarity  such methods employ probabilistic
models and similarity scoring to define an articles content            or matrix factorization
methods such as content based collaborative
filtering  cbcf  to provide recommendations
to users          for our particular problem  an
article js content can be thought off as a topic
distribution vector  j  rk   across ktopics 
when a new item is introduced  a similarity
function  e g  cosine similarity  is used to determine the k items that are most similar to
the new item  the new item is then recommended to users who in the past have rated
any of the k items favourably
despite their intuitive appeal  similarity
and neighborhood models  such as k nearest
neighbors  are inadequate for providing recommendations in research literature  this inadequacy stems from the fact that content
similarity alone is not sufficient to determine
whether or not an author would cite an article  a neighborhood model  for instance 
would recommend an article that is of little
intrinsic value to a user  solely because the
article contains topics that the user has referenced in the past  this dependence on explicit features prevents neighbourhood models
from capturing hidden preferences of a user 
some of the most popular market recom 

because not all values of ri j     are equally
likely to predict a user item interaction  a confidence variable ci j     f  ri j   is introduced
to measure the confidence of observing pi j     
the constant  is a learning rate constant and
f  ri j   is an empirical function that depends
on the dataset  the latent factor vectors ui
and vj are then computed by minimizing the
objective function 
min
u v

p

i j

ci j  pi j  uti vj      

p

i

kui k   

p

j

kvj k 



   
the following update rules for both latent vectors are then derived from the objective function 
ui   v ci v t   i   v ci pi
vj   u cj u t   i   u cj pj

   

where u  v are the user and item latent
factor matrices  c is the confidence variable
matrix and p is the preference variable matrix  updates are thus performed through an
alternating least squares model 
recommender systems based on latent factor models have been shown to provide better
recommendations than neighborhood methods
         however  because cf relies on observing prior user item interactions to provide recommendations  it is unable to recommend articles that have not been previously cited or
 

filiked by researchers 
to address the shortcomings of cf  david
m  blei and chong wang recently developed collaborative topic regression  ctr 
     much like cf  ctr assigns latent features
to every user and item based on prior useritem interactions  however  ctr differs from
cf in its usage of latent dirichlet allocation
 lda  to construct topic distributions  drawn
from      k unique topics  for every item 
rather than describing vj as an exclusively latent factor based vector  blei et al  choose
to describe the item vector as vj   j   j  
where j  rk represents the lda derived
topic distribution of item j  and j is a latent variable that captures fluctuations away
from the topic distribution  these latent offsets augment the content similarity based approach through the flexibility that they afford
the model to understand hidden features about
items and users  since regularization for the
topic enhanced items must inherently be different than that for pure latent users  separate
parameters u and v are applied to user and
item feature vectors respectively  the resulting
log likelihood function is intractable  a type of
expectation maxmization algorithm is therefore used to arrive upon the optimal parameters 

l    v  vj  j  t  vj  j  
 

p p
n

k

   

jnk logjkk  wjn  logjkn 

the free variational parameters upon which
the distributions are generated are optimized
by minimizing the kullback leibler  kl  divergence between the variational distribution
and the true posterior  the resulting update
equations  for determining  and  are given
below

ni  iwn exp eq  logi     
x
i
i   i  

   
   

n

the predicted rating variable ri j for inmatrix predictions is then computed by 
ri j   uti vj   uti  j   j  

   

when an item is new and in matrix prediction is not possible  the rating variable is
computed ignoring the latent offset 
ri j   uti j

    

consequently  users are still represented by
latent factors but items are represented by a
p
p
combination of their topical distribution and a

t
t
l     
   
i ui ui   
j  vj  j    vj  j  
latent factor offset  the latter aiming to capture
p p
p
p c
t
 
variables conducive to a user item interaction
  j n log  k jk k  wjn    i j    rij  ui vj  
that are not related to the items topic  ctr
the derived update rules for u and v then
was shown to perform better as a recommender
become 
system than collaborative filtering using both
t
 
latent factor and content based methods 
ui   v ci v   u i  v ci pi
   
t
 
vj   u cj u   v i   u cj pj   v j  
u

v

ij

 

given u and v  the topic proportions are
learned by variational inference  a family of
distributions on the latent variables
is generq
ated  q   z         q      n q zn   n   and
jensens inequality is applied to find the tight
lower bound for the log likelihood function below 

collaborative neighbors

given the performance improvement ctr saw
by introducing topic modeling for the items  we
developed an algorithm that also introduced
topic modeling for the user vectors to increase
prediction accuracy  in this section we describe
 

fithe resulting algorithm  collaborative neighbors 
as in ctr  our users are i researchers and
our items are j scientific articles  the preference variable pi j       indicates whether or
not user i cited article j  the preference variable is computed from the predicted ratings as
in eq      and the predicted rating variable
remains ri j   uti vj  

optimize for the topic distributions  the most
important difference is that our update rules
for ui   vj now become 
ui   v ci v t   u i    v ci pi   u i  
vj   u cj u t   v i    u cj pj   v j  
    
our algorithm then additionally has to incorporate topic modeling for the users in the same
way as ctr does it for the items 

 

experimental study

dataset  a total of     millions articles were retrieved from the pubmed open access dataset 
we parsed the title  abstract  authors  keywords and citations associated with each article  we removed articles missing any one of the
fields of interest to obtain a dataset of        
scientific articles 
articles  for each article  we concatenated
its title  abstract and keywords into a document  we then removed all english stop words
and built a vocabulary consisting of the x
words that appeared in our corpus more than
once  next  we used a hierarchical dirichlet
process  hdp  model on our dataset to determine the number of k topics contained within 
and subsequently ran lda to determine the
k vector topic distribution for each article 
users      million unique authors were
identified in the initial open access dataset 
user article interactions were generated by
mapping users to all the citations that they
had across all their publications  we removed
self citations  where an author cites their past
work  and filtered out users that had cited
fewer than    papers in our dataset  our final
user item matrix consisted of        users by
        thousand articles  with an average of
     interactions  citations  per user and     
publications per user  lastly  we assigned a
topic distribution to each user by taking the
average topic distribution of all papers they
had co authored  because of computational

we now introduce a way to represent topic proportions for both users and items  we denote
j as the topic distribution for item j  where
each j is drawn from      k unique topics 
conversely  we introduce i as the topic distribution for user i  each i drawn from        l  
in our experiment  we chose i to be the average topic space of user i but there are several other strategies one could use to represent
the user  since matrix factorization requires
for u  v  rk  the user and item factor matrices have to align   both  and  have to
be drawn from the same topic space or  alternatively  topic models of the same magnitude
               since finding the optimal value
of     u and v given      becomes intractable 
our algorithm will only be tested in the case
where       so we can assume   and
use the same em style algorithm as in ctr to
 

ficonstraints   our tests routinely took up to   
hours on stanfords barley machines due to alsqr     all tests were run on a random fraction
of the original dataset consisting of        articles 

   

out of matrix predictions  for out ofmatrix recommendations  recall consisted of
the number of articles recommended to a user
that were also in the out of matrix set over the
total number of articles in that users out ofmatrix set 

evaluation

cross validation  the training and testing
sets for all tests were split as follows  from
the original m  n matrix containing all user
interactions  a total of m   m    user row
indices and n   n    item column indices
were randomly selected  interactions belonging to these m randomly selected users were
separated into a different m  n  n matrix
for user out of matrix cross validation  interactions belonging to the n randomly selected
items were also separated  this time into a
m  m  n matrix for user out of matrix cross
validation  interactions in both the m selected
rows and n selected columns were discarded 
the remaining bulk of the interactions were
assigned to a m  m  n  n matrix  of these
interactions      were randomly selected and
placed in a separate m  m  n  n for inmatrix prediction cross validating  the other
    were used for training the models  the
user and item topic matrices were split and
distributed according to where their representative rows columns were assigned during the
shuffle  we saw no significant changes in our
training and testing recall values when implementing multiple folds of this matrix shuffle
split 

   

settings

blei and wang established that the independence of the topic distributions j relative to
user vectors allowed for the optimal topic distributions to be found before beginning to optimize for ui and vj   j   j   consequently 
we used hdp to find an optimal topic number
of k       and also set the dimensions of our
latent vectors equal to k  we set      and iterated for values of v   u                       
to find that v      u       gave optimal
results for ctr using    training epochs  values of v       u      gave optimal results for cn  as prior literature had already
shown ctr outperforms cf  we simply used
k        u   v        for our ctr iterations to provide a point of reference without
optimizing the parameters 

   

results 

comparisons  our algorithm performed better than collaborative filtering and comparable to collaborative topic regression when
performing in matrix recommendations  this
is consistent with prior research on the performance of ctr  in our particular dataset  we
found that recall using cn was almost identical to that measured using ctr during the
first predictions and consistently higher than
ctr in the ranges after    predictions  this
could mean that our algorithm generally performs better in matrix recommendations than
ctr but it could also be attributed to the
more direct topical connections of our dataset 

in matrix predictions  following blei and
wangs prior work  we established our measures of accuracy to be standard precision and
recall within the first       highest scored predictions  for in matrix recommendations  recall consisted of the number of articles recommended to a user that were also in the testing
set over the total number of articles in that
users testing set 
 

fisignal processing techniques to filter time series data in his her research  more generally 
these offsets capture passive interests that can
allow recommender systems to make more informed judgments on what to recommend  in
our dataset  we observe the topic associated
with words such as south  variation  india  asia 
geographic and madagascar exhibit the largest
offsets 
examining article characteristics  similarly cn allows us to understand which topics attract a broad range of interest from researchers from a diversity of fields  we accomplish this analysis by calculating the average magnitude of each item latent feature offset  topics with a large offsetting magnitudes
on the item side  tend to be topics that have
been cited by users in a variety of fields  in
our dataset we observe topics associated with
words such as world  skin  biodiversity and
communities to have the largest offsets 

for item out of matrix predictions  our algorithm demonstrated having considerably
higher recall figures compared to ctr  indicating the value of our algorithm is strongest
when performing cold start recommendations 
we attempted to perform user out of matrix
predictions multiple times with no more success than random recommendations  we attribute this failure to the strategy we used to
establish the user topic space as an averaging
of a users publications is likely to be similar
to too many publications without much specificity 

 

conclusions

we demonstrate in this study the ability of
collaborative neighbourhoods of predicting
the citations made by researchers in medical
literature  we obtain results that are superior to traditional collaborative filtering and
collaborative topic regression in in matrix
and out of matrix predictions  furthermore 
we demonstrate the ability our model to develop a semantic understanding of an authors
preferences  as well as to identify the types of
articles that enjoy the most reception from a
variety of fields  our method can be generally applied to any user item recommendation
problem where there is sufficient information
about each user  future work will focus on
eliciting further meaning from the latent features derived  and augmenting the ability of
cn to recommend items to users whose prior
interactions have not been observed 

examining user profiles  we can explicitly
analyze user profiles from the lda representation of topics that were generated by averaging
the topic distribution across all their publications  with cn  we are able to extend the
analysis further by analyzing the magnitude of
each latent offset from the authors topic distribution  these offsets represent large deviations of an authors preferences  from their
core topics of research  for instance  a financial engineer might apply electrical engineering

 

fireferences
    wang  chong and david m  blei  collaborative topic modeling for recommending scientific articles  proceedings of the   th acm sigkdd international conference on knowledge
discovery and data mining  new york  ny  usa  acm                
    hu  y   y  koren  and c  volinsky  collaborative filtering for implicit feedback datasets 
data mining        icdm    eighth ieee international conference on      
    stm international association of scientific  technical and medical publishers  stm 
n p   n d  web     dec       
    d  blei  a  ng  and m  jordan  latent dirichlet allocation  journal of machine learning
research             january      
    j  chang  j  boyd graber  s  gerrish  c  wang  and d  blei  reading tea leaves  how
humans interpret topic models  in y  bengio  d  schuurmans  j  lafferty  c  k  i  williams 
and a  culotta  editors  advances in neural information processing systems     pages        
     
    s  m  gerrish and d  m  blei  predicting legislative roll calls from text  in proceedings
of the   th annual international conference on machine learning  icml          
    d  agarwal and b  c  chen  flda  matrix factorization through latent dirichlet allocation  in proceedings of the third acm international conference on web search and data
mining  wsdm     pages        new york  ny  usa        acm 
    content based recommendation systems michael j  pazzani  daniel billsus
    burke  r   hybrid web recommender systems  in  brusilovsky  p   kobsa  a   nejdl 
w   eds   the adaptive web  methods and strategies of web personalization  lncs  vol 
      pp          springer  heidelberg       
    mooney  r  j   and roy  l        content based book recommending using learning for
text categorization  in proceedings of the fifth acm conference on digital libraries         
     r  salakhutdinov and a  mnih  bayesian probabilistic matrix factorization using
markov chain monte carlo  in proceedings of the   th international conference on machine
learning  pages         acm       
     r  salakhutdinov and a  mnih  probabilistic matrix factorization  advances in neural
information processing systems                    
     y  koren  r  bell  and c  volinsky  matrix factorization techniques for recommender
systems  ieee computer                   
     d  agarwal and b  c  chen  regression based latent factor models  in proceedings
of the   th acm sigkdd international conference on knowledge discovery and data mining 
pages       new york  ny  usa        acm 
     k  yu  j  lafferty  s  zhu  and y  gong  large scale collaborative prediction using a
nonparametric random effects model  in proceedings of the   th annual international conference on machine learning  pages           new york  ny  usa        acm 
     j  l  herlocker  j  a  konstan  a  borchers  and j  riedl  an algorithmic framework
for performing collaborative filtering  in proceedings of the   nd annual international acm
sigir conference on research and development in information

 

fi