solomon
an algorithm predicting the survival of bills
in the house of representatives
cs     final project report
suids   bjang   dokwon  gyujinoh  jipark   
authors   brian jang  do kwon  gyujin oh  ji park 

   introduction
predicting the survival of a congressional bill is analogous to the general problem of predicting human
responses to general ideas  a congressional bill is a collection of long living social themes  such as
abortion  jobs  and economy  by looking at the voting records of representatives on bills of the same
subject  we can predict how they will vote on future bills 

   prior work
while there has been previous work on predicting the survival of bills in congress  we have yet to
discover algorithms that attempt to capture the topicality of the bill text  two projects have aimed for
bill survival prediction  the first by cain et al  in a cs     project  and yano et al  while yano et al s
work focused on congressional committees  cain et al s work only focused on the textual similarity of
the bills without capturing the topicality  previous work  by neglecting to account for the topic of the
bills  fares much more poorly than our algorithm 

   task definition
we divide the task into three components  topicality analysis  individual vote prediction  and party
vote prediction  first  using the plsa algorithm  probabilistic latent semantic analysis  we look at
the text of the bill to determine the topicality  second  given a new bill  we try to predict the way each
representative will vote  given his her voting record on bills with a similar topic structure  since bills
have a binary decision structure  one either chooses to support the bill or oppose it  we formulate the
problem as a logistic regression problem 

   method
    intuition
when presented with a proposition   in the form of a bill in the congressional context  human beings
make decisions on the basis of its related themes  thematic ideas are the key basis underlying human
decisionwe decide we agree or disagree with the ideas of capital punishment  abortion  and free
speech  the key intuition of our algorithm is capturing this topicality behind the human decisionmaking process 
    preprocessing of data
we collected the full text of bills tendered to the house of the    th congress                as well as
the votes of each representative on the bills from the us government printing office 
  

 

fi http   www gpo gov fdsys   each bill has an associated metadata that is already tagged with its
relevant topics  we parsed the full text body of the bills  its metadata  and the votes of each
representative  and created xml files that suit our purposes 
before the text of the bills could be used  we had to perform a substantial amount of preprocessing  to
remove extraneous data  we stemmed each of the tokens  removed punctuation and stop words  and
converted all words to lowercase 
    leveraging topicality
one of the most important features of a bill responsible for each persons decision would be the list of
topics relevant to it  models that aim to draw topics from documents are called topic models  among
various topic models available  we in particular were interested in topic models that can take advantage
of a pre assigned range of topics  to be more specific  in our settings  every bill has several tags
associated with it  and each tag indicates a specific topic that might be relevant to the bill  in this sense 
chose the probabilistic latent semantic analysis  or  plsa   formulated as follows 

figure    the probabilistic latent semantic analysis algorithm  source  wikipedia 
in the above equation  w is a word  d is a document  in our setting  a bill   and c is a topic 

the advantage of using probabilistic model is that we can lay additional conditions that p c d      for
every topic c not occurring as a tag of d  given such conditions  like svm  there are very few nonzero
summand  which enables us to handle a larger number of topics with faster speed  also  among many
ways to maximizing p w  d  in plsa model  expectation maximization e m  method preserves the
condition p c d      in each step  in this spirit  we used e m method to implement plsa 

figure    e step of em method update rule  source   a tutorial on plsa  http   arxiv org abs           

figure    m step of em method update rule  source   a tutorial on plsa  http   arxiv org abs           

  

 

finote that what we are really interested in is the relevance of each tag  or  topic  to the bill  thus  after
optimizing all the prior and conditional probabilities  we will primarily utilize p c d   the conditional
probability of each topic c in a document  or  a bill  d 
    classification
given that we obtained the data about relevance of each topic tagged to the bill  we can hone the
feature vector of bills more accurately  the downside of using binary classification algorithm only
based on the list of tagged topics is that not so relevant topics might be too effective on determining
the classifier  by setting each entry of feature vector to be p c d   instead of   or   indicating whether
the topic is tagged in the bill or not  the effect of less relevant topics will subside  indeed  we observed
better performance by using detailed conditional probabilities obtained from plsa step above  also  to
naively include the so called party line  we used  as a feature of a bill  which party suggested the bill 
note that the party line also would rather be expressed as a real number  not   or   
in order to find the optimal classification algorithm  we deployed logistic regression  support vector
machine  nearest neighbor  with   neighbors   decision tree  and linear discriminant analysis
through cross validation 

   result
for accurate evaluation of the algorithms applied  we have randomly selected    percent of the data set
as a training set and rest of the    percent as a test set 
first off  we compare our results incorporating topicality with the results of a previous cs     project
that attempted to do the same through a simplistic textual similarity model      incidentally  the
previous team used the same dataset and performed near identical preprocessingmeaning that any
improvements must come from our topic analysis  our algorithm  with little special honing done
besides capturing topicality  far outperforms the results of the previous work 

error  rates  with without  topic  
analysis  
     
     

     

     

     

     

     
     
    
    
topic     logistic  

knn   cain  et  al   
training  

svm   cain  et  al   

test  

figure    comparison of error of topic   textual similarity models

  

 

fifigure    predicting congressional outcomes results   

we also experimented with various binary classifiers  and selected logistic regression  as it was the
most performant classifier  we purposefully kept the binary classification simple  as to strengthen the
argument our good performance originated from the topical analysis portion of the algorithm 

error  rates  on  different  
classi iers  
     
     
     
     

     

     
    

     

     

     

    

    

    

    
logistic  

svm  

nearest  
neighbor  
training  

decision  tree  

lda  

test  

figure    e step of em method update rule  source   a tutorial on plsa  http   arxiv org abs           

   evaluation
the baseline of our algorithm is a simple logistic regression algorithm without topic analysis  and the
results from our implementation are as follows 
evaluation of logistic regression   plsa  with plsa  we were able to generalize the error rate 
compared to logistic regression only mechanism  we were able to achieve lower variance through
training error of     and test error of     
evaluation of best performant other work   using knn  cain et al  was able to get a     test error 
   more than ours 
on the democratic side  we achieved nearly zero error on yes votes on the bill  whereas for the
republicans similarly low error was seen for no votes  these results are in line with the then
  

 

fipolitical reality of a democrat controlled congress with the former party pushing through most
legislation  and the latter party investing most party line resources to opposing and filibustering
legislation 
the oracle for the algorithm is not clear  as we are trying to predict what human representatives would
do  there is no way to build a predictive model with a zero error rate  lacking such an objective oracle 
we will set the upper bound performance of our algorithm to be one with a zero error  though we will
never actually get there 

   example
in       the house of the    th congress had the vote of id h     and it was on the bill hres    
tags on this bill are given as congress  house rules and procedure  and taxation  the summary
of this bill is given as sets forth the rule for consideration of the bill  h r     to make the repeal of the
estate tax permanent   to give a concrete example  we provide one with very short summary  but for
other bills  the summary can be long  
based on these tags and summary text  we run plsa algorithm to weight each subject  with the sparse
feature vector utilizing those weights obtained by this algorithm  we train by logistic regression for
each representative with the result whether he voted supports or not for this bill  for example  the
representative of id        voted yes for this bill  so his tendency toward voting yes for tags
congress  house rules and procedure  and taxation would increase by this training  more
concretely  by plsa algorithm  weight on taxation would be larger than those on congress and
house rules and procedure for this bill and it affects to the tendency of the representative more 
after training each representative with a large enough history of his votes  we test for testing set with
same method  weight on each subjects of the bill  create the sparse feature vector  and predict the result
with learned weight vector 

   conclusion
throughout the development and analysis of the solomon algorithm  we were able to discover the
critical role topics play in human decision making and the computer powered predictions that try to
emulate it  topic analysis in regular  formatted text such as legislation just begins to scratch at the
surface of a much larger  more interesting family of problems  namely  isolating ideas and intentions
from natural language  this project will be the basecamp for further research that tackles those
problems  and tackling the challenges of machine comprehension of human language semantics 

   references
    yano  t   smith  n a    wilkerson  j d         textual predictors of bill survival in
congressional committees 
    cain  z  n a    chua  p  n a gampong  k  n a         predicting congressional bill outcomes 

  

 

fi