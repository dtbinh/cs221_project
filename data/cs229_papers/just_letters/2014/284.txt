 d scene retrieval from text with semantic parsing
will monroe
stanford university
computer science department
stanford  ca        usa
wmonroe  cs stanford edu

abstract
we examine the problem of providing a
natural language interface for retrieving  d
scenes from descriptions  we frame the natural language understanding component of this
task as a semantic parsing problem  wherein
we first generate a structured meaning representation of a description and then use the
meaning representation to specify the space
of acceptable scenes  our model outperforms
a one vs  all logistic regression classifier on
synthetic data  and remains competitive on a
large  real world dataset  furthermore  our
model learns to favor meaning representations
that take into account more of the natural language meaning and structure over those that
ignore words or relations between them 

 

introduction

we look at the task of  d scene retrieval  given a
natural language description and a set of  d scenes 
identify a scene matching the description  geometric specifications of  d scenes are part of the
craft of many graphical computing applications  including computer animation  games  and simulators 
large databases of such scenes have become available in recent years as a result of improvements in


this project is part of a joint research project with angel
chang  computer science  and christopher potts  linguistics  
i have omitted their names from the author section to avoid confusion  as neither is a cs     student  however  their contributions are substantial  angel implemented the infrastructure
for working with  d scenes and collecting data via mechanical
turk  prof  potts has been our primary faculty advisor for this
research project 

brown room with a refrigerator in the back corner

a

b

c

d

e
figure    one instance of the scene retrieval task 

the ease of use of tools for  d scene design  a
system that can identify a  d scene from a natural language description is useful for making such
databases of scenes readily accessible  natural language has evolved to be well suited to describing
our  three dimensional  world  and it provides a convenient way of specifying the space of acceptable
scenes  a description of a physical environment encodes logical propositions about the space of environments a speaker is describing 
this logical structure of scene descriptions suggests that semantic parsing is an appropriate framework in which to understand the problem of retrieving scenes based on their natural language descriptions  semantic parsing  zelle and mooney       
tang and mooney        zettlemoyer and collins 
      is the problem of extracting logical forms
from natural language 

fif  o  p o 

scene  identify the scene y  i  that inspired the description from among a set of scenes y  i  consisting
of y  i  and one or more distractor scenes 

p  

   

spfp

o  room green weird       
figure    context free grammar for parsing scene descriptions 

a large and growing body of literature from the
computer vision and information retrieval communities exists surrounding the task of scene retrieval
over images and video given descriptions  sebe et
al         datta et al         snoek and worring 
       however  relatively little work has looked
at identifying  d scenes from natural language descriptions   d scene representations offer advantages in the form of a highly structured  segmented
input that is semantically annotated 
other work has looked at generation of  d scenes
from text  wordseye  coyne and sproat       
pioneered the approach of visualizing natural language by constructing a  d scene that represents
its meaning  more recently  chang et al        
built a system for text to scene generation which can
learn scene synthesis from a database of human built
scenes  fisher et al         and be trained interactively  updating the weights for object support hierarchy priors in response to user corrections  this
helps ensure that generated scenes are realistic  by
sampling from an estimate of the density of humangenerated scenes that is trained on both positive and
negative examples 
both of these systems notably lack sophisticated
approaches for extracting meaning from natural language descriptions  our work relates to this goal in
that we define a space of meaning representations
that can be used for both  d scene retrieval and  d
scene generation  we aims to fill the natural language understanding gap in this work by applying a
state of the art semantic parser to map textual input
to these meaning representations 

 

models

we define the scene retrieval problem as follows 
given x i    a natural language description of a  d

logistic regression

we train and evaluate two models for solving this
problem  the first is a one vs  all logistic regression
 lr  classifier  which learns to estimate the probability of a scene being correct 
 
    exp  x  y t  

h  y x   

in training the lr model  we maximize the l  regularized log likelihood of the dataset  counting
each true scene and each distractor scene as one example 

        
 
m x  n
o
x
  y   y  i  log h  y x i     

o x  y   

i   yy  i 

o

n
  y    y  i  log    h  y x i    
at test time  the model predicts the scene with the
highest estimated probability 
y  i    arg max h  y x i   
yy  i 

   

semantic parsing

the second model we consider is a structured prediction model that uses the s empre semantic parsing framework  berant et al         to derive a structured logical representation  z  a latent variable  of
the meaning of a scene description  s empre uses
a structured softmax regression model with features
defined over utterancelogical form pairs 
exp  x  z t  
  t
z   d x   exp  x  z    

h  z x    p

the space of logical forms compatible with an input
utterance d x  is in general exponentially large  so
s empre approximates this sum using a beam search
algorithm  guided by the learned parameters   to
search a subset d x    of possible outputs 
for each logical form z  our model uses deterministic scoring rules to select the scene that best

fimatches the constraints expressed in the logical
form 
jzk   arg max score y  z 
yy  i 

the training objective is to maximize the l  regularized log likelihood of the correct scenes 
marginalized over z 
o x  y           
m
n
o
x
x
log
  jzk   y  i  h  z x i   
i  

zd x i    

the final prediction of the model is the scene selected by the logical form on the beam that is the
most likely according to the model 
t
 
y  i   

arg max h  z x i   

zd x i    

d x   the true set of logical forms compatible
with a scene description x  is defined by a contextfree grammar over the input augmented with semantic interpretations of each grammar rule  figure  
shows the simple grammar we use  any terminal
and nonterminal symbol in this grammar can be surrounded by zero or more tokens that are skipped  not
used in the output logical form   the symbol o represents the lexicon for this grammar  which consists
of phrases mapped to subsets of a database of  d
models  either by category  e g  chair is mapped to
the set of objects categorized by humans as chairs
in the database  or by model id  e g  crazy poster
is mapped to the specific model poster      our
logical forms then consist of a conjunction of predicates denoting the existence of at least one object
from each subset  for example  one possible logical
form might look like 
 and category room
model refrigerator    
      features
both models use binary valued features indicating the co occurrence of a unigram or bigram and an
object category or model id  the logistic regression
model uses features defined over every unigram and
bigram in the input  a total of        features on the
development dataset and         features on the full

dataset  s empre uses unigram and bigram features
only for entries in the lexicon o  approximately    
for the development dataset and       for the full
dataset   these features are very sparse  for a given
input x containing n words  at most  n    of these
features are non zero in the lr model  and in the
s empre model  at most   n     z  are non zero 
where  z  is the number of object descriptions in a
given logical form 
for the s empre model  we also have features
over the logical forms  z   these consist of counts of
words skipped by part of speech and counts of grammar rules applied in constructing the logical form 
these features allow the algorithm to adjust the fraction of the natural language input that is used or ignored in building the output as well as the complexity of the output logical forms  on the development
set  the model stored weights for    rule application
features and    pos skipping features  for the full
dataset  the numbers were    and     respectively 

 
   

experiments
datasets

we collected a dataset of      d scenes and      
descriptions of these scenes from workers on mechanical turk  one set of turkers are shown a sentence  one of    seed sentences we wrote describing
simple configurations of interior scenes  and asked
to build a scene using the webscenestudio interface
 the program used by fisher et al         to build
their scene synthesis database   other turkers are
then asked to describe each of these scenes in one to
two sentences 
our development was done on a smaller dataset
of     machine generated scenes  using an existing
scene generation system  chang et al         
these are created from a set of    logical forms 
some of which were augmented with spatial constraints  such as  and category candle
category table 
and
 on top of
category candle category table  
for each of these  we generated a number of scenes
that satisfy the requirements expressed by the logical form  e g  that have both a candle and a table  
manually filtering scenes to eliminate low quality
models and unphysical object placement  we then
wrote one description for each of these     scenes 

fitrain
   
    
    
    
     
     
     
     
   

test
   
   
   
   
   
   
   
   
   

 

   

   

   
accuracy

model
random
lr raw uni
lr raw
lr lem
s empre raw
s empre lem
s empre lex raw
s empre lex lem
size

   

   

table    development dataset results  raw and lem indicate using unprocessed and lemmatized text for unigram
and bigram features  uni indicates unigram features only 
lex indicates use of a lexicon assembled from the training
set instead of written by hand 

model
random
lr
s empre
size

train
   
     
     
     

test
   
     
     
   

   

   

lrdev
lrtrain
sempredev
sempretrain

   
 
  

 

 

  

 

 

  
  
regularization constant 

 

  

  

figure    effects of regularization on development set
accuracy  we found that regularization did not improve
performance on either model 

table    results on the mechanical turk dataset 

results

table   shows the performance of our model on
the development dataset  our best semantic parsing model achieves     accuracy at distinguishing
a scene that matches a description from four distractors  chance is      on a held out set of     scenes
from this development dataset  the one vs  all classifier achieves     accuracy on the held out dev set 
the fact that the lr model is able to perfectly
classify the development training set indicated that
it was overfitting  to reduce variance  we looked at
the effects of regularization and training set size on
model performance 
figure   shows held out dev set accuracy as a
function of the regularization constant   we found
that including regularization only barely improved
the lr model  and hurt performance of the s empre
model across the board   note that lr uses l  regularization and s empre uses l  regularization  so
the constants are not directly comparable  but in both
cases larger numbers represent a stronger prior  
figure   shows the learning curves of the two
models on the development set  the slopes of the

 

   

   

   
accuracy

   

   

   

   

lrdev
lrtrain
sempredev
sempretrain

   

   
  

  

  

  

   
   
   
training set size  examples 

   

   

   

   

figure    learning curve on the development dataset 
the upward slope indicated that additional data was
likely to improve performance  the steeper line for the
lr model suggested  correctly  that lr would outperform s empre on the larger dataset 

filearning curves suggest that the s empre model does
well in the low data setting  but the lr model benefits from the larger dataset  this can be explained
by the fact that s empre has a fixed lexicon that encodes some amount of prior knowledge about word
meanings  as the training data grows  this lexicon
becomes less capable of accounting for the variety
of language found in the data  whereas the lr model
continues to add features and learn from the additional data 
the results on our dataset collected from mechanical turk  figure    support this conclusion  the lr
model performed better than the semantic parsing
model on this larger dataset  achieving       accuracy on the test set compared to       for the semantic parsing model  chance is again      

 

discussion

on the smaller dev set  the semantic parsing model
had higher performance than the simple classifier 
however  with a larger dataset  logistic regression
outperforms the structured model  this discrepancy
is best explained by a combination of two factors 
firstly  additional data provides a greater benefit to
the lr model than to the semantic parsing model 
as mentioned in section      secondly  the larger
dataset contains descriptions collected from many
workers  whereas the descriptions in the smaller
dataset were written only by two people  this naturally leads to greater linguistic diversity in the full
dataset  making the problem harder for both models
 as we can see from the lower test set scores in figure    but disproportionately affecting the semantic
parsing model because of its limited capacity for encoding linguistic variation in the logical forms 
one promising outcome we observed is that the
semantic parsing model gives negative weights to
the word skipping features  with the exception of
verbs  wh pronouns  and punctuation  and the grammar rule application features with counts of zero 
this indicates that paying attention to all of the language in a description and producing outputs with
complex structure are empirically beneficial 

 

future work

for future work  we plan to examine ways to speed
up training times  so we can use a larger lexi 

con  we also plan to add new features and new
kinds of meaning representations  incorporating spatial relationships between objects and other information about  d models that is available in our
model database such as human written descriptions
of models  other attributes that can be extracted
from the models that could be useful in features include color  size  and proportions 
the meaning representations produced by the
s empre model can also be used for scene synthesis  a line of work we plan to pursue over the coming
months 

references
jonathan berant  andrew chou  roy frostig  and percy
liang        semantic parsing on freebase from
question answer pairs  in emnlp 
angel x  chang  manolis savva  and christopher d 
manning        interactive learning of spatial knowledge for text to  d scene generation  in acl illvi 
bob coyne and richard sproat        wordseye  an
automatic text to scene conversion system  in siggraph 
ritendra datta  dhiraj joshi  jia li  and james z  wang 
      image retrieval  ideas  influences  and trends
of the new age  acm computing surveys  csur  
        
matthew fisher  daniel ritchie  manolis savva  thomas
funkhouser  and pat hanrahan        example based
synthesis of  d object arrangements  acm transactions on graphics  tog             
nicu sebe  michael s  lew  xiang zhou  thomas s 
huang  and erwin m  bakker        the state of the
art in image and video retrieval  in image and video
retrieval  pages     springer 
cees gm snoek and marcel worring        conceptbased video retrieval  foundations and trends in information retrieval              
lappoon r  tang and raymond j  mooney        using multiple clause constructors in inductive logic programming for semantic parsing  in machine learning 
ecml       springer 
john m  zelle and raymond j  mooney        learning to parse database queries using inductive logic programming  in aaai  pages          
luke s  zettlemoyer and michael collins        learning to map sentences to logical form  structured classification with probabilistic categorial grammars  in
uai 

fi