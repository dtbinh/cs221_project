bike share usage prediction in london
ford rylander

bo peng

jeff wheeler

fordr stanford edu

bpeng stanford edu

jeffsw stanford edu

abstractthe rapid growth in recent years of bike sharing around the world has led to real challenges balancing
supply and demand  to provide a possible solution for this
situation  bike sharing usage prediction is critical  in this
study  a model based on k mean clustering and polynomial
regression is applied to predict the bike sharing usage in
a given time period and station  london bike sharing data
are used for training and testing our model 

i  i ntroduction
bike sharing is a short distance bike rental service that allows customers to pick up a bike at
one station  use it for transportation as needed 
and return it to another station  this transportation
model delivers customers the conveniences of a bike
without the headaches of bike ownership including
theft  parking  storage and routine maintenance 
demand for bike sharing services has exploded
in recent times  as of june       public bikesharing systems can be found in     cities on five
continents  with approximately         bicycles in
circulation at a total of        stations     
demand prediction at bicycle sharing stations is
crucial to ensure that there are neither too many
bikes  and hence not enough bikes at some other
station that needs them  nor too few bikes  and
thus lost profits   this paper presents the findings
of an algorithm that utilizes historical usage and
weather data to accurately predict the number of
bikes required at a given station in london 
an examination of prior arts reveals several proposed methods to predict bike demand including an
autoregressive moving average  arma  algorithm
     linear regression  and support vector machine
 svm  regression      the arma model leverages
time domain autocorrelation to highlight underlying
periodicity in the bike demand data  linear regression uses a computationally efficient yet powerful
model to fit the time series data  and svm regression is more computationally intensive  taking the

pros and cons of these prior art approaches into
consideration  this paper presents the performance
of a  nd order polynomial model that is fit after
clustering the training set using the geographical
coordinates of the start stations 
ii  data
historical bike share station demand and weather
data are publicly available for download as a list
of rides and weather data in a given day  the
bike rental raw data includes time and location
information for each rental  these raw data are then
processed with a binning algorithm to separate the
data in the required time segment granularity and
then time correlating this with the weather data  the
ride counts are then shifted by several time intervals
and joined back with the original data to generate
the historic features 
the list of all bike rides is available directly from
transport for london     
iii  f eatures
we designed a pipeline structure that transforms
our basic feature set into a  nd order polynomial
feature set  and then reduces it to only the best
features 
x  original feature set
we have aggregated these data into a single
design matrix  where each row represents an hourlong segment of time for any given station  each
row in x is given by
x i     d  d  d  d  weather mean temp      
weekday is weekend      
h        h   t  r    
the values in this vector are given by

fi    

cluster    lr

cluster    lr

cluster    lr

cluster    lr

     

cluster    lr

cluster    lr

cluster    lr

cluster    lr

     

cluster    lr

cluster    lr

cluster    lr

cluster    lr

cluster    lr

cluster    lr

figure    geographic based k means on stations grouped by overall popularity


x    polynomial feature set
we create x   by applying a  nd order polynomial
transformation to x  each row is given by
 i 

x  i       x 

 i   i 

x  x 

 i 

 i 

x        x        
 i   i 

 i   i 

x  x        x   x    t  r     


x     reduced to best features
finally  we perform feature selection to limit the
variance problems and reduce regression complexity
by selecting the best    features 
x   i    f eature selection x  i     r    
we chose    features experimentally by optimizing the test error  as shown in figure    with large
numbers of features  the test error degrades because
we overfit the training samples 

feature selection to
optimize performance
   
    

score

d    d    d    d 
dn is the number of rides during the same
hour n days prior 
weather
is a binary representation of the weather
events from the day of x i   
mean temp
is the mean temperature on the day of x i   
weekday
is an integer representation of the day of
the week  with weekday         
is weekend
is a single bit that encodes whether x i  is
on a weekend or not 
h           h 
hn is the demand n hours prior to the hour
of x i   

   
    
   

test error

 

  

  

train error

  

  

   

number of features
figure    selecting number of features

iv  m odels
we divide the dataset into stations by overall
popularity  and then cluster these divided data based
on gps coordinates of each starting station  in
each cluster  denoted as clusterrs in figure    
we fit a  nd degree polynomial model using linear
regression  when predicting  we find the cluster
closest to the station whose demand were trying to
predict and use the fitted polynomial for that cluster 
we use more data for the less popular stations         while reducing the number of stations in each
cluster by increasing the number of clusters  this
is necessary because the less popular stations have
data which is more sparse  and thus we need more
data to train on 
a  nd order polynomial was chosen experimentally to optimize the performance of the model  the
performance of the model with varying degrees is
shown in figure   
the k means within each set of stations uses the
gps coordinates to find stations that are located
near to each other  we train on features g  i  given
by


latitude
 i 
g  
 r   
longitude
and then perform k means by optimizing the

fiperformance vs  model complexity

   

test error

train error

score

    

the performance metric that we used was explained variance  which computes the normalized
variance of the difference between the actual and
predicted bike demands in a given hour  in particular  explained variance is defined as
explained v ariance     

v ar y  y 
 
v ar y 

   

the performance results for each of our models
are summarized in table i 
the learning curve shows  satisfyingly  that our
training
and test scores converge to        this
    
 
 
 
 
suggests that we have sufficient data  to improve our
polynomial degree
learning algorithm  we required additional features
that convey unique information about the problem 
figure    performance vs  model complexity
the polynomial regression  linear regression over
our polynomial feature set  performs very similarly
to ridge regression  which adds a penalty term for
cluster centers according to
outlying data  because the penalty term was not
m
x
useful for our application  it was rarely significant
 
arg min
kg  i    i 
c k  
and therefore ridge and simple polynomial regres c
i
sion performed almost identically  because the extra
the use of k means was inspired by      the complexity of ridge came without benefit  we chose
preliminary k means clustering algorithm used eu  the simpler model 
clidean k means in the original feature space  howvi  d iscussion
ever  we found that k means clustering on the geoour learning algorithm performs very well on
graphic coordinates was more effective at predicting
the bike demand  the geographic based k means high traffic stations  performance degrades on less
linked stations that were likely to have similar popular stations as their demand is not as pretraffic patterns  furthermore  segmenting stations dictable because their usage is sporadic in nature 
by total demand prior to k means  as shown in that is  the number of bikes taken each hour from
figure    helped separate the stations that performed less popular stations is much more difficult to predifferently  further work in     could also be useful dict because only a few bikes are taken in an hour
for clustering the stations according to their traffic and they do not follow regular patterns  weekend
traffic is also difficult to predict at the high traffic
profiles 
each regressor cell performs regression on the stations because most of the traffic at those stations
occurs on weekdays  e g  during commutes or lunch
 nd order polynomial feature set according to
breaks   their weekday traffic likely corresponds to
k
x
h  x   i      t x   i   
j x  j  i   
j  

table i
m odel p erformance

v  r esults
we tried several regression algorithms inside each
cluster  and have plotted the overall performance of
each of them in figure    we found that a  nd order
polynomial regressor performed best among all the
algorithms we tried 

 st order polynomial regression
 nd order polynomial regression
 rd order polynomial regression
 th order polynomial regression
sgd  l  regularization 
ridge        
ridge        

     
     
     
     
     
     
     

     
     
     
     
     
     
     

fi 
   
   

score

   
   
   
testing score  ridge          
training score  ridge          
testing  sgd 
training  sgd 
testing  linreg 
training  linreg 

   
   
   
   
 

   

   

   

   

   

   

   

   

   

 

fraction of all data
figure    learning curve

vii  f uture
the fundamental limit of our algorithm was determined by the features that were available  given
more time  we would like to incorporate other
features such as subway ridership which we believe
would be an accurate predictor of bike demand  we
would also like to implement geographic visualizations of the data to better understand how geography
affects our learning algorithms performance 
r eferences
    s  a  s  et al   public bikesharing in north america during
a period of rapid expansion  understanding business models 

bike sharing prediction vs 
actual value

bikes demanded

local events happening nearby  which we did not
attempt to capture in our algorithm 
we expected to be able to predict the total usage
for all stations  but were surprised by our ability
to predict per station traffic quite well  to which
we credit our usage of k means clustering on the
geographic station coordinates 
figure   shows our predicted bike demand vs 
actual bike demand for a particular week in january
      this particular station is relatively high traffic
and our algorithm does a very good job of predicting
demand  many other high traffic stations share a
similar profile  some others have two peaks each
weekday corresponding to morning and evening
commutes or morning and lunch commutes 

   
  
 

 

  

   

   

time
predicted

actual

figure    bike sharing prediction vs  actual value

   

   

   
   

industry trends and user impacts  in mineta transportation
institure  mti         p  pp   
a  kaltenbrunner  r  meza  j  grivolla  j  codina  and r  banchs 
urban cycles and mobility patterns  exploring and predicting
trends in a bicycle based public transport system  pervasive and
mobile computing  vol     no     pp               
h  xu  j  ying  h  wu  and f  lin  public bicycle traffic flow
prediction based on a hybrid model  appl  math  inf  sci  vol    
pp               
transport for london  city of london   online   available 
https   www tfl gov uk 
h  wu  x  fang  and h  xu  station segmentation of hangzhou
public free bicycle system based on improved randomized algorithm  in machine learning and cybernetics  icmlc       
international conference on  vol     ieee        pp      
     

fi