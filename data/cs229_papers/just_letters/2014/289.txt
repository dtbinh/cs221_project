machine  learning  for  predicting  delayed  onset  
trauma  following  ischemic  stroke  
anthony  ma    gus  liu   
department  of  computer  science   stanford  university   stanford   ca         
  

  

stroke is currently the third leading cause of death in the united states  interestingly  however  only a small percentage of
stroke patients        die immediately from the initial trauma  some of the leading causes that eventually lead to death
may be initial ischemic infarction  recurrent ischemic stroke  recurrent hemorrhagic stroke  pneumonia  coronary artery
disease  pulmonary embolism  and other vascular or nonvascular causes  most studies that apply machine learning to stroke
focus on predicting the risk of having a stroke or the likelihood of survival given attributes of a patient  but not so much on
likely outcomes of patients that do survive the initial stroke attack  therefore  the goal of our project is to apply principles
of machine learning over large existing data sets to effectively predict the most probable life threatening risks that may
follow the first incident  in this paper  we show our models generating predictions with over four fold accuracy compared
to determining outcomes by chance  further refinement in these algorithms could provide immense utility in clinical
settings and stroke therapy 
  

introduction    

methods  

in this paper  we apply both unsupervised and supervised
machine learning methodologies to patient profile data 
first we will demonstrate  i  that features from differential
diagnoses and medical interviews can be used in building
classifiers that discriminate between likely outcomes of
fatality   ii  crucial features in determining outcome can be
identified through principle components analysis  pca  
 iii  unsupervised learning principles such as k means
clustering can be applied to group individuals into
canonical patient profiles  appending data on cause of
death  we can then gain insight on the most likely cause of
death for a new patient fitting one of these profiles   

data  
patient profile data was obtained from a   year trial
retrieved from the international stroke trial database  we
started with over        data points  but performed a
refinement process to remove patients with incomplete
patient profile  and those that remain alive  since our goal is
predicting outcome of death if one were to die  in the end
we generated preprocessed data set of       patients  for
each patient  there are    features that we are focusing on 
sex  age  atrial fibrillation  visible infarct under ct  aspirin 
systolic blood pressure  facial  arm  leg deficit  dysphasia 
hemianopia  visuospatial disorder  brainstem signs  and
other deficits  possible outcome of death dead   dead  
 dead  correspond to initial stroke  recurring ischemic 
recurring hemorrhagic  pneumonia  heart disease 
pulmonary embolism  other vascular  and non vascular
causes  to avoid comparing binary and continuous
features  we set age    and bp     to   and    otherwise 
feature

    figure      outline  of  tools  used  in  study  
by demonstrating how the cause of fatality following
ischemic stroke is highly connected to patient profile
extracted from initial examination  our results in this paper
serve not only as an effective classification tool  but also
lay the foundations for creating more robust prediction
tools for clinical applications 

sex
age
ratrial
rvisinf
rasp 
rsbp
rdef 
rdef 
rdef 
rdef 
rdef 
rdef 
rdef 
rdef 

metric

description

gender of patient  male      female     
    
age in years                     
     
    presence of atrial fibrillation
    
    infarct visible on ct imaging
    
    aspirin taken within   days of randomization
    
    systolic blood pressure      
     
face deficit  yes  no  cant access 
      
arm hand deficit  yes  no  cant access 
      
leg foot deficit  yes  no  cant access 
      
dysphasia  yes  no  cant access 
      
hemianopia  yes  no  cant access 
      
visuospatial disorder  yes  no  cant access 
      
brainstem cerebellar signs  yes  no  cant access 
      
other deficits  yes  no  cant access 
      
table    feature description and quantification

fioutcome

metric

description

dead 
   
    initial stroke
dead 
   
    recurrent ischemic stroke
dead 
   
    recurrent hemorrhagic stroke
dead 
   
    pneumonia
dead 
   
    coronary heart disease
dead 
   
    pulmonary embolism
dead 
   
    other vascular or unknown
dead 
   
    non vascular causes
table    outcome descriptions
  

feature  selection    
principal components analysis  pca  maps data of
original feature dimension n to smaller dimension k  these
new principal components or pcs are linear combinations
of original features that carry maximal variance when data
is projected onto it  original data set is represented by only
   features  which happen to be predictive of stroke risk
according to literature  therefore most algorithms were
done on full feature dimension  feature selection
techniques such as pca  however  can give intuition on the
most important factors in determining patient outcome    
  

k    means    
k means clustering algorithm was implemented in matlab
with   and   centroids  k means is an unsupervised
learning algorithm  which clusters patient profiles into k
centroids by minimizing weighted norms between data
point and centroid position  we represented each patient
with pj representing a    dimensional vector containing
profile information  and j denotes the mean of points in
cluster gi 

argmin 

 
   

     

       

our algorithm runs until convergence after      iterations 
  

supervised  learning  algorithms  
after performing pca analysis and seeing how the original
   features were indeed highly representative and
predictive of eventual patient outcome  all supervised
learning algorithms were performed on full feature
dimension  n      each learning algorithm was performed
on varying sample size after applying randomization
algorithm to choose subset of size m                   
from full data set  in addition to generalization error 
training error was computed as well for knn and
multiclass logistic regression 
  

nave  bayes  
multiclass nave bayes was implemented in matlab based
on frequency of observed features values and
corresponding outcomes  laplace smoothing of smoothing
parameter       was applied  assumption of independence
and gaussian distribution was made despite some features
having high correlation  i e  facial  arm  and leg deficit
usually come together  
  

support  vector  machine   svm   
support vector machine was implemented in r using
e     package  a variety of linear  gaussian  sigmoid  and
polynomial kernels were applied to predict patient fatality

outcome  training was performed on     patients  which
generated     support vectors            and a c  
constant of the regularization term in the lagrange
formulation 

multinomial  logistic  regression   softmax   
the multinomial logistic regression  is a supervised
learning algorithm where output can take on arbitrary k
outcome classes  it requires significantly more training
time than nave bayes since iterative algorithms are
necessary in parameter estimation  most of the computation
was done with mnrfit function on matlab  in order to
build the multiclass model  we estimate       k  rn  
parameters  where i vector stores coefficients of ith
outcome for each n feature and intercept term  probability
of a patient being classified into certain outcome equals 
exp           
                   
     
      exp      
applying maximum a posteriori decision rule  we classify a
new patient into outcome of highest probability 
 
      


 

 

  

 

    

       

exp           
     
      exp      

we use the cost function as defined by and determine
corresponding theta parameters 

k  nearest  neighbors   knn   
knn classifies each new test patient based on the most
popular labeling of k nearest neighbors  as determined by
the weighted norm of euclidean distances  for our model 
we have k     since it is large enough to reduce noise on
classification but avoids making boundaries between
classes indistinguishable 

results
profile    n     
dead 
dead 
dead 
dead 
dead 
dead 
dead 
dead 

profile    n     

p   value

       
       
      
       
       
      
      
      
      
       
       
    e   
       
       
      
      
      
       
       
      
      
      
      
    e   
table      cluster k means profile outcome distribution

fifigure    a   patients are clustered on feature profiles with   centroids 
outcome distributions shown below b   patients are clustered on feature
profiles with   centroids  outcome distributions shown below  different
profiles  i e  male vs female  presence absence of facial  arm  and leg
deficit  have distinct outcome distribution 
  clusters 

figure    training testing error vs number of samples  relatively high
error percentages       due to failure of convergence in determining
theta parameters 

profile    m     n n n bp     y y y y n n n n
profile    f     n n n bp     n y n y n n n n

  clusters 
profile    f     n y n bp     y y y y y y n n
profile    f     n n n bp     y y y n n n n n
profile    m     n n n bp     y y y n n n n n
profile    m     y n n bp     y y y y y y n n

figure    training testing error vs number of samples  average    
generalization error with significantly lower testing error      

figure    testing error for nave bayes multi classifier in relation to
patient sample size 

figure    percent of variance over training data accounted for by each
principal component 

figure    testing accuracy for  n       on svm with sigmoid  linear 
polynomial  and radial kernels  it is evident that polynomial and radial
kernel leads to drastic decrease in generalization error as number of
training examples increase past the threshold of n      

figure    principal component scores in lower dimension by first two
pcs  lack of distinct clusters observed implies poor linear separation of
data 

fimodel
testing error
n iterations
nave bayes
    
    
softmax
    
    
knn
    
    
svm  sigmoid 
    
    
svm  linear 
    
    
svm  polynomial 
    
    
svm  radial 
    
    
table    generalization error for different supervised learning algorithms

discussion  
feature  selection  
based on literature studies on predictive factors of ischemic
stroke  it is well known that features such as age  sex  blood
pressure  infarct size  and craniofacial deficits are very
important in determining patient outcome  therefore  our
initial hypothesis was that running our learning algorithms
on full feature dimension produces lowest generalization
error  which is true  although our data is not characterized
by large feature dimension  principal component analysis
could still reveal some important relationships between
different features as well as the predictive value each
individual feature has on outcome of fatality  as shown in
figure      over     of all variance is accounted for just by
the first two principle components  features  age  sex  and
blood pressure were quite indicative of death outcome 
finally  there seems to be high correlation between
arm hand deficit and leg foot deficit as well as hemianopia
and visuospatial disorder 

unsupervised  learning  
in this project  we used k means clustering algorithm as
both an exploratory tool to determine underlying structure
within data points as well as a way to generate canonical
patient profiles for important clinical applications 
resultant clustering representation confirms the presumed
idea that gender is one of the most predictive measures for
eventual outcome of death  this is evident in both the case
with   centroids and   centroids  from figure    a  we
gain insight on the characteristics of the common stroke
victims  they are profile    male  age    or older  highblood pressure  with facial  arm  leg deficit  and signs of
dysphasia  and profile    female  age    or older  high
blood pressure  with arm hand deficit and dysphasia  there
were     patients corresponding to profile    and    
corresponding to profile    after appending supervised data
for these patients  calculating distribution of death
outcome  and conducting a   sample t test to compare the
differences in mean patients falling into each outcome
category  we determined p values for differences in
outcome distribution  from table      it is evident how
profile   patients have a statistically significant higher
chance of eventually dying of pneumonia immune system
failure or other vascular causes  p       e    and p  
      respectively  similarly profile   patients face much
higher risks of coronary heart disease and non vascular
causes of death than former candidates  p         and

p       e    respectively  figure   b illustrates k means
algorithm applied in generating four profiles of distinct
outcome distribution 

supervised  learning  
all results from learning algorithms were performed on full
feature set  which led to minimization of training and
generalization error  we first implemented a multiclass
nave bayes classifier as our baseline supervised 
parametric model  as seen in figure      the model
performed fairly well  achieving approximately    
testing accuracy      error   considering there were  
outcomes to choose from  comparing this to percentage
accuracy of random decision        we achieved a greater
than   fold prediction accuracy increase  as the number of
classification outcomes increase  generalization error
generally rises as well  furthermore  in the context of
predicting likely outcomes following initial ischemic
attack  even minor increases in prediction accuracy carries
high clinical utility  there are future steps to take in
reducing error reducing error percentages  it was also
discovered that most death outcomes corresponded to
initial stroke  pneumonia  and non vascular causes
 dead   dead   and dead  respectively  and our
nave bayes model almost exclusively predicted those
three outcomes  thus resulting in a fairly high
generalization error 
the next parametric supervised learning algorithm we
explored was the multiclass logistic regression  softmax  
as seen in figure     the algorithms generalization error
was quite high at approximately     for all sample sizes 
training error starts relatively low at     and
asymptotically increases to match generalization error as
sample size increases towards n       this larger error
value was largely due to failure upon converging on true
theta parameters during training for large sample sizes with
mnrfit matlab software  overall  multinomial logistic
regression can only serve as a reference point  and has less
capability in outcome prediction 
taking a different approach with the non parametric
knn classifier  with k     we achieved a     testing
accuracy      generalization error   which is slightly
worse than nave bayes  figure     depicts the significantly
smaller training error 
finally  to gain more insight into the data  we used
support vector machines with multiple kernel options
 figure       our svm model using polynomial kernels
provided the best accuracy of     when using at least
     training examples  this leads to the optimal     fold
increase in prediction accuracy  radial kernels performed
quite well as well with     accuracy  finally  linear and
sigmoid kernels performed with only     and    
accuracy respectively  given that linear kernels had a
relatively poor performance  we confirm the fact that our
data is not linearly separable as indicated previously by
pca results  for the polynomial and radial svms  the
generalization error decreases with increasing training
examples  specifically past the threshold of n       our
svm algorithm was limited because of the extremely high

fifeature vector dimensions  resulting in over fitting and
inaccurate generalization to other data  though this issue
could have been mediated by extensive parameter
adjustment or feature reduction  we chose not to apply
these techniques because of the complexity of our data  the
significance of all of our utilized features  and already
having reduced our error significantly 

conclusion  
in this article  we demonstrated how nave bayes and
support vector machines  polynomial  leads to maximal
outcome prediction accuracy of       and    
respectively in classifying   different death outcomes
following initial ischemic trauma  using    crucial features 
comparing to the average predictive accuracy following
randomization          our best algorithm achieves up to a
    fold prediction accuracy increase  which carries
immense clinical utility in improving a patients chance of
survival and quality of life  with the combination of
unsupervised learning algorithms such as k means and
supervised outcome data  we also built canonical profiles
of the most common patients doctors are likely to
encounter following initial stroke attack  each one
represents a corresponding distribution of death outcomes 
new patients can then be fitted into the most representative
profile and plan of action will be taken to minimize
chances of the most likely ensuing risks 

future   d irections  
future work involves discovering predictive value of
individual features and their relationship correlation
strength with each other  we also plan on extending our
classification model to patients that do not die immediately
after initial ischemic infarction  furthermore  our models
can take into account the likelihood of outcomes at
different timespans after initial attack     days    months   
year  etc  such that physicians can gain intuition on
optimal treatment plans based on particular stage of patient
recovery  finally  many more related studies may be done
using similar learning tools but starting with different sorts
of initial trauma  i e  hemorrhagic stroke  thrombotic
stroke  transient ischemic attack    as well as discovering
the role of pre and post conditioning factors on survival
rates 

  
  
  
  
  
  
  

references  
    ishikawa  h   n  tajiri  j  vasconcellos  y  kaneko  o 
mimura  m  dezawa  and c  v  borlongan   ischemic stroke
brain sends indirect cell death signals to the heart   stroke
                        web 
     machine learning blog   software development news  
datumbox  n p   n d  web     nov       
noback  charles r  the human nervous system  structure
and function  totowa  nj  humana        print 
    sandercock  peter ag  maciej niewada  and anna
czonkowska   the international stroke trial database  
trials                   web 
    shan  li yang  ji zhao li  ling yun zu  chen guang
niu  albert ferro  ying dong zhang  le min zheng  and
yong ji   platelet derived microparticles are implicated in
remote ischemia conditioning in a rat model of cerebral
infarction   cns neuroscience   therapeutics              
        web 
    stetler  r  anne  rehana k  leak  yu gan  peiying li 
feng zhang  xiaoming hu  zheng jing  jun chen  michael j 
zigmond  and yanqin gao   preconditioning provides
neuroprotection in models of cns disease  paradigms and
clinical significance   progress in neurobiology         n 
pag  web 
     types of stroke   johns hopkins  n d  web     nov 
     
     understanding stroke risk   understanding stroke risk 
n p   n d  web     nov       

fi