amazon employee access control system
shijian tang  jiang han and yue zhang
department of electrical engineering
email  sjtang stanford edu
abstractin this work  based on the history data of          from amazon inc   we build up a system which aims to
take place of resource administrators at amazon  our analysis
shows that the given dataset is highly imbalanced with categorical
values  thus in the preprocessing step  we tried different sampling
methods  feature selection as well as one hot encoding to make
the data more suitable for prediction  in the prediction step 
initially we tried single models which are suitable for categorical
data like naive bayes  k nearest neighbors  k nn  and decision
tree  then due to the performance limitation  we further applied
ensemble methods like random forest and gradient boosting  in
addition  with one hot encoding which transforms the categorical
data into binary values  we are able to apply linear classifier
and obtain satisfied performance  finally  we ensemble three
best prediction results from random forest  gradient boosting and
logistic regression  with encoded data   and improved area under
curve  auc  from initial         decision tree  to        
keywordsimbalanced classification  categorical feature  one
hot encoding  random forest  gradient boosting 

this paper can be organized as follows  we will first
describe and preprocess the data set in sections ii and iii 
then  we will briefly introduce several types of models such
as single classifiers described as well as ensemble models in
section iv  in section v  we will present the prediction results
for these models  at last we will summarize our work and
draw conclusions in section vi 
ii 

data d escription

the data comes from amazon inc  collected from           published on kaggle platform  with training set of
      samples and testing of       samples  as shown in
table i  each of the data samples has one label attribute
called action  where value   indicates this application is
approved and   indicates rejection  in addition  each samples
has eight features  which basically indicates different role or
group of one employee at amazon 
table i 

i 

i ntroduction

an employee may need to apply for different resources
during his or her career at the company  for giants like google
and amazon  due to their highly complicated employee and
resource situations  the application review process is generally
done by different human administrators  in this project  based
on the history data of      to      done by human administrators at amazon inc   we aim to build up an employee
access control system  which automatically approve or reject
employees resource application 
determining resource access privileges of employees is a
popular real world challenge for many giant companies like
amazon  when employees start to work  they first need to
know what kinds of resources of the company they are or they
are not supposed to get access to  the resources maybe very
diverse  like computing resource and storage resource  it is
supposed that employees fulfilling the functions of the same
or similar roles should access the same or similar resources 
here we have the data set from a knowledgeable supervisor
who takes time to manually grant the employee requests for
resource access  for the purpose of saving money and time
to allocate resources for the coming and going employees 
we built up a predication model that automatically determine
resource access privileges of employees 
in this problem  the data set is extremely imbalanced 
where one of the classes action     has a significant
less number of occurrences than the other action          percent   due to most of the learning algorithms design
principle of minimizing the overall error rate to which the
minority class contributes less  they always perform poorly in
problems with imbalanced data set 

data f eature d escription

feature name
action
resource
mgr id
role rollup  
role rollup  
role deptname
role title
role family desc
role family
role code

feature meaning
   approved     rejected 
resource id
id of the employees manager
company role category id 
 e g  us engineering 
company role category id 
 us retail 
department description
business title description
role family extended description
role family description
 e g  retail manager 
unique id for each company role
 e g  manager 

as for the evaluation metric  receiver operating characteristic  roc  curve is used to summarize classifier performance
over tradeoffs between true positive and false positive error
rates  and we use area under the roc curve  auc  as a
useful performance metric for imbalance classing problems 
iii 

data p reprocessing

in this section  we did three parts of work  which are 
balancing the dataset  one hot encoding and feature selection 
a  imbalanced dataset
as we described above  the given dataset is extremely
imbalanced with the number of one class significantly lower
than the other  in real life  many issues can be described as
imbalanced classification problem  such as medical diagnose 
text categorization  online resources management and so on 
recently  the main approaches to solve the imbalanced
classification is trying to balance the distribution between

fitable ii 

o ne   hot encoding example

category data
      
      
      

table iii 
feature index
variance       
feature index
variance       

frequency variance of each feature based on eq      
 
x f req sj   
sum
v ar fi    
f req sj   
sum
 fi uniq  
s

one hot encoded eata
   
   
   

f eature f requency variance
f 
      
f 
      

f 
      
f 
      

f 
      
f 
      

f 
      
f 
      

   

j

f 
      

minority and majority classes in training set         to make
the dataset suitable for standard machine learning models 
these techniques includes oversampling  undersampling    
and synthetic minority over sampling technique  smote 
    
   random oversampling and undersampling  oversampling typically refers to balance the data distribution by
sampling the minority class data with replacement  on the
other hand  undersampling changes the distribution of data by
randomly removing the data in majority class  although the
performance will be improved by the above sampling methods 
the shortcomings of oversampling and undersampling are obvious  oversampling will result in overfitting  and undersampling
may loss the importance information from dataset 
   smote  smote is an oversampling method  which
will generate synthetic training samples     instead of removing or duplicating raw data  the basic idea of smote is that
for each minority class sample  we create a synthetic example
from some of the k nearest neighbors of that sample  based
on the number of new samples we need  we will randomly
choose some neighbors among all the nearest neighbors  this
process can be interpreted as choosing a random point in the
line between two feature vectors as our new samples 
b  one hot encoding
since the original features are discrete category values
which indicate different types  we can not directly apply linear
classifier models on this kind of data  in order to apply linear
classifier on this data  we need to use one hot encoding 
one hot encoding refers to bits that only have one single
active   while all remaining bits are inactive  s  in the
given amazon data  one feature may include multiple discrete
categorical values  in order to apply linear classifier  it is
necessary to separate those values with only one active at a
time  table ii shows the example with one hot encoding on
a feature with three categories  which will be encoded into
         and     separately  we see that this encoding
method will expand the feature space from one to five  sine
most of the sample values are  s  we use sparse matrix to
represent the newly encoded feature space 
c  feature selection
removing features with low variance is a common approach in feature selection      in this work  we calculate the

where sj  fi uniq   and fi is the ith feature and fi uniq is the
set with all the unique feature values of fi   function f req sj  
indicates the frequency of sj    fi uniq   is the size of fi uniq  
i e 
p the unique value number of feature fi   in addition  sum  
f req sj    which is the frequency sum of each sj  
sj

table iii shows the analysis result of frequency variance
of all nine features  from which we can see that feature   and
feature   have obviously small variance  hence  we remove
those two features in the further analysis steps 
iv 

p redictions m odels

a  single classifier
in this section  we briefly introduce some single classification models we applied for initial testing  here  single
corresponds to the ensembling in the next section  they are
commonly used  thus we do not introduce the details here 
   naive bayes  in this project problem  we treat all the
features to be mutually independent  this naive independence assumption allows us to apply naive bayes algorithm in
the given categorical data  also  laplace smoothing is applied
to those features never seen in the training  thus  one sample
is labelled with   when p    f     fn     p    f     fn   and
vice versa 
   k nn  k nn algorithm is also suitable for categorical
data  it will label testing samples based on their nearest k
neighbors in the training set  since the given data is categorical 
we use hamming distance instead of educlidean distance 
smaller hamming distance between test sample and specific
training sample indicates they two are closer in the space 
besides  we combine the labels of k neighbors based on their
hamming distance  closer neighbor will own higher influence 
   decision tree  decision tree builds classification models in the form of a tree structure  it breaks down a dataset
into smaller subsets based on its features while an associated
decision tree is incrementally developed  the final result is a
tree with decision nodes and leaf nodes  a leaf node represents
a classification or decision 
   logistic regression  logistic regression is a commonly
used linear classifier  which is simple but relatively efficient 
b  ensemble methods
ensemble method is a type of supervised learning  which
employs a set of classifiers and their decisions are combined in
certain way  compared with single classifier  in the ensemble
model  the output  decisions  depends on the vote of all the
individual classifiers  generally  the ensemble model containing bagging is also known as bootstrap aggregating     and
boosting     
the main idea of bagging is that we generate several new
training data set by randomly uniform sampling the original
data set with replacement  then use each new dataset to train

fia model  and the output equals to the dominate vote by all
the trained models  typically  we choose decision tree as each
training model in many practical problems 
boosting is an alternative ensemble method in machine
learning  compared with bagging  the basic rule of boosting
is that by combining a set of weak learner properly  we can
obtain a strong learner  the boosting algorithms are typically
performed iteratively      in each iteration  we add a new weak
learner to the set of learners 
among several boosting algorithms  the adaptive boosting
 ada boosting      and gradient boosting     are most popular 
in the subsection iv b   we will briefly describe the
random forest method  which is developed based on bagging
and will be adopted in our paper  then  in subsection iv b  
we will introduce the gradient boosting model in detail  we
employ the above two models to solve our problem 
   random forest  random forest     combines the methods of bagging with random subspace  the main idea is that
we build a set of decision trees not only depends on the
random sampling of training data  but also randomly selecting
the features when we building each tree  in prediction  we
will takes all the decisions made by each tree into account
and select the majority result as our prediction  in      each
tree in the forest can be generated in the following three rules 
first  randomly choose samples with replacement from original
data set to form a new data set  same as bagging   second 
randomly choose a subset of features for each tree  and we
split the nodes during building the tree based on this subset of
features  the last is building the tree without pruning 
in      it reveals the fact that random forest model is able
to prevent overfitting  that is as the increase of tree number 
the generalization error will converge to an upper bound 
pe      s    s 

   

where pe is the generalization error   as the mean value of
correlations and s is defined as the classifier set strength 
based on eq      we find that the performance of random
forest depends on the correlation between each tree  the
performance will degrades as the increase of correlations  and
the author of     also shows that the correlation of trees is
mainly determined by the number of the features we selected
when we split the nodes  the less number of features we
choose  the trees will become more uncorrelated  and then the
generalization error
 will decrease  the authors suggest that 
we choose the n as the number of features we selected to
build the tree  with n as the number of features in training
dataset 
   gradient boosting  the gradient boosting     is a type
of boosting algorithms  boosting process can be described as
fi   fi    i hi  x  ai   where fi is the learner in the i th
iteration which may be a poor learner at this step  i is a
parameter to weight the new estimator hi  x  ai    and ai is the
parameter in function h  in gradient boosting  the parameters
i and ai are determined by minimizing the cost functions in
current iteration 
m
x
 i   ai     arg min
l yj   fi   xj     hi  xj   a      
 a

j  

where xj   yj are the j th training samples with j           m 
h x  a  is a simple functions added in the i th iteration
with a as the parameters to be determined  l yj   fi   xj    
hi  xj   a   is the cost function between the output yj and the
model in the i th iteration which is fi  xj   
solving eq      consists of two steps  the first step is
determining ai follows the expression as
ai   arg min
ai  

m
x

ri j  h xj   a 

   

j  

with rj i is the pseudo residuals with details in     
after finding the current estimator h x  ai    we can further
solve i by 
i   arg min


m
x

l yj   fi   xj     hi  xj   ai   

   

j  

from eq           points out that in the case of cost function is
convex  the gradient boosting is actually equivalent to gradient
descent in function space 
based on the description above  the most significant parameters in gradient boosting are the selection of weak learners as
well as the cost function  there are several candidates for cost
function such as least squares and exponential functions  for
week learner  the most popular choice is decision tree  where
the gradient boosting model is often called gradient boosted
decision trees 
in the following section  we will discuss how to implement
the gradient boosting to solve our problem 
v 

p rediction r esult

in this section  we will show the simulation results with
different prediction models  firstly  we try single predication
models which can be applied directly on categorical data like
naive bayes  k nn and decision tree  secondly  since we
found out that single classifier does not well on the given data 
we further try ensemble models including random forest and
gradient boosting based on decision tree  in addition  we show
the auc performance of logistic regression with one hot encoded data  which verifies the advantage of one hot encoding 
in the final  we combine the three best prediction results from
random forest  gradient boosting and one hot encoding based
logistic regression to obtain further performance improvement 
a  single model with categorical data
in this subsection  we present the prediction results based
on different single models  in addition  different dataset with
raw data  under sampling  over sampling and smote are also
taken into consideration for comparision 
table iv shows the prediction results of naive bayes  knn
and decision tree  we can see that since the data size is
big enough  the difference between training and test auc
is generally quite small  for different sampling method  we
see that direct prediction on raw data can not work well
due to the imbalanced data type  while under sampling and
smote generally work better than over sampling method 
which mathes the conclusion drawn by     

fithe training auc as a function of maximum depth of decision tree

auc performance of random forest
    

    

    

    

    

    

    

area under curve  auc 

area under curve  auc 

training auc

    
    
    
   
    

    
    
   
    
    

test auc
training auc

    
    

    

 

  

   

   

   

   

    
   

    
 

tree number

 

 

 

  

  

  

  

the maximum depth of decision tree as weak learner

fig    

the training and testing auc for various tree numbers 

fig     the training auc as a function of maximum depth of decision tree
with     iterations 

auc curve of random forest with tree number equals    
   
training auc
testing auc

degrade too much as the tree number increases  i e   the overfit
can be prevented  these results match with the conclusion we
described in subsection iv b  

area under curve  auc 

    

   

    

   

    

   

 

   
 
training data size

   

 
 

x   

fig     the training and testing auc for various training data set with tree
number as     

another important information conveyed by table iv is
that since the best test auc performance is around      here 
we may conclude that one single prediction model can not
work well on the given problem and dataset  this makes us to
think about using some upgraded ensembel method 
table iv 

auc of naive bayes   k nn and d ecision t ree
raw data

training auc
test auc

      
      

training auc
test auc

      
      

training auc
test auc

      
      

under sampling
naive bayes
      
      
k nn
      
      
decision tree
      
      

over sampling

smote

      
      

      
      

      
      

      
      

      
      

      
      

b  ensemble model
   random forest  first  we will adopt the random forest
model for prediction  as suggested in      the number of
features we random selected for each tree is the root square
of the total number of features  we use cart trees without
prune  which is also implied in     
first we choose different number of trees to build our
model  the training and testing auc for different tree numbers
from    to     are depicted in fig     the auc for training
data is the average auc calculated from    fold cross validation from training data 
fig    demonstrates that as the increase of tree number  the
performance of testing auc gradually converges and does not

from fig     we can observe that     is a good choice for
the tree numbers  which will not degrade the auc performance
compared with the cases of less trees  on the other hand  it is
also not necessary to choose too large number of trees  the
time complexity will increase but the performance will change
sightly  therefore we choose the tree number as     in our
further prediction 
in fig     we plot the learning curve characterized by auc
versus the size of training data set  for the training auc  we
use    fold cross validation to calculate the average auc for
each size of training data  the learning curve implies that as
we enlarge the training data set  the training and testing auc
converge to an expected value         this means that random
forest is a good model for this problem and no overfitting
yields 
   gradient boosting  in this subsection  we will discuss
the results of gradient boosting  we choose the decision tree
as weak learner  recall the discussion in subsection iv b  
we should select the parameters in the tree to specify the
weak learner  typically there does not exit a general method
to determine the parameters such as maximum depth and
minimum sample splits in the decision tree  they depends on
the practical problems  in      the authors suggest that the depth
of tree is more important than other parameters 
therefore  we go through several maximum depth from
  to    over     iterations  note that we have test that for
this specific data  after     iterations  the performance of
model will converge  the training auc based on    fold cross
validation for each maximum depth has been plotted in fig 
   fig    indicates that the optimal depth locates at    next 
we consider the training and testing auc based on the weak
learner we just found  by increasing the size of training data 
the training auc based on    fold cross validation and the
testing auc are illustrated in fig     similar with other models
we have implemented  the auc curves will converge to an
expected value  auc        for full training data set  
finally  let us compare the results from two ensemble
models  random forest and gradient boosting  we find that
for large training data size  the performance of random forest
are competitive with gradient boosting  with testing auc as

fiauc curve with gradient boosting with maximum depth as   and     iterations
   
training auc
testing auc

auc of logistic regression with onehot encoding
 

    

   
area under curve  auc 

area under curve  auc 

training auc
test auc

    

   

    

   

    
   
    
   
    
   

    
 

    
   

 

   
 
training data size

   

 

   
 

   
 

x   

fig     the training and testing auc with gradient boosting with maximum
depth as   and     iterations 

       for random forest and        for gradient boosting 
this conclusion matches the experimental results from    
where the authors conclude that the performance of random
forest will be competitive as boosting  however  from the view
of practical problems  the random forest will beat the gradient
boosting in some aspects  first  the random forest is more
flexible since we do not need to select the weak learner which
will cost additional time in boosting  second  the random forest
runs much faster than gradient boosting especially when weak
learner depth is large  therefore  to make our model more
flexible and efficient  random forest is a better choice 
c  linear classifier with one hot encoding
in section iii  we mentioned that linear classifier can not be
applied directly to the raw data due to the categorical feature
values  with auc for svm around       in this subsection 
we apply one hot encoding to transform the raw feature into
binary feature values and thus expand the feature space  after
one hot encoding  with only one unique feature value active
in each column  we can apply linear classifier in new feature
space 
here  we choose the logistic regression to fit the model 
fig    shows the prediction result of logistic regression with
one hot encoding  different data size is chosen here to show
the difference between training and test auc performance 
from fig    we can see that after one hot encoding  the
best test auc value can achieve         which shows the
great advantage of one hot encoding  also  note that with
training data size increase training and test auc performance
converges to very close values 

until now  we have three relatively better prediction results 
which are  random forest  test auc          with tree number
of       gradient boosting  test auc           and logistic
regression with one hot encoding  test auc            in this
subsection  we will ensemble those different prediction models
for further performance imporvement 
roughly consider the above three models are mutually
independent  and since they have similar auc performance 
lets roughly take their test error as   for three classifiers with
binary classification  their ensemble model will make incorrect
prediction only when more than two of them are incorrect 
   

 

   
 
training data size

   

 

   
 

x   

auc of logistic regression with one hot encoding

here  ensemble is the prediction error rate of ensemble model 
solve inequation ensemble    and get         thus by
ensembling those three models  we generally get better result 
in this last step  we combine the prediction results of
random forest  gradient boosting and logistic regression with
one hot encoding  by getting the weighted  training auc as
the weight  average value of the three models  we finally
improve the test auc result to        
vi 

c onclusion and f uture w ork

in this work  based on the history data from amazon
inc  we built up an automatic system to review employees
application on resources  in the preprocessing  low variance
feature remove method is used for feature selection  we also
applied different sampling methods and one hot encoding to
make the data balanced and suitable for linear classifier  in
the prediction step  we tried single models on categorical
data  verified one hot encoding with logistic regression  after
that  we also applied ensemble methods like random forest 
gradient boosting and best three ensemble to further improve
auc  the auc performance finally achieves        from the
initial        by single decision tree  in the future  we plan to
apply feature grouping strategy  use more linear models with
one hot encoding data and try different boosting models for
performance improvement 
r eferences
   

   

d  further ensemble

ensemble   c             c             

fig    

   

   

   
   
   

   

n  japkowicz  class imbalance  are we focusing on the right issue  in
proceedings of the icml   workshop on learning from imbalanced
data sets       
n  chawla  l  hall  k  bowyer  and w  kegelmeyer  smote  synthetic minority oversampling technique  journal of artificial intelligence research  vol      pp                
i  guyon and a  elisseeff  an introduction to variable and feature
selection  journal of machine learning research  vol     pp                 
l  breiman  bagging predictors  machine learning  vol      no    
pp               
l  breiman  random forests  machine learning  vol      no     pp            
m  collins  r  schapire and y  singer  logistic regression  adaboost
and bregman distances  machine learning  vol      no       pp               
j  friedman  stochastic gradient boosting  computational statistics  
data analysis  vol      no    pp                

fi