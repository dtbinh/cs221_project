classifying syllables in imagined speech using eeg data
barak oshri  boshri   nishith khandwala  nishith   manu chopra  mchopra 
   introduction

language is understood in common use  for this reason
we pursued the paradigm that phonetic qualities of
words affect how their associated syntactic rudiments
are stored in the brain  where it follows that language
as thought in the mind is being produced with some
correlation to how the language was learnt and understood on first basis  given this hypothesis  the role of
machine learning in imagined speech classification is to
tailor models that can evaluate and predict syntactic
features 

an increasingly important advancement waiting to
happen in brain computing technologies is interfacing
with speech in the mind  as fluency and dependence
on technology raises the demands for faster  cleaner 
and more productive interfaces  the pathways such an
accomplishment would pave in the scope of our communicative abilities would lead to a revolution in our
natural and digital interaction with the world 
advancements in imagined speech technologies is suffering from evading a holistic approach to understanding how we can read and interpret language in the
mind  current research in this field is producing a
limited and acute set of tools to systemize far too specific instances of a task  such as classifying yes and
no  not only are these studies archetypal cases of
over fitting to the details of the experiment with which
they were run under  but they encourage an outlook for
studying imagined speech that is myopic and fails to
represent the complexity of the task  for any solution to
this problem must be scalable to large groups of people
and preferably multiple languages 

the focus of our research  then  is to discuss how
multiple syllables can be classified between each other
with the ambition in future research that accurate classifications of syllables will allow predictions of arbitrary
strings of them  or words   it is no less than a beauty
that a finite number of syllables give rise to the entire
breadth of a language 
we will thus explore two machine learning approaches
to do this task  the first includes using knn and naive
bayes to examine how we can build a model out of elementary features of the data  and the second involves
the use of artificial neural networks to seek nonlinear
patterns for prediction 

the shortcomings of imagined speech research  however  are not wholly unexpected  given our severely
limited neurological understanding of what conscious
thoughts are and how imagined speech is carried by this
mechanism  it is near impossible to make assumptions
and predictions about the structure of eeg data that
attempts to measure them  also  whereas other imagined actions such as spacial movements are lateralized
to one hemisphere over the other  imagined speech has
equal levels of significant activity in both hemispheres 

   experiment
we created our own data set by making use of takako
fujiokas eeg lab at the center for computer research
in music and acoustics  ccrma   we used a      
system eeg with    channels covering the entirety of
the subjects head  three additional nodes tracked eye
and upper facial movements to assist removing blinking
and face movement artifacts from the data  the eeg
sampled at a rate of    hz 

this paper does not proclaim to overcome this challenge  what it does do is attempt to engage with and
reason through an experiment that breaks through the
mold of treating imagined speech studies as application oriented exercises and highlights what models and
approaches may yield the best insights in the future of
this promising field 

a subject was asked to imagine speaking the pair of
syllables ba   ku and im   si alternating between
trials  a low and a high pitch tone were predecided
before the experiment to correspond to the the pair of
syllables  the lower tone corresponding to ba or im
and the upper tone corresponding to ku or si  in
one round of readings      trials of a syllable pair     
    approach
of each syllable  were mixed randomly and presented
an approach to understanding imagined speech using to the subject as the tones  after a short break  the
eeg needs to be foundational and scalable  it needs experiment was repeated with the other pair of syllato model a system from eeg data just as a natural bles  we then performed the first pair again in another
 

fithat were imagined with the same pitch 

round and the second pair in the next  in total     
readings each of ba  ku  im  and si were collected 
the length of the queuing sound lasted for     seconds  enough to perceive the pitch but not too long
that response to the tone interferes with thinking  the
subject was given     seconds and asked to utter the
correct syllable once  after which he was asked to rest
his mind until the next beep is heard 
a time line for a single trial for the syllable pair  ba 
ku  is shown below 

   features
    mean feature extractor
perhaps the most natural extractor is to approximate
each wave with a series of points that are averages of a
segment at the points position  this is principally useful because the feature space considering every recordthe obtained eeg data contained the presence of
ing of the wave for all    channels would amount to a
artifacts from blinking and facial muscle contractions 
feature dimension that is too large and would overfit
the eeg data was preprocessed to remove these arthe data  we also use this feature extractor because it
tifacts in eeglab  the electromyographic artifacts
is neurologically relevant and can be used to identify
were removed and the signals from electrodes closest
event related potentials  erps  and other characterto the ear   neck discarded  data processing identiistic motifs by identifying points and times that are
fied that     of the     trials recorded were too noisy 
especially informative of the class 
mostly in the pair of trials ba   ku  the results for
im   si were accordingly given greater significance 
the mean feature extractor also provides an intuitive
way of producing canonical syllable waves with higher
after processing out the artifacts  we trimmed out
signal to noise ratio by averaging all trials of a syllable
each trial to the length of the relevant data  given
together  this will be useful in making measurements
that it takes a regular subject approximately     secof deviation of the individual trials from a representaonds to imagine speaking the syllable  we trebled that
tive  the figure below shows a wave from a channel
time frame to include the decision process  imagination 
which is divided into   parts and averaged with all
and decline of the thought signal  so we reduced each
trials of the class 
trial to     to     of the original signal starting at     
note that by deciding to include the part of the signal where the subject is simultaneously reacting to
the sound and deciding which syllable correctly corresponds to its pitch  we have inadvertently created
a separating criterion that allows a machine learning
model to classify the trials based on the brain response
to the pitch  this is a nontrivial complication that
is not accounted for in most syllable studies  but for
which we have considered by making multiclass classi  so if ch i j  represents the value of point j in chanfications that include classifications between syllables nel i  then the feature vector is
 

fi ch             ch        ch             ch         y               
accuracy

which has             dimensions  we use the notation y     to donate ba  y     to donate ku and so
on 

ba

ku

im

si

      

      

      

      

table    multiclass knn

the results for knn are promising but not ideal 
ku and im are being classified at rates significantly
better than random        but the prediction rates for
we also extracted the wavelet coefficients by decomposba and si are insignificant  since one syllable in the
ing the eeg signal using a discrete wavelet transform
two trials performs well and the other doesnt  it leads
 dwt   dwt has proven useful in characterizing the
suspect that biases between conjoining the two experisignals of eeg data because it uses non stationary time
ments are leading to this symmetrical result 
series analysis and leads to good time frequency localization by using longer time windows at low frequencies
    naive bayes
and vice versa  since the transform leads to an excessively large coefficient space  we performed principal naive bayes can overcome some of the biases in knn
component analysis independently on each of the ap  by generating a model for each class independently 
proximation matrix  first level horizontal and vertical essentially  the naive bayes assumption in this case
images of the transform to produce a smaller four di  means that a wave is characterized by its amplitudes
mensional space  each point was the coefficients of a and that syllables are matched to sample waves that
channel wave with number of dimensions equal to the have the right registers 
length of the transformed signal  the projection then
represents the space of coefficients that best character  the parameters for each class are given as l              
ize the transformed signal 
so

    discrete wavelet transform

k y l  

   classification
    k nearest neighbors

pm pni
 i 
  xj  ky  i   l   
i  
pmj    i 
  y
 l ni   v  
i  

where v is the size of the feature extracted signal and

pm
using k nearest neighbors  knn  allows us to make
 y  i   l
y l   i   m
inferences about how distinct the syllables are from
each other  it is useful as a measure of how successful
after the parameters and probabilities are trained 
our feature space is in drawing out salient linear features of the classes  if knn classifies accurately  than we make estimates for test cases using max likelihood
the syllables partition the feature space into voronoi statistics  we then use   fold cross validation to get
cells with boundaries that have neurological signifi  test predictions 
cance for why they distinguish syllables  if knn is less
predictive then we know that nonlinear patterns are
ba
ku
im
si
needed for more effect 
accuracy                            

we run a modified knn where each trial is assigned
table    multiclass naive bayes
to the averaged wave form of the four syllables it is
closest to  this is so that we can measure how noisy an
individual trial is with respect to an ideal of its class      neural networks
for a given trial wi   we assign to wi
in artificial neural networks  the burden of making
assumptions about the structure of the data is transferred to the training of hidden layers that solve subargmins baavg  kuavg  imavg  siavg   d  wi     s  
problems of the given input  this allows us to find
nonlinear relationships of features along and between
where d  w i   s  is the euclidean distance metric be  channels that can offer greater predictive power than
tween the feature extraction  of wi and a class average the earlier models discussed 
syllable 
 

fia classification of       on the entire data set with
      training accuracy and       testing accuracy is
the number of inputs is the size of the feature vec  suffers from mild overfitting but not to excess  the suctor used  the hidden layers are linear weighted sub  cess of neural networks suggest that the most predictive
problems over a sigmoid activation function  if wi is a features occur in patterned combinations that are not
signal  for each hidden unit hj  
immediately identifiable with single feature expansions 
the neural network with hidden layer of size   also
worked remarkably well in binary classification of the
syllable pair im and si 

hj    vj   wi   

with vj a learned weight and logistic activation function
 z         ez   

we trained a feedforward network using a scaled conjugate gradient backpropagation to update the weights
and measured performance using cross entropy  we
evaluated the performance on different size hidden layers and found that a hidden layer of size   maximizes
the training and test performance      of the trials
were used for training and     of the trials were held
out for testing 

accuracy

ba

ku

im

si

      

      

      

      

this is not surprising given the success of the multiclass classifier  note  however  that the network scaled
to the multiclass case because the number of correct
predictions in the binary and multiclass classifier are
not too distinct 
the neural network also classifies the pair of syllables ba and im that were recorded in response to
the same pitch with equal accuracy  which is especially
interesting because now the nature of the experimental
data has changed  gathered from independent rounds
of measurement  

table    multiclass neural networks

   analysis
an       overall classification rate for neural networks
is stunning and far exceeds results of similar studies
in the field  which generally have prediction accuracies
between     and     and often times on binary classifiers  below is a confusion matrix for the four class
classification of syllables ba  ku  im  and si in that
order 

 

fistate eeg data is used for control experiments  we
think that the accuracy reported in this paper is beyond that expected for given past results in the field 
and that further experiment should be conducted on a
larger data set including multiple subjects 

unlike the naive bayes and knn classifiers  the neural
networks performed consistently well on the variety of
cases tested on  whereas naive bayes and knn did not
scale as well when they classified four syllables instead
of two  this is noticeable comparing the charts of binary and multiple classifications of the models studied 

an ideal approach to imagined speech and general
bci applications can encompass new functionality  and
many of the approaches traditionally used  especially
support vector machines  do not have the representational mechanics to pursue general imagined speech
understanding and expansive bci needs  neural networks are versatile tools for modelling networks of sizes
that grow  alter and expand  and we believe that they
show promising hopes for elucidating brain data 

   acknowledgements
special thanks to cs    ta dave deriso for his incredible support and assistance in this project  we could
not have collected our own data set without takako
fujiokas patience for teaching us how to use and run
the eeg in her lab  and thanks to andrew ng without whom we wouldnt be introduced to this wonderful
material 

   references
   bhagavatula v  advanced signal processing and machine learning approaches for
eeg analysis  jun      
http   www 
researchgate net publication           
advanced signal processing and machine 
learning approaches for eeg analysis
   mingjun zhong et al  classifying eeg for
brain computer interfaces using gaussian process       http   people rennes inria fr 
anatole lecuyer prl   zhong pdf

   future work
neural networks should be further studied for their potential to uncover neural patterns that we do not know
from existing neurological sources  we note informally
that a hidden layer of size   was the optimal size for all
cases studied with neural networks in this experiment 
and that this warrants special attention for it reflects
on a level of patterns implicit in the data and in the
functional sites of the brain it originated from 

   bekir karlk and sengl bayrak hayta  comparison machine learning algorithms for recognition of epileptic seizures in eeg  aug     
http   iwbbio ugr es      papers iwbbio 
     paper   pdf
   michael dzmura et al  toward eeg sensing of
imagined speech       http   link springer 
com chapter                             
page  

given the success of multiple classification of four syllables  we further propose that neural networks be tested
against more a wider range of syllables and that resting

 

fi