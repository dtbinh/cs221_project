cs   

net neutrality language analysis

li tao  xinyi xie

net neutrality language analysis
li tao  xinyi xie
department of electrical engineering  stanford university
email  ltao  stanford edu  xinyixie stanford edu

abstract  the federal communications
commission  fcc  has been seeking public
comments about net neutrality  it is found that a
great majority of these comments were written
from format letters potentially provided by several
campaign groups  principle components analysis
 pca  was first used to visualize the data set and it
is found that the data are obviously clustered 
based on this fact  several classifiers were built up
based on k means clustering  logistic regression 
and na
ve bayes event model to identify if a certain
comment is written from format letters 

public  the comments are being reviewed now
and the fcc is expected to make their final
decision by the end of the year 
in this project  we try to make use of this
rich dataset  specifically  we aim to use natural
language processing techniques and topic
modeling methods to identify the most relevant
keywords in these comments  then  we can make
use of these keywords to group the comments 
once grouped  some of the hidden features
behind the comments can be exploited  for
example  we can classify the comments into agree
and disagree categories  we can also identify if a
certain comment is written from any templates
provided by organized campaigns 
the results of our study will potentially be
considered by the fcc to help them to make the
final decisions  which would greatly influence all
giant internet companies  the whole internet
industry  and everyones life as long as he or she
uses the internet 

keywords  net neutrality  classification  principle
components analysis  k means clustering  logistic
regression  na
ve bayes event model

i  introduction
net neutrality is the principle that internet
service providers and governments should treat
all data on the internet equally  not discriminating
or charging differentially by user  content  site 
platform  application  type of attached equipment 
or mode of communication 
the federal communications commission
 fcc  recently launched a notice of proposed
rule making  nprm  seeking public comments
on how best to protect and promote an open
internet  as its largest ever public comment
collection  the commission announced the bulk
release of all the comments received from the

ii  data processing
the original comments released by the fcc
serve as our raw data and we process this data set
with several java programs designed  our first
goal is to use the original data to build up a
lexicon containing the most frequent and
relevant words in our training set  secondly  we
use the raw data and the lexicon to get a
statistical result that records how many times
   

fics   

net neutrality language analysis

each word in the lexicon appears in each
comment  below is a detailed description 

li tao  xinyi xie

unformatted comments 
iii  models and results

a  building the lexicon
our first java program is designed in order
to build the lexicon  in this part  the program
scans the whole file which contains all the
selected comments in the training set and extracts
every non duplicate word and then records the
times that each of these words appears  the first  
most frequent words are  the  and  internet 
to  a 
leaving out the words with no special
meanings  we manually select out the first   
most relevant words based on the result above
and that comes our lexicon  with the first  
words  choice  common  open  protect 
use 

to visualize the data points  we first
implement principle components analysis  pca 
method to map the data onto a three dimensional
space  after that  k means clustering  logistic
regression  and nave bayes event mode are used
to build the classifier for the data 
all methods are implemented in the same
ways as on cs    lecture notes and problem sets 
we will not talk about the math in details in this
report 
a  principle components analysis
first  we want to visualize the data points to
get preliminary knowledge of how the data points
are clustered  pca method was used in this
process  the distribution of the data points after
being mapped to a three dimensional space is
shown in figure   

b  analyzing original comments with lexicon
our second java program is designed to
count how many times each word in the lexicon
appears in each comment  we store the results in
a   d array  our data matrix  where each row
represents one comment and each column
represents one word from our lexicon  the i  j th
element stands for how many times word j
appears in comment i 
we manually label our data set with two
methods  first  just two labels are used    for
formatted comments and   for unformatted
comments  in addition  since we know exactly
that   different templates showed up in our
training set  we then use a total of   labels       
        for the   different templates we identified
and   for unformatted comments 

figure    pca mapping of data points onto  d space

the pca result shows an obvious clustering
of the data points to several centroids  this can
justify our assumption that the comments are
written based on several templates  it also gives
us ground to use unsupervised clustering to
analyze the data 

c  training set and test set
we randomly select out     comments for
the training set and     for the test set  both sets
are made sure to contain both formatted and
   

fics   

net neutrality language analysis

b  k means clustering
based on the pca result  we then used
k means method to cluster our data  during this
process  we first used just two centers  one for
formatted comments and one for unformatted
comments  we then used a total of   centers   
for the   different templates we identified and  
for unformatted comments  the comparison of
the training error and test error of these two
clustering methods is shown in figure   

we used gradient ascent to maximize the
log likelihood when implementing logistic
regression algorithm 
since each example shows the frequencies of
each lexicon word showing up in a certain
comment  the number of features used in logistic
regression will be equal to the total number of
words in our lexicon  which is    in this case 
this large number of features will result in severe
overfitting of our model and we need to select out
just a few features that can contribute the most to
our classification problem  therefore  we first did
our feature selection using forward search method 
the change of training error and test error during
the forward search process is shown in figure   

k means clustering
    
    

learning error

training error
    

li tao  xinyi xie

testing error

    
    

feature selection result
   

    

 

 

number of clusters

learning error

    

 

figure    comparison of k means method with different
number of centers

training error

    

testing error

   

    

from the comparison  we can see that using
the correct number of centers greatly reduces both
training and test errors  therefore  in the process
of unsupervised clustering  identifying the most
appropriate number of centers used should be the
very first step 

 

 

  

  

 

 

 

 

 

 

 

index

figure    change of training and test errors during
forward search process

we can see that by using the first   most
relevant features we can already achieve
satisfactory performance  adding more features
will not decrease the training error or test error
any further  therefore  we chose to use only the  
features with indices               and   as our
features in logistic regression 

c  logistic regression
in logistic regression  we first simplified our
data labeling  we used to label the comments
according to the   different templates they were
written from  in logistic regression and nave
bayes event model  we kept a simplified labeling
for the data without distinguishing different
templates  i e   we labeled   for all the formatted
comments and   for all the unformatted
comments 

d  nave bayes event model
in nave bayes event model  we used the
same data matrices and labeling method as in
logistic regression  but we took into account all
   

fics   

net neutrality language analysis

the    features  corresponding to the    words in
our lexicon  we also made use of laplace
smoothing in our algorithm 
in this final step  instead of just learning a
classifier  we would like to study the effect of the
training set size on the training and test errors 
therefore  we generated a learning curve to show
the relationship between the size of our training
set and the training and test errors  the learning
curve is shown in figure   

li tao  xinyi xie

table    comparison of methods

model

training
error

test
error

speed

k means

     

     

fast

logistic
regression

     

     

slow

na
ve bayes
event model

     

     

fast

from the comparison  we can see that
logistic regression after feature selection gives us
the smallest training and test errors  this is
related to the fact that logistic regression is a
more general model and relies less on the
assumptions of the data set  given enough
training examples  logistic regression can
generate a classifier that can best represent the
data set 
the errors of nave bayes event model are
the largest  this might result from the fact that
our data do not obey the nave bayes
assumptions perfectly  i e   the consecutive words
in each comment are actually related to each other
rather than independent 
based on our preliminary attitude analysis
 not shown in details here   more than     of the
comments agree with net neutrality  which makes
format letter analysis more meaningful and
feasible than attitude analysis 

figure    learning curve generated with nave bayes
event model

from the learning curve  we can see that the
training error and test error will converge to a
similarly low level with increasing training set
size  our model selects a training set of around
    examples  which corresponds to the point
where the two errors have already converged 
this will guarantee a satisfactory performance of
our model 
iv  discussion and conclusion
from the pca visualization and our analyses
of the data  we can see that a great majority  more
than      of the comments collected by fcc are
written based on format letters provided by
certain campaign groups 
we develop several algorithms which
successfully classify the data points  the
comparison of the methods we used is
summarized in table   

v  future work
given more time  we would like to proceed
with the following aspects 
   collect more data into the training set and test
set 
   exploit different feature sets to classify the
data 
   

fics   

net neutrality language analysis

   implement semi supervised learning with the
data 
   study more aspects of the data set in addition
to identifying formatted or unformatted
comments  such as the relationship between
the content of a certain comment and the age 
educational background  and or geographic
location of its writer 

acknowledgement
the authors would like to thank our mentor
professor dan jurafsky for providing us with
such an interesting topic  we would also like to
thank professor andrew ng and all the cs   
staff for a great course 

references
     cs    lecture notes and problem sets 
     fcc website 
http   www fcc gov guides open internet
     wikipedia 
http   en wikipedia org wiki net neutrality
     leticia miranda  the fccs net neutrality
proposal explained  the nation  may    
     
     bob lannon  andrew pendleton  what can
we learn from         public comments on
the fcc s net neutrality plan   sunlight
foundation  sep          

   

li tao  xinyi xie

fi