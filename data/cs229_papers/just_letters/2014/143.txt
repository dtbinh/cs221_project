on line kernel learning for active sensor networks
stefan jorgensen 

i  introduction
in this algorithmic project we consider how to leverage
increasingly capable mobile sensor networks to simultaneously exploit a changing environment and maintain
low uncertainty about the previously explored regions 
this problem  known as coverage estimation or active
sensing in the literature  has applications in many fields 
tracking interesting oceanographic or atmospheric data
using a robotic network  finding and clearing environmental hazards such as pollutants     or radioactive
waste      searching for humans in wreckage      and even
game theoretical formulations such as the multi armed
bandit problem      much of the literature focuses on
either the estimation problem of exploring an unknown
environment or the coverage problem of exploiting a
known environment 
a  contribution
the main contribution of this project is to apply online adaptive kernel estimation techniques to the coverage estimation problem in an environment which reacts
to observation  to the authors knowledge  this approach
has not been tried in the published literature 
b  related work
in     a kernel based gaussian regression approach
to coverage estimation is proposed by carron et al  
where a centralized base station computes trajectories
for each agent based on the measurement history up to
the current time  the data dimension grows linearly with
time i and hence the complexity grows as o i    due to a
matrix inversion of the problem data  nodes are directed
toward areas with higher variance in order to improve
the estimate  once the maximum estimate variance is
below a predefined threshold  the algorithm switches to
a partitioning algorithm  which assumes the environment
is static and moves agents to a centroidal voronoi partition  a well known optimal coverage configuration for
distance based problems        the algorithm in     is not
well suited for on line learning tasks since it does not
provide the network with the ability to switch back from
this exploitation state to the former exploration state 
and the complexity of the exploration algorithm grows
as o i    
a distributed  parametric and non parametric approach to the same problem is proposed in      the
 department of electrical engineering  stanford university 
project advised by dr  marco pavone  this work was funded in
part by nsf grant dge         stefantj stanford edu

statistical model used is more general than     because
they consider distributions which are not gaussian random fields  starting from an optimal centralized policy 
the authors develop a distributed approximation by assuming that the agent locations are all independently
identically distributed and using a consensus filter to
explicitly evaluate the kernel based feature vector for
neighboring measurements  note that this precludes an
implicit infinite dimensional feature vector   only the
one shot estimation case is considered  so the active
sensing question of how to move sensors is not addressed 
a method for choosing the most significant features is
proposed  and it is claimed that this computation can be
run online  however  given the weak assumptions made
on the ad hoc network  it is non trivial to guarantee
that at any given time  the agents have agreed on the
basis functions  and ordering  to use in the algorithm 
without this guarantee  the inner product evaluations
that the algorithm relies on are not meaningful  if the
important features are chosen ahead of time  the kernel
method reduces to a parametric method similar to those
described in     
c  motivation of proposed work
the approach to active sensing of a scalar field taken in
this project is inspired by the non parametric methods
used in      parametric methods suffer from the same
fundamental problem of linear estimators  due to the
finite number of basis functions used to parametrize
the space  parametric methods require a large number
of functions to estimate general functions well  and
there will always be a pathological case which is poorly
estimated   in problems where prior knowledge is not
available or where the statistics may change significantly  nonparametric kernel based methods provide an
adaptive  general learning framework  they still require
knowledge of the expected smoothness via the kernel
bandwidth 
d  statement of work
this work examines the coverage estimation problem
with kernel adaptive filters  which kernelize familiar linear estimators  in particular  kernel least mean squares
 klms  and kernel recursive least squares  krls  are
used  derivations and variants of the klms and krls
algorithm are summarized in      the goal of this project
is to provide an on line  kernel based approach to the
problem of maximizing the minimum value of timevarying  reactive fields 

fiii  problem formulation
a  model
assume we have n mobile sensors  and a central base
station  we denote measurement times by the index i 
agent n has position xin in a polygon x   and takes
measurements over a footprint b xin    x   the measurements follow the model
yi n  x    f  x  t  x  i   i    i n
for x  b xin    where i is the time of measurement  i n
is sensor noise and t  x  i  is given by
t  x  i   

n
i
  xx
  x  b xjn   
i n   j  

which is the fraction of total time that the point x has
been observed up to time i  in this context      is the
indicator function  if multiple agents observe the same
location  this fraction can be greater than    though
not greater than n   agents move according to noise less
integrator dynamics 
xin   xi 
  uin
n
b  system requirements
we have the following communication and computation requirements 
 c   agent n can identify itself to the base station and
can send information to the base station 
 c   agent n can measure  y x    f  x  t  x  i   i    vi  
over a region b xin   
 c   agent n can measure its position xin
the base station must be able to 
 c   store measurements taken at time a given time step
by all agents  in addition to the current estimates
of f
 c   compute partitions on x
 c   send information to each robot
the goal of the network is to develop a observation policy t  x  i  to maximize the minimum value of
f  x  t  x  i   i  
c  example problems
   scalar field estimation  this applies immediately 
where we take f to be the time varying error in measurement 
   sweeping and persistent robotic tasks  this problem is proposed in       where they describe the field by
the differential equation


if x   n
n   b xn  
p x 

f  x    p x   c x  if x  n
n   b xn   and f  x     


 
if x  n
n   b xn   and f  x     
integrating  we find that  assuming that p x  and c x 
are independent of time 
f  x  i    ip x    f  x      t  x  t c x    f  x  t  x  i   i  

their policy seeks to minimize the maximum of the
field values  which fits out model by a simple change of
variables 
   border patrol and intruder detection  assume that
there are intruders trying to penetrate a region x undetected  their risk of failure is dictated by environmental
factors and being caught by a patrol  intruders have access to the patrol frequency t  x  i  along the region  but
not to real time position information of patrols  at every
time step i  the intruder examines the environment and
frequency of patrols  and compares it to a risk threshold
i   we also assume that intruders are impatient  so their
risk threshold increases over time  i   i   
patrolling agents move to a location and wait until
they see an intruder or grow impatient  then move on in
order to maximize the minimum intrusion time over x  
in a game theoretic context maximizing the minimum is
the nash equilibrium  since to choose any other policy
will reduce the patrolling agents value function  by definition   and the intruders cannot unilaterally increase
their value function  to get in quickly  
we can formulate this problem as maximizing the
minimum of a field representing the risk of failure  for
intruders  over the patrol frequencies t  x  i   explicitly
constructing this problem analytically typically requires
strong statistical assumptions  such as are used in multiarmed bandit problems   but even without those we can
say that this is a problem of maximizing the minimum of
some function of space  time and average coverage time 
thus  this fits the model from section ii a 
iii  proposed solution
our proposed solution is outlined in algorithm    which
is very similar to      with two major differences  an
adaptive kernel estimator is used in place of gaussian
regression  and the field is assumed to respond to observation  coverage is achieved by running a range limited
version of lloyds clustering algorithm       each agent
finds the centroid of a reward function based on f over
all points nearest to itself and travels there  in a static
environment  this algorithm will eventually converge to
the centroidal voronoi partition  which is the solution to
many locational optimization problems  in our case  the
field is time varying  so the locations of agents will not
converge  instead  we look for convergence of the smallest
field values 
the methods estimator update u  d  and d  
estimator predict d u   and r   estimator predict r u 
are described in     for klms and krls  but are not
repeated here for brevity  the argument u is the measurement vector  d is the scalar output of the model  or
observation  and r is the variance of the estimate d 
the method movereward map  xij   only considers the
points which are closest to agent j  e g   in its voronoi
partition   the method reward d  r  is described next 

fialgorithm    coverage estimation
for i     do
for x  x do
d   estimator predictd   x t  x  i  i  
r   estimator predictr   x t  x  i  i  
map x    reward d  r 
end for
p   partition map 
c   centroids p 
for j     n do
if  event or timeout  then
estimator update  xij   t  xij   i   i   y xij   
xi  
 movereward map  xij  
j
else
xi  
 xij
j
end if
end for
end for

a  reward function selection
the behavior of the algorithm will depend greatly on
the choice of reward function reward d  r   which drives
agent motion  three functions were considered in this
project 
   reward d  r    exp d   this method directly
rewards traveling to areas with short intrusion times  low
risk   the big downside is that there is no benefit given to
exploration  which results in poor performance of regions
which contain many local minima 
   reward d  r     bd     r    bd      this function
comes from the cantelli probability inequality which
states that for a positive  real random variable x with
mean  and variance      pr x    a             a    
switching then probability and substituting b   a   
yields 
 b    
 
pr x  b    
    b    

minimization function from the multi armed bandit
problem 
iv  simulations
algorithm   was implemented in c in order to allow
reasonable simulation time for modest size problems 
numerous problem settings were explored  with various
environments and reward functions  in the following 
only the most recent results are presented as they most
clearly express the properties of our algorithm 
a  problem set up
the equation used by intruders to assess difficulty at
point x is
d x       prior x    t  x  i   
the prior function used for this problem is of the form
sin x  sin y   and is shown in fig     note the severe nonconvexity of the prior  with two distinct local minima
regions  the intruder impatience starts at     and grows
by   with each time step  and an event occurs when
the impatience at x exceeds d x   impatience resets on
event   a gaussian kernel was chosen with bandwidth
parameter     agents have impatience of     if nothing
is seen for    iterations  they move on  
simulations are run over a   x   grid with   agents
that can see manhattan distance    this means that for
every time step     of      grid points are observed    
of the region  
   

  

  
  
  
  
  
  
  

  

  

this choice of reward then corresponds to a conservative
policy which minimizes risk  this runs into a similar
problem as with the direct method  because when the
variance r is large  the lower bound tends to    this is
addressed in the next function 
p
   reward d  r    d    r log i  s    r log i  s 
this is based on a function developed in      based
on a multi armed bandit formulation  the multi armed
bandit problem is the idealized coverage estimation problem  everything is independent  identically distributed 
markov  and time invariant  a regret bound is also given
in       here s   it  x  i  is the number of times x has
been sampled and b is the support of the reward function
 in this formulation  the impatience of the patrolling
agents   this approach tries to balance exploration and
exploitation in a meaningful way 
the first two methods do not explore well  unless
otherwise specified  reward d  r  is taken as the regret 

  
  
  
 
  
 

 

  

  

  

fig    

  

  

  

  

  

  

   

prior field difficulty

b  desired results
intuitively  we should see agents focusing their efforts
in the upper left and lower right corners  to compensate
for the relatively easy environment there  fig    shows
the difference between the initial and final difficulty
function for the krls implementation  qualitatively 
the patrols are taking the right action and we quantify
how good their responses were below 

fi   

 

minimum
standard deviation

  
 

   

  
 

 

  
  

 

  

 

normalized values

  

 

   

 

  
 
  

   
 

  
 

 

  

  

  

  

  

  

  

  

  

   

fig     change in perceived difficulty over      iterations  single
krls trial

an upper bound for the maximum minimum field value
was computed using a centralized  omniscient controller
with no constraints on how to apply patrol effort  in
particular  frequency allocation at a given time step can
be scattered and is not restricted to points within a given
manhattan distance of the patrolling agents 
ideally  the minimum field value will approach this
upper bound as time goes to infinity  from the problem
structure  we also expect the variance of the field to
decrease over time  if there are sufficient agents  then
the difficulty field could theoretically be flattened  in
our case  we only consider a sparse patrol scheme so we
simply look for decreasing variance over time  we expect
a transient at the beginning while agents are exploring
the region 
c  klms results
the minimum and variance of the field for the klms
algorithm are shown in fig     the curves were generated
by averaging the results of     runs of        iterations 
clearly  the algorithm is not able to generate a coherent
policy  since the field variance settles near its initial value 
this implies that the algorithm is simply generating
random walk trajectories  which is verified by looking at
the change in perceived difficulty for a single trial  shown
in fig      from this we can conclude that the random
walk trajectory is able to accomplish approximately    
of the optimal maximum minimum field value 
our best explanation for the poor performance of
klms is that the algorithm is not able to learn quickly
enough for the given problem dynamics  since in some
more pedantic environments klms performed more reasonably  this lack of generalizability is a serious problem 
and even though klms has linear time complexity  versus o i    for krls   it is not suitable for our application 

    

    

    

    

    

    

    

    

    

     

iteration

fig    

klms results  averaged over     trials

fig     change in perceived difficulty over        iterations  single
klms trial

d  krls results
the minimum and variance of the field for the krls
algorithm are shown in fig     the curves were generated
by averaging the results of    runs of       iterations 
the reduced number of iterations is because of the
significant increase in complexity for krls  after approximately     iterations  the agents  implicitly  decide
on the locations of interest and begin to focus their efforts
there  after      iterations  the variance reduces by
    from its initial value  and the maximum minimum
achieves       of the upper bound  given the very
minimal modeling and tuning of this problem this is
impressive 
sparsification techniques such as the ones outlined in
    were implemented  but turned out to be very sensitive 
a     difference in threshold value switched behavior
from overly aggressive  never accepting a new point  to
useless  accepting all points   due to this sensitivity  it
is not practical to use for a generic problem scenario 
table   summarizes the simulation results 

fiminimum
standard deviation
   

normalized values

 

   

 

   

 

   

    

    

    

    

future work should focus on developing theoretical
guarantees for applying this algorithm  or a variant  to
the interactive coverage estimation problem  properties
such as convergence time  as related to environment
dynamics   expected regret  minimum number of agents
to achieve a given maximum minimum field value  and
probabilistic service guarantees are derived for similar
problems and would provide much insight to this problem  there are quite a few applications in the literature
and industry which fit the model that was formulated in
section ii a  and there is the potential for combining the
results from several fields if a theoretical backing can be
developed here 

    

iteration

references
fig    

krls results  averaged over    trials

metric  normalized 

klms

krls

ideal

minimum
variance

      
      

      
      

   
   

table i
summary of results

v  conclusions
this project applied on line adaptive kernel estimation
techniques to the coverage estimation problem in an
environment which reacts to observation  this approach
has not been tried in the literature  and for krls there
is potential for success  the klms approach suffered
from sensitivity to problem dynamics  the specifics of
which should be investigated in future work  the krls
approach was able to get within       of an upper bound
of the solution  which is good considering that the bound
is not particularly tight 
the results are particularly impressive given then nonconvexity of the problem and existence of local minima 
the three agents learn to divide their time among the two
local minima  crossing a less desirable region occasionally
to balance effort  the main drawback from using krls
is its need for many samples to learn  and quadratic
complexity in the number of samples used  sparsification
techniques were tried  but proved too difficult to tune for
general applications 

    j  oyekan  huosheng hu  and dongbing gu  a novel bioinspired distributed coverage controller for pollution monitoring  in mechatronics and automation  icma       
international conference on  pages           aug      
    r  andres cortez  herbert g  tanner  and ron lumia  distributed robotic radiation mapping  in tracts in advanced
robotics  pages         springer       
    vijay kumar  d  rus  and sanjiv singh  robot and sensor
networks for first responders  pervasive computing  ieee 
           oct      
    jerome le ny  munther dahleh  and eric feron  multiuav dynamic routing with partial observations using restless
bandit allocation indices  in american control conference 
      pages           ieee       
    andrea carron  marco todescato  ruggero carli  luca schenato  and gianluigi pillonetto  multi agents adaptive estimation and coverage control using gaussian regression  corr 
abs                 
    qiang du  vance faber  and max gunzburger  centroidal
voronoi tessellations  applications and algorithms  siam
review                     
    damiano varagnolo  gianluigi pillonetto  and luca schenato  distributed parametric and nonparametric regression
with on line performance bounds computation  automatica 
                      
    mac schwager  daniela rus  and jean jacques slotine  decentralized  adaptive coverage control for networked robots 
the international journal of robotics research           
          
    weifeng liu  jose c principe  and simon haykin  kernel
adaptive filtering  a comprehensive introduction  volume    
john wiley   sons       
     stephen l smith  mac schwager  and daniela rus  persistent
robotic tasks  monitoring and sweeping in changing environments  robotics  ieee transactions on                     
     francesco bullo  jorge cortes  and sonia martinez  distributed control of robotic networks  a mathematical approach
to motion coordination algorithms  princeton university
press       

fi     jean yves audibert  remi munos  and csaba szepesvari 
explorationexploitation tradeoff using variance estimates
in multi armed bandits 
theoretical computer science 
                       

fi