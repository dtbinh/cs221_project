machine learning for network intrusion detection
final report for cs      fall     
martina troesch  mtroesch stanford edu  and ian walsh  iwalsh stanford edu 
abstract
cyber security is an important and growing area of data mining and machine learning applications  we address
the problem of distinguishing benign network traffic from malicious network based attacks  given a labeled dataset
of some  m network connection traces  we have implemented both supervised  decision trees  random forests 
and unsupervised  local outlier factor  learning algorithms to solve the binary classification problem of whether a
given connection is normal or abnormal  malicious   our results for lof are mixed and hard to interpret  but with
decision trees we are able to achieve prediction accuracies of over     for both normal and abnormal connections 
posterior analysis of the best performing trees gives us new insight into the relative importance of different features
for attack classification and suggests future avenues to explore 

 

background

dataset compiled by mits lincoln laboratory at the
behest of darpa in            the data consists of
simulated network connection traces representing a variety of network based attacks against a background of
normal network activity over a seven week period at
a medium sized air force base  and there is a smaller
two week section of test data with identical features 
for the kdd cup    subset  there are about  m total
network connections worth of training data  and a test
set of about    k connections 

as networked systems become more and more pervasive
and businesses continue to move more and more of their
sensitive data online  the number and sophistication of
cyber attacks and network security breaches has risen
dramatically      as fbi director james comey stated
earlier this year  there are two kinds of big companies in the united states  there are those whove been
hacked    and those who dont yet know theyve been
hacked      in order to secure their infrastructure and
protect sensitive assets  organizations are increasingly
relying on network intrusion detection systems  nids 
to automatically monitor their network traffic and report suspicious or anomalous behavior 
historically  most nids operate in one of two styles 
misuse detection and anomaly detection  misuse detection searches for precise signatures of known malicious
behavior  while anomaly detection tries to build a model
for what constitutes normal network traffic patterns
and then flag deviations from those patterns  for all the
same reasons that signature based antivirus software is
becoming obsolete  the ease of spoofing signatures and
the increasing diversity and sophistication of new attacks   misuse detection is struggling to remain relevant
in todays threat landscape  anomaly based intrusion
detection offers the enticing prospect of being able to
detect novel attacks even before theyve been studied
and characterized by security analysts  as well as being
able to detect variations on existing attack methods  in
our project we focus on classifying anomalies using both
supervised and unsupervised learning techniques 

 

the data consist of network connections captured
by a unix tcpdump like utility and analyzed by a tool
similar to tcptrace      each connection is described
by    features and is labeled as either normal network traffic or with specific type of network based attack  some of the features include duration  protocol
type  the number of source bytes  and the number of
destination bytes  the full list of features can be found
at      the types of attacks present in the dataset can
also be found at     and include malicious activities such
as buffer overflow and smurf attacks  rather than try
to predict the exact type of attack  which may be very
difficult if not impossible to do accurately from a single connection  we focus on the somewhat easier binary
classification problem of simply labeling connections as
normal or abnormal 
obtaining public datasets for network intrusion detection is very difficult  for both privacy reasons and
the costly  error prone task of hand labeling connections
 and given fbi director comeys warning  the accuracy
of such labels must be suspect    as one of the few available public datasets in this area  the kdd cup    data
has been widely studied and cited by the intrusion detection community       while there has been criticism
raised against the dataset  and it is no longer an accurate representation of network activity in most environments  it still serves a valuable role as a benchmark for
training and comparison of new detection algorithms  as
well as a minimal sanity check that any new scheme
must pass to be considered credible     

data and features

our dataset comes from the third international
knowledge discovery and data mining tools competition  kdd cup          the goal of the competition
was to build a model capable of classifying network connections as either normal or anomalous  exactly the task
we want to accomplish  the kdd cup    data is itself
a subset of an original intrusion detection evaluation

 

fi 

approaches

in      the quantity lrd i  is known as the local
reachability density of point i  and it represents the
density of points in a local region around i  it is given
mathematically by
 
 nk  i  
   
lrd i    p
nnk  i  reachdk  i  n 

we have implemented three different machine learning algorithms to classify the kdd cup    data  with
the goal of optimizing their performance and comparing their strengths and weaknesses  local outlier factors  lof  is an unsupervised learning method that
assigns every data point a numeric score representing
its likelihood of being an outlier  based on its local density of nearby points relative to its neighbors  decision trees are a supervised approach that models the
decision boundary as leaves of a binary tree  with the
interior nodes representing different features of the input connections ordered by their relative importance for
classification  random forests are a variation of decision
trees wherein instead of training a single tree on the full
feature set  we train an ensemble of smaller trees each
on a random subset of the features  and aggregate the
predictions of each small tree into our final prediction
for a sample  we discuss the details of each in turn 

   

where the reachability distance is defined as
reachdk  i  n    max kdist n   dist i  n   
the scores generated by lof tend to     for points
that are clearly not outliers  and scores higher than    
indicate an increasing likelihood of being an outlier 
lof has three parameters that need to be chosen
by the user  the value of k  which controls how many
neighbors we consider local to a point  the distance
metric for comparing points  and the threshold score for
declaring a point as either normal or abnormal 

   

decision trees  dts  are a supervised learning algorithm that can learn complex decision boundaries for
handling both classification and regression problems 
the algorithm works by constructing a tree from the
training data in which interior nodes correspond to one
of the input features and the leaf nodes contain a prediction of the output value or category  each interior
node also contains a cutoff value  and in a binary dt
like we have implemented  a left and a right subtree  to
make a prediction using a dt  we walk down the tree
from the root with our feature vector  branching left at
each node if our feature is    the cutoff value at the
node  and right otherwise  until we reach a leaf 
in constructing our dt  we intuitively want to put
those features most strongly correlated with the classification near the top of the tree  so that we make our
most important decisions first  non informative features should be placed lower  near the leaves  or as an
optimization they may be removed entirely  we quantify these notions through the concept of information
gain between the feature and the label  which is formulated in terms of the related quantities entropy and
conditional entropy 
entropy 
xm
h x    
pj log pj
   

local outlier factors

the local outlier factor  lof  algorithm is an unsupervised algorithm developed by     that assigns  to
every data point  a numeric score representing its likelihood of being an outlier  higher scores correspond to
a greater outlier factor  the intuition behind lof
is that points whose local density is much less than
the local density of their nearest neighbors are highly
likely to be outliers  the following figure from     illustrates this idea by showing the density around point p
compared to the density around its nearest neighbors 

concretely  the lof score of every example i is
calculated using the equation
lrd n 
nnk  i  lrd i 

j  

conditional entropy 
x
h y  x   
p  x   vj  h y  x   vj  

p
lof  i   

 nk  i  

binary decision trees

j

   

   

information gain 
ig y  x    h y    h y  x 

nk  i  is the set of closest examples  or neighbors  that
are within kdist i   where kdist i  is the distance of
the k th nearest example to i  thus  nk  i     k  usually 
but it may be greater than k if multiple points are tied
as the k th nearest neighbor to i 

   

the quantity ig y  x  represents how much knowing x tells us about the value of y   with these definitions  constructing the tree is relatively straightforward  beginning at the root  for every interior node we

 

fiselect the feature having the greatest information gain
with the class label  and we choose the cutoff value as
that value having the highest specific conditional entropy for that feature  once a feature has been selected
for a node  it cannot be selected again for any of its children  the left and right subtrees are trained recursively
on the appropriate subset of the training data  based
on the feature and cutoff selected  the process stops
when all features have been used or when the number
of training samples in a node becomes too small  in our
implementation  we stop building the tree when there
are  s        training samples at a node  or when all
samples at a node are identical  in predicting the label
for a leaf  we use the following heuristic  if any of the
training examples that made it to the leaf are abnormal  we predict abnormal  else we predict normal 
we made this decision to increase the number of malicious connections we correctly classified  fewer false
negatives  at the expense of misclassifying some benign
connections as abnormal  more false positives  

   

old was chosen such that    of the samples would be
classified as abnormal if they were being tested  the
distance metric used for comparing feature vectors was
chosen to be the cosine distance after some preliminary
experiments 

trial  
 k
threshold
trial  
 k
threshold

 
  
    
 
  
    

 
  
    
 
  
    

 
  
    
 
  
    

 
  
    

random forests

in practice  single decision trees often tend to overfit
the training data  and may generalize poorly as a consequence       random forests is a technique for reducing
dt test error due to overfitting  instead of training a
single dt on the entire set of features  we instead train
an ensemble of n trees  each considering only a random
subset of m of the features  in making a prediction for
a test example  we generate the n predictions from each
tree and we output our final classification as the mode
of these predictions 
our implementation uses ensembles of n      trees 
each trained on a random subset of m      features 
we chose m      because  after expanding symbolic
features in binary sub features  each connection contains     distinct features 
and there is evidence in the
p
literature that m   f   is usually a good choice  we
had to alter our heuristic for leaf predictions from the
single dt case  for forests  we choose the prediction for
each leaf to be the mode of all training samples it saw 
without this change  our random forest were classifying every sample they saw as abnormal  so a more
conservative prediction policy was necessary 

 

 
  
    
 
  
    

classification accuracy as a function of training set
size for single dts is shown below  test dataset   contained dfnsdlf samples  and test dataset   contained
       samples 

experimental results

the results for the lof algorithm are shown in the
following plot  the y axis shows the percent of the examples that were classified correctly  the x axis shows
the trial number  where a trial number uses a particular percentage of the examples as the k value and
corresponding threshold value  the threshold values
were chosen for each k value using a method proposed
by     where the lof score of five thousand random
normal samples was calculated  and then the thresh 

classification accuracy as a function of training set
size for random forests of    dts  each trained on   
features can be seen in the following plot  only test
dataset   was used 

 

finormal connections simultaneously  we have two theories of why this was the case  first  the entire concept of anomaly based intrusion detection is predicated
on the assumption that intrusions  or malicious connections  are relatively rare or anomalous  interestingly 
we found this was not the case in the kdd    dataset 
both the training and test data contain     abnormal connections  this means that lof is fighting an
uphill battle when trying to identify abnormal connections as outliers  secondly  lof is very sensitive to the
distribution and size of the dataset relative to the parameter k  too small a k  and points wont look very
far when calculating their local densities  even small
clusters of outliers may be self reinforcing  too large
a k  on the other hand  and the local neighborhood
becomes too big  points are compared against essentially the entire dataset  so everything looks abnormal 
random forests performed reasonably well at classifying abnormal connections  but did worse than we
expected at recognizing normal connections  we hypothesize two reasons for the poor performance  first 
we implemented them as a safeguard against overfitting the training data  but our single dt results show
no evidence of overfitting  if the test and training data
are mostly homogeneous  much of the benefit of random
forests is lost  secondly  our single dt analysis  below 
indicates that very few features were significantly indicative of the final classification  most features were
just noise  by restricting each tree in the forest to a
random subset of the features  then  we were actually
hurting our predictive power by weakening the influence
of the best features 
somewhat surprisingly  single decision trees were
the best performing algorithm we studied  they were
able to achieve over     classification accuracy for every training sample size and test dataset we attempted 
and near perfect classification of abnormal connections 
wed expected that single trees would show evidence of
overfitting by having higher testing errors  the fact that
they did not suggests that the test data does not vary
significantly from the training data 
an important advantage of dts is that the decision
boundary they produce is framed in terms of the original feature set  so their results are relatively natural
to interpret  we took advantage of this by dissecting
some of our best performing dts to see what insights
we might glean about the dataset  we found that the
best features  those most strongly predictive of the
classification  were connection duration and the protocol service  udp  icmp  smtp  etc    while the worst
predictive features were the time averaged features for
a destination host  number of connections in the last
 s  for example  
armed with this knowledge  we investigated the distribution of these features in test dataset    the distributions for the duration feature are presented above  
we found that duration  for example  showed a very

distribution of values for the duration feature in
test dataset   is shown in the below histogram 

a zoomed in view of the same distribution for test
dataset   can be seen in the next plot 

 

discussion

our lof results were poor  we were not able to achieve
better than chance accuracy for both normal and ab 

 

ficlear correlation with classification  abnormal connections tended to be relatively short lived  while virtually
all lengthy connections represented benign network traffic  and the other top features showed similar associations  with this knowledge  we can begin to understand
why our decision trees performed so well on this data 
they excel at finding the most informative features to
split on  and our analysis indicates that these same features were the most predictive in both the training and
test data 

 

be able to improve performance by restricting our analysis to fewer  more important features  so that the distances between normal and abnormal feature vectors
would increase  secondly  while the authors in     were
able to achieve     classification accuracy  they were
using certain time based features not present in the
kdd data itself  if  like those authors  we went back
to the raw      darpa dataset and used tcptrace or
a similar utility  we could extract these same features
and more  which could indicate which subsets of data
we should apply lof scoring to for best results 
we note that our approaches are complementary 
the importance of features learned in training single
dts can be fed back in to inform feature selection in
random forests and lof  and these models can generalize better than dts to different distributions  i e   new
network attacks  once trained 
in conclusion  we have implemented three machine
learning algorithms for detecting anomalies in network
connection data  we have analyzed their performance
and found that single decision trees give the best performance for this application  with surprisingly good
classification accuracy  in addition  they can expose
valuable properties of the underlying data  which may
inform future analysis  our results convince us that
while network intrusion detection is a very hard problem  machine learning algorithms can help and will have
an important role to play in future nid systems 

conclusions   future work

while our single dt results are encouraging  the accuracy of our random forest and lof algorithms could
be improved  for random forests  we can think of two
likely enhancements  first  we should aggressively remove training features that are shown to have little
predictive power  either through their information gain
scores or some other feature selection algorithm  this
would reduce the probability of some tree being trained
with only poor features  secondly  instead of outputting
the mode of the    trees as our final prediction  we could
assign weights to each tree based on their performance
on the training data  and take a weighted average of
their predictions as our final result  this technique 
known as boosted random forests  has proven to be
extremely powerful in many applications 
in the case of lof  as with random forests  we might

references
    testing intrusion detection systems  a critique of the      and      darpa intrusion detection system evaluations as performed
by lincoln laboratory  acm trans  inf  syst  secur            no            
    dhruba kumar bhattacharyya and jugal kumar kalita  network anomaly detection  a machine learning perspective  crc press 
     
    markus m breunig  hans peter kriegel  raymond t ng  and jorg sander  lof  identifying density based local outliers  acm
sigmod record  vol      acm        pp        
    kdd cup      data  kdd cup      data  http   kdd ics uci edu databases kddcup   kddcup   html  web  nov      
    ibm  ibm security services      cyber security intelligence index  ibm statistics on data breach epidemic  http   www     ibm 
com services us en it services security services data breach   april       web      nov      
    cbsnews  cbs interactive  fbi director james comey on threat of isis  cybercrime  http   www cbsnews com news 
fbi director james comey on threat of isis cybercrime   october       web      nov      
    aleksandar lazarevic  levent ertoz  vipin kumar  aysel ozgur  and jaideep srivastava  a comparative study of anomaly detection
schemes in network intrusion detection   sdm  siam        pp       
    shawn ostermann  tcptrace official homepage  http   www tcptrace org   web  nov      
    robin sommer and vern paxson  outside the closed world  on using machine learning for network intrusion detection  security
and privacy  sp        ieee symposium on  ieee        pp         
     vladimir svetnik  andy liaw  christopher tong  j christopher culberson  robert p sheridan  and bradley p feuston  random
forest  a classification and regression tool for compound classification and qsar modeling  journal of chemical information and
computer sciences            no              
     mit lincoln laboratory  communication systems  cyber security  cyber systems  and technology  darpa intrusion detection
evaluation  http   www ll mit edu mission communications cyber cstcorpora ideval data     data html  web  nov      
     mahbod tavallaee  ebrahim bagheri  wei lu  and ali a ghorbani  a detailed analysis of the kdd cup    data set  proceedings of
the second ieee symposium on computational intelligence for security and defence applications            

 

fi