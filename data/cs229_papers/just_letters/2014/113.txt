predicting popularity of pornography videos

predicting popularity of pornography videos
estefania ortiz  cs      jessie duan  cs    

i 

introduction

popularity of online pornography videos is often seemingly random  in this project  we examine a dataset of pornography
videos  and attempt to predict the success of a video based on its metadata  including title  description  categories  and
uploader  popularity is defined as a combination of views  comments  and votes  with views most heavily weighted 
determining the expected popularity of a video has applications in both industry and research  professionals
in the pornography industry will better understand how to produce a video  ex  length   present it  by adjusting
title  description  and selecting uploader   and analyze the success of a video  in addition  researchers in a variety of
fields including feminist studies  sexuality studies  sociology  anthropology  and other fields that study pornography
will have a tool to track trends in the industry  identify words  categories  and other factors that increase a videos
popularity  and draw insights from the data 
in this project  we will explore algorithms to predict a pornography videos success  specifically  unsupervised
learning  using k means   and linear regression 

ii 

problem definition

we are examining an exhaustive dataset of metadata for all         videos published on the xhamster pornography
website from its creation in      until february       the data was acquired from http   sexualitics org   and provides
the following metadata for each video is 
id  upload date  title  channels  i e  categories   description  number of views  number of votes  number of comments 
runtime  uploader id
we choose to use k means clustering and linear regression  as two very different algorithms  to explore this data 

i  assumptions
we must keep in mind the assumptions that we are making about the data  namely that 
   viewers are randomly presented with videos  in other words  videos have an equal opportunity to be chosen for
viewing  this is the most important assumption  as it ensures randomness  in practice  this is most likely not
true  as the xhamster site has a promoted videos section  however  some element of randomness is provided by
the recently uploaded category on the homepage 
   viewers choice of videos to watch is mostly based on the available metadata  the ideal predictor would take in
every factor of a viewers choice  however  we can only work with the data that we have 
   viewers are able to see all video metadata when making a decision on what to view  in other words  viewers can
see runtime  uploader  title  description  etc   and or be able to filter by category  uploader  or other features  if
one element of video metadata is not visible  it cannot affect the viewers decision 

ii  data model
a visual examination of all data shows that number of views follows an approximately exponential distribution  as seen
in figure   
because it is hard to see the specific shape  we transform the number of views into a log scale to get an approximate
bell curve in figure   

 

fipredicting popularity of pornography videos

figure    distribution of all views

figure    distribution of views on a log scale

iii  training
to analyze our algorithms  we split the data into a train and test set  we randomly assign each video to either test or
train with a    probability of being test  this gives us         train videos and        test videos  we then train
each of our algorithms on the train set  and evaluate on the test set 

iv  scoring
our predicted result uses number of views to approximate popularity  we attempted three different scoring methods 

   the first measures the percentage of videos where our predicted result is within n percent of the actual number
of views  in other words  given m test videos 
  x  y i   yactual  
   n  
  
 i 
m i  
y
m

s   

 i 

actual

 

fipredicting popularity of pornography videos

we chose to examine n       and n       
   mean sum of squared errors 
 y i   yactual   
m
this scoring mechanism is only valuable for comparison between methods  rather than serving as an absolute
measure of error 
 i 

s   

   k means bucketing 
s   

m
k
x
  x
 i 
  s j   
min  s j   yactual        y  i   
m i  
j  

this mechanism was used to get an intuitive sense of the effectiveness of k means  the buckets in this case
represent the number of views assigned to each centroid  the score is the percentage of test videos that were
given the value that minimizes the difference between the assigned value and the actual value  let s be the
solution set of the k buckets defined by the training step 

iii 

methods

i  baseline
as a baseline  we calculate the mean of all views in the training set and assign this mean to every video in our test set 
in other words  for all test videos i 
n

y i   

  x  j 
y
n j  

this mean turns out to be        views 

ii  unsupervised learning   k means
the training set will be clustered into a number of groups based on a distance function that determines the similarities
between the videos 
i 

feature vector

we attempted to use the following features  those with the asterisk     are the ones that were ultimately used 
individual words in the title in the format of title  word 
individual words in the description in the format of description  word 
individual categories in the format of category  category name 
individual words in the title
individual words in the description
 categories
 tokenized title in the format of tokenized title  token id 
tokenized title in the format of tokenized description  token id 
uploader id
log runtime 
 runtime
upload date
where tokenid is the index of stemmed non stop words in either the title or description 
many combinations of these features and their respective weights were tested with parameters were k       training
size         stopping point when     of cluster are not changing by more than      and the threshold for changing
 

fipredicting popularity of pornography videos

a video from one cluster to another is     improvement in distance  the values were selected based on previous
exploration  more details about these values are below 
the smallest combination of features yielding the best result is  categories  tokenized title words  and runtime  this
is to be expected given that the tokenized title takes out the most important words from the title which is clearly
visible unlike description or uploader  the categories inform decisions based on preference and filtering ability  and
runtime contributes to what the viewer expects from the video  thus  we chose to use these three features only  and
weighted title tokens  categories  and runtime with           and   respectively  these weights were arrived at through
experimentation as well 
ii 

distance function

the distance function consists of taking the squared distance between the values of the features present in either of the
two videos compared  the distance if only one of the videos contains the feature is the features value squared 
different distance functions were explored before arriving at this one  we tried quantifying and weighting similarities
between videos and maximizing rather than minimizing the distance in different ways  these attempts yield similar but
inferior results as the method explained above 
iii 

initialization strategies

the initial k centroids are set to be random videos from the training set  these training videos are used again for the
algorithm 
another exploration was setting the initial centroid values to videos in succession  where each newly selected video
has at least twice as many views as the previous one  in order to guarantee a variety of values  the results were very
similar for both strategies 
iv 

centroids

the centroids are calculated by combining all of the videos in the cluster  text based features are accumulated  date
and runtime are averaged  and the cluster average is inherited and only updated after assignment 
v 

updating cluster assignment

in order to minimize the algorithm time  and avoid bouncing equilibriums the centroid to which a video belongs to is
updated if the difference between the distance to the closest cluster and the current cluster is greater than     of
the smaller distance  the algorithm stops when at least     of the clusters have reached an equilibrium  and this
is determined by the fact that after updating the centroids and allocating the new videos the last average and new
average are no more than     of the old average apart  more about this below 
vi 

prediction

after training  the prediction for each cluster is given by either the mean or median number of views across all training
videos in that cluster  the number of views for a test video is then predicted by assigning the video to one of k clusters 
and selecting the prediction for that cluster 
vii 

hyper parameters

as shown in figure    increasing the training set size above      did not significantly improve performance 
based on measured runtime of the algorithm in comparison with the results achieved  the values determining the
stopping point of the learning part of the algorithm were determined  there are   values contributing to this point 
a  how many clusters have been updated in the last iteration  if the number is less than     of the total number of
clusters k  there are no more iterations 
b  how do we decide when to update a cluster  once assignment has been made  the average of all the videos in the
cluster is calculated  if the average diverges by more than     of the old value from the old value  the cluster is
updated to the new average 

 

fipredicting popularity of pornography videos

figure    k means mse using optimal hyper parameters  features  and k     

c  when do we change a video from one cluster to another  if the cluster that minimizes the distance and the current
cluster for the video have a distance difference of more than     the video is changed to the cluster that minimizes
the distance 
viii 

choice of k

to determine the optimal value of k  we ran the k means algorithm with several different values of k and observed mean
squared error  although k      provided the lowest mean squared error  we chose to use k      as a local minimum
that still ran in a reasonable amount of time 
figure    mean squared error as a function of k

iii  supervised learning   linear regression
linear regression used a subset of the available features 
runtime
days uploaded before feb           the last date of a video upload 
categories  as a series of vector entries marked   if the video was in the given category and   otherwise
title
to incorporate the title  we took all words in training video titles  removed stop words  stemmed them using the
python nltk library  and counted their frequency  because the range of frequencies was from   to         out of almost
 

fipredicting popularity of pornography videos

        training videos   we chose to only examine the n most frequent stems  for each video  we then created a vector
representing the title as a series of binary entries indicating presence of each of the top n title stems  to select the
optimal n  minimizing noise while providing enough data  we ran linear regression using several values of n  ultimately
finding that n      provided the lowest squared error 
figure    test squared error as a function of number of title stems used in linear regression

finally  the value that we predicted was the natural log of the number of views  using the python sklearn package 
experimentation with predicting the log number of views  versus the number of views  showed slight improvement with
the natural log 

iv  further exploration   human prediction
as part of this exploration into prediction  we wanted to compare our performance against an optimum solution  we
chose to use the average humans prediction as this comparison  and used amazon mechanical turk  we had humans
look at the available features  title  description  categories  runtime  and date uploaded   and predict the number of
views to be within logarithmically increasing buckets 
      views
        views
          views
            views
              views
                views
         views
we then evaluated what percentage of these were correctly classified  with the intent of gathering an intuitive sense
for how well humans could perform 

iv 
method
baseline
k means  w  mean 
k means  w  median 
linear regression

mean squared error
    e  
    e  
    e  
    e  

results

correct w      margin
     
     
     
     

correct w      margin
     
     
     
     

k means bucket

      
    


 

fipredicting popularity of pornography videos

contrary to what we expected  qualitative observation of the clusters did not seem to yield any strong correlation with category  title  or any other feature 
furthermore  coefficients from linear regression were determined below  implying that runtime and categories had
the largest impact on prediction of views 
feature
days since upload
runtime
categories  sum 
title stems

coefficient
    e 
    e 
    e 
varies  order of e 

finally  our human prediction method showed that humans predicted the correct view bucket       of the time 

v 

analysis

clearly  both k means and linear regression outperformed the baseline  interestingly  k means with median had a
similar mse to the baseline but better correctness scores  whereas k means with mean had a better mse but similar
correctness to the baseline  the median seems to perform better from this correctness and bucketing standpoint  which
makes sense because of our data distribution  with few videos having very high number of views  skewing the mean  
although linear regression had the lowest mse  its correctness was between that of the two k means methods  this
is most likely because linear regression is based on minimizing squared error  however  it is particularly interesting that
the features identified as being most influential by linear regression are the same as those for k means  simply weighted
differently  these different weights may be because of the way the two different methods calculate distance  the
most important features themselves  though  were not surprising since non stop title words  categories  and runtime
inform the user about what to expect from the video  are more visible than description  and are less arbitrary than
upload date 
one of the biggest challenges with k means was optimizing many variables at the same time  looking for the
optimal size of training set  k  and hyper parameters to optimize for both speed and performance was very complicated 
finding out that increasing the training set size was not as effective in terms of improving performance as we would
have expected made the process easier  at first it was surprising  but given the features we are using it makes sense
that the training set size is not that influential after a certain point  we only have    categories  categories are one of
the biggest predictors of popularity  and a lot of words used in the video titles are redundant 
the challenge with linear regression was extracting the most important features  ideally  every possible token in the
title and description would be included in the regression  however  the resulting vectors had over    k entries and were
not possible to fit  choosing the top n title word stems seemed to be effective because most title word stems were used
less than     times across the training dataset of    k videos  and indeed  the noise from using too many title words is
visible 
our results seemed fairly poor at first  however  human prediction showed that even humans dont perform very
well in predicting video popularity  knowing that  it is not surprising that our algorithms performed poorly   ultimately 
there was limited information and we had made strong assumptions about randomness 
overall  it seems that k means with median is most successful at predicting an almost correct number of views for
a specific video  while linear regression is most successful at minimizing error across the entire dataset 

vi 

further work

further work could involve additional adjustment to the k means objective function  perhaps deriving more features 
we could also consider shaping the data by detecting and discarding anomalies  however  because the data does fit
a rough bell curve  it is not clear how far from the median a data point would have to be to be considered an anomaly 
another avenue to explore is dimension reductionality  such as with pca  although we attempted to reduce
the number of dimensions for linear regression  we were unsuccessful in using only those features for the regression 
reductionality would help identify the most important features as well 
however  the largest improvement will most likely come from obtaining visual information that users see when
browsing a pornography website   specifically  thumbnails 

 

fi