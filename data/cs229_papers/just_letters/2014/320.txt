levi franklin
lefrankl            
cs    final project
        

predicting march madness  winning the office pool
i  introduction
each year at the end of the ncaa basketball season a massive tournament  called
march madness  is played to determine the ncaa champion  the tournament consists of   
of the best teams during the regular season competing to win the designation of champion 
when the teams are announced  they are placed into   different regions and seeded     
based on their performance during the regular season  during march madness  people all over
the nation compete to fill out a bracket predicting the outcome of every game of this
tournament  people look at many metrics such as the end of season rankings  seeds  team
records  and many others  my goal in this project is to take a large historical dataset of
basketball season results and attempt to predict the outcome of the march madness
tournament 
ii  dataset
i have acquired a large dataset of historical data for ncaa division   basketball seasons
and their respective tournament results  this dataset was acquired from kaggle and was
compiled by kenneth massey  the dataset provides several files 







seasons  a list of every season  its dates  and an identifier for the rest of the files 
teams  a list of all the teams and an identifier 
regular season results  a list of every game that was played  the winning and losing
team as well as their scores  and other information like date 
tourney results  a list of all the games that were played in each tournament and their
results 
tourney seeds  a list of each team in the tournaments and what seed they were        
tourney slots  a description of the format of each tournament  informing which teams
played each other and in what order 

this data is very comprehensive and is much of the same data that sports analysts and
layman alike use in making their own predictions  the data spans    seasons from            
the goal is to process this data in a way that an analyst could not by utilizing the machine
learning techniques we have used in class 

fiiii  features and preprocessing
one of the primary difficulties of this project lies in extracting features from the large
dataset  while the data is interesting in its original format  it is not very useful for machine
learning problems  i wrote a c  application to assemble all of the data into a useable form  and
then process it to extract features  after looking at the data for an extended period of time  i
decided on the following features to begin my investigation 







team   margin of victory over team   in regular season
difference between team   and team   seeds
difference between margin of victory for team   over common opponents and margin
of victory for team   over common opponents
difference between team   wins and losses for season and team   wines and losses for
the season
teams performance during last years tournament  number of games played 
difference between overall margin of victory during season for team   and team  

these features are similar to things that an analyst might look at in determining the
strength of a team  though some are hard to calculate without using computers  an interesting
feature is the seed  because it is not a result of the teams performance  this feature comes
from a group of analysts looking at the teams  and determining who they think is best based on
information similar to our other features  therefore  i think it is also interesting to remove that
feature from our training  despite it being a good indicator of success  and see how our model
performs 
iv  models
once i had preprocessed the data i was left with a very large training set  i had     
games that occurred during all of the tournaments throughout the    seasons  because every
game used a comparison of the winning team to the losing and i made every feature just a
comparison between two teams  i made a copy of each row and inverted the features and
labels so that we would have some negative training examples as well as positive  this gave
     total rows that i used to train 
my initial experiment was to build an svm model  i considered this problem to be a
classification problem asking does the first team win or not  to achieve this i used libsvm to
train over my   features  initially  my result was ok  but not great  i was getting much better
results than a       guess at winners but was not scoring very well compared to the kaggle
leaderboard for this problem  to combat this  i began doing cross validation of my model  the
kernel i used was a radial basis function kernel  as they suggested in the libsvm documentation 
i used cross validation to train the parameters of my model by maximizing cross validation
accuracy and achieved an accuracy of       this resulted in a testing accuracy of around    

fii next decided to try logistic regression as it might give a better matching  i implemented
logistic regression in matlab and went about training my model  i used stochastic gradient
ascent with the update rule discussed in class  after experimenting with various learning rates i
was able to get it to converge  this resulted in similar results to the svm 
after thinking more about the issue  i realized that assigning each game a class of win or
lose leaves out some valuable information  a game where a team wins by one point is very
different than a blow out by    points  after thinking about this i decided to consider this as a
regression problem  instead of assigning a class of win or lose  i set each training label to be the
margin of victory of the game 
i decided to use a similar technique as in my classification modelling by using libsvm
regression  i again used cross validation  though this time to minimize the mean squared error  i
was able to get the mean square error down to around      unfortunately  this also had similar
results to the classification problem 
lastly  i implemented linear regression to see if it offered any advantages  instead of
using gradient descent i decided to use the normal equation to save myself development time 
the thetas resulting from this computation provided me some insight into what features were
most prominent in my models and helped me understand why achieving high accuracy is
difficult in this problem 

v  results
first  i compare my results to the results that you would get by assigning each team a
    chance in every game  intuitively  this is the approach that one would take without any

fiprior knowledge about the teams  this obviously results in a very poor accuracy as only     of
games will be chosen correctly 
second  i compare my results to the results that you would get by basing teams success
on their seed  any time a team plays another team with differing seeds  the higher seed wins 
this is the approach many people take when filling out march madness brackets and it is a
reasonable approach  because these seeds are chosen by experts looking at very similar data to
what i am  i hope to get similar results to this approach or slightly better  additionally  i want to
get similar results to this metric without taking seeds into account in my model 
lastly  because this started as a kaggle competition  there is a leaderboard with lots of
information about how other students scored  many of these students are probably very skilled
and put in much more time than a class project as         was on the line  so i do not expect to
have results on par with the leaders  however  i expected to be in the range of some of the
medium competitors 
method
    evaluation
seed based evaluation
svm classification
svm classification w o seeds
logistic regression
logistic regression w o seeds
svm regression
svm regression w o seeds
linear regression
linear regression w o seeds

correct games
  
  
  
  
  
  
  
  
  
  

method
    evaluation
seed based evaluation
svm classification
svm classification w o seeds
logistic regression
logistic regression w o seeds
svm regression
svm regression w o seeds
linear regression
linear regression w o seeds

kaggle score
     
     
     
     
     
     
     
     
     
     

percentage
     
     
     
     
     
     
     
     
     
     

fipercentage of games correct
svm classification w o seeds
seed based evaluation
linear regression w o seeds
svm regression w o seeds
logistic regression
svm regression
svm classification
linear regression
logistic regression w o seeds
    evaluation
 

                           

vi  discussion and conclusions
as can be seen from the results above  all models did nearly as well as or better than the
seed based evaluation  every model did significantly better than the     evaluation method 
this shows that these features are effective at predicting winners of games when trained using
machine learning  even more interesting is that in many cases the models performed better
without the seeds than when using seeds as a feature  i believe this shows that these models
can predict march madness based on data alone  independent of any panels opinion of the
team  furthermore  this system is a very good way of ranking the teams and could be used for
seeding them very similarly to the panel 
i think it is also prudent to compare these models to the kaggle scores  kaggle mentions
the average score on its leaderboard of        these scores are calculated using a log loss
function  my best log loss model score is       for linear regression  this would place me at
number     place out of     submissions  i think this is a respectable number in that they had
more time and could use outside data  which i did not have to take advantage of 
overall  i think these results are very successful  after taking a large dataset of historical
data on games  i was able to get a     success rate for predicting tournament game winners  i
think this is better than the average person could do by just looking at teams  it is interesting to
see how the inclusion or exclusion of features impacts the results for various machine learning
algorithms  though the problem of predicting march madness tournaments seems to be too
random for machine learning to do extremely well  these models can definitely provide insight
into how a tournament will progress 
vi  references
    chih chung chang and chih jen lin  libsvm   a library for support vector machines  acm
transactions on intelligent systems and technology                       software available at
http   www csie ntu edu tw  cjlin libsvm

fi