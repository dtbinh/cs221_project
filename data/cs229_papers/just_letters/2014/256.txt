cs     project final paper

accurate campaign targeting using
classification algorithms
jieming wei sharon zhang
introduction
data preparation  feature selection 
training set and test set selection

many organizations prospect for loyal
supporters and donors by sending direct mail
appeals  this is an effective way to build a
large base  but can be very expensive and
have a low efficiency  eliminating likely
non donors is the key to running an efficient
prospecting program and ultimately to
pursuing the mission of the organization 
especially when theres limited funding
 which is common in most campaigns  

the original dataset is    dimensional with
        observations on demographic
features of prospects and campaign
attributes 
 demographic  zip code  mail code 
company type 
 prospect attributes  income level 
job  group 
 campaign attributes  campaign
causes  campaign phases 
 result   success failure
in order to serve the purpose of this study 
we adapted the dataset  reducing it to a   dimensional dataset to keep the relevant
features and selected training set and test
set 

the raw dataset  with    mixed  categorical
and numeric  features  is from kaggle
website  raising money to fund an
organizational mission  we built a binary
classification model to help organizations to
build their donor bases in the most efficient
way possible  by applying machine learning
techniques  including multinomial logistic
regression  support vector machines 
linear discriminant analysis  we aimed to
help them separate the likely donors from
the non likely donors and target at the most
receptive donors by sending direct mail
campaigns to the likely donors 

table    feature analysis
company project
cause 
type
type
      
       
       

feature selection
we selected features based on their
relevance to the result of the campaign 
estimated by the correlation of a given
feature to the result  we selected   features
with relatively large correlation with the
result  we found that donor income level is
the most correlated variable 

cause 

phase

zip

       

      

     

original dataset 
   dimensional with         observations
features 

donor
income
     

result
 

project id  mail id  mail code id  prospect
id  zip  zip   vector major  vector minor 
package id  phase  database id  jobid 
group  id

 

fics     project final paper

processed dataset 
  dimensional  training set     
observations  test set      observations 
features 
 company type  campaign
organization type  
 project type 
 cause     indicating whether the
campaign is for profit or non profit  
 cause     further classifying causes
into policy  tax  pac  cnp 
congress  mem  
 phase 
 zip 
 candidate income 
  result  the distribution of these
variables are displayed below 
where  result is a binary value indicating
good bad prospects  it is where well base
our training and gauge the prediction 

we generated histogram to understand the
distributions of the features  as candidate
income  the most relevant feature  has large
variance  we performed log transformation
to visualize its distribution  as well as its

      
  
  
 

  

frequency

cause  histogram

 

 

 

 

  

causes

income histogram

  

  

distribution visualization

  
  

  

  
  
  

 

  

frequency

   

frequency

  

phase histogram

 

  
 

 

  

  

  

  

  

  

  

  

  

natural log of income

  

phase

cause  histogram

    

  

frequency

   
  
 

frequency

   

  

   

project type histogram

   

   

   

   

candidate non profit

   

   

 

 

 

 

 

project type

 

  

fics     project final paper
methods
company type histogram

  
  
  
 

  

frequency

   

we tried the following approaches to
classify mailings into two classes  namely
donors who are likely to donate and those
who are not  multivariate regression  svm 
decision tree  neural network  and
random forest  training errors   test errors 
false positive error rates  false negative error
rates are calculated for each model 

 

 

 

 

 

 

trainin

overa

false

false

g error

ll test

positiv

negativ

error

e

e

mvr

 

    

    

    

svm

     

    

    

    

neural

  

     

     

     

     

    

    

    

nets

 

rando

 

m

 

forest

we noticed that test errors for most models
are relatively high  with mvr and random
forest models having high variance
problems  and svm having high bias
problems  false positive errors are high for
most models  with neural net model having
the least false positive error  we want to
minimize false positive error so as to save
costs for campaign companies 

 

result

 

  

company type

  

  

  

  

  

  

  

natural log of income

distribution with respect to result 

training set and test set selection

algorithm selection

we created a training set by randomly
selected     observations from the original
dataset  and     observations as the test set 
and replaced categorical variables with
numbers 

from the previous initial fitting with
different algorithms  we found that the
dataset is a little messy and irregular in
terms of patterns  there are some random
processes in which a prospect would end up
donating money or not  it is a character of
this dataset  while it is not uncommon in real
world datasets 
when datasets have this degree of
randomness  it is hard to lower the overall
error ratio  however  we can still distinguish
false positive and false negative  and
specifically lower the error type that yields
better profit  saves more efforts  etc 




cause         are replaced for
candidate non profit 
cause         are replaced for
congress  cnp  tax  policy 
def  senate  pac  mil  mem 
imm  rel 

 

fics     project final paper
whatever makes more sense  in this case  we
want to lower false positive error  it is
because when a prospect is mistakenly
considered will donate  then time and
money resources would be spent and
wasted 
we choose to use neural network for this
experiment  since it has the lowest false
positive rate  there are three steps  first
choose the number of neural nets and the
threshold for the structural model  then
choose the optimal regularization parameter
under this optimized structural model  and
lastly choose the threshold for false positive
minimization 

nets

  
  
  

  

  

  

misclassification errors with different decay level

  

  
  

  

percentage of misclassification error

this step we choose the optimal
regularization  weight decay for parameters
              for the structural model found
above by averaging our estimators of the
overall misclassification error on the test set 
we calculate the average with over    runs
with different starting values  from this
tuning process we found that decay
parameter     yields the lowest overall
misclassification 

  
  

percentage of misclassification error

   

   determine the optimal
regularization under the
structural model chosen

nets selected

 

   

thus  we use       as threshold and   layers
of hidden nets for our structural model 

misclassification errors with different nets

 

    

thresholds

we did a looping experiment with    nets 
with    threshold values ranging from     
to      for each value pair we calculate an
overall estimation of misclassification  and
get a        matrix  applying averages to
rows and columns  we choose the lowest
average in both column and row to be the
number of nets and threshold value  the
result of applying average is as below 

 

  
    

   pick the number of neural nets
and threshold for the structural
model

 

threshold selected

  

percentage of misclassification error

misclassification errors with different thresholds

decay level selected

   

   

   

   
decay

 

   

   

fics     project final paper
categories  positive  false negative  false
positive  negative  when threshold is      
every prospect is classified as non donators 
thus the false positive error is    when the
threshold increases  false positive errors

   determine threshold to minimize
false positive misclassifications
a way to control the false positive
misclassified donors to be less is to choose a
threshold of being a donor or non donor 

classification results     with different threshold values
  
  
  
  
  
  
  
 

 

 

 

  

  

  

positive

  

  

false negative

when there is a higher bar for classifying
prospects to be a donor  we filter the
prospects with most certainty of being a
donor 
we tried    different threshold values and
drew the result chart with four different

  

  

false positive

  

  

  

  

negative

increase while false negative error decrease 
the question now is to find a balanced point
of two types of errors so that the overall
campaign is cost effective  we use the
following formula 

                             
where donation     and
package cost    are
assumptions  donors  m 
corresponds to the number of
positive occurrences  and
packages sent  n 
corresponds to the sum of
positive and false positive
occurrences since the model
predicts those prospects will
donate  when we use the
assumptions donation      
and package cost        we
observe the following net
collected amount trend in
chart on the right 
thus  the most cost effective
threshold is r       with
false positive rate     

net collected   with different threshold
values
   
  
  
  
  
 
   
   
   

 

  

  

fi