machine learning in javascript
david frankl
dfrankl stanford edu
december         

 

introduction

the web is ubiquitous  yet many machine learning algoriths cannot be readily found and applied in
javascript  an inherent downside to machine learning in javascript is lack of speed  however  as
the language becomes increasingly more popular  the need for machine learning algorithms steadily
rises  first and foremost  javascript is the language of the web browser  having machine learning
available in the web browser allows for delivery of machine learning tools to users in the most
convenient way possible  this opens up opportunities for non software developers to gain access
to the power of machine learning  in addition  browser based machine learning allows for effective
visualization of algorithms  which can help with education  as well as quick visualization of data 
second  with the rise of node js  javascript is being increasingly relied upon to do non browser
based work  the growth of the node js ecosystem will rely on the availability of easy to use
libraries  a final reason for implementing machine learning in javascript is atwoods law  any
application that can be written in javascript  will eventually be written in javascript     

 

implementation

my project consists of two relatively isolated pieces of implementation  first is the algorithm
implementation  and second is visualization of some aspect of the algorithm  typically convergence 
the result is a library which i have called machinelearningjs  and a website which hosts the
visualizations  machinelearningjs com 

   

preliminaries

to minimize dependencies and library size  i have implemented the basic mathematical operations
myself  most important are operations on vectors and matrices  which i have represented as onedimensional and two dimensional arrays respectively  required matrix operations include matrix
multiplication  transpose  and inverse  to improve the stability of the matrix operations  at the cost
of decreased efficiency   the library has optional exact arithmetic by using rational representation 
to allow for this usage  we convert from floats to fractions based on the theory of continued fractions 
suppose the continued fraction representation of real number r is
r   a   

 
a   

   a    a    a           

 
a   

  
 

 

fithen 
r   a     a    a    a           
 
where  a    a    a            is the continued fraction representation of rbrc
  thus we have an iterative
procedure for finding the best possible rational representation of r 

   

algorithms

i implemented linear regression  logistic regression  least squares approximation of polynomial
fit  and k means clustering  both linear regression and logistic regression utilize stochastic
gradient descent  the step parameter  is tuned dynamically with the following procedure on
each iteration 
if error current iteration    error previous iteration  
alpha   alpha  
else with probability    
alpha   alpha      
this allows  to converge to the maximum step size possible  without the need for manual
tuning  least squares is implemented using the normal equation  with exact arithmetic on by
default 
algorithm usage follows an object oriented approach  whereby the user creates an object representing the model  then calls train   and test   manually  in total  the library consists of  kb of
compressed javascript 

 

visualization

visualizations of linear and logistic regression make use of a trendline which shows the progress
of gradient descent on converging to an optimal solution  with linear regression  the adjacent
figure gives a plot of error rate over time  the adjacent figure to logistic regression gives a plot of
percent of correct classifications of the training set over time  for polynomial regression  i allow
the user to manipulate the degree of the polynomial  which gives an intuitive understanding of the
relationship between polynomial degree  approximation error  and under over fitting  for k means
clustering  the clusters are represented by concentric circles  and their center point is updated on
each iteration  all of the algorithms can be tested on multiple datasets  i get many of the test
datasets from an archive of real world data hosted by larry winner     

 

future work

in the future  two improvements can be made  first  the breadth of the library can be increased  in
addition  the implementations can be tuned for efficiency  for example  the matrix operations are
for now implemented naively  both matrix inverse and matrix multiplication would benefit from
relatively simple improvements  finally  i plan to adapt the codebase to function as a module on
the node js platform  and provide convenience functions to allow the use of input files rather than
input arrays 

 

fireferences
    jeff atwood 
the principle of least power 
the principle of least power 

http   blog codinghorror com 

    larry winner  miscellaneous datasets  http   www stat ufl edu  winner datasets html 
accessed             

 

fi