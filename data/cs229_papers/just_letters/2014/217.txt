cs   

prediction of consumer credit risk
marie laure charpignon
mcharpig stanford edu

enguerrand horel
ehorel stanford edu

flora tixier
ftixier stanford edu

abstract
because of the increasing number of companies or startups created in the eld of microcredit and peer to peer lending  we tried through this project to build an ecient tool
to peer to peer lending managers  so that they can easily and accurately assess the default
risk of their clients  precisely  the main purpose of this project is to predict if a consumer
will experience a serious delinquency     days or worse  during the next two years  thus
it is a classication problem   the dataset consists of roughly         consumers characterized by    variables  two of the models we implemented present a very good predictive
power  auc around        they are obtained by combining trees  bootstrap and gradient
boosting techniques 

 

introduction

its main goal is to predict if a consumer will
experience a serious delinquency     days or
worse  during the next two years  the data 
the methods and the models used will be presented in sections two and three  then the results will be interpreted and discussed in section four 

credit and default risks have been in the
forefront of nancial news since the subprime
mortgage crisis that began in       indeed 
people realized that one of the main causes of
that crisis was that loans were granted to people whose risk prole was too high  that is
why  in order to restore trust in the nance
system and to prevent this from happening
again  banks and other credit companies have
recently tried to develop new models to assess the credit risk of individuals even more
accurately  besides  the nancialization of our
economies implies that more and more stakeholders are involved  however it can still be
very dicult for some people   either because
of their banking history or of their atypical situations   to get a loan  this imbalance has led
to the development of new alternatives to the
bank system  the number of peer to peer lending websites  microfinance institutions  mfi 
and companies that back their development  is
currently growing quickly  and the quite recent
stock market listing of
lendingclub is adding evidence of that  it is
precisely in that dynamic that this project ts 

 

data

   

presentation of the data

the data used in this project comes from the
competition  give me some credit  launched
on the website kaggle  it consists of        
consumers  each characterized by the following
   variables 









 

age of the borrower 
number of dependents in family 
monthly income 
monthly expenditures divided by monthly
gross income 
total balance on credit cards divided by the
sum of credit limits 
number of open loans and lines of credit 
number of mortgage and real estate loans 
number of times the borrower has been      days past due but no worse in the last

fics   
train them on a dataset where the proportion
of positive outputs was higher  in this con   days past due but no worse in the last text we increased this proportion to     in
two years 
the training set  this was done by randomly
 number of times the borrower has been   
selecting the positive outputs to add in the
days or more past due 
training set  this improvement has allowed
they are all continuous variables and the us to obtain much more precise results 
dependent variable is if a person experienced
   days past due delinquency or worse in the   methods
last two years    if yes and   if not  
two years 

 number of times the borrower has been    

   
   

processing

models

classication trees are appropriate for this
problem  as they successively determine decision criteria based on subsets of the initial
variables  it corresponds to an intuitive representation of the consumers  each one being
associated with a cluster linked to its credit
prole 
we chose to use four dierent models 

when we looked initially at the data  we
thought that they certainly should not all be
relevant  for instance the age of the borrower
does not seem so important  and the last three
variables look redundant  that is why we decided it could be interesting to try to select the
most useful variables  to do so  we tested the
signicance of each of the variables using linear
and logistic regressions  they both revealed
that the variable  balance on credit cards divided by sum of credit limits  was not really
signicant  however omitting it did not improve the nal results  so we decided to keep
it  to go further in that analysis  we also did a
pca of our data  it highlighted that a certain
combination of the three variables  number of
times the borrower has been some days past
due in the last two years  was the rst principal component  and that two other combinations of the same variables were the last two
components whose associated variances were
the lowest  it conrmed the intuition that
these three variables could be redundant if
they were not considered in the right proportion  we tried to keep only the rst eight principal components but again it did not improve
the results so we used the original data 
in order to normalized the range of this
dataset  we decided to scale all the data  we
also realized that this dataset was very unbalanced  the proportion of positive outputs
 consumers who had a default  was only    
as we wanted to predict if a person would experience a delinquency  we thought it could
increase the predictive power of our models to

 logistic regression as it is a very classic

model for this type of problems 
 classication and regression trees
 cart   we read in the literature that
trees were particularly ecient in classication 
 random forests  this model averages
multiple deep decision trees trained on
dierent parts of the training set  this
aims at reducing the variance  
 gradient boosting trees  gbt   gradient boosting algorithm improves the accuracy of a predictive function through
incremental minimisation of the error
term  after the initial tree is grown 
each tree in the series is tted with the
purpose of reducing the error  a tree at
step m partitions the input space into
j disjoint regions r m         rjm   the
output is then
hm  x   

j
x

bjm   x  rjm  

j  

where bjm is the value predicted in the
region rjm   the update rule of the
model is
jm   argmin


 

x
xi rjm

l yi   fm   xi   hm  xi   

fics   
where l is a loss function  the mse for itive rate versus the false positive rate and f instance   thus 
score is the harmonic mean between precision
 proportions of positive and negative results
j
x
fm  x    fm   x   
jm   x  rjm   that are true positive and true negative  and
recall  true positive rate   these two metrics
j  
are between   and   and the bigger they are 
the better the associated model is 
   
methods
the results presented in the next section
are calculated as an average over thirty iterto assess and compare the precision of our
ations of the models  at each iteration the
models  we realized that we could not use the
dataset is randomly split into two subsets  a
classic error measure  number of wrong pretraining and a testing set  the proportion of
diction over the total number of predictions 
positive outputs is increased in the training set
as the models implemented tend to underestiand then the trained models are tested on the
mate the proportion of positive outputs which
unbalanced testing set 
is already very low in the dataset we worked
on  we prefer to use the two following metrics 
auc and f  score  as they are complementary   results
and both adapted to binary classication  the
auc is the area under curve of the true pos      presentation of the results

figure    training and testing error with the auc metric

 

fics   

figure    training and testing error with the f  metric

comparison references

   

as explained in the previous section  we
decided to implement a logit model in order
to have some reference to which we could compare the results from the other three models 
both in training and testing  indeed  logit is
known to be one of the most appropriate algorithms for classication problems 

discussion   interpretation

our two best models are successful   with
an auc around        in predicting if a consumer will experience a serious delinquency in
the next two years  our results are very satisfying compared with those of the best competitors of the kaggle competition from which
we collected our data  when it comes to testing  our models are ecient  for two major
reasons  the rst one is that the structure
of trees is adapted to classication problems 
and the second one is that they are sophisticated  compared with the basic cart  as they
involve statistical and machine learning techniques such as bootstrap or gradient boosting  the only aspect that surprised us a lot
was the fact that random forest highly overts  it is astonishing because it is not what
is expected from this model  by construction 
it is indeed supposed to have a lower variance
than cart  there is only one determining parameter for this model  the number of trees 
and the same result has been obtained for dif 

comments
looking at the testing and training results
for the auc metric  we can clearly state that
two distinct groups of models appear  logit
and cart constitute the rst one  the more
sophisticated tree models   random forest
and gbt   form the second one  we also notice that the performance is quite similar for
testing and training  using this metric  unlike auc  f  score introduces a bigger gap between training and testing values  moreover 
it has a more gradual evolution  yet  it also
indicates that gbt is the best model 
 

fics   
ferent values of it  the problem may come from vestors reaching their specic return over risk
our database  and one possible improvement target 
could be to test with others 

 

references

conclusion

by combining trees and gradient boosting
technique  gbt model   we have implemented
a model which presents two principal features 
first  its predictive power is very accurate 
with an auc of       gbt beats the other
models we used and especially logit  which
was our reference   second  its small variance
makes it reliable  unlike random forest  its
training and testing errors are on the same
scale which means that it does not tend to
overt 

 

brown i   mues c 

   

chawla n  v 

   

galindo j   tamayo p 

   

hand d  j  

   

khandani a  e   kim a  j   lo a  w 

   

thomas l  c 

future

to go on with this project  we thought about
some ideas for improvement  we used a
database of ten variables for this study  it
could be interesting to try to add new variables  associated with some characteristics of
the loan for instance  and see if it improves
the predictive performances of the models  for
example  lendingclub is using more than    
variables to predict the default risk  besides 
according to the literature  neural networks
oer very good performance for credit scoring problems  thus  comparing its predictive
power with the one of our models could allow
us to put our results into more perspective 
in order to create a practical and useful
application from this study  we could develop
a credit risk management tool for peer to peer
lending companies  this tool could provide for
instance the ideal interest rate for a loan in order to minimize its risk  a peer to peer lending company connects borrowers and lenders 
the latter being investors looking for certain
returns and risk ratios based on their risk prole  predictions of credit risk of individuals
could also be used to create portfolios of loans
in order to diversify their risk and to help in 

  an experimental comparison of classication algorithms for imbalanced credit scoring data sets   expert
systems with applicaions                 
      

   

  data mining for imbalanced
datasets   an overview  springer          
      
  credit risk assment using statistical and machine learning  basic methodology and risk modeling applications  computational economics
                    
henley w  e   statistical
classication methods in consumer credit
scoring   a review  journal of the r  statist 
soc                         

 
consumer credit risk models via machinelearning algorithms   journal of banking  
finance                        
  a survey of credit and behavioural scoring  forecasting nancial risk
of lending to consumers   international journal of forecasting                      

fi