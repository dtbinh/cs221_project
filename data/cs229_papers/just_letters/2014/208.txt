predicting soccer match results in the english
premier league
ben ulmer

matthew fernandez

school of computer science
stanford university
email  ulmerb stanford edu

school of computer science
stanford university
email  matthew  stanford edu

abstractin this report  we predict the results of soccer
matches in the english premier league  epl  using artificial
intelligence and machine learning algorithms  from historical
data we created a feature set that includes gameday data and
current team performance  form   using our feature data we
created five different classifiers  linear from stochastic gradient
descent  naive bayes  hidden markov model  support vector
machine  svm   and random forest  our prediction is in one
of three classes for each game  win  draw  or loss  our best
error rates were with our linear classifier        random forest
       and svm        our error analysis focused on improving
hyperparameters and class imbalance  which we approached
using grid searches and roc curve analysis respectively 

i  i ntroduction
there were many displays of genius during the      world
cup  ranging from andrew iniesta to thomas muller  but
none were as unusual as that of paul the octopus  this
sea dweller correctly chose the winner of a match all eight
times that he was tested  this accuracy contrasts sharply
with one of our team members predictions for the world
cup  who was correct only about half the time  due to love
of the game  and partly from the shame of being outdone
by an octopus  we have decided to attempt to predict the
outcomes of soccer matches  this has real world applications
for gambling  coaching improvements  and journalism  out of
the many leagues we could have chosen  we decided upon
the english premier league  epl   which is the worlds most
watched league with a tv audience of     billion people     
in our project  we will discuss prior works before analyzing
feature selection  discussing performance of various models 
and analyzing our results 
a  related literature
most of the work on this task has been done by gambling
organizations for the benefit of oddsmakers  however  because
our data source is public  several other groups have taken to
predicting games as well  one example of the many that we
examined comes from a cs    final project from autumn
     by timmaraju et al       their work focused on building
a highly accurate system to be trained with one season and
tested with one season of data  because they were able to use
features such as corner kicks and shots in previous games  as
well as because their parameters were affected by such small
datasets  their accuracies rose to     with an rbf svm  we

chose to focus on a much larger training set with the focus on
building a more broadly applicable classifier for the epl 
another attempt at predicting soccer works was done by
joseph et al  this group used bayesian nets to predict the
results of tottenham hotspur over the period of           
their model falls short in several regards  self admittedly 
it relies upon trends from a specific time period and is not
extendable to later seasons  and they report vast variations in
accuracy  ranging between     and      however  they do
provide useful background on model comparison and feature
selection      while we took into account their insight on these
areas  we remained true to our philosophy of generality and
long term relevance 
finally  we were influenced by the work of rue et al   who
used a bayesian linear model to predict soccer results  notably 
they used a time dependent model that took into account the
relative strength of attack and defense of each team      while
we didnt have data available to us regarding statistics for each
individual player  we did take into account the notion of timedependence in our model 
ii  dataset
our training dataset contained the results of    seasons
 from the         season to the         season  of the epl 
and our testing dataset included the results of   seasons  the
        season and the         season  of the epl  as each
of the    teams plays all other teams twice per season  this
translates to      games in our training set and     games in
our testing set  for each game  our dataset included the home
team  the away team  the score  the winner  and the number of
goals for each team  we obtained this data from an england
based group that records historical data about soccer matches
called football data and preprocessed this data with python
    
iii  m ethodology
a  initial challenges
we ran into several challenges over the course to the
project  two were the most significant  a lack of data  and
the randomness of the data  since our data spanned a gap of
   years  there was always going to be a difference in the
amount of information available for the      season and the
     season  as such  we were limited to the features from the

fipredicting soccer match results in the english premier league
     season  described above   in our review of literature and
the current leading predictors however  we saw use of features
such as availability of specific players and statistics such as
shots on goal  the predictors used by gambling agencies had
the resources to keep track of or research injuries  we did not 
another challenge we faced was the randomness of the data 
for example  in the      premier league season      of the
games were draws        were wins  and       were losses
     if we calculate the entropy  a measure of randomness   of
these statistics we see an entropy value of     
entropy          log                  log              
    

   

this is close to an entropy value of    which corresponds to
pure randomness  this spread makes the data hard to classify
based on a map estimation  and makes it hard for classifiers
to discount or ignore a class  moreover  not only was the data
distributed evenly  but in soccer  there are a large amount of
upsets  it is not uncommon to see teams like wigan triumph
against teams like manchester city  famously  in       an
amateur side  luton town  beat epl team norwich  in a sport
where non league teams can overcome teams of the highest
league  the amount of upsets at the top level will be relatively
high  with many outliers such as these  the results become
hard to predict 
b  feature selection
many features make sense to include  literature and our
own intuition suggested using the features of whether a team
is home or away  features for each team  similar to an elo
ranking for each team   and form  results in recent matches  
we used form to be a measure of the streakiness of a team 
for example  if a team is on a hot streak  it is likely that they
will continue that hot streak  however  we ran into several
issues with calculating form  first of all  what to do for the
first x games of the season for which there are not enough
prior games to calculate form  we toyed with two approaches 
scaling the data and leaving out the games  to scale the data 
we calculated the form based on the results of the matches that
had already been played  and multiplied it by   x  however 
we found that the method of ignoring the first   games led
to better results  and  more importantly  allowed us to use
the feature of having time dependent weights for each game
played  separate weights for the last game  the second to last
game  the third to last game  and so on   we then had to decide
how many games to aggregate form over  we analyzed using
between   and   games and the results are shown in figure   
after testing for various numbers of previous games to
consider for our form feature  we found that the optimal
accuracy came from calculating form over the past   games
for the rbf svm model shown in figure    for every other
model we found the optimal number to be   games  so we used
that consistently across all models  finally  we occasionally
used the feature of goal differential  but found it often led
to overfitting  see model descriptions below to see where we
used this feature 

figure    error rate as a function of form length

c  models
we tried a variety of methods to address our three class
classification problem 
   baseline  we began our project by reducing the problem
from a   class classification problem to a   class classification
problem  and predicted whether a team would win or not win
by implementing and training our own stochastic gradient descent algorithm  for this preliminary test  we used as features
whether a team is home or away and the form for that team 
this method resulted in a test error of     and a train error of
     we then extended this model by implementing a   class
classification one vs all stochastic gradient descent algorithm
on the same set of features  this model achieved a training
error of     and a testing error of     
   naive bayes  we also implemented a naive bayes classifier  we didnt expect this model to achieve much success  as
its assumption of independence does not hold on the often
streaky results that are prevalent in soccer matches  as
features  we used the home teams form  the away teams form 
whether a team is home or away  and ratings for each team 
our gaussian naive bayes had a training error of     and a
testing error of      while our multinomial naive bayes had a
training error of     and a testing error of      as expected 
these models did not seem to be well suited for this dataset 
although they did perform better than our baseline 
   hidden markov model  due to the time dependence of
this problem  we tried a hidden markov model  we treated the
result of the match  win  loss  draw  as the unobserved states
and past results as the evidence  this model had a training
error of     and a test error of      the lack of success here
can be explained by the assumption of the model that past
states are hidden  while in reality  those states are known 
   support vector machines  literature suggested that the
most successful model for this task was an svm  so we began
by implementing one with an rbf  gaussian kernel  
k x  z    e  xz  

 

    

   
page  

fipredicting soccer match results in the english premier league
we used features of the home teams form  the away teams
form  whether a team is home or away  and ratings for each
team  we tuned the hyperparameters using a grid search with
k folds cross validation  we used a k value of     figure  
shows the largest range and figures   and   are zoomed
regions  in figure   our grid ranges are c            and
gamma           in figure    we focus on c             
and gamma                lastly in figure    we find the
optimal values of c       and gamma      

figure    rbf svm grid search for hyperparameters of c and gamma

figure    rbf svm grid search for hyperparameters of c and gamma

this kernel allowed us to use goal differential and more
complicated form features in addition to what we had used
previously  and we achieved test error of     and train error
of    
   random forest  we also tried an ensemble method  as
the upsets in the data means that many results arent entirely
representative of the matches we are trying to predict  we used
the same set of features as the svm above  and tuned the
hyperparameters with a grid search  this is shown in figure  
where we found the best hyperparameters were     for the
number of estimators and minimum of   examples required to
split an internal node 
our random forest model achieved a test error rate that
ranged between     and      due to random nature of the aptly
named random forest  we would get different error rates on
each run   but averaged at      similarly  our training error
was between     and      but averaged at      

figure    rbf svm grid search for hyperparameters of c and gamma

after optimizing our svm  we achieved a training error
of     and a test error of     we experimented with adding
additional features such as goal differential and separate
weights for each of the last seven games  but we found that this
only exacerbated our overfitting issue  at one point  we had
a difference of    between our training error and our testing
error   to address our overfitting issue  we attempted a less
complicated decision boundary  and used a gram kernel 
k x  z    x  z

   

figure    random forest error rate as a function of the number of estimators
and the minimum number of examples required to split an internal node

   one vs all stochastic gradient descent  surprisingly 
after we updated our features  we found that a one vs all
page  

fipredicting soccer match results in the english premier league
algorithm that used stochastic gradient descent to generate
scores performed well with a test error of     and a training
error of     similar to the svm with the gram kernel  the
simplicity of the decision boundary stopped the overfitting
which was a problem in models such as an svm with an
rbf kernel 
iv  r esults
we implemented and tuned   different models  those models and respective error rates are illustrated in figure   

predict draw
predict win
predict loss
 
   
   
 
   
   
 
   
   
table ii
c onfusion m atrix for l inear svm

actual draw
actual win
actual loss

performance on draws and dependence on training set size
suggests that  although the one vs all sgd model reported
the highest accuracy for this data set and training set  it
would not be easily extendable for real world applications
such as gambling  in contrast with the linear classifiers  our
random forest model and svm with an rbf kernel had
better accuracy on the draw class  the confusion matrices
for these models are shown in tables   and   
predict draw
predict win
predict loss
  
   
   
  
   
   
  
   
   
table iii
c onfusion m atrix for r andom f orest

actual draw
actual win
actual loss

predict draw
predict win
predict loss
  
   
   
  
   
   
  
   
   
table iv
c onfusion m atrix for rbf svm

actual draw
actual win
actual loss
figure    a comparison of error rates between models

we will focus on our best performing models  which were
an svm with an rbf kernel  an svm with a linear kernel 
a random forest model  and a one vs all sgd model  these
models achieved error rates of between     and      which is
comparable with the error rate of     for leading bbc soccer
analyst mark lawrenson  but still worse than an oracle of
    for the betting organization pinnacle sports     
out of our models with linear decision boundaries  we found
that the best model was a one vs all linear classifier created
with our stochastic gradient descent algorithm  however  both
of the linear models drastically under predicted draws  the
confusion matrices for these two models are shown in tables
  and    our results are expected for this type of system  their
unweighted average recall values are hindered  but weighted
accuracy is higher because win and loss classes have more
examples than the draw class 
predict draw
predict win
predict loss
 
  
   
  
   
   
  
  
   
table i
c onfusion m atrix for o ne   vs   all s tochastic g radient
d escent
actual draw
actual win
actual loss

moreover  our one vs all sgd model in particular was
highly dependent on training set size  when we reduced the
number of seasons to          and   our model reported
test error of                and     respectively  the poor

to add to our understanding of the performance of an rbfsvm and the random forest model  we implemented a receiver operating characteristic curve  roc curve  to compare
the two  while roc curves are normally used for binary
classification problems  we adapted them to show pairwise
comparison  one class vs  all other classes  in order to fit our
  class classification problem  from the figures   and   below 
it is evident from the area underneath the draw curve  class   
that the svm with an rbf kernel outperforms the random
forest model in terms of predicting draws  although it itself is
outperformed in terms of predicting wins and draws as well
as overall performance  the micro average curve  
overall  we found that every model under predicted draws
to some degree  which is in accordance with the models
presented in literature on the subject  we attempted to weight
this class more  but found that the trade off in accuracy for
wins and losses was detrimental  timmaraju et al  were only
able to report a recall value of          the failure to predict
draws stems from the fact that draws are the least likely result
to occur  even though draws occur only    less than wins or
losses  this is enough to affect our predictor      the models
that were more accurate in terms of predicting draw results
sacrifice accuracy on wins and losses 
while our project met with success comparable to expert
human analysts  it still lags behind leading industry methods 
this is in part due to the availability of information  we were
unable to use as features statistics for players and elements of
page  

fipredicting soccer match results in the english premier league
models referenced in rue et al  and joseph et al   however 
since these models met with limited success  we speculate
that they would perform even worse on a more limited dataset
          finally  we are extending this system to predict league
standings after a season  when we tried to predict the results of
the           epl season we correctly predicted manchester
united to win 
acknowledgment
we would like to thank professors andrew ng and percy
liang  and the tas of cs    and cs    for their contributions to our project  we would like to especially thank the
following tas for their guidance and insight  will harvey 
clement ntwari nshuti  and celina xueqian jiang 
r eferences
figure    a receiver operating characteristic curve of classes    win     
 draw   and   loss  from an random forest model

    the worlds most watched league  web     dec       
 http   www premierleague com en gb about the worlds most watchedleague html  
    a  s  timmaraju  a  palnitkar    v  khanna  game on  predicting
english premier league match outcomes       
    a  joseph  a  e  fenton    m  neil  predicting football results using
bayesian nets and other machine learning techniques  knowledge based
systems                      
    h  rue and o  salvesen  prediction and retrospective analysis of soccer
matches in a league  journal of the royal statistical society  series d
 the statistician                      
    mark lawrenson vs  pinnacle sports  web     dec       
 http   www pinnaclesports com en betting articles soccer marklawrenson vs pinnacle sports  
    england football results betting odds  premiership results   betting
odds  web     dec         http   football data co uk englandm php  
    soccervista football
betting 
web 
  
dec 
     
 http   www soccervista com soccer leagues ordered by number
of draws php  
    h  kopka and p  w  daly  a guide to latex   rd ed  harlow  england 
addison wesley       

figure    a receiver operating characteristic curve of classes    win     
 draw   and   loss  from an rbf svm model

previous matches such as corner kicks  however  this project
made strides in the evaluation of form as a feature  and
reducing the overfitting problem that comes with the variability
of soccer results 
v  f uture w ork
as mentioned above  one of our main challenges was the
limited amount of data from the earlier seasons of our dataset 
the obvious improvement to the accuracy of our system would
come from finding sources of more statistics from that time
period  many models in literature and in industry use features
such as player analysis  quality of attack and defense  statistics
from previous matches such as possession and corner kicks 
and one model went so far as to examine the effects of a
teams mood before the game  beyond researching data  we
would also like to try implementing some of the probabilistic
page  

fi