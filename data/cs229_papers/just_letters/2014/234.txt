predicting mobile application success

tuckerman  c j 

abstract  a machinery for downloading and extracting features about applications from the google
play store was developed and deployed  and the resulting data set was used to train three different
models to predict the success of a mobile application  a nave bayes based text classifier for the description of the application  a generalized linear model which categorizes applications as successful or
not  and a linear regression which predicts the average rating of the application  the performance of
the models is not sufficient to justify their use in driving investments in new applications  however
interesting observations about the ecosystem  such as the current trend in photo sharing applications 
are elucidated 

   introduction
mobile applications have turned into an enormously profitable business  with revenue from mobile applications expected to exceed fifty billion usd by           these profits are not distributed equally amongst
developers  with forty seven percent of developers making less than one hundred usd  more than half of
which make nothing at all      creating a successful application is not easy  luckily  an enormous amount
of data about mobile applications is made available publicly by google  apple  and microsoft by way of
the websites for their app stores 
in this study  features extracted from the data made available on googles play store website is used
as input to two different models  each model predicts the success of a given application  and interesting
observations about their behavior are discussed 
   data collection
google makes data available about its applications on http   play google com  these pages contain data
which can be extracted such the name of the application  the description  the number of installations  the
average rating of the application  and many more features  in order gather as much data as possible without
worrying about which features would eventually be used  a web crawler based on scrapy     was created 
deployed on amazon web services  aws  elastic compute cloud  ec    and the entire rendered doms
of the application pages were downloaded to aws simple storage service  s   and stored as html  the
crawling job is currently still crawling  and at the time of training models had downloaded data for more
than     million applications 
for each desired feature  a feature extracting function was written which  given an input html file 
would output just the feature in question  for all feature extracting functions and all output html files 
features were extracted and the resultant data is stored in aws relational database system  rds   as
new output html files are downloaded  all registered feature extractors are automatically ran on it  and
newly registered feature extractors are backfilled from the catalogue of previously downloaded html files 
   features  preprocessing  and labeling
numerous feature extractors were developed  features extracted include the average user rating  number
of                 star ratings  the number of installations  the description  the name of the application 
whether or not the developer is a top developer  the size of the android application package  apk   when
the most recent update was published  which android sdks are supported  the number of   s on the
date  december          
 

fi 

tuckerman  c j 

application  the price  and more  these extractors were written as a combination selectors     and regular
expressions 
   principal component analysis
principal component analysis was performed on the inputs to the glm and linear regression models 
while training these models  cross validation scores were lower than expected which might be explained
through overfitting  in order to help alleviate some of this problem  principal component analysis was
performed on the continuous features and the first two principal components were stored in the rds
database 
   text
preparing the description for the nave bayes algorithm involved using the nltk in python     to both
remove stop words and perform some basic stemming on the words in the description  bringing the feature
vector dimension to on the order of one half million 
     success metrics  the most obvious choice for a success metric would be revenue  however this
information is among the small amount of information not available publically  instead  we use number of
installations and average user rating as a proxy for success  the distributions of which are seen in figure   
hoping to select the top five percent of applications as successful  a natural region of success is found  for
some application x with average rating xscore and number of installations xinstalls   the successfulness of an
application  success x is defined as 
   


 
success x      xscore            xinstalls          

this region encompasses two clusters  one extremely high numbers of downloads and one with close to
one hundred thousand downloads  the cluster containing applications with large numbers of downloads
included those applications from developers such as google  facebook  and snapchat  the cluster with a
smaller number of installations contained a large variety of publishers but mainly consisted of very highly
rated card games and highly rated applications targeting non us markets 
we also consider average user rating as a possible success metric to see how a relatively straightforward
implementation of linear regression performs 
   prediction
     nave bayes  the first model attempted was to build a model which would classify an application
as successful or not based on its description  a nave based classifier text classifier was chosen  and the
implementation was written in java for use in a mapreduce pipeline over the text      cross validation was
performed so that the performance of the model might be measured  as seen in figure   
while not the best performing algorithm  the run time performance of the algorithm was extremely good
and allowed for quick changes  and some interesting results can be seen from the intermediate data of the
algorithm 
   

p  xphoto     success x           

   

p  xshare     success x           

   

p  xdownload     success x             

fi 

 e   

  installations

 
 
 
 
 

average rating

 

 e   

 
 
 
 
 

average score

 

predicting mobile application success

 e   

 e   

 e   

 e   

 e   

 e   

  installations

figure    the distribution of average scores and numbers of installations 

figure    training curve for the nave bayes model 

     glm  given our definition of success x  one could say that success x     is distributed bernoulli
with parameter    p success x             we could then use our continuous feature vectors to train a
generalized linear model to predict success x  in this case given the distribution  the glm would be logistic
regression   cross validation was performed so that the performance of the model might be measured 
the cross validation error is remains high  suggesting the possibility of overfitting  we instead switch to
performing logistic regression on the first two principal components of the continuous features  described
above  
the comparison between the two approaches is shown in the training curves in figure   
     linear regression  additionally  we try and use the continuous features to try and predict just the
average rating of the application  one might hypothesize that predicting a popular application might be

fi 

tuckerman  c j 

figure    training curve for glm models   left  raw  right  pca 

figure    rmse training curve for the linear model 

difficult whereas predicting whether an application makes users happy or angry might be easier  figure  
shows the performance of this model via the rmse 
   conclusion and further discussion
the accuracy of the above discussed models show that there does exists some  albeit limited  predictive power in the eventual success of an application which can be garnered from the publically available
information on the google play store 
more interestingly  certain insights can be garnered from looking at the models themselves instead of
just their output  it is shown that thirty five percent of all successful applications contain the stem photo
 eqn     and thirty one percent of all successful applications contain the steam share  eqn     somewhere
in their description  we are able to start to build a picture of the genres of applications in which users are
interested by using this model 
other interesting observation include those from the glm model  such that a high price and long length
of description are penalized  which is intuitive  but the degree to which they are important is surprising  as
seen in figure   
   future
while the models were shown to be able to learn to some degree of success and interesting conclusions
can be drawn from the data  it was not shown that our definition of success x actually correlates with any
economic success  there exists companies  such as appannie  which attempt to make available this data
for commercial purposes  a developer interested in modeling the current state of affairs to determine which
kind of application to develop  or an investor wishing to invest using models such as these would do well to
subscribe to such a feed of information to ensure that success x correlates with revenue 

fi   

 

   

   

successful 

   
   
   

successful 

predicting mobile application success

 

    

    

    

    

 

length of description

  

   

   

   

price  usd 

figure    success versus  length of description  price 
an additional future area of exploration is training on historical data  the most important conclusions
were related to what the trained models say about the current state of affairs  it would be a good space to
explore how trends and changes in the ecosystem could be explored using a similar procedure on historical
data 
additionally  during the exploration of the nave bayes model  certain stems such as download  eqn    
were found to be present rarely in the descriptions of successful applications  spot checking applications with
the stem download in their description turned up numerous low quality applications that appeared to be
spammy and very poorly rated  building classifiers to find these types of low utility  potentially dangerous
applications could help protect consumers from accidentally installing bad applications  or perhaps even
lower their ranking in the search results 
finally  spot checking some of the misclassified applications by the nave bayes model seemed to show
that keyword stuffing  i e  including unrelated  comma separated keywords in the description to help with
discoverability  was responsible for some of them  exploring methods for detecting these non sentence
segments of the description would be a natural next step to remedying the problem 
acknowledgements
the author would like to thank the cs    course staff for their plurality of help  guidance  and direction
for this project 
references
   
   
   
   
   
   

bird  steven  loper  edward  klein  evan  natural language processing with python  oreilly media inc       
maskey  sameer  mapreduce for statistical nlp machine learning       
scrapy  http   doc scrapy org en latest intro overview html       web     nov      
selectors  mozilla developer network sept       web     nov      
wilcox  mark  voskoglou  christina  state of the developer nation q        vision mobile  july      
worldwide mobile app revenues from      to       in billion u s  dollars   statista        web     nov       
http   www statista com statistics        worldwide mobile app revenue forecast 

fi