machine learning implementation in live cell tracking
bo gu
dec   th     
abstract
while quantitative biology has gradually become the major trend of biology  researchers have put their eyes on analysis tools that can give them more quantitative
read out of the biological system  cell biologists are researchers that have started to
use quantitative image analysis tools at the earliest time  and by using these tools 
information such as the dynamics of certain molecules of interest can be quantified
rather easily  among all the approaches  live cell cell tracking has become the most
informative but also the most challenging one  to date  most of the cell tracking
scripts are semi automatic of which parameters have to be heavily tuned as well as
observational supervision  to improve this method and make it more automatic is
thus a meaningful problem  in this project  we are hoping to implement machine
learning into the tracking dataset and look for potential improvement of the original
tracking method 

 

introduction

as more and more sub fields of biology is going into quantitative realm  biologists have
started to pay serious attention to tools that can help to generate quantitative data 
cell biologists are one group that firstly started and still lead this trend  thanks to
the fast development of state of the art microscope  cell biology has undergone a radical
transition from being mostly observational to real time  high throughput and quantitative 
using fluorescently tagged proteins and cellular organelles  researchers can perform all
sorts of experiments on live cells to understand the basic principle governing cell biology 
analyzing data from these experiments requires image processing to quantify the spatioand temporal dynamics of specific labeled proteins at the single cell resolution termed
tracking  by tracking the cell at this resolution  information such as variability among
the population of cells  which was never possible by traditional biochemical measurement 
can be reflected 
however  it turned out that the following analysis part of the image is rather tricky and
not close to the capability to precisely analyze the large amount of data  particularly  livecell tracking has become one of the biggest issues in quantitative image analysis  to date 
the general process of live cell tracking involves   major steps     image segmentation    
cell feature extraction and    image sequence assignment  of the   basic steps for live cell
tracking  the  rd step  which is to assign each single cell in one frame to its correspondent
cell in the previous frame  is the most challenging one  while there are sophisticated
open source software and packages that can help biologists process individual frames of
 

fi  method
image such as segmentation  there are not even good way to track cells in lab  let alone the
publicly available ones  in practice  researchers usually track cells by one of the five ways
below  including the centroid method  the gaussian fit method  the correlation method 
the sum absolute difference method  and the interpolation method  among them  the
most widely used method is simply by finding the nearest assignment between consecutive
frame for each single cell  this strategy works for at most     of the situations but
collapses in the situations where cells that are plated too dense or cells that are moving
too fast  in recent years  researchers have come up with different new ideas about how to
improve the tracking algorithm to make them work better  both the appearance features
which assumes that the shape of a certain cell changes slightly between consecutive frames
and the method to maximize the smoothness of trajectory and the velocity of the cells
have been raised  clearly  the take home message here is that more features have to
be incorporated to track cells more precisely  here  we are thinking about implementing
machine learning algorithm to    determine which feature of the cells weights more when it
comes to cell tracking     whether its possible to come up with generalization of tracking
method by implementing machine learning     hopefully  to generalize a good algorithm
for live cell tracking and integrate directly into the image analysis pipeline in our lab 

 
   

method
dataset

thanks to researchers from the meyer lab at stanford university  we got the live cell
tracking movies consisting of hundreds of consecutive sequences of frames of images taken
by confocal microscopy  each frame of image is a greyscale image of     x     pixels 
the tracking images are for different types of cells  one of which is a human mammary
gland epithelial cells  mcf  a   the other is a human umbilical vein endothelial cells
 huvec   for each type of cells  different channels of microscope recording the localization and dynamic changes of distinct tagged proteins are gathered  the features for each
single cell at each frame are extracted and recorded by an open source software package
and further customization of the scripts  features are then recorded for each cell in the
frame  for all frames  thus generating three dimensional matrices m rmxnxk with each
layer k represent the kth frame of the image sequence  the ith row representing the ith
cells identified within one single frame and the jth column for the jth feature for all the
cells in one frame 
with the customized script for cell tracking  individual cells between consecutive
frames are assigned to its putative correspondent cells  this is done by mostly finding the nearest cells or largest overlap between each two consecutive frames  the tracking
event for each single cell between consecutive frames are later on classified as either correctly tracked  assigned label    or mis tracked  assigned label     conveniently  since
all the features extracted are quantified by numbers  we take the difference of each feature between each consecutive frames for individual cells as their training features  the
tracking problem then turns into a supervised learning problem where we can implement
various learning algorithms on 

 

fi    feature extraction

   
     

  method

feature extraction
segmentation and feature extraction for individual frame

a typical workflow of live cell image analysis involves the processes shown in figure    the
first step is to preprocess the raw image into quantifiable digital data  this includes at
least segment specific cellular organelle and extract essential features of each individual
cell in a single frame as many as possible  traditionally  different labs come up with
their own customized script to do the image segmentation and feature extraction  which
include common features such as centroid position  meanintensity  stdintensity  meanintensityedge and perimeter  however  more complicated features that are typical in the
field of digital image processing is not accessible by most of the scripts written in house 
even matlab scripts written separately are not fully functional or available for some of
these features  considering the concern and recent progress in live cell image analysis 
we feel it might be useful to incorporate some of these features into our later tracking 
conveniently  a recently developed open source software package by researchers at mit
 cellprofiler  incorporated the capability to extract most of the features of digital image
processing  cellprofiler simultaneously measures the size  shape  intensity and texture
 including even the most powerful gabor features and haralick features  of a variety of
cell types at the single cell resolution in a high throughput manner  this greatly ease the
process of image segmentation and feature extraction and make this whole process modular so that each parameters can be tweaked interactively with a gui  in order to check
the real capacity of the software  we have done thorough challenges to the segmentation
power and feature extraction power and careful check of the source code  mostly written
in python and matlab   and concluded that for the segmentation and feature extraction
of individual frame  the software can do at least no worse job than most of the currently
available scripts written in the meyer lab  therefore  we decided to shift our whole working platform for image processing of individual frames to this pipeline  for each single
cell at individual frame  we can extract up to     meaningful features and all the features
are quantitative representation of specific aspect of the property of single cell 
raw image

segmentation

feature
correct

intensity
shape
edge
texture


assignment

incorrect

 a 

figure    typical pipeline of live cell quantitative image analysis  raw data are retrieved by confocal microscopy and sequences of collected images were later segmented
using customized script  cell tracking were done by assignment of individual cells to its
correspondent parent cells in previous images 

 

fi    feature extraction

     

  method

live cell tracking

after the segmentation and feature extraction  each cell is represented by a vector in r   
for each frame  the next step is to connect consecutive frame together so as to assign each
single cell to the previous next frame  to this end  we implement the tracking script
from the meyer lab instead of the ones in the tracking pipeline from cellprofiler due to
the poor performance the tracking by the software per se  after the assignment done
by primarily finding the nearest cell in the next previous frame within a certain range
of searching area measured in pixels  we represent each cell by a matrix where each row
vector represents the features extracted from an individual frame 
this then gives us a good starting point for building our training set  as always  the
assignment done by the scripts has a certain error rate  where cells are mis assigned even
if they fit the initial conditions  by manually check the error rate of several frames and
pick the data of lower error rate  we can further conduct manual correction of the dataset
or simply just filter out the cells that are mis assigned  the further filtered cells are then
used as our positive dataset  initially  to minimize the contribution of position factors
in differentiating between the positive and negative training sets  we limit our negative
training set to the cells that are assigned by the script  meaning they fit the condition of
nearest object so that the distance factor is eliminated  but are filtered out  however  due
to the fact that there will just be too little negative training set compared with positive
training set and the intuition that we cant simply eliminate the contribution of distance
in differentiating between positive and negative set  we relax our criteria in finding the
negative training set to as much as    fold of the distance limit than that of the positive
set  within    pixels   with that  the factors that contribute to negative training set is a
mixture of both the distance and other factors 
after we set up our criteria for choosing positive and negative training set  we do further transformation of the dataset for easier accessibility by machine learning algorithm 
given xki as the feature vector we get for the ith tracked mis tracked cell at the kth
frame  we think that the x   xji  xji    between each consecutive frames might be a
good estimation for the input feature we want  we try a different set of features which are
the square of the original features  the current approach eliminate the sign ambiguity 
     

dimensionality reduction of feature space

as mentioned before  the feature vector for each cell contains     entries  this high
dimensionality of input feature space might potentially cause over fitting to the learning
algorithm  aside increase the training set  dimensionality reduction might also be an
option to address the potential issue  to do this  we firstly implement pca to reduce
the dimensionality of our feature vectors  not only will this pre processing be helpful to
reduce the dimensionality of the feature  but it will also be essential for implementing
later on the naive bayes learning algorithm since the naive bayes assumption requires
that features x are conditionally independent given y  based on the top eigenvalue of
the cross correlation matrix we got  we decided to choose the top    linear combination
of feature which takes up     of the sum of eigenvalues and reduce the input feature
dimensionality from     down to    

 

fi  model training

 

model training

we chose the classification approach cause we can simply apply different methods and
compare the effect of them  we use the delta v between consecutive frame as the feature
space and the positively tracked feature as positive example and the others as negative 
in this sense  we should have way more negative examples than positive examples  to get
the data  we do pairwise comparison between the features extracted in each consecutive
frame and calculate the pairwise delta feature  then  by applying our original tracking
code  well identify the positively tracked pairs and its correspondent feature space 
to train our dataset  we choose to use discriminant analysis  as well as svm models
and compared their relative efficiency and precision 

   

logistic regression

we perform logistic regression on training set of different sizes by stochastic gradient
ascent in matlab  the mathworks  natick  ma  usa  

   

support vector machine with linear kernel

we train a support vector machine  svm  using the libsvm libraray  ref   we select
linear kernel  the default kernel  to get the optimal linear boundary hopefully at even
higher dimensional space for input features  however  we are not sure yet whether the
training set is linearly seperable at higher dimension  so implementing other kernels has
also been considered 
     

naive bayes

since the features in our training set are all continuous  we have to conduct gaussian naive
bayes which assumes that the probability distribution of some variable x given a class 
p x    c  can be computed by plugging v into the equation for a normal distribution
parmeterized by c and c  and the probability is simply given by
 c   
 

e  c 
p x    c    p
 c 

to perform gaussian naive bayes  we use fitnaivebayes function in matlab to create a
naive bayes classifier and later prediction  by default  the function models the predictor
distribution within each class using a gaussian distribution as described above 

   

gaussian discriminant analysis

to train a gaussian discriminant classifier  we use the fitcdiscr function in matlab 
later on  we use predict function to get the output label by minimizing the expected
classification cost
k
x
y   arg min
p  k x c y k 
y     k

k  

where is the predicted classification 

 

fi  result

 

     

  
pos
neg

  

 

  

 
 

u 

eigenvalues

 

   
 
   

 

 

   

 

  

  

  

order sorted by eigenvalue

  

   

   
   

   

 a  sorted eigenvalue

   

   

 

  

u 

  

  

 b  input feature x projected onto top   principal
components
pos
neg
pos
neg

  
  
  
  

 

u 

u 

 

  

 

   

   
   
  

  

   

   
  

  

  

 

u 

   

   

   

   

   

   

   

  

 

  

  

  

  

 

 

u 

  

   

   

u 

   

   

   

   

 

  

  

  

  

  

  

u 

 d  input feature x  projected onto top   principal components

 c  input feature x projected onto top   principal
components

figure    visualization of input features at lower dimension  blue and red dots represent
the positive and negative training sets respectively

 

evaluation of learning algorithm

for each learning algorithm we perform hold out cross validation  training on     of the
data and testing on the rest     of the data  we generate training error and testing error
and the learning curve for each method for comparison 

 
   

result
dimension reduction of input feature

as mentioned above  for each single cell  our input vector is in     dimension  however 
since all these features are extracted automatically by relatively independent programs
developed by different group  although they are integrated into the same platform  it is
not known whether all these features are independent  to check the mutual independence
of the input features  we first did pairwise cross correlation of the input features  as
expected  some features appear highly correlative  suggesting the possibility of dimension
reduction  in addition  some pairs of features shows strong negative correlation and such
 

fi    logistic regression

  result

correlation turned into positive correlation when we convert the input feature x into
their square feature x     we calculate the eigenvalues s of the cross correlation matrix
 
x t x  which is shown in figure   a  and sorted by their weight  it is interesting to
m
see that the top   eigenvalue already consists about     of the sum of the eigenvalues 
thus  we decided to choose the top   or   eigenvalues as the principal component for
visualization of the input feature  further inspection of the eigenvalue tells us that other
than the position information  texture features also have a high weight in constituting the
principal components  as shown in figure   b  and   c   input features are then projected
onto these three principal components for visualization  also shown in figure   d  is the
projection of original data x top   principal component  from the figure  we can tell
that these dataset are linearly inseperable when projected onto the arbitrarily chosen  
principal component  this indicates that we need to either increase the feature or to
incorporate polynomial of these three components in order to use linear classifier 

   

logistic regression

to check the efficiency of linear classifier  in this case the basic logistic regression without
regularization  we perform logistic regression on the new feature matrix converted by
            x  as shown in figure    the linear decision boundary created by logistic
regression really doesnt do a good job in separating the two sets of data  this lead us
to think maybe using logistic regression with the polynomial of these projected features
might help and we are in the process of check that  however  do to the time limit  we
dont have enough time to finish this part but it is definitely worth trying 
  

pos
neg
decision boundart

  

  

decision boundary
neg
pos

u 

 

  

u 

   
 

    

   

  
  
  

   

  

u 

   
   

   

u 

 
   
   

 

    
   

 

  

   

   

   

u 

   

   

   

 

  

  

  

  

u 

 

 a  decision boundary of x input

 b  decision boundary of x input

figure    decision boundary visualization of pca  blue and red dots represent positive
and negative training sets respectively

   

comparisons of performances of different classifiers

to test other more complicated classifier  we choose classifiers including gaussian naive
bayes  nb   support vector machine with linear kernel  svm  and gaussian discriminant
analysis  gda   shown in figure   are the learning curves of individual classifiers with
all the input features  interestingly  three approaches showed quite different behavior on
the same training set  as expected  for all three method  training error increases with
 

fi    comparisons of performances of different classifiers

  result

the increase of training set  when we take the testing error into consideration  gda
performs the worst and didnt do well in learning  nb performs the best and learns very
well even with small number of training set  also  the training error and testing error
converge on a very small number  indicating a very successful classification capability 
svm however  shows a significant reduction of the testing error along with the increase of
training set  but the change of training error showed strange pattern  where high frequent
spikes are observed on the learning curve  this could either indicate the quality of the
input set or simply because of the learning process is limited by the maximum iteration
number in the svm code used  in most of the cases  the optimization reaches the iteration
limit of the svm  therefore  we are further considering changing from linear kernel to
radial basis kernel and select appropriate parameters by performing a grid search in logspace to maximize area under the  receiver operator characteristic  curve obtained by
crossvalidation  in conclusion  among all three classifiers  gaussian nb performs the best
and we are going to further optimize this approach for later use 
   

   
training error
testing error

   

    

   

   

error rate

error rate

training error
test error

   

    

   

   

   

    

 

 

   

   

   

   

training set size

   

   

   

 

   

 a  learning curve of gda

 

   

   

   

   

training set size

   

   

   

   

 b  learning curve of gaussian naive bayes

   
training error
testing error

    
   
    
   
    
   
    
   
    
 

 

   

   

   

   

   

   

   

   

 c  learning curve of svm with linear kernel

figure    performance comparison between different learning algorithms  blue and orange
represents training and testing error respectively 

 

fireferences

 

future direction

in conclusion  in this project  we were managed to get new insight into the feature structure for live cell tracking and this project provided us chances to developing or optimizing
our original script for cell tracking  in addition  due to the good performance of gaussian
naive bayes classifier  we are having a good start of building a machine learning based
approach for cell tracking 
however  the further we dig into the project  the more we feel a lot more can be done 
we are at least thinking about including more dataset from different cell types with different morphology and moving speed and mix them together to train a more general model 
in addition  we are also thinking about training using different set of features as well as
the principal components by finding good classifier for these components 
acknowledgement we thank the people in the meyer lab for providing dataset and
knowledgebase about live cell tracking and also professor andrew ng and the teaching
staff for their guidance and hard working 

references
    use of texture classification to quantify stem cell differentiation during
time lapse imaging sunil pai  nathan loewke thomas m  baer       cs    final
project
    good cell  bad cell  classification of segmented images for suitable
quantification and analysis derek macklin  haisam islam  jonathan lu      
cs    final project
    cellprofiler  image analysis software for identifying and quantifying cell
phenotypes  genome biology   r     pmid           carpenter ae  jones
tr  lamprecht mr  clarke c  kang ih  friman o  guertin da  chang jh  lindquist
ra  moffat j  golland p  sabatini dm       
    high throughput  single cell nfb dynamics  current opinion in genetics and development  t  k  lee and m  w  covert  vol      no     pp      
           genetics of system biology
    gabor feature based classification using the enhanced fisher linear discriminant model for face recognition  liu  chengjun  and harry wechsler  image processing  ieee transactions on                      

 

fi