predicting africa soil properties using machine
learning techniques
iretiayo akinola    thomas dowd   
electrical engineering
stanford university  stanford  ca      
email   iakinola stanford edu   tjdowd stanford edu
abstractdifferent machine learning algorithms were assessed for estimating five functional soil parameters  soc content 
calcium content  phosphorous content  sand content  and ph
value   the algorithms used include variants of linear regression
and support vector regression  a closer look at the prediction
performance for each target revealed that apart from ph  which
consistently had worse performance  prediction for the other
soil properties was quite satisfactory  rmse         applying
machine learning techniques to soil properties prediction has
shown a lot of promising and encouraging results  getting more
data  domain knowledge and intuition  possibly from soil scientist experts  would surely maximize this potential for accurate soil
property prediction 

i 

i ntroduction

soil functional properties  such as primary productivity 
nutrient and water retention  and resistance to erosion  indicate a locations ability to perform important ecological
services  traditional methods of measuring and characterizing
soil properties require expensive and time consuming scientific
procedures  low cost measurements obtained through diffuse
reflectance infrared spectroscopy and remotely collected data
have the potential to quickly estimate these same characteristics without the use of costly chemical resources  inexpensive
characterization methods would allow large  data sparse regions to plan sustainable agricultural development and manage
local natural resources 
our objective was to accurately model the relationship
between these inexpensive measurements and five soil characteristics properties  soil organic carbon  soc  content 
calcium content  phosphorus content  sand content  and ph
value 
ii 

l iterature   review

since the mid     s  pedotransfer functions  ptf   which
are predictive functions of certain soil properties using data
from soil surveys  have been used to predict soils in temperate
regions  however  soil prediction methods can be adapted
across climates  according to minasnya             methods
developed in temperate regions can be applied for the soils
in the tropical regions albeit with adjustments to calibration
and choice of relevant available predictors  prior to model
selection  a literature review was conducted on past work
modeling spectroscopy data to soil characteristic qualities 
pedotransfer functions and most other models used in
 predictive  soil science are linear regression based  rossel

et al         performed an analysis on using visible  nearinfrared  and mid infrared absorbance data to determine soil
characteristic properties  their method used partial leastsquare regression  plsr  to model the system  and they were
most successful in developing predictions for ph  organic
carbon  phosphorous  and sand content using mid infrared
absorbance values     
rossel and behrens        experimented with a number
of machine learning methods to map full range spectroscopy
data to similar soil characteristics  support vector regression
provided the most accurate results for the three target variables
in question  soc content  clay content and ph levels      
more recent prediction of soil properties such as     and    
still embrace the linear model assumption for their research 
in this project  we explore how recent improved machine
learning techniques can be applied to the soil science domain
to improve the overall prediction performance 
iii 

dataset

the dataset consisted of a collection of       soil sample
measures  soil was collected from a variety of locations
in africa  each data point contained       features which
represent the following low cost measurements 


      mid infrared absorbance measurements  wavelengths ranging from         cm           cm    
originally obtained via diffuse reflectance infrared
fourier transform spectroscopy 



depth of the soil sample  topsoil or subsoil 



remotely collected data including climate  topographical  vegetation index  surface temperature  and other
information about the sample collection site obtained
via satellite  all satellite data was mean centered and
scaled 

the data set contains monotonically adjusted values for the
five target variables  soc content  calcium content  phosphorous content  sand content  and ph value  such that all target
variables take both positive and negative values 
the dataset was provided by the africa soil property
competition hosted on kaggle com 
iv 

m odel s election

noting the success of linear fitting in other datasets mapping spectroscopy data to soil content characteristics  a number

fiof linear regression variants were attempted  in an effort to be
thorough  other methods such as support vector regression and
clustering were also attempted  the choices of models tried
were also guided by the fact that the number of features is
far more than the sample size which eliminated options like
sgd regressor  stochastic gradient descent regressor  that
requires relatively large data points 
linear regression 
determines linear coefficients to map feature set to target
variables  linear coefficients    for the feature set data  x 
are determined for each target variable  y  across the entirety
 
pm
t
of the test set  of size m  such that
is
i   yi   xi
minimized 

linear regression is then conducted on the transformed sets 
   
support vector regression 
developed by vapnik             for a feature space of
xi  rn and target variable yi  r with a total of m samples 
parameters c     and       and a valid kernel function  x  
we can develop the following problem that would best fit the
model estimating y as wt  x    b 
pm
pm
minw b      wt w   c  i   i   i   i  
subject to
wt  xi     b  yi     i  
yi  wt  xi    b     i  
i   i     i           m
the dual of this problem is the following 

ridge regression 

min 

ridge regression is similar to linear regression in that it
determines linear coefficients to map the feature set to target
variables  however  ridge regression also attempts to limit the
magnitude of its linear coefficients by adding an additional
term that penalizes the l   norm of the  term   is chosen as
the following 
 ridge   argmin

m
x

yi   t xi

 

  kk  

i  

where  is a tuning parameter 
lasso regression 
lasso regression takes the same approach as ridge regression only it penalizes the l   norm of the  term  which results
in the following definition 
 lasso   argmin

m
x

yi   t xi

 

  kk 

i  

where  is again a tuning parameter 
principal component regression 
pcr uses principal component analysis  pca  to first
reduce the dimensions of the feature space  linear regression
is then used to determine coefficients mapping the new feature
space to the target variables  pca transforms the feature space
by using each samples feature measurements to determine correlation in the feature space variables  converts the feature data
into a set of orthogonal and linearly uncorrelated components 
and uses the first n components to limit the original feature
space to rn   pca work in this project was conducted through
packages using the singular value decomposition of x t x 
where x is the feature space data 
partial least squares regression 
plsr is a similar procedure to pcr  only the objective is
to identify and remove cross correlation between feature set
and the target variables  while pcr utilities the singular value
decomposition of x t x  plsr uses the singular value decomposition of the product of the transposed feature space and the
target variable space  x t y   to determine common orthogonal
factors and transform both feature and target variable space 


subject to

 
 t

        q 
pm    

i    i  i    
i   yi  i
t


pm

 i  

e          
   i   i  c  i           m

where
pm q   k xi   x   the approximate solution of the dual is
i    i   i  k xi   x    b      this project attempted to
fit the data using the gaussian kernel 
v 

i mplementation d etails

the error metric used in this project was the mean columnwise root mean square error  mcrmse  between the actual
target variables values and predicted target variable values 
v
  u x
m
  xu
 
 j 
t
mcrmse  
 y  yi  j   
  j   n i   i
root mean square error  rmse  was used to compare modelfitting performance of individual target variables 
v
u m
u   x  j 
 y  yi  j   
rmsej   t
n i   i
k fold cross validation  k       was used to develop
an accurate measurement of these error metrics  model
training and prediction was conducted in python using the
scikit learn package 
vi 

r esults

feature reduction
as the dimension of the feature set exceeds the number
of samples  dimensionality reduction through principal component analysis distilled the feature set to its most critical
components  most of the models used did not benefit significantly from the reduced feature space  likely because the other
algorithms constraints performed a similar action of reducing
highly related features 
the model with most improved performance was linear
regression  which  when conducted after pca became pcr  to
determine the optimal number of features  pcr was conducted
a     times with a range of feature reduction factors  from   
to the number of samples available in the training set   the

fitraining and test mcrmse of these models were calculated
for each reduced feature set  the results can been seen in the
plot below 

the soil data could be divided two classes of similar size 
topsoil and subsoil  after getting the performance for the entire
dataset  we repeated the whole prediction procedure for each
of the classes and found that training and testing errors were
very similar to that of the overall performance 

table    model prediction performance  mcrmse 

the table above contains only the results from the
most successful models  some other methods attempted that
achieved poorer results are summarized below 
fig     mcrmse vs  total features

using these results  the optimal number of features was
determined to be     to ensure the validity of this conclusion 
singular value decomposition was conducted on the feature set 
which determined that a reduced feature set in r   preserved
      of the data 
model performance
the figure below shows the prediction performance by six
best performing algorithms on the five target variables  the
overall prediction performance showed that the linear regression based models had comparable and better performances
compared to the others  ridge regression and pcr  the two
top performing models  both perform the same underlying
function of penalizing the non relevant features  while ridge
regression does this by constraining the regression coefficients 
pca transforms the feature set by removing redundancies 
lasso regression also had similar performance 

other models
one model attempted was a double layered estimation
model was considered where an initial a classification stage
on quantized data is followed by a linear regression prediction
of data in each of the quanta bins  the results of the first
svm based classification step were not as impressive enough 
while the linear kernel performed best  compared to gaussian 
polynomial  sigmoid kernel  which confirmed the notion that
linear models are best for soil prediction  the highest prediction
performance achieved for just two class quantization was less
    for all the target variables  this forms a poor basis for
the following regression step on as already misclassified datapoints would get poor estimations results in the end  besides
the misclassified datapoints from the first stage might corrupt
the regression model learning  training process 
bagged support vector regression was also conducted in
an effort to prevent overfitting for training data  however  the
bagged results were not significantly different from the regular
svr output 

vii 

fig     target variable rmse by model

d iscussions

for the majority of the target variables  linear regression
and other linear variations achieved high performance  the
exception was ph  which remained the most difficult to predict
for all models  figure     shows that ph was less correlated
with other target variables  this could be because the set
of features in the data does not capture all the factors that
contribute to the ph of soils  while other target variables might
have intersection of features that are commonly indicative
of them in varying degrees weights present in the dataset 
capturing indicators of some of the many different component
minerals that contribute to the ph of a soil might require other
types of features 

fiunlike the other linear methods  the reduction of common
correlations between features and target variables allowed for
a linear model that achieved similar rmse across all the target
variables 

support vector regression

fig     target variable correlation

support vector regression was used in an attempt to obtain
a better generalized fit for the data  svr was conducted with
a gaussian kernel  the result had a very low training error
metric  but suffered significant drop in performance for the
test data  suggesting an overfitting problem  further attempts
were made to improve the gaussian kernel svr performance
through bagging methods  but these did not yield better results 

linear regression
given that linear regression models seek to minimize leastsquares error  linear regression performed very well on the
training set  however  the higher test error suggested that
the linear relationship between the training features set and
target variables could not be directly extended to test data 
variations on linear regression were explored to compensate
for this deficiency without adjusting the feature set  while
other methods sought to increase accuracy by adapting and
increasing the feature set 
ridge regression
the estimation performance expectedly depends on the
choice of regularizer  since there are five different target
variables  different regularization values optimizes each of
the targets  in particular  as the regularization parameter was
varied in one direction  performance of the targets  except p 
improved  a compromise had to be made on the regularization
value chosen  performing pca before ridge regression did not
improve performance 

viii 

conclusion

asides from ph which performed poorly  the prediction
performance of our study shows that some soil functional
properties can estimated reasonably well  e g  ca with rmse   
using carefully selected cheaper soil characteristics as predictors and smart machine learning algorithms  our results
show that machine learning techniques applied soil properties prediction holds a lot of promise  with more data and
soil science domain specific tricks  the potential for applying
machine learning to soil property prediction would surely be
maximized 

ix 

f uture w ork

lasso regression

use of probabilistic graphical models for capturing correlations between target variables  the correlation map above
shows that some target variables are quite correlated  joint
probability models might be useful to incorporated these
correlation information into the prediction process to enhance
the overall prediction performance 

this is another regularized regression model and the performance was very comparable to that of ridge regression as
expected  however  it was observed that lasso did considerably better than ridge and and slightly better than pcr on the
prediction of ph  this suggests that the l  norm regularization
might be more suited for specific target variables than others 

get access to raw data and try out other transformation
techniques to extract features  the dataset obtained for this
project had been cured and conditioned by the source  it
would be interesting to try out different feature transformation
techniques on the raw spectrophotometer measurements  this
would help build more accurate models about the data 

principal component regression
based on the mcrmse metric  the pcr model had
the best performance of all models tested  a quick analysis
of the results for individual target variables reveal that the
pcr method achieved very similar results to lasso regression 
pcr served as a significantly better estimator for ph than
standard linear regression  demonstrating that removing the
highly correlated features contributed to a more generalized
model for ph 
partial least squares regression
plsr performed significantly worse than the other linear
regression variants for almost all the target variables  however  its higher performance for ph estimation was notable 

implementation of ensemble methods to combine successful estimation models  in addition to exploring other possible
prediction algorithms  ensemble learning technique could be
employed to combine the top performing algorithms to improve overall performance 
cluster analysis of the data might reveal and pull together
samples with similar soil characteristics  target variables can
then be separately predicted for each of the clusters 

x 

acknowledgement

we would like to thank professor ng for his excellent
instruction  and the cs     tas for their help and advice on
this project 

fir eferences
   
   

   

   

   

   
   

b  minasny and a  e  hartemink  predicting soil properties in the
tropics  earth science reviews  vol       no      pp               
r  v  rossel  d  walvoort  a  mcbratney  l  janik  and j  skjemstad 
visible  near infrared  mid infrared or combined diffuse reflectance
spectroscopy for simultaneous assessment of various soil properties 
geoderma  vol       no      pp               
r  v  rossel and t  behrens  using data mining to model and interpret
soil diffuse reflectance spectra  geoderma  vol       no      pp    
           diffuse reflectance spectroscopy in soil science and land
resource assessment 
j  a  c  medeiros  m  cooper  j  dalla rosa  m  grimaldi  and y  coquet 
assessment of pedotransfer functions for estimating soil water retention
curves for the amazon region  revista brasileira de cia do solo  vol     
pp                    
h  abdi  partial least squares regression and projection on latent
structure regression  pls regression   wiley interdisciplinary reviews 
computational statistics  vol     no     pp              
v  n  vapnik  the nature of statistical learning theory  new york  ny 
usa  springer verlag new york  inc        
c  c  chang and c  j  lin  libsvm  a library for support vector
machines  acm transactions on intelligent systems and technology 
vol     pp                  

fi