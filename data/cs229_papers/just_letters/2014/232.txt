sentiment as a predictor of wikipedia editor activity 
sergio martinez ortuno    deepak menghani    lars roemheld 

abstract we perform sentiment analysis on messages exchanged between wikipedia editors in the so called user talk
pages  to predict future user editing behavior  we found a
reasonably well performing model to predict the number of
edits next week on a per user level by applying the gbm
algorithm  and we discuss the relatively limited impact our
sentiment scores had for this model  our findings could be
used better engage editors  potentially resulting in better article
quality 

i  introduction
wikipedia  the worlds largest encyclopedia  is created by
millions of unpaid editors online  every user can edit every
article  and the project is protected against vandalism and
low quality contributions only through version control and
a system of  again unpaid  reviewers  somewhat hidden
to most casual readers of the encyclopedia  wikipedia also
features a simple social network  every user has a personal
user profile and a user talk page which acts as a publicly
accessible guestbook where users can leave messages to each
other 
the messages exchanged in user talk pages are often
related to a users editing behavior  for example  senior
users may welcome new users  or congratulate them on their
first edits  administrators may officially warn culprits after
transgressions of wikipedias content guidelines or policies 
users may also thank one another for certain edits  and  of
course  users engage in heated debates about what the ground
truth reflected in a certain article should be  not all such
debates are pleasant  although the community as a whole
has been noted for its considerable resilience against both
anarchy and uncontrolled aggression        
social feedback has long been known to be a strong
influencer of intrinsic motivation           observing praise
and gratitude may be a strong incentive for wikipedia editors
to keep up the good work  whereas repeated unpleasant
discussions  official warnings  or even personal insults may
discourage further editing behavior  with this intuition in
mind  we formulated our hypothesis  we ask if received message sentiment can help predict editor activity on wikipedia 
in so doing  we create the opportunity to engage with
frustrated editorsfor example  motivating emails could be
sent to users who are expected to significantly reduce their
  we thank the wikimedia foundation  and in particular leila zia of the
research and data team  for their generous help and support of our project 
this is a course project for andrew ngs course cs     and  by approval
of both teaching teams  for sharad goels course ms e     at stanford
university  we are grateful to both courses for an inspiring quarter 
  sergiomo stanford edu
  deemeng stanford edu
  roemheld stanford edu

editing due to received message sentiment  if effective  this
could increase overall editing activity  and editor happiness 
on wikipedia  for the scope of this paper we assume a
high number of edits to be desirable  since it enables the
encyclopedia to better reflect an everchanging world 
previous work analyzed the sentimental content of the
conversations between wikipedia editors           our work
is unique in that we focused on the personal messages
exchanged through user talk pages and their relation to
future editor activity  rather than analyzing the more factual
discussions on the so called article talk pages 
ii  data and methods
a  source data and sentiment scores
we accessed an anonymized replica of the english
wikipedia database through the wikimedia foundations
research servers      for all users who registered in       and
who had made at least one article edit  n             we
downloaded the contents  date and author of each message
received by these users through their user talk pages  and the
number of article edits made by each user per week in the
complete year      
wikipedias talk pages are implemented in such a way that
any user can not only add text  hyperlinks and images  but
also delete anything  even content added by other users  we
collected the revision history of each user talk page and we
performed a diff data comparison between each revision and
the previous one  if there was any text added or replaced
on a particular revision  then we considered these additions
to be the content of the user talk message  to prepare
the messages for sentiment analysis  we stripped them from
any formatting markup     and applied porters stemming
algorithm      to each word using pythons nlkt library 
we used two different sentiment dictionaries for message
scoring  well known bing lius opinion lexicon     provided two lists of words  one of      words with positive
emotional connotation  and one of      words with negative
connotation  we further used the nrc word emotion association lexicon       a lexicon of       words  where each
word is labeled with    interesting emotional dimensions 
positive  negative  anger  anticipation  disgust  fear  joy 
sadness  surprise and trust  we compressed every message
into    numerical features  each one providing the relative
strength of the measured sentiment and calculated as share of
words in a message appearing in one particular dictionary  
in mid       a new feature was introduced on wikipedia
that allowed users to express thanks for specific edits
  to

be specific  scorem  

 
 sentence 

p

wsentence

  w  dictionary 

fiwith a single click  the thanked editor would then see a
notification the next time he or she logged in  we enriched
our dataset with the number of thanks received by each user
per week 

sample  tneighborhood   events
edits in week

   

b  data analysis and models
manual data inspection showed the weekly number of
edits per user to be extremely noisy  with strong spiking
patterns even for the most active users  see figure     on
a weekly basis  the number of edits per user is clearly
dependent on the preceding weeks number of edits  edits
per week are a time series   typically  an editor would
receive user talk messages after periods of increased activity 
reacting on his editing behavior  under our hypothesis  these
messages would then influence his subsequent activity  given
this observation  we decided to model weekly differences in
editing behavior  and to employ a threshold model  specifically  we wanted to predict weeks where editing behavior is
outside a   neighborhood of the previous week   being a
model parameter  our basic model was to predict the binary
event
   ei  w   ei  w        i  w  
where ei  w  denotes the number of edits by user i in week
w  different functions for the i  w  values give different
predictors  we tried relative thresholds  historic rolling midrange  and historic standard deviation  the latter performed
best  and we defined i  w  as the empirical standard deviation in weekly edit count for user i  up until week  w     
i  w   

w 
  x
 ei  t   ei   
w    t  

figure   shows such a i  w  neighborhood for one exemplary user  and marks the events to be predicted with circles 

edits in week

activity of   rockstar editors
    
    
    
   
 
 

  

  

  

  

  

weeks since registration

fig     exemplary behavior of   of wikipedias most active editors signed
up in       editors have periods of very high engagement  followed by
times of relative inactivity 

in different model iterations we considered different subsets of our feature space  see ablative analysis in table ii  
our total feature space comprised the following features 
 number of weeks since user registration and
exp  weeks since registration    the average number
of edits across all users appeared inversely exponential
in the user account age  leading us to explicitly include
this factor
 historic count of edits

   
   
 
 

  

  

  

  

  

weeks since registration

fig     model visualization  we predicted the events signified by blue
circles  when a users edit count was outside of a   neighborhood of the
preceding week  grey ribbon  

historic count of thanks received
historic count of messages received
 historic count of message words received
 historic average message sentiment received  along   
emotional dimensions 
finally  we defined the relevant history for the model to
be two weeks  using weekly bins to reduce computational
complexity and to smooth over the somewhat sparse data 
to predict a significant change in editing activity event
in week w  we included editor activity and communication
history in week  w     and week  w      and treated the
two weeks separately to allow our models to catch temporal
patterns  we did not include more than two weeks to reduce
the risk of overfitting  implicitly assuming that motivational
effects of messages will not be significant beyond a time span
of two weeks  our total feature vector spanned    features 
the vast majority of wikipedia user accounts is inactive 
in that most users perform at most one edit  typically within
the first week of registration  after which the user accounts
become inactive   most users in our data will therefore not
receive any messages  or show any other signs of activity 
in fact  only about    of the users in our dataset had more
than one edit and received more than   messages on their
user talk page  the first one typically being an automated
welcome message   in order to get more meaningful effects
in our sentiment models  we reduced our dataset to these
users  n          users  
we split our data into a training set       and a test set
      to perform holdout validation  unless otherwise noted 
all performance metrics are calculated on the test set 
our definition of output variable and feature space framed
our research question as a binary classification problem  for
which we tried three algorithms  a logistic regression glm 
a support vector machine with linear kernel  svm   and a
bernoulli distributed gradient boosted tree model  gbm  



iii  results
we worked with relatively sparse and unorganized data 
and probing into the sentment dictionary scores showed them
to align only roughly our subjective ratings  given this 
our model performed surprisingly well  and we obtained
reasonable predictive power  the roc curve in figure  
summarizes the performance of the three algorithms tested 

figbm performed significantly better than the algorithms that
attempted to find a linear boundary between the positive and
negative classes 
model roc curve
    

true positive rate

    

    

model
    

bernoulli gbm
logistic regression
linear kernel svm

    
    

    

    

    

    

false positive rate

by removing features from our model and observing the
resulting test statistics  table ii   we found that removing
all message sentiment causes only a minute decrease in
model performance  whereas the historic number of edits
carried much greater importance  underlining the time series
character of our data once more  
adding sentiment back onto the overwise empty model 
the sentiment scores by themselves were enough to reach a
performance level comparable to that of the fully featured
modelespecially for the test comments set  since receiving any messages at all correlates with previous editing
activity  we attribute some of this effect to the implicit
inclusion of historic edit counts by including historic sentiment  especially given the effects on the less sparse test
comments set  we conclude that sentiment scores have
some predictive value for editor activity  they are not at
all sufficient  however  to build a reliable model 
figure   offers further insight into our best performing
gbm model  the model is well calibrated  and makes relatively many highly confident predictions  in particular  it
captures the fact that the bulk of users did not have significant
changes in week on week behavior 

fig     roc curve for glm  svm  and gbm  as calculated on test set  
our gradient boosted model showed the best performance overall 

model calibration curve

model

acc 

prec 

rec 

acc 

prec 

rec 

test
comments
acc  prec  rec 

glm
svm
gbm

   
   
   

   
   
   

   
   
   

   
   
   

   
   
   

   
   
   

   
   
   

test

train

   
   
   

   
   
   

table i
m odel c omparison    test comments  is a subset of our data  
excluding all weeks without received message history 

no

significant overfitting can be observed  

to further investigate this  we performed ablative analysis

   
   
   

empirical percentage

interestingly  this hints at a strongly non linear relationship
between our input features and the output event  this is not
immediately intuitive  since one could have expected that
more anger will always deter further editswe attribute
part of the nonlinearity to time patterns in the historic data 
gbms superior performance is not due to overfitting  as can
be observed in table i  test error  training error  
in table i  we present performance indicators for the test
and train datasets  additionally  we tested on a subset of our
data  which excluded all weeks without received message
history  test comments  only weeks with at least one
message in weeks  w     and  w       for all algorithms 
the recall corresponding to the test comments set stands
out for being significantly higher than the rest  while the
precision remains about the same across the board  in other
words  it appears that the models are more successful at
detecting a significant change in week on week activity when
they have information about the messages received by the
users during the past   weeks 

   
   
   
   
   
   
   
   
   

   

   

   

   

   

   

   

   

   

   

model prediction

fig     the calibration curve of our gbm model  the model was wellcalibrated overall  the large circle in the top right corner implies that our
model makes a strongly confident and correct prediction for the bulk of the
data where no significant change in week on week editing occurred 

iv  discussion and future work
while we found some predictive value for future behavior
in the sentimental content of messages received by wikipedia
editors  we do not have evidence to establish a causal
relationship between these variables 
furthermore  we note that our conclusions do not necessarily generalize outside of wikipedia and similar crowdsourced
environments  the first limitation that we see is that most
  the model with this feature set predicted the negative class for all
training examples 

fimodel

acc 

prec 

rec 

test
comments
acc  prec  rec 

time since registration    weeks of edits  thanks and messages
time since registration    weeks of edits and thanks
time since registration    week of edits and thanks
  week of edits and thanks
time since registration
time since registration    weeks of messages
time since registration    weeks of messages and thanks

   
   
   
   
   
   
   

   
   
   
   
 
   
   

   
   
   
   
  
   
   

   
   
   
   
   
   
   

test

   
   
   
   
 
   
   

   
   
   
   
  
   
   

table ii
a blative a nalysis

new wikipedia users do not make frequent use of the user
talk pages  this by itself limits the macro level impact of any
interactions that occur in these pages  second  our definition
of sentimental content was rather limited in that we only
performed a simple word matching analysis  we would like
to perform more elaborate bag of words classifiers in future
work to build on stronger messaging patterns 
most messages exchanged through user talk pages are
not sentimentally loaded  but rather talk about the wikipedia
guidelines and policies in a neutral manner  more sophisticated natural language processing techniques could help
identify more complex patterns in these messages  another
possible refinement could come from performing cluster
analysis on the contents of the messages  to find the set of
ideas that are most commonly exchanged in the user talk
pages  an example of one of such ideas might be  i reverted
you edit because you did not cite any sources  or i deleted
your image because it violated copyright law  
we would have liked to take into account the quality
 measured by later reverts  and size of the edits performed 
unfortunately  we were unable to obtain this data for this
study  that is  for this investigation we could not distinguish
between an edit that corrected a typo versus a new article
creation  for example 
nonetheless  we were able to detect macro level patterns
of behavior that appear to discredit the hypothesis that the
sentimental content of user talk pages is a main driver of
user churn on wikipedia  additionally  we undertook the
first steps in building a useful model to predict when a
user is about to suddenly stop making contributions to the
encyclopedia 
r eferences
    aniket kittur  bongwon suh  bryan a  pendleton  and ed h  chi 
      he says  she says  conflict and coordination in wikipedia 
in proceedings of the sigchi conference on human factors in
computing systems  chi      acm  new york  ny  usa          
    viegas  f b   wattenberg  m   kriss  j   van ham  f   talk before
you type  coordination in wikipedia  system sciences        hicss
        th annual hawaii international conference on   vol   no  
pp        jan      
    david laniado  carlos castillo  andreas kaltenbrunner and mayo
fuster morell         emotions and dialogue in a peer production
community  the case of wikipedia  wikisym       th international
symposium on wikis and open collaboration  linz  austria  august
     

    cameron  j     pierce  w  d          reinforcement  reward  and intrinsic motivation  a meta analysis  review of educational research 
               doi                          
    geister  s          effects of process feedback on motivation  satisfaction  and performance in virtual teams  small group research 
               doi                         
    d  iosub et al  emotions under discussion  gender  status and communication in online collaboration  in plos one      e       
     
    wikimedia tool labs  https   wikitech wikimedia org 
wiki help tool labs
    giuseppe attardi  wikipedia extractor code  http   medialab 
di unipi it wiki wikipedia extractor
    m  hu and b  liu  mining and summarizing customer reviews  in
knowledge discovery and data mining        pp          
     s  mohammad and p  turney  crowdsourcing a word emotion association lexicon  in computational intelligence               pp         
     m f porter  an algorithm for suffix stripping  in program    no    
      pp        

fi