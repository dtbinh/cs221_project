classification of accents of english speakers by native language
morgan bryant
mrbryant stanford edu

amanda chow
amdchow stanford edu

sydney li
sydli stanford edu

introduction

methodology overview

accents can reveal a lot about a persons
background  such as their native language  place
of origin  or ethnic background  being able to
recognize different type of accents can also
improve the quality of speech to text
transcription by allowing for specific
preprocessing of recordings based on the type of
accent  our goal is to classify various types of
accents  specifically foreign accents  by the native
language of the speaker  given a recording of a
speaker speaking a known script of english
words  we would like to predict the speakers
native language 

the distinguishing characteristic between accents
is the different enunciation patterns of specific
syllables  which are due to speakers difficulties
pronouncing english phonemes that do not
appear in their native language  therefore we
designed our classification algorithm to capitalize
on this difference by comparing different
speakers enunciations of each syllable in the
recording and using this information to model
how speakers of each language enunciate each
syllable in the script  the testing pipeline then
uses this information to determine which of the
five accents the speakers is the most similar to 
the algorithm we designed is a two step process 
first  we create a classification algorithm for each
syllable that gives us the likeliest accent of the
speaker based on that specific syllable  then  we
use this list of likeliest accents  one for each
syllable   pick the most frequent accent  and
declare it as the speakers likeliest accent  we
select the most important words to use in this
step later on and filter out unimportant and
repeated words  if we consider the list of likeliest
accents to be a feature vector for the recording 
this word selection process is analogous to
principal component analysis 

dataset
the recordings were scraped from the george
mason university department of english speech
accent archive       each recording is of a person
speaking the same english script 
please call stella  ask her to bring these things
with her from the store  six spoons of fresh snow
peas  five thick slabs of blue cheese  and maybe a
snack for her brother bob  we also need a small
plastic snake and a big toy frog for the kids  she
can scoop these things into three red bags  and we
will go meet her wednesday at the train station 

preprocessing data
recordings used for speech processing typically
require a decent amount of preprocessing before
feature vectors can be extracted  the first
preprocessing step would have been to remove
background noise  however  the data set had
minimal background noise 

for each clip  the archive contains information
about the speakers background  such as their
age  gender  birthplace  native language  other
languages spoken  age of english onset  english
residence  and length of english onset  the
characteristics that are of importance to us are
each speakers native language  we chose to
distinguish accents of only male speakers of the
five most common native languages in the
archive   english  spanish  arabic  french  and
mandarin   for a total of     sample recordings 

most of our preprocessing consisted of splitting
up the recording as mentioned above  because
most of the words in the script are monosyllabic 
we split the recording into individual words  we
aligned words using the munich automatic

 

fisegmentation system  maus          which
utilizes a variety of filters  processing  and
heuristics to search for divisions between words 
aided with the script above  we used maus to
split each recording into smaller clips and
samples of each word  clips of the same word
spoken by different speakers inevitably end up
being different lengths due to natural variation in
speaking rate from person to person  we account
this variation later on in the feature extraction
step 

milliseconds  for the process to be effective  as
mentioned above  we normalized for different
speaking rates of each word while extracting the
mfccs  we accomplished this by scaling the
sampling rates of the  wav files  which often vary
from microphone to microphone  the resulting
vector of the mfccs for each word is the set of
features that we use to model each word 

figure    the top row is the sample in frequencydomain  and the bottom row is a representation
of the cepstrum coefficients  the redness of a
square represents a higher valued number  we
used these coefficients as our features 

figure    interface of maus  the audio six
spoons of fresh snow peas is shown in timedomain and frequency domain  and the
phoneme word boundaries extracted from the
program are shown in blue 

the final step consisted of normalizing the clips
by volume  because different speakers may speak
at different volumes or distances from the
microphone  we can normalize for variation in
volume after aligning words by scaling based on
the extrema of each word to the average speaking
volume of each particular word over the entire
training set 

since the vector has many more features than we
need  we identified the    most important
features for each word with pca  running the
unsupervised learning model on the set
recordings of every word  the selected mfcc
buckets were not necessarily the same between
two given words  for each word  we set the
vector of only specific index identified mfccs to
be our newly slimmed down features vector for
that word  overall  using such a truncated feature
set was necessary for computational practicality 

feature selection per word

word models

for each sample of each word  our features are
the mel frequency cepstral coefficients  mfccs  
a convenient and compact way to extract features
that represent audio samples of waveforms  past
papers have shown that mfccs are particularly
useful for speech recognition purposes  which is
exactly what we are doing  the mel spectrum is a
method of categorizing the frequencies of a
sound in a way that distinguishes phonemes
effectively  the mfc process takes a signals
fourier transform and puts the powers into sized
buckets  as defined on the mel spectrum  the
time window must be small  around   

since our dataset was labeled  we used a variety
of both supervised and unsupervised learning
algorithms to create models for each word  for
supervised learning  we trained our models on a
randomly sampled     of the full data set
multiple times  to calculate the test error of a
given model  we ran the trained models on the
remaining     of the dataset and took the
average error  the training sets contained    
samples  and the test sets contained    samples 
the supervised training algorithms used were
svm  nave bayes  softmax logistic regression 

 

fiword selection pca

and gda  the svm model was implemented
exactly as learned in class  with a gaussian
kernel  the naive bayes model was modified to
classify between multiple classes instead of two 
essentially  we performed binary classification on
each category  such that all samples in that
category are classified as positive and all other
samples are classified as negative 

to eliminate bias due to repeated words or
unimportant words  we analyzed the strength of
each word as indicative of a certain accent  we
used the svm model to classify between english
and each of the other four languages using
features from each of our words  the words that
resulted in the lowest classification errors
between each of our language pairs were then
selected as features the classification algorithms
above 

the softmax model was generalized to classify
into five classes to minimize the cost function

in the form of multinomial softmax logistic
regression with the resulting hypothesis
figure    relative classification error from models
trained on each word  along the horizontal axis is
the word being trained  along the vertical axis is
the native language being classified against
english  a brighter rectangle for a word indicates
a higher classification accuracy than other words
for the same native language  for word
evaluation  we chose to discard words with under
       classification rates  close to random
chance  

for gda  we modeled our data as follows 

results
then we maximized the log likelihood 

our best classification rate for the supervised
learning algorithms was     with gda and
nave bayes  with gmm and k means clustering 
we were able to achieve up to     labeling
accuracy on average  and up to     accuracy 

we also experimented with two unsupervised
learning algorithms  a gaussian mixture model
and k means clustering  to see whether the
clusters would match reasonably with our
labelings  also  from previous research  gmms
seem to be a standard for tasks like speech
recognition and analysis  gmms and k means
were ran without modification as learned in class 
and then compared to our labels 

figure  a  left   average classification accuracy of
each accent over all the models  the number of
samples for each accent type  respectively          
          
figure  b  right   average classification accuracy
of each model

 

fithe training and test errors of our models are
summarized below 
learning model
svm
naive bayes
softmax regression
gda

to each of the samples and found that only a
handful of the    spoke with accents   the rest
spoke nearly perfect english 

training error test error
      
      
      
      
      
      
      
      

unsupervised model
gaussian mixture models
k means clustering

for supervised learning algorithms  the likely
result of this mislabeling is a model of a
mandarin accent that is very similar to
unaccented english  this would affect the
classification of all unaccented english samples
 of which we have many   which could be almost
arbitrarily classified into either the english or
mandarin class  for unsupervised learning
algorithms  the likely result would be the
mislabeled mandarin samples being clustered
with the unaccented english samples  if only a
handful  the truly accented samples  are
clustered into the mandarin cluster  that would
explain the low classification accuracy of
mandarin samples 

classification error
      
      

conclusions
our final classification accuracies of     are
much better than random chance       and are
on par with other attempts to classify accents
              as expected  the supervised learning
algorithms performed better than the
unsupervised learning algorithms  figure  b  
among various supervised and unsupervised
learning methods  our naive bayes and gda
models were the most successful at correctly
guessing the accent of a test file  we believe that
gda and nave bayes yielded the best results
because both account for our uneven prior
distribution of samples in each accent category 
the classification accuracies for each language
also have a very strong correlation with the
number of samples for each language  figure  a  

overall  we have obtained a reasonable
classification algorithm  but there is definitely
room for improvement in our methodology 

future
there are several potential measures we could
take to improve our results in the future 
beginning with the quality of our data 
as discussed above  some of our samples were
mislabeled in the sense that each speakers
native language was self identified and
sometimes unrelated to their speaking accent  in
the future  to create better models of true accents 
we would take into account each speakers
familiarity with english as an estimate of how
heavy their accent is  using the provided data of
the length and nature of their exposure to
english 

however  we had several sources of error that
were out of our control  for instance  we did not
have the manpower to manually verify the
results of our word separation with maus
during preprocessing  and we only accounted for
each speakers native language rather than their
familiarity with english  these sources of error
could potentially cause our model to
misrepresent the accents 

for the data preprocessing steps and overall
model design  there are several improvements
that can be made to make our model more
precise  first  we had a convenient system
 maus  at our disposal for splitting the
recordings into words  but rather than relying on
the fact that most of the words in the script are
monosyllabic  we would ideally build a more
robust model and split our recordings into
syllables or even further into individual
phonemes 

the second issue occurs the most prominently
with our mandarin speakers  which is a second
explanation  aside from the small sample size  for
the low classification accuracy of mandarin  of
our    mandarin samples  about    of them had
lived in an english speaking country for a
significant number of years  we actually listened

 

finext  the classification algorithms of each word
only output a hard     to represent which of the
five types of accents is the likeliest for that word 
the issue with this approach is that it simply
takes the accent with the highest posterior
probability and discards the posterior
probabilities of all of the accents without regard
for their values  for all we know  a clip could fit
the mandarin accent only very slightly better
than it fits the english accent  which could easily
happen when our mislabeled mandarin
samples cause the english and mandarin models
to be very similar   one solution would be for the
classification algorithms for each word to output
the vector of all five posterior probabilities  the
second step of our model would need to be
slightly modified to account for the posterior
probabilities of the five accents over all the
syllables 

reference

finally  the second step of our model assigns
black and white labels to each word about
whether it is important or not to distinguishing
between accents  rather than assigning these
black and white labels  we can use some sort of
weighted linear regression to weight the
syllables  and because certain pronunciations of
certain syllables are a red flag for certain accents 
we might even weight the syllables different for
each accent type  calculate a final posterior for
each accent using the posteriors described above 
and take the highest posterior to be the likeliest
accent 

     foreign accent classification   paul chen 
julia lee  julia neidert 

     accent classification   phumchanit
watanaprakornkul  chanat eksombatchai  peter
chien 
     accent issues in large vocabulary
continuous speech recognition  lvcsr    eric
chang  chao huang  and tao chen  microsoft
research  august      
     accent recognition with neural network  
matthew seal  matthew murray  ziyad khaleq 
     accurate short term analysis of the
fundamental frequency and the harmonics tonoise ratio of a sampled sound   paul boersma 
institute of phonetic sciences  university of
amsterdam       

     melfcc m   plp and rasta  and mfcc  and
inversion  in matlab  daniel p  w  ellis 
december       online web resource       
 http   www ee columbia edu  dpwe resource
s matlab rastamat  
     the munich automatic segmentation
system   ludwig maximilians universitat 
munich  germany  florian schiel  december
      web     march      
 http   www bas unimuenchen de bas basmaus html 

given that the distinguishing factor between
accents is the pronunciation of individual
syllables and phonemes  these three
improvements should make our model more
precise because they place more emphasis on

     phonemic segmentation and labelling using
the maus technique   florian schiel  christoph
draxler  jonathan harrington  bavarian archive
for speech signals  institute for phonetics and
speech processing  ludwig maximiliansuniversitat  munchen  germany 

an interesting and related path we could follow
is the existence of different english dialects and
regional accents  such as british accents or
regional us accents such as bostonian accents 
given enough samples  we would hopefully be
able to cluster our english samples into various
regional accents  and create models for these
regional accents in the same way we created
models for the foreign accents  these models
could form a classification algorithm for
predicting where the speaker originated from
based on their recording of the script 

     praat  doing phonetics by computer   paul
boersma  david weenick  december      
computer program  university of amsterdam    
november        http   www praat org  
      the speech accent archive   george mason
university  steven h  weinberger  december
      web     november      
 http   accent gmu edu  

 

fi