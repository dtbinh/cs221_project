a novel approach to predicting
the results of nba matches
omid aryan

ali reza sharafat

stanford university
aryano stanford edu

stanford university
sharafat stanford edu

abstractthe current paper presents a novel approach
to predicting the results of basketball matches played in
the nba league  as opposed to previous work that merely
take into account a teams own performance and statistics
in predicting a teams outcome in a match  our approach
also uses the data known about the opposing team in our
endeavor to make that prediction  our findings show that
utilizing the information about the opponent improves the
error rate of observed in these predictions 

i 

i ntroduction

statistics and data have become an ever more attractive component in professional sports in recent years 
particularly with respect to the national basketball association  nba   massive amounts of data are collected on
each of the teams in the nba  from the number of wins
and losses of each team to the number of field goals and
three point shots of each player to the average number of
minutes each player plays  all the data that is collected
from this great sport is truly intriguing  and given that it
is usually interpreted by people in the sports profession
alone  it is a fantastic and pristine field for people in the
machine learning field  and other data mining sciences 
to apply their techniques and draw out interesting results 
thus  we plan to do just that and utilize the algorithms
we learn in cs    to predict the nba matches 
the paper provides a novel approach to predicting
these matches  as opposed to previous work done in
this field  where the available data is directly fed to
the algorithms  we intend to find a relationship between
the data sets provided for the two teams in a match
and modify the data accordingly before feeding it to
our algorithms  section ii will describe the source and
format of the dataset we will use to train our models 
section iii will present an overview of the model we
intend to implement along with a description of each of
its components  section iv will present the results of our
implementation  and section v will conclude the paper 

ii 

data s et

we collect our data from basketball reference com 
for each game we get a set of    features for
each team  e g   http   www basketball reference com 
boxscores          lal html   the features are listed
in table   
table i  features given for each team and each game
in the season
minutes played
field goals
field goal attempts
field goal percentage
turnovers
personal fouls
points
free throws
free throw attempts
free throw percentage
offensive rebounds
defensive rebounds
total rebounds
assists
steals
offensive rating

blocks
  point field goals
  point field goal attempts
  point field goal percentage
true shooting percentage
effective field goal percentage
offensive rebound percentage
defensive rebound percentage
total rebound percentage
assist percentage
steal percentage
block percentage
turnover percentage
usage percentage
defensive rating

we created a crawler that scrapes the website and
collects the entire data set for all games for the past  
seasons             and stores them in a csv file per
season  we call this data set the game data  each team
plays on average    games per season  so we have about
     data points in each of those data sets  we primarily
use this data set to predict features corresponding to
teams playing an upcoming game 
we also collect seasonal data for each team  e g  

fihttp   www basketball reference com leagues nba
     html   here  there are   tables of features for each
of the teams in the league  we combine   of these tables
 team stats  opponent stats  team shooting  opponent
shooting  into one table  resulting in    features per
team  we call this data set the team data  we primarily
use this data set to cluster teams in order to have more
accurate feature predictions for upcoming games 
iii 

fig     model overview

m odel overview

the previous section described the data set with
which we intend to train our models  each training
example is of the form  x  y   which corresponds to the
statistics and output of a team in a particular match  x is
an n dimensional vector containing the input variables
and y indicates whether the team won  y      or lost
 y      in that match 
given such a data set  a naive approach would be
to feed the training examples directly to the existing
algorithms in machine learning  e g   logistic regression 
support vector machines  neural networks  etc   to predict
the outcome of a match  this approach is undertaken in
the referenced work  however  this method merely gives
a prediction of whether a team wins or loses regardless
of which team it plays against 
in this paper we plan to tackle the intrinsic problem of
the aforementioned method and take a different approach 
instead of directly utilizing the training examples in section ii to train our parameters and feed to our algorithms 
we intend to modify them based on the matches they
were obtained from as well as the relationship that the
different features have with one another  for example  the
statistics that a team is expected to have in each match
depends on the team it is playing against  we plan to take
this into account by clustering the teams into different
groups and to predict their expected statistics based on 
a the relationship that the two clusters corresponding to
the two teams have with one another and b their average
statistics from the previous matches  moreover  once we
have a prediction of how each team will perform with
respect to each of the features  we will congregate the
two feature sets of the two teams into a single feature
set based on how those features relate to one another 
ultimately  this single feature set is fed to our algorithms
in order to make a prediction 
an overview of our model is depicted in figure    it
is composed of the following three components 

   statistic prediction  in this component the two
teams to play in a match are given as input  e g  
los angeles lakers and boston celtics  and the
expected statistics of each of the teams  xa and
xb   in that match is predicted 
   feature formation  this component forms a single
set of input features x from xa and xb based on
how the individual features  xi s  are related to one
another 
   result prediction  this component contains the
different machine learning algorithms we intend to
utilize to predict the final outcome based on the
input feature set x from the previous component 
a  statistic prediction
we use several different predictive models to predict
the features for an upcoming game  using all the data
points from the previous games  we describe all such
models below 
   running average  in this model  the feature values
of a team in an upcoming game are predicted using
the running average of the features of that team in the
previous games it has played in the season  this is
the simplest prediction method one can use to predict
upcoming games  since this method relies on the team
having played at least one game already  we do not make
a prediction for the first game of teams in the season 
   exponentially decaying average  this is similar
to the previous model  but with the difference that the
previous games are weighed by a factor of          
that is  if a given team has played n games already with
gi representing its features in the ith game  our prediction
for the n    st game will be

gn  

n
    x ni
 
 gi
   n
i  

the point of using a decaying average is to test

fithe hypothesis that results have temporal dependence 
that is  more recent results are more relevant than
older results  the lower the value of   the higher the
importance of the recent results 

 basketball matches have no draws and one team must
win  

   home and away average  the hypothesis we aim
to test using this prediction is whether or not teams
perform differently at home and away  we use two
running averages for each team  for home and away
games respectively  then  if the upcoming game is a
home game for a given team  the running home game
average is our prediction  similarly  we predict features
if the game is away from home 

once we have the predicted feature set of a match 
we can then predict the outcome of that match by means
of any machine learning algorithm  the algorithms we
utilized are linear regression  logistic regression  and
support vector machines  svm   for linear regression 
the score difference of the two teams was used to train
and test the data 

c  result prediction

iv 
   cluster based prediction  the aim of this method
is to see if we can predict the behavior of a team  based
on the type of team they play  in order to cluster the
teams  we use our team data set  where for each team
we have    features  we first perform pca to reduce
the number of features that go into clustering to n 
then  we perform k means clustering to get k clusters 
then we keep a running average of each teams features
agains teams of each cluster  that is  we keep n running
averages for each team  then  if the upcoming game of a
given team x is against a team which belongs to cluster
i  our prediction of x s features is the running average
of x s features against teams in cluster i 
b  feature formation
a distinctive aspect of our approach from the previous
work is that we take into account the statistics of the opposing team before making a prediction  in other words 
we create a training example  to be fed to our algorithms 
for each match rather than for each team  this training
example would be the output of this component  where
the input would be the two  expected  training examples
of the two teams  which is also derived with knowledge
of the other team by the previous component   hence  the
task of the feature formation component is to form an
input variable vector for the match based on the expected
input variables of each team 
for our implementation  we have carried out the most
simplistic method of comparison  which is to simply take
the difference of the predicted feature values of each
team to form the final feature set  i e  
x   xa  xb

an output of y     would then indicate team as
victory  while y     would indicate team bs victory

i mplementation and r esults

the data was trained and tested for each season
individually  a collection of five seasons were tested
from      to       the foregoing results indicate the
average of the results achieved from these seasons  the
hold out cross validation technique was used for training
and testing  where     of the matches in a season
were used to train the algorithms while the rest of the
matches were used for testing purposes  the reported
error rate was computed by taking the average of    
iterations of this technique with different training and
testing sets  furthermore  the forward search feature
selection algorithm was used to choose the most effective
features for each of the algorithms 
here we break down our results based on the statistics
prediction method used 
   running average  the running average is the simplest predictor for the the features of an upcoming game 
we simply train our classifiers on a       training testing
set split  the results are shown in table ii  we see that
linear regression turns out to be the best classifier in this
case  we note that training and test errors were generally
very similar  one possible reason for that is that we used
predicted statistics for both runs  the fact that we were
using a prediction to train a classifier means that the noise
from our predicted statistics cannot be subsumed during
training 
   exponentially decaying average  we use the decaying averages and feed them into our   classifiers to
predict the outcomes of the matches in the training and
test sets  we experimented with various values of the
decay parameter    the results are shown in figure   
similar to the previous part  linear regression performs
the best amongst the classifiers  both training and test
errors decrease as the value of  increases  which signifies that there is no temporal relationship between the

fitable ii  training and test errors when using running
averages as predictors

linear regression
logistic regression
svm

training error
      
      
      

test error
      
      
      

different numbers of cluster and different pca components during the prediction phase  the results are shown
in figure    we find that in general the training and
test errors increase with the number of clusters and the
number of components in pca  we find that logistic
regression performs best amongst our classifiers  just
slightly better than how linear regression performed on
the running averages 

results  that is  the results from early in the season are
as important as the latest results   the training and test
errors for all values of  are still higher than those from
running averages 
      
      

linear  regression  tes ng  
error  

     

linear  regression  training  
error  

      

logis c  regression  
tes ng  error  

      

logis c  regression  
training  error  

      

svm  tes ng  error  

      
svm  training  error  

     
   

     

     

     

     

   

fig     the test training errors as a function of   x axis 

   home and away average  the classification part
is very similar to the two previous sections  the training
and test errors are shown in table    we see that linear
regression performs better in training and is marginally
better in testing  the other two classifiers perform worse 
however  this refutes our hypothesis that teams perform
differently at home and away from home  we see that the
running average  surprisingly  is still our best predictor 
table iii  training and test errors when using running
home vs away averages as predictors

linear regression
logistic regression
svm

training error
     
      
      

test error
      
      
      

   cluster based prediction  the classification part
is similar to the previous parts  we experimented with

fig     training and test error rates for various number
of pca components                from top to bottom 
and number of clusters              x axis  

fiv 

c onclusion

we used a variety of predictors to predict features
of teams in an upcoming game of basketball  we then
used those predictions to form a single feature set corresponding to a single match  we then used that feature
set to predict the outcome of the corresponding match 
we found that running averages of the feature set was
consistently the best predictor  we also found that linear
regression and logistic regression performed the best
when it came to classification  with svm at a distant
third  the reason for the poor performance of svm is
that our data was not nicely separable  our training and
test errors are in line with the literature referenced in the
bibliography 
r eferences
   

beckler  matthew  hongfei wang  and michael papamichael 
nba oracle  zuletzt besucht am                      
    bhandari  inderpal  et al  advanced scout  data mining and
knowledge discovery in nba data  data mining and knowledge discovery                     
    cao  chenjie  sports data mining technology used in basketball
outcome prediction         
    miljkovic  dejan  et al  the use of data mining for basketball
matches outcomes prediction  intelligent systems and informatics  sisy         th international symposium on  ieee       

fi