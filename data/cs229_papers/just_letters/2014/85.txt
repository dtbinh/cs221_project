twitter classification into the amazon browse node hierarchy
matthew long  jiao yu  anshul kundani
stanford university
december         
rected graph in that it children categories can have multiple parents  in these cases  the parent is chosen randomly 
   root categories were identified from the browse nodes
within the labeled dataset  but the distribution was heavily skewed  with        tweets in the books root category 
and    or fewer in   categories  furthermore  over half
of the tweets were re tweets  which have the same text
content as the original tweet  providing no additional information to a classifier while inflating accuracy misleadingly  once re tweets and tweets from categories with
fewer than   tweets were removed  the labeled corpus contained        tweets from    root categories 

abstract
in this project  we attempt to classify tweets
into root categories of the amazon browse node
hierarchy using a set of tweets with browse node
id labels  a much larger set of tweets without labels  and a set of amazon reviews  examining
twitter data presents unique challenges in that the
samples are short  under     characters  and often contain misspellings or abbreviations that are
trivial for a human to decipher but difficult for a
computer to parse  a variety of query and document expansion techniques are implemented in an
effort to improve information retrieval to modest
success 

 

amazon category
books
home   kitchen
clothing  shoes   jewelry
movies   tv
electronics

introduction

internet users post information regarding a topic on a
number of different websites  but companies and organizations typically only train their classification algorithms
using only the information posted on their own platform 
obviously  data from competitors is often difficult to acquire  but in cases where it is freely available  crossplatform analysis can only benefit a model as data from
other sources can be used only if it improves performance 
in order for this data to be valuable  it has to be correctly
classified by what it refers to 
the goal of this project is to to find a likely product
category within the root categories of the amazon browse
node hierarchy for a given tweet  twitter data consisted
of a training dataset with        tweets labeled with amazon browse node ids  and a much larger set of           
unlabeled tweets that can be used for augmentation  the
amazon data consisted of           reviews for products
labeled by their browse node id  all of the datasets originally were in json format and contained metadata as
well as text content for each review or tweet  to obtain
root nodes for tweets  a browse node id tree was created
so that a simple parent traversal could identify a root category  the amazon product hierarchy is more of a di 

tweets
     
    
   
   
   

common keywords
free  ebook  kindle
clock  lp  wall
woman  dress  skirt
dvd  video  instant
apple  hd  sony

table    top   categories by number of tweets

 
   

method
preprocessing

as the data consists of text strings  a bag of words model
was used to represent the tweets  to reduce feature
size and trim unhelpful data  all the tweets were converted to lower case and stripped of all punctuation except hashtags  additionally  urls and stop words from
both a list within the natural language toolkit and a
list we developed specifically for twitter were removed
and words were stemmed with the wordnet lemmatizer         with   fold cross validation  corresponding
to an       training testing split  the unprocessed tweets
had        unique words  which got truncated to       
words after pre processing  text was then transformed
to a sparse matrix representation of tf idf features in
order to be acceptable for downstream estimators  this
 

fiweighting scheme was chosen because it weights against
words that show up frequently across all documents and
thus implicitly reflects the importance of a word in a document          tf idf refers to the term frequency multiplied by the inverse document frequency and is calculated
as 
f
tfij  
 fi j
i

idfi   log

   

n
dfi

baseline models

to evaluate the impact of our tests  we compared different
learning algorithms performance when trained on the prefigure    anova f values for unigram features and uniprocessed dataset with all features  to ensure that there
gram bigram features
were both training and testing examples for each category
a stratified   fold cross validation was used to split up the
dataset into training and testing sets  the metrics associated with each classifier indicate the unweighted mean
of the metrics for each category  we choose to evaluate
model quality in this fashion because of the imbalanced
nature of the labeled dataset  the vectorization of the corpus and the training of the models were done using the
scikit learn package     
classifier
multinomial nb
logistic regression
linear svm
linear svm  w  class weights 

precision
    
     
     
     

recall
     
     
     
     

f  score
    
    
    
    

table    baseline classifier average test scores
class weights provide a way of correcting for imbalance by weighting for or against certain classes but would
be difficult to tune for each technique we will explore     
for this reason  an unweighted linear svm will be used
as the baseline against which to measure the effectiveness
of our approach  although class weights will be used for
final model  the evaluation metric for these comparisons
will be the f  score  as it combines precision and recall
into a single number 
f      

   

figure    f  scores for unigram features and unigram bigram features
it is clear from figure    that precision and recall in
the test set stabilize after using around     of the features in both the unigram and unigram bigram cases  as
the f  score for both of these cases were roughly similar 
and the absolute number of features for a given percentage is much lower for only unigram features  we decided
to use     of the unigram features for our models 

precision  recall
precision   recall

feature selection

   

features were ranked according to their anova f values
and models were evaluated when trained on the top n percent of features      we trained models for unigram features and unigram and bigram features 

expansion

as tweets are shorter than typical documents  expanding
them seems reasonable as it improves the vocabulary of
the model      in order to improve classification accuracy 
we considered query expansion  in which terms are added
 

fiamazon node expansion also slightly worsened performance  but not as drastically as training set twitter node
expansion  figure   details the results expansion for various expansion lengths 

to testing tweets  and document expansion  in which terms
are added to training tweets  both topics are areas of research in information retrieval  ir   although query expansion is the more promising  and thus more studied
field     
     

document

tweets from the training set were expanded based upon
hashtags contained within them and the root category they
belonged to  to perform hashtag expansion a thesaurus
was built up of the most frequent words in tweets containing a given hashtag using the large unlabeled twitter
dataset  n randomly selected words from the top  n words
from each hashtag were then added to each tweet containing that hashtag  no words from the stop lists would be
added  nor would the hashtag word  for root category expansion  one thesaurus was built using for each category
using the words in the training set portion of the labeled
tweets and another was built for the reviews in the amazon set  when building the thesaurus for root category
figure    f  scores for various expansion techniques
expansion using twitter  the top words for each category
were chosen with a tf idf weighting scheme  however 
because both the corpus the thesaurus was built upon was     overall
much smaller allowing the process to be computationally
in the final model  we used both hashtag document and
feasible 
query expansion and also added class weights to the linear svm classifier  the class weighting scheme that was
      query
added was primarily directed at reducing the effects of
the imbalance toward the books category so a weight of
as the hashtag thesaurus was built from an external
    was applied to that category  while other categories
dataset  hashtag expansion could be used on tweets from
weighted by        additionally  the c parameter of the
the testing set portion of the labeled tweets as well  an
svm estimator was tuned using the gridsearch function
identical process to document hashtag expansion was
of scikit learn and a value of   was selected  table  
used 
shows the results of our final model 
tweet
wepnewlyrelease
new
read bulletin board  fiction
 thriller
aburke   dead sister jessica
huntington deser free sample
 mystery

suggested expansion words
review  book  fiction  literature  child
get  read  star  murder

table    hashtag expansion examples

 
   

results
expansion

tweet expansion saw mixed results in category classification  hashtag expansion on both the training and testing
set marginally improved performance  while hashtag expansion on each set exclusively worsened performance 

figure    scores for various class weights against books
 

fiamazon category
baby products
health   personal
care
digital music
beauty
sports   outdoors
arts 
crafts  
sewing
video games
home   kitchen
kindle store
tools   home improvement
collectibles   fine
art
cds   vinyl
patio  lawn   garden
clothing  shoes  
jewelry
cell phones   accessories
books
pet supplies
automotive
musical
instruments
movies   tv
office products
toys   games
electronics
grocery   gourmet
food
category average
absolute average

precision
    
    

recall
    
    

f  score
    
    

support
 
  

    
    
    
    

    
    
    
    

    
    
    
    

  
  
  
 

    
    
    
    

    
    
    
    

    
    
    
    

  
   
 
  

    

    

    

  

    
    

    
    

    
    

  
 

    

    

    

   

    

    

    

 

    
    
    
    

    
    
    
    

    
    
    
    

    
 
 
  

    
    
    
    
    

    
    
    
    
    

    
    
    
    
    

   
 
  
   
 

    
    

    
    

    
    

    
    

so the effects of query expansion was only received by a
fraction of the test set 

figure    category size compared with f  scores

 

the next step to take would be to build up a thesaurus on
individual words from both amazon and unlabeled twitter data in order to expand testing and training tweets on a
per word basis  building these thesauruses will be space
intensive because for each word the frequency of all the
other words it has appeared with in a tweet or review has
to be stored  this step holds promise as it could be used
for both query and document expansion and could be used
upon all tweets  with a full word thesaurus  selective expansion could also be explored  where only certain categories are expanded  there are existing thesauruses that
can be downloaded such as wordnet  but the frequent use
of abbreviations and slang on twitter makes building a
thesaurus from a corpus of tweets potentially more beneficial citewn  another step that would provide immediate
benefits is building a larger corpus for under represented
categories  manually labeling a few dozen tweets for each
category could quickly improve categories with under   
tweets in them 

table    model results for       training testing split

 

future work

discussion

the model achieved an average f  score across all categories of      with average precision of     and average
recall of      categories with more tweets tended to be
classified more accurately than tweets with few samples
to draw upon  this makes intuitive sense as the vocabulary of the samples in the small categories is limited so
there are high odds that the testing samples do not contain
the same words as in the training samples  this is representative of the fact that the bound on generalization error
decreases as the sample size increases  so naturally larger
categories are capable of better testing accuracy  figure  
demonstrates this rough trend  query expansion is typically regarded to be more effective than document expansion and the only thing we expanded in the test set were
hashtags      many tweets do not contain any hashtags 

 

acknowledgements

we would like to thank aditya jami and professor
ashutosh saxena for providing us with the datasets and
for guiding us throughout the project  we would also like
to thank professor ng and the teaching assistant staff for
giving us the skills necessary to work on this project 

 

fireferences
    s  bird  e  loper  and e klein  natural language processing with python  oreilly media inc        
    princeton university  about wordnet  http   wordnet princeton edu       
    c d  manning  p  raghavan  and h  schtze  introduction to information retrieval  cambridge university press  
     
    g  salton and c  buckley  term weighting approaches in automatic text retrieval  information processing and
management                  
    f  pedregosa  g  varoquaux  a  gramfort  v  michel  b  thirion  o  grisel  m  blondel  p  prettenhofer  r  weiss 
v  dubourg  j  vanderplas  a  passos  d  cournapeau  m  brucher  m  perrot  and e  duchesnay  scikit learn 
machine learning in python  journal of machine learning research                    
    v  ganganwar  an overview of classification algorithms for imbalanced datasets  international journal of emerging technology and advanced engineering          
    y w  chen and c j  lin  feature extraction  foundations and applications  springer       
    e  agirre  x  arregi  and a  otegi  document expansion based on wordnet for robust ir  association for computational linguistics       
    b  billerbeck and j  zobel  document expansion versus query expansion for ad hoc retrieval  proceedings of the
tenth australasian document computing symposium       

 

fi