exposing commercial value in social networks 
matching online communities and businesses
murali narasimhan
muralina

camelia simoiu
csimoiu

anthony ward
tonyward

december         

abstract

many businesses in providing users with personalized
recommendations on products such as music  movies
and books  most user recommendation systems to
date  however  have been typically ego centric  focusing on recommendations for individuals based on
preferences of similar users in the system  we propose to add a socialized dimension to recommendation systems that leverages the structure of a users
social network and the preferences of their connections  this is based on two insights  firstly  consumption is often social  restaurant going  fitness activities  sports  etc    secondly  a users connections
often provides valuable information about their preferences  in such cases  marketing efforts may benefit
from targeting particular groups of users with similar
interests to increase the likelihood of purchase  for
instance  a business may offer groupon type deals or
discounts to such groups for collective purchase 
we incorporate these insights into analyzing the social network and business dataset provided through
the yelp  data challenge  our goal is to detect communities of users with similar preferences and predict
which businesses  restaurants  the group as a whole is
likely to prefer  and determine whether incorporating
user network information improves accuracy  in the
context of yelp   two users are thought to have similar preferences if they have both reviewed the same
or similar restaurants and have submitted a similar
star rating 
we first test the ability of various clustering algorithms to detect communities of users with similar restaurant preferences  secondly  we establish a
baseline cf model that predicts star rating for a userbusiness pair  and measure the change in prediction
performance after incorporating social network information  section   includes background information
and previous work  section   provides an overview of
the exploratory data analysis  section   outlines the
models and methodology used  section   presents results  section   outlines the conclusion and future
work 

this paper explores the problem of user recommendations in group settings  research in networked
social behavior has found evidence that individuals
tend to form connections to those having similar
interests to their own  known as homophily  this
tendency has been shown to significantly inform the
structure of social networks  collaborative filtering
 cf  techniques  however  typically do not take into
account explicit social relationships among users in
predicting user preferences  although the importance
of peer influence in user consumption and marketing
has long been recognized  we test for the existence
of homophily on the yelp  dataset and find ample
evidence that social ties are indicative of similar
preferences  based on this insight  experimental
results show we are able to improve on traditional
cf methods by    using clustering algorithms to
detect communities of users with similar tastes  and
   incorporating information about social structure
in cf techniques  we find that leveraging social
structure information improves the performance
of cf and reveals relevant and valuable matches
between businesses and the members of the group 
these results have important implications for targeted marketing 
keywords  collaborative filtering  homophily 
social network  community structure  clustering 
recommendation system  gaussian mixture model 
k means

 

introduction

a growing trend in the movement of e commerce is
the integration of online social network information
in websites with user generated content  ugc   with
rich data on user purchase history and preferences 
recommender systems have become a key tool for
 

fi 

previous work

 

a growing body of research gives evidence for the
principle that similarity breeds connection  known
as homophily  this principle is hypothesized to structure network ties of every type  marriage  friendship 
work   so that individuals personal networks are often homogeneous with regard to many behavioral and
sociodemographic characteristics  mcpherson et al 
         more intuitively  we often turn to friends for
recommendations on products unknown to us  or new
restaurants 

data and exploratory analysis

we use data from the yelp  dataset challenge  which
contains the      crowd sourced reviews for businesses in four cities  businesses and their attributes 
and social network of users  friend lists of users   we
limit our analysis to madison  as this city had a good
balance of a sufficiently large number of users business pairs and one of the least sparse graphs  we
further limit our analysis to the restaurant category  as this contains the largest set of reviews  based
on the intuition that someones preferences in other
categories  clinics  sports clubs  etc   will not be a
good indicator of their restaurant tastes 
we define the social network for a given city as
a graph g    u  e  where u is the set of users
and e is the set of edges representing an explicit
friendship between two users displayed publicly on
yelp   much like the connections existent other social
networks such as facebook  let b    b    b       bn  
be the set of businesses in the given city  and abi
be the set of attributes for the business i  these
include features like noise level  alcohol  patio 
good for families  divy ambiance etc 

we apply this insight to adapt traditional collaborative filtering  cf  algorithms by leveraging information about a users social structure  cf is a technique that makes automatic predictions about the interests of a user based by finding other users with
tastes that are similar to the target users  based on
their preference history  more specifically  classical
cf methods incorporate a version of the k nearest
neighbors  knn  song et al         in order to find
the k most similar users according to a particular
measure of similarity  inverse euclidean  cosine similarity  etc    a key assumption of cf is that individuals who agree in the past tend to agree again in the
future  as a result  cf first finds users with similar
preference to the target users and makes recommendations to the target user aggregating the ratings of
their top k similar userskoren         gross et al 
 n d   

basic statistics of the data set is presented in
table    we observe that the social graph is sparse 
with over     of users having zero degree  no
friends within the network  and low clustering 
the degree distribution of users approximates a
power law distribution  we observe a heavy tail for
high degree nodes meaning that most users have
very few connections  while a few users dominate the
connectivity and have a large number of connections 
 figure     this graph is dominated by a single large
component comprising of approximately of     of
users for madison  in order to appropriately test
the effect of network structure  we further limit our
analysis to the users in this connected component 
ie  those users who have at least one connection
within the component 

there are a number of challenges in traditional cf
systems  sparsity is an important issue  as even if
a user is very active  the number of items largely
exceeds the number of products a user purchases or
reviews  leading to a very sparse user business matrix  since predictions are based on similarity measures computed over the co rated set of items  large
levels of sparsity can lead to poor accuracy jameson
        other challenges that arise in designing recommendations for groups are  defining a similarity
metric to identify and aggregate groups of users with
similar preferences  and designing an algorithm to
generate recommendations based on the aggregated
preference profile of the group  gong         jameson         terveen   mcdonald          moreover 
we construct a feature matrix of business attributes
and use this to define a similarity score that captures
the affinity between users tastes and opinions  in order to overcome the data sparsity problem  we use
pca to reduce dimensionality  pca also makes our
feature space smaller and computationally allows us
to explore a number of clustering algorithms in order
to detect groups of users with similar preferences 

to test our hypothesis that explicit user connectivity is better indicator of restaurant preference  we
compute the percentage of categories for which users
have submitted reviews in common  the baseline
randomly sampled     nodes from the graph and calculated the percentage of pairs that had reviewed at
least one common category  the dyad set is defined
as the set of pairs of users that are connected by an
edge  a triad is a set of three nodes such that there
exists a tie between every pair of nodes  for all sets 
we only consider users that have degree greater than
 

fimetric
number of users
undirected edges
zero deg nodes
nonzero in out deg nodes
connected component size
closed triangles
frac  of closed triads
    effective diameter
clustering coefficient

madison
      
      
      
      
        
      
        
        
        

businesses reviewed by ui   in the case of categorical variables with more than two levels such as
price range  we define a binary variable for each
level  the vector is constructed by computing the
weighted mean of business attributes from all the
users reviews 
r

score ui    

  x
sri  br
 r r  

   

where r is the number of reviews user ui has
submitted for the given city  sr is the star rating
gave to the business in review r  and br is the
 x    binary attribute vector for the business being
reviewed  this quantity is normalized by  r  as  
is the maximum star rating possible  the intuition
is that a users preferences as captured through
their aggregate reviews will provide a strong signal
for the archetypal restaurant the user prefers  for
example  if a user consistently gives high ratings to
restaurants with live music  smoking and outdoor
patio  and a low rating to restaurant with attributes 
smoking  high noise level  formal  high price range 
the aggregated feature vector will capture this ranking of preferences  higher importance will be placed
on the features that were present for highly scored
businesses  and lower importance for features that
were present for poorly scored businesses  we can
then begin to ask which businesses are most alike
those preferred by the user  ie  which have the
attributes most highly ranked  

table    network statistics

figure    degree distribution of yelp users for users
in madison 

zero  ie  those in the weakly connected component  
despite the sparsity of the graphs  we observe almost
a      increase in the percentage of users having refor every existing connection in the network beviewed a common category from the baseline to the tween two users ui and uj   we also construct   differdyads  and a      increase from baseline to triads  ent social features 
confirming our hypothesis    
 percentage of friends in common
 average degree of ui and uj
 maximum degree of ui and uj
 average degree centrality of ui and uj
figure    percentage of users reviewing at least one
restaurant category in common 

 maximum degree centrality of ui and uj

a high percentage of friends in common is likely to
indicate the existence of a strong tie between users
ui and uj   an increased likelihood of having simi  methodology
lar tastes and being friends in reality  degree and
centrality are both measures of the popularity of the
    feature extraction
users  if a pair of users is connected to a large number
for each user ui   we construct a     dimensional of people or is very central to the network  it may be
binary feature vector from the attributes of the an indication that they are influences  trend setters
  this test was also used as part of camelia simoius cs   
and likely to be a source of influence to their friends
project 
opinions and tastes 
 

fi   

community detection

datasets  the objective function is as follows 

subsequent to normalizing the feature matrix  we apply pca dimensionality reduction in order to speed
up computation and correct for possible correlation
among the features  in order to discover communities of users with similar preferences  we implement
the k means algorithm as a baseline  we determine
the optimal k to be equal to the number of principal
components that account for      of the variance    
we represent each of the k communities identified by
its centroid  and use the inverse euclidean distance
to capture the similarity  or affinity of the groups
preference for each business and between users for
community detection  specifically  if u and v are
two vectors in this feature space  then the similarity sim u  v  between them is computed as

j 

v
k x x
x

p
wkv
 yiv  ckv  

p

   

j   isk v  

where wkv is the weight of feature v in cluster k  and
p is a user defined parameter tuned to achieve better
results 
we contrast this to the model based approach
of the gmm model  which uses the iterative
expectation maximization algorithm to fit a probabilistic model to the data  we expect the gmm to
improve on k means if the data in the k component distributions is densely distributed around its
centroid  and the mixture model covers the data well
 ie  the component  normal  distributions are able
to capture the dominant patterns in the data well  
gmm have the added advantage in that they offer
 
flexibility in choosing the component distribution and
sim u  v   
    norm u  v 
we are able to obtain a density estimation for each
cluster  our other motivation in trying a gaussian
where norm u  v  represents the euclidean distance mixture model is that it can be thought of as a soft
between u and v 
clustering method  since the posterior probabilities
for each point indicate that each data point has some
we have split the dataset into train and test sets probability of belonging to each cluster  all models
so that approximately     of reviews are in the used user and business data projected onto the hytrain set and     in the test set  the cutoff point perspace defined by the principal components 
was temporal  so that reviews before october     
were in the train set  and reviews after october     
were in the test set  this allowed the same users     collaborative filtering  predicting user ratings
to be in the train and test sets in order to test the
accuracy of the clustering algorithms 
we contrast the classical collaborative filtering technique as the baseline  as well as modified cf algoto evaluate how well the clustering methods rithm that focuses on the structure of a users soperform  we use the traditional evaluation metric cial network  our goal is to predict the star rating
of pairwise accuracy for ranked results in informa  given by a user ui to a particular business bi   we
tion retrieval  we compare how well each cluster implement the n nearest neighbors algorithm  knn 
predicts relative preferences of the users within the in song et al         for the cf baseline in order
cluster  and by assessing pairwise preferences  we to find the top k similar users having also reviewed
are comparing the global ranking of preferences for bi   similarity is defined as the inverse euclidean diseach user with those predicted by the cluster that tance between the ui s business attribute vector  and
the user is assigned to  more specifically  we define those of the other reviewers for bi   the predicted
the accuracy to be the fraction of business pair star rating is then the average rating of the k nearest
preferences correctly predicted for all users 
neighbors  we contrast the performance of this algorithm to a modified version where we use average of
we further try to improve on this baseline ui s connections to predict the star rating  weighted
with various other clustering techniques including  by the social features as described in section    and
minkowski weighted k means clustering  amorim use linear regression to learn the optimal weights of
  mirkin         and a gaussian mixture model each of the features  for example  if a uj is a less pop gmm   the minkowski weighted k means  mwk  ular connection  ie  lower degree or less central user 
has the advantage that it incorporates feature weight  their star rating will factor less than another user
ing in k means and has been shown to achieve bet  with higher degree or centrality  similarely  the opinter accuracy  particularly when dealing with noisy ion of a connection having more friends in common
 

fiwith ui will weigh more than one with less friends in
common 

 
   

results
community detection

after running pca on the feature matrix  we find
that    principal components explain almost     of
the data  we construct a histogram of the percentage
variance explained versus principal components  also
known as a pareto plot  and visually inspected the
incremental variance explained by each additional
component  not included as this is one of the
standard approaches to determining k  ding   he
        we then project the train  test and business
data onto this reduced feature space 

figure    clustering results for madison 
as a check  figure   show plots of k versus accuracy scores  we find that all three clustering algorithms achieve the highest accuracy for k     increasing k does not lead to further improvements 
we suspect that there is a lot of noise in the data 
especially due to low activity users  those with few
reviews submitted   businesses with few reviewers or
rarely seen attributes  which are lowering the accuracy values  time permitting  a possible solution to
this would be to restrict the set of businesses to the
top        or set a lower bound on the number of
reviews  another possible explanation is that there
may not be as much heterogeneity in the data as we
expected  while pca has the advantage of speeding
up computation  we may be loosing a lot of the heterogeneity encoded in the original business attributes 

results for the three clustering algorithms can be
found in figure    we observe that k means with
pca dimensionality reduction achieves the highest
accuracy with a score of         that is  we are able
to correctly predict with        the rankings of businesses preferences for each user from the businesses
rankings predicted by the cluster centroids  mwkmeans and gmm achieve similar and slightly lower
accuracy scores          with the chosen parameters  we explored sensitivity to parameters for all
three algorithms  however it was computationally expensive to do an exhaustive grid search of the parameter space to find the best parameters within the
timeline of the project  this may explain why we
see lower accuracy scores for the mwk means and
gmm models 
all three algorithms are sensitive to centroid
parameter initialization  k must be known in advance  in addition  k means is known to perform
non optimally for sparse  high dimensional data 
this is because k means tends to be sensitive to
outliers  which is especially the case in high dimensional data sets  since it uses squared deviations 
any extreme value will have a large effect on the
least squares metric  in addition  mwk means has
additional parameters that must be tuned  which
becomes increasingly difficult to do with noisy  high
dimensional data  this may be because there are
insufficient data points per mixture  resulting in
a poor estimator of the covariance matrices  we
suspect that outlier ratings may be preventing us
from achieving higher accuracy scores  for example 
businesses with low popularity  or those with features
that are rarely seen in the rest of the data may be
influencing the centroid 

   

adding social features

using the optimal number of clusters  we find that
including social affinities between users into the clusterin algorithm improves the pairwise accuracy score
by approximately     which is a much smaller increase than expected  we suspect that the improvement was not even higher because of data sparsity 
as we find there are many busineses with few reviewers  as we increase the number of k  even users that
have given dissimilar scores will be included in the
nearest neighbors set  resulting in a possible bias to
the prediction  the same holds for cf augmented
with social features  the limit of common reviewers
for a business is small  and we find that there are
few edges in the network reviewing the same businesses  however  the small number of such reviewers
that are found seem to be contributing to increasing
the accuracy score 
 

fifigure    mse as a function of train and test size 

 

figure    sensitivity analysis of feature weights 

conclusions
work

and

future

we update our similarity scores between user vec  despite the various challenges presented in the data
tors u and v by adding a value corresponding to the set  sparse review data and social network graph   we
find evidence that prediction accuracy of community
social affinity between u and v as given below
detection and star ratings are improved by exploiting
information about a users localized social network
 
sim u  v     sim u  v    w  social u  v 
structure  we are able to slightly improve mse of
the cf algorithm by exploting social features  as well
where w is the weight vector corresponding to the as the pairwise accuracy of the k means clustering
social features and social u  v  is the social feature algorithm  as a proof of concept  this results implies
vector representing the connection between u and v  that similar improvements to cf recommendation
to find appropriate values for the weights  we ana  systems may be a promising area of future research 
lyzed how sensitive the accuracy was to each social
feature with various values for the weights  the rethere is room for improvement to our methodolsults of our sensitivity analysis is presented in   
ogy and data processing  incorporating the content

   

collaborative
rithms

filtering

of reviews will definitely add an additional dimension of information that could be used to determine
the similarity of the users  for instance  negative
versus positive comments as related to topic models
might be one way to gain more insight into user preferences relating to service  ambiance  food quality 
etc  experimenting with different distance and similarity functions  eg  cosine similarity  might lead
to small improvements in results  however we feel
that it would not drastically improve our methodology  secondly  since our objective is to predict the
most well liked business for a community of users  our
test function could be modified to exclude businesses
that are  not in the top x  most rated businesses 
we are currently learning the weights using linear regression  however softmax regression might be better
suited  as the star rating can only take on integer values between      in terms of clustering algorithms  it
may be worth exploring soft k means and hierarchical models  hierarchical models would have the advantage of outputting a dendrogram  which is more
informative than the flat  unstructured set of clusters

algo 

for our analysis of the collaborative filtering algorithm  we compare how well knn performs with and
without social features for various training set sizes
varying from     to       we fix k    and we keep
the test size set constant at     for all our runs 
the results of our analysis using mean squared error
 mse  is shown in    we find that for all training
set sizes  the training error and test error are both
lower with social features than without  this clearly
indicates the value of adding appropriately weighted
social features to a traditional collaborative filtering
algorithm like knn  more specifically  we find that
incorporating social features into the cf algorithm
reduces the mse by approximately    from       
to         further  as we add more training data  the
training error and test error decrease for knn with
social features 
 

fireturned by k means and does not require the prespecification of the number of clusters as k means
does  these methods may also be an effective means
of removing outlier reviews and obtaining more cohesive clusters 

references
amorim  r c     mirkin  b        minkowski metric 
feature weighting and anomalous cluster initialisation in k means clustering  pattern recognition 
ding  chris    he  xiaofeng        k means clustering via principal component analysis  page    of 
proceedings of the twenty first international conference on machine learning  acm 
gong  songjie        a collaborative filtering recommendation algorithm based on user clustering and
item clustering  journal of software           
    
gross  tom  masthoff  judith    beckmann 
christoph  workshop on group recommender
systems 
concepts  technology  evaluation
 grouprs  
jameson  anthony        more than the sum of its
members  challenges for group recommender systems  pages      of  proceedings of the working
conference on advanced visual interfaces  acm 
koren  yehuda        the bellkor solution to the
netflix grand prize  netflix prize documentation 
   
mcpherson  miller  smith lovin  lynn    cook 
james m        birds of a feather  homophily
in social networks  annual review of sociology 
              
song  yang  huang  jian  zhou  ding  zha 
hongyuan    giles  c lee        iknn  informative
k nearest neighbor pattern classification  pages
       of  knowledge discovery in databases 
pkdd       springer 
terveen  loren    mcdonald  david w        social matching  a framework and research agenda 
acm transactions on computer human interaction
 tochi                 

 

fi