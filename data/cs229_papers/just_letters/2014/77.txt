accelerometer gesture recognition
michael xie
xie cs stanford edu

david pan
napdivad stanford edu

december         
abstract
our goal is to make gesture based input for smartphones and smartwatches accurate and feasible to use 
with a custom android application to record accelerometer data for   gestures  we developed a highly accurate svm classifier using only   training example per class  our novel dynamic threshold truncation
algorithm during preprocessing improved accuracy on   training example per class by     and the addition
of axis wise discrete fourier transform coefficient features improved accuracy on   training example per
class by     with   gesture classes    training example for each class  and    test examples for each class 
our classifier achieves     accuracy  with   training examples per class  the classifier achieves
    accuracy  which is greater than the    example accuracy of other efforts using hmms       
this makes it feasible for a real time implementation of accelerometer based gesture recognition to identify
user defined gestures with high accuracy while requiring little training effort from the user 

 

introduction

the touchscreen interface of smartphones and smartwatches limits the interaction with the phone or watch to the
gui based point and click interactions  similarly  current life tracking software largely relies upon user input to
collect data  which is often not effective  software that collects and interprets data should not have the deficiency of
needing manual input of data  by capturing acceleration data  it is possible to respond to gesture based commands
and to interpret daily activities as an automated data tracker  the objective of this project is to interpret and
respond to gestures using accelerometer data  the real life implementation of this project would be to automatically
detect gestures in a stream of accelerometer data and respond to user defined gestures  one major challenge for
this implementation is processing the data so that the classifier only takes into account the segment of data that
corresponds to the gesture and is invariant to gestures starting and ending at different times  the second major
challenge is to achieve high accuracy on   to   training examples per class  the user would then only be required to
define their gesture a few times before being able to use the gesture  we assume that in the real life implementation 
the training set would grow with time with correct classification of new instances of the gesture  improving the
performance over time 
in this project  we define a basic gesture to be a continuous sequence of movements  compound gestures
can be made of several basic gestures in sequence  which would be a layer of classification above the classification
of basic gestures  in this project  we focus on the classification of basic gestures 

 

data and preprocessing

to collect data  we constructed an android application that records accelerometer data upon the click of an onscreen
button and stores the data in a file with the gesture label provided by the user  the application collects a fixedlength matrix of     points of acceleration data from the x  y  and z axes sampled at   hz over a   second window 
let x t   y t   z t  be discrete time functions that return the acceleration in each axis at time t  we reshape this
  by     matrix such that each raw training example e i  is as follows 
e i     x          x       y          y       z          z      
each raw example and label is a pair  e i    l i    where l           n     for n different gestures in the training
set  the gestures that the training examples represent are labeled by the user and represents the ground truth
data from which we build our model  for the current purposes of this project  we assume that when acceleration
data is being recorded  the phone is in the right hand  upright  and screen facing away from the palm  our model
 

fi a  aggregate raw data for class o

 b  a single o example

figure    accelerometer data for the o gesture
further assumes that a gesture starts from rest and that the starting position of a gesture is irrelevant  which are
reasonable assumptions for gestures based on our definition in the previous section  our dataset consists of   
examples each of   different classes of gestures  o  x  z  w  and v  the names of the gestures correspond
to the movement the gesture encodes in the air  i e  gesture o is a counter clockwise circle drawn in the air using
the device 

   

filtering

to decrease noise from natural shaking of the hands and from idle moments in the beginning and end of the gesture 
we employ a low pass filter to smooth the data by axis  initially  we experimented with a box filter of window
size                 and     the average error after cross validation decreased with increasing window size until
converging at around        a gaussian filter was also tested  and while it represented an increase in accuracy of
the classifier  it yielded poorer results  for our final results  an exponentially weighted moving average filter with
       outperformed the rest  an exponentially weighted moving average filter is defined recursively as
st     xt           st 
where st is the smoothed point at time t and xt is the actual data at time t  the exponentially weighted moving
average filter weights the time step before the highest  with exponential decay in weight for further time steps in
the past  this is intuitive  as the position of the gesture can be modeled as obeying the markov property  where
the position of the next time step is dependent only upon the state in the previous time step  for this reason  there
are many approaches to this problem that use hidden markov models      we have found that the svm approach
we propose here gives better performance on a small number of training examples and has faster runtime     

   

dynamic threshold truncation

we want to remove data recorded before the gesture actually starts and after the gesture actually ends in order
to capture the essence of the gesture  in typical truncation  the longest continuous data segment starting at the
beginning of the data that is below some fixed threshold is removed  and so is the longest continous data segment
ending at the end of the data that is below the threshold  specifically  a data point  an acceleration vector  is below
the threshold if the norm of the difference between the data point and the intial point  first point or last point of
the data depending on which side the segment is on  is below the threshold  however  fixed threshold truncation
had inconsistent peformance across the number of training examples 
we modified truncation to use a dynamic threshold that depends on the standard deviation of the data to be
truncated 
p
threshold for data    standard deviation of data
where  is a nonnegative constant  the intuition is that a higher standard deviation means that the essence of
the gesture completes in a shorter time interval  so the threshold should be increased to improve the chance that
the data is truncated around that time interval  this helps overcome the problem that noise may stop truncation
prematurely before the essence of the gesture is captured in a tight window  we chose          any  between
     and      increases svm accuracy by at least     with one training example and no additional preprocessing
or feature extraction 

 

fi a  raw x axis data for gesture o

 b  after dynamic truncation

 c  after smoothing

figure    preprocessing visualized for x axis data of    examples of the o gesture

   

interpolation

after truncating the data to capture the essence of the gesture  we linearly interpolate the data back to the    
point length  by doing this  much of the phase differences between gestures are gone 

   

normalization

mean and variance normalization was tested due to the possibility of gestures being completed at different speeds 
and hence resulting in acceleration vectors that represent the same gesture with differing acceleration magnitudes 
however  standard score and feature scaling normalization decreased classifier accuracy 

 

feature selection

we can see after preprocessing the data that each gesture has a characteristic signal for each axis  however  there
may be phase differences due to starting the gesture at slightly different times that would shift the acceleration
values at each time point slightly for each example  we aim to add features that take into account the time series
data as a whole to combat these differences 

   

discrete fourier transform

the main intuition for the fft is that  if a gesture has many movements within the same time period  then the
individual axes will have higher frequency components  we posit that if acceleration data over a   second window
for a given gesture is repeated over consecutive   second windows  then this time series data is periodic over a
period of   seconds  or n       time points  using a    point fast fourier transform  we output n     periodic
complex coefficients
xk that encode the amplitude and phase of sinusoidal components  we take the amplitude

re x     im x   

k
k
ak    xnk    
  which is magnitude of each complex number  as features  thus  we ignore phase
n
differences in each example  we append these ak to each example  resulting in     dimensional example vectors 
where each spatial dimension has          features  we chose a fft with a small number of points to limit
the dimensionality of the data while adding valuable information  we found that a    point fft performed well 
adding n point fft where n     through    does not decrease classifier accuracy 

   

mean and variance

adding the mean and variance of each training example was also tested  but did not have any noticeable effect
on the accuracy  the intuition behind the attempt is that more variance implies more dynamic gestures and
differing mean in each axis implies a gesture that tends to accelerate in a direction over another  the naive bayes
classifier uses these features to classify with reasonable performance  so we believe that while these features encode
information about the gestures  this information is encoded in other features when using the svm 

 

fi 
   

classification techniques
nearest centroid classifier

in the nearest centroid classifier  we create a mean gesture for each class that represents the average of all
examples of the class in the training set  given a test example  we then predict by outputting the class of the
mean gesture with the shortest euclidean distance to the test example  this represents a very simple baseline
performance  this classifier had very good performance for such a simple solution  which suggests that euclidian
distance is a good measure of similarity between gesture time series data 

   

k nearest neighbors

given a test example  the k nearest neighbors algorithm outputs a classification based on which classes the
majority of the closest k neighbor training examples
belong to  this is essentially seeing which known gestures the new example looks like  and outputting that
result  this is sensitive to time shifts and scaling differences  fast or slowly executed gestures   in our testing 
we used k     neighbors and the euclidean distance
function as the measure of distance  this classifier had
reasonable performance on five classes that was comparable to the svm with    training examples per class 
however  this algorithm does not have enough information to classify gestures with only   training example
per class  as the   neighbors were likely all of different
classes 

   

naive bayes

the features used are the mean and standard deviation figure     d low rank projection using svd with feaof the accelerometer data  assuming conditional inde  ture extraction and dynamic truncation  maxmimizing
pendence  we weighted the probability of these features differences between data points  preprocessing feature
against each class  as well as the probability of each ges  extraction separates the data into well defined clusters 
ture class in total  however  if this is used in gesture
detection in a smart device and online learning is used 
input from the user provides more accurate custom
probabilities up to an extent  where a user that heavily prefers one or two gestures may cause the overall probabilities of each gesture to be skewed  interestingly  filters had little effect on the accuracy of the naive bayes classifier 
this may be because the filters have less overall effect on the features that naive bayes uses  such as the mean and
standard deviation 

   

svm

from the perspective of the svm  each example is a     dimensional data point  in this case  we have a large
number of features in comparison to the number of examples  but the large margin properties of the svm allows
it to learn a classifier that does not overfit  we find that a linear or polynomial kernel performs well for the data 
but the gaussian kernel doesnt perform as well 

 

results and ablative analysis

the above techniques were tested using    examples each of   different classes of gestures  o  x  z  w  and v 
with the small size of our dataset     fold cross validation tended to leave out classes in each fold  instead      
iterations of bootstrapping cross validation was used  in which we randomly sampled a given number of examples
from each class and tested on the rest of the data  this simulates the real life application  in which the user would
supply the application   to   examples to define each new gesture  with subsequent correct classifications  the
training data for each gesture class grows  out of the above techniques  the svm classified the gestures the best 

 

fiespecially with a low number of examples  it was able to achieve     accuracy on   training example per class
and     accuracy with    training examples per class  many other implementations use hidden markov models 
which achieve     accuracy on    or more training examples         other implementations  using dynamic time
warping  achieved     on one training example  however  the gestures used are simpler  move left  move right 
and perhaps more distinguishable then the ones we used     
accuracy of classifiers given a uniform  randomly sampled accuracy of classifiers given a uniform number
number of examples per class 
ples per class without features from fft 
classifier
 
 
  
classifier
 
 
svm
                     svm
             
naive bayes
nan
              naive bayes
nan
      
k nearest neighbors
                     k nearest neighbors
             
nearest centroid classifier                      nearest centroid classifier              
accuracy of classifiers given a uniform number
ples per class without dynamic truncation 
classifier
 
 
svm
             
naive bayes
nan
      
k nearest neighbors
             
nearest centroid classifier              

 

of exam  
      
      
      
      

of exam  baseline accuracy of classifiers without preprocessing or
additional feature extraction 
  
classifier
 
 
  
       svm
                    
       naive bayes
nan
             
       k nearest neighbors
                    
       nearest centroid classifier                     

conclusions and discussion

our results suggest that highly accurate  low training accelerometer based gesture recognition is feasible  importantly  dynamic threshold truncation results in a     increase in accuracy with one training example and increases
performance of every classifier  fft features add another     however  without dynamic threshold truncation 
fft features have no effect  the main topic of discussion is the relationship between standard deviation and
truncation threshold 
for future work  we will explore the nuances of dynamic threshold truncation further  experimenting with
more threshold functions  we will consider using rotational normalization to account for gestures done at different
orientations      we aim to test robustness further by adding more gestures and more training examples  finally 
wed like to test performance on real time data by implementing this in our data collecting android application 

references
    klingmann  marco  accelerometer based gesture recognition with the iphone 
    prekopcsak  zoltan         accelerometer based real time gesture recognition  in proceedings of the   th
international student conference on electrical engineering  prague  czech republic 
    jiayang liu  jehan wickramasuriya  et al         uwave  accelerometer based personalized gesture recognition and its applications  in pervasive computing and communications 
    david mace  wei gao  ayse coskun         accelerometer based hand gesture recognition using feature
weighted nave bayesian classifiers and dynamic time warping  in the proceedings of the      international
conference on intelligent user interfaces 
    chih chung chang and chih jen lin  libsvm   a library for support vector machines  acm transactions on
intelligent systems and technology                    

 

fi