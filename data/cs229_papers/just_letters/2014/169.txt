classification of alzheimers disease based on white matter architecture
tanya glozman  and rosemary kim le 

abstract alzheimers disease is the most common form of
dementia in adults aged    or older  although many studies
have measured the effect of tissue degeneration for subcortical
structures such as the hippocampi  amygdala  and the ventricles  little is known about the changes that occur in the
architecture of the white matter during the course of this
disease  the shape and properties of white matter structures
can be measured using diffusion tensor imaging  dti   a
relatively new neuroimaging technique  differences in these
structures have been shown to be related to behavior  cognition 
and neurological diseases      in this project  we use machine
learning tools to classify alzheimers patients and normal
controls based on the architectural attributes of white matter
tracts  the results are promising and demonstrate that the
shape of white matter structures is useful in the quest to better
understand the biomarkers and neural correlates of this disease 

i  introduction
alzheimers disease  ad  is a progressive  degenerative
brain disorder that leads to nerve cell death and tissue loss
in the brain  it is the most common form of dementia is
adults aged    and older  the worldwide prevalence of ad
was reported      million in      and is expected to rise to
over     million by           many studies provide scientific
evidence suggesting that ad progresses by selective degeneration of neuronal populations in several regions in the brain 
pathological structural changes in the brain occur many years
before the symptoms of the disease are observed  at which
stage significant neurodegeneration has already taken place 
on the molecular scale  neuropathological hallmarks of ad
are intraneuronal accumulation of neurofibrillary tangles 
extracellular deposition of amyloid beta protein as senile
plaques  and massive neuronal death      definitive diagnosis
of ad requires histopathologic confirmation of the presence
of amyloid plaques and neurofibrillary tangles  in practice 
clinical history and neuropsychological tests are used to
confirm the diagnosis  identifying meaningful imaging based
biomarkers for early detection and diagnose of the disease
are limited by lack of quantitative approaches to characterize
how the disease affects the human brain at different stages
during its degenerative advancement 
in the past two decades  diffusion tensor imaging  dti 
has become one of the most important tools for neuroscience
research and clinical practice      for its ability to model the
integrity and structure of the brains white matter architecture
in the living human brain  a white matter fascicle  also
called tract  is a bundle of axon fibers that forms connections
  t  glozman is with faculty of electrical engineering  stanford university  stanford  ca         usa  tanyagl stanford edu
  r  le is with the department of psychology  stanford university 
stanford  ca         usa  rosemary le stanford edu

between different  often remote  areas of the brain  in
general  dti measures the motion of water molecules in
the brain  which is free along the fibers and not across
the fibers  this difference between parallel and perpendicular
motion is called anisotropy  fractional anisotropy is among
the most widely used metrics in brain research      and
is also commonly used in the study of alzheimers patients
     previous work done with alzheimers disease and dti
primarily utilize statistical tests to demonstrate that there
are differences in tissue measurements  such as fractional
anisotropy  between these two populations  in this project 
we explore whether the architectural features of the white
matter may be informative in the classification of alzheimer
patients and normal controls  this paper will progress as
follows  we will describe the data and our pre processing
pipeline  we will describe the features extracted from the
data and the machine learning techniques that were applied
for classification  we will then report the results and evaluate
the performance of our method  we conclude with discusssion of the main insights and implications of this work and
outline the most interesting future directions of this project 
ii  dataset and pre   processing pipeline
the data used in the preparation of this paper were obtained from the alzheimers disease neuroimaging initiative
 adni  database  adni loni usc edu   the adni database
contains both t  weighted mr imaging as well as dti
imaging data  details about the acquisition protocol and the
initial processing steps can be found in      many software
tools for processing of dti data are available through the
vista lab at stanford led by professor brian wandell  figure
  outlines both the pre processing steps and the classification
framework  below is a detailed explanation of the preprocessing steps performed for each subject 






ac pc alignment of t  weighted images 
high quality anatomical images  t  weighted  serve
as a spatial reference for the dti data  this step is
manual and involves defining three landmarks in the
brain  the mid sagittal plane  the anterior commissure 
and the posterior commissure  this step resamples the
data to align all images to the first one 
conversion of the axial dti data from dicom format
to nifti format 
this step creates helper files that contain diffusion
tensor directions and magnitudes 
mrtrix 
mrtrix     is a set of tools that performs diffusionweighted mr white matter tractography in a manner

fif  afq


  e  tractography
b  dti raw data

 
d  dicom
to nifti
 conversion





feature ranking
rank  f eature   

 mean ad mean nc  

 std ad std nc   

   major white matter tracts

c ac pc

a  t  raw data

g  feature extraction
for each tract 
base  top  middle support
 fiber count
average fiber length
std of fiber lengths

classification
svm with linear and rbf kernels

  fold cross validation
logistic regression
    training examples
   testing examples

evaluation and diagnostics
training and testing errors
precision vs  recall
performance change with   features
comparison to other works

fig     overview of the classification framework  the top panel outlines the pre processing steps performed for every
subject as well as the features extracted for the classification   a  t  raw data provides the anatomical reference   b  dti
raw data   c and d  canonical alighment and format conversion were performed on the t  weighted data and the dti data
respectively   e  tractography algorithm estimates the direction and magnitude of water diffision at every voxel   f  afq is
run on the tractography output to find the    major white matter tracts in the human brain   g  feature extraction  for each
of the    tracts we extract the features listed above 
the lower panel outlines the classification procedure  first  we perform feature ranking on the training set based on the
differences in the average population values for each feature  next  classification is performed with approximately    testing
examples and     training examples  several machine learning methods were used  following the classification  we evaluate
our results as outlined above 

fig     the    tracts extracted from afq  the     dimensional
feature vector was constructed from properties of these tracts 
picture courtesy of yeatman            

robust to crossing fibers using constrained spherical
deconvolution and probabilistic streamlines 
 automatic fiber quantification  afq   afq      is
designed to automatically identify    major fiber tracts
and quantify tissue properties along their trajectories 
figure   shows an example of    major white matter
tracts extracted from afq with the t  weighted mr
image in the background for reference 
 fiber filtering and cleanup  this step involves automatic
cleaning and outlier removal of the generated fibers 
using probabilistic and heuristic approaches 
the pre processing time per scan is of the order of  
hours  we pre processed a total of    alzheimers disease
patients  ad  and    normal controls  nc    a total of    

scans       ad scans and     nc scans  many of these
scans were longitudinal scans collected over a period of up
to   years on the same subject  which is why we have more
scans than subjects   in order to keep the training and testing
set independent and uncorrelated  we randomly chose the
subset of subjects to use for the testing set  only one scan
for these subjects was used for the testing set  the other
longitudinal scans of the subject were not included in the
train or test set  for the subjects chosen for the training set
however  all longitudinal scans were used for training  as we
elaborated in the milestone      the probabilistic nature of the
tractography algorithms ensures that there will be a variation
even between the longitudinal scans of the same subject 
using the longitudinal data in the training set allowed us
to gain more training examples without jeopardizing the
independence of the testing set  as a result of this data
partitioning  for each experiment we have about     training
examples and    testing examples  balanced across classes 
iii  f eatures and f eature ranking
for each scan  we constructed a     dimensional feature
vector from the    extracted fibers tracts     measures for
each tract  number of fibers  the mean and standard deviation
of all fiber lengths  and an estimate of support at the
endpoints of each tract  as well as the support of the middle
point of all fibers in a tract  support was calculated as
the volume of the cube that encapsulates the endpoints on
each end and the middle  intuitively  the endpoints support

fifig     subjects data projected onto the first two principal components  separability can be observed between alzheimers patients
 in red  and normal controls  in blue  

values provide us with the measure of the cortical projection
of the fascicle  and these features turned out to be extremely
important for the classification  all features were normalized
to lie in the range        according to the following formula 
f     f  min fi    max f j  min fi  
i

j

fig     the population distribution of features sorted from highest
 at x    to lowest ranked  at x      feature  values for alzheimers
patients are colored red and values for normal controls are colored
blue 

iv  m odels
a  logistic regression
in logistic regression  our hypothesis is of the form

i

where i  j           n   where n is the total number of examples 
we then ranked each feature according to how much its
values differed between the populations  according to the
following equation 
 mean ad   mean nc  
rank  f eature    p
 std ad   std nc  
where ad stands for alzheimers disease patients and nc
stands for normal control subjects  this feature ranking was
performed on the training set  features were then sorted
according to their ranking 
figure   clearly shows that in the highest ranked features
 corresponding to features numbered        a separation is
apparent between alzheimer patients  in red  and normal
controls  in blue   this was encouraging and suggested that
a learning algorithm would be able to dinstinguish these
classes with reasonable performance 
to further assess the separability of the data  we performed
pca  principal components analysis  on the data  figure
  shows the data projected on the first and  nd principal
components  it is clear that the data is separable 
to find the optimal dimension n of the feature vector
for classification  we repeated the classification experiments
using a growing set of features  n was taken to be the number
of features that resulted in the lowest testing error for the
learned hypothesis  in our experiments  n was    for both the
rbf kernel and linear kernel svms and    for the logistic
regression 

h  x   
where

 
h  x     
h  x    

 
    exp   t x 
alzheimer patient
normal control

the learned n dimensional variable  corresponds to the
feature vector x  rn that corresponds to the n strongest
features  the parameter  is found by gradient ascent  where
the update rule is as follows 
 i 

 j     j    y i   h  x i   x j

to find the hypothesis that would result in minimal testing error  we iteratively calculate the hypothesis and the
corresponding testing set error for feature dimensions n  
             
b  svm
the support vector machine algorithm is calculated by
minimizing
m
 
kk   c  i  i
 
i  
subject to
y i    t x i    b      i
i   
for i              m 
we used svm with a linear and an rbf kernel  in the
linear kernel 

k  xi   x j      x x
i j

fiin the rbf kernel 
k xi   x j k   
   
as with logistic regression  we found the testing error for
the classifier learned when using the n strongest features 
we performed   fold cross validation to choose the optimal
parameters for the classifier training  each svm experiment
was repeated    times   the training and testing set were
randomly chosen in each repeat  as explained in section
ii  the reported training and testing errors  precision and
recall values are the average of these experiments  we also
calculated the standard deviation of these experiment to make
sure the results are consistent  standard deviation was on the
order of up to about    
k  xi   x j     exp 

v  r esults and a nalysis
in table i  we display training error  testing error  precision  and recall for the three classifiers  precision p and
recall r are defined as follows 
tn
tp
 r  
p 
tp  f p
tn   f p
where tp   true positive  tn   true negative  fp   false
positive  fn   false negative 
figure   depicts the testing error achieved with an rbf
kernel classifier as a function of number of features used 
we see that the error achieved using just one feature is
about      and the error increases with adding the first
few features  however  following this initial increase  the
error drops to       at    features  its interesting to
note that once the testing error reaches its minimal value 
each additional feature just serves as noise in the data and
confuses the classifier  this is consistent with figure    
where we clearly see that there is no difference between the
two populations for features ranked    and up 
in order to evaluate our results  we show a comparison of the precision vs recall values of our best classifier
 rbf kernel svm  to other works  a comparative study by
cuingnet et al       evaluated the performance of several
approaches using     subjects from the adni database  note
that none of these approaches used dti data  as that data was
not available at the time of the study  the classifiers used in
these works were based on gray matter data features such
as volume of the hippocampi  cortex shrinking measures and
voxel based measurements  additionally  as we are using a
different dataset for our work  this comparison merely serves
as a rough evaluation of the merit of our method 
vi  d iscussion
tractography algorithms are inherently uncertain and sensitive to choice of parameters      furthermore  data acquired
from the adni database were collected from over    institutions with differing scan parameters  it is likely the results
would be improved with standardized data collection  as well
as with additional training data 
in this work we were interested in understanding the
changes in the architecture of the white matter as a result

fig     testing error achieved with an rbf kernel classifier as a
function of number of features used  note the initial increase in the
error  following this initial increase  the error drops to       at   
features  its interesting to note that once the testing error reaches
its minimal value  each additional feature just serves as noise in
the data and confuses the classifier 

fig     comparison to other works  based on      previous studies
 as denoted by the xs  perform classification based on features
calculated on the gray matter and other subcortical structures  note 
however that since we used dti imaging data in this study  this
comparison is not performed on the same dataset  at the date of
the study of     dti data was not yet available  nevertheless  we
believe that this comparison provides an estimate of the merit of
our work and we find that using white matter properties as features
results in a substantial improvement 

fisvm linear
svm rbf kernel
logistic regression

training error    
    
    
 

testing error
    
    
    

precision
 
 
      

recall
      
      
      

table i  classification results for three models  svm with linear kernel  svm with rbf kernel and logistic regression 
about     training examples and    testing examples were used      please note that the reported training error is very low 
we believe the reason for this is that the training set contains correlated examples  since we used longitudinal scans data in
this set to gain more examples  n      for svm and n      for logistic regression 
of alzheimers disease  in addition to achieving good classification performance  we found it interesting that there is
no statistically significant change in the number of fibers 
and their average length following alzheimers disease 
even more so  we found that our top ranked features were
the support values for the major fascicles  as shown in
figure    this feature showed separability between ncs and
ads  with ads having a smaller value of support  as
the support can intuitively be considered to estimate the
volume encapsulating the area of the cortical projection of
a fascicle  we expect that as the cortex shrinks during the
course of ad  this volume will decrease  it has been long
known that tractography algorithms are especially unreliable
near the cortex  thus we believe that our support feature is
coarse enough to overcome this uncertainty  while still being
accurate enough to be able to discriminate between ad and
nc subjects 
in addition to constructing good features  feature normalization and ranking also proved to be extremely benefitial to
the performance of the classifiers 
in the study of alzheimers disease  most machine learning
techniques have been applied to measurements of gray matter
and other subcortical structures  since diffusion tensor imaging is a relatively recent neuroimaging technique  it is not
yet widely used with regards to classification of alzheimers
disease  the few works that do consider the white matter 
focus on tissue properties  such as fractional anisotropy  to
the best of our knowledge  this is the first work on classification of alzheimers disease using architectural attributes of
the white matter  we believe that shape and function in the
human brain are strongly related  and are excited to continue
exploring this direction 
vii  c onclusions
we show that the classification of alzheimers patients
using white properties achieves state of the art results  diffusion tensor imaging  in conjunction with machine learning
algorithms  has the ability to advance our understanding of
alzheimers disease 
viii  f uture d irections
including more complex geometric features that describe
the architecture of the white matter may improve the classification results even further  we are also interested in
understanding whether the features we constructed are useful
as a screening tool for the prodromal stage of ad   the mild
cognitive impairment  mci  disease  the adni dataset

includes dti imaging data for mci patients along with
the information whether or not these patients converted to
alzheimers disease within a course of    months  being able
to identify the mci converters is of utter importance as this
has the potential to aid clinicians in determining the course
of treatment for these patients  our next step will involve
applying the method developed here on this additional data 
acknowledgments
the authors would like to thank the course staff for providing
valuable feedback  prof  franco pestilli and dr  hiromasa takemura
from the vista lab led by prof  brian wandell for their advice and
help with implementation of the image pre processing pipeline 

r eferences
    ron brookmeyer  elizabeth johnson  kathryn ziegler graham  and
h  michael arrighi  forecasting the global burden of alzheimers
disease  alzheimers amd dementia                      
    remi cuingnet  emilie gerardin  jrme tessieras  guillaume auzias 
stphane lehricy  marie odile habert  marie chupin  habib benali  and olivier colliot  automatic classification of patients with
alzheimers disease from structural mri  a comparison of ten methods
using the  adni  database  neuroimage                       
multivariate decoding and brain reading 
    r  douglas fields  white matter in learning  cognition and psychiatric
disorders  trends in neuroscience                     
    tanya glozman and rosemary kim le  classification of alzheimers
disease based on white matter attributes   cs    milestone 
    melbourne australia j d tournier  brain research institute 
http   www brain org au software  
    clifford r  jack  matt a  bernstein  nick c  fox  paul thompson 
gene alexander  danielle harvey  bret borowski  paula j  britson 
jennifer l  whitwell  chadwick ward  anders m  dale  joel p  felmlee  jeffrey l  gunter  derek l g  hill  ron killiany  norbert schuff 
sabrina fox bosetti  chen lin  colin studholme  charles s  decarli 
gunnar krueger  heidi a  ward  gregory j  metzger  katherine t 
scott  richard mallozzi  daniel blezek  joshua levy  josef p  debbins 
adam s  fleisher  marilyn albert  robert green  george bartzokis 
gary glover  john mugler  and michael w  weiner  the alzheimers
disease neuroimaging initiative  adni   mri methods  journal of
magnetic resonance imaging                     
    yangling mu and fred h gage  adult hippocampal neurogenesis and
its role in alzheimers disease  molecular neurodegeneration        
     
    fillard p  descoteaux m  goh a  gouttard s  jeurissen b  malcolm
j  ramirez manzanares a  reisert m  sakaie k  tensaouti f  yo t 
mangin jf  and poupon c  quantitative evaluation of    tractography algorithms on a realistic diffusion mr phantom  neuroimage 
                   
    parente  d  gasparetto  e  l  cruz jr  l  c  h  d  domingues  r  c 
baptista  a  c  carvalho  a  c  p   and domingues r  c  potential
role of diffusion tensor mri in the differential diagnosis of mild
cognitive impairment and alzheimers disease  american journal of
roentgenology                        
     assaf y  and pasternak o  diffusion tensor imaging  dti  based white
matter mapping in brain research  a review  journal of molecular
neuroscience                   
     jason yeatman  https   github com jyeatman afq 

fi