semi supervised learning for sentiment analysis
john miller  aran nayebi  amr mohamed
 millerjp  anayebi  amr    stanford edu

abstract
we leverage vector space embeddings of sentences and
nearest neighbor methods to transform a small amount of
labelled training data into a significantly larger training set
using an unlabelled corpus  the quality of the larger training set is measured by prediction accuracy on a benchmark sentiment analysis task  our results indicate it is
possible to achieve accuracy within      of the baseline
using only      the amount of labelled data 

 

introduction

many statistical learning approaches to sentiment analysis
require large amounts of labelled training data  acquiring
large corpora of labelled data is often a time consuming
and expensive process  additionally  the internet contains
vast stores of data that could be useful for sentiment classification  but there is not an obvious way to use this data
without first hand annotating each sentence 
the goal of this project is to explore how to use a small
set of labelled data and a large set of unlabelled data
to construct models with accuracy comparable to those
trained on large sets of exclusively labelled data 
given a large training set with just a few pieces of labelled data  the naive approach is to simply ignore the unlabelled data and train a classifier only on hand annotated
sentences  intuitively  however  one should be able to
achieve improved accuracy by also considering the unlabelled data  one might hope to find some way to use the
labelled data to find good labels for the unlabelled data 
in general  this problem is as difficult as the original inference task  so we focus on fast  heuristic procedures 
at a high level  our approach will be to find similar sentences in the unlabelled data and assign them a label that
matches a reference sentence in the seed set  to make the
notion of similarity between sentences precise  we represent each sentence as a vector in a high dimensional vector space and use euclidean distance between sentences as
a proxy for similarity 
to construct embeddings that capture the semantics of
a particular sentence  we build embeddings directly from

distributed representation of words  e g      
given some fixed sentence embedding  we use the seed
set to assign labels to the closest neighboring sentences
in this high dimensional space  then  equipped with this
expanded training set  we use the resulting sentence embeddings as features in a standard sentiment analysis task 
the performance of our semi supervised inference procedure is evaluated against the baseline training set  which
uses the entire labelled corpus  despite receiving significantly less training data  our results indicate that it is possible to achieve accuracy within      of the baseline
with a seed set    of the size of the baseline and a small
number of nearest neighbors 

 
   

preliminaries
data

we apply our semi supervised approach to the benchmark
sentiment analysis task introduced in      the data for this
task is the stanford sentiment treebank      the stanford sentiment treebank consists of        single sentences extracted from www rottentomatoes com
movie reviews  and includes a total of         unique
phrases that have been annotated by three human judges 
each sentence is labelled with one of   sentiment
classes    for very negative    for negative    for neutral    for positive  and   for very positive  this
dataset is then decomposed into training  development 
and test sets of             and      sentences  respectively 
as a simplification  we consider only the more coarsegrained   class classification task  where the labels are
 negative  neutral  positive  obtained by bucketing very
negative and negative as well as positive  and very
positive into two classes 
from this larger corpus  we allow our algorithms to
only access the true labels of a small subset of this data 
which we refer to as the seed set  we stress that the text
of the other sentences is known to the algorithms  but their
corresponding labels are not 
to ensure the models we develop are robust to changes
in the seed set  we generate a new seed set on each run of

fifigure    visualization of distributed sentence representations
the algorithms by randomly sampling the set of sentences 

   

projecting the data into two dimensions  the sentences are
roughly ordered along the first principal component with
respect to sentiment  sentences with positive sentiment
are positive along this axis  neutral sentences are near   
and negative sentiment sentences are negative 

features  distributed sentence representation

each sentence s is represented as a vector s   r      to
construct this representation  we use a semantic vector
space model of language  where each word is represented
by a real valued vector  these vector representations are
taken from a database of   billion word vectors trained on
a corpus of     billion tokens using the glove model     
to obtain a sentence representation for sentence s  
s  s            sn   we take the average of the word vectors
s    s            sn where si is the glove vector corresponding to the i th word in the sentence  as demonstrated in
     this naive word vector averaging often outperforms
bag of words and bag of n gram models  equipped with
this representation  the distance between two sentences is
then simply the    distance 
to gain some intuition about the topology of the resulting vector space of sentences  we visualize a random subset of the sentence embeddings using both t sne     and
principal components analysis  the corresponding plots
are given in figure   
one salient observation from figure   is that the vector
space representation appears to encode semantic qualities
of the individual sentences  examining the local geometry in the t sne plot reveals that sentences with similar
sentiment tend to appear together in local clusters  furthermore  examining the pca plot shows a desirable ordering of the examples with respect to sentiment  after

this result makes intuitive sense since we expect the
words typically in positive reviews to be somewhat distinct from the words typically in a negative review and appear together in a local cluster in the glove vector space 
hence  the corresponding vector averages and the clusters
for each of these classes should also be distinct 

figure    distribution of nearest neighbors sentiment

 

fi 

models

   

multi class support vector machine

we also explored the performance of an open source
multi class svm implementation      in particular  we
motivated by the discussion in the previous section  we used a one versus one svm  which constructs and trains
propose the following approach to extend the small seed a separate     soft margin svm for each pair of classes 
set of labelled data into the full training set  let s denote at test time  each svm separately classifies the sentence 
the set of sentences  and let i denote the seed set 
and the sentence receives the label of the class with the
to construct a larger training set  we find the k nearest highest number of votes  for each svm  the objective is 
neighbors for each sentence s   i  as measured by eu 
 
n
clidean distance  then we add each of the nearest neighx
 
 
min
kwk   c
i
bors to the training set with the same label as s 
w  b
 
i  
we emphasize that the true label of these sentences is
unknown to the model  and the assigned label is only a
subject to
heuristic guess  both the size of the initial seed set i and
the number of nearest neighbors  k  are parameters in the
yi  w  xi b    i   i   for i            n
model  and we will study classification accuracy as these
numbers vary 
as a justification for this approach  consider figure   
this plot gives the number of nearest neighbors with   results
a particular sentiment label for each label in the seed
set  for each seed set label  the most common nearest  to evaluate the success of our nearest neighbor methods 
neighbor label is precisely the original label with the dis  we first trained and tuned both classifiers on the entire
tribution being particularly accurate for positive and labelled training set  the table below gives the classifivery positive sentences  as should also be clear  this cation accuracy for various choices of and kernels in
procedure does introduce some noise into the training set  the svm  where parameters are not specified  they are
we discuss the effect of this noise and its impact on clas  set to the optimal values found via cross validation    
indicates the top performing models 
sification accuracy in section   
after constructing the expanded training set  we train
baseline model
accuracy
a sentiment analysis classifier on the resulting sentences 
  softmax
 
 
     
     
we briefly describe the top two performing models for
 
softmax
 
 
  
 
     
this task  as measured by accuracy on the full  labelled
softmax       
     
training set 
  svm  linear kernel 
     
svm
 gaussian
kernel 
     
    regularized softmax regression
svm  polynomial kernel       
regularized softmax regression generalizes logistic resvm  sigmoid kernel 
     
gression to the multi class setting  the model is param   
eterized by i   r
for classes i                 k and a
regularization parameter   r  which is chosen via   the following table gives the performance of the topfold cross validation  the objective function is given by
performing models for different seed set sizes  i  and
 
 
m x
k
k x
n
number of nearest neighbors k  figure   shows classi x
x
exp jt x i   
 
j    
 y i   j log pk
 
ij
fication accuracy as a function of the number of examples
t
 
 
  i   j  
j   exp j x
i   j  
  i   k  for various k number of nearest neighbors comto improve the rate of convergence  we implemented pared to the baseline  which is the accuracy of the classisoftmax and optimized j   using adagrad  which im  fier trained on the full dataset  results are averaged over
proved convergence by an average of      iterations         random trials 

   

extending the training set

 

fifigure    classification accuracy as a function of seed set size and number of neighbors
model with nearest neighbors
softmax  i         k     
softmax  i         k      
svm   i         k     
svm   i         k      

   

accuracy
     
     
     
     

the space 
additionally  the labels for neutral sentences  even
those made by human judges  are often imprecise  as
a canonical example  consider the sentences  it s never
dull and always looks good and alas   another breathless movie about same  the first sentence is seemingly
positive  while the second one is seemingly negative  but
both are neutral sentences in the treebank 
this ambiguity makes it difficult to train classifiers that
can correctly distinguish between a positive review and
a neutral review with positive words or a negative review and a neutral review with negative words

error analysis

to better understand the errors made by both classifiers 
consider the confusion matrices given below for each classifier trained on the full labelled training set  both classifiers are extremely accurate in predicting labels for positive and negative sentences  further examination reveals
that as few as         labelled sentences and      nearest
neighbors is actually sufficient to separate the positive and
negative classes for most examples with either classifier 

 

discussion

as the tables in section   and figure   indicate  extending
the subsampled training set using nearest neighbor produced classification accuracies within      of the baseline achieved on the entire training set  even with      th
the amount of labelled data 
in the k     case  where half of the data is unlabelled 
it is somewhat surprising that we can achieve performance
roughly equivalent to simply doubly the labelled training
set  what is also especially interesting is the k     
case  where only    of the data is originally labelled 
even when the training set is significantly subsampled 
extending the training set by a factor of    obtains accuracy within    of the baseline as the number of examples grows  this suggests  for problems lacking significant amounts annotated training data  our nearest neighbor methods allow one to significantly expand the training
set and obtain correspondingly higher accuracy 

on the other hand  both classifiers experience poor performance on the neutral class  with increases in labelled
data only slightly improving accuracy  there are several
potential reasons for this inequity  first  the t sne plot
given in figure   suggests that neutral sentences do not
exhibit the same clustering properties as positive and negative sentences and are more loosely scattered throughout
 

fione observation from figure   is all of the models
have performance that is asymptotically lower than using
purely labelled data  this is likely the cost of noise introduced by expanding the training set using nearest neighbors  as figure   indicates that not all of our examples are
accurately labelled  while this was not a significant issue
in our experiments  it is an open question as to how this
approach scales with the problem size 
finally  all of our methods had difficulty correctly classifying neutral sentences  we posit that neutral sentence
vagueness breaks our assumption that the words typically
in neutral sentences are unique to neutral sentences  consequently  unigram averaging is an insufficiently powerful model to capture this ambiguity and does not produce
classifiers with good accuracy 
these inaccuracies are a failure of our sentence representation rather than a failure of our nearest neighbor
methods  it is likely that  given access to a more powerful
sentence representation  nearest neighbor methods would
yield the same boost in accuracy obtained by extending
the training set  but also provide better classification of
neutral sentences 

 

are more evenly distributed in the semantic vector space
than the locally clustered positive and negative sentences 
all of the classifiers we tried asymptotically converged
to roughly     accuracy when trained on the full labelled
training set  this appears to be a fundamental limit on
the capabilities of simple unigram averaging as a form
of sentence representation  to improve this number  we
must use a more complex sentence representations and
perhaps more sophisticated classifiers  in these instances 
it is likely that our technique of extending the training set
via nearest neighbors will yield improvements in accuracy 

 

future work

our results suggest several extensions to generating a
more effective classifier  first  averaging word vectors
destroys valuable context and syntactic information  we
are exploring different representations of sentences that
preserve more of the linguistic structure in an attempt to
improve accuracy beyond      additionally  the seed set
has a large impact on the chosen nearest neighbors  it
would be interesting to explore how choices in the seed
set affect our results 

conclusion

our results indicate that a small seed set of labelled sentences and nearest neighbor methods are often sufficient
to achieve classification accuracy within      of the
baseline consisting entirely of labelled data  this suggests  at least in the case of sentiment analysis  it is possible to achieve high accuracy without a substantial investment in the construction of a large  hand annotated
training set 
viewed in another light  we expect that classifiers tuned
and trained on benchmark datasets could be further improved by applying our techniques to large unlabelled
bodies of text  e g  the wikipedia corpus  and then retraining them on an expanded training set 
much of the improvements in accuracy come from increased performance on positive and negative sentences 
our experiments suggest         labelled sentences and
   nearest neighbors is sufficient to separate these two
classes  however  neutral sentences are substantially
more difficult  and increases in seed set size only slightly
improve accuracy  this is likely because neutral sentences

acknowledgements
we thank richard socher for his guidance and advice 

references
   
   
   
   
   

 

http   scikit learn org stable  
j  pennington  r  socher  and c  d  manning  glove 
global vectors for word representation  in proc  emnlp 
     
john duchi  elad hazan  and yoram singer        adaptive subgradient methods for online learning and stochastic
optimization  jmlr     
l j p  van der maaten and g e  hinton  visualizing highdimensional data using t sne  journal of machine
learning research       
r  socher  a  perelygin  j  y  wu  j  chuang  c  d  manning  a  y  ng  and c  potts  recursive deep models for
semantic compositionality over a sentiment treebank 
in emnlp      

fi