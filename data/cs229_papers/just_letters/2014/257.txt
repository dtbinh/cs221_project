cs      machine learning  autumn     
final writeup

yelp restaurants open hours
samuel bakouch    adrien boch    benjamin favreau 
abstract
this paper aims at identifying when restaurants registered on yelp are open or closed based on the reviews
written by yelps users  our initial approach was to use a binary classification model with a bag of words
representation of the reviews  we then conducted multiclass classification where logistic regression reaches
       accuracy but with a        false positive error rate which is critical for yelps user experience  we then
pointed out that there is a tradeoff between model accuracy and false positive error rate 
  sbakouch stanford edu 

department of management science and engineering  stanford university
department of earth sciences  stanford university
  bfavreau stanford edu  department of management science and engineering  stanford university
  aboch stanford edu 

introduction
yelp is an online platform publishing crowd sourced reviews about local businesses  it is now a platform broadly
used and it attracts numerous types of businesses  it has even
become a key success factor in several industries such as
restaurants and bars  it is now essential for these types of
businesses to be referenced on yelp with positive reviews 
high rating and meaningful information 

to keep on growing and taking
an increasing importance in our everyday life  yelp aims
at providing valuable and complete information to its users 
unfortunately  when entering information into the platform 
restaurants often forget to include and update elements that are
particularly relevant for yelps users   e g  the open hours of a
business  yelp must provide its users a consistent experience
across the platform  and a restaurant without registered or
accurate open hours should not jeopardize the overall user
experience  indeed  what is worse than choosing a restaurant
on yelp  driving there thinking about the menu to eventually
find the door closed  this need for consistency and accuracy
led us to apply machine learning techniques to determine the
open hours of a restaurant from yelp users reviews 
objectives and motivation

dataset we used the dataset publicly available  from the
yelp dataset challenge website  the dataset provides two
 json files that we used in our study 
 a file containing information and characteristics about
more than        businesses from the city of phoenix
 a second file consisting of more than           reviews
over these businesses
among the characteristics available for a business are some
labeling category settings   e g  restaurants  bars  health 
beauty      and open hours 

   data transformation
in order to be able to apply learning algorithms on reviews to
predict the hours of operation of a restaurant  we first needed

to transform the  json files we received  in the review file 
every line contained one review for a given business  in the
business file  one line contained the hours of operation of a
given business  in order to facilitate processing  we not only
needed to merge both files  but also to aggregate all the reviews
of a business and to filter businesses that are restaurants 
    map reduce on stanford corn cluster
the business and review files contained about        lines
and           lines respectively  looping over these two files
would potentially entail over                              
iterations  however  as we only consider restaurants  the number of iterations boils down to        iterations 
nevertheless  it is still a massive number of iterations and
as a result extremely time consuming  that is why we designed a map reduce algorithm to do parallel computing on
the stanford corn cluster  in the mapping part  we broke
down the business file into     different new files or pieces 
for every single one of these pieces  a script was submitted a
job on the corn cluster so that multiple tasks could be run in
parallel  using up to    different nodes      output files were
therefore created in the process  a second script has reduced
these     output files together in order to get the output into
one single file  at this point  we built a  json file of       lines
in which one line corresponds to one restaurant  containing
its aggregated reviews and its open hours 
    data preprocessing
we performed stemming on the reviews in order to reduce
the dimension of our feature vectors  stemming is a common
practice used in natural language processing  which reduces
words to their root   e g  thinking is represented by think
after stemming processing  we used the nltk python library 
which performs porters stemming algorithm      we also
removed stop words to eliminate tokens that do not convey
any information  applying stop words algorithm enabled us
to remove high frequency words such as the  i  and 

fiyelp restaurants open hours     

   binary models

  
test error
train error
     restaurants considered

  

  

error    

our goal being to predict the hours of operation of a restaurant
from users reviews  we must predict for each day of the week 
if a restaurant is open or closed for each one hour block of
the day  due to the large computing requirements needed for
such an operation  we chose to focus on tuesday exclusively one of the most representative day of the week for restaurants
excluding the weekend  we ran all our models on python 

  

  

  

    model hypotheses
first  our feature selection will follow the bag of words model 
i e  the dictionary used by the learning algorithms is defined as
the union of all the words that appear in the reviews included
in our training set  size o f dictionary
z
  
 
         


            


nb  rest 
f       

 
 
          
      



        
where fi  j indicates whether feature j appears in the reviews
of restaurant i 
our aim is to predict for each one hour block of tuesday
if a restaurant is open or closed  there are several ways
to represent this output and define the labels predicted by
the learning algorithm  for instance  we could look at the
   hour vectors  or we could view the output representation
as    binary predictions where   for each one hour block the learning algorithm will predict   or    in this case  we
apply a binary algorithm for every one hour block  thus the
number of labels is                 in this section  we chose
to take the latter approach considering the potential huge
number of classes of the previous output representation        
             
    methodology
      error metric

when choosing an error metric  a key characteristic should be
the ability to benchmark our results against several types of
algorithms  we chose the standard average test error looking
at the accuracy of the prediction for each one hour block
t

  

 
    

i   ho  

n

  h x i   ho   y ho 

o

    t

where t is the size of the test set  y ho  is the true state of
operation of the restaurant at hour ho  h x i   ho being the
predicted output for hour ho and training example i   we
then used a    fold cross validation which is standard for text
classification problems     
      training set size

in order to determine the training set size on which we will
train our algorithms  we first decided to plot   cf  figure    the
training and test errors for different training set sizes ranging

  

  

 

  
  
  
  
  of the total number of restaurants considered

   

figure    learing curve for binomial naive bayes

from     to the maximum        we used the binomial naive
bayes algorithm to perform this analysis  we observe two
main behaviors  from     to        the algorithm overfits and
from       to        the behavior is similar as the training
and test errors slightly differ in functon of the training set
size  thus  as the complexity of the learning algorithms is at
least o t     where t is the size of the training set  we decided
to choose       training examples for the rest of our study 
also  one can notice that       training examples correspond
to the one standard error rule  which is a standard parameter
selection criterion used in statistics     
      baseline algorithm

in order to accurately measure the performance of the learning
algorithms we choose to apply  we need a baseline model for
which the previously defined error metric will be computed 
we will consider two baseline algorithms 
 predict close   i e    for every hour  error    
 predict open   i e    for every hour  error    
to compute the error metric that should be the reference to
benchmark against  we will compute the quantity
 re f   min           
running these two naive algorithms on our dataset outputs  we
obtained  re f           thus  we will not consider learning
algorithms with an error greater than        as the baseline
algorithm performs better 
    learning algorithms
      naive bayes

first  we decided to apply the binomial  bnb  and multinomial  mnb  naive bayes algorithms in order to test our
hypotheses  the bnb led to        of error and the mnb led
to        of error  we note that these errors have the same
order of magnitude and both are under the baseline error cap 
      knn  svm  logistic regression  perceptron

then  we decided to test additional algorithms and thus to
refine our model  indeed  applying naive bayes to our dataset 

fiyelp restaurants open hours     

we made the implicit naive bayes assumption that the features
are conditionally independent given a label  as this is a strong
assumption that is not verified in our problem  we applied
svm with a gaussian kernel  svm   k nearest neighbors
 knn   logistic regression  and the perceptron algorithms and
compared their respective performances 

  

  

cross validated error    

  

before applying learning algorithms  it
is standard in text classification problems to apply feature
weighting to our count matrix in order to reflect the relative
importance of features     to do so  we used the tf idf measure  which increases proportionally to the number of times a
word appears in the document  but is offset by the frequency of
the word in the corpus  which helps to adjust for the fact that
some words appear more frequently in general  the formula
to compute tf idf is the following 
feature weighting

wi  j   t f i  j  log

n
d fi

where t f i  j is the number of occurrences of word i in training
example j  d f i is the number of training examples containing
the word i  and n is the total number of training examples 
applying tf idf to weight our features and running the aformentionned learning algorithms  we note that knn with
k       ranks first with        of error while logistic regression with regularization parameter        and svm
and a regularization parameter c       closely follow with
respectively        and        of error   cf  figure    multiple parameters k    c were tested and the chosen ones were
determined as they minimized the cross validated error 
    feature selection
another way to account for the relevancy of features to a
given classification problem is to select a subset of features 
indeed  the dataset contains many redundant and irrelevant
features  redundant features are those which provide no more
information than the currently selected features  and irrelevant
features provide no useful information in any context  the
main advantages of applying feature selection are to improve
the model interpretability  to enhance generalization by reducing overfitting  and to shorten training times 

without feature selection
with feature selection
baseline

  

  

  

  

  

 

 

binomial nb

multinomial nb knearest neighbors gaussian svm logistic regression

perceptron

figure    binary classification results

we applied the bisection algorithm in order to find the optimal number of features to use for each learning algorithm 
corresponding to the minimum of the cross validated error for
the hour   am   cf  figure    we chose   am as a proxy since
it is the hour for which our baseline algorithm performs the
worst    am represents     of the total error compared to
     if the error was uniformly distributed 
    analysis
after applying feature selection  we conclude that knn with
k        logistic regression with parameter        and
svm and parameter c       perform similarly as in the no
feature selection case  moreover  we note that the algorithms
that were performing worse   i e  bnb  mnb  and the perceptron algorithm  now perform significantly better with feature
selection      improvement for bnb      improvement for
mnb  and     improvement for perceptron  though these
algorithms improved with feature selection  they still do not
reach the level of performance provided by knn  svm  and
logistic regression 

   

where e j denotes the occurrence of feature j  ei denotes the occurrence of the class i  and nei e j denotes the counts of training
examples when either ei or e j is equal to    last  eei e j is the
expected frequency asserting that the occurrence of feature j
and the occurrence of class i are independent 

   

cross validated error    

to perform feature selection  we applied the chi square method
that is standard in the text classification literature      we use
it to test whether the occurrence of a specific term and the occurrence of a specific class are independent  thus we estimate
the following quantity for each feature j and we rank them by
their score 
 nei e j  eei e j   
 
     j    i      e       e      
i
j
 
eei e j

   
   
   
   
   
   
   
   

   

   

   

   
   
   
number of features

   

   

   

    

figure    feature selection for binomial naive bayes

fiyelp restaurants open hours     

   multi class models

  

    motivation
in section    we applied several algorithms based on binary
classification outputs  for a given business  the predicted
operation hours are obtained by concatenating the prediction
of one algorithm over    hours  thus  algorithms are run
independently every hour and the prediction from one hour is
completely independent from the prediction of the adjacent
hours  as mentioned earlier  in this setting  k nearest neighbor  svm and logistic regression have a similar prediction
accuracy  but lead to unrealistic predicted answers as we can
see in the example below  such example would mean that the
associated restaurant opens   times during tuesday 

  

cross validated error    

  

  

  

  

  

 

 

    results
we extended the models tested in section   to fit the new
type of answer   except the svm classifier only accepting
binary answer vectors  in short  we tested bnb  mnb  knn 
logistic regression and perceptron algorithms  we used the
same methodology as in section   for every models 
   we used a bag of words model to transform reviews
into usable feature vectors
   we weighted the features based on tf idf   except in the
naive bayes algorithms
   we fitted algorithms using all features available
   using    test  we reduced the number of features
   we fitted our algorithms with the optimal number of
features obtained at step  
based on this methodology  we obtained the results presented
in figure    we not only did not lose any prediction power 
but we even improved it  multi class logistic regression hits
       prediction accuracy improving our former performance by      

multinomial nb

knearest neighbors logistic regression

perceptron

    analysis
even though our new methodology does not focus on maximizing the cross validated error and the f   score on an
hourly basis  it classifies restaurants in observed classes  binary classification reduces the bias on every hour slot considered  but increases the overall variance of our prediction
algorithm   as predictions are independent from one hour to
another  variances are simply summed over the hours  using
multi class classification  we have introduced an additional
bias to our model  but we decreased the variance on a   hour metric   variance pooling  which explains why our new
methodology has good performance 
we can also observe that our models are less sensitive to
feature selection than earlier  this might be explained by the
fact that the answer vectors contain more information than
earlier  moreover  in our subset of restaurants  we have    
classes  i e  on average one class has a size of less than   
restaurants  while reducing the number of features  our algorithms tended to be less performant  and the performance was
monotically increasing with the number of features included
in the model  which tends to support our theory 
as we can see in figure    the prediction error is not uniformly

   

   

cross validated error

to withdraw the uncertainty on how to make our predictions
on each time slot  we decided to use the entire    hour vector
as mentioned in part      we noticed that our dataset contains only     different vectors  thus  running multi class
classification algorithms on     classes over more than      
businesses seems realistic  in order to be able to benchmark
these new algorithms  we used the same measure of accuracy
as in section   using the same notations  h x i    ho  being the
hoth element of the predicted class h x i    

binomial nb

figure    multi class classification results

y                             t
one solution to avoid this kind of patterns would be to group
a given number of hours and make prediction over this group
of hours  such algorithms are called multi class classification 
however  how to make a prediction on a specific hour slot ho 
we would need either to make several predictions based on
all the groups containing the slot ho or to arbitrarily choose
one of these groups 

without feature selection
with feature selection
baseline

  

   

   

   

 
 

 

  

  

  

  

hours

figure    multi class logistic regression cv error per hour

fiyelp restaurants open hours     

at this point  we chose to focus on the logistic regression
model based on the results observed in section    as mentioned earlier  multi class logistic regression is not sensitive
to feature selection  it performs even worse when we reduce
the number of features  given yelps business strategy  predicting that a restaurant is open while it is currently closed
is particularly harmful for its brand image  thus  we will try
to implement new strategies not only to improve the overall
prediction power of our model  but also to reduce the      
false positive error rate obtained so far 

actual

  

  

  

  

 

  

 

 

 

 
class weight

 

 

 

 

figure    cv error vs  false positive error rate

further reduce the false positive error rate  we thus need to
tolerate a lower prediction accuracy 

predicted
close open


  

fp    

   improvement strategies

cross validated error    

distributed over the    hours of the day  in particular  we observe two error peaks centered at hour      and     even if
the logistic regression model performs well in between and
outside of these peaks  there is still room for improvement 



close              
open
           

    bigram  trigram
based on the observation that cross validated error tends to its
optimum while increasing the number of features  we decided
to introduce new features in the model  our model intrinsically depends on the order of words in a review  a simple
observation supports this argument    am is one of the top
features in our current prediction algorithm  however  while
tuesday   am is relevant to our problem  friday   am is
particularly misleading  these observations motivated us to
introduce a new type of feature  bigrams i e  on top of the
usual bag of word model  we added all the sequences of two
consecutive words in the reviews  therefore  from        
unigram dictionary used so far  we introduced              
new bigram features  we then ran our multi class algorithm
on the new input matrix and obtained an error rate of        
which did not lead to a significant improvement in terms of
prediction power  we then ran our algorithm including trigrams   consecutive sequence of three words  and obtained
       error rate  thus  we can conclude that neither bigram
nor trigram enabled significant accuracy jump 
    classification error weighting
one strategy to align our algorithm with our objective to
decrease the false positive error rate is to weight the misclassification of the class closed more heavily than the misclassification of the class open  in order to be able to implement
this strategy  we came back to binary algorithms  we can
notice in figure   that our optimal cross validated test error
       is obtained when penalization false positive misclassification three times more   false positive error rate of       
  we note that there is a tradeoff between decreasing the crossvalidated error and reducing the false positive error rate  to

   discussion
during this project  we have implemented several supervised
text classifier algorithms with different output representations 
while binary models gave good prediction power  they produced unrealistic predictions  we then transformed our outputs and performed multi class classification  using a very
large dataset of yelp reviews and a logistic classifier  we have
been able to correctly predict hours of operation        of
the time   error rate of         moreover  multi class classification algorithms performed particularly well  since they
significantly reduced the variance problem observed for binary models  we then particularly focused on refining our
algorithm in order not only to increase its prediction power
but also to fit to yelps overall strategy  by penalizing a
certain type of misclassification  we have been able to significantly cut the false positive error rate  which is critical to yelp 
in the future  it would be interesting to consider several new
strategies to improve the performance of our algorithm 
 training set selection  monitor more closely the businesses present in our dataset   restaurants with fewer
reviews introduce bias due to the lack of information
 feature filtering  use backward or forward selections
to reduce the noise due to the high number of features
 feature representation  test new feature representation instead of the usual count  which is slightly biased
toward businesses that contain more reviews

references
    e  loper          natural language toolkit  http   www 
nltk org 
   
m  stone          asymptotics for and against cross validation
    r  tibshirani          model assessment and cross validation
    p  meesad          a chi square test for word importance differentiation in text classification
    s  m  weiss   al          text mining  predictive methods for
analyzing unstructured information

fi