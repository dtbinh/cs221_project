pose estimation based on  d models
chuiwen ma  liang shi

 

introduction

ing dataset from rendered images  there is an obvious
drawback of this approach  the statistical propthis project aims to estimate the pose of an object erty of the training set and the test set are differin the image  pose estimation problem is known to ent  for instance  in the real world  there exists a
be an open problem and also a crucial problem in prior probability distribution of poses  which might
computer vision field  many real world tasks depend be non uniform  furthermore  even for features from
heavily on or can be improved by a good pose the same pose  real image features might be more diestimation  for example  by knowing the exact pose verse than rendered image features  in this paper 
of an object  robots will know where to sit on  how we proposed a method to revise the influence of the
to grasp  or avoid collision when walking around  difference in prior probability distribution  detailed
besides  pose estimation is also applicable to auto  methods and experiment results are shown in the folmatic driving  with good pose estimation of cars  lowing sections 
automatic driving system will know how to manipulate itself accordingly  moreover  pose estimation
dataset  features and
can also benefit image searching   d reconstruction  
and has a large potential impact on many other fields 
preprocessing
previously  most pose estimation works were implemented by training on manually labeled dataset 
however  to create such a dataset is extremely timeconsuming  laborsome  and also error prone because
the labelization might be subjective  therefore  the
training datasets in existing works are either too
small or too vague for training an effective classifier 
in this project  we instead utilized the power of
 d shape models  to be specific  we built a large 
balanced and precisely labeled training dataset from
shapenet      a large  d model pool which contains
millions of  d shape models in thousands of object
categories  by rendering  d models into  d images
from different viewpoints  we can easily control the
size  the pose distribution  and the precision of the
dataset  a learning model trained on this dataset
will help us better solve the pose estimation task 

   

training data

as we mentioned in section    we collected our training data from shapenet  a  d shape model database 
which contains      chair models  for each model 
we rendered it on    viewpoints  evenly distributed
on the horizontal circle  shown in figure   

in this work  we built a pose estimation system of
chairs based on a rendered image training set  which
predicts the pose of the chair in a real image  our
pose estimation system takes a properly cropped
image as input  and outputs a probability vector on
pose space  given a test image  we first divide it into
a n  n patch grid  for each patch  a multi class
classifier is trained to estimate the probability of this
patch to be pose v  then  scores from all patches
are combined to generate a probability vector for the
whole image 

figure    chair models and rendering process

we chose      models  accordingly        images
to build the training dataset  and leave the rest     
models to be our rendered image test set  when extracting image features  we first resize the images to
         pixels  and then divide it into      overlapped patch grid  with patch size        and patch
stride    on both axes  after that  we extract a    
dimensional hog features     for each patch  so the
whole image can be represented by a       dimensional feature vector  those        feature vectors
although we built a larger and more precise train  constituted our training dataset 
 

fi   

test data

for each patch  we build a classifier  which gives a
prediction of the conditional probability p  v fi   
to better evaluate the performance of our learning to respresent p  v i  in p  v f    i           n     we
i
algorithm  we built three different test sets with
 
n
q
increasing test difficulty  they are rendered image assume p  v i  
p  v fi    so  we can calculate
i  
test set  clean background real image test set and
p  v i  and the according v using the following
cluttered background real image test set 
formula 
rendered image test set consists of         
rendered images  which also comes from shapenet 
clean background and cluttered background real image test sets are collected from imagenet      containing      and      images respectively  both with
manually labeled pose ground truth  some sample
images are shown in figure    obviously  these three
datasets are increasingly noisy and difficult to tackle 

 
n
q

p  v i   

p  v fi  

i  
v n
p
q 

p  v fi  

v   i  

v   arg max p  v i 
v

in sum  our model takes fi   i           n   as input 
and outputs p  v i  and v 

 

methods

   
     

learning algorithms
random forest

in this project  we choose random forest     as a primary classification algorithm based on following considerations 
 suitable for multiclass classification 
 non parametric  easy to tune 

figure    clean background   cluttered background

 fast  easy to parallel 
for the test sets  we used the same scheme to process the image as the training set  that is  convert
each image into a       dimension hog feature 

 robust  due to randomness 

during classification     random forest classifiers
are trained for    patches  as a trade off between
spatio temporal complexity and performance  we set
  model
the forest size to be     trees  we also tuned the
maximum depth of trees using cross validation  where
rather than using global image feature as the input the optimal depth is     when classification  each
of classification  our pose estimation model is patch  random forest outputs a probability vector p  v fi   
based  by dividing image into patches and training after laplace smoothing  we calculated p  v i   estia classifier for each patch  our model can be more mated the pose to be v   arg max p  v i  
v
robust to occlusion and background noise  also 
this approach reduced the feature dimension  thus
      multiclass svm
reduced the sample complexity for each classifier 
actually  we did try the global method  while the in binary classification  svm constructs a hyperplane
classification accuracy is     lower than patch based or set of hyperplanes in a high  or infinite dimensional
method  the mathematical representation of our space that will separate data with different labels as
patch based model is as follows 
wide as possible  in c svm model  the hyperplane
is generated by maximizing the following function
define fi as the hog feature of patch i 
m
x
 
i    f         fn     to be the hog feature of the
min w b
  w      c
i
 
whole image  v            v   to be the pose space 
i  
 

fis t 

y  i   wt x i    b      i  

p  v fi    here  p  v   p  fi  v  and p  fi   are distributions in the test set 

i     i             m 

p  v p  fi  v 
p  v fi    
two important factors will shape the outcome of
p  fi  
model  kernel and soft margin parameter c 
assume the training data and the test data have at
kernel defines a mapping that projects the input
least
some similarity  specifically speaking  assume
attributes to higher dimension features  which could
p
 f
 v 
  p  fi  v   p  fi     p  fi    then we have 
i
often convert the non separable data into separable 
c determines the trade off between the training error
p  v 
p  v fi     p  v fi  
 p  v fi  p  v 
and vc dimension of the model  the smaller c is 
p
 v 
the less effect will the outliers exert on the classifier 
to recover p  v fi    we just need to achieve a good
in our problem  we face a multiple classification estimation of p  v   one possible method might be
problem which can not be addressed by building a randomly choosing some samples from the test set 
single svm model  here  we apply two methods to and manually label the ground truth of pose  regard
solve it     one versus rest  ovr     one versus  the ground truth pose distribution of samples as an
one  ovo   both these two methods reduce the sin  estimation of global p  v   however  we still need to
gle multiclass problem into multiple binary classifica  do some labor work 
tion problems  ovr method train classifiers by separating data into one exact label and the rest  which
noticing the above formula can also be written as 
results in n models for n label data  then it predicts
 
p  v fi  
p  v fi  
the result as the highest output  in ovo approach 
  p  v      v  v
 
classification is done by a max wins voting strategy 
p  v 
v
p  v 
for n label data  n n       classifiers are trained 
with each trained by picking   label data from entire we came up with another idea to automatically
n label data  in prediction  each classifier assigns the improve the classification result  for p  v fi    we
input to one of the two labels it trained with  and have 
finally the label with the most votes determines the
 
p  v   
 p  v fi     p  v fi  
instance classification 
v
 
 p  v fi     p  v fi  
p  v   
    optimization
v
that means  when testing  frequently appeared
constructing training dataset from rendered images
poses are underestimated  while uncommon poses are
has many advantages  but there are also drawbacks 
overestimated  here  we will propose an iterative
as i mentioned in section    the prior probability of
method to counterbalance this effect  basically  we
pose in real images can be highly different from that
will use p  v fi   to generate an estimation p  v  of
in rendered images  as we know  pose distribution in
the prior distribution  assume p  v  and p  v  have
the training set is uniform  however  in real images 
similar common views and uncommon views  in other
there are far more front view chairs than back view 
words  p  v  and p  v  have the same trend   smooth
fortunately  this difference can be analyzed and modp  v  to keep the trend while reduce fluctuation range 
eled as follows 
multiply the original p  v fi   by smoothed p  v   and
iteratively repeat the above steps  finally  due to
      probability calibration
the damping effect in combination step  p  v  will
converge 
and p  v fi   gets closer to p  v fi    forin classification step  each classifier ci will output a
mulation
of
this iterative algorithm is as follows 
probability vector p  v f    using bayesian formula 
i

we have 

   calculate p  v i  j     j           m 

p  v p  fi  v 
p  v fi    
p  fi  

 
n
q

p  v i  j     

here  p  v   p  f  v  and p  f   are learned from training data  whereas  the real p  v fi    which satisfies the following formula  could be different from

v   i  

 

 j 

p  v fi  

i  
v n
p
q 

 j 

p  v fi  

fi   accumulate p  v i  j    on all test samples to calculate p  v  

 
ground truth
a  
a      
a     

   

   

m

  x
p  v i  j   
p  v   
m j  

c o n v e r g e d p   v  

   

   

   

   

   

   smooth p  v  by factor  

   

   

p  v    
ps  v   
      

 
 

 

 

 
po s e

  

  

  

  

figure    stable distribution p  v  w r t  

   estimate p  v fi   by letting 
p  v fi     p  v fi  ps  v 

is almost monotonically increasing with respect to  
such
as blue curves  some are monotonically decreas   use p  v fi   to re calculate p  v i  j    in step   
ing  such as the black curve  while others will decrease
while remain p  v fi   in step   unchanged  repeat
after first increase  such as the red curves  recall
the above steps 
the distribution change with  in figure    we found
p
 v  will first approximate p  v  then be smoothed 
after several iterations  the algorithm will converge 
so 
patterns with turning points are reflection of this
and well get a final estimation p  v fi   of p  v fi   
trend  sum on those components  we get figure   
and take the turning point of the curve as our esti      parameter automatic selection
mated   here  is    very close the optimal value
however  different  will lead to far different converg      
ing results  as shown in figure    from experiment
results in figure   we observed that if  is too small 
viewpoint with the highest probability p  v  will soon
beat other viewpoints  and p  v  converges to a totally biased distribution  while  if  is too large 
smoothing effect is too strong to make any change of
p  v fi    however  there exists an intermediate value
of  to maximize the classification accuracy and result in an optimal estimation p  v fi    in figure  
and    it is     
v 

v 

    
    

v 

   

   

    

    

v 

    

    

    

    

   

   

   

    

    

    

    

    

 
 

   

 

x   

 

   

 

 
 

   

v 

 

   

 

 
 

   

v 

   

 

   

 

 
 

   

v 

     

 

 

   

 

   

 

   

 

   

 

v 

    

    
    

    

    

   

    

    

 

    

     

    

   

 
 

   

 

x   

 

   

 

 
 

   

v 

 

   

 

 
 

    

   

v   

 

 

   

 

 
 

   

v   

 

v   

    

    

    

    

    

    

    

    

 
 
    

 

  

 
 

       
  

a c c         

   
 

x   

  

 

   

 

 
 

   

v   

 

   

 

 
 

   

v   

 

   

 

 
 

   

v   

 

   

 

 

    

   

 

    

   

  

 

    

   

  

 
 

 
v   

   
    

    

ac c urac y

   

 

    
   

 

   

 

 
 

    

   
   

 

   

 

 
 

   

 

   

 

 
 

   

 

  

  

  

  
 

figure    p  vj   curve with respect to 
   

   

   

   

 
log 

   

   

   

   

 

figure    classification accuracy change w r t  

 

results and discussion

to solve the optimal   we conducted deep analysis
    classification performance
to the relationship between stable p  v  and   we
found three patterns of relationship between p  vj   table   shows a promising classification results on
and   shown in figure    for some viewpoints  p  v  all three test sets  under our scheme  ovo svm
 

fi   

    

    

   

prob ab i l i ty

    

   

    

   

    

figure    confusion matrix on rendered  clean  cluttered test sets

   

    

 
 

   

   

   

   

 
log 

   

   

   

   

 

results verified the effectiveness of our scheme  more
experiment details are omitted due to page limit 

figure    estimated 

future work
achieves     accuracy on clean background real im   
age test set  and     on cluttered background test
set  which beats other algorithms  after calibrating our ideas for the future work are described as follows 
the conditional probability p  v fi   using automat take into consideration the foreground and backically selected   performance on clean test set is
ground information in the image  fully utilize the
boosted by     as well    on cluttered set  the
information in rendered images 
relatively low improvement on cluttered test set may
 further model the difference between three
result from our assumption of p  fi  v    p  fi  v  and
datasets  revise our inaccurate assumption 
p  fi     p  fi   are too strong for cluttered images 
rf   
rfopt    
ovo   
ovoopt    
ovr   
ovropt    

render
     

     

     


clean
     
     
     
     
     
     

 learn the discriminativeness of patches  give different weight for different patches 

cluttered
     
     
     
     
     
     

references
    breiman  leo  random forests  machine learning                   
    chang  chih chung  and chih jen lin  libsvm  a library for support vector machines 
acm transactions on intelligent systems and
technology  tist                 

table    classification accuracy on three test sets

figure   shows the confusion matrix on three test
sets respectively  from left to right  as test difficulty increases  confusion matrix becomes increas      dalal  navneet  and bill triggs  histograms of
oriented gradients for human detection  comingly scattered  on rendered image test set  an inputer vision and pattern recognition       
teresting phenomenon is that some poses are often

cvpr       ieee computer society conference
misclassified to poses with    difference with them 
on  vol     ieee       
one possible explanation is that the shape of some
chairs are like a square  also  front view and back    deng  jia  et al  imagenet  a large scale hierview are often misclassified  because they have similar
archical image database  computer vision and
appearance in feature space 
pattern recognition        cvpr       ieee
conference on  ieee       

 

conclusion

    pedregosa  fabian  et al  scikit learn  machine
learning in python  the journal of machine
learning research                      

in this paper  we proposed a novel pose estimation
approach  learn from  d models  we explained
our model in bayesian framework  and raised a new     su  hao  qixing huang and guibas leonidas 
optimization method to transmit information from
shapenet   http   shapenet cs stanford edu 
test set to training set  the promising experiment
 

fi