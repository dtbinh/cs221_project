who matters  finding network ties using earthquakes
siddhartha basu  david daniels  anthony vashevko
december         

 

introduction

the intutitions behind network measures  nevertheless  our results appear to be disappointing
while social network data can provide a rich his  for researchers who wish to rely on trace data as
tory of personal behavior and interpersonal in  a high quality measure of social life 
teractions  it is often unclear how high quality
data maps onto real social constructs  deep
  data
trace data  e g  emails  cell phone logs  provides thorough measurement  but cannot often this paper relies on a novel dataset of cell phone
identify important aspects of behavior      is a calls and texts acquired from a chinese telecomperson emailing their friend  their spouse  their munication company  the data covers phone use
colleague  because the content of such relation  in a single province  sichuan  over a period of
ships can be of extreme importance to social the  four months  march june        the data inory      researchers have looked for ways to iden  cludes information on all calls and texts made by
tify such ties in the absence of true data  often or two a population of     thousand subscribers 
relying on tie weighting  using a trace dataset along with basic demographic information about
that allows for the identification of close relation  these subscribers  such as phone and plan charships  we attempted to uncover network charac  acteristics 
teristics that predict close relationships  as well
two features set this data apart  first  the
as to quantify the granularity of network data data includes information about family plans 
necessary to be able to perform this prediction allowing us to differentiate communications bereliably 
tween family members from communications to
the attempt was not successful  we at  outside partners  second  a major earthquake
tempted to predict the presence of two kinds of struck the province during the period of obserclose relationships using support vector machines vation  following other ongoing work on this
 svms  and logistic regression in networks  op  dataset      we propose that the first calls and
timal prediction models failed to predict any im  texts made after the earthquake reach out to important relationships in the test set  that is to portant individuals  key providers of support
say  though models were occasionally able to sep  and resources  emotional and otherwise  to the
arate unimportant ties from important ties dur  subscribers in the data set  these people reping training  they predicted that all test ties were resent a unique ground truth for identifying the
unimportant to the focal ego 
contacts that matter to people  our goal in this
these results are naturally disappointing  project is to attempt to predict these two classes
they suggest that standard network measures of of important ties  family members  and targets
tie importance are incredibly coarse for the kind and sources of first calls 
for each ego  we identify the first call or text
of social science conducted on trace data  the
conclusion of the paper discusses various flaws made to or from that ego  and label the source
of the approach we took here  suggesting ways to or target of that communication as the first call
improve this analysis in a way that might confirm partner  one weakness of this approach is that
 

fiwe examine only first calls  it would of course
be straightforward to extend this measure to be
a ranking of alters by their ordinal importance
to the ego 
a more serious shortcoming of this dataset is
that the chinese telecommunications market is
split into several major firms  because our data
comes from only one of those firms  we have no
knowledge of the communications among alters
 we do not have the complete network of communication  and in fact we do not have complete
communication networks even for the immediate
ego network around any subscriber  as such  we
arent able to use measures of network embeddedness to identify important ties 

communication  that is to say  we had separate
features for the amounts of texts a subscriber
sent to some communication partner and for the
number of texts the partner sent back  finally 
because several of these measures were undefined
in the absence of sufficient communication from
i to j  we included indicators for missing data as
hopefully informative features 

 

model   model   included tie weight features
only  to represent a barebones network dataset 

 

models

to capture the idea that researchers might have
limited information available in any given data
set  we nested the above information in three
models 

features

we used several classes of data to represent the
kind of information that might be available to
researchers  we examine tie weight  coarse network timing information  and finer network timing information  we restrict data to all communication that took place prior to the time of the
earthquake 

model   model   included all features from
model   as well as tie variance features  to capture the availability of limited network timing
data 

model   model   included all features
from model   as well as the response time featie weight tie weight is the overall number tures  to represent a rich network timing dataset 
of times that i contacted j 
our data analysis was conducted in r  using
tie variance tie variance is the week to  the e     wrapper to aid us in implementing libweek variance in the number of communication svm  libsvm is a powerful package that provides
events that occured from i to j 
extensive flexibility in classification algorithms
and analysis which proved to be useful in apinterresponse time we calculated the me  plying the following learning models and then
dian time elapsed between the last communica  studying how they performed     
tion from j to i and the next event from i to j 
because the average inter response time is essen  logistic regression our first cut at the analtially the inverse of the frequency of communica  ysis is by implementing logistic regression on
tion events  we used the median to capture the the data  using rs base package  we ran logisextent to which communication events clustered tic regressions to predict one of two dependent
between the two agents  as an alternative mea  variables  the first of these is an indicator for
sure of the same concept  we calculated the frac  whether two individuals are in the same famtion of all inter response times that took place ily plan  and the second of these is an indicator
within an hour of each other 
for whether there was a call between two people
tie weight and variance were split between in the immediate aftermath of the earthquake 
voice calls and text  and were additionally split the independent variables are those described
for ego to alter communication and alter to ego above  specifically  the first model includes call
 

fiand tested them on another subset  our optimality criteria were models with minimal rmse
and maximal recall  we selected the rmse criterion in order to capture the overall accuracy
of the model  the number of positive examples
was very small  however  egos had about    
possible contacts on average  and only about    
of these were family ties  and only one of these
was a first call tie  because we were interested
in identifying instances of these rare important
ties  we also chose to maximize recall 
figure   shows the outcome of these tests  the
plots are jittered because almost all parameter
values produced identical prediction outcomes 
the major difference was how many positive predictions a given model was able to make  there
are two points to note here  first  rbf outperformed the sigmoid kernel on rmse measures 
but the sigmoid kernel showed better recall and
greater variability of recall across both family
and first call models  second  rbf was completely unable to predict instances of first callers 
with these results in mind  we proceeded to
the full models by selecting the grid parameters
that produced the lowest rmse at the highest
observed recall  essentially  those models that
had the fewest false positives of those that had
the most true positives  we tried out different
combinations of these optimal results  but this
did not substantially affect results from the final
models 

volume  the second includes volume and call variance  and the third includes the second combined
with time between calls and texts  and how long
it takes people to respond to calls and texts between egos and alters 
support vector machine we then proceeded to analyze the data using support vector
machines  a main advantage of svms is that by
using kernels  we can gain insights from higher
dimensional spaces while still using a relatively
small number of features  our first svm implemented a gaussian kernel  we did this by utilizing libsvms radial basis function  rbf   the
outcome variables  same family not  and call after earthquake not  were the same as in the logistic regression  the same can be said of our
features  the second kernel that we used was
the sigmoid function  the outcome variables and
features are again the same as before 
finally  our modeling strategy assumes the independence of ties  we select samples for training and testing by selecting a random subset of
subscribers and including for analysis all alters
who called or were called by these subscribers 
there is a problem here in that one of our measures of importance  the first call  is by definition
constrained to a single alter for any given ego 
any person had to have exactly one first call 
we did not incorporate this constraint into our
model  doing so would appear to lead towards a
relatively complicated approach of multinomial
classification with a variable number of classes
per ego  given more time  this approach would
be worth exploring  nevertheless  our hope was
that the current approach would at best produce
a high rate of false positives  as the model identified important alters that were not first calls 
but came close 

   

full models

as explained above  we estimated the three models above with three techniques  logistic regression  svm with a gaussian kernel  and svm
with a sigmoid kernel  because solution time for
the svm algorithm grows quickly in the size of
the data set  we restricted the training and test
sets for all models to a     percent sample of all
subscribers  this about        tie observations
  results
for about     subscribers  table   presents the
rmse and recall on the test set after fitting all
    svm parameter selection
models 
as the table suggests  most models were unwe attempted to select optimal parameter settings for two classes of svm via a grid search able to predict any true positives  table  
procedure  we fit models to a subset of the data presents a sample confusion table for the logistic
 

fi       














recall

recall























 

      
      
      



       
       















































































      

      







































      



























































































      



       

      


 







 

 









   



 







 
  


 
  

  
 
 


 








 


 



 











   


 





 




 






  




 








 

 











   
 






   









 








 



 
   



 


 




 
 



 








       



      







      

rmse

 a  rbf   same family





















    
    




































































    








    

     

     







    











 





























































































































 

































 






















 












    

rmse










     
     


















































































recall

recall

    









     



 








    

      

 b  rbf   first call
















    

      

rmse

    

    

    

rmse

 c  sigmoid   same family

 d  sigmoid   first call

figure    svm parameter tuning  recall and rmse
model on same family  which was the most successful model for producing positive predictions 
as the confusion table suggests  the rmse and
overall accuracy were substantially driven by the
true incidence rate of same family or first call ties
 because the models classified almost all ties
as non instances of the same family or first call
class  they misclassified all of these as false negatives  in fact  all svm models made no positive
predictions  failing completely to identify important ties in the test set 

models  it may have been better to measure tie
strengths relative to the egos average or total
volumes of communication 
the more troubling possibility is that dependence among ties made binary classification unviable  no model that doesnt take into consideration the overall network of ties around an ego
could successfully make same family or first call
predictions  given our inability to observe most
members of the network  however  it is unclear
how far we could have gone down this route 

 

 

discussion

conclusion and future

the most surprising findings are that network information does not appear to easily identify important ties  and perhaps more importantly  that
adding deeper information appears to have little
if any discriminatory benefit in this task  this is
troubling for existing studies of social networks 
as well as for the research promise of trace data 
the broad conclusion appears to be that important ties hide well in networks  it is not clear
that detailed network data is capable of identifying family members or important personal and
support ties  svms in particular seem to have
trouble making reasonable predictions  as such 
it remains unclear the extent to which standard

there are several concerns with the models presented here  first  it may well be that our features imperfectly captured the true nature of
the network  this is troubling  at the very
least model   measuring total tie communications should have helped discriminate between
important and unimportant ties  in fact  it did
show significant predictive power in the logistic
regression  nevertheless  it did not help discriminate among observations in the test set 
it may well be that our modeling strategy
failed to capture ego level heterogeneity in communication  people with radically different volumes of communication may have confused the
 

fisame family
rmse
logistic  m  
      
logistic  m  
      
logistic  m  
      
svm rbf  m  
      
svm rbf  m  
      
svm rbf  m  
      
svm sigmoid  m         
svm sigmoid  m         
svm sigmoid  m         
first call
rmse
logistic  m  
      
logistic  m  
      
logistic  m  
      
svm rbf  m  
      
svm rbf  m  
      
svm rbf  m  
      
svm sigmoid  m         
svm sigmoid  m         
svm sigmoid  m         

    unanticipated lapses in cell phone service  etc 

recall
      
      
      
 
 
 
 
 
 

   extend to analysis of exogenous shocks to
other social networks such as twitter  facebook  or linkedin     

references
    joshua blumenstock  nathan eagle  and
marcel fafchamps  risk and reciprocity
over the mobile phone network  evidence
from rwanda       

recall
 
 
 
 
 
 
 
 
 

    chih chung chang and chih jen lin  libsvm  a library for support vector machines 
acm transactions on intelligent systems
and technology                        
    nathan eagle  alex sandy pentland  and
david lazer  inferring friendship network
structure by using mobile phone data  proceedings of the national academy of sciences of the united states of america 
                sep      

table    rmse and recall of full models

    mark s  granovetter 
the strength of
weak ties  american journal of sociology 
                     

network measures of tie importance are effective 
further research could further improve on our
methods  and might include the following tasks 

    jayson j  jia and jianmin jia  tie importance and social network embeddedness re   implement svms on a larger subsample of
vealed by earthquake       
the dataset
   explore alternate estimation processes  per      jure leskovec and andrej krevl  snap
datasets  stanford large network dataset
haps moving to hadoop mapreduce to alcollection       
low us to process both the volume of data
and an extended set of features 
    a  craig mackinlay  event studies in economics and finance  journal of economic
   extend analysis to other exogenous shocks
literature                   
to cell phone communications  such as other
natural disasters      surprise financial news 
true
predicted  
 

 
     
  

 
   
  

table    confusion table  logistic  m   for
same family
 

fi