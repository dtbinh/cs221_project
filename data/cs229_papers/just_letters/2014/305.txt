p r e d i c t i n g h o s p i ta l
readmissions in the
m e d i c a r e p o p u l at i o n
sajid zaidi 

 

introduction

avoidable hospital readmissions cost taxpayers billions of dollars each year 
the medicare payment advisory commission has estimated that almost
    billion is spent annually by medicare on potentially preventable readmissions within    days of a patients discharge from a hospital      the
medicare program has begun to apply financial penalties to hospitals that
have excessive risk adjusted readmission rates  there is much interest in
the health policy and medical communities in the ability to accurately predict which patients are at high risk of being readmitted  not only are there
strong financial reasons to avoid readmissions  readmission to the hospital
can be a sign of poor clinical care and can indicate a worsening of a patients
condition      if doctors and nurses were aware of which patients were at
highest risk  they could focus their efforts on these patients and could improve coordination of care with post acute providers and family physicians 
there has been some interest in this problem in the machine learning community as well  the heritage health competition was a predictive modeling competition with the objective of predicting hospital readmissions  with
a    million cash prize  however  the dataset used for that competition was
highly de identified and thus was missing much of the key information useful for predictions  it also had a low number of patients who were generally
healthy    in this paper  i will apply machine learning methods to a dataset
of medicare claims to predict which patients are at a high risk of being readmitted to the hospital  i will then compare my results to the performance of
risk adjustment models currently used by the medicare program to predict
readmissions 

 

dataset

i use a dataset consisting of all medicare claims for the year       medicare
is the government health insurance program for seniors over    years of age 
and a claim is evidence of a health care service that contains information on
  szaidi stanford edu
  this is likely why no team was able to surpass the performance threshold to claim the grand
prize

 

fifeatures and preprocessing
diagnoses and procedures performed on a given date  i take all inpatient
hospital claims during       and construct indicators for whether or not
the patient was readmitted to any hospital within    days  this is the same
definition that medicare uses for its financial penalties   each observation
is thus a patients hospital stay  this dataset has           observations 
however  this is too large for the computing resources i have available  so
i took a    random sample  resulting in a dataset of          observations 
      of the observations have a readmission 

 

features and preprocessing

this is a classification problem  where the positive class is the       of patients who are readmitted  i construct features using the hierarchical condition model  hcc model   this is a standard classification of diagnoses
and illnesses used in medical research     for each patient  i take all the
claims occurring in the   months prior to the hospital admission and use
these claims to construct binary variables that indicate whether a patient
has a given condition  i also include demographic data such as the patients
age and gender  and whether the patient is enrolled in medicaid  or is institutionalized in a nursing home  it is important to note that all the features i
construct use information available at the time of admission to the hospital 
so the model could be used to make real time predictions while the patient
is in her initial hospital stay  after this preprocessing  i have    features 
i reserve a random     sample of the data as a pristine test set  i will
only use this test set at the end to compare my models performance to that
of models in the literature  i split the data using stratified random sampling 
to ensure that the training and test sets have the same proportion of positive
classes 

 

models

i will use five different machine learning algorithms  all these models will
be trained on the     training set 
logistic  the first is l  regularized logistic regression  i will use   fold cross validation in order to determine the penalty parameter 
gbm  the second algorithm i will use is gradient boosting with logistic
regression  i tune some of the hyperparameters  such as the number of
models in the ensemble  using   fold cross validation 
randomforest  the third algorithm i will use is the random forest
algorithm     this is an ensemble learner that constructs a series of decision
trees and averages the results 
svm  the fourth algorithm i will use is l  regularized svm with a linear
kernel  the data is too large to use a kernel on my computing hardware 
and since almost all my features are binary indicators  a kernel may be less
useful in any case  to determine the c penalty parameter  i use the heuristic
c function available in the liblinear package 
ensemble  finally  i will construct my own ensemble learner  i will use
logistic regression to combine the predictions of the previous four models 

  a health care program for the poor

 

firesults and discussion

 

the features in this logistic regression are the predictions output by the
other four models 
i will report three performance metrics  f  score  area under the receiver
operating characteric curve  auroc   and the classification error  auroc
will not be calculated for svm since it is not probabilistic  for the other
  methods  to determine classification for the f  score and classification
error  for each model i will use the probability threshold that maximizes
the f  score on the training dataset  in other words  i will not use a    
probability threshold to predict a positive class  but rather i will do a grid
search to find the threshold that maximizes f  on the training set  of course 
the same threshold will be used for prediction on the test set  i use this
method because i have skewed classes  and f  score is the objective i want
to maximize 

 

results and discussion

the following table presents the results from these algorithms 
table    performance of learning algorithms

model
gbm
random forest
l  regularized logistic
svm
ensemble

training
f 
      
      
      
      
      

test
f 
      
      
      
      
      

training
auroc
      
      
      

test
auroc
      
      
      

      

      

training
error
      
      
      
      
      

in general  these models have performed poorly  gbm  logistic regression  and svm do not seem to have overfit the data  since their test set
performance is almost exactly the same as their training set performance 
this indicates that these models have high bias  and future efforts should
focus on feature engineering  random forest  on the other hand  seems
to have overfit the training data by quite a bit  as evidenced by the difference in performance between the training and test sets  in the future  i
would try lowering the number of decision trees used by the algorithm  and
perhaps determine that hyperparameter through cross validation  the ensemble learner also overfit  but that is certainly due to the random forest
predictions 
one notices that the classification error for logistic regression and gradient
boosted logistic regression is around      even though positive values are
only     of the data  this may seem strange  but this occurs because i
did not use a probability threshold of      instead  i used the threshold
that maximized f  score  which happens to be around       in effect  i
lowered the probability threshold to increase recall  at the cost of somewhat
lowering the precision  this has the effect of worsening the classification
error  however  i believe f  score is more useful in the case of skewed
classes  so i think the tradeoff is worth making 
comparing my results to the literature  horwitz et al     developed the official readmissions prediction model that is used by medicare to determine
each hospitals financial penalty  medicare uses the model to calculate each
hospitals excess readmission rate over and above the rate predicted by the

test
error
      
      
      
      
      

ficonclusions and future work
model   they developed   different models  for   different medical conditions  and they report area under the roc curve ranging from      to      
my results are very close to that range  albeit the bottom of the range  they
do not report any other performance metrics 

 

conclusions and future work

there is a lot of work that can be done in the future  based on the lack of
overfitting for most of my models  it seems the most promising avenue is to
construct more features using the claims data  such as indicators for prior
hospitalizations or more fine grained diagnosis features  the claims data is
very rich  and there are enormous possibilities for the features that could be
constructed  if clinical notes and text data from electronic medical records
were added to the mix  the feature space could become very large  since
this is an area with an enormous amount of data and a vast feature space 
new approaches such as deep learning may be valuable 
finally  the fact that my models have performed poorly  and yet still come
very close to the performance of the official medicare model  raises questions about the accuracy of the prediction models used by the federal government  these models are used to calculate over    billion in financial
penalties to american hospitals  so this is certainly an area of immense policy importance where machine learning experts can contribute a lot  up to
this point  most work in the health policy community has focused on using
single logistic regressions  if the entire toolbox of machine learning were
applied to this problem  i am sure that we could achieve far better performance than the current state of the art  i hope this paper has contributed to
that effort 

references
    medpac  promoting greater efficiency in medicare  june      report to
congress   www medpac gov       
    mohsen bayati  mark braverman  michael gillam  karen mack  george
ruiz  mark smith  and eric horvitz  data driven decisions for reducing
readmissions for heart failure  general methodology and case study 
plos  one       
    gregory pope et al  evaluation of the cms hcc risk adjustment model 
centers for medicare and medicaid services       
    andy liaw and matthew wiener  classification and regression by randomforest  r news                  
    leora horwitz et al  hospital wide all cause unplanned readmission
measure  final technical report  centers for medicare and medicaid services  
     

 

fi