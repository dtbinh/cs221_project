  

automated music track generation
louis eugene

guillaume rostaing

stanford university
leugene stanford edu

stanford university
rostaing stanford edu

abstract  this paper aims at presenting our method
to generate drum tracks to accompany guitar tracks 
our approach was to work on songs in the midi
format  separate them into several segments and
then design our own features for the input guitar
tracks as well as for the output drum tracks  we
performed clustering algorithms  k means  mixture
of gaussian  dbscan  as well as k nn to group
similar guitar tracks from the training set  our main
hypothesis was that guitar tracks that are close to
each other might have close drum tracks as well 
after assigning a test input to a cluster or set of
neighbors  we generated a new drum track by
randomly picking it in a specified group of existing
drum tracks from the training set  this method has
allowed us to obtain very good acoustic results 




in the end  we obtained      midi files which
constituted our data set  to read the midi format in
matlab  we used an existing library  midi toolbox  see
      which allowed us to represent our music segments
by matrices  see   c  

  features
one of the most important part of the project
was to design and choose our features  we tried to
determine the most relevant features to perform our task
by looking at the melodic and rhythmic behavior of our
segments  our goal was to find what features
characterize the style of each music segment and
which correlations exist between the different
instruments  for example when the guitar plays a metal
riff  drums are often fast with a lot of notes while when
the guitar plays a solo  drums tend to fade  

introduction
wouldnt the possibility to create a whole song
from a single instrument track be terrific  if it is
currently possible to add some computerized drum
loops to accompany a guitar track  one can realize a
good result is often hard to achieve due to the huge
amount of different loops available  many of them being
a poor fit to the original track 

a  guitar features

our goal in this project is  given a guitar track 
to find the best possible drum track to accompany it  in
order to cover the largest possible scope of situations 
we are training our algorithms on a wide range of songs
from different but close genres  mostly poprock rock metal songs  our model is thus in its current
state more intended to support applications in these
musical genres 

we currently use the    following features 
 the number of notes
 the tempo
 the mean  max  min and standard deviation of the
duration of the notes
 the mean  max  standard deviation of time
intervals between two notes
 the number of different musical intervals  the
mean  max and standard deviation of musical
intervals
 the percentage of chords  number of different
pitches and percentage of pitches different from the
fundamental 

  dataset
representing music on a computer can be done in
different ways  we personally decided to work on
notational music  i e  on the information contained in
music scores  we built our own data set in the following
way 



b  drum features target representation 

we downloaded     free guitar pro tabs
we worked on the tabs to remove every tracks
except the guitar and drum tracks

we aim at generating drum tracks  as a drum
track is not a real mathematical value  we had to

   
  

we exported the tabs in the midi format
we segmented the     songs in parts of exactly   
beats

fi  
engineer features like we did for the guitar track to
work on it  we chose    features 
 the number of drum ticks  notes 
 the tempo
 the mean  max  standard deviation of time
intervals between two notes
 the number and proportion of appearance of pedal
hi hat  acoustic snare and acoustic bass drum which
are the three staples elements amongst a drum
track 
c 

applications with noise  it is a data clustering
algorithm using the notion of density reachability 
dbscan works with two parameters  a distance  and
a minimum number of points required to form a dense
region  minpts   the principle is as follow  for each
point of the dataset  we retrieve the  neighborhood  all
points within distance   and check if the number of
points is greater than minpts  if it is the case  we start a
cluster and extend it to all the points  reachable from
the cluster  otherwise  we label as noise  the point
might later be found in a sufficiently sized environment of a different point and hence be made part
of a cluster  

extraction

to get the features from the midi files we first
used the function readmidi java which loads the
information contained in the midi file in a n by   matrix
with n the number of all the notes  a line is a note  and
the column corresponding to the onset time  in beats  
the duration of the note  in beats   the midi channel
 integer between   and     traditionally   for the guitar
and    for the drum   the midi pitch  the conversion of
the pitch and octave in an integer  see       the velocity 
the onset time  in sec  and the duration of the note  in
sec   using the function getmidich  we split the matrix
in two matrices corresponding to the two channels
 guitar and drum   we worked on the separate matrices
to obtain the features  from the guitar matrix  and the
targets  from the drum matrix   we only extracted the
features of the segments in which the two channels were
present  finally  we normalized the features between  
and   in order to calculate norms with no flaws 

b  music generation
we explored different technics to generate a
drum track  given a new input  we assigned its closest
clusters in the feature  guitar  space using k means 
dbscan or mixture of gaussians or we fetched the
nearest neighbors with k nn  we then explored
different ideas to actually output a drum track  based on
the hypothesis that for a group of similar guitar tracks 
the drum tracks should be close to each other as well 
 we picked a drum track within the cluster or
neighbors and assigned it to the test vector
 we performed k means in the target  drum 
space on the training set  determining the
major drum cluster within a guitar cluster or
set of neighbors  correlation  and then picking
up a random drum in the drum cluster
 based on the mean drum values within the
cluster set of neighbors  we can also think of
randomly generating a track  which satisfy
theses values  however we did not implement
this method as we think it is hard to generate a
computerized battery track and more research
is required to build from scratch a drum track
which sounds as good as a real track 
we then merged the two notes matrix in a new midi
file  processing this way  we get a new segment ready
to be played in a music player 

  model
a  algorithms
the purpose of our work is to generate drums that
can accompany guitars in an efficient way  machine
learning helps us go over thousands of famous songs to
figure out what kind of patterns make different
instruments fit together  because music is a subjective
field and there are no labels to describe music
segments  we had to use unsupervised algortithms  we
worked with  linear regression  k means  k nearest
neighbors  k nn   mixture of gaussians and dbscan 
linear regression performed very poorly thus we
abandoned it early  while k means splits our data set in
k clusters in which each observation belongs to the
cluster with the nearest mean  k nn gives for each point
its k closest neighbors in the feature space  dbscan
stands for density based spatial clustering of

  results
because we dont have any labels  it is hard to
figure out how good our algorithms and choices of
features are  to measure the relevance of our different
clusters set  we implemented our own metrics 

   
  

fi  
metric    we decided to implement a function giving
the standard deviation of the values of the features in
each cluster set of neighbors  we then compared these
values to the standard deviations of the entire training
set to get percentages       if equal   it works both for
guitar features and drums features 

a  features validation
to check the relevance of the features and to
sort them by order of importance  we used our metric  
 standard deviations  for each algorithm in the different
clusters set generated  in other words  we tried to figure
out which features were more homogeneous in the
clusters set and thus more characteristics of a cluster 
to get an insight  we preceded using backward feature
selection  we removed one feature at a time  computed
our different algorithms and compared the standards
deviation of the guitar features in the different
clusters set with n features and n   features  a
percentage over      means that the feature is relevant
 removing it resulted in an increased dispersion  

metric    for each elements  we calculated the average
euclidian distances in the feature space between our
segment and every other segments in its the cluster set 

the guitar features are respectively  number of
notes      note duration mean      duration standard
deviation  std       duration max      duration min     
number of different intervals      mean of the intervals
     intervals std      interval max      time interval
between   notes  time  mean       time std       time
max       tempo       chords percentage       number
of different pitches       percentage of pitches different
from the fundamental      

metric    to have a sense of how good our drums
generation are  we computed the euclidian distance in
the drum space between the generated drums and the
original drums 

in addition to the standard deviations of the
different segments in each clusters set in the guitar
feature space  we also calculated the standard deviations
of the different segments in the drum feature space 
in the drum space  the features are respectively 
number of ticks      proportion of hi hat      proportion
of acoustic snare      proportion of acoustic bass drum
     number of hit hat      number of acoustic snare     
number of acoustic bass drum      time interval between
  ticks  time  mean      time standard deviation     
time max       tempo      

   
  

fi  
we also implemented backward feature selection
with our metric    we generated drums without one of
the guitar features and computed the distances to the
original drums 

for k means  as the number of clusters is increased  the
deviation value decreases which is logical as clusters of
fewer points are more representative of local structures 
however  the computation time increases  we decided
that a good trade off was to select    clusters  we did
the same for the mixture of gaussian 

finally  we computed the mean standard
deviation of all the features in the clusters sets over the
mean standard deviation in the whole training set for the
  algorithms to know which features were more
characteristic of a cluster set and know which features
were the best to discriminate between the segments 

for k nn  as the number of neighbors is
increased the mean standard deviation increases  more
dispersion  which is logical as we consider higher sets
of points less representative of local structures  we
determined that    neighbors was a reasonable choice 
for dbscan  we ended up with a distance of     and a
number of points minimum to form a cluster of   
once we had a good choice of parameters  we used
our metric   to compare the relevance of the different
algorithms  we calculated the distances between each
point and their neighbors other points of clusters  both
in the guitar space and the drums space  the following
graphs give these distances  ordered and with an
indication at a distance of     

b  parameters selection
in order to determine the right parameters to
use in our algorithms  that is to say the number of
clusters for k means  the number of neighbors for knn  the minimal distance number of points for
dbscan  we trained our algorithms several times with
different parameters and then computed  with method   
the mean standard deviation of all the features in all the
clusters sets of points 

   
  

guitars  kmeans

guitars   dbscan

drums  kmeans

drums  dbscan

fi  
c 

drum generation results

merging the results  however this doesnt give much
consistency in the progression of drums  we can think
of implementing hidden markov models   kalman
filters to have a smooth transition of drums sequences
 the goal is to estimate what the drums should be based
on the previous drums segments and merge the result
with the actual drum generation from our algorithms  

we ran through our entire dataset and
generated multiple times different drums for each
segment and each algorithm  we then used our metric  
to compare the distances between the generated drums
and original drums  we found 
dbscan  x         
kmean  o         
knn            

all of our work has been focused on generating
drums for guitar segments but we would like to adapt
our algorithms to other combination of tracks  bass
from guitar  guitar from drums  etc

here is the detail  feature by feature 

we currently use midi files for our algorithms  our
goal is to be able to generate drums based on a real
guitar recording  we started to implement an algorithm
able to convert a  wav into a  mid but the results are
imperfect for now  our algorithm is able to efficiently
recover the general pitch of a sound but we are still
unable to tell if it is a chord or a single note and we
have trouble in finding the correct starting time and
ending time of the different notes  because our features
depend heavily on the times intervals  our generation of
drums from  wav are still imperfect 
finally  if we can solve the previous problems  we
would like to write our algorithms in objective c and
java in order to make a mobile application offer our
work to the world and make musicians happy 

  conclusion

references

the results presented in the previous section
have been mostly used to discriminate between the
different algorithms but do not and cannot really
provide a deep insight in the actual result  i e  the
acoustic output of a generated track  in some cases  the
drum generated is pretty close to the original drum and
the result is excellent to hear  but sometimes  the drum
sounds quite differently and yet  the acoustic output is
also very good even if it differs from the original song 
in fact  trying to generate music is inherently subjective
and it is extremely hard to create accurate metrics  that
is why we mainly used ours to classify the algorithms
and restrained ourselves from creating an absolute
training and test error that we could have done by
taking the mean of the targets values for a cluster or set
of neighbors 

    eerola tuomas and toiviainen petri  midi
toolbox  matlab tools for music research 
university of jyvskyl 
www jyu fi musica miditoolbox        
    http   www tonalsoft com pub news pitchbend aspx

  future work
we currently generate drums for guitar segments of
   beats  we already implemented a function to
generate drums for an entire song by sub segmenting
the song  generating drums segment by segment and

   
  

fi