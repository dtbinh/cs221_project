 moralmachines  developing a crowdsourced moral framework for
autonomous vehicle decisions
tara balakrishnan
taragb stanford edu

jenny chen
jchen   stanford edu

abstract with the advent of artificial intelligence algorithms  computer systems are capable of making decisions
independent of human control  it is therefore important for
computers to have a moral framework that dictates their
response to a particular action or situation  in this paper  we
investigate the following questions  given an ethical dilemma 
can we build a crowdsourced moral framework  can our
trained model provide a response that mimics human behavior
and judgment with high accuracy  what features impact an
individuals moral decision when faced with an ethical dilemma 
we address these questions via a modified trolley problem  a
common ethical thought experiment   placed in the context of
autonomous vehicles  we survey approximately     students to
determine the most statistically significant course of action for
each of the     posed scenarios  we then utilize feature selection
to determine the most relevant features  and model selection
techniques to find the most accurate classifier for the given
survey data  we are able to accurately reflect popular moral
judgment in        of trolley problem scenarios using  in best
case  an svm classifier  we thus determine that the framework
developed by our model is successful and is  infact  a hybrid of
the standard utilitarian and care ethics frameworks 

i  background
a  motivation
as we begin to create machines that have the ability to
make decisions  it is imperative to consider the ramifications 
especially when a human life is at risk  giving a machine
responsibility also requires giving it an ethical framework
within which it can act  no such models currently exist 
because of the difficulties inherent in generalizing a concept
as difficult to define as morality  as such  we decided to
crowdsource a moral framework by polling responses from
a large audience  and using statistical learning to teach a
model to generalize a populations ethical standards 
previous research in moral decision making notes the
difficulties in accruing accurate ethical statements from individuals  often because such decisions can be motivated by a
number of hidden factors  the research therefore highlights
the success of simple standard ethical experiments  singerclark   we chose to use the trolley problem  a famous
thought experiment  as our basis for studying ethical dilemmas  the basic form of the problem forces individuals to
choose between allowing a rogue trolley to kill five people
standing in its path  or pulling lever to divert the trolley onto
a side path  thereby killing only one person who was standing
in the alternate path 
b  our problem
we converted the trolley problem into one that is more relatable to the modern day dilemmas surrounding autonomous

tulsee doshi
tdoshi stanford edu

vehicle ethics  in this modified problem  we pose individuals
with the choice of saving their own car or saving the other
car  in the case of an on coming accident between two
vehicles  though accidents are often complex  we simplify
the problem to the binary case of being able to definitively
save only one car  in the question  we provide subjects with
a number of facts or demographic information regarding
the occupants of each car  the demographic information
provided was selected based upon their relevance in the
context of deontological  care ethics  and utilitarian moral
frameworks  these facts include the number of people in the
cars  their ages  occupations  stages in life  and relationships
 or lack thereof  with the individual making the choice 
based on this information  the individual must determine
what the moral decision should be we limit the infinite
scopes of the facts in the problem by allowing the people
in each car to have only one of   occupations    stages in
life  and   possible relationships to the individual 
c  past work
there has been much discussion about machine morality 
yet very little successful and concrete implementation of
ideas  especially with regards to machine learning  previous
similar studies have discussed operational morality   purely
rule based systems  wallach   statistical implementations are
sparse  with a few studies regarding medical ethics and
euthanasia showcasing promising results for medical robots
 wallach  
there are many previous works that describe crowdsourced machine learning techniques and how to handle
the presence of noisy labels  these works have determined
nuanced methods to use maximum likelihood to eliminate
biased voters and therefore better select the gold standard
response from a number of survey responses  they also
discuss majority voting  selecting the response with the
greatest number of votes as correct  as a viable baseline
method when faced with a limited number of voters  or
survey responders   donmez  
ii  data s et
a  the survey
as previously mentioned  our goal was to use crowdsourced data to statistically learn a moral framework  because we created a novel question and set of inputs and
outputs  we were required to self generate the data in the
form of an online survey 

fiwe created a corpus of     questions  each with at least
one value for each of the features described  an example
survey question is below 
your car contains  you and your best friend  who is also
your age the other car contains  nine    year olds  one of
whom is your brother  and their    year old teacher who
you have met before what should your car do  save your
car save the other car
in order to constrain our data to a reasonable pool 
the survey was limited to the context of stanford  and
was distributed to     students  these students covered
a wide spectrum of diversity with regard to class year 
major  ethnicity  and religion  each student was randomly
presented    of the     questions  thus  each question
received approximately       responses 
b  features
in order to convert the survey questions into feature
vectors  we mapped the occupancy of each car to a set of
features  for each question  we created a    dimensional
feature space with the first    features corresponding to the
first car  and the second    to the second  the set of features
included the following values 
   number of people in each car
   minimum  average  and maximum ages of people in each
car
and binary values    or    for the presence of each type of
the following 
   occupations of people in each car  president  teacher 
terrorist  student  retired  or none 
   stages of life of people in each car   child  adult  parent 
single parent  elderly  or none 
   connections to decision maker of people in each car 
 self  child of  immediate family  extended family  friend 
acquaintance  or none 
the majority response from students for each survey
question has been selected as the gold standard response 
and used as the correct value  in other words  for a particular
feature vector  the y value is represented as   if the majority
of respondents deemed that the other car should be saved 
and a   if a majority of respondents deemed that their cars
should be saved 
iii  m ethods
a  cross validation
we selected the models to optimise further by finding
the baseline models with the lowest test errors using cross
validation  to apply cross validation techniques we split the
training data into   sets of    random examples  we first determined a single generalization error by training the model
on   sets and then testing on the remaining single hold out
set  because our data set is incredibly small      examples  
we let our test error equal the average generalization error
for each baseline model after running cross validation across
all training sets and hold out set permutations 

b  model selection
the first step of building a moral framework entailed
selecting the most appropriate model  ie  that with the lowest
training error   we note that our problem is one of binary
classification  and are feature vectors are high dimensional
and sparse  with mostly binary features  thus  we selected
the following three techniques to attempt classification  l regularized svm  logistic regression  and bernoulli naive
bayes  all models were implemented using sci kit 
in addition  we tried each model both on the data as it
was collected and after each feature vector was standardized
to be gaussian with zero mean and unit variance  because
most of our features were binary  the features for age and
number of passengers in the car could have been a larger
role in weighting the eventual decisions  simply because of
their larger size  normalizing the vector had the potential to
reduce this bias 
   the svm  the svm is a standard choice for classification problems  because it is known to be one of the
best models for supervised learning  we chose to penalize
the svm with the l  norm in order to account for the high
likelihood of having non linearly separable data  given that
the data was crowdsourced and potentially erroneous 
furthermore  with potentially non linearly separable data
in mind  we start with a baseline radial basis function
 rbf  kernel  this is because the rbf kernel  unlike the
linear kernel  maps the features to a non linear higherdimensional space  the rbf kernel references the following
equation 
 
k x  x      exp  kx  x  k  
with our rbf kernel  we started with the recommended
baseline c value of     and gamma value of


 
       
number of f eatures
 sci kit  
because the two parameters that must be experimented
with are c and gamma  we implemented the svm while
varying each of these parameters in order to fine tune and
find the most accurate choice 
   logistic regression  logistic regression is the most
common discriminative algorithm choice for supervised
learning classification because of its ease to implement and
reasonable accuracy  logistic regression allows us to take
a non linear problem and classify it in a linear form  for
logistic regression  we experimented with both l  and l 
penalization  and for each  with the c  cost  value  we note
that the difference between the two penalizations can be seen
with regard to the vector w  the baseline selected was l 
penalization with c        sci kit   l  penalization 
n
x
minw c kwk   c
 log exp yi  xit w   c        
i  

vs  l  penalization 
minw c wt w   c

n
x
i  

 log exp yi  xit w   c        

fi   bernoulli naive bayes  because    of our    features
are binary  we also attempt a bernoulli naive bayes model
in which the features that are not binary are given the value
of    this model could theoretically lead to accurate results
in cases where the average age or number of individuals in
the car hold little relevance  we note that bernoulli naive
bayes is a generative algorithm  and therefore utilizes the
probability that a particular feature will be   or   to conduct
classification 

a bound  logistic regression applies discriminative analysis 
thus  with    features  the svm creates a bound that is strict
and potential overfitting  logistic regression is more likely to
achieve success  we also note that normalization positively
benefits both the svm and logistic regression models  but
it has enormous effect on svm  this is because the svm
model is not inherently scale invariant  thus  modeling the
feature vector around the gaussian served as an equalizer
among the features 

p  xi  y    p  i y xi       p  i y      xi  
 sci kit  
c  feature selection
in order to minimize the risk of overfitting  it is necessary
for the number of training examples to be  than the
number of features  however  our feature vector is of size
   whereas we are training on sets of only     examples 
which is not significantly greater than     therefore in order
to improve the performance of our models on the hold out or
test sets  we implemented recursive feature elimination using
our baseline svm model to reduce the size of our feature
vector  recursive feature elimination  rfe  uses backward
search to recursively consider smaller and smaller sets of
features until a desired number of features is reached  the
svm model used in rfe assigns weights to features  which
rfe then consults with to recursively prune the features with
the smallest weights  from the desired feature set  sci kit  
the features with smaller weights are ones that are generally
redundant  conflicting  or lead to overfitting  to determine the
desired number of features  we iteratively implemented rfe
over all possible desired numbers of features    to     and
computed the number of features which returned the lowest
error 
d  continuous regression
because we used majority voting to determine our goldstandard  our labels were inherently noisy and didnt take into
account the distribution of people who chose a particular
answer  in order to account for the fact that not all users
chose a single label on each example  we trained a baseline
svm continuous regression model to predict the likelihood
that humans choose a particular answer  this model is helpful
in conducting error analysis on the questions which the
binary models predicted incorrectly 

fig    

model versus generalization error for baseline parameters

b  modfications to the model
as mentioned in the methods  in order to improve our
models  we tested our training data with various variations
of c and gamma for the svm model  and penalizations
and c values for logistic regression  because naive bayes
performed significantly worse than the other two models 
we decided to forego further testing on it  the figures below
 fig     fig     showcase the effects of various combinations
of c and gamma and c and penalty norm on the models in
question  we see that c     and gamma        lead to the
lowest training error for an svm with dimension     with
logistic regression  we see that l  regularization and a c  
    lead to the largest result  thus  l  regularization provides
the right amount of penalty  and a small c is necessary so
that there exists flexibility in the bound 

iv  r esults and d iscussion
a  baseline
for the three tested models  we present a table and graph
 fig     with the averages of the generalization errors across
each held out set of    examples before and after normalization  as can be seen below  all three models achieve an
accuracy that is      and therefore better than random 
logistic regression  post normalization  achieves the lowest
error of      in fact  logistic regression appears to work
better than svm both before and after normalization  we
hypothesize that this is the case because while svm creates

fig    

effects of c and gamma on svm rbf kernel

fihighest importance are ones immediate family and children 
at the same time  retired individuals and terrorists  despite
their family relation  are downweighted while the president
is upweighted  when considering the greater good 
table i
s elected f eatures

fig    

effects of c and penalty norm on logistic regression

features   car  
ones child
immediate family
acquaintance
retired individual

features   car 
ones child
immediate family
terrorist
president

c  feature selection

d  final results

also as discussed in the methods  to reduce overfitting and
improve our models  we enabled recursive feature elimination  this process further served to help us understand
the features that held the most importance in our model
and  therefore  were the most valuable when making ethical
decisions 
the following graph  fig     showcases how reducing the
number of features affects the generalization error for each of
the   models we attempted  we see that  as predicted  while
an extremely low number of features leads to underfitting 
less than    features does  in all   cases  produce a lower
error  for the svm  the lowest error occurs with    features 
with logistic regression  it occurs with    

our final results  shown in the graph below  fig     
showcase the success rates found for the most optimized
svm and logistic regression models  with the ideal number
of features  we see that both examples have success rates
greater than      with the svm performing the best  logistic regression has an       success rate  while the svm
has an       success rate 

fig    

final models

e  error analysis

fig    

number of features versus generalization error

we took this understanding further  and realized that an
svm tested and trained with    features would potentially
require a lower c value  ie  that of       thus  it would
be possible that a smaller feature vector and a stricter c
could actually train a more accurate model that would have
been previously missed because it overfit on    features 
trial and error showcased that this hypothesis was  in fact 
correct  training an svm with c       and gamma        
with an   feature vector leads to the overall lowest training
error of      these selected   features  listed to the right 
reflect the importance of family values and social good  of

the vast majority of errors came from examples with
noisy labels where there was an equal  or close to equal 
number of people for and against saving your car  if more
people had answered that example question then it is possible
that the majority label would have been the opposite of
our gold standard  since humans themselves were unable
to come to a consensus regarding these questions  it is likely
that the model would have also had trouble determining an
answer  either the example contained conflicting features or
no features that correspond to the feature vector  conflicting
features refer to the presence of multiple features which
have the opposite effect on classifying the example  for
example  if you have your sister in your car  your car is
more likely to be saved  but if a terrorist is also in your
car  then your car is less likely to be saved than before 
an example with no features that occur in the recursively
determined feature vector is rare  but it exists due to the

fifact that we have a small data set  for example  if your car
contains one adult who is a stranger to you and the other car
contains five adults who are strangers to you  neither car has
feature which correspond to the feature vector  and the model
essentially makes a random guess in the binary classification
problem  using the svm continuous regression model  we
attempted to classify a decimal answer rather than a strict
binary   or    where a   represents saving your car and a  
represents saving the other car  the result of the continuous
regression model gives us a rough estimate of the certainty
with which the classifier chose to save either your car or
the other car  the distance of the classifiers result from    
gives us a certainty value  if the result is very close to    
then the model was extremely unsure about its choice  the
figure to the left graphs the certainty values for all examples
which were predicted incorrectly by our optimised svm
binary classifier  all values are under     which proposes
that our incorrect results are partially due to low certainty
and increased noise in the labels themselves 

fig    

certainty of incorrect svm predictions

v  c onclusions
overall  we see that while both the svm and l regularized logistic regression models are effective  an
svm with   features  c        and gamma         leads to
the highest accuracy with respect to predicting the majority
human choice for ethical action  use of continuous regression
also shows that the answers classified incorrectly by the
model are those with a low confidence score  indicating
that majority voting may be the culprit for an amount of
inaccuracy 
perhaps even more exciting  in conclusion  that crowdsourcing responses for a simple ethical question can indeed
build a stable  accurate  well predicting moral framework  in
fact  the moral framework is a hybrid of utilitarianism and
care ethics frameworks  a hybrid that makes sense because
it emphasizes a desire to protect ones immediate social circle
while still retaining caveats with respect to the greater good 
this duality can be seen in both feature selection and the
answers that the model provides to each individual question 
this result paves the way for considering crowdsourced
statistical learning as a feasible method for research in ma 

chine ethics  further  going forward  we should perhaps consider adopting a similar hybrid model as a basis for decisionmaking when considering human owned autonomous
vi  f uture w ork
though we were happy with the level of success of our
model  we would work to improve this success by accruing
more survey results  with a larger set of voters on each
question  we would apply an em algorithm  see  raykar
      in order to select a more appropriate answer as the
gold standard  especially in cases where the votes were close
to        the majority of our incorrectly classified answers  
raykar et  als research indicates that utilizing a maximumlikelihood approach to eliminate certain voter bias leads to
significantly less noisy labeling  and a more accurate overall
model 
furthermore  we chose to simplify our problem by creating
a virtual world in which we self determined a select list
of possible feature values  in extending this project further 
we would make the problem more realistic by allowing
for a wide range of possible feature values and using textprocessing to classify the values into particular groups  this
would allow for a more dynamic set of questions that
better capture real life scenarios  in fact  many of these
questions could be pulled directly from a database of accident
scenarios 
with the data we currently have  conditioning on ethnicity 
major  or religion could lead to interesting skews in the moral
framework learned  as well as the accuracy of the framework 
we would condition on these values to better understand the
differences in morality that accompany such social groups 
lastly  it would be interesting to apply the learned model
to other binary ethical dilemmas  such as those in medical
ethics with regards to patient life or death  it would also
be interesting to crowdsource data about other theoretical
problems  learn frameworks  and similarly compare them 
r eferences
    donmez  pinar  jaime carbonell  jeff schneider  et al  efficiently
learning the accuracy of labeling sources for selective sampling 
new york  ny  acm       carnegie mellon university  acm       
web  dec       
    raykar  vikas  shipeng yu  linda zhao  et al  learning from
crowds learning from crowds         n  pag  journal of machine
learning research  journal of machine learning research  apr       
web  dec       
    scikit learn  machine learning in python  pedregosa et al   jmlr    
pp                  
    singer clark  tyler  and    june    morality metrics on iterated
prisoners dilemma players   n d    n  pag  web 
    wallach  wendell  and colin allen  moral machine  teaching right
from wrong  new york  oxford up              web     dec       

fi