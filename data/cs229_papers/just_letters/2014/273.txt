analyzing vocal patterns to determine emotion
maisy wieman  andy sun
   introduction
the human voice is very versatile and carries a
multitude of emotions  emotion in speech carries
extra insight about human actions  through further
analysis  we can better understand the motives of
people  whether they are unhappy customers or
cheering fans  humans are easily able to determine
the emotion of a speaker  but the field of emotion
recognition through machine learning is an open
research area 
we begin our study of emotion in speech by
detecting one emotion  specifically  we investigate
the classification of anger in speech samples  in our
analysis of emotion  we start by delineating the data
used  we transition to discussing our methodology 
and through this analysis  we investigate the best
algorithms to select features that are relevant to
predicting emotion  we also consider multiple
machine learning models with which to classify
emotion 
   data
the stanford university linguistics department has
an emotional prosody and speech corpus that
contains many wav files of professional actors
reading dates and numbers in the following emotions 
happiness  anger  sadness  despair  and neutral  upon
receiving appropriate access permissions from the
stanford corpus ta  the data files can be accessed
from an online repository  each file stores a short
audio clip of a professional actor actress reading a
neutral word or phrase in a specific emotion  we also
recorded our own audio clips  these extra recordings
were intended to reduce variance  but the quality of
the recordings  as we are not professional voice
actors  might have introduced extra error to the data
set  approximately  of the     examples exhibited
anger 
   methodology
we want to determine whether or not an audio file
contains angry emotions  at a high level  each audio
file from the repository is processed and used to build
a feature vector with corresponding labels that are
either angry or not angry  after extracting features 
we implement feature selection algorithms to
determine the most relevant results  and apply
various models to the features with the highest
scores  to determine the testing and training error 
we use k fold cross validation  we use k   bins of   

examples each  for a total of     training examples
and    testing examples 
    feature extraction
the time domain representation of sound is very
complex  and in its original form  it does not provide
very good insight into key characteristics of the
signal  because of this characteristic of sound signals 
we map this time domain representation into more
telling features  the most straightforward technique
involves determining the average energy of the
signal  this metric  along with total energy in the
signal  indicates the volume of the speaker 
duration also offers insights into emotion  as do
statistics like the maximum  minimum  range  mean 
and standard deviation of both the signal and
spectrum  these may indicate fluctuations in the
volume or pitch that can be useful in determining
emotion  for both the signal and spectrum  we also
derive skewness  the measure of departure of
horizontal symmetry in the signal  and kurtosis  the
measure of height and sharpness of central peak 
relative to a standard bell curve 
we also process the signal in the frequency domain
through the  fast  fourier transform  we use
windowed samples to get accurate representations of
the frequency content of the signal at different points
in time  by taking the square value of the signal at
each window sample  we can derive the power
spectrum  we use the values of the power spectrum
as features  but we also find the frequencies that have
the greatest power  we obtain the three largest
frequency peaks for each window and add those to
the feature vector  in addition  we find the maximum
and minimum frequencies with substantial power for
each time frame  and use these values to determine
the frequency range for each frame  the auditory
spectrum can be derived by mapping the power
spectrum to an auditory frequency axis by combining
the fast fourier transform bins into equally spaced
intervals 
the mel frequency cepstrum captures characteristics
of the frequency of the signal represented on the mel
scale  which closely aligns to the nonlinear nature of
human hearing  by extension  the mel frequency
cepstrum coefficients  mfcc  represent the
spectrum of the spectrum  mfccs can be derived
by mapping the powers of the frequency spectrum
onto the mel scale  and then by taking the log of these

fipowers  followed by the discrete cosine transform 
mfccs are commonly used as features in many
speech recognition applications 
changes in pitch over time are measured on both a
coarse time scale and a fine time scale  for coarse
measurement  the signal is divided into   parts
 beginning  middle  and end   and the part of the
signal with the highest average pitch is used to
determine whether the pitch rises or falls over time 
for fine measurement  the dominant frequency of
each windowed sample is compared to the dominant
frequencies of the windowed samples immediately
preceding and following  this difference is recorded
in the feature vector 
    feature selection
after we processed the original sound signal to
extract features  the high variance of our algorithm
revealed that we needed to filter the many features to
determine which contribute most to the classifier 
our input speech signals were windowed  with
approximately    windows per audio sample  and
each of these windowed samples provided a total of
    features  in total  we extracted        features 
this large number of features  much larger than the
number of examples  resulted in a very high variance 
clearly  we needed to extract the most important
features  because of the large number of features  we
used heuristics to score each feature  rather than
implement a brute force forward or backward search 
we used three methods  mutual information 
principal
component
analysis 
and
binary
classification tree 
      mutual information  we discretized the
continuous feature values into    bins  these bins
spanned an equal range of values  but did not
necessarily contain the same number of examples 
after discretizing  we applied the formula for mutual
information given by 
       



      

             

     
     

the results with the highest values indicate the most
relevant features  we found that the most relevant
features were the kurtosis and skewness  in the
frequency domain   the locations of the frequency
peaks  and several power spectrum values 
      pca  we used principal component analysis
to transform the features into a new space represented
by a smaller number of dimensions  to prepare the
feature matrix for pca  we normalized it so that each

feature had zero mean and a variance of one  we
used the method described by song et al  to
determine feature selection  given by the following
formula 


      
  

where vpj represents the jth entry of the pth
eigenvector of the covariance matrix of pca  this
sums the contribution of each feature to the
eigenvectors corresponding to the m largest
eigenvalues  the resulting score was used to
determine which features were most heavily used in
the final  lower dimension pca representation  and
thus gives a good indication of which features are
most relevant  we also created a weighted pca
representation  in which we weighted each
eigenvectors contribution by the corresponding
eigenvalue  to reflect the relative importance of
each eigenvector 


         
  

these two methods produced relatively similar
results  which  surprisingly  indicated that the most
relevant features were solely power spectrum and
auditory spectrum values 
      decision tree  we applied a third method 
binary classification tree  to choose the best
features  matlabs binary classification tree tool box
internally uses the input data to form predictive
models using the optimal combination of possible
binary splits  binary splits at nodes are made based
on ginis diversity index  gdi   which is a measure
of impurity and is given by 
           


where the sum is over the classes i at the node  and
p i  is the observed fraction of classes with class i
that reach the node  a node with just one class  a
pure node  has a gini index    otherwise the gini
index is positive  by looking at the predictive tree
model matlab then creates  we can select the most
relevant features by observing the most important
nodes and slits used in the predictive model  the
most relevant features were mostly power spectrum
and auditory spectrum values  additionally  some
weight was placed on both the coarse and fine
frequency changes  and the skewness of the signal 

fifrom the aforementioned feature selection heuristics 
we have determined which features are likely most
relevant to emotion detection  the results of the
feature selection calculations are shown in table   
heuristic
mutual
information

pca
unweighted
pca
weighted
binary
decision
tree

most relevant features
kurtosis
skewness  in the frequency domain 
locations of the frequency peaks
power spectrum values
power spectrum values
auditory spectrum values
power spectrum values
auditory spectrum values
power spectrum values
auditory spectrum values
coarse and fine frequency changes
skewness of the signal

table    features with the highest scores for various
feature selection heuristics

   results and discussion
applying the features selected with the various
algorithms revealed that  with the right model  anger
in speech samples can be predicted with relative
accuracy  the results are summarized in table   
heuristic
mutual
information
pca
unweighted
pca
weighted

error
type
train
test
train
test
train
test

svm

glm

   
   
  
   
   
   

            
   
        
   

dec 
tree
  
  
  
  
  
  

table    performance of models with various feature
selection algorithms  numbers given represent the average
value as the number of features increases  the glm error
with features derived from mutual information has been
removed from the table because the error increased with the
number of features 

    svm
   models
in addition to finding the most relevant features  we
also sought to find the most relevant model  towards
that end  we implemented the following classification
models  support vector machine  generalized linear
model  specifically  logistic regression   and binary
decision tree  for each model  we ran the simulation
multiple times  with each simulation using a different
number of the most relevant features  the top feature 
the top two features  etc   we repeated this for each
feature selection method 
support vector machines  we used libsvms oneclass model with gaussian kernel to map training
vectors to a higher dimensional subspace  and find
the separating hyperplane with the largest margin in
this new space 

figure    error in svm model with mutual information
feature selection

generalized linear model  we used a generalized
linear model using a binomial distribution and the
logit link function form of a glm  logistic
regression  to iteratively determine a weight with
which to implement binary classification for each
example  the weight is used in the sigmoidal
hypothesis function 
binary classification tree  we used a binary
classification tree formed by taking in the most
relevant features  previously determined by mutual
information or pca  and creating a predictive model
based on binary splits and tree nodes that were
dominated by one class 

figure    error in svm model with unweighted pca
feature selection

fifigure    error in svm model with weighted pca feature
selection

figure    error in glm model with weighted pca feature
selection

for the svm model  we found that the features
selected by mutual information performed better 
asymptotically approaching an error of      as
opposed to     with pca selected features   the
model exhibits overfitting  and only the first    
features seem to contribute to the testing accuracy 

for the glm model  we found that the testing error
increases when using more than about    samples 
we saw the same results when using the features
selected by mutual information and the features
selected by pca  this indicates that  for the number
of examples that we have  there is a high variance for
even a small number of features  the performance of
the features selected by pca is much more erratic
than that of mutual information because matlabs
glm model reached the iteration limit for each
training attempt  which in turn was caused by the
similarity
in
features
chosen
by
pca
 multicollinearity decreases convergence  

    glm

    binary decision tree

figure    error in glm model with mutual information
feature selection

figure    error in binary decision tree model with mutual
information feature selection

figure    error in glm model with unweighted pca
feature selection

fiin conclusion  the binary decision tree outperformed
the other two models  matlabs binary decision tree
is able to determine the most relevant features as well
as predict  but to reduce time  the mutual information
of the features can be calculated  and the top results
of this calculation can be used by the binary decision
tree for prediction 

figure    error in binary decision tree model with
unweighted pca feature selection

figure    error in binary decision tree model with
weighted pca feature selection

for the binary classification tree model  we found
that the features selected by mutual information
performed better  asymptotically approaching an
error of     as opposed to    with pca selected
features   the optimal method used by the binary
decision tree to split the examples at each node
resulted in a much lower error than for either of the
other two models 
the results for both pca methods of feature
selection were quite similar  weighting by the
eigenvalues did not significantly change which
features were most relevant  nor did it improve
performance  both feature selection methods of pca
resulted in higher error than selecting features via
mutual information 
for all feature selection methods and models  we
encountered a high variance  this likely occurred
because of the large number of features and the
relatively small number of examples  this might
explain why performance either plateaus or degrades
after adding a certain number of features for all
models 

   future work
in the future  we would seek to expand the number of
examples by obtaining a larger set of emotionally
labeled  professional voice recordings  this could
decrease the variance in our results  in addition  there
are many nuances of each model and feature that we
could seek to optimize  one of these nuances that we
hope to investigate is the performance of mutual
information in feature selection when the features
take on continuous values  in this paper  we
discretized the continuous features into an arbitrary
number of discrete bins  however  this could pose an
interesting problem on its own  how does the number
of bins affect the scores of different features  and
how can we optimally divide features into discrete
sets  we also hope to expand to use a multi class
model in order to distinguish between a more diverse
set of emotions  such models include multi class
svm  neural networks  and multinomial logistic
regression 

   references
    liberman  mark  et al  emotional prosody speech
and transcripts ldc    s    web download 
philadelphia  linguistic data consortium       
    ellis  daniel p  w   plp and rasta  and
mfcc  and inversion  in matlabusing melfcc m and
invmelfcc m   plp and rasta  and mfcc  and
inversion  in matlab using melfcc m and
invmelfcc m    jan        web 
 http   labrosa ee columbia edu matlab rastamat   
    fengxi song  zhongwei guo  dayong mei 
 feature selection using principal component
analysis   system science  engineering design and
manufacturing informatization  icsem       
international conference on   vol    no   pp       
      nov      
    chang  chih chung and lin  chih jen  libsvm 
a library for support vector machines    p                 
    ratanamahatana  c   a    gunopulos  d         
 feature selection for the naive bayesian classifier
using decision trees   applied artificial intelligence
                  

fi