final report

classifying the brain s motor activity via deep learning
tania morimoto   sean sketch
motivation
over    million americans suffer from mobility or dexterity impairments  over the past few decades  research in
engineering and neuroscience has resulted in brain  computer interfaces  bcis  that show promise to return independence
to this movement impaired population  generally speaking  bcis aim to determine their users intention and convert this
intention to a control signal for some external device  although it may be possible to decode the activity from any
region of the brain  most research has focused on that produced by the motor cortex  the control signals developed from
decoded motor activity have been used to move computer cursors and drive robotic arms  algorithms to more quickly and
accurately decode motor activity are an expanding area of research 
background
bcis generally record neural activity in one of three ways      intracortically  via an implanted electrode array     
intracranially  via electrocorticography  ecog   or     from the surface of the scalp  via electroencephalography  eeg  
unsurprisingly  invasive bcis   intracortical and ecog   are rare  there are probably fewer than ten patients in the united
states with implanted arrays  eeg based bcis  on the other hand  can be used without an invasive procedure or doctors
supervision  however  accessibility comes at a cost  compared to recordings from intracortical or ecog arrays  eeg
signals have low spatial resolution and are easily contaminated by non neural signals  such as movements of the face and
head  these characteristics make it difficult for conventional
decoding algorithms to reliably determine user intent     
for motor activity  these conventional algorithms are based on
the brains mu and beta rhythms  electrical oscillations between
  and    hz that arise from large populations of neurons in the
primary motor cortex  the nature of these rhythms can be
monitored by eeg  and there is evidence that both motor
movements  e g   opening and closing the hand  and motor
imagery  e g   imagining opening and closing the hand  affect
their amplitude  as seen in fig     this amplitude modulation
 relative to a resting state  is obvious when raw eeg signals are
converted from the time domain into the frequency domain  it
occurs on different eeg channels  recording locations   see fig 
figure    eeg amplitude is modulated between  
   at different frequencies for different types of motor imagery
and    hz  mu beta band  during motor tasks    
 e g   left versus right hand movement   by examining plots
similar to the one in fig     it is possible to manually select the most relevant channel frequency pairs for each type of
motor imagery  these become the features for the classification algorithm  bci      an open source platform for bci
research  uses such features      it will serve as the standard of comparison in the results below 
although this conventional approach to feature selection and classification for motor eeg is ubiquitous  eegs low signal
to noise ratio makes it such that bci users must be extensively trained before their features are clear enough to manually
extract  in this report  we propose an alternative method for feature extraction from eeg  just as deep networks were able
to learn phonemes from speech data      such networks could extract basic neural activity units as features from eeg
recordings  such neural activity units could serve as features for enhanced bci classification as well as improve our
understanding of the brains processing 

fimethods
the following sections describe the nature and source of our data  how this
data is preprocessed  the autoencoder network used to extract features from
the data  and the supervised learning algorithms used with these features to
classify motor activity 
data  as shown in table    our eeg data was taken from two sources     
physionets online database           of     subjects performing right and left
hand motor tasks  both movement and imagery  and     personal recordings in
the stanford charm lab during motor imagery based cursor movement
tasks  while physionets subjects were recorded from    locations in the      international system  see fig      the eeg cap available in the charm
figure    electrode locations according
lab only records from fc  and fc   the right and left hand areas of the
to the       international system    
primary motor cortex  these signals recorded in the charm lab were
collected as microvoltages  relative to a common ground  with a guger
technologies g mobilab  wireless biosignal acquisition system and the bci     software  during the task  the cursor
moved in accordance with bci    s feature selection and classification algorithms  as noted in the background  this
provided a standard of comparison for the performance of our features and classification 

source
physionet eeg motor
movement   imagery
database
experiments in stanford
charm lab

subjects

motor task

   

right left hand
movement   imagery
  separate datasets

 

right left hand imagery

number of
electrodes
  
  used a subset

 

electrode locations

sampling
frequency

  to    in      
international system

    hz

fc    fc 

    hz

 right and left hand areas 

table    sources of eeg data

preprocessing  because eeg signals are known to be noisy and contain artifacts  we preprocessed the raw time series
before using them as an input for the autoencoder network  the signals were first passed through a common average
reference spatial filter to reduce signal blurring between electrodes  they were then low pass filtered to eliminate noise
above    hz  finally  chunks of the data were randomly selected and used as sequential inputs to the network 
deep learning for feature extraction      rather than manually extracting features  as described in the background  
we implemented an autoencoder neural network to automatically learn features from unlabeled eeg data  by setting the
networks output  l   equal to its input  l   and inserting a smaller hidden layer  l   in between the input and output 
the autoencoder learned an approximation to the identity function   as captured by weights w l  and biases b l   the
weights and biases were iteratively updated using a version of stochastic gradient descent called backpropogation  the
algorithm proceeds in four steps 
   perform a feedforward pass  computing the output values  activation  for l  and l  
   compute the error term for the final  output  layer as the difference between the networks activation and the true
target value 
   compute the error term for the remaining layers 
   update the parameters w l  and b l  

 

an identity function would exactly map from input to output if the hidden layer were the same size as the input and output 

fifigure   displays a schematic of the autoencoder architecture and eeg preprocessing  as noted in the schematic  the
resulting features are the inputs to the network that maximally activate each of the hidden neurons  in other words  they
are the characteristics of eeg signals that each neuron is tuned to detect  the feature for a given hidden neuron is
visualized by normalizing a vector of the weights that connect that neuron to each element of the input 

figure    method for preprocessing eeg data and extracting features using a single hidden layer autoencoder neural net

classification learning algorithms  we implemented two supervised learning models   binary logistic regression
 blr  and a support vector machine  svm    due to their success in eeg classification throughout the neural engineering
literature  training and testing data were first filtered and chunked using the same preprocessing steps described above 
then  in a forward pass through the neural network  the weights and biases learned by the autoencoder transformed the
preprocessed time series into the compressed feature space  the output of the networks hidden layer l    these l  outputs
became the inputs for blr and the svm  the label associated with each input was    left  or    right  for blr and   
 left  or     right  for the svm 
results
feature extraction  after trial and error optimization over the autoencoders number of hidden neurons  chunk time 
and regularization weight  we implemented an autoencoder network with   hidden neurons  a chunk time of    
seconds  and a regularization weight of      this network was trained on data from channels above the primary motor
cortex  fc   fc   fc  on the right and fc   fc   fc  on the left   and we visualized the learned feature for each hidden
neuron  split up channel by channel  as displayed in fig     the features for each channel converged to waveforms with
increasing iterations of gradient descent  i e   longer training of the network  
in addition  electrodes recording from opposite hemispheres   for example  fc  on the left and fc  on the right produced features with opposite phase  this was true regardless of the order in which the channel data was input to the
network  this indicates that the autoencoder is extracting basic physiological information from convoluted eeg signals 

fifigure    features converge to waveforms with more training of the autoencoder network
  this set of channel wise features was derived from a single hidden neuron 

classification  both binary logistic regression
and an l  regularized  l  loss svm were
implemented without substantial parameter
tuning  fig    shows the training and testing
error when the svm was implemented using
data from the six motor electrodes  fc   fc  
fc   fc   fc   fc    as expected  the
training error increased while the testing error
decreased as the number of training examples
became larger  other parameters  including the
chunk time of the input data and the number
of iterations performed during feature
selection  remained constant 
table   compares the testing error of blr 
svm  and bci     classification algorithms 
the inputs to blr and the svm were outputs
from the autoencoders compressed feature
figure    training error increases and testing error decreases
as more examples are used to train the svm
space  as explained in the methods above  the
inputs to bci     were raw eeg signals 
which were classified using the conventional algorithms explained in the background section  although manual feature
selection and bci     classification outperforms the autoencoders features and blr svm  there are benefits to our
method  most notably  the conventional method is limited by the nature of the brains mu and beta rhythms  there is
likely additional information in eeg signals not captured by such a narrow analysis  therefore  the performance of our
method should increase with the addition of more electrodes  true of neural networks and deep learning in general  
whereas conventional classification should remain the same  due to its dependence on recording over the motor cortex  in
fact  this improvement is evident when comparing errors in table   and fig     trained on two and six electrodes
respectively  finally  there is room for substantial optimization in selecting parameters for both the autoencoder and
supervised learning algorithms 

ficlassification
method
binary logistic
regression

number of training
examples

number of testing
examples

     
    
     
n a

testing error
     

    

svm

bci    

training error

n a

     
n a
  classifying in real time with

     

   s window

table    comparison of classification error

future work
future work on the project can be organized into three categories      optimization      application  and     extension 
optimization pertains to both autoencoder feature learning and the supervised classification algorithms  although we
performed a crude optimization for several autoencoder parameters  using nested for loops and reasonable parameter
ranges   there are significantly more efficient methods  potentially using cross validation  specifically  we are interested
in finding the optimal number of hidden neurons  aka  features   regularization weight  and time duration of the signals
used for feature selection 
as noted above  the eeg bci setup in the charm lab allows for real time cursor movement experiments  currently 
however  it can only decode the eeg using manually selected features and bci    s classification algorithms  this
online control task will be useful in verifying the performance of our algorithms and deep learned features  given that the
user can modulate his or her brain activity in reaction to the cursors movement  our algorithms and features will likely
perform better than shown in the figure and table above  in addition to this application  using our method to learn features
from intracortical or ecog recordings might reveal more fundamental truths about the brains processing 
finally  the features learned by our autoencoder network can be extended to other classification tasks  for example  if the
same features were able to identify the current user of a system  from a known set of users   there would be less need for
recalibration  which currently limits the practicality of bcis 
acknowledgements
this work was supported by stanford university and the collaborative haptics and robotics in medicine  charm  lab 
the authors wish to thank professor andrew ng and the course assistants for cs      machine learning for their
technical support  as well as jim notwell for providing explanations and resources relevant to deep learning 
references
  
  
  

  
  

  

c  guger  g  edlinger  w  harkam  i  niedermayer  and g  pfurtscheller  how many people are able to operate an eeg based brain computer
interface  bci    ieee transactions on neural systems and rehabilitation engineering  vol      no     pp          jun       
g  schalk  j  mellinger  a practical guide to brain computer interfacing with bci      springer       
h  lee  p  pham  y  largman  and a  ng  unsupervised feature learning for audio classification using convolutional deep belief networks  in
advances in neural information processing systems     y  bengio  d  schuurmans  j  lafferty  c  k  i  williams  and a  culotta  eds 
cambridge  ma  mit press        pp           
g  schalk  d  j  mcfarland  t  hinterberger  n  birbaumer  and j  r  wolpaw  bci      a general purpose brain computer interface  bci 
system  ieee transactions on biomedical engineering  vol      no     pp            jun       
a  l  goldberger  l  a  amaral  l  glass  j  m  hausdorff  p  c  ivanov  r  g  mark  j  e  mietus  g  b  moody  c  k  peng  and h  e 
stanley  physiobank  physiotoolkit  and physionet  components of a new research resource for complex physiologic signals  circulation 
vol       no      pp  e        jun       
trans cranial technologies        system positioning  trans cranial technologies       

fi