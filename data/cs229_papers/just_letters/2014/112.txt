cs    project report 
yelp personalized reviews
thomas palomares  alexis weill  arnaud guille
december         

 

introduction

using data from yelp dataset challenge  we wanted to provide personalized
restaurant recommendations to users based on the reviews they previously
left on yelp  to do so  we used one users past reviews and ratings  as well
as other users reviews and ratings of the establishment we are predicting
the rating of  the training is therefore made for a specific user and the
predictions based only on his or her specific preferences 
one of the main applications of this project is to be able to recommend
restaurants that a user is likely to appreciate  this could lead to a new
business opportunity for yelp  they could partner with restaurants willing to
offer discounts to users likely to enjoy the restaurant and make a commission
for every positive recommendations  this business model is currently used
by thefork  lafourchette   a european company launched in      linking
users and restaurants offering discounts through their app with thefork
taking a commission on every transaction  offering this service without
personalized recommendations  thefork managed to expand to   countries
in   years and was acquired by tripadvisor in      for     m  leveraging
yelps data  such a service could easily be implemented and become a solid
source of income for yelp before other competitors enter this niche 

 

dataset

yelp has made a subset of its data publicly available in the context of the
yelp dataset challenge      data is provided for users  tips  reviews checkins and businesses  there are     million reviews and         users in the
dataset provided  from which we removed all the reviews that were not about
restaurants then we only kept users that had given at least    reviews 

 

fithe data provided was exclusively in json format so we used jsonlab    
to convert the data in matlab format  the conversion time was non linear
so we developed a code to break the data in smaller chunks  convert that
data in matlab format  and recombine those pieces together 
while studying the data obtained  we quickly realized that most users had
only posted a handful of reviews  offering only a very small training set
given the way we set up our algorithms  as explained at greater length
in the discussion section  a way to compensate for this challenge would be
to use unsupervised algorithms on the every reviews to separate them into
different categories  a user with few reviews can be associated with one of
these bigger data set which the machine learning algorithms could be trained
with 

 

features and preprocessing

for our main features  we considered all the features available for each
restaurant  from the average rating of the restaurant  its price and the
type of restaurant we were considering  to more subjective features such as
the ambiance or whether the place is good for romantic dates  we then
used feature selections algorithms to keep only the most relevant features as
presented on figure   for the linear regression  the label considered is the
rating attributed by the user to a restaurant 
as discussed in details in the future section  one of the difficulties of this
approach is that many restaurants are missing some features in the yelp
dataset  making the implementation of the algorithms more challenging 
this reduces the amount of data available and might skew our results 

 

models

we have tested various models on the data  unsupervised algorithms  kmeans with different number of clusters  and supervised algorithms  learning
regression  naive bayes      we then used feature selection algorithms to
ensure that used relevant features 

 

first results

to get representative results for our models  we decided to only consider
users with the highest number of reviews  more than     reviews per user  
we then split this training set for cross validation             and computed
the resulting errors according to the number of features considered  in the
figures below we used     training examples and    testing examples  we
 

ficonsidered that the algorithm was making an error if  when applied to a
restaurant  the rating predicted was different by more than     than the
actual rating given by the user  for instance  a predicted rating of     would
be considered as good for an actual rating of either   or    we decided to
compare our performance to results obtained by only using the median value
of the ratings       as the prediction and called this model dumb      the
results are presented on figure   and   

figure    results for the different algorithms

figure    results for the different algorithms

we implemented different algorithms  either supervised or unsupervised
learning and then applied feature selection to find the best set of feature
for a specific user  while  at first glance  the results seemed correct for the
linear regression and unsupervised algorithms  when comparing them to the
dumb algorithm we realized that the errors were comparable 
in spite of many efforts to diversify the algorithms  considering labels   
or   for good and bad restaurants instead of actual ratings  or feature
selections  the results of the algorithms were still very close to the ones of
the dumb algorithm  we also observed that our algorithms  when optimised
to reduce the errors  tended towards the value of the dumb algorithm  in the
linear regression  most of the parameters were close to   while the intercept
term was close to      as far as the unsupervised algorithm is concerned  the
parameter rating from the user was generally similar among the clusters
and close to      we then wondered if better results with the current data
and features were really reachable 

 

fi 

new models

because our results were disappointing  we decided to see if generalizing
the problem to all users would generate better results  we tried to predict
restaurant ratings based on its features  we decided to use k nearest neighbors to get a sense of whether there was a way to group restaurants based
on features to estimate their rating  see     for k nearest neighbors   for features  we chose the categories the restaurants belonged to  such as italian
or gastropub   the number of reviews  its price range and a handful of characteristics  parking  kids friendly   we chose to round our real numbered
estimate and considered valid any guess that was     away from its actual
average given by the users 

 

new results

we can see that the testing error of our k nearest neighbors algorithm converges to around       as detailed on figure    given that the distribution of
ratings for all restaurants can be modeled by a normal distribution with an
average around      this result is not much better than guessing the median 
which could indicate that the features we had at our disposal were not good
indicators of the value of a restaurant 

figure    testing error of k nearest neighbors algorithm with varying k values

 

discussion

based on our results for individualized ratings  we decided to look at generalizing review predictions based on similar features  we realized that we
were getting similar results  which seems to indicate that the features we
were considering might not be representative of the ratings left by users 

 

fidespite using feature selection methods  we had trouble having good features to use for our algorithms  part of this issue is due to the fact that
there were only very few features that had data for all restaurants  most
of their data points are optional which makes our algorithms weaker when
using those features 

 

future

we believe that the features we used had low correlation to the reviews  to
get better results  we have to either find better features or use a different
approach 
one method would be to process the text of a users reviews to get rid of all
common words  such as the or restaurant  and take the most common
relevant words  such as tortilla or patio  in the reviews to create new
features that could capture information about a users preference missed by
our current features  we could extend this to all the restaurants reviews in
the dataset in order to identify new relevant features and therefore increase
the number of features we can use for each restaurant  a restaurant may
have a new feature for its amazing tacos or french bread  
using those new features  a new approach would be to apply unsupervised
learning algorithms to form restaurant clusters  we will then suggest new
restaurants to users based on the clusters of restaurants they liked before 
similar to the process of product recommendation on amazon 
from yelps perspective  it would be very useful to urge restaurants to fill
the missing information on their page  indeed  much information is currently missing about the restaurants characteristics we used as features for
our algorithms  which impacts the effectiveness of our machine learning algorithms 

references
    public data  http     www yelp com dataset challenge
    json lab  http   iso mesh sourceforge net cgi bin index cgi jsonlab
    larose  d  t          knearest neighbor algorithm  discovering knowledge in data  an introduction to data mining         

 

fi