gender identification by voice
kunyu chen
stanford university
kunyu stanford edu

i 

introduction

gender identification by voice is useful in
speech based recognition systems which employ gender dependent models  vogt and andr     suggested that gender differentiation
help improve automatic emotion recognition
from speech  harb and chen     reported that
classifying speakers gender is an important
task in the context of multimedia indexing 
our paper will examine the applicability of
standard machine learning techniques to the
voice based gender identification problem 

ii 

dataset

we use a subset of timit acoustic phonetic
continuous speech corpus  which is publicly
available online  the corpus consists of    
sentence recordings by   female and   male
speakers  we only use     recordings because
the rest have serious noise  the recordings are
in wav format and the sampling rate is    khz 
on page    figure   plots the amplitude of
audio waves over time of a sentence recording
of a female speaker  figure    on page    plots
the recording of the same sentence while the
speaker is a male 
the complete timit acoustic phonetic
continuous speech corpus contains recordings of     speakers  and each speaker reads
   sentences  some of the sentences are shared
among speakers  and figure   and figure  
plots a sentence that is spoken by them all 

iii 

features and preprocessing

we utilize yaafe to extract audio features out
of sentence recordings  our strategy is to first
build models with all the features     in total 

that yaafe is able to extract  we then evaluate
the performance of different models and run
backward search for feature selection on the
most performant model 
yaafe takes blocksize and stepsize as input
parameters for all available features  blocksize
defines the frame size  the width of a sliding
window over which yaafe computes feature
values  stepsize is the step between consecutive frames  the first frame is always centered
on the first signal sample  with blocksize    s
padded to the left  whenever the number of
signal samples is not enough for the last frame
to have blocksize samples   s are padded to the
right  for illustration  if blocksize   and blocksize    the first frame is centered on the  st
signal sample and the second frame is centered
on the  th  therefore  the first frame has  
padded zeros together with the first   signal
samples  while the second frame covers the
first   signal samples 
we use blocksize      and stepsize     for
all features  each features frame coincides perfectly  therefore the set of all features at each
frame can be treated as a single data point 
we have       such data points  among which
     are labeled female and      are labeled
male  we randomly pick up      data points
      as training data  and the rest serves as
test data for cross validation 

iv 

models and results

we train naive bayes  nb   discriminant analysis  da   support vector machine  svm  with
linear kernel  nearest neighbor  nn  and classification tree  ct  classifiers with the training
data   and we test the models against the test
set  table   on page   summarizes the results 
note  when fed with all available features 
 

fithe discriminant analysis  da  classifier is most
performant in terms of test error rate and precision  we do not include linear regression nor
generalized linear models here because with
all available features  model terms are rank
deficient 
we run backward search for feature selection on the discriminant analysis classifier  the
test error rate column of table   on page  
presents the performance measure when we
start with    features and iteratively remove
one feature from the model at a time  the feature is selected so that the new model with one
fewer features has the minimum test error rate 
we apply similar step wise greedy algorithms
to get the other two columns 
observe that the discriminant analysis classifier with   features performs even better than
the model with    features 

v 

discussion

our best performant model still suffers from
a test error rate of greater than      in order
to better understand the nature of our classification problem  as well as to direct our future
research in the right direction  we run diagnostics to see if our model has high variance or
high bias  figure   and figure   on page   are
the learning curves of two discriminant analysis models  one with   features and the other
one with all available features 
it turns out that even the all feature discriminant analysis model depicts a typical learning
curve for high bias  the high bias problem
implies that the set of all available features
we are considering does not capture enough
gender specific characteristics of voice 

vi 

conclusions

our experiments involve applying standard
machine learning techniques to the voice based
gender identification problem  discriminant
analysis works well and we are abel to achieve
    accuracy  precision and recall  by running
backward search for feature selection and diagnostics  we better understand the structure
 

of the problem  in addition  we also conclude
that general purpose audio features may not
be able to capture enough gender specific characteristics of voice 

vii 

future

zeng  wu  falk  and chan     reported that
applying gaussian mixture models combined
with high order audio features as parameters
achieves robust results  it would be interesting to introduce high order audio features to
our models and see its impact on our high
bias problem  in addition  harb and chen    
also published promising results using neural
networks 

references
    t  vogt and e  andr  improving automatic emotion recognition from speech via
gender differentiation  in proc  language
resources and evaluation conference  lrec
       genoa  citeseer       
    h  harb and l  chen  voice based
gender identification in multimedia applications  journal of intelligent information
systems  vol      no       pp     
            online   available 
http 
  dx doi org         s                
    j  garofolo  l  lamel  w  fisher  j  fiscus  d  pallett  n  dahlgren  and v  zue 
timit acoustic phonetic continuous speech
corpus  http   web mit edu       share 
nltk lite timit        
    b  mathieu  s  essid  t  fillon  j  prado 
and g  richard  yaafe  an easy to use
and efficient audio feature extraction software  in proceedings of the   th international
society for music information retrieval conference  utrecht  the netherlands  august
           pp          http   ismir     
ismir net proceedings ismir        pdf 
    r  e  fan  k  w  chang  c  j  hsieh  x  r 
wang  and c  j  lin  liblinear  a li 

fibrary for large linear classification  journal of machine learning research  vol     pp 
               
    y  m  zeng  z  y  wu  t  falk  and w  y 
chan  robust gmm based gender classification using pitch and rasta plp parameters of speech  in machine learning and

cybernetics       international conference on 
ieee        pp           
    h  harb and l  chen  gender identification using a general audio classifier  in
multimedia and expo        icme     proceedings       international conference on 
vol     july       pp  ii     vol   

 

fi    

    

   
   

    

    

amplitude

amplitude

   
    
 

 
    
   

    

    
   

 

   

 

   
 
length  in seconds 

   

 

   

   

 

figure    voice of a female speaker

nb
da
svm
nn
ct

   

 

   
 
length  in seconds 

   

 

   

figure    voice of a male speaker

test error rate

precision

recall

      
      
      
      
      

      
      
      
      
      

      
      
      
      
      

table    performance of different models built with all available features

  of features

test error rate

precision

recall

 
 
 
 
 

      
      
      
      
      

      
      
      
      
      

       
      
      
      
      

table    performance of da models built with a select subset of features

   

   
training error
test error

    
   

   

    

    
   
error

error

   
    
   

   
    

   

   

    

    

 

    

    

    
    
m  training set size 

     

     

     

figure    learning curve for a   feature da model

 

    

    

 

training error
test error

    

 

 

    

    

    
    
m  training set size 

     

     

     

figure    learning curve for an all feature da model

fi