multiclass sentiment analysis of movie reviews
robert chan   michael wang
cs     stanford university

abstract
we perform sentiment analysis on a new multiclass dataset  we apply various machine learning
techniques to this dataset  including naive bayes and the stanford corenlp  we then consider various
methods for optimizing these algorithms  finally  we conclude that incorporating syntactical information
in our models is vital to the sentiment analysis process 

 

introduction

previous studies on sentiment analysis consider a bi classification problem where only polarized
examples are considered  pang et al        maas et al         while these studies achieve high accuracy 
they do not consider neutral examples  or the magnitude of the sentiment  i e  somewhat positive  
however  sentiment is often not unequivocal  and a bipolar view of sentiment has only limited
application  in our study  we consider the problem of multiclass classification sentiment analysis   
labels are considered  negative  somewhat negative  neutral  somewhat positive  and positive  the
stanford recursive neural tensor network  socher et al        provides a baseline for our study  we
consider methods for optimizing basic text classification algorithms  as well as the stanford corenlp
package  in order to maximize performance on a new multiclass dataset provided by kaggle 

 

data sources

data is publicly available to kaggle users under the competition titled sentiment analysis on
movie reviews  in the training file  there are         rows and   columns  phrase id  sentence id 
phrase  and score  class   a phrase is a concatenation of words separated by a space  and is assigned a
score of   through    in the testing file  there are        rows  it has the same columns as the training
dataset  except for score  data pre processing was not necessary when we evaluate the stanford
corenlp library because the model consumes the text corpus as is 

 

research question

formally  the research question we seek to answer is   given any phrase x  what is the
sentiment score y     namely  we wish to learn some hypothesis h that maps from a phrase x to its
sentiment score y 

 

naive bayes and support vector machine

for our initial analysis  we analyze the performance of two basic classification learning
algorithms   multivariate naive bayes  and support vector machine 
data preprocessing
for our initial stage of analysis  we wanted to see if we can determine the sentiment of a phrase
based on the occurrence of certain words  therefore  we decide to use a collection of single words as
our feature set  and construct a word count matrix with words as columns and phrases as rows  this
generates        unique features  we then perform a simple feature selection process based on the

fientropy of a words occurrence and its sentiment  we then select the first      words with lowest
entropy as our feature set  our calculation of entropy is given as follows 

where pi is the probability of i 

svm
multiclass vs  two class svm
we first experiment with a multiclass svm classification model  there are many ways to handle
multiclass classification in svm  but to keep thing simple  we chose the one versus all approach where
we decomposed our problem into training five binary classifiers and had each classifier generating
probability estimates for our training set  then  we assigned a sentiment score to a phrase based on the
highest probability estimate  the result was less than promising  with an average accuracy of       
next  we simplified our problem  we observed that about half of our training data are classified
as    neutral sentiment   with the other four classes making up the rest of the labels  we wanted to
know  given our feature set  if svm could distinguish phrases with strong sentiment from neutral ones 
therefore  we converted the training labels such that all non   classes took on the value     while class  
became    with this reformulation of our problem  we still achieved a disappointing     accuracy 
out of sample vs  in sample testing
so far  we had been performing    fold cross validation to obtain our out of sample testing
error and accuracy  we wanted to know how well our classifier would do if we ask it to classify data that
it has already seen  the in sample testing accuracy is only        
naive bayes
we performed multivariate naive bayes with laplace smoothing  this algorithm achieved    
accuracy on the test set 

fithe multinomial event model assumes that any example picked from the distribution is first
randomly determined to be of a certain sentiment  and then is composed by running through a
dictionary and deciding whether to include a word independently and according to some conditional
probability  however  we believe this view of how phrases are generated is not a reasonable
approximation  namely  we believe that the naive bayes assumption does not hold for sentiment
analysis  for example  given a phrase of positive sentiment of a certain length  the presence of the word
 good  is conditional on the previous words chosen  as well as the words that come afterwards  for a
phrase of length   and a sentiment score of    the probability of the word  good  as the second word
will be very low in the case that the first word is  not   and high in the case the first word is  very  
therefore  if we wish to use multivariate naive bayes  we need to consider another feature set where
the naive bayes assumption holds 
improved naive bayes
we believe that the feature vectors we are using to train our learning algorithms have little to
no correlation with the labels  while the presence of certain words is probably indicative of sentiment
 i e   good    bad   etc   their effect on the sentiment is likely conditional on the presence of other
 inversion  words before or after these indicative words   not    although    but   etc    we perform
pre processing on the dataset in order to create a more relevant feature vector  we start by trying to
identify  inversion  words  i e  words that indicate a polar switch in sentiment   we select a set of   
words in the dictionary that we believe have strong sentimental value  for example   good    bad  
 well   and assign to each a polar sentiment score  i e   good  or  bad    for each of these sentimental
words  we calculate the conditional probability of the other words in the dictionary given the presence
of a sentimental word and the opposite strong sentiment score  i e  for a word that we assign to be
 good   we consider sentiment score of     we are then able to create a list of    words from the
dictionary that have highest probability of inverting sentiment  we then process the dataset such that
we create feature vectors that contain the number of inversion words present  as well as the word
frequency of the sentence snippet that is after the last inversion word  for example  the sentence  this
movie could have been good  but did not achieve its potential  becomes a feature vector containing the
number    since there is one inversion word  not    and the word frequency vector of  achieve its
potential   the sentence snippet that is after the last inversion word not   logically  such a feature
vector considers that the sentiment of a sentence is dependent only on the number of inversion words 
and the words that appear after the last inversion word  this logic can be verified by consider the simple
sentence  it s not good   such a sentence probably has a negative sentiment  and it s negative
sentiment is a function of the presence of an inversion word  not  and the word  good  that appears
afterwards  we then performed naive bayes with laplace smoothing using these new feature vectors 
and achieved     accuracy on the test set  an increase of    from naive bayes performed on the word
frequency vectors alone 

 

stanford corenlp

another approach to sentiment analysis that is different from svm and nave bayes is the use of
natural language processing  this method incorporates linguistic information such as word order  part of
speech  and named entity to understand a corpus  thus allowing it to better infer sentiment of a given
text  for this paper  we use the stanford corenlp library as our tool  which comes bundled with stateof the art models for the natural language processing pipeline  more importantly  the sentiment
analysis portion of this tool is the direct result of sochers work on the recursive neural tensor network 
which is of special interest to us because we want to explore the concept of inversion words and socher
claimed in his work that it is the only model that can accurately capture the effects of negation and its

fiscope at various tree levels for both positive and negative phrases  socher et al        
to use stanford corenlp for sentiment analysis requires the propagation of text through a chain
of processes that form a pipeline  options are available at each stage of the pipeline that can be
configured to suit the body of text being processed  without a deep understanding of each stage of the
pipeline and all the options available to us  we selected a few parameters that we believe are applicable
to our dataset  or that the literature suggest may improve performance  table   summarizes the options
we used  the reason we chose them  and their corresponding training and testing error 
options

reason

training
error

testing
error

baseline

default setting of corenlp are  tokenize whitespace   false  ssplit eolonly  
false  pos model   left words  ner model    class   class  miscclass 
parse model   pcfg
we set this option to true because the dataset provided by kaggle is already
pre processed such that each phrase contains tokenized words separated by
spaces  therefore  we dont want corenlp tokenizer to introduce new tokens 
similar to tokens  we set this option to true because our dataset is already preprocessed such that each line is a phrase  we dont want corenlp to further
split our phrases 
we experimented with bidirectional dependency network tagger because it is
said to outperform previous single automatically learned tagging result
 toutanova et al       
we experimented with conll distsim iob  crf ser gz because it is said to
perform better than the models being distributed with stanford corenlp 
 http   nlp stanford edu software crf faq shtml k  accessed    dec       
corenlp allows us to define our own named entities  so we created our own
list of movie titles   thinking that itll help the sentiment analyzer to not be
influenced by words appearing in titles 
we experimented with neural network dependency parser  rnn  because it
has the highest f  score compared to other available parsers
 http   nlp stanford edu software srparser shtml  accessed    dec       

       

       

       

       

       

       

       

       

       

       

       

       

       

       

tokenize 
whitespace
ssplit 
eolonly
pos 
model
ner 
model
regexner 
mapping
parse 
model

table    various options we experimented with in stanford corenlp and their results 

it is worth noting that since all the processes form a pipeline  the effect of each option being tested is
cumulative  unless they dont improve the overall performance  highlighted in yellow   or they increase
the testing error  highlighted in red   therefore  the final model that we use to analyze our dataset has
the options tokenize whitespace and ssplit eolonly set to true  highlighted in green  

 

discussion

we show that we can achieve higher accuracy achieved by simple text classification algorithms
by optimizing the features that are considered  specifically  by using basic sentence structure logic  we
can identify the words in the dictionary that are most likely to invert sentiment  then by considering only
the words that appear after all inversion words  we were able to create a set of features that improved
the performance of naive bayes  we believe that by doing more sophisticated processing using
sentence structure  we can identify other categories of words that have high correlation to the
sentiment  for example  we can divide each sentence segment into noun  verb  and object segments 
then considering how each segment relates to the overall sentiment score  i e  the presence of  smart 
and  provocative  in the noun segment have high correlation to a positive sentiment  but may not have
high correlation when present in the object segment  
although our preliminary result from using stanford corenlp for sentiment analysis already

fioutperformed svm and naive bayes  the task is far from complete and the result is far from its
potential  for one  we never used the training data provided by kaggle to train our own model  an
attempt was made to process the data into the penn treebank  ptb  format  which is required by the
stanford corenlp library  however  the way in which the sentences were broken down into phrases in
the training dataset was not consistent  making the task of converting it to ptb format error prone and
time consuming  another task that would substantially improve the performance of this method is to
get a better understanding of each stage of the natural language processing pipeline and to utilize all the
options available to fine tune the model  as the saying goes  a tool is only as good as the person who is
using it 

 

acknowledgement

we want to thank the cs    course staff at stanford for suggesting that we incorporate some
syntactical information in our models  as well as to motivate us to explore stanford corenlp 

 

sources

accurate unlexicalized parsing  dan klein and christopher d  manning  proceedings of the   st meeting
of the association for computational linguistics       pp         
a fast and accurate dependency parser using neural networks  danqi chen and christopher d manning 
proceedings of emnlp     
feature rich part of speech tagging with a cyclic dependency network  kristina toutanova  dan klein 
christopher manning  and yoram singer  proceedings of hlt naacl       pp          
incorporating non local information into information extraction systems  gibbs sampling  jenny rose
finkel  trond grenager  and christopher manning  proceedings of the   nd annual meeting of the
association for computational linguistics  acl        pp          
learning word vectors for sentiment analysis  andrew l  mass  raymond e  daly  peter t  pham  dan
huang  andrew y  ng  and christopher potts  proceedings of the   th annual meeting of the association
for computation linguistics     
libsvm   a library for support vector machines  chih chung chang and chih jen lin  acm transactions
on intelligent systems and technology                    
nlp stanford edu          the stanford nlp  natural language processing  group   online  available at 
http   nlp stanford edu software crf faq shtml k  accessed    dec        
nlp stanford edu          the stanford nlp  natural language processing  group   online  available at 
http   nlp stanford edu software srparser shtml  accessed    dec        
recursive deep models for semantic compositionality over a sentiment treebank  richard socher  alex
perelygin  jean wu  jason chuang  chris manning  andrew ng and chris potts  conference on empirical
methods in natural language processing  emnlp       
thumbs up  sentiment classification using machine learning techniques  bo pang  lillian lee  and
shivakumar vaithyanathan  conference on empirical methods in natural language processing  emnlp
      

fi