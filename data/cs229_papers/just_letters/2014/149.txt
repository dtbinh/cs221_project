predicting reddit post popularity via initial commentary
by andrei terentiev and alanna tempest
   introduction
reddit is a social media website where users submit content to a public forum  and other
users of the website can either upvote or downvote the submitted content  the number of
downvotes subtracted from the number of downvotes determines the score of the post  posts
with higher scores are then more prominently featured on the website  one interesting note is
that the popularity of the post is often times determined by the discussion that occurs in the
comment section of the post  the goal of this project was to determine if there were any
features in the first ten comments of a given post that would help us predict the future score of
the post  we chose this task after observations from a previous     project predicting reddit
post popularity     

   data set
we collected a dataset of roughly      training examples and     testing examples by
scraping reddit s website using their api  for each example  reddit post  we preserved the
post s score and text bodies of the earliest ten comments  reddit fuzzes some of its data  so
the oldest ten comments were not necessarily in order  nor were other metrics about post
popularity necessarily accurate  score was guaranteed to be accurate  so we chose to use
this as our label value instead of something like vote counts or upvote ratios  both of which
are fuzzed  

   task definition
initially we sought to model the problem as a regression task  where given our input of
features we would attempt to predict a value for the future score  we attempted some linear
regression models  but felt that this task would prove to be infeasible because of the strange
distribution of the scores     percent of our data never achieved greater than a score of ten 
additionally there were very few posts with large scores that skewed the regression heavily 
so instead we decided to model the problem as a binary classification task  where a post was
given a label of   if it did not surpass a certain threshold  where the threshold is just some
arbitrary score 

   features
the input features are solely metrics on post comments  since not all posts had at least   
comments  our first feature was the fraction of first ten comments that existed  additionally we
considered sentiment analysis on the comments as well as comment length  since the
comment ordering was fuzzed  we could not use metrics on individual comments as features 
instead  we used metrics on the ten comments as a whole  thus  our features were
maximum  minimum  lower half average  upper half average  and average of the comment
sentiment analysis scores and the comment lengths  additionally  we had another feature 
polarity  which was the maximum sentiment analysis score minus the minimum sentiment

fianalysis score  sentiment analysis was done with the stanford nltk  which for each
sentence in a comment body returns a rating of very negative  negative  neutral  positive  or
very positive  we assigned numerical scores                  respectively to sentences based
on those ratings  each comment received a sentiment score that was the average of the
sentiment scores of each of its sentences 

   evaluation metric
the metric that we used to evaluate our data was classification error  for a post
where
as described earlier the label of   is given if the post surpassed the
threshold  the classification error was

all of our algorithms were compared against a baseline algorithm which simply predicted zero
for each post  as we mentioned earlier the majority of posts never even surpassed our lowest
threshold  a score of ten  for the rest of the post we will also use the term accuracy which is
simply   classification error  in the results section we also describe how we compare
algorithms across all thresholds 

   results
to the right we can see how the
testing error changes for various
algorithms against the baseline as
we increase the value of the
threshold  we will describe each
algorithm in more detail below 
however we can see that there is a
trend of increasing test accuracy
as we increase the thresholds 
more sophisticated models like
support vector machine learning
and logistic regression are more
stable with the changes in the
thresholds
whereas
simpler
algorithms like perceptron and kneighboring algorithms  despite
having some high peaks behave more erratically  in the analyses of the separate algorithms
we chose to look at the confusion matrices across all thresholds and then normalize  this will
give us an average which we will use as our overall performance grade  obviously something
like variance is not taken into account  but we believe that this aggregate accuracy across all
thresholds holds the most insight into which algorithms were most successful 

fiactually actually
positive negative
predicted
positive

 a  k neighbors

           

where yn is one of the k closest neighbors in the training set  we
chose five as our k value which is the default in the scitkit library  kpredicted             
neighbors is a very simple algorithm  but is also computationally
negative
expensive  however  we are able to obtain very high accuracy at low
k neighbors
thresholds  the success of this algorithm faded when we used
higher thresholds  this would suggest that there are many
moderately successful posts which are clustered together feature wise  but more variation in
the features of highly successful posts 

 b  perceptron
perceptron and linear classifiers in general are great if the data is linear
separable  it was immediately clear that our data did not fit into this mold 
trying to create a line between this data is reflected in the inconsistency
of the accuracy of the algorithm  even dipping below the baseline at
certain points  using algorithm with the given data set  was infeasible
due to these circumstances  our update rule was the standard
perceptron update below  where are hypothesis was the dot product of
theta and x  we used the default alpha for the scikit library 

actually actually
positive negative

actually actually
positive negative

           predicted
positive

             predicted
negative

perceptron

 c  svm

we ran an svm with a linear kernel and l  regularization  when an
svm with a gaussian kernel had extremely low test set error and
           
higher training set error  we switched to a linear kernel with l 
regularization in order to be less sensitive to the suspected outliers 
predicted             
the resulting increase in test set error and decrease in training set
negative
error confirmed that the data has many outliers  below is the
svm
optimization problem corresponding
to this model  where c is a chosen constant
used to influence the weights of the error
terms  inside the summation   w is the
weights vector 
predicted
positive

fi d  logistic regression
logistic regression is a discriminative learning algorithm  it fits the
sigmoid function  below  to the data  the implementation of logistic
regression relied on the liblinear library      the performance of
this algorithm was well above baseline for all thresholds we tested 
logistic regression uses maximum likelihood estimates to find the
parameter vector theta that best fits the training data to the
hypothesis below  this is also known as the sigmoid function 

actually actually
positive negative

            predicted
positive

             predicted
negative

logistic regression

stochastic gradient descent is used to find the maximize the likelihood  with update rule 

 e  aggregate training and test accuracy
algorithm

training set accuracy

testing set accuracy

baseline  guess all  s 
where   means below
threshold 

              

              

logistic regression

              

              

support vector machine

              

              

k neighbors clustering
 k   

              

              

perceptron

              

              

   discussion
based on our results  we can conclude that there is some amount of correlation between the
initial commentary of the post and the score of the post itself  though we are able to achieve
better than random accuracy with our baseline  simply predicting below threshold for every
post   for most thresholds  all algorithms achieve even better accuracy  it is interesting to see
both logistic regression and svm converge as we increase our threshold amounts while our
other algorithms seem to bounce up and down and have more variability  the results are
satisfactory  but if we could figure out a way to have high success rates at both low and high
thresholds that would be much better  but are currently unsure of how to solve this problem 
as expected the commentary did have significant impact on the success of the post  however

fithere remains significant error  since the success of the post is also dependent on features of
the post itself and some amount of randomness 

conclusion
reddit post popularity definitely has an element of randomness but using characteristics of its
early comments  a post s popularity with respect to a fixed threshold can be predicted with up
to     accuracy  of course popularity of a post is dependent also on the content of the post 
which we ignored here  perhaps metrics on post characteristics could improve our predictions 
additionally  more data and more time to fine tune our algorithms would likely have helped
smooth out the error analysis curves and so inspire more confidence in our results 
nevertheless  it is remarkable to have such strong success in predicting post popularity
simply from characteristics of reddit posts  earliest comments 
future work
in the future we would like to perform a more extensive analysis on our features  it would be a
good idea to perform an ablative analysis in order to determine which features are most
useful in our prediction task  additionally it may be a good idea to see if we can think of more
features to use in our analysis  for example exploring the presence of key words  could help
us use something like a nave bayes classifier 

references
   http   cs    proj     zamoshchinsegall predictingredditpostpopularity pdf
   http   www csie ntu edu tw  cjlin liblinear 

fi