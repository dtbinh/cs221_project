methodology for sparse classification learning  arrhythmia
lee tanenbaum  stanford university

introduction
cardiac arrhythmias represent changes in the human hearts normal rhythm  which maybe be either immediately fatal
or  if sustained over a long duration  cause irreparable cardiac damage 
therefore  i propose to study ekg data from the uci arrhythmia dataset    with a machine learning approach to
improve machine classification performance to assist doctors in their diagnosis 
this dataset contains     samples  each sample containing     features about patient physiology  divided into
healthy     non empty arrhythmia classes  and one other class distributed as below 
class
 
 
 
 
 
 
 
 
 
  
  
  
  
samples    
  
  
  
  
  
 
 
 
  
 
 
  
this problem poses four hurdles that learning models must account for  mainly that there are    classes  a heavily
imbalanced class distribution  many features relative to number of training examples  and missing data points 
the methodology i use here is applicable to other problems with similar difficulties so my goal is to both improve
classification accuracy to improve medical preventative care as well as to explore these challenges more thoroughly
and help set precedence for future research 

ensembles 

ensemble voting method creates many decision processes  varying either the training parameters or model
structure between individual learned constituents  and then takes the mode average of its constituents votes to
make a prediction  ensembles have been shown to perform best results when there is significant diversity
among constituent models  this is maximized when using a variety of strong learning algorithms rather than
simplifying models to promote diversity due to lack of individual model accuracy  therefore  for my
classification ensemble i will attempt to build strong classifiers based on different models  run with feature sets
derived from different feature selection algorithms that will accurately represent the data while maintaining
variation in structure from each other so as to have varying sources of error  as such  creating an ensemble for
arrhythmia classification can be reduced to an analysis of learning models and feature selection algorithms that
can be adapted to handle multiple imbalanced classes with many features relative to number of examples 

measurements 

i want to represent a measure of performance of my model  as opposed to accuracy which doesnt take into
account imbalance in data  i am interested in the f score of the minority classes as a way to represent
performance  due to the multiclass setting  i will therefore calculate the average of the f score of the classes
throughout the distribution to represent performance in a meaningful way 
i will also report overall accuracy for ease of readability 
all of the performance measurements are reported as    fold cross validation averages 

design process

such datasets require a non standard learning approach  the process i followed was as follows 
 create models and measure training error to select multiclass models of sufficient complexity
 explore feature selection to reduce overfitting
 measure validation f score and graph confusion matrixes to guide progress 
 create an ensemble of models and feature sets 
 review the performance of the ensemble was comparable to the individual classifiers 
 exploring the ensemble voting procedure  i notice many misclassifications are unanimous 
 given that cardiologists can recognize arrhythmias based on these features  i create more relevant
features  here  i analyzed the confusion matrix and focused on the greatest sources of misclassifications 
 to give an example of assisting the feature selection with medical research  consider 
o to predict arrhythmia types by vector angle structures i calculated a feature to represent if
 is between     and     if t is near qrs  and if p isbetween   and     and to map all
combinations to different values 
      

 
 
 


     



 

 
 

   



 

 
 

 

fifeature selection 

first  i must address the problem of missing data points  i choose to impute the missing data points with the
nearest neighbor of non missing features  if its nearest neighbor is also missing that value  i instead replace the
value with the mean value for the dataset 
i attempted to perform principal component analysis on the data to extract a small set of features
representative of a large percent of the variation in the dataset  however i did not see strong performance from
this algorithm  this seems intuitive  the examples differing from the standard direction of variation are  by
definition  those representatives of cardiac abnormalities 
for my solution  i performed backwards search on the minimum redundancy maximum relevancy  mrmr  of
the data      this is a measure of the mutual information of a feature with the class label minus its average
mutual information with other features 
the mrmr search algorithm is therefore to iteratively remove features based on
     min  


 
 
                  
  
  
 

   

the other feature selection algorithm i employ in the ensemble is the more random undersampling approach of the
gini index of a random forest classifier  during rf classification  the gini index of a variable i is the average
difference between the impurity of the descendants of the tree split at nodes with variable i minus the impurity
of the nodes to be split with variable i  for the case of m total features  and with fi representing the fraction of
items with the value i in the set  this becomes


        
  

notice that the impurity is therefore    minimum  when all cases under the node fall into the same classification
category 
i also performed forward search by adding one feature at a time that increased most the average f score validation
performance of a svm  i believe svms to be a good choice due to high classification performance and the
deterministic aspect of creating a svm decision boundary  which none of the other models used here have 
also note that i stop feature selection when there is a relatively large number         features remaining  which
is larger than the recommended maximum of     th of the number of samples  this is to be expected  however 
because of the existence of    classes  which requires more information encoded into the feature set than a
small number of features would contain  i suggest that future research look into the relation between sample
size and number of classes to distinguish to make predictive ranges for the optimal number of features for
classification 

models
trees  random forest  rf 

a basic strategy for performing multi class classification would be to create decision trees that branch based on
feature values being greater than or equal to some threshold  and to predict class labels based on the
percentage of training data in each leaf of a decision tree  this could be improved for imbalanced datasets by
normalizing the probabilities of data  and further improved by boosting  by creating an ensemble of such trees
and sampling more from classes with poor prediction values or bagging by randomly selecting samples from the
training set to create ensembles of decision trees  based on existence of many features relative to the number of
examples  i chose an ensemble of decision trees with randomly selected features for decision nodes  which is
called random forest  rf      
one elegant fact about the random forest algorithm is the lack of parameters to adjust to fit the dataset  in
particular  the main selections needed to be made are the number of trees  which has little significance as long
as enough trees are selected to sample the population  and the number of parameters chosen  or depth  of each
tree  which i have chosen to be  for a dataset with p features 

fithere are many ways to vary a random forest to handle extremely imbalanced datasets  from manipulating
misclassification costs to sampling techniques  i chose to sample uniformly between classes to balance the class
probabilities  because i believe it is more important not to misclassify one of the few extreme arrhythmia class
cases than misclassify a healthy patient  i wish to also apply a lower cutoff for the minimum number of votes
required to end an ensemble search and select a class  and my cutoff deviation is proportional to the extremity
of the minority class imbalance 

one vs rest nave bayes  nb  with gaussian smoothing  uniform prior probabilities  and
imbalanced misclassification costs

nb calculates the most likely class for an example by treating conditional probabilities of features given class
labels as independent and maximizing the likelihood of the example 
this model is designed initially for discrete random variables  and cannot represent in its initial form the
continuous random variables in arrhythmia readings  therefore  i treat the variables as gaussian distributions
to calculate the conditional probabilities  to explain this  for a variable x  let c be the mean of the values
in x associated with class c  and let c be the variance of the values in x associated with class c  therefore  the
probability distribution of some value given a class p x v c  can be computed by plugging v into the equation
for as n c  c   
   

 
 
        
  
 
 

to extrapolate this binary classification model to multi class for this arrhythmia data  i use a one vs rest model
where i compute binary classification between one class vs the rest of the classes  i compute this individually for
every class  and then select the class with the greatest likelihood 
if there are k classes  and fk x  is the likelihood of class k versus the set of all other classes  i chose class
   argmax f  x 
 

this allows us to apply binary classification models like the nb model to multiclass settings  also  the nb
algorithm needs to handle the imbalanced class distributions  which can be done either through creating an
ensemble with majority classes under sampled  or can run once with the minority classes oversampled to
create balance  i chose to oversample the minority classes rather than create an ensemble of undersampled
majority classes to help runtime of training and testing at no noticeable hit to performance to create balanced
prior probabilities  as well as to restrict misclassifications of minority classes further with heavier
misclassification costs for minority classes 
therefore  the nave bayes decision boundary between class   and   with misclassification costs ci proportional
 
to  the number of examples of class i in the true distribution 


 

   



                             

note that this does not take into account prior probabilities of the classes  because i sampled uniformly from all
classes 
note that nb classifiers are strongly dependent on direct correlations between features and class labels because
they cannot model dependent relations between variables  therefore  nb with a one vs rest modification was
an initial model attempted and discarded due to not reaching even a high training set accuracy  however  once i
improved feature selection and had fewer  stronger individual features the nb performance improved
dramatically 

one vs rest support vector machine svm  with regularization and a kernel threshold
offset  and imbalanced misclassification costs

svms create decision boundaries between two classes  i can use this binary model  and again consider
comparing each individual class against the group of all other classes  after training  i have decision boundaries
based on the maximally confident one vs rest decision classifier in that space 
kernel threshold offset and misclassification costs

fithis model suffers a similar problem to the nb in that a one vs rest svm will strongly favor majority classes
over minority classes  solving this problem by creating an ensemble of svms with under sampled majority
classes would be too time intensive  and oversampling minority classes has little effect on svm models  instead 
i handle imbalanced class distributions by modeling imbalanced misclassification costs and implementing a
kernel threshold offset 
i offset the svm kernel decision boundary in the direction of the under represented minority classes based on
the magnitude of the imbalance 
the kernel threshold offset is calculated as such  let f x  be the decision function for an example x  a new sample x
will be assigned to the positive class if f x   and the negative class if f x     and let us assume without loss of
generality that minority classes are the positive side of the boundary and majority classes the negative  chen et al     
and lin    showed that adjusting the decision threshold can increase minority class prediction accuracy  therefore  we
adjust the decision threshold to be offset by   and replace the misclassification costs with a weighted misclassification
cost  where n  and n represent the sizes of the majority and minority classes  cost  and cost  are misclassification
costs inversely proportional to n  and n   and a is a constant to modify global magnitude of these adjustments for all
classes 
        

  
      

               

where   

and selecting the values of p and a that yield the greatest average f score validation performance 

 





varying these two parameters can be viewed by the following graph and explained by the following table 
notice the following general regions that i expect 
because both smaller a values and larger p values both
increase minority class prediction likelihood 
p cost exponent
p cost exponent
large
small
low a
always predict
predict classes
offset
minority classes
evenly and more
value
accurately
high a
predict classes
always predict
offset
evenly but
majority class
value
inaccurately
this demonstrates that the svm with threshold offset
actually performs best with its costs approximately
 
proportional to       and with its threshold offset value a   


svm regulation parameter c
i have found that the svm gets better validation performance by decreasing the regularization parameter c to
increase the regularization to inhibit overfitting  to add the regularization term c  the svm hypothesis becomes 


 

 

 
min                           

 
  

  

neural network with regularization removed from ensemble 

neural networks have been studied extensively on this dataset  and i confirmed their high performance 
however  publications each select many variables for their nn  such as forward transfer function  back
propagation method  structure  and many other parameters  and it is little understood why different structures
would perform better or worse on this dataset 
therefore  i remove nn from the ensemble as more research is needed to optimize and understand relevant
tradeoffs in their application 

firesults
ablative analysis
removed
accuracy
f score
nothing
   
   
feature extraction
   
   
feature ensemble
           
           
feature selection
   
   
model ensemble  
           
           
parameter tuning
svm nb rf
svm nb rf
note that a majority of the improvements came from feature
manipulation and adapting models  and therefore i spent a majority of my
time exploring this area of research due to the large number of features 

individual model feature set pair accuracies and f scores
accuracy f score
gini
mrmr
svm
svm
       
       
       
nb
       
       
n a
rf
       
       
       
ensemble
       
note that nb with svm feature search was not included in the ensemble  this combination performed poorly 
presumably because svm feature search detects dependent correlations to class labels which nb cannot
represent 

conclusions and future work

for classifying datasets that learning models were not designed to fit  one must 
 adapt models to fit data structure
o for ideas on how to adapt a model  one should either work through the derivation of the model
and consider all assumptions and altering significant calculations  or look up model
transformations in previous publications and consider applying variations to their project 
 take meaningful measures of performance
 study the many layers of the classification process to diagnose error causes
 understand expectations for individual module performance
future work should focus on
 understanding model adaptations to imbalanced data  both for effectiveness at classifying this dataset
and to extrapolate to general recommendations 
 research could expand the feature set further using polynomial regression or performing other feature
selection techniques such as lasso or ridge regression on the expanded feature set 
 pay close attention to increasing classification accuracy for the other class  the greatest current source
of error

references 

   dataset  ecg arrhythmia   uci repository of machine learning databases  available from   ftp  ics  uci 
edu pub machine learningdatabases   accessed may              
   ding  chris  and hanchuan peng   minimum redundancy feature selection from microarray gene expression
data   journal of bioinformatics and computational biology                      
   breiman  leo   random forests   machine learning                   
   chen jj  tsai ca  moon h  et al  decision threshold adjustment in class prediction  sar qsar environ res
               
   lin  wei jiun  and james j  chen   class imbalanced classifiers for high dimensional data   briefings in
bioinformatics         bbs    

fi