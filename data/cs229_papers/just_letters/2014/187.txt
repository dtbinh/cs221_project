object detection for semantic slam using convolution neural
networks
saumitro dasgupta
saumitro cs stanford edu

 

introduction

image classification and detection tasks      this has
motivated us to use it as the core of our detection
framework 

conventional slam  simultaneous localization and
mapping  systems typically provide odometry estimates and point cloud reconstructions of an unknown
environment  while these outputs can be used for
tasks such as autonomous navigation  they lack any
semantic information  our project implements a modular object detection framework that can be used in
conjunction with a slam engine to generate semantic
scene reconstructions 
a semantically augmented reconstruction has many
potential applications  some examples include 

 

datasets

we used a number of datasets for developing our
framework  while the primary dataset used in the
final system was based on imagenet  the rest were
used for evaluating the network in network cnn
architecture described in section   

 discriminating between pedestrians  cars  bicyclists  etc in an autonomous driving system 

   

imagenet

the imagenet dataset     is a collection of over   
 loop closure detection based on object level de  million labeled rgb images organized according to
scriptors 
the nouns in the wordnet hierarchy  currently  each
node has on an average about     images  the as smart household bots that can retrieve objects sociated imagenet large scale visual recognition
given a natural language command 
challenge  ilsvrc  has been used for benchmarking
an object detection algorithm designed for these image classification algorithms since      
applications has a unique set of requirements and
constraints  the algorithm needs to be reasonably
fast   on the order of a few seconds at most  since the
camera is in motion  the detections must be consistent from multiple viewpoints  it needs to be robust
to artifacts such as motion blur and rolling shutter 
currently  no existing object detection algorithm addresses all of these concerns  therefore  our algorithm
is designed with these requirements in mind 
in the past couple of years  convolutional neural
networks have experienced a resurgence in popularity  they currently dominate the benchmarks for

   

cifar   

the cifar    dataset     is a labeled subsets of the
   million tiny images dataset collected by krizhevsky 
nair  and hinton  it consists of          x   color
images in    classes  there are       images per class 
the first        images were used for training  while
the remaining        comprised the validation set 
we pre processed the data by performing zca
whitening and global contrast normalization as described in     
 

fiobject
proposals

image

final
detections

non maximum
suppression

detection
candidates

feature extraction
 nin cnn 

softmax
regression

figure    the object detection pipeline  the compo  figure    visualization of the parameters from the
first convolutional layer of the network  along with
nents shown above are described in section   
the corresponding  partial  feature map 

   

mnist
   classification  the extracted features are fed
to a softmax regression classifier to obtain the
detection label 

mnist     is a collection of   x   grayscale images
of handwritten digits  it consists of        training
and        test examples 

 

   non maximum suppression  object proposals tend to yield multiple overlapping detections
for a given object  we address this here by first
finding bounding boxes with an iou  intersection
over union  score greater than a certain threshold      in our current implementation   and then
retaining only the one with the highest score 

framework architecture

figure   provides an architectural overview of our
framework  broadly  the components involved are 
   object proposals  since our network is trained
on whole image classification  we need a way to
re purpose it for localized detections  one possibility would be to use a sliding window approach
at multiple scales  however  this would be too
slow for our purposes  therefore  we adopt the
object proposal paradigm where an algorithm
is used to generate bounding boxes for regions
likely to contain an object  in particular  we
use the recently published edge box proposal
algorithm by zitnick and dollar      it provides
state of the art level proposals while still being
extremely fast 

the resulting detections are then propagated to the
slam engine for eventual localization in  d  we
exclude a discussion of the slam subsystem as it is
beyond the scope of this report  for one potential
approach  we refer interested readers to     

 

model

a wide range of methods have been proposed for
both object classification and detection  up until
recently  the dominant methods involved the use of
hand crafted feature descriptors such as sift and
lbps  however  in       krizhevsky et  al      demonstrated that convolutional neural networks  cnns 
can be efficiently trained for achieving superior image
classification results in the imagenet large scale visual recognition challenge  since then  cnns have
dominated the image classification benchmarks  more
recently  girshick et  al     have shown state of the 

   feature extraction  for each proposal  we use
a convolutional neural network trained on the imagenet dataset to extract features from an rgb
image  figure   visualizes the parameters learned
by the network along with the corresponding feature map  the model is described in greater
detail in section   
 

fi   

   

   

   

   

   

   

    

figure    the network in network architecture  as described in    

error

art results for object detection using cnn features
dataset
test error
coupled with linear svm classifiers  therefore  we
chose cnns as the core of our detection framework 
cifar   
      
mnist
     
our implementation uses the novel network in
imagenet
       
network  nin  architecture proposed by lin et  al
in      the convolutional layer in the commonly used
architecture described by krizhevsky et  al  in     table    benchmark results for the network in net often referred to as alexnet  uses a linear filter  work architecture
the nin model replaces this with a multi layer per 
ceptron  mlp  which slides over the input to produce
training error
test error
the feature map  as mlps are universal function
   
approximators  this tweak results in greater abstrac   
tion capabilities over local patches  in addition  the
fully connected layers present in alexnet are replaced
   
by global average pooling  this greatly reduces the
   
number of parameters and makes it less prone to
overfitting 
   
   

 
   

results

   

network in network benchmarks

   

   
table   summarizes the test errors obtained by the
 
   
    
    
    
    
    
    
iterations
network in network architecture on the datasets
described in section    on the cifar    dataset it
achieves state of the art results  achieving a test error figure    the training and test errors for the first
of         without image augmentation  interestingly       stochastic gradient descent iterations on the
a nin trained on imagenet produces a much smaller cifar    dataset 

 

fiparameter set when compared to alexnet    mb vs same hardware  furthermore  as our current imple   mb when using caffes format       while perform  mentation hasnt been optimized for speed yet  we
ing slightly better 
expect its performance to improve 

   

object detections

 

figure   shows a series of frames taken from the
tum rgb d slam dataset       these frames capture roughly the same scene from multiple viewpoints 
each of them has been annotated with the bounding
box of the detected object along with its label  the detector only considers    of the      imagenet classes
for this sequence  excluded classes include those that
are unlikely to be stationary and or encountered in
an office environment  such as wildlife  

in this report we described our implementation of
an object detection framework that is suitable for
use with a slam engine  we demonstrated that
the network in network cnn model trained on the
imagenet dataset  coupled with edge box object proposals and non maximum suppression provides fast
and reasonably accurate results 

 
 
   

future work

discussion
the current implementation operates solely on  d
images  however  given that its designed to be used
within a slam framework  it would be interesting
to incorporate depth information into the detection
process  recent work along these lines have shown
promising results      
we also plan to fine tune tune our implementation
using large datasets intended specifically for object
detection  such as the ones published for the pascal
voc  we expect this to improve our detection performance  as well as provide an objective benchmark
for evaluating our system 
yet another interesting addition would be to incorporate bounding box regression  as described by
girshick et  al  in     

precision and recall

the classification score threshold significantly affects
precision and recall  an aggressive threshold reduces
false positives but also suppresses true positives  on
the other hand  a conservative threshold leads to
improved recall  but reduced precision  in figure   
the bottle in the first frame is an example of a false
positive  whereas in the third frame  the power drill is
missed  our current implementation uses a hardcoded
hand tuned threshold for the tum dataset  however 
a dynamically adjusted threshold would be a more
robust solution 
another significant hyper parameter is the number
of object proposals  we found that increasing the
number of edge box proposals beyond     does not
significantly influence the quality of the results  for
comparison  r cnn     generates      proposals using
the selective search algorithm 

   

conclusion

references
    olga russakovsky et al  imagenet large scale
visual recognition challenge  arxiv preprint
arxiv                 

speed

the current implementation takes about     seconds
to fully process a single frame  a component wise
breakdown is given in table    for comparison  rcnn  the current state of the art cnn based object
detection algorithm     takes about    seconds on the

    jia deng  wei dong  richard socher  li jia li 
kai li  and li fei fei  imagenet  a large scale
hierarchical image database  in computer vision and pattern recognition        cvpr      
ieee conference on  pages         ieee       
 

fifigure    frames from the tum rgb d slam dataset annotated with object detections 
stage

time  seconds 

object proposals
feature extraction   classification
non maximum suppression
total

   
   
     
r

table    time required by each component in the pipeline  the time quoted for object proposals include
edge box proposal generation  which takes less than a second   as well as the overhead introduced by our
implementations  un optimized  cropping algorithm 
    alex krizhevsky and geoffrey hinton  learning
multiple layers of features from tiny images  computer science department  university of toronto 
tech  rep       

information processing systems  pages          
     
    ross girshick  jeff donahue  trevor darrell  and
jitendra malik  rich feature hierarchies for accurate object detection and semantic segmentation 
in computer vision and pattern recognition 
     

    yann lecun and corinna cortes  the mnist
database of handwritten digits       

    c lawrence zitnick and piotr dollar  edge
boxes  locating object proposals from edges  in      yangqing jia et al  caffe  convolutional architecture for fast feature embedding  in proceedings
computer visioneccv       pages        
of
the acm international conference on multispringer       
media  pages         acm       
    jorg stuckler  benedikt waldvogel  hannes
schulz  and sven behnke  dense real time map       jurgen sturm  stephane magnenat  nikolas
engelhard  francois pomerleau  francis colas 
ping of object class semantics from rgb d video 
w
burgard  d cremers  and r siegwart  tojournal of real time image processing  pages
wards
a benchmark for rgb d slam evaluation  in
          
rss  volume    page         
    min lin  qiang chen  and shuicheng yan  network in network  arxiv preprint arxiv                 saurabh gupta  ross girshick  pablo arbelaez 
and jitendra malik  learning rich features from
     
rgb d images for object detection and segmen    alex krizhevsky  ilya sutskever  and geoffrey e
tation  in computer visioneccv       pages
hinton  imagenet classification with deep convo        springer       
lutional neural networks  in advances in neural
 

fi