facial keypoints detection  yue wang   yang song

 

facial keypoints detection 
yue wang and yang song
stanford university

abstractin this project  we are given a list of      pixel  bit graylevel images with their corresponding  x  y  coordinates
of    facial keypoints  we first adopt hold out cross validation to
randomly split the data set into a training set and a test set  so
that we can develop our algorithm on the training set and assess
its performance on the test set  our algorithm first performs
histogram stretching to enhance the image contrast by stretching
the range of pixel intensity of each training image  then  in order
for noise reduction  we apply principal components analysis on
the stretched images to obtain the eigenfaces  using the resultant
eigenfaces  we implement the mean patch searching algorithm
with correlation scoring and mutual information scoring to
predict the left  and right eye centers for any query test facial
images 

integers from   through              characterizing the
intensity of each of the               pixels  therefore  the
given training set is a huge matrix of size           where
each row corresponds to one image  the first    columns give
the  x  y  values of the    facial keypoints  and each entry in
the last column is a long list of      numbers representing the
pixel matrix of each image melted row by row  we also note
that in some examples  some of the target keypoint positions
are misssing  encoded as missing entries in the csv file  i e  
with nothing between two commas  
table i  the    facial keypoints
left eye center
left eye inner corner
left eye outer corner
left eyebrow inner end
left eyebrow outer end
mouth left corner
mouth center top lip
nose tip

i  i ntroduction

a  data
the idea and data set of this project come from the kaggle
online competition       our data set consists of a list of     
two dimensional   bit graylevel training images with their
corresponding  x  y  coordinates of the    facial keypoints
as listed in table i   see figure    which shows two sample
images marked with those    keypoints   each image is
represented by a        pixel matrix  whose entries are
 advisors  prof  andrew ng and cs    course staff team 
 email  yuew stanford edu
 email  sy     stanford edu

  
  
    
  
  

  

  

    

  

  

f

ace recognition is one of the most significant branches
in computer vision research  it aims to determine the
locations and sizes of human faces on digital images  by
detecting and extracting faces from the other surrounding
objects  such as buildings  plants and other backgrounds  to
develop a sophisticated face recognition algorithm  the most
fundamental but by far the most important task is facial
keypoints detection  that is  to find out the locations of specific
keypoints on face images  which include left eyes  right eyes 
noses  mouths and so forth  in this article  we explore this
appealing yet challenging topic in depth 
the challege of facial keypoints detection is that the facial
features may vary greatly from one image to another due to
the difference of individuals generic appearances  besides 
the facial features may also be significantly affected by other
physical factors such as position  viewing angle  illumination
condition  contrast  and even the psychological factors such
as the emotion of individuals  our objective is to develop
a relatively accurate and efficient algorithm to automatically
recognize where the facial keypoints are located on digital
images 

right eye center
right eye inner corner
right eye outer corner
right eyebrow inner end
right eyebrow outer end
mouth right corner
mouth center bottom lip

  

  

  
    

  

  

  

  

  

    

fig     two sample images marked with the    keypoints as
listed in table i 
b  goal
this is a supervised learning problem  where we are given
the above mentioned relatively large data set of      training
examples  consisting of their image pixel matrices and their
corresponding true positions of the    facial keypoints  we
would like to develop some efficient hypotheses that can
provide relatively accurate prediction on positions of the facial
keypoints for other query images  due to time limitation  we
would only concentrate on the positions of left and right
eye centers  more specifically  our goal is that our resultant hypotheses are able to predict left eye center and
right eye center given any query facial image represented
by a        pixel matrix as input 

fifacial keypoints detection  yue wang   yang song

 

ii  m ethodology
a  preprocessing
recall that we are given a set of      examples  denoted
as s   in order to evaluate the performance of our learning
algorithm  we adopt hold out cross validation and randomly
split s into strain and stest   which contain            examples  and            examples  of the data  respectively 
we will train our learning algorithm on strain   and then test
the resultant hypotheses on stest by calculating the root mean
sqaured error  rmse 
v
u n
u  x
 yi  yi     
   
rmse   t
n i  
where yi is the true value and yi is the predicted value  this
rmse on the hold out test set is expected to give a reasonably
good estimate of the generalization error of our learning
algorithm  and our objective is to minimize this rmse 

intensity values too significantly  however  selecting the current range limits a and b as the minimum and maximum
pixel intensity values is very sensitive to outlying pixels if
any  and this could lead to very unrepresentative scaling  see
      as remedy  we adopt a more robust version of histogram
stretching  eq        which selects a and b as the  th and   th
percentile  respectively  in the histogram of the original pixel
intensities  this prevents ouliers from affecting the scaling too
much 
now  back to our facial keypoints detection problem  we
perform this modified histogram stretching algorithm on each
of the      training images and the      test images with
the desired range  l  u              yielding a total of     
stretched images with much better contrast  for each training
and test stretched image  its true facial keypoints positions are
unchanged 
figure   shows three typical pairs of images before and after
performing the modified histogram stretching algorithm  we
can see that the stretched images have much better contrast
effect 

b  histogram stretching
as mentioned in the beginning  the images may be corrupted
by random variations in contrast  illumination and other imaging conditions      suggests that we deal with these problems
in the early stages of vision processing  in this subsection  we
resolve the problem of poor contrast  in this next subsection 
we tackle the other noises 
mathematically  poor contrast means the pixel intensity
values of a certain image lie within only a small range  this is
fairly common in real life images  including our data set  in
this subsection  we introduce histogram stretching  a simple
but effective image enhancement technique that attempts to
improve the contrast in an image by stretching the range of
its pixel intensity to span a desired range of values  which is
often the full range of pixel intensity allowed  for our   bit
graylevel images  the full range is from          
given an image  represented by its pixel matrix   the
histogram stretching algorithm first scans the entries to find
the minimum and maximum pixel intensity values currently
present in the image  denoted as a and b  respectively  thus 
the current pixel intensity range is  a  b   let  l  u  be the
desired range that we would like to span  for our   bit
graylevel images  l     and u         then  each pixel
intensity value p in the original range  a  b  is mapped to a
new value p  in the desired range  l  u  in a such way that the
proportion of p  in  l  u  is the same as the proportion of p in
 a  b   that is 
p   l
pa
 
 
ba
ul

fig     upper  three original images  lower  three corresponding stretched images after performing the modified
histogram stretching algorithm 

   

c  principal components analysis
aside from contrast  the images may also be affected by
the other external factors such as illumination and imaging
conditions  in order to reduce these noises  to reduce the complexity of the hypothesis class to help avoid overfitting  as well
as to enhance computational efficiency  we employ one more
unsupervised data exploration tool  principal components
analysis  pca   before performing the supervised learning
algorithm 
since we are interested in finding principal components
that can retain the systematic variations between faces while
reducing the noises  we first write the design matrix x as


 
 
 
x   x  x     x       
 
 
 

the advantage of histogram stretching is that it enhances
the image contrast without distorting the relative graylevel

where each xi  r       i                    corresponds to
the ith stretched training image pixel matrix melted row by

implying that
p   

u  l

 p  a    l
ba
ul
bl  au
 
p 
 
ba
ba

fifacial keypoints detection  yue wang   yang song

 

row into a column vector  performing pca on x gives the
principal components  called eigenfaces in computer vision 
see     
pc       x       x                x    
pc       x       x                x    
  
where                          t  r      with k  k    
                            t  r      with k  k       
       are the loading vectors of pc    pc           respectively 
the theory of pca states that the loading vectors        
      of the principal components pc    pc          are just the
ordered sequence of the normalized eigenvectors of the matrix
   xt x  and the variances of the pcs are the corresponding
ordered eigenvalues 

fig     the first   eigenfaces  row by row  pc  through pc   
d  mean patch searching 

fig     scree plot  depicting the cumulative proportion of
variance explained  cpve  by each principal component 
figure   is the resultant scree plot  which provides a
common way for us to decide on the number of principal
components required to explain a sizable amount of variation in the data  one typically eyeballs the scree plot and
looks for an elbow point at which the cumulative proportion
of variance explained  cpve  by the subsequent principal
component significantly slows down increasing  by inspecting figure    we find that the elbow point occurs at    
principal components  which can explain more than     of
the total variance in the training data  therefore  we expect
that the first     principal component stretched images  i e  
eigenfaces    pc           pc    can approximately represent the
original      stretched images x           x     with noises
further reduced  and will use them as our training images
in supervised learning later  for each principal component
stretched image pcj  j                    we obtain its true
facial keypoints positions by computing the weighted average
of the corresponding true positions in the original  stretched or
not  since their true keypoints positions are the same  images
xi  i                    with weight equal to  ij  recall that
p    
kj k     i    ij      
figure   shows the first   eigenfaces extracted from the
     training stretched images 
  more precisely  they should be called eigen stretched faces  but we will
be consistent with literature and just call them eigenfaces 

finally  in this subsection  we perform supervised learning 
we adopt a relatively simple but effective algorithm for facial
keypoints detection  called mean patch searching  we take the
facial keypoint left eye center as an example to illustrate
this algorithm 
given a set of n training images  in our problem  n      
eigenfaces after performing modified histogram stretching and
pca  with their true  x  y  coordinates of left eye center 
from each of them we extract patch size number of pixels
in each direction around the true keypoint  x  y   yielding a set of n patches  of size     patch size      
    patch size       we then compute the mean patch
as the entry wise mean of the n patches obtained above 
mathematically  let pi  r  patch size     patch size    be
the pixel matrix of the ith patch  i              n   then the pixel
matrix of the mean patch p is given by
n

p  

 x
pi  
n i  

this mean patch is expected to be a typical representation
of the respective facial keypoints  i e   left eye center
in our illustrative example   moreover  we can obtain
the mean left eye center position  denoted as
 mean left eye center x  mean left eye center y  
across the n training images by computing the average of the n
coordinates of  left eye center x  left eye center y  
now  given a new test facial image  represented by a        pixel matrix   we search
in a certain region of candidate pixels around
 mean left eye center x  mean left eye center y 
for our prediction on its left eye center position  a
relatively simple but effective searching scheme is square
searching  denoting search size  a tuning parameter  as the
maximum search step we move in both directions starting from
 mean left eye center x  mean left eye center y  
  this algorithm is inspired by       and we implement it with some
modifications 
  if any patch is out of boundary  we just discard it  so more precisely  the
number of patches is less than or equal to n  but for the purose of illustration
here  we will assume we have obtained n such patches 

fifacial keypoints detection  yue wang   yang song

we essentially search in a square region of width
    search size      centered at that point  around
each of those candidate pixels is a candidate patch of
size     patch size           patch size       we
investigate those surrounding candidate patches to see which
one has the highest relation with the mean patch p found
above 
to measure the relation of two patches  we first melt each
of the two pixel matrices row by row into a column vector
and then calculate their relational score  we use two scorings 
 i  correlation   ii  mutual information  mi  
finally  we select the candidate pixel whose surrounding
candidate patch produces the highest score 
note that search size is a tuning parameter  this means
we can adjust search size in order for our model to produce
the smallest rmse  eq       on the hold out test set stest  

 

table iii  training and test error rates for predicting
right eye center 
search size
 
 
 
 
 
 

scoring
correlation
mi
correlation
mi
correlation
mi
correlation
mi
correlation
mi
correlation
mi

training error

test error

      
      
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      

iii  r esults and d iscussion
table ii lists the training and hold out test errors for predicting left eye center using histogram stretching plus pca
plus mean patch searching with correlation scoring and mi
scoring  where the uning parameter search size changing
from   to    we complie them into the training and test error
curves  as shown in figure   
table ii  training and test error rates for predicting
left eye center 
search size
 
 
 
 
 
 

scoring
correlation
mi
correlation
mi
correlation
mi
correlation
mi
correlation
mi
correlation
mi

training error

test error

      
      
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      

fig     training and test error curves for predicting
right eye center 

several points are worth to be mentioned 




fig     training and test error curves for predicting
left eye center 
in parallel  we obtain the training and hold out test errors for
predicting right eye center in table iii  and depict them
into figure   



for left eye center prediction  both of the scorings achieve the minimum hold out test error rate at
search size             for mutual information scoing
and        for correlation scoring  moreover  mutual information scoring always outperforms correlation scoring
in terms of both training error and test error  therefore 
for predicting left eye center  we would like to adopt
histogram stretching plus pca plus mean patch searching
with search size     and mutual information scoring
as our final hypothesis 
for right eye center prediction  mutual information
scoring attains its minimum hold out test error rate at
search size              whereas correlation scoring
does at search size               moreover  correlation scoring always outperforms mutual information
scoring in terms of both training error and test error 
therefore  for predicting right eye center  we would
like to adopt histogram stretching plus pca plus mean
patch searching with search size     and correlation
scoring as our final hypothesis 
note that as search size increases  the model flexibility  i e   model complexity  increases  in both figures
  and    we observe a striking phenomenon that as
model flexibility increases  the four training error curves
monotonically decrease  while the four test error curves

fifacial keypoints detection  yue wang   yang song



all exhibit u shape  this is a fundamental property in
machine learning that holds regardless of the particular
data set at hand and regardless of the learning algorithm
being used  when the test mse deviates vastly from
the corresponding training mse  the model is overfitting
the data  this is the case when we choose a fairly
large search size  since the resultant model would be
working too hard to find patterns in the training data and
may be picking up some patterns that are just caused
by random chance rather than by true properties of the
unknown underlying mechnism 
another interesting observation is that for each of
left eye center and right eye center  the holdout test error rates for different scorings converge to
each other at search size      this is also true
for the corresponding training error rates  the reason is
that at search size      we are just predicting each
facial keypoint as the mean of the corresponding keypoint
positions of the training stretched images  and thus the
scoring does not matter 

iv  c onclusion
we first summarize our whole algorithm in the following
flowchart  figure    
hold out cross
validation
training set
     
histogram
stretching

test set
     
histogram
stretching

stretched
images
principal
component
analysis





left eye center 
histogram stretching  pca  mean patch searching
with search size    
and mi scoring 
right eye center 
histogram stretching  pca  mean patch searching
with search size    
and correlation scoring 

the minimum hold out test mse for predicting
left eye center is         and the minimum holdout test mse for predicting right eye center is        
thus  our best
q average test mse for predicting both facial
 
 
keypoints is                   
          this result would
 
make us rank   out of the    submissions in the outstanding
public leaderboard of kaggle 
v  f uture w ork
due to time limitation  this term project has not exhausively
tried many different methods in the arsenal of machine learning  if this project could be continued in the future  in order to
compensate the unequally distributed illuminations and other
imaging details  we could perform several nonlinear image
enhancement and correction approaches such as homomorphic
filtering to normalize the brightness across an image and
increases contrast  in addition  we could implement template
matching to the image to search possible location of eye pair  
moreover  we will also try locally linear embedding and other
algorithms 
acknowledgment
we would like to express our sincere gratitude to prof 
andrew ng and the cs    course staff team  who have
given us insightful guidance and inspiring advice throughout
this project 
r eferences

eigenfaces
mean patch
searching

 

apply our
model to a
test stretched
image

our model

fig     flowchart of our algorithm for facial keypoints detection 
as discussed in the previous section  we conclude our final
hypotheses for predicting the locations of left eye center
and right eye center as follow 

    t  hastie  r  tibshirani  and j  friedman         the elements of
statistical learning  data mining  inference  and prediction  springer 
 nd edition 
    r  jain  r  kasturi  and b g  schunck         machine vision  mcgrawhill  inc 
    g  james  d  witten  t  hastie  and r  tibshirani         an introduction
to statistical learning with applications in r  springer 
    a  ng         lecture notes for cs      machine learning  stanford
university 
    l  sirovich and m  kirby         low dimensional procedure for the
characterization of human faces  journal of the optical society of
america a  vol        pp          
    q  wang and j  yang         eye location and eye state detection in
facial images with unconstrained background  journal of information
and computing science  vol        pp          
    contrast stretching 
http     homepages inf ed ac uk rbf hipr  stretch htm 
    eigenfaces for dummies 
http     jmcspot com eigenface default 
    eigenface tutorial 
http     www pages drexel edu  sis   eigenface   tutorial htm 
     kaggle online competetion  facial keypoints detection 
https     www kaggle com c facial keypoints detection 
     reconstructing pca matrix 
http     www r bloggers com reconstructing principal component analysis

fi