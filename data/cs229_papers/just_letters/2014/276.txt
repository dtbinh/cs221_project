multilevel local search algorithms for modularity clustering
randolf rotta and andreas noack  brandenburgische technische universitat cottbus

modularity is a widely used quality measure for graph clusterings  its exact maximization is np hard and
prohibitively expensive for large graphs  popular heuristics first perform a coarsening phase  where local
search starting from singleton clusters is used to compute a preliminary clustering  and then optionally a
refinement phase  where this clustering is improved by moving vertices between clusters  as a generalization 
multilevel heuristics coarsen in several stages  and refine by moving entire clusters from each of these stages 
not only individual vertices 
this article organizes existing and new single level and multilevel heuristics into a coherent design space 
and compares them experimentally with respect to their effectiveness  achieved modularity  and runtime 
for coarsening by iterated cluster joining  it turns out that the most widely used criterion for joining clusters
 modularity increase  is outperformed by other simple criteria  that a recent multistep algorithm  schuetz
and caflisch       is no improvement over simple single step coarsening for these criteria  and that the
recent multilevel coarsening by iterated vertex moving  blondel et al        is somewhat faster but slightly
less effective  with refinement   the new multilevel refinement is significantly more effective than the
conventional single level refinement or no refinement  in reasonable runtime 
a comparison with published benchmark results and algorithm implementations shows that multilevel
local search heuristics  despite their relative simplicity  are competitive with the best algorithms in the
literature 
categories and subject descriptors  i      pattern recognition   clusteringalgorithms  e    data   data
structuresgraphs and networks  g    mathematics of computing   mathematical softwarealgorithm
design and analysis  efficiency
general terms  algorithms  design  experimentation
additional key words and phrases  graph clustering  local search  modularity  multilevel  refinement
acm reference format 
rotta  r  and noack  a        multilevel local search algorithms for modularity clustering  acm j  exp 
algor         article      june           pages 
doi                           http   doi acm org                        

   introduction

a graph clustering partitions the vertex set of a graph into disjoint subsets called
clusters  modularity was introduced by newman and girvan        as a formalization
of the common requirement that the connections within graph clusters should be dense 
and the connections between different graph clusters should be sparse  it is by far not
the only quality measure for graph clusterings  gaertler       schaeffer       porter
a previous version appeared as multilevel algorithms for modularity clustering at the  th international
symposium on experimental algorithms  sea       
authors address  r  rotta  lehrstuhl theoretische informatik  btu cottbus  konrad wachsmann allee   
      cottbus  germany  email  rrotta informatik tu cottbus de 
permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for profit or commercial advantage and that
copies show this notice on the first page or initial screen of a display along with the full citation  copyrights for
components of this work owned by others than acm must be honored  abstracting with credit is permitted 
to copy otherwise  to republish  to post on servers  to redistribute to lists  or to use any component of this
work in other works requires prior specific permission and or a fee  permissions may be requested from
publications dept   acm  inc     penn plaza  suite      new york  ny            usa  fax         
          or permissions acm org 
c      acm                   art          

doi                         http   doi acm org                        
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi     

r  rotta and a  noack

et al        but one of the most widely used measures  and it has successfully been
applied for detecting meaningful groups in a wide variety of real world systems 
the problem of finding a clustering with maximum modularity for a given graph is
np hard  brandes et al         and even recent exact algorithms scale only to graphs
with a few hundred vertices  agarwal and kempe       brandes et al        xu et al 
       in practice  modularity is almost exclusively optimized with heuristic algorithms  and existing experimental results indicate that relatively simple heuristics
based on local search can be highly efficient and effective  e g   blondel et al        
and schuetz and caflisch      a   
elementary local search strategies are the iterated joining of cluster pairs  clauset
et al        newman     b  and the iterated moving of vertices between clusters
 barber and clark       blondel et al         two such heuristics can be combined
as a coarsening phase  which computes a preliminary clustering starting from singleton clusters  and a refinement phase  which further improves this clustering  typically
by vertex moving  schuetz and caflisch     a   this approach can be generalized to
multilevel local search  during the coarsening phase  a series of successively coarser
clusterings called coarsening levels is recorded  and the refinement moves entire clusters of these coarsening levels  not just individual vertices  such multilevel algorithms
proved to be very effective for minimum cut partitioning problems  hendrickson and
leland       preis and diekmann       karypis and kumar       walshaw and cross
       but have not previously been adapted to modularity clustering 
in order to systematically describe and compare a large number of existing and new
local search heuristics for modularity clustering  we organized them into a design space
with the following dimensions   i  coarsening algorithm   ii  criterion for choosing the
joined clusters or moved vertices in coarsening   iii  refinement algorithm   iv  criterion
for choosing the moved vertices or clusters in refinement  and  v  number of coarsening
levels  with the conventional single level as special case   sections   and   describe
design choices for each of these dimensions  including some new proposals  overall  the
design space contains major existing heuristics as well as a vast number of promising
new variations and extensions 
even for the existing heuristics  the comparability of the available evaluation results
is a major problem  the published modularity values and runtimes for the individual
heuristics have been obtained with different  and often small  graph collections and on
different hardware and software platforms  moreover  the design space contains many
new heuristics  which have not yet been empirically evaluated at all  therefore  we
have performed an extensive experimental comparison of the algorithms in the design
space  and present the results in section   
to demonstrate that multilevel local search algorithms are among the most effective
and efficient heuristics for modularity clustering  section   provides a comparison
with published benchmark results and implementations of various algorithms from
the literature 
   graph clusterings and modularity
     graphs and clusterings

a graph  v  f   consists of a finite set v of vertices and a function f   v  v  n
that assigns an edge weight to each vertex pair  to represent undirected graphs  this
function is symmetric  an undirected edge of weight w between vertices u   v is represented by f  u  v    f  v  u    w  a self edge  at vertex v by f  v  v     w  and missing

  undirected

self edges have to be counted in both directions 

acm journal of experimental algorithmics  vol      no     article      publication date  june      

fimultilevel local search algorithms for modularity clustering

     

edges have zero
 weight 
 the weights are naturally generalized to sets of vertices by
f  u    u       u  u  u  u  f  u    u    
the degree deg v  of a vertex v is the total weight
f   v   v   of its edges  it is naturally

generalized to sets of vertices by deg u      uu deg u   note that deg u    f  u  u  
for all u  v   and in particular deg v     f  v  v   
a graph clustering c    c            ck  partitions the vertex set v into disjoint nonempty
subsets ci  
     modularity

modularity is a widely used quality measure for graph clusterings  it was defined by
newman and girvan            a  for undirected graphs as

  f  c  c 
deg c  
 

q c    
f  v  v   deg v   
cc

intuitively  the first term is the actual fraction of intracluster edge weight  in itself 
it is not a good measure of clustering quality because it takes the maximum value   for
the trivial clustering where one cluster contains all vertices  the second term specifies
the expected fraction of intracluster edge weight in a null model where the end vertices
of the deg v     edges are chosen at random  and the probability that an end vertex of
deg v 
an edge attaches to a particular vertex v is deg v
 newman     a    in this null model 
 
the edge weight f  u  v  between a vertex pair  u  v   v   is binomially distributed with
deg v 
   among the many clustering quality measures that have
the expected value deg u 
deg v  
been proposed in the literature  gaertler       schaeffer        only few share this
important benefit of modularity  gaertler et al        noack     a      b   the clear
interpretation of its values as deviation of the clustering from the expectation in an
explicit null model 
joining two clusters c and d increases the modularity by
qc d   

  deg c  deg d 
  f  c  d 

 
f  v  v  
deg v   

and moving a vertex v from its current cluster c to another cluster d increases the
modularity by
qv d   

  deg v  deg d     deg v  deg c v 
  f  v  d     f  v  c v 

 
f  v  v  
deg v   

from an algorithmic perspective  this means that the modularity of a clustering can
be quickly updated after each move or join  there is no need to recompute it from scratch 
moreover  the search space can be restricted  because joining two nonadjacent clusters
  f  c  d       never increases the modularity  and moving a vertex to a nonadjacent
cluster   f  v  d       never increases the modularity more than moving it to a new 
previously empty cluster  where deg v  deg d  takes the smallest possible value    
modularity has a formal relation to  a specific notion of  intracluster density and
intercluster sparsity  let the weighted density between two different clusters c and d
f  c d 
be defined as deg c 
  in each maximum modularity clustering of a given graphin
deg d 
fact  in each clustering whose modularity cannot be increased by joining or splitting
clustersthe weighted density between any two clusters is at most the weighted denf  v v  
within the entire graph  and the weighted density between any two subclussity deg v
  
ters obtained by splitting a cluster is at least the weighted density within the graph
 reichardt and bornholdt       noack        this follows from the fact that joining
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi     

r  rotta and a  noack

two clusters c and d increases the modularity if and only if
f  c  d 
f  v  v  
 
 
deg c  deg d 
deg v   
the modularity measure has been criticized for its so called resolution limit  that
is  the fact that two dense subgraphs connected by only one light weight edge are
joined into a single cluster if the overall density within the graph is sufficiently small
 fortunato and barthelemy        however  the resolution of optimal clusterings can
be arbitrarily increased or decreased by multiplying the second term of the modularity
measure with a positive constant greater or smaller than   
   local search algorithms

cluster joining  cj  and vertex moving  vm  are two classes of local search heuristics
that are widely used for improving clusterings in general  and for increasing modularity
in particular  cj algorithms iteratively join two clusters  vm algorithms iteratively
move individual vertices to different clusters  including newly created clusters   the
cluster pair of each join  or the vertex and target cluster of each move  are chosen
according to a certain priority criterion  called prioritizer  which is a parameter of
the algorithm  this section introduces two cj algorithms  three vm algorithms  and
several prioritizers 
among the large variety of local search heuristics  aarts and lenstra        the
presented techniques were selected because of their simplicity  popularity  and proven
suitability for modularity clustering or related problems  notable exclusions are
simulated annealing kirkpatrick et al          used for modularity clustering in
guimera and amaral         massen and doye         medus et al          and
reichardt and bornholdt         and extremal optimizations  boettcher and percus
       used for modularity clustering in duch and arenas          for these heuristics 
a thorough experimental evaluation is particularly difficult and expensive due to their
explicit randomness 
     single step joining

single step joining  cj   iteratively joins the cluster pair with the largest priority
until this join would not increase the modularity 
implementation notes  the join priority of each cluster pair can be computed in constant
time from the total edge weight between the two clusters  see section       these total
weights change locally with each join and are thus stored in a dynamically coarsened
graph where each cluster is represented by a single vertex  in each join of two vertices
u and v  the edge list of the vertex with fewer edges  say u  is joined into the edge list
of the other vertex  using the sorted double linked edge lists proposed by wakita and
tsurumi         this requires linear time in the list lengths  however  if some neighbor
vertices of u are not neighbors of v  then one end vertex of the edges to these neighbors
changes from u to v  and the position of these edges in the neighbors edge lists must
be corrected to retain the sorting 
let n be the initial number of clusters  m be the initial number of adjacent cluster
pairs  and d be the final height of the join tree  merging the edge lists of two clusters
has linear runtime in the list lengths  and each edge participates in at most d joins 
thus  the worst case runtime is o dm  for the joins and  given that the length of each
edge list is at most n  o dmn  for the position corrections  in practice  the number
of corrections and the list lengths are typically much smaller than the worst case
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fimultilevel local search algorithms for modularity clustering

     

algorithm    multistep joining algorithm
input  graph  clustering  join prioritizer  join fraction
output  clustering
while  cluster pair  c  d    qc d     do

l  join fraction    c  d    qc d      
sort cluster pairs by join prioritizer 
mark all clusters as not joined 
for  l
 most prioritized pairs  c  d  do
if c and d are not marked as joined then
join clusters c and d 
mark clusters c and d as joined 
end
end
end

bounds   the implementation of clauset et al         has better worst case bounds  but
experimental results in section   indicate that it is not more efficient in practice  
in order to quickly find the prioritized cluster pair for the next join  a priority queue
 max heap  is used  as proposed by clauset et al          the priority queue contains
the currently best partner of each cluster  after each join  the best partners of all
adjacent clusters are updated  as proposed by wakita and tsurumi         the total
number of these updates is bounded by dm  taking at most o dmlog n  runtime 
     multistep joining

to prevent extremely unbalanced cluster growth  schuetz and caflisch      a  introduced multistep joining  cjx   which iteratively joins the l disjoint cluster pairs having
the highest priority  excluding pairs not increasing the modularity  a follow up
paper

 schuetz and caflisch     b  provided the empirical formula lopt           e  for the
modularity increase prioritizer on unweighted graphs 
however  the optimal value of the parameter l is highly dependent on the graph size
and not necessarily on the total edge weight in weighted graphs  for example  doubling
a graph by adding a second copy of itself doubles the number of disjoint pairs and thus
also doubles the optimal value of l  and doubling all edge weights would change lopt but
not the optimal clustering 
therefore  we specify l as percentage of the number of modularity increasing cluster
pairs  and call this percentage join fraction  it performs as good as the empirical formula
lopt  see section    and is suitable for weighted graphs as well  single step joining  cj  
conceptually corresponds to the special case of l      and for uniformity  we also denote
it as cjx with    join fraction 
implementation notes  the same basic data structures as in cj  are used  a pseudocode
version is shown in algorithm    to iterate over the l best cluster pairs in priority order 
the edges are sorted once before entering the inner loop  this requires o mlog m  time
in the worst case  alternative implementations optimized for very small join fractions
could use partial sorting with o mlog l   but a larger constant factor   of these l cluster
pairs  only disjoint pairs are joined by marking the used clusters  the number of
iterations through the outer loop may be close to n if few disjoint pairs of adjacent
clusters exist  as in some power law graphs but is typically much smaller 
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi     

r  rotta and a  noack

     global moving

global moving  gm  repeatedly performs the globally best vertex move until no further modularity increasing vertex move is possible  here the best vertex move is a
modularity increasing move with the highest priority over all vertices v and target
clusters d  including a new  previously empty cluster  
implementation notes  vertices are moved in constant time using a vector mapping
vertices to their current cluster  to find the best move  the move priority for each
vertex v and each cluster d needs to be determined  this move priority can be computed
in constant time from the total edge weight f  v  d  between v and d  see section      
for each vertex  the algorithm collects these weights in one pass over its edges and
stores them in a temporary vector  thus  finding the globally best move requires a
constant time visit of all m edges  assuming o n  moves yields a runtime of o nm  
     local moving

the local moving  lm  algorithm repeatedly iterates through all vertices  in randomized order  and performs the best move for each vertex  until no modularity increasing
move is found for any vertex  the best move of a vertex is the modularity increasing
move with the highest priority over all target clusters  including a new  previously
empty cluster   if no modularity increasing move exists  the vertex is not moved 
lm has been previously proposed by schuetz and caflisch      a   ye et al         
and blondel et al         
implementation notes  the implementation is very similar to gm  the worst case time
for one iteration over all n vertices is o m   and very few iterations usually suffice 
     adapted kernighan lin moving

kernighan lin moving  kl  extends gm with a basic capability to escape local maxima 
the algorithm was originally proposed by kernighan and lin        for minimum cut
partitioning  and was adapted to modularity clustering by newman      b   though
with a limitation to two clusters   in its inner loop  the algorithm iteratively performs
the globally best vertex move  with the restriction that each vertex is moved only once 
but without the restriction to increase the modularity with each move  after all vertices
have been moved  the inner loop is restarted from the best found clustering  preliminary
experiments indicated that it is much more efficient and rarely less effective to abort the
inner loop when the best found clustering has not improved in the last k       log   v  
vertex moves  rotta       
implementation notes  the implementation is largely straightforward  see algorithm     to improve efficiency  the current clustering is only copied to peak when
the modularity begins to decrease  the worst case runtime is the same as for gm  assuming that a few outer iterations suffice  in practice  the kl method runs somewhat
longer because it also performs modularity decreasing moves 
     join prioritizers

a join prioritizer assigns to each cluster pair  c  d  a real number called priority and
thereby determines the order in which the cj algorithms select cluster pairs  because
the joining algorithms use only the order of the priorities  two prioritizers can be
considered equivalent if one can be transformed into the other by adding a constant or
multiplying with a positive constant 
the modularity increase  mi  qc d resulting from joining the clusters c and d is
an obvious and widely used prioritizer  newman     b  clauset et al        schuetz
and caflisch     a  ye et al        
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fimultilevel local search algorithms for modularity clustering

     

algorithm    adapted kernighan lin moving algorithm
input  graph  clustering  move prioritizer
output  clustering
repeat
peak  clustering 
mark all vertices as unmoved 
while unmoved vertices exist do
 v  d   best move with v unmoved 
move v to cluster d  mark v as moved 
if q clustering    q peak  then peak  clustering 
if k moves since last peak then break  
end
clustering  peak 
until no improved clustering found 
f  c d 
the weighted density  wd  is defined as deg c 
  that is  as the quotient of
deg d 
the actual edge weight between c and d and the expected edge weight in the null
model of section      up to a constant factor   it is equivalent  in the earlier sense 
qc d
to deg c 
  as derived in section      clusterings with maximal modularity have a
deg d 
small intercluster density and a large intracluster density  despite this close relation 
the wd has not previously been used as prioritizer in modularity clustering 
the z score  zs    another new prioritizer  is defined as  qc d
  and is thus a
deg c  deg d 

natural compromise between mi and wd  a further motivation is its relation to the
 im probability of the edge weight f  c  d  in the null model described in section     
under this null model  both the expected value and the variance of the edge weight
deg d 
for large enough deg v    and the zs is
between c and d are approximately deg c 
deg v  
equivalent to the number of standard deviations that separate the actual edge weight
from the expected edge weight  in contrast  the standard deviation of mi grows with
deg c  deg d   and thus it is biased toward joining large clusters  while  conversely 
wd is biased toward joining small clusters 
the graph conductance  gc  measure   kannan et al        was proposed as join
qc d
  based on the observation
prioritizer by danon et al         in the form min deg c  deg d  
that the mi qc d tends to prioritize pairs of clusters with large degrees  it equals the
zs if deg c    deg d   and it is another compromise between mi and wd 
wakita and tsurumi        found that joining by mi tends to join clusters of extremely
uneven sizes 
to suppress unbalanced joining  they proposed the prioritizer
 size c 
 
min size d 
q
  size d 
  where size c  is either the number of vertices in c  priorc d
size c 
itizer whn  or the number of other clusters to which c is connected by an edge of
positive weight  prioritizer whe  
other types of prioritizers are clearly possible  for example  vertex distances from
random walks or eigenvectors of certain matrices have been successfully applied in several clustering algorithms  pons and latapy       donetti and munoz       newman
    a   however  preliminary experiments suggest that these relatively complicated
and computationally expensive prioritizers may not be more effective than the simple
prioritizers in this section  rotta       
  this
  this

prioritizer was named significance  sig  in earlier publications 
prioritizer was named danon  da  in earlier publications 

acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi     

r  rotta and a  noack

algorithm    multilevel clustering algorithm
input  graph  coarsener  refiner  reduction factor
output  clustering
   coarsening phase
level     graph 
repeat
clustering  vertices of level l  
clustering  coarsener level l   clustering  reduction factor  
if cluster count reduced then
level l     contract each cluster of clustering into a single vertex 
end
until cluster count not reduced 
   refinement phase
clustering  vertices of level lmax   
for l from lmax    to   do
clustering  project clustering from level l    to level l  
clustering  refiner level l   clustering  
end

     move prioritizers

a move prioritizer assigns a priority to each combination  v  d  of a vertex v  v
and a target cluster d  c  again  the modularity increase  mi  qv d is the most
obvious prioritizer  and it is used by all previously published moving algorithms  arenas
et al        blondel et al        liu and murata       lu and huang       mei et al 
      newman     b  schuetz and caflisch     a  sun et al         move prioritizers
corresponding to the other join prioritizers can be constructed canonically using the
priority of the join   v   d   ignoring the current cluster of v   for the mi move prioritizer 
qv d is equivalent to q v  d if v is fixed  
if move priorities of the same vertex  for different target clusters  are compared  as
in lm  then ignoring the current cluster of the vertex does not distort the order of the
priorities  because the current cluster is the same for all compared moves  however  if
move priorities of different vertices are compared  ignoring the current cluster means
that small improvements of already well assigned vertices can be favored over much
larger improvements of poorly assigned vertices  therefore  only mi  which takes the
current cluster into account  will be used with gm and kl 
moving a vertex v to a previously empty cluster d is a special case  because deg d   
   the values of the formulas for all move prioritizes except mi are undefined  joining  v 
with the empty cluster d does not change the clustering  thus q v  d      because all
move prioritizes except mi are  or can be expressed as  normalized forms of q v  d 
their natural value for an empty d is   
   multilevel local search algorithm

vm algorithms move only a single vertex in each step  they are thus unlikely to move
an entire group of densely interconnected vertices to another cluster  because this would
require a series of sharply modularity decreasing vertex movesa serious limitation 
particularly for large graphs  however  a successive coarsening  started from singlevertex clusters  may well have joined this densely connected vertex group into a single
cluster at some stage of the coarsening  then  a vertex mover could easily reassign it
by moving entire clusters of this intermediate clustering  instead of individual vertices 
this is the basic idea of multilevel search heuristics 
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fimultilevel local search algorithms for modularity clustering

     

definition  the multilevel clustering algorithm proceeds in two phases  see algorithm     the coarsening phase produces a sequence of graphs called coarsening levels 
the first coarsening level is the input graph  on each coarsening level  a clustering
is computed using a coarsener  which can be any cj or vm algorithm from section   
the coarsener starts with a clustering where each cluster is a single vertex  of the
respective coarsening level   and runs until  i  it terminates  or  ii  it has decreased the
number of clusters by a certain percentage since its start  this percentage is provided
as a parameter called reduction factor  the next coarsening level is generated by contracting each cluster of the resulting clustering into a single vertex  the coarsening
phase ends when a fixed point is reached  i e   when the coarsener terminates without
changing the clustering  
the subsequent refinement phase visits the coarsening levels in reverse order  that is 
from the coarsest graph to the original graph  and computes a clustering for each level 
on the coarsest level  the final clustering is the trivial clustering with single vertex
clusters  on each subsequent level  the initial clustering is obtained by projecting the
final clustering of the previous level  that is  the initial cluster of each vertex is the
final cluster of the respective vertex on the previous level  then a refiner is applied
on this initial clustering to compute the final clustering of the coarsening level  the
refiner can be any vm algorithm  cj algorithms are unlikely to find joinable clusters
in a nearly optimal clustering 
as abbreviated name for this multilevel refinement  moving on all coarsening levels 
mlx will be used  where x is the reduction factor used during the coarsening phase 
the conventional single level refinement  moving just vertices of the original graph 
will be abbreviated by slx  where x is the reduction factor again 
discussion  generally  the number of coarsening levels increases with decreasing reduction factor  on the one hand  this means that the refiner has more opportunities to
improve the clustering  on the other hand  the more frequent contraction in coarsening
and the more thorough refinement tend to increase the runtime 
for coarsening by cj  the reduction factor does not affect the final coarsening
level  because the initial clusters of each coarsening level have essentially the same
properties  degrees  edge weights  as the final clusters of the previous level  thus 
the final clustering of the coarsening phase is independent of the reduction factor   in practice  minor variations are possible due to different tie breaking of join
priorities  
for coarsening by vm  a smaller reduction factor generally decreases the final clustering quality produced by the coarsening phase because the vertex movers on each
level are terminated before they have reached their modularity optimum  and some of
the resulting suboptimalities may not be correctable subsequently on coarser graphs 
on the other hand  the premature termination reduces the total runtime of the coarseners  but  as mentioned before  increases the total runtime of the graph contraction and
the refinement phase  
with a reduction factor of       coarsening by cj produces exactly two coarsening
levels  the refiner works on only one level  namely the original graph  in contrast  coarsening by vm may still produce several coarsening levels  on each level  the coarsener
terminates when no further modularity increasing vertex moves exist  but then each
cluster is contracted into a single vertex  which may enable new modularity increasing
moves at the next coarsening level 
related work  the basic idea of multilevel search heuristics already proved to be very
effective for minimum cut partitioning problems  popular implementations of such
heuristics are chaco  hendrickson and leland        party  preis and diekmann
       metis  karypis and kumar        and jostle  walshaw and cross       
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi      

r  rotta and a  noack

instead of maximizing the modularity quality measure  their task is to simultaneously
minimize the between cluster edge weight and the cluster weight imbalance for a fixed 
configurable number of clusters 
in the coarsening phase  the minimum cut heuristics use join prioritizers related to
cut minimization and balancing the cluster weights  because the requested number of
clusters is known  most implementations abort the coarsening phase earlier and use
other heuristics to find a good initial clustering with the required size  in contrast 
prioritizers for the modularity should be related to the null model and finding a good
number of clusters is part of the modularity clustering problem  here  the coarsening
phase already produces an initial clustering with a good size  and clusters are dynamically added and removed in the refinement phase  for minimum cut partitioning  very
efficient implementations of kl exist and are used often  unfortunately  the modularity measure introduces more global dependencies  which makes global move selection
inefficient 
several recent algorithms for modularity clustering are related to the multilevel
clustering algorithm  but differ in crucial respects  blondel et al         first proposed
multilevel coarsening by lm  but their heuristic has no refinement phase  many previous heuristics combine a clustering algorithm with single level refinement  that
is  refinement only on the original graph  massen and doye       newman     b 
richardson et al        schuetz and caflisch     a   algorithms by sun et al        
and ye et al         move vertices in several clusterings of different coarseness  but
only vertices of the original graph instead of coarse vertices  clusters   djidjevs       
method is not itself a multilevel algorithm  but a divisive method built on an existing
multilevel algorithm for minimum cut partitioning 
implementation notes  with coarsening by cj and reduction factor   the number of
generated coarsening levels is at most log       n   with coarsening by vm  the number
of levels will be slightly higher due to levels forced by local optima 
to generate each coarsening level  the vertices and edges of the previous level are
contracted using the clustering produced by the coarsener  only the clustering produced
by the not the coarse graphs  coarsener  are used to decouple the multilevel clustering
from details of the coarsener  to contract the edges  for each cluster the outgoing edges
of its vertices are collected and sorted by the cluster of their target vertex  then a
single iteration over the sorted edges suffices to add a new coarse edge each time a
new target cluster occurs  the weights of the edges falling into the same coarse edge
are summed so that the total edge weight f  v  v   and deg v   does not change  all
together  constructing the coarse graph takes at most o mlog m  time per level 
the projection of clusterings from each coarsening level to its previous level is trivial 
for each vertex the cluster name of its coarse vertex is copied using a vector that
maps each vertex to its coarse vertex  this vector is constructed as by product of the
contraction  thus  cluster projection is a linear time operation 
   experiments

the multilevel clustering algorithm introduced in the previous section has five parameters  as summarized in table i  the coarsener  including the join fraction  with
its prioritizer  the coarsening and refinement levels  including the reduction factor  
and the refiner with its prioritizer  the values of these parameters are encoded using a simple naming scheme  as for example in cj  mi ml   lm mi  this section
examines empirically the impact of the parameters on the effectiveness  achieved modularity  and efficiency  runtime  of multilevel clustering  after a description of the
experimental set up  four sections present the results concerning
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fimultilevel local search algorithms for modularity clustering

      

table i  parameters of the multilevel clustering algorithm
coarsening method  section    
cj 
single step cluster joining     join fraction 
cjx
multistep cluster joining  with x  join fraction 
lm
local vertex moving
gm
global vertex moving
coarsening prioritizer  section      
zs
z score prioritizer
gc
graph conductance prioritizer
mi
modularity increase prioritizer
wd
weighted density prioritizer
whn  whe wakitas node  and edge based prioritizers
levels  section    
slx
single level refinement  vertex moving just on the original graph
mlx
multilevel refinement  on all coarsening levels  with x  reduction factor 
refinement method  section    
lm
local vertex moving
gm
global vertex moving
kl
adapted kernighan lin moving
no
doing nothing
refinement prioritizer  section      
zs
z score prioritizer
gc
graph conductance prioritizer
mi
modularity increase prioritizer
wd
weighted density prioritizer

the parameters of coarsening by cj 
the parameters of coarsening by lm 
the comparison of the coarsening algorithms  joining  lm  and gm  with their best
parameters  and
the parameters of refinement  by lm and gm  
     set up

the algorithms  were implemented in c    the software uses the boost library  dawes
et al        version      and the boost graph library  siek et al        for interface
definitions and graph adapter classes  all experiments were performed on a    ghz
intel core   duo processor  without using the second core  with  gb main memory 
the operating system was macos        with the gnu compilers version       from
apples developer tools 
to compare the effectiveness of the algorithms  the mean modularity over a fixed set
of benchmark graphs is measured  higher means indicate more effective algorithms 
thus  only the differences between the means are interpreted  the absolute values are
not intended to be meaningful  the runtimes of the implementations are compared
using the geometric mean of runtime ratios relative to a reference implementation 
this mean ratio indicates how many times longer an implementation runs on average 
compared to the reference implementation  all runtime measurements exclude the
time required for reading the input graphs 
the sample of benchmark graphs is composed of    real world graphs from various
public sources as listed in the appendix   the available graphs were classified by their
application domain  and graphs of diverse size that represent fairly all major domains
were selected  with a preference for common benchmarks like zacharys        karate
club network  the graphs range from a few to   k vertices and    k edges 
  source
  the

code available at http   www informatik tu cottbus de rrotta  
complete graph collection can be requested from the authors by e mail 

acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi      

r  rotta and a  noack

to indicate the significance  of the differences between the algorithms  we specify for
each measurement value  sample mean of the modularity or sample mean of runtime
ratio  a confidence interval on the     level of the population mean   to improve
the readability of the diagrams  some confidence intervals are not shown if they are
similar to nearby intervals   if  for example  the sample mean of the runtime ratio for
an algorithm lies outside the confidence interval of the population mean for another
algorithm  the actual efficiency of the two algorithms differs with high probability 
to be precise  the confidence interval listed for each modularity value does not refer
to the mean modularity achieved by the algorithm  but to the mean difference of its
modularity to the modularity of a specified reference algorithm  as mentioned earlier 
only the differences  not the absolute values  of the modularities are meant to be
interpreted  because nothing is known about the distribution of the measurement
values  bootstrapping is used to compute the intervals  diciccio and efron        note
that absolute differences between modularity values are not always a reliable indicator
for the significance of differences between algorithms  close to the optimum  modularity
differences necessarily become smaller  but may still be highly significant 
besides real world graphs  algorithms and quality measures can also be compared
on synthetic graphs with known clusters  the conformance of computed clusters to
known clusters can be quantified using a distance measure for clusterings  for example 
the normalized mutual information  see delling et al         for a review   girvan
and newman        proposed random graphs with fixed probabilities for within  and
between cluster edges  which were used in barber and clark         brandes et al 
        danon et al          newman and girvan         and pons and latapy        
recently  interest in other models of clustered random graphs increased  especially
for other vertex degree distributions  karrer and newman       lancichinetti and
fortunato     a      b  mei et al         sun et al         studied a bias of spectral
clustering methods on erds renyi random graphs  and arenas et al         used
deterministically generated graphs with hierarchical clusters  while such experiments
help to evaluate combinations of an algorithm and a quality measure with respect to
their ability to reconstruct certain a priori clusterings  they do not contribute to the goal
of this section  namely to compare algorithms with respect to their ability to maximize
a given fixed quality measure 
     coarsening by cj

for all coarsening experiments  results without any refinement and results with standard refinement will be presented  where standard refinement is lm with mi prioritizer  as discussed in section      this choice of refinement parameters does not bias
the results of the coarsening experiments because it is as effective as all other choices
 except kl   independently of the coarsening parameters 
figure   compares the prioritizers and join fractions for coarsening by cj without
refinement  with refinement at reduction factor       and with multilevel refinement
at reduction factor     
observations on the effectiveness of the prioritizers  left diagrams  include the following 
the zs and gc prioritizers are among the best for all join fractions without and with
refinement 
wd is slightly worse without refinement  but competitive with refinement at reduction factor      apparently  refinement benefits from its bias toward balanced cluster
growth 
  the

term significant is used in its statistical sense  probably not caused by mere chance 

acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi







geomean runtime ratio  logscale
           
   
   



   

mean modularity
                                  

multilevel local search algorithms for modularity clustering

 

  

  
  
join fraction    

  

   

      



cj zs no
cj gc no
cj wd no
cj mi no
cj whn no
cj whe no











  
  
join fraction    

  

   







  
  
join fraction    

  

   





  

   



 

  








cj zs ml    lm
cj gc ml    lm
cj wd ml    lm
cj mi ml    lm
cj whn ml    lm
cj whe ml    lm
cj zs no

    



 

  

  
  
join fraction    

  

geomean runtime ratio  logscale
           
   
   









   



mean modularity
    
    
    

    

 a  without refinement   no  

   

 

  









    



 

  



cj zs ml   lm
cj gc ml   lm
cj wd ml   lm
cj mi ml   lm
cj whn ml   lm
cj whe ml   lm
cj zs no

  
  
join fraction    

  

   









   



mean modularity
              

    



geomean runtime ratio  logscale
           
   
   

 b  with multilevel refinement at      reduction factor   ml    lm mi  

 

  

  
  
join fraction    

 c  with multilevel refinement at     reduction factor   ml   lm mi  

fig     coarsening by cj with different prioritizers and join fractions  all confidence intervals and runtime
ratios are relative to cj  zs no  zs prioritizer at    join fraction without refinement  

mi is competitive without refinement  but not with refinement  apparently  the refinement suffers from its bias toward unbalanced cluster growth 
wakitas prioritizers whe and whn are much less effective than the others 
concerning the effectiveness of the join fractions  in particular the comparison of
single step joining  join fraction     and multistep joining  join fractions greater
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi      

r  rotta and a  noack

than      the figures allow the following observations 
only for the mi prioritizer with join fractions below     and without refinement 
cjx is more effective than cj   here it counteracts the bias of mi toward unbalanced
cluster growth 
for the best prioritizers  in particular zs  cj  is more effective than cjx  here  the
artificial restriction of cjx regarding the joinable cluster pairs is not necessary to
balance cluster growth  but impedes some effective joins 
in respect of the efficiency  right diagrams   the most efficient prioritizers are the zs
and the wd  independently of the join fraction  and cj  is faster than cjx 
overall  cj  with the zs prioritizer  closely followed by wd and gc  produces
the best clusterings in the shortest time  particularly in the more effective case with
multilevel refinement 
     coarsening by lm

figure   compares prioritizers and reduction factors for coarsening by lm 
concerning the reduction factors       is most effective without refinement  because the coarseners are not terminated before they reach their local optimum  with
refinement  the effectiveness is similarly good for reduction factors above     and
slightly degrades with lower reduction factors  the efficiency is best for reduction factors around     to      for smaller reduction factors  generating the large number
of coarsening levels is expensive  while for larger reduction factors  the coarseners run
significantly longer 
concerning the prioritizers  the impact on the achieved modularities and runtimes
is rather minor  especially for the most effective reduction factors  the differences
between the prioritizers are not statistically significant  they are naturally smaller
than in cj because the prioritizers are only used to compare moves of the same vertex 
which reduces their difference  and because the vertices are moved in randomized
order  which reduces the risk of unbalanced cluster growth 
overall  in the more effective case of refinement with high reduction factors  vertex
moving is similarly effective with all prioritizers  and most efficient  by a small margin 
with the mi prioritizer 
     coarsening by cj vs  coarsening by lm and gm

figure   compares coarsening by cj  with its best prioritizer zs and best join fraction     i e   cj    lm  with its best prioritizer mi   and gm  with its only applicable
prioritizer mi  
gm is by far the slowest coarsener  more surprisingly  it is also less effective than
lm  the reason is the unbalanced cluster growth caused by the mi prioritizer  which
is less pronounced in lm due to the randomized order of the moved vertices 
without refinement  lm with the best reduction factor        is more effective
than cj with any reduction factor  however with refinement  cj with reduction factor
below     is more effective than lm with any reduction factor 
concerning the efficiency  the best lm  with refinement at reduction factor       is
around two times faster than the comparable effective cj  with refinement at reduction
factor      
     refinement by lm and gm

for these experiments  a good joining  cj  zs  and a good moving heuristic  lm mi 
will be used as standard coarseners 
figure   compares move prioritizers for refinement by lm in combination with
coarsening by joining  cj  zs  and coarsening by moving  lm mi   all prioritizers are
almost equally effective and efficient  after a reasonably effective coarsening phase 
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fimean modularity
    
    
    








      

 

  

  
  
reduction factor    

  

   

lm zs ml no
lm gc ml no
lm wd ml no
lm mi ml no













   

    



geomean runtime ratio  logscale
   
   
       

    

multilevel local search algorithms for modularity clustering

 

  

  
  
reduction factor    

  

   










lm zs ml lm
lm gc ml lm
lm wd ml lm
lm mi ml lm
lm mi ml no






  
  
reduction factor    

  

   

     

mean modularity
                 







geomean runtime ratio  logscale
   
   
       

     

 a  without refinement  ml no   modularity relative to lm mi ml    no 

 

  

  
  
reduction factor    

  

   

 

  

   

 b  with standard refinement  ml lm mi   modularity relative to lm mi ml    lm 
fig     coarsening by lm with different prioritizers and reduction factors  the runtime ratios are relative
to lm mi ml    no  mi prioritizer at      reduction factor without refinement  

few opportunities for increasing modularity are left  so there is not much to prioritize 
therefore  the mi prioritizer is used for the standard refinement and in the following
experiments 
concerning the reduction factor  figure   a  shows that it is irrelevant for multilevel
coarsening by cj without refinement  cj  zs ml no   but has a significant impact
when adding refinement  cj  zs ml lm   thus  with coarsening by cj the reduction
factor is essentially a parameter of the refinement  a reduction factor of     turns
out to be more effective than     and       and is similarly efficient  reduction
factors below     do improve the modularity slightly  but increase the runtime  with
coarsening by lm  figure   b    the impact of the reduction factor on the effectiveness
is limited  apparently  its opposing effects on coarsening and refinement  see section   
almost cancel out  here  reduction factors from     to      are effective and efficient 
figure   compares refinement by lm  refinement by gm  and refinement by kl
for various reduction factors and the only common applicable prioritizer  modularity increase   refinement by lm significantly improves the clusterings with limited
additional runtime  around two times slower than without any refinement   gm
is as effective as lm  but around five times slower  this confirms the observation
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fimean modularity
     
     



 









  

  
  
reduction factor    

  

   

geomean runtime ratio  logscale
        
           

r  rotta and a  noack

     

      

cj  zs ml no
lm mi ml no
gm mi ml no







 

  



  
  
reduction factor    

  



   







mean modularity
     
     
     



     



 

  

  
  
reduction factor    

  

   

geomean runtime ratio  logscale
        
           

     

 a  without refinement  ml no   modularity relative to cj  zs ml   no 






cj  zs ml lm
lm mi ml lm
gm mi ml lm
cj  zs ml no



 

  

  
  
reduction factor    





  

   

 b  with standard refinement  ml lm mi   modularity relative to cj  zs ml   lm 
fig     coarsening by joining  cj   and moving  lm  gm  with their best prioritizers  the runtime ratios
are relative to cj  zs ml   no  zs prioritizer at     reduction factor without refinement  

from the prioritizer comparison  that the order of the vertex moves is irrelevant during
the refinement phase  only kl turns out to be more effective than lm  apparently  its
ability to escape local optima is indeed effective  however  the huge runtime overhead
makes it unsuitable for most applications 
figure   compares refinement on all coarsening levels  multilevel  ml  and refinement on just the original graph  single level  sl    for coarsening by cj  zs  the
multilevel refinement is significantly more effective than the conventional singlelevel refinement for reductions factors smaller than       for a reduction factor of
      both are identical  for coarsening by lm mi  multilevel refinement is more
effective than single level refinement for all reduction factors  and  of course  better
than no refinement  
overall  a significant improvement of the coarsening results in reasonable time is
achieved by lm refinement with any prioritizer and a reduction factor around     for
coarsening by cj or around     to      for coarsening by lm 
  for

the largest graph  wordnet    cj  zs at reduction factor     produced just    coarsening levels  and
lm mi at reduction factor      produced   coarsening levels 

acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi







mean modularity
     
     
     



     



 

  

      

  
  
reduction factor    

  

   

cj  zs ml lm zs
cj  zs ml lm gc
cj  zs ml lm wd
cj  zs ml lm mi
cj  zs ml no



geomean runtime ratio  logscale
   
       
   

     

multilevel local search algorithms for modularity clustering






 

  

  
  
reduction factor    



  

   

 a  based on coarsening by cj  zs  modularity relative to cj  zs ml   lm mi 





     

mean modularity
     
     



 

  

  
  
reduction factor    

  

   

lm mi ml lm zs
lm mi ml lm gc
lm mi ml lm wd
lm mi ml lm mi
lm mi ml no



geomean runtime ratio  logscale
   
       
   

     













 

  

  
  
reduction factor    

  

   

 b  based on coarsening by lm mi  modularity relative to lm mi ml    lm mi 







mean modularity
     
     







     



 

cj  zs ml kl mi
cj  zs ml gm mi
cj  zs ml lm mi

  

  
  
reduction factor    

  

   

geomean runtime ratio  logscale
 
  
 
 
  

     

fig     lm refinement with different move prioritizers  the runtime ratios are relative to
cj  zs ml   lm mi  single step joining with zs at     reduction factor  





 

  

  
  
reduction factor    

  



   

fig     comparison of refinement algorithms  kl gm lm  using the mi move prioritizer  for the coarsening phase  cj  with zs prioritizer is used  all confidence intervals and runtime ratios are relative
to cj  zs ml   lm mi  lm refinement at     reduction factor   the mean modularity results of
cj  zs ml no were left out to improve the readability  see figure   a   

acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi      

r  rotta and a  noack



mean modularity
           



     



 

  

  
  
reduction factor    

  

   

geomean runtime ratio  logscale
   
   
   
       





     







cj  zs ml lm mi
cj  zs sl lm mi
lm mi ml lm mi
lm mi sl lm mi




 

  

  
  
reduction factor    

  



   

fig     comparison of multilevel  ml  and single level  sl  refinement  all confidence intervals and
runtime ratios are relative to lm mi ml    lm mi 

     conclusions

the best performing algorithms are coarsening by cj  with zs prioritizer and a
reduction factor of      and coarsening by lm with any prioritizer and a reduction factor of     to       both combined with refinement by lm with any
prioritizer 
concerning our new techniques  the zs prioritizer is indeed the best overall prioritizer for cj  it is slightly better than the gc prioritizer  and much better than the
widely used mi prioritizer  for coarsening by vm  the prioritizers have a marginal impact  multilevel refinement is indeed significantly more effective than the conventional
single level refinement and no refinement for both  coarsening by cj and coarsening
by local lm 
interestingly  single step joining  cj   outperforms the more complex multistep
joining  cjx  and lm is a similarly effective refiner compared to gm and is only
slightly less effective than kl 
   related algorithms

an exhaustive review and comparison of the numerous existing algorithms for modularity clustering is beyond the scope of this article  the purpose of this section is to
provide evidence that the heuristic cj  zs ml   lmcoarsening by cj  with the
zs prioritizer combined with multilevel refinement by lm with mi prioritizer and
reduction factor    is competitive with the best methods in the literature 
after a brief overview of modularity clustering algorithms in the first section  the
second section compares the results of cj  zs ml   lm with modularity values from
various publications  this type of comparison is widely used in the literature  but its
conclusiveness is severely constrained by the limited accuracy  printed digits  of the
modularity values  the small number of graphs shared by most publications  and the
unavailability or incomparability of published runtimes 
in order to directly compare the new heuristics with existing algorithms  a range of
publicly available implementations was retrieved from authors web sites and through
the igraph library of csardi and nepusz         because some of these implementations
can process only graphs with integer edge weights or unit weights  the comparison
is split into two sections  experiments on rounded edge weights and on unweighted
graphs 
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fimultilevel local search algorithms for modularity clustering

      

table ii  published algorithms related to the design space
algorithm
clauset et al          cnm 
danon et al        
wakita and tsurumi       
schuetz and caflisch      a   sc 
pons and latapy         pl 
pujol et al          pbd 
ye et al          yhy 
liu and murata         lpa 
blondel et al          bgll 
lu and huang         lh 
sun et al          sdjb 
cj  zs ml   lm
lm mi ml    lm

coarsening
multilevel refinement
cj  mi
no
cj  gc
no
cj  whn whe
no
cjx mi
sl
lm mi
cj    random walk
no
prejoining  modified cj  no
mixed gm mi  cj  mi
sl
gm mi
mixed lm mi  cjx mi
sl
lm mi
lm mi
ml      no
subdivision by tabu search sl
tabu search
spectral bisection   kl mi sl
kl mi
cj  zs
ml     lm mi
lm mi
ml      lm mi

     overview of algorithms

algorithms for modularity clustering can be categorized into the following four types 
subdivision  cluster joining  vertex moving  and mathematical programming  most
recent implementations actually use a combination of these approaches  table ii summarizes how some of these roughly fit into the design space 
subdivision heuristics successively divide clusters  some methods naturally produce
any number of clusters  for example by iteratively removing individual edges  bader
and madduri       newman and girvan        other algorithms  djidjev       duch
and arenas        in particular many eigenvector based methods  newman     b 
richardson et al        sun et al        white and smyth        essentially split the
graph into a fixed number of clusters  but are extended to arbitrarily cluster counts
through recursive application 
cj  or agglomeration  heuristics iteratively join clusters  cluster pairs can be selected based on random walks  pons and latapy       pujol et al         increase of
modularity  clauset et al        schuetz and caflisch     a  ye et al         or other
criteria  danon et al        donetti and munoz       wakita and tsurumi       
vm heuristics move vertices between clusters  with kl style  newman     b  sun
et al        and locally greedy moving  barber and clark       blondel et al       
liu and murata       mei et al        schuetz and caflisch     a  being the most
prominent examples  other approaches include tabu search  arenas et al        lu and
huang        extremal optimization  duch and arenas        and simulated annealing
 guimera and amaral       massen and doye       medus et al        reichardt and
bornholdt       
finally  mathematical programming approaches model modularity maximization as
a linear or quadratic programming problem  which can be solved with existing software
packages  agarwal and kempe       brandes et al        xu et al         for small
graphs  the integer linear programming methods allow the computation of optimal
modularity values 
     published modularity values

table iii compares the best modularity values from various publications with the
results of the heuristic cj  zs ml   lm  for small graphs  all classes contain algorithms that produce comparable or better clusterings  for larger graphs  the results of
cj  zs ml   lm are better than any published value  this can be attributed to the
multilevel refinement  which is not present in previous implementations 
on several small graphs  the label propagation algorithm lpa is able to find better
clusterings than cj  zs ml   lm  the algorithm basically produces a single coarsening level through lm mi and then applies cjx as postprocessing  liu and murata
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi      

r  rotta and a  noack

table iii  best published modularity values for four algorithm classes and the cj  zs ml   lm
heuristic in the last column
graph
size
karate
  
dolphins
  
polbooks
   
afootball
   
jazz
   
celeg metab
   
email
     
erdos  
     
pgp main
  k
cmat   main   k
nd edu
   k

subdivision
 n      
 n       
 gn      
 ws      
 sdjb      
 sdjb      
 sdjb      
 n       
 sdjb      
 sdjb      

joining
 yhy       
 pl       
 sc       
 yhy      
 sc      
 sc      
 sc      
 pbd       
 sc      
 yhy      
 sc      

moving
 da       
 lpa       
 lpa      
 lpa      
 da       
 lpa      
 lpa      
 lh       
 lpa      
 lpa      
 bgll      

math prog
 ak       
 xtp       
 ak       
 ak       
 ak      
 ak      
 ak      

cj  lm
      
      
      
      
      
      
      
      
      
      
      

where possible  missing values were substituted with results from published implementations 
which are shown in italics  for references to the literature see section     

       the reported high modularity values are mostly due to selecting the best values
out of     randomized runs  as can be seen  randomization is a useful tool to find good
clusterings more reliably  though at a high computational expense 
mathematical programming approaches consistently find better clusterings than
cj  zs ml   lm  though by a small margin  however  they are computationally
much more demanding and do not scale to large graphs  agarwal and kempe       
references  the graphs are  karate  the famous network of karate club members
 zachary        dolphins  a social network of bottlenose dolphins  lusseau et al        
polbooks  a co purchasing graph of books about u s  politics  krebs        afootball 
a network of college football matches  girvan and newman        jazz  a collaboration
network of     jazz musicians  gleiser and danon        celeg metab  a metabolic
network of the worm c elegans  duch and arenas        email  a network of e mail
interchanges between university members  guimera et al         erdos    the famous
co authorship network around paul erds  grossman        pgp main  a pgp keysigning network  boguna et al         cmat   main  a collaboration network of scientists
in condensed matter physics  newman        and nd edu  a web page network from
the nd edu domain  albert et al        
the subdivision methods are the betweenness based edge removal algorithm gn by
newman and girvan         newmans      b  recursive spectral bisection n  sdjb  a
spectral clustering combined with kl refinement  sun et al         and the spectral
clustering ws by white and smyth        
the cj algorithms comprise the walktrap algorithm pl of pons and latapy         the
multistep heuristic sc of schuetz and caflisch      a   and two algorithms that combine
joining with some preprocessing by vm  pbd  pujol et al        and yhy  ye et al        
the vm algorithms are bgll  the hierarchical lm algorithm of blondel et al         
gc  an extremal optimization method combined with recursive subdivision  duch and
arenas        lpa  a label propagation algorithm  liu and murata        and lh  an
iterated tabu search  lu and huang       
the results for mathematical programming algorithms were collected from the relaxed linear and quadratic programming ak of agarwal and kempe        and the
mixed integer programming xtp of xu et al         
     published implementations on graphs with rounded weights

implementations that support graphs with integer edge weights are available for
the multistep
joining algorithm of schuetz and caflisch      a   with parameter

l        f  v  v      as recommended by schuetz and caflisch      b    the algorithm
of pons and latapy        based on short random walks  here of length    the default
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fiwith refinement
basic algorithm

cj  zs

lm mi

cj  mi

louvain

schuetz

cj  mi

pons

cj  zs

lm mi

cj  mi

louvain

schuetz

cj  mi

pons

 

    

with refinement
basic algorithm

      

geommean runtime ratio
             

mean modularity
    
    

multilevel local search algorithms for modularity clustering

fig     mean modularity  left  and runtime ratio  right  from published implementations on graphs with
rounded weights  the refinement bars refer to the standard refinement of the respective implementations 
the modularity confidence intervals are relative to cj  zs ml   lm  runtime ratios are relative to the
louvain method  the fastest in this experiment  

value   and the hierarchical lm algorithm of blondel et al          known as louvain
method 
the graphs for this experiment were derived from the    benchmark graphs by
removing self edges  extracting the largest connected component  and rounding the
edge weights to the next nonzero integer if necessary  in order to minimize rounding
errors  the weights were multiplied with           deg v   before rounding 
figure   shows the obtained results  coarsening by cj  zs  with     reduction factor  and by lm mi  with      reduction factor  are significantly more effective than
the other algorithms when combined with multilevel refinement  only the louvain implementation by blondel et al         is slightly faster  but produces worse clusterings 
coarsening by cj  mi  with      reduction factor  is included in the figure because it is equivalent to the widely used fast greedy joining of clauset et al         
lm mi without refinement is conceptually equivalent to the louvain algorithm  accordingly  both are similarly effective and efficient  cjx mi corresponds to the algorithm of
schuetz and caflisch  although the two implementations use a different formula for the
parameter l  both produce equally good clusterings  thus  differences in the implementations or in the formulas for the parameter l do not affect the conclusions about cjx  in
particular its inferiority to the simpler and parameter free cj  with the zs prioritizer 
the absolute runtimes and their dependency on the graph size are shown in figure   
both the louvain implementation and cj  zs ml   lm scale well with graph size
and generally are very efficient  the longest runtime of only     seconds was measured
on the graph eatrs  which has   k vertices and    k edges 
     published implementations on unweighted graphs

implementations for unweighted graphs are available for further clustering algorithms  the fast greedy joining of clauset et al          the spectral recursive
bisection of newman      b   the spinglass simulated annealing of reichardt and
bornholdt         and the fast joining algorithm of wakita and tsurumi        
because these implementations cannot process graphs with weighted edges  only   
unweighted graphs of the benchmark collection were used  in some of these graphs 
negligible differences in edge weights and small amounts of self edges were removed 
figure   shows the results  compared to our implementation cj  zs with optional
refinement ml   lm  only reichardt and bornholdts implementation produces clusterings of similarly high modularity  but it is much slower  and again  only the louvain
implementation is slightly faster  but produces worse clusterings  as can be seen in
figure     cj  zs ml   lm is consistently among the fastest implementations  independently of the graph size 
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi      

r  rotta and a  noack

runtime  s   logscale
 e  
 e   
 e   

 e   



 

pons
schuetz refinement
cj  zs ml   lm
louvain





    seconds










 e  












 e   


































 





























 e   

 e   
 e   
 e   
number of vertices  logscale

 e   

 e   

 e   

cj  zs

reichardt

schuetz

louvain

clauset

wakitahn

pons

wakitahe

with refinement
basic algorithm

newman

cj  zs

reichardt

schuetz

louvain

clauset

wakitahn

pons

wakitahe

newman

with refinement
basic algorithm

geommean runtime ratio
          
  

mean modularity
    
    
    

fig     runtime by graph size on graphs with rounded weights  the dashed line marks the longest runtime
of the multilevel algorithms 

fig     mean modularity  left  and runtime ratio  right  from published implementations on unweighted
graphs  the refinement bars refer to the standard refinement of the respective implementations  the modularity confidence intervals are relative to cj  zs ml   lm  runtime ratios are relative to the louvain
method  the fastest in this experiment   newmans spectral clustering is on average     times slower than
the louvain method and reichardts spinglass algorithm is around       times slower 

   summary

the three primary contributions are  i  new heuristics for modularity clustering with
improved effectiveness and efficiency   ii  a coherent organization of existing and new
heuristics and their combinations  and  iii  a systematic experimental comparison of
the heuristics 
concerning the algorithmic contributions  experiments have shown that the new
criterion zs for choosing joined clusters slightly outperforms the best existing criteria 
and clearly outperforms the most widely used criterion mi  moreover  the new  for
modularity clustering  multilevel refinement has turned out to be significantly more
effective than the conventional single level refinement and no refinement 
concerning organization and unification  several existing and new heuristics and a
vast number of combinations are comprised in a design space with five dimensions  the
coarsening algorithm with its prioritizer  including vertex moving as well as singlestep and multistep cluster joining   the reduction factor for controlling the number of
coarsening levels  and the refinement algorithm with its prioritizer  including singlelevel and multilevel refinement by vertex moving  
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi      






reichardt
newman
clauset

schuetz refinement

cj  zs ml   lm

wakitahn

 


























 

runtime ratio to louvain  logscale
  
   
    

     

multilevel local search algorithms for modularity clustering

 e   

 e   

 e   
 e   
 e   
number of vertices  logscale

 e   

 e   

 e   

fig      runtime ratio by graph size on unweighted graphs  all ratios are relative to the louvain method
 dashed line  

table iv  graph sources
source
aarenas
aclauset
anoack
cx nets
graphdrawing
jfowler
mnewman
pajek
urialon

web address
http   deim urv cat aarenas data welcome htm
http   www santafe edu aaronc hierarchy 
http   www sst informatik tu cottbus de an gd 
http   cxnets googlepages com 
http   vlado fmf uni lj si pub networks data gd gd htm
http   jhfowler ucsd edu judicial htm
http   www personal umich edu mejn netdata 
http   vlado fmf uni lj si pub networks data 
http   www weizmann ac il mcb urialon 

the experimental comparison of achieved modularities and required runtimes
yielded several significant results  the two primary coarsening approachescluster
joining and vertex movingturned out to perform fairly similar with their best parameter values and refinement  moreover  some widely used  complex  or computationally
expensive design alternatives  e g   multistep cluster joining  join prioritization by
mi  single level refinement  and global vertex moving were outperformed by new 
simpler  or more efficient alternatives  overall  single step cluster joining with zs
prioritizer combined with multilevel local by local vertex moving refinement is one
of the most effective and efficient algorithms for modularity clustering in the literature 
appendix

table v lists the graphs used for the experiments  the graphs postfixed with  main
just contain the largest connected component of the original graph  all graphs from
the subset uw were used without edge weights and self edges for the experiments
in section      for each graph the source collection is named in the last column  web
addresses of these collections are listed in table iv  for information about the original
authors  please visit the respective web sites 
acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi      

r  rotta and a  noack
table v  graph collection

southernwomen
karate
football
morse
food
dolphins
terrorist
worldimport    
grass web
lesmis
world trade
a   main
polbooks
adjnoun
afootball
baywet
jazz
smallw main
a   main
celegansneural
usair  
a   main
netscience main
worldcities main
celeg metab
usair   
s   
roget main
smagri main
a  
email
polblogs main
ndyeast main
java
yeast main
scimet main
odlis main
dutchelite main
geom main
kohonen main
epa main
eva main
ppi scerevisiae main
uspowergrid
hep th main
california main
zewail main
erdos  
lederberg main
pairsp
pgp main
daysall
foldoc
astro ph main
as   july  
eatrs
dic   main
judicial main
hep th new main
cmat   main
ussc main
wordnet  main

subset
uw
uw

uw

uw
uw
uw
uw
uw
uw

uw
uw
uw
uw

uw
uw
uw
uw
uw
uw
uw

uw
uw

uw

vertices
  
  
  
  
  
  
  
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
      
      
      
      
      
      
      
      
      
      
      
      
      

edges
  
  
   
   
   
   
   
     
   
   
   
   
   
   
   
     
     
   
   
     
     
   
   
     
     
     
   
     
     
     
     
      
     
     
     
      
      
     
     
      
     
     
      
     
      
      
      
      
      
      
      
       
      
       
      
       
      
       
       
       
       
       

edge weight
    
    
     
        
        
     
     
          
     
     
           
     
     
     
     
       
       
       
     
       
       
     
     
        
       
            
     
       
       
       
        
        
       
       
       
        
        
       
        
        
       
       
        
        
        
        
        
        
        
         
        
         
         
        
        
         
        
         
         
        
         
         

type
social
social
economy
similarity
similarity
social
social
economy
biology
social
economy
software
similarity
linguistics
social
biology
social
citation
citation
biology
flight
biology
co author
social
biology
flight
technology
linguistics
citation
software
social
citation
biology
software
biology
citation
linguistics
economy
co author
citation
web
economy
biology
technology
citation
web
citation
co author
citation
similarity
social
similarity
linguistics
co author
web
linguistics
linguistics
citation
co author
co author
citation
linguistics

source
pajek
mnewman
pajek
anoack
anoack
pajek
aclauset
anoack
aclauset
mnewman
pajek
graphdrawing
pajek
mnewman
mnewman
pajek
aarenas
pajek
pajek
mnewman
pajek
graphdrawing
mnewman
pajek
aarenas
cx nets
urialon
pajek
pajek
graphdrawing
aarenas
pajek
pajek
graphdrawing
pajek
pajek
pajek
pajek
pajek
pajek
pajek
pajek
cx nets
pajek
mnewman
pajek
pajek
pajek
pajek
pajek
aarenas
pajek
pajek
mnewman
mnewman
pajek
pajek
jfowler
pajek
mnewman
jfowler
pajek

acm journal of experimental algorithmics  vol      no     article      publication date  june      

fimultilevel local search algorithms for modularity clustering

      

acknowledgments
the authors thank g  csardi  t  nepusz  p  schuetz  a  caflisch  p  pons  m  latapy  v d  blondel  j  guillaume  r  lambiotte  e  lefebvre  k  wakita  t  tsurumi  a  clauset  m e j  newman  and c  moore for
kindly providing their implementations  we are also grateful to u  alon  a  arenas  a  clauset  v  colizza 
j  fowler  m e j  newman  r  pastor satorras  a  vespignani  and especially the pajek project  batagelj and
mrvar       for collecting and publishing benchmark graphs 

references
aarts  e  and lenstra  j  k   eds        local search in combinatorial optimization  princeton university
press  princeton  nj 
agarwal  g  and kempe  d        modularity maximizing graph communities via mathematical programming 
eur  phys  j  b               
albert  r   jeong  h   and barabasi  a  l        diameter of the world wide web  nature                   
arenas  a   fernandez  a   and gomez  s        analysis of the structure of complex networks at different
resolution levels  new j  phys             
bader  d  and madduri  k        snap  small world network analysis and partitioning  an open source
parallel graph framework for the exploration of large scale networks  in proceedings of the ieee international symposium on parallel and distributed processing  ipdps     ieee  los alamitos  ca 
    
barber  m  and clark  j        detecting network communities by propagating labels under constraints 
phys  rev  e               
batagelj  v  and mrvar  a        pajek datasets  http   vlado fmf uni lj si pub networks data  
blondel  v  d   guillaume  j  l   lambiotte  r   and lefebvre  e        fast unfolding of communities in large
networks  j  stat  mech  theory exp  p      
boettcher  s  and percus  a  g        optimization with extremal dynamics  phys  rev  lett               
boguna  m   pastor satorras  r   diaz guilera  a   and arenas  a        models of social networks based on
social distance attachment  phys  rev  e            
brandes  u   delling  d   gaertler  m   gorke  r   hoefer  m   nikoloski  z   and wagner  d        on
modularity clustering  ieee trans  knowl  data eng                
brandes  u   gaertler  m   and wagner  d        engineering graph clustering  models and experimental
evaluation  acm j  exp  algorithmics         
clauset  a   newman  m  e  j   and moore  c        finding community structure in very large networks 
phys  rev  e            
csardi  g  and nepusz  t        the igraph software package for complex network research  inter  complex
syst       
danon  l   diaz guilera  a   and arenas  a        effect of size heterogeneity on community identification in
complex networks  j  stat  mech  theory exp  p      
danon  l   diaz guilera  a   duch  j   and arenas  a        comparing community structure identification 
j  stat  mech  theory exp  p      
dawes  b   niebler  e   rivera  r   and james  d        boost c   libraries  http   www boost org 
delling  d   gaertler  m   gorke  r   and wagner  d        engineering comparators for graph clusterings  in
proceedings of the  th international conference on algorithmic aspects in information and management
 aaim     springer verlag  berlin         
diciccio  t  j  and efron  b        bootstrap confidence intervals  stat  sci                
djidjev  h  n        a scalable multilevel algorithm for graph clustering and community structure detection 
in proceedings of the  th international workshop on algorithms and models for the web graph  waw    
springer verlag  berlin         
donetti  l  and munoz  m  a        detecting network communities  a new systematic and efficient algorithm 
j  stat  mech  theory exp  p      
donetti  l  and munoz  m  a        improved spectral algorithm for the detection of network communities 
proc  aip                
duch  j  and arenas  a        community detection in complex networks using extremal optimization  phys 
rev  e            
fortunato  s  and barthelemy  m        resolution limit in community detection  proc  national acad 
sci               

acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi      

r  rotta and a  noack

gaertler  m        clustering  in network analysis  methodological foundations  u  brandes and t  erlebach  eds  springer verlag  berlin         
gaertler  m   gorke  r   and wagner  d        significance driven graph clustering  in proceedings of the  rd
international conference on algorithmic aspects in information and management  aaim     springerverlag  berlin       
girvan  m  and newman  m  e  j        community structure in social and biological networks  proc  national
acad  sci                   
gleiser  p  and danon  l        community structure in jazz  adv  complex syst               
grossman  j        the erds number project  http   www oakland edu enp  
guimera  r  and amaral  l  a  n        functional cartography of complex metabolic networks  nature                   
guimera  r   danon  l   diaz guilera  a   giralt  f   and arenas  a        self similar community structure
in a network of human interactions  phys  rev  e            
hendrickson  b  and leland  r  w        a multilevel algorithm for partitioning graphs  in proceedings of the      acm ieee conference on supercomputing  supercomputing     acm  new
york     
kannan  r   vempala  s   and vetta  a        on clusterings  good  bad and spectral  j  acm               
karrer  b  and newman  m  e  j        random acyclic networks  phys  rev  lett                  
karypis  g  and kumar  v        a fast and high quality multilevel scheme for partitioning irregular graphs 
siam j  sci  comput                
kernighan  b  and lin  s        an efficient heuristic procedure for partitioning graphs  bell sys  techn 
j                
kirkpatrick  s   gelatt  jr   c  d   and vecchi  m  p        optimization by simulated annealing  science                   
krebs  v        a network of books about recent us politics sold by the online bookseller amazon com 
http   www orgnet com  
lancichinetti  a  and fortunato  s      a  benchmarks for testing community detection algorithms on
directed and weighted graphs with overlapping communities  phys  rev  e            
lancichinetti  a  and fortunato  s      b  community detection algorithms  a comparative analysis  phys 
rev  e            
liu  x  and murata  t        advanced modularity specialized label propagation algorithm for detecting
communities in networks  physica a                  
lu  z  and huang  w        iterated tabu search for identifying community structure in complex networks 
phys  rev  e            
lusseau  d   schneider  k   boisseau  o  j   haase  p   slooten  e   and dawson  s  m        the bottlenose
dolphin community of doubtful sound features a large proportion of long lasting associations  behav 
ecol  sociobiol             
massen  c  p  and doye  j  p  k        identifying communities within energy landscapes  phys  rev  e    
       
medus  a   acuna  g   and dorso  c  o        detection of community structures in networks via global
optimization  physica a                  
mei  j   he  s   shi  g   wang  z   and li  w        revealing network communities through modularity
maximization by a contractiondilation method  new j  phys             
newman  m  e  j        the structure of scientific collaboration networks  proc  national acad  sci        
       
newman  m  e  j      a  analysis of weighted networks  phys  rev  e            
newman  m  e  j      b  fast algorithm for detecting community structure in networks  phys  rev  e    
       
newman  m  e  j      a  finding community structure in networks using the eigenvectors of matrices  phys 
rev  e            
newman  m  e  j      b  modularity and community structure in networks  proc  national acad  sci          
         
newman  m  e  j  and girvan  m        finding and evaluating community structure in networks  phys  rev 
e            
noack  a      a  energy models for graph clustering  j  graph algorithms appl                
noack  a      b  unified quality measures for clusterings  layouts  and orderings  and their application as
software design criteria  ph d  thesis  brandenburg university of technology 

acm journal of experimental algorithmics  vol      no     article      publication date  june      

fimultilevel local search algorithms for modularity clustering

      

noack  a        modularity clustering is force directed layout  phys  rev  e            
pons  p  and latapy  m        computing communities in large networks using random walks  j  graph
algorithms appl                
porter  m  a   onnela  j  p   and mucha  p  j        communities in networks  not  amer  math  soc        
         
preis  r  and diekmann  r        partya software library for graph partitioning  b  topping  ed  advances in computational mechanics with parallel and distributed processing  civil comp press  united
kingdom       
pujol  j  m   bejar  j   and delgado  j        clustering algorithm for determining community structure in
large networks  phys  rev  e            
reichardt  j  and bornholdt  s        statistical mechanics of community detection  phys  rev  e            
richardson  t   mucha  p   and porter  m        spectral tripartitioning of networks  phys  rev  e            
rotta  r        a multi level algorithm for modularity graph clustering  m s  thesis  brandenburg university
of technology 
schaeffer  s  e        graph clustering  comput  sci  rev             
schuetz  p  and caflisch  a      a  efficient modularity optimization by multistep greedy algorithm and
vertex mover refinement  phys  rev  e            
schuetz  p  and caflisch  a      b  multistep greedy algorithm identifies community structure in real world
and computer generated networks  phys  rev  e            
siek  j   lee  l   and lumsdaine  a        the boost graph library  user guide and reference manual 
addison wesley  upper saddle river  nj 
sun  y   danila  b   josic  k   and bassler  k        improved community structure detection using a modified
fine tuning strategy  epl  europhysics letters            
wakita  k  and tsurumi  t        finding community structure in mega scale social networks 
http   www     org posters poster    pdf 
walshaw  c  and cross  m        mesh partitioning  a multilevel balancing and refinement algorithm  siam
j  sci  comput              
white  s  and smyth  p        a spectral clustering approach to finding communities in graphs  in proceedings
of the  th siam international conference on data mining  sdm     siam  philadelphia         
xu  g   tsoka  s   and papageorgiou  l  g        finding community structures in complex networks using
mixed integer optimisation  eur  phys  j  b               
ye  z   hu  s   and yu  j        adaptive clustering algorithm for community detection in complex networks 
phys  rev  e            
zachary  w  w        an information flow model for conflict and fission in small groups  j  anthropol  res     
       
received november       revised september       accepted march     

acm journal of experimental algorithmics  vol      no     article      publication date  june      

fi