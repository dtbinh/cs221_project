review scheduling for maximum
long term retention of knowledge
stephen barnes  stbarnes   cooper gates frye  cooperg   khalil s griffin  khalilsg 
many people  such as languagelearners and medical students  currently use spaced repetition
softwaretolearninformation however itisunclearwhenthebesttimetorepeatis inorderto
improve longterm recall  we used machine learning to find the best time for someone to schedule their
nextreview 

prior work
themathematicalinvestigationofhumanmemorywasfirstundertakenbyebbinghaus whoin
      while experimenting with memorizing pairs of nonsense syllables  discovered a mathematical
descriptionofmemoryhecalledtheforgettingcurve seeen wikipedia org wiki forgetting curve  
this knowledge was first applied by sebastian leitner  who devised the leitner flashcard scheduling
system seeen wikipedia org wiki leitner system  
leitners system was improved on by piotr wozniak  a researcher in neurobiology  who wrote
thefirstspacedrepetitionsoftware seeen wikipedia org wiki piotr wozniak  researcher  aspartof
his quest to learn english  wozniak has been profiled by wired  see
archive wired com medtech health magazine      ff wozniak  
there are now several opensource spaced repetition implementations  such as anki 
mnemosyne andpauker theseareverypopularamongpeoplelearninglanguages andhavealso
found a following among medical students  wozniak and others have continued to attempt to improve
theirschedulingalgorithms thoughthereisnoagreementastotheoptimalschedulingalgorithm
current implementations use different algorithms 
moreinformationonthepracticeofspacedrepetitioncanbefoundinwozniaksessays
 www supermemo com english contents htm articles   for information on the theory of spaced
repetition seethefollowingpublications 
 toppino  t c     bloom  l c          the spacing effect  free recall  and twoprocess theory 
acloserlook journalofexperimentalpsychology learning memory andcognition       
       
 greener l        repetitionandspacingeffects inroedigerh l iii ed   learningand
memory  a comprehensive reference  cognitive psychology of memory           oxford 
elsevier 
 cull  w  l          untangling the benefits of multiple study opportunities and repeated testing
forcuedrecall appliedcognitivepsychology           
 woniak  p  a     gorzelaczyk  e  j          optimization of repetition spacing in the
practiceoflearning actaneurobiologiaeexperimentalis         

dataset
weusedadataprovidedbytheopensourcemnemosyneproject thisdatatrackedmany on
theorderofmillions offlashcardsandpeoplereviewingthemuptohundredsoftimesoveryears 
aftereachtimetheyreviewedacard thestudentsratedthemselvesonascoreof  withhow
comfortabletheywere thedatasetalsoincludedotherinformationforeachreview suchasthetimeat

fiwhichitwasperformed andtheamountoftimeittookbetweenseeingthecardandgettingtheanswer
 thinkingtime  forexampleentries seetheattacheddata zip 

problem definition
givenastudentshistoryonaflashcard wewantedtogivethebesttimeforthemtonext
reviewitinordertomaximizetheirlongtermrecall inordertodothis weusethefollowing
assumptionbasedonthepriorwork thebesttimetoreviewsomethingisrightbeforeyouwould
forgetit thus wewanttofindthetimeatwhichtheinformationwillbeforgotten wesplitthis
taskintotwoparts 
   writeafunctionthattakesthehistoryofreviewsforasinglecard andatimeinthefuture and
returnsthemostlikelypossiblescoresatthegiventimeforthatcard 
   writeafunctionthatusesthefunctionfrompart   tofindthetimeatwhichtheexpected
scorecrossesacertainthresholdthatwedefineasforgetting 

methods
forthepredictiontask weusedafeaturevectorandlogisticregression theyoperatedona
reviewhistory andclassifieditintooneofthescorebuckets     weusedthescikitlearnlibraryin
ordertoperformthesetasks 
weused     features including 
 numberoftimesreviewed togetherwithadiscretizationfeaturetemplate bucketsfor
                           and   reviews 
 averagescore andfrequencyofpreviousscores
 thescoresforeverypreviousreview alongwiththeindexofthat forexample a
scoreof onthemostrecentreviewwouldbeencodedas
 history back score     
 averagethinkingtime togetherwithadiscretizationfeaturetemplate
 acombinationofthinkingtimeandscoreforeachpreviousreview
 theaveragescoreofentriesthatfallintoeachtimebucket
 combinationsofsomeoftheabovefeatures
forpart  weusedanunboundedbinarysearchoverdifferenttimes findingtheprojected
scoreatthosetimesusingpart  wereturnedthetimeatwhichwepredictedthescorehadahigh
likelihoodofbeingbelowathresholdofforgetting 

evaluation
sincepart wasthebulkoftheproject wefocusedourevaluationonthat forourtestdata 
wetookexistinghistoriesfromthedatabase removedthelastscore andtriedtopredictwhatthatscore
was forexample ifahistoryconsistedofascoreof attimet   attimet  and attimet  we
wouldtrytopredictthescoreatt givenhistory  t      t      
overthecourseoftheproject weusedthreedifferentevaluationfunctions thefirstwasa
bayesianscorebasedontheprobabilityweassignaresult usingthefunction   log   p  wherepis
theprobabilityweassignedthecorrect result thisscorecouldrangefromnegativeinfinitytozero 
foradditionalinsight wedecidedtouseamodifiedf score wecreatedaconfusionmatrix 
andthencalculatedandf scoreforeachoftheclasses then wecalculatedaweightedsumofthese
f scoreswiththeweightsforeachscorebeingthefractionofthedatathathadthatscore aperfect
resultwouldgetascoreof  andaperfectlywrongresultwouldgetascoreof  
this f scorerevealedanotherproblem uponlookingatourconfusionmatrix wenoticedthat
thereweremanytimeswhenwewereclose butnotquitecorrect forexample weoftenguessed 

fiwhenthecorrectresultwas  underthef score thiscountedasamiss andwasjustasbadas
guessinga whenthecorrectresultwas  
tofixthisproblem weusedascorethatwassimplythenegativeoftheaveragesquareerror
fromallofourdata forexample ifwepredicta andtheactualisa  thenthescoreis         
however ifwepredicta  thescoreis         thisway wepenalizescoresthatareverywrong
morethanscoresthatareclose asaconcreteexample ifwehavethefollowingpairsof guess 
actual                      thescorewouldbe                              aperfect
resultwouldgeta  andthetheoreticalminimumwouldbe   

results and analysis
wecomparedourresultstoabaselineandanoracle thebaselinewasasimplemodelthat
predictedaprobabilitydistributionbasedonthecountsofscoresinthehistory withlaplace
smoothing  for example  if the history had scores               it would predict   with     probability 
 with     with     with     with    and with    theoraclepredictedthecorrect
answer all of the time 

regression correct  

correct  

correct  

correct  

correct  

correct  

guess  

 

 

 

 

 

 

guess  

 

  

 

 

 

 

guess  

  

   

   

   

   

  

guess  

 

  

  

  

  

 

guess  

   

   

   

   

    

   

guess  

  

  

  

  

   

   

figure    confusionmatrixfromarunon    testhistories

trainerrors

   log   p 

f score

 guessactual  

baseline

             

              

             

ourregression

            

              

             

oracle

 

 

 

figure    scoresforbaseline oracle andourfunctionfortrainingexamples

testerrors

   log   p 

f score

 guessactual  

baseline

             

              

             

ourregression

             

              

             

oracle

 

 

 

fifigure    scoresforbaseline oracle andourfunctionfortrainingexamples

thetrainingandtestresultsareclosetogether showingthatwedidnotoverfit 
unfortunately  our model was not able to do much better than the baseline  with both the log
scoreandthef score wewereveryclosetothebaseline thisimpliesthatforboththeprobability
distribution  and the exact classification tasks  our features were not able to to perform the task well 
however wewereabletomakenoticeableimprovementonthescorebasedonthemagnitude
of our error  this shows that  even if we werent able to get exactly correct more often  we were able to
getclosertothecorrectanswerthanthebaseline forthisapplication thatimprovementisimportant
we want to be able to predict as close as possible to the actual score  getting closer  while not as good
asgettingexactlycorrect ishelpful 

data trends
tobuildintuition weusedvisualizationsof
our algorithms behavior  for instance  this
 dimensionalgraphshowstherecommended
time to the next review  on the vertical axis  in
seconds againstthetimetakenfortheprevious
review  on the bottomright axis  in
microseconds andthegradeoftheprevious
review  on the bottomleft axis   as expected 
greatergradesgenerallyincreasetheinterreview
time  though the surface is not entirely smooth 
theplotbelowisalearningcurveforourlinear
regression model  the first nontrivial model we
tried  showingtestscore blue andtrainingscore
 red  on the vertical axis  plotted against the
datasetsizeonthehorizontalaxis ascanbeseen 
the score generally increases as more data is
added thisgraphalsoshowsthataddingmore
data does not substantially improve the
algorithmsscorepastathresholdataround   
data points  this shows that the main problem
with thelinearregressionmodelisbias notvariance forthisreason wedecidedtoworkonbetter
features  which reduces bias by increasing the size of the hypothesis space  we also decided to use a
bettermodel logisticregression  whichfurtherreducedthebias 

fi

insights






the feature weights provided some insight into the importance of various features 
thetimeeachreviewtookhadlittlepredictivevalueastothenextgrade 
the model generally predicted improvement  if the previous score was a       or    it gave a
high likelihoodofscoringa  ifthepreviousscorewasa    or  itgavehighlikelihoods
for   and    however  if the secondmostrecent score was a    it gave a very high likelihood of
stayinga  
the previous scores only mattered a short ways back  for example  the scores from    reviews
agohadverysmallweights 
the previous score frequency mattered very little  even users who score fifty  s previously
didnthaveanincreasedlikelihoodofscoringa nexttime 

conclusion
in conclusion  we were able to improve significantly on our baseline  in terms of the predicted
gradeaswellastheoveralldistributionswepredicted however ourbaselinewasnottoosophisticated 
so we suspect there is still a fair amount of room for improvement  the second component of our
projectiscurrentlybasedonsomeassumptionsfrompriorresearch whilethatmakesitmore
wellfounded  it also doesnt give us an independent method to compare to the previous ones 
forfuturework thereareacoupleofareas approachesthat seemparticularlypromisinggiven
more time and or resources 
 experimentwithmulticlassclassificationmethodsotherthanlogisticregression
 find ways to evaluate our performance on part   indirectly  for instance  by developing a way
toquantifyhowsimilaracardsrealreviewhistorywastowhatwewouldhavesuggested 
then  given a particular proposal for a scheduling algorithm  you could see whether ones
similartoitsproposaldidbetteronaverage andtowhatextent 

fi