topic analysis of the fccs public comments on net neutrality

sachin padmanabhan
spadman stanford edu

leon yao
leonyao stanford edu

luda zhao
ludazhao stanford edu

timothy lee
timothyl stanford edu

department of computer science
stanford university

abstract
the fccs proposed net neutrality policy change in      was
met with widespread public controversy and outrage  the
fcc recently released to the public millions of comments
that it received about the issue  it is abundantly clear that
the vast majority of citizens prefer to have net neutrality
intact  but what exactly are the people saying  what are
their main arguments and reasons for wanting to maintain
net neutrality  in this project  we use natural language processing techniques to analyze the arguments in         of
the comments 

   introduction
     motivation
the open internet proceeding of the fcc  federal communication commissions  is a critical regulatory effort to determine the future of the internet  the proceeding concerns
net neutrality  the principle that all internet traffic should
be treated equally  and no internet provider will be given
control over internet traffic  should the fcc decide not to
maintain net neutrality  isps will have more power to regulate internet traffic and scrutinize data sent over the internet 
in addition  isps will be able to discriminate between internet traffic to provide a fast lane for high paying consumers 
proponents of net neutrality argue that this will severely restrict free speech and privacy on the internet  in addition 
they assert that giving isps differential control over internet
traffic will ultimately result in extremely slow internet for
average consumers  including individuals and corporations 
that cannot afford to pay as much as large corporations  in
turn  this will hamper fair competition between businesses 
shifting the balance largely in the side of large companies
to the immense detriment of innovative startups  instead 
proponents maintain that the internet should instead be reclassified as a common carrier 

project done in stanford universitys cs      machine learning 
course taught in autumn      by professor andrew ng 

the debate on net neutrality has attracted a large response
from the american public  as of writing  the fcc proceedings has attracted over   million comments  these comments
are important to the fccs decision making process  and are
usually read by people  however  given the unprecedented
number of comments  this is not possible  under this context  natural language processing is an effective technique
that can help gain insight into the comments as a whole  can
we automatically determine which issues were most pertinent
to proponents of net neutrality 
     our work
after reading many of the comments  we saw that the arguments were almost unanimously in favor of maintaining net
neutrality  however  the arguments presented varied greatly
in length  relevance  level of insight  and topic  we wanted to
determine what peoples arguments are and why they are in
favor of net neutrality  the majority of the comments made
at least one of the following arguments 
 net neutrality is needed to protect freedom of ideas 
creativity  speech  and communication on the internet
 ideafreedom 
 net neutrality is needed to protect fair market competition for small businesses and startups  fairbusiness 
 net neutrality is needed to protect the internet from
further legislation and government intervention in the
future  fairgov 
our goal was to classify the argument of each comment into
one or more of the above topics using supervised learning 
we decided against using an unsupervised learning approach
since it was attempted earlier by a team at sunlight labs 
the results they got were not very inspiring because the clusters they found were only indicated by a few key words  but
were too vague to have any concrete topic behind it  among
some very bad clusters  we did see some interesting ones like 
small market  bidding  premium  and disadvantage 
this exactly fits our idea of free business  instead of having
  in nearly     clusters be interesting  we thought it would

fitopic analysis of the fccs public comments on net neutrality

be interesting to remove the noise and just focus on   topics
we knew were in the dataset 

   data
the original dataset released by the fcc consisted of    
million raw comments along with metadata  many of which
were blank  unparseable  or too long  les miserables and
war and peace were both submitted as comments   fortunately  the team at sunlight labs processed the dataset to
remove these unworkable comments and provided a cleaner
dataset of         comments with metadata in json format 
 
 applicant    kara j  walton  
 datercpt              t        z  
 statecd    va  
 zip          
 text    allowing the cable companies to
start charging companies for    
 
to train and test our classifier  we drew a random sample of
    comments from the dataset  we manually read through
each comment to discern the arguments presented and correspondingly labeled each comment 
 
   
 topiclabels    
 ideafreedom     
 fairbusiness     
 freegov    
  
 formletter     
 personal    
 
the rest of the comments were used after we built the classifier to glean interesting insight on the entire dataset 

   methodology
     form letter detection
by reading through the dataset  we noticed that a majority
 about      of it was composed of form letters  which were
mostly identical comments written by third party organization who had its supporters send in the same professionally
written messages 
to chairman tom wheeler and the fcc commissioners to the fcc please build any net neutrality
argument upon solid legal standing  specifically 
this means reclassifying broadband under title ii
of the telecommunications act of           au 

thority from the telecommunications act has been
repeatedly struck down in court after legal challenges by telecom companies  take the appropriate
steps to prevent this from happening again  sincerely  xxxx
clearly  a form letter could often times sound exactly like
a regular comment  we decided to use form letters in our
topic classification because  despite their spam like nature 
they still signify the intentions of the individual sender who
agrees with this mass message  otherwise they wouldnt have
taken the time to actually send it  we found that most  if
not nearly all  of these messages were from different people 
thus  one of the main problems we had to tune for was
overfitting the training set 
instead  our goal was to use unsupervised learning to detect
exactly which comments were form letters so that we could
perform analysis on just the form letters themselves  we did
this using the simhash algorithm  which is a generally fast
method to calculate the similarity between two documents 
and is effective for near duplicate detection 
using the simhash algorithm  we we found the nearduplicates to the document being classified  if there existed
a significant number of comments that were near duplicates 
then the comment was classified as a form letter  we used
a    bit hash size  shingle width of   letters  and hamming
distance threshold of    bits as parameters for the model 
given a labelled data set of     comments  the model classified form letters with     accuracy  on a data set containing
       comments  the model showed that     of the comments were form letters  similar to our initial observations
    proportion 
     feature selection
we first preprocessed the data by removing stop words such
as the  a  and  etc  that appear in nearly all comments
but are essentially useless features  we also stemmed our
words  so that different conjugations of the same word would
be counted as the same  we also tried using different size
n grams to increase our feature space and to capture more
of the word contexts 
we used several standard features for typical nlp datasets 
we first found the word counts of our comments  then normalized them and used tfidf  term frequencyinverse
document frequency  features  which is a weighting factor
for each word that gives a value proportional to the frequency
of that word in the comment offset by the frequency of the
word in the entire corpus  this allowed us to remove words
that appear in every comment  but are bad features to use
for training a classifier  for example  words like internet
and fcc were used in nearly every comment  but are not
helpful for determining if a comment is from a given class 
tfidf allows us to hone in on the most important features 

fitopic analysis of the fccs public comments on net neutrality

which is one of the best methods for feature selection 
   f  t  d 
tf t  d         
max f  w  d    w  d 
n
idf t  d    log
  d  d   t  d  
tfidf t  d  d    tf t  d   idf t  d 
on top of tfidf we also used a min max frequency pruning  if a word only appears once or twice in the dataset or
in every single comment  tfidf will assign it a low score 
but we wanted to actually reduce our feature space so as to
not overfit  if a word has word frequency less than our min
or greater than our max  then we removed it 

used logistic regression with    regularization  which corresponds to a gaussian prior on the data  thus  we implemented a stochastic gradient descent classifier to minimize
the cost function
   arg max j    


m
x

log p y  i   x i      

i  


kk  
 

the results are summarized in table   
table    classification accuracies for ell   regularized logistic regression

     model selection

topic

for each of our classifiers we learned a one vs  all classifier
because a particular comment could have multiple different
topics  we used    fold cross validation for each model  so
each training testing accuracy we report are the generalization accuracies 

ideafreedom
fairbusiness
freegov

training

testing

      
      
      

      
      
      

       support vector machine
       bernoulli nave bayes classifier
the first classifier we tried was just a simple nave bayes
with laplace smoothing for data distributed according to the
bernoulli distribution  by finding the maximum likelihood
estimates
pm
 i 
 i 
    
i     xj      y
pm
j y    
 i 
    
i     y
pm
 i 
 i 
    
i     xj      y
pm
j y    
 i 
    
i     y
pm
 i 
  y     
y   i  
m
and then determining the class with the highest posterior
probability  we obtained the results in table    we saw that
table    classification accuracies for nave bayes classifier
topic
ideafreedom
fairbusiness
freegov

training

testing

      
      
      

      
      
      

the nave bayes classifier suffered a lot from the form letters
and also overfitted the training set 

we finally tried an     norm soft margin svm classifier with
a gaussian kernel 
min


s t 

m
x

m

i 

i  

m

  x x  i   j 
y y i j k x i    x j   
  i   j  

   i  c  i              m
m
x
i y  i     
i  


k x  z    exp

kx  zk 
 



although computationally more intensive  we felt it would
yield better results  indeed  chosen with default parameters 
this gave better results than the previous methods  in order to further improve the results  we ran a model selection
algorithm to search for the best parameters for the model 
and the resulting classifier yielded even better results  the
results for the optimized classifier are summarized in table
  
table    classification accuracies for support vector machine with
gaussian kernel
topic

training

testing

      
      
      

      
      
      

       regularized  bayesian  logistic regression
since overfitting was a problem for nave bayes  we decided
to use regularization to restrict the norm of the learned parameters to control the vc dimension of our classifier  we

ideafreedom
fairbusiness
freegov

fitopic analysis of the fccs public comments on net neutrality

figure    training accuracy

figure    distribution of topics among all comments

guments  these results are shown in the venn diagram in
figure   

figure    testing accuracy

     evaluation
after selecting our best classifier  an svm with gaussian
kernel  we also looked at the precision and recall statistics
in terms of a confusion matrix  where each column of the
matrix represents the instances in a predicted class  negative  positive   while each row represents the instances in an
actual class  negative  positive   splitting data half and half
for training and testing  we obtained the following confusion
matrix for each topic 
ideafreedom


      
      

fairbusiness


      
      

fairgov


     
 
 

precision       
recall       

precision       
recall       

precision      
recall       

we see that for all of our topics  the classifier achieved both
high precision and high recall  this result boosts our confidence that this particular classifier will be able to obtain a
reasonable classification on our unlabeled data 

   results   analysis
since the svm with a gaussian kernel was our best classifier 
we used this classifier to derive insights on the entire dataset
of comments 
overall  we found that the vast majority of comments talked
about either the idea of freedom or fair business practices 
with the plurality of these comments mentioning both ar 

in addition  we thought it would be interesting to analyze
the arguments that people in different states made  california had about     of the total comments  and they lead
the percentage in every topic as well  so in order to see
the the topic breakdown for specific states  we found the
percentage of each state that argued about each topic  for
example  only       of california talked about freedom from
government interference while      of florida and       of
texas talked about it  although free government was not
a very common topic talked about  florida and texas still
had a significant number of people talk about it compared to
the overall percentage of free government comments in the
dataset          considering about     of comments that
argued about free government did not specify a state 
these results are interesting because texas and florida are
both predominantly republican states compared to california  so people in these states would care more about the
traditionally republican ideal of having a small government 
this directly corresponds to their distaste towards government involvement with net neutrality 
additionally  california accounts for about     of all the
comments  but accounts for about     of the idea freedom topic  this indicates that a majority of california
cares about topics relating to our first amendment rights and
the ability to freely post things on the internet  this makes
sense because california is one of the most liberal states in
the country 
other than these two anomalies  other states topic distributions were mostly the same as the overall topic distribution 

   conclusion
through our investigation  weve gained a better understanding of the issues that people have raised regarding net neu 

fitopic analysis of the fccs public comments on net neutrality

trality in the fccs public comments  by identifying the
most prominent concerns and training a classifier using a
pre labeled training set  we were able to classify         comments and capture their broad sentiments using a fraction of
time and manpower as traditional procedures of review  in
addition  we were able to apply our topic classification labels
to make interesting observations about the geographical distribution of topics  in which we found out that distribution
of our topic seems to follow certain regional political trends 
an unexpected but fascinating result 
furthermore  as with most publicly gathered comments  our
dataset contains a large percentage of largely identical form
letters  since they provide a useful metric of the level of active public participation  we found it a worthwhile endeavor
to identify them  we were fairly successful in this regard in
using the simhash algorithm  as our predicted percentages
of     matched closely with the actual amount 

   future work
from this project  there are many multiple directions we can
take to abstract information from the comments for a deeper
analysis  for example  the analysis of comments pertaining
to form letters could provide very useful information  after finding the clusters of comments from form letters in the
dataset  we can observe the geographic origins of form letters 
in addition  we can apply the same model to perform topic
classification on the set of comments of form letters only 
also  we can group comments by time to see what events
cause form letters to be sent  for example  a television advertisement impels viewers to send the comment through a
website   besides form letters  we can look at the comments
at a finer granularity through the lens gender  we can apply
the same model to perform topic classification to sets of comments from different genders  by continuing this work  we
hope to achieve more interesting results about the publics
perception of net neutrality 

acknowledgments
special thanks to professor dan jurafsky 

references
andoni  alexandr and indyk  piotr  near optimal hashing
algorithms for approximate nearest neighbor in high dimensions  in foundations of computer science       
focs      th annual ieee symposium on  pp         
ieee       
bishop  christopher m et al  pattern recognition and machine learning  volume    springer new york       
charikar  moses s  similarity estimation techniques from

rounding algorithms  in proceedings of the thiry fourth
annual acm symposium on theory of computing  pp     
     acm       
gong  caichun  huang  yulan  cheng  xueqi  and bai 
shuo  detecting near duplicates in large scale short text
databases  in advances in knowledge discovery and data
mining  pp          springer       
hastie  trevor  tibshirani  robert  friedman  jerome 
hastie  t  friedman  j  and tibshirani  r  the elements
of statistical learning  volume    springer       
lannon  bob  what can we learn from         public comments on the fccs net neutrality plan  sunlight foundation blog       
manning  christopher d  raghavan  prabhakar  and
schutze  hinrich  introduction to information retrieval 
volume    cambridge university press cambridge       
pedregosa  f   varoquaux  g   gramfort  a   michel  v  
thirion  b   grisel  o   blondel  m   prettenhofer  p  
weiss  r   dubourg  v   vanderplas  j   passos  a   cournapeau  d   brucher  m   perrot  m   and duchesnay  e 
scikit learn  machine learning in python  journal of machine learning research                    
russell  stuart and norvig  peter  artificial intelligence  a
modern approach  artificial intelligence  prentice hall 
egnlewood cliffs           

fi