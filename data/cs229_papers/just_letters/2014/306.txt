email filtering by response required
christopher knight
december        

abstract

data set  in section   i discuss the two models i use and the reasons why they were chosen 
in section    i fit the models to the data and
present the results with respect to what features
are the most valuable  in section   the results
are discussed and conclusions presented  lastly 
in section   i discuss further directions that this
project could take 

this project explores the feasibility of applying
machine learning to answer the following question  how likely is it that one will have to read
and respond to an email that has just arrived 
to answer this question  a data set was derived
from several months worth of a software engineers work email and served as the input to both
a multinomial nave bayes classifier as well as an
svm classifier  specifically  the project explores
the details of which email features provide the
most useful information in terms of predicting
the output 
neither of the two models studied was absolutely better than the other  with that being
said  satisfactory prediction performance was
never achieved from any of the features with either of the models due to the classification depending on far more information than what was
available in the immediately preceeding email 

 

 

source data

considering the data set for this problem wasnt
in a usable form at the start of the project  a significant amount of time went into data extraction and manipulation  the result is a python
script that is capable of accessing email via the
microsoft outlook mapi com interface  the
program iterates through all the received email
in the local microsoft outlook account within a
specified time period and populates various data
structures that allow easy access to the source
data for the features  with which i am interested
in experiementing  running the script results in
a feature matrix written to disk for each of the
features being examined as well as the classification matrix  the classification matrix has the
emails to which i replied classified as the positive class  refer to figure   for the list of top
level features 
each feature matrix contains a row for each
email that i received   each column is a sub 

introduction

very frequently i am interrupted by the notification of a new email arriving  should i break
away from my current task to read it or not 
ideally  i would only accept the disturbance to
my work if said email requires an urgent reply  each of the following sections in this paper
outlines the steps i took to answer this question  my goal was to model various features
of my qualcomm email data set using multinomial nave bayes and svm classifiers to determine which feature is most effective at predicting whether an email requires a response from
me 
in section    i detail the data collection process and the format content of the resultant

 

when i say feature here i am referring to an aspect
of the email  each of these features almost surely results
in more than   column worth of data in the feature matrix
itself
 
i implicitly filtered out a large set of the negative
class by only examining the subset of received email that
has a reasonable chance of requiring a reply  i e  email
sent to massive email lists to which i am subscribed are
not included  

 

fi   

component of the feature 

the first two derived features that i constructed
changed the feature vector from being raw frequencies of the term to be the tf idf metric of
the term     i theorized that this would improve
the algorithms ability to train on the more important words in each email rather than the
dead words 
the last two derived features capture the percentage of the emails audience made up by me 
the idea is that  for example  if im one of only  
people receiving the email  then im more likely
to reply than if i were   of    people receiving
the email  if im not explicity in the to or cc
fields  the associated toprop or ccprop feature
will be zero  if im present in either of those
fields  this feature is the inverse of the number
of recipients in the field  see equation   below 

raw features
ref  name
body term frequency
body
subject term frequency subject
to names
to
cc names
cc
from name
from
derived features
ref  name
body tf idf
bodytfidf
subject tf idf
subjecttfidf
my fraction of to toprop
my fraction of cc ccprop
figure    tables of the raw and derived features
i used for modeling and the name by which i
will refer to them 
i gathered   different time periods worth of
data     days      emails with    positives  
   days       emails with     positives      
days       emails with     positives   all of
the periods end at the same point in time  additionally  all features that depended on indexing
text fields  subject  body  bodytfidf  subjecttfidf  
were treated with the porter  stemming algorithm before any frequencies were computed    

   

derived features

f ieldprop  

 

  chris knight  f ield 
 f ield 

   

models

multinomial nave bayes was selected as the
initial model due to its very simple implementation  lack of complex  empirically determined
model parameters  and reasonable performance
on text classification problems  svm was selected so as to possibly fit a far more complex
decision boundary  when using a non linear kernels   thus giving a richer model  additionally 
a large amount of email history is available and
svm is better able to take advantage of the additional data points in terms of providing better
predictive accuracy 
the metrics used to explore the performance
of these various features are the classification errors and the f  score    the f  score attempts
to provide a good measure of a models accuracy
by taking into account the models precision as

raw features

the body feature was sourced from the body
of each email  a body dictionary was constructed by splitting up the text and removing
various punctuation   column i for each email
is the number of times token at index i in the
dictionary occured in the email  similarly  the
subject feature was constructed the same way
from the subject field and had indices that
referred to its own associated subject token dictionary 
the last three raw features i extracted were
sourced from the to  cc and from fields 
column i for each email in these feature matrices
was a binary feature corresponding to whether
or not the person at index i in the associated
person dictionary was present in the respective
field of the email 

 
an f  score of   indicates the model perfectly classifies the given data  the f  score is very sensitive to
the number of false positives and false negatives relative
to the true number of positives and negatives  respectively  giving a powerful indicator of model success even
in imbalanced data sets 

 
note that i explicitly only looked at the body content
of the top level email  quoted material from prior emails
in the thread was discarded 

 

fiwell as recall     see equation   
f     

 precision  recall 
precision   recall

subjecttfidf or bodytfidf features  the to  cc 
from  toprop  and ccprop features were practically useless as they resulted in a model with
training and test f  scores below     for all data
sizes 

   

ill be focusing almost exclusively on the f 
score as it is a better indicator of success when
dealing with data sets as imbalanced as mine 

 

interestingly  the only feature on which mnb
was able to decently model the training set was
bodytfidf  all the other features had f  scores
below     on the    and     day training sets 
this indicates a serious bias problem with our
model with respect to features other than bodytfidf as we cant even properly model our training
data  that being said  bodytfidf was capable of
modeling the training data  but failed to generalize and still performed poorly on the test data 

results

in this section  i train multinomial nave bayes
as well as svm on each of the aforementioned
features and present the results  for both of the
below models  i ran k fold cross validation with
k      on all   timeframes  the error metrics
reported for each timeframe are averaged over
all    folds 

   
   

svm

nave bayes
next  i ran svm against each feature  i used
the c svm implementation of svm present in
libsvm for matlab     according to the svm
guide associated with the libsvm authors  the
imbalance in my data set can be compensated
for by using different weight parameters for each
class     i ran an empirical exploration of the
weights for my positive class and significantly
improved my results by weighting the positive
class   times more than the negative class  that
is  i used c       and c      in the below
formulation of c svm  equation     the full
svm results can be seen in figure   

multinomial nave bayes was run against each
feature to determine each features value  to
start off  let us only examine the body feature
in the     day data set  the classification error
was       on the training set and        on
the test set  at first glance those values would
appear reasonable  if not a bit high  however 
the confusion matrices presented in figure   for
the same scenario tell us that our classifier was
doing a mediocre job fitting the training set and
a downright terrible job predicting the test set 
for the rest of this paper  i will be focused on
the f  score 
training set predict     predict    
truth    
      
    
truth    
     
    
test set predict     predict    
truth    
     
    
truth    
    
   

x
x
 
f  x    wt w   c  
i   c 
i
 
yi   

   

yi   

overall  svm is more versatile and is capable
of obtaining at least a mediocre model on the
majority of the features  the only feature that
completely failed was ccprop  features body and
bodytfidf extremely overfit the training data and
had the next most lackluster performance after
ccprop  the rest of the features performed comparitively well with subject  to  and subjecttfidf
being the best with obtaining stable f  scores
on the test set between     and     for both the
   day and     day data sets 

figure    training and testing confusion matrices that resulted from training multinomial
nave bayes on body  averaged over all runs of
   fold cv 
the full results of the mnb runs can be seen
in figure    mnb behaves similarly on the body 
subject  and subjecttfidf features with the most
valuable model obtained coming from either the
 

fi 

 

conclusions

further study

i think the largest gains in this problem space
will come from improved feature selection that
would better capture the aspects discussed
above  along another line of thought  if i had
more time i would have liked to explore the possible improvements to the mnb model outline
by rennie et al    

the overall problem that plagued this project
was the high bias error associated with the majority of the model feature pairings which lead
to significant underfitting and inability to adequately fit even the training data  furthermore 
the few models that were able to fit the training
data well  mnb run on bodytfidf and c svm
run on body and bodytfidf    failed to generalize
and ended up significantly overfitting the training data 

references
    chang  c  c   and lin  c  j  libsvm  a library for support vector machines  department of computer science 
national taiwan university       

i believe that these problems all stem from
the fact that i didnt have what i would consider complete data for this problem  specifically  the following aspects of the problem were
not captured appropriately in the features     
only   person within a role or team needs to provide a response  responses from those equivalent people should be included in the positive
class      responses can be sent over different
media  in my job it is common to interact with
someone via instant message after receiving a
critical email rather than emailing a reply  alternatively  i might just go to their office rather
than sending a reply      multiple emails might
be exchanged on the same thread between when
an email was sent and when i send my reply 
in this case  the features that triggered the reply are not in the email that occured immediately prior  but several emails ago  which is not
a scenario that can be captured with my current
approach 

    chaput  m 
stemming     
https 
  pypi python org pypi stemming     
feb        python implementation of the
porter  stemming algorithm 
    hsu  c  w   chang  c  c   and lin  c j  a practical guide to support vector classification  department of computer science 
national taiwan university  taipei  taiwan 
     
    rennie  j  d  m   shih  l   teevan  j  
and karger  d  r  tackling the poor assumptions of naive bayes text classifiers 
    wikipedia 
f  score 
http   en 
wikipedia org wiki f  score  wikipedia
page for the f  score 
    wikipedia  tf idf  http   en wikipedia 
org wiki tf e       idf 
wikipedia
page for the tf idf metric 

additionally  its important to note that as
people switch projects and change what they are
working on over time  a model trained on various features   months ago might do a very poor
job generalizing to the current email flow  this
can be seen even in my data sets where some features improved performance when moving from
   days of history to    days but either stayed
the same or in fact got worse when moving up
to     days of history  

 
this change could also be attributed to the curse of
dimensionality as the dimensionality of the text features
increased dramatically as i increased the timeframe 

 

fi   
   

   

f  score

 
  
   
   
time spanned by data  days 
from
 
from train
   
from test
   

   
   

   

   

   

 

 

 

 
  
   
   
time spanned by data  days 
cc
 
cc train
   
cc test
   
   

 
  
   
   
time spanned by data  days 
to
 
to train
   
to test
   
   

 
  
   
   
time spanned by data  days 
cc
 
cc train
   
cc test
   
   

   

   

   

 

 

 

 
  
   
   
time spanned by data  days 
bodytfidf
 
bodytfidf train
   
bodytfidf test
   
   

 
  
   
   
time spanned by data  days 
from
 
from train
   
from test
   
   

 
  
   
   
time spanned by data  days 
bodytfidf
 
bodytfidf train
   
bodytfidf test
   
   

   

   

 

 

 

 

f  score

   

 
  
   
   
time spanned by data  days 
toprop
 
toprop train
   
toprop test
   
   

 
  
   
   
time spanned by data  days 
subjecttfidf
 
subjecttfidf train
   
subjecttfidf test
   
   

f  score

   

f  score

   
 
  
   
   
time spanned by data  days 
subjecttfidf
 
subjecttfidf train
   
subjecttfidf test
   

 
  
   
   
time spanned by data  days 
toprop
 
toprop train
   
toprop test
   
   

   

   

   

   

 

 

 

 

 
  
   
   
time spanned by data  days 
ccprop
 
ccprop train
   
ccprop test
   

 
  
   
   
time spanned by data  days 

   

 
  
   
   
time spanned by data  days 
ccprop
 
ccprop train
   
ccprop test
   

 
  
   
   
time spanned by data  days 

   

   

   

 

 

 
  
   
   
time spanned by data  days 

subject train
subject test

   

   

f  score

f  score

f  score

f  score

 

   

   

f  score

 
  
   
   
time spanned by data  days 
to
 
to train
   
to test
   

f  score

f  score

 

   

 
body train
body test

f  score

   

   
f  score

   

subject train
subject test

f  score

   

   

subject

 

f  score

body train
body test

f  score

f  score

   

body

subject
 

f  score

body
 

 
  
   
   
time spanned by data  days 

figure    f  score of mnb on each feature with
no scaling of the data 

figure    f  score of c svm on each feature
with no scaling of the data 

 

fi