yelp user rating prediction
yifei feng

zhengli sun

yife stanford edu

zsun  stanford edu

i  introduction
yelp is a popular crowd sourced local business reviews
and social networking platform  for each individual business 
users can submit a review on their products or services using a
one to five star rating system while interacting with each other
through following users and voting on reviews  having
accumulated an enormous amount of data on information 
reviews  and ratings of businesses  yelp has become an
important reference for making consumer decision  however 
going through a large quantity of raw data can be time
consuming  in order to overcome information overload  we
would like to create a more efficient option that gives users
suggestions that are tailored to their personal preferences 

for review table  there are         reviews  each contains
information such as business id  user id  star ratings etc  the
business and user tables provide further information about
each business user such as their review counts  average
reviews  etc  there reviews come from         users for
       business  this yields a sparsity of         which is
relatively high  netflix data have a sparsity of            to
see the review count distribution of the users  we plot the
histogram as shown in figure    we only used restaurant
reviews by users with over    reviews  which boosted the
sparsity to        

recommender systems have become a key tool for
providing users with personalized recommendations on items
such as movies  music  books  news  and web pages 
we aim to create a recommender system for yelp users by
predicting the users future ratings of businesses  we will use
the data set provided by yelp dataset challenge 
we are building a few models using three different
approaches  namely content based filtering  collaborative
filtering and hybrid approach 

figure   histogram of user review count

iii  evaluation metric

content based filtering methods are based on a businesss
profile and the users preference  we can predict the rating
score from a user to a business by matching users interests
with description and attributes of the business  standard
machine learning techniques such as logistic regression can
be applied to implement this approach 

according to      the most widely used evaluation metrics
for recommender system are root mean squared error  rmse 
and mean absolute error  mae   we used both systems to
check the performance of various methods implemented 
rmse is defined as 

collaborative filtering methods are based on analyzing the
information of users reviews  ratings or preferences and
predicting what users will like based on their similarity to
other users  we will build a k nearest neighbor model for this
approach 

       
rmse   


the hybrid approach is to combine collaborative filtering
and content based filtering  recent research has demonstrated
this approach can have better performance in some cases  we
will explore a few ways of combination and implement them 
ii  dataset
our dataset is the yelp dataset challenge data
 http   www yelp com dataset challenge  
this
dataset
contains five tables for business  review  user  check in and
tips  we are using three  business  user and reviews  of them 

 

  and mae is defined as 
   

       


where   is the predicted rating from user u on item i    is
the actual rating and n is the size of test set  we used k fold
cross validation where k     to calculate the evaluation
metrics 

fiiv 

baseline

our baseline model is similar to the model used in      a
baseline estimate rating is denoted by bu i and accounts for the
user and item effects 
bu i      bu   bi
where  is the mean rating of all reviews in the system  the
parameter bu indicates the difference between the average
rating of user u and   the parameter bi indicates the
difference between the average rating of business i and  
for each review in the dataset  we predicted the rating
from the user to the business using the formula above and
compared the prediction to the actual rating to calculate our
baseline rmse and mae 

   ln  

       
    
    ln  
 
     
         

if we use covariates into the model and make the coefficient
of each feature identical across the   logit equations  we have
that
                     
                     

                     
matlab function mnrfit was applied to the training set to
calculate the intercept terms  and coefficients   then  and
 were used to calculate the proportional odds of testing data 

v  content based filtering
in order to create user and business profiles  we used raw
numerical data from selected features in the user and business
tables  as well as derived feature based on restaurant
categories  for raw data input  we used   features  user
average review  review count and fan count  for users and  
features  business star rating  review count  longitude and
latitude  for businesses 
content based filtering predicts the rating score from a
user to a business by matching users interests with
description and attributes of the business  in order to create
more comprehensive profiles for users and businesses  we also
derived a feature that reflect users preference to restaurants of
a certain category  in order to get this data  we wanted to
create a binary table of what categories each restaurant belong
to  as well as a table for what are the average review of each
category for every user  however  there are     total available
categories but each user only have     reviews  to solve this
issue  we used k means to cluster all the categories into five
groups and created the above mentioned two tables based on
the new categorization 
we created our review data matrix by replacing the
business id column with business features  replacing the user
id column with user features  and the derived users
preference of this category  ordinal multinomial logistic
regression and binary decision tree was applied to implement
this approach 

a  ordinal multinomial logistic regression
the review ratings we are trying to predict can take on a
value                    since these categories are ordered  we
used a proportional odds cumulative logit model    to fit the
data  assume the associated probabilities of each value y can
take are                      and the accumulative probability
of y being less or equal to j is 
              
the proportional odd is 

b  binary decision tree regression
because the reviews are ordered  we used classification and
regression trees  cart  to split the dataset on each feature to
maximize the standard deviation reduction  we swept a range
of minimum numbers of observation per leaf node  as shown
in figure    a minimum number of around     yields the
lowest error rate 

figure    rmse vs the minimum number of observation per leaf

vi 

collaborative filtering

a  item based k nearest neighbors  knn 
in the collaborative filtering method  in order to predict the
rating of user u on item i  we look at the top k items that are
similar to item i  and produce a prediction by calculating the
weighted average of ratings from user u on these items 
its crucial to calculate the similarity between each two
items  we use the cosine similarity of item x and y as the
similarity measure 
       cost      

    
 
 
  
  

where  is the set of users who rated both x and y  and  
and   are the ratings from user u on item x and y 
we predict the value of ratings user u gives to item i as a
weighted average of similar items user u has rated 

fi   

           


        

we used a stochastic gradient descent optimization    by
simon funk to minimize the equation above 



where     is the top k neighbors of item i that user u has
rated 
we used cross validation to train the model with different
k 

we also used the biased stochastic gradient descent algorithms
    by yehuda koren to take bias of users and items into
accounts 
 

min                      
 

   

              
where  is the global average of ratings  and  and  are the
bias of user u and item i respectfully 
vii 

one observation from the result is that as the value of k
increases  we can get a lower mae  i e  a better prediction 
however  the improvement plateaus at      
another observation is that comparing this result to our
baseline  this models performance is not good  the main
reason is that yelp review data is highly sparse due to the
relatively high costs of writing review for yelp users 
specifically  even we are aware of the k items most similar to
the item i  the probability of user u having reviewed any of
these items is relative small  so we are still not able to make
good predictions 
b  user based k nearest neighbors  knn 
another approach of collaborative filtering is user based
k nearest neighbors  similar to item based knn  this model
first found the top k users who are most similar to the user u 
and based on their ratings on item i to predict the rating from
user u on item i 
c  matrix factorization
matrix factorization is a factor method that performs well
on sparse datasets  it was proved to be efficient in several top
submissions to the netflix prize contest 
the idea of this method is to map both users and items to a
joint latent factor space  each user u is associated with a
vector pu  and each item i is associated with a vector qi  the
rating can be predicted as
      
we ran updates on each user and feature vectors by
minimizing 
min                        
 

   

where   is the known rate from user u on item i  and  is the
regularization parameter 

hybrid

we implemented a hybrid model to combine both contentbased filter and collaborative filter  the purpose is to take the
advantages of users and restaurants profiles while also
maintaining the advantages of a neighborhood model 
specifically  we trained a knn model first and obtained
predictions for each users based on their neighbors  the
prediction was then added to mnolr as a feature to
recalculate the proportional odds model  the prediction was
also added to bdtr for comparison 
viii  results
table   below shows the rmse and mae of each applied
algorithms 
table   results of various algorithms

method
baseline
omnlr
bdtr
knn  item based 
knn  user based 
matrix factorization
 stochastic gradient descent 
matrix factorization
 stochastic gradient descent
with bias 
omnlr   knn
bdtr   knn
ix 

rmse
      
      
      
      
      
      

mae
      
      
      
      
      
      

      

      

      
      

      
      

discussion

for content based filtering  with the limited information
given in the user table  it was difficult to create user profiles
that reflect user preference of business types  therefore  we
didnt see drastic improvements from the baseline  for
collaborative filtering  knn algorithm is not efficient because
the sparseness of the dataset makes it difficult to find
representative neighbors for users  while matrix factorization
solution has a slightly better performance on the sparse data 
our hybrid models produce a significant improvement since
both users and neighbors preferences are taken into account 

fix  future work
we would like to analyze the review text and use this
information to create more comprehensive user and business
profiles  we would also want to explore more sophisticated
hybrid techniques  such as cascade or switching methods 

references
  

  

  

  

  
  

mendeley data vs  netflix data         november      from
https   synthese wordpress com            mendeley data vs netflixdata 
yehuda koren        factorization meets the neighborhood  a
multifaceted collaborative filtering model  in proceedings of the   th
acm sigkdd international conference on knowledge discovery and
data mining  kdd       acm  new york  ny  usa          
doi                        
http   doi acm org                        
shani  guy  and asela gunawardana   evaluating recommendation
systems  recommender systems handbook  springer us               
lops  pasquale  marco de gemmis  and giovanni semeraro   contentbased recommender systems  state of the art and trends   recommender
systems handbook  springer us               
stat       analysis of discrete data   n d    from
https   onlinecourses science psu edu stat    node    
koren  yehuda  robert bell  and chris volinsky   matrix factorization
techniques for recommender systems   computer                    

fi