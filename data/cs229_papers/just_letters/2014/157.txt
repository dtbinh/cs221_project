predicting hit songs with midi musical features
keven  kedao  wang
stanford university

kvw stanford edu

abstract
this paper predicts hit songs based on musical features from
midi files  the task is modeled as a binary classification
problem optimizing for precision  with billboard ranking as
labels  million song dataset  msd  is inspected audibly 
visually  and with a logistic regression model  msd features
is determined too noisy for the task  midi files encodes
pitch duration as separate instrument tracks  and is chosen
over msd  fine grained instrument  melody  and beats features are extracted  language models of n grams are used
to transform raw musical features into word document frequency matrices  logistic regression is chosen as the classifier  with increased probability cutoff to optimize for precision  an ensemble method that uses both instruments 
melody as well as beats features produces the peak precision
      at probability cutoff        recall is         alternative models and applications are discussed 

      monterola et al         a majority of the research
have taken low level features from audio file formats such
as  mp   and  wav by using signal processing techniques to
extract mfcc values spanning short time window  serra
et al        pachet and roy        this project extract instrument  melody and beats features from midi files  surprisingly good results are obtained in this project 
since it is more valuable to correctly predict popular songs
than correctly predicting unpopular songs  the precision metric is optimized 

  

   
keywords
music  hit song  classification  midi

  

introduction

the goal of this project is to predict hit songs based on
musical features  a song is defined as a hit if it has ever
reached top    position on a billboard weekly ranking  predicting hit songs is meaningful in numerous ways 
   help music stream services to surface upcoming hits
for better user engagement
   improve the iteration process for artists before releasing music to the public
various factors determine whether a song is popular a
hit  including the intrinsic quality of the music piece  and
psychological social factors  pachet and sony        the
latter encompass peer pressure  public opinion  frequency
of listening  and artists reputation  these psychological 
behavioral factors are harder to quantify  and is out of scope
for this project  the popularity of a song does correlate to
its intrinsic quality  pachet and sony        therefore this
paper focuses on the analysis of musical features  which are
quantifiable and encapsulated in the audio file itself  the
following musical features are analyzed 
   timbre instrument
   melody
   beats
relatively few projects have explored the hit song prediction space  pachet and sony       ni et al        dhanaraj
and logan       herremans et al        fan and casey

data

both midi and million song dataset are explored for
feature extraction  midi is shown to produce much higher
quality features that results in higher performance  and is
therefore chosen for this project 

midi

musical instrument digital interface  midi  is a technical
standard that allows musical devices to communicate with
each other  a midi file contains up to    tracks  each representing an instrument  each track contains messages  which
encodes the pitch and duration of an instrument key press 
midi files are close approximations of original music piece 
although lacking the fidelity and human ness of raw audio
files such as  mp  and  wav  it is nevertheless a faithful representation of high level musical features of timbre  melody 
and beats  midi suffices the purpose of feature extraction
in this paper 
     midi songs are used as training samples  with exactly       split between positive and negative training examples  the definition of positive and negative labels is
outlined below in labels section 

   

million song dataset

the million song dataset  msd  is a musical feature
dataset of one million contemporary songs  it is publicly
available from the joint collaboration between labrosa
and the echo nest  labrosa        the dataset is readily
parseable via a python api with getters and setters to individual features  further information could be queried via
the echo nest api  which is freely available  the echonest
      
in pursuing this project  visual and audio examination 
as well as a logistic regression model was used to test the
effectiveness of the   k subset  however  the result was unsatisfactory  the following introduces inspections and findings on why msd is not ideal for this project 

fi  

preprocessing

    type   to type  

figure    left  million song dataset  does not distinguish between tracks  right  midi   represents
each instrument as separated tracks 

two types of midi music files are of interest  type   is
easier to process for feature extraction  as each track represents distinct instruments  therefore all type   midi files
are converted into type   
   type    each individual track represents one musical
instrument       of training samples 
   type    one single track contains messages across all
channels       of training samples 
the open source python module mido provides a friendly
api that parses a midi file into native python data structures  bjrndalen and binkys        it is used to extract
instruments melody and beats features from midi files 

   feature extraction
in msd  the features of interest are 
 popularity labels  hotttness score  a score from  
to     from the echo nest representing popularity 
 instruments melody features  pitch matrix of
size    by length of song  size    represents the   
semitones in an octave  the value of each cell correlates to the relative strength of particular semitone at
a given time  sampling is done every     milliseconds 
with some variation based on the beats 
the pitch matrices are not effective representation of instruments melody features  as it does not distinguish between instruments  percussion can greatly distort the dominant melody of the song  jiang et al         figure   is a
visualization comparison between msd and midi melody
features  in the left figure  the red color represents a loud
signal and the blue color represents a quiet signal  the
visualization shows a noisy representation of melody  a listening test was performed on the transformed sine wave 
with frequency determined by the loudest semitone in a
pitch matrix column  the result audio is completely unrecognizable for multi instruments track songs  a baseline
model is implemented  with    fold cross validation showing a fluctuation around     precision  recall  and f  score 
this is not an improvement over random baseline 
midi files  on the other hand  encodes each instrument
into separate tracks as in the right figure  therefore it is
decided that the msd dataset is not effective as melodic
features  and is not used for this project 

   

labels

the problem of hit song prediction is modeled as a binary
classification problem  with positive labels representing the
popular songs and negative labels representing unpopular
ones  the billboard ranking is used to determine whether
a song is popular  billboard is a prominent music popularity ranking based on radio plays  music streaming and sales
published weekly  billboard contains ranking dating back to
the     s  in this paper  the labels are assigned as follows 
 positive  if a song ever reached the top    position
on any billboard ranking  since      
 negative  if a songs artist never had any song reaching top     position on any billboard ranking
this requirement is rather strong  leaving out a large midclass songs in between  this is done to emphasize the differences between the two classes 

fine grained features are engineered to capture the subtle
characteristics of a song  language models of n grams are
used to capture the building blocks of melody and beats  in
order to extract the features  the following midi messages
are of interest 
 set tempo  specifies tempo of music piece in microseconds per quarter note  beat 
 note on  specifies the start of a music note event  e g 
piano keyboard press 
 note  specifies the pitch  with    representing the
middle c
 velocity  specifies how much force a note is played
with  a note on message with velocity   is the
same as a note off message 
 note off  specifies the end of a music note event
 program change  specifies the instrument for track
 delta time  specifies the number of ticks since last midi
event  for each midi event  this can be converted to
delta time in seconds 
besides  the metadata of pulse per quarter note is needed 
it specifies number of ticks per beat  this is needed to
compute time delta between midi messages 

    instruments
each midi track contains a program change message 
with instrument type encoded with          a manual grouping on instrument types is done based on suggestions from
 mckay       and  association        the grouping shrinks
the feature space  while capturing the distinguishing timbre
of instrument classes 
table    midi instrument grouping by program
change number          
midi program change number instrument
   
keyboard
             
electric
     
other
      
chromatic percussion
       
organ
      
acoustic guitar
       
electric guitar
       
bass
   
         
percussive

fi   

melody

melody features are represented by chord progression characteristics  these defining characteristics in music theory is
captured in features below 
 consecutive two notes    grams   captures musical
interval  musical interval defines transition between
two consecutive music notes   wikipedia       
 consecutive three notes    grams    caswell and ji
      suggests that markov models looking at previous
  or   note pitches produced the best results 
the instruments and melody features are combined to represent the distinct instruments melody combination  as an
example  the following midi note on messages are transformed into the following features 
midi messages 
 track   
program change  value       instrument 
note on  note       velocity     

  

electric guitar

j    

  grams 

keyboard        keyboard        electric guitar      

  grams 

keyboard         

the beats features are represented by extracting time
delta between consecutive musical notes  the idea of  grams and   grams is used here again  in midi  time delta
between midi messages is specified in number of ticks  the
following calculation is needed to calculate the delta time  in
seconds  between consecutive midi messages 
tempo
           p p qn

   

     

yi  w  xi  b      i
 

   

argmin
w  b

note duration

dimensionality reduction

two dimensionality reduction techniques are explored to
avoid overfitting  however  due to their limitations and the
effectiveness of regularization term in logistic regression 
no dimensionality reduction algorithm is used in this project 

n

x
 
kwk    c
i
 
i  

   
 
   

yi  w  x  b      i   i   

   

   

naive bayes

naive bayes assumes each feature is independently distributed  this assumption is too strong for melody segment
features  n grams   as they are dependent on neighbors and
the overall chord progression distribution of the song 

percussion

track   is always the percussion track  percussion track
is more important as a beats feature than other instrument
tracks  therefore a prefix is added for features extracted
from percussion track to distinguish from other tracks 

   

svm

   

midi contains various messages other than note on  time
delta occurs between each consecutive midi messages  work
is done to accumulate the time delta between consecutive
note on messages  afterwards  time delta is converted to
beat per minute  a standard way of capturing tempo information and accounting for small time delta 

 
    et x

   

svm is regarded as one of the best off the shelf models 
it has the advantages of being time efficient and avoiding
overfitting  in this project  time efficiency is not a concern
given the relatively small sample size         to work with 

tempo is in microseconds per quarter note 
ppqn  pulse per quarter note  is in ticks per quarter note 

     

m
n
x
  x
    h  x i     y  i       
j   
 m i  
j  

h  x    p  y     x     

beats

delta time   delta ticks 

logistic regression

logistic regression is chosen as the model for task  logistic regression outputs the confidence probability for each
prediction  this is ideal for optimizing for precision  since
the probability cutoff for positive labels can be increased to
form a stricter criteria on popular songs  a regularization
coefficient  is added and iterated on to decrease overfitting 

extracted features 

   

models

the problem is modeled as a binary classification problem 
this allows for plug and play of many off the shelf classification algorithms  a more practical model is outlier detection 
since it is much more valuable to predict a popular song than
an unpopular song  however  i was not able to find such a
model with satisfying results  the following models are used
in training and testing on the dataset 

   
piano

note on  note       velocity     
note on  note       velocity     
 track   
program change  value        instrument 
note on  note       velocity     
note on  note       velocity     

pca  principal component analysis  transforms feature
space into a lower dimensional subspace composed of pairwise linearly independent vectors  in practice pca tends
to favor features with high variance  feature selection prioritizes features with highest marginal increase decrease in
performance  feature selection itself is time consuming 

 
argmin p  y   yi  
y

   

n
y

 
p  xi  y 

   

i  

one class svm

the supervised outlier detection problem is attempted 
one class svm is an one class classification algorithm that
takes only positive training examples and adds a negative
example at the origin  compared to other clustering  kmeans  and outlier detection algorithms  mixtures of gaussian   one class svm allows for supervised learning 

fi  
   

results
models comparison

logistic regression  cutoff probability        regularization          svm  naive bayes  and one class svm are
used to compare performance     fold cross validation is
performed on the      samples      positive      negative   mean precision is used as evaluation criteria  logistic
regression and svm resulted in the highest mean precision 
table    logistic regression and svm
highest mean precision
features
model
precision
  class svm
     
naive bayes
     
beats
logistic reg 
     
svm c    
     
  class svm
     
naive bayes
     
melody  
logistic reg 
     
instrument
svm c    
     

   

produces the
recall
     
     
     
     
     
     
     
     

f 
     
     
     
     
     
     
     
     

figure    using the ensemble method  precision
peaks at        recall is       

ensemble method

the ensemble method with logistic regression  regularization         gave the highest overall precision  this
method uses both instruments melody features and beats
features  two separate logistic regression classifiers are
run on each feature sets separately  the combined output
is positive if both predicted probabilities are greater than a
confidence cutoff 
precision is optimized by increasing the probability cutoff 
the best precision       is achieved at probability cutoff
of        recall is         the increase in probability cutoff
can be intuitively understood as the increased confidence
required to qualify for a positive label  a popular song  

figure    using the ensemble method  probability
cutoff can be increased to increase precision 

figure    ensemble method produces the best performance by combining both instruments melody
features and beats 

   

features comparison

using only instruments melody features or only beats features resulted in identical performance  roughly     precision   combining the two features as in ensemble method
improves the precision by roughly     or more 

figure    combining instruments melody and beats
features results in      increase for mean precision 

fi   

regularization

experiment is done in tweaking the regularization parameter  in logistic regression  p         the result shows an
insignificant change in precision as a result of regularization
parameter change  therefore  is kept at the default     

  

discussion

the peak precision       at probability cutoff       is surprisingly good  the corresponding recall is        precision
is optimized since it is more valuable to have true positives
than true negatives  the high precision demonstrates that 
   the distinguishing characteristics between popular and
unpopular songs can be learned 
   midi files are able to produce high quality features
for hit song prediction purposes 
   it is promising to borrow language models for melody
and beats feature extraction 
   the feature extraction of instruments  melody  and
beats features is able to capture the distinguishing
characteristics of a song  the ensemble of instruments 
melody and beats features is promising 
the top     features with highest logistic regression coefficients are analyzed  there is no clear pattern on these
features  given the large feature space and the large number
of features a single song has  a positive prediction is likely
attributed by the aggregation of a large number of features 
one class svm hardly gives any improvement over random baseline  this can be explained by the strict information loss by replacing all negative training examples with a
single negative example at origin 

  

future work

supervised outlier detection models could be explored  in
this project  the hit song prediction problem is modeled as a
binary classification problem  modeling as outlier detection
would be more suitable because 
   it is more valuable to correctly predict popular songs
than predicting negative ones  modeling as outlier
detection removes the need to collect negative label
songs  which are vast and harder to define 
   there could be a vast number of reasons as to why a
song is not popular  it is better to focus on finding
defining features of popular songs 
neural network has produced excellent results for speech
recognition tasks  and could be used for feature selection
purposes  generative models such as mixture of gaussians
and k means can be used for outlier detection  neural networks could be supervised to learn features for these unsupervised models 
a natural next step would be auto hit song composition 
the result could augment human in composing hit songs by
offering inspirations  a combiner is needed to reconstruct a
song coherently from building blocks of melody and beats 
the bottom up construction mechanism would first combine
n grams into musical bars  then into verses choruses  and
eventually into the entire song 

  

references

 association       midi manufacturers association       
general midi level   sound set         
http   www midi org techspecs gm sound php

 bjrndalen and binkys       ole martin bjrndalen and
rapolas binkys        mido   midi objects for
python          http   mido readthedocs org en latest 
 camenzind and goel       tom camenzind and
shubham goel         jazz   automatic music genre
detection         
 caswell and ji       isaac caswell and erika ji       
analysis and clustering of musical compositions
using melody based features         
 dhanaraj and logan       ruth dhanaraj and beth
logan        automatic prediction of hit songs   in
ismir         
 fan and casey       jianyu fan and michael a casey 
      study of chinese and uk hit songs prediction 
       
 herremans et al        dorien herremans  david
martens  and kenneth sorensen        dance
hit song prediction  technical report 
 jiang et al        nanzhu jiang  peter grosche  verena
konz  and meinard muller        analyzing chroma
feature types for automated chord recognition  in
audio engineering society conference    nd
international conference  semantic audio  audio
engineering society 
 labrosa       columbia labrosa        million song
dataset         
http   labrosa ee columbia edu millionsong 

 mckay       cory mckay        automatic genre
classification of midi recordings  ph d  dissertation 
mcgill university 
 monterola et al        christopher monterola  cheryl
abundo  jeric tugaff  and lorcel ericka venturina 
      prediction of potential hit song and musical
genre using artificial neural networks  international
journal of modern physics c               
         
 ni et al        yizhao ni  raul santos rodrguez  matt
mcvicar  and tijl de bie        hit song science once
again a science         
 pachet and roy       francois pachet and pierre roy 
      analytical features  a knowledge based approach
to audio feature generation  eurasip journal on
audio  speech  and music processing                
 pachet and sony       francois pachet and csl sony 
      hit song science  music data mining        
      
 serra et al        joan serra  alvaro corral  marian
boguna  martn haro  and josep ll arcos       
measuring the evolution of contemporary western
popular music  scientific reports          
 the echonest       the echonest        echo nest api
overview          http   developer echonest com docs v 
 tzanetakis and cook       george tzanetakis and perry
cook        musical genre classification of audio
signals  speech and audio processing  ieee
transactions on                      
 wikipedia       wikipedia        interval  music  
wikipedia  the free encyclopedia         
http   en wikipedia org w index php title interval 
  music  oldid          

fi