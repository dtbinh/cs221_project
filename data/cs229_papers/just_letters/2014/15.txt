attribution of contested and anonymous ancient greek works
sarah beller and james spicer
 sfbeller  jspicer  stanford edu
december         

abstract

as stylometry  the famous study of the federalist papers by mosteller and wallace in     
publicized the field  and the advent of modern
computing has increased the scope of research 
early studies were hampered by computational
limitations  and common algorithms tended to
overfit data when feature dimensionality became too large      the development of faster
computers as well as new machine learning algorithms allowed researchers to overcome this
issue  since newer classifiers were better able to
deal with higher dimensions  recent work has
combined lexical and syntactic measures  leading to promising initial results     

authorship attribution has been a persistent
problem in the classical genre  as texts that
reach us from antiquity are often corrupted 
edited  or forged over the thousands of years
since their initial production  scholars have
worked on identifying writers stylistic differences in an attempt to distinguish genuine texts
from fakes  and to attribute an author to previously anonymous works  increasing computing
power allows the derivation of more complex
features  giving us new information about each
authors linguistic signature and writing style 
our system is able to accurately predict the author of a complete anonymous work  as well as
many text fragments that currently have contested authorship  we experimented with using semantic and lexical features  and explored
both discriminative and generative classification algorithms  our highest performing system achieved an attribution accuracy of       

 

 

data

the entirety of the classical corpus is digitized
and available online through the perseus digital library     as xml files  we use a selection
of    of the most influential texts that ranged
in age from the  th century bce to the  nd century ce  the    works with known authorship
make up the training set  and the   works with
either unknown or contested authorship make
up the test set  the texts genres include epic
poetry  prose  tragedy  comedy  and history 

prior work

scholars have discussed means of determining
authorship since antiquity  rigorous modern
authorship attribution studies began in earnest
in the nineteenth century  when it was described
 

fi 

features   preprocessing

naive bayes
naive bayes is a generative model that assumes
all features of a data point are independent  for
a class c and features f  
p
log p c f     log p c     ni   log p fi  c 
it is less prone to overfitting than other models 
which is important for this project due to the
relatively small dataset  in general  generative
models excel with little data 

beginning with the ancient greek words  we
implement our own data processing to increase
model accuracy by reducing feature dimensionality  we remove accents and stem words to
their root by removing noun and verb endings 
proper nouns including character names and
place names are ignored so that our models are
as non subject specific as possible 
to get baseline accuracies against which
further work can be compared  we first train
our classifiers only on word frequencies  bagof words   we then derive ten other lexical
features  including words per line  syllables per
word  and the frequency of various parts of
speech such as prepositions  particles  and hapax legomena  words that appear only once in
the entire classical corpus   the focus on words
context rather than their meaning isolates the
works writing style rather than topic  which according to morton     leads to superior discrimination between authors writing in the same culture and language 

 

svm
svms are discriminative models that map data
points into two separate categories that are as
widely separated as possible  we use the many
auxiliary binary models created by libsvm to
give a pseudo multiclass svm model  we assume that authorship categorization is linearly
separable  svm optimimization problem 
p
 i   j    hx i    x j  i
maxa w      m
i j
i   y y p
 i     
s t  i     i           m   m
i   i y
svms are used because they work well with
high dimensions  furthermore  author detection with svms on full word forms has been
shown to be remarkably robust  even if the author wrote about different topics     

models
knn

we implemented four different classification algorithms  naive bayes  support vector machines  svms   k nearest neighbors  knn  
and decision trees  all were trained on the
training matrix x            features    
works  and corresponding class label vector y
    author labels   to improve performance  we
assign each author a unique number so that the
models are manipulating integers rather than
strings 

knn is a discriminative model that weighs the
label of each training point according to how
closely it matches the query point  to find k
 i 
nearest neighbors of data point xn   choose  
pk
p
 i 
 i 
if i   yn  k   and   if ki   yn  k   
we used knn because it performs well with
evenly distributed  continuous variables  so is
suited to our dataset where works are spread
between a relatively large number of authors 
 

fidecision trees
decision trees are discriminative models that
create a tree data structure with class label
leaves and feature branches  they perform
well with large datasets with a high number of
both features and class labels 

 a  accuracy on
entire feature set

 b  accuracy on
best feature set

discriminant analysis
we attempted to implement both lda and
qda  but the two algorithms struggled with
the high             dimensions required by our
program 

 

and some works are longer than others  figure
  shows this variation 

results

due to the small size of the dataset  we used
leave one out cross validation on the training
set 
model
naive bayes
svm
knn
decision trees

baseline    
     
    
     
     

best    
     
 
     
     

table    accuracy of baseline and best models 

figure    number of works compared to total
words  by author 

we also used our most accurate models to
predict authorship on contested and anonymous
works  see table    

 

another issue is the lack of consistent writing
style throughout longer works  including plays
in which different characters are expected to
speak in different ways  our most significant
problem was balancing our sparse data with the
high dimensionality of our feature set and high
number of class labels  it was this issue that resulted in the poor performance of svms  which
is primarily a binary classifier 

discussion

there are several difficulties inherent in authorship attribution based on writing style  our
data is skewed by class imbalance  different authors have different numbers of surviving texts 
 

fifigure    performance for each lexical feature on its own 
work
prometheus bound
iphigenia at aulis
phoenissae
rhesus
the shield of heracles
homeric hymns

naive bayes
euripides
euripides
euripides
aeschylus
hesiod
pindar

knn
euripides
euripides
euripides
euripides
hesiod
pindar

decision tree
aeschylus
euripides
sophocles
aeschylus
aeschylus
hesiod

table    authorship predictions on unknown and disputed works 

 

conclusions

performed particularly well  perhaps because
they are most indicactive of a particular writers
style 
the predictions on the anonymous and
contested works lead to interesting conclusions 
prometheus bound is usually attributed to
aeschylus  although modern scholars are divided on the plays authenticity due to nonaeschylean meter  style  and portrayal of zeus 
our     split against aeschylus is not too unsurprising  however  as euripides and aeschylus
share the same genre and many stylistic features 
iphigenia at aulis  phoenissae  and rhesus are all attributed to euripides  but have
had their authorship called into question due

we noticed a significant performance improvement when we trained on only the most common words in the data  resulting in our top accuracy when we combined the     most common words with our derived lexical features
 see table     in fact  this combination proved
more accurate than when we included trained
on all words  this is due to fact that the rarest
words are often topic specific  and so will hinder
prediction rather than help it 
as figure   shows  the lexical features we
derived proved remarkably accurate even by
themselves  the ratios of various parts of
speech  prepositions  particles  articles  etc  
 

fireferences

to their stylistic differences from the rest of euripides work  our classifiers split on each one
reflects the academic view that the style is certainly euripidean  but with many foreign elements introduced 

    www perseus tufts edu
    stamatatos  efstathios         a survey
of modern authorship attribution methods 
journal of the american society for information science and technology            

the shield of heracles was viewed as an
imitation of hesiods epic poetry as early as the
hellenistic period  at times the text even copies
directly from the iliad  modern scholars are
not in consensus  but the common view is of
the work as being in the style of hesiod  a view
reflected by our classifiers     result 

    stamatatos 
efstathios 
fakotakis 
nikos  and kokkinakis  george        
computer based authorship attribution
without lexical measures  computers and
the humanities             

lastly  the homeric hymns are a set of
hymns to greek gods  ascribed to homer from
antiquity  it is agreed that the poems imitate
homers style but were written centuries after his death  it is a notable success for our
program that none of the classifiers ascribed
homeric hymns to homer despite its eponymous similarity to homers works 

 

    michaelson  s  and morton  a q         
the new stylometry  a one word test of
authorship for greek writers  the classical quarterly  new series              
    morton  a q          the authorship of
greek prose  journal of the royal statistical society  series a  general                 

future work

    dietrich  joachim  kindermann  jrg 
leopold  edda and paass  gerhard        
authorship attribution with support
vector machines  applied intelligence    
        

our next steps for the project include using a
feature selection algorithm to reduce the dimensionality of our feature set  although a reliable
pos tagger does not exist for ancient greek 
the perseus project has a small dependency
treebank for a small number of texts  which
we will use to develop a more robust and less
context specific system  additionally  we plan
to refine and split several of our lexical features
from broader categorizations into more specific
features  on a larger scale  we will also use
the system to predict authorship for unclassified fragments of larger works  as well as the
larger works themselves 
 

fi