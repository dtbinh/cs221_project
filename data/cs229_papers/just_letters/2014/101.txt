an adaptive system for standardized test preparation
  

julia enthoven
bs mathematical  
computational sciences      
jjejje stanford edu
cs    
   introduction
how can software improve test
preparation based on a student s past
performance  by applying supervised
machine learning algorithms  i designed and
implemented an adaptive standardized test
prep platform that emphasizes instruction on
the concepts and skills  rule nodes  where
the student is weakest  with questions
organized around a set of testable topics  the
adaptive engine estimates a students
proficiency
with
maximum
likelihood
techniques and draws questions from
conceptual areas where the student is
weakest  applying the algorithms to data
from large populations will also show which
topics are the most difficult for students to
pick up or remember  which further informs
the question engine  i designed the system
to be content agnostic so that it could be
used with any standardized curriculum and
expand access to adaptive learning tools in a
limited access  high return industry 
   dataset
for test and train data  i implemented
and added content for quantitative section of
the graduate record exam  gre   the
systems content database is composed of
questions and explanations are taken from
practice tests available on the ets website 
similarly  the     procedural and fact based
rules are taken from the standards published
by ets  for each row  i extrapolated from
the question and explanation which rules
apply to that question 
the student learning database  slo 
tracks learner responses  for the ith learner 
the student learning database  slo  starts
off empty and expands by a row after each

question attempt  each row of the design
matrix designates a question answer pair 
where xtj     if the tth question employs
knowledge of rule j and   otherwise  the
binary response variable represents a
correct incorrect answer 
   models
the model estimates a students ability
or proficiency on a set of procedural  and
fact based rules as a function of their wellcorrelated responses to test questions  the
engine then employs this parameter to
predict the likelihood that the student will
answer a question that depends on the jth
rule correctly 
               exp      
the effect of forgetting 
the
literature
evidences
the
importance of recency on memory and
learning      in an adaptive learning context 
if a student has mastered a skill then his
recent responses are likely to contain correct
answers  i studied two models that give
emphasis to more recent results  weighted
logistic regression and recent performance
factor analysis  r pfa   linear weights
multiply the effect of a question in proportion
to its distance from time t 
                exp tj    
in contrast  r pfa includes only
results within a recency window and gives
exponentially more weight to those nearest
to time t 
the exponential weights are
multiplied by the average rate of success on
past questions with rule j to get the

fiexponentially weighted moving average
 ewma  at time t  a is a tuning parameter
used to promote or demote the importance of
recency  following convention in the literature
     i set a    
           
   
    
     
     

   results
when tested on a students response
history  training set    questions  test     
the basic model  along with an svm and a
nave bayes calculation   performed only
slightly better than chance  mse       the
linear weighted model did much better 
correctly predicting    
of student
responses to future questions  the two
parameter model  which incorporates the
effects of guessing  performed slightly better
but still with high bias 

this formula for the ewma reduces
noise when the student first starts answering
questions by including a few ghost
responses prior to the students first guess 
assuming that the student does not know the
rule node before answering a question  y    y     y     once calculated  the ewma is
used as an additional feature on the design
matrix  which is incorporated in logistic
regression 
                exp j         
in addition to the ewma  i examined
the effect of including the total number of
questions attempted for rule j  the total
successes  and both as features  these
results may indicate the effect of seeing a
question in comparison to answering a
question correctly as predictors of a
students performance 
the effect of guessing 
on a multiple choice test  a correct
answer may indicate either proficiency in the
questions rules or a successful guess  in
reality  a correct answer may be a
combination of competence and guessing  a
student might eliminate answer choices
based on his knowledge of the context and
choose from among the remaining options 
this pseudo guessing parameter called c
represents the probability of a guess leading
to the correct answer and can be estimated
with    number of answer choices   since my
testing focused on preparation for the gre 
c     
by applying the law of total
probability  i incorporate this into our logistic
regression model 
                          exp         

  

 mse 

svm

nave
bayes
    

logistic
regression
 unweighted 
    

logistic
regression
 weighted 
    

oneparameter
model
 train    
n   
test    
twoparameter
model 
c    
rpfa
 with total
attempts 
rpfa
 with total
successes 
rpfa
 with total
successes
and total
attempts 

    

    

    

    

    

    

      

    

 

    

    

    

 

   

    

   

recent performance factor analysis
outperformed both of the simpler models 
when both the total number of attempts and
the total number of past successes  for
student i in the jth category  were included as
features  the predictions on whether or not a
student would answer the next question
correctly rose to     accuracy  on the same
features  an svm categorized     of future
questions correctly 
the addition of total successes as a
feature greatly improve the models accuracy
from     to     mse  the model that
included both total successes and total
attempts as features had the lowest mse 

  

fi   discussion
these test results show that using an
svm training algorithm based on the results
seen up to time t is more accurate than a
nave bayes estimate or basic logistic
model  this svm classifier can be used both
as a predictive tool and as a proxy for
estimating the proficiency of a student  with
    accuracy  the svm model can identify
problems that a student is likely to answer
incorrectly  focusing their study on weak
areas 
the results also show the importance of
including both the number of questions a
student has answered up to time t and the
number answered correctly as features 
according to the r pfa model  both
questions answered and questions answered
correctly show a statistically significant
correlation with the likelihood that a student
has mastered the underlying material 
nonetheless  there is still a significant
amount of bias in the system  to fulfill its
potential and provide meaningful feedback 
the adaptive model must give accurate
estimates of a students competence  the
above results may be improved by
incporating
an
additional
parameter
representing the difficulty of each problem 
the analysis above treated the probability of
the student answering two question with the
same rule requisites
with the same
probability  however  as any test taker
knows  questions can vary in difficulty
regardless of their content  the relative
difficulty of a problem may be due to the mix
of its answer choices  its wording or
presentation  its numeric values  or a number
of other hidden variables the current system
does not have the capacity or dataset to
estimate bj  but i do hope to implement it in
future iterations of this adaptive system
testday system  bj is updated according to
the percentage of studiers in the dataset who
have answered the question correctly 
finally  a broader question answer
dataset is needed in order to test effectively 
the question rule mapping i have now has

too few questions  making logistic regression
less useful 
   platform design    future 
in addition to implementing the predictive
models  i worked on the design of the
adaptive learning system  i built a content
management system  which maintains and
delivers content  questions  answer choices 
and explanations   stores the correct answer
to determine y i   and maps questions to
rules  a student learning database that stores
the time stamped student input  the adaptive
engine that delivers content according to a
students estimated proficiency  and a
reporting dashboard 
content agnostic
the platform requires input of n
proceduraland
fact based
rules
representing the content standards  a
mapping of questions to those rule nodes 
and the questions  answers  and choices
themselves  beyond that  the adaptive
engine function without user maintenance to
help prepare students for standardized
exams  i hope that eventually the curriculum
input can be crowd sourced  so that new
questions are submitted regularly and so that
these educational materials  often guarded
by test prep companies  become accessible
to everyone 
visualization
when students have more information
about their proficiency in content categories 
they can be more effective studiers 
dashboards also give insight to teachers and
parents  who may want feedback about how
a student is performing in relation to
standardized curriculum  using javascript
and photoshop  i designed the adaptive
systems
interface
for
questions 
explanations  and visualization of progress
on content categories  although the data is 
at this point  static  i hope to incorporate the
above results to make it adaptive to student
answers and interaction

fifalakmasir  mohammad et al  a spectral
learning approach to knowledge tracing   
conference    month          
http   www cs cmu edu  ggordon falakmasir etalspectral kt pdf
hu  david  how khan academy is using machine
learning to assess student mastery   nov      
http   david hu com            how khanacademy is using machine learning to assessstudent mastery html

interface
designs
   conclusion
adaptive learning systems have the
potential to expand access to effective
instruction and valuable test prep resources 
if applied efficiently and accurately  machine
learning can help students identify their
competence on core skills and motivate them
to focus on their weak areas  moreover 
algorithm based instruction systems are
smarter than conditional technologies
because they are more dynamic  a student
can switch between questions and topics
without losing their data track  making a
content agnostic platform would enable
teachers to use the power of machine
learning in any subject  making education
more meaningful and impactful for students 
   references
   baker  ryan et al  detecting learning
moment by moment   international journal of
artificial intelligence in education           
http   www columbia edu   rsb     bgh ijaiedv   pdf
   galyardt  april and ilya goldin  recentperformance factors analysis    th international
conference on educational data mining 
stamper  j   pardos  z   mavrikis  m   mclaren 
b m 
 eds   http   educationaldatamining org edm    
 uploads procs     posters    edm     poster pdf

thorpe  geoffrey l  and favia  andrej   data
analysis using item response theory
methodology  an introduction to selected
programs and applications    july      
psychology faculty scholarship  paper    
http   digitalcommons library umaine edu psy fac
pub   

fi