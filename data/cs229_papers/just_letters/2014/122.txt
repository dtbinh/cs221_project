forecasting bike rental demand
jimmy du  rolland he  zhivko zhechev
abstract
in our project  we focus on predicting the number of bike rentals for a city bikeshare system in washington d c  
as part of a kaggle competition  through our project  we identified several important feature engineering ideas that
helped us create more predictive features  we then trained and tuned several different models with our data  and
experimented with ensembling methods as well  in the end  we found that decision tree based models perform well on
the bikeshare data  in particular  using a conditional inference tree model yielded both the best cross validation result
and leaderboard performance 

 

introduction

predicting demand of ride sharing systems has become a common problem in the modern world  with companies such as
uber and lyft emerging in the car sharing service  similarly  bike sharing services have gained considerable traction in
the u s  in the past decade      heavy street traffic in busy cities and a desire for an environmentally friendly form of
transportation make biking an attractive alternative to traveling by car  a limited supply of bikes  increasing demand for
bikes  and cost of storage and relocation of bikes serve as motivation for forecasting the demand of bikes 
this paper examines the capital bikeshare program implemented in washington d c  we are provided hourly bike rental
data with weather and date information spanning   years  and our goal is to predict the total number of bikes rented on an
hourly basis  our target optimization metric is the root mean squared logarithmic error  rmsle   which is computed
as follows 
v
u n
u  x
t
 log pi       log ai       
n i  
where n is the number of observations  pi is our predicted count  and ai is the actual count  we seek to identify the models
that result in predictions which minimize this error 
we worked on this problem as part of a kaggle competition  the data was split between a training and test set  and each
day we were allowed to submit up to   sets of prediction values for the test set  and the rmsle error results for each set
of predictions would be tracked on a public leaderboard 

 

data

   

original data

the raw training data consists of       observations  each training sample consists of    data entries  the first   contain the following features  date and hour  season  holiday  working day  weather  temp  atemp  the temperature it feels
like   humidity  and wind speed  date and hour are provided as a single string  weather is a categorical variable with  
levels representing different weather conditions  holiday is a binary indicator variable representing whether the particular
day was a holiday  and working day is a binary indicator variable signifying whether the day was a non holiday weekday  in addition  the last   data entries are casual  registered  and count  casual and registered represent the number
of bike rentals made by non registered and registered users  respectively  count is the sum of casual and registered values and is the value that we seek to predict  the training data represents the first    days of each month for a   year period 
similarly  the test data consists of      observations with the same features  the registered  casual  and total count
data is withheld  though  as that is what we are trying to predict  the test data represents the remaining days  after the
first    days  of each month in the same   year period 

   

featurization and preprocessing

to start off  we converted the date and hour variable into   separate components  which were added as new features 
month  day of week  and hour of day  from this dataset  we identified   ways the feature space could be altered in order
to improve generalization error 
 converting categorical variables into binary variables and discretizing continuous variables
we discretize continuous variables like temperature by splitting them into buckets  where each bucket represents
a range of values  and classifying an observation under one of these buckets  we do this primarily to improve the

 

fifigure    plot of cross validation errors by training a ctree model on    of our    featurized datasets  we ended up
selecting the dataset represented by the bar highlighted in red 
performance of linear models  since variables such as temperature clearly do not have a linear relationship with bike
rental count  each bucket  however  can be roughly approximated linearly   in addition  we also split categorical
variables into binary indicator variables  as one of our models  glmnet  could not handle categorical data 
 replacing the season variable by a variable indicating the month
there might be some differences between individual months of the same season  and therefore are not captured in
the season variable  we conjectured that having a month variable instead could improve predictions 
 adding a new variable that represents the day of the week
we noticed some slight differences in the mean bikes rented between the different days  and wanted to see whether
adding such a variable would positively influence our results 
 removing the temp variable
the features temp and atemp  temperature it feels like  are highly correlated  as one might expect  so removing one
of them might reduce collinearity issues  we experimented with removing the temp variable  as we believed that
atemp would be more relevant for an individuals decision of renting a bike 
 removing the holiday variable
we looked at the data and noticed that bike rentals did not seem to change when there was a holiday  therefore 
we tried removing the variable to see if it was just noise 
 adding peak hour indicator variables
some hours clearly have more demand than other hours  so we looked at the data to identify peak hours for bike
rental  we noticed that on weekdays  the peak hours for bike rentals were between     am and     pm  on weekends 
the peak hours were anywhere between    am     pm  then we classified each observation depending on whether it
fell into the weekday peak hours  the weekend peak hours  or none of them 
in order to select the best subset of these different featurizations  we wrote a matlab script that generated all    featurized
datasets    for each subset of these featurization methods applied to the original data  we then used    fold crossvalidation to compare the performance of all of these datasets  trained using a ctree model  which is described in the
models section   and selected the   datasets that yielded the lowest rmsle error  figure     we then submitted predictions
to the leaderboard for these   datasets  and found the one that gave the best leaderboard performance  this particular
dataset used only   of our featurization ideas  removing the holiday variable and adding the peak hour variables  we
then performed the rest of our experiments and tests exclusively on this dataset 

 

models

for each of the following models  we tuned the relevant hyper parameters via    fold cross validation 

 

fi   

linear model

we used a basic linear regression model with no modifications in order to get some baseline predictions 

   

generalized linear models with elastic net regularization  glmnet 

glmnet     is an extension of glms we saw in class  by adding in additional regularization terms  this model solves the
following problem 
n
  x
wi l yi        t xi           kk        kk   
min
   n
i  
in the formula above  l gives the negative log likelihood contribution from training example i and          controls the
elastic net penalty   controls the overall strength of the penalty  and the regularization path is identified via coordinate
descent  the model can be adapted to many distributions  including the gaussian and the poisson distributions  for our
particular problem  we chose to use the poisson distribution  given that we are predicting the value of a discrete occurence
 the number of bikes that will be rented in a particular hour  in addition  by running some quick experiments  we found
that the poisson distribution did indeed give the lowest generalization error 

   

generalized boosted models  gbm 

this model uses gradient boosting      which builds an additive decision tree model in order to predict the outcome in
a regression  the model greedily adds base learners from a select hypothesis class  and attempts to find a weighted
combination of them that minimizes the training error  though the performance of single base learners is generally poor 
they can be combined to form a very strong learner  this process is known as boosting  gbm is a flexible model that
can be adapted to a wide range of distributions  including the poisson distribution  which again turns out to give the best
generalization results out of the different distributions 

   

principal component regression  pcr 

we created a new set of features using pca  covered in class       and ran a linear regression on a subset of these
transformed features  it turned out that using all of the components gave the lowest generalization error 

   

support vector regression  svr 

this model works similarly to svms as described in class  but is adapted to handle regression  it attempts to approximate
the value of a continuous value by using a loss function that is insensitive to the errors      we found that using the gaussian
kernel with a squared error penalty performed the best for our data 

   

random forest  rf 

random forest     is a meta algorithm that combines a large number of decision tree models  each individually built on
bootstrapped samples of the data  this process of sampling the data and combining the individual decision trees is called
bagging  and is able to reduce the variance of the predictions without increasing the bias  the final predictions are formed
by taking the mean of the individual decision tree predictions 

   

conditional inference trees  ctree 

ctree     builds a decision tree model by iteratively creating splits for the variable that is most significantly associated
with the response variable  which is measured using p values  the algorithm stops when no remaining variables have a
significant p value  the original idea to use ctree came from a forum post made by a fellow competitor     

   

ensemble learning  stacking

we utilized a type of ensemble learning called stacking      this involved holding out a small portion of the training
dataset as the ensembling set  and forming predictions on this set with our best models after training on the rest of the
data  then we train a meta model using these individual predictions as the new input data  finally  we retrain the best
models on all the training data and form predictions on the test data  afterwards  we apply the trained meta model on
those predictions to form our final predictions on the test set  for our data  we trained a stacking model using ctree and
rf as sub models and linear regression as the meta model 

 

fi 

results

we performed    fold cross validation on our models  and submitted predictions for most of our models to the leaderboard 
below are the rmsle error values  discussed in the introduction  obtained for each model 
models
linear
glmnet
gbm
pcr
svr
rf
ctree
ensemble

   fold cv error
     
     
     
     
     
     
     
n a

leaderboard error
n a
     
     
n a
     
     
     
     

table       fold cross validation results and leaderboard performance using rmsle metric

 

discussion

below we list some of the observations and interpretations we made from the results 

   

performances of linear model and pcr

we expected the linear model to do relatively poorly  as it is an extremely inflexible model and tends to overfit the noise in
a dataset with so many observations  we also expected pca to not be particularly useful  and by extension  pcr  since
our dataset has few features to begin with  thus  the dimensionality reduction benefit of pca is lost for out data  while
we guessed they wouldnt do very well  we still found it useful to create these models to serve as a basis of comparison 
and to become more practiced with implementing regression models 

   

variable importance

we found that hour was by far the most important variable in our data  and contributed to the predictions significantly 
this is quite reasonable as certain hours  peak hours  will clearly have significantly more bike rentals than other hours  in
addition  the weather variables also had a small  but still positive  effect on our predictions  this indicates that weather
can indeed help predict demand for bikes 

   

tree based models

two of the three tree based models did very well  namely ctree and rf  our guess is that they were able to capture the
subtle non linear interaction effects between variables  since tree based models are equipped to do this 

   

cross validation vs leaderboard results

we observed that our cross validation results were generally lower than the leaderboard errors  therefore  we ended up
getting slightly worse results when submitting to the leaderboard than we were expecting  this can be attributed to the
fact that the training and test sets are a bit different  and the cross validation estimates of error can often be a bit biased 

   

regressing on registered and casual separately

since we are provided with the number of bike rentals that were made by registered and non registered users  these  
numbers add up to the total count   we also attempted to regress separately on registered and non registered users  and
add the result together  we expected that this would give us better results  since some of the features may influence
non registered and registered users differently  however  we ended up finding that simply regressing on total count had
better cross validation results  and performed better on the leaderboard   one explanation is that regressing on both
components separately introduces the chance for more noise and greater variance  thereby making the predictions worse 

 

fi 

conclusion

using different combinations of models and featurizations  we found that hour is by far the most predictive feature for our
problem  whereas weather variables play a much smaller  but still noticeable effect in contributing to accurate predictions 
in addition  decision tree models  in particular  ctree  were able to best capture the relationships within the data 
which led to the best performance on the leaderboard 

 
   

future work
using multiple featurized training sets

we narrowed down which of the    featurized training datasets to use by training all of them on a ctree model and using
cross validation to select the dataset with the lowest error  then we exclusively used this dataset to test all of our models 
however  the training set that achieved the lowest error with the ctree model may not be the optimal training set if we
were to train with another model  therefore  we can instead select a featurized dataset that does best for every different
model we use 

   

unsupervised methods

in our project  we mainly used supervised learning algorithms  however  unsupervised methods such as clustering can
often provide insight into some of the relationships in the data that can be otherwise missed  therefore  it could also be
worthwhile to perform some initial clustering techniques to identify some of the more meaningful relationships in the data 

   

time series analysis

the given training data only spans the first    days of each month  and the predictions are made for the remaining days
of the month  in our project  we used the entire training set to make our predictions  although a realistic model should
only be using data observed prior to or close to the time of the prediction  in order to usefully apply bikeshare prediction
in the real world  using a sort of time series analysis like this would be more useful for improved generalization 

references
    bill chappell  firm buys big bike share service  expansion and higher rates seen       
    jerome friedman  trevor hastie  and robert tibshirani  regularization paths for generalized linear models via coordinate descent  journal of statistical software                  
    brandon harris  a simple model for kaggle bike sharing       
    andy liaw and matthew wiener  classification and regression by randomforest  r news                  
    bjrn helge mevik  ron wehrens  and kristian hovde liland  pls  partial least squares and principal component
regression        r package version       
    david meyer  evgenia dimitriadou  kurt hornik  andreas weingessel  and friedrich leisch  e      misc functions
of the department of statistics  e       tu wien        r package version       
    kurt hornik torsten hothorn and achim zeileis  unbiased recursive partitioning  a conditional inference framework 
journal of computational and graphical statistics                     
    greg ridgeway with contributions from others  gbm  generalized boosted regression models        r package version
    
    david h  wolpert  stacked generalization  neural networks                 

 

fi