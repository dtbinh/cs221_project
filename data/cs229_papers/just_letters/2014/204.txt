vignette  reimagining the analog photo album
david eng  andrew lim  pavitra rengarajan

  abstract

principal components to consider  we let
x    x      x           x n    be the training set of face images 
where x i   rd  

although the smartphone has emerged as the most
convenient device on which to capture photos  it lacks the
tools to effectively view and organize these photos  given
the casual nature of smartphone photography  we propose a
system that can streamline and simplify the post capture
process  we propose vignette  a content management
system for smartphone photography that improves the
visual story by automating the organization of a user s
photo album  we hope to provide dynamic organization of
photo albums that supports user queries including requests
for images of a particular person or genre  the main task
we consider is clustering photos of a particular individual 

   compute the mean of x 
 

 
n

pn

i  

x i 

   compute the covariance matrix of x 
p
 i 
   x i    t
s   n  n
i    x
   solve for the eigenvalues  i  and eigenvectors v  i  of
x 
sv  i     i  v  i    i              n

  introduction
the basic structure of the system involves a pipeline that
first sorts a photo album into images those that contains
people and those do not  further processing is then carried
out on the photos of people to cluster the images into
sub albums with photos of a particular person  this would
allow the user to perform some basic queries over what was
a previously untagged set of photos 

   choose the eigenvectors that correspond to the k
largest eigenvalues 
   we project the test images into the pca subspace and
use the features in this reduced dimensional space to
train a multiclass svm 

    fisherfaces
for the purposes of comparison to pca using the eigenfaces
algorithm  we consider a second dimensionality reduction
technique based on linear discriminant analysis  lda   we
now describe the fisherface algorithm  let us assume that
our training set contains images of n different people  we
let x    x    x         xn    where xi is a set of images of
person i  we compute the total mean of all the images 
p
p
   pn    xi   n
i  
xxi x 

figure    photo organization pipeline

i  

we consider a pipeline that involves both unsupervised and
supervised learning  early on  the system has no notion of
any labels  thus  on the arrival of a new image  we perform
unsupervised clustering to add it to either an existing
cluster or a new cluster  at some point  however  there may
be a sufficient number of different clusters with high enough
density that we could use as labeled training data for a
supervised facial recognition algorithm 

we also compute a between class scatter matrix defined as 
p
t
sb   n
i    xi   i    i   
and a within class scatter matrix defined as 
p
p
t
sw   n
i  
xxi  x  i   x  i  
the fisherface algorithm then solves the following
optimization to compute a projection wopt that maximizes
the class separability 

  face detection

wopt   arg maxw

at the moment  we have focused more on the facial
recognition and clustering task  as our face detector  we use
a haar feature based cascade classifier trained on various
facial features including the position and shapes of eyes  the
nose  and facial outline 

 w t sb w  
 w t sw w  

   w  w     wk  

the xi s correspond to the generalized eigenvectors of sb
and sw that correspond to the k largest eigenvalues  we
note that there can be at most n    nonzero generalized
eigenvalues  thus  we have an upper bound on k of n    

  feature extraction

we note  however  that the within class scatter matrix sw
will always be singular  thus  we perform pca and
reformulate the optimization problem as 

    eigenfaces
we consider the eigenface algorithm  which performs a
principal component analysis  pca  on the training set of
face images to generate a set of basis vectors  given a pixel
grid with a face image  the eigenface algorithm models faces
as a composition of different eigenfaces  which we discuss in
detail below  we now describe the eigenface algorithm 
which is parametrized by k where k is the number of

wp ca   arg maxw  w t st w  
wf ld   arg maxw

t
 w t wp
ca sb wp ca w  
t
 w t wp
s wp ca w  
ca w

the transformation matrix w is given by 
w   wftld wptca
 

fi    gabor wavelets

several manually annotated or tagged photos 

to provide a computationally inexpensive means to extract
relevant features from our image  we applied various gabor
wavelets  a selective filter for both scale and orientation of
the face  since it convolves a gaussian kernel and sinusoid
fft  the filter is parameterized by the gaussian   sinusoid
phase   orientation w  and wavelength  
we took a variety of approaches to clustering these filtered
images  let us assume that our training set contains n
images of different people 

    k means clustering
      model selection with cv using aic
one metric we consider for determining the number of
clusters  used as a parameter  for k means clustering in the
set of images is a modified form of the akaike information
criterion  aic   we note that the reconstruction cost is a
monotonically decreasing function in k  which is minimized
when k   n  in other words  if we minimize reconstruction
cost  the optimal clustering will place each image in its own
cluster  which is clearly not desirable  using aic  however 
we can impose a penalty for each additional cluster to
penalize more complex models  cross validation using aic
optimizes 

   generate g gabor kernels by varying the values of
    w  and  
   for each image   to n  represent the image as a list of
g convolutions of each gabor kernel with the original
image  to reduce the feature space  we also attempted
to represent the image as a list of g means and
variances  based on least squared error for simplicity 

k   arg mink rc k    k
we note that a larger value of  will favor solutions with
fewer clusters  using the aic metric  we have that     m  
where m is the number of features used to represent an
image  for our application  however  we have found that
experimentally using       m yields a more appropriate
penalty term due to the larger feature space r      used to
represent the pixel grid of an image 

   during k means clustering  centroids take on the
dimensionality of the filtered images 

      model selection with tuned regularization
term
since the cost function incurred by k means monotonically
decreases with the number of clusters  we append the
following tuned regularization term which varies with the
number of clusters 
r k    t  k  f or  k       k k    
figure    gabor filters   feature extraction

to tune the parameters  for our regularization term  we
first selected     random samples of    images from our
dataset of images  therefore  the correct number of clusters
in each of these     examples ranged from   to     then  we
defined the following objective function to minimize by
stochastic gradient descent 
p
 
 
 
 
min m
i     arg mink  c k    r k    ki            

    neural networks
in addition to the more engineered feature extraction
techniques discussed  recent work has shown the validity of
applying the deep learning framework to vision tasks  we
now consider how the deep learning framework can be
applied to the face recognition problem in facebook s
deepface system  deepface feature extraction pipeline
consists of two phases  an alignment phase and a
representation phase  the alignment phase involves explicit
 d modeling of the face based on fiducial points in order to
warp an input facial image into a cropped  d frontal mode 
allowing deepface to learn from raw pixel rgb values  the
network architecture of deepface is nine layers deep and
involves more than     million parameters  the first three
layers of the neural network are used to extract low level
features such as edges and texture  the middle layers are
locally connected and apply various filters to different
regions based on local patterns  the final layers of the
neural network are fully connected and are able to capture
correlations between features in distant parts of the images 
the output of running an image through the neural network
is then used as the feature representation     

however  the presence of the argmin resulted in a
discontinuous function for which the gradient could not be
computed  therefore  we reformulated our objective
function to a continuous function minimized at the same  
p
 
 
 
 
min m
i      mink   c k  r k   c ki   r ki              
with this objective function  we applied stochastic gradient
descent on the set of examples to tune our parameters  
      unsupervised clustering with eigenfaces
as an unsupervised clustering approach  we consider
k means with eigenfaces  we first use the pca algorithm
known as eigenfaces  described in section      to extract
principal components from a set of examples images that are
independent of the actual images we wish to cluster  in our
application  we use      images from the labeled faces in
the wild face database to extract the eigenfaces that can be
considered as representative of the space of all possible
faces  we then project the face images that we wish to
cluster into the space specified by the extracted eigenfaces 

  unsupervised clustering
in order to provide the best user experience  we will begin
with unsupervised facial clustering techniques in order to
provide automatic photo organization without requiring
 

fisystem  has accurately clustered the previous stream of
images  we can use the cluster assignments as labels to
create a training set for supervised learning  we have
considered two canonical supervised face recognition
algorithms  namely eigenfaces and fisherfaces  for
eigenfaces  we use an svm with eigenface features  and for
fisherfaces  we extract fisherfaces features and run nearest
neighbors 

thus  each image is reduced to a feature vector of weights
representing the contribution of each eigenface to the
particular image  we can then run the k means algorithm
on the images using the reduced dimension feature vectors 

    lbp
we also considered an approach using the local binary
patterns histograms  lbph  algorithm  which extracts local
features of the image and is rooted in two dimensional
texture analysis 

  results

      model
we now describe the model of the lbph algorithm  the
algorithm functions by comparing each pixel with its
neighborhood  if the center pixel intensity is greater than or
equal to that of its neighbors  then denote this relationship
with a    otherwise  denote it with a    more formally  this
can be written as follows 
p   p
lbp  xc   yc     p
p     s ip  ic   

    model selection
we first begin by considering the efficacy of model selection
for k means clustering using aic 

where  xc   yc   is the central pixel with intensity ic   with in
being the intensity of the neighbor pixel  then  s would be
the sign function defined as follows 

 
if x   
s x   
 
otherwise

figure    k means cross validation cost with aic

the lbp image is divided into m local regions  in our
implementation  the lbp image is divided into  x  local
regions   and a histogram is extracted from each  the
spatially enhanced feature vector is obtained by
concatenating the local histograms 

we find that running cross validation with the modified cost
function based on aic generates representative models for
the number of clusters in the training image set  we run the
cross validation algorithm described in section       on two
training sets  the training sets are generated from randomly
sampling    percent of the at t and yale face datasets 
the at t dataset consists of    subjects and the yale
dataset consists of    subjects  model selection using the
modified cost function based on aic estimates    subjects
for the at t dataset and    subjects for the yale dataset 
we thus find that the aic provides a reasonable and simple
heuristic for initially tuning the unsupervised clustering of
the initial photo album 

      algorithm
we employ the following iterative algorithm 
   the first face image is used to initialize the first
cluster 
   we manually preset a threshold for a confidence value
at which a new cluster is created 
   subsequent images are then run through the face
recognizer  if the confidence value is greater than our
threshold  we instantiate a new cluster  otherwise we
update the existing clusters 

    unsupervised clustering
to gain a better understanding of the efficacy of the lbph
algorithm  we consider two primary metrics  homogeneity 
which describes the purity of a cluster  and completeness 
which describes the purity of a class  we first consider the
homogeneity and completeness scores when performing   
trials of entirely unsupervised learning  with a training set
of size    and testing on                   and     images
from the at t face dataset 

   the images within each cluster that obtained the
highest confidence are considered representative
samples for the clusters and are used to re initialize
the face recognizer model 
   the algorithm repeats steps     for a few iterations
until convergence 
since the lbp algorithm extracts local features  we note
that it is quite robust against monotonic gray scale
transforms and thus limits the effects of confounding factors
such as lighting 

  supervised recognition
we imagine that at some point  once the system has
clustered a fair number of face images  the previously
unsupervised task of facial clustering could be transitioned
into one of supervised facial recognition  assuming that the

figure    lbp evaluation with train size   on
at t face dataset
 

fik means clustering with eigenfaces  we see that the
homogeneity and completeness scores are slightly higher
with lbp for the at t and yale face datasets  likely due
to the algorithm s robustness against monotonic grayscale
transformations 

when performing entirely unsupervised clustering  we were
able to achieve a high homogeneity score of       and
completeness score of        we now consider the option in
which we have the user correctly tag a small subset of
photos  when performing    trials of lbp with a training
set of size    correctly tagged images and testing on        
          and     different images from the at t face
dataset  we obtain the homogeneity and completeness
scores pictured in the plot below 

    supervised clustering
we first evaluate the eigenfaces algorithm  from the at t
face database of     images containing    different
subjects  we uniformly sample     of the images to
construct our training data set and we test on the remaining
    of the images  preliminary results using a gaussian
kernel yield a precision of     and a recall of      we
perform a similar evaluation of fisherfaces as that
performed on eigenfaces  from the at t face database of
    images containing    different subjects  we uniformly
sample     of the images to construct our training data set
and we test on the remaining     of the images 
preliminary results yield a classification accuracy of     

figure    lbp evaluation with train size    on
at t face dataset
we see a general increase in lbp efficacy with a larger
dataset  after which the scores seem to plateau  as
expected  when correctly tagging    images  lbp performs
achieves higher homogeneity and completeness scores  we
were able to achieve a high homogeneity score of       and
completeness score of       
figure      eigenfaces     fisherfaces generated
from at t face database

as a means of unsupervised learning  we consider how the
k means algorithm performs on the yale face dataset using
different features 

for the supervised task of face recognition  we considered
eigenfaces and fisherfaces  the experimental setup
considered the at t face dataset and compared the
eigenface and fisherface features on a hold out set that
comprised a random sampling of    percent of the dataset 

figure    k means baseline vs  eigenface features
we assume that during the model selection phase that we
are able to determine the correct number of subjects in the
dataset  the results from the cross validation experiment
with aic show that this assumption is not unreasonable 
we then consider using k means with eigenface features 
using eigenfaces  we are able to improve the clustering to a
maximum homogeneity of       and completeness of    the
    eigenface features selected are representative of the
lfw dataset and are assumed to generalize to the facial
images that comprise the yale dataset 
when we compare the lbp algorithm with unsupervised

figure    eigenfaces vs  fisherfaces comparison
we note that the fisherface accuracy plateaus after   
features  this results from the fact that the at t dataset
contains images of only    unique subjects and fisherfaces
uses a number of features that is at most the number of
distinct labels  we decided to consider the eigenface svm
for our supervised experiments since its high mark accuracy
 

fiof confidence when evaluating whether a new photo belongs
to an existing cluster  in our svm  we note that the penalty
parameter term c is weighted such that the penalty term is
inversely proportional to class frequencies 

of         is higher than that of fisherface  which is
          to explore whether it would be possible to
transition to supervised learning with inaccurate clusters 
we randomly mislabel    percent of the dataset 

  literature
to date  facebook s deepface algorithm  as described in
section      is one of the most accurate face recognition
algorithms  achieving        accuracy on the labeled faces
in the wild  lfw  dataset      prior to facebook s
deepface algorithm  the most successful system using a
large labeled face dataset adapted a joint generative
bayesian model learned on a dataset containing       
images from       different subjects to the lfw image
domain      another approach involves the use of a
multi task deep convolutional neural network which
simultaneously learns the face nonface decision  the face
pose estimation problem  and the facial landmark
localization problem  locating major features or landmarks
of a face       multi task learning was applied to the neural
network using a shared representation for the different
problems by learning multiple targets and making them
share the common lower layers  on the unsupervised front 
a state of the art algorithm that has been used for facial
clustering is over complete local binary patterns
 oclbp   a multi scale modified version of the lbp
algorithm      while lbp capitalizes on the locality of its
feature extraction  oclbp is computed with overlapping
blocks and improves the robustness of classification systems
by using richer descriptors 

figure    svm with eigenface features on noisy
dataset
we note that    percent noise is less than what would be
generated by the unsupervised clustering algorithms we
considered  thus  it offers a reasonable baseline to consider
whether supervised recognition on noisy clusters is feasible 
the result of training on a randomly sampled set of   
percent of the training data set and testing on the
remaining    percent peaks at about an f  score of   
percent  the f  score is the harmonic mean of precision
and recall and we use it as a measure of a test s accuracy 
from this result  we conclude that with the existing
techniques considered  we cannot perform supervised
recognition on noisy data  alternatively  the user could
provide the necessary feedback to correct the clusters 

   future work
for the purposes of this project  we have focused primarily
on the task of clustering photos that contain people  in the
future  we would love to expand on this work by supporting
user queries over non people photos as well and clustering
on criteria such as genre  we are also interested in
investigating the tradeoffs between k means clustering and
lbp clustering for online unsupervised learning  using the
svm as an additional measure of confidence  furthermore 
we would like to attempt to extract other features including
edges or corners  lastly  we would like to experiment with
local pca and local ica as well 

to measure the performance of the svm trained on
eigenface features  we trained on a randomly sampled set of
   percent of the yale data set and tested on the remaining
   percent  we varied the number of eigenface features
extracted and experimented with both a linear kernel and a
gaussian kernel 

   references
   c  zhang  z  zhang  improving multiview face detection with
multi task deep convolutional neural networks  in applications of
computer vision  wacv        
   h  akaike  information theory and an extension of the maximum

figure     svm with eigenface features on pure
dataset

likelihood principle  selected papers of hirotugu akaike  springer
new york                
   o  barkan  j  weill  l  wolf  and h  aronowitz  fast high

experimentally  we find that the gaussian kernel
outperforms the linear kernel  we note that the high mark
f  score for the svm using a gaussian kernel incorporated
   eigenface features and achieved an f  score of       
the high mark for the linear kernel was       using   
features as well  these results confirm the potential for
transitioning to supervised recognition if the likelihood of
adding a photo of an unseen person is low  if the user 
however  is likely to add photos of new people  the
supervised recognition could be used as an additional metric

dimensional vector multiplication face recognition  in iccv       
   p  belhumeur  j  hespanha  d  kriegman  eigenfaces vs 
fisherfaces  recognition using class specific linear projection  pattern
analysis and machine intelligence  ieee transactions on             
        
   x  cao  d  wipf  f  wen  g  duan  and j  sun  a practical
transfer learning algorithm for face verification  in iccv       
   y  taigman  m  yang  m  ranzato  l  wolf  deepface  closing the
gap to human level performance in face verification  in conference
on computer vision and pattern recognition  cvpr        

 

fi