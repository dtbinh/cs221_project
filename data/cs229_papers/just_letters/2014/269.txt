detecting ads in a machine learning approach

dizhang zhangdi stanford edu 


   background
therearelotsofadvertisementsovertheinternet whohavebecomeoneofthemajor
approachesforcompaniestoadvocatetheirproductsandforwebmasterstomakemoneyby
postingtheseads somebigplayersinthismarketaregoogleandfacebook withalotof
othercompanies 

theseadscansometimesbeuseful whilecanalsobeveryannoyingatsomeother
occasions oneofthepurposesforthisprojectistoanalyzingthedistributionsofads
providedbydifferentsources sowecouldhavearoughideaabouttheenvironmentof
internet 


   model selection
onlineadsareusuallyintheformofjavascript whichdynamicallyloadsadvertisement
contentsfromserveratthetimeapageisrendered thesecodeareoftencopiedfromthe
provider orrequestssamefilesfromprovider whichmeanstheymayhaveawelldiscernable
patterninthehtmlfile therefore theinputsareabunchofstatichtmlfiles whilethe
outputiswhetherafileisconsideredascontainingornotcontainingads thisledmetothink
abouttheclassicalgorithmsoftextclassification morespecifically naivebayesandsvm 


   first analysis
   dataset
irandomlygot    webpagesforbothpositiveandnegative  apageispositivemeansit
containsads whilenegativemeansitcontainsnoads  amongthesepages iused    
positivepagesand    negativepagesasmytrainingset andtheother    positive
pagesand    negativepagesasmytestset 

   preprocessing
advertisementsonwebpagesaretypicallypresentintheformofexternaljavascript soionly
consideredthehttplinksinthepage andignoredeverythingelse foreachlinkinapage itis
tokenizedintomultiplewords withallnonalphanumericalcharactersbeingdropped for
example http   www amazon com willbetokenizedinto http www amazon com  
andalltokensbeingparsedoutfromapagemakesantraining testingexamplefedintothe
learningalgorithm 


fi   learningalgorithms
atthispoint theproblemisprettymuchsimplifiedtoastandardtextclassificationproblem so
naivebayesmightbetherightthingtodoasastartingpoint withoutmuchsurprise igotthe
followingtrainingandvalidationaccuracy 



trainingaccuracy

testingaccuracy

naivebayes

      

      

svm

       

      

figure  trainingandtestingaccuracyfornaivebayesandsvm

onestepfurther ifwethinkalittledeeperaboutthenatureofadvertisementlinks they
usuallyhaveaprettystablepattern orevenexactlysameurl therefore insteadofusingthe
unigramtokens itmightmakesensetousengramtokens thisindeedhelpedthe
performance andigottheresultoffigure byvaryingthetokensize i e howmanywords
makesatoken 

wecanseethatbothnaivebayesandsvmgetagainwhenwehavemultiplewordsina
token duetothedifferenceintheirnatures thesetwoalgorithmsreachpeakatdifferent
sizesoftokens naivebayespeakedat  whilesvmat  


figure  accuracyagainstngramterms

fi   discussions
   motivation
figure showedthatsvmalgorithmcanmakeapredictionwithalittlelessthan   
accuracywheniusedtrigramasinput itwouldbeinterestingtostudymoreaboutthe
propertiesaboutsvmalgorithm 

   kernel
kernelisprobablythemostimportantpartofthesvmalgorithm andfigure showssome
resultforpolynomialandgaussiankernel however tomysurprise theperformance
degradesveryfastwhenthedegreeofpolynomialkernelincreases anditbasicallybecomes
randomguesswhenthedegreegoestoinfinity gaussiankernel  

kernel

linear

 ndorder

 rdorder

 thorder

gaussian

testing
accuracy

        

        

        

        

        

figure  testingaccuracyforkernelsindifferentorder

   rational
   wouldbeinspiringonexplainingwhygaussiankernelisnotgoodattextclassification
problems ifwetakethefouriertransformationofthegaussianfunction weget
x 

f  e      



x 
  

 e ejxdx    e



  
 



wheretheresultisessentiallyalowpasssignalfilter i e thefunctionvaluedecreasesas
frequencyincrease however whenweworkontextclassificationproblems the
appearanceofmostfeaturesareprettysparse whichmeanseachappearanceislikeadirac
function asweknow diracfunctionhasabundanthighfrequencyinformation whichwould
befilteredoutbythegaussiankernel andthustheperformancedegradesbadly 

   stopwords
onewidelyappliedtechniqueintextclassificationisstopwordelimination thesewordsare
frequentlyappearedanddonthavemuchrealmeaning inourcase theyarehttp www
andcom however tooursurprise theperformancedegradesalittlebitwhenthese
stopwordsareremoved naivebayesgives      testingaccuracy whilesvm       
whicharebothalittlebitlowerthantheoriginalresult 


   distribution analysis
intheprevioussections eachwebpageisclassifiedbywhetherithasanadvertisementonit 
regardlessofwhatkindofaditis therefore ithasbeenaclassictextclassificationproblem 
theproblembecomesamultilabelonewhenwewanttodetectwhatkindofadvertisements
arepresentoneachindividualwebpage 

fi
onestraightforwardextensionfromwhatihavealreadydonewouldberunningtheprevious
algorithmforeachindividualadvertisement thiscanbetimeconsuming butisstilldoable
givenionlyhaveafewdozensofdifferentadsintotal 

here iusedhomepagesoftop      sitesgivenbyalexa    

rank

name

count

 

googleanalytics

    

 

facebookconnect

    

 

google  

    

 

facebooksocialplugins

    

 

googleadsense

    

 

omniture

   

 

twitterbutton

   

 

quantcast

   

 

scorecardresearchbeacon

   

  

doubleclick

   

figure  mostwidelydistributedadvertisements

fromfigure wecouldseethatgoogleandfacebookareoccupyingalargeportionofthe
market infact peoplearemorecarefulwhendecidingwhethertoanadonhomepage users
areeasilyirritatedwhentheyseetoomanyadsonapage sofeweradswouldappearon
homepagesthanotherpagestobettercaptureusers thatbeingsaid ourinternetmaybe
muchmoreoverloadedbyadswhatweseehere 


   conclusion and future work
aswehaveseeninthiswork advertisementdetectioncanbeconsideredastext
classificationproblemwithreasonableamountofdataandaccuracy andngramtokenization
couldhelpoverallperformancewhilehigherorderpolynomialkernelhurts also wecould
havearoughideaabouthowoverloadedbyadstheinternetis 

forthefuture itwouldbenicetotrainregularexpressions   usinginputwebpagesforeach
advertisement also morewebpagesareneededtomakethedistributionanalysismore
thoroughandaccurate 

fireferences
   https   charlesmartin   wordpress com         
   http   www alexa com 
   lietal  regularexpressionlearningforinformationextraction proceedingsofthe    
conferenceonempiricalmethodsinnaturallanguageprocessing pages     honolulu 
october     

fi