 ml  nlp  autonomous tagging of stack overflow questions
mihail eric  ana klimovic  victor zhong
 meric  anakli  vzhong  stanford edu
december        

a post is a burden for users which degrades the overall user experience  we envision a platform that can
infer the tags of posts automatically  to this end  we
propose a multi label classification system that automatically assigns tags for questions posted on a forum 
we implement and test our classifier on a dataset of
stack overflow questions 
the remainder of this paper is organized as follows 
section   outlines previous work on text classification 
section   describes our methodology and provides system architecture details  including feature extraction
and classifier tuning  we present results in section  
and discuss key insights in section    concluding in section   with opportunities for future work 

abstract
online question and answer forums such as
stack exchange and quora are becoming an increasingly popular resource for education  central to the functionality of many of these forums
is the notion of tagging  whereby a user labels
his her post with an appropriate set of topics that describe the post  such that it is more
easily retrieved and organized  we propose a
multi label classification system that automatically tags users questions to enhance user experience  we implement a one vs rest classifier for a stack overflow dataset  using a linear svm and a carefully chosen subset of the
entire feature set explored  our classification
system achieves an optimal f  score of       
on a subsampled portion of the original data
restricted to     tags and a minimum of    
instances of each tag across the data 

 

 

background

text classification  the process of classifying text documents into classes based on their topic  is a common
application of natural language processing and machine
learning  in general  text classification is both a multiclass and multi label classification problem  meaning
there are multiple classes to choose from when labelling
an input and each input might correspond to more than
one class 
there are two common approaches for tackling
multi label classification       one common approach 
called one vs rest  decomposes the classification problem into k independent binary classification problems 
training a separate classifier for each of the k possible output labels          an alternative approach for
multi label classification  collectively known as the set
of adaptive algorithms  tries to predict all labels at once
along with a confidence ranking associated with each
label          examples of adaptive algorithms include
boosting and random forests         
in our classification system  we take the one vs rest
approach using support vector machines with a linear
kernel  we also investigate lexical and syntactic features extracted from the data to enhance our model 

introduction

with the advent of online education  question and answer forums are becoming an increasingly popular resource for information  examples include stack exchange  quora  and forums for massive open online
courses  moocs  like coursera and openedx  while
the quantity of information available on these forums
is steadily increasing  there is currently no efficient and
automatic way of grouping and classifying the information so that it can be displayed to users in an intuitive
way  it would be useful to automatically infer and tag
the topic of a question posted on a forum  a system
that automatically infers the topic of a question can improve user experience on online forums by    grouping
questions about common topics together for users to
browse and    showing users posts related to a question they are inputting  since their question may already have been answered on the forum  in order to
allow the grouping of common posts  some forums such
as quora require users to manually enter tags associated with their questions  however  manually tagging
 

fi 
   

methodology

   

feature extraction

the majority of our feature set corresponds to ngram
features and label counts  figure   depicts our complete feature extraction pipeline  in this section  we
describe our process for selecting and tuning feature
extractors and classifiers in the pipeline 
we find that starting with a feature set corresponding to the number of occurrences of a label in the title
and body of the question  we refer to this as label
counts   yields the highest precision of all features we
tried stand alone  thus  to construct our complete feature set  we start with label counts  then introduce and
greedily tune feature extractors  through   fold cross
validation  one at a time 
we add body and title ngrams to capture terms
that co occur with certain tags  hyperparameter tuning for ngrams and label counts consists of choosing binarization settings  bernoulli vs  multinomial counts  
and idf and norm settings for the proceeding tfidf
transformer  we use tfidf      or term frequency
inverse document frequency  to reweight the count of
each term in accordance with how relevant it is to each
label  unigram tuning additionally entails choosing binarization and cut off settings for the counter 
we find that bigram features do not significantly
improve performance and only hinder our ability to use
a larger dataset  we also find that terms in the title
are more indicative of labels because a user typically attempts to summarize and categorize the question in the
title  empirically  we discover that extracting ngrams
for the body and the title separately to allow for independent weightings of terms improves performance 
extracting raw ngrams for the code portion of the questions  if such sections exist  decreases performance due
to large variations in the code content  thus  we separate the text and code portions for each question and
only extract ngrams for the text portions 

experimental setup

to conduct our experiments  we use the scikit learn
machine learning suite     and the natural language
processing toolkit      all source code from the project
can be found at the following github repository 
https   github com vzhong        n project
the dataset we use to develop our classifier is from
a past kaggle competition      the dataset consists
of approximately           user questions spanning
roughly        unique tags from the stack overflow
site  each post from the data contains a unique identifier  the title of the question  the body of the question 
and the associated tags  the large quantity of data in
our dataset caused memory to become a bottleneck for
computing  developing models for the full dataset was
computationally intractable  hence before testing any
model or set of features  we subsampled the data  typically restricting it to only those posts with one of the
   or     most common tags seen in the entire data 
we also ensured that our subsampled dataset contains
at least     training examples for each label  this ensured that we have sufficiently diverse training data so
that we can learn statistics for the relevant tags 
we chose f  score as the metric for evaluating
our multi label classification systems performance  f 
score is the harmonic mean of precision  the fraction of
returned results that are correct  and recall  the fraction of correct results that are returned   f  score is
a common metric for multi label classification and was
also the chosen metric for the kaggle competition from
which our dataset originates 

figure    feature extraction pipeline

 

finext  we hand engineer features to make use of code
portions of questions and improve performance on tags
our classifier found most difficult to predict  we aim
to enhance the performance on the    most common
tags  as most examples have one of these tags  over
  million of the questions had at least one of the top
   tags   after tuning our system for the top    tags 
we examined the worst performing tags and manually
created simple string matches for commonly occurring
syntax related to these tags and the various programming languages frequently occurring in the questions
 e g   property   include  
we also explored collecting unigrams over only
noun terms  after pos tagging the question body  and
over only named entities  after pos tagging and ner  
the noun features were introduced to capture the intuition that the set of nouns in a question are a less noisy
means of identifying the main entities in a question 
which should be good indicators of the central topics
of the question and thereby the associated tags  ner
was considered because often a set of organizations such
as microsoft or google may be indicative of certain
tags like windows  windows    or chrome  the system
with ner unigram counts achieved marginally better
f  scores  and the system with pos unigram counts
achieved our absolutely highest f  score  collectively
our best performing system was trained on a training
set with         questions consisting of         features and tested on a data set of        questions with
the same number of features 
finally we explored using lexer guesses from the
pygment python package over the code portions  the
lexer features were an attempt at capturing the abundance of information contained in the code portions of
a question  i e  the occurrence of certain programming
syntax such as def or init may be strong indicators
of certain tags such as python 

   

rameter c and the loss function used  l  or l     for
every different subsampled dataset and feature set we
considered while developing our classification system 
we tuned the classifier hyperparameters through   fold
cross validation with f  score as the performance metric  in all cases  l  loss provided better results  with
the c value varying in accordance with the number of
training examples  as we increase the number of training examples  variance decreases and thus less regularization is required 
the objective function we use for our svm linear
classifier is as follows  where w  b    respectively denote the weight  bias  and soft margin variables  x i 
denotes the feature values  eg  unigram counts and
string matches  for a given example and y i denotes the
classification output  whether a given label is assigned
to a question  
m

min w b

x
 
  w      c
i
 
i  

 i 

t  i 

s t  y  w x

  b      i   i           m

i     i           m
we also experimented with alternative classifiers 
within the one vs rest classification paradigm  we tried
training the individual binary classifiers for each label with logistic regression  multinomial naive bayes
and bernoulli naive bayes models  however  the linear svm performance was superior  we chose to use a
support vector machine for our system because we intended to make use of the models ability to learn complex separating boundaries and its well known robustness in learning regularities across diverse data sets 
using a gaussian kernel for the svm was computationally intractable for our large dataset  we also considered random forests as an alternative to the one vsrest family of classifiers  however  since random forests
classifiers randomly sample examples from the dataset
to construct each decision tree and require each trees
sampled dataset to contain positive examples for each
tag  the number of examples the classifier required was
intractable for our computing resources 

classifiers

we use a one vs rest paradigm for multi label classification  for a collection of labels  a    a      ak    a onevs rest classifier is as a collection of k binary classifications  where for every label ai   we treat a training
example that has been labelled with ai as a positive example and a training example that is not labelled with
ai as a negative example  hence the output for a given
example can be viewed as a binary vector of length k 
 c    c         ck    where cj     if label j has been chosen
for the example and   otherwise 
we use a discriminative support vector machine
with a linear kernel  for which we tune the loss pa 

 

results

we evaluate our multi label classification system using
the f  score metric and report results for predictions of
the     most common tags  trained on a dataset with a
minimum of     questions for each label  we construct
our test set by randomly sampling the original dataset
 

fiwhile ensuring a minimum of    questions for each label  our multi label classification system achieves an
optimal f  score of        on the test set 
the contribution of each type of extracted feature
is summarized in table   which presents the f  scores
for our classifier  starting with label counts features
and gradually introducing and tuning additional feature sets discussed in section      label counts allowed
us to achieve a        f  score  adding ngrams from
the title and body of the question further improved performance and our hand engineered features provided a
small additional improvement  adding ner ngrams
also achieve marginal improvements  though not as
large as we would hope  we found the implementation
of the nltk ner system to be unreliable  as the regularities it required  eg  proper capitalization  spelling 
were often not met by the stackoverflow questions 
adding noun ngrams also produced small improvements and allowed us to achieve our best performing
system with the associated f  in bold below  due to
time constraints of hyperparameter tuning and feature
extraction  we were not able to attempt testing a system with both ner and noun ngrams 

   as expected  the addition of more examples causes
training f  score to decrease while cross validation f 
score increases  the relationship between the training and cross validation learning curves suggests that
our classification system has high variance  specifically 
cross validation f  score approaches     while training asymptotically approaches the significantly higher
f  score of     
finally  in table    we report the precision  recall
and f  score of our system on the   most common tags 

 
 
 
 
 

label
c 
php
java
javascript
android

precision
     
     
     
     
     

recall
     
     
     
     
     

f 
     
    
     
     
     

table    performance on most common labels

   

learning curves  linear svm top   min    

   

precision
     
     
     
     
     
     

recall
     
     
     
     
     
     

f 
     
     
     
     
     
     

f  score

  
  
  
  
  
  

features
label counts
    title ngrams
     body ngrams
     hand engineered
     ner ngrams
     noun ngrams

   
 

table   shows the systems f  scores when adding
additional features  we report the scores associated
with these features in a separate table since none of
these feature extraction techniques resulted in significant performance improvements  the pygment lexer
package relied heavily on rules such as looking for
the standard unix header    usr bin env python
and file extensions to distinguish between languages 
neither of which is common in short stack overflow
postings 

  

precision
     

recall
     

   
   

table    feature tuning

features
     lexer guess

   

training score
cross validation score
     

     

     
     
training examples

      

      

figure    learning curve

 

discussion

memory constraints were a major challenge we continued to encounter while developing our multi label
classification system  our dataset was too large to fit
in ram so we were forced to subsample the dataset
and deal with sparse matrices in our pipeline  as a
result  we were not able to benefit from the use of certain machine learning libraries in sklearn such as pca 
z normalization  and gaussian kernel svms which required dense matrices 
we found that extracting relevant and useful natural language features was quite difficult given the nature of stack overflow questions  which tend to vary
greatly both in length and in content  moreover  the

f 
     

table    additional features
using the final feature set in table    we show the
training and cross validation learning curves in figure
 

fiuniqueness of source code makes it challenging to construct features more complex than string matching of
common syntax  while techniques such as parsing and
named entity resolution improved performance  they
did not provide significant gains due to the noisy nature of the data  relevant tags are often very domainspecific and will  more often not  be directly mentioned
by name in a question  hence  it is often quite effective
to just do very precise keyword matching 
to debug our multi label classification system  we
examined which of the    most common tags had the
worst performing classifiers  lowest f  scores   we
identified html  windows and  net as problematic tags
for prediction  hand engineering features specifically
associated with these tags  such as counting the number of occurrences of  lt   gt and other html syntax to improve prediction of the html tag  marginally
helped overall performance  we hypothesize that tags
such as windows and  net are difficult to predict since
they are closely related to other tags such as asp net
and windows    respectively  in fact  the tags exhibit a
hierarchical relationship  meaning a question tagged as
windows   is also windows  a fundamental limitation
of our one vs rest classification system is the assumption that all tags are independent 

the hierarchical nature of the tags by modeling tag correlation could benefit performance  we can also explore alternative  non linear classifiers such as gaussian
kernel svms and neural networks  since non linearity
might allow for a better separation of the data 

 

    mccallum  a  k          multi label text classification with
a mixture model trained by em  in aaai    workshop on
text learning 

references
    joachims  t          text categorization with support vector
machines  learning with many relevant features 
    kaggle        
facebook recruiting iii   keyword
extraction 
https   www kaggle com c 
facebook recruiting iii keyword extraction 
    klassen  m  and paturi  n          web document classification by keywords using random forests  in networked digital
technologies  volume    of communications in computer and
information science  pages         springer berlin heidelberg 
    loper  e  and bird  s          nltk  the natural language
toolkit  in proceedings of the acl    workshop on effective
tools and methodologies for teaching natural language processing and computational linguistics  etmtnlp     pages
      stroudsburg  pa  usa  association for computational
linguistics 
    manning  c  d   raghavan  p   and schutze  h          introduction to information retrieval  cambridge university press 
new york  ny  usa 

conclusion and future work

we implement a one vs rest classification system to
automatically tag online forum question topics  our
classification system  implemented using a linear svm
model and carefully selected features  achieves an optimal f  score of        for a sampled portion of the
dataset with     of the most popular tags and a training set consisting of at least     examples of each tag 
as future work  we plan to address the high
variance our classifier exhibits through feature selection techniques such as principal component analysis
 pca   we also plan on exploring additional features
through the use of distributed representations of words 
for example  we can train a neural language model over
a corpus and consider as the ngrams vocabulary the
set of labels and the set of k words that are most semantically similar to each label  we began exploring
this approach using word vec     on the stackoverflow
dataset itself  but could not produce word vectors that
yielded meaningful nearest neighbors  this approach
can probably be improved with further tuning and the
use of pre trained vectors        
considering the difficulty in classifying general tags
such as windows  we believe that taking into account

    mikolov  t   chen  k   corrado  g   and dean  j         
efficient estimation of word representations in vector space 
corr  abs           
    pedregosa  f   varoquaux  g   gramfort  a   michel  v  
thirion  b   grisel  o   blondel  m   prettenhofer  p   weiss 
r   dubourg  v   vanderplas  j   passos  a   cournapeau  d  
brucher  m   perrot  m   and duchesnay  e          scikitlearn  machine learning in python  journal of machine learning research              
    pennington  j   socher  r   and manning  c  d           
glove  global vectors for word representation  conference on
empirical methods in natural language processing 
     schapire  r  e  and singer  y          boostexter  a
boosting based system for text categorization 
     tsoumakas  g  and katakis  i          multi label classification  an overview  int j data warehousing and mining 
         
     ueda  n  and saito  k          parametric mixture models
for multi labeled text  in in advances in neural information
processing systems     pages         mit press 
     zhang  m  and zhou  z          ml knn  a lazy learning approach to multi label learning  pattern recognition          

 

fi