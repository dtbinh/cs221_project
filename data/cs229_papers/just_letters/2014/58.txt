cs   

 

from classical to hip hop  can machines learn
genres 
aaron kravitz  eliza lupone  ryan diaz

abstractthe ability to classify the genre of a song is an
easy task for the human ear  after listening to a song for just
several seconds  it is often not difficult to take note of that songs
characteristics and subsequently identify this genre  however 
this task is one that computers have historically not been able
to solve well  at least not until the advent of more sophisticated
machine learning techniques  our team explored several of these
techniques over the course of this project and successfully built
a system that achieves         accuracy in classifying music
genres  this paper discusses the methods we used for exploratory
data analysis  feature selection  hyperparameter optimization 
and eventual implementation of several algorithms for classification 

i  i ntroduction

h

istorically  attempts made by others to build music
genre classification systems have yielded fine but not
extraordinary results  some who used the same dataset that
we used for our project  which comprises one million songs
each belonging to one of ten different genres  often chose to
reduce the number of genres they attempted to identify  while
those who decided to work with all ten genres only achieved
accuracy of         
the hardest part of music classification is working with time
series data  the cutting edge of machine learning research is
looking into more effective ways of extracting features from
time series data  but is still a long way off  the most promising
attempt is done by goroshin et  al in their paper unsupervised
feature learning from temporal data     
the problem with temporal data is that the number of
features varies per each training example  this makes learning
hard  and in particular makes it hard to extract information on
exactly what the algorithm is using to learn  algorithms
that extract temporal features can be thought of as extracting
a more reasonably sized set of features that can be learned
from  to address the difficulties of working with temporal
data  we used the idea of an acoustic fingerprint     to extract a
constant sized number of features from each song  improving
our accuracy on the testing set substantially 
we also used bayesian optimization  a relatively modern
technique  to optimize the hyperparameters of our classification algorithms  this increased our accuracy by a few
percentage points  and is substantially faster than grid search
and leads to better results than random guessing 
in short  the task of developing a music genre classification
algorithm is not a trivial one  and often requires substantial
tuning  the best models we discuss in this paper achieve an
accuracy of       

ii  t he dataset and f eatures
for this project we used the million song genre dataset 
made available by labrosa at columbia university     
this dataset consists of one million popular songs and
related metadata and audio analysis features such as song
duration  tempo  time signature  timbre for each segment 
and key  in this dataset  each training example is a track
corresponding one song  one release  and one artist  among
the many features that this dataset contains for each track is
genre  which was of obvious importance to our project as it is
the ground truth which we aimed to predict with our models 
in particular  there are    genre lables  distributed according to
table i  this dataset is clearly imbalanced  making the ability
to accurately classify genres other than classic pop and rock 
which makes up about     of the dataset  a challenge 
we changed the original dataset so as to not increase the
size of the features to over      while adding to the ability
to differentiate between genres  the original million song
dataset contains timbre vectors for each segment of each song 
where a segment is defined as a small section of the song 
usually denoting when a new note comes in  the creators of
the dataset performed mfcc on the data  which is explained in
greater detail in sahidullah and saha      and then performed
pca on the results of mfcc to separate the timbre of each
segment into    principle components  the genre dataset only
includes the average and variance of each of these segments 
which we felt did not contain enough information to describe
the data  to remedy this issue  the solution we came up with
was to take the most meaningful segment of the song  using
a variation on the idea of an acoustic fingerprint     
to achieve this  we used a variation on the idea of an
acoustic fingerprint      research shows that when a person is
listening to a piece of music  the brains attention is heightened
during transitions  which frequently coincide with the loudest
parts of the music  as such  we decided determine the loudest
point of each song in our dataset and use the corresponding
timbre feature vector for that segment  an idea that is based
upon work done by vinod menon at the stanford school of
medicine      the use of this feature improved our model
accuracy to approximately     from around     originally 
for further improvements  we multiplied the loudness of that
particular segment and the individual timbres of that segment 
which boosted accuracy to     
to get a better understanding of the dataset  we first normalized and scaled the dataset  and then plotted the data using
pca in fig     we then plotted the data with the new added
features  which does seem to have slightly better clustering of

fics   

 

classes in fig    
iii  m ethods

fig     random forest learning curve

improvement upon simple bootstrap aggregation of trees as it
decorrelates the trees      for the purposes of our project  we
used pythons sklearn package to construct a random forest on
our test data set  we first used bayesian optimization  which
is explained in greater detail in section    to tune several
hyperparameters  the results of this optimization indicated that
the optimal minimum number of samples required to split an
internal node in a tree is    the optimal minimum number of
samples that must be in a newly created leaf is    and the
optimal number of trees in the forest is      having tuned
these parameters  we built a random forest classifier using our
training set  which we then used to make genre predictions
for

our test set  for each split we considered p   n features 
the random forest achieved accuracy of       and an f 
score of        the learning curve for this method is shown
in fig     and while our results seem to be an improvement
upon those of previous years  the random forest suffers from
high variance  that is to say  the model captures too much of
the variance and noise in the training set  and as a result the
generalization error suffers 
table i  msd genre dataset statstics

a  random forest
after completing preliminary exploratory data analysis  we
shifted our focus to various supervised learning methods 
turning first to tree based methods  which segment the feature
space of a data set into distinct  non overlapping regions
using a greedy approach known as recursive binary splitting 
prediction of a test example using a classification tree is
performed by determining the region to which that example
belongs  and then taking the mode of the training observations
in that region  a classification tree is grown by successively
splitting the predictor space at a single cutpoint which leads
to the greatest possible reduction in some chosen measure 
for our project  we chose as our measure the gini index  g  
which is often thought of as a measure of region purity 
g 

k
x

genre
classic pop and rock
classical
dance and electronica
folk
hip hop
jazz and blues
pop
metal
punk
soul and reggae
total 

counts
       
      
      
       
   
      
      
      
      
      
       

percent
      
     
     
      
     
     
     
     
     
     
    

pmk     pmk  

k  

where k is the number of classes and pmk is the proportion
of training observations belonging to the kth class in the mth
region  thus  for every iteration of recursive binary splitting 
the splitpoint s is chosen so as to minimize the gini index and
thus maximize the purity of each of the regions  this splitting
of the feature space continues until a stopping criterion is
reached  for example  if each region in the feature space
contains fewer than a certain number of training observations  
while one single classification tree might not have extraordinary predictive accuracy in comparison to other machine
learning methods  aggregation of decision trees can substantially improve performance  for our project  we chose to use
a random forest of classification trees as one of our prediction
methods  random forests are constructed by building a number
of decision trees on bootstrapped observations  where each
split in each tree is decided by examining a random sample of
p out of n features  in this way the random forest method is an

fig     pca with original features

b  gaussian discriminant analysis
in addition to tree based methods  we also explored two
different types of gaussian discriminant analysis  first  we
performed linear discriminant analysis on our training set
using interactive polynomial features of degree    before
running the analysis  we created the interactive features by
computing the  element wise  product of every pair of distinct

fics   

 

fig     pca with added features
fig     linear discriminant analysis learning curve
features  that is to say  for every pair of features n    n 
where n     n    we added n   n  to our feature space 
after completing this pre processing  we used pythons sklearn
package to perform linear discriminant analysis  this method
assumes that our observations x    x          xn are drawn from
a multivariate gaussian distribution with class specific mean
vectors and a common covariance matrix  thus  the classifier
assumes that an observation from the jth class  for example 
is drawn from a distribution n  j      the assumption that
each class has the same covariance matrix  forces the
decision boundaries in the feature space generated by linear
discriminant analysis to be linear  the diagnostic results of
this analysis are summarized in table ii 

   gaussian processes  as the prior to our bayesian optimization problem  we used a gaussian process  gp   gaussian
processes are defined by a multivariate gaussian distribution
over a finite set of points      as more points are observed 
the prior is updated  as in    what makes gaussian processes
useful for bayesian optimization is that we can compute the
marginal and conditional distributions in closed form  for
more information on gaussian processes  consult rasmussen
and williams      

table ii  lda diagnostics
genre
classic pop and rock
punk
folk
pop
dance and electronica
metal
jazz and blues
classical
hip hop
soul and reggae
average   total

precision
    
    
    
    
    
    
    
    
    
    
    

recall
    
    
    
    
    
    
    
    
    
    
    

f  score
    
    
    
    
    
    
    
    
    
    
    

support
    
   
    
   
    
   
   
   
  
   
     

fig     gaussian process prior
c  bayesian optimization
bayesian optimization tries to address the global optimization problem
x   arg max f  x 
xx

where f x  is a black box function  meaning that we have
knowledge of the input and output of the function  but have
no idea how the function works  bayesian optimization is a
way of solving this optimization problem effectively 
to use bayesian optimization  we first decide on a prior
distribution for the unknown functions  this essentially captures our belief about the family of functions that the unknown
function comes from  the then decide on an acquisition
function  which is used to select the next point to test     

   acquisition function  in order to optimize our function 
we want to test points that have the highest chance of being an
argmax  our function f  x  is drawn from a gaussian process
prior  meaning yn  n  f  xn       the acquisition function is
the function the chooses the next point to try  with a gaussian
process  there are a few acquisition functions to choose from 
but the one we used was expected improvement 
expected improvement chooses the point that maximizes the
expected improvement over our current best point       with
a gaussian process  this has a closed form
a x x  t     e  max    ft    x   ft  x    x  t  
    u u     u  

fics   

 

classifier
bernoulli naive bayes
multinomial naive bayes
latent dirichlet allocation     topics 
latent dirichlet allocation      topics 

precision
    
    
    
    

recall
    
    
    
    

f 
    
    
    
    

table iii  results on       training size       test size

s t u  

ymax  


we will not go into the details of the closed form here  but
see snoek et al  for details     
   bayesian optimization of algorithms  we used bayesian
optimization to tune the random forests algorithm and the
svms  svms did not perform very well on the data originally 
but after tuning the hyperparameters  the f  score increased
from around     to      this is a non negligible increase
that required performing only    iterations of bayesian optimization in a couple of hours  as opposed to the hundreds
of iterations required by grid search  which did not even
finish running on the dataset provided after    hours  for
random forests  the accuracy of the classifier increased from
      to       using bayesian optimization  this is an
increase of about    percent  with minimal work from the
implementation side  bayesian optimization took about an
hour to find a reasonable optimum  while grid search again did
not complete in a reasonable amount of time  the paramater
space examined by each of these algorithms contained        
different configurations of hyperparameters  so the fact that
bayesian optimization was significantly more efficient is not
a surprise 

d  lyrical modeling
the million song dataset supplied a subset of data of
         songs with lyrics in a bag of word  term frequency
counts  format  from this data set we were able to extract
those songs contained in the million song dataset to perform
supervised learning on songs with lyrical information 
   naive bayes  using the naive bayes algorithm on the
terms contained in each document we were able to construct
a generative model to predict the documents genre  we
preprocessed the data by removing common stop words  first
we implemented bernoulli naive bayes in which the features
are  v   length vectors indicating if a term appeared in the
document or not  next we utilized the term count in the data
by running multinomial naive bayes 
   latent dirichlet allocation  latent dirchlet allocation
models documents as coming from some number of topics 
each word has a probability of being genereated by some topic 
we hypothesized that the data could be modeled as documents
containin words generated from topics relating either directly
or indirectly to genre  by running latent dirichlet allocation
 using the gensim python package  with varying number of
topics we were able to generate a feature set for each document
that was the fraction of the document accounted for by each
model  running these features through a svm with a linear
kernel we generated class predictions

iv  r esults
a  lyrics analysis results
the result of analysis of lyrical data was that bernoulli
naive bayes performed the best  dividing songs into topics
using latent dirichlet allocation did not result in classification
gains  regardless of the number of topics  the results could
potentially be improved by using a larger data set  only        
of the         labeled songs in the million song dataset had
lyrical information  additionally  the fact that many songs
across genres use similar words and the fact that the dataset
was multilingual affected the accuracy of classification 
b  sound results
model
random forests
linear discriminant analysis

training error
    
    

test error
    
    

test f  score
    
    

table iv  results on pure sound data

v  d iagnostics
a  confusion matrix
in this section  we analyze how our primary models performed  and discuss reasons why they did not perform even
better specifically  we will analyze why certain genres were
commonly confused with others  confusing classic pop and
rock and folk was common with our models  this makes sense 
as both have similar time signatures and generally use acoustic
instruments  they also have similar loudness  which makes
differentiation even more difficult  punk was often confused
with classic pop and rock  due to the fact that the punk sample
size was relatively small  additionally  these genres tend to
have similar time signatures and make heavy use the electric
guitar  pop again was commonly confused with classic pop and
rock  which makes sense because even humans would have
trouble discerning between classic pop and pop  most
surprising  however  was the fact that dance and electronica
was also often confused with classic pop and rock  potentially
due to a lack of training examples  as was the case with punk  
our hypothesis is further confirmed because of the precision
and recall of the dance and electronica class  the precision is
quite high  at around       while the recall is lingering around
    the likely explanation is the class imbalances  as classic
pop oand rock is the biggest class and thus has the highest
prior probability  metal actually did very well in both precision
and recall  again being confused for classic pop and rock
the most frequently due to class imbalances  jazz and blues
had very good precision  yet again bad recall  which again
is probably due to class imbalances  it seems that classical
did the best in both precision and recall  which makes sense
because it generally has a very different timbre than most other
genres  hip hop  the smallest class  does very poorly  and is
not worth talking about as there is not enough data to make a
comment  soul and reggae again has very good precision  but
the recall is not great  we believe this is again due to the fact
that it is mostly acoustic  and because of the class imbalances 

fics   

 

table v  confusion matrix for linear discriminant analysis
    
   
   
   
   
  
   
  
  
   

   
   
  
 
  
  
 
 
 
 

   
  
    
  
  
 
  
  
 
  

   
  
  
  
  
 
  
 
 
  

   
  
  
  
   
  
  
  
  
  

  
  
 
 
  
   
 
 
 
 

   
 
  
 
  
 
   
 
 
  

  
 
  
 
  
 
  
   
 
 

  
  
  
 
  
 
 
 
  
  

   
  
  
  
  
 
 
 
  
   

table vi  confusion matrix for random forest
    
   
    
   
   
   
   
  
  
   

  
   
 
 
 
  
 
 
 
 

   
 
    
  
  
 
   
  
 
  

 
 
 
 
 
 
 
 
 
 

  
 
  
 
   
 
 
 
 
  

  
  
 
 
 
   
 
 
 
 

  
 
  
 
  
 
   
  
 
 

 
 
  
 
  
 
  
   
 
 

 
 
 
 
 
 
 
 
 
 

  
  
 
 
  
 
 
 
 
   

b  learning curves
after feature selection  both of our models performed similarly on the test set  this implies that more feature selection
work could have been done  the reason for this is that with
both a high bias algorithm  which underfits the data  and a
high variance algorithm  we get similar results  see fig   
and fig      this implies that perhaps the features are not
descriptive enough 
vi  f uture w ork
given more time we would work to develop or improve
on several ideas  the first idea we had was to extend the
fingerprint algorithm to find the top   sections of the song 
rather than the top    based on these    we would calculate
the average and variance of the timbre vectors multiplied by
the loudness of each segment  this hopefully would provide
more data as to how different parts of the song interact  and
is a way of keeping our feature vectors small  while adding to
the acoustic fingerprint 
the second method we wanted to try was an ensemble
method to combine classifiers  some of the classifiers had
high bias  such as linear discriminant analysis  and some
had high variance  such as random forests  an interesting
topic that we have not had time to explore is combining these
models  along with a lyrical classifier where the data exists 
using an ensemble method  such as bayesian model averaging
 bma        unfortunately  we did not have the time to code
an implementation of bma 
further work could also have been done with applying deep
learning to this problem  a few viable methodologies might be
to use techniques described in unsupervised feature learning
from temporal data     for unsupervised feature extraction  or
use a supervised recurrent neural net to perform classification
directly  these algorithms would have been able to take into

account all of the time series features of each song  possibly
allowing for greater prediction accuracy 
vii  c onclusion
to conclude  we have constructed a relatively accurate classifier to determine the genre of a given song  processing the
acoustic features of the million song dataset by identifying
the most significant  loudest  segment and feeding this data
into a random forest classifier  we were able to achieve
        accuracy on our test set  after using bayesian optimization to tune hyperparameters  steps such as expanding the
dataset and feature set and using ensemble methods to combine
classifiers have the potential to improve upon on results in the
future 
r eferences
    miguel francisco and dong myung kim  music genre classification
and variance comparison on number of genres  stanford university 
tech  rep          online   available  goo gl nl jza
    ross goroshin  joan bruna  arthur szlam  jonathan tompson  david
eigen  and yann lecun  unsupervised feature learning from temporal
data  in deep learning and representation learning workshop       
 online   available  goo gl znvtfc
    evaluation
tools
for
persistent
association 
 online  
available 
http   mpeg chiariglione org standards mpeg    
evaluation tools persistent association
    msd
genre
dataset 
 online  
available 
http 
  labrosa ee columbia edu millionsong sites default files additionalfiles 
msd genre dataset zip
    m  sahidullah and g  saha  design  analysis and experimental
evaluation of block based transformation in mfcc computation for
speaker recognition  speech communication  vol      no     pp 
        may        online   available  http   www sciencedirect com 
science article pii s                
    e  wold  t  blum  d  keislar  and j  wheaten  content based classification  search  and retrieval of audio  ieee multimedia  vol     no    
pp             
    m  baker  music moves brain to pay attention  stanford study
finds   online   available  http   med stanford edu news all news      
   music moves brain to pay attention stanford study finds html
    g  james  d  witten  t  hastie  and r  tibshirani  eds   an introduction
to statistical learning  with applications in r  ser  springer texts in
statistics  new york  springer        no      
    j  snoek  h  larochelle  and r  p  adams  practical bayesian
optimization of machine learning algorithms  in advances in neural
information processing systems     f  pereira  c  j  c  burges 
l  bottou  and k  q  weinberger  eds  curran associates  inc  
      pp             online   available  http   papers nips cc paper 
     practical bayesian optimization of machine learning algorithms 
pdf
     c  e  rasmussen  gaussian processes for machine learning  ser  adaptive computation and machine learning  cambridge  mass  mit press 
     
     h  j  kushner  a new method of locating the maximum point of
an arbitrary multipeak curve in the presence of noise  journal of
fluids engineering  vol      no     pp         mar         online  
available  http   dx doi org                  
     j  a  hoeting  d  madigan  a  e  raftery  and c  t  volinsky  bayesian
model averaging  a tutorial  statistical science  vol      no     pp     
     nov         online   available  http   www jstor org stable        

fi