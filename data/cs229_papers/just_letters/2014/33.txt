cs      r classifier   subreddit text classification
andrew giel

jonathan necamp

hussain kader

bs stanford       computer science
agiel stanford edu

bs stanford       computer science
jnecamp stanford edu

bs stanford       computer science
hkader stanford edu

abstractthis paper presents techniques for text classification
of reddit posts over    subreddits  leveraging a variety of natural
language processing techniques such as lexicalized features  tfidf weighting  sentiment classification  parts of speech tagging 
and latent dirichlet allocation along with machine learning
practices such as filtered feature selection  principal component
analysis  and multinomial classifiers as well as domain specific
knowledge we were able to construct systems capable of high f 
over many classes 

i  t he task
reddit is one of the largest anonymous online communities
in the world  with over     million unique users per month 
reddit is a collection of interest based communities known as
subreddits  whose content vary from news  to sports teams  to
hobbies  to basically anything you can imagine  when posting
a link or text post to reddit  one must select the subreddit to
post to  as each post lives in a particular subreddit  users can
upvote or downvote posts  expressing approval or disapproval
with the content of the post  the number of upvotes and
downvotes are fed into a hot ranking algorithm to determine a
score for the post  with higher scoring posts rising to the top
of the subreddit 
our task is simply  given a text reddit post composed of a
title and body  classify the subreddit the post belongs to  this
can serve two main functions 
   to lower the barrier to entry for new users to reddit who
do not know which subreddit to post to
   to help suggest which subreddit a post will be most
successful in  helping users to achieve high visibility
for their content
in order to make this project tractable  we reigned in the scope
of the task  currently  there are over         active subreddits 
with varying degrees of activity  we chose a subset of   
subreddits to classify over  with hopes that our efforts here
can generalize over larger domains  similarly  we chose to
only classify text  self  posts  and not links  the majority
of links shared on reddit are from image hosting sites such
as imgur com  object classification is notoriously one of the
hardest tasks in computer vision and machine learning  with
cutting edge techniques only now beginning to show large
improvements in performance  avoiding these bleeding edge
pursuits  we have focused on text posts  making much of our
task nlp related  we feel that these two adjustments to the
task definition allow for us to expect reasonable performance
while remaining an academic and implementation challenge 

this task is commonly referred to as a text classification
problem  more formally  given a post
pd
where d is the space of all reddit posts  and given a set of
subreddits s    s         sk    train a classifier
h ds
that appropriately determines the optimal subreddit assignment
of p 
ii  t he data
our dataset can be found at  https   github com umbrae 
reddit top     million
we are using data from twelve subreddits 
nostupidquestions
shortscarystories
confession
unsentletters
askphilosophy
askmen

showerthoughts
debatereligion
relationship advice
self
shittypoetry
askwomen

these particular subreddits were chosen based on an analysis
that showed them to be the the subreddits with the largest
percentage of text only posts that had no very easily identifiable features  for example  when posting in r todayilearned
users lead their posts with the tag til  effectively making
it incredibly easy to build a simple model that consistently
correctly classifies every post from r todayilearned  we didnt
want to work with subreddits that had features such as these
because we believed it would trivialize our task  so we
particularly selected our subreddits to be vague enough to
make the task interesting  each post contained in the dataset
is made up of information spanning everything from the author
of the post to the number of upvotes  the only elements that
we use are the title of each post and its text contents  in total 
we have        posts which amounts to       posts from each
of the twelve different subreddits 
iii  f eatures
in order to give our models information regarding the correct classification of a reddit post  we used lexicalized features
based on the text within a given post  incorporating multiple
natural language processing techniques to do so  as is the
case for many text classification problems  we found ourselves
spending the majority of our time experimenting with different

ficombinations of feature representations  additionally  since
most of our feature representations revolved around a bagof words model and the size of the set of possible words is
quite large  we experimented with different ways of reducing
our feature space 
a  base reddit post representation
our base way of representing a reddit post in a form able
to be used by our learning models was with the bag of words
approach  that is  we created feature vectors where each
element holds a weighted value corresponding to a word  or
word pair in the case of bigrams  in the vocabulary   note 
we experimented with using unigram and bigram terms and
found unigrams to perform the best  so for the rest of this
paper we consider only unigrams   more formally  for some
subreddit post p over some vocabulary v    w    w         wn   
we created a vector p    a    a         an   where ai is some
weight associated to wi   we used two different methods for
calculating this weight term  ai   for a word 
   binary  ai held either a   if wi did not show up in the
post p or a   if it had appeared in p  using this weighting
meant our feature vectors were binary vectors  this may
seem like an overly simplistic of representing a post but
it actually performed quite well and was computationally
fast 
   tf idf  this type of weighting aims at more accurately
representing the reddit post as a mathematical object 
taking into account term frequency instead of just a
binary value  in particular  tf idf weights are found
as follows
     f  wi   p 
tf  wi   p         
max f  w  p    w  p 
m
idf  wi   d    log
 p  d   wi  p 
tf idf  wi   p  d    tf  wi   p   idf  wi   d 
where d is the set of all posts  m    d   and f  wi   p 
is a function returning the number of times word wi
appears in post p 
one qualitative way to assess the helpfulness of binary and
tf idf weighting in practice is to visualize the vectors 
using t distributed stochastic neighbor embedding  t sne  
a dimensionality reduction technique specifically helpful for
visualizing high dimenionsal data  we plotted      feature
vectors corresponding to      different reddit posts  as seen
in fig    and    the color of a given point corresponds to the
subreddit the post belongs to  one can notice that points in
the tf idf plot are more clustered by color than in the binary
plot  this seems to mean that tf idf weighting is better
at representing documents as vectors where similar vectors
correspond to posts belonging in the same subreddit  although 
in practice we found that binary vectors often performed
similiarly to tf idf in terms of f  
initially  we started with just these base representations of
the text of a reddit post  where the text was the combination

fig     binary vectors in r     visualized in r  using t sne 

fig     tf idf vectors in r     visualized in r  using t sne 

of the text body and title  however  there are a few problems
with using just this approach  first  representing posts over
a large vocabulary means having feature vectors of large
dimension which can be computationally unwieldy and also
lead to overfitting  second  the bag of words approach is rather
simplistic as it disregards word ordering in a given post as well
as higher level post information  these problems and measures
taken to remedy them are the topics of the sections that follow 
b  reducing feature space dimensions
there are          different words in the        reddit
posts we train over  putting each of these words in our
vocabulary means having feature vectors with         
dimensions  initially  this is what we did and we were able
to train our models  although  it took a very long time to
complete the training and we found this to not be conducive
towards rapid experimentation  additionally  since        
dimensions is larger than the         posts we train over  our
models could be prone to overfitting  to tackle both of these

fiissues  we experimented with two methods of reducing our
feature space 
   feature selection via mutual information  although
       different words appear in the posts  only some of
these are telling as to what subreddit a post belongs  as
such  we wanted to intelligently select a subset of the words 
filtering out those which give us little to no information
regarding the classification task  we chose to filter using the
notion of mutual information  using the notation found in the
novovicova paper  we defined mi between a set of classes c
and some feature wi as follows

c  additional features

using just the bag of words features gave decent results 
however  we discovered a slight modification by considering
title and body separately performed noticeably better  additionally  combining lexical features with features that gave
higher level information such as word count  latent dirichlet
allocation topic distributions  sentiment scores  or number of
parts of speech tags gave us consistently higher scores than
any of the individual component feature representations  this
was a major takeaway from this project 
   title split  we wanted to create a feature that utilized
some domain based knowledge of reddit in order to boost
m i c  wi    
our performance  we realized that there was a lot of implicit
information lost when combining the title text and body text
 c 
 c 
x
x
p  ck   wi   together  this led us to create a featurization procedure we
p  ck   wi  
 
p  ck   wi   log
p  ck   wi   log
called title split  instead of lumping the title and body
p  ck  p  wi  
p  ck  p  wi  
k  
k  
text together  we selected features and created feature vectors
completely separately  then concatenated these two vectors to
where wi indicates that the word did not occur  note that mi
create our feature vector 
is the sum of the kullback leiber  kl  divergence between
the class distribution and the feature presence distribution and
    title body  
the kl divergence between the class distribution and the
we found this to be a very useful feature  some of the
feature non presence distribution  intuitively  mutual informasubreddits we were experimenting on proved to be especially
tion gives us a quantitative assessment of how helpful a
impacted by this feature  as a large portion of the subreddits
feature  in this case word  will be in classifying across our
which were question based  eg  askmen  would contain only
k      classes  as seen in fig     filtering with mi performs
a title and no body  title split helped to encapsulate the
much better than randomly selecting the subset of words to
separation of information found within a reddit post title and
be used 
its body 
   principal component analysis  we used the dimensionality reduction technique of pca to reduce feature vectors
to a more manageable dimension  although this helped with
overfitting and achieved similar performance to feature selection with mi  performing pca on the original large vectors
is nearly computationally intractable itself  we actually had to
use a faster randomized variation of pca  

fig     tuning the hyperparameters ntitle and nbody

fig     reducing dimensionality via random selection  mi  and pca

   latent dirichlet allocation for featurization  our most
experimental feature vector representation was based on the
topic distribution vectors inferred by latent dirichlet allocation  lda   lda is a generative topic modeling algorithm 
that assumes that a document is created as a mixture of
a finite number of topics  and each topic has some distribution over words  given a corpus of documents and the

finumber of topics k  lda infers the the topic mixture model
  rk  dirichlet   and the topic to word distributions
  rk v    dirichlet    given a new document d  lda
will predict the topic distribution d  rk in the form of a
vector whose elements sum to   
our hypothesis was that lda was a perfect tool for our
task  as we have a finite number of subreddits which are
communities for a variety of topics  in order to utilize the
topic models  we trained an lda model on the post text 
presenting each post as a document  not applying titlesplit   once these models were trained   and  are estimated
via expectation maximization   we ran our dataset through
these models again  giving us the predicted topic distribution
vectors for each of our titles and bodies  this vector of topic
distributions d     rk which we then gave to our classifier
 the notation here is overloaded   at test time  we used the
lda models created during training to create d and then fed
this as  to our linear model 
   word count  one simple feature we used was simply
the number of words in a post  we found this very simple
feature to be very powerful  especially when combined with
other features 
   sentiment score  the sentiment score proved to be an
interesting feature that did not make a large difference in
the overall average f  score  but did affect some specific
subreddits quite substantially  for every post  we calculated
a sentiment score that was a float ranging from    to    some
subreddits  like relationship advice  askmen  and askwomen
did significantly better with sentiment as a feature  sentiment
definitely helped us tell the difference between askmen and
askwomen  which is something we struggled with throughout 
unfortunately  sentiment did not work well with some subreddits   particularly shortscarystories and shittypoetry  both
of which it caused significant decreases in accuracy in  we
believe this is because things such as poetry and stories can
have a wide range of different sentiments  so there is less
reliability in a sentiment score being indicative of the category 
   parts of speech tagging  for our parts of speech tagging feature  we tagged the part of speech for each word in the
post and then iterated through the post and counted up the total
number of adjectives  nouns  proper nouns  and verbs  we then
normalized these numbers to account for the fact that all of our
posts are of varying sizes  the results of the parts of speech
tagging feature were similar to sentiment in that it worked
pretty well for some subreddits  but then was significantly
worse for others  we saw a huge positive increase in our f 
for debatereligion and askphilosophy but took subtantial hits
in accuracy for showerthoughts and shittypoetry 

each k  k as well as p xi  ck    or the probability of the
feature xi conditioned on the class ck   given some new input
x to evaluate  multinomial naive bayes selects the class via
arg max p c 
c

n
y

p xi  c 

i  

b  multinomial logistic regression
we also experimented with multinomial logistic regression  a multi class generalization of logistic regression  just
as in logistic regression  multinomial logistic regression
trains via stochastic gradient descent  learning some parameters  to minimize the cost function j  
m
n
 
  x  
  x
h  x i     y  i   

j    
m i  
c i   i
where

exp jt x 
h  x j   pk
t
k   exp k x 

which is the softmax function 
v  h yperparameter t uning
in order to maximize our performance  we tuned our hyperparameters using    fold cross validation  we optimized
our performance by evaluating on f   the harmonic mean
between precision and recall  across all    classes  recall 
hyperparameters are parameters to our model 
   and therefore not associated with the optimization objective  these
parameters must be optimized for using other methods  such as
grid search  for our models  these parameters included n  the
number of features  c  the regularization parameter  and k  the
number of topics inferred by latent dirichlet allocation  by
tuning these parameters  we were able to find large increases
in the performance of our overall system 

iv  m odels
we experimented with two multinomial models capable of
classifying our reddit posts over    classes 
a  multinomial naive bayes
our first model was multinomial naive bayes  naive bayes
is a generative model which learns the class prior p ck   for

fig     tuning the hyperparameter c  the inverse regularization parameter

fivi  r esults

classifier
baseline   nb
baseline   lr
lda tf idf   lr
sentiment binary   lr
count binary   lr
performance of different

train
dev
p
r
f 
p
r
   
   
           
   
   
           
   
   
           
   
   
           
   
   
           
systems on the development set

f 
   
   
   
   
   

we are very pleased with the end results of our system  both
on the development set and on the held out test set  in our first
table  you can see the performance of a subset of our systems
on both the train and development sets 
in the end  we chose our best system to be a multinomial
logistic regression model using title split  word count 
and      unigram mutual information selected binary valued
features  this system was chosen as it consistently performed
the best on the development set  as such  we evaluated this
system on a held out test set  obtained by scraping reddit 
consisting of    posts from each of the    subreddits  with
results documented in fig   and our second table 
a large source of our errors in both dev and test came
from trying to differentiate between askmen and askwomen 
often times when adding different features  such as sentiment
or parts of speech tags  the classifier was better able to
differentiate between these two  but it still did not do very
well  the reasoning behind this is that the two categories are
inherently very similar  they have almost exactly the same
average length      vs      and have have an overlap of
seven words in their most frequent ten  removing the askmen
subreddit gave us an astounding increase to     f  for average
dev accuracy 
it is also worth noting that two classes  class   r confession
and class   r self  performed much worse on the test set than
previously seen in dev  this may be due to the fact that our
train and dev set were top posts of all time for the subreddit
while our test set was top    of a week  or that these subreddits
happen to inherently have high variability in the posts 
subreddit
nostupidquestions
shortscarystories
showerthoughts
debatereligion
confession
relationship advice
unsentletters
self
askphilosophy
shittypoetry
askmen
askwomen
overall

p
   
   
   
   
   
   
   
   
   
   
   
   
   

r
   
   
   
   
   
   
   
   
   
   
   
   
   

f 
   
   
   
   
   
   
   
   
   
   
   
   
   

fig     confusion matrix for our best classifier  logistic regression with titlesplit  word count  and      mi selected binary features  on the held out test
set

vii  f uture w ork
although our classifier performs well  there are a few
improvement ideas we never had time to pursue 
one improvement which was discussed was attempting to
use latent dirichlet allocation as more than a tool to give us
feature vectors  more concretely  we would like to use lda
to be our classifier  since lda is a generative model  it has
probabilities for topics given a document and for words given a
topic  it seems plausible that one could train k different lda
models  one for each class  and then in testing determine the
class of a document d by a simple arg maxc p  c d  where
p  c d  could be approximated from lda  unfortunately  we
never found a tractable way to approximate this  and thus never
was able to use lda in more than a feature space sense 
besides looking at ways to improve our classifier  there are
also ways of expanding our project  for one  we could explore
how our classifier performs when classifying to a larger       
number of subreddits  similiarly  instead of limiting ourselves
to text posts  we could try classfying link posts by following
the link and scraping text and other data that could be used in
a classifier to discern the subreddit  both of these expansions
are part of a general goal of ours  we believe that our classifier
would be a useful tool on reddit and are interested in scaling
this project to a level at which it could be actually used by
reddit 
r eferences
    li  lei  and yimeng zhang  an empirical study of text classification
using latent dirichlet allocation 
    novoviov  jana  antonn malk  and pavel pudil  feature selection using
improved mutual information for text classification  structural  syntactic 
and statistical pattern recognition  springer berlin heidelberg       
          
    fuka  karel  and rudolf hanka  feature set reduction for document
classification problems  ijcai    workshop  text learning  beyond
supervision       

fi