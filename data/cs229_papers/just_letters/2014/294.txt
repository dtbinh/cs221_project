automated identification of artist given unknown paintings   quantification of artistic style
nicholas dufour  kyle griswold  michael lublin
 ndufour  kggriswo  mlublin  stanford edu
december         

 

introduction

certain painters have visual styles that make them immediately identifiable  even to a layperson  in this paper  we examine
whether artists features that are obvious to the human eye can be encoded using modern visual features and learned by
existing machine learning algorithms  our goals here are threefold 
   show that our featureset captures information about artistic style  i e   properties consistent within artist and across
paintings  by demonstrating it can be used for significantly above chance prediction of painting authorship 
   show that the features are similar to those humans use for the same task by demonstrating that algorithmic confusion
between two artists is predictive of human assessment of similarity 
   use differences in classification accuracy as a function of hyperparameters to study properties of artistic style 
classifying paintings by artist is a task usually left to experts  but recently the machine learning literature has begun
to approach this problemespecially as it pertains to forgery detection     

 

data

our dataset consisted of     paintings from   different artists  with each painting labelled with its artist  table   gives an
overview of our dataset  including the number of paintings per artist  paintings were scraped from online sources  wikipedia 
google  etc  under fair use  any images that included elements not chosen by the artist  i e   picture frame  monochromatic
borders  captions  were discarded  data were divided into training        dev        and test       sets 

artist
alfred sisley
hans holbein
john millais
claude monet
rembrandt
vincent van gogh

table    summary of
style
impressionism
northern renaissance
pre raphaelitism
impressionism
dutch baroque
post impressionism

artists used
birth
country
    
britain
c       germany
    
britain
    
france
    
netherlands
    
netherlands

n images
   
   
   
   
   
   

these artists were chosen because they represent several important artistic styles  however  we also include multiple
painters from the same style so that our classification objective is not simply to classify paintings by genre  but to distinguish
among the artists of a genre 

 

methods

figure   summarizes our feature extraction pipeline visually  a detailed explanation follows  for image sources  see     

figure    the three steps of feature extraction are shown  hog descriptors are computed  clustered via k means  and then
the image is assigned catenated spatial pyramid histograms  the first image is the authors own work  adam and eve 
holbein        with hog descriptors overlayed   the second and third images are from web sources 
 
 

http   www mathworks com matlabcentral fileexchange screenshots      original jpg
http   www mathsisfun com data images histogram heights gif

 

fi   

feature extraction

images are converted to grayscale and then downsampled using linear interpolation  grayscale was chosen because it allows
classification based purely on image structure as opposed to color composition  given that color composition is not natively
considered in the computation of our features and would greatly expand the featurespace 
     

hog features

hog features were selected as the primary source of image features  given their robustness in a variety of contexts        
the image is divided into a set of  x  pixel cells  two   dimensional gradient mask kernels are applied to each pixel  which
permits calculation of gradient intensities 
          and          t
each pixel in the cell then casts a vote for each of the   evenly spaced  from   to     degrees  gradient channels  i e  
orientations   gradients are normalized locally within  x  pixel blocks  each of which contains    cells  while other cell
and block sizes have shown differential performance on certain tasks  i e   human recognition   given the abstract nature of
the task there was no clear method of selecting them besides testing on the dev set  which would have greatly expanded our
hyperparameter space  blocks were spatially contiguous but nonoverlapping  and image downsampling was such that each
image yielded an array of   x   hog descriptors 
     

k means clustering

hog descriptors were transformed from continuous measures into discrete labels via k means clustering  which essentially transforms them into visual words  k means clustering proceeds by constructing k non overlapping sets of hog
descriptors hi where each hog descriptor set has an average point i in descriptor space such that 
arg min
h

k
x
x

khog  i k 

i   hoghi

 

i e   the sum of the squared l norm for every hog descriptor to the mean point for each set  in every set of descriptors 
is minimized  k was treated as a hyperparameter and tuned using a dev set 
     

spatial histograms

the final image level descriptor x was produced by dividing the image into quadrants and subquadrants n times  such
that  n quadrants were produced in total  arrayed in a uniform grid over the image  a histogram of k means labeled hog
features in each subquadrant was computed as a vector  resulting in a matrix x  nnnk such that xi j m is the number
of times a hog descriptor was labeled m in subquadrant  i  j   this matrix was then flattened into a vector by stacking
the histograms for each subquadrant on top of each other  the final feature vector v for each image was thus a vector of
positive integers where  v     k   n  

   

machine learning algorithms

three algorithms were tested  each was considered as a separate experiment  given their disaparate qualities 
     

k nearest neighbor  knn 

k nearest neighbor is the simplest classification method used  each training example is assigned a point in feature space 
for a test example x  the algorithm merely finds the k closest points to x  and combines their labels according to some
function  in the case of classification  taking the plurality  
     

random forests  rf 

random forests have previously been shown to be successful at various vision tasks         rf trains a set of t decision
trees  the number of which is treated and tuned as a hyperparameter  of some maximum depth  treated and tuned as a
hyperparameter  on random subsets of the data  if we let pt  x    a be the prediction a from the set of artists a of tree b
for unseen example x  then computing the predicted classification is merely taking the mode 
arg max
aa

     

t
x

  pt  x    a 

t  

multi class support vector machine  svm 

mutli class svms are the most mathematically complex method employed  this method constructs a series of hyperplanes
in high  in our case  infinite  dimensional space  and uses the position of the test datapoints relative to these hyperplanes
to classify them  for our purposes  we used a radial basis  i e   gaussian  kernel  given by
k x    x      exp  x   x      

 

fiwhere  is treated and tuned as a hyperparameter  our svm was amongst multiple classes  and implemented a oneagainst one        method  in which n   n       classifiers are constructed for all binary pairwise combinations of the
n classes  in this case  n    a   each binary classifier solves the dual problem
  

x
 
min t q 
i
  
i  
s t  y t      and    i  c  i              where qij   k xi   xj   and c is an upper bound on values of   individual
decisions are made according to  for testing example x   
n
x
sgn 
yi i k xi   x      
i  

where  is an intercept term  each of the n   n       classifiers makes such a classification  which are combined
according to a majority rule  similar to the rf 

 
   

results
classification

each classification method was trained on the training set  hyperparameters  number of clusters  maximum depth of
decision trees  etc   were optimized using the dev set  the results reported here correspond to the performance of the
indicated classification method on the unseen test set using hyperparameters found to be optimal via the dev set 
all classification methods performed remarkably well  and far above chance  one tailed z test p         for all methods  
hit rates for each classifier are summarized in figure   

figure    hit rates for each model
the svm performed best with a hit rate of      followed by knn       and rf        random chance is also shown 
at      additionally  svm and rf perform extremely well on the training setlikely due to overfitting  though much
work was done in the feature extraction and hyperparameter optimization steps to reduce variance  we can see that variance
remains high for the rf and svm classifiers  this is discussed more in the future work section  
a confusion matrix for the svm classifier is depicted in table  a  table  b summarizes this data into counts of true
positives  false positives  true negatives  and false negatives for each artist  as well as calculates the classification acccuracy
for each artist 

n    
alfred sisley     
hans holbein     
john millais     
claude monet     
rembrandt     
van gogh     

alfred sisley
  
 
 
  
 
 

table  a  confusion matrix 
hans holbein john millais claude monet
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 

 

rembrandt
 
 
 
 
 
 

van gogh
 
 
 
 
 
 

fiartist
alfred sisley
hans holbein
john millais
claude monet
rembrandt
vincent van gogh

table
true positives
  
  
 
  
 
 

 b  confusion matrix statistics 
false positives false negatives
  
  
  
  
  
  
  
  
 
  
  
  

true negatives
  
   
   
  
   
   

accuracy
   
   
   
   
   
   

our methods are substantially more effective if we classify artists one vs one  detailed in table    

holbein
sisley
monet
millais
van gogh
rembrandt

table    maximum   vs    hit rate    
holbein sisley monet millais van gogh
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

rembrandt
    
    
    
    
    

these results allow us to quantify how similar artists are  according to our features  by looking at how frequently the
paintings of artist i are classified as artist j  we can see that artists with similar styles are confused more frequently than
artists with disparate styles  thus lending more support to the hypothesis that our featureset captures information about
artistic style 

   

coreference analysis

coreference frequency  number of websites mentioning both artist i and artist j  did not correlate significantly with algorithmic confusion  r         p          although this could be artifactual due to difficulties in obtaining coreference
frequencies 

   

analysis of artistic style

there are stylistic interpretations of the hyperparameters used in our feature extraction which can be used to study
properties of artistic style  the number of clusters in our feature extraction relates the amount of textural information
preserved in the feature vector  because more clusters allows the model to distinguish between more classes of hogs  which
correspond to specific methods of painting and other such textural information   in addition  the number of spatial levels
in the feature extraction relates the amount of spatial information preserved in the feature vector  because more spatial
levels gives more information about the location of different elements in the painting  therefore  the relevance of textural
and spatial information to style by artist can be computed by averaging the optimal values of these hyperparameters across
pairs of artists  the results of this analysis are detailed in figure   

figure    textural and spacial relvence by artist

 

fithe spatial and textural information found here is largely in line with what one would expect from these artists  this
analysis also allows us to formalize notions of similarities and differences between artists  for example  the primarily
portraiture artists millais and holbein both have relatively high levels of spatial and textural importance  as both the
spatial information  i e  where the different elements of the human body are in the portrait  and textural information
 i e  information about the brushstrokes themselves  play important roles in identifying their works  another interesting
example is monet  monet painted a variety of scenes  such as landscapes  portraits  etc   so one would expect that spatial
information would not be very relevant in identifying his paintings  whereas he had a very intricate and distinctive style  so
one would expect textural information to be very indicative of his work  indeed  these are the results seen in our analysis 

 

conclusions

hog features are a significant part of what makes a painters work identifiable as their own  the more than double increase
in the probability of correct identification over random chance shows this  furthermore  hog features are also a part of what
makes a works style identifiable  as shown by artists who worked with similar styles having their paintings misclassified
as each others more often than other artists 
perhaps the most exciting aspect of this work is its utility in quantifying aspects of artistic style  while we make no
suggestion that artistic style may be boiled down entirely to numeric values  it is not unreasonable to suggest that some
portion of it can be expressed as such  further  by dividing the image up into variable numbers of cells and using variable
numbers of clusters  the method affords fine control over the amount of spatial vs  textural information preserved in the
final feature vector  this permits careful exploration and comparison of how artistic style is encoded in art 

 

future work

there are two major directions that this work can go in the future to continue to improve classification accuracy  the first
is to improve the classification accuracy of our existing models by continuing to reduce the variance of the rf and svm
classifiers  this can be done by collecting more data to increase the size of our training and test sets  and also by continuing
to shrink the feature set by experimenting with more values of our models hyperparameters  second  we can experiment
with different types of features to see if other features capture more information about artistic style  for example  we
can experiment with features involving colors  introduce deep learning generated features  experiment with the  d fourier
transform  or try scale invariant feature transform  sift  features 
in addition  we can conduct further analyses relating our models accuracies with the accuracies of expert humans to
better understand the similarities between our features and the features humans use to distinguish between artists  another
possible direction would be to apply our techniques to the domain of forgery detection 

references
    leo breiman  random forests  machine learning                  
    navneet dalal and bill triggs  histograms of oriented gradients for human detection  in computer vision and pattern
recognition        cvpr       ieee computer society conference on  volume    pages         ieee       
    juergen gall  nima razavi  and luc van gool  an introduction to random forests for multi class object detection  in
outdoor and large scale real world scene analysis  pages         springer       
    stefan knerr  leon personnaz  and gerard dreyfus  single layer learning revisited  a stepwise procedure for building
and training a neural network  in neurocomputing  pages       springer       
    ivan laptev  improving object detection with boosted histograms  image and vision computing                     
    gungor polatkan  sina jafarpour  andrei brasoveanu  shannon hughes  and ingrid daubechies  detection of forgery in
paintings using supervised learning  in image processing  icip          th ieee international conference on  pages
          ieee       
    ting fan wu  chih jen lin  and ruby c weng  probability estimates for multi class classification by pairwise coupling 
the journal of machine learning research                  

 

fi