predicting a songs commercial success based on lyrics and other metrics
angela xue  angelax  and nick dupoux  njdupoux 

 

task definition

given quantifiable metrics from a song  such as lyrics  genre  and tempo  we wanted to predict its commercial success 
we used a pre defined and pre existing rating system  specifically  an aggregate attribute in the data called hotttness 
as a proxy for determining popularity and success 
our system takes as an input a subset of songs drawn from the million song dataset and their associated metadata 
including genre  year  artist  rhythm tempo  and instrumentation  the desired output for each of these songs is the value
of the corresponding aggregate attribute in the dataset called hotttnesss  this attribute is assigned to songs by the api
providers based on a number of metrics  including mentions in the news  play counts  music reviews  radio airtime  and
billboard rankings  we will measure the accuracy of our prediction by looking at the percentage difference between our
prediction of hotttnesss and the ground truth value of hotttnesss 
for our baseline  we trained a linear classifier on a feature set of just the songs artist  for our oracle  we simply used
the ground truth value of the input  i e  the hotttnesss score 
due to issues with our datasets  see the datasets section   we didnt have time to fully implement all the approaches
we had hoped to explore  but in this paper we will detail the approaches we attempted and discuss the rest in the future
work section 

 
   

datasets
echo nest api

for our project  we started out using data drawn from the echo nest api  echonest is an organization that offers an array
of music data for use in applications and research  we utilized its api to gather information about songs from various
genres  we collected a random sample of     songs from each of the    genres we selected by hand  then  we filtered
out songs that encountered api failures  which ultimately left us with      songs in our echo nest dataset  for each
song in this dataset  we collected the attributes of tempo  danceability  energy  loudness  key  duration  time signature 
speechiness  liveliness  and hotttnesss for each song  we also scraped the associated lyrics for     of the songs in this
initial dataset to use for later lyric analysis 
after running linear regression with l  penalty  standard linear regression  and k nearest neighbors regression on our
initial dataset and getting results that were counterintuitive and made very little sense  we realized the problem was due
to the fact that that this dataset had a large number of songs       or about        with a value of   for hotttnesss 
our evaluation metric  we initially thought that a hotttnesss score of   indicated that a song was not popular at all 
so we included those songs because we thought they would provide data on attributes of unsuccessful songs  we were
mistaken  in the echo nest api  a value of   for hotttnesss is meant to indicate that the song has no hotttnesss score
calculated for it at all 
this fact rendered the echo nest dataset effectively useless to us because it meant that we had a very strong incorrect
data labeling that would overshadow the effects of any other features in the analysis  discarding all the songs with a
hotttnesss value of   would have reduced the size of our dataset down to      songs  which we thought would be too
small 

   

million song dataset

our second attempt at finding useable data led us to the million song dataset  the million song dataset is a freely
available collection of metadata and audio features for a million contemporary popular songs  among the many raw
metadata features included in the million song dataset  we interested ourselves only in     genre  duration  artist
familiarity  artist hotttnesss  year  tempo  danceability  energy  loudness  key  time signature  and hotttnesss  the
dataset also includes lyrical data for a large portion of the songs in it 
we curated our data based on whether or not associated lyrical data was available for each song  this narrowed down
the number of useable songs to roughly          from there  we further filtered out songs that were missing values for
any of the    the metadata attributes we were interested in  including songs with a hotttnesss value of    this brought
the size of our dataset down to      songs  the distribution and frequency of hotttnesss scores in our dataset can be
found below 

 

fi 

approach

our planned approach to the task of predicting the hotttnesss of a given song had two main parts  feature selection
and prediction based on features  our approach was iterative   we started with a list of features  described in the table
below  that we thought would intuitively make sense  we intended to derive new features from existing features if we
found that the raw metadata features were insufficient  the focus of this project is not the implementation of l  penalized
regression  linear regression  or k nearest neighbors regression  as this these are algorithms that have been perfected  but
rather in the construction of meaningful features 

then  we applied a linear regression with l  penalty to get an idea of which features would be more or less predictive
so we could trim down the feature vector  after narrowing down the feature vector  we ran three different regressions
 linear  l  penalized  and k nearest neighbors  to attempt to predict a songs hotttnesss 

 
   

model and algorithms
model

we are given a dataset of xi s  where each xi represents a song and its associated metadata features  call the space in
which our xi s live   our goal is find a function  f     r  which predicts the hotttnesss score of a song 
to make the problem tractable  we model f as a linear regression function  i e 
f   wt  x 
to specify f   we need to specify w and   w will be determined by the algorithm we run  while we will have to specify  
the feature map  as part of the model  note that      rd is required for f to be well defined 

   

the trivial algorithm  choosing the mean

for each song  the predicted hotttnesss value is the mean hotttnesss value in the training set  we consider this trivial
algorithm as a much needed sanity check 

 

fi   

linear regression

our first and simplest  real  algorithm  and the one we also use for our baseline  for estimating w is ordinary least squares
linear regression  given a weight vector w  a feature map  and a dataset  xi   yi    define the loss of w to be
l w   

n
x
 wt  xi    yi   
i  

finding the optimal w can be thought of as finding the best linear predictor of y in the least squares sense at the training
points  a huge upside of ordinary least squares is that an exact solution exists  and is given by
w   arg max l w     x t x   x t y
w

   

l  penalized linear regression

we now turn to the algorithm we will use to find the weights w  ordinary least squares is a good candidate  but for this
application  a major goal is to determine which features are useful predictors  for example  we expect our measure of
lyrical meaning and song genre to be more important than the songs duration  to this end  we instead use least squares
regression with l  penalty  this algorithm has the feature that it outputs sparse vectors for w  where the zeros in w
correspond to uninformative features  we will use a precoded l  penalized regression from the sklearn package  but for
the sake of completeness  we discuss the basic workings of the algorithm 
given a weight vector w  a feature map  and a dataset  xi   yi    define the loss of w to be
l  w   

n
x

 wt  xi    yi      kwk 

i  

where we tune  to promote sparsity in the optimal w  larger  corresponds to sparser outputs  for the output of our
regression  we seek
w   arg max l  w 
w

as of now we tune  by hand 

   

k nearest neighbors regression

as an alternative scheme for prediction  we employ k nearest neighbor regression  the idea is similar to k nearest neighbor
classification  we are given a training dataset of labeled examples  xi   yi    where in our case each xi is a raw music file
and yi its corresponding hotttnesss  using the same feature map as before       rd   we transform the dataset into
  xi    yi   
suppose we are now given a new song s whose hotttnesss we wish to predict  we first transform s with our feature
map   and then find the k closest songs in our training set  where we use euclidean distance as follows 
d xi   xj     k xi     xj  k 
just as in k nearest neighbor classification  we use this list of k nearest neighbors to predict song ss hotness  for the
sake of concreteness  let l be the list of the indices of the nearest neighbors of s  our first scheme assigns uniform weight
to each neighbor to do prediction  more precisely 
k
  x
yl
f  s   
k i   i

in essence  we take an unweighted average  for an alternative scheme  we weight each neighbor by the inverse of its
distance from x  as follows
k
x
d s  xli   
f  s   
pi yli
where
pi   pk
 
j   d s  xlj  
i  
this has the effect of placing more weight on nearer neighbors 
k nearest neighbors directly captures the intuitive notion that similar songs should have similar success  where we
measure similarity in terms of our feature map   if we have a sufficiently dense training set  since k nn is a local
method  we expect a very smooth extrapolation from the training set  one potential problem with k nn is we may have
a feature with very low prediction capability but high range which dominates the neighbor selection  this can be avoided
 

fiby first selecting features with l  regression  and mitigated by properly normalizing the feature vector so no one feature
dominates the selection  as before with l  regression  the crux of the work for implementing a successful k nn algorithm
is in constructing our feature map   with a good set of features  which result in a dense training set  k nn regression
enjoys the good properties we mentioned above  particularly low bias since k nn is a local method 

 

results

   

feature selection

we ran an l  penalized linear regression on the training dataset with        the following feature vector 
 duration  artist familiarity  artist hotttnesss  year  tempo  danceability  energy  loudness  key  time signature  genre 
and got the resulting weight vector 
           e               e               e                e                e               e                e    
           e               e               e               e     
this suggests that the only feature that seems to be even somewhat predictive is duration  which we found to be
somewhat unsettling  the strange result prompted us to investigate further 
we had intuitively expected genre to be a reasonable predictor  so we decided to look more deeply into why we had
gotten a weight of   for it  for each of the genres with more than    songs     chosen to ensure our results are statistically
meaningful   we calculated the percentage of popular songs in our entire dataset  for the purposes of this analysis  we
consider a song popular if it has a hotttnesss score of     or above  if genre is not useful in predicting the hotttnesss
of songs  we would expect the percentage of popular songs to be independent of genre  however  as the table of selected
genres below shows  this is not the case 

some genres  despite having over    songs did not feature a single  popular  song  let us compare country and hip
hop  both have around     songs in the database  yet hip hop has      popular songs while country has only      
metal has only      with over     songs  we believe our data set to be unbiased  starting with         songs for which
we found lyrics   so this implies that genre is in fact a useful feature in predicting hotttnesss  but our algorithms have
not been able to utilize this feature 

   

prediction

below  we have included a table of the accuracy rates of each of our algorithms on each of the feature vectors we considered 

the histogram below shows the distribution of the predicted hotttnesss scores from running linear regression on our
metadata   genre feature vector 

 

fi 

discussion and conclusions

the most notable result is that none of the feature vector   model combinations performed notably better than the trivial
algorithm  defined in model and algorithms  above   therefore  we cannot say with any great certainty that our feature
vectors or models make any particular progress towards solving the problem of predicting hotttnesss 
however  the results of the best performing combination of features and model  full metadata   genre  suggest that
some of our features may be weakly indicative of hotttnesss  from the histogram in the results section  we see that full
metadata   genre is heavily biased against labeling a song popular  this combination makes very few high hotness
predictions  especially compared to the actual distribution of hotttnesss scores in the data  see the histogram in section
      we believe the implication of this is that none of the features or attributes that make a song exceptionally popular
are in our data  for all other algorithms  we actually did not predict any songs to be popular  i e  have a hottttnesss
score above       this could be due to a number of factors  including the limitations inherent in the linearity of our model
and the poor predictive power of our features 
ultimately  we believe that the features we considered are simply not very good at predicting the hotttnesss of a
song 

 

future work

more work could be done in to adding to and refining our features  most significantly  we would like to to incorporate the
themes and meanings of songs into our model  we would do this by classifying songs with nave bayes  and then using
pca to narrow down the different theme labels to only the top several most significant 
in fact  to derive meaningful features from the lyrical data  we would certainly have to do some natural language
processing  our preliminary effort would be to train a naive bayes classifier to classify songs by subject matter  then we
could use this classifier on test examples to guess subject matter  as a more advanced step  we would use topic modeling 
this would allow us to organically pick song topics  and judge song success based on them  we would use this more
complicated metric to replace the indicator variables in the feature map referring to subject matter of the song 
another approach to deriving features from the lyrics of the songs we thought of is to perform sentiment analysis on
the lyrics themselves  similar to how analysis is done on tweets from twitter  the sentiment analysis would analyze the
mood of the songs  e g  happy  neutral  sad  or angry  and could possibly be paired with tempo   time signature   key
data to get an even better estimate  both the sentiment and topic of songs are similar conceptually to pre defined genres
for the song  so they would likely prove indicative of success just as genre is 

 

references
    echonest  echonest api  oct       url  http   developer echonest com docs v 
    thierry bertin mahieux  daniel p w  ellis  brian whitman  and paul lamere  the million song dataset  in
proceedings of the   th international society for music information retrieval conference  ismir             

 

fi