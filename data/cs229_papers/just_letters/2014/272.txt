cs    final report   machine learning madness
elliot chanen  john gold
december     

 

introduction

difficult to predict every game correctly  but
people continue to research and try their best 
last year  warren buffett offered a one billion dollar prize to any person s  who could
correctly predict the outcome of the tournament  no one was able to claim the prize 
we hope to create a model which best allows
us to fight for that prize 

march madness is the ncaa mens division i basketball championship tournament
that happens every march  the tournament 
organized by the national collegiate athletic association  ncaa   was founded in
     by the national association of basketball coaches  it started as an   team single
elimination tournament and has since been
expanded  most notably to    teams in      
as the tournament has grown  so has its national popularity  march madness has become one of the most famous annual sporting events in the united states  partially because of its enormous television contract with
cbs  but mainly because of march madness
pools  for years fans have been entering
gambling related contests to see who can predict the tournament most correctly  some
people have even gone as far as saying that
filling out a tournament bracket has become a
national pastime  even president obama 
famously  fills out a bracket every year 
ignoring the four play in games  which is
done in most pools   there is a    team pool
which means there are       or     quintillion
possible brackets  needless to say it is very

 

data

we used data from two main sources 
sports reference com and kenpom com  both
of which track college basketball statistics 
the data is organized by division   team 
and has seasonal statistics in many categories  sports reference has basic information such as wins  losses  rebounds  points
scored  points allowed  and so on  kenpom
was created by a statistician  and uses propietrary stats built from other factors  such as
offensive and defensive efficiency  that try to
represent teams more wholistically  there
was a march madness kaggle competition and
they provided a nicely formatted list of regular season and tournament games from previous years which we used as well 
 

fi 

features

 

models

we were faced with a classification problem  a binary decision of win or loseleveraged
the python library scikit learn to run our
regression and support vector machine models  we defined our training data as the regular season games  of which there are roughly
      each season  and the test data were
the    tournament games  for development
we used cross validation on our training set 
splitting the season into ten different buckets
and training on nine while holding out the
last for testing 

there are many statistics compiled for every basketball game  so it was difficult to decide which ones to use  one of the simplest
but most useful factors we could think of was
average margin of victory  generally  the better teams will win more games  and specifically win those games by more points  another feature we used was shooting percentage  and this statistic can get at two important factors of the game  primarily  teams
with a higher shooting percentage have better players  and secondly  it can be explained
by taking more open shots which is a proxy
for ball movement  a feature we wanted to
include but has limited statistical data  we
ended up compling    different features of
each team  so our initial input vector was
in r   because their are two teams for each
game 

 

results

the structure of the ncaa tournament is
a    team bracket  split up into   groups of
    each team is then seeded based on the
tournament committees exhaustive selection
process  the committee gauges teams based
on wins and losses  success in conference play 
success in tournaments  and an overall assessment based on players  coaching  and program tradition  called the eye test  we use
a baseline of the percentage of higher seeds
 favorites  that win their games  depending on the year  the higher seeds have won
between     and     of their games  with
an average of     since       below we
have a graph containing the baseline  and
our models using the sports reference data 

however  we wrote a script for feature selection and it turned out some of the statistics
were largely irrelevant and did not change our
classifiers enough to make a difference  additionally  we found that the same subset of
features was not optimal for both the support vector machine and logistic regression 
so there was tuning there as well  in the end
we used seven basic statistics from the sports
reference data for the logistic regression  and
just three for the support vector machine 
for the kenpom data  we used a five dimensional feature vector for each team  and kept
those features consistent for both models 
 

fi 
   

discussion
overall

we ran our algorithm over multiple seasons
of data and tried many different features  after initially beginning with    features we ran
some tests to prune out with ones were either
ineffective or adding noise  we narrowed it
down to   key statistics  but svm had a lot of
variance and turned out to overfit  performing very well on the training data but poorly
on the test set  logistic regression was more
effective and consistent  using a data aggregation source helped our svm model  but
slightly decreased performance for the logistic regression  we feel confident in the results  and will be constructing our brackets
this spring with the help of our program 
these next two tables are our aggregated
results over multiple seasons  with both models  data sources  and training testing data 

the red line  which is our logistic regression model generally performs better than the
baseline  although not by much  we were
having some over fitting issues with the svm
model previously  but we adjusted the features and saw a noticeable improvement so
that the scores are roughly on par with the
baseline 
below we have our results using the statistics from kenpom com to train our model 

sports reference
training data
test data

lr svm
         
         

we initally had a problem of overfitting 
and our accuracy on the training data scores
were much higher than the test set  we corrected for this by emphasizing the strength of
schedule feature  previously the in season results were skewed by dominant teams in small
conferences having trouble when they faced
this graph is similar to the previous one  medium skill teams from the bigger conferalthough we generally perform worse using ences 
the svm which was unexpected  our unken pom
lr svm
derstanding of theses statistics is that they
training data          
would capture more of the underlying truth
test data
         
that is a teams skill 
 

fi   

 

example bracket

conclusion

we believe our discussion can be enalthough we did not achieve substantial
hanced by a specific tournament example  improvments from the baseline  we were consistently in a similar range  often performing
slightly better  in this case  we believe that
even getting to the baseline is an accomplishment  because those rankings are choosen by
people who watch hundreds of games a season 

 

future work

there are a couple more things we would
have liked to try given more time  mainly
testing different features and algorithms 
there are novel features such as distance
traveled and past season performance  as well
as player by player data that we did not have
access to  another big factor in sports is injuries  and right now we have no way to quantify the effect on a team if a player got hurt
before the tournament started  we would
also like to experiment with regularization
and other machine learning libraries 

there are a couple interesting things to
note when we looked at where our results
were coming from  the bracket has looked
like this     teams   since       and in those
almost    years  there has never been a   
seeded team that won against a   seed  however  our model predicts this will happen  in
the theme of picking upsets  we also choose
three of the four    seeds to win their first
round game  this has only ever happened
  times  although one of those upsets did
happen in this tournament and we correctly
predicted it  florida gulf coast   fgcu  
our picks seemed to get worse as the tournament progressed  which we believe is due to
the increased concentration of roughly equal
teams  our model became less confident in
the choices as the weaker teams were eliminated 
 

fi