predicting paper quality in the biological sciences
matthew denton  mdenton   jose hernandez  josehdz   debnil sur  debnil 

abstract
predicting the success of a paper is an important problem in the growing eld of bibliometrics and one with relevance to researchers  journals  and academic institutions  an accurate
predictor of a paper s citation count would enable better academic indexing and expedite
the research process  in this paper  we investigate the following question  given data about a
paper in the biological sciences  can we predict its citation count  we use a paper s journal
impact factor  author history  topic  age  and number of references  to build a classifer  we
use supervised and unsupervised learning techniques  including latent dirichlet allocation 
softmax logistic regression  support vector machines  cross validation  and grid search  the
method accurately classied     of testing data into a bucket of citation counts modeling its
impact  feature analysis demonstrated that age  author history  and references most strongly
inuenced a paper s eventual success  topic clustering had lower accuracy than analysis of
the entire data set  suggesting the strength of interdisciplinary research in biology 

  introduction
    motivation
an article s citations are considered a measure of the scientic recognition the study has received
and thus indicate its value and impact on the scientic eld      researchers commonly aim to publish articles that will attract citations and thus be regarded to have a high scientic impact  as this
may be associated with career advancement      similarly  citations are the main factor determining
a journal s scientic impact  denoted by the journal impact factor      accurately predicting citation
counts  then  helps institutions better understand what determines a paper s ultimate success and
provides guidance for funding allocation  enables researchers to more eectively publish their work 
and generally creates more ecient research processes by nding papers likely to succeed 

    past work
previous studies have considered the correlation of factors intrinsic to a paper  such as its age 
journal impact factor  and author history  with its eventual success  though holistically performed
in other subjects  such as chemistry or the environmental sciences  bibliometric studies of biomedical and life sciences literature have not used the repository of open access journals to perform a
similar analysis        instead  they focus on specic topics or regions  which removes the potential
for comparative analysis and results in smaller data sets that sacrice robustness          

    our work
our research has three major design advantages over previous bibliometric studies in biology 
scale  as mentioned  prior studies utilized a small data set  on the order of        papers  this
prevents the generalization of ndings for meaningful predictions  the advent of open access publication has meant that data no longer bottlenecks statistical analysis as in older papers      utilizing
the pubmed central database provides over a million journals for feature analysis  this helps
understand general trends in biology  as opposed to specic elds  in particular  scholars can see
if a particular feature especially inuences citation counts in general and in topics 
 

ficlassication  previous studies used a regression based approach to predict specic citation
counts of papers         instead of predicting citation counts  we classify a paper s impact into one
of a group of buckets based on citation count  a paper with       or   citations has not had a
wide impact  and one with    or     citations is being cited a signicant amount  accordingly 
we still quantify the impact of a paper while eliminating sources of skew  a larger sample lets us
better classify papers into individual buckets and increases the robustness of our ndings 
topic analysis  rather than handpicking topics from certain journals or subjects  we utilize a
version of latent dirichlet allocation called scireader  written by the pritchard lab in the stanford
school of medicine  unpublished   given a paper s full text  this algorithm returns the probability
that a paper is in one of     topics in the biological sciences  using this  we can see how topical
clustering aects the prediction of citation counts for biomedical and life sciences literature 

  dataset
we utilized the open access subset of pubmed central  a database of biomedical and life sciences
journal literature      the subset as a whole contains     million journals  and we used a sample
of        articles  for a given paper  the database provides publication date  information about
authors  journal  and references  and the abstract and full text  we found the journal impact
factor of each paper through citefactor       we excluded journals lacking an impact factor 
which decreased to        samples  the pmc web service helped us nd a paper s citation count
and the career citation count of the paper s principal investigator      the features for each paper
were as follows  paper age  journal impact factor  number of authors  number of pi citations  and
number of references  after analyzing the entire data set  the scireader algorithm assigned a topic
number to each paper  techniques were then run within each topic 

  methodology and results
    initial classication
      softmax
the softmax approach generalizes logistic regression for classication problems where y   f         kg 
each representing a dierent category that the hypothesis function can select  specically  the
hypothesis will estimate p y   ijx     for every value of i            k  for our preliminary models 
papers were assigned a citation count bucket number y   f          g  where y     represented     
                         we chose the buckets with two criteria in mind  papers in the same bucket
have similar impact  and each bucket has enough samples  inspection of the data set indicated
that many papers had very few citations  while few papers had very many  thus  the choice of
citation counts generate buckets of a signicant number of papers with similar impacts  each
bucket had adequate samples for analysis  ranging from y     with        samples  to y     with
       samples 
the softmax regression  run with       and        papers  had training and testing accuracies
clustered around       since the training accuracy is too low  softmax regression is likely optimizing the wrong function  indicating that our data may not be linearly separable 
      support vector classier
since our data may not be linearly separable  we continued with
a one vs one scheme multi class svm classier  which used a
gaussian kernel  we varied our sample size and separated our
training and testing data with a       random split to analyze
the behavior of the training and testing accuracies  our svm
aimed to optimize the function on the right  with c     
       and m  sample size 
 

fi      results
sample size test accuracy train accuracy
     
     
     
      
     
     
      
     
     
      
     
     
      
     
     
       
     
     
table    as the sample size increased  the
training accuracy decreases at a slower rate
than the testing accuracy increases 

figure    shows the confusion matrix
for the testing data for the    k model

the svm performed consistently better than softmax  training accuracies are asymptotically
approaching      table     however  the quick increase of test accuracy suggests that more data
may see continued increase  the disparity between the training and testing accuracy  indicating
high variance  suggests that we may need either more data or a dierent set of features 
the confusion matrix  for the testing data  shows that most samples for each class were classied
correctly  misclassication tends to predict a lower class  likely due to the data s left skew 
to explore this high variance  we ran the svm classier on four of the ve features  because a
smaller set of features might improve our accuracy  additionally  we used principal component
analysis  pca  to project our data to four principal component vectors 
trial
  k  train 
  k  test 
   k  train 
   k  test 

 pi citation count    authors  journal if  age    references pca
     
     
     
     
     
     
     
     
     
     
     
     
     
    

     
     

     
     

     
     

     
     

table    training and testing accuracies for modeling using one step of backwards
indicated by  feature  and pca to project data to four components 

     
     

search 

    additional techniques
      latent dirichlet allocation
latent dirichlet allocation  lda   a generative model for
natural language processing  allows sets of observations
to be explained by unobserved groups  these groups  in turn 
explain similarities between parts of the data       if it observes
words collected into documents  it posits each document as a
mixture of a small number of topics and attributes each word s
creation to one such topic  shown on right   we utilized a
version of the algorithm that assigns a given paper the
probability it appears in     dierent biology topics  we then
assigned each paper to the topic that it most likely belonged to
and ran the above classication methods in each topic 
      validation and model selection
to cross validate  we placed     of the data into   dierent folds  using every combination of  
folds to train   dierent models  we then chose the model that performed best on the odd fold out
and tested it on the remaining     of our data  because of computational and time limitations 
we only utilized this method on the smaller sized clusters to add robustness 
 

fiwe also used grid search to improve model selection  some parameters of the model  such as choice
of the constants c    and the kernel function in svm  are not selected by training but rather are
design decisions  grid search tries every possible combination of these parameters and trains each
model separately  using   fold cross validation accuracy as a scoring mechanism  we then chose
the model with the highest accuracy 
softmax grid searched over the combinations of the following parameter values  penalty function 
l  and l   and c                      svm chose the following parameters for the gaussian kernel 
 used   points on a logarithmic scale from     to      c                  
      results
method
test accuracy train accuracy
softmax
     
     
softmax  cv 
     
     
softmax  gs 
     
     
svmc
     
     
svmc  cv 
     
     
svmc  gs 
     
     
table    average topic accuracy  weighted by
sample size per topic   cv  indicates crossvalidation   gs  indicates grid search 

the numbers displayed on the left are the average
accuracy between samples weighted by the number
of papers per topic  note that disparities exist
between topics in accuracy  highest accuracies were 
for svmc      train     test and  for softmax 
    train     test  lowest accuracies were for svmc
    train     test and  for softmax      train    
test  cross validation and grid search slightly helped
training accuracy 

  discussion
predicting article citation counts helps explain dynamics of academia  previous bibliometric studies
use small data sets  utilize regression to predict specic counts  and handpick certain topics  this
research provided a novel method to estimate the citation count of biological sciences literature 
the method accurately classied     of papers into a bucket of citation counts  modeling impact 
it utilized a data set of unprecedented size in biological bibliometrics  approached it using classication  not regression  and understood the impact of topical clustering on classication accuracy 
feature analysis helps demonstrate which features more signicantly determine accuracy  principal
component analysis lowered training and testing scores  suggesting that no pairs of our features
have a strong linear relationship  additionally  a step of backwards search showed that the paper s
age  pi career citation count  and number of references strongly indicate classication  removing
features showed that the other two features  journal impact factor and number of authors  are not
strong class indicators  because testing accuracy remained near the original model s  since pca
indicated no strong linear relationship between these two features and the others  they likely were
independent features and did not signicantly aect the model  this suggests that at least within
biology  neither the reputation of the journal  as measured by impact factor  nor the number of
authors signicantly impacts a paper s citation count  two signicant ndings in bibliometrics 
these tests also suggest that we may benet from changing our features  because removing features
didn t help the testing accuracy converge  more data is required to optimize the svm classier 
interestingly  topic clustering did not improve classication test or train accuracy  in reality  there
was a     decrease in testing accuracy from the entire data set to average of the topic based
models  even in the largest topic  with around      training examples  testing accuracy was only
        less accurate than running our original model on      samples  this suggests that topic
clustering did not help build a better model  because it should group papers within similar circles
of academic research and activity and therefore provide better accuracy  one potential implication
is that there may be a large number of interdisciplinary work between biological topics  even if one
topic has signicantly more papers  citing work in other topics would somewhat evenly distribute
citations across topics  more research is needed in examining links between topics to understand
this distribution  however  more papers in each topic may improve model accuracy  since there
are     topics and only about        papers in our nal data set  the vast majority of topics only
had a few hundred papers  consequently  though test error was high  larger data sets increased
the model s accuracy over the entire data set  and signicantly increasing the number of papers in
each topic may have a similar eect 
 

fifinally  note that even though we used previous years for feature data and age as an input variable 
the model can still be used for prediction  because the paper s age is given to the model  to predict
the number of citations of a newly published paper in x years  we can input x as the paper age 
additionally  other variable feature data  such as the principal investigator s career citation count 
will only increase into the future  so at worst  our model generates a lower bound for paper
performance 

  future work
generally  more data will increase the robustness of our ndings and potentially create a more
accurate classier  notice that as the size of training data increased when using the svm classier 
testing accuracy increased faster than training accuracy decreased and never converged  more
papers would thus help build a better classier over the entire data set and within each topic 
changing features may also benet the model s accuracy  characteristics of the paper s form 
like its syntactical structure  active versus passive voice   paper length  and number of images 
could all inuence citation      additionally  other common bibliometric methods could be used 
an example is the h index  a quantication based on the set of the scientist s most cited papers
and the number of citations received in other publications      furthermore  some quantication of the author s institution s reputation may provide interesting results  the output variable
could also be changed  rather than counting immediate or primary citing papers  we could also
count secondary citations that cite primary papers  and determine some heuristic to combine
this with primary citation count 
finally  in response to the seeming ineectiveness of topics  social network analysis could help
understand the relationships between papers of dierent subjects  this would demonstrate which
topics are strongly related and thus nd the most popular subjects for interdisciplinary research 

  references
   cheek j  garnham b  quan j        what s in a number  issues in providing evidence of impact and quality
of research ers   qual health res             doi                          
   falagas me  zarkali a  karageorgopoulos de  bardakas v  mavros mn        the impact of article length on
the number of future citations  a bibliometric analysis of general medicine journals  plos one       e      
doi         journal pone        
   gareld e        how can impact factors be improved  bmj              doi          bmj             
   willis dl  bahler cd  neuberger mm  dahm p        predictors of citations in the urological literature  bju
int                doi          j         x            x
   van raan a        comparison of the hirsch index with standard bibliometric indicators and with peer judgment
for     chemistry research groups  scientometrics               doi          s                
   kulkarni av  busse jw  shams i        characteristics associated with citation rate of the medical literature 
plos one    e     doi          journal pone        
   filion kb  pless ib        factors related to the frequency of citation of epidemiologic publications  epidemiol
perspect innov       doi                       
   bhandari m  busse j  devereaux pj  montori vm  swiontkowski m  et al         factors associated with citation
rates in the orthopedic literature  can j surg            
   europe pubmed central  ebi europe pmc web service        online 
    citefactor       impact factor list  online 
    blei d  ng a  jordan m        latent dirichlet allocation  ml research        p           
doi         jmlr               

 

fi