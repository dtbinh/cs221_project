domain specific sentiment analysis using cross domain data
marcello hasegawa and praveen rokkam
abstract
sentiment analysis is a tool used to guide critical
business and engineering decisions  such applications
demand sentiment analysis specialized in specific domain areas  in this work we investigate the effectiveness of standard machine learning techniques and feature engineering that can effectively be applied in the
industry  further we investigate the use of labeled data
from multiple domain areas to improve the results in a
specific domain area in a product review setting  finally
we propose a method based on dimensionality reduction
and clustering to reduce the size of the problem without
loss in performance 

industry applications where quality  specific scenarios
and ease of implementation are constraints  in this work
we consider four different domain areas in product reviews 
a common assumption in machine learning is that
the training data is drawn from the same distribution
as the unseen test data  in this work  we will explore
the assumption that the features we employ for product
reviews sentiment classification  in different domains 
come from similar distributions  within this context 
we explore two ways of leveraging out of domain data
for model training  particularly we propose a method
to reduce the amount of necessary training data when
augmenting the training set with out of domain data by
the use dimensionality reduction and clustering 

   introduction

   data description

sentiment analysis is a well established tool in the
industry  besides consumer applications  sentiment
analysis has place among various applications in companies which have been using it as a tool to guide critical business and engineering decisions      such applications demand sentiment analysis specialized in specific domain areas  in this work we explore domain
specific sentiment analysis 
the goal of sentiment analysis is to quantify positivity or negativity from subjective text data  positivity
or negativity can be expressed as a range of discrete values or polarity  polarity typically is expressed as positive  neutral or negative  further  sentiment analysis
can be scoped around documents  sentences or target
particular aspects in text  in this work we address the
problem of detecting sentiment in product reviews  this
particular application restricts the problem to short text
cases  in addition we consider only positive and negative sentiment removing possible ambiguities from neutral reviews  typically sentiment analysis is approached
through the use of sentiment lexicons or as an nlp and
statistical classification problem      we rely on the
later approach 
while the state of the art research have been pushing the performance in sentiment classification  simpler
techniques yielding good results are of great value for

we use the multi domain sentiment dataset  version           this dataset is a five star rating product
review dataset from amazon com  the dataset contains
multiple domains where each domain is a product area 
in this work we considered four domains  apparel  music  video and electronics   each domain was separated
into positive and negative sentiment reviews  ratings
one and two were considered negative labels and ratings four and five were considered positive labels  we
disregarded reviews with rating three  column two of
table   shows the dataset sizes for each domain  both
positive and negative labels are approximately balanced
within the domains 

   model description
     learning algorithm
linear models are known to perform well with bagof words features on text  we considered support vector
machine  svm  with a linear kernel and regularized logistic regression models      we chose the regularized
logistic regression model as it has lower computational
cost for large number of features and had a better performance on prediction accuracy and f scores  optimal

fitable    training set sizes
domain
electronics
apparel
music
video

baseline
     
     
     
     

  increase  cross domain
    
    
    
    

parameters for the models were chosen via parameter
sweep and ten fold crossvalidation  for logistic regression we considered a range of regularization coefficients
and both l  and l  norms  l  regularized logistic regression performed better 

  increase  cluster selection
    
    
    
    

cluster selection reduction gain
     
     
     
     

across most domains but with the cost of significantly
increasing number of features and data volume resulting in a high computational cost  in order to reduce this
problem we focused in adding data to the training set
selectively while still aiming good performance by exploring similarities on the data 

     features
the traditional bag of words feature modeling approach typically employs n grams and skip grams  a
number of publications reported good results using bigrams for sentiment classification  we obtained better
results using both 
 one grams  bi grams and tri grams combined for
review title and text body 
 one grams of pos tags for text body 
all features were treated to limit sparsity problems 
these features result in high dimension feature spaces
proportional to the size of the vocabulary  column two
of table   shows the feature set sizes for different domains 

   data selection
     in domain baseline
we start with baseline models trained solely on
the datasets corresponding to each individual target domain 

     cross domain
in order to achieve better performance we add outof domain data to the target domain training set  the
approach consist in splitting the data for one particular domain into training and test sets  to the training
set we add the entire datasets from the other domains 
the model is evaluated on the test set extracted from
the target domain only  this approach resulted in satisfactory improvement to the classification performance

     cluster selection

a previous work proposes a method to measure
similarities among domains      the work describes the
use of labeled data from similar domains to adapt classifiers from one domain to another  we propose the use
of similar data extracted from several domains simultaneously to enrich the target domain training set in a
selectively way  to identify similar data we project onegram features generated across all domains into a lower
dimensional space by use of latent semantic analysis
 lsa       we retain a smaller number of dimensions m
and the resulting vectors in this space are clustered using k means clustering      the input data is the target
domain data plus the out of domain data  once a cluster
has been assigned to each data observation  the method
compute the cluster assignment frequencies within the
target domain only  the clusters are ordered in decreasing order of frequency  and the first n clusters are selected  the out of domain observations that were assigned to these same clusters are added to the target domain training data  the parameters to be adjusted are
the total number of clusters k  the number of lsa dimensions m and the number of clusters to be retained n 
the algorithm   illustrates the method  in algorithm   
i is the target domain data and o is the out of domain
data  the procedure frequentclusters receives the cluster assignments corresponding to the target domain data
i and return the most frequent clusters in decreasing order of frequency  the procedure selectdata receives the
out of domain data o and select all observations whose
cluster assignments were the top n most frequent clusters found in the target domain data 

fitable    feature set sizes
domain
electronics
apparel
music
video

baseline
      
      
      
      

  increase  cross domain
    
    
    
    

algorithm   cluster selection
   procedure s elect data  i o k m n 
  
features    generatefeatures i   o 
  
pro jected    lsa features 
  
clustered    kmeans pro jected     m   k 
  
 c         ck      frequentclusters clustered i  
  
selected    selectdata o   c         cn   
  
return i   selected
   end procedure

   results
table   shows the accuracy and f scores for models trained on the baseline in domain datasets  the crossdomain enriched training datasets using all data available and the data selected training sets using the clusterselection algorithm described in the previous section 

     sentiment classification
each domain was individually tuned for performance using simple crossvalidation  the apparel domain resulted in the best accuracy         whereas the
music domain displayed the lowest accuracy        
combining all the domains to the target domain
boosted performance  for electronics  accuracy increased       increases in performance were evident
in apparel and the video domains as well  for music 
we observed a decrease in performance with a drop of
     in accuracy  the average increase across all domains was      showing that the method can help improve the results 

     problem size reduction
despite the gain in performance  adding out ofdomain data to the training set results in larger number of features as the vocabulary increases  this comes
with a cost in feature generation time and model training time  to illustrate this  when adding out of domain
data  the electronics domain sees an increase of     

  increase  cluster selection
   
    
   
   

cluster selection reduction gain
     
     
     
     

in training set size  table     across all domains  the
average increase in training set size was       regarding number of features  the electronics domain had an
increase of       table     the average increase in feature set size across all domains was       a detailed
view is presented in tables   and   
the cluster selection algorithm reduced training
and feature set sizes considerably  for instance  in
the electronics domain we saw decreases of      in
the training set size and      in the feature set size
when compared to cross domain numbers  when using cluster selection  the average decrease in training
set size was      and the average decrease in feature
set size was      

   discussion
the cluster selection approach described in     was
able to reduce the number of features while keeping
comparable performance to the cross domain approach
where we simply add all data available from other domains  the cluster selection improved the performance
with respect to the baseline for three of the domains 
the exception was apparel  the accuracy obtained for
this particular domain was     higher in average than
the accuracy for other domains and it seems this result
is nearing the limits imposed by the model and features
we are considering 
the advantages of cluster selection is the reduction
of the number of features  its cost overhead for the domains considered was limited to a maximum of       
features to be projected into a lower dimensional space
through lsa  the computational overhead  besides the
svd decomposition cost  includes    starts of the kmeans algorithm  for the current problem we found
this cost to be negligible compared to the cost of running the full model  we believe a problem with a much
larger dataset and larger number of features could benefit from this approach were the advantage of the reduction of memory resources outweighs the computational
cost overhead 
while working in obtaining the best baseline num 

fitable    accuracy and f scores
domain
electronics

apparel

music

video

training data
in domain
cross domain
cluster selection
in domain
cross domain
cluster selection
in domain
cross domain
cluster selection
in domain
cross domain
cluster selection

bers we explored a number of approaches using ngrams  particularly we found that not all approaches are
best suited to the different domains  for instance  while
fine tuning the feature selection for the domain electronics  we found that one grams could hurt the performance of the model in the presence of the words hard
drive  while in other domains hard is negative  for
this case it is neutral 
in this work we also investigated a few other approaches to extend the available features  particularly
we found that adjectives and adverbs obtained from
pos tagging doesnt add much value when compared
to the n gram approach we adopted  although with
little gain  we concluded that the one gram pos tagging feature counts we employed helps in certain cases
to little computational cost  two promising areas in
which we did little investigation was the use of topic
features through latent dirichlet allocation  lda     
and features enrichment with sentiwordnet      lda
didnt performed better than n grams for this particular
problem  we believe lda can be particularly useful
in longer text sentiment classification problems  sentiwordnet features had a neutral effect on the models
and we believe a better tuning could have yielded good
results but we decided to scope out this approach given
the good performance with simpler features 

   conclusions
we have obtained good results in classifying sentiment from product reviews using standard machine
learning techniques  further we explored the use of
aditional out of domain data to improve the initial results  adding data from diverse domains increased the
training set size and the vocabulary size resulting in a

accuracy
     
     
     
     
     
     
     
     
     
     
     
     

f score    
     
     
     
     
     
     
     
     
     
     
     
     

f score    
     
     
     
     
     
     
     
     
     
     
     
     

much large number of features  we devised an algorithm which reduced the number of features in average
by      while maintaing the performance of the bruteforce approach of employing all out of domain data 

references
    ronen f  techniques and applications for sentiment
analysis  communications of the acm  vol     no    
pages       
    pang  b   lee  l  foundations and trends in information
retrieval         pp             
    http   www cs jhu edu  mdredze datasets sentiment 
    blitzer  j   dredze  m   pereira  f  biographies  bollywood  boom boxes and blenders  domain adaptation
for sentiment classification  association of computational linguistics  acl        
    landauer  t  k   dumais  s  t  a solution to platos
problem  the latent semantic analysis theory of acquisition  induction  and representation of knowledge  psychological review                   
    hastie  t   tibshirani  r   friedman  j  the elements of
statistical learning  data mining  inference  and prediction  springer       
    blei  david m   ng  andrew y   jordan  michael i  lafferty  john  ed  latent dirichlet allocation  journal of
machine learning research         pp               
    http   sentiwordnet isti cnr it 

fi