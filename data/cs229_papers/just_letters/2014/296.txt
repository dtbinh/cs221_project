on the recognition of handwritten math equations
quan nguyen  maximillian wang  le cheng fan
december         

 
   

introduction
background

handwriting recognition is a classic machine learning problem that has led to extensive research and a
number of highly accurate solutions  some handwriting recognition algorithms are achieving near human
level performance 
we employ tools used in handwriting recognition to handwritten math equations  while typing is generally much faster than writing by hand  math equations have the opposite property  writing equations by hand
is more efficient than typesetting them  furthermore  whereas handwritten equations are human readable 
the code of typesetting languages are often highly nested and difficult to edit  these problems of typesetting present an opportunity for improving the workflow of writing math equations digitally  in addition 
recognizing mathematical equations is important for digitalizing past scientific works 

   

goals and outline

though typesetting equations is difficult  storing equations in typeset form allows for concise storage that
is relatively flexible for future editing  since latexis the most popular typesetting tool  our teams longterm goal is to produce a system to recognize images of handwritten equations and output the corresponding
characters in latex  under the given time constraints  building the full system is infeasible  so our team chose
a more reasonable goal of constructing a system for recognizing individual math symbols  with the possibility
of building some functionality necessary to recognize multi symbol expression  in the next section  we discuss
the data collection process to obtain a wide array of characters  afterward  we discuss preprocessing and
algorithmic methods used to implement the system  finally  we discuss our results and compare each of the
different approaches we took 

 
   

methods
process

we run all of our images for both training and testing through a sequence of steps in order to improve the
effectiveness of the system as a whole 
we begin by reading in each image and preprocessing it as outlined below in order to reduce the variation
between different examples  this allows the system to create a much clearer picture of the distinctions
between different labels  the next step is to detect features in the images and place them in a feature vector 
finally  we train and test several different machine learning models on our generated features 
we use a pipeline analysis approach in our research  since our system consists of a series of separate
steps  the overall performance is affected by several factors  at each step of the process  we compare different
methods used for preprocessing  feature detection  and learning  in doing so  we can achieve a more complete
understanding of how each step affects the system   see figure   

 

fifigure    pipeline steps

   

software

our main tool for performing all preprocessing  feature detection  and learning algorithms is the opencv
library for c    this software package includes utilities for every computer vision and machine learning
functionality that we require for this project 

   

data set

all the training and testing data we use are handwritten greek letters produced in photoshop with varied
brush sizes and hardness values  the dataset consists of    x    grayscale images of the following letters 
            and   there are     images of each greek letter  and hold out cross validation is used to
separate the data set into training testing sets and to compare training and generalization error 
in order to reduce variations between images  we implement two different preprocessing techniques  in
m  
the first method  we calculate the centroid   x  y   of the image via moments  these are given by x  
m  
m  
and y  
  where
m  
    x
   
x
mpq  
xp  y q  imageintensity x  y  
x   y  

once we find the centroid  we then translate the entire image inside the    x    square such that the centroid
lies on the center of the image  namely at           this corrects for differences in symbol positioning in the
hand drawn images 
our second technique is to eliminate as much background white space in the image as possible  this is
done by drawing a bounding box around the actual symbol  and then expanding that section of the image to
fill the entire square  the technique corrects for size differences in each image  it also adjusts for positioning
since the end result is tightly snug in the    x    square  since the centroid of the original image is generally
not the same as the centroid of the blown up image  we only perform one of these preprocessing techniques at
a given time  we also run the system without preprocessing to see how the techniques affect the performance 
 see figure   

   

feature detection

we compare two different types of feature vectors for our learning models  the first is treating the grayscale
image as a matrix of pixel values  and then reformatting this matrix into a single row vector  this vector
thus encodes the each of the          pixel values of the image  the second type of feature detection
method we use is the harris operator for detecting corners in an image  we use an abstracted opencv
implementation which assigns a confidence level for each of the detected corners  and then returns a vector
of the coordinates of the k top scores  in our research  we compare the performance when using   corners   
corners  and raw pixel values 

 

fi a  original

 b  centered

 c  resized

figure    data set with preprocessing

 

models

we use three different learning algorithms in our project  support vector machines  k nearest neighbors 
and random forest  here we outline each of these algorithms 

   

support vector machine

a support vector machine attempts to find a hyperplane that divides training examples of two different types 
such that the distance between the plane and each of the training examples is maximized  when training
data is linearly separable  this hyperplane will perfectly divide the points into groups by label  however  in
most cases  data is not perfectly separable  so l  regularization is used  more precisely  find
max

m
x
i  

such that    i  c  i           m and

m
x

ai 

m
  x  i   j 
y y i j hx i  x j  i
  i j  

i y  i       and then calculating w as

m
x

i y  i  x i   

i  

i  

for our implementation  we tested a few different kernels for differences in performance  since the svm
is only used for binary classifications  the opencv implementation creates one svm for each pair of labels
in order to generalize the algorithm to multiclass situations  like our own research  

   

k nearest neighbors

the k nearest neighbors is a non parametric method which classifies a test data point by a majority vote
of the closest training example  by euclidean distance of feature vectors   given a test point  the algorithm
finds the k nearest neighbors to that point  and predicts the new points label as the mode of the labels of
the neighboring points  the algorithm breaks ties arbitrarily 

   

random forest

the random forest model bootstraps by selecting  with replacement  a random subset of the data for training
each new decision tree  bagging   furthermore  a random subset of the data is selected at each decision
point  in total     decision trees were constructed for our forest 

 

fi 

results and analysis

   

results

we found that the best performance came from a combination of either centering or resizing  raw pixel value
features  and a support vector machine model  figure   below shows our results when using a linear kernel 
we were later able to achieve slightly better results using a degree   polynomial kernel  yielding approximately      generalization error rate when centering the images and using raw pixel values  other kernel
types  such as radial basis function and higher order polynomials  performed significantly worse due to overfitting  as shown by a training error of    and generalization error of greater than      we also found
that the use of centering and resizing did not yield significantly different results  although they both were
significantly more effective than no preprocessing  in addition  the corner detection method produced very
high error rates  proving infeasible for our desired application 

 a  comparison of feature detection  with centering 

 b  comparison of preprocessing  with pixel detection

figure    comparison of results

   

analysis

our results were somewhat unexpected  we had hypothesized that the corner detection method would yield
features that were more unique to each symbol  and would therefore be more effective at classifying them 
our results disagreed with this hypothesis  we believe that the high error rate associated with the corner
detection method is due to the relatively low dimension of the feature space  meaning that less information
is encoded in the feature vectors  in addition  the corner detection technique is sensitive to individual
handwriting habits  while the dark pixels will generally occur in a similar pattern when preprocessed  the
corners detected depend strongly on where the writer draws a rounded edge or a pointed one 
while initial efforts were funneled toward testing different types of learning algorithms  the most significant
results came from preprocessing  figure     using the centered or resized images increased all algorithms
to at least acceptable performance  it is interesting to observe that the relative difference between each the
algorithms remained approximately constant  knn had about twice the error rate for un processed  resized 
and centered images  preprocessing decreases noise in the data due to variations in different positions and
symbol sizes 
lastly  the training and testing error curves for the different models  figure    show that our choice of
   training examples is sufficient  and that adding more training examples will not decrease generalization
error significantly  the curve shows that training and testing error converge past    training examples for
both svm and rf  the small difference between training and testing error         and the low training
error for svm  also implies that both bias and variance are low  we cannot do much better by generating a
larger training set  so we must look elsewhere for improvements 

 

fi a  testing and training error

figure    comparison of results

 

future work

we will extend our framework to work for full handwritten math equations  the primary addition will be
a segmentation algorithm for dividing a full expression into individual symbols  which may be identified
using our current work  in addition  we hope to test our system on photographs taken of real handwriting
rather than photoshop drawings  we predict that this use case will require some additional pre processing
techniques  such as contrast boosting  to achieve current performance levels 
finally  we will further study neural networks as an option to outperform our other learning models 
we tested neural networks with all preprocessing and feature selection permutations during our research 
however  due to problems with overfitting  we did not achieve useful results  some successful preliminary
results have shown an error rate of    for   classes with a training set of    examples 

 

references

a  graves  et  al  a novel connectionist system for improved unconstrained handwriting recognition 
ieee transactions on pattern analysis and machine intelligence  vol      no          
ciresan  dan  ueli meier  and jurgen schmidhuber  multi column deep learning neural networks for
image classification   ieee conference on computer vision and pattern recognition                   
ieee  web 
hsu  chih wei  and chih jen lin  a comparison of methods for multiclass support vector machines  
ieee transactions on neural networks                       web 
knerr  s   l  personnaz  and g  dreyfus  single layer learning revisited  a stepwise procedure for
building and training a neural network springer                    web 
liu  cheng lin  kazuki nakashima  hiroshi sako  and hiromichi fujisawa  handwritten digit recognition  investigation of normalization and feature extraction techniques   pattern recognition              
        web 

 

fi