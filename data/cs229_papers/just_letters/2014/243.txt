 
lee  wang  and wong

cs          project

forecasting utilization in city bike share program
christina lee  david wang  adeline wong
  introduction
in this project  we use a variety of machine learning models to predict the number of bikes in use in a given
hour in a public city bike share program  bike share programs allow riders to check out a bike at one location and
deposit it at another  usually at an electronic bike station  these public bikes offer an alternative to providing
maintenance and security for a personal bike  and fit transportation niches including the last mile between public
transit termini and a commuter s final destination     
bike share systems have a relatively young history  whereas bicycles were invented in the early     s and
cars have been around since the late     s  bike share systems only came into existence in       bike share
systems and computing actually have an intertwined history  early bike share systems suffered from theft of the
bikes  so later systems evolved locks  as computing devices have grown smaller  it became possible to build
electronic bike stations that allowed users to check bikes out with a card and enforce the bike s return with a hefty
fine      such systems also enable tracking of bikes  movements  and modern bikes are even equipped with gps 
which can allow fine grained tracking of bikes and rider habits 
we think this is a cool project because while the mechanics of bike sharing are simple  the individual rider
choice and the movements of bikes during a day allow room for a great deal of complexity  machine learning is the
tool of choice when working with problems that are either too complex for a human to comprehend or are infeasible
to program by hand  and it seems an appropriate tool to apply to the prediction of bike demand over time  in
addition  the relative newness of bike share systems and their steadily growing popularity make this an interesting
problem from a practical perspective  we hope that the results of this study will help bike share program managers
better design models to predict utilization  which could inform decisions such as when to perform maintenance and
when and reallocate bikes within the system without affecting customer satisfaction with bike availability 
  dataset
the data used for this project comes via the kaggle contest bike sharing demand  kaggle dataset from
     from capital bikeshare  based in the washington  d c   metro area  capital bikeshare began operations in
september      with     bicycles at    stations and by september       had grown to       bikes at     stations
    
the kaggle data spans the two years from january         to december           for the purposes of the
competition  in addition to training data  there was a standardized  unlabeled test set provided to all contestants  the
training data covers the first    days of each month  and the test data covers of the remaining ten or eleven days 
the test data consists        data points  one for each hour  with    features  given below  the test set consists of
      data points with the same features 
field

description

datetime

hourly date and timestamp

season

   spring     summer     fall     winter

holiday

  if the given day is a holiday    otherwise

workingday

  if the given day is neither a holiday nor a weekend    otherwise

weather

   clear to partly cloudy     misty and or cloudy     light rain storm     heavy
rain snow storm   fog

temp

temperature in celsius

atemp

feels like temperature in celsius

humidity

relative humidity

windspeed

wind speed

fi 
lee  wang  and wong

cs          project
casual

number of bikes rented by non registered users

registered

number of bikes rented by registered users

count
total number of bikes rented
table    description of data fields 
  features and preprocessing
from the raw data  the following features were extracted  raw data was used as is for binary data  holiday 
workingday  and numeric data  temp  atemp  humidity  windspeed   categorical variables  season  hour of the day 
weather  were divided into multiple binary features  for example  instead of keeping season as a feature on its own 
there are three binary features  season     season     season     the season    feature is excluded because it is
determined by season     season     and season     and dependent variables can have deleterious effects on
machine learning models  the result is a total of    features  for this problem  the target variable is count  i e  total
number of bikes rented in a given hour  thus  the task at hand is a regression problem 
  models
the following models were used to predict bike utilization per hour 
poisson regression
we expected that utilization would depend on the weather buckets and hour buckets  so it makes sense to
run a general linear model regression on the various buckets  the poisson distribution is used for predicting the
number of events over time  and therefore seems to be an appropriate model for this problem  poisson distributions
are in the exponential family  so this model is a standard glm 
   neural network
the poisson regression model assumes that the variables are more or less independent  another way to
view the problem is throw at the problem a black box machine learning model that is able to capture complexity 
such as interacting variables  neural networks are good at recognizing these hidden patterns  hence our choice to
train a neural network  after trying a variety of parameters  the final neural network consisted of four hidden layers
   nodes in the first hidden layer    in the second hidden layer    in the third hidden layer  and    in the fourth
hidden layer   trained using the neuralnet r package and learning rate of       with resilient backpropagation
with weight backtracking 
the following are intermediate training and test results with increasingly complex models  the error
function used was root mean square log error  rmsle   which is explained in the following section 
  

model

       
train

        test

  

       

       

model

       
train

        test

  

       

       

model

       
train

        test

        

       

       

model

      train

      test

      train

      test

       train

        test

       

       

       

       

       

       

       

fi 
lee  wang  and wong

cs          project
model

      train

      test

      train

      test

        train         test

        

       

       

       

       

       

  

       

markov model
one of the more obvious patterns in this problem is that the data is cyclic  during weekdays  there are the
morning and evening rush hours  and on weekends  folks take joyrides and run errands in the afternoons  in contrast
to making no judgments about the data  a third way of viewing the problem is to try to capture in the model some of
the obvious cyclicness of user demand  to do so  we trained a set of markov models  one for each  working day or
non working day  hour  current weather  combination  in addition  bikes can be in one of two states  either checkedin or checked out  so the model captures state in four variables 
one of the strongest assumptions made by markov models is that the transition matrix does not change
over time  since this is obviously not true over the course of a day  for example  users checking bikes out to go to
work at   am and tend to be checking in bikes after arriving at work at    am  we model demand by bucketizing
by hour and giving each hour its own transition matrix  in figure   are graphs of average demand in the training set
and predicted on the test set 

fi 
lee  wang  and wong

cs          project

figure    the top figures are working days  and the bottom figures are weekends and holidays  on the left are
averages on the training data  while on the right are averages of predictions on the test set  the model was able to
broadly capture demand fluctuations  including the weekday morning and evening rush hours 
  results
to evaluate our predictions  we used root mean squared logarithmic error 

where pi is the value of prediction for the i th datapoint  and ai is the actual value  the metric is reasonable since the
error value grows larger as the log value of the ratio of the predictions and the actual values grow larger  the chart
below summarizes the errors for the various models we trained 
model

training error

test error

neural network

        

       

poisson regression

        

       

markov model

       

       

mean value benchmark 
        
       
 for reference purposes  predictions take the mean value of the training data 
in the kaggle competition  we are rank     out of       teams entered  the top score  lowest reported
error  is         
  discussion
qualitatively  we see that both neural network and poisson regression perform much better than the mean
value benchmark  neural network outperformed poisson regression quite significantly  this result was as expected 
we used poisson regression under the assumption that  given the nature of the problem  predicting number of users
given different factors   it would lend itself well to poisson regression  however  this means that if the distribution
does not follow a nicely poisson distribution  it would result in large errors  neural networks  on the other hand  are
a flexible model that are good at recognizing complex  non linear patterns that are not easily observable by humans
or other learning algorithms  it picked up on the patterns of the dataset and adapted itself 
the markov model had mixed results  while  it had a training error in around the same ballpark as the
neural network and poisson regression  its test error was worse than even the mean value benchmark  it appears that
the trained model overfit the training data  in an overfitting regime  it would be reasonable to reduce the number of
variables  however  this model already used many fewer variables than both the neural network and poisson
regression  which used the full set of    variables  variable reduction should probably come in the form of training
fewer trainsition matrices  perhaps one matrix for group of two or three consecutive hours would be an
improvement 
to better understand the performance of the models  keep in mind that this is a regression problem and we
are trying to predict the number of bikes in use  the baseline error  i e   we predict that the number of bikes checked
out is always the average over all training data points  is          an error of         means a     reduction in
error      times less error   the error of         means a     reduction in error  a   fold decrease  
  conclusion
as expected  neural networks were able to capture a great deal of subtlety in the data  surprisingly  the attempt to
capture transitions over time via the markov model had terrible performance 
  future

fi 
cs          project

lee  wang  and wong

there seems to be evidence that casual users and registered users have different usage patterns     it would
be interesting to look at that  another interesting problem would be to look at the interaction of different
transportation methods and bike share  for example  how does a metro strike affect the utilization of a bike share
program 
the feature space could also be expanded by using consecutive pairs of hours as data points  rather than
single hours  furthermore  the kaggle dataset is from only one bike share program  we would like to look at data
from different bike share systems as well  for instance  bay area bike share provides a similar dataset as the
capital bikeshare one  but is enhanced with the start time and station and end time and station fo each ride     
jcdecaux has a rich data set across many countries  but data is only accessible in real time via an api  presumably
the use case is for visualizations of bikes currently in the system and their precise locations      
another idea is to apply a recurrent neural network  that is  a neural network that allows cycles of
neurons  this effectively gives the neural network state  which can be thought of as a short term memory  which
could allow them to take into account cyclical variables  such as daily demand and seasonal changes  while the
upside is great  unfortunately  recurrent neural networks are a relatively new idea and training them has so far
proved challenging      the short term memory  in practice  tends to be short  so it is uncertain whether it would
even be able to capture a the    x   states required to learn weekly variations in bike demand  let alone the year long
variation due to weather 
finally  since the data comes from the early history of the bikeshare program  as it was ramping up  error
might be reduced by fitting a line on maximum daily demand  and scaling predicted usage based on the demand
capacity at that time in the program s history 
references
  
  
  
  

  
  

  

bike sharing system   n d    retrieved december           from
en wikipedia org wiki bicycle sharing system 
capital bikeshare   n d    retrieved december           from en wikipedia org wiki capital bikeshare 
fanaee t  h    gama  j         event labeling combining ensemble detectors and background knowledge 
progress in artificial intelligence                 
gebhard  k    noland  r         the impact of weather conditions on capital bikeshare trips  trb
     annual meeting  retrieved december          from
https   phillymotu files wordpress com         the impact of weather conditions on capital bikesharetrips pdf 
getting started   n d   retrieved october           from https   developer jcdecaux com   opendata vls 
page getstarted 
hinton  g  lecture    learning in recurrent networks  personal collection of geoffrey hinton  university
of toronto  toronto  retrieved december          from
http   www cs toronto edu  bonner courses     s csc    lectures lec  pdf 
open data callenge   n d   retrieved october           from
http   www bayareabikeshare com datachallenge 

fi