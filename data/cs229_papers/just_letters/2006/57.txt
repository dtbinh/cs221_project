computational beauty analysis
libby day and fawntia fowler

 

background

our project was a continuation of the recent research published by yael eisenthal  gideon dror 
and eytan ruppin entitled  facial attractiveness  beauty and the machine      the authors used
a variety of machine learning techniques to predict facial attractiveness ratings from photographs 
they had two data sets  each consisting of ninety two photographs of young  caucasian women  all
images in the first data set were taken by the same photographer under the same lighting conditions
and with the same orientation  these high resolution photographs were of americans with neutral
facial expressions who were wearing no glasses or jewelry  the second data set was of somewhat
lower quality  the women in these photographs were israelis  some of whom were wearing jewelry
or smiling with closed lips 
eisenthal  dror  and ruppin used two distinct representations of the womens faces  the feature
representation and the pixel representation  the feature representation consisted of distance measurements between feature landmarks on the face and ratios between these distances  examples of
feature landmarks include the centers of the pupils  the corners of the mouth  and the endpoints of
the eyebrows  all distances were normalized by the distance between pupils  additionally  average
hair color  skin color and skin smoothness values were included as part of the feature representation  the image representation was simply the original photograph converted to grayscale and
concatenated by columns to become a vector 
the authors of     used both classification and regression techniques  for classification  they
retained only the photographs with average attractiveness ratings in the top or bottom quartile 
they labeled these photos as attractive or unattractive accordingly  their best classification
results are summarized in fig     they attempted several kernels but found that a linear kernel
worked best for svm  they also tried k nearest neighbors  knn  
besides classification      used the regression version of svm to predict attractiveness ratings 
they were able to achieve a      correlation on a test set by combining the predictions from the
feature and pixel representations  but the feature representation alone performed nearly as well
with a     correlation  a very promising result was the shape of the learning curve   see fig 
   by extrapolation  it appears that significantly higher correlations can be achieved by using a
moderately larger data set  this expectation was a big motivator for this project  which leads to
our objective  to repeat the work of eisenthal  dror  and ruppin  but using a larger training set 

 

data collection

practically unlimited numbers of photos of young women rated according to attractiveness are
available on hotornot com  we received permission from hotornot to use their photos for our
project  we originally acquired     color photographs of women between the ages of    and
   with corresponding ratings from the hotornot web site  after sorting through more than a
thousand other photos that were deemed unusable due to poor resolution  poor lighting  bad angle 
et cetera   we ended up keeping about one in ten perused photographs in the end   initial selection
requirements were that both sides of the nose had to be in view  the woman had to be looking
reasonably straight ahead  and both eyes had to be visible  also  no pictures of women showing a
 

filot of skin were used  as this would likely bias the ratings   we avoided full body shots in general  
upon recording feature landmarks  we realized the need for being even more particular  and further
reduced the size of our data set to     photos  however  this is still more than twice the size of the
original dataset from     
all     photos were rotated so that the head was vertical and cropped around the face  we
recorded    feature landmark locations on each photo using a java applet we wrote that outputs
the coordinates of mouse clicks to a file  the    feature landmarks are shown in fig     they
include all the feature landmarks used in     and an additional four points  one on the arch of
each eyebrow and on the sides of the chin  another applet averaged the rgb color values of pixels
in a selected region  we used this applet to collect average hair  eyebrow  skin  eye  lip  and teeth
colors   in contrast  eisenthal  dror  and ruppin used only hair and skin color   photos without
visible teeth were assigned a teeth color equal to the mean of the teeth colors in the other photos 
we wrote a matlab program to convert the feature landmark locations into the feature representation  the feature representation is made up of several distance measurements  normalized by
the distance between pupils  it includes a few ratios between distances as well  see the appendix
of     for details  in addition to the distances and ratios in      we also measured average chin
slope and the height of the eyebrow arch  however  our feature representation did not include
the symmetry indicator used by      because the validity of their symmetry indicator relies on the
lighting conditions being the same in every photo   which was not the case for our data set  also 
because many of our photos had relatively poor resolution  an edge detector found edges created by
pixelation rather than by imperfections in the skin  thus  we were unable to use a skin smoothness
indicator as in     
for the pixel representation  we scaled the  already rotated and cropped  photos so that they
were all the same size  then we converted them to grayscale  unfortunately  due to time constraints 
we did not align the mouths and eyes as in     

 

data processing and results

we performed principal component analysis  pca  on all     grayscale images to obtain eigenfaces 
the eigenfaces form a basis for the original images  with eigenfaces corresponding to larger eigenvalues capturing global information  and eigenfaces corresponding to smaller eigenvalues capturing
fine detail   see fig      we ran svm  with linear kernel  to classify the top and bottom quartiles
of the data set as attractive or unattractive  this resulted in a training error of zero and a generalization error of       as estimated by hold out cross validation by training on    randomly chosen
images and testing on the remaining     we then ran filter feature selection to lower the number
of eigenfaces used for prediction in order to reduce the amount of variance and improve generalization error  the scores we used for filter feature selection were the magnitudes of the correlations
between the coefficients of the eigenfaces and the human ratings  again  we used       hold out
cross validation to estimate generalization error during filter feature selection   see fig      the
minimum generalization error occurred at about     eigenfaces  thus  we chose to use eigenfaces
with the     top scores  to get a better estimate of generalization error with the     eigenfaces 
we used    fold cross validation  the result was a generalization error of       the training error
was still zero  the learning curve for the pixel representation using the top     eigenfaces appears
  their symmetry indicator is the sum of squares of the differences in pixel values when the pixels are reflected
across a vertical axis 

 

fiin fig    
we also performed pca on the feature representation before performing classification svm 
the best generalization error was about      with a      training error  since the training error
was lower than the generalization error  we again performed filter feature selection as on the pixel
representation  prior to pca   the resulting plot is shown in fig     the minimum generalization
error occurred at    features  however  performing pca and then svm on just the top    features
did not improve generalization error significantly  the generalization error  using    fold cross
validation   was       while the training error was      

 

conclusions

looking back to      our results are comparable  we both were able to accurately predict attractiveness classes about     of the time  but by using different representations  while     obtained their
best results with the feature representation  our best results came from the pixel representation 
this seems very reasonable since our data set was far more varied than either of the training sets
used by      presumably  the very sensitive feature representation works much better on uniform
data sets  the values of measurements and proportions in the feature representation can vary
significantly with only a slight head tilt  very rarely was a woman in a photo from our data set
looking precisely straight ahead  furthermore  our lack of consistent photo quality and lighting
could also have an impact  perhaps our biggest source of error was the variety in facial expressions
 serious versus large smiles with teeth  et cetera   on the other hand  our much larger data set
was able to improve notably upon the pixel representation results  despite the poor quality of our
data  in the end  it seems that while the feature representation prefers quality to quantity  the
pixel representation will perform well  despite relatively poor quality  as long as the data set is
large enough  we predict that for data sets where both quality and quantity are present  both the
pixel representation and the feature representation will lead to accurate predictions 

 

ideas for future work

due to the time consuming nature of our data collection process  we did not have enough time to
try out everything we thought of during our research  in the future  we would like to perform a
regression version of svm on our data to see if our larger sample size would increase the correlation
achieved by      additionally  we would like to align the mouths and eyes in the photos  for
potentially better results using the pixel representation  we also considered testing different kernels
for svm  although     determined that a linear kernel worked best  that might not be the case for
our data set  additionally  we would like to test both representations using knn 
another idea is to change the feature filter so that it can account for nonlinear relationships 
many facial features are considered to be most desireable at neither extreme  for example  a huge
nose is not often thought well of  but if it is too small  that can also be undesireable  if we were
able to design such a feature filter  it would probably have a positive effect on our generalization
error  it is also possible  considering the learning curve in fig     that adding still more photos to
our data set could lead to better classification and regression 

 

fireferences
    dror  g   eisenthal  y   and ruppin  e          facial attractiveness  beauty and the machine 
neural computation              
and thanks to

figure    the feature representation is derived from    points and six color samples 

figure    eigenfaces obtained from our data set 

 

fifigure    classification results of     

figure    generalization error as a function
of the number of features used in the feature
representation  as estimated by       hold out
cross validation 

figure    correlation learning curve obtained
by     using regression svm 

figure    estimated generalization error for
the pixel representation as a function of the
number of photos in the training set according
to    fold cross validation 

figure    estimated generalization error as a
function of the number of eigenfaces used 

 

fi