temporal ordering of event descriptions
nate chambers and shan wang
this paper describes a machine learning approach to ordering real world events
based on their newswire descriptions  understanding and ordering free form text
has been a challenge in natural language processing  nlp  for many years  but
only recently have machine learning techniques been utilized  we describe steps
taken to advance the state of the art  focusing on learning temporal relations
between pairs of events  we propose feature vectors based on linguistic
principles  and furthermore  we choose additional features that can be
realistically automated instead of dependent on hand tagged data  we show a
    increase in accuracy compared to previous work in the area 

  introduction
many areas of language understanding  such as question answering  would benefit from a
temporal ordering of events  however  eliciting the true order of world events from a
textual description is a very difficult task  even with a surface understanding of
sentences  the temporal order of the individual descriptions is not obvious  recently  with
the creation of hand tagged newswire corpora  new research in machine learning has
taken strides to accomplish this difficult task 
newspaper articles often describe the most important event first  followed by a series of
more descriptive paragraphs of different  related events  the linear order of sentences
generally does not follow the linear order of time  this paper describes an approach to
temporal ordering that uses linguistic features to train machine learning algorithms  in
addition  it describes new features that are automatically extracted from untagged corpora
using current nlp tools  we compare these linguistic features to previous work that used
hand tagged features 
  previous work
mani et  al        used time relations between events to build a classifier that marks each
pair of events with a temporal relation  mani builds his classifier off of perfect humantagged features only  he also applies rules of temporal transitivity to expand the small
number of trainable relations  he reports     accuracy on event event relations 
although     is the baseline majority tag 
lapata and lascarides        trained an event classifier for inter sentential events  they
built their own corpus by searching for key time words  e g  after and before  and
saved sentences that contained two events  one of which was triggered by the key word 
they constructed a learner based on syntax and clausal ordering features  boguraev and
ando        approached different but related tasks of     extracting events and    
relating events to time periods  they used a chunking approach with part of speech tags

fi pos  as features  both tasks are different than this papers  we focus on finding time
relations between events 
each of these groups focuses on different subtasks  our work is most similar to manis in
that we are learning relations given event pairs  lapata addresses this task only within
sentences  not full document understanding  our work is unique in that we use imperfect
automatically extracted linguistic features in addition to the corpus features for learning 
  training data
our training set is derived from the timebank corpus  pustejovsky        a set of    
newswire articles tagged with the timeml schema through a combination of automated
tagging and human verification  timeml is an annotation schema designed to capture
and represent temporal information  event tags identify semantic events in the text and
classify them with high level features  e g  tense  aspect  class   the corpus also contains
temporal links between pairs of events  called tlinks  we condensed the original set of
thirteen tlink relations into six  as many tlinks are synonymous or inverses of
others  given pairs of events  it is these tlinks that this paper learns 
we also use the opinion corpus  unofficial  unreleased   a set of    articles tagged in the
same manner as timebank  but by a different set of researchers  this corpus is used for
comparison purposes to previous work only  the combined timebank and opinion
corpus is called the otc corpus in our evaluation 
    closure
since the training data is sparse  we increase its size by performing temporal closure  as
suggested in mani et al          for example  if an article contains the relations  a
after b  and  b include c   we infer the relation  a after c   we created
   such rules and performed full closure  roughly increasing corpus size three fold 
  features
event features
every event s event tag contains the attributes  class  tense  aspect  modality  and
polarity  an event can belong to one of seven classes ranging from action to
situation  tense  aspect and modality are the verbal features attached if the event is
a verb  not a nominal noun   otherwise null  we found seven unique modals in our
dataset  the polarity represents if the event is happening or not  in the usual sense  we
also added another feature that is the event string itself  finally  we added pair dependent
features that are on or off if the two events share the same tense  aspect  or class  mani et
al  used these base features in their work  the rest are unique to this paper for this task 
part of speech  pos 
for each identified event  we include the pos tag for the event and the tags for the two
tokens preceding and one following  to extract pos tags  we used lingpipe  www aliasi com lingpipe   a suite of java libraries for linguistic analysis  this tagger uses   
 brown  pos tags  but we mapped these tags into a set of     penn treebank  pos tags

fiin order to improve performance in the face of sparse training data  we also created
bigram pos features of the event and the token before the event 
co referential entities
we use lingpipes utilities to identify co referential named entities  we hypothesize that
if two events involve the same entity  they have a higher probability of being related over
events involving distinct entities  for example  consider the following pairs of sentences 
    jane fell  mike pushed her 
    jane fell  mike pushed mary 
in the first pair  the events fell and pushed both involve jane  so we conclude that the
two events are related  in the second pair  the relation no longer exists  we used the
stanford parser to create the syntactic parse tree for each sentence and aligned the
timebank event tags with the lingpipe co referential ids  when classifying an event
pair  we match if both events include the same entity id among the events modifiers 
event event properties
a phrase p is said to dominate another phrase q if q is a daughter node of p in the
syntactic parse tree  we leverage the stanford parser syntactic output to create this
feature for intra sentential events  it is either on or off  depending on the two events
syntactic location  obviously  two events in different sentences are always off  we also
include a feature representing the linear ordering of the two events in the text  this
applies even when two events appear in separate sentences 
prepositional phrase
we created a feature for whether or not the event is part of a prepositional phrase  the
features values range over    english prepositions 
  evaluation
we used four corpora  timebank  timebank with closure  timebank opinion  otc  
and otc with closure  the baseline is the relation that occurs most frequently  we also
define a test case of base features that mainly uses the tagged features in the corpus  as
in mani         these consist of the event features as described above in section   
on each corpus  we performed nave bayes classification with    fold cross validation 
we performed both feature addition and feature removal  reporting performance for the
method of feature selection that performed best  we also used libsvm  csie ntu edu tw 
 cjlin libsvm  for multi class svm classification with linear  polynomial  and radial
kernels  finally  we compared performance of brown and penn pos tags  but found they
gave comparable performance  thus we only present results using penn treebank tags 
  results
figure   shows the nave bayes results on the two corpora and their temporally closed
counterparts  closure raises the baseline  but performance does not increase by the same
amount  we saw       accuracy over the baseline     and over previous works

fifeatures        it is difficult to directly compare the results as mani et al  report only
otc scores  however  our implementation of his features performed nearly the same and
achieved       compared to his reported        even with this slight discrepancy  our
new features still performed better at       

  
  
  

   

   

  
  
  

  
  
  

  
  
  

  
  
  

   

  
  
  
  
  
  

  
  
  

   

  
  
  

   

  
  
  
  
  
  
  
  
  

nave bayes results

nave bayes
base features
baseline

   
   
   
  
timebank

timebank  closed

otc

otc  closed

figure    nave bayes results  comparing two baselines to our features 

svm results

   

  
  
 
    
  
 
    
  
 
    
  
  

  
  
 
    
  
  

  
  
 
    
  
  
  
  
  
  
  
  

   

  
  
 
    
  
  

   

  
  
  
  
  
  

   

  
  
 
    
  
  

   

linear
radial
polynomial
baseline

   
   
   
  
timebank

timebank  closed

otc

otc  closed

figure    support vector machine results  comparing three different kernels 

figure   shows svm performance  a linear kernel had the best performance  but was
outperformed by nave bayes  as seen with nave bayes  corpus closure surprisingly
had no beneficial effect  our closure algorithm increased timebank from      to     
relations and increased otc from      to        relations  the otc closed set appears
to have introduced significant noise and learning is minimal over the baseline 

fi  discussion
there is a large jump in performance by including new features  most of the new features
included dependencies between the two events  rather than new features about each event
individually  phrasal dominance  co referenced entities  and tense aspect class event
pairs all capture syntactic and semantic dependencies between the events  this suggests
that nave bayes has too many independence assumptions  the     increase from
manis base features  what he calls perfect features  rises from       to        this
clearly shows that some dependencies need to be captured within the features themselves
if not in the statistical model 
the importance of closing the data is unclear from our experiments  our results show
that the closed corpus performs worse than the unclosed corpus when compared to the
baseline  if the closed data is similar to the unclosed  then the large increase in training
data should have helped  we suspect that closing the data introduces new event event
relations that have long range dependencies not captured by the original relations  most
event event pairs in the raw corpora are no farther than one sentence apart  however 
closing the data introduces distances that cover the entire article  we believe these new
relations require more knowledge beyond sentential syntax  mani et al  does not show
this result  but it is unclear where the difference lies  our features clearly outperform his 
but he reports abnormally high results on an unknown closed dataset 
the results on the otc corpus show an improvement as with timebank alone  but not as
large  we evaluated this corpus to compare against manis work  but our evaluation
performed very differently from theirs  it is important to note the wide difference in
event relations in timebank and opinion  the opinion corpus has       before
relations        in timebank  and only     simul        timebank   such a
difference is astounding  and it surely affects the baseline as the opinion corpus is so
heavily skewed to the before relation  we believe the tagging schema needs to be
studied  as two divergent corpora should not be compared directly  we also believe this
leads to the discrepancy with manis paper as all their results are reported from otc 
  conclusion
we have shown how important linguistic features that capture dependencies between two
events are to the temporal ordering of events  we showed improvements over previous
work from       to        a     improvement  we also describe results questioning
previous success on a divergent corpus  particularly with the use of temporal closure to
expand the training data size 
references
    b  boguraev and r k  ando        timeml compliant text analysis for temporal reasoning 
in proceedings of ijcai  uk 
    m  lapata and a  lascarides        learning sentence internal temporal relations  journal
of ai research  volume     pages        
    i  mani et al  machine learning of temporal relations        acl  australia 
    j  pustejovsky et al        the timebank corpus  corpus linguistics          

fi