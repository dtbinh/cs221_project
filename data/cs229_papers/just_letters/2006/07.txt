sean augenstein
su id          
cs     project report
learning techniques to aid pose estimation via sift
overview
i am working on machine learning techniques to intelligently track and match features in a
sequence of visual images  specifically  the feature i am tracking is known as the scale
invariant feature transform  sift   my project involves using a camera to capture
images of the motion of robotic objects in my lab  i used pca to find a small subset of the
sift vectors that best match the object between images  i also investigated using svms
to reduce the size of the data we are working with  and aid the speed quality of the overall
matching process  this should result in a recognition of which features are most distinct
for tracking a target  as well as a speedy and computationally inexpensive way to identify
the object  and ultimately its pose  in future images 
background   hardware   software
i work in the aerospace robotics lab in the aero astro dept  we are researching
techniques to autonomously track  rendezvous  and dock with a satellite that has lost
attitude control and is tumbling  one can consider the case of an important asset  such as
the hubble telescope  losing a gyro and thus its ability to point or stabilize  towards this
end  we are interested in ways to do efficient and robust pose estimation  which would be
used by a spacecraft coming in to autonomously dock with the damaged satellite 
the sift technique was conceived by dr  david lowe at the university of british
columbia  lowe         sift vectors are invariant to image scale and rotation  partially
invariant to illumination change  and highly distinctive  because they are vectors in high
dimensional space   this would make them ideal for application to the space environment 
where illumination and perspective change quite a lot 
sift vectors are found by taking a difference of gaussians pyramid  we then find scalespace extrema  and keep all those that have high enough contrast  at each extrema  a
keypoint descriptor is constructed  consisting of histograms of the gradient of the image 
sorted by orientation  these histograms form the elements of the sift vector 
as a test vehicle  i used a free flying robot that floats on an air bearing on a frictionless
granite table  overhead cameras image the vehicle  as it moves on the table  i used code
written by dr  lowes lab to take an image and output its sift vectors  as well as their
location in pixel space  i wrote a parsing script to bring these vectors into matlab  and
then wrote functions to perform pca  label match sift vectors  and interact with svmlight  a software package that trains svms  joachims       
machine learning aspects
while sift vectors are highly useful and distinctive features  the price we pay is their
large size  and thus computational complexity  typically  sift vectors contain    
elements  in the images i took  there were usually           sift vectors  this means

fimathematical manipulations to register common vectors between images can take many
operations  because of their size and large population  it would be useful to reduce the
number of sift vectors were searching for matches with 
in this project  i investigated   different ways to speed and simplify the sift vector
matching process  i used pca to choose an easily distinguishable sub set of the sift
vectors associated with the target  i also investigated the uses of svms for pre filtering
images  to check if the target is present in an image  or to classify lighting as bright dim 
figure   shows how these techniques fit into the overall pose estimation process 

new image
 sift vectors 

target
in
view 

y

 svm 

lighting 
contrast 
 svm 

n

high
contrast
match set
low
contrast
match set
 pca 

matched
sift
vectors
 to pose
est  step 

figure    applications of machine learning to pose estimation

pca for smart id vector selection
what is a good sub set of the target sift
vectors in image i to use  in order to find the
target among the sift vectors in image j 
we wish to select id vectors that are easy to
distinguish  and wont be mismatched with
extraneous sift vectors  i e   not residing on
the target   see figure    the yellow dots in
the left image are the sift vectors we know
correspond to the target  we want to match
these vectors to vectors in the right image  in
order to find the target in that image  so our
id set is chosen from the yellow set 
figure    the sift vector matching problem

we can do principal components analysis on the full set of sift vectors in image i 
which will give us the eigenvectors  the principal eigenvector  u   represents the direction
 in     space  of highest sift vector density  and the minimal eigenvector  u    
represents the direction of lowest sift vector density  so an id vector that is closely
aligned with u    should be easy to distinguish  it is less likely we will form a false match
to some other  extraneous  sift vector in the new image   note i am implicitly assuming
that the overall sift population of images i and j are similar  
this motivates our choice of id vectors  we select a group of n vectors from the target set
 st i    that are the most distinct from the general sift vector population  we do this by
selecting the sift vectors that maximize inner products with the smallest eigenvectors 
beginning with the minimal eigenvector  u      we then find the second target vector by
repeating with u     and then go to u      u     and so forth 

fis    arg max  s t u       s     arg max  s t u     
sst  i  

sst  i  

m
t

s n     arg max   s u      n
sst  i  

      

   s n   arg max  s t u     n
sst  i  

      

 

in this way  we have chosen an id set of sift vectors that should be easily distinguishable
from each other  as well as from the general population of sift vectors present in the
picture  figure   shows the matches in a new image  for an id set of     sift vectors 
approximately     of the id set was matched in the new image     matches  out of    
id vectors   the number displayed is the index of the vector in the id set 
i applied the same matching algorithm that lowe uses in the sift paper  basically  it tests
euclidean distance  finds the vector that minimizes  and accepts a strong match with this
vector as long as it is less than    times the euclidean distance to the next smallest vector 

figure    forming matches with id vector set

i also wanted to observe slightly weaker matches  so i tested for minima that were less than
   times the next smallest vector  in figure    magenta represents strong matches  and
green represents weaker matches 
forming the id set is a supervised learning process  since it requires a labeled set from
which to select  if this algorithm is to be used autonomously or semi autonomously  we
would like to minimize the number of times we need to build a new id set  i tried to
maintain a single id set  and match it to successive images in time  this resulted in fewer
and fewer matches as time progressed  with only about   matches occurring after the robot
had moved through    images  to improve match performance  i reassigned the id vector
to its match when one occurred  in this way  the vectors of the id set were propagated
through time to keep up with the changing robot  this still resulted in eventually no
matches  so in the future  the id set selection algorithm will need to be modified to
autonomously re select the optimal set of id vectors  and to do this periodically so that
match performance is maintained 

fisvm for pre filtering   logic blocks
our matching problem suggests the use of a svm  or other classifier  to separate sift
vectors belonging to the object from extraneous other sift vectors  once the vectors have
been located on the image  i might classify them as being on the object  y i       or off the
object  y i        i attempted this  using the svm light software package to train an svm
with the features being the     elements of the sift vectors  i failed utterly  in
retrospect  i realized that this is a data set that cannot be separated by a hyperplane in    space  put another way  there is nothing intrinsically different about a sift vector
associated with the target vs  an extraneous sift vector 
the next idea was to use svm classifiers as logic blocks  to help make decision on how
the algorithm should proceed  based on the overall scene  in this case  the training
example is not an individual sift vector  but rather a complete image  in order to
construct an svm  i had to find a common feature vector framework  that would represent
images containing different numbers of sift vectors  based on the previous section  i
decided to try pca  and use the concatenation of the eigenvectors as a feature vector  so
the feature vector contains      elements 
the first logic block was a basic target present identifier  could i train an svm that
would decide if the robot was visible in the scene or not  i used a training set of   
different images  and then tested  the results were not promising  i found that at different
illumination levels  the classifier performed poorly  i also changed the image size  and
found the classifier was rejecting images  even when the robot was visible in the frame  in
the future  i might try to retrain this classifier  with a larger training set  covering a broader
range of illumination levels and image dimensions 
a second use of an svm as a logic block was to judge the relative illumination level of an
image  i observed in the previous section that matching of sift vectors tended to be
sensitive to how bright the scene was  a set of sift vectors chosen to use as an id set
under darker conditions would perform worse when the lights in the room were turned
brighter  and vice versa  so  we can improve registration of the target  if we choose an
appropriate id set based on the illumination of the scene 
again using svm light  i used a training set with    images  showing the robot and
granite table set up under both darker and brighter conditions  this time  an svm worked
very well  properly classifying         test images  my motivation for using a smaller
training set was to minimize the amount of help the system gets  ultimately  i would like
the sift vector selection match process to be almost completely autonomous 
observations and ideas for future work
when using pca  i observed there is sensitivity to noise  which manifests itself in the
lowest eigenvectors  if i take different images from the test set  and use my algorithm to
find the first six id vectors  different vectors are selected  see figure     i hypothesize this
is due to variations in sift vectors from image to image  which affects the directions of
the lowest eigenvectors  because these are the directions of lowest vector density  

fifigure    some difference in the  st six id vectors chosen

this could be corrected for by doing k means  or some kind of discriminant analysis 
clustering over images of an identical scene  like the   images above   and then doing pca
on the clusters  this would give us a set of eigenvectors that are more stable from image
to image  also  this process could be applied to the set of target vectors from which we are
choosing our id set  so that we are sure the sifts we select are strongly recognizable  and
not just fluctuating at the edge of scale space detection 
the idea that the smallest eigenvectors are the most sensitive to changes in the overall
vector set motivates an idea for changing the svm we build for pre filtering  i used a
feature vector of      elements  the concatenation of all the eigenvectors   in a brief
attempt to find a smaller feature vector  i tried using the principal eigenvector for training
svms  and was not successful  i tried again  using the concatenation of the   largest
eigenvectors  and again failed  but  as i observed above  it is the smallest eigenvectors that
most reflect gradual changes to a vector set  so therefore  it might be a good idea to train an
svm with the smallest eigenvectors  my future plans for building an svm would be to
use feature selection in choosing some set       of eigenvectors  to confirm my hypothesis
that it is the smaller eigenvectors that are more indicative of changes to the overall set 
acknowledgements
the author would like the thank professor andrew ng  catie chang  and kiran murthy for
many useful discussions concerning intelligent target sift vector selection  stephen
russell and sean kamkar assisted in data collection  finally  deborah meduna and
michael vitus helped with understanding of general machine learning concepts 
references
lowe  d g  distinctive image features from scale invariant keypoints  in international
journal of computer vision       
joachims  t  making large scale svm learning practical  advances in kernel methods support vector learning  b  schlkopf and c  burges and a  smola  ed    mit press 
     

fi