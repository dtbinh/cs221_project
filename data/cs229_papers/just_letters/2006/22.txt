learning planar geometric scene context
using stereo vision
paul g  baumstarck  bryan d  brudevold  and paul d  reynolds
 pbaumstarck bryanb paulr   stanford edu
cs    final project report
december         

abstracta reliable method for detecting planar regions in a
ii  the algorithm

video stereo scene would be of great use to the field of computer
vision  solutions to this problem are applicable to object
recognition  scene identification  and robot related applications 
in this paper we present a plane finding algorithm that uses data
from a binocular stereo camera system to produce labeled output
images showing the major planes in a video scene  the algorithm
is based on the three dimensional hough transform but also
presents many useful approaches and heuristics applicable to
general plane finding 

a  depth map processing
before proceeding with computation  we observed that the
stereo depth maps suffered from two main sources of noise 
gaussian noise on the distance readings and another source
akin to salt and pepper noise which was caused by poor
feature matching from the stereo camera  returning distance
readings many meters off from the true values   to combat
both of these sources of noise the depth map was subjected to

i  introduction

t

he goal of our project was to use image and depth data
from a stereo camera system to locate the major planes
in an image  a successful algorithm would find immediate
application in areas such as scene identification  object
recognition  and robot environment interaction  after trying
several approaches built around unsupervised learning
algorithms  we converged on an algorithm based on the
three dimensional hough transform 
our data was gathered using a binocular stereo camera
with a   cm baseline  our input data set consisted of images
of indoor office and hallway scenes with varying levels of
clutter  each entry in the data set consisted of an image pair 
one  a monochrome image from the camera s left eye  and
two  a depth map containing the estimated distance value
for each pixel  provided directly by the camera software      
figure   shows two example pairs of images  dark blue
regions in the depth map indicate points where no distance
readings were returned due to lack of distinct features in that
area 
one of our primary assumptions was that there were two
types of evidence for planes  one  localized and contiguous
evidence found on textured surfaces  such as desks   and
two  sparse and scattered evidence when most of the plane is
featureless and returns no depth data  such as walls and
ceilings   our algorithm focuses primarily on utilizing the
first type of evidence since it was typically the most reliable 
in regions where the second type of evidence predominates 
our algorithm uses the mono image data to assist plane
classification 

fig    two example mono camera images  left side  and their
corresponding depth maps  right side   dark blue in the depth maps
indicates places where no data was returned 
a

b

fig    effects of modified low pass filtering on the point cloud
obtained by back projecting the depth map shown on the lower right in
fig     here  a  is the original  unfiltered depth map and  b  is the
filtered one  note that the three vertical lines from the door are lost in
 a  but appear strongly in  b  

fimore heavily than points farther away  thus roughly preserving
the density of data points per surface area in the point cloud  in
images with many data points  the decimation ratio was usually
      but in sparse images no decimation was performed so as
to retain all of the given data from the stereo camera 

d
d

a

b

c

fig    example of the sensitivity of the  d hough transform to
d  the maximum response of the hough transform in each case
is shown in yellow  in  a  d is chosen well and the maximum
response selects a strong plane  in  b  d is slightly too large and
the plane fit is off  and in  c  d is much too large and all planar
information is lost 

d

fig    example of the maximum response of the hough
transform being skewed by separate groups of planar points even
when d is chosen well 
a

b

c

fig    the effects of segmenting the point cloud in  a  are shown
as color coded groups in  b    c  is obtained by projecting the
color coded groups back to a  d image 

modified low pass filtering before it was used  after backprojecting the smoothed depth data into a  d point cloud  the
beneficial effects of this step can be seen in figure   
the depth map was also decimated in order to reduce
computation time  we used a modified random decimation
algorithm where points closer to the camera were decimated

b   d hough transform
next the  d hough transform is run on the  d point cloud 
in the hough transform  every point votes for every plane
that passes within some distance of it  thus the maximum
response over the transform indicates the best guess for a plane
in the region 
planes in the  d hough transform are described by their
normal vectors which are specified by two angles  azimuth   
and elevation    and the vectors euclidean norm     since
the hough transform is discrete  it is parameterized by the
step size in all three of these variables  of the three of these 
the hough transforms maximum response was most sensitive
to d  as illustrated in figure     we addressed this sensitivity
by setting d to be    cm since this was small enough to detect
most planes throughout the data set while still large enough to
accommodate the noise  step sizes of   proved sufficient for
both d and d 
another problem was that the hough transforms maximum
response over several  unconnected groups of points was often
non planar even when the individual groups themselves were
very planar  this is illustrated in figure     we addressed this
problem by first performing  d segmentation on the point
cloud and then running the hough transform on each of those
segmented groups in isolation 
our  d segmentation algorithm works by quantizing the
entire point cloud into a series of quantum boxes of size
  x  x   cm  next it selects the quantum box containing the
highest number of points and connects to it all of the other
contiguous quantum boxes also containing a high number of
points  this group is then labeled and removed from the set of
points  this procedure is repeated until     of the point cloud
has been grouped  the remaining     were typically outliers  
a sample result of this  d segmentation is shown in figure   
after this  the hough transform is run on each segmented
group of points in the following manner  first  it is run over all
of the points and the maximum response is determined  this is
shown in figure   a with the red points   then all of the points
corresponding to the maximum response are extracted and the
hough transform is re run on the remaining points  figures
  b and   c show these successive applications of the hough
transform   this is repeated until     of the original points
have been exhausted  processing the final     often generated
many weak plane guesses  
c  plane guess processing
after the hough transform step  the algorithm possesses a
series of plane guesses specified by their normal vectors 
centroids  and all of their assigned points  these raw results
often contain many false planes so they are first decimated 
those guesses that are drawn from too few depth points or

fiwhich occupy too little surface area are thrown away 
also  because of the fineness of d  these guesses often
contain many repetitious guesses for a single plane  thus the
guesses are clustered  in this step  two or more planes are
combined if their normal vectors are highly aligned and if their
centroids also satisfy some similarity conditions  also factored
in are elements from each point clouds singular value
decomposition which contained vital information on each
planes geometry 
we also made use of the requirement that valid planes do
not occlude too many of the given stereo data points  we
assume all planes are solid and opaque  so line of sight
constraints must be satisfied   thus  before any two plane
guesses are combined  the supposed new plane is checked to
see if it occludes too much depth data  this is illustrated in
figure     single plane guesses are also dropped if they violate
this occlusion rule themselves 
figures   e and    e show the results after this step  colored
regions indicate points in evidence for the final plane guesses 
and the attached point cloud plots show the normal vectors of
all plane fits 
d  plane region labeling
finally we desired to make the plane labels match the
monochrome images better  the output labels of the last step
did not match very well because they were drawn entirely
from the stereo data and so had little direct relation to the
mono image boundaries  we corrected this by introducing
image segmentation on the mono images  we used a superpixel   graph based approach published by felzenszwalb and
huttenlocher      an example output of their segmentation
algorithm is shown in figure   
for the segmented images  we adjusted the parameters so
that the segmentation was fine enough that each segment
overlapped with only one final output plane with high
probability  thus  in the final step of the algorithm  each
image segment is assigned to the plane label with which it has
the most overlap  examples of these processed images appear
in figures   c and    c   this has the effect of spreading out
the final plane labels into locations better defined by the
image boundaries  and it also allows a small amount of depth
data to provide a plane label for large  texture less regions that
returned no data 

a

b

c

d

fig    iterative procedure for running the hough transform   a 
shows the first maximum response   b  shows the next maximum
response after the points from the first have been removed  and  c 
shows the last maximum response   d  shows these three plane labels
on the corresponding mono image 

fig    plane occlusion example  here the algorithm considers
combining the two separate light blue groups into one plane  it
calculates the convex hull  blue outline  of the new  proposed plane
and checks whether it occludes any points  in this example  the
purple points lie in front of the plane and are not occluded  but the
yellow and green points lie behind the plane and are occluded  thus
the two blue planes are not combined into a single plane 

iii  results
figures   and    depict some representative results  for
reference  images showing the results on all of our input data
are attached to this report 
figure   shows a typical result on a textured  close up
image  our algorithm performs best on these types of images
since the planes are highly textured and are close to the
camera  producing dense point clouds and enabling very
reliable results 
figure    shows a result on a cluttered indoor scene with
most objects lying farther away from the camera than in figure
   here the algorithm still succeeds at finding most of the

fig    sample output of the image segmentation algorithm by
felzenszwalb and huttenlocher      parameters set to k           

fiplanes but it has trouble assigning them to the proper image
regions  it also exhibits many more spurious results than in the
previous example 

a

b

c

d

iv  conclusions and future work
overall our algorithm succeeded in finding many planes in
certain settings  it works best in scenes with high texture and
low clutter where it is able to identify both the correct planes
and their orientations with high accuracy  it is still weak in
finding occluded planes in cluttered environments as well as in
low texture images with very sparse depth data  and even
when it finds the correct planes it is still prone to mislabeling
them in the output step 
the results achieved so far are promising  but there are
many possible directions for improvement  for instance  our
algorithm produces hard classifications  but another approach
would be to build a probabilistic model that estimates the
number of planes through an adaptive method and then assigns
weights to each point indicating how likely they are to appear
in each plane 
one could also employ prior assumptions about the
geometry of the room to reduce spurious results  some
possible assumptions include that there are always walls
bounding the scene  that the major planes should be
orthogonally oriented  the walls  floor  and ceiling   and that
the best planes tend to be strictly horizontal or vertical  table
surfaces  desk tops  and doors  
a

b

e

fig     another set of example results with the same image
arrangement as given in figure    here the scene contains more
clutter and is a more open shot 

lastly  we only examined the task of finding planes given a
single image  but in a mobile robot application it would be
possible to make use of information from multiple  adjacent
video frames when attempting plane classification 
c

d
acknowledgments

e

we would very much like to thank the many people who
provided advice and direction on this project  including prof 
andrew ng  prof  jana kosecka  stephen gould  ashutosh
saxena  and the members of the fall      stair vision
team 
references

fig    example results   a  shows the original mono image   b  the
original depth map   c  the process and labeled output   d  the handlabeled ground truth  and  e  a composite image showing the points
for each final plane as well as their normal vectors 

   

tyzx stereo camera information 
http   www tyzx com products index shtml

   

p  f  felzenszwalb and d  p  huttenlocher   efficient graph based
image segmentation  international journal of computer vision 
volume     number    september      
http   people cs uchicago edu  pff segment 

fileft camera image

appendix

depth map

segmented image

labeled planes

ground truth planes

fileft camera image

appendix

depth map

segmented image

labeled planes

ground truth planes

fileft camera image

appendix

depth map

segmented image

labeled planes

ground truth planes

fileft camera image

appendix

depth map

segmented image

labeled planes

ground truth planes

fi