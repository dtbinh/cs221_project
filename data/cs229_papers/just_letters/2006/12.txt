teaching stair to identify and manipulate tools
deborah k  meduna
december         

introduction

sary for translating tip estimates from pixel coordinates to robot coordinates 

one of the current areas of research in robotics is in
the development of robots which can interact with
humans in performing a variety of tasks  in particular  there is a desire to enable robots to use objects as
tools to perform tasks  for example  assembly tasks
may require the robot to use a screwdriver to tighten
screws or a hammer for nailing  in this project  i am
concerned with the problem of robotic tool manipulation for the purpose of carrying out higher level tasks 
this involves developing a learning algorithm to detect the tip of a tool  the control point   as well as
algorithms for incorporating the tool as an extension
of the robot system and controlling its subsequent
movement 
i performed this research on the stair robot in
the cs department  ashutosh saxena and others
have recently completed work in identifying grasping
locations on generic objects     their algorithm enables stair to pick up most objects  cups  dishes 
pens  tools  etc   within its field of vision  the goal
of my project is to extend this work to allow stair
to manipulate tools once it has picked them up with
the grasping algorithm  one long term application
being considered is to enable stair to construct a
bookcase from ikea  given a set of simplified tasks 

figure    stair
the stair arm consists of   joints which are motor
controlled to rotate about single axes  pre existing
code controls movement of the arm to specified locations with respect to the arm base 

 

tool tip identication

the first step in allowing the robot to move and position a given tool is to locate the tool tip   the control
point   with respect to the robot  since the grasping
mechanism has already been developed on stair 
my specific goal was to identify the location of a tool
tip given stairs image of the tool once it has been
  stair hardware
grasped by the arm  i focused the tool tip identificathe stair robot consists of a robotic arm and sen  tion process on a single tool  screwdrivers 
sor network mounted to a segue motion platform  it
is shown in figure    the vision sensor used for the
project is a focus robotics stereo camera with pixel     logistic regression algorithm
resolution of    x     i installed the camera and developed code to extract depth information from the to implement tool identification  i used a weighted
images which i then used to calibrate the camera im  logistic regression algorithm  since the tool tip size
ages in the robot coordinate system  this was neces  is relatively small in an image  the number of positive training examples is far less than the number
  learning to grasp novel objects using vision  ashutosh
of negative training examples  adding a weighting
saxena  justin driemeyer  justin kearns  chioma osondu 
andrew y  ng    th international symposium of experimental parameter        to positive examples serves to partially offset this imbalance  the resulting classifier is
robotics  iser      
 

fi     

given by 
   argmin

n
x

 i 

w  y

 i 

 i 

 

 h  x   

i  

where

 
h  x i      g t x   
    et x

   y  i     
and w i   
    y  i     

selective classified patch removal

the first step in estimate consolidation is selective
    removal of classified patches  estimated patches were
removed if 
   

   patches were far away from all other estimated
patches  isolated 
   patches were far away from edges  as defined
from canny edge detection 

   

   patches had no neighboring patches but there
since individual pixels contain little information  the
were other classified patch clusters in the image
image is reduced to a smaller set of    x    patches
of pixels prior to feature creation  the features used these rules remove many false classifiers  always leavinclude   laws mask  relates orientation properties  ing at least     classified patches in the image  figand   texture gradient  includes edge detectors  fea  ure   shows an example of the removal process results 
tures for a total of    features per image patch  these
are shown visually in figure    in addition  i use a
canny edge detection feature with value   if an edge is
found within the patch and value   otherwise  this is
meant to account for the fact that the screwdriver tip
will likely be on or adjacent to an edge in the image 

figure    classifier patch removal  red squares infigure    image texture features  the first nine dicate positive classified image patches
images are laws mask filters  followed by the texture
in this particular example  all patches were removed
gradient filters 
except for the two on the tool tip because the two
patches are clustered 
in addition to the    image features described above 
the algorithm appends the features for the neighbor  in the future  the number of false classified patches
ing patches to each patch feature vector in order to can also be reduced by limiting the image search
gain more global information  the appended features space  since the tool is assumed to be grasped by
are associated with the patches to the top  bottom  the arm  the gripper location can be used as a prior
left and right of the current patch  altogether  the to reduce the image space to a box around the gripfeature vector for a given patch contains    features  per capable of containing all possible sizes and orienx i   rn for i      m  where n       the number tations of known screwdrivers  this would alleviate
of training examples is given by m    rcn q   where false classifiers far from the screwdriver location and
r and c are the number of rows and columns in the improve overall algorithm performance 
image  n is the number of total training images  and
q      is the patch size  in general  m    n so
      screwdriver edge detection
the  parameters can be uniquely determined from
gradient descent 
once the number of classified patches has been reduced  another algorithm uses the remaining patches
to identify the screwdriver edge in the image  canny
edge detection is used to select edges in the image 
    consolidating tip estimates
then the edge is selected which is closest to the
the classifier described above often positively clas  remaining classified patches  examples of this result
sifies multiple patches within a new image  it was are shown in figure   
thus necessary to develop a method for consolidating
the estimates into a single  best estimate of the tip the image on the left shows the resulting screwdriver
location 
edge classification for the images in figure    here 
 

fifigure    sample images  left is cluttered backfigure    screwdriver edge identification  red lines ground  right is uncluttered 
indicate identified edges  green lines indicate identified screwdriver edge 
in order to characterize the performance of the classifier  i performed k fold cross validation with a k of
the identified edge is defined just along the screw      the results are shown both before and after the
driver end  the image on the right shows a case patch removal step in the following tables 
where the identified screwdriver edge includes some
of the robot arm edge as well  this happens as a
table    k fold cross validation results   no patch
result of the canny edge detector choices in breaking
removal
up distinct edges  adjusting parameters in the edge
fn
fp
tl
se
detection could help reduce some of this effect 
uncluttered
test     
             
background train          
   
      finding tip from screwdriver edge
cluttered
test                    
background train               
once an edge is identified  the next step is to select the screwdriver tip from the edge  several paths
were explored for this purpose but have not yet been
successfully implemented  the two most promising table    k fold cross validation results   with
directions are 
patch removal
fn
fp
tl
se
   extract line segments from the identified edge
uncluttered
test     
           
using the hough transform  then choose the tip
background train               
as the end point on the best line  unforunately 
cluttered
test
                
the longest line segment is often not the line
background train               
with the tip  requiring a more sophisticated algorithm 
here 
   estimate the curvature of the identified edge line fn   avg false negatives image
and choose the tip as the point corresponding fp   avg false positives image
to maximum curvature  the difficulty with this tl   fraction of images which correctly classify
technique is in accurately calculating the curva  actual tip location
se   fraction of images which correctly identify
ture 
screwdriver edge
these methods and others are still being explored 
as expected  the average number of false positives is
reduced for both data sets when the patch removal
process is included  however  the ability of the
  results
classifier to correctly identify the trained tip location
the classification algorithm described in the previous is reduced  this worse perfomance is partially artifisection was tested on two sets of data  one with     cial  the patch removal process sometimes removes
images taken in uncluttered background  the other patches right at the tip because those patches are
with    images taken in cluttered background  all often isolated  at the same time  however  the
images were taken with the screwdriver in the robot patch removal process improves the accuracy of the
arm grasp  examples of cluttered and uncluttered screwdriver edge detection significantly for both data
images are shown in figure   
sets  by about       as expected  the uncluttered
background data set performed better than the
 

ficluttered background data 

the tip location and the gripper location with respect
to the base can then be related as follows 

finally  the similarity of the test and train results for
the uncluttered data set indicates that the algorithm
has relatively small variance  this also indicates that
in order to reduce the errors further  i will likely need
to include additional features  additional features
could include other edge detector algorithms or other
image characteristics such as hue 

  t   tb  b
 xb
xb
xgtip  tb  b
tip   
g   tbg  

 xb
g   tb   l g

 

 

   
   

in equation    tb  is the transformation matrix from
the arm base to the  th joint  right before the grip  tool incorporation on stair per   and l g is the length of the arm segment from
joint   to the gripper  the resulting expression for
in order to use the tool tip estimate to manipulate the tool vector is 
the tool using stair  the estimate is first used to
compute the tool transformation vector  the resultt
t
 
 xgtip    tbg
tbg    tbg
  xb
xb
   
tip   
g   tb  b 
ing vector is then incorporated into the prexisting
stair control code to move the tool to a specified
as the equation indicates  in order to find the tool
location 
transformation vector  all that is necessary is a set
of gripper and tool tip positions with respect to the
    tool transformation vector
base  i programmed a pre planned trajectory to move
the grasped tool through    distinct positions and
orientations  at each point  the gripper position is
stored and the tool tip position with respect to the
base is estimated using the identification algorithm
from section    the estimated tool tip position in the
image plane is transferred to a position with respect
to the arm base using the camera to robot transformation matrix  see section    

   

commanding tool movement

once the tool transformation vector has been determined  it can be incorporated into the pre existing
stair control code  the current code commands
movements to stairs arm joints based on minimizing a cost function which exponentially penalizes
for arm joints being too close to obstacles and walls
and being far away from the goal  the goal is a  d
position in space  relative to the robot arm base 
specifying the gripper location 

figure    diagram of screwdriver in arm
the tool transformation vector gives the tool tip
position in the gripper coordinate frame  once in
gripper coordinates  the tool tip position can be
determined with respect to any part of the robot
arm through pre existing coordinate transformation
matrices  this then allows for control of the tip
position using pre existing code 

the current incorporation of the tool into this
positioning system uses the tool vector to specify
the tool tip position as the goal and penalizes for
distance between the goal position and the tool tip
position at each iteration  this implementation
provides accurate tool tip positioning to within a
radius of   mm of the goal  however  it does not
yet allow for specifying tool orientation in the final
position state  this will be a future extension 

the screwdriver and gripper coordinate frames are
illustrated  along with the robot arm  in figure   
in terms of the parameters in this figure  the tool
transformation vector is given by 


ls cos s     lg


 

 xgtip   
   
 ls sin s   
 

if tbg is the transformation matrix from the gripper figure   shows an example of moving the tool to a
frame to the arm base frame  then  xb
xgtip   desired location  here the tool goal and tool vector
tip   tbg  
 

fiadjusting these parameters will give further insight
into the problems arising in each step of the algorithm 

were hard coded ahead of time  but the positioning
system was all automated  once the tool tip estimation algorithm is complete  the system will be able
to seamlessly transition from tool calibration to tool
positioning without external input 

finally  once the process has been acheived for the
screwdriver  further extensions of this work can be
done to include other tools such as hammers  pliers 
etc 

acknowledgements
i would like to acknowledge and thank ashutosh saxena and andrew ng for their help on all aspects
of this project including primarily algorithm development and project direction  i also thank justin
drieymeyer and morgan quigley for invaluable hardware and software help on stair 
figure    moving tool tip from initial position to
desired location

 

conclusions

the goal of being able to identify a grasped tools
orientation and move it to a desired location was
almost achevied  many of the sub steps proved very
successful  including the tool transformation vector
calculation and the incorporation of the tool into the
robot positioning system  the primary missing link
is the ability to predict a single tool tip location from
an identified screwdriver edge  the selective patch
removal and the screwdriver edge identification
algorithms seem to give promising results in terms of
progressing towards a single tip estimate  the final
step in finding the tip from the screwdriver edge
will likely be a combination of hough transform and
concavity analysis 
in addition  work can be performed on improving the
performance of the algorithm for cluttered and unstructured environments  much of the algorithm performance improvement can be explored by analyzing
the effect of the numerous parameters in the system 
these include 
     the weighting parameter for the regression algorithm
   q  the patch size for the feature creation
   the canny edge detection parameters
   the distance parameter in the patch removal process corresponding to the threshold at which
patches are kept
 

fi