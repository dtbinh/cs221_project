cs    final report
statistical analysis and application of ensemble method
on the netflix challenge
jack cheng  virginia chu  yang wang
december   th      
   introduction
the netflix prize project is proposed by the neflix inc   in order to seek accurate predictions on movie
ratings  as one group in the stanford netflix prize team  our responsibility is to explore useful statistics
and data curation in the training data set  and to explore ensemble methods for improving prediction
accuracies  we imported the netflix data into a mysql database for data aggregation  and then the
aggregated results can be analyzed using matlab or c   scripts  so far  we have finished multiple
clustering analyses to the movies and the customers by the k means clustering techniques learnt from class
     we clustered the movies by multiple interesting criteria  such as the number of ratings to a movie  the
average ratings to a movie  time progression on monthly numbers of ratings and rating averages  and the
probability of different ratings for a movie  the customers are clustered with similar criteria except the
time progression because the monthly numbers of ratings and rating averages change from time to time 
depending on the movies the customers watch in those months  after the training data have been properly
clustered through various criteria  we used ensemble methods to effectively combine the advantages of
various classifiers and obtain improved results 

number of ratings

   statistics and clustering results
    long tail phenomenon
online dvd sellers can beat the local sellers because there
      
      
is virtually unlimited shelf space for the online sellers to
      
satisfy the needs for a large amount of customers  while
      
the local sellers can capture and sell the top thousands of
      
movies  the amount of movies not captured can be
     
     
enormous and the revenue generated from selling these
     
unavailable movies can be comparable to that generated
     
from selling only the top thousands  this is an example of
 
 
    
    
    
    
the famous phenomenon in the online business world 
cumulative number of movies
called long tail phenomenon 
fig     number of ratings to different movies
the items popularity and users participation in
online rating systems often demonstrate long tail
phenomenon as well  from figure    it can be observed that a large amount of the movies have small
amount of ratings whereas a small amount of movies have an extremely large amount of ratings  similarly 
a large amount of users contribute small amount of ratings whereas a small amount of users contribute an
extremely large amount of ratings  this shows the typical extremity of the movie popularity and user
contribution in the online technology world 
    rating averages and standard deviations
the movie and user rating averages and standard deviations are distributed close to the normal distribution 
therefore  performing k means clustering would just give most of the cluster centroids close to the average
rating of     and standard deviation of    one exception to the normal distribution was found in the
standard deviation of the user ratings  there is a group of users that had a rating standard deviation of zero 
this group comprises of users that gave only   rating or gave the same rating every time 

 

fi    time progression on monthly number of ratings and rating averages for movies
monthly numbers of movie ratings in the first    months after the first rating are considered for k means
clustering  k means clustering with k      is performed  fig      numbers of movies in these    clusters
from top to bottom are                                       and        respectively  according to the
cluster centroids  almost all movies started out having very little rating during the first   months  however 
some movies gained a lot more ratings in the   months to follow  peaked at around   months  and then the
numbers started to decline  yet  there are movies that slowly picked up speed and only started to observe
significant increase in the number of ratings in the  th or  th month  and continued to increase throughout
the first year  despite these trends observed  most of movies        out of        in the probe set
remained very low in the number of ratings throughout the year  the average number of ratings these
movies got per month remained at    per month 
we also performed clustering on the time progression for average rating  the average rating time
progression is clustered using k means  k     looking at the cluster centroids  most clusters seemed to
have ratings that stay fairly constant throughout the months  with only small increasing trend or slight
declines within the first four months 

fig     time progression on monthly number of ratings

fig     movie clusters by probability of different
ratings 

    movie rating profile
rating profile is the number of each rating    to    divided by the total amount of ratings  therefore  this is
the probability distribution of the movie receiving each rating  p   rating   k   where k                  
calculated empirically based on the sample data 
we used a clustering of k     cluster centroids  fig      number of movies in these   clusters
from top to bottom are                                                     respectively  the clustering
showed that most movies have a peak rating that they receive the most counts  and it tapers off the two ends 
variations come from the peak rating value and how fast the ends taper off  none of the clusters centroids
represented movies that received uniform distribution of ratings  this information is useful  as it tells us

 

fithe importance of the predictive power mean and standard deviation  all the clusters have relatively the
same number of movies in them 
    user rating profile
similarly  the rating profile of each user is empirically
determined using the same way as the movie rating profile 
to cluster the user rating profiles  we used a clustering of k
     the cluster centroids are plotting in fig    the number
of users in each cluster are as follows                      
                                          from the top to
the bottom respectively 
the cluster centroids are
representative of the users in that cluster  the centroids
revealed that there is a group of users that give a very
evenly distributed number of ratings from rating   to   
however  most of the other users have a peak rating that
they tend to give a lot of  there are variations on how fast
they taper off  some clusters showed a very distinct peak 
where they almost always give the same rating  where other
groups distribution resembles a normal distribution 

   ensemble method
an ensemble of classifiers is a set of classifiers whose
individual decisions are combined in some way  typically
by weighted or un weighted voting  to classify new
examples      if the classifiers are accurate and diverse  i e 
fig     user clusters by probability of different
if the individual classifiers have error rates below     and
ratings 
their errors are at least somewhat uncorrelated  an ensemble
of classifiers are more accurate than the individual classifiers  an ensemble method by weighting
predictions from multiple approaches is employed in our project  we try to find an optimal way of
combing the predictions from algorithms such as logistic regression  mixture of multinomial  matrix
factorization  k nearest neighbor  and k means 
    concept of the ensemble method
first  we cluster the whole training data into n clusters   ci   i     l   n   by certain criterion  assume that we
have predictions for the test data set from m classifiers  h j   j     l   m   the weighting factor of classifier

h j on cluster ci is denoted as wij   if the entry x to be predicted belongs to cluster ck according to the
clustering criterion  the ensemble prediction is 
m

r   x      wkj h j   x  
j   

    two approaches of training the weighting factors
we train our weighting factors wij using the probe dataset specified by netflix  a deterministic approach
and a gradient descent approach are employed to compute the factors  in the deterministic approach  the
root of mean square error of classifier h j on cluster ci is fist computed 
rmseij  

ni

 
 wi   j h j   ci   k      r   ci   k     

n
k    i

 

 

fihere ni is the number of probe entries that belong to cluster ci   and ci   k   is the k th probe entry that
belong to cluster ci   a performance index is then computed using following equations 
 

 rmse   rmseij   
pij   
ij
  max pik   rmseij    
k
rmse
 

 
ik


finally  the deterministic weighting factor is calculated 
m
pij
     wij      
wij   m
 pil j   
l   

in the gradient descent approach  an error index to be minimized is first defined 
n

m

ni

j     wi   j h j   ci   k      r   ci   k     

 

i    j    k   

the derivative of this index over weighting factor wp   q is 
 n m ni
 np
j
      wi   j h j   ci   k      r   ci   k        h q   c p   k    
wp   q  i    j    k   
 k   

then the gradient descent searching is defined by  a learning rate  of       is found to be appropriate  
wp   q    wp   q  

j
wp   q

    k fold cross validation while computing the weighting factors
for each of the above two approaches computing the weighting factors  the concept of cross validation is
employed 
   the probe data is randomly divided into totally k      subsets  s    s    l s k  
   for j     l   k
compute weighting matrix w j on s  ulu s j   u s j    ul u sk  i e  leave out s j   
test w j on s j to get generalization error  j  
   pick w j that has the lowest generalization error  j   then use w j to apply the ensemble method over
the whole probe data set to compute the overall ensemble rmse   
    ensemble analysis results
the rmse over the whole probe data set predicted by the five available algorithms is listed as following 

mixture of multinomial
      

knn
      

matrix factorization
      

logistic regression
      

k means
      

from our experience  including knn and k means does not help in improving ensemble prediction  the
reason is probably that the rmses from these two algorithms are much higher than the other algorithms 
therefore  for the results presented in this paper  the ensemble analysis only combines predictions from
mixture of multinomial  matrix factorization  and logistic regression 

 

fifive different clustering criteria  cc  are tested  three of them are by movies  time progression
on monthly number of ratings to the movie  cc    time progression on monthly rating averages to the
movie  cc    and movie rating profile  cc    the other two criteria are by customers  time progression on
monthly number of ratings by the customer  cc    and customer rating profile  cc    using the weighting
matrix computed by the deterministic or gradient searching approach  ensemble predictions for the whole
probe data set are made  finally  the overall ensemble rmse  is found for each of the above clustering
criteria 
deterministic
clustering criterion
ensemble rmse 
cc 
        
cc 
        
cc 
        
cc 
        
cc 
        

gradient descent
clustering criterion
ensemble rmse 
cc 
        
cc 
        
cc 
        
cc 
        
cc 
        

the minimum rmse out of the original five algorithms is        by matrix factorization  while
the ensemble method with deterministic approach generally results into an rmse around        
therefore  the ensemble analysis improves the prediction performance by about     the rmse from the
ensemble method with gradient descent approach is about         which is slightly higher than the
deterministic approach  but still obviously lower than this of the matrix factorization algorithm 

   conclusions and future plans
we have performed k means clustering on the movies and users by different clustering criteria  with the
movie and user clusters  the ensemble method shows a    improvement on the rating prediction rmse
compared to the best classifier from        to         which is approximately    improvement to
cinematch  the existing prediction system netflix is using 
the performance of ensemble method depends on both the performance of classifiers and the
ability of clustering to group the data into portions each classifier perform well and portions the classifier
does not  therefore  it would be helpful to investigate the clusters in which each classifier has the least
rmse so as to evaluate the effectiveness of the clustering criteria and suggest a finer grouping in those
clusters to better fit the classifier to the data in those clusters 
more clustering criteria  for instance content based grouping by genre and actors  would be used 
implementation of new classifying algorithms or modification on classifiers such as higher k value for kmeans would also be done  by employing a rich and diverse set of clusters and classifiers  we look forward
to higher benefits from the strengths of the classifiers and hence further improvements on the result rmse 

   acknowledgements
we hope to express our sincere thankfulness to professor andrew ng for leading the netflix prize group
and providing helpful comments and recommendations  thuc vu  chuong tom do and vasco
chatalbashev are also greatly appreciated for their mentoring and technical assistance  we would like to
extend our gratitude to other teams in the group for their prediction results and cooperation 
references
    a  ng  lecture notes  cs     machine learning  department of computer science  stanford
university  usa      
    t g  dietterich  ensemble methods in machine learning  in multiple classier systems  cagliari  italy 
     

 

fi