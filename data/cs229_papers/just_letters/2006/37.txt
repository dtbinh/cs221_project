learning projections for hierarchical sparse coding
chaitu ekanadham  david ho  daniel wagner
cs    final project
     december   
abstract
olshausen and field        suggest a method for learning a set of gabor like bases that activate
sparsely to reconstruct natural images  we extended this approach by learning a sparse
representation of these filter activations using an adapted version of the sparse coding algorithm
 tisc   we trained our models on a simplified dataset with three shapes  and then on a subset of
the caltech     dataset  we found that for the shapes data  svm classification accuracy improved
when using either the first or second layer responses compared to the original images  while for
the caltech data  only the first layer yielded improvement  we also attempted to learn a projection
of the first layer responses for the caltech data to use for learning a second layer  but the algorithm
failed to converge  we discuss reasons why this may have occurred  and also evaluate all
representations that we learn by applying svm classification 
background
sparse coding
sparse coding theory has met with much success as a functional model for neurons in primary visual cortex  the
theory stems from the landmark result in olhausen   fields paper        demonstrating that the response
properties of v  simple cells can be learned by training a model that represents a static natural image as a linear
combination of some set of basis images  the objective function to be minimized is 
f     x  b s         s    
where x is a vector containing the original image data  b  is the matrix containing the basis images as columns  and
s  is a vector containing the coefficient values  activations  for each basis  thus  b s  is the models reconstruction
of the image x  and so the first term in f represents reconstruction error  while the second term measures the
sparseness of the coefficient values s  by taking its l  norm 
b

b

hierarchical sparse coding
we focus on the problem of extracting higher level features of images by learning a second layer of sparse coding
bases on top of the first layer activations  one desirable property of high level features is their invariance to small
transformations  such as rotation or scaling   ultimately  of course  it would also be nice if this hierarchical sparsecoding could more accurately model higher levels of biological visual processing  or improve svm classification
accuracy over first layer sparse coding alone   unfortunately  we can expect that a nave strategy  using the first
layer activations directly as input to a second layer of sparse coding  will not allow us to achieve this kind of
invariance  because of the sparse nature of the first layer activations  slight transformations of the original image are
likely to activate completely different bases in the first layer  thus  the first layer representations of the original
image and the slightly transformed image might appear mostly uncorrelated to the second layer algorithm  making it
hard to learn a transformation invariant second layer representation for both images 
distance metric learning
our approach to this problem is to transform the first layer activations using some linear projection  before applying
the second layer sparse coding algorithm on the transformed data  here  the objective function would look like 
f     x  b s         s         ws   wb s         s    

fiwhere x b   and s  are as above  b  is the matrix with second layer bases as columns  s  are the coefficients of the
second layer bases  and w represents some projection matrix  note that the third term represents the squared
difference between the projections  by matrix w  of the first layer outputs  s   and the second layer reconstruction of
these outputs  b s    which can also be written as   s   b s   w   intuitively  we would like to learn a projection w
that maps images of the same object to be close together  and images of different objects to be far apart 
presumably  a good projection might allow us to achieve some degree of invariance with the second layer of sparse
coding  as well as better image classification with both layers 
b

b

conveniently  eric xing        suggests a supervised learning algorithm to learn such a projection  given a matrix
of similarity and dissimilarity judgments  this distance metric learning algorithm can learn a distance metric w
that assigns small distances to pairs of images a human would judge as similar  and large distances to pairs of
images a human would judge as dissimilar   for classification tasks  we can simply label all images in the same
category as similar to each other  and dissimilar to images in different categories  
the algorithm is summarized in error  reference source not found   it takes an initial guess for the distance
metric  and then iteratively projects it to ensure that it satisfies both constraints  intuitively  the two constraints are 
maximizing the distance for dissimilar pairs and keeping the distance for similar pairs under    and keeping the
distance metric in the set of positive semi definite matrices  
table    distance metric learning algorithm of xing et al         
optimization problem

algorithm

key  a  distance metric  s  set of all similar pairs of data points  d  set of all dissimilar pairs of data points
xi  data point       f  frobenius norm 
c   positive semi definite matrices     convolution operator
s i j   array with the activations of basis j to image i at each point 
c  

indeed  in his paper  xing demonstrates that the supervised distance metric learning algorithm can be used as a
preprocessing step to increase the effectiveness of unsupervised clustering algorithms  in our experiments  we
address the question of whether distance metric learning can be applied to learn an appropriate projection matrix that
can be coupled with sparse coding to yield representations that lend themselves easily to accurate classification 
experiments and results
methods
we ran our experiments on two datasets  the first     images  consisted of    rotations of each of three hand drawn
shapes  a circle  a triangle  and a rectangle  the images from each class were rotated in     degree increments  from
   to    we started with this dataset because it made it easier to understand the features extracted by the second
layer bases  and because we wanted to see whether the projection matrix and second layer could achieve some
degree of rotational invariance  and therefore higher svm classification accuracy   our second dataset     images 
consisted of    images from each of three randomly chosen categories from the caltech      faces  motorbikes  and
starfish  sample images from each of these datasets are shown below in figure    to evaluate our results
quantitatively  we fed the representations of the images at each stage into a linear kernel support vector machine 
and reported the classification error with leave one out cross validation 

figure    original data from shapes dataset  left  and caltech dataset  right 

fisince we knew that first layer basis learning produces bases very similar to gabor filters  honglak lee  personal
correspondence   and since our true aim was to evaluate the projection matrix and the second layer  we chose not to
learn the first layer bases from scratch  instead  we used six gabor filters as reasonable approximations for the firstlayer bases that would have been learned  figure     we then used the translation invariant sparse coding algorithm
developed by roger grosse to generate a reconstruction of the images using these bases  figure     translationinvariant sparse coding is similar to the vanilla sparse coding algorithm  except that it constructs an image using all
possible translations of the basis set  the modified objective is shown in equation   

figure    gabor filters for  st layer

figure    first layer reconstructions of shapes
  st row  and caltech images   nd row 

equation    tisc objective function

shapes
to establish a baseline for the distance metric and second layer sparse coding  we first learned the second layer
bases directly on top of the first layer activations  figure   shows the second layer bases for the geometric data set 
each colored pixel represents a corresponding first layer basis at that location  the intensity of the color represents
the coefficient for that first layer basis  the bases for the shape data clearly show some high level features that are
closely related to the original pictures  such as circular shapes and edges 

figure     nd layer bases for shapes dataset
interestingly  on the shape data  we found that the classification error was already quite low on the raw images
       and it dropped to zero after the first layer  with or without the distance metric  table     while this validated
the utility of first layer sparse coding  it did not shed light on the usefulness of the distance metric and second layer 
moreover  the distance metric learned on the first layer responses was very close to the identity matrix 
the fact that distance metric learning returned a matrix close to i  combined with the fact that classification
performance hit ceiling so early  suggested to us that we should consider more complex data  perhaps the distance
metric learning didnt need to project the first layer representations very far  simply because they already so well
clustered  thus  we turned to the caltech image set 

ficaltech
again  we learned the second layer bases directly on top of the first layer  as a baseline  the bases for the caltech
data  figure    are  of course  more difficult to interpret  so we moved on to the quantitative analysis  figure    

figure     nd layer bases for caltech data
again  compared to the raw images  using the first layer responses yielded a huge decrease in classification error
 from      to        on this dataset  though  running second layer sparse coding directly on the first layer actually
decreased performance  even so  we still hoped that the distance metric learning could improve the accuracy 
unfortunately  learning a distance metric on the first layer activations of the caltech images proved to be a fragile
process  the step in the algorithm that projects a guess of the distance metric onto the constraint sets c  and c 
failed to converge in a reasonable number of iterations  as a result  the learned metric was again very similar to the
initial guess  in the end  after the first layer  very few of the other manipulations seemed to help at all  this is likely
to be due to the fact that the distance metric algorithm did not converge properly on the first layer data 
analysis
we verified our result in several ways 
 to ensure that the algorithm was failing to learn   and that the identity matrix was not  in fact  the best
answer   we initialized the algorithm once with the identity matrix and once with a random positive semidefinite matrix  in both cases  the learned metric was very similar to the initial guess 
 furthermore  to rule out the possibility of a bug in our implementation  we tested it on hand generated gaussian
data in two dimensions  it produced a reasonable result  and moreover  the objective function increased with
each iteration of the outermost loop  table     with our actual data  we had been unable to see whether the
objective function increased with each iteration of the outermost loop  because the algorithms convergence
criterion is based on the difference between the guess for the distance metric on the previous iteration  and the
new guess after iteratively projecting to satisfy constraint sets c  and c   since the algorithm repeatedly failed
to find a suitable projection simultaneously satisfying both constraints  the final result was very close to the
original result  and the algorithm halted 
therefore  we propose a few possible reasons for the algorithms failure in our case 
   the high dimensionality of the data  d        for the first layer responses   which could make a very high
number of training examples necessary  in fact  the metric for which we are optimizing has size d   indeed 
xing et al         had only tested the algorithm on data sets with dimensionality of up to thirty 
   the robustness of the sparse coding algorithm  which could potentially output activations which represent
significantly different data in significantly different ways under a high variety of simple transformations 
perhaps the distance metric learning code was unable to find appropriate projections for sparse  highdimensional data 
despite the fact that the distance metric learning failed to converge  we used the result to learn a second layer of
bases  to transform the first layer activations  we multiply by a matrix a such that ata is the learned distance
metric  the results are shown below for both initializations  figure   and figure    

figure     nd layer bases on caltech data 
with distance metric initialized to i

figure     nd layer bases on caltech data  with
distance metric initialized to random psd matrix

ficlassification results
we fed the following as input to a standard svm classifier 
   original images  both datasets 
   first layer responses  both datasets 
   second layer responses without distance metric applied  both datasets 
   first layer responses with distance metric applied  caltech     only 
   second layer responses learned with distance metric  caltech     only 
for parts     and     we used   fold cross validation  the results for the shapes data is shown in table    also
shown are the results on the caltech data  table   and figure    
table    shape classification errors
triangles

rectangles

circles

overall

baseline

      

 

 

      

first layer

 

 

 

 

first layer with
distance metric
second layer

 

 

 

 

 

 

 

 

baseline
 st layer
 nd layer
 st layer    eye  dm
 st layer    rand  dm

 
   
   
error
   
   
 
faces

 nd layer    eye  dm

m otor bi kes

st a r f i s h

t ot al

shapes

 nd layer    rand  dm

figure    caltech classification errors
conclusions
our initial reaction was that navely applying the sparse coding algorithm to the first layer activations would not be
useful  while this turned out to be true  this is likely to be a testament to the effectiveness of the first layer of sparse
coding rather than to our ingenuity and insight  all our tests indicate that the first layer is so effective than any postprocessing only detracts from classification performance  at the very least  we can say that neither the simpleminded approach nor the distance metric learning approach outlined here are appropriate next steps  we hold out
hope  however  sparse coding is a linear transformation of data  and so is applying a distance metric  combining
two linear transformations yields another linear transformation  and this may perhaps explain the uselessness of
using the metric we learned  yet there may be some nonlinear post processing step that could allow a second layer
of sparse coding to learn a more interesting set of features  and ultimately improve our understanding of vision 
references
olshausen  b  a     field  d  j          emergence of simple cell receptive field properties by learning a sparse
code for natural images  nature              
eric p  xing  andrew y  ng  michael i  jordan  and stuart russell  distance metric learning with application to
clustering with side information  in s  thrun s  becker and k  obermayer  editors  advances in neural
information processing systems     pages         cambridge  ma        mit press 
yang  l         phd thesis  distance metric learning  a comprehensive survey  department of computer science
and engineering  michigan state university 

fiappendix  caltech classification errors

table    caltech classification errors

faces

motorbikes

starfish

overall

baseline

 

 

   

      

 st layer

    

   

 

    

  layer

    

   

    

   

 st layer    eye  dm

    

   

 

    

   

   

    

      

  layer    eye  dm

    

   

    

   

 nd layer    rand  dm

   

   

   

      

nd

st

  layer    rand  dm
nd

fi