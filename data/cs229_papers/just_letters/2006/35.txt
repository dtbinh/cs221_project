predicting visual saliency and saccade probability
bob schafer  boyko kakaradov  mindy chang
continually throughout the day  the brain must process incoming visual signals and transform them into appropriate actions 
namely saccadic eye movements to the most behaviorally salient stimuli  the overarching problem that we address is how to use
visual information to predict the parts of a scene that are most salient  and more specifically  to predict the targets of saccadic eye
movements 
predicting the targets of saccades is a difficult problem for several reasons  first  there are many different cognitive
influences on the saliency of a visual object  for example  a set of keys sitting on a desk might go overlooked when scanning
the scene for a coffee mug  but will immediately draw the gaze of a viewer who has been locked out of the next room  secondly 
the saliency of a target is history  and state dependent  a nearby object will often be targeted by a saccade over a more salient 
but more distant  alternative  finally  although repeated viewings of the same visual stimuli are necessary for data collection and
proper analyses  saliency changes as objects become more familiar 

background
because of the difficulty in predicting eye movements  the benchmarks described in the literature do not evaluate the ability
to predict the single most likely saccade target at a given point in time  instead  the metric used to evaluate a model of saccade
prediction involves the creation of saliency maps  which are probability distributions over the entire visual scene  itti et al 
evaluated several models including their surprise metric by calculating the average saliency of thousands of randomly chosen
pixels across all frames of a movie  and then calculating the saliencies of the pixels that were actually chosen as the endpoints of
saccades      the model evaluation  hereafter called the itti metric  is defined as the fraction of saccade endpoints with saliency
calculations greater than the average value across the saliency map  additionally  itti et al  used the kullback leibler  kl 
divergence to describe the difference in the distribution of saccade endpoint saliencies and the randomly chosen pixel
saliencies  the best performing model  and the one that we use as a comparison in this study  results in an itti metric of     
and a kl divergence of      
research on visual saliency and active vision typically follows one of two approaches  a high level analysis of objects 
context  and the  gist  of a scene      or a low level analysis of luminance  contrast  and local contours      we chose to
concentrate on the ability of low level visual features to predict saliency  the hierarchical feed forward model of the visual cortex
proposed by serre et al  for object recognition provides a framework for extracting features from a visual scene      the proposed
model uses biologically inspired filters that have been previously shown to be similar to the spatio temporal receptive fields of
visual cortical neurons        the superior performance of this model on class specific object recognition tasks suggests that the
features it generates may be relevant to saliency prediction 
many neural structures involved in planning and executing eye movements  including the frontal eye fields  fef   superior
colliculus  pulvinar nucleus of the thalamus  and the lateral intraparietal area  have been characterized as having neural activity
that reflects the likelihood with which a saccade will be made to a certain region in visual space  specifically  the fef has been
implicated as a visual salience map      activity in this cortical area underlies both covert visual attention and the preparation and
execution of saccades  the firing rate of an fef neuron is believed to describe the saliency of the represented area of the visual
field  thus the neural activity of a population of fef neurons provides a representation of both the amount of attention allocated
to specific spatial regions of a scene and the instantaneous probability of executing a saccade to each part of space as the scene
changes over time  our project includes the analysis of experimental neurophysiological data in addition to image and eye
position analyses 

methods
for our experimental setup  we collected data from   macaque monkeys  which viewed an lcd display during the
presentation of a grayscale video  the two types of data acquired were eye position data during free viewing and neural data
from the fef during fixation  five      second movie clips were taken of office scenes  outdoor foot traffic  and moving vehicles

fiaround the stanford campus  a single movie  of an office scene with moving people and chairs  was used for the analyses
presented here  the movies resolution was    x    pixels and was played at    frames second for a total length of just under
  seconds  figure   illustrates the two types of data collected and the resulting saliency metrics 

eye position data
fraction of examples

   
   

itti metric        
kl divergence       

   
   
   
 

 

  
  
 

trial

 

fef recording

 

  

data collection

  
  
  
  
eye position saliency

  

  

   

  

fraction of examples

mean firing
rate  hz 

neural data

 

 

                             
time ms 

itti metric        
kl divergence       

   
   
   
 
 

 

saliency metric

  
  
  
neural saliency

  

  

  

saccade prediction

figure    experimental setup and saliency measures used for saccade prediction 
eye position data   left  gaze targets were tracked as monkeys freely viewed a video   center  sample eye position saliency
map  right  distributions of eye position saliency for randomly selected points  blue  and saccade endpoints  green  neural data 
 left  the electrical activity of single neurons in fef were recorded while monkeys fixated on a spot and the video was shown at
different positions relative to the visual receptive field of the targeted neuron   center  sample raster plot of neuron spiking and
corresponding mean firing rate in response to a single location in space throughout the course of the movie  right  distributions of
neural saliency for randomly selected points  blue  and saccade endpoints  green 
eye position data
eye movement data was collected from two macaque monkeys freely viewing a grayscale movie  which spanned visual
angles of approximately    x     precise eye positions were recorded at     hz using the scleral search coil technique  a coil of
insulated  biocompatible wire was implanted into one eye of each monkey such that it moved with the eye  during the task  the
monkey sat in a magnetic field  and the small currents induced by the changes in coil position were used to determine the
direction of the monkeys gaze 
for each frame of the movie  a saliency map was obtained by overlaying the eye trajectories from all trials and representing
each gaze target as a small gaussian        pixels   gaussians  rather than single points  were used to account for a  any
imprecision in the eye position readings  and b  the assumption that direction of gaze often indicates salient objects or regions 
rather than simply salient pixels  because it takes time for the brain to process an image  plan an eye movement  and execute the
saccade  the eye position at any time t reflects the movie frame on the screen at approximately t      ms  we therefore shifted
the eye position maps back in time by   movie frames  or     ms  so that eye movements would reflect the images that
influenced them  rather than the images occurring after their completions  saccade endpoints were defined as the eye positions
during movie frames following drops in eye velocity below a threshold of    deg sec 

fioriginal image

   biologically tuned gabor filters
at   orientations

   s  maps
 parafoveal simple
cells in v  

max like pooling

    features
   c  maps

   c  difference

 complex cells with

maps

slight shift size

 raw change detection 

invariance 

temporal derivative

figure    feature selection  sample features from a single frame of the video 
neural data
monkeys were previously set up for chronic neural recording from the fef in accordance with national institutes of health
and society for neuroscience guidelines  before each recording  a single tungsten electrode was lowered with a
micromanipulator into the cortex until neurons were detected and eye movements could be evoked with     ms trains of low   
  a  current pulses at     hz  the vector of these evoked saccades defined the sites response field  rf   and determined the
part of visual space represented by the neurons that were then isolated and recorded  while the monkey fixated on one spot  the
movie was played at different positions on the screen such that different patches of the video fell within the rf of the targeted
neuron 
the neural saliency metric of a location of the movie was defined as the average firing rate of the neuron whose rf was
centered on that region 

we were interested in the neural activity produced by the characteristics of individual frames of the

movie clip  therefore  spike trains were shifted back in time by     ms  which is an estimate of the visual latency of neurons in
the fef  and were aligned to the image on the screen at that time 
feature selection
for feature selection  we used the matlab code from serre et al  available online  figure   shows sample features
obtained for a single frame of the movie  the first layer  s   emulates parafoveal simple cells in v  via    biologically tuned
gabor filters  paired in   size bands  ranging from       pixels to         pixels  each containing   orientations             and
      the second layer  c    representing complex cells with slight shift size tolerance  generates    responses using a
max like pooling operation  the change in c  response between consecutive frames was also taken as an additional    features 
thus for a given pixel  a total of     features were extracted by taking the values of the s   c   and c  difference responses
corresponding to that pixel 

firesults
svm
as an initial pass at saccade prediction  we treated saccade occurrence as a binary categorical variable  support vector
machine classification was used to distinguish between saccade endpoints and randomly selected non gaze targets using the
    features      an equal number of pixels were selected for each of the two classes  and     were used for training  while
    were used for testing  the optimal cost  c  and gamma    parameters for an rbf kernel were found using a grid search
across several orders of magnitude to select the parameters yielding the highest    fold cross validation value  the overall
accuracy was             but only     of actual saccades were predicted as saccades  by adjusting the weightings of the
error costs to penalize false negatives more heavily  i e   penalize actual saccades that were not predicted   we achieved an
overall accuracy of             but were able to predict     of actual saccades 
regression
saccades are discrete and therefore a binary categorization between saccade targets and non targets is accurate  but the
underlying saliency of a visual target is continuous  our data sets provided us with two continuous saliency measures of regions
across the movie clip  which allowed us to use regression as a complement to the svm analysis  the first set of saliency values
came from the pixel intensities of the eye position maps for each frame of the movie  figure    top  center   the second set of
continuous saliency labels was produced by the neural data  the instantaneous firing rate of an fef neuron in response to the
presentation of a movie frame is thought to indicate the saliency of the part of the image within the cells rf  figure    bottom 
center  
in the first regression  a vector x of     features was calculated  as described above  for each of    evenly spaced pixels
across each frame of the movie clip  the label y was the luminance intensity of the corresponding pixel in the eye position
saliency map  which was in the interval        in the second regression  the training data x was confined to the pixels at the
centers of the fef rfs  and the labels y were the firing rates  normalized to the interval        after learning the feature weights
 using each of these two training sets and their respective labels  these weights were used to calculate the predicted saliencies
of pixels in two different test sets  a grid of pixels across all frames of the movie clip  and the pixels that were actually endpoints of
saccades 

  x    


m
m


  x   m  

 y     
x n    




    
 
m  m     m 




  n  
 y  m  
l x n  m   



l

 i 

where x

 i 

y

  s   c   c  difference map values for pixel i
  saliency value for pixel i

using the weights learned with the eye position saliency map labels      of saccade endpoint pixels had calculated
saliencies greater than the average pixel saliency  figure    top  right   this result was similar to the number published by itti et
al         the kullback leibler divergence comparing the distribution of saccade endpoint saliencies to the randomly chosen
pixel saliencies was       much greater than ittis value of       using the weights trained on the neural data      of saccade
endpoints had greater calculated saliencies than the average pixel  and the kullback leibler divergence was       figure   
bottom  right  

discussion
natural vision is an active process which involves two concurrent  interdependent subprocesses  decoding of visual
information  and decision of the most relevant  or salient  parts of the visual world  our results corroborate and extend recent
studies on visual saliency that have explored the sufficiency of biologically plausible low level visual features to explain what is
salient  this suggests that high level  global image analysis and saliency prediction is not necessary to account for and predict a
significant level of visual saliency  the results of our eye position and saccade analyses can be directly compared to the recent

firesults published by itti et al  using various machine learning techniques  we have achieved comparable  and sometimes
superior  results in predicting the salient parts of a visual scene  similarly  because saliency drives the guidance of saccadic eye
movements  we are able to predict the endpoints of saccades at least as well  and in some cases better than  previous studies 
we do not suggest that the brain is able to execute the types of machine learning algorithms described here  we as
researchers use these algorithms to determine the relationship between image features  neural activity  and eye movements  but
these relationships do not necessarily need to be learned from scratch by the brain  neuroanatomical connections between
visual cortex and the fef are present from birth  and thus the only learning necessary in the brain is a tuning of the weights of the
synapses underlying these hard wired connections  if moving the eyes appropriately to salient objects leads to a reward in one
form or another  the learning of synaptic weights might be accomplished through a form of reinforcement learning  considerable
recent work has shown that reinforcement learning does in fact occur in the brain  and that the neurotransmitter dopamine might
underlie this process 
our results bolster the argument that the primate frontal eye field  fef  serves as a saliency map in the brain  and that
neural activity in this area appears to be informed by low level visual cortex  not purely by cognitive processes  complex objects 
and global features  according to several computational models of visual cortex  such as the dynamic routing model   the visual
cortical hierarchy receives feedback from a high lever structure reminiscent of a saliency map  it is known that neurons from
fef synapse directly onto visual cortex in a spatially specific manner  suggesting feedback from the saliency map onto the
incoming feature maps  to our knowledge  no existing model includes this type of feedback in the calculation of visual saliency or
prediction of eye movements  our model can be extended to include feedback from the saliency map onto the feature detectors 
modulating the signals on future frames  it is possible that including such biologically inspired dynamic control over the feature
detectors could improve saliency prediction  additionally  several models of object recognition and eye movements include the
importance of high level visual features  such as geometric shapes  complex objects  and global features  by including
additional layers of processing in our model of visual cortex  and by implementing feedback from these layers onto the lower
levels  it would be possible to model the influence of these high level features on the formation of the saliency map 
an alternate approach to predicting visual saliency considers a hidden markov model  hmm   in which hidden states are the
true saliencies of the pixels of an image and the observations are    the visual features produced by the image     the neural data 
and    the eye position data  by using expectation maximization  we could simultaneously determine the optimal state transition
probabilities and the mean observations produced by each state  these results would provide further insight into the relationship
between saliency and neural activity  eye movements  and visual processing 
references
    itti  l  and baldi  p  bayesian surprise attracts human attention  in  advances in neural information processing systems  vol 
    nips        pp       cambridge  ma  mit press       
    torralba  a   oliva  a   castelhano  m     henderson  j m          contextual guidance of eye movements and attention in
real world scenes  the role of global features in object search  psychological review               
    serre  t   l  wolf and t  poggio  object recognition with features inspired by visual cortex  in  proceedings of      ieee
computer society conference on computer vision and pattern recognition  cvpr   ieee computer society press  san diego 
june      
    bell  a j  and sejnowski  t j        the  independent components  of natural scenes are edge filters  vision research 
               
    van hateren  j h  and ruderman  d l         independent component analysis of natural image sequences yields
spatio temporal filters similar to simple cells in primary visual cortex  proc r soc lond  b               
    thompson  k g   bichot  n p         a visual salience map in the primate frontal eye field  progress in brain research      
    chih chung chang and chih jen lin  libsvm   a library for support vector machines        software available at
http   www csie ntu edu tw  cjlin libsvm

fi