language classification in
multilingual documents
gorkem ozbek  itamar rosenn  eric yeh
summary
we investigate the use of machine learning techniques
for language classification in a multilingual setting  we
consider three contexts in which this task may be
performed  identifying the language of monolingual
documents  identifying the language of individual
tokens  and finally identifying and correctly classifying
spans of monolingual text in multilingual documents 
our broad goal is to achieve the third task with optimal
efficiency and accuracy  we pursue this goal by
building and examining various morphologically based
classification methods that attempt to classify  within a
document  the language identity of individual words
whose language is not known  thereby approximating a
potentially multilingual setting 

  introduction
in todays increasingly integrated and multilingual
world  when developing natural language
technology  one cannot always assume that the
text one will encounter will be solely in one
language  maintaining this assumption and
uniformly applying single language specific textprocessing techniques may result in erroneous
handling of terms in other languages  for
example  in information retrieval tasks  singlelanguage approaches can result in lower precision
and recall scores  an english language
preprocessor may not effectively capture subtleties
relevant to languages such as turkish  where
linguistic structure differs drastically even at the
word level 
traditionally  the task of language identification
has been applied in settings where the entire
document is assumed to be in a single language 
however  with the advent of the world wide
web  instances of mixed language documents
have become more prevalent  for example  the
online edition of the german magazine d e r
spiegel uses a sidebar of text written in english
 see http   www spiegel de    in addition  phrases
are often appropriated from one language into the
context of another  such as the english phrase
sexiest man alive  which appears in a d e r

spiegel article about george clooney  the reality
of multilingual text introduces the task of
identifying when the language of a span of text in
a document differs from the primary language of
that document  to our knowledge  this multilingual
identification task has not yet been sufficiently
explored  at one extreme  this problem can be
reduced to identifying likely language of origin for
a single observed token in a possibly multilingual
setting  this approach motivates our present work 
  feature engineering
previous work
a large body of previous language identification
work has focused on statistical classifiers
primarily operating over character level  nonlinguistically motivated features  such as n gram
character models            these methods
generally perform well only after a certain number
of characters has been seen by the classifier     
however  as mentioned previously  these efforts
have focused on instances where the text to be
classified is considered to be of a single language 
furthermore  in a possibly multilingual setting 
these methods would also be unreliable because a
single language portion of the text may be too
short to contain sufficient characters for the
character based classification methods 
our approach
the character based approach achieves nearperfect classification accuracy within about        characters  without exploiting any features
that are idiosyncratic to linguistic characteristics
of different languages  in the hopes of achieving
high accuracy classification within a short textual
span  as is needed for multi lingual classification 
we would like to develop a classification system
based on linguistic factors that differ among
languages  using light weight features that can
accrue significant statistics within short word
spans of text  using morphological features is an
obvious choice given these desired criteria 
linguistic theory teaches us that word tokens of a
given language are comprised of smaller elements
called morphemes  see figure     which are the
smallest components of a language that carry

fisemantic value  thus  a language model may be
estimated using morphemes as lexical units 
instead of the words in which they appear 

algorithm assumes that morphemes fall into two
categories  stems and affixes  and the latter
category is divided into prefixes and suffixes 

we restrict our inquiry to four languages  english 
finnish  german  and turkish  our approach is to
construct a feature set for each of these languages
by obtaining a morpheme based language model
estimated from a unilingual corpus of the
language  the prima facie difficulty with this goal
is that construction of a broad  linguistically
informed morphological lexicon for a given
language requires a considerable amount of work
by trained experts  thus  for our purposes and for
the general task of engineering a successful
morpheme based language classifier  obtaining
such a lexicon is prohibitively costly  particularly
in the context of many possible languages or
highly evolving languages 

creutzs algorithm uses an hmm to model
morpheme sequences  without assuming prior
knowledge of the segments  morphemes 
themselves  nor of their individual functional
categories  the algorithm performs a baseline
segmentation  then estimates probabilities of
observing a particular morph given its category 
and the probability of a transition from one morph
category to another  using em 

an alternative approach has recently been
explored in the literature  designing generative 
minimally supervised algorithms that attempt to
automatically discover morphemes in a corpus 
we rely on one such algorithm to construct
individual feature sets  morpheme language
models  for each of our languages in an efficient
and unsupervised manner  the algorithm has been
developed by mathias creutz  who demonstrates
its high accuracy for various languages     
creutzs algorithm
the algorithm uses segmentation and is
formulated within a probabilistic framework  two
features of the algorithm enable it to handle
various morphologically disparate languages 
making it especially appropriate for our purposes 
first  the algorithm treats words as arbitrary
sequences of alternating stems and affixes  making
it more flexible with respect to languages having
different levels of inflection  within our own
framework  turkish and finnish are far more
inflective than german and english  second  the
algorithm considers sequential dependencies
between functional categories of morphemes  an
approach known as morphotactics   which
increases its accuracy in an arbitrary multilingual
setting and provides us with a richer feature set
than a simple collection of morphemes  the

our features
the main advantages to creutzs approach for our
purposes are that it allows us to extract an
estimated morphological and morphotactic feature
set for each language  without any supervision or
prior linguistic knowledge  we develop an
analyzer that uses creutzs algorithm to identify
morphological units and their appropriate
functional categories within each languagespecific training document 
  methodology
corpora
each of our models  discussed below  uses
documents made available for morpho challenge
          the site provides sets of unilingual
documents in english  finnish  german  and
turkish  which we use for train and test corpora in
each of our language identification procedures 
baseline
in order to establish a baseline for the language
identification task  we implement a nave bayes
classifier using n gram  i e  unigram  bigram and
trigram  character models  in accordance with
current state of the art language classification
systems  we choose nave bayes for our baseline
and morphological models  we also use laplacian
noise modeling throughout  for the baseline  our
n gram character models are built from word lists
constructed from english  finnish  german  and
turkish training corpora  each word list contains
unique words  i e  word types  encountered in the

ficorpus for one of the four languages  along with
the token frequencies for the words  the classifier
is then trained with these character models for
each of the four languages 
test documents in each language  similar to the
training documents  are also obtained from
morpho challenge  accuracy vs  number of
corpus characters read is measured to establish the
success of the baseline approach for varying
amounts of data  the tokenized version of the
corpus  in the form of a wordlist  is also used to
examine baseline performance with respect to
classifying individual tokens 
morph classification
as a first attempt to improve upon the character ngram approach of the baseline and obtain a
classification system appropriate for multilingual
settings  we obtain a morpheme feature set for
each language by applying the creutz algorithm to
each individual language training document  we
limit our feature set only to a morpheme count for
each language  which serves as a simple
morphological language model for the language 
the morpheme count list contains a list of the
unique morphemes found in the document  along
the frequency of each morpheme  we then
implement a nave bayes classifier using our
morpheme counts as features  in the testing phase 
each language specific test document is first
analyzed using the creutz procedure in order to
identify best guesses of the correct morpheme
segmentation of each word in the test document 
we then apply our nave bayes classifier  along
with the morpheme feature list for each language 
to the segmented test document  the classifier
identifies the language of each word in the
document according to its maximum likelihood
classification  note that the classifier does not
rely on the assumption that the entire document or
even sequences of words of the document are all
in one language  therefore  although the test
documents are all unilingual  the classifier itself
performs exactly as it would in a multilingual
setting  restricted to our candidate languages  
even in the extreme case where the identity of
each word was entirely independent of the
identities of other words in close proximity to it 

morph   morphotactics classification
in addition to the simple morpheme feature
classifier  we develop a classifier that takes
advantage of the morphotactic information that the
creutz analyzer provides  for this classifier  we
also obtain a feature set of   gram morpheme
category sequences for each language  this set is
obtained by examining the language specific
training documents after they have been creutzanalyzed  and creating a count of all   gram
morphological category sequences within the
document  thus  for each of our four candidate
languages  the creutz analyzer provides us with a
morphological language model based on
morpheme frequency count and morphotactic
sequence frequency  we then implement a nave
bayes classifier to use the original morphemecount as a feature set together with our new  gram morphotactic feature set  for each of our four
languages  as before  in the testing phase  each
language specific test document is first analyzed
using the creutz procedure in order to discover
morphemes and their functional categories  prefix 
suffix  stem   then  the nave bayes classifier 
along with the morpheme and morphotactic
language features  is applied to the tagged
document  the classifier identifies each word
according to its maximum likelihood language
identity  using both the morphological and
morphotactic features of the word 
filtering
in an attempt to reduce computation time  as well
as to improve the accuracy of our morphological
language models  we also applied filtering to the
training documents  for each language specific
training document  we obtained a new document
that filtered out words occurring less than        
and      times  we performed new rounds of
testing classification for each of these filter levels
to see if efficiency and performance are increased 
  results and discussion
when attempting to identify the language of a
single document  the performance of the baseline
character n gram model increases as the number
of characters observed increases  see figure    
resembling performance curves seen in previous

fistudies  baseline identification of single tokens is
far less successful  as suggested by the low
accuracies observed in figure   when    or fewer
characters have been seen 
the results of the nave bayes classification task
using our morphological feature sets  in
comparison to the results of baseline n gram
nave bayes classification  are shown in figures
     the first notable observation is that in
unfiltered settings  the morpheme feature
classifier  morph  and the morpheme feature plus
morphotactic feature classifier  morph   mts 
achieve at least a slight improvement in
performance over the baseline  our classifiers
achieve the most success in classifying turkish
words  morph does slightly better than the
baseline  which is roughly at      and morph  
mts achieves very close to      accuracy 
filtering does not greatly alter these results 
suggesting that creutzs method gives a reliable
morphological morphotactic model of turkish 
with respect to finnish and german  unfiltered
classification using morph and morph   mts
achieves slightly higher accuracy than the
baseline  but not near the levels of success seen
with turkish  furthermore  adding morphotactic
features does not increase performance beyond
classification using only morphemes  filtering
seems to reduce accuracy somewhat with both of
these languages  suggesting that the full training
documents supplied to creutzs algorithm yield
the most information in terms of a morphological
language model 
the results for english are the most discouraging 
as figure   shows  neither morph nor morph  
mts classification achieves accuracy scores as
high as baseline  with the worst performance given
by morph   mts  with only     accuracy  once
filtering is introduced  morph   mts accuracy
gradually climbs up toward the accuracy of the
other two classification systems  this suggests
that the   gram morphotactic model is particularly
unsuitable for english morphotactics  since at a
high level of filtering the richness of morphotactic
feature set disappears  and the system works
similar to simple morph classification 

  future work
our success on the turkish test document suggests
that the true potential for better performance stems
from constructing an appropriate morphotactic
model for a language  if the near perfect accuracy
of morph   mts in classifying turkish could be
replicated for other languages  then morphological
and morphotactic feature sets would be more
accurate than character n grams or other current
methods  such as most common substring  at
identifying the language of a document 
furthermore  because such success is achieved at
the word level  these methods would be
appropriate for classifying the language of word
sequences of any length within a multilingual
document  an achievement that n gram character
classification cannot replicate  however  we are as
yet unable to develop accurate classifiers for our
other candidate languages  this may be because
the   gram morphotactic model is appropriate for
the morphology of turkish  but not for other
languages  a different n gram model must be used 
therefore  the first and crucial avenue for future
work is to examine and test this hypothesis 
without a reliable and accurate n gram model of
morphotactics  our proposed morphological
approach does not have much to offer in
comparison to the character based state of the
art  however  if future work does identify
successful n gram morphotactic models for other
languages  other methods can be applied to
attempt to increase performance  for example 
rather than nave bayes classification  one can use
svm for the task  which turned out to be too
computationally costly for the scope of our work 
the lightweight  informationally dense attributes
of morphological features suggest that
morphological approaches to text classification
may be extremely promising  however  with
respect to the language classification task  the
reality of this potential is as yet uncertain 
references
 
    n gram based text categorization  william
b  cavnar  john m  trenkle 
http   citeseer ist psu edu       html 

fiturkish

    statistical identifaction of language  ted
dunning  computing research lab  new mexico
state university 

 

accuracy

   
baseline
morph
morph   mts

   
   
   

  
  

  
 

 

 

d
u

nf

ilt
er
e

 

 

    unsupervised morpheme analysis  morpho
challenge       kurimo  creutz  varjokallino 
http   www cis hut fi morphochallenge     

 

    applying monte carlo techniques to
language identification  arjen poutsma 
smarthaven  amsterdam 

   

filtering

figure  

    unsupervised segmentation of words using
prior distributions of morph length and
frequency  matthias creutz  proceedings from
acl              sapporo  japan  july      

finnish
    
    

figures

accuracy

   
baseline
morph
morph   mts

    
    
    
    

  
  

u

nf

 

 

  

 

 
 

ilt

er

ed

    

filtering

figure  
german
    

baseline
morph
morph   mts

   
   
   

  
  

 
 

er
ilt
u
nf

   

filtering

figure  

   
   

  
  
 

 

  

 

 
 

nf

ilt

er

ed

 

u

accuracy

   

  

ed

   

 

   

 

english

baseline
morph
moprh   mts

    
   
    
    
    
    

 

accuracy

figure  

    
   
    
    
    

filtering

figure  
figure  

fi