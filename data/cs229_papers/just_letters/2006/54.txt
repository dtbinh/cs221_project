extracting meeting topics using speech and documents
katherine brainard  tim chang  and kari lee
cs    final project
   overview
the calo project is an ongoing effort to develop a cognitive assistant that learns and organizes 
stanford csli is working on the meeting assistant section of the calo project  which involves recording
a meeting  dividing the meeting into topics  and summarizing the meeting for later reference  at this
point  automated speech recognition has been used to determine the word distributions of the meetings 
but the topics are difficult to extract because the speech transcripts still have a high word error  our goal
is to first correlate a set of documents with their associated meetings based on their word distributions and
then improve topic extraction for the meetings by using these clusters of related documents and meetings 
   background information
the corpus consists of forty six meetings held by different sets of calo researchers over the course of a
year regarding their ongoing project  thus  many of the meetings discuss very closely related topics 
making the task of distinguishing between separate meetings very challenging  each speaker used a
separate microphone  so there is no confusion about which utterance was made by which speaker 
approximately sixteen of the meetings also have associated documents  which can include e mail threads 
published papers  web pages  attendee notes  and powerpoint presentations  the size of the document sets
range from one to twenty two  and the total number of documents is around eighty 
   preprocessing transcripts and documents
one of our initial problems was that our word vectors were extremely large  because our data is
composed of documents and speech  there were a significant number of words associated with each
transcript we read  thus  before assembling our word vectors  we explored various hypotheses on how
the removal of certain words would impact the effectiveness of our clustering algorithms  these five
hypotheses are as follows 
first  we sifted out all punctuation from the text other than hyphens  changed all letters to lower case 
changed all contractions to two distinct words  removed all stop words  filler words devoid of content 
such as uh   and removed non verbal expressions  such as  laugh    this filtration reduces the word
vector size  and also reduces the differences between the meeting transcripts and their associated
documents  thus  we hypothesized that this filtration will always improve our clustering 
second  the transcripts from the speech recognizer could be output in a format that either included or
excluded the names of each speaker  presumably  including the names of the speakers would lead to a
high similarity between the transcripts themselves and cause them to group with each other rather than
with the documents  thus  we hypothesized that removing the names would increase the effectiveness of
clustering 
third  we decided to test the effect of stripped rare words  those that only appear once in any of the
documents  out of the documents  we hypothesized that this smoothing would increase the effectiveness
of the clustering by making them more similar overall  which in fact it did  we then tailored the
algorithms and our processing of the data to more effectively deal with the disparities between meeting
transcripts and documents 

fifourth  we tested the effects of removing numerical digits from the documents and transcripts  we
hypothesized that even though documents may cluster on these items  they would reveal little about the
topics of the documents and meetings  and thus could lead to adverse effects on our clustering coherency 
it turns out that removing digits had a negligible effect on clustering 
finally  we removed all but the top    words from each word vector to see if we could isolate only the
most important words to cluster on  unfortunately  this actually hurt performance  as too much
information was lost in this blind eradication of words  the more intelligent removal of words from our
general filtering was much more effective in reducing our error rates 
   algorithms
the central algorithm to our project was k means  k means is a simple coordinate descent algorithm that
has been extended and applied extensively in text classification            it turns out that k means is
both quick and fairly effective for document and speech clustering  note that we treated the meeting
transcripts as documents  so in this paper we occasionally use the term document to refer to all
documents and transcripts  a plaintext version of each document was created for every file that was not
originally in plaintext 
we tried four main variations of k means  the first variation was the standard algorithm  the number of
clusters chosen was     which is the same as the number of meetings in the corpus  the clusters were
originally initialized by randomly selecting existing documents and setting the centroids of the clusters to
be equal to the selected documents  the algorithm was run until the cluster centroids no longer moved
within a tolerance of        this algorithm worked reasonably  but often developed clusters of either
transcripts or documents  thus  we sought an alternative that would encourage the transcripts to group
with the documents rather than with each other 
this was achieved with our second variation  we initialized each centroid to an associated transcript
rather than a random document  and proceeded to run k means from there  this method has two
advantages  first  the transcripts and documents are now forced to cluster together  so we didn t have to
worry about normalizing spoken text to written text  second  since the clusters were no longer random
and the search space was extremely dependant on the initialization  we could now more accurately
compare error rates of the algorithm run on different sets of pre processed data  however  this method
also encouraged documents that start off being clustered in the  correct  cluster to move away from their
original location  which increased our error rates 
our third variation of k means attempted to take this initialization one step further by fixing the meeting
transcripts to a particular cluster  the cluster centroids could change in successive iterations due to the
assignment of the documents  but the assigned transcript would in some way anchor the cluster to a
particular region 
the last variation of k means only ran the algorithm for one iteration  which forced the documents to
cluster solely based on their initial distance to the different transcripts  the idea behind this method is that
it would provide a hard comparison of the difference between each transcript and all the documents 
which may be more representative of topical relevance than a result achieved by allowing the system to
conduct coordinate descent to some optimal value  in this case  each document would be clustered with its
closest transcript without having the possibly of moving away from the cluster due to other similar
documents not in its meeting  this last method actually worked well for badly processed data  but our
lowest error rates came from running allowing k means to run in full on properly processed data with the
centroids initialized to the meeting transcripts 

fiin addition to these four variations on k means  we also tried two different ways of weighting the word
vectors that we generated from our preprocessing  first  we weighted the words in each vector by their
tfidf  term frequency inverse document frequency  scores  the tfidf weight for word j in
 n 
 where tf   number of times j occurs in i  n   number of documents in
document i is wij   tf ij  log
 df 
 j
the corpus  and df   number of documents in which j occurs  this reduces the weight of common words in
a word vector and increases the relevance of unique words in determining the similarity of two vectors 
overall  tfidf focuses the clusters on words that are central to the meeting s topic by discounting words
that offer no discriminating value between the documents  second  we normalized the lengths of both the
transcripts vectors and the documents vectors  which prevented the documents from clustering to the
shortest meeting  these weighting mechanisms  combined with appropriate filtering  allowed us to
improve dramatically from the baseline performance 
   results
we scored the results of the algorithm as follows  for each meeting  we find the cluster which contains the
largest proportion of the documents for that meeting  the coherency error is a measure of cluster purity the percent of documents in the cluster that are not for that meeting  the density error for the meeting is
the percent of the documents for the meetings that are not in that cluster  in the example below  meeting  
has the largest proportion of its documents in cluster a  because the total size of cluster a is    the
coherency error is                meeting   has   total documents  so its density error is              
cluster a
 
 

meeting  
meeting  

cluster b
 
 

looking at both these error rates gives a better view of how the algorithm is performing than looking at
either separately  a perfect clustering would have coherency and density scores of    an improvement in
density error accompanied by a decrease in coherency error tends to reflect fewer  larger clusters
containing multiple meetings  while an improvement in coherency accompanied by a decrease in density
tends to reflect lots of small clusters with very fragmented meetings  neither of these is ideal  so using
both measures prevents optimizing our clusters with respect to one error value without actually
improving the quality of the clusters 
our main results can be seen in the table below 
filtering top   

tfidf

fixed meeting transcripts coherency
density error
to each cluster
error

no

no

no

no

    

    

yes

no

no

no

    

    

yes

yes

no

no

    

    

yes

yes

no

yes

    

    

yes

yes

yes

yes

    

    

yes

no

yes

yes

    

    

yes

no

yes

no

    

    

the first row of the table is our baseline  the very low density error is a result of everything basically
clustering into one cluster  which can be seen in the high coherency error  the last row of the table

firepresents the best score we achieved  while the density error is worse than the baseline  it reflects a much
higher degree of clustering by topic  as shown by the significantly reduced coherency error  we can see
that filtering and tfidf improved both the coherency and density error of our clustering  however  it
came as a surprise that allowing meeting transcripts travel between clusters actually improved the
coherency error and the density error  this was unexpected because we assumed that allowing for
moving transcripts would allow the transcripts to cluster together too much  apparently the combined use
of filtering and tfidf prevented this from being a significant problem and instead  allowing k means to
run in full actually encourage the transcripts to move towards more similar documents rather than each
other 
as a whole  the error rates from our table seem to be very high  however  we made a couple assumptions
on our metrics that are slight approximations to what we want  so at some point further reduction of these
error rates would deviate from our true goal  first  although these documents were assigned by meeting
participants to their associated meetings  there may be documents from other topically related meetings
that may also be beneficial  thus  direct correlation between meetings and documents may not always
provide us with the best results  second  these error scores are artificially raised because many of the
meetings had the same documents associated with them  and clearly the same document can t cluster with
two different meetings  finally  some documents may be tied only tangentially with a meeting  perhaps
with some topic that was only touched upon briefly in the meeting  thus  these documents  although they
should belong to that meeting  could be classified elsewhere because their primary topics may not align
with the primary topics from the meeting 
   qualitative topic extraction
having seen the results and limitations of our clustering algorithm  we decided we needed additional
information to determine if the clusters were actually being grouped by topic correctly  unfortunately  we
could not come up with a great quantitative measure of topic relevance other than the ones we have
already trained on  thus  in order for us to observe the topic cohesion of each cluster  we developed four
qualitative metrics to determine the effectiveness of our algorithm  the clusters themselves are word
vectors that represent the centroids of the documents and meetings that belong to that cluster  thus  their
word frequency values are used to determine what words are most representative of the documents in that
cluster  an example of all four metrics for each cluster in presented in  b   these metrics also are a very
crude form of topic extraction that could be used for future extensions 
first  we determined the most similar words in each cluster  similar here is a misnomer  it actually refers
to the similarity in the tfidf value of the word  we chose the words in each cluster that had the smallest
squared distance between all the documents and meetings in that cluster  this was then weighted by the
frequency of the word to avoid the fact that words with small frequencies would all tend to cluster
together  since they very little variation  
second  we determined the most different words in a cluster with respect to all other clusters  again 
different here is a misnomer because difference refers to a difference in tfidf value and not in the actual
appearance of a word  we chose these words as the greatest squared distance between the cluster and all
other clusters  weighted by the frequency of the word to prevent the selection of low frequency words that
may not be representative of the words in this cluster 
finally  we determined the most common and least common words in a cluster based on the size of the
tfidf value  therefore  the least common words can actually be very common by number of occurrences
if the document frequency is high 
looking at the results  we found that the  most different words between clusters  gave us the most
qualitative coherency of topics for a given cluster  for example  cluster    has words like  recruiters  

fi people    hr    talent   and  employees   when we looked at the actual content of the meetings and
documents associated with this cluster  it turns out the meeting was about hiring a new software developer
for the team  with associated documents on best hiring practices  many of the  different words  for the
other clusters were found to have similar cohesion in their topics as well  thus  from a human heuristic
standpoint  it appears that our algorithm works quite well on grouping documents and meetings by topic 
furthermore  it turns out that our method using associated documents to help us extract topics from the
meetings despite speech recognition errors is highly effective  cluster     contains the word wubhub
among its most different words list  the cluster consists of a meeting and some of its related
documents  although part of the meeting is spent discussing the website wubhub  the speech
recognizer interpreted the term in various ways such as what pulp  nowhere in the meeting transcript
does the term wubhub appear  but the word was still able to be extracted in the cluster topic from the
related documents 
   further work
further work on this topic could be conducted in several ways  first  having more meeting transcripts
with uniquely associated documents would be very helpful  since our data set was fairly small 
additional meetings could be used to identify errors caused by quirks in the data and make sure that our
filtering does not over fit the data  second  using the probabilities associated with each word  generated
by the speech recognition system  could also be helpful  this might reduce errors in a situation where the
recognizer picks the wrong word  but the correct word has a very similar score  another algorithm that we
could experiment with is fuzzy clustering  where documents can belong to more than one cluster  this
might help the solve problem of having documents assigned to more than one meeting  finally  we could
also try pca to further reduce the noise in the data by reducing the dimensionality of the word vectors 
references
    dhillon  inderjit  jacob kogan and charles nicholas  feature selection and document clustering 
cadip research symposium       
    hotho  a  s staab  g stumme  wordnet improves text document clustering  proceedings of the
sigir      semantic web workshop  maryland       
    karypis  george  vipin kumar and michael steinbach  a comparison of document clustering
techniques  kkd workshop on text mining       
    zhao  y  and g  karypis  empirical and theoretical comparisons of selected criterion functions for
document clustering  machine learning  vol     number    pages          boston  kluwer
academic publishers  june      

fi