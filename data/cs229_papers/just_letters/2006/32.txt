rotation invariant sparse coding and pca
nathan pflueger  ryan timmons

abstract  we attempt to encode an image in a fashion that is only weakly dependent on rotation of objects
within the image  as an expansion of roger grosses work on translation invariant sparse coding 
our approach is to specify only a small set of basis images  from which some reasonably large number
rotated bases are calculated  the image is trained to this set of rotated bases  so that ultimately the spare
code representation is given in terms of rotations of a small set of vectors 
we develop an image representation scheme and several algorithms suited to this problem  particularly
gradient descent methods for sparse coding and an investigation of rotation invariant principal components
analysis  our experimental results suggest that pca is significantly more fruitful  unless better algorithms
for the sparse coding side can be developed in the future 

   motivation
we are motivated ultimately by image recognition and classification  all existing algorithms are overly
sensitive to rotations  and often translations  of the image  which can drastically alter the way it is encoded
and thus the way an algorithm might classify it  this research is aimed at producing an image coding method
in which even rotations of individual objects in the image will not drastically alter the image representation 
as an example  an image might contain several objects  each of which can rotate freely  we develop a system
in which all possible rotations of these objects would be coded nearly identically  differing only in the index
of some coefficients   in a manner that is not predisposed to any orientation of the overall image  or indeed
the orientation of any subportion of it 

   rotation formulation and image construction
the base for both our sparse coding and pca attempts is a robust formalism for representing the image
in terms of rotated bases 
the building blocks of our image representation are circular image patches  a parameter n  the radius of
the patches  is given  and each patch is represented in two forms  as a  n       n     matrix  where those
entries of distance greater than n from the center are ignored  and as a column vector listing all the elements
within distance n of the center in an arbitrary order 
the vector representation allows rotations to be defined simply as linear transformations of vectors  in
particular  before construction begins  we define the number of rotations r  and rotation matrices t            tr
are calculated to represent rotating a vector by  i
r radians  note that while ideally these would form a group
under multiplication  there is some distortion due to fitting images into pixels  so we generally compute each
ti individually rather than composing them with each other 
given a basis set b of b vectors  a radius n  and a number of rotations r  we use the following procedure to
construct the image from these bases  the image specification is given by a b  r  w  h matrix s  where
w  h are the dimensions of the image  s gives the weights of each possible rotation of each basis  centered on
each point in the image 
we first construct the intermediate matrix z  which is w  h  m 

date     december      
 

fi 

nathan pflueger  ryan timmons

   

zx y    

r
x

t    j bs  j x y  

j  

in words  z gives the content of the image patches centered at a given point  in vector form  each value of
j constitutes a different rotation of the basis vectors  and these are summed to gain the overall patch centered
at the point  next z must be expanded into y   the value at each point  x  y  is the sum of the contributions
from all nearby pixels  in particular  for each pixel within n units of  x  y   there is a unique value of i such
that the point  x  y  corresponds to the ith entry in the vector for the patch centered at the nearby point 
thus y is given as follows 

   

yx y  

m
x

zx uxy  i  y vxy  i   

i  

in the above summation  the functions u  v simply transform from a point x  y to a new point u  v  according
to that point in the image where component i of the basis patches centered on  u  v  contribute to the shading
at  x  y  
above  we interpret the indices of z to be numbers in modulo w and h respectively  so that bases in
fact wrap around the edge of the image  this is in the style of      and achieves a pleasing symmetry in
the representation  though the problem could certainly be formulated otherwise  note we can also write this
explicitly as the following horrific summation 

   

yx y  

m x
r x
b
x

 t    j b i k sk j uxy  i  vxy  i   

i   j   k  

the is the basic image construction model on which all of our procedures are built 
   sparse coding
denote the image constructed from s by y   then we pose the following sparse coding optimization problem  for some constant  

   

minimizes b fobj     x  y         s    subject to  bi        

note that this formulation is identical to that used in     and      though the method of constructing y
from s differs  it is as described in the previous section 
as in     and      the optimization problem is divided into two problems  image reconstruction and basis
learning  we solve these two problems in alternation  due to the complexity of dealing with the fourdimensional matrix s  the only algorithms we were able to make practical used some form of gradient descent 
coupled with a modified version of the feature sign algorithm in     
     algorithms  the relevant gradients can be computed as follows  we must introduce some new nota 
tion  the functions u    v   are the reverse functions for u  v discussed above   u zw  i   vzw
 i   converts from the
coordinates of the center  z  w  of a basis patch to the point influenced by the ith component of the basis
vector centered at  x  y  

   


sc d z w

   

m
x

   i   
 t    d b i c  x  y  u zw  i  vzw

i  

for implementation purposes  it is most efficient to precalculate two matrices for each value of i  mi  
 ti      b t and ni    x  y  u   v    noting that

firotation invariant sparse coding and pca

 s   x  y          z w    

   

m
x

 

mi   ni  z w  

i  

this is the equation used to calculated gradient in our algorithm  it must be calculated for each coordinate
pair  z  w  
similarly to the feature sign algorithm in      we implicitly keep track of the desired sign of each coefficient
in s  compute the gradient of fobj assuming these signs  and then perform a line search in the direction of this
gradient  this cannot be done in closed form since the gradient involves both the coefficients of s   x  y    
and also s   s      thus we use the following algorithm to optimize     in terms of s 
   
   
   
   

initialize s    
compute the gradient g of   x  y     with respect to s
set to zero all elements of g  of magnitude less then 
guess the signs of all elements of s according to either their current sign  or the sign that they will
become according to the gradient  and use this to compute s   s    and thus s fobj  
    compute in closed form the ideal  so that s  s fobj minimizes the objective function  assuming
that no signs will change 
    using this value of  as an upper bound  find the true optimal   allowing for sign changes  by
successively increasing and decreasing   and computing the resulting objective function 
    once the previous step converges  return to step     
in essence  this algorithm guesses a descent direction which will certainly be locally true  and then using
efficient guess and check  a much more efficient calculation that computing the gradient anew   performs a
line search along this direction  before computing a new gradient and thus a new direction 
likewise  the basis solving step is accomplished by gradient descent  here we trade the troublesome   s   
error term in equation      which is invariant with b  for the regularization condition   bi         the gradient
can be computed  after some difficulty  as 
 
m
x
x
t
b fobj    
t  i        
 x  y  i y su v  
i  

x y

here u  v are functions discussed above to transform from vector to matrix representational forms  our
algorithm successively computes the gradient  performs a small step in that direction  and then projects to
satisfy the regularization term  much as in      this algorithm is not terribly fast  but converges reasonably
well in only   to    iterations 
     experimental results  we applied these two algorithms  in alternation  to images from the caltech   
dataset        in particular  we tested on images from the categories yin yang  soccer ball  and water
lily  in all cases  we found that our algorithms only tended to produce very simple sparse coding bases  not
nearly as robust as those found in traditional efforts  more often than not  bases would train to gray sets such
as the following 

bases such as these resulted from random initilialization as well as most hand made bases that we attempted
to use  a notable exception was the use of hand defined gabor filters  the original bases  and the result of
the learning  are shown 

this resulted in those bases sufficiently suited to edge detection being spread out into pure edge detectors 
this was further reinforced by the resulting basis activations  shown for a ying yang image below  note that
the only bases being used for image coding are the edge detectors and solid white patches to give the overall
brightness 
in this diagram  and in several in the future  the image on the left is the original image  the image on the
right is the reconstructed  in between are shown all basis vectors  and the region on which they are used 

fi 

nathan pflueger  ryan timmons

regardless of rotation  dark is high negative activation  light is high positive activation  gray is zero  

in general  attempts to apply our sparse coding algorithms in their current form  for all values of  we
attempted  simply created the blurry images shown above  though it is interesting that general edge detectors
have a tendency to arise 

   principal components analysis
an unanticipated but quite fruitful alternate effort in our research was instead to learn rotation invariant
principal components  rather than sparse bases  there are a number of ways to pose this problem  our first
attempt  and ultimately the only tractable option we were able to uncover  is simply to compute the principal
components of all rotations of all patches in an initial image set  the net effect achieves significant rotation
invariance  a particular patch being rotated will not affect the principal components found  since all possible
rotations are given equal weight in finding these components 
algorithmically  we applied the pca formulation from class to the set of all rotations of all patches from
the images being trained  in particular  each w  h image generates w  h patches of radius n  each of which
is rotated r times to produce a total of w  h  r vectors for each image  the sum of the outer products of
all these vectors is computed  and the rotation invariant principal components are the eigenvectors of this sum 

     results  the resulting components learned are fascinating in their own right as curious visual patterns 
and reveal interesting things about the structure of natural images  we ran trials on the yin yang  soccer
ball and water lily categories of      and all produced qualitatively similar components  so we shall present
only the result of training on the water lilies  below is shown the full set of principal components learned on
the water lily category  with patches having radius    pixels  and    total rotations allowed 

it is also of interest to observe the activation patterns of the top several eigenpatches on one particular
image  shown below are the encodings of two images from      which were encoded with our same algorithm
from sparse coding  altough we set        as before  the images on the left are the originals  the images
on the right are encoded  and in the center are shown each basis and the density of its activation  where all
rotations are considered equally  note the two example below come from different trials  so they use different
basis sets 

firotation invariant sparse coding and pca

 

we note first of all that  like in rotation invariant sparse coding  rotation invariant pca also leads to
patches easily recognizable as edge detectors  of varying complexity  substantial further investigation might
be possible into the utility of these more complex rotational edge detectors  and their applications to image
description  classification  and recognition 
   future work
first and foremost  it would be of interest for future research to refine our sparse coding algorithms until
they can produce results comparable to existing procedures  even under the added duress of the computational
difficulty  both the results of successful pca and sparse coding would likely be very robust if applied to
object classification problems  having achieved a robust form of rotation invariance 
   acknowledgements
we would like to thank honglak lee and roger grosse for their invaluable advice and support throughout
this project  we would also like to recognize mark linsey  who contributed to the early stages of this research
but was unable to remain on the team 

references
    fei fei  l   r  fergus and p  perona  learning generative visual models from few training examples  an incremental bayesian
approach tested on     object categories  ieee  cvpr       workshop on generative model based vision      
    grosse  r  translation invarient sparse coding  unpublished write up       
    lee  h   alexis battle  rajat raina and andrew ng  efficient sparse coding algorithms  end stopping  and ncrf surround
suppression  unpublished draft       

fi