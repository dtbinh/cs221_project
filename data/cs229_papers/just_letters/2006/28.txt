programming by example gesture recognition
kevin gabayan  steven lansel
december         
abstract
machine learning and hardware improvements to a programming by example rapid prototyping
system are proposed  exemplar  a sensor interaction prototyping software and hardware
environment  currently uses a dynamic time warping gesture recognition approach involving
single signal channels  we use a five channel accelerometer and gyroscope combination board to
sample translational and rotational accelerations  and a microcontroller to perform analog to
digital conversion and relay incoming signals  template matching via linear time warping  ltw 
and dynamic time warping  dtw  are performed offline  as well as reinforcement learning via
hidden markov models  hmm  in real time 

background
exemplar is a current research project of the stanford hci group  a
programming by example tool for interaction designers used to
rapidly prototype interactions involving sensors  it consists of a
microcontroller board  a variety of sensors  and a gui used to
visualize multiple signals  specify detection thresholds and windows 
and map outputs  a user can perform a gesture using the available
sensors and then view the gesture signal within a signal buffer  he can
then markup the signal plot with signal threshold values beyond which
an event will be triggered  the user may also select a time window
that contains the gesture to train a gesture recognizer that will trigger
events when the gesture is repeated  the pattern recognizer currently
uses a dynamic time warping  dtw  algorithm that is intended to
recognize gestures from a single training example  but it is not robust  we would like to improve
the detection and classification accuracy of the gesture recognition system and allow a wider
vocabulary of gestures to be detected by performing recognition across multiple signal channels 
a demonstration video of the current system is available at http   hci stanford edu exemplar  

hardware
to increase the amount of information available to the gesture
recognizer  weve used a five degree of freedom inertia measurement
unit  imu  combination board  the board includes the   axis analog
devices adxl    accelerometer chip providing accelerations in x  y 
and z axes and the dual axis invensense idg    gyroscope chip
providing roll and pitch 

weve built a power and data relay board  which regulates usb power from
 v to    v and relays the imu boards analog outputs to the microcontroller
ports  a long ribbon cable connects the imu board to its power and data board
so that users will only have to hold the small and light imu board while
performing gestures 

firecording template gestures
the imu board output was digitally sampled at    hz at    bit resolution while sets of six to ten
examples of each training gesture were performed while holding the imu  these gestures
included motions common to a kitchen   fry  pound  tossplate  rolldough  etc    motions
common to sports action games   lasso  punch  tennisserve  spy   drawing numbers   through
  in the air  and other miscellaneous gestures  wavehello  conductbeats  chickendance  

detection algorithm using linear time warping
   smooth incoming data and all training gestures with rectangular window of length    
   for each gesture in the training set  generate   gesture templates of varying lengths
uniformly distributed over     to      of the original gesture length  the value for
each sample of the scaled gesture templates was found using weighted averaging of the
two sample values from the training gesture that are closest to the same percent from the
beginning of the signal to the end as the original point in the template 
   for each of the above gesture templates  select windows throughout the input data that
have the same length as the template and use hop size of   samples 
   the distance between each of the gesture templates and the window from the input data is
calculated using an average absolute error metric for all three accelerometer readings
   if the input data window has a variance lower than a particular predefined constant  we
add a penalty to the above distance measure  the penalty is directly proportional to the
deviation of the window variance from the predefined constant  the proportionality
constant is chosen so that a window with variance   has a penalty equal to a predefined
parameter   
   any of the gesture templates that generate a penalized distance larger than a threshold are
discarded  the remaining gesture templates are plotted in the figure below on the left 
   out of the remaining gesture templates  declare that the gesture template with the
minimum penalized distance metric occurred 
   remove all remaining gesture templates that have a nonempty overlap in time with the
recently declared gesture template 
   repeat steps   and   until there are no remaining gesture templates  the final result is
plotted in the figure below on the right 
matching algorithm plots for a series of nine consecutive number   gestures
 notice the number   gesture is very similar to the number   gesture so this is why the  
gesture was a close match on the left  
final declared gesture sequence

  

  

  

  

penalized distance metric

penalized distance metric

all gesture templates with distance less than threshold

  

  

  

  

  

  

three
two
 

   
    
    
sample index from data

    

two
 

   
    
    
sample index from data

    

fidiscussion of algorithm steps
step    smoothing is needed to remove noise in the accelerometer data and generate velocity like
signals that are easier to match  the length of the filter was chosen to adequately remove the
noise but not destroy the underlying signal 
step    we provide an example of how the scaling works  if we count the samples starting with
   the value of sample   in a gesture template of length     samples generated from a training
gesture of length    samples is equal to     times the value of sample   plus     times the value
of sample   from the training gesture because              
step    without the variance penalty  the algorithm generated a number of false positives  a
majority of these errors occurred when the incoming data window had a small energy
corresponding to periods of inactivity of the input device  in general  it is easy to match a gesture
to a period of low activity since gestures in general have low energy  it was decided to use a
variance penalty instead of a hard variance threshold so that gestures that match very well but
have low variance can still be detected  varying the parameter  adjusts the relative importance
of the distance metric and variance penalty 
step    instead of discarding gesture templates that have nonempty overlap  it may be an
improvement to only discard gesture templates that have an overlap larger than a small
percentage of both gesture templates  this will make the algorithm more robust when the
incoming data has a quick series of gestures without intermittent pauses 

linear time warping performance
the above algorithm has been tested in matlab with   different gestures  a single instance of
each gesture was used for training  and a total of    test gestures were processed  the algorithm
successfully detected and classified all gestures and generated no false positives  the smoothed
accelerometer readings for the input data and the correctly identified gesture are plotted in the
figure below on the left 

dynamic time warping optimal
matching

comparison of input data and matched number  
gesture
x accelerometer

y accelerometer
   
   

   

   

  
   

   

   
   
   
   
z accelerometer

t rain in g g es ture index

   

   

   

   

   

   
   

training gesture
input data

   

horizontal axis  sample index
vertical axis  smoothed reading

   
   

   

   

   
   
                      
time scaled input window index

fidynamic time warping  dtw 
although the above algorithm is able to account for gestures that are performed at a constant
speed different than the training gesture using the windows of different lengths  it may not
perform well for gestures that were performed at a number of different speeds relative to the
training gesture  for example  the first part of a gesture may be performed slower than the
training gesture and the second half may be performed very quickly  with linear time warping 
which was implemented in the final algorithm  the two gestures will be misaligned in time 
dynamic time warping attempts to find the optimal alignment of the two gestures by solving a
dynamic programming problem 
the dtw algorithm was implemented by changing only step   above  an optimal time
alignment found with dtw is shown in the figure above on the right  the optimal alignment
path is highlighted in dark red  for linear time warping  the only alignment path considered is the
one that lies on the diagonal of the figure  orange  light blue  pixels correspond to an optimal
horizontal  vertical  movement from the pixel  and dark blue pixels correspond to a horizontal
movement or a correct matching of those time instants  we decided the dtw was not needed for
our current data set because our gestures had a relatively constant speed within each gesture 
however  the dtw may be needed for more challenging data sets 

hidden markov models  hmms 
the gesture process that governs our imu readings may be modeled with hidden markov models
 hmms   this approach estimates the unobservable gesture process as a state at every time step
and learns from training examples the probabilities of the process transitioning to other states in
the model  our implementation of this hmm classifier in exemplar is based on the georgia tech
gesture toolkit  gt k   which implements the cambridge university hidden markov model
toolkit  htk  
a motionless accelerometer produces a range of output values depending on its tilt due to
gravitational acceleration  so the same gesture performed using multiple orientations will have a
range of raw data values  to correct for this in individual dimensions  baseline values for each
sensor are updated every time the accelerometer becomes still 

bt          bt         s t
where b is the baseline value and alpha is an update weight given to the new motionless sensor
value  chosen to avoid abrupt changes in the baseline value and the affected energy measurement 
the squared difference between sensor input and sensor baseline values is integrated over an
analysis window to generate an energy measurement 
to assist in exemplars training and testing modes of data collection  gestures with energy above
a threshold are automatically segmented  doing so reduces the number of classifications
performed by waiting for gestures of interest  but fails to pick out adjacent gestures that can be
bounded by sliding windows  without having a ui to allow label editing  after a training mode is
begun each successive set of ten gestures is labeled with the same label  the gesture signal
sequences are stored in a library of examples  and an eight state hmm for each label present in
the library is trained on its examples using the viterbi algorithm  in recognition mode  a
segmented gesture is labeled with the hmm whose transition matrix most likely produces an
observation sequence best matching the input 
the system was trained to recognize digits drawn in the air with the imu unit  fifteen training
examples of each digit drawn in the air with motionless periods separating each gesture were

firecorded and used to train the hidden markov models  a test sequence of ten gestures of each
digit produced the following confusion matrix 

 
 
 
 
 
 
 
 
 
 

 
   
 
 
 
 
 
 
 
 
   

 
 
   
 
 
 
 
 
 
 
 

 
 
 
   
   
 
 
 
 
 
 

 
 
 
 
   
 
 
 
 
 
 

 
 
 
 
 
   
 
   
 
 
 

 
 
 
 
   
 
   
 
 
 
 

 
 
 
 
 
 
 
   
 
 
 

 
 
 
 
 
 
 
   
   
 
 

 
 
 
   
 
   
 
   
 
   
 

 
 
 
 
 
 
 
 
 
 
   

confusion matrix  the confusion matrix for the test set of     gestures  the digits in the horizontal entries
are the correct labels of the input signals  and the digits in the vertical entries are the classifier outputs  the
numbers represent the rate at which the inputs were classified under each target class 

these results represent an     digit recognition rate  some digits were classified quite well  and
some were classified perfectly  digit three was more often confused as digit five  the similarities
in the final strokes of both three and five may help explain for this confusion  the addition of
more hmm states and data features may remedy an underfitting of data 

future work
the classifiers may be further generalized by training upon gestures generated by multiple
people  or generating multiple target classes that span the range gesture signals of many people
performing the same gesture  classifier parameters may be tuned for more optimal classification 
such as those controlling sliding window sizes  window scaling  and hmm topologies  ui
elements designed for entering training labels  viewing classifier outcomes  and removing poorly
performed training examples would improve the exemplar user experience 

fi