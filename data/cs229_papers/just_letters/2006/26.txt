automatic identification of red eye in photos
paul cuff
department of electrical engineering
stanford university
stanford  ca         usa
e mail  pcuff stanford edu 

abstract a simple algorithm is proposed for detecting
the red eye defect in photographs on a pixel by pixel
basis  the algorithm implements a support vector machine
using the degree of redness in the surrounding context
as features  results are sub par  chiming in at    false
positives and     false negatives 

i  i ntroduction
from personal experience with photos  i realize
that red eye removal is still a serious annoyance 
many software applications require the user to manually identify red eye in order to remove it  for
this project i use a support vector machine  svm 
to identify which pixels in a picture have red eye 
this can serve as the first step to automatically
replacing the red with appropriate colors  after redeye is successfully identified in photos  a number of
things can be done to automatically correct it  that
is beyond the scope of this project 
algorithms do exist which purport to solve this
problem  due to their often non free nature  i am
under the impression that they are complicated and
proprietary  one goal of this project is not only to
solve the problem but to do so in a simple manner 
demonstrating the capabilities of the svm 
a group at the university of dublin trinity college     attempts to solve this same problem  however  their algorithm is very hand tuned and doesnt
take advantage of the machine learning techniques
that we have studied in this course  their algorithm also misclassified the eyes in various specific
settings  in my opinion this is because it was so
carefully designed for the typical face in an ideal
environment 
i do the entire identification on a pixel by pixel
basis  without first locating the eyes or using any
heuristics  because the classification considers each
pixel individually  i can train the algorithm quite

well with only a few photographs because each
supplies many training pixels of data 
the features that will be passed into the svm will
come from the context of the pixel in question 
by context i mean a small section of the photograph
centered around the pixel  it seems reasonable that
this could work well since the context of a redeye pixel should have red in the center surrounded
by some darker color which is surrounded by some
white  patterns like this should be picked up automatically during the training of the svm 
finding an appropriate inner product for the svm
in this problem provides some difficulty  the difference in photographs is not measured well by
the difference in color intensities of the pixels
for several reasons  one is that the photos might
not have the same temporal scale  one might be
larger than the other  having different resolution  but
still be a very similar picture  another problem is
that two identical pictures with different brightness
will not cancel each other through subtraction  the
approach that i take to resolve these concerns is
discussed in section iii 
the exact feature calculation is explained in section iv  and the collection of training data and svm
parameters are explained in section v  finally  results are summarized in section vi  and conclusions
are drawn in section vii 
ii 

description of problem

when a photograph is taken of a face sometimes
the flash causes the eyes to glow red  the pupil
appears red instead of black and is often larger than
normal  we call this effect  and the affected area 
red eye  the automatic algorithm must correctly
identify all pixels included in the red eye while not

fifig     data matrices  original photograph  left   data matrix i
 center   and data matrix c  right 
fig     manual selection of red eye  original photograph  left  and
manually selected red eye marked in black  right 

incorrectly classifying other regions as red eye  such
as lips or a red coat 
iii  a pproach
i train a support vector machine to classify a
pixel as red eye or not based on the context of the
photograph around the pixel  because each photograph is taken in different lighting and at different
resolution  i do a couple of things to normalize the
contexts so that they can be reasonably compared
with the gaussian kernel  the degree of redness of
each pixel is weighted more heavily in the feature
set  see section iv  than the overall intensity  degree
of redness is invariant to intensity  so that helps
normalize the lighting condition  in addition  i use
several different scalings of each context  by downsampling  when collecting the training samples  see
section v   this way  if the resolution of two
photographs are not exactly the same they might
at least be comparable for one of the combinations
of scalings 

the features that i use for the support vector
machine for a given pixel are all the entrees of i
and c in a        square centered around the
pixel in question  however  for the features that
come from i  the set is first normalized to have zero
mean and a standard deviation of       this way the
overall intensity of the photograph is ignored and
the intensity features play a less important role in
the inner product than the color features 
v  t raining

i took four photographs that contained a total of seven faces affected by red eye and four
photographs that did not contain red eye  i first
manually identified the red eye in photos where it
was present  as illustrated in figure    the top image
in the figure shows a section of the original photo 
and the bottom image shows the same section with
the pixels designated as red eye indicated in black 
i randomly selected     red eye pixels and    
iv  f eatures
non red eye pixels from each of the affected photos 
a photograph can be described using three ma  as well as     pixels from each of the photos that
trices of equal size  r  g  b  that specify the didnt contain red eye  for each selected pixel i
brightness of red  green  and blue in each pixel  collected up to three training samples by gathering
respectively  the element in the ith row and the jth the features described in section iv at three different
column of r will be designated rij   and likewise zoom scales  in other words  i gathered one sample
for the other colors 
using features exactly as described  one after downi form two data matrices  i and c  illustrated in sampling the photo by two  and one after downfigure     from which i will take the features for the sampling the photo by four  in cases where the
algorithm  i and c are the same size as the original selected pixel was too close to the edge of the photo
photo  and i  intensity  represents the brightness of to retrieve the full context  set of features   that data
each pixel while c  color  represents the redness  sample was omitted  in all there were about      
training samples 
iij   rij   gij   bij  
the support vector machine used a gaussian kerrij
nel
with            and the    norm regularization
cij  
 
iij
scaling factor was c      

fifig     automatic classification  original photograph  left  and
red eye marked in black  right 

fig     automatic classification  original photograph  left  and
red eye marked in black  right 

fig     automatic classification  original photograph  left  and
red eye marked in black  right 

vi  r esults
i tested the algorithm on eight photos that werent
used for training  in these photos  each pixel that
wasnt too close to an edge was classified by
gathering the features in the context around it after
down sampling by a factor of two  overall misclassification was around       with false positives at
   and false negatives at     
in figure    figure    figure    and figure   the
pixels classified as red eye are marked in black 
figure   shows an example where the red eye
is correctly identified  but also some skin locations
are incorrectly classified as red eye  figure   nicely
illustrates the fact that the algorithm is not only
searching for red color  notice that the lips are red 
but they are not falsely identified as red eye  on the
other hand  some stray marks on the forehead and
ear are made  and not all of the red eye is completely identified  figure   shows a case where no
red eye exists and the algorithm correctly handled
it  figure   also shows a case with no red eye  yet
the algorithm has some false positives in the skin
region again 
vii  c onclusion
the red eye detection algorithm presented in this
paper takes a simple approach to detect red eye in a
photograph using only a support vector machine and

fig     automatic classification  original photograph  left  and
red eye marked in black  right 

information from the context of each pixel  other
tools could be used in conjunction with this  such
as first identifying faces and eyes before searching
for red eye  but these would also be at the expense
of the simplicity of the algorithm 
the current performance of this algorithm is too
poor to be useful for practical purposes  the false
positive error rate is    on a pixel by pixel basis 
which means that most photographs will contain errors  perhaps with more training data this algorithm
could perform acceptably 
r eferences
    h  y  hui  automated red eye detection   correction  final
year project  the university of dublin  trinity college  april
     

fi