a machine learning approach to opponent
modeling in general game playing
tyler hicks wright         
eric schkufza         
december         
abstract
general game playing is an area of research in artificial intelligence that focuses on the development
of agents that are capable of playing competent and even competitive matches of arbitrary games that they
have never seen before  successful general game playing focuses largely on the search and expansion of
game trees in a limited amount of time  our goal is to further enhance the efficiency of that search by
relaxing the assumption that a player will always select the move that is most detrimental to its opponent
 via minimax  and instead to compute the probabilities with which a player may make its next move  once
those probabilities are determined  an agent can make educated guesses as to which parts of a game tree to
invest search time in  and which can be trimmed from that search all together 

 

general game playing

plementation of a ggp testbed known as gamemaster  at http   games stanford edu      

general game playing is an area of research in artificial intelligence that focuses on the representation
of games in terms of a universal  abstract language
known as game description language  gdl   the
abstract nature of that language allows for the development of intelligent agents that without modification can perform competently on games that they
have never seen before  based on exploitable  common
features of games described within that framework 
gdl allows for the representation of discrete 
multi player  deterministic  complete information
games  gdl represents games as sequences of states
in which each state is represented as a set of facts
that are currently true of the world  for instance  a
particular state of tic tac toe might contain the fact
that there is an x in the center cell   gdl represents
game dynamics as sets of moves that players can perform  players are each permitted one legal move per
state  where the legality of a move is a function of
the facts that hold true in that state  for instance 
in tic tac toe  a player may place an x in the center
square if and only if he is playing the role of x  and
that square is currently empty   gdl allows for turn
based games by specifying that a players only legal
move when it is not his turn  is to noop 
the stanford logic group maintains a working im 

 

opponent move modeling

general game players typically rely on two main techniques for determining which of a host of legal moves
is the best one for them to play  either established
search techniques based on game theory  such as minimax and alpha beta pruning  or because game trees
tend to be too deep to fully search  a suite of heuristics to determine the utility of each players position
during a game 
difficulty often arises because proper application of
game theorys search techniques requires an accurate
evaluation of each state in a game tree  and unfortunately  there is no single heuristic that provides an
accurate state evaluation function for all games  additionally  the cut throat assumption that any other
player will choose the move most detrimental to its
opponents tends to be too strong  as there are a number of games which require cooperation  and can be
un winnable if a player makes the wrong assumption
about some other players intentions 
by forming a conjecture as to the likelihood of a
player choosing a certain move based on its previous
behavior rather than by way of search  two major
 

fido not consider move history 

advantages can be gained  first  assuming low error rates have been achieved  moves can be searched
in order of highest probability  and very low probability moves can be trimmed from search altogether 
this simultaneously decreases game tree search time
and increases the likelihood that the consequences of
a players chosen move will be evaluated more thoroughly  additionally  it allows a player to judge the
expected utility of each of its moves  based on the likelihood of its opponents responses in such a way as
to allow it to improve over the results it would obtain
with traditional methods  consider  for example  a
situation in chess where a player has a winning move
which would be a guaranteed if its opponent didnt
have the option of a sacrifice which created a winning
position for itself  if that player knows that the probability of its opponent playing that sacrifice is very
low  then it can determine that the expected reward
obtained by playing that move is worth the risk of its
opponent discovering the win 

 

 
   

implementation
gamemaster test bed

gamemaster provides a test bed from which it is possible to simulate general games and generate training
data  a suite of games of varying difficulty have already been encoded in gdl and are available for bulk
simulation  a small set of general game players are
also maintained by gamemaster  including a random
player  a deterministic legal player  and an iterative
deepening minimax player 

   

data representation

training data is recorded as a matrix x  where each
row  x i   r a    represents a game state  where a is
the vocabulary of axioms encountered during train i 
ing and xj         indicates whether or not the
j th axiom occurred in the ith game state  for the
games that we considered  the axiom vocabulary  a 
was never so large that the matrix  x  proved unwieldy  however  there may exist some games for
which this representation is infeasible  similarly  each
y  i   r   is an index into the vocabulary of a games
legal moves   
additionally  although not strictly part of a gdl
game state encoding  game states are occasionally
augmented to include the set of legal moves that they
admit 

technique

given an instance of a general game  our technique
is to develop an accurate model of the strategy employed by an opponent while playing that game 
to do so  we simulate matches of that game by replacing every player other than the opponent by a
random player  one that selects a non deterministic
move from the set of legal moves available in each
state    and record both the sequence of states observed during that game  and the corresponding
moves performed by the opponent 
a training set s     x i    y  i      i                 m 
is then formed by creating a pair  x i    y  i    for each
of the game states observed during simulation  where
x i  represents one of those states  and y  i  represents
the move that the opponent performed  the only
restriction that is enforced while developing training
data is that all instances of the games being simulated
are generated from identical initial conditions  for
instance  in the case of tic tac toe  all games begin
with an identical empty board 
from s  a classifier is trained to rank an opponents
legal moves based on the probability that they will
be performed  given some arbitrary game state  the
resulting predictions are markovian  insofar as they

   

classification and move ranking

training data is used to tune a multivariate naive
bayes classifier  modified to make use of chi squared
feature selection  opponent move predictions are
formed by considering the set of legal moves that a
game state allows for and ordering those moves based
on their probability  given the current state 

 
   

experimental results
experiments

experiments were performed on three separate domains  each intended to represent qualitatively
unique opponent types  the mummy maze domain 
the tic tac toe domain  and the racetrack domain 

  remark 

because the ggp framework does not support
non determinism  non determinism can be artificially injected
by introducing a random player thats only purpose is to manipulate game dynamics 

 

fition of traditional game theoretic techniques computationally infeasible 
training data was obtained by simulating    
games of racetrack between a random player and a
general game player designed to augment iterativedeepening minimax search with game state utility
estimation heuristics  the objective of the experiment was to determine whether our opponent modeler could successfully predict an imperfect strategy 
figure    the mummy maze and racetrack domains
     

   
     

mummy maze

the mummy maze domain is a one player game 
played on an  x  grid  the objective is to maneuver an explorer  one step at a time between adjacent
cells towards an exit  additionally  the explorer must
avoid a mummy  which is allowed two steps for each of
his own  but is constrained to move in a deterministic
fashion  first horizontally towards the explorer if possible  and then vertically if possible   successful play
involves capitalizing on the mummys determinism to
trap him safely behind walls 
training data was obtained by simulating    
games of mummy maze played by a random explorer 
the objective of the experiment was to determine
whether our opponent modeler could successfully predict a deterministic strategy 
     

mummy maze

figure   presents a top n curve for the mummy maze
domain obtained by accumulating predictions made
over ten test games  it plots the percentage of instances in which the moves performed by the mummy
were ranked somewhere between   and n 

tic tac toe

the tic tac toe domain is a simulation of the well
known two player game with the advantage that its
relatively small size  the complete game tree contains
just over         states  allows for the application
of traditional game theoretic techniques  such as the
minimax algorithm 
training data was obtained by simulating    
games of tic tac toe between a random player and a
minimax player  the objective of the experiment was
to determine whether our opponent modeler could
successfully predict a perfect strategy 
     

results

figure    top n curve for mummy maze
the results are encouraging  for n      there was
a      chance that the mummys moves would be
ranked somewhere between   and n 
being able to outright discount eight of the twentyfive legal moves available to the mummy for each turn
amounts to an enormous saving in number of the
number of nodes that need to be explored to reach a
given search depth in the mummy maze game tree 
figures   and   explore this fact further  their contours represent the number of nodes that need to be
explored to reach a given search depth while remaining p  confident that at each level of that search 
the moves actually performed by the mummy will be
considered 

race track

the racetrack domain is a two player game in which
players attempt to move from one end of a hallway
to the other in as little time as possible while at the
same time are given the ability to place walls in their
opponents way  its modest size renders the applica 

fitraining solely on game state data and assuming every
move to be legal in every state  although a poorer result than that obtained for mummy maze  it suggests
that even in the absence of legal move information 
some intelligent predictions can still be made through
application of our technique  the pink curve  which
represents a modest improvement  was obtained by
training on game state data  augmented with the set
of legal moves available to each player at each state 
finally  the maroon curve represents the results obtained when only the legal moves available to a player
were considered for each state  a much stronger result  it suggests behavior more typical of what might
be expected if our technique were to be employed
during a live game 
figure    confidence manifold for mummy maze

figure    top n curves for tic tac toe

     

figure    confidence contours for mummy maze

figure   presents a top n curve for the racetrack
domain based on ten test games  it is encouraging to
note its similarity to the top n curve obtained for
mummy maze  even when confronted by an opponent that makes heavy use of non deterministic
heuristics and incomplete information  our opponent
modeling technique appears to be able to to safely
eliminate the need to explore every legal move available to that opponent 

the results suggest that a player with fixed computational resources would be able to search down
several additional levels than it would have been able
to otherwise  if it were willing to make only a modest sacrifice in the certainty that it considered the
mummys actual moves at each level 
     

race track

tic tac toe

figure   presents top n curves for the tic tac toe
domain based on ten test games  tic tac toe differs
from mummy maze in a significant way  the set of
legal moves available to a player varies as the game
progresses  in particular  a legal move can only be
played once  
the blue curve represents the results obtained by

   
     

error analysis
mummy maze

the primary source of error in the mummy maze domain was the abundance of instances observed during
training where the move performed by the mummy
 

fiproven itself useful and computationally feasible  the
next step in its development is its deployment as a
standard feature to be used by the general game
players maintained by gamemaster 
once successfully integrated into gamemaster  additional work might focus on the implementation of
on line learning techniques and more sophisticated
feature selection algorithms 

   

transfer learning is a field of artificial intelligence
that attempts to formalize the mechanisms by which
an agent trained on a particular game can apply that
knowledge to games of varying degrees of similarity 
as an attempt to apply our work to transfer learning  we will consider the implementation of opponent
modeling techniques that through source game experience can develop opponent models that can be
applied to target games that differ slightly in their
axiomitization  in the case of tic tac toe for instance 
to games that begin with non empty boards  

figure    top n curve for racetrack
was  move  nowhere nowhere   this occurred every other move  when it was the explorers turn to
move  and whenever the mummy was stuck behind
a wall  which happened frequently   the resulting
bias in the training data presumably caused the classifier to over fit itself to classifying  move  nowhere
nowhere   making it less likely that the mummys
actual move could be identified 
training only on instances when it is a players turn
to move  for turn based games  and narrowing the
number of legal moves available to a player in a state
by disallowing moves that would require a player to
move through a wall might help significantly 
     

 

   

conclusion

the technique presented in this paper for probabilistic opponent modeling produced strong results 
wherever applied  it afforded the possibility of ignoring some subset of an opponents legal moves when
performing game tree search 
in the future  in combination with existing heuristics  the rankings that it generates for each of an
opponents legal moves might be used to better estimate state utility  in combination with existing game
theoretic techniques  such as alpha beta pruning  its
rankings might be used to promote earlier pruning
and gains in computational efficiency 

race track

classification accuracy suffered greatly in the racetrack domain due to the fact that its legal moves are
specified absolutely  move white a   b    as opposed to relatively  move down   this fact forced
the classifier to tune itself to    different moves  which
greatly reduced the amount of training data available
to each  a re axiomization of the rules of racetrack
to make use of relative moves would greatly increase
the accuracy of the classifier and effectiveness of our
modeling technique 

 

application to transfer learning

future work
deployment on gamemaster

the underlying motivation beneath this paper was
standardization and proofing of an opponent modeling technique to be used as a general game playing heuristic  to the extend that that technique has
 

fi