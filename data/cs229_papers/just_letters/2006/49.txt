pose estimation from occluded images
kanako hayashi
kanako hayashi stanford edu

lionel heng
lionel heng cs stanford edu

abstract

vikram srivastava
vicky    stanford edu

problem  we use silhouettes with interior edge information
as they are invariant to many nuisance parameters such as
illumination  clothing  color and texture  these silhouettes
are represented by shape contexts      which are robust feature descriptors 
to estimate the pose in an input image given a database
of images with known  d poses  we find shape context descriptors whose distances from the context descriptor representing the pose in the input image are less than a specified
threshold  to estimate the parameters for the input pose  we
compute the weighted average of the body part positions
corresponding to these shape context descriptors 

we propose a learning based framework for inferring the
 d pose of a person from monocular image sequences  we
generate a silhouette from each input image via a robust
background subtraction algorithm  and compute the corresponding shape context descriptor using the shape context
algorithm  we compute the weighted average of neighbor
poses in a database to estimate the positions of different
body parts in the input image  we discuss several ways to
make the framework more robust 

   introduction
   previous work

the estimation and tracking of  d human body pose is a
challenging problem in computer vision  this problem has
important applications in a wide variety of areas such as
visual surveillance and human computer interaction  with
tools to recover  d human body pose from images  computers can model and recognize human behaviors and analyze
human body dynamics 
to make pose estimation more robust to ambiguities
resulting from occlusion of body parts  cluttered backgrounds  varied clothing and other nuisance parameters  we
can use a range camera     or multiple cameras      however  it is desirable to be able to estimate  d poses using
monocular vision as the use of a multiple camera setup or
a range camera is infeasible for many situations such as
surveillance and analysis of archived videos 
there are two types of approaches to the pose estimation problem  example based and model based  generally  example based approaches utilize supervised learning
in which we store a set of training examples with known
 d poses  search for training examples similar to the given
input image  and interpolate from the set of poses corresponding to the similar training images  in contrast  modelbased approaches assume an explicitly known parametric
body model  and estimate the pose either by directly inverting the kinematics or by numerically optimizing some
form of model image correspondence metric over the pose
variables  using a forward rendering model to predict the
images 
we adopt an example based approach in order to avoid
the use of complicated models and overcome the occlusion

there has been much recent work on the monocular pose
estimation problem  sigal et al      adopts a model based
approach  eliminating the use of a database  this approach
uses a learned mixtures of experts  moe  model to infer a
distribution of  d poses conditioned on  d poses  however  this approach is constrained to finding  d pose in a
monocular image sequence  and does not work for a single
image  in addition  this approach makes assumptions about
a reasonable image likelihood model and the availability of
detectors for specific body parts  in      shape contexts are
used to represent the contour shape of the human body  resulting in generally accurate pose estimation  but we can do
better by utilizing useful information relating to appearance
within a silhouette  such as the presence of body parts  especially the arms  within the silhouette  also  this approach
has a high time complexity and can take several minutes for
the analysis of a single image  hence it is infeasible for a
real time system  in      parameter sensitive hashing permits possibly real time pose estimation  the estimation of
 d pose from single input images gives rise to ambiguous
poses in some cases  but we can use a tracking framework
such as in     to mitigate this problem  our approach to the
monocular pose estimation problem is similar to      but we
introduce interior edge information into silhouettes  and use
parameter sensitive hashing to quickly infer the body joint
angles from a single image 
none of the approaches discussed so far take into account the problem of occlusion by foreign objects  the features used to describe the pose can change drastically under
 

fiocclusion  the bottom up approaches  as described in     
which depend on finding the different body parts may fail
to operate under such cases  hence  we model the effects
of occlusion explicitly in order to make the system more robust  we specifically investigate occlusions in five different
ways which can cover most of the scenarios we can come
across practically 

   pose estimation
we propose a shape context based approach for the problem of pose estimation  belongie et al  have used this concept for matching shapes in      for our purpose  we apply
this algorithm for finding the best matching image from our
training database  the entire procedure is divided into two
phases  the training and testing phases which are described
in sections     and     respectively 

 a 

 b 

 c 

     training phase
in this phase  we use vikram as the model for creating
the training database      images were collected with him
standing in different poses  artifacts such as shadow attachment and background noise can significantly impact the
performance of our pose estimation system  as these artifacts distort the silhouettes  hence  we require a robust
background subtraction algorithm  we use tolas implementation     of the kernel density estimation based background subtraction algorithm explained in          to obtain
silhouettes  this algorithm is robust to background clutter  changes in illumination  and shadows  then we run the
shape context algorithm on these silhouettes 
     

 d 

 e 

figure     a  original image of vikram   b  the corresponding
silhouette   c      points on the silhouette   d  the    bins
used to quantize the vectors   e  shape context histogram for
the uppermost point in  c  

shape contexts

the shape context algorithm treats a shape as a set of n
points  these points can be taken by doing sampling on the
silhouettes or edge images  from each of these n points 
we consider the vectors to the remaining n    points 
these vectors are quantized into    bins on the basis of
their lengths and the angle they make with the horizontal 
thus  for each of the n points  we obtain a histogram with
   bins and each bin containing the number of vectors that
are closest to it in terms of  r    co ordinates  this process
is described for a single point in figure   with n        in
figure   e   we divide the lengths of the vectors into   levels
by dividing each of them by the length of the longest vector 
the x axis contains the    polar bins corresponding to each
of the   levels in ascending order 
the shape context of a single point gives information
about how the rest of the image looks with respect to it 
hence  it is a rich descriptor of the overall shape of the image  now  the image is divided into   zones of equal size
as illustrated in figure   a   the mean of histograms of all

 a 

 b 

figure     a  the division of the points into   zones   b  the
final histogram for the image in figure   a  

 

fi a 

 b 

figure     a  the five images give an example of the five categories of occlusion   b  shape context histograms for each image 

parts  we use the following distance metric to compute the
similarity between two shape context descriptors  each representing a silhouette 

points falling in the same zone is taken  and then all the  
histograms are appended to create a final histogram of    
bins representing the entire silhouette  this histogram is
taken as the feature vector for comparing the silhouettes 
the histogram corresponding to figure   c  is shown in figure   b  

d i  t    

   
x
 hi  k   ht  k   
k  

     

histograms for the occluded images
where i corresponds to the ith image from the training
database  t corresponds to the test image  and h k  gives
the normalized histogram value for the kth bin 

in addition to the histogram for the complete image  we
also compute   other histograms for occluded versions of
each image  the occluded images are created by artificially
blocking the images in the following   ways   i  right   ii 
left   iii  below   iv  left bottom  and  v  right bottom 
for each of the five categories  we computed histograms by
occluding the original image to different extents and then
finding the mean of all the histograms  figure   a  shows
one of the occluded images belonging to each of the five
categories and the corresponding shape context histograms
are shown in figure   b  
     

hi  k    ht  k 

     

testing on stored images

we collected images of lionel and kanako  which then
served as the test images for the training images of vikram 
a shape context descriptor was computed for each of these
images  and compared with the descriptors corresponding
to all the training images to obtain the best matching silhouette  we first tested for cases where there was no occlusion  the algorithm performed reasonably well in the
cases where the silhouette can express the overall shape of
the pose  the physiques of lionel and kanako are significantly different from that of vikram  and the algorithm still
manages to find the best match for both of them  figure  
shows the best match for the images of lionel and kanako 
we further tested the algorithm by artificially occluding the images of lionel and kanako and finding the best
matching image from the database  the occlusion for the
test cases was random and did not belong specifically to
one of the five categories described in section        figure
  shows the best matching image from the database for each
of two test cases 

labeling of training data

we hand label the positions of the following body parts for
each silhouette in the training database  the head  hands 
shoulders  center of the body  and knees  we normalize the
coordinates of these positions so that we can use them with
test silhouettes of varying sizes  this normalization allows
us to use the training database for people standing at different distances from the camera  and with different physiques 

     testing phase
we divide the testing phase into two parts  testing on stored
image sequences  and testing using a live demo  for both
 

fifigure    the best match for images of lionel  top  and
kanako  bottom  from the database of images of vikram 

figure    positions of body parts for different poses along with
the closest silhouette from the training database 

 a 

figure    best matching silhouettes under random occlusion 

     

testing using a live demo
 b 

we decided to convert all the code written in matlab to c  
in order to increase the processing speed for the live demo 
we used a popular open source computer vision library 
opencv  to perform all the image processing  for the live
demo  we estimated the locations of the different body parts
mentioned in section        we first obtained the shape context feature vectors for the silhouettes  and then obtained all
feature vectors from our training database whose distance
from the test feature vector was below a certain threshold 
since the number of such vectors is usually small  and each
vector is extremely high dimensional      dimensions   we
cannot use linear regression to estimate the positions of the
different body parts as the matrix x   x will often be singular where x is the matrix containing the training examples
body part positions in its rows  hence  we obtained the positions of the body parts using a weighted mean of the positions of the body parts in the set of close training examples 
the formula for the position is 
n
x

pest  

figure    positions of body parts for different poses along with
the closest silhouette from the training database for  a  occlusion by a tripod and  b  occlusion by a chair 

descriptor of the ith close example and that of test image t  
and pi is the position of the body part in image i 
figure   shows the positions of the different body parts
marked by green dots for an unoccluded test subject 
we further tested the system by placing a tripod and a
chair in front of the test subject in order to create natural
occlusion  figure   shows the estimates of the positions of
body parts for a few cases 
the hands move most rapidly compared to all the other
body parts  hence  we plot the results for our estimate of
the hand positions for all the three cases described above 
the graphs are shown in figure   

   d i  t   pi

i  
n
x

 

discussions and future work

our pose estimation system runs in real time and works
well for poses which have close neighbors in the training
database  as we see in figures   and    for each test image  the closest silhouette in the training database closely
matches the image  and the green dots correctly mark the
positions of the body parts  occlusion of a significant part
of the body does not compromise the accuracy of pose es 

   d i  t   

i  

where pest is the estimated position in the test image t  
n is the number of close training examples   is the upper threshold of the distance between two shape context descriptors  d i  t   is the distance between the shape context
 

fitimation  in figure    the estimated position of each hand
does not deviate significantly from the actual position 
we note that the performance of the system is constrained by the size of the training database  which in our
case contains roughly      images  this is clearly insufficient for robust pose estimation  as these images cover a
small subset of all possible human poses  to obtain reliable results  the database should contain at least       
images with parameter values sampled independently and
uniformly within anatomically feasible ranges      in future
work  we can use poser      to render synthetic training
images from a humanoid model 
in such a large database  it is inefficient to search through
all the images to find the best match  we can use parametersensitive hashing     to preserve the real time performance
of the system  parameter sensitive hashing uses parametersensitive hash functions  in other words  hash functions that
are sensitive to the similarity in the parameter space  and
retrieves in sublinear time approximate nearest neighbors
of the test image with respect to parameter values as well
as the shape context feature vectors  the sublinear running
time achieved by examining only a fraction of the dataset 
yet not compromising the accuracy of the pose estimation
makes real time performance possible  we can then use robust locally weighted linear regression      to find the positions of the body parts in the image  even if we come
across a test image which has no exact match in the training database  we can still obtain an estimate of their coordinates by computing a weighted average of the values
for the k training images most similar to the test image  furthermore  robust lwr minimizes the influence of outliers 

 a 

 b 

due to the loss of depth and limb labeling information
for single silhouettes  the resulting  d pose can be ambiguous  to make the system robust to such ambiguity  we can
implement a regressive tracking framework described in    
as long as our pose estimation system can accommodate a
high frame rate  this framework recovers the most likely
pose at each time step by using a dynamical model of the
human body learned from training data to predict the  d
pose distribution and a learned regression value  results in
    show that the regressive tracking framework tracks long
sequences stably 

 c 

figure    the graphs on the left column show the plot of the
estimated position of the left hand against the actual postion 
and the graphs on the right column show the plot of the estimated position of the right hand against the actual position 
for a  an unoccluded test subject  b  a test subject occluded by
a tripod  and c  a test subject occluded by a chair 

 

acknowledgements

we would like to thank rahul biswas for his help and guidance throughout the course of the project and for providing
the necessary equipment 
 

fireferences
    david a  simon  martial hebert and takeo kanade  realtime   d pose estimation using a high speed range sensor  proceedings of the ieee international conference on
robotics and automation       
    tomas izo  w  eric l  grimson  simultaneous pose estimation and camera calibration from multiple views  proceedings of the conference on computer vision and pattern
recognition workshops       
    engin tola   http   cvlab epfl ch tola 
    b  birant orten  medeni soysal and a  adym alatan  person identification in surveillance video by combining mpeg  experts   th international workshop on image analysis
for multimedia interactive services  montreux  switzerland 
     
    ahmed elgammal  david harwood  and larry davis  nonparametric model for background subtraction   th european
conference on computer vision  dublin  ireland       
    serge belongie  jitendra malik and jan puzicha  shape
matching and object recognition using shape contexts 
ieee transactions on pattern analysis and machine intelligence       
    gregory shakhnarovich  paul viola and trevor darrell  fast
pose estimation with parameter sensitive hashing  proceedings of the international conference on computer vision 
nice  france       
    ankur agarwal and bill triggs  recovering  d human pose
from monocular images  ieee transactions on pattern analysis and machine intelligence                    
    leonid sigal and michael j  black  predicting  d people from
 d pictures  amdo        iv conference on articulated motion and deformable objects  mallorca  spain       
     e frontier  scotts valley  ca  poser     reference manual 
     
     w  s  cleveland  robust locally weighted regression and
smoothing scatter plots  journal of american statistical association                        

 

fi