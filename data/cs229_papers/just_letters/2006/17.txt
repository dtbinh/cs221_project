use of knn for the netflix prize
ted hong  dimitris tsamis
stanford university

 tedhong  dtsamis  stanford edu
    smaller data sets

abstract
this paper analyzes the performance of various knns techniques
as applied to the netflix collaborative filtering problem 

   introduction
in the netflix collaborative filtering problem  the goal is that
given a set of training data x     ui   mi   t i   ri      consisting of a
sample of prior movie ratings ri  an integer from   to    
associated with user u i   movie mi   time t i to be able to
accurately predict the rating that should be associated with a new
point  u  m     in this first pass  because we cannot easily ascertain
the time associated with the new point we will ignore the time
dimension  furthermore  to simplify the analysis we will not take
into consideration any features that could be associated with
knowing the actual movie characteristics 

the training data set provided by netflix was huge  consisting of
    million ratings  if we were to run our algorithms on that
dataset  we would lose a significant amount of time waiting for
the method to train  this would impair our ability to test small
changes quickly  therefore we created training sets that are      
    and    times smaller  meaning they have so many times
fewer users   along with their respective testing sets  for each size
  different datasets were created  by randomly selecting users 

   pearsons correlation coefficient
if we consider that a given user u i rates movies with a distribution
ri      i    i   then a natural similarity metric between users u i
and u j is the correlation coefficient between the two distributions
ri   and r j    ij  

e   ri   i    r j   j   

   knn
our main premise is that similar users rate similar movies
similarly  with knn  given a point  u  m   to predict  we
compute the k most similar points and average the ratings of
those points somehow to obtain our predicted rating r   different
spaces  similarity metrics and different averaging techniques
would affect the performance of knn 
in the following sections we will consider primarily user
similarity  ignoring movie similarity and saving that for future
work  in essence  our knn algorithm becomes  given a point
 u  m  to predict  compute the k most similar users and average
the ratings of those users gave movie m to obtain our predicted
rating r  

 i   j

 

we estimate the covariance and variances by considering the m
movies user i and j have in common and
e   ri   i    r j   j    

i 

 
m

 
m

  rik   i   r jk   j    
k

  rik  i        j 
k

 
m

  r jk   j    
k

but we estimate the means by considering all movies user i j has
rated irrespective of the other users  if a particular user as no
ratings  then we consider the users mean to be    probably should
be changed  

   top q optimization

the values of the pearson correlation coefficient lie in the
interval          at knn the values of the similarity function
typically lie in the       interval  a very simple way to convert
from the first interval to the second is to consider  ij          

in order to calculate the similarity between two users  we consider
the movies they have rated and combine them in some way  by
looking at every single rating this takes roughly o m   time were
m is the average ratings a user would have  in order to compute
the knn for every user  we need to compute the similarities

related the two distributions are  we consider its use solely as a
similarity metric and also as a component in the mse linear
estimate of the rating r  

we will consider approximations to knn to obtain predictions in
a reasonable amount of time  and several distance metrics 

 

 

between all the users for roughly o n   m log k time to finish
computing knn and o  kn   space to store the k nearest
neighbors for each user  however  many users dont rate a
significant number of movies  for these users  it is unlikely that
they would help in predicting the rating for a random movie  by
this reasoning we should lose little information if we consider
only the top q users with the most number of ratings  with this 
knn topq would take o  nqm log k   time to complete and
o  kn   space  we will analyze the effect of k and q after
defining our initial distance metric 

the correlation coefficient  ij is a measure of how linearly

    baseline measure  average
if the user distributions are all independent  then the best we can
do is to consider every user individually and estimate the rating as
the mean of all prior ratings of a particular user  with this
baseline  user average  we get a rmse error of around      

    x set

rmse of
training data

rmse of
testing set

fi 

        

       

 

       

       

       

 

        

       

average

        

        

        

 

        

       

 

       

       

 

        

       

average

        

      

we also noted by how much did the predicted rankings change
from the average baseline
set

average
delta from
baseline

correct delta
from baseline

 

        

        

     as a similarity metric

 

        

        

we consider a user j to another user i if  ij is close to    in other

 

        

       

words  when user j rates a movie high  relative to his mean   user i
would do similarly  our knn algorithm creates a list of k
neighbors with high correlation coefficients  with a cap on the
minimum similarity it would consider at     even if the knn isnt
met  then when it is time to estimate the rank user i would give
to movie m we consider the other users in the knn set that have
ranked movie m and compute the weighted average of the
  ik  rk   k  
rankings  r   k
  k  
 abs   ik  

 

        

        

 

        

        

average

        

        

ws can be seen  the prediction is too conservative  its predictions
are too close to the mean 
we then considered the same metrics but applied to the same
testing data as it was trained on 

k

with this algorithm our rmse is around      for k     and
q entire training set      
    x set

rmse of
training data

rmse of
testing set

 

        

      

 

       

       

 

        

       

 

        

       

 

        

       

average

        

        

    x set

nn w      

nn actually
used

percentage
when nn  

 

       

       

       

 

       

       

       

 

       

       

       

 

      

       

       

 

       

       

       

average

        

        

        

set

average
delta from
baseline

correct delta
from baseline

despite performing significantly better on the training data set 
the algorithm performs slightly worse on testing 

 

        

        

 

        

        

      statistics on knn

 

       

        

 

       

        

 

        

        

average

        

        

one thing we thought would be interesting to see is along with
how many nearest neighbors are we actually using both because
of the similarity floor of ignoring those with similarities less than
    and because the nearest neighbors might not have rated the
movie being predicted as well 
for the testing data with k     and q     as before
    x set

nn w      

nn actually
used

percentage
when nn  

 

       

       

       

though the prediction is still too conservative  the prediction
spread is closer to the actual spread  however  there still isnt too
much of a difference between the behavior on training data and
the testing data so the difference has to be in the makeup of the
two sets  users and movies to be predicted 

 

       

       

      

   sparseness of training data

 

       

       

       

 

       

       

       

from section    though we set k      we actually only use
around   nn when predicting  this shows that preselecting the
knn without regard for the movies might not be such a good

fiidea  it would be possible to get better nn if we select the knn
off those persons that have rated the movie  this is confirmed by
the rmse of this algorithm which is        slightly less than that
of the average baseline

set

average
delta from
baseline

correct delta
from baseline

    x set

rmse of
training data

rmse of
testing set

 

        

        

 

        

       

 

        

        

 

        

       

 

        

        

 

       

       

 

        

        

 

        

       

 

        

        

 

        

       

average

        

        

average

         

        

   cosine similarity

for the testing data 
    x set

nn  that
rated movie 

nn actually
used       

percentage
when nn  

 

       

       

       

 

       

       

       

 

       

       

       

 

      

       

       

 

       

       

       

average

        

        

        

instead of using the pearsons correlation coefficient  we could
use the cosine similarity to determine the similarity between two
e   ri    r j   
users  sij  
which is the same as pearsons but
 i   j
without normalizing the means of the distribution to    we ran
several experiments comparing the rmse of cosine similarity and
pearsons on various k and q  on   larger training testing set 
pearsons
with p      

cosine

pearson

q      k    t 

       

 

 

q      k     t 

        

        

      

q      k     t 

       

       

      

q      k     t 

       

       

       

q      k     t 

       

       

       

set

average
delta from
baseline

correct delta
from baseline

 

        

        

 

        

        

 

        

       

as we can see  cosine similarity performs worse  however  we
are at a loss to explain why converting persons inequality to be
from       instead of from        would be better 

 

        

        

   default values

 

        

        

average

       

        

for the training data 
    x set

nn  that
rated movie 

nn actually
used       

percentage
when nn  

 

       

       

       

 

       

       

       

 

       

       

       

 

       

       

       

 

       

       

       

average

        

       

        

as we have seen in the past sections  the actual number of nearest
neighbors is much less than k  we can fill in these gaps if we
also predict the ratings the missing knn users would give  we
call these default values and they are essentially a weighted
average of the average rating the particular user rates his movies 
the average rating the particular movie received from all users 
and the average rating in the whole system 
avgrating
   avguserrating i    avgrating                 exp  numuserratings i    a  
   avgmovierating j    avgrating                 exp  nummovieratings j    b  
the above baseline has the advantage that it predicts different
ratings per user and per movie  the constants a and b were
specified by members of another team  based on hand tests 
in order so that these default ratings do not drown out the real
ratings  we weight these default values by      we get slightly
better results on the same training sets as in section   

fi   x data set  k       

pearsons with
p      

cosine

pearson

q      k    t 

       

 

 

q      k     t 

        

       

       

q      

       

       

q      k     t 

      

       

       

q       

       

       

q      k     t 

       

       

      

q       

       

       

q      k     t 

       

       

       

q       

       

      

rmse

nn  that rated
the movie 

   confidence intervals
so far most of our tests were on the small     x dataset  which
only contains     users  we were able to test knn on larger data
sets to get a clearer view of how its performance correlates to the
number of neighbors that are used during the prediction phase 
we tried various values for q  which lead to different sets of knearest neighbors being chosen each time 

nn  that rated
the movie 

q      

       

       

q       

      

       

q       

       

       

q       

       

       

  x data set  k       

rmse
q      
q       
q       
q       
q       

rmse
q      
q       

   x data set  k       

rmse

  x data set  k       

      

nn  that rated
the movie 
       

    

       

       

       

      

       

       

       

q       
q       
q       

       

nn  that rated
the movie 
       

       

       

       

     

       

       

       

       

it is interesting to note that for the    x data set the lowest q still
gives the best results  while for the   x data set the best q is      
this indicates that there needs to be large enough q to contain the
working set of the training data but too large q decreases the
quality of the predictions by having not enough ratings in the
nearest neighbor set 
in order to discount similarities based off the number of ratings 
we decrease the pearsons similarity by one standard deviation in
the method of      essentially we convert the similarity to a zscore via fischers z transformation     
z   

 
 

 log         log        

and then decrease the value by one standard deviation 

  

 
commonratings   

and convert back to a similarity metric
we observe that as the number of nearest neighbors that are
actually used decreases  the rmse increases  what is more
interesting to observe is that nn decreases as q increases  this is
explained as follows  the smaller the q  the more movies the
neighbors have rated and thus it is more probable that they have
rated the movies in the testing set  as q increases  we discover
users with higher similarity  but this turns out to be negative since
they have rated less movies  the fact that users with higher
similarity are discovered is not only due to the larger search
space  but also because they have rated less movies and the
similarity is computed upon less common ratings 
as a counter measure for this phenomenon  we decided to
penalize the similarity of users that have rated few common
movies  from the results we can see that this feature does pay off 
since the number of neighbors used gets higher and the rmse
gets better 

 

e  z     
e  z      

in the end  if there are not enough common ratings  the standard
deviation would be large  forcing the z score to be low and close
to zero  and hence the similarity of the two users will be low and
close to   

   movie similarity and k nn
one problem mentioned before is that running knn on the entire
data set is too prohibitive  top q was used as an optimization but
past      users  taking more users on is actually harms the results 
if the poor results are due to these similar users not having enough
ratings  perhaps we can artificially introduce ratings  default
values based on averages were analyzed in section   and were

fifound to perform only slightly better  instead of using baseline
approach we can also the similarity of movies to help improve the
ratings  essentially  if a nearest neighbor happens to have not
rated the movie  we would find a similar movie and make the
prediction based off that  we implemented movie similarity just
like we did user similarity  pearsons similarity of two movies
based off of common user ratings  however  we found that using
movie similarity as default values actually hurt us  furthermore 
we created a movie similarity baseline  instead of rating based off
the average  we take the weighted average of similar users the
user to be predicted has already seen  but saw that though the
average baseline on the     x set gives around      rmse  using
movie similarity as a baseline gets      rmse  while using
movie similarity would help with problem of sparseness the
method still needs tweaking 

    clustering
one idea we had was that if we split up similar users  we could
run knn separately for each cluster  speeding up the calculation
and potentially increasing accuracy as only similar users would
ever be considered in the first place  in order to test this out  we
used the k means clustering results from brian sa and patrick
shih for    clusters  for the     x smaller data set we get rmse
of around      and use around   neighbors  for the    x we get
rmse of around      and use around    neighbors  we also ran
the algorithm for the entire training set and found similar results 
with clustering we are able to find fewer neighbors and our rmse
is harmed  just like high topq  a simple clustering approach hurts
rmse by decreasing the available nearest neighbors 

    conclusion
as shown by its performance on the training rather than testing
set  knn has the potential to perform good predictions  with
rmse lower than       however  the rmse for testing hovers
around       we found that techniques that required higher more
accurate statistics or higher nearest neighbors to performed worse
though they has the potential to perform better  vector mmse
linear estimators  and clustering were two examples  techniques
that attempted to increase the accuracy of the statistics  or increase
nearest neighbor count like default values  and clustering
improved rmse by a small amount  movie similarity was a
hybrid approach  it required more statistical data but its purpose
was to increase nearest neighbor count  it just happened to
perform worse  more complex predictors would not help unless
the first problem  sparseness of the data  is taken care of 

    future work
the way to attack problems like the netflix prize is to create some
hybrid method  combining more than one model  we understand
that other teams are working on different approaches on the
problem and once they are finished we could use their results to
enhance the knn model 
knn as it is does not exploit extra information about the movies 
like their genre  director  actors  etc  this information can be
extracted from the imdb and could be used a simple contentbased prediction model  we could then use this content based
model to create the default values of the prediction stage of knn 
we could also go as far as filling up the entire user movie matrix
before computing the user similarities  melville et al     propose
one way such an approach could take 

we think clustering on users could still be very useful  we could
search for the nearest neighbors only within the cluster that a user
belongs to  finding neighbors that are more strongly correlated 
given reasonably sized clusters we could abandon the topq
optimization and search all the users in the cluster  however 
well need some method to incorporate users with high number of
ratings into multiple clusters so that the nearest neighbor count
does not drastically decrease due to clustering 
another approach is to cluster on movies and create different
similarities for every movie cluster  for example  when we
examine movie cluster    we would only consider only movies
that belong to this cluster during the phase of the similarity
generation  then  for each test we would use the similarities that
belong to the same cluster as the movie of the test 
finally  considering that the rankings are integers  we should
examine ways to round off our results to an integer value  real
values would be useful if we wanted to implement a
recommendation system  but since for the competition we only
wish to predict the ratings  integer predictions could improve the
rmse  of course  this would first require to improve our
algorithm  so that the classification would get us closer to the test
value and not create larger errors  much like how logistic
regression generally outperforms linear regression on discrete
data  we expect a increase in accuracy if were able to come up
with a smart method to discretize the results 

    acknowledgements
thuc vu coded the initial knn algorithm and helped with the
direction of the project  so did chuong do  brian sa and patrick
shih created the k means clustering program and clustering
results we used  we also thank the rest of the netflix team for
sharing their ideas and successes 

    references
    ali  k  and van stam  w        tivo  making show
recommendations using a distributed collaborative filtering
architecture  in proceedings of the tenth acm sigkdd
international conference on knowledge discovery and data
mining  seattle  wa  usa  august                 kdd     
acm press  new york  ny           doi 
http   doi acm org                        
    http   davidmlane com hyperstat a      html
    melville  p   mooney  r  j   and nagarajan  r       
content boosted collaborative filtering for improved
recommendations  in eighteenth national conference on
artificial intelligence  edmonton  alberta  canada  july    august            r  dechter  m  kearns  and r  sutton 
eds  american association for artificial intelligence  menlo
park  ca          

fi