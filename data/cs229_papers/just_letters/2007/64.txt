getting the position and the pose using stereo vision
youngjun kim
youngjun stanford edu
aeronautics and astronautics  stanford university  stanford  ca      
abstractcontrolling a quadruped robot is a
challenging problem in robotics  in this report
i present an application to get the position and
the pose of the little dog robot using stereo
vision  i built a vision system on top of the
little dog robot and reconstructed a   d
terrain model using a stereo camera  then i
aligned sequential   d models to get the
position and the pose using icp algorithm  in
the future  this information will be integrated
to the controller of the robot as feedback so
that it can get over a tough terrain without
support of motion capture system 

figure    the little dog robot  designed and built by
boston dynamics  inc 

i  introduction
the goal of my project is getting the position
and the pose of the little dog robot shown in
figure    using stereo vision  the little dog
robot has four legs and the same degree of
freedom as a real dog  its shape resembles a
real dog but it doesnt have a head and a set of
eyes  thus  it cannot recognize new terrains 
and it only knows the initial coordinates of the
terrain which we internally programmed  in
addition  the motion capture system shown in
figure   gives the position and the pose of the
little dog robot  if we have a new terrain or the
motion capture system is gone  it cannot see
the new terrain and we cannot get the accurate
position and the pose  my first work was to
build the vision system using a stereo camera
and integrate it within this system  the stereo
camera gathered left and right images and i

figure    motion capture system  built by vicon mx
system

reconstructed the   d model from these images 
but as the little dog robot was moving  it built
sequential   d models which were not aligned 
and aligning these   d models was a challenging
problem  i solved this problem using icp
algorithm to align these   d models and with
this  i could get the position and the pose of the
little dog robot 

fifigure    left  right images and depth map from a stereo vision  made by tzyx inc 

a    d trigonal meshes from depth maps
original data was a series of depth maps  i
sampled points uniformly from depth map and
reconstructed   d coordinates assuming
perspective camera model      since the
intrinsic parameters of the camera were known 
i could have relative world coordinates  then i
used delaunay algorithm     to build trigonal
meshes 
figure    terrain and the little dog robot equipped with
a stereo vision

ii  getting the position and the pose
as a first step  i set up a vision system and
equipped the little dog robot with this system 
as shown in figure    then i built a   d model
from a series of stereo images  the original data
were a series of depth maps tyzx stereo camera
had calculated from left and right images  as
shown in figure    i converted these depth
maps first to   d point clouds then to the
trigonal meshes  then i used the efficient icp
algorithm to align images sequentially  before i
utilized aligning information for getting the
position and the pose  i needed to know
relative position between the robot body and
the stereo camera  using a camera calibration
technique  i could calculate the relative distance 
as a result  i could get the position and the pose
information of the little dog robot 

there were some noises in a depth map 
among the many kinds of noises  the most
prevalent one was salt and pepper noise  i
applied the median filter to remove it and i also
removed outliers which had long edges in
trigonal meshes 

b  pairwise alignment of consecutive
images
the dominant algorithm for geometric
alignment of   d models is the icp  iterated
closest point  algorithm  icp algorithm takes in
two triangular meshes and finds the translation
and rotation between those two  as shown in
figure    among a number of variants in icp
algorithm  i used the efficient icp algorithm
developed by rusinkiwicz and levoy      the
little dog will need to be able to understand
the   d structure of the terrain as it moves on it 
meaning that the reconstruction of the model
should be real time  for that purpose  i chose to
use efficient variant of the icp algorithm     

fifigure    calibration images  extrinsic parameters  camera centered   setup for getting the relative distance

c  relative distance between the robot
body and the camera

figure    unaligned and aligned meshes

this variant icp improved performance in speed
by choosing a projection based algorithm to
generate point correspondence  the point toplane error metric     and the standard selectmatch minimize icp iteration      for the other
stages that are not critical to high speed  it uses
simplest ones  random sampling of points 
constant weighting of pairs  and the distance
threshold for point rejections      in addition  i
found parameters of icp algorithm to achieve
high speed and accuracy by experiments 
the efficient icp algorithm gives the
transformation between the two range maps 
the icp algorithm first pairs points in one mesh
with nearby points in the other and then finds a
rigid   d motion that aligns the paired mesh
points iteratively  the icp needs initial rough
registration to avoid failure to find the global
minimum and achieve high speed  i assumed
that the transformations between the
consecutive images are small enough that initial
guess of no transformation is acceptable 

using aligning information between two
images  i can get a translation and angle
between initial and next positions of the
camera  but the goal is to get a translation and
angle of the robot body  to get this information 
knowing the relative distance and angle
between the robot body and the camera is
important  because measuring these data
directly is inaccurate  i used a calibration
technique to measure the configuration  as
calibrating the stereo camera for taking several
pictures of a known square grid panel  i could
get extrinsic parameters  and after setting up
the robot body and the panel in a known
position  i could get the relative distance and
angle between the robot body and the stereo
camera using the extrinsic parameters  as
shown in figure   

iii  experimental results
at first  i compared aligned terrain meshes
with a terrain model provided by ipto
 information processing techniques office 
based on the given information about a terrain
board  i used the volumetric method     to
merge a set of aligned terrain meshes  rms
error between a given terrain model and a
corresponding merged terrain mesh is within
 mm 

fisecondly  i compared a position and a pose
from the vision system with these from the
motion capture system  as the little dog robot
walked across a terrain  the vision system
calculated a position and a pose ever y one
second  before the little dog robot finished to
cross a terrain  the vision system gave      
position and pose data on average  an average
error of poses is within   degrees on each axis 
this result is quite accurate  and an average
error of positions is varied between     mm  i
think the errors of positions are mainly due to a
calibration error and a motion capture system
error 

iv  future work
in the future  the position and the pose
information from the vision system will be
integrated to the controller of the little dog
robot as feedback so that it can get over a
tough terrain without the support of motion
capture system 
the errors of positions from the vision system
still needs to be investigated where the errors
are from and it might need to be decreased for
giving this information to the controller of the
little dog robot as feedback 

references
    e  trucco and a  verri  introductory
techniques for   d computer vision 
prentice hall       
    b  delaunay  sur la sphre vide  izvestia
akademii nauk sssr  otdelenie
matematicheskikh i estestvennykh nauk 
               
    s  rusinkiwicz and m  levoy  efficient
variants of the icp algorithm  proceedings

of the third intl  conf  on   d digital
imaging and modeling       
    m  deans  c  kunz  r  sargent and l 
pedersen  terrain model registration for
single cycle instrument placement 
proceedings of the ieee rsj intl  conference
on intelligent robots and systems       
    yi ma  stefano soatto  jana kosecka and s 
shankar sastry  an invitation to   d vision 
springer       
    b  j  besl and n  d  mckay  a method for
registration of   d shapes  ieee trans patt 
anal  machine intell                      
    y  chen and g  medioni  object modeling
by registration of multiple range images 
image and vision computing                
    
    b  curless and m  levoy  a volumetric
method for building complex models from
range images  proc  siggraph     acm 
    

fi