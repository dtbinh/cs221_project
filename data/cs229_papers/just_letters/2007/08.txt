predicting new search query cluster volume
jacob sisk  cory barr
december         

  problem statement
search engines allow people to find information important to them  and search engine
companies derive their profit from delivering paid advertisements in response to user
queries as well as organic results  the paid advertisements are matched to the users
query  usually by way of shared similar keywords or topics  this poses many problems for search engine companies and their advertisers  almost all of which stem from
the long tail of the distribution of user queries  search engine companies have spent
tremendous effort monetizing this tail by providing imaginative techologies to match
low frequency queries  riemannian manifold  to relevant advertisements  springer
book sale  
novel queries are an under monetized segment of this long tail  the world changes
rapidly  new products  news  gossip  memes  stories and ideas consistently emerge 
predicting the volume of queries about these novel topics is the subject of this report 
if we observe a novel query  the likelihood of never seeing that query again is
       measured one month past the querys initial appearance   on the other hand 
if we observe that novel query occuring a few times  even better if by a few different
people   it becomes more probable the query is about some new idea or thing  and we
are more likely to see it again in the future 

  data
   

query logs  dataset construction

to build a corpus of novel queries  we constructed a bloom filter    gigabytes in size
with an estimated false positive rate of less than       containing over    billion
queries issued to the yahoo  search engine in      and       we then sampled     
of the search traffic from january       retaining only queries not issued in      or
      there are      million unique queries in this sample  since we are looking for
new topics and believe queries about new topics may take many different lexical forms 
we porter stemmed the queries  then  for each novel query q occuring at time t    we
built a regular time series beginning at t  using a period of one minute that recorded
   the number of times q was re issued in each subsequent minute  for up to    days  
   the number of new users in each minute t    i who issued q but never issued q in
 

fif  q i   t   t      
 
 
  to  
   

 qi  
    m
   k
  k
   

  
      
      
      
      

   min 
      
      
      
      

   min 
      
      
      
      

   min 
     
      
     
      

  hrs
     
      
      
      

  day
      
      
      
      

  days
      
      
      
      

   days
      
      
     
      

table    probability of query repetition given frequency in first   minutes
u q i   t   t      
 
 
 

 qi  
    m
    
   

  
      
      
    

   min
      
      
     

   min
      
      
    

   min
      
      
     

  hrs
      
      
    

  day
     
      
     

  days
      
      
   

   days
     
      
     

table    probability of query repetition given user count in first   minutes

t        t    i     and    the number of repeat users who issued q in minute t    i and also
issued q at some point prior to t    i 

   

descriptive statistics

to help design features  we examined how informative tallies of query frequency were
in small time windows early in the history of a novel query  specifically  if a novel
query q i  is first issued at t  and has frequency f  q i    in  t   t     which we will
denote f  q i   t   t     it is instructive to empirically estimate the likelihood that q i 
is issued in some larger  later time window  t     t          it is equally instructive
to do this considering the number of novel users issuing q i    which we denote u q   in
 t   t       this gives us an estimate of


p f  q i   t     t            k f  q i   t   t    
   
table   shows an estimate for the conditional probability of repeated query issuance
given the frequency we observe for that query in the first five minutes of its lifespan 
this table demonstates that seeing a novel query more than once in five minutes greatly
increases the chances we will see that query again  both in the next few minutes as
well as up to a month in the future  table   demonstates we can estimate the same
reoccurrence for u q t     t          and the effect is even stronger 

   

clustering  from queries to topics

after examining the recorded queries  we felt clustering semantically and temporally
related queries would provide aggregate cluster statistics and much more informative
training data for a supervised learning problem than examining individual query behavior  in addition  a substantial portion of novel queries are not useful to search engine
advertisers  including navigational queries        of queries in our sample   dns errors  etc  we hypothesised a cluster inclusion criterion could be designed that many
of these unwanted queries would not pass  and eliminating unclustered queries would
improve our training set 
 

filabel

queries

coverag execut hussein videotap jazeera
coverag of saddam execut
al jazeera coverag of saddam execut
videotap of saddam hussein execut
saddam hussein execut full coverag
saddam hussein hospit bed execut

carbon collector nikki spe ne
ne for spe carbon nikki
ne spe
free download of ne for spe carbon
ne for spe carbon g
carbon collector nikki spe ne
ne for spe carbon collector locat p

table    example query clusters and their labels

we clustered using an agglomerative algorithm based on the jaccard distance between two queries  this distance was extended to a jaccard distance between a query
and a cluster by means of comparing a query to a computer generated cluster label
of tokens in the cluster selected by a tf idf criterion  this technique did discard most
non informative queries in addition to ameliorating data sparsity issues  unfortunately 
despite implementing an inverted index to eliminate comparing queries to others with
no token intersection  the algorithm was computationally expensive  and we had to subsample down to        of the queries from january       table   presents examples
of some clusters and their labels 
it should be noted that the scope of this study is to examine the feasibility of predicting search query volume through supervised learning  however  focusing on clustering lies outside our present scope  consequently  our experiments are designed to
confirm the feasibility of predicting search query cluster volume and persistence given
a reasonably well clustered training set  which our initial clustering method achieved 

  predicting future query volume
   

experimental framework

for every experiment  our design matrix was constructed by breaking up the first t  
of a clusters query volume history into a regular time series of n pieces some  apart 
recording query volume  or log   volume   for each of the time slices  the dependent
variable was the total query volume observed in the next t   units of time for that
cluster 

   

regression

due to data sparsity  logistic regression performed unpredictably  linear regression
faired better  regressions were compared to a baseline model of predicting zero future
query volume  for almost all choices of t    t  and   regression outperformed the baseline  sometimes radically  table   shows root mean squared error for the regression
with the baseline in parentheses  statistics are the result of    fold cross validation 

   

support vector machine prediction

we had constraints on computing time  but preliminary experiments showed an svm
with a polynomial kernel could significantly outperform the linear model  furthermore 

 

fit            hour 
t          hour 
t           hours 

t          one day 

t           one week 

t            day 
                 
                 
                 
                  
                  
                 
                  
                  
                   
                  
                  
                   
                    

t             week 
                 
                 
                 
                  
                  
                 
                  
                  
                   
                  
                  
                   
                    

t              days 
                 
                 
                 
                  
                  
                 
                  
                  
                   
                  
                   
                    

table    linear regression for future query volume prediction

the svm did a very good job of predicting outliers  this is important  since outlier
queries are likely the most easily monetizable 
figure   provides evidence of the models accuracy  the graph displays a distinctly
modal tendency  our model either predicts correct search volume extremely well  or
predicts no volume  however  above a certain volume threshold the svm performs
with exceptional precision  since our goal is to ultimately predict novel  persistant
large volume clusters for search engine monetization  performance below some volume threshold is likely to be unimportant or perhaps entirely irrelevant  therefore  the
performance of this model implies fitting a model using an svm provides satisfactory
application performance 

figure    svm regression  t     day  t     week    rd degree polynomial kernel 

   

markov model

we felt a markov model prediction system could be appropriate for our time series
data  we defined states as discretized volume levels with the following ranges    

 

fistart
 
 i
 d
 i
 d
  i
  d
  i
  d
   i
   d

start
    
    
    
    
    
    
    
    
    
    
    
    

 
    
    
    
    
    
    
    
    
    
    
    
    

 i
    
    
    
    
    
    
    
    
    
    
    
    

 d
    
    
    
    
    
    
    
    
    
    
    
    

 i
    
    
    
    
    
    
    
    
    
    
    
    

 d
    
    
    
    
    
    
    
    
    
    
    
    

  i
    
    
    
    
    
    
    
    
    
    
    
    

  d
    
    
    
    
    
    
    
    
    
    
    
    

  i
    
    
    
    
    
    
    
    
    
    
    
    

  d
    
    
    
    
    
    
    
    
    
    
    
    

   i
    
    
    
    
    
    
    
    
    
    
    
    

   d
    
    
    
    
    
    
    
    
    
    
    
    

table    markov model state transition probabilities

                               and        in addition  each volume bucket state is
partitioned into an increasing and decreasing state  where increasing is defined
as having at least     of the query volume in the latter half of the time span  in our
experiment  each state covers one day  table   presents state transition probabilities 
a phenomenon occurs when the volume reaches    queries in a day  the state
transition indicates the probability of maintaining at least the current volume increases
     which suggests a possible metric for cluster persistence 
our markov model prediction system consistently predicts a daily total volume of
  if the previous day had volume less than     in our experiments  the prediction for
higher volume clusters was always several states too low  but never     we believe a
second order markov model could offer greater prediction  the markov model also
has two advantages over the svm  first  it can readily model query volume per day of
the week  which differs radically  second  it offers the distinct advantage of being intuitively understandable for non quantitive employees  however  we believe the svm
model remains the superior choice 

  future work
though tangential to our supervised regression study  it seems clear that increasing performance of query clustering is the most likely means to increase the ultimate utility
of the supervised learning research  consequently  current efforts are focused on unsupervised clustering techniques that incorporate cluster inclusion criteria and automatic
determination of the optimal number of clusters 
it would also be worthwhile to add richer features  specifically  including standard
arma time series features  second order  differenced  etc  and to comparing their performance to that of an svm on the first order features with a non linear kernel might
prove informative 
the primary motivation for this research is to quickly alert online advertisers about
emerging topics for which people are searching  advertisers bid on phrases they
think will be issued by users who want their products or services  consequently  a
query  or query in a cluster  becoming bidded by an advertiser is as useful a dependent
variable as future query volume  behavior encoded in the time series may help predict
biddedness  however  biddedness might prove best handled as an addition classification problem once high volume  persistant clusters are identified 
 

fi