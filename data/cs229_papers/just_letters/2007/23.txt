 

robust building identification for
mobile augmented reality
vijay chandrasekhar  chih wei chen  gabriel takacs

abstractmobile augmented reality applications have received
considerable interest in recent years  as camera equipped mobile
phones become ubiquitous  we have developed a point and
find application on a cell phone  where a user can point
his cell phone at a building on the stanford campus  and get
relevant information of the building on his phone  the problem
of recognizing buildings under different lighting conditions  in the
presence of occlusion and clutter  still remains a challenging problem  nisters scalable vocabulary tree  svt      approach has
received considerable interest for large scale object recognition 
the scheme uses heirarchical k means to create a vocabulary
of features or visual words  we first show how we can use
a svt and an entropy based ranking metric to achieve     
recognition on the well known zubud data set      we present a
svm kernel based extension to the svt approach and show that
it achieves a      recognition rate as well  we discuss the shortcomings of the zubud data set  and present a more challenging
stanford nokia data set  with promising results 

i  i ntroduction

h

igh end mobile phones have developed into capable computational devices equipped with high quality
color displays  high resolution digital cameras  and real time
hardware accelerated  d graphics  they can exchange information over broadband data connections  and be aware of their
locations using gps  these devices enable many new types of
services such as a car or pedestrian navigation aid  a tourist
guide  or a tool for comparison shopping  for many of these
services knowing the location is a critical clue  but that is not
enough  for example  a tourist can be interested in finding
information on several objects or stores visible from that
location  pointing with a camera phone provides a natural way
of indicating ones interest and browsing information available
at a particular location  once the system recognizes the target
that the user is pointing at  it can augment the viewfinder with
graphics and hyper links that provide further information  such
as the menu or customer ratings of a restaurant  or services
 reserve a table and invite friends for a dinner   we call such
a system a mobile augmented reality  mar  system 
a  stanford nokia mar system
figure   gives an overview of the system which is divided
into two major components  a mobile device and a server 
these components communicate over a wireless network 
once the user takes a picture  we extract surf features
    from the image and send them to a server  the server
recognizes the building or the object in the picture by matching
the image against a database of geo tagged images  the server
groups the geo tagged images into location cells typically of

fig    
a snapshot of the outdoors augnted reality system being used 
the system augments the viewfinder with information about the objects it
recognizes in the image taken with a phone camera 

fig    
system block diagram  the system is divided into two major
components  a mobile device and a server  which communicate over a wireless
network 

the size   km    km  a location cell of this size would
typically have        points of interest  buildings  restaurants 
signs  etc   the recognition algorithms used are described in
the following sections  the recognition algorithms return a
ranked list of database images that are closest in content
to an incoming query image  affine geometric consistency
checks are then carried out to remove spurious matches  in
this paper  however  we will be focusing on the recognition
algorithms that return a ranked list of images  prior to the
geometric consistency check  once the recognition is done 
the server sends relevant information back to the phone  the
phone finally overlays the information on the image  as shown

fi 

in figure   above 
b  contributions and paper outline
this paper describes two methods for identifying the contents of the picture taken by a user with a camera phone  the
algorithms described here allow recognition among a large
number of classes or points of interest  a coarse estimate of
the users location via gps or cell tower triangulation suffices
to narrow down the search space  e g     km    km   even
when a coarse estimate of the users location is available  the
search space may still be substantial and the user could be
looking at one of many objects or buildings  we propose using
a scalable vocabulary tree  svt      in order to allow for
image queries against a larger collection of images  the svt
allows us to define a bag of visual words  analogous to a
set of textual words  first  we use an entropy based distance
metric proposed by     to rank the similarity of images in
the database to a query image  we then propose a support
vector machine  svm  extension of the svt to learn the class
membership by representing the different classes as bags of
visual words 
section ii discusses some of the prior work in this field 
sections iii and iv describe the algorithms used for image
matching on the server  section v describes the two data
sets used in the paper  section vi evaluates the performance
of the algorithms on the two data sets  we propose some
enhancements vii to the schemes described here and conclude
in viii 
ii  p rior w ork
our work represents a special category of content based
image retrieval  cbir                 we want to recognize
real world images from a large set of categories  buildings 
landmarks  logos  but we want to do it under a variety of
viewing and lighting conditions  we want the algorithms to
work in the presence of transient clutter in the foreground  and
changes in appearance  recent work in object based image
retrieval uses a vocabulary of visual words to search for
similar images in very large image collections               
     the svt approach has received considerable attention in
the last year  due to its simplicity and its ability to categorize
an object amongst a large number of classes 
iii  s calable vocabulary t ree
for the mar application  we are interested in fast retrieval
from a database of features containing noisy data  in this
paper  we evaluate the bag of visual words approach for our
application  there are two parts to the svt  building the data
structure for the images in the database  and then retrieving
the closest match for an incoming query image 

fig     feature cluster  the features assigned to the same scalable vocabulary
tree node are similiar 

stored as    dimensional floating point numbers  the vocabulary tree is built using hierarchical k means clustering  a
large set of representative descriptor vectors are used in the
unsupervised training of the tree  instead of defining the final
number of clusters or quantization cells  k defines the branch
factor  number of children of each node  of the tree  first  an
initial k means process is run on the training data  defining
k cluster centers  the training data is then partitioned into k
groups  where each group consists of the descriptor vectors
closest to a particular cluster center  the same process is
then recursively applied  the path down the tree to any node
can be encoded by a single integer  which is then used to
represent that node or quantization cell  the hierarchical kmeans  compared to the traditional k means  is a scalable
approach as it allows us to add features to the tree without
having to rebuild the tree with the addition of new features 
on the server side  we group images into location cells of
  km    km  a svt is built for all the features in each
such location cell  we envision having            images in
a location cell of this size  for this paper  we consider all
the images in one such location with around a      images
in it  we extract features from all the images in the data set
and insert them into the vocabulary tree  each feature in the
vocabulary tree is quantized to a leaf node of the tree  each
node of the tree stores a pointer to all the features that were
quantized to the cell  the features  thus  point back to the
images from which they were extracted  a typical cluster of
features is shown in figure   
b  scoring metric
once the quantization is defined  we wish to determine
the relevance of a database image to the query image  the
relevance score is based on how similar the paths down the
vocabulary tree are for the descriptors from the database image
and the query image  we take into considerations all the leaf
nodes as well as interior nodes  since interior nodes will be
visited more frequently then leaf nodes  an entropy weighting
wi should be assigned to each node i 
wi   ln

a  hierarchical k means
an svt is a data structure that allows for efficient vector
quantization and nearest neighbor searching of feature vectors 
the features in consideration are surf features  which are

n
ni

where n is the total number of features in the database  and ni
is the number of features in the database that pass through node
i  the entropy weighting in the metric gives less weight to the
nodes that have more paths through them  and more weight to

fi 

the nodes visited less frequently  this is because nodes that are
encounterd more frequently are less discriminative and carry
less information about the image 
having computed an entropy measure for every node in the
svt  we can then compute vectors that represent each database
and query image  we define q and d to represent query and
database vectors  respectively 
qi   ni wi
di   mi wi
here ni and mi are the number of descriptor vectors of the
query and database image  respectively  with a path through
node i  thus  each image is represented by a vector with t
elements  where t is the number of nodes in the vocabulary
tree  a database image is then given a relevance score based
on the normalized difference
s q  d   k

q
d

k
kqk kdk

between the query and database vectors  here  we consider
an l   norm 
the two parameters that need to be fixed for the svt are the
branch factor and the depth  based on the recommendations
in      we fix the branch factor to    and the depth to    this
generates  m leaf nodes in the tree 
once the relevance scores are computed  we have a ranked
list of images  additionaly  geometric consistency checks are
carried out to figure out the correct match  the geometric consistency check is computed via a random sample consensus
 ransac  algorithm that fits an affine model to the point
matches in the query and database image  however  for this
paper  we are interested only in the quality of the retrieval
prior to the affine consistency check 
iv  s upport v ector m achine e xtension
we treat this problem as a traditional classification problem
and present a svm extension to the svt approach  the
svt approach allows us to define images as distributions  or
histograms  of features  let the cluster centers of the t nodes
of the vocabulary tree be  p    p         pt   
we
extract
the
features
from
each
image 
and
represent
the
image
as
the
distribution
 p    u      p    u      p    u           pt   ut   where the ui s
are the number of features assigned to cluster i  divided by
the total number of features  thus ui s are the proportion of
features in the image assigned to cluster i  note that we use
all the nodes of the svt as visual words  and not just the
leaf nodes 
we compare two histograms by using the   distance 
d u  w   

   ui  wi   
i
 
ui   wi

we can train a svm classifier with gaussian kernels based
on a   distance between two image distributions  such an
approach has been used in the literature for texture and object
recognition      

in a two class case  the decision function for a test sample
x has the following form 
g x    i i yi k xi   x   b
where k xi   x  is the value of a kernel function for the
training sample xi and the test sample x  yi is the class label
of xi     or      ai is the learned weight of the training sample
xi   and b is a learned threshold parameter  the training samples
with weight ai     are support vectors 
we define a gaussian kernel function  as defined below 


 
k si   sj     exp  d si   sj  
a
it is shown in the literature that the gaussian kernel with a
  distance function is a mercer kernel      
for a svm  there are two parameters that need to be chosen
carefully  the kernel parameter a and the svm regularization
parameter c  the c parameter is chosen using cross validation  we set a to the mean value of the   distances between
all training images in the data set as suggested by       the
paper claims that choosing this value produces comparable
results to the brute force search with cross validation  we
choose this method since it is computationally cheaper 
as described in the system diagram  gps information significantly narrows down the search space  however  the input
image can belong to one of many point of interest classes 
standard svms are used in the two class setting for binary
detection  to extend the svm to multiple classes  we use
the one against one technique  the one against one technique
trains a classifier for every pair of classes  and a majority
vote is carried out to determine to which class a query image
belongs  this approach also returns a ranked list of classes
for an incoming query image  we use the one against one
technique to avoid the problem of unbalanced data sets  also 
the one against one technique is said to perform as well as the
one against other technique for multi class svms      
v  data sets
a  zubud dataset
the zubud database     consists of        pixel  color
images of     buildings in zurich  each represented by  
images acquired at random arbitrary view points  it also seems
that the images were collected around the same time  the
images in the training set and the test set are very similar
to each other  as evident in the results shown in figure   
the authors of the zubud database also created     query
images          of a subset of the same buildings to test the
performance of their recognition system  to our knowledge 
six papers have reported results on the zubud dataset with
recognition rate ranging from        in      to     in     
to      in       here recognition rate is defined as the percent
of the time that the systems top choice is correct 
b  nokia stanford dataset
the nokia stanford outdoors image data set contains     
   x    images taken with a camera phone from stanford
campus  stanford shopping center  and santa cruz avenue 

fi 

table i
table     of top matches correct
zubud
stanford nokia

svt entropy scoring
   
  

svm extension
   
  

the images have a wide coverage of    different points of
interest  however  the dataset is intentionally non uniformly
sampled  the images are taken from difference seasons  under
varying lighting conditions  from different angles  and with a
lot of image clutter  with this dataset it is generally more difficult to achieve good matching performance  we use    query
images for evaluating the performance of our algorithms 
vi  e xperimental r esults

fig     sample matching results for images from the stanford and nokia
data set
zubudsvt results
 

   

   

  of correct matches

   

   

   

   

   

   

   

 

 

 

 
match num

 

 

fig     eth data set  plot of   of correct matches vs  rank  the results
are for the svt entropy based scoring approach  we observe that the first
match is always correct  and the   of correct matches decreases as we walk
down the ranked list 
zubudsvt results
 

   
  of query images with      correct match within top n

to evaluate the performance of our algorithms  we consider
two metrics  for the svt ranking metric algorithm  we look
at the percentage of correct matches for each one of the top  
ranked images  additionally  we also consider the percentage
of images that have at least one correct match among the top
  matches  the svm algorithm returns a ranked list of classes
aswell  we consider the percentage of correct class matches
among the top   ranked classes 
for the svm  the regularization parameter c was chosen by
carrying out a brute force search  the value of c that gave the
highest accuracy by using   fold cross validation was chosen
as seen in figure     a modified version of the open source
libsvm library      was used for the svm algorithms 
in the eth dataset  figure   shows that all the images at
the top of the ranked list are correct  however  the percentage
of correct matches decreases as we go down the ranked list 
shown in figure    since the top match is always correct  there
is at least one correct match in the top   matches  shown in
figure    the svm algorithm performs well on the eth data
set  as seen in figure    for each query image  the class at
the top ranked list is correct  we believe that this is because
the training set and test images are very similar   this is most
probably because the test data was collected at the same time
as the training data  we observe that the svm algorithm is
faster than the svt approach  this is because the svm is
o number of classes   while the svt approach is o number
of database images with at least one feature in common  
however  these approaches do not work as well on the
stanford dataset  we observe     of the top matches are
correct in figure    also  just like in the case of the eth
data set  the percentage of correct matches decreases as we go
down the ranked list  as shown in figure    this is because
the stanford dataset is much more challenging and the images
have a lot more occlusion and clutter  however  we do find
atleast one correct match among the top   matches  shown
in figure    for the svm      of the top match classes are
correct  and the correct matching class is found     of the
time within the top   classes 
partial occlusion of the building causes the distribution of
features to change  thus affecting the entropy based scoring
metric  as well as the svm training 
the results have been tabulated in tables i and ii 

   

   

   

   

   

   

   

   

 

 

 

 
match num

 

 

fig     eth data set  plot of   of query images with atleast one correct
match within the top n ranks vs  rank  the results are for the svt entropy
based scoring approach  since  the first match is always corret  the plot stays
constant at     

fi 
stanfordsvm results
   

table ii

zubud
stanford nokia

   

of matches correct in the top

svt entropy scoring
   
   

 

svm extension
   
  

zubudsvm results
 

  of query images with correct class within top n

   

  of query images with correct class within top n

table    

   

   

   

   

   

   

   

   

   
 
   

 

 

 
class num

 

 

fig      stanford data set  plot of   of query images with correct class
within the top n ranks vs  rank  the results are for a    class svm with
majority voting  we observe that the top ranking class is correct     of the
time  the correct match lies within the top   for     of the query images

   

   

   

c vs  accuracy

   

  

 

 

 

 
class num

 

 

fig     eth data set  plot of   of query images with correct class within
the top n ranks vs  rank  the results are for a     class svm with majority
voting  we observe that the top ranking class is always correct 

stanfordsvt results
   

cross validation accuracy for multiclass svm

   

  

  

  

  

   

   

  

 

  of correct matches

  
c  regularization parameter
   

fig      stanford data set  plot of accuracy vs the svm regularization
parameter c  the value of c is varied from        to    this is for stanford
data set for a    class svm with majority voting  we observe the optimal
value of c to be   

   

   

   

vii  e nhancements

   

 

 

 

 
match num

 

 

fig     stanford data set  plot of   of correct matches vs  rank  the
results are for the svt entropy based scoring approach  we observe that the
first match is correct     of the time  and the   of correct matches decreases
as we walk down the ranked list 

stanfordsvt results
 

  of query images with      correct match within top n

   

   

   

   

   

   

we would like to improve the performance of the svm
and svt algorithms on the stanford nokia dataset  currently 
we have a relatively small number of images per class  on
average        for the svm training stage  and a total of only
about a      images  our database is constantly growing as
more people upload images  we are interested in performing
experiments on data sets as large as       images  the
performance of the svm might improve if more training data
were available for each class     
also  as user generated images tend to be noisy  we would
like to learn the discriminative features for each point of
interest  similarly  we would like to use supervised and unsupervised machine learning techniques for learning foreground
and background features in each image      

   

viii  c onclusion

   

   

 

 

 

 
match num

 

 

fig     stanford data set  plot of   of query images with atleast one correct
match within the top n ranks vs  rank  the results are for the svt entropy
based scoring approach  we observe that all query images have atleast one
correct match within the top   images

we present algorithms for building recognition in a large
database of images  we use hierarchical k means to create a
bag of visual words  these visual words are used to train
svms for different classes of buildings  for recognition  we
consider two algorithms  an entropy based scoring metric
based on the svt  and a majority voting scheme based on a
multi class svm  we test our algorithms on the well known

fi 

eth building data set  and a more challenging stanford nokia
data set  collected from cell phone camera images in the
last one year  we observe that both the svt entropy based
scoring  and the svm algorithm work exceedingly well for
the eth data set         the results are promising for the
more challenging stanford nokia data set  the svt entropy
based scoring algorithm finds the top match correct     of
the time  and finds the correct match      of the time within
the top   images  the svm approach finds the correct class
within the top   classes      of the time 
ix  n ote
the following modifications were made after the poster
session and led to a significant improvement in results for
both approaches described in the paper 
   including interior nodes of svt as words for the svm
approach 
   selection of regularization parameter via brute force
search and n fold cross validation 
   using libsvm package for svm algorithms 
r eferences
    d  nister and h  stewenius  scalable recognition with a vocabulary
tree  in ieee conference on computer vision and pattern recognition
 cvpr   vol           pp           
    eth zurich  zurich building image database  available at
http   www vision ee ethz ch showroom zubud index en html 
    h  bay  t  tuytelaars  and l  v  gool  surf  speeded up robust
features  in eccv            pp         
    a  w  m  smeulders  m  worring  s  santini  a  gupta  and r  jain 
content based image retrieval at the end of the early years  ieee
trans  pattern anal  mach  intell   vol      no      pp                 
    j  z  wang  j  li  and g  wiederhold  simplicity  semantics sensitive
integrated matching for picture libraries  ieee trans  pattern anal 
mach  intell   vol      no     pp               
    t  yeh  k  tollmar  and t  darrell  searching the web with mobile
images for location recognition  in proc  of conference on computer
vision and pattern recognition  cvpr   vol     ieee computer society 
      pp       
    g  fritz  c  seifert  and l  paletta  a mobile vision system for
urban detection with informative local descriptors  in icvs    
proceedings of the fourth ieee international conference on computer
vision systems        p     
    j  philbin  o  chum  m  isard  j  sivic  and a  zisserman  object
retrieval with large vocabularies and fast spatial matching  in proc 
of conference on computer vision and pattern recognition  cvpr  
     
    g  schindler  m  brown  and r  szeliski  city scale location recognition  in proceedings of the international conference on computer
vision and pattern recognition  cvpr     minneapolis  june      
     j  zhang  m  marsza  s  lazebnik  and c  schmid  local features and
kernels for classification of texture and object categories  a comprehensive study  international journal on computer vision       
     v  t  t  v  g  l  hao shao  svoboda  t   ferrari  fast indexing for
image retrieval based on local appearance with re ranking  image processing        icip       proceedings       international conference
on  vol     pp  iii      vol          sept       
     j  h  lim  j  p  chevallet  and s  gao  scene identification using discriminative patterns  in icpr     proceedings of the   th international
conference on pattern recognition 
washington  dc  usa  ieee
computer society        pp         
     j  matas and s  obdrzalek  object recognition methods based on
transformation covariant features  in eusipco       september
       online   available  http   cmp felk cvut cz  matas papers mataseusipco   pdf
     c  c  chang and c  j  lin  libsvm  a library for
support
vector
machines 
     
software
available
at
http   www csie ntu edu tw  cjlin libsvm 
     d  liu and t  chen  discov  a framework for discovering objects
in video  in ieee transactions on multimedia       

fi