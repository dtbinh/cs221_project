multiple object detection with optimized spatial
weighting
jay ni  kiat chuan tan  takashi yonebayashi
abstract

objects a stronger weight than the background  see
figure     the algorithm  known as spatial weighting  led to a      improvement over the original err
 error equal rates  of       demonstrated by zhang
et al on the pascal training data       this improvement was mostly due to a higher success rates on the
more difficult pascal training sets containing high
background clutter  there was no significant improvement over images which did lacked background noise 
as there was little or no background to remove  nevertheless  their results showed promising improvements
over training images that few classifiers can utilize 

this paper illustrates a method to enhance spatial weighting in object recognition as presented by
marszalek and schmid      the original algorithm
uses spatial relations and boundaries to weight relevant areas of an image  and is robust for single object
detection  we have derived a method that is both less
expensive to run  and can detect multiple object clusters in an image in a single pass  the two methods described in this paper will be called nearest neighbor
weighting  nnw  and correlation tree elimination  cte   our tests have shown cte to be
effective  but nnw to be somewhat ineffective 

 

introduction

the bag of features representation is a popular image classification technique that uses local descriptors to create a visual vocabulary to represent image
data  we achieve this representation by first clustering a random set of local image descriptors  and
then discretizing the descriptors of a particular image to the closest respective words in our visual vocabulary  while this technique performs very well
under simple circumstances  it is still vulnerable to
intra class variation  background clutter  and pose
changes  the resulting descriptors obtained from unwanted noise makes bag of features less effective by
increasing false positives  zhang et al      suggested
that using context information within an image could
significantly improve the test accuracy under such
conditions 

figure    test images of graz   data set  left   generated
masks  middle   multiplication of two  on right   source 
marszalek and schmid    

marszalek and schmid     further proposed an extention their spatial weighting algorithm by using the
segmentation masks to localize the target object of an
image  we can achieve this by selecting the point in
the segmentation mask with the highest probability 
and applying thresholding to determine the boundaries of the image  however  the segmentation masks
generated by the original spatial weighting algorithm
are only effective for images where only one object
is present  furthermore  the original algorithm is extremely runtime intensive during testing  as it involves
convolving the image several times for each descrip 

marszalek and schmid     extended this idea and
proposed a method for object recognition that exploits the spatial relations of an object to decrease
background clutter in training images  using localized features  they were able to generate segmentation masks for training images that gave the target
 

fitor in our test image  we have developed two multiclass variations  nnw and cte  of the segmentation
mask that will allow a single mask to detect multiple
objects in one image  these methods are not computationally intensive and have shown significant improvements when compared to no weighting during
our initial tests 

tracted by the hs detector  using the hs points as
the centers of   x   pixel windows  we first weighted
the magnitudes of the pixels in each window using a
gaussian window of         for each pixel  we then
calculated its discretized relative orientation and its
weighted contribution to its   x   grid  see figure    
the result was a    dimensional feature vector  which
we normalized to unity to negate the effect of illumination  the final vector was clipped to a threshold to
filter out extremities  and then renormalized for training  since our method differs from the conventional
sift algorithm in keypoint extraction  we did not use
an external library to compute the descriptors  as it
was more practical to implement by hand 

we will first describe our implementation for feature extraction based on the work of marszalek and
schmid     in section    in section    we present a
summary of the original spatial weighting algorithm
and our two algorithms  nnw and cte  section  
describes our final results  and proposed extensions
to our work 

 

feature selection and bag offeatures representation

our feature selection is primarily based on the work
of marszalek and schmid     as an extension of zhang
et al       our method first extracts several local
image descriptors     dimensional hs sift and lssift  from each class in our training set  which it
then clusters to create the bag of features over several classes of objects  this differs from the original
method  which clusters the centroids over all descriptors randomly sampled from the entire data set  regardless of class  for a given test image  classification
is based on the confidence of which class a particular
descriptor belongs to  several descriptors with high
confidence intervals are then chained together to create the boundary of the object 

   

figure   

the calculation of a keypoint descriptor 
weighted by a gaussian window  in blue  and accumulated over  x  subregions  these generate a  x      dimensional feature space  source  lowe    

   

class based k means clustering

during training  we sampled approximately      descriptors from each of our five classes of images  mug 
stapler  scissors  clock  and keyboard   using kmeans clustering with k        we clustered each set
of      descriptors  obtaining   centroid sets of    
elements each       centroids total   we can then
assign each raw descriptor a confidence interval and
a label by the closest  in    dimensional space  euclidean distance centroid from all      centroids 

hs sift and ls sift

for scale invariant feature detection  we implemented
both the harris laplace  hs  and laplacian  ls  detectors for extracting corner and edge regions of our
image  our detectors  based on lowes implementation      sampled descriptors over   octaves of the image  using difference of gaussians  dog  to calculate
relevant keypoints  for all training and test images 
we limited our number of descriptors to     hs sift
and     ls sift to speed up both training and classification 

during testing  after extracting our descriptors
and running our filter  nnw cte   we determined
each descriptors closest centroid in our class based kmeans centroids  the confidence level of the descriptor matching the centroid is given by the difference
in the angles of their orientations in    dimensional
ab
   we then filter the descriptors
space  
  a         b    
to only those that have a confidence level greater than

we then used lowes sift descriptor     to compute the gradient orientations of the local regions ex 

fi     and for each descriptor  we search for other descriptors within  pixel distance to the current descriptor  where  increases with confidence   and repeat this process until we have a chain of descriptors 
when the chain exceeds a certain threshold  the pixel
location bounds of the chain determine the location
of an object  for our purposes  we chose a threshold
of    descriptors  figure   illustrates the technique of
chaining descriptors together 

figure    chaining descriptors together to detect the lo 

figure    pseudocode for marszalek and schmids algo 

cation of an object 

rithm  source  marszalek and schmid    

 

do not have a strong correlation with other descriptors in the image  our tests indicate that cte is
more effective than nnw 

spatial weighting

spatial weighting is a technique that reduces the influence of background clutter and thus highlights descriptors that are unique to the image  for example 
it is possible for a training image for a bike to have
both a bike and a dog in the background  whereas
we are only truly interested in the bike for training
purposes  using the visual vocabulary from hs sift
and ls sift  we can hypothesize about the location
of an object given its spatial relations to words in the
visual vocabulary 

   

nearest neighbor weighting

nnw is heavily based on the original method of spatial weighting  however  instead of obtaining information from the training information ground truth 
it navely assumes that the general shape of an object
can be approximated by a sum of gaussians  we repeat the process of weighting the entire image over the
descriptors which fall into the top n      centroids 

these hypothesis allow us to weight relevant areas of the image  and the least weighted portions of
the image correspond to background clutter and contribute significantly less to the overall image  marszalek and schmids method first calculates the n      
closest descriptors to each descriptor in the test image  and generates a segmentation mask by repeatedly
convolving the mask with gaussians based on the descriptor locations   see figure    
figure    result of using nnw on the first few frames of
we have developed two alternatives to spatial
weighting that are less computationally expensive and
support multiple object detection  both methods are
effective at filtering out background descriptors  although both methods make the general assumption
that background descriptors are generally weak and

the cs    test video 

although nnw was effective at eliminating interest points beyond the weighted boundaries  the issue
was that it could not eliminate enough points within
the interest boundary that were not necessarily spe 

ficte yielded very positive results for eliminating
background noise  figure   shows illustrates the result of running cte on cs    test video  it successfully eliminates almost poor keypoints caused by the
granular texture of the wall and board 

cific to the object  for example  the orientation of
the hands  or the shape of the numbers on a clock
are not indicative of whether the object is a clock itself  furthermore  nnw was poor at eliminating interest points on more elongated objects  such as keyboards   we also noticed that although nnw eliminated background noise  the algorithm is not guaranteed to converge and can often alternate between
different weighting configurations  in general  nnw
did not improve performance overall and we will not
discuss it further 

   

correlation tree elimination

figure    cte example of keypoint elimination on the
cs    vision project  before  left  and after  right  

cte is our original algorithm that uses the same idea
of spatial weighting  but at a very localized level  the
idea behind cte is to construct several correlation
trees out of the descriptors in our set  and classify
only based on descriptors that are in a correlation tree
that exceeds some size threshold t  to construct each
correlation tree  we first compute the closest n     
centroids to each descriptor in our test image  for
each descriptor  we then check every other descriptor
to see if it matches the top n centroids  and add recursively add it to the tree  performing a depth first
search  we do not insert elements into the tree if they
were previously encountered  the result is a partition
of all descriptors into several trees of varying lengths 
all descriptors that belong in a certain tree of length
less than t      are eliminated 

 

results and extensions

we ran our test algorithm on both the easy and moderate cs    testing videos  the easy video has almost
no background clutter  and the moderate video has a
fair amount of background noise  we used the scoring
algorithm as specificed in cs     which computed the
area overlap between pairs of correct objects penalized
by the number of true negatives and false positives 
the results are shown by the following graphs 
improved results using the cte algorithm were
mostly from filtering out false positives  as expected 
in both cases  the cte yields significantly higher
scores than running on our entire set of hs sift and
ls sift descriptors  it should be noted  however 
that our algorithm for detection was not particularly
accurate for all objects  and our current results are
not representative of an improvement over the original method my marszalek and schmid  however 
cte was able to serve our purposes by eliminating
background keypoints quickly while still having the
ability to identify multiple objects in one frame  the
reason for this is because cte keeps all relevant keypoints that belong to some contour of some object  to
show that cte does not in fact decrease the rate of
general object detection  we ran both test videos with
all labels untagged  the cte scored an average of
       on the moderate video  compared with       
without  on the easy video  cte scored        and
       without  the insignificant difference between
score shows that our improved results from cte is
not due to a lack objects being detected 

figure    pseudocode for cte algorithm
 

fisults in the cs    test videos  cte is a viable alternative to spatial weighting  especially in cases where
speed is needed  such as classifying a streaming video 

references
    d  lowe  distinctive image features from scaleinvariant keypoints  international journal of
computer vision   submitted       
    m  marszalek  c  schmid  spatial weighting
for bag of features  ieee computer society
conference on   computer vision and pattern
recognition  v   pp                 
    s  winder  m  brown  learning local image
descriptors  ieee computer society conference on   computer vision and pattern recognition  pp           
    j  zhang  m  marszalek  s  lazebnik  c 
schmid  local features and kernels for classification of texture and object categories  an indepth study  technical report rr       inria
rhone alpes      

figure    score per frame for the easy and moderate
cs    test videos  results shown are run with and without cte 

   

future extensions and summary

there are several potential extensions to our cte algorithm  one potential extension is the addition of
cte to the training process  when training images
contain a significant amount of background clutter  it
is possible to approximate centroids using descriptors
of previously trained images  and use those centroids
to eliminate the clutter in future images  we believe
that some of the inaccuracy from testing is due to
inaccurate descriptors during training  such as logos
on mugs  numbers on clocks  and other various noise
that may appear in the background  another possible extension is to use the partitions generated by
cte as features for bag of features  partitions using
cte generate edge curvature like features that may
be effective as an addition to our hs and ls sift
descriptors 
in this paper  we have shown a new and efficient
algorithm for filtering out unwanted background keypoints of an image  we demonstrated that cte is
effective and significantly improved our initial test re 

fi