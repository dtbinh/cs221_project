classifying press releases and company relationships
based on stock performance

mike mintz
stanford university

ruka sakurai
stanford university

nick briggs
stanford university

mintz stanford edu

ruka sakurai gmail com

njbriggs stanford edu

abstract
we classify press releases as good or bad
news for   companies based on whether the
stock increases n minutes after publication 
we tried different classifiers  multinomial
naive bayes  regularized svm  and nearest neighbors  and various feature representations  such as the tf idf of the words in the
document   we do a few percent better than
majority baseline with our best setup  nearest neighbor classifier with a cosine similarity metric  binary word in doc features  and
n      minutes  stemming words to base
forms helped significantly  using the clustering to predict the stock price of related companies did not work  overall a lack of sufficient press release data was the limiting factor
of our research  various suggestions for improvement are discussed in the conclusion 

 

introduction

press releases are usually the first time news about
companies is made available to the public  we therefore hypothesized that the contents of the press releases are a majority indicator of the short term value
of a companys stock  a machine learning approach
would be able to analyze these press releases and
make predictions about the stock price much faster
than a human analyst could  such a tool could aid
a trader in making quicker decisions based on press
release information  and also help classify press releases as good or bad news for a particular company 


thank you dan ramage for the great advice for text classification 

we compiled a large corpus of press releases for
publicly traded companies  as well as a corpus of
stock price changes for these companies  with high
time precision  we created a classifier for these articles  and trained it using the short term percent
change in stock price for the company  then  given a
press release when it is announced  our classifier attempts to predict whether the stock price of its company will increase or decrease in the short term 
   

prior work

previous work in this area was performed by mittermayer      who designed a system to analyze press
releases in real time and make stock transactions decisions based on them  he used an svm and reported that the svm had trouble marking press releases as good news or bad news 

 
   

data collection
stock data

through the graduate school of business library 
we collected stock data from the new york stock
exchange trade and quote database  nyse taq 
provided by university of chicagos center for research in securities prices  crsp   we focused on
intraday data about all companies in the nyse  for
the intraday data we retrieved the price  volume
and time  to the second  of all trades that occurred 
typically there are multiple transactions that occur
within a minute  this provides us with stock values that are highly precise with respect to time  this
data is also used for clustering companies with similar market fluctuations 

fia months worth of data for all companies in the
nyse comprises more than    gigabytes of information  therefore the challenge is to store this data
in an efficient way without losing the precision that
is needed in our analysis  since press release times
are recorded with precision to the nearest minute  we
store the stock value at each minute  the stock value
at a specific minute is calculated by the weighted
average of the trades that occurred in that minute 
where the weights are the volumes of the transactions  the value of the stock at times without data
from the nyse taq are computed by taking the
value from the nearest minute that has price information 
   

article data

we retrieved press releases and news articles from
the factiva system through the graduate school of
business library  we focused on press releases from
     and       since there was a lot less data available for other years  to simplify the problem  we
limited ourselves to classifying press releases from
three large companies  boeing  mcdonalds  and
verizon  
the press releases were available as xml files 
and contained information about the title  date  paragraph structure  and other metadata that factiva used
for indexing  we simply stored the date and calculated a set of all words contained in the article 
all letters were converted to lowercase  punctuation
was removed  stop words were dropped  and we did
some generalization by replacing specific numbers
with generic number tokens 
articles are kept only if they have date and time
information fully set  some articles only have a published date  which makes it impossible to associate
them with stock price changes during the day  at
our milestone  we had a lot of noisy articles in our
database that were not actually press releases  since
factivas press release classification was not very
accurate  by identifying the most common distributors of true press releases in our corpus  we were
able to remove this noise 
we also test the publication date against the stock
 

since we train a separate classifier on each company  it
would not improve our performance to gather data from more
companies  but doing more than one allows us to do better error
analysis 

data to make sure there were trades going on around
that time  articles that do not have any trades between its publish time and    minutes later are discarded  this brings the number of articles down
from      articles with full time information to
     
over our entire corpus of articles  our vocabulary
size is about         after lower casing words and
removing stop words and numbers   we incorporated a word stemmer     into our project to convert
every word to its base form  for example  it converts both running and run to run  and reduces
our vocabulary size to about             fewer features   as described in our results  this helps our
accuracy significantly 
we wanted to identify bigrams  and possibly
higher order phrases   since phrases like high
profit are only recorded as high and profit  each
of which on its on is not particularly correlated with
good or bad news  we tried adding all seen bigrams as features  but because of the large number
of unique bigrams used in our entire corpus  we had
a data explosion and could not store the feature vectors for even one company in memory 

 
   

classification
implementation

a press release was categorized as good news if
it preceded a rise in stock price over the next n
minutes  and bad news otherwise  we associated
each press release with stock trade data in the appropriate window  we trained on     of our data
for each company  selected randomly using a consistent random seed  and tested on the remaining
     we implemented and trained three classification algorithms  multinomial naive bayes  nb  
support vector machine  svm   and nearest neighbor  nn  
our implementation of nb was based on     
since we only had   categories  we did not implement complement naive bayes as described in the
paper  instead  we implemented category weight
normalization  document length normalization  text
frequency adjustment  using the power law distribution log     fi    where fi is the number of occurrences of a term in the document   and inverse document frequency 

fito implement the regularized svm  we adopted
the libsvm library     
nn was suggested by      at first  we tried to calculate distances by using the euclidean norm  later
testing showed that max cosine similarity   u  uv
    v   
gave the best results 
in addition to these three classifiers  we also implemented a voting classifier that trained these  
classifiers  and used a majority vote to make a prediction  weighted by the confidence of each classifier that supported probabilistic predictions  
   

features

we started out by using tokens from press releases
as is  one of the first things we added to increase
accuracy was a stemmer      reducing the feature
set size by removing different forms of the same
word  as we experimented  we began to take into
account document length  term frequency in a document  and the inverse document frequency of terms
 it is assumed that especially important individual
terms appear in few documents  hence inverse document frequency   for our final round of tests  we
had four configurations for nn and svm  existence
of a term in a document  the count of a term in a
document  the count of a term divided by the documents length  normalized word count   and tf idf
 normalized word count times a term that penalizes
words that appear in many documents   for nb  the
features mentioned in     were always used 

 

classification results

a comparison of the classification accuracy of various algorithms and feature types are shown in figure    the vertical axis shows how much more accurate the results were compared to a majority baseline
classifier  the majority baseline classifier classifies
all examples as the most frequent class in the training set  in this case since the stock market increased
on average in our corpus  the majority baseline classified press releases as positive  the majority baseline classified with a        accuracy 
among the various algorithms  nn performed
the best  followed by svm  computing the feature
values as a binary word in doc out performed the
other methods  normalized word count and tfidf performed below majority baseline  it is es 

figure    the performance of classification with various algorithms and feature types  algorithms  svmsupport vector machine  nb  multinomial naive bayes 
nn  nearest neighbors all combination of three algorithms  feature types  wid  word in document  wcword count  nwc  normalized word count  tfidfterm frequency inverse document frequency 

pecially surprising that the normalized word count
performed significantly worse than the unnormalized word count  its possible that our classifiers
were taking advantage of the document length being
an important feature  and by normalizing the word
counts  we removed this information from our features 
the classifiers worked best for classifying the
press releases of mcdonalds  the nearest neighbor classifier with features represented as a binary
word in document classified mcdonalds press releases     better than the majority baseline classifier 
press releases are written by each company itself 
so it is reasonable that our algorithms perform differently for different companies  the press releases
on some companies may have a very neutral tone
at all times  using very similar vocabulary  on the
other hand the press releases of other companies
may vary its vocabulary significantly between publications  the positive correlated features of mcdonalds  according to naive bayes weights  were
mostly related to its service such as variety  foodservice  and customers  on the other hand  the
negative features of mcdonalds seem to be related

fito finance such as share  outlook  and report 
this might suggest that press releases announcing
news related to its services correlates with an increase in stock price  whereas press releases announcing financial information correlates with a decrease in stock price 
positive
variety
over
visit
llc
ingredients
foodservice
inc
restaurants
customers
through

negative
now
common
shares
full
outlook
you
open
related
report
stock

figure    most important features for mcdonalds

figure    the effect of trade timing on accuracy  trade
timing is how long the algorithms waits after the press
release publication time to compute the change in stock
price 

when the stock market response time was assumed
to be    minutes  without more data and test results  the difference in accuracy may not be significant enough to make a confident conclusion about
the response time of the stock market to a press release 

 

figure    the effect of stemming on accuracy 

figure   shows how stemming improved our classification accuracy  for each classification method 
the results when stemming is used outperform the
results when stemming is not used in all but one
case  stemming reduces the feature size  the improvement in performance may be due to reduced
overfitting by decreasing the feature size 
the algorithm depends on the time it takes for the
stock market to respond to a press release  tests
were performed with various assumptions about the
stock market response time  some of the results
of these tests are shown in figure    the graph
shows the performance of the nearest neighbor classifier  using word in doc  as a function of various
response times  the best performance was observed

clustering

we implemented a clustering algorithm to find
stocks that perform similarly  we obtained one
month of stock trades for every company available
in taq  we discretized the average trade price by
the hour  and for every hour from the beginning
to the end of the month  we calculated the percent
change in price for every stock from the previous
hour  thus  for every stock  we had feature vectors
with about     features representing the direction of
stock movement 
at first we clustered the stocks using k means 
but no matter how high k was  there were always
some very large clusters  we simplified the algorithm by just finding the k closest stocks for
each stock  using the same euclidean distance metric   as validation for the success of using percent
changes every hour  we noticed that the closest company to boeing was rockwell collins  an independent branch of a company that boeing bought sev 

fieral years ago  also  we found that for oil companies like exxon and bp  other oil companies were
in its cluster  which makes sense since their stock
prices are all dependent on a single variable for the
price of oil  however  most of highly related companies were big investment companies that we had
never heard of  which are probably correlated with
the companies because they invest in them 
specifically  we looked at the     closest stocks
to mcdonalds  verizon  and boeing  for each related company  we trained a new classifier for its
stock price  based on the press releases of the original company  e g   mcdonalds   however  on our
best classifier setup  the accuracy of the related companies was in general significantly worse than the
accuracy of the original companies  and in   of the  
related companies  was worse than majority baseline  this suggests that short term stock changes
are not correlated very well with related companies 
which is an unfortunate result  but it also tells us that
the features we got from the press releases are actually meaningful to the company they were trained
for  at least  meaningful enough that the classifier
performs worse on data from other companies 

figure    the performance of related companies vs  original companies with nn wid  parenthetical companies
are the original companies they are clustered with 

 

conclusion

although we had positive results after fine tuning
our classifier setup  we believe that a lot of our neg 

ative results are due to most of the press releases actually being uncorrelated with changes in the stock
market  changes in the stock market only happen
when investors get new information that affects their
judgment about the profitability of the company  and
many articles might not actually provide information
to this effect  upon further analysis of our press releases  only    of the      press releases that happened during trading hours saw a    or higher stock
price increase  lowering our standards to change in
either direction by at least       we found that only
half of the articles have this  we tried considering
only examples where the stock price rose above a
threshold percent positive  and the rest negative  but
this only lowered our accuracy because of very few
positive examples  since we depleted our source of
press releases for      and       it may not be possible to get more data  but what might help is having
our system analyze more volatile stocks  since more
exciting news tends to be announced which can surprise investors  we wanted to find nasdaq data
but the best database we found at the library was the
nyse taq 

as possibilities for further research  we could decrease the number of features and add more variety to the type of features  we could decrease
our features by ignoring words that appear with approximately equal distribution in positive and negative examples  and more advanced word clustering  in addition to stemming  we could use wordnet to collapse synonymous words to the same feature   we could increase the variety of the types features by adding other metadata about press releases
and stocks  such as the change in stock price before the press release was published and the number of words in the press release  as well as bigrams
 without those that appear rarely or in equal distribution among positive and negative examples   finally  we could try reducing noise by removing the
overall change in the stock market from the change
in price  so that external effects like interest rate cuts
have less effect on our data  we could use a clustering algorithm to divide the companies by industry
so that we could train companies differently based
on their industry 

fi 

references
   jason d  m  rennie  lawrence shih  jaime teevan  david r 
karger  tackling the poor assumptions of naive bayes text
classifiers in proceedings of the twentieth international conference on machine learning  icml        washington  d c  
      available http 
http   groups csail mit edu haystack papers rennie icml   pdf
   chih chung chang  chih jen lin  libsvm   a library for support vector machines  available http 
http   www csie ntu edu tw cjlin libsvm 
   christopher d  manning  prabhakar raghavan and hinrich
schtze  introduction to information retrieval  cambridge
university press        available http 
http   www csli stanford edu hinrich information retrievalbook html
   m a  mittermayer  forecasting intraday stock price trends
with text mining techniques in proceedings of the hawaii
international conference on system sciences  january     
      big island  hawaii  available http 
http   www ie iwi unibe ch staff mittermayer resource hawaii pdf
   martin porter  snowball  available http 
http   snowball tartarus org 

fi