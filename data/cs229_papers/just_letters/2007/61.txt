semantic website clustering
i hsuan yang  yu tsun huang  yen ling huang

   abstract

   proposed approach

we propose a new approach to cluster the web pages 
utilizing an iterative reinforced algorithm  the model
extracts semantic feature vectors from user click through
data  we then use lsa  latent semantic analysis  to
reduce the feature dimension and k means algorithm to
cluster documents  compared to the traditional way of
feature extraction  lexical binomial model   our new
model has better purity       and f measure        we
can further use features combined from both methods and
reach purity     and f measure      moreover  the
same method can be used to cluster queries  and with the
result purity     and f measure     

   introduction
as the tremendous fast growing speed of the number of
web pages on the internet  automatic approach for
clustering web pages are more desirable than ever before 
many research groups are developing various techniques
trying to solve the web page clustering problem and there
are also many applications available as well  besides the
lexical features which are used for traditional clustering
method  we further consider utilizing click through
features in order to capture more relationship on
semantics  we revise and improve the iterative reinforced
algorithm to define new similarity measure in several
dimensions on which we can build semantic cluster on
both query and web pages 
in the traditional cluster  it uses only the text to build
features  but there is a lot of information such as picture 
multimedia  meta data  hyperlinks that wont be
captured  since the click through data is manipulated by a
huge set of users  it can be seen as the judgment from
actual users  therefore  the real semantic similarity can be
easily observed via calculating the users real clicks  we
will use the aol click through logs and web pages
automatically crawled from the internet as the training
data  we then compare the performance between our new
features and traditional lexical based features  we also
use user perception test as our evaluation method 
besides web page clustering  we can use this method as
clustering query terms  there are also useful applications
for query term cluster  such as also try suggestions  query
term auto completion 

figure    clustering model flow diagram

    semantic feature vector extraction  blue blocks in
figure   
instead of lexical frequency  we want to use the real
semantic meaning of each web page  using the aol
click through data fits our needs  since those clicks are
judged from real users cognition and conception  we
assume the relevance between queries and documents is
very accurate based on a great deal of data cumulated 
here the documents are web pages 
whenever a user clicks a link from the search result page
 aol data is from google search engine   it produces a
vector containing five fields  users id  usually cookie
number   query  query timestamp  item rank  url  here
we use the query and url field  
to build our
bipartite graph model 
     

bipartite graph model

in xues recent work      they used a bipartite graph
model to fit the click through
data scenario and improved the
search result relevance  one
node of left hand side
represents one query key word
and one node of right hand side
represents
one
document 
assume there are m queries and
n documents  the graph
     
contains node
      at
at left and
right  there exists a link from
to
if and only if there is at least one click data

ficontaining the tuple
 
  moreover  each link has
weight
  which means the frequency of the tuple
    it can be seen as one kind of relevance between
and  
in this project  since the difficulty of labeling the gold
standard clustering  we use a subgraph with two different
sizes
    and
       therefore  the
input of this model is the raw aol click through data and
output will be a data structure of a bipartite graph 

     

where

is the decay factor  and is set to be     here 
represents all the out links for query   and
represents all the in links for document   after several
runs of iteration  in our experiments        runs for size
and
will
    and       runs for size       
converge to a fixed number and to be output to the
semantic feature vector extraction model 
     

iteration method ii

 
since iteration method i doesnt use the frequency
iteration method ii uses the weighted version  the revised
version of the update rule 

nave method feature vector

for each document  we will produce a feature vector with
dimension m  the num of total queries   define the
normalized frequency 

 



 



     

     
 

  it contains the

iteration method i

 
 
 
 



for each iteration  we use the update rule based on the covisited assumption above and update until converge 

  

 

  

 

  

 

 

 
 

 

 



 

in our experiments  it converges a little faster than method
i 
semantic feature vector

 
 
     
 
we have
 
       
 
        and
        here we will use the co visited assumption
again  for each pair  
       
       
which is similar to
first taking all of the queries
 
 
       then sum up all the values
 
  and assign this summation to
 
therefore  the vector
 
  
will be the
semantic feature vector of document  
now

 
 

 

 

    lexical feature vector extraction  green blocks
in figure   



 

 

 



     

the features from nave method can be used for clustering
itself  but there are some problems to overcome  noise 
incompleteness  sparseness and volatility  the point is we
dont want too many zeros in one vector  whereas the
original weight
is very sparse  here  we utilize an
iteration method to fix the problem of raw click data  this
method is based on the assumption of co visited method 
web pages are similar if they are visited by similar
queries  and queries are similar if they visit similar web
 
to be the similarity
pages  here we define
between queries
and
  and
 
to be the
and  
and
are
similarity between documents
initialized to   if the components are identical 

 

 



  

therefore  for document  
feature vector
 
  



 

 

  

 

 



we use lexical words as features to define the similarity
between documents in terms of lexical meaning  two
documents would be considered highly related if they
share plenty of common lexical words  we build a web
crawler to extract all the content text in each document  in
this paper its actually website   applying the porter
stemming algorithm and stop word filter to filter out
unnecessary word to create the lexicon for all training
data  we build the index for each document from the
lexicon and thus the feature for each document is
consisted of all the lexicon words in the lexicon 

fi    latent semantic analysis  pink blocks in figure   
since we have a relatively sparse data even after applying
the iteration method  we use lsa to reduce the dimension
of the feature vector for the document and condense the
feature vector to more concept space  using the
standard svd decomposition to get the singular value and
the eigenvector for   and    we set a target
dimension k equal to the number of clusters labeled in
gold standard clustering  k    in our experiment  and
reduce the higher dimension feature vector to kdimension feature vector 
    combine semantic features with lexical features
we think that the two different kind of feature are
essentially complementary  by combining these two
feature sets we can achieve better performance  the
lexical features can capture the lexical relation between
documents and queries while the semantic feature sets can
capture the semantic relationships  as shown in the
figure   below  we apply lsa to reduce the dimension to
  d to show distribution of our training data in   d space
demonstrating the idea  semantic features can
significantly help to explore the relationship between
documents which could be hard to see in lexical features 
figure    document data distribution in   d projection

provides the users an easier way to navigate and browse
on the internet 
     

document to document search

by constructing the clusters of relevant documents  given
a specific document  we can search for the documents
which are highly related in terms of both lexical and
semantic 
     

query to query search

by constructing the clusters of relevant query  given a
specific query  we can provide the user other highly
relevant query terms as the common also try
functionality widely used on search engines and ecommerce documents 
     

semantic relevance web search

in our model  document will have the feature vector
 
  
  this vector can be utilized to build
additional metadata


  
for   this metadata will improve search result quality
by adding the semantic meaning into the relevance
between query and document  by adjusting weight for
semantic relevant metadata  we can have different kinds
of search result  semantically or lexically  

 

experiment

    data description

    k means algorithm
we use k means algorithm to cluster websites and user
queries terms respectively  we set the k equal to the
number of clusters labeled in gold standard clustering and
start with random seeds  the purity  precision  recall and
f measure are computed by averaging several trials 

we use aol click through log data collection as our
training data  this collection consists of    m web
queries collected from     k users over three months
from    march            may        the data is sorted
by anonymous user id and sequentially arranged  this
click through data collection provides real query log data
that is based on real users  it could be used for
personalization  query reformulation or other types of
search research  the detail statistics of the collection is
showed in table   

    application
this approach can be applied to several applications 
     

automatic web categorization

we always need a good way to automatically categorize
the web pages on the internet  the growing speed of the
internet is too fast that the cost of manually categorizing
the web pages by hand is extremely expensive or even
unaffordable  an automatically generated clustering

table     aol click through dataset stats
basic collection statistics
lines of data

          

instances of new queries  w  or w o clickthrough 
requests for  next page  of results
user click through events

          
         
          

queries w o user click through

          

unique  normalized  query

          

unique user id s

       

fievery data entry in this click through collection data has
the columns  anonid  query  querytime  itemrank 
clickurl  
anonid   an anonymous user id number 
query   the query issued by the user  case shifted with most punctuation

also appear in the machine generated cluster  therefore 
the purity of a clustering is the average precision of all
clusters relative to their best matching clusters in the
gold standard  the f measure is defined as the average fmeasure of the clusters relative to the clusters in goldstandard 

removed 
querytime   the time at which the query was submitted for search 
itemrank   if the user clicked on a search result  the rank of the item on
which they clicked is listed 
clickurl   if the user clicked on a search result  the domain portion of

    result
we conduct the experiment on two tasks 
internet website clustering
user query clustering




the url in the clicked result is listed 

we extract two test dataset as our development set  the
smaller set contains approximately     user queries and
documents  the larger set contains approximately     
user queries and documents  after ranking all the queries
and documents by the frequency in our dataset  we ignore
the first    queries and documents in order to reduce the
number of navigational search in our dataset and extract
the queries  documents and corresponding links between
them in two different sizes as our test set 
    experiment procedure
we conduct the experiment on both semantic feature
vector and lexical feature vector and also the composite
feature vector  various parameters of linear combination
of the two feature vector are used for the composite
feature vector and we perform the experiments on two test
sets of different size  the gold standard clustering for our
development sets are manually labeled by human for
evaluation purpose  the experiment result and clustering
example will be showed in the following section 
    evaluation measures
there are three main approaches for the clustering
evaluation  gold standard  task oriented and user
evaluation  in our experiment  we use gold standard as the
evaluation measures for our clustering  for gold standard
approach  we manually construct an ideal clustering by
human labeling  the ideal clusters are then compared
against the machine generated clusters  a machine
generated clustering is considered perfect if it matches
ideal clustering in gold standard  there are two ways for a
cluster to be less than perfect  it may have poor quality as
it doesnt match any cluster well in the gold standard  and
it may have poor coverage to those websites in goldstandard clustering  we use purity     and f measure    
as our evaluation measures for a clustering  they are
based on the precision and recall of the clusters  precision
is defined as the fraction of documents in the cluster that
also appear in the gold standard  recall is defined as the
fraction of documents in the gold standard cluster that

for website clustering  we conduct the experiment on two
development sets  we have   result sets corresponding to
  different feature vectors  in result r  r  we only use
the semantic features to generate the clustering  in result
l we only use lexical features to generate the clustering
and in result c  c  we use the composite features which
contain both semantic and lexical information 
in the table   below  we can see that nave method and
result l which only use lexical features give us baseline
results  iteration method i and ii both perform better than
nave method as expected  we get even better result at    
of purity and     of f measure when combining those
two feature sets together which is reasonable since we
expect the two feature sets to be complementary  in table
  we show the experiment result on development set   
due to the limitation of affordable work of manually
labeling gold standard  we use a slightly different method
to evaluate the clustering  we only label part of the goldstandard and selectively match the machine generated
clusters to the best matched cluster in the partial goldstandard and only evaluate the purity here to understand
mainly the quality of the clustering  same trend can be
observed as in development set   that the iteration
methods perform better than the nave method  we also
show the result with different parameter
for the
interpolation parameter when combining the two feature
sets for nave method  iteration method i and iteration
method ii in figure     

table    experiment result for document development set  
website development set    size       
purity
f measure
precision
recall
      
      
      
      
result r 
      
      
      
      
result r 
      
      
      
      
result r 
      
      
      
      
result l
      
      
      
      
result c 
      
      
      
     
result c 
      
      
      
      
result c 

fitable    expperiment result forr document develoopment set  
website developm
w
ment set    size        
purity
      
r
result
r 
      
r
result
r 
      
r
result
r 
      
r
result
l
     
r
result
c 
      
r
result
c 
      
r
result
c 

table    experriment result for query
q
developmentt set
user query
q
developmeent set    size       
 
purity
f measure
precision
recall
      
      
      
      
result r 
      
      
      
     
result r 
      
      
      
      
result r 

in figure   below we
w show the acctual clusteringg result
m result c  for website deveelopment set    it is easy
from
to seee that similar websites
w
in term
ms of both lexiical and
semaantic meaning are
a clustered toogether 

figuree    experiment result
r
for nave meethod
   
   
   
   
   
   
   
   
   
 

figure    clusttering example forr website developm
ment set  

method
naivem
purity
precision
recall
fmeasure

                               
         
alpha
figure   
  experiment ressult for iteration method
m
i
   
   
   
   
   
   
   
   
   
 

iterationmodeli

 
purity
precision
recall
fmeasure

                                        
alpha

figure   
  experiment resu
ult for iteration method ii
   
   
   
   
   
   
   
   
   
 

iterationmodelii
purity
precision
recall
fmeasure

                                        
alpha

we also conduuct the experim
w
ment on the usser query data 
u
using
the samee method desccribed in sectioon      we cann
a
also
compute the similarity
y between useer queries andd
g
generate
clusterring on user qu
ueries 

c
conclusion

in thhis web clusteering project  we utilize thee semantic
inforrmation from click through data to extraact feature
vectoors  this novell feature extracction model com
mplements
the traditional lexxical feature extraction method and
proviides an effecctive way to generate sem
mantic rich
clustering  the itteration methood also overccomes the
difficculty of sparseeness from thee nature of clicck through
data and convergess to a fixed pooint representinng the real
simillarity betweenn queries andd documents  using the
combbination of seemantic and lexical
l
featurees we can
achieeve the best performance
p
inn terms of cluuster purity
and f measure 
f

 

r
reference

    g  r 
g
xue  h  jj  zeng  z  cheen  y  yu  w   y  ma  w 
x w g  fan  optimizing web
xi 
w search using
u
web
c
click through
d
data 
in proceeedings of thee thirteenth
a
acm
internatioonal conferennce on inform
mation and
knnowledge maanagement  washington
w
d  c   usa 
n
november
            
    g 
g pass  a  chhowdhury  c  torgeson 
t
 a picture of
search 
the first internnational confe
ference on
mation systems  hong kong  june       
scalable inform
a strehl  relaationship basedd clustering and
a cluster
    a 
e
ensembles
for high dimensional data miining  phd
thhesis  facultyy of the graaduate schoool of the
u
university
of teexas at austin        



fi