introduction 
mobile robots intended to interact with people in indoor office environments  such as the
stanford ai robot  need to be able to detect and locate people in their surroundings 
unfortunately  the task of detecting people with vision methods is very difficult due to the wide
variety of possible poses that people can take on as well as variability in body shape and
haberdashery  we worked on detecting people with  d range data and passive infrared data as a
robust alternative  a side benefit of this approach is that we are capable of accurate  d
localization of people in addition to simple detection  this localization enables interactions such
as fetching an object and bringing it to the person 
related work
there is a very large body of past work in person detection  yet none of it has been very
successful  it is a very active area of research  because of the many potential applications  which
include robotics  surveillance and pornography filtering 
much research has explored the possibility of person detection via vision methods 
mohan  papageorgio  and poggio claim     recall with less than      false detection rate  using
an svm with haar wavelets for features  tunzel  porikli  and meer claim less than    miss
rate with less than   false positive per     frames  using covariance matrices of image brightness
and derivatives of brightness as features for a custom machine learning algorithm that exploits
the fact that covariance matrices lie in a manifold rather than a complete vector space  both of
these examples are somewhat misleading  however  because both place significant constraints on
the pose of the person 
other vision methods include using background subtraction to detect motion and
assuming that any large  moving object is a person  elgammal   these methods are acceptable
for surveillance applications but not for mobile robots  because the background does not remain
constant if the camera is moving  other methods get very good accuracy but rely on the persons
face being visible  such as patil  rybski  kanade  and velosos tracking system 
the use of range data to detect people has been very limited so far  arras  mozos  and
burgard search for the shape of knees in  d range data from a sick laser  and achieve a
maximal detection rate of      xu and fujimura use the same  d data that we use  but only
search for ellipses of hand coded size  their system does not use any machine learning and they
do not publish any quantified results 
much work has also been done with infrared person detection  in general  infrared person
detection suffers badly from false positives  even the best infrared detection systems  such as the
one due to fang  yamada  and ninomiga  can get false detection rates that exceed true positive
rates  even with low detection rates  their false positive rate can be as high as      in some
environmental conditions 
to our knowledge  the combination of infrared and depth has only been explored
previously by bertozzi  who uses stereo vision in both infrared and the visual spectrum
 tetravision  to get depth estimates  the maximal detection rate of his system is in the       
range 
apparatus 
the  d range data is provided by a swissranger       d camera  which returns entire
point clouds at video frame rates through a time of flight method  it also provides a grayscale
image of near ir reflectivity of the scene at a resolution of    x    pixels  the ir data is

fiprovided by a flir thermal infrared camera at a resolution of    x     unfortunately  our
model of infrared camera does not produce temperature calibrated outputthat is  it does not
return absolute temperatures but rather relative temperatures  this means that while brightness in
the image is correlated with heat  we cant use any absolute thresholding features in our model
 unfortunate given that healthy people fall in a very narrow temperature range  
we built a mount for the cameras that immobilizes them at a width of approximately   
centimeters apart and facing in the same direction 
backprojection of the ir image into the point cloud requires accurate calibration of the
two cameras  while this was not a primary focus of our research it turned out to be a more
difficult problem than anticipated  two camera calibration techniques for stereo vision are very
mature  but coming up with corresponding points quickly and accurately in such different sensor
modalities turned out to be troublesome 
our  d camera conveniently provides a near ir reflectivity image in addition to the point
cloud  however  designing a calibration object that has features visible in both near ir
 essentially the same as a visible spectrum grayscale image  and thermal ir would have required
an active source of heat and significant investment of time in designing and fabricating the
object  as a compromise we used a standard calibration checkerboard and shone a strong light
on it  the ink selectively absorbed much more heat and the checkerboard became visible in
thermal ir  unfortunately the heat dissipated quickly  and the resulting images were rather
fuzzy 
the calibration we obtained was usable  but a better calibration would likely improve our
results  our current calibration often projects the infrared values for people onto the points of a
wall behind the person in the  d point cloud  so the correlation between infrared brightness and
personhood is weakened 

approach 
we began the project with an existing person detection system that ian created as part of
the curis program  it works only with  d range data  not with infrared data  and achieved a
detection rate of about     for a recall rate of about     on a relatively easy data set  the
detector works in three stages 
    d point cloud is filtered to remove spurious points that integration in the  d camera
inadvertently introduces at depth discontinuities  we consider a point to be an artifact if the
variance of the z coordinate of the  x  pixel neighborhood is greater than a hand picked
threshold  these points are thrown out  as they do not generally correspond to physical objects 
   each horizontal scan line and each vertical scan line is split at the depth discontinuities
discovered in the first step  this generates a collection of object cross sections for our classifier
to work on  the benefit of the segmentation into cross sections is that it produces a small 
tractable number of regions to classify and that it prevents artifact points at the edges of regions
from affecting our shape features  otherwise artifacts would actually be the most salient features
of the data  
   a variety of features are then computed for these segments  and standard classification
approaches are applied to the problem of determining if a given segment is a segment of a
person  several variations on the features and classifiers are described below  we train separate
classifiers for different elevations  absolute y coordinate  and so as an ensemble the classifiers
are capable of learning different distributions of people in different locations  people are rarely

fifound on the ceiling for example  so lumpy shapes up high are much more likely to be lights  
since we are targeting a mobile robotics application  we are considering data taken from a
uniform height 
   the probabilities returned from the horizontal and vertical scan line are then used to
generate features for a second layer of classification  this stage looks at the distribution of
probability values of points that fall into a person sized rectangular prism to provide a final
result  this step uses the same classification algorithm as the second step  and the result is a set
of probabilities for a variety of rectangular prisms in the scene containing people  after
thresholding and suppression of similar results we obtain the final detections of people 
we maintained this same classification pipeline for this project  and focused on
augmenting the  d features with ir features to improve performance 
classifiers 
for the two classification steps we initially used a bayesian logistic classifier which had
the advantage of training and classifying very quickly  we found it useful for feature selection
because the regularization term drives the weights of less informative features to zero  we
initially used our own implementation of logistic regression but then changed the training
algorithm to use an lbfgs library for compatibility with our research groups codebase  jorge
nocedal  
we also experimented with an svm using the radial basis function as a kernel  for this
we used the libsvm implementation  chih chung chang and chih jen lin  
features 
our  d features for each cross section include 
the raw depth of    points along the cross section  this is normalized by
subtracting the mean depth of the cross section  so that shapes up close produce the same result
as shapes far away   we down or upsample each cross section with a rect kernel in true  d space
 rather than pixel space  so that the same shape always produces the same collection of   
sampled values regardless of its location 
the width of a cross section
coefficients and intercept terms of  st and  nd degree polynomials fit to the
sampled depth values
the angle between two lines fit to opposite halves of the cross section
earlier experiments during curis found that with these features  many other features
become redundant  their weights are driven to zero by regularization  or they do not improve
classifier performance   these include fitting ellipses to the data or including features for the
error between the true values and the shapes fit to them 
our infrared features include 
the mean infrared brightness of a segment
the mean normalized infrared brightness of a segment  where the brightness at
each pixel is normalized by subtracting the mean brightness of the image and dividing by the
variance of the image  this is to compensate for drift in the cameras output over time 

fia   bucket histogram of the brightness of the image points in the segment  this
is to compensate for cases where the calibration projects only half of the image of the person
onto the point cloud for the person  the histogram can discriminate between a region of
uniformly medium brightness and a region that is half dark and half bright 
additionally  when using the logistic we also include some of the feature values squared 
so that the classifier can learn a two sided boundary on that feature  we limit this only to features
that we find it to be useful for  such as width and brightness  because adding too many features
begins to cause overfitting rapidly 
data
we captured over     image pairs and labeled     of them  the new images are
considerably more difficult than the ones ian used for the curis project  we captured scenes
with a greater variety of backgrounds than had been used before  and were sure to include
several scenes that would disrupt the  d segmentation algorithm  such as images of people
holding camera tripods that bisect their body  we also had a much wider range of heights in this
data  and had many images of mainly occluded people  such as people sitting down in a chair
with their back to the cameras and only their head and shoulders visible 
when experimenting with only the cross section classifiers we used     for training and
   for testing  when experimenting with both layers  we used    to train the cross section layer 
   to train the second layer  and    for testing 
results
our most important result was to demonstrate an improvement in our detection accuracy
by incorporating infrared features  the following pr curve demonstrates a significant
improvement at most areas along the curve 
pr curve for cross section models
   
 
   
testir
testnoir

   
   
   
 
 

   

 

   

recall

we think that we could see a much stronger improvement with better ways of
normalizing the infrared values and better calibration 
other experiments confirmed that our logistic models work nearly as well as an svm
using the rbf kernel  this is good to know because it means that we can continue to depend on
the logistic for development and feature evaluation 

fione thing that is troubling about these results is that the performance of the second layer of
classifiers is worse than the first  in other words  we would be better off using our local
probability map to produce our final decision on where people are located than we are using our
probability map that was meant to evaluate the probability of a rectangular prism region
containing a person  this indicates that the features we extract from the prism discard too much
information 

conclusions and future work 
the use of both ir and  d range data for person detection results in reliable detection of people
of very different sizes and in difficult poses  there is significant room for improvement using
our existing approach  particularly in establishing the correspondence between infrared images
and  d point clouds  and in the second classification stage  in preparation for a paper submission
to rss or aaai  we plan to work on using gradient ascent on correlation between edge maps to
automatically learn a better calibration  and to conduct experiments to determine the best way of
normalizing infrared values  we expect that this will yield a very fast and reliable means of
detecting people in indoor environments 

acknowledgements
we are part of the stair vision team  all of our work uses the stair vision library  in
particular  much of our code  such that used to working with camera extrinsics and intrinsics 
was written by stephen gould 

fi