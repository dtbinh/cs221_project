cs    final project  december         

 

hmm analysis and synthesis
of acoustic drum signals
nicholas j  bryan
center for computer research in music and acoustics

abstract hidden markov models  hmms  have been widely
used for speech processing  understanding  and synthesis with
great success  the purpose of this work is to apply this prior
knowledge and investigate the effectiveness of hmms on shortduration percussive musical signals  three main topics of interest
are investigated  isolated instrument recognition  isolated rhythm
transcription for the purpose of genre recognition  and isolated
instrument synthesis  overall  satisfactory results were achieved
with clear motivation for improvement 

i  i ntroduction

p

ercussion  drums  and other rhythmic acoustic signals
and patterns are an integral aspect of modern day music 
entire music genres  careers  and extensive software applications are based off of rhythm or musical patterns through
time  providing a large motivation to learn and model such
information  more specifically  large databases of previously
recorded drum sounds are common place throughout the music
industry with little or no method of automatically labeling 
identifying  or searching with respect to musical parameters 
forcing manual searching with real time auditory assessment 
to attack this issue and provide insight on such problems
as search by rhythm or search by rhythm genre  isolated
instrument recognition  short duration rhythmic recognition 
and isolated re synthesis of acoustic drum set signals of typical
performance are investigated  to model the time series information of both the acoustic pressure information of the musical
samples as well as the rhythmic information of a musical
measure  continuous and discrete observation hidden markov
models are used respectively  once the isolated instrument
recognition hmm models are complete  synthesis can be
performed using the learned hmm models  for an overview
of percussion transcription techniques see     

out of a     point fft using      seconds windows overlapping every      seconds  ideally  the mfcc data effectively
captures a pitch independent frequency response of the audio
signal over time  using such feature vectors also allows for a
respectable synthesis of the instrument sounds 
iii  i solated r ecognition
to break down the problem of isolated acoustic drum set
recognition  six basis classes are used to represent each major
sub instrument of a typical drum set  s   snare drum  b  
bass drum  h   hi hat  t   toms  c   cymbals  and si  
silence   two hundred audio samples for each basis class are
used for learning from a commercially available drum sample
database      the em  or in this context the baum welch 
algorithm is used for learning the continuous observations
using a single gaussian mixture model           to effectively
model the remaining combinations of drum sounds such as a
snare drum and bass drum played simultaneously  sb   snare
  bass   combination data is created via random sampling 
adding together  and amplitude normalization from the basis
class audio files      using all physically realizable combinations  no more than four simultaneous sub instruments at a
time as well as silence exclusion  of the six basis classes  a
total of    overall classes were used  additionally  the level of
combination of each class was identified with a corresponding
complexity level  basis class      two added together  
   etc   for each class  a   state left to right state sequence
hmm model was generated  for recognition  a maximum loglikelihood classification is used 
mfcc parameters

ii  f eature v ectors
with respect to the input feature vectors  the input timedomain audio signals are converted to mel frequency cepstral
coefficients  mfccs       introduced in      mfccs attempt
to more closely model the human auditory response  while
exploiting the decorrelating property of the cepstrum      the
cepstrum of an audio signal can informally be defined as the
inverse fourier transform of the logarithm magnitude of the
fourier transform  the synthesis step  inverse transform  in
application actually uses the discrete cosine transform and
in     was shown to be effective in approximating principal
component analysis  thirteen mfcc coefficients are generated

s 

s 

s 

continuous

fig    

continuous observation hmm state sequence

iv  r hythmic t ranscription for g enre
r ecognition
once each isolated recognition model is learned  musical
sequence or rhythmic recognition of audio files can be applied

fics    final project  december         

 

by using multiple instances of isolated recognition  the sequence or rhythmic recognition must decode each event of the
sub instruments or sub instrument combinations  specifically 
isolated recognition must be processed on each event within
the rhythmic drum pattern  typically one to two measures  
where an event occurs at every smallest division of musical
time or beat  additionally  each rhythm data example must be
normalized with respect to time  once time normalized  the
sequence recognition becomes straight forward and independent of beat detection errors  reason     with dr  rex loop
player  a commercially available music production software 
was used to set a standard     beats per minute for each multimeasure example of a standard     time signature with   th
note quantization  i e  for a two measure pattern     isolated
recognition classifications well be made   for training and

fig    

isolated recognition for every   th note division

testing purposes  a small collection of fifty rock rhythmic patterns and fifty hip hop patterns  previously defined by genre 
were decoded into discrete events consisting of the isolated
recognition classes  once the decoded instrument patterns are
generated  the data can then be used to model the rhythmic
characteristics of the respective genre  a discrete observation
    class  hmm model can then be used to classify using
a maximum log likelihood approach  the two class dataset
illustrated significant results considering the minimal number
of examples  see results
snare   bass
snare

hi hat

as a result  a source filter model can be used with a shapednoise input signal to excite the synthesized parameters      
pink noise  filtered white noise  is used as the excitation and
convolved with the frequency response parameters  mfccs 
for the final output audio signal  pink noise can be defined
by a power spectral density proportional to the reciprocal of
the frequency  the overall synthesis model can be illustrated
in fig     similar to       each time window of mfcc data
essentially acts as a dynamic filter  shaping the spectrally flat
 or sloped  noise  ideally  the generated state sequence can
be used to parametrically control the synthesis of the audio
waveform such as controlling the attack  decay  sustain  and
release parameters of the drum signals  the parameters of the
synthesis were unfortunately difficult to control with respect
to auditory evaluation due to the transient behavior or drum
signals  this is not the case for the typical speech application  
moreover  numerous hmm models of varying state sequence
lengths were used with little noticeable improvement  overall 
a   state sequence was used 
drum sample
database
spectral
parameters
hmm training
optimal state
sequence

analysis
synthesis

hmm spectral
parameter
generation
shaped noise
excitation
fig    

synthesis

audio output

synthesis model

hi hat   snare

vi  r esults
s 

s 

s 

discrete

fig    

discrete observation hmm state sequence

overall results proved moderately successful  the following
will be a presentation and discussion of the results for the isolated recognition  rhythmic transcription for genre recognition 
and synthesis  for all confusion matrices  the rows represent
the known correct classification  while the columns represent
the predicted classification 
a  isolated recognition

v  s ynthesis
independent of the rhythmic transcription  the isolated basis
class hmm models can be used to re synthesize audio wave
forms  the trained hmms and an optimal state sequence can
generate the modeled mfcc parameters using the expected
value observations for each state  unfortunately  while the
mfcc features give an approximate form of the frequency
transfer function of the audio signals  difficulty arises when
attempting to invert the mfcc process  all phase information
of the signal is lost by taking the logarithm of the magnitude  

with respect to isolated recognition  two main training and
testing schemes were implemented  initially     fold crossvalidation was used on the six basis class      examples class 
hmm models only  very accurate results were obtained  see
the confusion matrix in fig     after basis class verification 
   fold cross validation was used to train test all    classes together and can be seen in fig      unfortunately  classification
accuracy greatly decreases as the complexity level increases 
making musicological analysis of the rhythm transcription less
useful  the misclassifications  however  are typically educated

fics    final project  december         

 

confusion matrix    
s
b
c
h
t
si
fig    

s
   
 
 
   
 
 

b
 
  
 
 
 
 

c
 
 
    
 
 
 

h
 
 
 
    
 
 

t
 
 
 
 
    
 

si
 
 
    
 
   
   

confusion matrix    
rock hi hop
rock
  
  
hi hop
  
  

fig    

confusion matrix    
rock hi hop
rock
  
  
hi hop
  
  

basis class confusion matrix    
fig    

in some manner  i e  a snare drum gets misclassified as a
snare   bass drum  and can be interpreted as resonances of the
basis classification  a general analysis of the complexity vs 
classification accuracy result can be seen in fig     see fig    
for a confusion matrix of all classification 

fig    

complexity vs  classification accuracy

b  rhythmic transcription for genre recognition
although the performance of the isolated recognition significantly decreases with complex instrument combinations 
accurate genre recognition using sequential isolated recognition was obtained  using leave one out cross validation and
the minimal database of fifty hip hop and fifty rock classified
two measure audio files  genre classification by rhythmic transcription provided around        classification accuracy  see
the confusion matrices for multiple tests using varying statesequence lengths  it should be noted that a large improvement
on the classification accuracy should result with a significantly
larger database  providing promise for rhythm based genre
recognition 
confusion matrix    
rock hi hop
rock
  
  
hi hop
  
  

fig    

   state discrete observation hmm results

   state discrete observation hmm results

  state discrete observation hmm results

c  synthesis
recognizable synthesis was achieved and can be seen by
comparing the original energy  time domain  and spectrogram
data to the optimal state sequence synthesized data  the
synthesis  however  proved quite difficult to control using the
simplistic synthesis model shown in fig     additionally  the
limited frequency range of the mfcc coefficients severely
limited the quality of the synthesized sounds  unfortunately 
increasing the feature vectors limits the overall accuracy of
hmm model due to the limited size of data  moreover  the
mfcc data does little to model time domain information
which is critical for modeling the transient behavior of drum
signals  an attempt to integrate the delta and delta delta
mfccs was made with little success due to the limited
database size  increasing the dataset size and adding significant
features such as time domain volume envelope information
should significantly increase the behavior for synthesis  see
figures            below for an example of a synthesized
hi hat drum sound  see http   ccrma stanford edu njb cs   
for sound examples   the state sequence transitions can be
visibly seen through the abrupt changes in each plot of data
over time  when comparing sound quality between the isolated
instrument synthesis sounds  the hi hat and snare instruments
proved the most effective because of the more noise modeled
sound  the tom drum and bass drum proved to be more
difficult and require a refined excitation signal 
vii  c onclusions
overall  satisfactory results were achieved  isolated recognition and rhythmic transcription or sequential isolated recognition for genre classification illustrated significant promise
with little future refinement making search by rhythm a possibility for future revision  unfortunately  the hmm synthesis
proved to be quite difficult and exhibited a large need for
improvement with respect to the signal processing synthesis
model  moreover  increasing the dataset size will be needed
and should significantly improve the synthesis model as well
as the isolated recognition 
acknowledgment
thank you to professor andrew ng  the cs    course tas 
and professor ge wang of the center for computer research
in music and acoustics  ccrma  for advice and guidance 

fics    final project  december         

fig     

original vs  synthesized optimal state sequence energy

 

fig     

   
   
    
    

fig     
signal

original vs  synthesized optimal state sequence time domain

r eferences
    d  fitzgerald and j  paulus  unpitched percussion transcription  in
signal processing methods for music transcription  a  klapuri and
m  davy  eds  springer verlag        pp         
    d  ellis  rasta plp mfcc feature calculation and inversion 
 online   available  http   www ee columbia edu dpwe resources 
matlab rastamat 
    p  davis  s   mermelstein  comparison of parametric representations
for monosyllabic word recognition in continuously spoken sentences 
acoustics  speech  and signal processing  see also ieee transactions
on signal processing   ieee transactions on  vol      no     pp     
     aug      
    t  f  quatieri  discrete time speech signal processing  principles and
practices  new jersey  prentice hall       
    b  logan  mel frequency cepstral coefficients for music modeling 
in proceedings of the first international symposium on music
information retrieval  ismir   plymouth  massachusetts  oct      
 online   available  citeseer ist psu edu logan  mel html
    jason mcgerr sessions refill   online   available  http   www 
propellerheads se 
    l  r  rabiner  a tutorial on hidden markov models and selected

original vs  synthesized optimal state sequence spectrogram

applications in speech recognition  proceedings of the ieee  vol     
no     pp               
k  murphy  hidden markov model  hmm  toolbox for matlab 
       online   available  http   www cs ubc ca murphyk software 
hmm hmm html
j  paulus and a  klapuri  conventional and periodic ngrams in
the transcription of drum sequences         online   available 
citeseer ist psu edu paulus  conventional html
t    yamagishi  j  
a  tokuda  k   heiga zen  black  an hmm based speech synthesis
system applied to english  speech synthesis        proceedings of     
ieee workshop on  pp                sept       

fics    final project  december         

 

confusion matrix    
s

b

c

h

t

si

sb

sh

st

bc

bh

bt

ch ct

ht

sbc sbh sbt

bch bct

cht

sch sct

sht

bht

sbch sbct

s

  

 

 

 

 

 

        

 

 

 

 

 

 

 

 

 

   

 

 

 

 

 

 

   

 

 

 

b

 

  

 

 

 

 

      

 

 

 

 

   

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

c

 

 

      

 

 

 

   

 

 

   

 

 

  

 

 

   

 

 

 

 

 

   

   

 

 

 

 

h

 

 

 

      

 

 

 

  

 

 

   

 

     

 

 

   

 

 

 

 

 

 

 

 

 

 

t

 

 

 

 

  

 

 

 

 

     

 

  

 

 

 

 

 

   

 

 

 

 

 

 

 

 

 

si

 

 

 

 

 

     

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

sb

   

      

 

 

 

  

 

   

     

 

 

 

 

 

 

   

   

 

 

 

 

 

 

 

 

 

sc

      

      

 

 

   

        

 

   

 

 

     

 

 

   

 

 

 

   

        

 

 

   

 

sh

  

 

 

 

 

 

 

 

      

 

 

 

     

 

 

   

 

 

 

 

 

 

   

   

   

 

st

   

   

 

 

   

 

 

 

 

  

 

 

 

 

 

 

 

 

  

 

   

 

 

 

   

 

 

   

bc

 

 

 

 

 

 

 

 

 

 

      

 

 

   

 

      

 

   

   

 

   

 

 

 

   

   

bh

 

 

 

 

 

 

   

 

 

 

 

      

 

 

 

 

      

 

 

 

 

 

   

   

   

 

bt

 

 

 

 

      

 

 

 

     

 

  

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

ch

 

 

  

   

 

 

 

 

   

 

 

 

 

  

 

 

 

 

 

   

 

 

        

 

 

   

 

ct

 

 

 

 

 

 

 

 

 

 

 

 

 

 

  

 

   

 

 

 

      

 

      

 

   

  

ht

 

 

 

 

 

 

   

 

 

     

 

 

 

 

      

 

   

 

 

 

 

 

           

 

sbc

 

 

 

 

 

 

 

 

 

 

  

 

 

       

 

      

 

   

 

   

   

   

 

 

 

   

sbh  

 

 

 

 

 

  

   

   

 

 

      

 

 

 

 

  

   

   

 

 

   

 

   

 

   

 

sbt

   

 

 

 

 

 

 

 

  

 

 

      

 

 

 

 

      

 

 

 

 

   

 

 

 

bch  

 

 

 

 

 

 

 

   

 

  

 

 

 

 

 

      

 

        

 

 

 

 

   

  

   

bct

 

 

 

 

 

 

 

 

 

 

 

 

 

 

  

 

   

 

 

 

      

 

      

 

   

  

cht

 

 

 

 

 

 

 

 

 

 

   

 

 

 

 

   

   

   

 

 

   

        

  

   

   

 

    

sch

 

 

 

 

 

 

 

 

 

 

 

 

 

  

 

 

 

 

 

 

 

   

        

   

 

 

 

sct

 

 

 

 

 

 

 

 

 

 

   

 

 

 

  

 

      

 

 

   

 

   

        

 

 

  

sht

 

   

 

 

 

 

   

 

   

     

   

 

 

 

  

 

   

 

   

 

 

 

 

       

 

 

bht

 

   

 

 

 

 

 

 

   

 

 

  

 

 

 

  

 

   

   

 

 

 

 

 

   

  

   

 

sbch    

 

 

 

 

 

 

 

 

 

   

 

 

     

 

  

 

 

  

 

   

   

   

 

 

  

 

sbct  

 

 

 

 

 

   

 

 

 

   

 

 

 

      

   

 

 

   

  

 

 

  

 

   

 

  

 

fig     

sc

all class confusion matrix    

fi