how to win at the track
cary kempston
cdjk cs stanford edu
friday  december         

 

introduction

gambling on horse races is done according to a pari mutuel betting system  all of the money is
pooled  the track removes its take  and whatever is left is divided among the winning bettors  a
consequence of this is that the final odds are not known at the time of betting  since later bettors
could influence the odds  usually  however  estimated odds are posted based on the money wagered
so far     another consequence of pari mutuel betting is that all bets have a negative expected value
if one uses the market odds posted by the track  this negative expected value is a consequence of
the track take  thus  to develop any successful gambling model of horse racing  one must develop
better estimates of the horses win probabilities than the posted odds    
the other necessary component of a horse race betting system involves figuring out exactly how
to bet  this sounds like an easy task  but there are many different possible types of bets  one can
wager on a horse finishing first  win   first or second  place   first  second  or third  show   as well as
many other bets involving multiple horses  quinella  trifecta  exacta  superfecta  and multiple races
 daily double  pick    pick         determining the optimal strategy in the face of these complex
betting choices is beyond the scope of this project  so i will only consider simple  single horse and
single race bets 
these two components would comprise a complete horse race betting system  this project 
however  is concerned only with the first part of this system  developing a method to predict the
winners of horse races 

 

data

my data comes from a one month trackmaster subscription     this allowed me to download data
about every horse race from twenty three tracks from september          until november          
comprising       different races and      finishing horses  i only considered thoroughbred horse
races  since that is the most common type of horse racing in my data  i also only considered horses
that finished  since my model has no notion of not starting or not finishing a race 

   

features

my data consisted of information about each horse in each race  the features i selected out of this
data are given in figure   

 

fifeature
previous wins by horse
number of races by horse
weight carried
horse age
horse sex
medication given
previous wins by jockey
number of races by jockey
previous wins by trainer
number of races by trainer
post position
final odds
track conditions

explanation
percentage of races won by this horse
weight of jockey and saddle
one of  colt  filly  gelding  mare  stallion
bute and or lasix
percentage of races won by this jockey
percentage of races won by this trainer
how far from the inside of the track the horse starts
final odds for this horse to win given by the track
one of  freezing  fast  good  heavy  muddy  snow 
slow  sloppy

figure    features for machine learning algorithms

all features that have values outside of        are normalized to be within that range  the past
performance history is only for the time period that my data spans  as i was unable to find a
source of win data by horse that was both comprehensive and inexpensive  the values in the horse
sex category are colt  young male   filly  young female   mare  older female   gelding  castrated
male   or stallion  older male   that feature  and the track conditions feature were encoded as
binary variables   i e  each sample has a feature that is   if the horse is a filly  and   if not  for each
of the five possible values of horse sex and eight possible values for track conditions 
as target output value  i have both the finishing position of the horse  and the lengths behind
the leader that the horse finished 

 

approaches

this project models horse races  there are some number of entrants in a race  and they cross the
finish line in a ranked order  there are a number of machine learning approaches that can model
races  including ranking algorithms  i e  ordinal regression   classifiers  and regression  all of these
approaches assume independence of each horses chance of winning  the other horses in a race are
not involved in any probability calculations 

   

ranking

initially horse racing seems like a natural place to use a ranking algorithm or some sort of ordinal
regression  which  given a training sample  tries to learn its ordered rank  in this case  the rank
would be the finishing position of a particular horse  using an ordinal regression classifier would
then involve giving it the feature vectors of each horse in a race  and having it predict the finishing
place for each horse  there is a problem with this approach  however  because of the independence
assumption  ordinal regression would output that a particular horse is a fourth place horse in
general  ignoring the other horses in the race  this could result in either multiple predicted first
 

fiplace finishers  or no predicted first place finishers  i discovered no easy way around this problem 
so i did not implement any ranking algorithms 

   

binary classification

binary classification is a more promising approach  this approach learns a classifier on the data
that predicts whether a horse will win the race or not  this algorithm still faces the same problem
as trying to rank finishers  in that multiple or no winners could be predicted  but most classification
algorithms give us some measure of the confidence of the prediction  such as the distance from the
separating hyperplane in an svm   after running a classifier on every horse in a race  we can
predict the winner by picking the horse that the classifier has the highest confidence of winning 
this approach is shown schematically in figure   

figure    using individual binary classifiers to predict one winner 

   

regression

the final approach is using regression to predict how far behind the leader a horse will finish  after
predicting this for each horse in a race  it is an easy matter to sort the horses by the distance behind
the leader and pick the smallest one as the winner  the schematic for this looks very similar to the
classification approach  but with regression replacing each box labeled classifier  and sorting
by the output of the regression instead of confidence 

   

error rate

since the data is on a per horse level  but we are really interested on a per race level  some work
is required to determine the error rate  instead of counting every win loss misclassification as
an error  we should instead go through the data for each race  predict the winner based on the
classification approach described in section      and count the prediction as correct if the picked
horse won  regardless of any other horses classified as winners 
furthermore  it is possible that our approach may not be good at predicting the winner of a
race  but is still good at predicting fast horses  since there are win  place  and show bets  we

 

fifinishes in top n
 
 
 

probability horse wins
     
     
     
figure    success rate of nave prediction strategy 

can calculate the error rate based on the horse coming in first  first or second  and first  second  or
third 
to determine whether these approaches are successful  consider a nave prediction strategy that
involves predicting the winning horse by picking the horse with the most favorable odds  the
results for this strategy are given in figure   

   

method

all learning  classification and regression  was done with support vector machines  using both
linear and gaussian kernels  i used svmlight     for all svm calculations  cross validation holding
back     of the data was done to generate the test success rates  in experimenting with different
parameters  i found that using c      and           for gaussian kernels  to give reasonable
values for the classification problems  i used values c     and         for the regression problems 
although it turns out that regression is not a good approach for this problem  and all values of the
parameters are equally bad 

 

results

initial results are given in figure    these results are not very good  for the regression tests 
the test set success rate is higher than the training set success rate  while for classification the the
training set success rate is significantly higher than the test set success rate  suggesting overfitting 

kernel type
regression
linear
gaussian
classification
linear
gaussian

n  
train test
   
    
   
    
         
         

n  
train test
         
         
         
         

n  
train test
         
         
         
         

figure    training and test set success rates     using all features  n is the place the predicted
horse can finish and still count as a success  

the performance of the regression tests is not very good  most likely because the output variable
 i e   the finish distance behind the leader  is not consistent across races  for example  a horse could
come in second in two races  but finish right behind the leader in one and a long distance behind
the leader in another  these outcomes should be treated the same  but they are treated very
differently by a regression algorithm  regression is therefore taking some element of competition

 

fiinto account  since finishing immediately behind the leader suggests a more competitive race   but
not in any meaningful or consistent way 
the success rates of the classification experiments suggests overfitting  the most likely cause
of this is that i only have win loss history for each horse for the    days that my data spans  this
data includes results for       horses  of which approximately     only raced once  this resulted
in a large number of my training features about the win loss record of the horse to be either   
or       which is not good data for probability calculations 
to correct for this likely overfitting  i repeated my calculations with all the win loss data
removed  these results are given in figure    removing the previous win loss history corrects the
overfitting for the classification tests  but the problems in the regression tests remain 

kernel type
regression
linear
gaussian
classification
linear
gaussian

n  
train test
   
    
   
    
         
         

n  
train test
         
         
         
         

n  
train test
         
         
         
         

figure    training and test set success rates      excluding all previous win features  n is the place
the predicted horse can finish and still count as a success  

 

conclusion

my results show that machine learning techniques can be used to better predict the outcomes
of horse races than the odds  i was able to predict first  second  or third place finishes    
more often than the nave strategy of picking the horse with the best odds  although this is a
small improvement  the large size of the horse racing industry needs to be taken into account in
interpreting the results 

references
    glossary of horse racing terms  http   www drf com help help glossary html 
    ruth n  bolton and randall g  chapman  searching for positive returns at the track  a
multinomial logit model for handicapping horse races  management science                 
     
    t  joachims  making large scale svm learning practical  advances in kernel methods   support vector learning  b  scholkopf  c  burges and a  smola  ed    mit press       
    pari mutuel betting  http   en wikipedia org wiki parimutuel betting 
    trackmaster  http   www trackmaster com 

 

fi