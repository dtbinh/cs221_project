self calibration of a pair of webcams for stereo
vision

rebecca illowsky and landry huet
stanford university
cs     and cs     nal project
december         

fi 

motivations

the idea of the project was originally given by steve gould  a phd student at
the ai laboratory  researchers often waste a lot of time calibrating the cameras
they are using as sensors for their robots  there are two kinds of parameters
for cameras  the rst ones are internal to the cameras  they account for
the properties of their lenses and for their defects  using these parameters
helps getting rid of both linear and quadratic deformations of the pictures and
therefore enhance the pictures for use with computer vision algorithms  they
are called the intrinsic parameters because they depend only on the cameras
themselves and not on their environment  they only need to be computed
once  the second kind of parameters is the class of extrinsic parameters  they
relate the cameras to the outside world  usually the only interesting extrinsic
parameters are the positions and orientations of the cameras  in the case of a
pair of cameras  the extrinsic parameters are essential for stereoscopic vision 
however  these parameters are sensitive to the outside world  if an engineer is
tuning a robot  it means that he will have to start the calibration of extrinsic
parameters all over again every time the cameras of his robot are moved 
a common technique for camera calibration requires taking multiple pictures
of a checkerboard under various angles  and then feeding them to the matlab
camera calibration toolbox  although the process is eective  it is very tedious
and takes at least half an hour for a trained operator  this is not what you want
to focus on when you are working on a robot  but it might use a lot of your time
and energy nonetheless if you have to remove the video sensors of the robot
and put them back often  our aim was therefore to design a technique that
would make the robot recalibrate the extrinsic parameters of its video sensors
by itsself  just by looking at the outside world 

 
   

theoretical background
scene reconstruction using two cameras

let  c    c    be a pair of cameras  let us suppose that we know the translation


vector t and the rotation matrix r that link the image plane of camera c 
to camera c    as well as the matricesha i and a  accounting for the intrinsic


x
parameters of each camera  let m   y be the position vector of a physical
z
point m in space  relative to the frame of the rst camera  let p  and p 
be theh projections
of hm ion the frames of cameras c  and c  respectively  and
i
u 
u 
pe    v  and pe    v  be their homogeneous coordinates in their respective
 
 
frames  m lies on the lines linking the focal centers of the cameras c  and c 
to p  and p  respectively  so there must exist two real numbers s  and s  such
that 
 

m


m

 
 

e
s  a 
  p 


    e
s  r a  p   t

except in degenerate cases there is always a unique solution to this system


of equations  this is not the case when doing numerical computation but m
can be well approximated by plugging the result of the minimization problem
 

fi




    e
e
min s   s    s  a 
  p   s  r a  p    t  back into the system  hence the need
 


for r and t to reconstruct the position of points in space 
   

general scheme to compute the extrinsic parameters

the rst step of our method is to nd corresponding points in various pairs of
images  it turns out that for our purpose it is not necessary that all the points
belong to the same pair of images  from these correspondences we can infer the
epipolar constraint in the form of a matrix  the epipolar constraint is the fact
that all the points of the image plane of c  that could possibly be related to a
given point p  of the image plane of c  as coming from the same physical point
in space lay on a straight line  the knowledge of this constraint then gives us


the translation vector t between the origin of the image plane of camera c 
and that of c    as well as the rotation r of space that transforms the rst image
plane into the second image plane 
we started from pairs of corresponding points  we did not want to study
this part because there are already plenty of librairies that can do the job  and
because it should really be up to the user of our method to choose which one
he prefers  let us now take a closer look at each step of our algorithm 
   

getting the essential matrix

using the same notations as in subsection        let us consider a point m that
projects onto p  and p    let us moreover consider f  and f  the respective
focal centers of cameras c  and c   
m

p 
p 

f 
f 

p    p  and m are coplanar  with respect to an arbitrary origin this constraint yields the equation  
p  




t   rp       

this is bilinear in p  and p  and can be summed up by the matrix e   tbr

 

where tb is the matrix of the map 
u   t  
u   e is called the essential matrix
of the pair of views  and it sums up all the geometry of the system  in practice
the  d coordinates of p  and p  are not directly known  we can x this by
considering pe    a  p  and pe    a  p    as dened in subsection        writing

 

fithe same constraint now gives us
  e
b
pe   a 
  t ra  p     

   

 
b
f   a 
  t ra  is called the fundamental matrix of the uncalibrated system 
since pe  and pe  can be directly measured  we can use     to compute f and
then infer e  given a sucient number of reliable corresponding points between
our two frames  f and e are determined up to a scale factor  so since we want

to keep a track of the sense of displacement  if we know a non null essential
matrix e  we will also be interested by e 
   

from the essential matrix to the extrinsic parameters

 
b
given e   tbr we are looking
t and r  according to        if e   u v is
    for
 
the svd of e and rz         then there are exactly two possible pairs of
    
values for tb and r  





tb    r    u rz u     u rz  v  



tb    r    u rz  u     u rz v  

   

since we get two essential matrices already  we now have four possible solutions 
three of which are physically incorrect  it is possible to nd out by reconstructing the spatial positions linked to the pairs of corresponding points we already
used for the calibration  then we can simply discard the pairs  tb  r  that reconstruct one or more points behind the cameras  negative z  value   note that
since the essential matrix is dened up to a scale factor  so is the translation
vector we nd  theory tells us this is the best we can do without a measurement
of a recognized object in the actual scene 

 
   

from theory to practice
implementation

we programmed a c   implementation of the method 

point correspondences

we used the scale invariant feature transform  sift 
algorithm from the stair research group  which seems to give fairly acurate
results 
the open computer vision library has a built in function
that can compute the fundamental matrix of a pair of pictures given pairs of correspondences  our program gives it all the correspondences the rst step could
nd  the essential matrix is then obtained with two matrix multiplications 

essential matrix

retrieving the extrinsic parameters we use the svd decomposition function from the open computer vision library  it is impossible to select the correct parameters just by eliminating the parameters that produce bad reconstructions  because incorrect correspondences may give inconsistent reconstructions
 

fieven with the right parameters  we therefore keep the solution that produces
the least bad results  we assume that this will be correct if we have many more
good correspondences than bad correspondences 
   

results

in order to assess our method we conducted a series of    experiments    all
the experiments were run on the same setup of our pair of cameras  there were
four runs of experiments  three with an incresing threshold for sift  therefore
getting more and more correspondences of decreasing quality   the last one with
another technique  see      to replace sift  for each run we used more and more
pictures and therefore got more and more points 

fundamental matrix

since our method is supposed unbiaised  the mean of
the fundamental matrices we get can be considered the closest guess we have
about the true fondamental matrix of our system  let us plot the distance to
this best guess against the sift threshold    stands for      

the leftmost points refer to the experiments with the best correspondences
but the least points  whereas the rightmost points correspond to the experiments
with the most correspondences  of lesser quality  we can infer from this that
quantity and quality are about equally acceptable to nd a good fundamental
matrix 
the nal extrinsic parameters only depend on the fundamental matrix  it is
likely that better fundamental matrices will give better results in the end  so let
us choose a particularly successful experiment as far as the fundamental matrix
is concerned  and assess the quality of the other experiments by comparing
their parameters to that of our selection  let us plot the distance between the
translation vectors  and our supposedly good translation vector  against the
quality of the fundamental matrix  distance to the average  
  you
  the

can email rebeccai stanford edu for full results 
translation vectors are normalized so this quantity is to be considered with care 

all the more as the vectors we found are scattered 
rotations 

 

a similar problem would arise with the

fias we can see  even if the supposed quality of the fundamental matrix is
good  the nal result is not necessarily acurate  however  as soon as the fundamental matrix goes bad  the result for the translation vector is always very
bad  the bad conditionning of the matrices of intrinsic parameters is probably
accountable for the extreme sensitivity of the end result to inaccuracy of the
fundamental matrix 

conclusion
the results of our work are promising but our implementation should be tuned
up before being used in real applications  even though it is doubtful that self
calibration will be as acurate as the matlab calibration toolbox  our technique
can be very helpful when time is a bigger issue than precision  as is sometimes
the case in experimental robotics 
finally our work could be improved in several ways 
 by improving accuracy  for instance with a better algorithm to nd correspondences or to approximate the fundamental matrix of the system 
 the program could be made more iterative  so that the user could give the

algorithm correspondences until a certain degree of precision is reached 

bibliography and acknowledgements
references
    yi ma  stefano soatto  jana koeck  s  shankar sastry 

  d vision

an invitation to

self calibration of a stereo rig from
unknown camera motions and point correspondences

    quang tuan luong  olivier faugeras 

    metamorph v    r  universal image corp  automated object tracking with
 track objects  app

best thanks to the stair research group and to steve gould in
particular 
 

fi