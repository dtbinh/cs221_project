object tracking in a video sequence
cs     final project report
young min kim
ymkim stanford edu

abstract
object tracking has been a hot topic in the area of
computer vision  a lot of research has been undergoing
ranging from applications to noble algorithms  however 
most works are focused on a specific application  such as
tracking human  car  or pre learned objects  in this
project  objects randomly chosen by a user are tracked
using sift features and a kalman filter  after sufficient
information about the objects are accumulated  we can
exploit the learning to successfully track objects even
when the objects come into the view after it had been
disappeared for a few frames 

key words  object tracking  sift  kalman filter
   introduction
object tracking is useful in a wide range of
applications  surveillance cameras  vehicle navigation 
perceptual user interface  and augmented reality     
however  most of the research on tracking an object
outperforms using selective algorithms that are applicable
for fixed settings 
the focus of this project is tracking a general object
selected in a real time  the object to be tracked in a frame
is chosen by a user  scale invariant feature transform
 sift  features      point features that are highly
distinguishable for an object  are used as a reliable feature
to track with lack of initial training data  the motion of a
selected object is learned assuming a gaussian model by
kalman filter         while tracking the object  more
features are accumulated and the prediction made by
kalman filter becomes more reliable as more frames are
passed 
the rest of paper is organized as follow  section  
presents the theoretical background about sift features
and kalman filter  the two most important ideas used in
the tracking algorithm  the tracking algorithm is
explained in section   including the usage of sift

features and kalman filter in detail  section   concludes
the paper with possible future extensions of the project 

   background
     sift features
sift     is an efficient way to find distinctive local
features that are invariant to rotation  scale  and possible
occlusion  to find sift features  you produce images in
different scales  each image is convolved with a gaussian
kernel  and the differences between adjacent scales of
convolved images are calculated  candidate keypoints are
local maxima and minima of the difference  from the
candidates  keypoints are selected based on measures of
their stability  one or more orientations are assigned to
each keypoint location based on local image gradient
directions  the gradients at the selected scale in the
region will represent the keypoints  the full description
on calculating sift points and usage of them for
matching images can be found at     
since we do not have any prior knowledge of the
objects  point features are used to represent and detect an
object rather than texture  color or structure 

     kalman filter
kalman filter assumes gaussian distribution of states
and noise  suppose x is the state  z is the measurement  w
is process noise  v is measurement noise  and they are all
gaussian  the noises w and v are independent to states
and measurements  then we have       

where p denotes the error covariance 

fithen  the kalman filter estimates the state x of time
k   and correct the prediction using measurement z of
that time using the following equations 
time update  prediction  

measurement update  correction  

prediction error is smaller than the pre set threshold value 
in the beginning of the algorithm  where we do not have
enough information of the motion of the object  the
identical location of the object as the previous frame is
considered  the following step matches the keypoints
between the candidate area of object and the stored sift
features  the true location of the object is found from the
location of matched keypoints and the measurement value
is used to correct kalman filter  from the location found 
the algorithm continues on to the next frame repeating the
same process  figure   shows the screen shot while
running the tracking algorithm 

the values with bar on the top are predicted value and
k is kalman gain  the full derivation of above equations
is shown in     
       object tracking using kalman filter to use
kalman filter for object tracking we assume that the
motion of the object is almost constant over frames  the
state variables  dynamic matrix and measurement matrix
commonly used for  d tracking can be found in     
figure   algorithm flowchart each step of algorithm interacts
with the kalman filter and the stored sift features of the object 
shown on the right side  when the error of prediction is large 
prediction is set to be the location of the object in the previous
frame 

    the state vector

   tracking algorithm
figure   briefly depicts the basic steps of algorithm in
connection with sift features and a kalman filter of the
object  as shown on the right side of figure    we store a
collection of sift features found and a kalman filter that
is used to predict the next location for each object  the
information is kept even when the object is disappeared
from frame  so that it can be reused when the object
comes into sight in the future 
the tracking algorithm begins when a user selects the
object the object to track  the sift features found in the
location of the object are stored  in the next frame  a
kalman filter makes prediction for a possible location of
the object  the algorithm looks into either the location
predicted by the kalman filter or the identical location as
the previous frame depending on how reliable the kalman
filter is  we use the prediction of kalman filter when the

in the tracking algorithm  not only location but also
size of the tracked object is estimated  as an extension
from section        the width and height of the rectangular

fiselection  and the velocity of change for the width and
height are added as components of state vector 

and the size  w  h  are independent  the assumption is
reasonable in the sense that the direction of which the
object is moving does not have a linear relationship with
the width or height of the object 

    measurement using sift features

figure   transform of feature location from pixel
coordinate to relative coordinate

the coordinates of sift features are transformed into
relative location of the feature to be used as means of
finding location and size of selected object  as seen in
figure    we rescale the selection rectangle into square
with length    the relationship between the stored
coordinate  x  y  and the pixel coordinate  x  y  can be
easily written as 

suppose we have a new frame  and we found matched
feature with relative coordinate  x  y  from pixel
location of  x  y  in the frame  if there are more than one
matched sift features for the object  we can calculate x 
y  h  w by solving the least square solution of following
matrix equation 

     change of noise model

figure   screen shot of every    frames the objects are
shown in green boxes  and sift features are shown in blue dots 
a monitor and a mug are being tracked 

the kalman filter used for the tracking algorithm is a
simple extension from       assuming the location  x  y 

although sift features are distinctive and result in
reliable matching in most of times  sift feature can
rarely pick a matching point that is similar  usually points
within the same object  but not at the exactly same
location  the predictions are not very reliable after the
single mistake  to reduce the effect of the wrong
matching point onto the kalman filter  we will design a
different noise model for measurement update 

fiwhen  is close to   and r  is small and r  is large 
the rare error can be dissolved into case of noise model n
    r    that is  the ordinary correct matching between
sift features in two pictures corresponds to the noise
model with low error  small r  and  close to    while the
rare mismatch case corresponds to the noise model with
higher error  large r    but low probability        after
modifying the kalman filter by the new noise model  the
prediction is robust to wrong measurements 
full derivation of the modified kalman filter
equations with the new noise model  density filtering  is
available in the appendix a 

   experiment
as a standard to compare  i manually leveled tracking
objects at each frame  the performance of the proposed
algorithm and simple optical flow method are compared
in the sense of relative error from the manual standard 
please note that the optical flow algorithm compared is
rather nave algorithm calculated only on the four corners
of the selected region  there are more sophisticated
approaches that we were not able to compare against due
to time constraints 
the optical flow works relatively well in the beginning 
but the error blows up once it lost track of the object  the
average performance measure is  error of proposed
algorithm    error of optical flow            the plots
comparing the two algorithms with different objects are
shown in figure    the large jump at the last frame for
monitor  the second plot  and the mug  the third plot  are
due to the fact that the objects moved out of the view 

   conclusion and future works
with sift features and kalman filters to learn the
motion  you can follow a general object that user selects 
the nobility of the proposed algorithm is robustness in
the cases when it loses track of the object  with higher
resolution and more motion of camera involve  this work
can further extended into finding the location of
stationary objects as well as the odometer of camera 

   acknowledgement
i would like to thank to steve gould for his help
setting up video labeler and providing data set to run and
test the tracking algorithm  this project has been possible
with his invaluable advice  siddharth batra kindly
provided a library to find sift features modifying david
lowes code  professor andrew ng gave advices and
guidelines  i would like to appreciate their contribution on
the project 

figure   plots comparing performance of proposed tracking
algorithm against optical flow

fi   references
    yilmaz  a   javed  o   and shah  m   object
tracking  a survey  acm computing surveys        
article     dec           pages 

the first term 

    lowe  d  g   distinctive image features from scaleinvariant keypoints  international journal of computer
vision               pp         
    weissman  t   ee    handout  kalman filter 
lecture notes on ee    statistical signal processing 
http   eeclass stanford edu ee     

second term 

    intel coporation  opencv reference manual  http   
www cs unc edu research stc faqs opencv opencvref
erencemanual pdf            
    thrun  s   and kosecka  j   lecture    tracking
motion 
lecture
notes
on
cs   b 
http   cs   b stanford 
edu notes cs   b l   tracking ppt

the equations for modified kalman filter that uses the
new model for measurement update can be found by
adequate substitutions of noise into the mean and
variance found above  n is r  g is k  and p is the
covariance 

appendix a  density filtering
suppose h is a deterministic matrix and u and n are
independently gaussian vectors  then  the probability
distribution of u given v is also gaussian when v  u 
and n are related as below 

now  suppose our noise model n is changed in
accordance with random variable z 

the distribution of u given v is still gaussian but the
mean and the variance is changed  the mean is easily
calculated 

to calculate variance  we can use the law of total
variance 

the hat means it is the value  kalman gain  corrected
state  posterior error covariance  of new noise model for
measurement update 

fi