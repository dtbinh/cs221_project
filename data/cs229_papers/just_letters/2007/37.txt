structural edge learning for   d reconstruction from a
single still image
nan hu
stanford university
electrical engineering
nanhu stanford edu
abstract
learning   d scene structure from a single still image
has become a hot research topic recently  during which
edges played a very important role as they provided
critical information about the structures  while not all
the intensity edges are useful  existing   d reconstruction methods suffered heavily when not differentiating
structural edges with non structural ones  in this report  we consider learning structural edges rather than
edges from intensity values of the image  through supervised learning  the learnt edges as shown in this report carries more stuctural information and less noise
than intensity edges  the comparison of two kinds of
edges are also shown in the report 

for about     of the testing set  however  their methods suffered from not differentiating structural edges
for non structural ones  since not all the intensity edges
carried useful information about the structured scene 
for the small planes  edges are very useful in estimating the connectedness of those planes  without the
correct structural edges detected  visually far apart objects could be connected together by the mrf  thus 
it is imperative to develop an algorithm to learn structural edges to improve the performance of the their
system 

   introduction
 a 
classical work on   d reconstruction mainly focus on
using methods like stereovision     and structure from
motion      which requires two  or more  images and
triangulation for depth estimation  recently  monocular vision has arouse interests of many researchers 
since there are numerous monocular cues that could
be utilized when estimating the depth  an good example of analogy is the human eyes  even when using
only one eye  people can always have a very good estimate the relative depth about the scene  saxena et al 
    proposed a method to estimate the   d depth information from a single still image  their proposed approach took an image over segmemted into a number
of small planes called superpixels  and used markov
random field  mrf  to infer both the   d position
and the orientation of each of these small planes  the
mrf parameters were trained using supervised learning  their algorithm was able to infer qualititively correct and visually pleasing   d models automatically

 b 

 c 

fig     comparison of edges   a  original image 
 b  edge after manually merging connected parts   c 
edge by cannys method 
in this report  we proposed a supervised learning
algorithm to learn the structural edge from non structural
ones  for each image in the training set  felzenszwalbs
method     was used to group similar pixels together
to get superpixels  texture based summary statistic
features  and superpixel shape and location based features were then extracted from each superpixels in the
image  by manually labeling connected objects  superpixels representing connected objects are merged
together and the structural edges are at the boundary
of the superpixels representing disconnected objects 
through our labeling  structural edges are differentiated from non structural ones  logistic regression
parameters were afterwards trained using the labeled

fistructural and non structural edges  as can be seen
from our testing sets  our proposed method successfully inferred edges with more structural information
than the intensity edges as well as less noise 
the rest of the report is organized as follows  in
section    our proposed models and the feature filters
will be described  the experimental results are shown
in section    in addition  some discussion and the conclusion will be presented in section  
   model description
       d scene reconstruction model
since the features extracted has a strong connection
with ashutoshs   d reconstruction model         a
brief introduction of his model will be first described 
in      a polygonal mesh is used to represent the   d
model  where the world is assumed to be composed
of a set of small planes  in detail  given an image of
scene  small homogeneous regines were found in the
image  by using felzenszwalbs method      those
small regines are called superpixels  such regions
represent a coherent region in the scene with all the
pixels having similiar properties  and hence is a reasonable representation  markov random field  mrf 
are then used to infer both the   d position and orientation information of the superpixels  thus  each node in
the mrf is correponding to a superpixel in the image 
the mrf model is supposed to capture the following
properties 

them togeter  confidence factor needs to be set up for
them in the mrf  as can be imagined  edgels  edges
between two neighboring superpixels  are a good way
to express the confidence on the connectedness and the
co planarity of two adjacent superpixels 
     learning model
it can be easily seen that edgels are very useful indicators of the occlusion boundaries and folds  places
where two planes are connectedby no co planar   when
there is an edge  the two neighboring superpixels are
more likely to be either belong to two diferent objects distant from each other  which corresponds to an
occlusion  or belong to two parts of a single object 
which is a possible fold  hereafter  we will use yij
to indicate the binary edge value between superpixel
si and sj   then we have yij          specifically 
we set yij     to be the edge  which doesnt conform
with the conventional setting  simply because we want
the larger yij values represent the higher confidence
of the connectedness or co planarity of two adjacent
superpixels 
let the features extracted from the image for each
pair of neighboring superpixels be xij  the extraction
of features are dicussed in section       we can then
model the response between yij and xij as a logistic
function 
p  yij  xij      

 
 
    exp t xij  

   

to obtain the yij s for each pair si and sj of the su image features and depth  the image features
perpixels 
images were first manually labeled to conof a superpixel bear some relation to the depth and
nect
those
superpixel that are visually connected toorientation  of the superpixel 
gether  by this means  part of the superpixels detected
 connected structure  except in case of occluautomatically are merged together  fig    showed
sion  neighboring superpixels are more likely to
an example of the manually labeled edge image as
be connected together 
compared with the automatically detected edge using
cannys method     
 co planar stucture  neighboring superpixels
as can be seen  in our special problem  the edge
are more likely to belong to the same plane  if
shown as fig     b  looks more reasonable as it conthey have similiar features and if there are no
forms with the   d spatial structure of the scene  which
edges between them 
is our goal for the edge learning 
 co linearity  long straight lines in the image
are more likely to be straight lines in the   d
     features
model  for example  edges of buildings  sidefor each superpixel  a number of features are comwalk  windows  etc 
puted to capture the monocular cues that is useful to infer the edges  for each superpixel at location i  texturenone of these properties individually can determine
based summary statistic features  and superpixel shape
the   d structure of the scene  thus  when combining

fi    

fig     the convolution filters used for texture energies and gradients  teh first   are      laws masks 
the last   are the oriented edge detectors at      the
nine laws masks do local   edge detection and spot
detection  the    laws mask were applied to the y
channel of the image  only the first averaging filter
to the color channels cb and cr were applied  thus   
filter reponses were obtained  as both of energy and
kurtosis were calculated  totally    features were obtained for each patch 
and location based features are computed  particularly 
the features are computed as the output of each of the
      laws masks    color channels in ycbcr space
and   oriented edges  see fig     filters  as the structural edge is a characterization of the two adjacent superpixels  the    features for each of the two superpixels are combined together to have a totally    features 

   experimental results
our experiment was done on a desktop with amd
athlon      ghz cpu and  gb memory  in the
experiment     images from the database are first manually labeled by the tools provided by
http   make d stanford edu scribble index     
where     are the image number in the database 
considering the vertical difference in terms of the catogories of normally seen objects within an image  for
example  normally the ground is at the bottom part of
the image and the sky is at the top  we separate the
image vertically into    rows as the features in different vertical rows are supposed to be different  logistic
regression is then applied to each row such that the parameters trained are for each row only 
in addition  to reduce the redundancy of the features  pca with      of total variance preserved was
applied to the feature vectors before the logistic regression  a comparison of the training error with pca applied and with it not applied for each row is shown in
fig    
as can be seen the error rates for both methods are
roughly the same  the training time differed quite a lot
as shown in table    thus  the method with pca is
prefered 

   

    
logis c
   

logis c   pca       

    

 
r  r  r  r  r  r  r  r  r  r   r  

fig     error rate of each row  r  r    for logistic
regression with pca  red  and without pca  blue  

average
training time

logistic

logistic with
pca       

    s

    s

table    total training time for logistic regression
with and without pca 
to test our proposed method on unseen images  a
leave one out cross validation  loocv  is done on
all the    labeled images  the averaged testing error
compared with the training error for the logistic regression with pca applied are reported in fig    
   
    
   
    

training error
tes ng error

   
    
 
r 

r 

r 

r 

r 

r 

r 

r 

r  r   r  

fig     training error vs loocv testing error for logistic regression with pca applied 
as expected  the testing error is a little larger than
the training error  however comparable  which thus consolidates our previous assertion that the use of pca
prior to logistic regression is a reasonable choice 
shown below in fig    are some of the learnt structural edges from the cross validation  as can be seen 

fithe learnt edges improved from the edges from superpixels by emphasizing on the edgels with more structural information 

    d  scharstein and r  szeliski  a taxonomy and
evaluation of dense two frame stereo correspondence algorithms  intl journal of compter vision  vol           

   discussion and conclusion

    d  forsyth and j  ponce  computer vision  a
mordern approach  prentice hall       

logistic regression is by no means the only choice 
experiments also done using support vector machines
 svm  with radial basis function  rbf  kernels  the
comparison of the training error is shown in fig    
as can be seen  svm   rbf method improved the
training error a little bit  the reason we didnt choose
this method is because of the long training error  in
our experiment  training of    images using svm  
rbf took around a whole day on the same computer 
    

   

    
svm   rbf   pca       
   

logis c   pca       

    

 
r  r  r  r  r  r  r  r  r  r   r  

fig     training error for svm   rbf and logistic
regression both with pca applied 

acknowledgement
the author would like to thank ashutosh saxena for
helpful discussions  as edge learning is part of the
project in      the overall structure of the   d reconstruction is from the paper 
   references
    ashutosh saxena  min sun  andrew y  ng 
learning   d scene structure from a single still
image  in iccv workshop on  d representation
for recognition   drr           
    ashutosh saxena  sung h  chung  andrew y 
ng  learning depth from single monocular images  in neural information processing systems
 nips           

    f  felzenszwalb and d  huttenlocher  efficient
graph based image segmentation  intl journal
of computer vision  vol           
    j f canny  a computational approach to edge
detection  ieee trans pattern analysis and machine intelligence                 nov      

fi  a 

  b 

  c 

  a 

  b 

  c 

  a 

  b 

  c 

  a 

  b 

  c 

fig     comparison of edges   a  original images   b  learnt structural edges   c  edges from superpixels 

fi