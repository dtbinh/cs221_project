inferring  d scene structure from a single still image
gabriel yu and jing chen  advised by ashutosh saxena 
   introduction 
in this project  we revisit the problem of
constructing  d structures from single still images 
we build upon previous work done by saxena  sun
and ng     by improving on the inference
techniques used in their algorithm  with the goal of
producing  d models that are more quantitatively
accurate  as well as more visually pleasing 
one area of improvement in the existing
algorithm is the penalty function used during map
inference of plane parameters  when inferring  d
models from single still images  the penalty
function is used to enforce constraints such as
connectedness  co planarity  and co linearity 
properties of the penalty function consequently
determine whether the transition between two
planes in the  d model is smooth or sharp  the
current penalty function  the l  norm of the error 
does not prefer either a smooth transition or a sharp
transition  as a result  the resulting  d models
often have walls sloping away from the ground 
rather than standing straight up  our goal was to
find a suitable penalty function that prefers a sharp
transition over a smooth transition 
another area of improvement is to make use of
user provided scribbles during inference so that
the result is closer to how a human perceives the
image  the idea is that these scribbles could be
used to help the algorithm make immediate
improvements in inferring the  d model of a given
image 
a subproblem to using scribbles during
inference is finding the correct scribble  which is
the one that would give optimal performance in the
new inference algorithm  we devised an algorithm
that used supervised learning to make use of the
coarse scribbles provided by users to infer
information about other areas in the image that
have not been filled in by scribbles 

this report is divided into three portions  each
describing the work that has been done in the three
areas described 
   penalty function
the penalty function that is currently used  the
l  norm  approximated by   x    does not prefer
either a smooth transition or a sharp transition  the
goal of this portion of the project was to find a
penalty function that prefers a sharp transition over
a smooth one  in order to bring foreground objects
to the front  for images where the object would
slope into the background when using the original
penalty function 
current progress 
a   l  norm  we started out by implementing the
l  norm  to gain familiarity with the system  this
gave a result that was not significantly different
from the original  although it made more mistakes
than the original in certain test images 

figure    graph of the penalty functions
b   log       x    we saw encouraging results
with this penalty function  for one particular test
image  the result was clearly better than the
original results  see figure     rather than sloping
inward to the background  a bush in the foreground
stayed vertical in the foreground  this shows that
the log       x   function performs better than the
original in certain cases  for images where there
was no clear improvement  the results from this
function were at least as accurate as the original

fifigure           a  original                b  log     x                                      c     x   
the images above show the improvement that the new penalty functions give over the original 
results  although the two functions often made
mistakes in different areas 
c      x     we saw similar results with this
function  in the same test image that was
mentioned above  the bush also came to the
foreground  in examples without such obvious
improvements  its performance was roughly the
same as the log       x   function and the l 
norm 
d   min a    x    this function is not differentiable 
but we used the fact that 

min a  b   

a  b   a  b  
 
 
 

using gamma x  to approximate the absolute value
function again  we came up with an approximation
of the min function that was differentiable 
unfortunately  the results for this function were
not usable due to numerical problems  possibly
caused by a badly conditioned hessian close to x  
  

numerical stability
the new penalty functions resulted in
numerical inaccuracies at lower values of   than
the original penalty function  where higher values
of   give more accurate approximations of the
absolute value function  the initial solution to cap
the number of iterations  thus capping the value of
   however  this did not work for all images  since
the threshold at which the numerical inaccuracy
appeared was different for each image 
to deal with this  we instead checked when the
hessian matrix of the penalty function became
singular while incrementing    then capped   at the
value before the step where the matrix became
singular  and reset   to that value for the next
iteration  this meant that the penalty function
would work for all images  while maximizing   for
each image 
this method also proved to be useful for the
user provided hints portion  since the increased
weights caused numerical inaccuracies to appear at
lower values of    even when using the original
penalty function 

fifigure    typical results from our algorithm  the first three models are considered  good   for the 
last model  while the plane of the front of the house is separated from its side planes as expected  
its orientation is incorrect  
edge maps
mixed penalty functions
we also tried using different penalty functions
checking whether a change to the algorithm
for different properties  co linearity  co planarity 
worked was initially done by visually inspecting
the resulting  d model for each image  however 
connectivity   with the idea that a penalty function
may work better for one property than another 
this method is inaccurate and subjective  and it
however  the results showed no significant
becomes easy to miss minor differences  to
improvement over using either the log function or
attempt to make testing new methods more
objective  we generated edge maps for each result 
the   norm  there were minor differences in the
these edge maps were generated from the
resulting  d structure  but the differences were not
residuals that resulted from the penalty function 
clearly better or worse than the results from using
the higher the residual for a given pair of
non mixed penalty functions 
neighboring superpixels  the more likely it was that
   inference with scribbles 
algorithm was classifying the edge between the
for this portion of the project  an online
pair as a boundary between two separate planes 
drawing
tool was provided to let users scribble
the resulting edge maps from trial runs could be
colored lines on top of their images  neighboring
compared much more easily and objectively than
superpixels with the same scribble color are
visually inspecting the  d model 
interpreted as being on the same plane  while

fineighboring superpixels with different color
should be on different planes 
since the scribbles drawn by users are often
coarse and imprecise  we have to first pre process
the scribble image  we do so by first filling in any
holes encompassed by the scribble lines  we then
apply a non linear filter to the scribble image  in
which each pixel takes on the most frequent color
in its  x  neighborhood  this essentially expands
the user provided scribbles with inferred auxiliary
colors 
we then hand tuned the weights of the
co planarity and connectivity constraint functions
used in saxena  sun and ng  in order to enforce
co planarity between two superpixels  the weights
of the co planarity constraints are set to high
values  to enforce non co planarity  weights to
both the co planarity and connectivity constraints
are set to low values  because connectivity often
indirectly enforces co planarity  in addition  a
lower weight is given to neighbors with auxiliary
colors than to those with actual scribble colors 
results and discussions
we randomly picked    images uploaded to
the website and subjectively selected those that are
not visually pleasing  we then added scribbled
lines to the images  and used the algorithm to
re infer the  d models 
to get a fair qualitative evaluation of the result 
we should have collected ratings from users in the
websites  but we were unable to publish the latest
algorithm to the web in time to collect statistics 
however  by visually comparing the original
model with the new models  the modified
algorithm improves the visual quality of the model
in more than half of the cases 
in all cases  the algorithm is successful in
making planes co planar  while separating planes
that should not be co planar  however  since the
scribble does not explicitly provide hints about the
orientation of the planes  the algorithm sometimes
makes certain planes that are correct in the original
model co planar attached to a plane with an

incorrect orientation  thus magnifying the original
problem  see the last sample in figure     in other
words  the algorithm works well when the majority
of the scribbles cover planes whose orientation
was correct in the original model 
for complete results  please visit 
http   ai stanford edu  gbrlhkyu images
   on the fly learning of scribbles
the  d models re inferred using the scribbles
are only as good as the scribbles provided by users 
therefore  as described in the previous section  we
tried using various tricks to modify the scribbles 
however  the resulting scribble image is still
highly dependent on original scribble 
therefore  to make better use of the scribbles 
we experimented using supervised learning to
intelligently infer the scribble on the fly 
learning algorithm
the learning problem is formulated as follows 
for each pixel on the image not scribbled by users 
we want to use the information given by the user s
scribble to infer a scribble color that should be
assigned to this pixel  this is a multi class
classification problem  and we reduce it to multiple
binary classification problems 
specifically  for each scribble color c  the
input features are the rgb value of a given pixel 
and the class labels are   if color c is scribbled on
the pixel and   if otherwise  the training data are
all the pixels in the images that are currently filled
in with scribbles by users  we then model the
relationship between the input features and class
label using logistic regression with gradient
descent  the resulting learned hypothesis will then
output the probability that the given pixel belongs
to color c 
after learning the hypothesis for each scribble
color  we then use it to model the probability that a
given pixel should be assigned a particular color 
for each pixel that was not filled in by the user 
these pixels are then assigned the color with the
highest probability for that pixel 

fifigure    selected 
results from our 
algorithm   as 
seen in the second 
results  the 
algorithm 
performs wells if 
planes contain the 
same color    

function that gave a noticeable improvement in
performance for samples where a foreground
object appeared attached to the background  we
also succeeded in using user provided scribbles to
improve the quality of the result  to improve the
results even further for cases where the provided
scribble is very coarse or inaccurate  we
implemented a method for inferring more
comprehensive information from the given
scribble  the end result is a system that gives
better results on several samples  without
degradation in quality for samples with no clear
improvement 

results and discussions
we randomly picked   sets of images and
scribbles from the websites and use them to test the
learning algorithm  we then visually evaluate
whether the inferred scribble covers regions that
should or should not be co planar in the human
eyes 
as expected by the simplicity of the features 
the algorithm works well only if each plane has the
same colors  however  it will not work well if the
planes contain different colors  see figure    
there are many way to improve the current
algorithm  we can use hgv or ycbcr values
instead of rgb values  which are known to give
better performance for image processing  we
could also increase the number of features by
looking at properties of the neighboring pixels 

we would like to thank ashutosh saxena for
the many helpful ideas and thoughtful advice that
he provided throughout the course of this project 

   conclusion 

   references 

the goal for this project was to improve the
performance of the original system  especially the
mistakes that appeared frequently for typical
images  we succeeded in finding a penalty

    learning   d scene structure from a single
still image  ashutosh saxena  min sun  andrew
y  ng  in iccv workshop on  d representation
for recognition   drr          

   acknowledgements 

fi