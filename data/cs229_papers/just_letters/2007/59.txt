corporate valuation using machine learning
stanford university cs    project report
aditya mittal  simon ejsing  javier mares romero

fiproject overview
terabytes of information on more than    million companies around the world are
available for analysis  wharton business schools wrds software makes it trivial to
obtain arbitrarily large datasets of the most up to date information on any aspect of those
companies 
quoting googles peter norvig on his talk on  theorizing from data  avoiding the
capital mistake 
rather than argue about whether this algorithm is better than that algorithm  all you
have to do is get ten times more training data  and now all of a sudden  the worst
algorithm     is performing better than the best algorithm on less training data 
the super exponential increase in price performance of information technologies is
enabling fast and cheap analysis of vast amounts of data  this can bring about suggests
that qualitatively deeper insight is feasible  it is fair to assume that the most advanced
insight to be drawn from these data will be produced by a process combining machine
and human intelligence  in the case of quantitative analysis  computer clusters can
observe millions of market transactions 
a good example of this synergy is the fatkat hedge fund which incorporates the insights
and style from the worlds number one hedge fund manager james simons 
this project aims to find subtle  persistent patterns in successful companies attributes
using machine learning algorithms  stanford has access to a long list of business
databases through wrds  we used amadeus  a pan european database containing
information on over   million private and public companies  the type of data used
includes yearly or quarterly balance sheets  income statements  cash flow statements in
other words  any numerical attribute of a company 

data acquisition
the concept is to aggregate the information from all databases on each company into a
matrix  the rows corresponding to a single company and the columns to each attribute 
unfortunately  we have found that our data sources are sparse in the sense that a lot of
data values are reported as not available  therefore  a very small dataset of    
companies was at first used to avoid handling missing values  this dataset was generated
by prune ever sample with missing entries from the training dataset  however  this
method of dealing with missing values caused too much data loss 

fifigure   data loss
therefore  it seems intuitive to try to recover some of the lost data  in our first attempt we
insert zero values for every missing value  regardless of which feature they correspond to 
this approach has the obvious drawback of introducing erroneous data points into the
dataset  but we have found that the gain in valid data more than up weighs the introduced
errors  anyway  the testing process should reveal whether or not this approach is better
than to prune examples with missing data 
an even better approach is to try and estimate the true value of the missing data points 
this seeks to reduce the introduced errors  a simple approach is to set the missing data to
be the observed average of that particular feature  while a more elaborate approach would
be to try to approximate the distribution on the feature using a normal distribution and
then randomly draw the missing values from this distribution  however  we stress that
whichever labeling is used  these cannot be recovered in this manor  as it would lead to
miscalculations of the test error percentage 
visualizing the data
data is visualized early on to get an idea of the relationship between trends and to find
any spurious data  here is an example 

fifigure    correlation between features representative of the size of a company
in finance when making a decision based upon the size of a company  decision makers
use three different aspects  some use total assets  others use number of employees 
and yet others use the total operating revenue of a company to make this decision  we
expect that the three features should be highly correlated and we represent our
expectation in the graph above and observe that it is the case that the three features are
highly correlated  this leads us to a more general realization about the nature of the
features in our databases that many of the features are highly correlated  this inspires the
removal of features that are highly correlated from the feature set derived directly from
the database 
extracting the principal components
inspired by the above observation  in this part of the project we apply principal
component analysis  pca  to extract the feature vectors which are necessary to
evaluating the valuation of a corporation  this reduces the dimensionality and hence the
complexity of the problem  before applying the pca we preprocess the data to have zero
mean and unit variance  we also use only features for which data exists for most
companies and not the features which we have data only for very few of the companies in
the data set  this way we end up considering only orthogonal components of the data
and eliminating features that can be represented as linear combinations of other features 
in our work for example  this algorithm successfully reduces datasets of    features to
just about    features with only    relative error 

fifigure    applying principal component analysis to financial datasets
we predict that in financial data there is a high reduction of dimensionality by using pca
because many of the financial features are ratios and sums of other features 
labeling the dataset
the labeling of the dataset defines our merit of performance of a company  in our project
we use each companys stock turnover as the merit function  in particular  we are
interested in whether a given company is performing better than the market  we
approximate the market performance as the mean of the stock turnover for all companies
in the dataset  if a company performs above average we label it with     otherwise    
labeling of the companies is done based on stock turnover from       while all
features are extracted annually from             the extracted features do not include
data on stock turnover 
logistic regression
after computing the principle components we use logistic regression learning algorithm
to classify binary data  the purpose of this is to be able to apply this machine learning
algorithm and classify binary data  in our code we have created a function which can
take any vector of data and convert it to binary data around either the mean of the data
vector or a set threshold value  the binary classification using logistic regression works
pretty well when we apply it to vectors within the data  however  the classification fails
when we apply it to the real test data from of stock turnover values from wrds  this is
because this dataset is very complex and closely related values occur even in higher
dimensions and the algorithm is unable to find a hyper plane that can separate this data 

fisvm and cross validation
after realizing the failure of logistic regression on our training dataset  we look into other
algorithms  our choice fell on the svm implementation because we are able to adjust the
c parameter to allow the separation boundary to be imperfect  thus circumventing the
problem we encountered with logistic regression  we picked up from the smo
implementation we did in homework   and adjusted some minor details 
we were first able to successfully train the svm on our small sample dataset of    
companies  during our training we used a tolerance value of        a c of     and
max passes of     having completed the training procedure we performed a test on    
companies that was left out of the training set  we carried out this test in a k fold leave
out manor  and were able to obtain at best     test error  while at worst     error 
given the vague testing basis  this can easily be attributed to chance 
c
   
 
 
 
 
 

tolerance
     
     
      
     
      
     

max
passes
  
  
  
  
  
  

min error
   
   
   
   
   
   
   

max error
   
   
   
   
   
   
   

hereafter we trained on the larger  but contaminated dataset of     companies using a
variety of different svm parameters  table   lists the outcome of the k fold cross
validation for each set of svm parameters along with the minimum and maximum test
error  it is evident from the table that a large portion of parameters results in inconsistent
behavior  which indicates that the training process did not converge  however  in our best
case we were able to obtain a test error range of           which is a much more
accurate classification of the test data than the previous approach  we can thus conclude
that our approach of introducing erroneous data points into the dataset to recover more
data increases the performance of the svm 

results
we have promising results but at this moment we are still in the process of testing our
results  all of these promising results are from testing on the same dataset  we are now
testing on an even larger       companies  and new dataset completely independent
dataset from the same time frame to see how well the system performs  we are not sure
we fully understand why our model fully works but so far it seems to converge and
perform well  so far the k fold errors have been                and     which is
pretty good 

fireferences
    k  pelckmans  j  de brabanter  j a k  suykens  b  de moor          handling
missing values in support vector machine classifiers  neural networks    
www elsevier com locate neunet
jstor articles 
     the cross section of expected stock returns   eugene f  fama  kenneth r  french 
the journal of finance  vol      no      jun          pp         
     the conditional relation between beta and returns   glenn n  pettengill  sridhar
sundaram  ike mathur  the journal of financial and quantitative analysis  vol      no 
    mar          pp         
     stock returns  expected returns  and real activity   eugene f  fama  the journal
of finance  vol      no      sep          pp           
     the distinction between merit and worth in evaluation   yvonna s  lincoln  egon
g  guba  educational evaluation and policy analysis  vol     no      jul    aug         
pp        
     the conditional relation between beta and returns   glenn n  pettengill  sridhar
sundaram  ike mathur  the journal of financial and quantitative analysis  vol      no 
    mar          pp          

fi