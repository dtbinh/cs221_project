automatic transcription of solo piano music
alex landau
cs      autumn   
music transcription is the process of recovering the pitches and timings of notes in a piece of
music from a recording of the music  this can be accomplished by a trained human musician  but
automated music transcription  performed entirely by computer  has been a difficult task  for this
project  i am exploring the problem and the potential applications of machine learning therein  i have
examined the problems reducing the effectiveness of other groups work on the subject and developed a
structure for a new algorithm that can eliminate these problems 
one straightforward application of machine learning techniques to this problem was done by
graham poliner and daniel ellis of columbia university    their approach used one versus all svms to
train one classifier for each note  the features from the svm were short time fourier transforms from a
spectrogram  this gave them estimates of the   which they used to estimate the probability that the
prediction is correct  this was then followed by a hidden markov model application to smooth the
results for each note over time  both classifiers were trained on a large array of sample music 
this paper also provides a methodology for determining the error produced by a transcription
algorithm  it separates the music into short time frames on which it performs its predictions  and it
matches this against an already calculated set of data  the errors are further classified into substitutions 
misses  and false alarms  they also suggest another error measure  involving note onset detection  this
avoids problems associated with determining the endpoints of notes that fade out over time  as often
happens in piano music 
selecting appropriate features is crucial for note recognition  raw audio data comes in the form
of numbers representing the amplitude of the sound wave at various points in time   this is the format of
 wav files   mp  files have the same data  but in compressed form   one very useful technique for
analyzing this data is the short time fourier transform  or stft  this transforms the sinusoidal data in a
short period of time from the amplitude space to a frequency space  furthermore  the stft can be
applied repeatedly to overlapping segments to form a spectrogram  which shows the strengths of each
frequency over time   matlabs signal processing toolbox provides this as a feature   the spectrogram
can be inverted to retrieve the original audio data  this is a guarantee that it contains enough data to
perform transcription 
the output of the stft is a series of complex numbers  the absolute values of these coordinates
reflect the strength of the sinusoidal signal of the given frequency  the complex numbers angle in polar
form represents the specific phase of the signal  one of my experiments regarding the spectrogram data
involved removing the phase from this data to see if information needed to transcribe the notes would be
lost  this involved generating a spectrogram of some sample audio data  modifying the spectrogram 
and inverting it to retrieve the equivalent audio data   this was accomplished with the use of a
spectrogram inverter written by daniel ellis   in the resulting audio file  the original notes were clearly
audible and distinguishable  so there is sufficient information to perform audio transcription if phase
information is ignored  the remaining amplitude information  represented entirely by positive real
numbers  is easier to work with and visualize 
one feature that is peculiar to the piano can help in transcription  the noise produced by the
hammer when a new note is struck  this sound is clearly distinguishable from that produced by a
vibrating string  it fades as quickly as it rises  and  more importantly  it is spread across a broad
 

poliner  graham e  and ellis  daniel p w  a discriminative model for polyphonic piano transcription  eurasip
journal on advances in signal processing 

fispectrum of frequencies  as a sound with these properties appears at the beginning of each new note  it
can be used to determine when new notes are struck  a simple version of this function is as follows 
function hammertimes   gethammertimes s threshold 
t   size s    
hammertimes   find sum s     t  s      t          threshold      
 this gives the leading edge of each hammer strike  the last one should be
 in roughly the middle of the hammer strike 
hammertimes   keeplastofeachgroup hammertimes    keeps the last of each series
 of consecutive integers

this version was tested on three different sample audio clips  two recorded by myself and one
professionally recorded  in all three  its threshold parameter could be set to accurately list every time
that a beat was beginning and nothing else  unfortunately  no single threshold was optimal for all three 
it may be possible to determine the correct threshold using other features of the music  even if the
parameter cannot be automatically set for the piece  it is a useful input for determining the points in time
likely to be the beginnings of notes   the difference in total amplitude taken by itself is also a useful
input  but this method has the advantage of narrowing the initial time frame to a single value  
it would be logical that other versions of the function taking advantage of how hammer noise is
spread across the frequency spectrum would be even more effective  however  my attempts at
incorporating this effect have failed  part of this may be that this particular implementation also
incorporates the increased noise from strings  also marking the beginning of a new note 
the problem that arises with the svm method described above is that it frequently makes
mislabelings in which the labeled and correct notes are off by an octave or similar interval  to see why
these intervals are difficult to distinguish  we need to consider the forms the spectrogram data takes 
each note played during a timeframe contributes its own fundamental frequency  but it also
contributes additional frequencies that are integer multiples of the fundamental  these can be seen as
gaussian spikes in the frequency chart  this makes it easy to distinguish individual notes based on
which spikes are present  however  when there are multiple notes and ones fundamental frequency is a
multiple of the others  the spikes will overlap  hiding the second 

the gaussian spikes generated by one note  a second note an octave higher  and the interval containing both 

to distinguish these two cases  we need to know more about the heights of the spikes relative to
one another and how they differ in those cases  looking at several examples  we see that the changes of
amplitude of each spike in a given note are predictable  even when keys are played with different
weights 

fimiddle c evolving in time on two different pianos  each colored line represents a different gaussian spike 

one way of incorporating this data would be to add time as a component of the svms feature
vector  specifically  we could add to the feature vector a parameter consisting of the time since the
beginning of the note  times some constant factor to make it more relevant in computing the distance  as
needed   this would be easy to incorporate when training the svms  as this can be computed from the
data set   the negative samples would need to have this parameter filled in according to some
distribution matching that of the positive samples   the problem comes in applying the svms to real
data  we no longer know what offset to use as a feature  the solution is to make use of hammer noise  if
we have some set of times  a subset of which are the correct hammer strike times  then we can apply our
svm test once for each recent hammer time  a note can be considered likely to be played during a given
time frame if it passes an svm for any one of its likely time parameters 
the problem with this improvement is that its usefulness is severely restricted by its need for
training data  as mentioned before  note variations over time are instrument specific  so the training data
must come from the instrument to be tested for full usefulness  matched recordings and note data are
only practical to acquire with synthesized instruments  and even then only with access to the original
synthesizer  therefore  it would be preferable to have a method that learned from the unlabeled
recording itself 
we can envision the problem in terms of likelihood maximization under an em approach  in this
case  the hidden labeling is the set of notes that are played at various times with various amplitudes  a
labeling consists of the number of note assignments along with each assigned notes pitch  amplitude
relative to the models  and timing 
to reduce the complexity of the problem  the e step only tries to propose one labeling  instead of
weighing multiple possible labelings  a solution to this problem is very difficult  but feasible  in theory 
it could be solved by treating it as a hidden markov model problem  each timeframe has a labeling 
most of the transition probabilities will be zero  if one time frame has a given pitch being played  the
next time frame can only contain that pitch being played in the subsequent time step with the same
relative amplitude or not being played at all  when a pitch is not being played  it can either continue to
not be played or be played with some amplitude  discretized for the purposes of the hmm  
a suitably optimized viterbi like algorithm  taking advantage of the high likelihoods of
maintaining the status quo and of playing small numbers of notes as opposed to larger ones  might be
able to solve this in a reasonable amount of time  i have instead pursued a different algorithm that takes
advantage of a certain property of the notes  the lowest frequency can only be contributed by its own
note   unfortunately  given my current treatment of the music  this property breaks down in the lowest
octave or so  where the lowest frequency of each note is too close to distinguish  this could be
addressed by using a broader range of spectrogram data  a larger stft window would allow greater
resolution at these low frequencies  at the expense of precise time measurements  

finotation 
x  t     observed frequency vector of a timeframe t
 n r     proposed distribution of the frequency vector of note n at time r with respect to the beginning of
the note
   distribution of background noise  half normal distribution 
si   starting time of assignment i  measured in time frames 
ai t     relative amplitude of assignment i if it is played during time t  otherwise    
ni   note  i e   pitch  of assignment i

  t     predicted distribution of the frequencies at time t  given the assignments
then an additive model gives   jt      ai t   n it j si        j   however  this model gives incorrect
i

results because it does not take into account the effects of destructive interference  each note contributes
to a given frequency some complex value representing both its amplitude and its phase  the
contributions are added in this complex space  so they are as likely to cancel each other out as they are
to add perfectly 
we can create a reasonable model for this interference if we make the assumption that one note
has a significantly higher mean value than the others  suppose that we have random gaussian variables
a and b  and we want to find the distribution of c   acis   bcis   with  and  uniformly and
independently distributed   this reflects how the waveforms are added   under the assumption that
a   b   we find that this is equivalent to c     a   b cos        b   sin      a       ab cos    b    
which is closely approximated by a   b cos    this in turn has expected value  a and variance

    

 

var a   var  b sin       a    e b   e sin     e  b   e  sin       a     b          b           a     b          b  
  adding background noise gives variance  a     b          b          then  our estimated distribution for



 

 

 

 


  t  s m    
  a m t   mj
         ij t  si            ij t  si        where m   arg max ai  t    ij  t  si      
i
im


 t  
the likelihood to maximize is l      p       p   t    x f   

  tj   becomes n   mj t  s

m    

t

f

j

is our assumption about the relative values of a and b practical  in fact  it describes most cases 
particularly because the parameters vary both with frequency and with time  rarely do the curves of the
multiple notes come close to matching  and when they do  the variance is high  so they contribute little
doubt to the model if the m chosen is incorrect 
in practice  when two notes contribute
the same frequency at the same time  this leads
to the phenomenon of beating  this happens
when the frequencies from the two notes are not
quite the same  as a result  the amplitude of the
frequency in general  its associated spike 
oscillates over time  this produces a good
indicator to the algorithm that the frequency is
best explained by a high variance combination
of notes  rather than a single note 
examples of beating as seen on a spectrogram 

the m step of the algorithm assumes
that our assignment of notes is correct and subsequently tries to maximize     by changing the values

fiof   if we allow arbitrary iterated maximization this way  then we could potentially end up with note
forms that are dissimilar from the intended notes  or from any actual notes  to prevent this  we apply a
bayesian prior to each  n    an alternative would be to allow arbitrary evolution of the  s  then try to
distinguish the notes coming from the resulting evolutions  but this could misclassify octaves as notes 
for example  
the prior probabilities require some knowledge about how the notes are distributed  the
fundamental frequencies are easy to calculate  due to even tempering  the other frequencies of a given
note are approximately the integer multiples of the fundamental   there is a property called
inharmonicity which causes some deviation at high multiples  but i have found it not to be a problem  it
only applies at high frequencies which have low amplitudes anyway  and most of its effect as i observed
it earlier vanished when i started measuring the mean of each spike  rather than the highest value  
observations suggest that the relative values of successive spikes at a given time roughly follow an
exponential decline  furthermore  this decline is in terms of the frequency  not in terms of the number of
the spike  as mentioned before  the spikes themselves are gaussian  with roughly equal standard
deviations  as for decline with respect to time  previous observations have shown how this is
unpredictable  in addition  data to approximate this is complicated to assemble because it requires inputs
from multiple pianos as well as multiple keys  however  if the string is assumed to be an underdamped
harmonic oscillator  then physics suggests that the amplitude over time roughly follows a power law in
the general case  finally  hammer noise should be included in the prior  so that the algorithm is not
confused by otherwise unexplained noise  these observations have allowed me to construct a model for
how to generate the prior  but as it is untested and relies on arbitrary constants  it adds no new
information to the above 
the approach advocated here is complicated in that it takes one difficult problem and replaces it
with two slightly less difficult problems  nevertheless  if implemented and shown to work  this approach
could have multiple advantages over other envisioned transcription methods  it uses minimal training
data  it identifies how loudly notes are played  relative to one another  and it collects data on the
instrument being analyzed   for example  it could be used to make a synthesizer imitating a recorded
piano   most importantly  it addresses the fundamental problem behind errors of octaves and similar
intervals which plague other approaches 
although i was ultimately unable to make productive use of the paired music data i collected for
this project  i would like to acknowledge and thank the contributors to the allegro and audacity open
source projects  whose code for handling midi files allowed me to collect it 
of course  special thanks are due to graham poliner and daniel ellis for laying down
groundwork for this research 

fi