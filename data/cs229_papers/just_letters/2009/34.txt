learning  d point cloud histograms
cs    machine learning project
brian jones

michel aoun

december         
abstract
in this paper we show how using histograms based on the angular relationships between a
subset of point normals in a  d point cloud can be used in a machine learning algorithm in
order to recognize different classes of objects given by their  d point clouds  this approach
extends the work done by gary bradski at willow garage on point clouds recognition by
applying a machine learning approach to learn the histograms  this approach has been tested
on a database of    types of ikea models with    samples for each type of object 

 

introduction

with the advent of robotics and machine learning  the presence of human like robots in the home
is no longer a figment of our imagination  but is becoming a reality  in order for robots to conduct
human like tasks within the home  they need to be able to recognize objects they want to interact
with  our project is aimed at improving this ability  in order for a robot to work independently  it
must be able to identify and classify various objects into different categories  research has already
been done in this area through both the use of neural networks and support vector machines 
the research done with support vector machines was aimed at classifying objects while reducing
the number of view points used during training  this research was very successful and showed that
support vector machines are a more suitable approach to the object classification problem  see      
these svm experiments used the objects shape and color for classification  other research papers
have proposed  d point clouds recognition based on histograms  different types of histograms have
been proposed  in     sapiro and al  propose histograms based on local curvature and diffusion
distances  another type of geometric histograms has been proposed by rusu and al  in     we
conduct similar experiments with svm  using such histograms based on normal vectors projecting
out from the surface of the object of interest 
 

fi 

description of the learning procedure

our learning approach procedes in two steps  we start building histograms for each of the
objects in our database  the idea of these histograms have been suggested to us by professor gary
bradski and is described in      it requires computing the normals for each point in the point
cloud  to learn these features  we use a support vector machine algorithm that is adapted to our
multiclass learning task 

   

building the histograms

normals embed essential information about the vicinity of each point in the cloud  they are
considered to be reliable information and are commonly used for surface reconstruction  computing
a normal to a point m  has been done by first defining a region of interest around point m as being
a sphere of radius r centered on m  r is proportional to the mean distance between all pairs of
points  the points lying in this region of interest are close to the tangent plane at point m  we
therefore try to fit to these points the best plane in terms of mean square error  that is done using
principal component analysis as described in      the normal to point m is taken as the normal
to that plane  this normal is a non oriented normal  orienting these normals could be done by
propagating the normal direction information over neighboring points  however  we chose to build
our histograms with non oriented normals 
our feature vector takes into account the relation between all couples of  d points and their
corresponding normals  for each couple of points we can compute three angles characterizing the
position of the normal to one point relatively to the normal of the other one as described below  

we compute the histogram of all these   angles    and   this histogram is used as the feature
 

fidescribing the point clouds  this feature doesnt depend on how we rotate and translate our object 
in pratice we didnt compute the histograms directly on the entire set of points  we instead
downsampled our point clouds  that was done by taking a grid over our whole image and choosing
at most one point of the point cloud in each cube of the grid  the step of the grid was fixed
empirically in such a way the overall number of points after downsampling is around       points 
this procedure is described below over two different types of objects  we draw for each type 
two histograms corresponding to two different point clouds for the same type of object  we can see
a similarity between histograms in the same class and a difference between histograms of different
classes of objects  this will allow our learning procedure to behave properly 

 a 

 b 

 c 

 d 

 e 

 f 

 g 

 h 

 i 

 j 

figure    point clouds normals computation and histograms generation   first is our original
point cloud  second is the downsampled point cloud followed by the display of the computed
normals  two histograms are shown with colder colors corresponding to lower values  these
histograms are computed for a discretiztion of each angle into   bins  their size is  x x        

 

fi   

learning the histograms

in order to learn to classify new objects based on their histograms we used support vector
machines  in      chang and al  describe a type of svm algorithm that is adapted to regression
tasks  this type of svm called  svr  r for regression  is useful in the sense it gives a score
between   and   that quantifies the probability an object belongs to a certain class of objects  our
training procedure consists in training     svr  one for each class of objects  when it comes to
testing  we test a feature histogram with each of our     svr  that gives us    scores between  
and    we choose the highest score and the corresponding class c  if this score is higher than a
certain threshold t we consider that our testing cloud belongs to class c  if the score is less than
threshold t   we consider that our object doesnt belong to any of our trained classes 

 

results

the data consists of  d point map clouds of    ikea models with    samples for each model 
this database has been provided by gary bradski  at willow garage  we have first generated
histograms for all objects in our database  the histograms were taken of size     following a  
bins discretization for each of our angles   two histograms were compared using chi square  this
comparison let us verify our histograms were behaving properly  this is shown in the figure below 
after this step of verification  we used k fold cross validation to train each of our    svr  we
did therefore   cross validations with    elements for training and   for testing in each class of
object  the results of this k fold cross validation is reported in the figure below  here we have
chosen different thresholds t and plotted for each threshold the percentage of objects that were
misclassified on the y axis and the number of objects that couldnt be classifier on the x axis  we
did this plot for different sizes of histograms in order to select the most optimal size 
we define the most optimal size of histogram as the one for which the rate of misclassifications 
when equal to the rate of unclassified objects  is the lowest  this rate is equal to       for a   bins
per angle discretization  it is equal to       for a   bins per angle discretization 
we have drawn for the     histogram k fold cross validation the confusion matrix among the
different classes of objects in order to understand where the algorithm misclassified the objects
the most  as it is shown below misclassification has occured on pairs of objects that seem highly
similar for a human eye  moreover  it should be noted that our histograms do not take scaling into
account  this explains the misclassification between types    and     

 

fi a 

 b 

figure     a  comparing histograms of the first five classes of objects using chi square  hot colors
correspond to pairs of histograms that are highly similar    b  results of the multiple  svr k fold cross
validation tests on ikea database  the  x x  feature  green curve  is performing the best 

 a  confusion matrix

 b  objects of highest confusion degree

figure     a  confusion matrix among the    types of objects obtained with k fold cross validation
   b  identification of the couples of similar types of objects that are the most confused by our
trained  svrs     v s        v s        v s   and    v s    
 

fi 

acknowledgments

we would like to thank very much professor gary bradski for his help and support  for his
suggestions and for sharing with us his ikea models database 

 

conclusion

through this project we have proven that combining histograms with machine learning algorithms is a good approach for solving the multi classification problem on a point clouds data set 
the misclassified objects in the data set we have been using correspond to objects of which point
clouds are almost the same for a human eye  our multiple svm k fold cross validation approach
defined the best histogram size to be a  x x  bins histogram  the success of this learning approach
is essentially based on the power of the histograms as it was stated in previous articles such as     
we have proven again that these histograms can be considered as a strong discriminative feature
to be used 

references
    c  c  chang and c  j  lin  libsvm  a library for support vector machines        software
available at http   www csie ntu edu tw  cjlin libsvm 
    m  mahmoudi and g  sapiro  three dimensional point cloud recognition via distributions of
geometric distances  graph  models                   
    n  j  mitra  a  nguyen  and l  guibas  estimating surface normals in noisy point cloud data  in
special issue of international journal of computational geometry and applications  volume    
pages              
    d  roobaert and m  m  v  hulle  view based  d object recognition with support vector machines  in in ieee international workshop on neural networks for signal processing  pages
           
    r  b  rusu  z  c  marton  n  blodow  and m  beetz  persistent point feature histograms for  d
point clouds  in proceedings of the   th international conference on intelligent autonomous
systems  ias      baden baden  germany       

 

fi