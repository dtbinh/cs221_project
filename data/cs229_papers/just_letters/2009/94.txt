question classication
gaurav aggarwal  richa bhayani  tejaswi tenneti
december         

 

abstract

type is number  versus how do the nazis justify the
killings of jews in the holocaust   required answer
type is manner   thus we might need syntactic information of the question sentence for good classication  however  consider a what question like
what do bats eat   where the intended answertype  which is subtle to determine  is of food category  here the syntactic structure of a sentence
might not be useful for determining the focus in the
question  thus we require features at many levels
i e lower order features containing syntactic information  and higher order features like encoding of worldknowledge  like saying that a country is a kind of
location   many such issues stand in the way of accurate question classication which makes it an interesting problem to tackle 

question classication is the task of identifying the
required answer type for any question posed to a
question answering system  the space of required
answer types often varies based on the purposes of the
q a system  so  it is more useful to do a two level
classication of the question  we present a machine
learning model which achieves this goal using various
surface features present in a question  we have tested
various features and analyzed the usefulness of each
of these for classication purposes  using a maxent
classier our system is able to achieve an accuracy of
    on the coarse level classes and     on ner level
classes 

 

introduction
 

any question answering system consists of three major modules     question classier    relevant documents retrieval    pinpointing and scoring answer
candidates  a question classier addresses the issue of determining the required answer type for the
question  an answer type can be a generic category like humans  location  time  denition
and can be classied into ner categories based on
the requirements of that question answering system  a simple method to achieve question classication  henceforth referred to as qc  would be to
consider a bag of words model and use cue words like
who  when and so on to determine the answer
type  however  question answering systems can be
domain specic  say  for lawyer or amongst the medical community   it follows that the required answertypes dier for each of the question answering systems  hence  rule based template based approaches
suer from poor scalability 
furthermore  questions can be paraphrased in
many ways and the answer type is not immediately
obvious  it is easy to see that this is a problem in
questions starting with what and how  we can
see the dierence between the questions how many
jews were killed in the holocaust   required answer

dataset

the cognitive computation group at uiuc has
a dataset for question classication experiments  
http   l r cs uiuc edu  cogcomp data qa qc   it
contains   coarse grained classes  abbreviation  entity  description  human  location and numeric 
and about    ne grained classes  there are     
labelled questions available for training and     test
questions  lists of semantically related words were
also provided in the data set  which could also be
obtained tools like word net 

 

approach

one goal of this project was to gure out what level
of features would be useful to obtain a good classication at each of the levels described in the motivation section  just relying on surface features like
n grams  bag of words is not expected to perform
well as they would not be able to capture the semantics of the question  so we have used higher
order language features like pos tags  stems  synonyms related words  interrogative pronouns  word
category for sparse words  question focus 
 

fi   

features

belonging to a particular class is calculated as follows 

we use syntactic features like named entity tags 
        

   
        
part of speech tags  and semantic features related
 
       
concepts to words present in the question  we are using stanfords named entity recognizer which tags
where  c is the class  d is the data point we are
each word in the question with one of person  lo  looking at  and  is a weight vector maxent makes
cation  organization  other category  the pos no independence assumptions for its features  unlike
tags features was used to capture the syntax patterns nave bayes  this means we can add features like
that similar kind of questions might share  the re  bigrams and phrases to maxent without worrying
lated concepts features is also a very useful feature to about feature overlapping 
capture some amount of semantics inside the question  for example  away and distant belong to a
we also implemented svm  however the results
list of words semantically related to the class dis  were not signicantly better than maxent 
tance  the intuition is that some semantic classes
might be good indicators of specic question categories  other features include n grams uni bi and  
results
tri  
we ran the classiers mentioned in     on our training
set  accuracy obtained on the test set is reported in
    classiers
table    as seen from the table  maxent classier
we decided to choose naive bayes and maxent for performed the best 
this stage of analysis  since nb often works well on
text classication problems   and maxent is a repre      naive bayes
sentative for conditional models 
naive bayes does well for coarse grained classes but
is only as good as a random classier in case of ne      naive bayes
grained classication  besides  in the latter case 
used a simple multiclass multinormial nb model it there are many classes for which the classier comassumes each feature is conditional independent to pletely ignores and does not classify even a single
question into those classes 
other features given the class  that is 
     

      
   

training set

   

    
    
    
    
    

where c is a specic class and t is text we want to
classify      and     is the prior probabilities of
this class and this text  and     is the probability the text appears given this class  to avoid the
problem of having zero frequencies  we make use of
some smothing techniques  otherwise  the likelihood
will be   if there is an unseen word when it making
prediction  we simply use add   smoothing in our
project and it works well 

coarse grained
nb
maxent
     
     
     
     
     
     
    
     
     
     

fine grained
nb
maxent
     
     
     
     
     
     
     
     
     
     

table    accuracy for dierent classiers

   

maxent

maxent was our best classier achieving good accuracy for both coarse and ne grained classication 
we made use of stanford classier to code the max  it is also interesting to look at precision and recall
ent section  the idea behind maxent classiers is scores achieved by maxent on individual classes when
that we should prefer the most uniform models that trained on      questions  this is illustrated in tables
satisfy any given constraint  maxent models are fea    and    for some ne grained classes  the classier
ture based models  we use these features to nd a does not predict that class at all  such classes have
distribution over the dierent classes using logistic nan in the f  score in the table  figure   shows the
regression  the probability of a particular data point learning curve for both class types 
     

maxent

 

ficlass
enty
desc
num
abbr
hum
loc

precision
    
    
    
    
    
    

recall
    
    
    
    
    
    

f  
    
    
    
    
    
    

class
plant
abb
body
other
weight
desc
count
reason
state
date
lang
city
currency
substance
title
def
ind
event
techmeth
money
perc
animal
speed
instru
sport
period
country
product
exp
veh
termeq
mount
color
food
temp
manner
gr
dismed
dist

table    precision and recall scores of maxent for
individual coarse classes

figure    learning curve for maxent

   

feature selection

precision
    
    
    
    
    
    
    
    
    
    
    
    
    
    
nan
    
    
    
    
    
    
    
    
    
    
    
    
nan
    
    
    
    
    
    
nan
    
    
    
    

recall
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

f  
    
    
    
    
    
    
    
    
    
    
    
    
    
    
nan
    
    
nan
    
    
    
    
    
    
    
    
    
nan
    
    
    
    
    
    
nan
    
    
    
    

in order to identify the best performing features  we
did feature selection using forward feature search algorithm as seen in class  tables   and   show successive iterations of the selection algorithm  at each iteration  we pick the best remaining feature and add it
to the feature set  from the tables  one can conclude
that part of speech tag features  pos and poscomb  and related word feature  relword  correspond to the maximum gain in accuracy 
it was a bit un intuitive to see the pos feature performing the best in the rst iteration  we felt that
since pos tag for the current word lack contextual
information  pos feature would not provide useful
signals  with this in mind  we had added the poscomb feature so that it captures syntactic structure
of the sentence  but suprisingly it did very well  on table    precision and recall scores of maxent for
the other hand  it makes sense to add semantic fea  individual ne classes
tures  so we expected relword feature to do well 

 

what is tmj  and what does the technical term
isdn mean  are both misclassied as desc  also 
what is feature is common to many classes like definition and entity which might lead to some errors 
for abbreviations  it might help to add a binary
feature which is activated whenever the question has
a word containing all capital letters 
chunking of entities in the question might also
help  consider this question   what is the ohio state

analysis and future work

we also tried to do some error analysis on the maxent classier  for coarse grained classes  it achieves
   plus accuracy for all classes except abbreviation
 abbr  and entity  enty   we observed that the
classier often confuses abbr and enty class questions with description  desc  class  for example 
 

finew feature added
pos
pos comb
relword
  gram
  gram
ner
  gram

 

accuracy
    
    
    
    
  
    
  

dan roth et al in their seminal paper     laid much
of the groundwork for the task of question classication  the authors also used intelligent text based
features and a heriarchical classier using the snow
algorithm  we borrowed some of their features like
relword and added some more like pos comb 
however  we experimented with dierent classiers
and achieve similar accuracy 
in      the authors developed a novel tree kernel
based svm classier that attempts to capture the
syntactic structure of the questions 

table    feature selection for coarse classes

current feature set
pos
pos comb
relword
  gram

related work

accuracy
    
    
    
    

references
    xin li and dan roth  learning question classiers  in proceedings of the   th international conference on computational linguistics  pages    
morristown  nj  usa        association for computational linguistics 

table    feature selection for ne classes

bird    this question denitely belongs to enty
class as we are looking for the specic bird  however      dell zhang and wee sun lee  question classication using support vector machines  in sigir
our classier labels this as location probably because
    proceedings of the   th annual international
of the word ohio  using clever ner and chunkacm sigir conference on research and developing algorithms  it may be possible to combine ohio 
ment in informaion retrieval  pages       new
state and bird into one entity ohio state bird  it
york  ny  usa        acm 
would then be easier to identify this chunked question
with the class enty 
coarse grained classier does much better than the
ne grained one  this is in conjunction with the intuition that the more specic things get  unless we
have more features  we will not get a very good performance  hence  hierarchical classication seems to
be a promising approach  we can use our existing
coarse grained classier to predict the top two coarse
classes  then we train a separate classier using only
the questions that belong to those coarse classes and
use that to predict one ne grained class  in      the
authors claim that hierarchical classication does not
help  however  it would still be worth a try since we
use dierent features than those used in the paper 
we could also try to add more semantic features
given the success of the relword feature  using
corpora like wordnet and framenet  we could try
to more accurately identify the semantic classes of
individual words occuring in the question 
in our experiments  svm with a linear kernel does
only as well as the maxent classier  using nonlinear kernels would be an interesting option to exploit higher dimensional features such as conjunction
of current features 
 

fi