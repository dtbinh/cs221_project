rafael witten
yuze huang
haithem turki
playing strong poker
   why poker 
chess  checkers and othello have been conquered by machine learning   chess
computers are vastly superior to humans and checkers and othello computers play optimally 
part of what makes these games tractable is that both sides have perfect information  poker is
fundamentally different because the players do not know their opponents cards and are instead
left to create opponent models to guess what their opponent holds  it is a game of imperfect
information  in chess  for instance  the standard assumption is that your opponent will make
the best possible move  in poker that is not a reasonable assumption since your opponent lacks
perfect information  largely because of this added complexity  computers still lag behind
humans in almost all poker variants 
the interesting variants of poker are sufficiently complicated as to be intractable  the
computer cannot simply apply game theory tactics to create an in exploitable solution 
creating programs to operate with incomplete information in such a complicated system is
fundamentally challenging and techniques used are similar to those throughout other
applications of machine learning 
   the rules of the game
the variant of poker we chose was heads up limit texas holdem  it is a standard
choice for machine learning because it is considered one of the deepest variants of poker and
is quite commonly played 
each of two players is dealt two face down cards  first a group of three face up cards
are put in the community area  the flop   then a fourth one  the turn  and finally a fifth  the
river   at any point these cards are called the board  limit style betting is allowed before the
flop  turn and river and finally after the river  players make the best possible poker hand using
five of the available seven cards   if this summary is insufficient  the reader should read
http   www pokersavvy com texas holdem limit holdem rules html because some
understanding of the rules of poker is necessary to proceed  
   a broad overview of hardbot
a poker program  most broadly  is a function that takes a players hand  the board  the
action thus far in the hand and the opponents history and returns a three tuple  which
represents the programs probability of folding  calling and raising  no strong poker program
plays deterministically  strong poker programs can be made that do not make any use of
information about the opponent and instead attempt to play in a nash equilibrium  or in a way
which is non exploitable  meaning that the best the opponent can do is achieve parity 
the fundamental problem with attempting to play in nash equilibrium is that poker is
intractable  so computing the nash equilibrium is impossible  however  it is possible  under
some assumptions  to compute a e nash equilibrium  or a strategy that is very close to being a
nash equilibrium under those assumptions  however  how close the strategy actually is to the

finash equilibrium is subject to the accuracy of the assumptions  a general weakness with bots
based purely on nash equilibria is that they tend to be bad at exploiting poor play by their
opponents because they assume that their opponent is a rational actor similarly in a nash
equilibrium  
instead of assuming that our opponent is in nash equilibrium  we instead base our
original estimates of opponent strategy on empirical data  since no such data is available for a
new opponent  we train from a corpus of high level machine play  about        hands  and
use bayes law to update our estimate of the probability distribution over our opponents
hands  this approach is unique in the literature and has so far produced exciting results  our
play  given a probability distribution over the opposing hands  is based on an expert system of
similar complexity  but optimized for heads up play  to the prominent university of alberta bot
poki  perhaps the best existing limit poker bot in multiway play  
these two methods together define a full poker algorithm  every time our opponent
acts  we use our corpus and opponent data to update the probability distribution over our
opponents action  when it is our turn to act  we feed the probability distribution of our
opponents hand and the state of the game into the expert system and it probabilistically
decides how to act 
   parts of hardbot
i  updating opposing probability distribution
in response to an opponent action  hardbot needs to update the probability of each
possible opponent hand using bayes law  to train from a corpus of past poker hands  it is not
enough to simply lookup how each possible opponent hand has been played in an identical
situation  even removing suit isomorphisms  we would encounter severe sparsity issues  for
example  on the flop there are approximately   million different states and they increase
exponentially on future rounds of betting 
further  doing such calculations on a hand by hand level is computationally expensive
and for the future analysis we assume we have bucketed opposing hands into hands that we
believe will play similarly  a step which is discuseed in   iii  first we developed a technique
for estimating the state of poker hand that can be compared across different hands and boards 
essentially turning each opponents hand into a vector of describing numbers  this
vectorization is the key step that allows us to take advantage of the corpus of past poker hands 
by consulting this corpus  we are able to  despite not having any knowledge of the opponent at
the beginning of the match  update our probability distribution in a bayesian way  assuming
that our opponent is a mean opponent from the corpus 
to calculate p action bucket  we query a mysql database to find hands that have an
identical betting history  then we perform the following update  where the sum across entries
means summing across each entry with an identical betting history  here each bucketv is the
vectorization of the bucket  entryv is our vectorization of the entry and entrya is the action that
was taken in that case 

this gives us exactly what we need to find p bucket action  using bayes law  because

fiour sample space is not discrete we need to decide the relevance of each of the entries in our
database based on how far they are from our current term  this is what caused our use of the
exponential term  it is a natural choice that goes from    one the entries vector is very close
to the buckets  to zero  when they are very far away   thus similar to our intuition about how
much to weight each example 
we built further on this formula to do opponent modeling  this formula works well at
first when our knowledge of our opponent was limited  but by taking opponent specific
knowledge into consideration we can make a better estimate  we decided upon this update 

where we then normalized the k terms to get a probability distribution  here p action  
opponentmodel  is a smoothed nave bayes modeled parameterized on the hand history  we
used a generalization of laplace smoothing  initializing our observations with instead of one of
possible action with six total observations attempting to best fit our p action   database  entry 
then when there were new actions we updated p action   opponent   thus learning from our
opponents action 
preflop vectorization proved difficult because the computations  even using monte
carlo simulation  are somewhat expensive and unnecessary because of the relatively small
preflop history space  therefore  preflop we instead considered hands on a case by case basis 
this was possible because there are only      hands an opponent can have preflop and fewer
than    betting sequences can occur on the flop that have the additional property that they do
not end the hand  given our huge corpus  we were therefore left with a meaningful number of
hands after each betting sequence and had no sparsity issues 
ii  vectorizing hands
although two poker hands and boards may be different  they may call for similar lines
of play  the key step in the previous section was determining how to find these similarities
between different situations  the task was equivalent to feature extraction 
e and e  are two particularly critical values we used in measuring poker hands  e
describes the hands chance of winning and e  is an information estimate of the value of our
hand  let f be the set of possible next observed cards  let  be a random variable distributed
uniformly over f  and let h be a hand  i e  two hole cards  we compute e h  using the following
formula  in each case where we sum over our space of opponents hands  

and we compute e  h  using the following formula 

in order to see why this formula for e  gives us an idea about how much information
we would gain by playing the hand  consider an abstract variant of poker where there are only

fifive possible  equally likely  flops  so f    f   f   f   f   f    consider two hands  h  and h  
suppose h  has a probability   of winning given f   but probability zero of winning the rest of
the flops  and suppose h  has zero probability of winning given f  but has     probability of
winning each of the rest of the flops  in our case  e h     e h          but e  h          while
e  h           this follows intuition  because after the flop  we will have already known
whether we can win with h   but we are still uncertain on four of the five flops if we play h  
gaining knowledge early in the hand is very valuable from an information theory perspective
and follows intuition on how humans play 
these two numbers  combined with npot and ppot measures of the chance of a hand
improving and getting worse  allowed us to find hands that had different hole cards or boards
but would tend to be similarly played    other options for feature extraction were tried  such as
outs  or number of ways to dramatically improve your hand  and a couple of other features
that humans use to classify hands  but they were found to have little significance in the later
bucketing step and were therefore eliminated to save computational time  it is worth nothing
that e  e   ppot and npot are all numbers that humans are unable to calculate in real time
but appear to have greater significance than the metrics humans use 
iii  bucketing
running the bayesian update rule for each hand is very slow and moreover completely
unnecessary  through the vectorization  we were able to find hands that would be played
similarly  we then used k means clustering to group hands that would have approximately the
same update rule  then  using the update rule established in   i on the updates  we are able to
determine p bucket  action   by our assumption that all of our hands in the bucket would be
played the same way  we are able to define the hand update rule  p hand   action  
  p bucket action  p bucket   p hand  
we chose to run clustering with k    the intuition behind this choice is weak  but the
resulting buckets were very similar to how a human would classify them  overall  the resulting
system very much reflected how a human poker experts think about poker hands  classifying
opposing hands into hands that have similar strategic implications and assigning probabilities
to these hands 
iv  expert system
ultimately we used an expert system to decide how to act given a probability
distribution over the opponents hand  our final design was based on the equivalent poki
algorithm  hardbot would consider a range of possible actions from most aggressive to least
aggressive  or equivalently considering first those that would dictate a raise  then those that
would dictate that we call   for each  if the conditions necessary to take it were met we would
consider taking the action probabilistically  ultimately hardbot would fold if it chose none
of the actions  this expert system was somewhat unsophisticated but worked quite decently    
   conclusion
for our implementation  we used meerkat api to interface with a popular poker
application often used by researchers  known as poker academy pro  because we were using
the meerkat api we were able to compare hardbot to poker academy pros bots  which are
touted as being among the best in the world  however  simply playing a single bot is
insufficient because strength at poker is not transitive  if a beats b and b beats c  a does not

finecessarily beat c   as can be seen in the data at the aaai annual poker competition
website  
in order to test our bot  we devised a gauntlet of strong bots of different styles 
hardbot played sparbot  which attempts an e nash equilibria strategy  vexbot  which relies
on very aggressive opponent modeling and poki  which was probably the best heads up limit
bot when it was developed in       although it no longer has that distinction  and has a more
balanced strategy  only after checking out the expected earnings that our bot gets against all
these bots can we determine our algorithms strength 
the following tables measures hardbots small bet gain per hand averaged over one
thousand hands 

hardbot

sparbot

poki

vexbot

        

     

        

although hardbot appears to have lost to sparbot and vexbot in a statistically significant
way  it was a great victory to  even narrowly  beat poki  moreover our performance differences
against sparbot and vexbot were hardly large  indicating that our poker bot was playing at a
rather high level 
our failure against vexbot demonstrates the primary weakness with hardbot  our
opponent modeling was the weakest part of our algorithm  hardbot effectively played
statically  and not even in an estimate of a nash equilibrium   therefore  vexbot was able to
find exploitive strategies  the solution to this problem is for hardbot to do more opponent
modeling  both to find weaknesses in the opposition strategy but also to update its own
strategy  thus making opposing modeling less accurate 
our corpus based strategy for poker appears to have been rather successful  however 
the corpus was  although large  only        hands  because it is backed by a database  we
could easily increase it to         hands without taking a performance hit  moreover 
hardbot suffered from a weak expert system  we devised it ourselves since pokis is not
completely available so it was probably somewhat subpar  increasing the size of the corpus 
optimizing the expert system further and doing more sophisticated opponent modeling would
perhaps dramatically increase the success of our bot 
sources 
    schauenberg  terence c   opponent modelling and search in poker   opponent modelling
and search in poker  university of alberta        web     nov       
 http   poker cs ualberta ca publications schauenberg msc pdf  
    billings  darse   algorithms and assessment in computer poker   algorithms and
assessment in computer poker  university of alberta        web     nov       
    papp  denis   dealing with imperfect information in poker                university of
alberta        web     nov         http   poker cs ualberta ca publications papp msc pdf  
    we would like to extend our thanks to ben phillips  a carnegie mellon university cs
major  class of       and a semi pro poker player who gave us considerable advice when
designing the expert system 
    sklansky  david  the theory of poker  two plus two pub         print 
          computer poker competition   department of computing science   university of
alberta  web     dec         http   www cs ualberta ca  pokert      index php  
sklansky  david  the theory of poker  two plus two pub         print 

fi