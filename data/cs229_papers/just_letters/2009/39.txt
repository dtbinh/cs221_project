 

sentiment analysis of microblogs
vipul pandey and c v krishnakumar iyer
abstractin this project we attempt to perform sentiment based classification of micro blogs using machine
learning techniques  sentiment analysis of short messages
posted on micro blogging tools can be helpful in determining the current usability and acceptance of any target product or service  it can help in raising alarms in the wake
of sudden shifts in user sentiments or attitude towards the
service  we present a system that can read messages relevant to a particular topic from a micro blogging service
such as twitter  analyze the messages for the sentiments
they carry and classify them as neutral positive or negative 
we try out different feature selection and classification algorithms in our search for the best combination  we also
evaluate different strategies in order to get the best performance over the imbalanced dataset   caused by relatively
infrequent changes in user sentiments   and to understand
the underlying nature of this problem 

sages and polar  negative or positive  ones  the messages
deemed polar by this classifier are then forwarded to the
second classifier in the scheme  which is trained to distinguish in between positive and negative sentiments  the
overall scheme is depicted in the fig   

i  introduction
sentiment or opinion mining has been an active area
of research in academia because of the challenges that it
poses  it is also a vital question that is sought in the
industry as it gives an insight into the consumers mind  the
influences he is subject to  and his decision making process
  besides being an explicit feedback about the performance
of any widely used and talked about product  service  event
or a phenomenon 
in our efforts  we try to detect the current attitude of the
users towards an online service  the model that can be extended to other services or products without any difficulty
whatsoever 
there has been a widespread interest in the area of opinion mining and sentiment analysis because of the challenges it offers and its potential applicability      gives an
excellent survey of the recent developments and the work
done in this field      performs a work that is very similar to ours in that it seeks to identify market sentiments 
they develop hybrid methods for extracting opinions in an
automated manner from the discussions on the stock message boards  however  they report a maximum accuracy
of         low ambiguity  test set size        training set size             details different feature selection
metrics for text classification that we plan to apply in our
work     consider a classification problem of discriminating
in between the positive and negative sentiments  and test
their approaches using naive bayes classifiers  max  entropy classifiers and svms  they operate on the movie
reviews dataset  and report a maximum accuracy of      
with svms using the presence absence of features  in addition  they also study the effects of a few variations in the
parameters  just as we do 
ii  approach
we follow a simple approach of chaining two classifiers to classify messages into the three desired categories 
the first classifier discriminates in between neutral mes 

fig     components of the system

following operations are performed in the system to
achieve the final results  
 data collection   in which data is collected from the
source 
 preprocessing   in which collected data is preprocessed
for further action 
 feature selection   in which a subset of features is
selected to reduce dimensionality 
 model selection   in which a model is trained using
the training set 
 classification   in which a trained model classifies the
newly arriving messages 
we developed most of the infrastructure in house although we use    weka framework for standard machine
learning algorithms for prototyping and evaluation 
iii  data
we primarily focus on messages obtained from twitter
for prototyping and benchmarking but the system can be
easily extended towards other sources as well  we use
the twitter search api to obtain the tweets mentioning the product that we focus on  we collected over      
such messages and manually classified them as negative 

fimild negative  neutral  mild positive and positive  while
manually classifying the data we realized that the data
is imbalanced in that there are significantly more neutral
messages than the polar ones  we also noticed that the
mild negative and mild positive messages  though having
some trace of polarity  either had a large overlap with neutral messages or were bipolar thus adding to the ambiguity  therefore in our exercise we primarily focus only
on neutral  positive and negative messages by ignore the
ambiguous ones while training the classifier 

since urls are unique  and it would be too expensive to
crawl urls for their content  we abstract the links to a
single keyword to avoid feature explosion 
 cvkkumar the itunes store
  hasallcaps        url  

reeaaally rockss  

d  detection of pointers
we define pointer as the means of addressing a user
inside a microblog  in twitter  pointers take the form
of  user   where user is the username  again  to avoid
explosion of features  we abstract it to a constant symbol 

iv  preprocessing
as soon as the data is collected  it is passed through
a series of preprocessors that aid in the conversion of the
message strings into the feature vector  that is used by the
feature selection algorithm and eventually by the classifier 
the preprocessing step also performs the important task
of extracting the relevant signals from the messages  while
leaving out the irrelevant ones  in our feature extraction
process we not only consider the common text based features as used in traditional information retrieval tasks but
also use several domain specific features  this assumes a
greater significance in our domain of micro blogs since the
text  by its nature is short and hence we must depend on
many other features to identify the polarity in the message
and the type of polarity that it exhibits 
few of the preprocessors and the preprocessing steps
that we follow are explained with examples below  this is
one of the more important steps in the entire classification
process since the quality of the features that we extract
ultimately decides the performance of the classifiers  let
us consider a running example  

  ptr   the itunes store reeaaally rockss  
  hasallcaps        url  
e  identification of emoticons
emoticons are one of the most powerful signals that we
use in our system to differentiate polar from non polar messages and positive from negative messages  we identify a
range of emoticons and substitute the keyword smile if
it is positive and frown otherwise 
  ptr   the itunes store reeaaally rockss  
  hasallcaps     smile     url  
f  identification of punctuations
the punctuations are also a potential source of insight
into the polarity of the message  for instance  exclamation
marks are used to convey powerful emphasis which may
correlate to polar messages  as was observed  in this step
we remove the irrelevant punctuations as well so as to avoid
redundant noise in our feature set 
  ptr   the itunes store reeaaally rockss   ex  
  hasallcaps     smile     url  

 cvkkumar the itunes store reeaaaally rockss  
   http   bit ly madeup

g  stop word removal

a  all caps identification

this is a standard information retrieval technique to
remove words that are highly common  have a high idf
value  and hence do not add substantial value to the classification process  common words like a  an and the
fall in this category  in addition  the search term that is
bound to be present in every message is also added to this
list 

this forms the first filter in our preprocessing step  since
we operate on the micro blogging space  we observed that
it was very common to use all capital words to represent
powerful emotions  and hence are a good indicator of the
polarity of the message 
 cvkkumar the itunes store reeaaaally rockss  
  hasallcaps     http   bit ly madeup

  ptr    reeaaally rockss   ex  
  hasallcaps     smile     url  

b  lower casing

h  compression of words

having already exploited the fact of the all caps  we
fold the case of all the terms in the message to have a
consistent casing  this is extremely important for us due
to the erratic casing  often found in microblogs 

we also realized that people tend to be very informal
while writing microblogs and most of the times elongate
the words to express strong emotions  for example ssslllooowwww coveys a higher degree of power than
slow  however  both these modifications refer to the
same fact  we employ a heuristic in which we compress
such words to what we call as shadows  a shadow of a
word is just the compressed form of the word with at most
one character repeating consecutively twice  e g  ssslllooowwww gives out the shadows sslow  sllow  sloow 

 cvkkumar the itunes store reeaaally rockss  
  hasallcaps      http   bit ly madeup
c  url extraction
most of the microblogs often point to much more elaborate sources of information as a means of sharing content 
 

fisloww   slow where the last one is the most compressed or
the shortest shadow  in our experiments we also compare
the inclusion of either original  shortest or all shadows as
potential features  we later see that the shortest shadows
give the best results  an idea that is fairly intuitive 
our initial empirical analysis of the kinds of feature vectors obtained does seem to agree with the intuitive reasoning behind the incorporation of those features  after the
feature extraction and preprocessing  the message is converted to a feature vector that can be used by the feature
selection algorithms and classifiers 

the count of times a word appeared in the message didnt
help much  it confirms the intuition that the likelihood of
a word repeating in micro blogs is generally low since the
messages are themselves very short 
vi  experiments and observations
we tried a combination of different feature selection and
classification algorithms in our search for the best models for both the classifiers  we trained over      models
for neutral polar  np  classifier and an equal number of
models for polarity classifier  a self guided evaluator
was coded which  at every iteration  randomly selects one
of all possible models and trains it over the given samples 
once trained  the models were evaluated against the holdout cross validation set and the performance statistics were
captured in the database  training time for each iteration
depended upon the nature of the feature set selection algorithm  the classifier and the number of iterations wherever
boosting was applied  training time generally varied from
anywhere in between a couple of minutes to a few hours 
while manually trying to train models for classification
we realized that the ambiguous messages are playing a
key role in confusing the classifiers and making them perform badly  even the human classifiers were were not so
sure about which category to put those ambiguous or notso strong messages into  discarding ambiguous messages
from the training set gave a significant improvement in
classification accuracy  our initial manual training also
suggested that the optimal feature set size was close to
     features 

v  model selection
our classification mechanism consists of two classifiers
as depicted in fig    the first one is the neutral polar
classifier which is responsible for classifying the incoming
message as either neutral or polar  the polarity classifiers job is to classify polar messages as either positive
or negative  we select the most popular algorithms for
feature selection and classification and carry out our evaluation of each possible combination for each classifier  in
our experiments we randomly pick one feature selection
algorithm from the list below  
 gain ratio
 information gain
 
 
 symmetrical uncertainty
and pair it up with a randomly selected classifier to get a
model  a model consists of a trained classifier and the feature space   selected by featureset selection algorithm   to
which any new message should be translated for classification  we use the feature selection algorithm to select only
pre determined number of best features and then transcribe
the training messages to the selected feature space  this
is followed by training of the classifier with the transcribed
training set using hold out cross validation  the selected
feature subset and the trained classifier instance is then
forwarded to the respective classifiers  the five classifiers
we choose from   along with their possible configuration
values   are listed below  
 svm   kernels  rbf  linear and polynomial     
c               
 voted perceptron  exponent       
 naive bayes
 bayesian logistic regression  prior  gaussian  laplacian  
 adaptiveboosting baseclassifier  any of the above  
iterations          
thus randomly selecting a classifier means selecting one
of the five algorithms above and then randomly selecting
its possible attributes  e g  svm  c        with rbf
kernel is one possible choice  adaboosting    iterations 
over bayesian logistic regression with laplacian prior is
another and svm  c      with polynomial kernel is yet
another one 
in our model we treat each message as a bag of words
and account for only presence or absence of a word in the
message  our initial experiments suggested that capturing

a  models for neutral polar  np  classifier
in order to generate the models for the neutral polar
classification  there were two major selections to be made 
feature selection algorithm given a set of features 
what is the best way to select the most discriminating
features amongst them 
classifier for the given data set  what is the best
model 
a   feature selection algorithm selection
feature selection is the process of choosing the most discriminative features so as to enable the classifier to perform
better  this becomes especially relevant in the case of text
classification where there are an extremely large number of
features  the different feature selection algorithms that we
considered along with the average f  scores of the models that they were associated with is summarized in table
below 
feature selection algo
gain ratio
information gain
symmetric uncertainty
 

avg f 
      
      
      
      

the averages in the above table were calculated over
     different models  each of which was evaluated using
the hold out cross validation technique 
 

fia   classifier selection
we started with individual classifiers and later applied
the boosting based ensemble methods to deal with imbalance in the data set as suggested by           imbalance in
training set also makes the accuracy measure of a model insignificant hence we focus on the recall  false positive rate
and f  measure of each model for comparison  after filtering the ambiguous messages our training set was reduced
to around      polar messages and over       neutral messages 
the observed performance of the classifiers without any
boosting is given in the following table 
classifier
blr gauss 
blr laplace 
naive bayes
svm linear 
svm poly 
svm rbf 
voted perceptron

avg f 
     
     
      
      
      
      
      

avg acc 
     
     
     
     
     
     
     

fig     legend for fig          

max acc 
     
     
     
     
     
    
     

it was very astonishing to see svm with the rbf kernel
perform so badly  one reason of this low accuracy could
be over fitting of the model to the training data  hence
we remove the svm rbf  from further consideration here 
fig     all models f  scores   np classifier

when boosting is applied along with oversampling of
minority samples and undersampling majority samples  
we get the following results for the classifiers 
classifier
blr gauss 
blr laplace 
naive bayes
svm linear 
svm poly 
svm rbf 
voted perceptron

avg f 
     
     
     
     
     
     

avg acc 
     
     
     
    
     
     

the fig   represents the legend for figures           
the figures   and   represents the f  and accuracy scores
for all of the np classifiers that we trained  it is interesting
to see how the triangles and  s   representing boostedclassifiers   pervade the top portion of the plots  though
maximum accuracies are high  the f  scores are relatively
low since either the recall is low or the false positive rate
is considerably high 
based on these observations  we can clearly see that
though  in both the cases  with and without boosting  the
accuracy is high whereas the f  score is pretty low  this
happens because of the data skew that is present in our
dataset 

max acc 
     
     
     
     
     
     

a   actions to counter skew and observations
there are a set of observations that we gathered from
these runs of the classifiers 
of the shelf classifiers   classifiers with no boosting 
oversampling or undersampling gave lower recall with
relatively lower false positive rate  while in some
cases it may work but generally not being able to identify the minority class with a good success rate is not
acceptable   which is true in our case as well 
boosting  on an average  classifiers with boosting had
a bit of improvement over the classifiers without
boosting  this is understandable since boosting is
supposed to enhance the accuracy by making a relatively stronger classifier out of a committee of weaker
classifiers 
oversampling with boosting   oversampling is a tech 

fig     accuracy of all models for np classifier

 

fi    recall while also giving less than     false positive
rate

nique that we attempted to use against the data skew 
it involves the duplication of the already existing minority class instances so that the sizes of the classes
become comparable  we saw some improvement with
this over the scenario where we had just boosting 
undersampling with boosting   undersampling is a
technique in which some samples of the majority class
are discarded so that the sizes of the classes become
comparable  we find that even undersampling gives
only a slight improvement over boosting 
both undersampling and oversampling with boosting  
this gives better results than any of the methods
given above  and has yet been our most successful tool
to counter the skew in the data and address the recall
issue  with this we got over     recall in some cases
though with the cost of a higher false positive rate 
smote   smote is proposed by chawla et al in     
it tries to counter the imbalance in the skewed dataset
by synthetically generating the samples for minority
class  we briefly tried smote but didnt see much
improvement 
we can see from the roc plots in fig   that for the
models trained without boosting  oversampling or undersampling and with      features the maximum recall attained is close to      the points on the lower left corner
of the plot correspond to either feature selection based on
gain ratio and or svm classifier with rbf kernel  repeating this test for all the possible models with     and
     features did not give much improvements 

fig     classifier performance   boosting  oversampling

b  models for polarity classification
polarity classification was not plagued with the class imbalance problem in our case  although we have very small
training set   of      samples with almost equal number
of positive and negative messages   to train the classifiers
with  the resulting models  their accuracies and the f 
scores can be found in fig   and  

fig     classifier performance   no boosting  oversampling or undersampling

we then applied the boosting techniques to get a better
recall for the minority class  we saw that oversampling
the polar messages and undersampling neutral ones improved the overall recall of all the possible models but at
the same time also increased the false positive rate  as
show in fig   oversampling the polar messages to become
equivalent to the under sampled neutral message gave us
the highest recall of over     with the false negative rate
touching about      which we consider to be very high 
naivebayes and smo gave the best recalls  votedperceptron and bayesianlogisticregression always gave less than

fig     accuracy all models polarity classifier

we again saw that svm with rbf kernel is performing
poorly and gives high bias towards any one class in each
run  as can be see in fig    rbfs either give a very high
falsepositive rate or a very poor recall 
 

fifig      classifier performance   svm rbf   logisticregressionlaplacian

vii  future work
our future efforts will be focused on finding a model
for neutral polar classifier that gives a better f  score 
as of this writing  models with high recall also give a
high false positive rate whereas the ones with a low false
positive rate have a lower recall  boosting based ensembling methods helped in uplifting the f  score but we believe that we can get even better performance by applying
smarter heuristics and other techniques  for instance  we
believe that applying natural language processing techniques might help in identifying the context and nature of
the phrases thus assisting in finding similarities  although
our initial guess is that it might still not give a very high
performance gain because microblogs are very short and
not very well structured making them further difficult to
be analyzed with language parsing techniques 
we also believe that considering   grams or   grams
might give us slightly better performance  the intuition is
that the word limit on the microblogs increases the probability of the messages that are closer in intent to be closer
in syntax 
we briefly tried smote to synthetically generate the
samples for minority class oversampling but without much
success  we believe that we can give smote another try
after understanding its nuances  coming up with our own
method of synthetically generating minority class data can
also prove to be useful 
other areas that we can look for improvements are the
preprocessing of messages and feature selection that can
help better discriminate the messages 
we also saw that svms gave a very good precision but
were plagued with lower recall  we can consider introducing bias in svms towards the minority class by using
different error cost functions for the two classes thus penalizing heavily for any minority class misclassification  further  using smote with this technique can give better
performance as suggested in     
another possible solution is to use svm with a kernel
that exploits the semantic relations in between the words 

fig     all f  scores polarity classifier

fig     top f  scores polarity classifier

classifier
blr gauss 
blr laplace 
naive bayes
svm linear 
svm poly 
svm rbf 
voted perceptron

avg f 
     
     
     
     
      
     
     

avg acc 
     
      
     
     
     
     
     

max acc 
      
     
     
      
      
      
     

svm with polynomial kernel gives a reasonably good
performance for polarity classifier but not as good as the
one with linear kernel  we also observed that naive bayes
gives only marginally better performance than svm  voted
perceptron and bayesian logistic regression also seem
to perform comparably  also  the best performance is
achieved by considering either the shortest shadows of the
words or all shadows  also  svm and voted perceptron
give better performance with both informationgain and
  based feature selection as opposed to naive bayes that
seem to favor   over information gain  boosting based
ensembling methods seem to give no significant performance gain with any classifier in this case 

viii  conclusion
in this work  we analyzed the problem of sentiment classification of micro blogs  that is significantly different from
 

fithe other usual sentiment classification problem on structured and detailed messages  we used a two classifier approach where the first classifier was a neutral polar classifier and the second was a positive negative polarity  classifier  we tried different models  different parameters and
different feature selection algorithms to address the problem  the biggest unsolved challenge for the neutral polar
classifier is the imbalance in the dataset that gives a high
accuracy but low recall  in an attempt to counter this effect we tried different re balancing  sampling and boosting
algorithms  the most successful of which is the combination
of the boosting  oversampling and under sampling taken
together  we have been able to find a range of models from
the ones giving a low false positive rate but a lower recall
to the ones with higher recall but higher false positive rate 
some applications may benefit from the first extreme of the
models and some may from the other but the best model
is yet to be discovered that gives an optimal f  score  in
the case of polarity classifier may combinations seem to
perform well with naive bayes and svm being marginally
better than the others  this cascade of a balanced neutral
polar classifier  coupled with an efficient positive negative
classifier marks our approach to this problem and leaves a
wide scope for further research 
references
    weka   data mining software in java  the university of waikato
http   www cs waikato ac nz ml weka 
    bo pang and lillian lee  opinion mining and sentiment analysis
    s  r  das and m  y  chen yahoo  for amazon  sentiment
extraction from small talk on the web  management science 
vol      pp                
    g  forman an extensive empirical study of feature selection metrics for text classification  journal of machine learning research 
vol    pp                 
    bo pang  lillian lee and shivkumar vaithyanathan thumbs
up  sentiment classication using machine learning techniques 
proceedings of emnlp     
    mahesh v  joshi  ramesh c  agarwal and vipin kumar predicting rare classes  can boosting make any weak learner
strong 
    chris seiffert  taghi m  khoshgoftaar  jason van hulse and amri
napolitano building useful models from imbalanced data with
sampling and boosting
    rehan akbani  stephen kwek  nathalie japkowicz applying support vector machines to imbalanced datasets
    nitesh v  chawla  kevin w  bowyer  lawrence o  hall  w 
philip kegelmeyer smote  synthetic minority over sampling
technique

 

fi