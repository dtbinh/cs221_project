video presentation slide alignment
apurva shah

abstract
this paper presents an application of machine learning used to enhance slide recognition and alignment in
online video presentations  i describe an approach based solely on image features  intended to be robust enough
to handle the wide variety of online videos  using a binary classifier to determine whether a given frame and
slide match  coupled with a temporal markov process  the alignment produced is better than using vanilla object
recognition techniques  the classifier is trained on features derived from sift keypoint matches between frame
slide pairs  this approach proves robust to partial occlusion and moderately tolerant to poor lighting conditions 
empirical results demonstrate that a large and diverse training set is necessary and that better features are
necessary to handle the most ambiguous cases  in this paper  the videos used for training and testing were
constrained to videos where the entire slide is always present in every frame  and the view point and zoom are
mostly stationary  however  the techniques used can be expanded to work on a larger class of videos 

introduction
the internet has allowed for the wide distribution of recordings of live slide presentations making the content
available to a much wider audience  however  the online video watching experience often suffers because of the
poor image quality resulting from high compression  the slides  which are often critical to the presentation 
commonly become completely indecipherable  authors are aware of the issue  and often provide the associated
slides with video  the goal of this project is to come up with an automated process for aligning the slides to a
video  having proper alignments has the potential to improve the viewing the experience by providing the user
with a synchronized display of the digital format of the slides while watching either in a separate window  this
alignment also has implications for information retrieval allowing for videos to be internally indexed based on
the features of slides displayed at that given point and time 
in this project  i attempt to align videos and their corresponding slides by training a classifier that as input  takes
in a video frame   slide pair  and detects whether the pair is an actual match based on the matching key points
identified by the sift algorithm  i leverage the assumption that presentations are mostly monotonic and do not
often have very large jumps from slide to slide  from my training data  i construct a naive markov process that
models the probability of slide transitions from one frame to the next  i induce a probability from the classifier 
and combine it with the markov process  and use a modified version of the forward algorithm for determining
the most likely path  using sift keypoints  allows the alignment to be robust to the variable renderings power
point slides and partial occlusion of the slides  perhaps caused by the presenter   this method also avoids the
problem of finding the bounding box which can be tricky 

related work
work from foote et al        proposes an algorithm for identifying when periods in videos where there is a
presentation given  they achieve     accuracy  but do not attempt to do the slide identification  and the model

   foote  j   boreczsky  j   and wilcox  l        finding presentations in recorded meetings using audio and
video features  inproceedings of the acoustics  speech  and signal processing        on      ieee
international conference   volume    march                 icassp  ieee computer society  washington 
dc             doi  http   dx doi org         icassp            

firelies on acoustic data from the presentation  girgensohn et  al  promote discrete cosine transform and
hadamard transforms
 
to classify presentation in to certain categories  e g   graphics    speaker    both    long  shot    both of
these approaches are very successful at their task  but do not address this specific issue 
general approaches to image recognition  e g  sift  apply naturally to this problem but do not fully leverage
the special circumstances of this problem  the temporal information can provide a strong prior for a potential
match  most videos have proper orientation and slide image in the video generally retain the same aspect ratios
as the original slide  also per construction  i have limited the task to videos where every frame contains a slide 
this constraint is mainly imposed by the limited training data that i was able to acquire 

data
for my training data and test data i extracted used videos and power point presentations from programming
systems seminar series         from intel reearch   despite coming from the same event the distortion in the
videos vary quite a bit  for training  i extracted frames from      hours of video  relating to    slides  the test
data was from one hour long video corresponding to    slides  given the time to process and annotate the data  i
did not have enough time to generate more  the videos were in wmv  yuv   p compression     x    pixels  
and had       frames per second  i used ffmpeg  to extract one frame every    seconds and convert it to   bit
pgm format  i used openoffice  to convert the slides to pgm format  i used sift keypoint detector to
extract features from v   the images 
from the keypoints extracted from the frames and slides  i used a modified form of the standard sift
matching algorithm to derive matching points between every frame   slide pair  sift accepts matches that have
a euclidean distance a certain threshold better than the second best match  by default  sift requires that the
closest match must be less than    times the distance of the second best match  i increase this threshold to    to
compensate for the heavily distorted videos  this averaged to      matches per frame slide pair in the training
data and     matches in the test data 
this led to        training samples for the classifier 

alignment
video slide pair classification
my binary classifier was built to determine whether a given frame   slide pair is actually a true alignment  i
trained it on every frame slide pair for a given video  this data set is biased towards negative samples  as there
are m   negative examples for evey   positive example  where m is the number of slides  given that every frame
only matches one slide  to account  for this i reweighed the training data to balance out the training data  using
the weka library s cost sensitive classifier   without this rebalancing  the classifiers which i experimented
with  simply classified every thing as not a match 
i aggregated the matching points between a given frame   slide pair and constructed a feature vector with the
following features 
feature category
features
intuition

   girgensohn  a   foote  j  video classification using transform coefficients  proc  icassp      vi  pp          
   http   irbseminars intel research net 
   http   ffmpeg org 
   http   www openoffice org 
   http   people cs ubc ca  lowe keypoints 

fi average distance
   of matches with
distance between a given
interals

distance

the matches with the lowest
distance are more likely


scale

average scale of
keypoint in the frame
   of matches with frame
keypoint scale between
given set of intervals

i figured that given the compression
artifacts some high scale features
would be completely noise

orientation

 average square
difference between the
orientation of the
keypoints in the match
   of matches with the
squared differences
between given intervals

the orientation of matching
keypoints should be the same given
that frames and slides are always
upright 

matches

 total number of matches
 number of matches
proporti

more matches more likely indicate
a stronger correspondence

temporal

 percentage of video
completed at this frame
 percentage of slides
before and include

since slide presentations tend to
monotonically increase this could
be a basic indicator

markov process 
using the training data  i computed the probability for transitioning between any two slides based on position  i
counted number of times a given transition occurred a with distance  in slides  and direction  forward or
backward  and divided it by the total number of transitions  the test data contained     transitions  i used
laplace smoothing to have at least some probability for every transition given the sparseness of data 
let

be the set of all slides  let

the optimal alignment  optimal path through the markov process 

be the set of all frames  the probability of
that has frame

containing

is

upper bounded by 

is the transition probabilities that we computed from the transitions in our training data 
is the normalized probability induced from our classifier  the normalization is to ensure

i then used the forward algorithm to compute the most likely path  and use the path to derrive the alignment 

experimentation results
i first trained my classifier using the weka library s smo algorithm with a second degree polynomial  i used i
then fit a logistic regression classifier to the resulting model to induce probabilities from the model  the

fibaseline sift alignment  is computed for each frame by choosing the alignment for the slide that has the most
matching points  this is not affected by the amount of training data  this baseline is a little unfair  since it does
not have my temporal model 

analysis and conclusions 
this result seems to indicate a combination of problems with this model  from a classification aspect  the fact
that there is very low training error  and a bit higher test error seems to indicate that there is high variance 
possibly indicating over fitting to my data  however  as the amount of data increased  there was no real
improvement in this gap  this indicates that the training data needs to be much larger and more diverse to
capture the variation in data  the video used for test set may just have some fundamental distortions that are
unseen during training 
looking over the misclassified frames in the alignmen and the corresponding keypoints it is apparent that there
are certain regions of frames where sift is not sensitive enough  the      accuracy is a big step up from the
baseline  howerver for the alignment indicates that my objective function should include the final alignment 
one reason for this could be that the penalty for a misclassification is not truly realized  given the magnified of
affects of misclassification in the markov process  making the alignment the true objective function could force
the classifier to give lower probability to its predictions when it is not completely confident 

a frame the method fails to align 

fifi