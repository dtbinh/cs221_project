spoken language identification with hierarchical temporal
memories
dan robinson
danjr   stanford edu

kevin leung
kkleung stanford edu

xavier falco
xfalco stanford edu

december         

 

introduction

the task of spoken language identification has enjoyed many promising approaches via machine learning
and signal processing since the late     s  however  most either employ hidden markov models  hmms  to
model sequential data or use language dependent phoneme recognizers as primary features     p       the
former has sparsity related issues and is sensitive to previously unseen events  which are common in human
language  the latter requires extensive labeling of training data on a phonological or prosodic level  which is
often impractical  and depends upon specialized information for each spoken language under consideration 
our project is an attempt to use hierarchical temporal memory  htm  to do spoken language identification  htm  implemented and distributed by the numenta company  is a new technology inspired by
the human neocortex  distinguishing characteristics of htms include their ability to natively process both
temporal and spatial information and their potential for deep hierarchical structure  these two features of
htms suggest their utility in audio and language tasks 

 

hierarchical temporal memory

an htm is a tree shaped hierarchy of nodes  where each node implements a learning and memory function
and thus encapsulates a primitive algorithm  nodes are organized into layers or levels and dont interact
directly with other nodes of the same layer  lower level nodes receive sensory data and output coincidence
predictions to higher levels  in this way  an htm network abstracts information as it is passed up the
hierarchy 
during training  the htm is presented with examples of data as it changes over time  the temporal
element is critical  the algorithm expects input that changes over time in predictable patterns  and it attempts
to discover and learn these patterns  this makes htms particularly suitable for audio processing  previous
research on audio classification using htms includes promising results in the training of htms to recognize
spoken digits     
each node in an htm is made up of a spatial pooler and a temporal pooler  the former quantizes
and clusters input data to the node  and the latter learns temporal patterns amongst incidences of these
quantization points   for simplicity  one can conceive of the former as a preprocessing step for the latter  which substantially reduces sparsity   there are many specific algorithms for spatial and temporal pooling  several of which are implemented in the numenta release  for more information  see http 
  www numenta com for developers software prog guide output prog guide      html  we used
the standard nupic gaussian spatial pooler and sumprop temporal pooler throughout our code 

 

fi 

dataset description

thus far  our dataset includes approximately      utterances from each of american english  british english 
french  russian  and japanese   we have and would like to incorporate data from    other languages  but
have been unable to do so thus far due to afs space constraints   most utterances range from one word to
one short sentence and are less than   seconds long  utterances are spaced evenly over a variety of speakers 
which represent many ages and genders 

 

experiments

so far  we have run experiments on the following   language classification tasks  with varying amounts of
training data 
   american english vs  french
   american english vs  british english
   four way classification between american english  french  japanese  and russian

 

algorithm details

as input to our htm  we used a log linear mel spectrogram of our data files  taken with    frequency bins
at     frame increments over our audio  as our data files have a sampling rate of  khz  this corresponds
to    ms wide frames  most speech recognition literature seems to use some variant of this cepstral feature
model         which also has some validity as a biologically inspired model of the mammalian cochlea 
when using htms for classification  a single classifier node is added to the top of the htm  which
produces a frame by frame likelihood distribution over the relevant classes  in this case  our     languages  
we experimented with off the shelf knn and svm models  an htm application has many other configurable
variables  including the number of layers  number of nodes per layer  and a handful of variables internal to
the nodes at each level  we refer to the former two of these as the htm architecture  and the latter as the
internal node variables 
the frame by frame classification results can be converted into classifications for our utterances in several
ways  such as taking the average  product  or max over the frame by frame classification likelihoods to chose
a most likely class  intuitively  even   second long utterances have over       frame samples  with frameby frame likelihoods that are even slightly better than random guessing  taking products or averages of
distributions can produce a strong utterance classifier 

 

svm results

our best utterance by utterance accuracies achieved were        for english vs french classification       
for american enlgish vs british english  and     accuracy for the four language classification task  all
three of these were achieved with one layer of four nodes  using svms as classifiers  all three of these used
at most     utterances per classifier  with the latter two using at most     note that  in the latter test 
our frame by frame accuracy was only         demonstrating the powerful multiplicative effect of a weak
classifier taken over many thousands of frames 
thus  a one level htm with an svm classifier is able to reach near perfect classification between english
and french with fewer than    training examples  this architectures performance on the other tests is less
impressive but still of significantly higher accuracy than any architecture using a knn classifier 
confusion tables from our multiclass classificatons of highest accuracy are included below for each classifier type   both use this one layer  four node htm architecture  

 

fieng
fre
jap
rus

eng
  
 
 
 

fre
  
  
 
 

jap
 
 
  
 

rus
 
 
 
  

eng
fre
jap
rus

eng
  
 
 
 

fre
 
  
 
 

jap
 
 
  
 

rus
 
 
 
  

table    best utterance by utterance confusion tables with frame product classification  using knn  left 
and svm  right  classifiers  trained on     and    utterances per language  respectively 
unfortunately  the computation time required by our svm classifier on larger training sets was prohibitively long  whats more  though this svm architecture does successfully identify spoken languages  we
wanted to investigate different htm architectures  so as to empirically compare the quality of the discovered
features at each layer  with these two facts in mind  we resolved to pursue other architectures and node
configurations  using only knn classifiers 

 

varying the htm architecture

for the remainder of our project  we attempted to modify our htm architectures and internal node configurations to exploit the potential of htms to discover deeper audio features and  hopefully  more accurately
classify our languages 
we found the default internal node values performed the best for all five of the parameters we considered 
modifying any of them independently decreased our classification accuracy at both the frame and utterance
level  though these parameters interact in deep and complex ways  our primary goal was to explore various
htm architectures  not to hand tune internal nodes  we settled on the initial parameters and held them
constant throughout our remaining tests 
in addition to a baseline architecture  in which initial input features are fed directly into our frame byframe classifier  we explored three single layer htm architectures  two configurations with three layers  and
one of two layers 
our one layer structures used two  four  and eight nodes  splitting the    initial input features evenly  of
these  the four node structure performed uniformly better  and it is the only single layer htm we consider
henceforth 
our first three layer structure consisted of four nodes at the first layer  two at the second layer  and a
single node at the top layer  using the output from the top layer as input for our classifier node  our second
three layer structure had a similar layout  but with the concatenated output from every layer as input for
our classifier   that is  at every frame  we passed the output from all seven nodes directly to our classifier  
diagrams of the four htm architectures we consider further are presented below 

 

fitable    from left to right  top to bottom  our baseline classifier  single layer htm with four nodes  three
layer htm using only top layer output  and our three layer htm using all three layers of output 

 

binary classification results and conclusions

between our binary classification tasks  relative performance between our htm architectures remained
constant  performance was generally better when classifying between british and american english than
between english and french  learning curves for these two tasks are presented below  with our svm results
added for perspective 

table    training curves for our two binary classificaton tasks  with british english vs american english on
the left and french vs american english on the right

amongst the configurations with a knn classifier  our baseline system performed best  followed by the
one level architecture  the architecture using features from all three layers  and lastly by that using only our
top level features 
it seems that  for these tasks  additional htm use decreases performance  indeed  adding a first htm
layer from our baseline causes a uniform decrease in accuracy accross the training curve  as do adding more
layers on top of that  even when adding the second and third layer outputs as features to a model using
just the first layer outputs  we hurt our overall accuracy 
there are several possible analyses of this phenomenon  first  the training of the htm layers is completely unsupervised  the patterns it learns at each level need not have any correlation to our tasks  it may
well be that the unsupervised portion of our learning produces a feature set that is less and less useful for
our task at each layer  indeed  fundamental to the training is clustering of input  which may obscure some
of the intricate  low level information necessary for language classification 
additionally  note that the variance of our model increases significantly with each level of input added 
indeed  the first layer typically learns on the order of     features  made up of spatiotemporal patterns
 

fifrom the original     the total number of features from our three layer model is often greater than         
with this forty fold increase in the number of features comes a large increase in variance  compensating for
which with equally massive training sets would be impractical given reasonable limits to our computational
resources  noting that our training error is usually    at the utterance level  this variance issue may well be
our chief source of error  these deep htm networks may merit further work  either with more supervision in
the training of each level or with significant pruning of feature sets  which we can accomplish with standard
model selection techniques 

 

four language classification results and conclusions

the results from our four language classification task differ in that our one level htm configuration does
outperform our baseline system  whats more  this system is uniformly worst in accuracy at the frame level 
and yet is best in utterance classification accuracy  learning curves for frame and classification accuracy are
presented below 

table    training curves for our four language classificaton task  frame classification accuracy on the left
and utterance classification on the right

this discrepancy between frame accuracy and utterance accuracy can be explained by the fact that our
one level htm yields the most balanced set of frame errors  the baseline knn system produces a frame
by frame confusion table that is highly lopsided   that is  between any two languages  well above half of
the frame classifications align with one of the two languages   this phenomenon yields a high error rate 
whereas the one layer htm produces a frame confusion table with a large numbers of errors  but which is
nearly symmetrical a system such as the latter is more favorable for use in utterance classification  in which
individual frame misclassifications matter very little but statistics over thousands of frames are critical 
thus  for language classification involving more than two languages  it does seem that htms add some
value  as our best performing system did utilize our lower level htm features  with further tuning and
improved feature filtering  one may be able to classify spoken language in close to real time  and with high
accuracy  that said  current htm implementation does not seem suited for binary language classification 

references
    h  li  b  ma  and c  h  lee  a vector space modeling approach to spoken language identification  ieee
transactions on audio  speech  and language processing                     
    j  van doremalen and l  boves  spoken digit recognition using a hierarchical temporal memory  proceedings of the  th international conference of interspeech  pages                
    m  a  zissman  comparison of four approaches to automatic language identification of telephone speech 
ieee transactions on speech and audio processing                  

 

fi