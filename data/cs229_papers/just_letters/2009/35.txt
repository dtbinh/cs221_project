identification of nano particle absorption by
circulating macrophage
melisa orta  kimberlee shish  brendan tracey
abstract detection of cells within a photoacoustic image of a
slab of tissue is an inherently difficult problem  not only are the
cells themselves shape and intensity variant  but the background
is bright as well  taking a   d slab and reflecting it into a   d
plane causes different orientations of the same cellular structure
to emerge  this task is currently accomplished by humans 
though the process is laborious and error prone  in this paper 
we describe our approach and results in trying to solve this
problem using various machine learning techniques  we chose
features that reflect that cells are ovular  bright  and will have
some contrast with the background  we compare results obtained
with different algorithms and different combinations of features 
concluding that more work is necessary to obtain acceptable
results 

cellular regions than the hand marked image  we needed a
better data set  and so we hand classified the top third of our
image pixel by pixel using the fully marked image as a
guideline  we found that our algorithms were consistently
over classifying the bottom corner of our image due to its
brightness relative to the rest of the image  we hand classified
the lower right corner of the image and added it to our training
set  in short  the data on which we are using to train is a pixelby pixel marking of cell locations based on a third of the
provided hand marked image  the other two thirds we use to
test by eye to get a feel for how well a given algorithm is
functioning
iii 

i 

introduction

one forthcoming branch of cancer research attempts to take
advantage of carbon nanotube absorption and imaging
properties  nano particles can be designed to be attracted to
tumor cells  and can also act as contrast agents in photoacoustic
imaging  with these images  researchers analyze which types
of the nanoparticles should be used as trojan horses to kill
tumors  at stanford  dr  bryan smith is researching the
convection of nano particles from macrophages to tumor cells
within tissue  in his experiments  nanoparticles are injected into
the blood stream of mice with surgically implanted tumors 
this analysis requires determining the percentage of nanoparticles absorbed within the macrophages  which involves
identifying macrophage within raster images of the
nanoparticles  the cells themselves are not visible  only
nanoparticles exhibit fluorescence  
in this paper  we address the automation of finding cellular
structures in the raster images of the nanoparticles  currently 
trained scientists do this by hand  which is not only tedious  but
also causes bottlenecks in project progress  this problem is
inherently difficult in that even humans must be trained to
correctly identify cells from images  and even then they only
agree to      accuracy  therefore  obtaining this level of
accuracy would be sufficient for automation 
ii 

preprocessing training data

we were provided a single hand marked image with boxes
around regions where there are cells  and we have used this
image as the right answer  see milestone for full image  or
zoom view in figure x   at the beginning  we trained on   
regions of interest     cells     not cells  provided for us  given
in the form of pixel coordinates of these regions  we developed
features which made the training set clearly linearly separable 
but when classifying the whole image it predicted many more

choosing features

by examining our training data  we began to learn what
identifies a region as a cell  the region has to look roughly
circular or ovular  it has to be sufficiently bright  and it has to
have a high contrast between it and its surroundings  regions
of high intensity but low contrast are more likely to be
conglomerations of nanoparticles within the tissue rather than
the macrophage  and regions of high contrast but low intensity
are more likely to be noise in the image rather than an actual
cellular structure 
a  ring intensities
for our first attempt at choosing features we chose a three
feature set  the average intensity of the pixel  the average
intensity of the   pixels surrounding the pixel and the average
intensity of    pixels around those   pixels  in order to reduce
over classification in the brighter areas  we tried a few
approaches to normalization  ie normalizing mean and
variance  subtracting the average intensity of the surrounding
 x  pixel region   after performing tests with this feature  we
realized that there were areas of concentration of nanoparticles
that were not necessarily cells but that were of equal average
pixel intensity 
b  edge features
we decided to take advantage of local gradient and shape
information  the matlab function edge m uses the prewitt
approximation to find points where the gradient of the
grayscale intensity is large  using this edge function and some
filtering to clean up noise in the edged image  we calculated the
distance from each pixel to the nearest edge in each of four
main directions  right  left  up  down and used the sum of these
distances as a feature in order to eliminate orientation issues 
an illustration of the above two features is shown in the
following figure 

fi    of positive pixels and all remaining negative pixels are
used for testing 

figure    example of edge and intensity features

c  circle finder      
a circle finding algorithm was implemented to better
exploit the fact that cells are roughly circular  this algorithm
uses a hough transform based on the gradient field of an
image  and inputs based on the approximate size of the circles
to identify the locations and radii of circular shapes  using this
method  circles were identified both in the image of the edges
 obtained using edge m  described above  circle finder    and in
the original image  circle finder     a feature was assigned
based on the euclidean distance in pixels from the center of the
nearest identified circle  with a threshold at    pixels 
d  morph
for our last shape feature  we used several of matlabs built
in morphological operators  first  edge m was run to capture
the gradient information  then fill m and erode m were used to
fill closed edges  and cleaned up noise  then dilate m was used
to enhance the remaining positive cell classifications  lastly 
the average intensity of the center pixel  a  x  box  and a  x 
box were calculated on this altered image  and used as features 
while many of the shape features alone do not find all of the
cells  but it was hoped a combination of them would help
classification 
e  individual intensities and k means
when looking at components of our feature space  it was
clear that it was still highly inseparable  we added one feature
set of the individual intensities of each of the pixels in a  x 
box around the test pixel  as well as the mean intensity and the
variance of the intensities for a total of twenty seven features 
lastly  to better find features in our data  we used the above
feature set on all of the pixels in our image and ran k means
clustering on the data  ordering based on mean intensities  we
assigned values to each of the regions predicted by k means 
and assigned each pixel a value based on its region 

when training using nave bayes  a k means algorithm was
used to discretize each feature space into five clusters  then  a
multinomial nave bayes algorithm was run on the training
data  given the imbalance in our data set  for some of the
feature spaces the algorithm would classify the data as all nos
due to the high unlikelihood that any given pixel is actually a
cell  as a result  for some runs we tried to optimize the decision
boundary  py     db  py    for maximum precision and
recall  and minimal distance between precision and recall on
the test data  after the optimal decision boundary is found  we
then test our algorithm on the test data and the entire data set 
and then classify the whole image  in addition  we
implemented a forward search feature selection algorithm to
identify important features 
we trained on svm using both a linear and a radial basis
function  rbf  kernel  like nave bayes  when training on
svm with both the linear and rbf kernels  we sometimes
optimized the choice of c using a five fold k fold testing
algorithm  in the guassian kernel  gamma was chosen to be   n 
where n is the number of features  as recommended by     
v 

we ran each of the individual features on each of the
algorithms  the forward search feature selection algorithm was
used to identify important feature combinations  from this  we
determined that for nave bayes  in descending order of
importance  the top three features were          we also tried a
sampling of other combinations we thought would work well
together  the results are tabulated below  the linear kernel
svm results are provided to give an overview of how the
features performed relative to one another  while the next two
images are indicative of the relative performance of the
algorithms 
                                    
 

training algorithms andfeature selection

we used two main algorithms to test our data  nave bayes 
and svm lib      features are assigned as well as classified on
a pixel by pixel basis  our training data is very imbalanced 
having only      of the pixels as cells  and is very large 
comprising over       pixels  as a result of these two factors
and computational limitations  we reduced our training set to
    of our total positive  is a cell  pixels  and fifteen times this
number of negative pixels  is not a cell   selected at random 
this is only        of our total training data  the remaining

   

 

     
     
       
       
     

   

   

   

   

        

        

       

        

        

 
 
        
        

 
   

   

 
 

 
 

   

 
 

 
 

   

        

 

             

iv 

results

            
        

        
        
        

        

        
        
        

        

       
        
        
        
        

        

figure    results for various feature sets    kmeans    edges    ring
intensities    circle finder      individual intensities    circle finder    

ficlassification is done on a pixel by pixel basis  if we classify a
larger region of pixels as part of a cell than is actually marked
in the cell  this will result in a lot of false positives 
alternatively  if we get only some of the pixels that are
classified as a cell  we will have a lot of false negatives despite
having accurately found the cell  in reality  the labeled
boundary between cell and not cell is very imprecise  as it is
impossible to tell on the scale of a pixel exactly where the cell
is  due to this uncertainty  our actual precision and recall are
not completely indicative of our true precision and recall in
finding regions which are cells  in the image below  figure    
a hand count of cells returns precision and recall values for the
entire training data in the order of      however  this alone
cannot completely explain our low accuracy 
figure    comparison of algorithm performance for features found through
feature selection

figure    illustration of misrepresentative precision and recall  training data
sections are marked off by green lines  white and black indicates train
matching classification  blue indicates false negative  and red are false
positive 
figure    comparison of algorithm performance using all features

overall  none of the algorithms preformed much better than
the others  the svm algorithms tended to over fit our training
data  performing extremely well on the training data but very
poorly on the testing data  our attempts to reduce over fitting
 through either k fold analysis or hand picking parameters  led
to one of two things  the algorithm would predict that there
were no cells in the image  or the improvements would be very
minimal  nave bayes had less  though still significant 
problems with over fitting the data  but was not able to perform
as well on the training data  aside form the feature sets
predicting no cells  attempts to optimize the decision boundary
had no effect on precision and recall or actually decreased the
performance on the training data due to over fitting  in the end 
the two algorithms performed roughly the same  with svm
being more accurate on the training data but over fitting  and
nave bayes doing less well on the training data but having a
more robust decision boundary 
vi 

a closer look at our feature space

in these results  our precision is very low  implying that our
algorithms are over classifying the number of pixels which are
cells  in analyzing our results we must keep in mind that

each of our features has its own problems dealing with the
difficulties of the classification  the edge feature has problems
with the noise of the image creating edges where there should
not be and blurring edges where there should be  furthermore 
the edges that are correctly placed may not match with the
provided classification  creating error where there may be
correct classification  our contrast features encounter
difficulties because there are some cellular regions which have
high contrast  but there are many others which do not  in fact 
there are many cases in which two regions that to the untrained
eye look morphologically similar have different classifications 
creating problems with any feature set that we could select  all
of the traits around which our features were selected  shape 
intensity and contrast  have high variability throughout both
classification classes  see figures     we had hoped that
combining the knowledge in each of the features would lead to
a robust classification  but it appears to not be the case 

fia more fundamental shift in classification procedure
would be to try to find regions that are cells rather than
classifying on pixels  this approach is potentially more
invariant to noise in the image and to mislabeling of cell
boundaries  on the other hand  a pixel by pixel classification
has the upside of being able to correctly identify a cell
boundary when working correctly  and will aid in the
computation of percent uptake 
lastly  a property of the cells that we did not explore for
this part of our work is that they move with respect to the other
tissue  one good example of this is illustrated in the following
image sequence 
here we can see the cell move from the place pointed by
the red arrow to a new position in a window of about  
minutes  this leads us to believe that exploring sift features as
a way of tracking the movement of cells across several frames
could be a good way of distinguishing them from other tissue 
even this may not prove to be adequate since not all cells move
as much as the ones illustrated by the above picture  one must
keep in mind that we cannot take very long video since it is
taken from tissue inside a live mouse which will not stay steady
for long periods of time 
figure    screenshots of video of cell movement

in conclusion  we have generated a variety of features and
applied a number of machine learning techniques to this
problem with disappointing results  in order to break further
ground on this problem  either more expertise will be needed to
generate more precise and robust features  or a brand new
method must be employed which uses time lapse images or at
the very least higher resolution images with less noise
acknowledgment

figure    illustration of photoacoustic image of nanoparticles  showing hand
marked  top   unmarked  middle   and training data  bottom  examples 

this project could not have been completed without the
help of dr  bryan smith and farchid moussavi  dr  smith
provided the motivation  understanding  and training data for
this work  farchid moussavi connected us with bryan 
suggested the use of the morph features  gave feedback on our
ideas  and was the source of much encouragement 

vii  future work
one method that may help improve our classification is the
ciss algorithm which deals with finding the most
representative data in a data set that is very imbalanced  we
propose to implement this algorithm  which iteratively trains on
the poorly classified data  to improve our results 

references
   
   

chang  chih chung  libsvm a library for support vector machines 
 http   www csie ntu edu tw  cjlin libsvm  
g  x  long  w l  cleveland  y l  yao  automatic detection of
unstained viable cells in bright field images using a support vector
machine with an improved training procedure  computers in biology
and medicine                  

fi