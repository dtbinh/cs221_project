finding the augmented neural pathways to math processing 
fmri pattern classification of turner syndrome brains
gary tang
 garytang     stanford    edu 

abstract

ated mental state  for this project  we are concerned
with the set of neural sequences that suggest a clinical brain is performing a math related task  while
its generally understood how healthy brains perform
math  it remains unclear how brains suffering from
cognitive deficiencies process math  one such population are individuals with turner syndrome  this
condition  affecting   in      girls  leads to different
types of cognitive impairment  including poorer than
average math skills 

the use of statistical and machine learning methods
for multi voxel pattern analysis  mvpa  has grown
rapidly in the past two decades  today  sophisticated
pattern classification techniques applied to functional
magnetic resonance images  fmri  have allowed researchers to reliably discern different mental states
with high accuracy  in this work  we perform mvpa
using support vector machines  svm  to study the
neural activity associated to math processing in a clinical population with cognitive deficiencies in math 
namely  we studied the effect of training to rehabilitate turner syndrome patients and its ability to
augment the neural pathways associated of math processing  applying a modified form of the canonical
recursive feature elimination  rfe  algorithm to spatial and spatial temporal formulations of the data  we
successfully classified the two groups with great predictive accuracy  unfortunately  the resulting classifiers were unable to demonstrate that post training
images were more similar than pre training images to
a healthy individual with any statistical significance 

problem statement

members of the stanford school of medicine conducted a study to rehabilitate the mathematical abilities of individuals with turner syndrome through
a series of training exercises that taught students
to mimic the way a healthy individual processes
math  testing before and after the program suggests
a statistically significant improvement in math performance  but a univariate analysis of the fmri data
found no identifiable difference between pre training
and post training brain activity  the overall goal of
this project is to determine which  if any  regions
of the brain can be used to discriminate between
introduction
pre training and post training images  and by corollary  identify the possibly new  math related  neusufferers of mental or cognitive disorders have traronal pathways that were generated as a result of the
ditionally been diagnosed using symptom based critraining 
teria  even common disorders  such as depression 
are not diagnosed in a rigorous scientific manner 
but rather through a checklist of known related  objective
symptoms defined in a medical manual  a rigorous
and precise measure of cognitive function and activity we separate and define the objective into two compohas long been the holy grail for psychiatrists and neu  nents  firstly  we wish find a reliable measure  in this
roscientist  today  many believe neuro imaging  such case a classifier  with which we can claim that a difas magnetic resonance imaging  mri  and computed ference exists between pre training and post training
tomography  ct   to be the prophetic technology  images  we must take steps to ensure that the clasin particular  functional magnetic resonance imaging sifier is well generalized such that it can predict on
 fmri  has emerged as one of the most popular tools persons from whom we have no prior data  what this
to map of neural activity to mental states  these paper refers to as disjoint data  which is acknowlimages track the hemodynamic response  hr  of the edged to be a much harder task  than simply predictbrain as a correlate to neural activity and its associ  ing on data left out of the training set  the second
 

fipart is simply to apply that measure  either directly challenges and strategies to analyzing
or indirectly  to determine if the post training images fmri
look more similar to that of healthy individuals  the
classifier chosen and the data objects that we are clas  overfitting
sifying is problem can be formulated in different ways
which will be presented in later sections 
if the ultimate goal for neuroscientists psychiatrists
to use classifiers for diagnosis  they need to have the
ability to generalize well  but for scientists who study
fmri  the problem is further compounded by the fact
materials
that the training size m is much smaller than the feature space dimension n  an svm applied under these
data
conditions will tend to overfit the training data  resulting in poor generalization  and while soft max
the fmri data comes from eleven turner syndrome regularization helps alleviate this issue  many believe
patients and five control patients who were imaged it is essential to explicitly remove features  pruning
while performing a block test  during this test  im  noisy and uninformative features      therefore  in
ages were sampled every two seconds over    blocks  this project we apply a modified form of the canoniwhich span    s in total  each block is either a   s cal recursive feature elimination  rfe  that seeks to
math task or a   s control task  where a control block further improve the generalization  details can be
follows a math block  each image is composed of found in later in the report 
        mm voxels  each turner syndrome patient
performed two block tests  corresponding to a pretraining date and a post training data  the two block
tests were separated by approximately six months 
data quality i
while much of the fmri data is noisy and uninformative  this is consequence after the data is in a usable
form  e g  greyscale numbers from an image   that
is to say  some factors affecting the quality of the
data are outside the control of the statistician or the
analyst  the ability of capturing a proper fmri is a
tenuous one  patients often move  the fmri machines
experience drift  etc  in order to obtain a useful fmri
volume  it must first be motion corrected  repaired 
transformed onto a template  and smoothed  not
only will this affect the signal that is ultimately sent
to the svm  but often times the images are simply
not salvageable and their inclusion into a training set
will adversely affect the performance of the classifier 
one example is when the pre pre processing  before our pre processing  see data quality ii  results
in a lot of redundant data  in general  the svm is
agnostic to redundant data so long as they are consistent  i e  the labeling of redundant data is the same  
but manual inspection indicated that the redundant
data is not consistent  evidenced by poorer prediction rates in a preliminary study  these datasets were
left out when producing the final results  because we
posit that each individual is statistically representative of the population we seek to classify  we did not
preclude the use of an individuals data obtained if
data obtained at a different time is usable  e g  if
subject a had a poor test   but a usable test    that
data is included in our pooled set of data  

computational tools
the images were processed by the matlab toolbox
spm  and a custom extension authored by professor fumiko hoefft  the optimizer cvx  was used
to solve the svm optimization problem  it primarily
employs a interior point method whose complexity is
either constant or weakly proportional to the number of features  this feature is critical to our problem since the data from each image is converted to
a single feature space with dimensions on the order
o        all additional programming development
was performed inside the matlab environment

approach
for this project we employ the support vector machine  svm  learning algorithm for its robustness and
proven record of effectiveness  more specifically  we
employ a linear svm since neither the author nor
the existing literature  has found a significant performance gain in the use of nonlinear svm  and while
we mainly use the algorithm in its classical form 
we explore different feature definitions  feature selection techniques  and pre processing strategies that
are best suited to handle our particular application 
 

fidata quality ii

principal component analysis  pca 

once useful a useful training set is selected  the data
often remains inundated with noise and other additive signals  e g  drift   we address this with several
strategies filtering detrending  masking and the use
of principal components 

the principal components highlight those features
whose variance is high  likely indicating a signal or
an informative voxel  this has the effect of further
de noising the data matrix before going it into the
svm algorithm  if filtering is applied  one should be
careful to examine the eigenvalues or squared singular values on a scree plot to ensure that the proper
number of principal components are taken  or rather 
that enough are taken  in this project  we essentially take all principal components  only removing
those that are likely the result of numerical round off
 e g  i          it also has the effect of removing redundant data  by virtue of the fact that the
maximum number of principal components does not
exceed the rank of the matrix in our case  which is
good from both a classification point of view  conflicting redundant data  and from a computational
point of view since we now are required to process less
data while extracting an equivalent amount of information  applying this within rfe has the effect of
subset matrix specific de noising  furthermore  because rfe is such a computationally intensive procedure  it is even more important to have an efficient
algorithm  it is important to remark that pca is
not a feature reduction method  the complete set of
original features is retained  pca is applied at each
step within the rfe procedure  i e  a new pca is
done on each resulting subset 

de trending
because of the data acquired by the fmri machine
experiences a significant amount of drift  the drift is
regressed out by a quadratic regression model  this
could also be performed using a high pass filter  but
using this particular form of de trending reduces the
possibility of removing any informative modes 
low pass filtering

it is well known within the neuroscience community
that fmri signal is very noisy   the authors own
preliminary study indicatesthat classification is much
more difficult without the use of a low pass filter we
used a discrete cosine transform  dct  to decompose the modes and perform the filtering  because
the signal of interest has a theoretical frequency of
about     hz  and motivated by a survey of the spectral distribution of our data  we use a    hz cut off
threshold  it is important to note that the survey is
best performed on voxels that lie inside the region of
interest  roi   otherwise  a random survey of unin  data definition
formative nodes can erroneously infer that there is no
the problem of classifying post training and preunderlying signal or similarly  there is no discernable
training math processing can be formulated in difdifference between noise and signal 
ferent ways  this study choose two particular formulations  instantaneous volume classification and
time series classification  traditional classification of
science driven feature reduction  masking
fmri uses single volumes  images  as samples and
the use of a mask immediately eliminates features has strongly demonstrated to be a reliable way to
that are definitively known to lack information  e g  classify differing cognitive states   alternatively  we
grey matter   a common practice  however  is also to can classify pre training and post training images via
mask the regions of the brain that are hypothesized an ensemble of volumes     math volumes      cona priori to carry no informative information  in this trol volumes   i e  a time series  since each image
study  we try both approaches  a minimalist mask  represents a snapshot of the given activity  i e  math
and a mask that includes only the roi  the results  task or control task  at some point within the   s inas expected  are strongly dependent on the choice of terval  one could imagine that the neural activity at
mask since most  and also in our case  fmri analy  the end of the interval looks very different from at the
ses are performed with very few samples  as most beginning of the interval  furthermore  we know that
learning and statistical methods rely on the assump  the brain signal within a block follows the hemodytion that the data is representative of the population  namic response  which is a lagging indicator  therewhen applied to small samples algorithms often find fore  we expect a single representative image of the
a solution that is strongly dependent on the specific math task or the control task to have a large variance 
training data and unrepresentative of reality  namely  alternatively  the collection images  strewn into one
science 
  x      feature vector  representing duty cycle is
 

filikely to have a lower variance and more amenable to
classification  results for both formulations are presented in this paper  this technique has also been
used to classify the time dependent changes in fmri
images in order to capture temporal features   although we built the implementation to conduct such
a study  it was not explored further at time of writing 

generalization weighted
feature elimination

recursive

as discussed earlier  the ability to maximize generalization at all steps will be critical to infer on disjoint
data  therefore  we begin with the classical rfe
algorithm   whose procedure can be found in detail
in the literature  and add modifications to improve
the generalization  firstly  the in our application of
the rfe procedure  we remove a percentage of the
worst ranking features as opposed to a single feature 
naturally this is for computational purposes since we
are working with a very large features space  we
begin our modification with where we perform our
ranking  in the authors experience  the rfe process has a very large variance with respect to the reduced subsets that it creates  therefore  within the
rfe algorithm  we perform a k fold cross validation 
furthermore  we seek to enhance the generalization
of our classifier by weighting the weight vectors vi
 corresponding to the ith step in the cross validation procedure  in the cross validation process by the
ability of vi to predict on the set atesting   a similar process can be applied to the disjoint set b but
experience shows that this has no effect on the resulting weight vector because the disjoint set b is almost
always predicted poorly to the same degree  one possible intepretation is for that particular iteration  you
want the separating hyperplane to fit your test data
well  another  possibly better interpretation  is that
you are picking separating hyperplanes that generalizes to all the data very well  that is  both training and testing  since training will always be low 
we expect that the generalization can be improved
if we weight against he performance of the test set
i e  when we weight it against hte performance on
the entire set  this idea isnt limited to fmri but
rather this is helpful whenever you have many more
features than samples and overfitting is expected to
be a problem  since we are essentially applying a
mean over the cross validation set  it is important to
have this weight factor since some particular data sets
will be conditioned such that the optimizer is unable
to converge of interest  roi  mask 

classifier formulation
the most intuitive form to achieve our objective is
to use the pre training images representing the math
task and comparing them to the post training images
representing the math task  the resulting discriminating weight vector  i e  the separating hyperplane
parameter w  would then be used to classify the control images representing math  that is  if the training
did indeed augment the neural patterns to be more
similar to a healthy individual  we expect the weight
vector to classify the control images with the label
corresponding to the post training images  alternatively  we can classify through a more indirect means 
we can classify the control and math images in the
mc
pre training set and obtain a classifier wpre
and simmc
ilarly for the post training set wpost and using those
two weight vectors  determine which weight vector
can classify the control data  math   task  the best 
results for both formulations can be found later in
this paper 

specification of our classification procedure
we follow the soft max form of the linear svm  
specifically  we chose a soft max regularization parameter c         although a nonlinear kernel was tried in the study  it did not demonstrate
provable performance improvements over the linear
form  which is consistent with existing literature in
fmri classification  furthermore  the discriminating
weight vector  i e  the support hyperplane  resulting
from a nonlinear kernel is much hard to interpret as
it relates to functional localization  the data is separated into three sets for each time the classification is
run  firstly  we create one set b that includes all the
data belong to one  or two  individual s   this will
be our disjoint set and will remain constant through
the rfe procedure  we then take all remaining data
and call this set a  for each classification  set a
is randomly broken into a testing set atesting and a
training set atraining in a       split  cross validation  k fold  loocv  etc  will be limited to the training
set only and prediction rates are calculated for each
of the three sets 

algorithm
algorithm generalization weighted rfe  x  s  r  k  p ca 
given a dataset x  a starting feature set s  a
removed feature set r  the number of folds in
cross validation k  and the option to perform
pca within iterations
   begin with set s    allf eatures  and r     
   do pca if desired
   randomly generate atraining   atesting
 

fi  
  

  
  

for i   k perform k fold or loocv cross validation perform svm obtain weight vector wi
now weightpobtain a weight averaged weight
k
i    i  
where  i is the testing error
vector w   p
k
i  i
associated to weight vector wi
perform ranking on w
update s  and r

comparing against healthy brains
data set
pre  mathvct  single
post mathvct  single
pre roi mathvct  single
post roi mathvct  single
pre roi filter mathvct single
post roi filter mathvct single
dutycycle
dutycycle  roi
pre math v post math

results

prediction control data
    
    
     
      
   
     
        ct post 
        ct post 
       ct post 

from the table above  we can see that we have
a very difficult time classifying the control data  as
wed expect from our experience trying to classify
the disjoint set  despite our attempts to maximize
the generalization  we were unable to discern from
the data whether or not the turner syndrome brains
were more similar to the healthy brains after training 

conclusion
the goal for our project was to determine if we could
discern pre training and post training fmri volumes
and if we could  whether or not we could claim that
the post training volumes look more similar to the
pre training volumes  although we can firmly state
that there is indeed a difference between pre training
and post training data  our attempts to generalize
those results to data that were disjoint from our
training were ultimately unsuccessful  analysis of
fmri data is strongly hindered by the lack of data
and until more data can be acquired  the holy grail
of diagnosing mental states with fmri classifiers remains just that 

references

figure    prediction rates for single volume and
duty cycle formulations 

    norman  a  kenneth  et  al  beyond mind reading 
multivoxel pattern analysis of fmri data  trends in cognitive science 
doi         j tics             
    guyon  i   vapnik  v  et al  gene selection for cancer classification using support vector machines  machine learning  kluwer academic publishers        p        

prediction rates

    mourao miranda  janaina  friston  karl j   and michael brammer  dynamic discrimination analysis  a spatial temporal svm  neuroimage
doi         j neuroimage             

overall  we can confidently classify pre training and
post training data with a great deal of accuracy  with
prediction rates averaging      we can also make
other observations from the figures  the top figure
shows that the disjoint set b does not change as we
proceed in the rfe process  which leads us to believe
that generalizing outside an individuals data remains
very difficult with the number of samples we have
for the study  the bottom figure shows the effect of
filtering on the prediction rate and demonstrates that
filtering is a key part to getting quality data 

    cox  david and robert savoy  functional magnetic resonance imaging
 fmri  brain reading  detecting and classifying distributed patterns
of fmri activity in human visual cortex  neuroimage  doi         s                    
    wellcome
trust
center
for
neuroimaging 
http   www fil ion ucl ac uk spm software spm   
statistical
parametric mapping  ucl institute of neurology  dec       

    m  grant and s  boyd  cvx  matlab software for disciplined convex
programming  web page and software   http   stanford edu  boyd cvx 
june      

 

fi