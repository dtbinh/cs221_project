cs     machine learning project final writeup
force feedback learning applied to robot object handling
cason male
the purpose of my machine learning project was to apply learning algorithms to a robotic hand 
in order to better hold and pick up various objects  my project was part of stair or the stanford
artificial intelligence robot whose next goal is to clean off a cluttered desk filled with objects the robot
has never seen before  my project for machine learning was to use the existing stair software and
hardware to implement force feedback control in the fingers of the robot  more specifically  my project
focused on the classification problem of detecting when the robot was actually touching an object and
when it wasnt  i worked with quoc le who helped guide me through this specific project task 
at first i didnt believe that applying learning algorithms would be necessary to solve the task 
that adding resistive force sensors to the fingertips of the robot would be enough to detect when the
finger is touching an object and when it is not  the problem occurs from the elastic hysteresis property
of the skin of the fingertip  the skin is an outer covering on the finger that transfers external forces to
the underlying sensors within the finger  the elastic nature of
the skin causes hysteresis when a force is loaded and
unloaded to the finger  elastic hysteresis means that the
deformation of the skin is not consistent when loading and
unloading a force  the material requires less force to deform
the same amount when unloading as compared to loading 
this means there is a period of time when the load is
removed  the material remains deformed and slowly comes
back to its original shape  what this means for the project is
that although a load is removed from the finger skin  the skin
remains deformed for some time after and so triggers the
touch sensors beneath it  without learning  unloading causes
figure    elastic hysteresis
the sensors to detect a touch even though the load from the
object had already been removed  the only way to solve this problem was by optimizing the mechanical
design and using learning algorithms to train the finger to know what a real touch is 
the first half of my machine learning project was focused on perfecting the mechanical design 
the fingertip design was a long process but proved to be time well spent to make learning process
easier  results from testing the force feedback in the sensors relies heavily on the design of the finger
and finger skin which can be optimized to make it easier for the learning algorithm to find better
solutions for touch and slippage when grasping objects  the model used in previous attempts to make a
robot finger i slightly modified for the project but the basics are the same  it is important for the design
to expose the sensors directly to the skin in a way that outside forces will be directed towards the
underlying force sensors  in this way the surface that can detect contact should be maximized  it was

fivery important to keep the three sensors secured to the base of the finger directly without any elastic
material between them and the finger model which was used before i began work on the finger 
most of my work on the mechanical design was for skin fabrication for the fingers of the robotic
hand  many different materials were tested for the finger in order to find the right one for the
application  i got to test and fabricate skins in the mechanical
engineering lab with the help of barrett hyneman and john
ulmen from mark cutkoskys lab  the previously used material
for earlier iterations of the finger skin was not strong enough to
last many cycles of picking up small objects or even fewer cycles
for heavier objects  the final material used is a tap silicone rtv
which is durable while providing a reasonable amount of force
transmission to the underlying sensors  the biggest problem in
figure    finger skin
fabricating the skins was actually getting a smooth cast without
any air bubbles  many different techniques were used in order to create a decent cast for testing 
modifications were also made to the fingertip mold itself to improve the skin shape  the previous
model has a groove in the top for the skin to slip into as a way to provide a good fit on the finger without
using any kind of adhesives  however  the grove in the
finger and the notch in the skin were not compatible  to
fix this  the groove made for the mold was removed so the
skin is flat along the finger model everywhere except of
course in the sensor region which has three pads made to
contact with the force sensors 
one of the other major problems with the original
fingertip design was the attachment of the sensors  some
sort of adhesive tack was used previously which provides
many potential errors for sensor feedback  since the
material was compliant  it acted as a cushion between
each sensor and the finger model itself  this is not a good
design since it brings a damping effect into the sensor
reading  making it harder to collect real data that reflects
the force acting on it  instead  the tack was removed and
each sensor was trimmed and super glued directly to the figure    finger and sensors
finger model  with a hard surface behind each sensor 
force readings will be much more accurate since each sensor now takes on the direct force applied to
the skin without compliance 
once the mechanical design was robust enough and optimally designed for testing  sample data
was needed for the learning algorithm to train on  data collection was made by the phidget usb input
data device which was directly connected to each of the finger sensors  the phidget has the capability
of collecting data from up to eight sensors but for my project  only three were needed for the finger  to

ficlassify the binomial distribution of the data  support vector machines were the optimal choice using a
linear kernel  data was collected for the svm by recording data sets that were pre labeled to be a touch
or no touch  to do this  i told the program that the data collected in the next x hours would have the
touch label which is    i would then press on the finger pad for a number of hours while data was
collected  i repeated the process again for no touch label    where i let the program record force
sensor values in the finger for a number of hours without the finger having any external loads applied to
it  this process took a number of iterations to collect adequate data for the svm to learn properly 
after the first iteration i tested the svm which drew the boundary so that soft touches were not being
detected by the finger  to fix this i recorded more touch data  this time making sure i gently pressed
the surface of the finger skin  after enough iterations of data collection the svm was able to find a
proper boundary to distinguish a real touch from a false one 
integration of the svm algorithm into the existing robot controller was the next task  the touch
function i created in c initializes the phidget data hardware then reads in the touch sensor values which
are then evaluated in the svm algorithm  the values are then multiplied as an inner product with the
generated svm parameters  tx with an intercept value of    if the resulting value is greater than zero
than the function returns a touch  otherwise if the resulting value is less than zero  a no touch is
returned  this function had to be written in c to use the phidget c libraries but the arm control program
is written in python  in order to get these programs to communicate  i used the simplified wrapper and
interface generator  which simply wraps the touch function as a python module to be used in the robot
control code  the program is able to constantly loop and check for a touch event from the finger in real
time 
currently the control code monitors a single
finger  since i was only able to fabricate one new finger
for testing  the code does work well for the single finger
and successfully reacts to the feedback in the finger tip
when grasping objects  before my work  the robot
simply grasped its hand around an object until the
motors could not clench the fingers any further  this has
the potential for many problems  and from a mechanical
standpoint  working the motors in this way is not good
for the arm  after my feedback integration was
implemented  the robot now stops closing its hand once figure    hand gripping a mug with force feedback
a touch is detected by the finger  the other big fix due to
the force feedback in the fingers is slip detection of an object from the robots hand  previously  if the
robot grabbed an object and moved it to a new location  there was no way to detect if the object had
slipped out of the hand during the transition  the finger sensors now prevent against this and similar
problems since the robot can detect in real time if it is grasping an object or not 
the results of the first force feedback finger sensor were successful but there is a lot of potential
for this new application and much room for improvement which i would like to pursue in the next
quarters  one of these improvements would be to tweak the mechanical design of the finger and skin to

fimake a greater touch surface along the whole finger  although the current version works  sensing is
directed only along the top of finger and not along the sides  side sensors will be critical for slip
detection which is a huge area of potential for the finger sensing application  it is quite possible to get
the robot to learn how to adjust for object slippage on the transition to prevent objects from falling  for
instance  when sensors read a particular value  the robot should learn to reorient its hand or grab the
object tighter  i also plan to build two more fingers to complete the hand  once three fingers are in
place  the controller will be adjusted to monitor each finger individually  in the future when the hand
closes  each finger will stop when it detects its own touch and adjust as the object shifts within the grasp
during movement  the last part will be to integrate this with the path planning and object recognition
projects being currently worked on  i thoroughly enjoyed working on this project due to my passion for
robotics and getting a chance to apply machine learning from class  coming from carnegie mellon with
a desire to continue my robotics studies at stanford  it was a pleasure and privilege to be able to work
with the famous stair robot and learn the fundamentals of machine learning in cs    

fi