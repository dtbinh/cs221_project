automatic graph classification
brian lukoff

 

motivation

in educational measurement  the objective is to
measure some unknown latent variable or variables
that represent a students underlying ability or abilities in a subject domain  the first step in this process is to collect observable data from the student
that will provide a window into these latent variables  typically  this takes the form of a students
response to a test question  usually called a test
item   multiple choice has proven to be the most
popular item format for large scale assessments because of the ease of automatically scoring student
responses  however  multiple choice items provide
only a limited view into a students knowledge and
understanding  and the proliferation of test prep
companies shows that multiple choice items can be
easily gamed 
because of these weaknesses  an ongoing avenue of research in educational measurement focuses on richer environments for assessing student
knowledge  such as questions that ask students to
highlight a phrase in text  drag items into the
proper place in the periodic table  and create concept maps  zenisky   sireci         but many of
these methods are simply glorified multiple choice
questionsthey do not provide a truly open environment for students to produce responses  when
it comes to scoring open ended responses  the educational testing service has made progress with
a trio of projects  the e rater and c rater projects
score essays and natural language responses  attali
  burstein        leacock   chodorow         and
the m rater project scores equations and graphs
 livingston        
it is this latter problemthe problem of scoring a students graphical response to a mathematics questionthat we will examine in this paper 
a weakness of the m rater system is that it asks
a student to generate a graph using a proprietary
graphing tool  and then it tests the correctness of
the graph by converting the graph to an equation
or testing points  livingston         an arguably
 e mail 

brian lukoff stanford edu

more natural question to ask a student is to sketch
the solution to a problem  such sketches are faster
for the student to produce  doesnt require them to
use an unfamiliar tool  and allows for a broad range
of items to be asked  perhaps more importantly  it
allows for items with multiple correct responses 
traditionally  free response graphical items on
large scale assessments were scored by hand using
human raters  this of course limits the amount and
degree to which they can be used  and also introduces interrater unreliability as a source of error in
student scores  an automated system would allow
free response items to be introduced and used more
widely  and might potentially help improve the reliability of item scoring 

 

problem statement

in this paper  we will attempt to build a system
that is able to score the following items 
problem    multiple correct responses 
sketch the graph of a quadratic function 
problem    single correct response  a car is
on a track that stretches from y     meters to
y       meters  and at y       meters there is a
brick wall  at time    it starts at y      drives at a
constant speed  and after   seconds it hits the brick
wall  for the next   seconds the car doesnt move
after crashing into the brick wall  sketch a graph of
position  y  vs time that illustrates the position of
the car over time 
note that question   has many correct responses 
any sketch that roughly corresponds to a graph
of a function of the form f  x    ax   bx c  a     
should be considered correct  in contrast  question
  has a single correct answer  the only correct responses are sketches that roughly correspond to
a graph of the function
 
   x  if    x   
g x   
   
    
if    x     
in both items  it is the definition of roughly that
leads to interrater unreliability when these items

fiare scored by humans  a student drawing with the
mouse on a computer screen will never sketch a
graph that exactly follows a simple function  human raters must decode whether it is a shaky hand
or a shaky understanding of the underlying mathematics concept that is driving a response that is
not unequivocally correct 
thus  the machine learning problem is the following  given an image of a students response to one of
these two items  make a binary  right wrong  classification of the correctness of the response that lines
up with human raters  as much as possible   we will
evaluate the quality of the hypothesis h generated
by each algorithm by using the error rate either on
a separate test set or estimated using leave one out
cross validation 

 
   

data sets and features
problem  

for problem    i generated simulated data consisting of m   graphs each of simulated sketches of linear  quadratic  and cubic functions  leading to training and test sets that were each of size m  each
simulated sketch of a polynomial of degree d  d 
           consisted of a plot of the function s x   
pd
i
i   ai x    in the window  m  m     m  m  
where a            ad  uniform  m          m    and
the noise variable   n            for the quadratic
or cubic sketches  sketches where  s m      m or
 s m      m were discarded and the parameters
reselected  because such a function s cannot be completely graphed in the graphing window  for these
experiments  i set        and m      the choice
of m is arbitrary  but there is no reason to believe
that any other value would make the simulation any
more or less realistic  and the choice of  is a subjective choice that gives what seems to be a realistic
shakiness in each curve  i generated m       
simulated responses for both the training and test
sets 
to derive the features of the classifier  i first
scaled the          pixel images down to a       
pixel image  where the  i  j  pixel in the smaller image consists of the sum of the grayscale values in the
box      in d   i     n d        jn d   j     n d  
each of the grayscale values of the           pixels
  the somewhat odd choice of distribution for the coefficients  ai   is because i wanted to avoid degenerate quadratic
or cubic functions where the term of the quadratic or cubic
term was near zero 

in the smaller image was used as a feature 

   

problem  

for problem    i collected real samples of humangenerated responses to the problem  using mechanical turk  m      subjects participated by reading
the problem statement and then sketching a solution with their mouse using a system based on an
existing javascript based painting solution  vock 
       a subjects solution was saved in png format and then imported into matlab for analysis 
subjects were paid a token amount for their participation  but were informed that they were paid
for their effort and not for the correctness of their
solutions 
i manually scored each participants response on
a binary  right wrong  scale  and trained an svm
classifier using these labels 
in addition to using the        pixels of the
shrunken image as features  an additional feature
extracted from the data for this problem was the
number of soft matches between pixels on the
shrunken       pixel version  response image and
a canonical correct solution generated by mechanically plotting the function given in equation     and
then reducing that image to      pixels   in other
words  this feature is the number of the     pixels
where the  scaled down  student response are both
nonwhite  i e   grayscale value    
a final feature for this problem was the number
of soft matches between the left and right halves of
the response image and each of two partial solutions that consist of the one of the two components
of the correct solution image  the diagonal line representing the car traveling at a constant speed and
the horizontal line representing the car after it has
hit the wall  

 

methodology

because of previous success using support vector
machines to solve the problem of handwriting recognition  lecun  bottou  bengio    haffner        
and because of the conceptual similarity between
handwriting recognition and the problem considered here  i elected to use svm to build the classifiers  svmlight  joachims        was used to train
and test the models 
i compared the following sets of classifiers 
  note

that this is not a feasible feature for problem   because in that problem there was no single correct response 

fifeatures
baseline
pixels only
pixels only
pixels and correct solution
pixels and correct solution
pixels  correct solution  partial solutions
pixels  correct solution  partial solutions
pixels and correct solution
pixels and correct solution

kernel

augmented 

linear
polynomial
linear
polynomial
linear
polynomial
linear
polynomial

no
no
no
no
no
no
yes
yes

p   quadratic function 
   
   
    

p   car position 
   
   
   
   
   
   
   
   
   

figure    experimental results
 a baseline classifier that consisted of predicting
the most frequent class for every training case 
 a svm with a linear kernel  setting c     
 a svm with a polynomial kernel  setting c  
  and d      i e   a quadratic kernel  
for p   a separate test set of m        cases was
used to estimate error  for p   since the training
set was so small to begin with  leave one out crossvalidation was used to estimate error 
for p   an augmented training set of    additional training casesthe correct solution and   
almost correct responses consisting of two almostcorrect line segments    was also used in some experiments  these additional training cases were
not left out in the leave one out cross validation  to
avoid inflating the estimated error 

 

results

figure   shows the results of the experiments  the
current results are very encouraging  in problem
   svm with a quadratic kernel classified all but
one of the      test cases correctly  unsurprisingly 
the results were not quite as good in problem   
there were fewer test cases  m      for p  versus
m        for p    and of course in p  the test cases
were generated through simulation and not actual
student responses  as they were in p   
given that there were only    cases in the entire data set for p   and the best svm  pixels
and correct solution used as features  polynomial
kernel  no augmentation of training set  classified
  in

other words  drawing two connected line segments 
but with slopes slightly different than the correct slopes of
    and   

            of the cases correctly  it is interesting to examine the   cases that the svm classified
incorrectly  figure   shows the four responses that
were classified incorrectly  there seem to be three
problems with the classifier 
   cases    and    have the first part  the
upward sloping line segment  correct  but these
participants neglected to add the second part
of the graph  the horizontal line segment  
   case    was labelled as correct because the participants intentto draw a horizontal line segment from t     to t     is clear  to a human grader  its clear that they simply didnt
consistently hold the mouse button down the
entire time as they were drawing the segment 
however  the svm seems to be relying on those
missing pixels and mistakenly classifies this
case as incorrect 
   case    has the correct graphbut also extends the horizontal line segment to the left 
making the response clearly incorrect  in this
case  the svm may be marking it as correct
based on the fact that the correct graph is
essentially embedded inside the response as a
subgraph 
it is also interesting to note that beyond adding
the correct solution soft match feature  neither additional features nor the augmentation of the training set helped improve the cross validation error 
several points about this can be made 
   the sample size for p  was relatively small  any
additional improvement beyond the current results would be at risk of involving features that
are cherry picking the specific attributes of the

ficase     incorrect

case     correct

case     incorrect

case     incorrect

figure    p  responses that were classified incorrectly by the best classifier

training cases that failed to match  and thus
might not be generalizable 
   it is not necessarily the case that even two human raters would agree on      of the cases 
for items like these  raters might disagree on
how much sloppiness in the students response is acceptable  for example  how close to
t     the pivot from a slope of     to a slope
of   must be 
   the highest cross validation error estimate was
obtained by using as features only the pixels of
the shrunken image and a single additional feature  soft matches of the response image with
the correct solution   this is nice because it
suggests that this technique is likely generalizable to other types of test items that require a graphical response  e g   other types
of position vs time car scenarios like the one
used here  due to the fact that there was no
fine tuning of the features for the particular
problem used 

 

limitations and future work

the results here point to potential applications of
this technique to using graphical response items in
computer based testing  however  there are a number of areas where future work is needed before such
items could be used in an operational setting  first 
more work is needed to see whether these results

generalize to different kinds of items  in this study
we presented two different items and found that an
svm performed well in either case  but the universe
of possible graphical response items is of course
much larger and so it is necessary to see whether
the technique generalizes 
a future study with a larger data set might investigate whether there are other features that would
further reduce generalization error  although it is
encouraging that in p  one of the classifiers attained
only    error in cross validation  a larger training set might contain other patterns of incorrectness  not seen in the small data set used here  that
might require additional features to correctly classify  similarly  although in p  the cross validation
error was quite low  the data set consisted only
of computer generated sketches of random linear 
quadratic  and cubic functions  if p  were presented
in a real test taking environment  some students
would inevitably respond by sketching graphs of
higher order polynomials  non polynomials  or even
non functions  the only way to test this would be
to gather large data sets of actual student responses
to train a  potentially more complex  model 
finally  one general limitation of this technique is
that it requires a training set of human scored data 
compare this to a typical multiple choice question 
which can be asked of students and scored automatically simply by supplying the scoring algorithm
with the correct answer  in practice  though  for a
variety of reasons  test items that appear on large
standardized tests are always rigorously pretested
on a relatively large group of students before making it onto a real test  the response images from
these pretests could be manually scored by human
raters and then used to train a svm for scoring the
item operationally 

references
attali  y     burstein  j          automated essay
scoring with e rater v    journal of technology  learning  and assessment             
holland  p     wainer  h          differential item
functioning  lawrence erlbaum 
joachims  t 
       
making large scale
svm learning practical  advances in kernel methods support vector learning  mit
press 
  for

example  looking for differential item functioning
 holland   wainer        

fileacock  c     chodorow  m          c rater 
automated scoring of short answer questions 
computers and the humanities             
    
lecun  y   bottou  l   bengio  y     haffner  p 
       november   gradient based learning
applied to document recognition  proceedings
of the ieee                      
livingston  s  a         september   constructedresponse test questions  why we use them 
how we score them  ets r d connections 
    
vock  r          ajax paint  http   smir
 andaloria de ajaxpaint  
zenisky  a     sireci  s          technological innovations in large scale assessment  applied
measurement in education                 

fi