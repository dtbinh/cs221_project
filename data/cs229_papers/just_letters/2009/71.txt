cs   
supervised entity and relation extraction
andrey gusev and mason smith
abstract
we present a system for extracting entities and relations from documents  given a natural text
document  identify and classify entities mentioned in the document  e g  people  locations  etc   and
relations between these entities  e g  person x lives in location y   we designed separate systems for
relation extraction given already labeled entities  and for entity extraction from plain text  and then
combined the two systems in a pipeline  we ran our system on a small set of sports articles and two
larger sets containing biomedical and newswire articles  both entity extraction and relation extraction
are trained in a supervised manner using annotations in the datasets  for entity extraction these
annotations allow us to train a conditional random field sequence classifier by matching annotated
types to part of speech parse trees that are built from the text  for relation extraction we ran logistic
regression using a set of syntactic and surface features of the sentence data  we evaluated the utility
of these features using forward search feature selection  and we also separately evaluated the
contribution of the syntactic features by running the system using surface features alone  as a result
the pipeline achieved an f  score of      on the small sports articles dataset and      on the larger
newswire article dataset  we present and discuss results from individual subsystem on these sets 
the discussed system is in java and comprises roughly    classes implemented for this project  this
system is integrated into stanford s javanlp infrastructure  is fully extensible and can be used as a
basis for more advanced entity and relation extraction systems 
the problem
we worked on the problem of entity and relation extraction for three datasets  the  football  
 newswire   and  bionlp  datasets  each dataset consists of a set of sentences  a set of entity types 
a set of relation types  and  for each sentence  annotations specifying the sentence s entities and
relations  the task was to reproduce the correct annotations  information on each dataset is shown in
table   
entity extraction subsystem
overview
there are three major components of the implementation for entity extraction subsystem  the first
component is parsing of the dataset to create a logical representation of annotated entities and the
relationships they describe  this component is shared with the relation extraction subsystem  the
next component is using a lexicalized parser to annotate sentences with part of speech tags  finally 
the last part of the implementation trains the model and runs the classifier on the test set  depending
on the dataset we either perform k fold cross validation or use explicit test and training datasets  the
parsing is dataset dependent and is not discussed in detail here  as an example we present the
format for the football dataset  where  arg type  refers to annotated entities and  relation type  refers
to relations that depends on an entities 
 relation type  gamedate  start       end       
by winning the national football league  nfl  playoff game  the   ers will host the winner of sunday s dallasgreen bay game on january    to decide a berth in the january    championship game at miami 
 arg type  nflplayoffgame  start       end       the january    championship game at miami  arg 
  relation 

part of speech annotation is done using a lexicalized parser  from the stanford javanlp library  that
attaches part of speech tags to each word in a sentence  these annotations are types such as np noun phrase  vp   verb phrase  pp   propositional phrase  etc  as can be observed in the example
above a lot of entity annotations are multi term annotations  in order to train our classifier we need
annotated single terms   thus for each multi term annotation we find its head word  we first try to
parse the entire sentence and then obtain a parse tree for the argument sub phrase  this approach

fidataset name

football

newswire
however  franca

san francisco s reign over the national
sample sentence

football league ended here saturday
with a    to    loss to green bay 

chlistovsky  who heads
the brera metereologic
institute in milan  said this
winter s dry spell was not
exceptional   

entity types

date  finalscore  nflplayoffgame 
nflgame  nflteam
gamedate nflgame date 
gameloser nflgame nflteam 

relation types

gamewinner nflgame nflteam 
teamscoringall nflgame finalscore 
teamingame nflteam nflplayoffgame 
teamfinalscore nflteam finalscore 

org  location  people

bionlp
leukotriene b  stimulates
c fos and c jun gene
transcription and ap  
binding activity in human
monocytes 

protein

kill peop peop 
workfor peop org 
locatedin loc loc 
orgbasedin org loc 

n a   relations not
extracted for this dataset

workfor peop org 

total number of
sentences

  

    

     

 testing training 
newswire from trec
data source

use case for darpa machine reading

corpus  with annotations

program  newswire with annotations by

by cognitive computation

linguistics data consortium at u  penn 

group at uiuc  used in

bionlp    shared task
 kim et al      

 roth   yih       
table    datasets used for entity and relation extraction

works a lot of times but in several cases  to be discussed in error analysis section  it fails to find the
appropriate subtree for given relation argument  since the goal is to find the head word of the
argument we use the fallback method of parsing the argument directly  the drawback of this method
is that parsing only the sub phrase may miss some phrasal context necessary to find the correct head
word  however  this method allows us to find the head word for all arguments  head word finding is
done by using an implementation of the head finder found in michael collins       thesis  below is an
example of an annotated sentence after argument head word identification  used for training the
conditional random fields sequence classifier  each position in a sentence is annotated with a word  a
part of speech tag and an entity type annotation 
  ron nnp   dixon nnp   s pos     cd  to to  yard cd  kickoff nn  return nn  provided vbd  the dt  giants nnps
nflteam    pos  only jj  points nns  in in  baltimore nnp nflteam   s pos     cd finalscore  to to    cd
finalscore  rout nn nflgame        

after all the sentences have been annotated we proceed with testing  due to the very small size of the
football dataset we proceed with    fold cross validation on that set  on bionlp and newswire sets
we have explicit training and test datasets  we build the model using the existing implementation of a
conditional random field classifier in javanlp library  during testing we use the classifier to
annotate entity types on sentences that only have part of speech annotations set  the results are
presented tables  a  c 
discussion error analysis
in this section we discuss results for the entity tagging problem  we also briefly consider some
reasons why part of speech parsing sometimes failed to find the subtree for an argument  first
looking at results we should notice that the football dataset provided is very small   there are about   
entities tagged per file and there are a total of    files  for each k fold test run we had    sentences
to train and   sentences as a test set   this is usually not enough to train a classifier accurately  the

fimost direct impact of lack of data can be seen in the nflplayoffgame class which appeared only  
times in the dataset  too few to correctly learn a hypothesis  on the other hand we can notice very
high rates for the finalscore class   this is expected since this class is very easy to learn  all of the
arguments are numeric and are usually preceded by either  to  or words such as  loss    win  
 victory   etc  we also introduced a gazetteer feature into the classifier for nflteam class  more
precisely we have enumerated a set of possible nfl teams  and added features to the classifier
based on that ontology  this increased the f  score from       to        finally we used a welltuned ner classifier from the javanlp library to identify dates  the results on bionlp do not suffer
from the small data set problems we observed above  although we only need to tag one entity type
which simplifies the problem  the protein entity type ontology is very rich  furthermore  it is very
content dependent   for example the term  il    tagged as nn part of speech can be either protein or
not protein depending on the sentence structure  such subtle differences were not found in football
dataset  therefore we found the resulting f  score of       to be encouraging  we also obtained very
high accuracy on all objects in the newswire dataset  we were surprised by the these results and
found that mutual information in training and test sets could be the cause of these high results  for
example a particular person s name can be present in both training and test sentences because both
were sampled from the same domain of articles  we would like to investigate this further  looking at
all datasets another potential source of errors is incorrect identification of the argument head word
due to inability to match the argument to some subtree in the parse tree  in these cases we had to
parse the argument directly which was more error prone for identifying the head word  no matching
subtree is found for an argument when there is no node in the parse tree which dominates exactly the
tree leaves spanned by the argument  some reasons why this can happen are  pp attachment
error  np parse error  tokenization  data error  possesive attachment  pp attachment implies that a
prepositional phrase was attached to the wrong node  this is similar to an obvious np parse error but
more subtle  tokenization means that the tokenizer used by javanlp made a mistake in tokenizing
the sentence datum  for a particular run of cross validation on the football dataset we were able to
match     arguments directly from the full sentence tree and    times by parsing arguments 
results
table b  newswire dataset

table a  football dataset
actual

retrieved

precision

recall

finalscore

  

  

     

     

     

date

  

  

     

     

     

 

 

     

     

     

nflplayoffgame

nflgame

  

  

     

     

     

nflteam

  

  

     

     

     

     
overall 

   

   

actual

f 

     

     

retrieved precision

recall

f 
     

loc

    

    

     

     

org

    

    

     

           

peop

    

    

     

     

     

overall       

     

     

     

     

   miscellaneous  category omitted from this table
table c  bionlp dataset
actual retrieved precision recall

f 

protein      

     

     

     

     

overall      

     

     

     

     

  extremely rate category  teamfinalscore  omitted from this table

relation extraction subsystem
we approach relation extraction as a supervised classification problem  each training datum is a pair
of entities from a sentence  labeled with the entities  relation type  which may be  no relation    for
testing  the system produces the labels for pairs of entities from test set sentences  the relation
extraction system was tested on entities identified in the annotated datasets  the  gold standard   as
well as on entities pipelined from the entity extraction system  logistic regression with l 
regularization was used for classification 

fifeature generation
we initially generated    feature types for the entity pairs  based on the words before  between and
after the entities   surface features    as well as the syntactic relations between the entities  the
syntactic features included features based on each sentence s parse tree  the path between the
entities in the tree and the path length  as well as features based on the path between the entities in
the graph of syntactic dependency relations in the sentence  relations such as subject  verb 
modifier  noun  these features included the relations along the path  the words along the path 
relations between the entities and verbs along the path  and path length   surface features included
windows of one  two  and three words before and after the entities  the part of speech  pos  tags of
words in these windows  the path of words between the entities  the pos tags of these words  the
distance between the words in the sentence  the pos tags of the entities  and the entity words
themselves  most of these feature types consisted of binary features  while the path length   distance
features were represented both as real valued features and as binary features with a feature for each
integer path length 
feature selection and system testing
to evaluate the utility of these features we implemented forward search feature selection  evaluating
the features using    fold cross validation on the newswire training set with gold standard annotated
entities   time constraints precluded evaluation using pipelined entities   interestingly  we found that
only seven features were required to achieve plateau performance  the selected features are listed
in table  a  the classifier was then trained using these features and tested on a held out set of
newswire sentences  one tenth of the dataset   we also implemented forward search feature
selection excluding syntax based features to generate a set of seven surface features  listed in table
 b  we used the same two sets of features for the football dataset  for that dataset we tested using
   fold cross validation  relation extraction was not implemented for the bionlp dataset  which has
a more complicated set of non binary relations  
surface and syntactic features
entity words

giants  rout

entity types

nflteam  nflgame

relations in dependency graph path between entities

poss   comp     prep in

words in dependency graph path

points provided

surface distance  binary features

surface distance  

surface path between entities  part of speech tags

pos jj nns in nnp pos cd to cd

length of parse tree path between entities  binary features

path length  

surface features only
entity words

giants  rout

entity types

nflteam  nflgame

surface path between entities  part of speech tags

pos jj nns in nnp pos cd to cd

surface distance  binary features

surface distance  

surface windows part of speech conjunctive

vbd dt  to cd  pos jj  null null

entity order

entity  before entity 

entity part of speech tags

nnps  nn

tables  a and  b  features used for relation extraction 
right column shows features of each type generated for the word pair   giants   rout   in the sentence  ron
dixon s    yard kickoff provided the giants  only points in baltimore s    to   rout   from the football dataset 

firesults and discussion
results from testing the system on the football and newswire datasets are displayed in figure    we
found that using surface features alone does give worse performance than using syntanctic features 
but not much worse  using entities from the pipeline rather than the gold standard had relatively little
impact on performance for the newswire dataset  where entity extraction was nearly perfect  but a
large impact on performance for the football dataset  where entity extraction was much more
unreliable  on the newswire dataset the combined pipeline system performed as well as the joint
entity and relation extraction system of  roth   yih        
one possible area for future improvement in our system is feature sparsity  for example  for     of
the relations annotated in the newswire test set  the dependency graph path between the relation s
arguments  i e  the third selected feature in table  a  appeared no more than once in the training set 
the f  score for relations whose dependency graph path feature was sparse in this sense was      
compared to      for relations with non sparse dependency graph path features  sparsity was also
observed for some potentially useful features which were eliminated in feature selection  e g  parse
tree path   future work could address feature sparsity by     using semi supervised approaches to
increase the quantity of data  or     learning higher level representations of features which could
generalize to features not seen before by the system  along the lines of  bengio et al         

figure    performance of relation extraction system 
different colors show feature set   entity annotation 

acknowledgements
we were advised on this project by chris manning and mihai surdeanu 
references
yoshua bengio  rejean ducharme  pacal vincent  and christian jauvin   a neural
probabilistic language model   journal of machine learning research              
     
jin dong kim  tomoko ohta  sampo pyysalo  yoshinobu kano  and junichi tsujii 
 overview of bionlp   shared task on event extraction   in proceedings of the naaclhlt      workshop on natural language processing in biomedicine  bionlp          
d  roth and w  yih   a linear programming formulation for global inference in natural
language tasks  conll     may      

fi