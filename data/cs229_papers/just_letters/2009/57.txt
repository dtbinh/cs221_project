applying machine learning in game ai design
yanzhu du  shisheng cui  and stephen guo
we developed a reinforcement learning mdp agent and a genetic programming learning agent to play the
game super mario bros  our results compare favorably with the current state of the art agents for this
game  in particular  our genetic programming agent would be the top performing learning ai agent in the
     ai mario competition 

introduction
electronic games are a pervasive part of the lives of many people around the world  in recent years  an
increasing number of scientists and institutions have been devoting their time to the study of artificial
intelligence in computer games 
one of the major factors for the fun and re playability of computer games is a good artificial intelligence
agent  developing competent ai agents by hand is a difficult and time consuming task  although ai has
been applied successfully in some games  most games do not contain true ai  as they utilize pre defined
scripts to simulate artificial intelligence 
we tackle the problem of developing an ai agent to play games  in particular  we consider the  d
side scrolling platform game super mario bros  the particular implementation that we use is an open
source java implementation from an annual international ai mario competition     

description
the agents objective is defined to be the progress through as many levels in the game as possible without
dying  this is measured by a mario game score  lesser objectives include collecting coins and defeating
enemies 
in our specific mario platform     times per second  the agent is given a       observation window of the
discrete cells around the agent  note that in the game physics engine  object coordinates have much finer
resolution  therefore  for object coordinates given to the agent  discretization is necessary 
in each of these     squares  the agent may observe one of the following 







bricks  stationary obstacle  may release coins or power ups if hit by large mario 
borders  stationary obstacle  mario cannot pass through borders 
hills  stationary obstacle  mario can jump up through a hill  but cannot pass down 
flower pots  pipes   stationary obstacle  enemy flowers appear periodically from pipes 
cannons  towers   stationary obstacle  cannons periodically shoot out flying bullets 
enemies  goombas  koopas  and their winged and spiky varieties 

in each discrete square  there are   terrain cell types and   enemy types  the state space of this problem
is        this space is of a size such that complete search is computationally intractable 

fiapproach
currently  the most successful agents for this mario game are agents which reproduce the game physics
and perform a  search through the       window  these approaches are domain specific  utilize external
information  and are not extendable to other games 
in choosing our approach  we considered multiple online and reinforcement learning techniques such as
online svms  online decision trees  mdps  pomdps and genetic programming  we ultimately chose to
implement a reinforcement learning mdp agent and a genetic programming agent which seemed to be
the learning methods most directly applicable to our problem  mdps provide a mathematical framework
for modeling decision making in situations where outcomes are partly random and partly under the
control of a decision maker  genetic programming is an evolutionary algorithm based
methodology inspired by biological evolution to find computer programs that perform a user defined
task 

method    mdp
features
to reduce the state space to a size computationally efficient to train  while also not giving up too much
information  we decompose marios observation window into the following features 


mario status  can mario jump  is mario on the ground  can mario throw a fireball 



two cells directly ahead and behind of mario



are there gaps in front of mario 



distance of enemies in front of mario

we also simplify cell types into the following four 
   passable cell    obstacles  bricks  borders  flower pots  cannons     half borders    enemies
our total feature space size is        keep in mind that our features are chosen to be expressive as
possible  while keeping the feature space size to be within the training abilities of our limited
computational resources 

actions
it is difficult to model the objective of moving forward efficiently using an mdp  therefore  we restrict
mario s actions to always move to the right  marios action space contains these four actions     right    
right fast     right jump     right fast jump 

reward function
in our mdp setup  we use a reward function of the form     a small penalty is given for jumping to
discourage random jumping  a small reward is given for being away from enemies and gaps  a large
penalty is given for touching the enemy 

fitransition probability function
though this game is mostly deterministic  due to limited visibility    x   window  and our feature
mapping  the feature space state transition is not deterministic  therefore  we must learn empirical
transition probabilities to estimate     

value function
in our training routine  we utilize a form of asynchronous value iteration to converge toward the optimal
value function of the bellman equation  the update equation used during training is the following 
  max            




note that the states we consider are now feature states vectors in our feature space  not the original
game states  to train our value function  we run the mdp agent on many randomly generated levels and
collect statistics about      while updating  through the bellman equation 

action selection
   argmax            




after training  our mdp agent uses the computed value function v to define a policy   during game play 
when the agent is presented with a game state  the state is mapped into a feature vector  which is then
given to the policy  to determine the next action to take 

method    genetic programming
summary
objective

find program to control mario s jump action

program

tree based  strong typed

value type

boolean  integer  float

variable

observation variable from mario game  mario status has boolean type  cell type
has integer type  enemy position has float type 

function set

         protected division          on integer and float   type casting between
integer and float  boolean and  or  not  if statement

terminal set

variable  and random constants

fitness

multi objective  mario game score  number of actions

selection

sort fitness according to pareto dominance

initial pop

random initialization  depth          of terminals are constants

ficrossover

typed one point crossover

parameters

population size           sub tree crossover      reproduction      mutation 
no tree size limits

termination

   generations

program
we choose to implement a strong typed tree based gp  strong type may be beneficial as each type has
corresponding semantics  by allowing only type correct programs  we can limit the program space to
programs that at least make semantic sense  all crossover and mutation operations preserve the
type correctness of the tree  to simplify design  we also restrict the program to control mario s jump
action only  while by default mario will always be moving to the right 

fitness and selection
the fitness measure is multi objective  it aims to maximize mario game score while minimizing the
number of actions taken  individuals performances are sorted according to pareto dominance 

genetic programming results
we ran    batches of experiments  the best individual from the genetic programming is shown below 

overall results
after significant amount of training  we evaluated our agents using the same environment specified in the
mario ai competition        cig and compared our agents against the published results     
rank

name

algorithm

score

levels

time left

total
kills

mode

fi 

robin baumgarten

a 

       

  

    

   

  

spencer
schumann

rb h

       

 

    

  

  

our gp agent

gp

        

 

    

  

  

matthew erickson

ev  gp

       

 

    

  

  

mario prez

sm  lrs

       

 

    

   

  

our mdp agent

mdp

        

 

    

  

  

alexandru paler

nn  a 

      

 

    

  

  

   
 

 
   
  

  

our gp agent would be the top performing machine learning agent in the competition  as the top  
entries are all either a  search or rule based algorithms which reproduce game physics  our code is
available for demo upon request 

discussion
comparing our mdp agent to better performing agents  our agent differs in the fact it sometimes tries to
kill the enemy with a fireball  rather than evade the enemy  if the fireball attack fails  mario often will not
have enough time to avoid the enemy  this suboptimal behavior comes from the fact that our mdp agent
only has a coarse observation about enemies  so if it detects an enemy in the distance  but is not sure
about relative position  it will continue moving forward and throw a fireball to try to remove the enemy 
ideal behavior would be to move toward the enemy and jump over them when near 
our gp agent only controls whether mario jumps or not  its general behavior is to evade enemies at all
times  though it appears that the gp agent works well  the evolved logic is difficult to decipher  this is a
common problem with solutions obtained by genetic programming 
the ai mario competition is planned to be at several ai and electronic game conferences in       there
may be a new online learning track of the competition  in which a  and rulebased agents will be at a
disadvantage compared to learning agents  we are planning to submit our top agent into this
competition 

references
   togelius  sergey karakovskiy and julian  mario ai competition   online  in association with the ieee
consumer electronics society games innovation conference      and with the ieee symposium on
computational
intelligence
and
games 
 
   
     
 cited 
  
  
      
http   julian togelius com mariocompetition      
   riccardo poli  william b  langdon nicholas f  mcphee  a field guide to genetic programming  s l   
http   lulu com  march                         
   ieee consumer electronics society s games innovation conference call for participation in the mario
competition   online               cited               http   ice gic ieee cesoc org competitions html 

fi