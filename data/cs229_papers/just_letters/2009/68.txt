automatic recognition of satire in web content
michael abercrombie  mabercr stanford edu 
december         

  introduction
irony and satire can be useful weapons in any communicators rhetorical arsenal  they provide a
nuanced means for expressing critical sentiments and for openly exploring divisive subjects 
however  the very subtlety that grants these devices their utility also lends to their greatest
drawback  implied meanings are often lost on their intended audience  in textual communication
this difficulty is magnified by the absence of any non verbal queues that might imply a non literal
interpretation 
the goal of this project is to utilize machine learning strategies to develop a classifier for
recognizing satirical or sarcastic web articles  such content is  by definition  written to resemble
more sincere communication and may be unrecognizable as ironic without sufficient contextual
information  sperber and wilson         therefore  in an attempt to capture broader context  the
proposed classifier will rely not only on original article texts  but also upon user generated
comments associated with each article 

  preparation
this project was implemented almost entirely in python  using the beautiful soup library  for web
interfacing 

    data collection
to support the notion of leveraging user generated comments in article classification  example
articles were collected by searching for popular content on a selection of major social bookmarking
sites  initially  in hopes of creating a more representative sample of web content  these articles
were to be chosen regardless of source  filtered according to a simple rubric  e g  all content must
be text of a minimum length   and labeled as sincere or otherwise  however  this method was
shown to have three major limitations  first  implementing a generalized article extraction
algorithm of satisfactory performance proved untenable  at least for this novice to web scripting  
second  evaluating article sincerity during data collection necessarily required human interaction 
limiting the speed and accuracy for which articles could be collected  lastly  it was found that
satirical web content made up only a small percentage of texts collected in this way 
thus  in the interest of time and having a larger  more evenly weighted sample size  several
major web content sources  both satirical and otherwise  were identified as appropriate for use in
this project  and the article selection algorithm was implemented to choose only articles from these
 

http   www crummy com software beautifulsoup 

fisources  this facilitated article text extraction  as the online presentation of the selected articles
was limited to a manageable set of formats  moreover  this eliminated the need for manual
classification  as each chosen web content source was known to produce satire either exclusively or
not at all  the final data collection script yielded a total of      articles with an average of      
words in the article text and an average of        words in associated comments 

    feature extraction
to reduce initial feature set size  the collected example articles and comments were first subjected
to stemming via porters stemming algorithm  note that stop words were not removed prior to this
preprocessing step  such vocabulary is often ignored in classification applications as it does not
contribute significantly to the meaning of many texts  however  stop words could conceivably
reflect the style of a written example and  therefore  could be useful indicators of subtle rhetorical
properties  namely irony  thus these words were at least initially afforded consideration for use as
features  allowing for them to be removed as part of later feature reduction if needed 
stemmed words meeting a minimum frequency requirement were selected to form a
vocabulary  each training example was then converted to an array of features  where each feature
indicated the presence of a particular vocabulary word at a particular point in the examples text
 indexed by word   it should also be noted that the source of each word in the training examples 
either article text or user generated comment  was preserved so that words collected from
differing sources could be treated as separate features  this is justified in that some words may be
more indicative of satire when used by a commenter than when used by an articles author  and vice
versa  

  classification
two classifiers were used in this project  one relying on nave bayes and the other using a support
vector machine with a linear kernel  the nave bayes classifier was implemented from scratch in
python while the support vector machine implementation were provided by thorsten joachims
smv light   the minimum generalization error achieved with the nave bayes classifier was       
while for the support vector machine based classifier achieved        graphs for the learning rate
of each classifier are given on the following page 

 

http   svmlight joachims org 

ficlassifier learning rates
   

generalization error

    
   
    
   
    
   
    
 
   

   

   

   

   

   

    

    

training examples
nave bayes

support vector machine

    testing methods
in testing these classifiers  it is important to remember that the training examples in this project
were selected from an artificially limited set of content sources  because of this  the straightforward
approach of using leave k out validation where the left out samples are selected randomly  could
yield highly deceptive results  when using such a strategy  the source of any given article reserved
for a test set would almost certainly still be represented in the corresponding training set by other
articles from the same source  for example  if during one iteration of validation  five articles from
www theonion com were chosen for the test set  there would still be dozens of other onion
articles in the training set  a low test error in this case might simply indicate that the classifier has
learned to recognize articles from the onion rather than to recognize satire 
to arrive at an error rate that might reasonably be generalized to content sources beyond those
used in this project  a form of leave k out validation was used such that  in each iteration  the test
set would be comprised of all the articles drawn from a particular content source  incidentally  this
method of testing also provided an insightful breakdown of error rates associated with each source
 shown on the next page  

fi real  content
generalization error
   
    
   
    
   
    
   
    
 

satirical content
generalization error
 
   
   
   
   
   
   
   
   
   
 

nb
svm

note that both classification algorithms are heavily biased against classifying articles as satirical 
this is relatively unsurprising result given that the data collection phase found more viable content
on legitimate news sources than on their satirical counterparts  and both classifiers tend to favor the
best represented labels in a data set 

    feature reduction
for the nave bayes classifier  two methods of feature reduction were explored  one was to reduce
the number of words selected as features in the preprocessing phase  the other was to train the
classifier using the entire data set  and then remove features with the lowest mathematical bearing
on classification  surprisingly  the first method was much more effective at reducing the classifiers
generalization error  the second method was able to improve generalization error given a large
initial vocabulary  but quickly reached  and then retreated from  a high minimum  combining the
two methods did not result in any recognizable improvement 
a similar tuning was performed for the support vector machine classifier by adjusting the
tradeoff parameter  c  this was used in place of true feature reduction to reduce the variance of
the classifier 

  discussion
initial results with small data sets suggested that a nave bayes classifier might prove very effective
for recognizing satire in articles from certain sources  while wholly ineffective with articles from
others  however  as the data set  and in particular the set of content sources  was expanded  this
source by source variance was reduced  the somewhat promising early results are probably due to
the distinct similarities and dissimilarities between the particular content sources of the initial data

fiset  this draws attention to the need for drawing test data from a representative sample of sources
 a need which this project has undoubtedly yet to fully satisfy 
one unexpected finding of this project was that splitting individual words into separate features
based on whether they were found in the article text or user generated comments did not improve
performance for both classifiers  the choice to use such a feature mapping was based upon the
assumption that the language used by those employing satire would be different from that of those
responding to satire  this assumption was somewhat legitimized in that changing to the split word
mapping resulted in a small boost to support vector machine classification performance  however 
the same change caused a sizeable decrease in the effectiveness of the nave bayes classifier  the
cost of adding new features to the system apparently outweighed any reward 
overall  the data from this project does suggest that a classification algorithm could at least
assist in recognizing satirical web content  moreover the leveraging of user generated comments
does seem to be useful  as performance was found to be reduced for both classifiers when
comments were ignored  as the successful use of satire relies heavily upon context and subtlety 
methods that consider only whether a word was used and not how it is used may ultimately prove
incapable of driving a highly effective classifier  further research may need to explore more
advanced language processing methods 

references
    sperber  d     wilson  d          relevance  communication and cognition 
oxford  england  basil blackwell 

fi