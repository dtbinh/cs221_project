face tracking in video
hamidreza khazaei and pegah tootoonchi afshar
stanford university
    serra mall
stanford  ca        usa

i  i ntroduction
object tracking is a hot area of research  and has
many practical applications  these applications include
navigation  security  robotics  vehicular communications 
and etc  it has also found applications in biology  where
people are studying cells and mitosis  one of the biggest
applications of object tracking is being able to track a
face 
in a face tracking application  boosting and cascading
detectors have gained great popularity due to the their
efficiency in selecting features for faces  however these
detectors suffer from high miss classification rates  in
addition they depend on the orientation of the face  they
require that the face be in a full frontal position  if there
is any deviations from this position  the face is tilted by
   degrees  or the face turns to a profile position  the
adaboost fails to detect a face 
we will implement a face tracking algorithm  and
compare it to other well known tracking algorithm presented in the literature  specifically we will be enhancing
the adaboost algorithm  and comparing the resulting
system to one that uses adaboost only  there are three
components to our algorithm  image representation  appearance model  and motion model  image representation
is done using haar like features  these features are
calculated efficiently using integral image representation  which allows the computation of these features
to be done in constant time  once the features have
been attained the face detection is performed using two
classifiers  the adaboost algorithm creates a classifier by
combining a set of weak classifiers  the motion model
tracks the aspect ratio  and the center of the face that it

has detected 
the paper is organized as follows  section ii will
provide the necessary background and present a detailed
description of our model  and will provide the necessary
background information  section iv will present the
results  section v will serve as a conclusion  and will
discuss possible future works 
ii  background and s ystem m odel
a  haar features
the features used to represent the pictures are the haar
features that were originally proposed by papageorgiou
et al       there are three types of rectangular features
that can be computed  for example a two rectangular
feature can be computed by the difference between the
sum of two rectangular blocks  viola jones proposed
a fast method for computing these features making
the features an attractive option for face detection     
their method  which is called integral image and can
be calculated with one pass over the picture  uses an
intermediate array to store a running sum of pixel above
and to the left of the point x y 
x
ii x  y   
i   x    y     
   
x  x y   y

where ii x  y  is the integral image  and i   x  y  is
the original image  now using this representation for
the image any rectangular sum  and thus haar features 
can be computed efficiently  for example the rectangular
region d in figure   can be computed by ii     ii    
ii      ii    

fiis constructed by combining well performed weak classifiers  it is shown that the training error of the strong
classifier approaches zero exponentially in the number
of rounds      the adaboost algorithm is summarized
below 






 normalize the weights wt i   pwt i
j wt j
 train each classifier hj corresponding to feature fj   the weighted error with respect to wt
p
is j   i wi  hj  xi    yi  
 choose the classifier ht with the lowest error
t  
 update the weights  wt   i   wt i t ei   where
ei     if example is classified correctly and   
t
otherwise  and     
t

fig     demonstration of the way integral image is used to compute
the sum of pixels in a rectangle 

b  adaboost
the number of haar like features in each window is
much more than the number of pixels  and it is not possible to efficiently classify the image using all the features 
however  an effective classifiers can be created by using
only a small subset of these features  the algorithm
used in this work is the adaboost     algorithm which
extracts the essential features to create a well developed
classifier  the adaboost algorithm creates a classifier by
combining a set of weak classifiers  which are trained
on only one feature 
we can explain the algorithm in two steps  first  each
weak classifier optimizes its performance  i e  minimizes
the classification error over the training set  in this
application  a weak classifier has a feature  fi    threshold
 i   and a parity  pi    it tries to find the optimal threshold
that correctly classifies the maximum possible number of
examples  the parity is used to determine the direction
of inequality sign 

x
hj  x   
 

if pj fj  pj j
otherwise

after the first round of learning  a weight is assigned
to each training example  in the first round they were all
equally weighted   in the next step  a strong classifier

given training examples  xi  yi   where yi        for
negetive and positive examples respectively 
 
initialize weights w  i    m
   l  for yi       
respectively  where m and l are the number of
negative and positive examples respectively 
for t         t



the final strong classifier is

  p  h  x  
t t t
h x   
  otherwise

 
 

p

t t

c  background subtraction
given a frame sequence from a fixed camera 
detecting all the foreground objects is based on the
difference between the current frame and the stored
 and frequently updated   image of the background 
if

 f rameij
backgroundij  
f rameij is foreground
else
f rameij is background



t hreshouldij

the threshold was chosen proportional to the variance
of pixel values of the current frame  for a more complex
model each pixel could have a different threshold
based on its own gradual changes   after detecting the
foreground objects  the background image is updated as
follows 

fifig    

overview of the face tracking system 

and set its value to       
if f rameij is detected as background
backgroundij    f rameij      backgroundij
else
backgroundij   backgroundij
where  is the updating rate which was chosen
to be a small value  furthermore in order to eliminate
the noise from the subtracted foreground image we
used the common low pass filters in image processing
called dilation and erosion filters  dilation  in general 
increases the size of objects and erosion causes objects
to shrink in size  the amount and the way that they
affect the objects depend on their structuring elements 
to explain them simply  dilation take each binary object
pixel  value    and set all background pixels  value   
that are connected to it  determined by the structuring
element  to value    but erosion takes each binary object
pixel  value    which is connected to background pixels

d  overall model
in order to display the results the face tracking system
draws a rectangle around the region that it has recognized
to be a face  the system will maintain a set of parameters  which are the center  width  height and the aspect
ratio of the rectangle from the previous frame and the
current frame 
the system initializes when the adaboost classifier
detects the first instance of a face  and initialize all
the parameters of the system accordingly  in the next
frame the adaboost classifier will try to draw a rectangle
around the position of the face  if this classifier could
not find a face or if the rectangles parameters are
significantly different from the previous rectangle  then
the background subtraction algorithm that was describe
in section ii c will process the image  and remove the

fibackground  the system will then draw a number of
random rectangles  nrectangles   near the vicinity of the
previous center  within each rectangle the sum of the
pixels is calculated  and the rectangle with the maximum sum is selected  the parameters are then updated
using this rectangle  so they can be used in the next
frame  an overview of the entire system can be seen in
figurereffig systemmodel 
iii  e xperiment setup
a     x     video  with      frames was used
to test the system  as described in section ii d when
the parameters of the current rectangle are significantly
different from the parameters of the previous rectangle  the background subtraction algorithm is used  two
criterions were used to determine whether the previous
rectangle and the current rectangle are different  first 
the difference between the centers of the rectangles were
calculated  and if the difference was greater than ten
percent of the video width       in the x direction  and
ten percent of the video height       in the y direction 
then the two rectangles were classified as being significantly different  secondly  if the aspect ratio of the two
rectangles differ by more than ten percent  then the two
rectangles were classified as being significantly different 
the threshold  that was described in section ii c was
set to be sixty percent of the variance of the picture 
this threshold was selected to take into consideration
the change in lighting of each frame  and finally  the
nrectangles parameter described in section ii d was set
to ten 
iv  r esults
the face tracking system was tested using the experimental setup described above  and was compared
to a face tracking system that only uses an ada boost
classifier to track faces  the results are summarized in
table i  as it can be seen our face tracking system out
performed the ada boost face tracking system  we have
managed to reduce the errors from     frames to    
frames which is a significant number  it must be noted
that the results do not make a distinction between no

table i
table comparing the a da b oost algorithm   and the
algorithm describes by this paper

adaboost only
algorithm
proposed algorithm

number of frames
missed  total of      frames  
   

percent
missed
     

   

     

detection and a false positive detection  in other words
we consider a missed frame as either a false positive or
no detection 
v  c onclusions
the face tracking algorithm proposed by this paper
does very well  and it was shown that it can enhance
performance significantly  the only problem with this
algorithm is that it is slow  which means face tracking
cannot be done in real time  currently  the face tracking
system is implemented in mat lab  and reading in a
frame and processing it takes a long time  in order
to increase the speed of the system the algorithm can
be implemented in c    where reading and writing
files can be done with ease  another modification that
can be made  is to reduce the number of times the
adaboost classifier is used to detect the face  instead
of having the adaboost classifier look at each frame 
the algorithm could be modified so that it calls the
adaboost classifier every ten or twenty frames  these
implementation changes could be laid out in the future
to increase the speed of the face tracking algorithm 
r eferences
    c  papageorgiou  m  oren  and t  poggio  a general framework for object detection  international conference on computer vision       
    p  viola and m  jones  robust real time object detection 
second international workshop on statistical and computational theories of vision   modeling  learning  computing 
and sampling       
    yoav freund and robert e  schapire  a decision theoretic generalization of on line learning and an application to boosting 
in computational learning theory  eurocolt     pages      
springer verlag      

fi    r  cucchiara  c  grana  m  piccardi  and a  prati  detecting
moving objects  ghosts and shadows in video streams  ieee
trans  on patt  anal  and machine intell   vol      no      oct 
      pp            
    image processing fundamentals  delft university of technology 

fi