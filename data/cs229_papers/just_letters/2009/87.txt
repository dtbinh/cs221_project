supervised learning in genre classification
mohit rajani and luke ekkizogloy
 i mohit luke ekkizogloy  gmail com
stanford university  cs     machine learning      

introduction   motivation
now that music collections can easily exceed many thousands of songs  organization and
classification of these collections are more important than ever  song genre tends to be an
attribute that can help in selecting songs to play  however  in mp s the genre metadata tends to
be non present  it would be very useful to be able to determine genre by analyzing the music
directly  song genre tends to be quite subjective and genre tends to be applied in a general fashion
to an artist as a whole  it would be more advantageous to group songs together that had the same
timbre  a k a  shape or color of sound   the associated genre of music tends to be closely
associated with timbre and is not necessarily an attribute of the artist  we try to address the
problem of genre classification using only the audio content of a music file and techniques from
machine learning 

feature vectors and learning algorithms
mel frequency cepstrum coefficients  mfccs 
mfccs are a short time spectral decomposition of an audio signal that conveys the general
frequency characteristics important to human hearing  mfccs are commonly used in the field of
speech recognition  recent research    shows that mfccs are capable of capturing useful sound
characteristics of music files as well  our premise is that mfcc s contain enough information about
the timbre of a song to perform genre classification  to compute these features  a sound file is
subdivided into small frames of about    ms each and then mfccs are computed for each of these
frames  since the mfccs are computed over short intervals of a song  they do not carry much
information about the temporal attributes of a song  such as rhythm or tempo 
process for converting waveforms to mfccs
the general process for converting a waveform to its mfccs is described in logan    and roughly
explained by the following pseudocode 
  
  
  
  
  

take the fourier transform of a frame of the waveform 
smooth the frequencies and map the spectrum obtained above onto the mel scale 
take the logs of the powers at each of the mel frequencies 
take the discrete cosine transform of the list of mel log powers  as if it were a signal 
the mfccs are the amplitudes of the resulting spectrum 

we compute n mfcc coefficients for all short duration frames of a wav file and store them in a f
x n size matrix  where f is the number of frames  figure   displays the mfccs for sample songs in
each genre  with n      

 

fifigure    graphical representations of mfccs for each genre

song level modeling
once the mfcc feature vectors for each frame of a song have been computed  an n dimensional
gaussian is fit to this data  where n           hence all mfcc vectors of each song are modeled as
coming from a multivariate gaussian distribution  using maximum likelihood estimation  the
optimal gaussian is calculated by simply taking the mean and covariance of the f x n mfcc matrix 
thus  ultimately each song is reduced to a   x n mean vector and an n x n covariance matrix  this
greatly reduces the size of training data 
distance function for songs
since each song is modeled as gaussian probability distribution  it is natural to compute distance
between songs using kullback liebler divergence     kl divergence is defined for any two
probability distributions  in the case where both distributions are gaussian of dimension   it can
be computed using the following closed form equation 

one thing to note is that kl divergence is not symmetric  whereas a distance metric needs to be
symmetric  to overcome this  we define our distance function to be 

supervised learning   k nearest neighbors
we use a simplistic approach for classification which gives surprisingly good results  during
training  we compute the gaussian model for each song  and store these for all training samples for
each genre  to guess the genre of a new song  we compute its distance  as defined above  with all
samples in the training set  pick the k closest neighbors and assign it the predominant genre found
amongst its nearest neighbors  the results are summarized in a later section 

 

fiunsupervised learning  kernelized  k means
we thought that by using the feature vectors and distance function as defined above could help
discover interesting relationships between songs  artists  genres  etc  so we devised a modified
form of the k means algorithm to cluster songs  each iteration of k means assigns clusters to each
of the data points and then computes the centroid for each cluster  however  in our case  each
point is a probability distribution and there doesn t seem to be a clear way to define the centroid of
a set of probability distributions  so while we do have a distance function between the data points 
we don t have a good way to compute the centroids for each cluster 
we overcome this  by not computing the centroids at all  instead we store the set of points for
each cluster  and let the centroid vector be implicit  if
is the set of points in the cluster   then
we define the distance between the centroid of this cluster and any other point
as  
using this approach we only need to know the distance between all pairs of samples points  this
can be passed to the k means functions in the form a matrix
  where
 
we were only able to do a limited amount of testing with this approach due to time constraints 
when we used songs from only two genres  classical and rock  the results looked promising  there
were two clusters  one containing mainly classical and another mainly rock  however when we
tested with songs from all four genres  the results weren t that good  there was one neat cluster
with just classical music  while the other clusters had a mix of genres 
visualization of data in  d with svd
to help visualize the differences between the   genres  we used single value decomposition to
project the high dimensional data onto   dimensions for visualization  we did not expect to see any
separation at these low dimensions  however there is a significantly visible separation between
genres  hip hop and classical show the most obvious separation at  d  alternative and rock show
much less separation but its still noticeable in  d  figure   shows these cases 

figure    svd projection of mfcc song data

 

ficlassification results
training testing data set
testing and training data was collected from our music libraries by randomly choosing     songs
spanning   genres  we wrote a script to extract the id  tags  metadata  from the files  and
populate a master file with song filename  and genre  the script then converted the mp  file to a
wav file  started matlab and ran a script to extract the mfccs and store them in a file  in order to
speed up training and testing  we created a simple test definition file format that identifies songs to
process  their respective genres  and whether to treat that file as a training file or a testing file 
this structure allows us to create customized train test cases with subsets of the data we have and
run a large number of experiments easily 
evaluation procedure
we evaluated the performance of our system in three different ways  the first approach is aimed at
measuring performance in the average case whereas the other two simulate unfavorable scenarios
for our system  each train test cycle generates a confusion matrix illustrating the algorithm s
guesses and the actual song label for each song  these are shown in figure   
randomized k fold cross validation      of the song data was randomly selected as training data
and     was used to test the learned model  the absolute accuracy across a large number of runs
ranged from     to     
new artist effect  since songs from the same artist tend to be similar  using knn tends to work
well given that some training examples from that artist exist  however  it is important to measure
the accuracy of the model when presented with a new artist  two artists  queen and pink floyd 
were completely removed from the training set and placed in the testing set  the result was    
accurate  also a new classical artist test was performed by moving all christopher o reilly data to
the testing set  this is unique since christopher o reilly arranges classical versions of popular rock 
alternative songs  the available data include all his performances covering an alternative band
radiohead  the accuracy of testing on a new classical artist was       finally  to cover the new
artist effect on a large scale      songs from completely new artists were tested  with the result of
    accuracy 
new genre effect  in addition to the  new artist effect   the ability to introduce a new genre with
limited data is important as well  to test the accuracy of the algorithm when presented with a new
genre  all hip hop songs were removed from the data set      pac songs and   wu tang clan
songs were chosen  two tests were performed  one where the  pac songs were included in the
training set and the wu tang songs were tested  this resulted in      accuracy  the roles of the
artists were then reversed and the   wu tang songs were used in the training set  and the  pac
songs were tested resultqing in     accuracy 
overall  these results are extremely encouraging especially since many of the errors tend to occur
between the rock and alternative categories  this was expected since the differences between rock
and alternative is extremely vague 

 

fifigure    confusion matrices for various tests

lessons learned   future work
it turns out that music genres are very subjective  individual tastes  the artist s previous work 
along with the song time period can drive genre classification  possibly a more successful approach
would be to create an entirely new classification language that would identify and classify each
song based on timbre  the work here shows a reasonably successful algorithm  that can separate
music based on timbre  some work has already be done in analyzing the content of timbre using
different auditory features    and perhaps this can be expanded to provide timbre classification for
popular music 
it would be interesting if this work can be extended to include more genres of music  the id 
standard specifies     different genres for music  here we tackled only   genres of music due to
time constraints  since genre is such a subjective classifier  additional research in unsupervised
learning possibly could yield some very interesting results illustrating some kind of timbral
grouping of music 

references
  
  
  
  
  
  

mandel and ellis  song level features and support vector machines for music classification 
http   www ee columbia edu  dpwe pubs ismir   svm pdf
logan  mel fequency cepstral coefficients for music modeling        http   ismir     ismir net papers 
logan paper pdf
xu et al    support vector machine learning for music discrimination  http   www springerlink com content 
 n  wf pxfxubt p fulltext pdf
laurier and herrera  audio music mood classification using support vector machine 
http   www mtg upf edu files publications b c    ismir mirex      laurier herrera pdf
stanley  auditory toolbox v   http   cobweb ecn purdue edu  malcolm interval          
de poli and prandoni  sonological models for timbre characterization  http   lcavwww epfl ch  prandoni 
documents timbre  pdf

 

fi