rapid natural scene text segmentation
ben newhouse  stanford university
december         

 

abstract

 

introduction

the second of these two problems is surprisingly complex  ocr on document has historically been one of
a new algorithm was developed to segment text from the true success stories in machine learning  due to
an image by classifying images according to the gra  lighting and geometric transformations in the natural
dient composition of each edge  this algorithm is world  ocr on natural scenes is nowhere as near as
translation  scale and rotation invariant  and touches well developed 
each pixel approximately    time less than a similar
while  it is true that images can be offloaded to
sliding window based classification scheme  the gra  a server to be processed  we believe that this is less
dient angles were bucketed into ten buckets  which ideal than an algorithm that can be done on a mobile
were then used as features to an svm trained with device such as an iphone in real time 
a variety of kernels  a kernel of polynomial degree
   achieved a weighted success rate of approximately
      
  process
in order to design an anlgorithm to be run on a mobile device  the mobile device must be characterized 
this proved extremely difficult with the iphone as no
api for accessing the live video stream has ever been
disclosed publicly by apple or anyone else on the internet  after spending a significant amount of time
looking for symbols in low level private c libraries 
an api was discovered that provided the programmer
with access to buffers of    x        x         x    
with the pixel data encoded as ycbcr 
next  a basic     input     output neural net with
two intermediate layers was trained using backpropagation on minst data  using the fann open source
library   to an error rate of approximately     using
this neural net  an iphone application was developed
to recognize handwritten digits in the top left   x  
pixel block of the luminance portion of the image
naively thresholded at a fixed threshold 
further algorithms  such as adaptive thresholding
and convolution of first order haar wavelets  were
compared on the iphone and a core   duo macbook
running os x       it was found that the iphone runs

in recent months  great attention has been given to
the idea of augmenting reality with additional
data  at yelp  we developed one of the first such applications that used the phones magnetometer  accelerometer  and gps sensors to attempt to label
venues located in front of the iphones camera  while
this application was generally well received  its usefulness is heavily constrained by the inaccuracies of
the gps       m   and the vulnerability of the magnetometer to passing magnetic fields 
the next generation of augmented reality devices
will inevitably rely on computer vision techniques 
this has already begun with the release of google
goggles in early december       these computer vision techniques can be largely divided up into two
branches of algorithms  algorithms for generic pattern recognition  and algorithms for text recognition 
the first of these two patterns is relatively mature  as
demonstrated by such algorithms as sift and surf 
 

fiat approximately    the speed of the core   duo and
in particular is very slow in performing floating point
computations 
generalizing the previous implemented ocr algorithm to the entire image would require touching each
pixel approximately     times  for         pixels in
a    x    image   this is approximately     million operations just on loads stores  incorporating
the time taken in cache misses for such an algorithm
would further slow down its execution  if an algorithm is to be used in real time classification  it cannot be based on an algorithm that uses sliding windows for analysis 
the algorithm we developed is called gradient
edge trace segmentation or gets and consists of
the following steps 

   take the set of angles in component  sort them
into m equally sized buckets  use each bucket as
a feature to an svm which classifies the edge as
being either text or non text 

   flood fill the remaining edges according to the
following algorithm 

running our algorithm on the    classified images to
obtain samples on which to train  our algorithm extracted        edges  edges of length less than three
were ignored   of these       were text edges and
       were non text edges  on average  each pixel
was touched approximately    times  according the
counts provided by our python abstraction  to in order to derive the features from which to train on 
the data was first analyzed in matlab  using matlab  random text and non text gradient edge traces
were plotted  plots can be found in appendix a  
in these plots  it was found that angles in non text

the motivating hypothesis behind this algorithm
that text has very complicated edges in that they
have many angles and the transitions from positive
to negative angles more often than generic shapes 
if the frequency of an angle in an edge is scaled according to the length of the edge then this algorithm
becomes scale invariant  if we rotate the array of
edges to start with  say  the longest angle  ie  the
longest stretch of pixels with the same angle value  
then this algorithm becomes rotation invariant  finally  because every edge in the image is traced  it is
translation invariant 
   adaptive threshold the image according to the
this algorithm was developed initially in python as
following formula 
abstractions could be made in order to keep track of
how many times a given pixel is touched for a given
pixel x  y    pixel x  y 
   
algorithm under development  additionally  developx n
x
x x n
ing in python allowed for faster iteration once we had
pixel x  y 
characterized the abilities of the iphone 
xn yn
    
       
in order to test this algorithm     assorted pho n      
tos were taken of a dorm room comprising assorted
   convolve horizontal and vertical haar wavelets books  documents  walls  clothes  etc  next  these
and take the tangent between the sums if the photos were individually processed by drawing masum of the sums is greater than a set threshold genta lines through all text in the image  next  training and test data was compiled by running our algo   pixel x  y   pixel x  y         rithm and classifying each edge if it intersected part
   pixel x  y   pixel x      y     of a magenta line drawn on the classified image 

pixel x  y    tan
if       
   

results
pixel x  y      if      
     

for pixel in image 
if pixel has not been touched
and pixel is an edge 
initialize a new component
create a stack with current pixel
while the stack isnt empty 
pop a pixel from the stack
add untouched edge neigbor pixels

 

fiedges tended to take a few discrete values  whereas
text edges tended to take continuously variable edge
traces  to digest this phenomenon into a more discrete feature  the edge angles were sorted into bins 
as if to be shown in a histogram  which can also be
found in appendix a   to ensure scale invariance 
buckets were normalized by dividing each by the total number of angles edge pixels  from inspection 
it can be seen that text is highly likely to have more
non zero buckets than non text 
next  an svm was used to classify each edge 
and k fold cross validation was used to evaluate the
performance of each  with k     in our case   in
addition  as a baseline  edges were deterministically
classified as text if they have less than or equal to
n zeros  where n was found best to be    linear 
gaussian  and polynomial of degree    kernels were
tested in additional to our deterministic classification  resulting in in the following confusion matrices 

success       
weighted success       
from this we can see  that using an svm is largely
useful for decreasing the number of false negatives 
marking text as non text  which the deterministic
approach is very vulnerable to   this is very important however  since it is better to try to classify
some non text  and fail  in an image than it is to
completely fail to let the letter classification even
look at an important edge  henceforth  the svm
approach is much better than the naive approach despite the lesser overall success rate  which can also
be attributed to the disproportionate sample sizes of
text edges vs  non text edges  

 

svm   linear kernel
labeled truth not text text
not text
     
   
text
    
    
success       
weighted success       
svm   gaussian
labeled truth not text
not text
     
text
    
success       
weighted success       
svm   poly   
labeled truth not text
not text
     
text
    
success       
weighted success       

conclusion and future research

improvements could likely be made in the order in
which the connected edges are traced  ensuring that
angular transitions are more coherent and continuous  furthermore as gradient edge tracing is  as far
as we know  a new feature  there are still questions to
be answered in terms of how much information can be
extracted form it  using ffts or other transforms
it might be possible to do character recognition in
addition to just binary text classification 
in conclusion  it was demonstrated that an svm
could be applied to gradient edge traces  to classify edges as text or non text  with an average accuracy of        furthhermore  this algorithm is
computationally efficient and translation  scale and
rotation invariant 

text
   
    

text
   
    

 

text if less than or equal to   empty bins
labeled truth not text text
not text
     
   
text
    
    

references
thanks

and

special

special thanks to otavio good for helping us figure
out that the iphone framebuffer is ycbcr encoded 
 

fi 

appendix a

   

edge angle sequences

   

histogram of angles per edge

 

fi   

neural net ocr running on the    
iphone

   

   

example original image

 

example training image

example edge filtered image

fi