practical option pricing with
support vector regression and mart
by
ian i en choo
stanford university
   introduction the black scholes  bs    approach to option pricing is arguably one of the most important ideas in all of finance today 
from the assumption that the price of a stock follows a geometric brownian motion with constant volatility  black and scholes derived
a formula that gives the price of a european call option on the stock  c  as a function of six variables  the stock price s  the strike
price k  the time to the expiration of the option t  the risk free interest rate r  the dividend rate paid by the stock  q  and the volatility
of the stocks return    
c     se qt  d     ke rt  d   
d  

log s   k     r  q         t
 t

  d   d    t

where    is the standard normal cdf 
in general  an estimate of the volatility of the stock return  can be obtained by estimating the standard error of the stock
returns from past data  however  the practice most commonly used by option traders is to assume that the black scholes formula is
correct and to solve for  by inverting the formula given above  this practice of calculating   which are called the implied
volatilities  is curious because the black scholes equation implies the volatilities obtained from options on the same stock are constant
across different strikes k and maturities t  this empirical prediction is frequently violated in practice  implied volatilities plotted
against strikes for most stocks typically exhibit a smile or skew effect 
to address this shortcoming  numerous attempts have been made to adapt the black scholes model to make it consistent with
this empirical observation  one approach is to directly model  as a deterministic function of the k and t  some notable attempts
include implied binomial trees by rubenstein  r     stochastic volatility models by heston  h    and discrete time garch models by
duan  d    
one of the most widely used option valuation techniques used in practice embodies this approach and is what christofersen
and jocobs  cj    term the practitioner black scholes  pbs  pricing scheme  the implementation of the pbs method is
straightforward and can be summarized in four steps as follows 
   use a cross section of european call options on the same stock with differing s  c  k  t  r and q to obtain the set of implied
volatilities  by inverting the black scholes formula 
   choose a linear functional form for the volatilities   k  t   and estimate it by regressing the implied volatilities obtained in step   on
powers  usually up to    of k  t and their cross terms using ordinary least squares  ols   
   for a new option we wish to price  use its values of k and t to obtain an estimate of its implied volatility through the function
 k  t   estimated in step   

   obtain the estimated option price using the black scholes formula by using

 k  t   as an argument  ie  calculating

c  s  k t   r q   k t     

although the pbs model using ols to estimate implied volatility is remarkably simple to implement  berkowitz  b    notes
that it surprisingly dominates the performance of other more complex  and theoretically sound approaches  most notably  the pbs
pricing scheme has been found to outperform pricing methods based on the deterministic local volatility function of rubenstein  r   
and hestons stochastic volatility model  dfw     berkowitz  b    offers some justification for the excellent performance of the pbs by
proving that the pricing scheme can be made arbitrarily accurate as the frequency at which we re estimate  k  t   goes to infinity 

fiour aim is largely grounded in empirics   given the widespread use of the pbs model by traders and the market in practice 
we consider the possibility of enhancing the performance of the pbs model through estimating  k  t   using machine learning
techniques 
we estimate the implied volatility function  for data consisting of the daily prices for european call options on the s p    
index from february      to august       using support vector regression  svr  and the multiple additive regression tress
 mart  algorithm  and compare the results with those obtained from an ordinary least squares  ols  regression 
   support vector regression given a data set

d  x i   yi 

n
i  

of n points  the method of   support vector regression  v     from

henceforth denoted svr  fits a function f to the data d of the following form 
f  x    wt  x    b

where  is a mapping from the lower dimensional predictor space  or x space   to a higher dimensional feature space  and w and b
are coefficients to be estimated  the svr stated as constrained optimization problem is 
n
   
w  c  i  i 
w  b   i   i
 
i  


y
 wt  x i    b    i

i


subject to wt  x i    b  yi    i 



i   i    




min 





the dual of the svr primal problem is

max



n
n
  n
 i  i    j  j   k  x i   x j       i  i      yi  i  i   

  i  j  
i  
i  

n



   i      



subject to  i   i


        c 


 i i 

where k  x i   x j   is the kernel function that is known to correspond to the inner products between the vectors  xi   and  x j   in the
high dimensional feature space  ie  k  x i   x j     x i  t  x j      the radial basis function  rbf  kernel  ss     k x i   x j    exp  x i  x j    
is known to correspond to a mapping to an infinite dimensional feature space and is adopted in this paper 
   mart  multiple additive regression trees  the mart algorithm is an ensemble learning method where the base learners are
binary decision trees with a small number of terminal nodes  m  m is usually between   and     the structural model behind mart 
which belongs to a class of learning algorithms called booted tree algorithms  is that the underlying function to be estimated f  is an
additive expansion in all the n possible trees with m terminal nodes than can be created from the training data  i e  f  x    i   ihi  x  
n

where h is the i tree whose opinion is weighted by i   since n is typically a enormous number  tractability is an immediate concern 
th

i

thus  the goal is to find sparse solutions for the i  s 
mart adds trees in sequence starting from an initial estimate for the underlying function f   at the n iteration of the
th

 

algorithm  the tree added best fits what friedman  f    calls the pseudo residuals from the n   previous fits to the training data 
this procedure is known as gradient boosting because the pseudo residual of the i training point from the n run of the algorithm turns
th

th

out to be the gradient of the squared error loss function l     l yi   fn  xi       fn  xi     the generalization properties of the mart are
enhanced by the introduction of a stochastic element in the following way  at each iteration of mart  a tree is fit to the pseudoresiduals from a randomly chosen  strict subset of the training data  this mitigates the problem of overfitting as a different data set
enters at each training stage  also  boosted trees are robust to outliers as this randomization process prevents them from entering every
stage of the fitting procedure  successive trees are trained on the training set while updated estimates for f are validated on a test set 

fithe procedure is iterated until there is no appreciable decrease in the test error  for specific details on the mart  the reader is directed
to friedman  f   f    
   experimental settings the data set consisting of the daily prices for european call options on the s p     index  obtained from
http    www marketexpressdata com  from february      to august      was selected for this experiment  there were     trading
days giving        unique price quotes in the data  we chose the same data used in panayiotis et al   pcs    where svr was used to
directly predict option prices  so that the results between our approach and theirs could be compared  as such  we have applied most of
their editing and filtering rules to the data as follows  all observations that have zero trading volume were eliminated  since they do not
represent actual trades  next  we eliminated all options with less than   days or more than     days to expiration to avoid extreme
option prices that are observed due to potential liquidity problems  t was calculated on the assumption that there are     trading days
in

a

year 

while

the

daily

   day

t bill

rates

obtained

from

the

federal

reserve

statistical

release

 http   

www federalreserve gov releases h   update   were used as an approximation for r  the annual dividend rate for the period was
q          the implied volatilities vol were then calculated using the financial toolbox in matlab  this yielded a final data set of
      points 
this data was then randomly partitioned into an in sample data set consisting of     of the data        data points  and an
out of sample set consisting of the remaining data  the in sample data was then used train models in each of the three competing
function classes  ols  svr and mart 
the out of sample set of      data points was then used to gauge the out of sample performance of the three competing
models  out of sample estimates of the implied volatilities ols   
   svr   
 and mart   
 were obtained and subsequently plugged into
the black scholes formula to obtain the practitioner black scholes  pbs  estimated option prices cols  s  k t  r  ols    
  

csvr  s  k t  r  svr   
 and cmart  s  k t   r  mart    
   these estimated values were then combined with their observed values to
construct statistical metrics that we used to compare the competing methodologies  these metrics are the root mean squared error
 rmse  and the average absolute error  aae  of the pbs predicted option prices  and the root mean squared error  iv rmse  and
the average absolute error  iv aae  of the predicted implied volatilities  we accessed the quality of the predictions of the volatilities
as

 is frequently used in hedging applications   the definitions of these metrics are  for n       
rmse 

 
n

n

  c
i  

i

ci    aae 

 

 
n

n

c
i  

i

 ci iv  rmse 
 

 
n

n

  
i  

i

 i    iv  aae 

 

 
n

n


i  

i

 i

   experimental procedure and results fitting an ols linear regression to any data set is a fairly standard procedure and there exist a
large number of numerical routines and software packages that can execute the task well  in our case  we used the built in function
capabilities of the r statistical programming language to estimate the parameters of the most general specification of the quadratic
deterministic volatility function in the dumas et al  dfw    study 

vol      k   k     t   t     kt
the results of the fit are as follows 
estimate

std error

t value

p   t  

 

    

    e   

      

  e   

 

     e   

    e   

       

  e   

fir         

 

    e   

    e   

     

  e   

 

     e   

    e   

      

  e   

 

    e   

    e   

     

  e   

 

    e   

    e   

     

  e   

f      

 

p   f      e   

as we can see  the f statistic and t statistics on all of the estimated coefficients are extremely significant  these results 
coupled with the relatively high r value indicates a good fit of the model to the data 
 

to fit the svr model  we used the r implementation of the libsvm library of support vector machine algorithms developed
by chang and lin  cl     the inputs to the svr were the same as those used for ols  the optimal values of the free parameters c 

   and   the parameter in the rbf kernel  were found by conducting a full grid search over a range of specified values for each
parameter using   fold cross validation  the values of the parameters we used for the grid search were                                 
                   and c                the best set of parameters thus obtained was c             and           the svr

was then trained on the entire in sample data set with these parameter values 
the r implementation of the mart algorithm that was developed by friedman  f    was used to fit the boosted tree model 
the inputs to the mart algorithm were the same as that in ols and the svr  the number of terminal nodes of each base learner
was set to        of the in sample data was used to train the model while the remaining     was used as a test set  a plot of the
training and test errors is displayed below  the smooth plot represents the test errors and we observe that they start to level off after
about     iterations 

after all three estimated functions were obtained  the metrics aae  rmse  iv aae and iv rmse were calculated for each
estimate as detailed in section    these results are summarized in the table below 

ols
svr
mart

rmse

aae

iv rmse

iv aae

        
        
        

        
       
        

          
          
          

          
          
          

fithe results of the experiment are evident  the mart procedure clearly performed the best  gives the lowest out of sample
error   followed by the svr procedure across all metrics  as the metrics were calculated using out of sample data that was not used in
the training of any of the models  they make a clear statement about the superior generalization properties of the machine learning
based pbs pricing models compared to the ols based pbs pricing model  offering the tantalizing prospect of significantly enhancing
the performance of the pbs pricing model in practice 
what is perhaps most startling about these results is the size of the reduction in the errors of the option price predictions
when the pbs pricing model is used with the svr or mart instead of the ols  use of mart in the pbs pricing model reduced both
the average absolute error  aae  and the root mean squared error  rmse  of the call price predictions by more than     on the
out of sample data  compared to the ols based pbs model  the svr based pbs pricing model offered more modest  but still
significant improvements over the ols based pbs pricing model  furthermore  our ad hoc approach to selecting the free parameters in
the machine learning algorithms used in this paper suggest that the performance of both machine learning algorithms can be
significantly enhanced through a more careful and systematic parameter selection procedure  bi et al  bh     and lendasse et al 
 lw    prescribe novel ways of selecting the gamma parameter in the gaussian kernel of the svr  but these are by no means standard
and the matter of parameter selection in svm remains an active area of research 
references
 b    berkowitz j        on justifications for the ad hoc black scholes method of
option pricing  working paper  department of finance  university of houston 
 b    bishop c        machine learning and pattern recognition  springer  new york 
 bh    bi l   huang h   zheng z   song h        new heuristic for determining gaussian kernels parameter  proceedings of the fourth international conference on machine learning and cybernetics 
guangzhou         august 
 bs    black  f   scholes  m        the pricing of options and corporate liabilities  journal of political economy            
 cl    chang c  and lin c        libsvm   a library for support vector machines  software available at http    www csie ntu edu tw  cjlin libsvm
 cj    christoffersen p   jacobs k        the importance of the loss function in option valuation  journal of financial economics  vol    issue           
 d    duan  j        the garch option pricing model  mathematical finance          
 dfw    dumas b   fleming j   whaley r        implied volatility functions  empirical tests  nber working paper no  w     
 f    friedman j        greedy function approximation  a gradient boosting machine  the annals of statistics  vol    no              
 f    friedman j        stochastic gradient boosting  computational statistics and data analysis  vol    issue            
 f  a  friedman j        getting started with mart in r  software available at http    www  stat  stanford edu  jhf r mart html
 h    heston  s        a closed form solution for options with stochastic volatility with applications to bond and currency options  review of financial studies            
 h     huber p        robust regression  asymptotics  conjectures and monte carlo  annals of statistics            
 h    huang  s        combining extended kalman filters and support vector machines for online option price forecasting  lectures in computer science  vol            springer  berlin 
 hn    heston  s   nandi  s        a methodology for assessing model risk and its application to the implied volatility function model  manuscript  rotman school of management  university of
toronto 
 htf    hastie  t   tibshirani  r  and friedman  j  h        elements of statistical learning  springer 
 lw    lendasse a   wertz v  verleysen m        model selection with cross validations and bootstraps  application to time series prediction with rbfn models  icann iconip       lncs      pp 
        
 lx    lai t   xing h        statistical models and methods for financial markets  springer  new york 
 mp    marwala  t  pires  m        american option pricing using multi layer perceptron and support vector machines  ieee internation conference on systems  man and cybernetics  vol             
 p    primbs  j        fingroup matlab toolbox  software available at http  www  stanford edu   japrimbs fingroup htm
 pa    perez cruz f   afonso rodriguez j a   giner j        estimating garch models using support vector machines  quantitative finance  vol         
 pcs    panayiotis a   chris c   spiros m        options pricing via statistical learning techniques  the support vector regression approach  working paper 
 r    rubenstein  m        implied binomial trees  journal of finance             
 rv    rouah f   vainberg g        option pricing models and volatility using excel vba  john wiley  new jersey 
 ss    smola aj  scholkopf b       a tutorial on support vector regression  neurocolt technical report tr  royal holloway college  london  uk 
 ss    scholkopf b   smola a  williamson r c  and barlett p l        new support vector algorithms  neural computation                
 v    vapnik v        statistical learning theory  john wiley  new york 

fi