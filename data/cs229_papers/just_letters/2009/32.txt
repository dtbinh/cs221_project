formation flight
cs     project  final report
zouhair mahboubi
tao wang
december   th       
stanford university

fiabstract
this paper is submitted as the requirement for the final project report for the
cs    project  however  it is well over the suggested length because it is also
intended as a comprehensive progress report of the formation flight project
being carried out in the ai lab  a great deal of effort has been put in getting
two airplanes to fly autonomously  and our goal is to document our work so
that similar attempts to use uavs in the future might be able to leverage it
and learn from our experience and mistakes 
acknowledgments  we would like to acknowledge the invaluable help and
advising of both zico kolter and geoff bower in this project  they are very
helpful with problem solving  decision making and fun having during the flight
testing  we would also like to thank our pilot garett  whose skills have avoided
some imminent crashes in the early stages of the flight testing 

fi 

introduction

the goal of our project is to demonstrate autonomous formation flight using unmanned air vehicles  uavs   the project is inspired by migrating birds which
fly in v shaped formations in order to decrease the induced drag  by flying in
the wake of a leading bird  they are able to either save energy or increase range 
researchers have a relatively good understanding of the phenomenon  but
apart from short flight demonstrations by f    carried out at nasa dryden
flight research center  the concept is still in its infancy  however  flight test
results and models of the wake vortices show that its possible to save as much
as     in fuel consumption  if commercial airplanes took advantage of this 
we could see a significant lowering of the fuel consumption by aviation  which
would translate into a positive environmental impact by lowering co  and n ox
emissions  this is also attractive for airlines since it represents a sizable cost
saving  especially in the wake of a potential carbon tax  without requiring
them to change their current fleet 

 

hardware and software architecture

in this section we describe the hardware and software that we are using to
accomplish this task

   

hardware

the airplanes we are flying are two identical remote controlled ready to fly
trainers  alpha   model   the following table summarizes their properties 
weight
span
wing area
aspect ratio
vcruise

    kg
     m
    m 
   
   m s

the airplanes were modified so that they can be flown autonomously  we
decided to use the paparazzi   autopilot to accelerate the development process  thus each airplane is equipped with a microprocessor  gps antenna for
positioning  infrared thermopiles and roll gyro for attitude      mhz radio for
telemetry and a     ghz receiver as a safety link  the trailing airplane also has
a current sensor for power consumption and an airspeed sensor 

  paparazzi

the free autopilot http   paparazzi enac fr wiki main page

 

fifigure    airplanes in cupertino foothills

in order to overcome the inaccuracies of gps positioning  we are relying on
vision to track more precisely the position of the trailing plane relative to the
lead plane  this is a reasonable approach and has been proposed for autonomous
aerial refueling by the military  for this reason  the lead airplane  batman  has
  high power leds that a camera on the trailing airplane  joker  captures  a
small computer runs a vision algorithm which is supposed to infer the orientation and relative position of the two airplanes  it uses the i c protocol to
communicate with the autopilot flight code  a more detailed description of the
hardware setup is provided in appendix a   

   

software

one advantage of using the paparazzi system is that it is open source software  allowing us to easily modify the behavior of the uav  both batman and
joker run essentially the same code  the only difference between the two is an
xml setting file which determines the appropriate gain and flight plans of each 
in order to be able to properly implement our own control laws  an in depth
analysis of the software architecture was necessary to understand all the details 
figure   summarizes the software architecture  the processing and attitude
sensing is done at   hz  while the gps refresh rate is only  hz  the ground
station  gcs  allows to uplink mission level commands as well as change gains
in flight 

 

fi 
figure    software architecture

fi 

aerodynamic simulation

while the paparazzi system comes with simulation capability which is useful for
testing flight plans  it is not realistic enough to be used for control law testing
or gain tuning  per example  it is possible to achieve positive climb rate with
   throttle in the simulation  
for this reason one of our goals was to integrate the system with a more accurate simulation  initially we planned to re write the control law in simulink
and use the simulator in matlabs aerospace toolbox  however  in order to keep
things rather lean  we decided to use jsbsim instead  jsbsim is a non linear
 dof dynamic simulator aimed for aerodynamic simulations written in c   
this means that it was possible to have a simulation environment which runs
the exact same code as the one that the micro controller runs  thus reducing
the workload as well as the risks of making mistakes when porting simulink
control laws back to c 
jsbsim relies on the concept of force and moment build up using stability
derivatives  these are function of the aerodynamics coefficients which mainly
depend on the geometry of the airplane  so in order to obtain these values  we
measured the airplane and used avl     a vortex lattice code meant for aerodynamic analysis  however  it should be noted that this is a non viscous and
linear method  which is only approximate  it usually does a good job  but it
does not give exact numbers and definitely does not have any of the non linear
aerodynamic effects 

figure    avl geometry for stability derivatives extraction

 

fi 

flight testing and results

flight testing is done near the rancho san antonio park in cupertino  ca  for
simplicity  a human pilot takes care of taking off and landing the planes  once
the lead plane is airborne and in autonomous mode  the second one takes off and
is put in autonomous mode as well  depending on the plane  we get between   
and    minutes of flight time  which is relatively short but with spare batteries
we have enough time to carry out the test flight plans 
so far we have been successful in getting both airplanes to fly autonomously
at the same time  we repeated this on more than one occasion and have been
able to resolve some of the major issues we had with the system  interference
between engine and transmitter  board resets  unreliable vision system  etc  
we have implemented two new algorithms for both longitudinal and lateral
control  the first one is an implementation of total energy control     which
allows us to control speed and altitude simultaneously using a multiple inputmultiple output  mimo  control strategy  we used the  dof simulation to
tune the parameters  but fine tuning during flight tests was still necessary  for
lateral control  we have closed the loop on the bank angle in an attempt to
achieve repeatable circles  by controlling the set groundspeed  we got each aircraft to catch up to a virtual carrot flying the same circle at a fixed velocity 
syncing the virtual carrot for each aircraft allows us to close the gap between
the two aircrafts 
unfortunately  our altitude hold and circle following has been less than satisfactory  although we are able to hold groundspeed to within  m s  altitude
error can be as much as  m with     m being common  as for the circle following  each airplane seems to do well over half of the circle  see figure     but
has difficulties on the opposite side  so far we have noticed that this is very
strongly correlated to the position of the airplanes relative to some of the hills
near our flight site  our hypothesis is that because we rely on ir sensors  i e 
horizon sensing  to determine attitude  the hills are a form of disturbance  indeed  the lateral errors occur when the airplane is flying parallel to the hills  i e 
disturbance in lateral sensing  while the altitude hold is at its worse when the
airplane is flying towards the hills  i e  disturbance in the longitudinal sensing  
its worth mentioning that we have been using gps altitude and climb rate
for altitude hold  this is known to cause problems given the noise in gps measurements especially in the vertical direction  apparently most professional
autopilots rely on barometric pressure for altitude hold  this might not be
critical once vision based positioning is achieved  since its the relative position
between the two aircrafts that matters 

 

fifigure    ground track during autonomous following

at this point  we have demonstrated that its possible to use gps alone to get
the airplanes close enough for the trail aircraft to acquire a visual of the leds
on the lead one  however  its questionable whether the sensors and control
algorithms currently in use are good enough to achieve precise navigation  this
leads us to think that the following steps in this project ought to focus on two
things  investigating whether sensor noise is an issue  and trying to implement
more advanced aggressive controllers that would allow us to achieve a better
performance  with this in mind  we propose the following as future work 
 carry out test flights to determine sensor accuracy

 

 log available states and control inputs and learn the aircraft model offline
 utilize the aircraft model to realize some more advanced controllers  ex 
lqr 

so far we have neglected the vision part of the project seeing how we have
assumed its an easy problem  but while its true that with   leds a simple svd
decomposition is enough to determine position and orientation  its interesting
to investigate whether redundant leds offer an advantage despite the added
complexity of the vision algorithm  we expect that the redundancy will lower
the potential of loss of lock due to occlusion  but it complicates the problem of
pose estimation 
  per

example  attempt to fly with constant roll  or simply fly somewhere without hills 

 

fifigure    sample pictures of lead plane from trailing plane  both autonomous 

references
    mark drela  extended vortex lattice model 
http   web mit edu drela public web avl 
    kevin bruce  nasa b    flight test results of the total energy control
system  nasa cr         january      

 

fia
a  

hardware description
the paparazzi system

we use the paparazzi autopilot system as our autopilot unit to realize autonomous flight  paparazzi is a free and open source hardware and software
project designed at enac university  france  for unmanned aerial vehicle
 uav  development  the hardware of the paparazzi autopilot system consists
of the tiny control board  a gps receiver  two ir sensor boards for attitude
measurement  and a gyroscope to measure angular rates 
the tiny control board uses the phillips lpc     micro controller as the
main processing unit  and integrates versatile interfaces with various peripherals  for example  as shown in figure    the control board interfaces with the
gps receiver and the radio modem via uart ports  while the ir sensors are
connected to the adc channels  apart from controlling the servos and motor
speed controller directly by outputting its own pulse width modulation  pwm 
signals in autonomous mode  tiny version   is also able to receive the pulseposition modulation  ppm  frame from the ar     spectrum r c receiver 
and decode it into separate  pwm  signals in manual mode  so that a human
pilot can takeover and control the plane via the r c transmitter during takeoff 
landing and emergency situations 

figure    tiny version   control board interfacing with peripherals
 http   paparazzi enac fr 

 

fiunlike most autopilot systems which use inertia measurement units  imus 
for attitude estimation  the paparazzi system uses infrared thermopiles for primary attitude sensing  the   orthogonal pairs of ir sensors measure the difference in ir radiation from the cold sky and the warm earth along the x  y
and z axes  and thus estimate the orientation of the aircraft with respect to
the horizon  while ir sensors are less susceptible to mechanical vibration than
imus  they are slower in reaction time  moreover  the ir sensors require manual calibration before each flight to compensate the difference in terrain and
weather conditions 

a  
a    

vision system
leds

in order for the follower plane to track the position and orientation of the leader
plane visually    phlatlight cbt     red leds  connected in series and powered
by a  cell lipo battery  are mounted to the leader plane  the four leds
are located at the right wing tip  the right landing skid  the right horizontal
stabilizer  and the vertical stabilizer  respectively  the power and brightness
of the leds is regulated by lm     current controller  and can be manually
adjusted by tuning a rheostat  an electrical brushed motor speed controller
acts as a switch of the leds  the speed controller is connected to the gear
channel of ar     r c receiver  so that it lets current through only when the
gear switch on the r c transmitter is turned on  in this setting  the leds can
be turned on or off remotely when the plane is in the air 
a    

camera and vision

a webcam and a video processing computer are mounted to the follower plane
so that it tracks the leader plane visually  initially we used the gumstix overo
embedded computer as the video processing unit  however  our vision processing program does not run well on the gumstix system  therefore  we switched to
fit pc   computer manufactured by compulab  which has slightly larger size
than the gumstix computer  but with much more reliable performance  fit pc
  computer runs on a intel atom z        ghz cpu and has  gb ddr  memory  a webcam is connected to the fit pc   computer via one of its usb port 
the footage captured during flight is stored in a  gb micro sd card plugged
into the fit pc   computer  the positioning information extracted by the camera is supposed to be relayed to the autopilot as an input sensor using an i c
link  this is still in the process of being done 

  

fia    

interface between autopilot and vision system

in order to control the trailing airplane based on the data from the camera  we
need to establish an interface between the fit pc and the paparazzi autopilot 
on the fit pc side  it is most convenient to use its built in usb port  on the paparazzi side  the only available data port now is the    v i c  inter integrated
circuit  bus  which uses only two bidirectional open drain lines  serial data
line sda  and serial clock  scl   internally pulled up with   k ohm resistors 
the usb and i c data are readily inter convertible by the devantech usb i c
adapter module  which acts as the master i c device that sends the scl signal 
paparazzi acts as the slave device which receives scl signal  although devantech usb i c adapter operates at  v logic level  the paparazzi tiny is  v
tolerant and can handle the signal despite the difference in logic levels  however 
the devantech usb i c adapter also has internal pull up resistors  therefore 
to ensure that the interface works properly  the pull up resistors on the paparazzi tiny board are removed  a simple schematic of the interface is shown
in the following figure 

figure    schematic diagram of interface between vision and autopilot systems

a  

airspeed sensor

since the tiny control board has a number of general purpose adc channels  we can add more sensors to the system  currently we have installed a
mpxv    dp differential air pressure sensor on to the plane to measure the
airspeed during flight  so that we have better estimate on the relative speed
of the plane  the differential air speed sensor has two holes  one connected to
a brass tube extruding in front of the wing  the other hidden inside the wing 
the sensor outputs a voltage proportional to the pressure difference measured
by the two holes  thus allowing us to estimate the airspeed relative to the plane
after a careful calibration on the sensor 

  

fia  

datalink

each plane is equipped with a maxstream  xtend rf module so that they
can both send and receive command from the ground control system  the rf
module is connected to the paparazzi system via a uart port and is set to
transmit at  watt to increase range  while those on the airplane transmit at
   watt to reduce power consumption 

a  

power system and integration

on the leader plane  a  s     v lithium polymer  li po  main battery powers
the entire paparazzi autopilot system  the r c receiver  the maxstream rf
module and the main motor and the servos  a separate secondary battery
is used to drive the leds  since they could draw as much as  a of current 
similarly  the paparazzi system  main motor and servos of the follower plane
are powered by a     v main battery  the fit pc   computer runs on   v dc 
and is thus powered by a secondary battery 
the airborne systems of both planes are integrated into a relatively compact
package  most of which fits into the fuselages  so that drag during flight is
minimized and on field setup is simplified 

a  

ground control station

we use the gcs that comes as part of the paparazzi system to monitor and
control the uavs in flight  but although it does display the attitudes and positions of the two planes using simple graphics  one can hardly visualize the
actual state of the planes with only the dots and lines  the paparazzi ground
station is useful in tuning the control gains and setting up desired routes for the
planes  so we decided to implement a secondary ground station just to visualize
the orientations and relative positions of the planes 
sending video directly down to ground would be a simple solution  but it takes
significant amount of cost and transmit power to setup a video link with reasonably good quality  not to mention possible interference between the video and
the datalink  moreover  mounting additional batteries and a powerful transmitter onto the follower plane would definitely increase its payload and power
consumption  thus reducing our flight time and decreasing the relative percentage of induced drag 
therefore  we made the secondary ground station eavesdrop on the existing datalink for the states of the airplanes  such as position  altitude  attitude 
velocities  and used flightgear simulation to visualize these states  flightgear
is a free open source project which creates advanced flight simulator framework
for use in research and academic environments  in the flightgear simulation 
we use rascal     as our aircraft model  which resembles our actual airplanes in
size  the flightgear program is run in parallel with a program which constantly
receives downlink data and updates the flightgear on the states of the aircrafts 

  

fithus  flightgear displays the real time simulated view of the airplanes with
sophisticated graphics  which allows us to better visualize their performance 
in the next stage of the project  fit pc   computer on the follower plane
will process the video and calculate its own relative position and orientations
with respect to the lead plane by tracking the leds  these data will also
be transmitted to the secondary gcs via the existing datalink and the lead
plane will appear in the simulated scene seen by the follower plane in flightgear
simulation  thus  we have a graphic visualization which resembles a real time
onboard video to assist our control on the airplanes  while not incurring an
additional video link 

figure    sample of simulation with flightgear

  

fi