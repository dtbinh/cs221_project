server load prediction
suthee chaidaroon  unsuthee stanford edu 
joon yeong kim  kim   stanford edu 
jonghan seo  jonghan stanford edu 

abstract
estimating server load average is one of the methods that can be used to reduce the cost of renting a
cloud computing service  by making an intelligent guess of how busy a server would be in the near
future  we can scale up or down computing requirements based on this information  in this experiment
we have collected website access and server uptime logs from a web application company s website
and extracted information from these data  we are able to build a prediction model of server load
average by applying a linear regression  locally weight linear regression  multinomial logistic
regression  and support vector regression  our experiment shows a trade off between computing
efficiency and prediction accuracy among our selected learning algorithms  the locally weight linear
regression has the most accurate prediction of server load average but takes a long time to converge 
on the other hand  the support vector regression converges very quickly but performs poorly on
sparse training samples  at the end of this paper  we will discuss on improvements we can do for
future experiments 

introduction
our clients operate a website and rent the cloud servers of amazon ec   the ec  allows them to
scale the computing capacity up and down as they need and they only pay for the computing capacity
that their website actually uses  this task is tedious and can be automated  we think that there should
be a way to automatically this task without having clients to monitor their server activities all the time 
our solution is to estimate a server load average based on the website users  activities  we assume
that the number of activities and transactions determines a server load average  we use this
assumption to build a prediction model 

methodology
we collected website access logs and server uptime logs during the past few months and processed
those two files by merging transactions and load average that occur in the same time interval  we
then use this processed file as our training samples  each line of a training sample file has a time
information  number of unique ip addresses  the total size of contents  protocol  and the load average
of the last       and    minutes  below are parts of access log and uptime files 
                    oct                       get  cgi bin uptime cgi http            
                    oct                       get  logs error log http              
                    oct                       get  logs error log http                              oct                       get  cgi bin uptime cgi http            
                    oct                       get  crossdomain xml http             
                    oct                       get  m s     f      f           bpk http             
                    oct                       get  m s     f      f           bpk http               

table    part of access log 
mon oct             pdt                 up    days     min    users  load average                  
mon oct             pdt                 up    days     min    user  load average                  
mon oct             pdt                 up    days     min    user  load average                  
mon oct             pdt                 up    days     min    user  load average                  
mon oct             pdt                 up    days     min    user  load average                  
mon oct             pdt                 up    days     min    user  load average                  

table    part of uptime log 

fiafter parsing and processing the data  the features available for us to use are  day of the week
 monday  tuesday  etc    month  date  year  hour  minute  second  number of unique users  number
of post requests  number of get requests  and content size of the interaction 
the diagram below represents our prediction model 

at the very bottom level  we predict the server load based on time  the problem of predicting the
server load only based on time would be extremely difficult to solve  so  we decided to divide the
problem into two parts  one to predict the server load  and another  to predict the user features based
on time  for regressions and classifications tests in the following section  we will assume that the user
features were correctly predicted 
the output value that we tested was chosen to be the   minute average server load because the
uptime command was run every   minutes on the server 

experimental result
linear regression
we assume that the user features such as number of unique users and number of requests  etc  were
correctly predicted by h  t   this assumption had to be made because of amount of data which was
not sufficient to predict the user features since the logs had been made only since this august  the
features month and year were dropped from the feature lists to create a training matrix that is of full
rank 
to create a larger set of features  we concatenated powers of the matrix x to the original matrix  so 
our training matrix 
 
n
x    xorig xorig     xorig   

fisince the full rank of matrix x could not be preserved from n      we could only test the cases
where n            to come up with the optimal n  some tests were done to compute the average
training and test errors  the following graph shows the errors 

as we can see from the graph above  the overall error actually got worse as we increased the number
of features used  however  because we thought that n     gave a prediction curve of shape closer to
the actual data  we picked n      below are the plots of parts of the actual and predicted server load
for training and test data  the corresponding errors with respect to n are listed below 

n

average
training error

average test
error

 

      

      

 

      

      

 

      

      

 

      

      

as the two graphs display  the predictions are not as accurate as it ought to be  however  the trends
in the server load are quite nicely fit  for the above regression  the training error was         and the
test error was         since the shape of the curve is quite nicely fit  for our purpose of predicting the
server load to increase or decrease the number of servers  we could amplify the prediction curve by a
constant factor to reduce the latency experienced by the users  or do the opposite to reduce the
number of operating servers 

multinomial logistic regression
in order to transform our problem into a logistic regression problem  we classified the values of the
server load  cpu usage  into ten values            as follows  if the cpu usage was less than or
equal to       it would be    else if less than or equal to       it would be      else if less than or

fiequal to       it would be    else it would be    we trained    separate hypotheses hi for each
classification  for testing  the system would choose the classification that gives us the highest
confidence level 
we use the same approach as linear regression case to find the maximum power of the matrix we
want to use when coming up with the matrix x  where
 
n
x    xorig xorig     xorig   
the following plots for training and test errors were acquired 

n

average
average test
training error
error

 

      

      

 

      

      

 

      

      

 

      

      

as in the linear regression case  we chose n     for logistic regression  the following is the resulting
plot of our prediction compared to the actual data 

as we can see  the multinomial logistic regression always outputs   as the classification no matter
what the features are  this is in part because too many of our data points has y values of   as the
below histogram shows  because the company we got the data from has just launched  the server
load is usually very low  as the website becomes more popular  we would be able to obtain a better

firesult since the y values will be more evenly distributed 

locally weight linear regression
like linear regression  we first assumed all features used as a input  such as number of users  total
number of requests and so on  were correctly predicted by
for the same reason  for building
up a hypothesis  we had to determine what weight function we would use  in common sense  it is
reasonable that server loads after five or ten minutes would be dependent on previous several hours
of behavior so we decided to use

as a weight function in our hypothesis  however  for using the weight function we were needed to find
out the optimal value of which is the bandwidth of the bell shaped weight function  so we used
hold out cross validation for picking up the optimal and the way and results are as follows 

      
     
    
    
    
    
    
    
   
   

      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      

fi 
 
  

      
      
      

      
      
      

      
      
      

first of all  we had picked     of the original data randomly and named it as training data and did
again     and named testing data  then we trained the hypothesis with various values of
on the
training data and applied testing data on the hypotheses and got test errors in each value of   above
chart shows test errors of sever loads tested on hypothesis h t u  with various   above plot displays
the pattern of the test errors with respect to   as we can see in the chart and graph  at        the
test error is the smallest value on all of three cases so we picked up this one for our weight function 

above plots show the actual server load and prediction of test and train data  respectively  as making
a prediction on every unit of query point x is prohibitively time consuming process  the prediction is
made on each query point in train and test data  though it seems that it followed the pattern of actual
load  sometimes it could not follow spikes and it needed very long time to predict even on query
points of test so it might not be suitable to be used in a real time system which would be needed in a
general sever load prediction system  thus  it is desirable that locally weighted regression will be
trained just on previous several hours not on whole previous history if sufficient training data were
given 

support vector regression

we use svm light  to perform a regression  we remove all zero features   which indicating that a
server is idle   and select training samples randomly  the trade off between training error and margin
is     and epsilon width of the tube is      we use a linear kernel and found that there are     support

fivectors and the norm of the weight vectors are          the training error is       and
the testing error is       

above plots are parts of the results from the support vector regression  the red curve is an actual
data and the blue curve is the prediction  although the support vector regression is quickly converged
for       training data set  its prediction has higher training and testing errors than the rest of learning
algorithms  we tried to adjust an epsilon width and found that the higher epsilon width will only offset
an estimation by a fixed constant 

conclusion
the prediction from the locally weight linear regression yields the smallest testing error but it takes an
hour to process       training samples  the linear regression also yields an acceptable prediction
when we concatenated the same feature vectors up to a degree of    both multinomial logistic
regression and support vector regression do not perform well with sparse training data  support
vector regression  however  takes only a few minutes to converge  but yields the largest training
error 

issues
bias with sparse data
our learning algorithms cannot estimate an uptime reliably because there are almost     of the
training samples have an uptime value between     and      we believe that the data we have
collected are not diverse due to the low number of activities of our testing web server 
not enough features
in our experiment  a dimension of the feature vectors are       of them are part of a timestamp  we
think that we do not have enough data to capture the current physical state of the cloud servers such
as the memory usage  bandwidth  and network latency 
weak prediction model
we think that our decision to use the number of transactions and unique users as part of the feature
vectors does not accurately model the computing requirements of the cloud servers  an access log
file and uptime file are generated separately by different servers  our assumption that a user activity
is the only main cause of high server load average may not be accurate  it is possible that a single
transaction could cause a high demand for a computing requirement 

future work
we have found a research paper that describes the use of website access logs to predict a user s
activities by clustering users based on their recent web activities  we like this idea and think that it is
possible to categorize website users based on their computing demands  when these type of users
are using the website  we think there is a high chance of increasing the computing requirements 

references

fi    access log specification  http   httpd apache org docs     logs html
    uptime specification  http   en wikipedia org wiki uptime
    svmlight  vers           k  aug           thorsten joachims  nov          

fi