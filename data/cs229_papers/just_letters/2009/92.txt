unsupervised clustering with axis aligned rectangular regions
jae young kim
stanford university

sung hee park
stanford university

 a  input data

 b  clustering with three rectangular regions

figure    an example of input and output of our clustering method

abstract
this project presents a new method for binary clustering that classifies input data into two regions separated by axis aligned rectangular boundaries  given the number of rectangular regions to use 
this algorithm automatically finds the best boundaries that are determined concurrently  the formulation of the optimization problem involves minimizing the sum of minimum functions  to solve
this problem  we introduce underestimate of the minimum function
with piecewise linear and convex envelope  which results in milp
 mixed integer and linear programming   we show several results
of our algorithm and compare the effects of each term in our objective function  finally  we demonstrate that our method can be used
in image capturing application to determine the optimal scheme that
minimize the total readout time of pixel data 
keywords 
machine learning  unsupervised clustering  axisaligned rectangular regions  mixed integer and linear programming

 

introduction

the main goal of clustering problem is to figure out an efficient algorithm to classify random data into several groups so that it can be
easily handled in more complex processing stage afterwards  each
clustering algorithm is designed to handle data in a systematic way 
based on the assumptions it makes on its input data  in this project 
we would like to propose an unsupervised clustering method that
classifies binary labeled input data into two separate regions  the
main difference from other existing clustering methods is that we
choose multiple rectangular regions to separate data  each rectangular region is axis aligned which means that its sides are aligned
to the axes of orthogonal coordinate system and it is not allowed to
rotate to arbitrary angles 
to make the clustering algorithm applicable to real world applications  we propose four desirable characteristics that our clustering
algorithm should have 
unsupervised clustering  it is desired that clustering algorithm
should work by itself  users can not always guide clustering if the
 e mail 

shpark  stanford edu
 e mail  jykim  stanford edu

size of input data is large or clustering should be done many times
iteratively 
optimality  rather than using heuristic methods  solving the optimization problem guarantees to have the best results  also  it can
be served as a standard reference case to evaluate other variant clustering methods 
robustness to outliers  the real data tend to be noisy and include
many outliers  the algorithm should be robust enough to handle
outliers  also  it is very common to get non separable input data
and error terms should be handled properly 
adjustable objective function  the method should be easily modified so that it can fit into various applications with different constraints  in addition  having explicit trade off parameters will help
users to tweak the algorithm to work well on the problem 
in the following sections  we will explain details about our algorithm and demonstrate it satisfies the properties stated above  finally  we will talk about the application for image capturing that is
utilized by our clustering method 

 

clustering as an optimization problem

input data is given with binary labels on the   dimensional plane 
we want to formulate an optimization problem to classify binary labeled data with axis aligned rectangles efficiently  figure   shows
one example when three rectangles are used to classify the given
input data  in general  input data may not be separable with rectangular classification as in the figure    therefore  our goal is to
maximize the number of interesting points classified in the rectangles  while keep the number of unwanted points as small as possible
in them  in the following sections  we will define several penalty
functions for misclassification and formulate an optimization problem for the case with one rectangular boundary  then we will extend our framework to handle multiple rectangles at the same time 

   

classification error for one rectangular region

we would like to define two types of classification error  type a error quantifies the amount of violation when unwanted points are located inside the rectangle  similarly  type b error is incurred when

fivolved in our objective  which are concave  this term prevents us to
directly apply convex optimization techniques  thus we use some
trick to formulate the problem as a milp which will be described
in section     

   

classification error for multiple rectangular regions

lets define a variable l as the number of rectangles  then every
terms we defined at the previous section can be used with index l to
represent they are the terms regarding lth rectangular region  thus
l
l
we can write yik
and zjk
as
l
yik
  max kl ai  kl     
l
zjk
  max kl bi   kl     

yil   min yik
k

figure    classification error for one rectangular region 

zjl  

 
x

zjk

k  

if we consider all l rectangles  then we have non zero type a error
when ai point is enclosed by any rectangular boundary  so  we
can represent type a error as yi   maxl yil as shown in figure
   likewise  type b points are located outside of all rectangles to
have non zero misclassification  therefore  we can formulate it as
zj   minl zjl   figure   shows type a and b errors when we
use two rectangles  as a result  for the case with l rectangular
boundaries  our optimization problem becomes 

ma
x

min y z

i  

l
yik
l
zjk

   

 

mb
x
j  

min
l

 
nx

l
zjk

k  

o

i              ma   l  k
j              mb   l  k

i              ma   l  k

j              mb   l  k

 
   
k       l  
   
 

where

 

 
 



milp formulation using integer variables

as noted at the beginning of this section  our objective function
is not a convex function  to reformulate the problem as a convex
form  we introduce new variables  lets consider type b error term
first 
vjl  zjl tlj
l
x

where ai is ith input data with label a  bj is j th input data with
label b  ma is the number of input data with label a and mb is the
number of input data with label b 
yik is an error incurred by ith data from kth side of the rectangle
and zjk is an error by j th data from kth side of the rectangle  when
a type a point is in the rectangle  then all the yik are positive  thus 
we define type a error of ith points as yi   mink yik   on the contrary  type b error happens when type b points have atpleast one
positive value of zik   type b error can be set as zj    k   zjk  
then our goal is to minimize the sum of two error terms over all
input points  however  we have the sum of minimum functions in 

k

l
zjk
 kl bj   kl

figure    classification error for multiple rectangular regions 

yik   max k ai  k     
zjk   max k bj   k     
i              ma   j              mb   k              k


 
     
for k        
   
 
 

l

l
yik
 kl ai  kl

s t 

our target points are not included in the rectangle  in figure    yi
is type a error of ith data point with label a and zj represents type
b error of j th point with label b  if we define a rectangle as a hyperplane set  k x   k   k                  type a and b error can be
formulated as follows 

l
max min yik
  

where tlj is     integer

tlj    

l  

tlj are integer variables that can have values   and   only  also 
since the sum of l variables is one  only one tlj will have the value
of   while other l    terms are zero  here  we want to make

tlj     where l   argminl zjl so that we have
l
x
l  

vjl   min zjl   min
l

l

 
nx

k  

o
l
zjk
 

fito enforce the relation  lets introduce underestimate of minimum
function by piecewise linear and convex envelope as done in  ryoo
      ryoo and sahinidis       
vjl  max zjl   m tlj  m    

j              mb   l

where m is an arbitrary positive number that is greater than the
maximum value of zjl   we can see that vjl will have non zero value
only when tlj     and the optimization process will minimize vjl to
have the minimum of zjl for each j  as a result  the terms relevant
l
in the objective function can be formulated into 
to zjk
mb
x

min
l

j  

 
nx

l
zjk

k  

o

mb l
x
x

 

j

k

l
ui   max uli   max min yik
 
l

k

then  we can redefine ui using integer variables and the underestimate as follows 
ulik

where slik is     integer

l
max yik



ui  uli  

 
x

i              ma   l

k  

x

slik    

min

u v y z t s

l

i  

k

ui

ma
x

c 

ui   c  

i  

s t 

mb l
x
x

l
yik


 
 
x
ulik
ui 

vjl

m slik

j              mb   l

m

i              ma   l  k

i              ma   l

k  

l
x

tlj    

 
x

slik    

j              mb   tlj        

l  

i              ma   slik          l

k  
l
yik
 kl ai  kl
l
zjk



kl bj

 

kl

i              ma   l  k

i              ma   l  k

l
zjk
 

j              mb   l  k

 

ulik

 

  wl       hl     

l  

 

clustering results
clustering results

we applied our algorithm to a test data set with    type a points
and    type b points  we used c      c        c        as weighting terms  ampl cplex is used to solve milp  figure   shows
the visualization of the results we obtained  when no additional
constraint is applied  the optimizer finds arbitrary axis aligned rectangles to minimize objective function  this case gives the tightest
rectangles that fit input data as shown in figure   a   if we give
fixed aspect ratio constraints      in this example  all boundaries
has the same shape but different scales  for l   case in figure
  b   we can see that rectangular regions are less tight than the case
for arbitrary rectangles  but it still tries to find the best ones with
same aspect ratio  figure   c  is obtained by locating fixed size
rectangles to reduce error terms  since the area of each rectangle is
the same  the third term in objective function are not taken into account  the solver places fixed size rectangles in the best locations 
the result looks quite compelling  which confirms the correctness
of our problem formulation 

   

the effects of the weighting terms

j              mb   l  k

l
yik
 

vjl

j   l  

l
x

wl   hl
w l        hl     

   

j   l  

vjl  zjl   m tlj  m
ulik

vjl   c 

i  

combining all together  our final convex optimization problem using integer variables becomes 
minu v y z t s

i  

mb l
x
x

moreover  we can specify the aspect ratio of the rectangle or exactly fix the dimension of the rectangles by adding the following
constraints 

l
consequently  our objective function for yik
becomes 
ma
x

ui   c  

hl wl      h l   wl   

i              ma   l

l
max min yik
  

ma
x

hl and wl correspond to the height and width of lth rectangle  thus 
the third term will make tighter rectangular bounds and user can
control c  to change the strength of the effect  this term also has
the effect of minimizing the area of the rectangles because it is minimizing the upper bound of the area  this relation come from the
following inequality 

k

ma
x

c 

hl    l    l
wl    l    l

  m slik  m    

ulik

applying additional geometry constraints

since our problem formulation involves only linear constraints  it is
straightforward to add additional geometry constraints to determine
the shape of rectangular regions  first  we can add quadratic terms
in the objective function to control the dimensions of the rectangles 

l

l
uli   min yik
 

l l
ulik   yik
sik

   

vjl

now objective function becomes linear  we can apply the same
l
linearization trick to type a error yik
  lets define the following
variable ui  

l

where c  and c  are weighting parameters  if we increase c 
weight by fixing c    then we consider type b errors are more important and optimization will try more to reduce type b classification error  on the contrary  if c  is increasing while c  is fixed 
then optimization will focus more on trying to exclude bj points 

j              mb   l
i              ma   l  k

here  we briefly show how the results will change depending on
the weighting terms in the objective function  first  we compare
the effect of first two terms of the objective  we set c     and use
c               the red rectangle in figure   a  corresponds to
c      case which has the largest area among three  it tries to minimize misclassification of type b data and the rectangular region

fi a  clustering with arbitrary size rectangles
 a  original

 b  l  

 c  l  

 d  l  

figure    results of clustering applied on real image data

 b  clustering with rectangles with     aspect ratio

 c  clustering with fixed size rectangles

figure    clustering results with different constraints for l      
    c      c       c       

 a  weights on type a and b mis   b  weights on the dimensions of a
classification
rectangle

figure    the effects of changing weight terms in the objective
function 

includes all type b points  on the other hands  the dark color rectangle  when c        makes correct decision for all type a points 
forcing them to be located outside the rectangle  figure   b  shows
the effect of the third term in the objective  let c      c      and
c                    as c  gets bigger  the resulting rectangular region becomes smaller  bigger c  is represented as darker color in
figure   b   this experiment shows that each term in the objective
function plays an important role in deciding the best classification
result and users can tweak the weighting parameters to obtain the
boundaries they want 

 

image capturing application

in this section  we will talk about a novel way of capturing image
data using our algorithm  the readout speed of imaging system is
often bandwidth limited and it becomes a bottleneck for increasing
capturing frame rates  for the limited amount of pixel budget you
have at a certain amount of time  it will be better if we can only capture image data that we are more interested in  rather than capturing
every pixel from whole scene  thus  we can adaptively design an
efficient image readout scheme by determining which information
is more interesting and how to capture that data efficiently  since

most image sensors are restricted to readout only rectangular windows from sensor plane  determining how to capture data becomes
a problem of deciding rectangular regions that efficiently incorporate important pixel data  thus  once you determined which regions
are more important  the next step can be solved by applying the algorithm discussed in this project 
for instance  lets say you cycle through multiple exposure levels by
changing parameter settings every frame to capture high dynamic
range video  if over exposed or under exposed regions are clumped
in small regions  you will want to capture only badly exposed regions again since most parts of image are already well captured by
mid exposure frames and you dont want to waste your pixel budget to capture them again  in this case  badly exposed pixels are
points you want to put inside rectangular regions in next capture 
while the rest of the area is supposed to be at outside of rectangles 
this case is shown in figure    here  we want to set the regions
so that we can capture most of over exposed area while minimizing total readout time  we defined interesting pixels as the ones
with value higher than the threshold  which means that they are saturated  a mask is generated to use it as an input data set for the
algorithm  figure   b  through   d  show the results applied on
   x     image for the cases of one  two and three rectangular regions  the total readout time for each case will be determined by
actual image sensor characteristics  the total readout time is the
sum of pixel readout time and overhead time  pixel readout time is
proportional to the sum of area of all rectangular regions and overhead time grows as the number of rectangles increases  thus  if the
sensor has very small overhead time  then having more number of
rectangular regions will result in less total readout time  however 
if overhead time is big relative to pixel readout time  using one or
two rectangles will be optimal 

 

conclusion

in this project  we have proposed an unsupervised clustering algorithm that classifies binary labeled data into two regions separated
by multiple axis aligned rectangles  by formulating the problem as
a mixed integer and linear programming  we are able to determine
the boundaries of multiple rectangles at the same time  it gives satisfactory results and easily extended to problems with additional
constraints such as enforcing rectangles to have specific aspect ratio or fixed sizes  we also demonstrated that this method can be
applied to real image data to come up with an optimal image capturing scheme 
we believe that it will be very useful to extend this method to be
applied on larger data sets  rather than using all input data samples 
finding a better representation of data by pre clustering can help
reducing the amount of computation required  using hierarchical
approach with some heuristics may give reasonable results in much
less time  also  our framework will serve as a good reference in
evaluating various heuristic approaches 

fireferences
ryoo   h  s   and s ahinidis   n  v        analysis of bounds for
multilinear functions  j  of global optimization               
ryoo   h  s        pattern classification by concurrently determined piecewise linear and convex discriminant functions  comput  ind  eng              

fi