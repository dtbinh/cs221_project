mood detection  implementing a facial
expression recognition system
neeraj agrawal  rob cosgriff and ritvik mudur

   introduction
facial expressions play a significant role in human dialogue  as a result  there has been
considerable work done on the recognition of emotional expressions and the application of this
research will be beneficial in improving human machine dialogue  one can imagine the
improvements to computer interfaces  automated clinical  psychological  research or even
interactions between humans and autonomous robots 
unfortunately  a lot of the literature does not focus on trying to achieve high recognition rates
across multiple databases  in this project we develop our own mood detection system that
addresses this challenge  the system involves pre processing image data by normalizing and
applying a simple mask  extracting certain  facial  features using pca and gabor filters and then
using svms for classification and recognition of expressions  eigenfaces for each class are used
to determine class specific masks which are then applied to the image data and used to train
multiple  one against the rest  svms  we find that simply using normalized pixel intensities
works well with such an approach 

figure    overview of our system design

   image pre processing
we performed pre processing on the images used to train and test our algorithms as follows 
   the location of the eyes is first selected manually
   images are scaled and cropped to a fixed size      x      keeping the eyes in all images
aligned
   the image is histogram equalized using the mean histogram of all the training images to
make it invariant to lighting  skin color etc 
   a fixed oval mask is applied to the image to extract face region  this serves to eliminate
the background  hair  ears and other extraneous features in the image which provide no
information about facial expression 
this approach works reasonably well in capturing expression relevant facial information across
all databases  examples of pre processed images from the various datasets are shown in figure a below 

fifigure  a  top  orignal images  bottom  processed
images with mask

figure  b  top  pre processed images  bottom  l 
norm of the gabor bank features

   feature extraction
    

normalized pixel intensities

every image in our training set is normalized by subtracting the mean of all training set images 
the masked region is then converted to a column vector which forms the feature vector  this is a
common  albeit nave  approach     and produces a feature vector of length        elements 

    

gabor filter representations

gabor filters are often used in image processing and are based on physiological studies of the
human visual cortex      the use of gabor filtered facial images has been shown to result in
improved accuracy for facial expression recognition              one approach to using these
filters is to generate a bank of filters across multiple spatial frequencies and orientations  the
filtered outputs are then concatenated  and down sampling or pca is often used to reduce
dimensionality  we use an approach similar to     that provides competitive results  and use the
l  norm of each of the gabor bank features for a given image  our gabor bank contains filters at
  spatially varying frequencies and   orientations  figure  b shows examples of our gabor
features 

   eigenface masks
the feature vectors discussed above suffer from high dimensionality  which can cause overfitting during classification  one approach to reducing the dimension of the feature vectors is to
apply principal component analysis  in      eigenfaces are used to generate a mask that
eliminates pixels that vary little across training samples in different labels  in our system  we
modify the approach to generate a separate mask for each expression class  the procedure is as
follows 
   pca is applied separately to images in each class and the first    principal components
are stored to represent the class subspace
   images of a given class are projected onto all other subspaces and then reconstructed
   the average reconstruction error is determined for all training samples within a class 
   pixels above the   th percentile rank  i e  high reconstruction error  are used in the mask
for the corresponding class  this gives a feature vector length of      

fithis approach stresses those facial regions  and pixels  that are most significant in defining a
particular expression  a few samples of the generated masks are shown in figure   below 

figure    top  training images of class contempt  happy  angry and
surprised  from left to right   bottom  masks generated by our method

   classification
in order to use the eigenface masks described above  we train five different one against rest
svms  one for each expression class except neutral   the algorithm is as follows 
classification algorithm
training
for each class i except neutral  
separate data into two groups of
 label i v s not label i
construct feature vectors using the class mask for class i
train one vs rest svm
 
testing
for each class i except neutral 
construct feature vector for the test image using the class
mask for class i
calculate probability of the test image being of label i
using the corresponding svm model
 
if  max prob    threshold 
label   class with the max probability
else
label   neutral
table    classification algorithm using eigenface masks

fi   experimentation and result
in order to focus on recognition across databases  we combined three publicly available image
datasets for training and testing our system  an appropriate subset of cmu pie     tfeid    
and ar    databases were chosen  only frontal images were chosen with uniform illumination
throughout the image  with multiple expressions of each subject  and subjects were limited to
those without glasses  our final dataset comprises of     images and six facial expressions 
for the evaluation of our system  we used the publicly available libsvm     library  the svm
was trained using a gaussian radial basis function kernel  we also used parameter fitting to get
the best values for the parameters            and c  c      coefficient in the regularization
term  to the svm kernel in the following equation 
since  our experimentation involves dividing the dataset randomly to get training and testing
images  each experiment was repeated for      iterations and average results obtained for
overall accuracy  figure   shows the roc curve for neutral expression with varying threshold
parameter  we used the roc to determine a threshold which gave a small false positive rate
while also correctly labeling most of the true positive  true neutral  expressions  we obtained a
threshold of     
in order to evaluate the overall performance for each expression  we used     of images of each
class for testing and a varying fraction of the remaining images for training  figure   shows the
training set error as we vary the training set size  the test error generally decreases with increase
in training set size for all classes 
test set error v s training set size

roc curve for neutral v s rest
   

 

normalized pixel values
l  norm of gabor filters

   
   

angry
contempt
disgust
happy
neutral
surprised

    

test set error

true positive rate

   
   
   
   
   

    

   

    

   

   
   

    
   
 

 

   

   

   

   

   

   

   

   

   

 

 
  

  

  

  

  

  

  

  

training set size  as   of full training set 

false positive rate

figure    left  roc curve for neutral v s rest of the labels  right  test set error v s training set size

table   shows the accuracy obtained for various expressions when using     images for testing
and remaining images for training  the accuracy for surprised and happy expressions was
observed to be relatively higher than other expressions   since these expressions did not vary
much across datasets  
angry

contempt

disgust

happy

neutral

surprised

gabor

     

     

     

     

     

     

pixel

     

     

     

     

     

     

table    accuracy     of recognition for each class  using both gabor and normalized pixels as features

fi   conclusion
in our final system  an approach using eigenface masks was developed and implemented to
classify facial expressions across publicly available databases  these learned masks along with
feature vectors of the image were used to train the svm  this method produced competitive
results across significantly varying databases 
the results were similar for both the normalized pixel value and the gabor filtered feature
vectors  with neither representation being clearly superior to the other  the performance across
databases is indicative of the methods robustness to variations in facial structure and skin tone
when recognizing the expression 
however  both representations of the feature vectors end up being very high dimensional  this
hurts the run time of the algorithm hampering the ability to use it in real time  as well as leading
to possible over fitting of the data during training  increasing the number of available training
images would help to compensate for over fitting  additional improvements to the method may
be obtained by experimenting with other techniques  for example using ica to further reduce
dimensionality       the use of adaboost in conjunction with gabor representations of the image
     and the use of facial action units      

references
    b  fasel  juergen luettin  automatic facial expression analysis  a survey  pattern recognition  vol     
no     pp           january     
    daugman  j g    two dimensional spectral analysis of cortical receptive field profiles   vision
res   vol          pp       
    seyed mehdi lajevardi  margaret lech   averaged gabor filter features for facial expression
recognition   digital image computing  techniques and applications  pp             
    bartlett  m s   littlewort  g   frank  m   lainscsek  c   fasel  i   movellan  j    recognizing facial
expression  machine learning and application to spontaneous behavior   computer vision and pattern
recognition        ieee computer society conference on   vol    no   pp          june     
    carmen frank and elmar noth  optimizing eigenfaces by face masks for facial expression
recognition  computer analysis of images and patterns vol             pp         
    sim  t   baker  s   and bsat  m        the cmu pose  illumination  and expression  pie  database 
in proceedings of the fifth ieee international conference on automatic face and gesture recognition
 may                 fgr  ieee computer society  washington  dc     
    li fen chen and yu shiuan yen          taiwanese facial expression image database
 http   bml ym edu tw download html   brain mapping laboratory  institute of brain science  national
yang ming university  taipei  taiwan 
    a m  martinez and r  benavente    the ar face database   cvc tech  report          
    chih chung chang and chih jen lin  libsvm   a library for support vector machines       
software available at http   www csie ntu edu tw  cjlin libsvm 
     bruce a  draper  kyungim baek  marian stewart bartlett  j  ross beveridge  recognizing faces
with pca and ica  computer vision and image understanding  volume     issues      special issue on
face recognition  july august       pages        
     ying li tian  takeo kanade  jeffrey f  cohn   recognizing action units for facial expression
analysis   ieee transactions on pattern analysis and machine intelligence  vol      no     pp         
feb      

fi