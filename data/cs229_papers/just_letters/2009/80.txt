final report for cs    

machine learning for pre emptive identification of
performance problems in unix servers
helen cunningham
abstract  the goal of this work is to use machine learning to understand server performance in a sunraytm
client server network  preliminary work shows differences between the data emitted by servers who are
performing well versus data emitted by those that are performing poorly  these differences emerge early in
an operational day  and so give an opportunity to pre emptively identify servers that will be operating in an
abnormal manner later in the day  the project reduces the size of the dataset by computing a covariance
matrix between the different system variables and doing supervised and unsupervised learning in this space
 instead of the time domain   k means clustering found   variable groups corresponding to hardware and os
subsystems  support vector machine algorithm was used to classify correlation output and raw data 

introduction

i  building a model of normal behavior

client server networks require high levels of
performance assurance to guarantee fast and
uniform response time for all clients  applications 
threads  and network processes operating at any
given time  in the sunraytm thin client system  this
is particularly important as nearly all application
processing    including graphics rendering    occurs
on the server and is communicated to the client in
udp packet streams  in this setting  performance
decrements manifest in subtle ways  often appearing
suddenly and disappearing just as quickly 

a sample of unix variables for    consecutive
wednesdays for    server machines was obtained 
after procedures detailed in  milestone  report
 but omitted here   we ended up with     serverday datasets that we knew to be normal  and   
that we knew to be atypical 

preliminary studies of memory  floating point
operations  and network variables have shown that
no single variable effectively captures the state of a
system for the purposes of performance evaluation 
and it is apparent that an effective characterization
of system performance must use a multivariate
model of system state 

a correlation matrix was formed for each of the    
 normal datasets  and a randomly selected subset of
   were inspected visually by running the matrix
through matlab s  surface  function which maps
a value to a color  an example surface  heat map 
is shown in figure    where data from several
similar looking datasets have been aggregated 
dark red cells correspond to high positive
correlation  dark blue cells correspond to high
negative correlation  pale green cells correspond to
zero correlation 

the purpose of this project is to observe and model
server performance and to devise measures that can
be used to classify  healthy  vs   suspect  servers 
a sun internal application samples and stores data
from the solaris  kernel  at    minute intervals  the
   minute samples are corrected for timestamp
irregularities  differentiated where cummulative 
then interpolated and smoothed 

covariance or multiple correlation reduces the time
series to a single number that relates each variable
to each of the other variables  and so realizes a large
reduction in size of the dataset 

after removing variables lacking non zero data  we
had    variables 
the        x    correlation
matrices were subjected to k means clustering to
see if variables from sub systems of the operating

fisystem  e g  cpu   user   disk   memory   and
network related variables  would cluster together  if
so  then we have reason to believe that
an
automated learning algorithm will  at the very least 
recover what we already know about the system  in
order to find  k  for the k means clustering  the
bayesian information criterion  bic  was found by
running     iterations of each of    values for k
       with random starting points 
see the
 milestone report  for details 
figure   shows the    clustered variables plotted in  
dimensions 
ovals added manually to highlight
structure  and descriptive labels derived from each
cluster s members  with clusters identified  the heat
map visualization was improved by reordering the
variables to group them by cluster  figure   shows
the resulting aggregate heat map 

figure    normal heat map

figure    distribution of normal correlations

figure    variable clusters in   d plot

mean           sd         
the same process was followed for server day
datasets identified as  atypical   figure   shows
one example of an atypical heat map  note that
the cluster structure is weak  figure   shows the
distribution of correlations for datasets identified as
atypical  against an aggregate  formed by cell wise
averaging  of all    atypical datasets  atypical
datasets have low correlation with their own
aggregate  meaning that they are heterogeneous in
their atypicality 
figure    an atypical heat map

ii  finding servers with atypical behavior
the    dataset template was used as a standard to
which all     datasets were compared by unraveling
the correlation matrix into a vector and correlating
against the template  the distribution of resulting
correlations looks truncated normal  see figure    

fiby contrast   normal  datasets are highly
homogeneous with respect to their aggregate 
figure   
distribution of correlations for
atypical datasets against atypical aggregate

mean           sd         

iii  using supervised learning to classify
servers   approach
   compose a training set of m datasets  in which
some proportion  p  are known to come from
 healthy  servers and some proportion     p  
come from servers visually identified as
 suspect  
   run multiple correlation on each set  send the
correlation matrices to a supervised machine
learning algorithm  support vector machine 
using positive and negative examples identified
from earlier steps 
generate a classification
output and examine the accuracy of this
algorithm in classifying the correlation outputs 
use different ratios of  healthy  to  suspect 
servers in the training set  to see how this choice
impacts the test error of the classification step 
see next section 
   also train an svm on the raw data instead of
the correlation outputs  it may be possible to
speed up and streamline classification by
skipping the computationally intensive multiple
correlation step 

iv  training set composition   test
error
intuitively  the training set must contain
examples of both positive and negative cases 

but one can ask  how many of each   does the ratio of
positive to negative traiing cases matter 
in the
absence of knowledge about the test set  then a      
ratio makes sense  but what if we have knowledge of
the ratio in the test set  i e   the real world   for
example  in the case of  healthy  and  unhealthy 
servers in a data center  there will always be more
healthy servers than unhealthy ones  or at least the
center s personnel hope so  if we want to train an
optimal classifier to detect a relatively small number of
unhealthy servers in a large group of healthy ones 
does it make sense to train the classifier on a ratio of
positive and negative cases that matches the realworld ratio  or is       best 
there is probably a straightforward mathematical
answer to this question based on the properties of the
svm algorithm  however  this author lacks the skills
required to examine the problem from that angle and
it is possible to test the idea empirically  accordingly 
the svm algorithm was run under a set of varying
training example ratios  as shown below  there were
    normal servers and    atypical ones in the set 
which constitutes a ratio of about     to    for the
study  random samples were drawn from the entire set
according to varying ratios of normal to atypical
servers 
normal atypical ratios used were                         
and      in combinations ranging in magnitude from
   normal    atypical up to     normal     atypical 
multiple     or      runs were conducted for each
ratio  with each run being a different random sample
from the set  and mean and standard deviation for the
ensemble of runs were computed  we started out
with sets of     but they took a long time  so switched
to runs of    
the svm software used for this study is the
smo train m script developed in problem set    of the
cs    course  autumn        its default settings are
     for tolerance and    for maximum number of
passes through the training set  these are the values
used for classification of correlation outputs 

fifigures  a e show the test error distributions for
each     or     iteration run  they are roughly
gaussian  truncated at the low end and long tailed
on the high end 
medians would give lower
estimates of test error  but means in this case are
more conservative and for comparisons the two
should be equivalent 
figures  a e

 a histogram of normal     atypical           ratio 

 b histogram of normal     atypical           ratio 

 c histogram of normal     atypical           ratio 

 d histogram of normal      atypical           ratio 

 e histogram of normal     atypical           ratio 

distributions from the           training set ratios
had average stddev of       compared to       for the
        ratios  and so are more variable  figure  
shows mean test error wrt training set size  for
various ratios  with standard deviations of           
most of these differences are not statistically reliable 
but the elevation of the           test error may be
real  and taking that together with the greater spread
of the distributions  better generalization performance
probably comes from a training set that mirrors the
expected test set s ratio of  positive  to  negative 
cases 
note   figure   is an update of the plot
shown at the poster session  and reflects additional
runs of random draw study   best  test error is now
around      

v  using svm to classify raw data
so far we ve done classification on the outputs of
multiple correlation  as shown in figures   and  
above  the template match distributions of normal
and atypical servers are well separated  though not
linearly separable  and our simple classifier achieved
test error of about      under the best choice of
training sets we could come up with 
but
correlation takes time because at least n n     
correlations are needed  where n is the number of
variables  it is of theoretical and practical interest to
ask whether the same classification results can be
obtained using the raw time series data and skipping
the correlation step 
so we ran the same smo train svm algorithm on raw
data files  by unraveling the    variable by     
interpolated time sample matrix for each

fifigure  
note   the poster showed a plot of mean test error
for the svm raw data classification  but with these
distributions mean error is not a good measure of
what is going on  what is going on 

vi  fun with svm

server day into a long vector 
initial trials
indicated the default settings  tolerance      and
max passes     were giving high and variable
test error  so we decreased tolerance to       and
increased max passes to    and got lower mean
error 
but this greatly increased the time
required to get a result  and  upon examining
the test error distributions  it became clear that
something puzzling is going on  figures      
show the distributions using     normal atypical
training set ratios  they are bimodal with spikes
in both the     error range and the     error
range 
given a binary classification task  a
random classifier would have a     error rate  so
could the spike near     mean the classification
is  correct  but for a sign change 
figure  

histogram of normal       atypical           ratio 

figure  

linear svm classification can also be used on datasets
preprocessed with pca or cross correlation  these
methods are visualizable in a  d space  figure   
shows normal   atypical servers plotted by crosscorrelation of unix variables users   run queue 
normal  green  have high magnitude  y axis  and
near zero lag  x axis   and are tightly clumped in the
  d space  atypical  red  have low magnitude and
high variance in lag  this dataset was linearly
separable 
 nice     though the plot seems to be
missing at least green support vector    in figure    
svm uses radial basis function to cluster unix
process  tcp  user  and disk 

figure    

 

figure   

 
discussion
normal servers have a  correlation print  that is
distinctly different from atypical servers and the
difference is classifiable by a simple svm algorithm 
however  svm on the raw data seemed to reversed
the classification of about     of the test set  is this a
property of the algorithm  the dataset  or an
interaction of the two  an error of this author  if we
can get raw data svm to work  then how should it be
visualized  is there a  d representation 
correlation outputs are approximately gaussian
distributed  so this report should have included a
gaussian model such as discriminant analysis or factor
analysis  and compared it with svm in terms of
accuracy and efficiency  unfortunately  time ran out 

histogram of normal        atypical           ratio 

it s been a great class  thanks 

fi