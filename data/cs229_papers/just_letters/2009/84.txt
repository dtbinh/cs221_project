automatic ranking of images on the web
hanghang zhang
electrical engineering department
stanford university

zixuan wang
electrical engineering department
stanford university

hhzhang stanford edu

zxwang stanford edu

abstract
we propose a new way to automatically nd representative images of a specied object category  given a large
collection of images returned by a web search for an object category  our approach learns the similarities among
images without any user help  we extract local features
from images  and represent each image using bag of words
model  the similarity of a pair of image is measured by
computing the distance between two signatures  after we
get the similarity graph  we run pagerank     algorithm to
nd representative images  we present results and a user
evaluation on a variety of object categories  demonstrating
the effectiveness of the approach 

tical to use geometric verication to check the consistency
between two images  which causes nding the similarity between two images is difcult  to solve this problem  our intuition is the canonical image should share the most features
with other images in the same category  we build a graph 
in which each vertex represents an image and the weight of
the edge reects the number of common features that two
images share  after having the graph  we use pagerank    
to assign a rank value to each vertex  vertices with higher
rank values are viewed as the canonical images 

   introduction
in this project  our goal is to rank images which have the
similar semantic meaning  the images can be the results
returned by common image search engines or other existing
image data sets like imagenet      figure   shows two examples  the rst example shows when we search stanford
gates building in google images and the second example
shows the rst page of vaulting horse in the imagenet  the
current search engines optimize the search results for popular keywords  but the results for less popular keywords are
still not organized in a desirable way  we consider the images that share most similarities with rest of the images the
most typical image in the collection and rank these images
on the top  for example  we do not want the panda image with a large potion of people appears in the rst  we
would like to see the canonical view of the object on the
top  we will mainly develop and test our algorithm using
imagenet  but the algorithm can be applied to other image
categories  including google image  or flickr   this work
is different from the previous work like nding iconic images     or re rank images returned from the search engine
     because the variance of images in each category is very
high  objects in the same category have the same semantic
meaning but with quite distinct appearances  it is not prac 

 a  images returned by querying stanford gates building

 b  images of vaulting horse synset

figure    image collection before ranking

fi   previous work
recent work in content based image retrieval has mimicked simple text retrieval systems using the analogy of visual words       images are scanned for salient regions and
a high dimensional descriptor is computed for each region 
these descriptors are then quantized or clustered into a vocabulary of visual words  and each salient region is mapped
to the visual word closest to it under this clustering  each
visual word has an inverted index  which records the index of images that contain it  this can improve the speed
for the retrieval  reducing the number of images to compare
from the size of corpus to the number of images that share
the same visual word with the query image  an image is
then represented as a bag of visual words  in which tf idf
 term frequency  inverted document frequency  can be used
and these are entered into an index for later querying and
retrieval  bag of words model was later applied in natural scene classication      content based image retrieval
     and recognizing landmarks       experiments show
that bag of words model has good performance in these areas 
fergus et al      and lin et al       dealt with the precision problem by re ranking the images downloaded from
an image search  the method in     involved visual clustering of the images by extending probabilistic latent semantic analysis  plsa      over a visual vocabulary  lin
et al       re ranked using the text on the original page from
which the image was obtained 

   approach
     outline
we outline our approach for re ranking images as shown
in figure   
   collect images corresponds to one specic object 
   for each image  detect a set of interest regions and extract local feature descriptors 
   use pca  principal component analysis  to reduce
the dimension of features 
   cluster feature descriptors using hierarchical k means
      each cluster center represents a visual word 
   represent each image by a sparse vector  compute the
distance between pair of images 
   compute the pagerank value for each image 

     bag of words model
we use two types of interest region detectors and in each
interest region  we adopt sift feature descriptor 

   lowes dog detector  scale invariant interest regions
are detected using differential of gaussian detector
     
   afne invariant detector  afne invariant interest regions are detected using harris afne and hessianafne keypoint detectors      
dog interest region detector is scale invariant  harrisafne and hessian afne interest region detector are afne
invariant  for each image  hundreds of local features are
extracted  after we get all features from the category  we
use pca to nd a subspace to approximate the features so
that we can reduce the dimension of features  this step can
reduce the computation time for the following clustering 
then we use k means to cluster those features into vocabulary  large size of vocabulary tends to have better performance since the visual words are more discriminative
when the vocabulary size grows  however  philbin et al 
     shows that when the size of vocabulary goes beyond a
threshold  typically one million  the performance stops increasing  in experiment  we test the performance of our
algorithm using different scale of vocabulary 
we use two methods instead of original k means to generate the vocabulary because when the k is large  each iteration in original k means takes o nk  time which is quite
slow  the rst is to use the hierarchical k means and the
second is to use approximate k means 
     

hierarchical k means

we use a tree structure to represent the whole vocabulary  if
k dening the nal number of clusters  b denes the branch
factor  number of children of each node  of the tree  first 
an initial k means process is run on the training data  dening b cluster centers  the training data is then partitioned
into b groups  where each group consists of the feature descriptors vectors closest to a particular cluster center  we
stop this iteration until the height of the tree reaches l  so 
we get a vocabulary tree whose size is bl   k  the hierarchical k means is faster than the original one but it has
drawback that when the data point lies close to voronoi region boundary for each cluster center  the quantization error is large  when the hierarchical structure is built  we can
quantize new data point in o bl    o log k  
     

approximate k means

in original k means  a large portion computation time is
spent on calculating nearest neighbours between the points
and cluster centers  we replace this exact computation by
an approximate nearest neighbor method  and use a forest
of   randomized k d trees      built over the cluster centers
at the beginning of each iteration to increase speed  the average computation time to nd the nearest neighbor in each

fifigure    pipeline of the re rank algorithm

iteration is reduced from o nk  to o n log k   k log k  
where n is the number of features to be clustered  usually
in a k d tree  each node splits the dataset using the dimension with the highest variance for all the data points falling
into that node and the value to split on is found by taking
the median value along that dimension  in the randomized
version  the splitting dimension is chosen at random from
among a set of the dimensions with highest variance and
the split value is randomly chosen using a point close to the
median  we combine the output found by these trees to get
the best result  a new data point is assigned to the approximately closest cluster center as follows  initially  each tree
is descended to a leaf and the distances to the discriminating boundaries are recorded in a single priority queue for
all trees  then  we iteratively choose the most promising
branch from all trees and keep adding unseen nodes into the
priority queue  we stop once a xed number of tree paths
have been explored  this way  we can use more trees without signicantly increasing the search time  philbin et al 
     show that for moderate values of k  the ratio of points
assigned to different cluster centers differs from the exact
version by less than     after we have k cluster centers 
we compute   randomized k d trees for the quantization 
the average time for quantizing new data point is o log k  
figure   show the parts of visual words we build using
hierarchical k means  to quantize new data point  we use
the soft assignment by assigning each feature to its c nearest
neighbors  we dene the weights to i neighbor as edi  
where di is the distance and  is the control parameter  we
get a sparse vector representation of the image  in which
each entry is the frequency of the particular visual word appears in the image  we normalize the vector to have the sum
of   

     similarity of images
after we get the sparse vector representation for each
image  we can simply use the inner product of two vectors to estimate the distance between a pair of images  it
is fast but it does not consider the relative position of each
visual word  consider the simple example shown in figure
   in which each shape represents a visual word  the tri 

angle is closer to the circle than other shapes  suppose we
only have these four visual words  triangle  circle  rectangle and pentagon  assume image a only contains triangle
so its index ia                and image b only contains circle  ib                and image c only contains rectangle 
ic                 if we compute the inner product  we get
the distance between a and b and the distance between a
and c are the same  but in fact  the distance between a and
b should be smaller due to the triangle and circle are closer
to each other 
to take into account of the relative positions of visual
words  we compute the emd  earth movers distance      
between two image signatures  computing emd is expensive compare with the inner product  recently pele et al      
propose a fast method to compute emd  alternatively  we
can use pyramid histogram matching     to approximate the
optimal solution 
the idea of emd is the following 
in the original emd paper  a signature is represented by
 sj    mj   mj     where mj is the position of the visual
word and mj is the weight given to this visual word  the
integer subscript j ranges from one to the number of features extracted from the specic image  the image index
can be viewed as a histogram hi   in which the vector i index a set of visual words and each visual word has a weight 
so the image index is a signature  sj    mj   mj    
now
suppose
we
have
two
images
 
p
 
  p    p              pm   pm    and q
  q    q              qn   qn     image p has m features
and image q has n features  d    dij   the ground distance
matrix where dij is the ground distance between visual
word pi and qj   we want to nd a ow f    fij   with fij
the ow between pi and qj that minimizes the total cost 
w  p  q  f   

n
m 


dij fij

   

i   j  

subject to the following constraint 
fij   
n

j  

   i  m     j  n

fij  pi

 im

   
   

fim


fij  qj

 jn

   

i  

figure    different local features
n
m 


m
n


fij   min  
pi  
qj  

i   j  

 a  dog keypoint detector

i  

   

j  

once the problem is solved  we have found the optimal ow
f  the earth movers distance is dened as 
m n
i  
j   dij fij
   
emd p  q    m n
i  
j   fij
intuitively  given two signatures  one can be seen as a mass
of earth properly spread in space  the other as a collection of
holes in that same space  then  the emd measures the least
amount of work needed to ll the holes with earth  here  a
unit of work corresponds to transporting a unit of earth by a
unit of ground distance 

 b  harris afne keypoint detector

figure    the positions of visual words

     re rank images

 c  hessian afne keypoint detector

figure    different local features

after we compute the similarity for each pair  we construct a similarity graph  we perform pagerank on this
graph and rank the images  we construct the similarity
graph as follows  we do content based image retrieval for
each image in the corpus and candidate images are returned 
we use the methods above to compute the similarity between the query image and the candidate image and add an
edge connecting these two vertices in the graph  we dene

fithe similarity matrix wn n and rn     where n is the
number of images in the corpus  the element in r is dened as the rank value associate with each image  its stable
state is derived from an iterative procedure as follows 
   dene the similarity matrix wn n as 
wij   edist i j  

 

   

where dist i  j  is the distance metric between image
i and image j and  is the control parameter 
   symmetrically normalize w by
s   d    w d   
where d is a diagonal matrix and dii  

   
n
j  

wij  

   do iteration until convergence
r t        s  r t         y

   

where t denotes the number of iterations and  is the
propagating parameter  y is the initial state representation for each vertex  yi     n   we set r      y  
we sort images according to their rank values in r 

   experiment
     images of the same object
in the rst experiment  we choose ten images from ickr
by searching statue of liberty  when we use hierarchical
k means  hkm  and approximate k means  akm   we get
the same result  the result is shown in figure   
in the second experiment  we take ten photos of the stanford main quad  the result is shown in figure   and figure
  
the running time of two experiments is shown in table
  

     images of similar objects
in the rst experiment  we randomly select    images
from the horn synset from imagenet  top    images after
ranking are shown in figure   
in the second experiment  we randomly select     images from the horse synset from imagenet  top    images
after ranking are shown in figure    
in both experiment above  we use inner product to compute the similarity of images since emd is too slow when
the number of visual word is large 

   conclusion
     analyze the algorithm
the current algorithm works on the static landmarks or
buildings since the feature we use is suitable for describing
the same object  since we do not segment the object in the
preprocessing step  images with complicated background
will affect the accuracy of ranking  for the objects that have
the same semantic meaning  like pictures in one synset in
imagenet  the sift descriptor is not robust enough 

     future work
to eliminate the affect of background  we can segment
the foreground objects rst and compute the visual words
using the foreground objects  to improve the performance
on similar images ranking  we should combine other image features including geometric blur feature     or gist
feature       the current emd algorithm is too slow to
rank images in a large scale  we need to integrate the fast
emd algorithm      to speed up the procedure of similarity
computation  when getting the similarity matrix  we can
also adopt graph cut algorithm to cluster images into subcategories  in which images in the same subcategory have
strong connection 

references
    a  berg and j  malik  geometric blur and template matching 
in ieee computer society conference on computer vision and pattern recognition  volume   
ieee computer society             
    t  berg and a  berg  finding iconic images       
    s  brin and l  page  the anatomy of a large scale hypertextual web search engine  computer networks and isdn
systems                       
    j  deng  w  dong  r  socher  l  li  k  li  and l  fei fei  imagenet  a large scale hierarchical image database  in proc 
cvpr  pages              
    l  fei fei and p  perona  a bayesian hierarchical model for
learning natural scene categories  cvpr  pages        
     
    r  fergus  l  fei fei  p  perona  and a  zisserman  learning
object categories from googles image search  in proceedings
of the tenth ieee international conference on computer vision  pages           citeseer       
    t  hofmann  probabilistic latent semantic indexing  in
proceedings of the   nd annual international acm sigir
conference on research and development in information retrieval  pages       acm new york  ny  usa       
    y  jing and s  baluja  pagerank for product image search 
     
    s  lazebnik  c  schmid  and j  ponce  beyond bags of
features  spatial pyramid matching for recognizing natural
scene categories  citeseer       
     v  lepetit  p  lagger  and p  fua  randomized trees for realtime keypoint recognition  in ieee computer society

fitable    running time

statue of liberty
stanford main quad

feature extraction
    s
    s

hkm akm
       s
       s

inner product emd
       s
       s

pagerank
   s
   s

figure    rank result for statue of liberty images using inner product

conference on computer vision and pattern
recognition  volume    page      citeseer       
     w  lin  r  jin  and a  hauptmann  web image retrieval reranking with relevance model  in ieee wic international
conference on web intelligence        wi       proceedings  pages              
     d  lowe  object recognition from local scale invariant features  in international conference on computer vision  volume    pages                
     k  mikolajczyk and c  schmid  scale   afne invariant interest point detectors  international journal of computer vision                   
     d  nister and h  stewenius  scalable recognition with a vocabulary tree  in proc  cvpr  volume    citeseer       
     o  pele and m  werman  fast and robust earth movers distances  iccv       
     j  philbin  o  chum  m  isard  j  sivic  and a  zisserman  object retrieval with large vocabularies and fast spatial
matching  in proc  cvpr  volume       pages          
citeseer       
     y  rubner  c  tomasi  and l  guibas  the earth movers distance as a metric for image retrieval  international journal
of computer vision                    

     c  siagian and l  itti  rapid biologically inspired scene classication using features shared with visual attention  ieee
transactions on pattern analysis and machine intelligence 
                
     j  sivic and a  zisserman  video google  a text retrieval
approach to object matching in videos  in proc  iccv  volume    pages           citeseer       
     y  zheng  m  zhao  y  song  h  adam  u  buddemeier 
a  bissacco  f  brucher  t  chua  and h  neven  tour the
world  building a web scale landmark recognition engine 
in proc  ieee conf  on computer vision and pattern recognition       

fifigure    rank result for stanford main quad images using inner product

figure    rank result for stanford main quad images using emd

fifigure    rank result of horns obtained in imagenet

figure     rank result of horses obtained in imagenet

fi