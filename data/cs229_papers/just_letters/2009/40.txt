toward a nirs brain computer interface
ilya sherman  nikil viswanathan  and tony wu
dr  xu cui and daniel m  bryant

abstract
nirs is a non invasive spectroscopic method for measuring
oxygenated and deoxygenated hemoglobin concentrations in
cortical regions of the brain  in this report we investigate the
use of machine learning techniques to train a model for online
classification of a specific motor activ ity    finger tapping  using nirs data  thus  nirs measurements of blood flow
serve as an indirect proxy for the direct signal    neural
activity  however  changes in blood flow to and from the
brain are relatively slow  and so there is a significant delay
before the brain activ ity registers at peak level in nirs output 
furthermore  the nirs signal tends to be extremely noisy  as
many factors may play a ro le in the concentration of blood in
the brain  to tackle these problems  we first pre filter the data
to smooth out the noise  and then compute key features of the
data  we use pca and greedy feature selection to improve the
robustness of our features and to reduce overfitting  finally 
we train classifiers using the resulting features to classify
nirs data as corresponding to periods of idleness or finger
tapping 

   introduction
imagine being able to turn on or off a tv not by pushing a red
button on your remote control  but just by thinking  tv on  or
 tv off   as a first step in the direction of brain computer
interfaces  we are wo rking on using the nirs brain imag ing
technique to detect a simp le  strong brain signal corresponding
to periods of active finger tapping  data is gathered through a
fairly simp le experiment  the subject puts on a nirs brain
scanner and is periodically instructed to start or stop tapping
her fingers 

channel layout for the left hemisphere scanner  for each
channel  the nirs scanner detects the concentrations of
oxygenated and deoxygenated hemoglobin  this signal is a
pair of real nu mbers  and is collected with a time resolution of
    seconds  the activity of cortical reg ions of the brain can
also be directly detected by measuring electrical fields 
however  the state of the art technique for measuring such
signals    the eeg technique    is far less practical as a signal
source for a brain co mputer interface  it is more expensive and
less robust than the nirs scanner  in that it does not allow
subjects to move around 
the nirs scanner measures a secondary or derivative signal
rather than the direct source signal of interest  as a brain
region becomes active  it requires energy to maintain its
activity and blood flows into it  bringing o xygenated
hemoglobin  as the oxygen is used up  the hemoglobin
becomes deoxygenated and flows out from the brain reg ion to
be replenished  this is a fairly consistent signal  but it
exhibits an inherent delay  due to the speed of blood flow  in
measuring brain activity 
our goal in this project is to design an online classifier that
can detect brain activity accurately and with a minimal delay   you wouldn t want to have to think  tv on  for ten seconds
straight before the tv actually turned on  the time difference
between when the patient begin tapping and when the
classifier first correctly identifies this is called the onset delay 
previous work has succeeded in designing classifiers with
very high accuracies  but onset delays in the    to   second
range        

   baseline
as a very naive baseline  we ran an svm based classifier
using only the raw nirs measurements fro m channel     the
one that directly measures the cortical region that controls
finger tapping   on the non noisy data set  this resulted in a
training accuracy of about     and an undefined onset offset
delay  by an  undefined delay   we mean that measuring the
delay doesn t make sense for this baseline  it is unable to even
identify any tapping  much less do it with any form of delay 

figure    nirs sensors
the nirs brain scanner is essentially just a head garment with
sensors that can measure blood flow in different regions of the
brain  roughly  each pair o f sensors corresponds to one
channel  the diagram on the right shows the sensor and

delay calculation
it is worth noting that establishing a good metric for the
testing delay is itself a nontriv ial task  the delays we present
are computed as follows  fo r each period of finger tapping
activity  we co mpute the delay to the earliest subregion l of
duration at least three quarters of a second  such that our

 

ficlassifier correctly classified each sample in l positively  we
then take the overall delay to be the mean of the delays over
all periods of finger tapping activity 

   classifiers
    svm
after plotting the raw data following some pre filtering  see
section     we predicted the feature space would form a
approximately linearly separable data set  for this reason a
majority of our trial runs were conducted using svm with a
radial basis function kernel  which resulted in a linear
separating hyper plane  in the end using the right combination
of features history and grad ient we were able to get a test
accuracy of        and a delay of      seconds  we used a
greedy feature selection algorithm in order to get a locally
optimal set of features  see section    

    adaboost
as an alternative to the svm classifier  we t ried using
adaboost to see if we could achieve better performance  we
ran two variat ions on the adaboost algorith m  gentle
adaboost and modest adaboost  adaboost toolbox   using
decision tree stumps for each  using only the features
oxygenated and deoxygenated bloodflow as a baseline  we
started off with an accuracy of around      both variations
performing similarly  and  again  and unbounded delay 
however  using all of the reasonable features  filtered through
pca  gave much better results  gentle adaboost is more
fin icky  prone to overtraining  but with careful parameter
tuning we were able to attain        test accuracy  with less
careful parameter selection  this variation achieved nearperfect training set classifcation  but test accuracies closer to
     modest adaboost is a variation that is inherently
resistant to overtraining  and pretty much any reasonable
parameter setting gave a test accuracy around        with a
similar training accuracy  both variations resulted in a delay
of about     seconds  thus  we found the peak performance of
adaboost to be nearly identical to that of svm  th is offers
some evidence that surpassing the present results likely
requires a radically different approach  perhaps with more
focus on pre processing the data than on novel features or
learning algorith ms 

figure    optimal adaboost output

   features
channel variation
the oxygenated and deoxygenated concentrations from
channel    turned out to be the most relevant to predicting
whether the subject was finger tapping  fro m both a empirical
and theoretical standpoint  however  we found that by using
also the channels adjacent to                  and     see figure
        we were able to improve test accuracy from the baseline
by    and reduce onset delay by     seconds 
gradient slope  rate of change
we looked at slope  rate of change  or first and second
derivatives of the values   in general  changes in bloodflow
through a region of the brain indicates  brain activity  in that
region  by measuring the gradients of the blood flow  the
classifier is able to identify critical transitions more quickly
than it could using a simp le threshold  simply using the
gradient of oxygenated and deoxygenated blood is not helpful
at all on its own  without any pre filtering  

figure    gradient features

figure    optimal svm output

firatio of oxygenated deoxygenated bloodflow
we added this feature as a cross term between the two signals
we could directly measure  but it only resulted in dramatic
overfitting to the training set  see results in section    
linear combi nations of oxygenated and deoxygenated
bloodflow
we chose linear combinations of oxygenated and
deoxygenated bloodflow concentration as one of our features 
which worked out fairly well on top of the pre filtering that we
did  we also took the gradient and second derivatives of these
values and they made  see results in section     somewhat of a
small d ifference in test accuracy 
classifying with look ahead
though we are u ltimately looking for an on line algorithm  if
we incorporate future data  we re able to get astounding
accuracy  in fact doing something as simple as taking
oxygenated data set and smoothing it so that the ith timestep is
the average of the next    time steps gives us astounding
results        accuracy and     seconds of delay  we did not
include these results in the table as they re not usable to the
end product of developing an online algorithm 

previous predicted label
we found that there was a tradeoff between attaining low
delays and high false positive rates  as one way to balance
these  we tried adding a feature that would introduce a penalty
for changing labels over time  of course  if we use the actual
label of the previous datapoint as a feature  this gives almost
perfect accuracy  but is not a valid feature for the test set  as a
replacement  we tried substituting the predicted label of the
previous data point  for the training set  we computed this
feature by initializing it to a constant  and then iteratively
running svm on the training data until the feature values
converged  we then labeled the test data one at a time  and
updated this feature for future data points based on the current
prediction  ho wever  this feature did not end up helping the
performance of the classifier  most likely because it was just
too noisy  a possible direction for further exp loration is to
instead look at the confidence values returned by adaboost 
and reject label transitions that have a confidence value less
than a learned threshold 

   pre filtering
nirs data is inherently noisy  as blood flow through the brain
can be somewhat sporadic  this turned out to be problematic 
as certain features like gradient  depend on a smoothed
surface  and taking the gradient of raw data proved not to be
effective  we exp lored several s moothing techniques that
worked fairly well in reducing the noise  it turns out that
smoothing the data was the singular most effective action in
terms of increasing accuracy and reducing delay 

figure    output without smoothing

figure    output with smoothing
    exponential moving averages
running classification techniques naively led to poor results 
and as we examined the feature space  we realized the need for
some type of smoothing of the data  we first smoothed the
data by taking at each timestep t the exponentially weighted
moving average of the previous timesteps and then normalized
the data afterwards  this proved enormously helpful in
smoothing the data and straightening out features such as
gradient and history  large fluctuations from t imestep to
timestep were removed and we were able to work with a more
natural transformation of the data set  for virtually all of the
features attempted  ema shifted our accuracy from the    
range to the     range 

    other filtering
we also tried other smoothing techniques such as taking the
average every k points  as well as running a low frequency
chebyshev filter  both type   and type     both filters had
litt le additional imp rovement over ema 

fi    reclassifying training data
another approach we tried was converting a two class
problem into a three  or a four class problem  this approach
was motivated by the simple observation that all of the other
approaches we tried either resulted in large delays or in high
false positive rates  this suggests that early finger tapping
blood flows look qualitatively more like a passive state than
an active state  but perhaps the best clustering of the data
would label these early regions as a distinct transition state 
qualitatively unlike either the passive or the active state  thus 
we tried relabeling the data so that early periods of finger
tapping belonged to a different class rather than the same
class  we then ran a one against one multiclass svm
classifier using these labels  finally  we co llapsed early finger
tapping and sustained finger tapping into one class for
evaluating the results  however  this approach proved
ineffective  the accuracies decreased by several percentage
points rather than increasing  one possible reason for this is
that we tried a fairly naive approach for distinguishing
between  early  and  sustained  finger tapping  one
interesting possibility for further explorat ion is to run a
clustering algorithm on the data corresponding to each label 
and assign different sublabels to each cluster 

   principle component analysis
with    channels of raw data  we noticed an increase in
generalization error when adding several features  indicating
overfitting  additionally when trying to decide which set of
brain data channels to use  we initially used all    channels to
figure out the best combination which resulted in each svm
run taking several minutes  when adding features  we needed
the increase in speed from pca  we applied pca as a
postprocessing step on the selected features  chose the first
 sorted by decreasing  k component  which cumulatively
accounted for      of the variance  and then passed the
features projected onto the reduced dimension space  typically
down to     dimensions  into the classifer  as noted above 
this merely imp roved the runtime of the svm classifier  but
actually contributed about    to the accuracy of the adaboost
classifier 

   feature selection
in order to discover the best set of features to use  we
implemented a greedy feature selection algorith m  using a
heuristic of best accuracy to choose the optimal feature to
add  though this might result in a local optimu m  we noticed
that several of the features had similar performance and that
we achieved  at least locally   optimal perfo rmance with just a
few features 

feature
 cumul ati ve 

accuracy
    

delay
 seconds 

gradient history

      

   

history

      

    

gradient scale

      

    

oxydata   deoxydata

      

    

oxygenated data

      

    

oxydata  deoxydata

      

    

deoxygenated data

      

    

gradient

      

    

emad gradient

      

    

oxydata   deoxydata

      

   

table    feature selection algorithm  with ema

feature  cumulati ve 

accuracy

delay

history

       

    

gradient

       

    

deoxygenated data

       

    

gradient sign

       

    

gradient emad

       

    

gradient

       

    

oxydata   deoxydata

       

    

oxydata   deoxydata

       

    

oxygenated data

       

    

oxydata   deoxydata

       

   

table    feature selection algorithm  without ema

fi   remarks   commentary
    which specific features
one majo r insight is that we get approximately the same
accuracy and delay as long as we pick two or three good
features  gradient  gradient history  oxydata   deo xydata 
oxy data   deo xydata  etc   therefore for the purposes of
reducing delay and or improving accuracy  which features we
select don t seem to make that big of a d ifference 

    which classifier
we also found that the specific learn ing algorithm did not
seem to matter too much  except insofar as it can help avoid
overfitting  both the svm approach and the boosted decision
trees approach indicated a tradeoff between low delays and
low false positive rates  with similar results attainable using
either approach 

    pre filtering makes a big difference
we found that pre filtering the data was what made the large
difference in ju mping fro m a        accuracy  adaboost and
svm  respectively  to the mid     range  whether it s taking
the fixed weighted average or an exponential moving average 
the smoothing effect allows the classifier to find cleaner
boundaries within the feature space  almost all the features
 especially gradient  and gradient direction  suffer huge
fluctuations as the nirs data is very noisy  so it makes
perfect sense that smoothing will help the classifier achieve
higher accuracies and better delays 

acknowledgments
we would like to thank dr  cu i and daniel bryant for the
data  advice  and guidance on this project 

appendix
definitions
nirs   near infrared spectroscopy  uses the transmittance of
tissues to detect haemoglobin absorption  this is useful for
tracking blood flow of o xygenated and deoxygenated blood in
the brain  we use this data in order to train on whether the
user is in a state of finger tapping or not 
channel   a location on the brain on the brain where nirs
records bloodflow in a particu lar region  in part icular the
channel we are most interested is channel     as that is the
location of where the motor cortex  the reg ion of the cerebral
cortex that controls motor movements   see diagram above 
onset delay   the difference in time fro m when the subject
begins tapping to when the machine learn ing algorith m first
classifies the time interval as tapping 
offset delay   the difference in time fro m when the subject
stops tapping to when the machine learn ing algorithm first

classifies
the
time
interval
as
not tapping 
accuracy   the percentage of time instances labeled  either
tapping or not tapping  by the algorithm co rrectly

references
    sitaram  ranganatha  caria 

andrea 
birbau mer  niels  hemodynamic b rainco mputer interfaces
for co mmunicat ion and rehabilitation

    sitaram  ranganatha  zhang  haihong  guan  cuntai 
thulasidas  manoj  temporal classification of mult ichannel
near infrared spectroscopy signals of motor imagery for
developing a braincomputer interface

   
adaboost
toolbox  http   graphics cs msu ru ru science research machi
nelearning adaboosttoolbox

libsvm
package  http   www csie ntu edu tw 
cjlin libsvm 

   

    exponentially weighted moving average 
http   en wikipedia org wiki moving a verage expo
nential moving average
   
matlab
chebyshev
filter 
http   www mathworks com access helpdesk help to
olbox signal cheby  html

fi