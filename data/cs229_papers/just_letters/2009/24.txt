machine learning in statistical arbitrage
xing fu  avinash patra
december         

abstract

therefore be neglected  the model suggests a
contrarian investment strategy in which we go
long one dollar of stock p and short beta dollars
of stock q if xt is small and  conversely  go short
p and long q if xt is large 

we apply machine learning methods to obtain an
index arbitrage strategy  in particular  we employ linear regression and support vector regression  svr  onto the prices of an exchange traded
fund and a stream of stocks  by using principal
component analysis  pca  in reducing the dimension of feature space  we observe the benefit
and note the issues in application of svr  to
generate trading signals  we model the residuals
from the previous regression as a mean reverting
process  at the end  we show how our trading
strategies beat the market 

 

opportunities for this kind of pairs trading depend upon the existence of similar pairs of assets 
and thus are naturally limited  here  we use a
natural extension of pairs trading called index
arbitrage  as described in      the trading system
we develop tries to exploit discrepancies between
a target asset  the ishares ftse macq traded
in the london stock exchange  and a synthetic
artificial asset represented by a data stream obtained as a linear combination of a possibly large
set of explanatory streams assumed to be correlated with the target stream  in our case  we use
the stock prices of the     constituents of ftse
    index to reproduce the target asset 

introduction

in the field of investment  statistical arbitrage
refers to attempting to profit from pricing inefficiencies identified through mathematical models 
the basic assumption is that prices will move towards a historical average  the most commonly
used and simplest case of statistical arbitrage is
pairs trading  if stocks p and q are in the same
industry or have similar characteristics  we expect the returns of the two stocks to track each
other  accordingly  if pt and qt denote the corresponding price time series  then we can model
the system as

we start with linear regression on the     constituents and take the window as     days from
april to september       after extracting significant factors by principal component analysis  we calibrate the model cutting the window
size down to    days  closed prices of each asset are used  the emphasis here is to decompose the stock data into systematic and idiosyncratic components and statistically model the
idiosyncratic part  we apply both linear redqt
dpt
  dt   
  dxt  
gression and supported vector regression  and
pt
qt
collect the residual that remains after the dewhere xt is a mean reverting ornstein uhlenbeck composition is done  finally  we study the
stochastic process 
mean reversion using auto regression model in
in many cases of interest  the drift  is small the residuals to generate trading signals for our
compared to the fluctuations of xt and can target asset 
 

fi 

linear regression

we apply principal component analysis to reduce the dimension of the model 

we consider the data of     days from apr    to
sep           the reason we choose this time period is that given     feature variables  we need
at least     observations to train the     parameters in the linear regression model  to avoid
overfitting parameters  we only use     training
examples 
denote pt to be target asset and qit to be the
ith stock constituent at time t  the linear model
can be written as
pt       

   
x

i qit  

i  

implementing the ordinary least squares algorithm in matlab  we get parameters  and
figure    generalization error on    testing days
training errors  i e  residuals 

 

principal
component
analysis  pca 

now we apply pca to analyze the     stocks 
the estimation window for the correlation matrix is     days  the eigenvalues at the top of
the spectrum which are isolated from the bulk
spectrum are obviously significant  the problem
becomes evident by looking at eigenvalues of the
correlation matrix in figures    apparently  the

figure    residuals of linear regression over    
constituents
from figure    we see that the empirical error is acceptable  however  when we test this
linear model using    examples not in the training set  i e  prices of each asset from sep     to
oct            the generalization error is far from
satisfying  as shown in figure    this implies
that we are facing an overfitting problem  even
though weve used the smallest possible training
figure    eigenvalue of the correlation matrix
set  there are so many parameters in the linear
model  which gets us into this problem  hence  eigenvalues within the first twenty reveal almost
 

fiall information of the matrix  now we apply validation rules to find how many principal components to use that can give us the least generalization error  given that the dimension of the
model is reduced  we reset our window size to   
days to avoid overfitting problem  after running
multivariate linear regression within the first   
components using    days training set  we find
that the first    components give the smallest
generalization error on the    testing days  the
out of sample residual is shown in figure   

figure    empirical error on the first    components over    training days

 

support vector regression  svr 

we apply svr on the    feature attributes obtained through pca  we use a gaussian kernel and empirically decide on the kernel bandwidth  cost and epsilon  slack variable  parameters   we used svm and kernel methods matlab toolbox  available online for implementation   we do not notice any improvement in this
approach as seen in the plots of training error
and test error  figure   and figure    a main
issue here is to be able to determine appropriate
svr parameters 

figure    generalization error on the first   
components over    out of sample days

 

we take a quick look back at the empirical error of these    components over    training days 
from figure    we see that the residuals are not
as satisfying as in figure    in terms of magnitude  but residuals here successfully reveal the
trend of residuals using     constituents  thus 
by applying pca to reduce the dimension of the
model  we avoid overfitting parameters  we will
use the in sample residuals from regression on
principal components to generate trading signals
in a following section 

mean reverting process

we want to model the price of the target asset such that it accounts for a drift which measures systematic deviations from the sector and
a price fluctuation that is mean reverting to the
overall industry level  we construct a trading
strategy when significant fluctuations from equilibrium are observed 
we introduce a parametric mean reverting
model for the asset  the ornstein uhlembeck
 

fifigure    empirical error on the first    compo  figure    generalization error on the first   
nents over    training days using svr
components over    testing days using svr
process 

  et
   et
v ar       
 
 
b

dx t     m  x t  dt   dw  t        

the term dx t  is assumed to be the increment
hence  we get
of a stationary stochastic process which models price fluctuations corresponding to idiosyn    log b                 
cratic fluctuations in the prices which are not
a
        
m  
reflected in the industry sector  i e  the residuals
 b
r
from linear regression on principal components
v ar     
in the previous section  note that the increment
          
  
   b 
dx t  has unconditional mean zero and condir
tional mean equal to
v ar  
eq  
         
   b 
e dx t  x s   s  t     m  x t  dt 

signal generation
the conditional mean  i e  the forecast of ex   
pected daily returns  is positive or negative acwe define a scalar varaible called the s score
cording to the sign of m  x t  
this process is stationary and can be estix t   m
s 
 
mated by an auto regression with lag    we
eq
use the residuals on a window of length    days 
assuming the parameters are constant over the the s score measures the distance of the cointewindow  in fact  the model is shown as
grated residual from equilibrium per unit standard deviation  i e  how far away a given stock is
xt     a   bxt   t     t                 
from the theoretical equilibrium value associated
with our model  according to empirical studies
where we have
in this field  our basic trading signal based on
a   m    et  
mean reversion is
 

fi   buy ishare ftse if s       

   days data  that using our strategy based on
the trading signals clearly makes a trading profit
as on average we purchase ishare ftse when
it is low and sell it when it is high  on
the other hand  in the future  idiosyncratic factors behaving erratically  such as occurrence of
some specific unforeseen event  might lead to the
index systematically under performing or doing
much better than the significant factors found
from pca and this could seriously undermine
the effectiveness of our approach  to achieve a
systematic method  online learning would be a
good way to try out  in order to update our feature set with the latest information 

   sell ishare ftse if s       
   close short position in ishare ftse if s  
    
   close long position in ishare ftse if s  
   
the rationale for opening trades only when the
s score s is far from equilibrium is to trade only
when we think that we detected an anomalous escursion of the co integration residual  we then
need to consider when we close trades  closing trades when the s score is near zero makes
sense  since we expect most stocks to be near
equilibrium most of the time  thus  our trading rule detects stocks with large excursions and
trades assuming these excursions will revert to
the mean 
figure   shows the signals we generate over   
days 

references
    g  montana  k  triantafyllopoulos and t 
tsagaris  flexible least squares for temporal data mining and statistical arbitrage  expert systems with applications  vol      issue    part    pp                  
    a  marco and jeong hyun lee   statistical
arbitrage in the u s  equities market  social science research network       
    t  fletcher  support vector macines explained      

figure    trading signals over    days

 

conclusion

we note that pca helped in getting rid of overfitting problem with     feature attributes  while
conducting linear regression  however  we see
that to effectively apply support vector regression  a technique to learn svr parameters might
have to be developed  we see on testing  over
 

fi