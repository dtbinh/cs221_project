region of interest identification in
breast mri images
jason forshaw

ryan volz

jasonlforshaw gmail com

rvolz stanford edu

abstractidentifying the region of interest in a breast mri
image is a tedious manual process that would be much more
suited for a computer  but it is necessary for performing useful
post processing on the image for breast cancer research and
treatment  we devise such an approach following the concept
that an mri image can be sectioned into a number of contiguous
regions based on pixel intensity clusters and edge detection  we
then train an svm algorithm to identify the specific sections that
belong in the region of interest  although our approach is not yet
ready to replace hand drawn regions of interest  the technique
shows promise for eventually being able to do so 

i  i ntroduction
in breast cancer research  magnetic resonance imaging
 mri  is being explored as a potential tool for monitoring
tumor size and assessing response to chemotherapy  currently 
researchers and clinicians often manually interpret mri images  but as mri gains wider adoption in the clinical realm 
the need for fast and robust automated image processing
techniques is becoming clear  in order to be able to process the
raw images and extract the required data  it is first necessary
to identify the region of interest  roi  of the image  roughly 
the roi should include all fibroglandular  breast  and fat tissue
but exclude other portions of the image such as the skin 
chest wall  and image artifacts  as of now  identification of
the roi is done manually by drawing a single closed contour
that encompasses the breast tissue and fat  the purpose of
this work is to apply machine learning techniques in order to
automate this process  in particular classifying one section of
an mri image as the roi 
as mri advances  the number of   d images collected
during an exam increases  within our data set  the number
of images per scan has increased over time from    to    
images  with hundreds of images per mri scan and multiple
scans necessary per patient during the course of treatment 
considerable time must be invested into identifying the roi
by hand  another benefit of this project is standardization of
the roi  with the current manual process  different research
groups and even different people within the same group may
identify the roi of a given image differently  this is not from
lack of agreement on what should be included in the roi 
but rather it is from different interpretations of the how the
contour should best be drawn 
the data we have used for this research  which includes    
breast mri images from    mri scans and the accompanying
hand labeled roi  was provided by dr  nola hylton and the
breast mri research program at the university of california 

san francisco  ucsf   the images have a resolution of
   x    pixels and are in grayscale format with pixel intensity
represented by a    bit integer  while the labeled rois have
been provided as matlab data files consisting of a sequence
of points which are intended to be drawn as the interpolation
points of a closed bezier curve 
ii  a pproach
in our view  the most critical step in applying machine
learning to this problem is the identification of appropriate
features  the raw data in each image basically consists of
two attributes for each pixel  intensity and location  if we were
to treat each image and its accompanying per pixel binary roi
labeling as a single element of our training set  which might
seem like a natural thing to do at first  the feature vector would
have                elements each taking on one of    
  
values while the number of possible labels would be     
clearly another approach  one which extracts from this raw
data only the important information  is necessary 
a  drawing a roi
our first step in trying to determine how to make this
data more amenable to machine learning was to think about
what information we  as humans  look for when drawing the
roi  at a high level  the first thing we do when we look
at an image is to pick out the approximate region we are
interested in by identifying the breast portion of the image 
we are looking for a distorted semi circle shape  and the
information crucial to accomplishing this task is rather coarse 
the majority of the breast tissue is composed of approximately
uniform intensity gray pixels and is surrounded on one side by
black pixels representing empty space and on the other side
by a more varied mixture of grays and whites representing the
chest cavity  see figure   for an example   basically all the
information that is necessary comes from identifying sets of
pixels with approximately the same intensity 
once the approximate region is identified  the information
needed to actually draw a region of interest changes from
coarse sets of pixel intensity to specific intensities for individual pixels  by taking the coarse view initially  we have
effectively already decided that the pixels in the center of the
approximate region are in the roi  so if we want to draw
a closed boundary separating the roi from the rest of the
image  we are necessarily interested in finding edges in the
breast region  we do this by looking for sharp gradients in

fifig     mri image showing the hand drawn roi boundary in green  because
the boundary is marked as a set of points and drawn as a bezier spline curve 
it includes portions of the skin  lighter pixels  left edge of boundary  and
chest wall  lighter pixels  top of boundary  that would not normally be in the
roi 

fig     mri image clustered into four regions  shown in black  dark gray 
light gray  and white 

a  clustering
pixel intensity  once we have identified those  drawing the
roi is a simple matter of following the edges that lie near the
boundary of the breast region and interpolating between them
in places where no edges exist 
b  data reduction
with this breakdown of the steps for manually drawing the
roi  we see that only a small fraction of the pixel information
is necessary in order to accomplish the task  specifically 
instead of classifying individual pixels as being in the roi
or not  we could section the image based on approximate
pixel intensity and edge detection  then classify the resulting
regions  clustering the pixels into a small number of groups
based on intensity would naturally divide the image into
contiguous regions of pixels belonging to the same cluster 
edge detection on the original image could then be used to
further split those regions at any boundaries that the clustering
may have missed  this way  the boundary for the roi would
be likely to coincide with the boundaries between some of the
regions  such an approach extracts the important information
edges that could potentially make up the roi boundaryfrom
the raw image data  it is much easier to assign features to a
few hundred regions and train or classify based on them than
it would be to do the same with each of the     individual
pixels 

the first step is to cluster the pixels by intensity  assign
them a new value based on the cluster they belong to  and
store the resulting image  we employed k means clustering
using matlabs kmeans command to group the pixels into
four clusters  roughly corresponding to black  dark gray  light
gray  and white in the original image 
to find the cluster centroids  we first shrink the image so that
it is     pixels in height  then run k means clustering on the
smaller image with cluster centroids initialized to be evenly
spaced over the range of pixel intensities  the reduced size
allows the k means clustering to converge much more quickly 
and the resulting centroids are then used to initialize clustering
on the full image  in both cases  we used the cityblock  l norm  metric  which in matlab for   d data places the
cluster centroids at the median value of the clusters  rather
than the mean  we found that with this metric  the resulting
images more closely resembled the originals  note that the
initial clusters are not randomized in any way  which means
they might not converge to the global optimum  we chose to
do this so that the results for each image would be exactly
reproducible every time the procedure is run  and in any case
the resulting centroids work well 
once the clusters have been obtained  we create a new
image that condenses the intensity range down to the number
of clusters  an example of the resulting image  which can be
compared with the original of figure    is shown in figure   

iii  p rocedure
the procedure we used to automatically identify the roi
of a given image follows from the concept of sectioning
the image into regions  each image in our data set includes
both the left and right breast  and though the eventual goal
would be to identify the roi for each breast  for development
of this procedure we decided to work with only half of
the image  corresponding to either the left or right breast
and depending on the availability of hand drawn roi data 
extending the procedure to include the entire image would be
straightforward 

b  edge detection
the second step toward sectioning the image involves
finding edges  to do this  we use the canny edge detection
algorithm  available in matlabs image processing toolbox 
under the default threshold settings  use of this algorithm via
the edge command easily identifies all of the major edges 
which are of most interest to us  plus many minor edges that
are potentially helpful  one can see in figure   that for our
example image  the algorithm finds the boundaries between
the breast tissue and skin and between the breast tissue and

fifig    

mri image with edges shown in yellow 

chest wall  which are precisely the edges we need for creating
the roi boundary 
c  region identification
with the clusters and edges  we are now ready to section
the image into contiguous regions  of most use for this task
is matlabs regionprops command  which can take a black
and white image  identify regions of connected pixels  and
calculate a number of properties pertaining to those regions
such as area and centroid location  thus  for each cluster 
we create a black and white image with pixels belonging to
the cluster shown in white  then to ensure that no regions
cross any edges in the original image  we force all pixels
belonging to the edges to be black  regardless of their cluster 
in order to avoid processing many small regions that will
be inconsequential for identifying the roi  we discard any
groups of connected white pixels which have an area below a
certain threshold     pixels   we do this separately for each
cluster and combine the results into a new clustered image
with black now representing pixels that do not belong to
any sizable region  representing the fact that the final roi
will be contiguous without any holes  we fill in any black
sections of the resulting image that are completely surrounded
by clustered pixels 
once again extracting black and white images identifying
pixels in each cluster  we then run the regionprops command
specifying a pixel connectivity of four  which means that a
pixel will only be considered part of a connected region if it
touches that region on any of its four sides and not just at
its corners  collecting the regions for each cluster gives the
regions for the entire image  the pixels belonging to each
region  the regions area  and its centroid are all stored for
later use  finally  in order to reduce the number of regions that
the supervised learning algorithm must work with  we discard
regions that we assume are extremely unlikely to end up in
the roi  namely  we discard any regions with an area greater
than one third of the entire image area and any regions with
their centroid lying in the top third of the image  this has the
effect of discarding the large region of black surrounding the
main image and many of the regions located well within the

fig     mri image divided into regions according to clustering and edge
detection  regions are shown in different colors 

chest cavity  this step is not strictly necessary  but it saves
computation time and does not hurt accuracy  the result of
this processing for our example image is shown in figure   
d  region attributes
now that the image data has been organized into at most
a few hundred regions  it is feasible to perform training and
classification on those regions  the question then becomes 
what attributes can we assign to these regions so that the
training and classification works well  obviously the location
of the region is important  as is information about its intensity 
for location information  we include in the feature vector
the regions geometric centroid given as an  x y  coordinate
pair from the upper left corner of the image  for intensity
information  we include the number of the cluster to which the
regions pixels belong  to allow for classification of images
of different sizes and perhaps a different number of clusters 
we also normalize these values by the image dimensions and
number of clusters  respectively  other information could be
included in the feature vector  but we found that including
other data that was readily available  such as region area  did
not improve classification accuracy 
e  region labeling
in the case when we have a roi to train on  it is necessary
to label the regions according to their inclusion in the roi 
starting with the roi boundary spline as shown in figure   
we first identify all of the pixels that it contains  then for each
region that weve identified  we label it in the affirmative if it
meets either of the following requirements  at least a fraction
of its pixels       are in the roi  or at least a minimum number
of its pixels      are in the roi and those pixels account
for at least a certain fraction        of the regions pixels 
this way  any regions that contain a significant portion of
the rois pixels are included  while regions that may contain
some roi pixels but otherwise lie substantially outside the
roi are not included  we place more emphasis on the former
because there are frequent instances when portions of the roi
boundary correspond to no discernible edge in the image  this

fifig     mri image with regions labeled as containing part of the roi shown
in red 

fig    
blue 

mri image with regions classified as being in the roi shown in

is the case for our example image as seen in figure    where
the labeled regions extend further to the right and left than the
actual roi boundary  in this case it is much easier to crop the
region than it would be to fill in missing pixels 
for display and error calculation purposes  the section of the
image that is labeled as roi is refined through the following
process  first  we create a black and white image where
white represents regions labeled as roi  all of the edges are
added to this image in white  the images holes are filled 
and then the edges that were added are removed  this has
the effect of filling in small regions that should be included
in the roi based on the edge information  because the spline
generating the roi is a somewhat smooth curve  we perform a
morphological closure on the region which essentially smooths
out bumps on the boundary  finally  all remaining holes in the
region are filled to reflect the fact that the roi cannot have any
holes  the result for our example image can be seen in figure
   note that because the original roi mistakenly overlaps the
chest wall  the corresponding chest region is labeled as roi
when in actuality it should not be 

g  classification

f  training

h  roi spline creation

with features and labels assigned to the regions of each
image  we can now proceed to train a supervised learning algorithm  because there is no obvious probabilistic interpretation
that we can find to describe the image regions  we elected
to use support vector machines  svms  for training and
classification  the algorithm we used for our implementation
was platts smo algorithm      which we programmed in
matlab  to train on a group of images  we first determine
the regions  their attributes  and their labels for each of the
images  then concatenate the results into an m by   feature
vector and m by   label vector  where m is the total number
of regions  after testing with linear  quadratic  cubic  and
gaussian kernels  we found that the gaussian kernel did the
best job of correctly classifying the training set  with the
attributes that weve defined  it turns out that the training set
is not separable in general  so regularization is necessary 

the final step for replacing a hand drawn roi with a
machine learning identified roi is to turn the region of connected pixels back into an roi boundary created as a bezier
spline curve  to do this  we find pixels on the boundary of the
classified roi that would act as logical interpolation points  in
other words  we identify extreme points on the boundary by
calculating the delaunay triangulation for the boundary pixels
using matlabs delaunay command and picking points with
the most edges  then the boundary spline is created as the
interpolation of those points  this works pretty well  as seen
in figure    but the resulting spline could still be improved if
necessary 

using the support vectors  lagrange multipliers  and bias
parameter returned by the svm training  it is straightforward
to classify the regions belonging to a single image and hence
judge which pixels belong in the roi  after training on six
images  not including the example image  from three scans 
the regions classified as roi for our example image are shown
in figure    filling and smoothing of the collective region has
again been performed as with figure   
aside from the inclusion of areas on the left and right that
do not belong to the roi  this example shows that even with
a relatively small training set  our procedure has the potential
to accurately predict the roi  for many images  the overflow
on the left and right is expected behavior  even for a human
drawing an roi  there is a heuristic involved that has not
been taken into account in our procedure  if the outer breast
boundary starts to curve toward the outside of the image and
there is no discernible edge to follow that joins with the chest
wall  the heuristic dictates that a reasonable interpolation be
performed between the outer breast boundary at that point and
the chest wall 

iv  t esting
to evaluate the performance of the procedure described
above  we performed validation on the region identification

fithe mean classification error for the     images was        
the minimum error    and the maximum error         this
shows that on the whole  our svm training classification
procedure only performs moderately well  it can classify the
roi perfectly  showing potential  but it can also perform quite
poorly  showing that a lot of work still needs to be done 
v  c onclusion

fig     mri image with the guess roi boundary spline shown in blue and
interpolation points marked with circles 

and labeling and cross validation on the svm classification 
the results show that on average  performance is good  but
corner cases still exist where performance can be poor 
a  validation of regions
region identification and labeling was performed on all
    images in our data set  the number of pixels labeled
incorrectly as being in the roi  false positives  and not in the
roi  false negatives  were counted for each image based on
their region membership  a normalized error metric reflecting
the fact that we prefer false positives to false negatives was
calculated as follows 
        false positives       false negatives 
eregion  
  pixels in roi
the image sectioning parameters such as the number of clusters  minimum area for a region  and the three region labeling
thresholds were tuned to roughly minimize this error  resulting
in the parameters given earlier  with these parameters  we
achieve a mean region error of         minimum error of
        and maximum error of         most of the time the
region identification and labeling works rather well  with the
bulk of the error coming from false positives on the upper
left and right of the roi  similar to those in figure    but
cases still exist where the labeled regions do not agree with
the original roi  so a little more work is needed to make this
procedure robust and reliable 
b  cross validation of svm
owing to the fact that processing the complete set of    
images produces over         regions and our implementation
of the smo algorithm cannot handle that much training data
in a reasonable amount of time  we elected instead to perform
cross validation on a total of     images produced by   mri
scans  within that data set  we divided the images into four
random groups and performed   fold cross validation  we use
an error metric for each image similar to the standard training
error and defined as follows 
  mislabeled regions in the image
ecls  
  roi regions in the image

based on preliminary testing  the procedure we have developed for identifying the roi in breast mri images works
well but is not yet ready to replace hand drawn rois for use
in breast cancer research  one problem is that the method for
dividing an image into regions  though accurate most of the
time  is not yet reliable enough to be considered ready for use 
the situations in which it fails are few  however  so it would
appear that the general approach is a valid one 
another area in need of improvement is the svm classification  which could be more accurate and reliable  although
it works in simple cases  improvements are still needed 
the region attributes that we have assigned do not provide
sufficient information for distinguishing regions that belong
in the roi in certain cases  so we have to look for better
attributes or a new approach to classifying the regions 
a  future work
there are a number of approaches that can be taken in the
future to extend the work we have accomplished  for region
labeling  many of the errors could be eliminated if the handdrawn rois were more accurate  the training data could be
cleaned up to increase the roi accuracy and thus increase
region labeling accuracy  classification could be improved by
incorporating information about neighboring regions into the
feature vector  right now  each region is classified independently  but knowing whether a neighboring region is in the
roi is clearly pertinent for classifying a given region  along
those lines  if one could devise a reliable way to pick out the
approximate location of the chest wall  knowing whether a
region is above or below that boundary would provide exactly
the information needed to correctly classify certain data points
that cannot be separated using the current attributes 
aside from those improvements to the procedure  future
work could also address the speed of our svm implementation  improvements to platts smo algorithm exist already  so
it would be a simple matter of including them in our code
or switching to a standard svm package  the final piece of
the puzzle would be to implement a heuristic that cuts off
the roi at the point where the outer breast boundary curves
to meet the chest  regardless of natural edges in the image 
with these improvements  our an automated roi identification
scheme should be able to replace the tedious hand drawing
process 
r eferences
    j  c  platt  fast training of support vector machines using sequential
minimal optimization  in advances in kernel methods   support vector
learning  mit press        ch      pp       

fi