estimating human pose in images
navraj singh
december         
introduction
this project attempts to improve the performance of an existing method of estimating the pose of humans in still images 
tasks such as object detection and classification have received much attention already in the literature  however  sometimes we are
interested in more detailed aspects of objects like pose  this is a challenging task due to the large variety of poses an object can
take in a variety of settings  for human pose estimation  aspects such as clothing  occlusion of body parts  etc  make the task even
harder 
the approaches taken up in the literature to solve this problem focus on either a top down approach  bottom up approach 
or a hybrid of the two  the top down approach involves comparing test images with stored examples of humans in various poses
using some similarity measure  this approach might require a very large set of examples of human poses  the bottom up approach 
on the other hand  uses low level human body part detectors and in some manner assembles the information to predict the entire
body pose  this project attempts to build upon a mostly bottom up approach  called loops  localizing object outlines using
probabilistic shape   that was developed in     by g  heitz  et al  in prof  daphne koller s group  specifically  we investigate the
construction and incorporation of a skin detector into the loops pipeline  and a couple of pairwise features in the appearance
model  the overall improvement in the localization is negligible  with some improvement in head localization  since the
improvements considered are within the framework of loops  a brief overview of the loops method is discussed next 

brief overview of the loops method as applied to humans
the main random variables defined in the loops method  described in detail in      are the locations of a set of key
landmarks that define an object outline  for humans  we consider the skeleton instead of the outline  and define    key
landmarks for the skeleton  landmark     right foot      right knee      right hip joint      left hip joint      left knee      left foot 
    right hand      right elbow      right shoulder       left shoulder       left elbow       left hand       neck       head   the
method uses a probabilistic model that combines a shape model over the landmark locations with appearance based boosted
detectors  for each individual landmark  and some pairwise features over appropriate pairs of landmarks  so  the model defines a
joint distribution over the location of these key corresponded landmarks of the human skeleton  as shown next 

the loops model
briefly  the shape of an object class is defined by locations of the n object landmarks  each of which is assigned to a pixel
in an image  with l denoting the vector of image pixel locations assigned to the landmarks  the probability distribution over l 
conditioned on a given image i  is a markov random field        

p  l   i   w      

 
p
 l        i exp w i f i det l i   i   i   j exp w i j f i j l i   l j   i 
z  i  shape

   

here   w  are the model parameters  and i and j index the landmarks of the skeleton  pshape represents the unnormalized
distribution over the object shape  fidet li  is a detector for landmark i  and fij are pairwise features over appropriate pairs of
landmarks  the notation in the last product term might be a bit misleading  as we can have more than one type of pairwise feature
 or even threewise and fourwise features  over groups of landmarks  the shape model and the detector features are learned in
parallel  as it is discussed in      in principle the weights w could be learned from data  but the process requires an expensive
inference step at each iteration  the authors  experiments indicated that the results are relatively robust to a range of the weights 
so  a fixed set of weights is used  e g  wi      wij      for all i j  

shape model
the shape component of     is modeled as a multivariate gaussian distribution over the landmark locations with mean 
and covariance   the gaussian form decomposes into potentials over only singletons and pairs of variables as described in     
during inference  however  a sparse approximation of the shape model is first used since the general gaussian includes pairwise
terms between all landmarks  after this discrete inference stage  a refined inference step occurs that involves the full gaussian 
the approximation to the maximum likelihood parameters of the full gaussian  which can be solved analytically  is obtained by
minimizing the kl divergence between the sparse and the full maximum likelihood parameters  the details are again given in     
the results shown later are all at the end of the refined inference stage 

 

filandmark detector features and pairwise features
to construct the landmark specific detectors  the well known boosting is used  that is  the feature in the mrf for the
assignment of landmark i to pixel li is then given by 

f idet l i   i  h i l i 
here  h i l i  is a strong classifier whose output is proportional to the log odds of landmark i being at pixel li  the
construction of this boosted classifier from weak detectors is described in      the main weak feature detectors used are randomly
extracted patches from object bounding boxes in filtered versions of training images  the patch is matched to a test image using
cross correlation  more details on how the weak detector is applied to a test image are given in      importantly  after learning the
boosted classifiers  we obtain a response map for each landmark for a given test image  these response maps are then used in
conjunction with the skin detector as described in the next section 
the pairwise features we tested were a feature between some adjacent pairs of landmarks that encodes the color variance
along the line segment connecting the two landmarks  since usually human figures have low color variance along adjacent
landmarks   and a feature encoding similarity in color space of symmetric landmarks  e g  left side hands  feet shoes  knees  etc 
usually have similar color appearance to their right side counterparts  

localization inference
using the mrf definition of the distribution over the assignments of the model landmarks to pixels  we can outline objects
by finding the most probable assignment 

l   argmax l p  l  i   w
the method is not that straight forward  however  as this involves inference over a very dense mrf  a method that
involves combination of pruning down the interesting pixels to consider and performing a discrete inference is discussed in     

the dataset
for an arbitrary object class  the task of deciding on key landmarks of the object outline and obtaining corresponded
training outlines is a tedious one  and     describes a way to do this automatically  however  for simplicity  for localizing humans
we just use manually labeled training skeletons  in particular  the manually labeled people dataset made available by deva
ramanan at http   www ics uci edu  dramanan papers parse index html is used  the dataset consists of     images  all scaled to
contain people of roughly     pixels in height  we use the first     images for training  and the remaining     for testing 

incorporating skin detection
one specific aspect of human figures that is missing from the model above is skin color  to learn a good skin detector in a
supervised manner  however  one needs labeled training examples of skin and non skin pixels  which can be a tedious task  while
we couldn t find a properly labeled dataset to train a skin detector  we did get access to the h d dataset from uc berkeley  which
contains several extensively annotated images containing humans  while the pixels are not given any labels  the dataset does
contain ground truth segmentations of human body parts  the skin pixels were therefore obtained by extracting the patches
corresponding to faces and hands  as these parts are almost always exposed and show some skin  a total of about   million skin
pixels were obtained in this manner  random non skin patches were used to obtain about    million non skin training examples 
we note that the skin labels were indeed a bit noisy  as some hands might be covered by gloves  some faces might have sunglasses
on  etc  a quick qualitative look at the extracted patches  however  showed that most labels were correct 
instead of learning a hard skin classifier  in our case we only needed a classifier that outputs the log odds of a pixel
belonging to a skin patch  the first approach tried was to learn a generative model using a single gaussian to model the skin
distribution  the features tried were color based  once the skin pixel data was extracted from the h d dataset  finding the
maximum likelihood parameters for the gaussian discriminant analysis model was easily done in closed form  the color spaces
investigated were rgb  cie lab  and hsv  with hsv providing slightly better results than the other two  to improve the model
further  however  we used a mixture of two gaussians to capture a larger variation of skin color seen in human images  the
standard em algorithm was used to learn the mean and covariance of the two gaussians  a brief comparison of the roc curves
between using a single gaussian and a mixture of two gaussians  both in hsv color space  is show below  the improvement is
marginal  and both models result in a satisfactory skin detector 

 

fishape learning

boosting

response maps
weighted average
with skin response map

localize
figure    incorporation of skin response maps into the
loops pipeline 

while the roc curve was obtained by varying the
detection threshold and then looking at the output binary
skin response maps  for incorporating the skin detection
into loops  we only take the soft skin response maps
 i e  the pre threshold response maps obtained by
figure    roc curves for skin detection using single gaussian  red  applying bayes  rule to the learned generative model to
find the probability of a pixel belonging to a skin patch 
vs  a mixture of two gaussians  blue  
and setting the output image s intensity at that pixel
location to be this log probability   in the loops pipeline  after the landmark response maps for test images are computed from
the boosted classifiers  we compute a weighted average of the head and hands response maps with a gaussian blurred version  to
reduce noisy peaks for discrete inference stage  of the soft skin response map for that image  only the head and hands landmark
responses are averaged in this way  since these are most likely to show skin  skin response weights of                and     were
tested in the averaging step  with a weight of     resulting in the most improvement in the average landmark based error metric
that s shown later  a brief illustration of where the skin detection is incorporated into loops is shown in figure    some examples
of improved overall localizations as a result of skin detection are shown in figure   

pairwise features
color variance between adjacent landmarks
the original loops method as described in     includes a pairwise feature that encodes a preference for aligning outline
segments along image edges  since in the human case we are dealing with skeletons rather than outlines  we don t use this gradient
feature  instead  we introduce a pairwise feature between some adjacent landmarks  such as elbow shoulder  hip knee  that
encodes a preference for low color variance  in hsv space  along the line segment joining the two landmarks  this is based on the
observation that most human figures  at least in the dataset used here   show low color variance along limbs  unless wearing
colorful clothes with lots of patterns   to encourage low variance  we set the feature value to be the negative of the sum of the color
variance in h and s space of the pixel values along the line segment  the weights tested for this features were       and     with all
three weights resulting in similar performance 

color similarity between left   right symmetric landmarks
a second pairwise feature tested was the similarity of appearance between left   right hand  left and right foot  etc  so 
this feature gets a value that s negative of the difference in color  again  in hsv color space  between the candidate locations of two
symmetric landmarks  to reduce noise  we compute the average color in a small  x  pixel patch around the candidate location in a
blurred version  with a gaussian of standard deviation of    of the test image  the weights tested in the model for this feature were
again       and     with minimal variation between them 

 

fifigure    some improved localizations due to skin detection  first column shows the baseline
localization  second column shows localization after averaging the skin response maps  with
weight       the third and fourth columns show as an example the original and skin averaged
response maps for the head landmark 

results
a landmark based error metric was used to see the effects of these methods   specifically  the metric is the rms distance
 mean calculated over the entire test set  between the ground truth landmark location and the localized landmark location 
normalized with respect to the size of the bounding box around the human figure in the test image  the errors for the    landmarks 
for the baseline  loops method without any of the additions described here   loops   skin detector  loops   skin detector
along with the color variance feature  and skin detector along with the symmetry feature  are shown in the next image  the largest
errors are seen in localizing both the left and right hands  the largest improvement  close to about     over baseline  is seen in
locating the head 

 

fifigure    landmark specific errors in x and y directions  landmark numbers are as described
earlier  the largest errors  the two peaks in the middle  are for the left right hands  most
improvement due to skin detection is seen in head localization  the pairwise features in general do
not lead to improvements 

conclusions future work
the results show that incorporating a skin detector mostly helps in localizing the head  but doesn t help much for hands on
average  a better  adaptive skin detector with a richer set of color based and geometric features  such as that developed in      can
be used to see if better skin detection leads to improvements  the pairwise features considered here do not lead to significant
improvements  either  another pairwise feature that could be tried is one that encodes a preference for requiring the localized parts
to lie in the image foreground  assuming the image background foreground can be reliably segmented  in general  the largest errors
occur in localizing hands  this perhaps indicates the need for a parts based model as used in     
a large part of the effort in this project went into understanding loops and its infrastructure  with more experience with
the loops code base  experimentation could be done with better features in the boosting stage  for example  in addition to using
the randomly selected filter response patch features  more human part specific features could be experimented with   on a long
term basis  integration of loops with holistic scene understanding seems to be an interesting direction to take  for example  given
a test image  if we can determine its class  e g  ballet   then a class specific shape model can be used that has a better tolerance for
out of the ordinary articulation of human figures 

acknowledgements
thanks to ben packer and tianshi gao  from prof  daphne koller s group  for providing assistance in understanding the
loops pipeline and giving access to their loops code library and assisting in adding pairwise potentials  also thanks to stephen
gould for helpful suggestions on skin detection 

references
    g  heitz  g  elidan  b  packer  and d  koller  shape based object localization for descriptive classification  nips       
    j  pearl  probabilistic reasoning in intelligent systems  morgan kaufmann       
    l  bourdev and j  malik  poselets  body part detectors trained using  d human pose annotations  iccv       
    q  zhu  k  cheng  et al  adaptive learning of an accurate skin color model  ieee international conf  on automatic face and
gesture recognition       

 

fi