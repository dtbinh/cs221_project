a prediction system for conversation likeability on anonymous chat
networks
andrei bajenov

saila talagadadeevi

abajenov stanford edu

saila stanford edu

abstractwe implement and evaluate a prediction system for
conversation likeability between a set of people on an anonymous chat network using support vector machines  logistic
regression  and k means clustering algorithms  here we use kmeans clustering for unsupervised feature learning which will be
fed to supervised classification methods  our algorithms draw
principles from supervised and unsupervised machine learning 
index termsk means  svm  logistic regression

i  i ntroduction
chatous is a text based  one on one  anonymous chat
network where users can have text based conversation with
random strangers  chatous has over     million unique users
across     countries  each user in chatous has a profile where
he she can specify a few simple facts such as gender  age  and
location  each user can perform actions such as starting a new
conversation  friending  reporting a conversation  and ending
a conversation 
when a user comes online in the chatous network  he she
is presented with the most probable chat buddy from a pool
of available online users  our work aims to improve the
algorithm used to select a buddy that will result in the highest
conversation likeability 
ii  p rior w ork
the creators of chatous have done some work in trying
to predict conversation likeability  they trained a logistic
regression model that was able to give them an edge over random matching  their successful features included gender  and
users history of previous interactions with mutual buddies 
we would like to build on their work by extending the
feature set and trying different algorithms  one thing that
was not incorporated into their models was the words used
by users in prior conversations  we claim that words used in
prior chats are good signal  we can use this information to
better match users with similar interests  we would also like
to add additional signal about a users chatting behavior  for
example  a users actions in the past time buckets  such as
ignoring chats in the past hour  may give a strong indication
to what he she may do next 
iii  data
chatous provided us with large data sets to build our ml
models 
 chat history            entries   contains information
about each chat  it includes the length of conversation 
the number of lines each user wrote  word frequencies

for each participant  which user disconnected  whether
a friendship was established  and whether a report was
made 
 user profiles          entries   contains user specific
information  user id  age  gender  location  and word
frequencies in the about me section 
for privacy reasons  words are masked in the data set  each
word is mapped to an id  and frequencies are given for each
word id  a list of stop words is also provided so that we can
ignore them while clustering 
iv  data p rocessing and f eature g eneration
a  labels
close to     of conversations on chatous are empty 
this means that     of users are matched up with a buddy
who disconnects right away  we think this is very poor user
experience and believe that if we can match up users who are
likely to begin a conversation  the overall user satisfaction will
improve 
as such  we label a conversation as good if it satisfies all
of the following 
 neither user reports the conversation
 both users write at least one line
 the conversation length is longer than    seconds or
the two users friend each other or both users choose to
leave the conversation open
this labeling is not perfect  since it may label very short
conversations as good  however  since so many of the conversations are empty  this gives us a decent indicator that a
conversation could turn into a satisfying one  moreover  this
labeling will help identify users who are generally bad actors 
or who are usually inactive 
b  features
every conversation involves two users  in order to predict
whether a conversation will be good  we extract features for
both users and combine them into one feature set  below is a
full list of features that we are working with  we discuss how
we prune this feature set later 
 users gender and whether or not they have the same
gender
 users age and age difference
 whether or not they are in the same country or region
 chat history features  we have multiple sets of these for
  minute  one hour  one day  and all time buckets  

fi how many times a user was reported and reported
someone
 how many times a user ended a conversation and
was left by someone in a conversation
 numbers giving the types of conversations a user
was involved in  for example  empty conversations
and one way conversations
 total number of conversations
 average conversation lengths
 the word cluster a user belongs to  determined via the
k means algorithm discussed later  
some of the features above are for a single user and some
are for pairs of users  where it makes sense  we average the
individual features for both users  for example  we average
the average conversation length for the two users  and include
it as a feature 
overall we get about      total features from this  excluding features related to user clusters  
v  a lgorithm s teps
our goal is to assign weights to pairs of users  to indicate
the likelihood of them having a conversation 
we first use logistic regression to train a model on the set of
all features  using the model learned by the logistic regression 
we identify the features that have a strong correlation to the
outputs and use only those features in subsequent training 
to gain signal from words used by user  we use k means to
cluster users  once we have assigned every user to a cluster 
we feed this information as features into the original classifier
and analyze the results 
having identified a set of good features  we train an svm
with various kernels to see if we get better results 
a  feature selection
we train a logistic regression model as an easy way to
identify features that have a strong correlation to the output 
since we have over       features  this is a quick and easy
way to identify bad features  to identify features that have
weak correlation to labels  we look at the  learned by the
logistic regression and pick the values with lowest magnitude 
we are able to do this since we scale our feature vector 

first we generate the jaccard similarity matrix to feed
into the k means clustering algorithm  the jaccard similarity
measures the similarity between two sets  it is defined as the
size of the intersection divided by the size of the union of the
sets  j a  b     ab 
 ab    we then normalize the similarities 
algorithm steps 
   we build common word vectors from raw data  we also
build an adjacency matrix with users vs  words 
   we build a similarity matrix from the adjacency matrix
using jaccard similarity 
   we run k means clustering on the similarity matrix 
kmeans will cluster users who used similar words  words
related to sports  movies  music etc    the underlying
assumption is that users who talk about a particular topic
will most likely chat again about the same topics and
will like chatting with people who like to chat about
those topics 
   we use a similar procedure to generate user clusters
based on words in the about me profile section 
vi  r esults and f indings
a  feature strength
after running logistic regression on a scaled feature set  we
identified the following top features 
   gender is by far the strongest predictor for a positive
chat  chats of opposite gender and chats with two female
users  tend to be non empty and last longer 
   a high age difference has a negative correlation to a
positive outcome  the higher the age of either user  the
lower the likelihood of having a conversation 
   the one hour chat history bucket seems to be a strong
predictor of future behavior  averages between two users
of the number of empty chats they had  how many times
they were ignored  how many times they engaged in a
conversation  etc 
   the average conversation lengths of two users in the all
time and   hour bucket have a positive correlation on
the outcome 
features for other time buckets  country and region features 
and reporting related features play a smaller role in the prediction 

b  support vector machines
we attempt to use svms for training because it gives us
the flexibility of using non linear kernels  we experiment with
various features to the svm as well as with different kernels 
c  k means clustering for feature learning
we use k means clustering as a feature learning step for our
supervised learning algorithms  in this method  we perform
clustering on a chat word similarity matrix to identify and
label users who tend to chat about similar interests and topics 
for each labeled sample  the distance to each of the k learned
cluster centroids is computed to induce k extra features for
the sample  the feature can be a boolean with value   for the
closest centroid and    for other clusters 

b  logistic regression performance
we trained a logistic regression model as a quick way to
study the data and select good features  it gave us a sense of
roughly how many data samples are needed for training given
our feature sizes 
initially we trained a logistic regression on    k chat
samples  we used all       features described earlier  excluding the clustering features   and got        cross validation
accuracy for    fold cross validation 
to get an idea of what to do in order to improve the
accuracy  we ran some diagnostics for the classifier  fig   
shows a diagnostic we ran  where we varied the number of
samples for our test and training sets  and plotted that against

fithe prediction error  the plot showed that a    k sample size
is large enough  in fact  we found that using more than   k
samples for training does not have a significant impact on
classifier performance 

just predict a single class all the time  which validated the
usefulness of our accuracy metrics 

fig     sample size vs  error for logistic regression with       features 
fig     precision recall curve for positive classification 

fig    also showed us that we were not overfitting  since
the training and test data had similar errors after   k samples 
this confirmed that adding additional features  such as word
clusters   or using a different classifier  such as svm  might
help overall accuracy 

fig     precision recall curve for negative classification 
fig     sample size vs  error for logistic regression with     features 

c  svm performance
since       features is quite a lot  and significantly slows
down training time for svm  which we train later   we decided
to prune our feature set to top     features  based on the
analysis from the previous section   with only     features 
we got a cross validation accuracy of         the small drop
in accuracy is not a high cost  given the benefits of using fewer
features  fig    shows a similar diagnostic for the logistic
regression classifier with only     features  we see that it
requires fewer training samples to obtain similar accuracy
results 
in order to verify the usefulness of our accuracy metrics 
we plotted precision recall curves for positive and negative
classification  fig    and fig    show these curves for logistic
regression  and also svm which we discuss later  using
    features  observe that we are doing much better than
random matching in both cases  the random lines were
generated based on the ratio of positive and negative labels  we
have about       positive labels and       negative labels 
these figures helped us confirm that the classifier does not

we used logistic regression to study the data and select
top features  we observed a high bias  so using an svm with
a non linear kernel had potential to improve accuracy 
we trained an svm with an rbf kernel  it had about
   higher          cross validation accuracy than logistic
regression  it also showed better precision for positive classification  see fig      unfortunately it showed lower precision
for negative classification  however  since we value matching
good users more  higher precision on positive chats is better 
we experimented with different values for c  cost  during
training and found that     works best  we also tried alternative kernels  and saw that the polynomial and rbf kernels
have the best performance  but the rbf kernel has a slight
edge        higher cross validation accuracy  
we also ran a sample size vs  error diagnostics for svm 
fig    shows the behavior of the svm model as we vary the
training set size  it requires more data to get good performance 
but otherwise looks very similar to that of logistic regression 
there is also a higher gap between training and test error at

fifig     sample size vs  error for svm with     features 

higher sample sizes  suggesting that training with more data
may further improve accuracy 
overall we found that svm with an rbf kernel shows
higher accuracy  but takes much longer to train and slightly
longer to predict than logistic regression 
d  clustering performance
having trained svm and logistic regression on a base set
of features  the next step was to add signal from words used
in previous chats 
we found that the adjacency matrix of chat words turns
out to be in several hundreds of megabytes if we consider
every word and every user who participated in the chats 
after analyzing the data  we found that most words have low
frequency of occurrence across chats  also a lot of users do
not chat a lot  these low frequency users and words prove
to be irrelevant for clustering and hence for prediction  after
pruning the data set we reduced the adjacency matrix to under
   megabytes  we did additional fine tuning by removing stop
words from the word vectors to improve the cluster quality
and word relevance to user interests  removing stop words
significantly increased our cluster quality 
we were then able to use k means to cluster users into   
clusters  for every cluster we added a feature to our svm  we
labeled the feature    if one of the users in the chat is from
that cluster  and    otherwise  we added another feature that
had a positive label if both users were from the same cluster 
this increased the svm cross validation accuracy by      
         
we also tried to add clusters for words in the about me
section of users profiles  we found that clustering against
these vectors had surprisingly little effect on chat likeability
predictions  we decided to remove these clusters from our
feature list 
vii  c onclusion
we built a system that predicts if a pair of users will
have a successful chat with up to        accuracy and good
precision recall performance  since chatous is an anonymous
chat network  its success is very much dependent on pairing
a user that comes online with the most likeable user that
is available at that moment  accuracy as well as speed of
prediction makes all the difference in a users experience 

fig     k means   d plot with first   clusters

even with very noisy data  we were able to identify several
strong features  we saw that gender is by far the strongest
predictor of a positive chat  chats of opposite gender tend to
last longer and have a higher chance of being non empty  we
also observed that users previous chatting behavior is a strong
predictor of future actions 
we also looked into using words from previous chats as a
signal for our predictions  we ran k means clustering on word
vectors from previous chats to cluster users into groups  we
then fed these clusters as features to our classifiers  we saw
a       improvement in accuracy  we also observed that the
words used in the about me section arent very useful for
predicting a successful chat 
for supervised learning  we used logistic regression and
svm  we found that svm with an rbf kernel has slightly
better cross validation accuracy than logistic regression  but
the runtime performance is worse 
we believe that integrating our prediction system should
improve the overall user experience in chatous 
acknowledgment
we thank chatous and kevin guo for providing the data
set and spending time explaining it 
r eferences
    csurka  gabriella  dance  christopher c   fan  lixin  willamowski  jutta 
bray  cdric        visual categorization with bags of keypoints  eccv
workshop on statistical learning in computer vision
    coates  adam  ng  andrew y          learning feature representations
with k means

fi