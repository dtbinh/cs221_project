personalized web search ranking
cs       project report
ankit kumar
ankitkr stanford edu

abstract
in this project  we investigate new approaches to personalize
web search result pages for users using anonymized search
logs with scant data per user  we investigate modelling users
into groups and personalize the users serp based on the
response of the users peers towards the documents in the
serp  for evaluation  we compare our personalization strategy
against the popular ranking strategy of sorting of documents
in the serp based on overall number of clicks  we quickly
realize that personalizing every serp makes our algorithm
perform worse  when then try to learn when to personalize a
serp using a svm on our chosen features  although we do
not achieve high tranining test accuracy in learning when to
personalize  the accuracy we achieve is sufficient to beat the
click sorted ranking scheme 

  

introduction

this project aims at personalization of web search results according to user preferences  by personalization  we mean the process
of showing the same set of  user independent  documents relevant
to the user query to different users in a different order in which he
is most likely to consume the documents  we try to develop an algorithm that models preference interests of a user and accordingly
re ranks the search engine result page  serp   to model a user  we
use the short term  seesion  user context as well as the long term
history of the user on the search engine  one way to formalize this
problem is to come up with a personalization score for every document which can then be mixed with the query relevance score to
give a personalized search experience  another way of formalization is to classify web pages as interesting non interesting to the
user based on his click history 
search personalization is a very important problem as it enables
us to provide the user the documents which he is most likely to
consume higher in the page  furthermore  the problem becomes
very interesting when the search query is ambiguous  in such cases 
user interests can help us greatly in narrowing down the pages the
user might be interested in  for example  for the query mouse  a
biologist might be interested in the animal  while a tech engineer is
most likely looking for computer hardware  given that majority of
queries on web search are short      personalization provides great
insight in query understanding disambiguation 

terested in  learned from his search click history  and then boost
documents that align with these topics 
there are aso approaches to use the web hyperlink structure in
personalization  for example  proposed a topic sensitive pagerank system      a modification of the original page rank model to
this effect 
there are also works on identification of potential queries for
optionalization      it is observed that not all queries are suitable
for personalization and for only a subset of queries we should
personalize to get better gains 

  

experimental setup

   

data set

the dataset     used for this project is provided by a popular search
engine yandex that includes anonymized user sessions extracted
from yandex logs of one geographic location during one month of
search activity comprising of user ids  queries  query terms  urls 
their domains  url rankings and clicks  we have about   gb of
uncompressed logs   with    days of search logs for training and  
days for evaluation 
the dataset has            unique queries             unique
urls            unique users             training sessions            
click records and             total records 
given the gigantic size of the dataset  we have decided to sample
a small portion of this dataset for faster experimentation and iterations of the learning algorithms  for training we randomly sample
       users and train the model on their search sessions  over   
days  only  for evaluation  we randomly sample      test users
from the aforementioned        users and take one query per test
user  in the   day test period  
we also selected      users  separate from the test set users 
and take one query per user  which was not used in training set  as
the validation set  this set will be used to train a svm later 
we do not include users with no click history in the training
period into our test set or validation set 
   

for evaluation of the search result pages  serp  reranked by our
models  we use the rank scoring           metric as well as the
average rank      metrics 
     

  

related work

there is rich literature         available on web search personalization strategies and user modelling  some of the approaches are
click based i e  try to boost documents which the user has clicked
sometime before while others are based on user profiling where we
try to represent a user using a set of topics             he is in 

evaluation metrics

rank scoring

the expected utility of a ranked list of web pages is dened as
x
 s  j 
rs  
 j      
 
j
where j is the rank of a page in the list   s  j  is   if page j is
clicked in the test query s and   otherwise  and  is set to   as the

fioriginal authors did  the final rank scoring reflects the utilities of
all test queries 
p
s rs
p
r      
max
r
s
s
rsmax is the maximum utility achievable when all documents
clicked are on the top of the page  large value of rank scoring
indicates better performance of personalized search 
     

average rank

the average rank of a query s is dened as  
  x
avgranks  
r p 
 ps   pp

for earch user   we create a click vector  where click vector i 
    if the user has clicked on document i at some point of time in
past  note that this representation of users will be very sparse  now 
after defining the click vectors for all users  we try to find groups
of users who tend to click on same set of documents  that  we
believe is a reasonable way of identifying users with similar interests  to achieve this  we use the k means clustering algorithm on
the click vectors of our training set users  however  given the very
high dimensionality of these sparse vectors  we decide to include
documents which have been clicked by atleast       users at some
point of time  this reduces the dimesionality of the click vectors
immensely and speeds up execution  we run the k means clustering algorithm for max num iterations     iterations to cluster
users into groups 

s

here ps denotes the set of clicked web pages on test query s 
r p  denotes the rank of page p  the final average rank on test
query set s is computed as 
avgrank  

  x
avgrankss
 s  ss

smaller average rank value indicates better placements of relevant result  or better result quality 

  

our approach

due to the fact that the data logs are completely anonymized for
query terms and documents as well  many most of the profiling
based apporached described earlier are not applicable as we do
not have access to the actual document queries  rather a bunch of
unique ids  in order to classify them into topics of interest  hence 
we investigate a different approach to profile a user based on the
set of documents that the user has clicked on in past  this idea
explores the hypothesis that the set of documents clicked by a user
over a period of time are a good indicator of his interests 
now  thae dataset we have does not have a lot of data per
user  on average       serps per user   hence the user history
click based methods decribed earlier do not work as well  in this
approach  instead of trying to predict what a user thinks of a
document by looking at his search history for that document  we try
to predict what the peers of the user think about the document 
the important steps in our approach are as follows  they will
be explained in detail in the coming sections 
   represent user profile by their click history and cluster users
with similar clicks
   develop a reranking strategy  
 given a serp l  let r   randomize l 
 csl   clicksorted l 
 u csl   u serclusterclicksorted csl 
 l is your yandex ranking  borda l  r  is a random strat 

egy  borda l  csl  is our baseline  borda l  u csl 
is our approach
   train a clasiffier on a traing set to predict when to personalize
   use the predictions and evaluate the strategies on a test set

   

reranking scheme

given a serp  we first ignore the query relevance of the documents
in serp and just consider them as a list of documents that are to be
ranked by some personalization strategy  the personalized ranked
list is then combined with the original ranking of the serp using
bordas rank aggregation method to get the final re ranked serp 
we now describe the personalization strategy we use to rank an
unordered list of documents 
for getting the personalized ranked list  we first randomize
the serp and then sort the documents by the popular strategy of
sorting based on overall clicks a document has got historically  in
this case  number of users who have clicked on a document   we
then again re sort the serp obtained by the number of users in
the testers cluster who have clicked on this document  note that
the re sorting will be a stable sort  i e  the documents with same
number of clicks from testers cluster have the same ordering after
re sorting as what they had by the globally click sorted ranking
scheme 
we evaluate the quality of the re ranked list obtained using the
rank scoring as well as the average rank metrics described in
the previous section  as baseline for evaluation  we compare these
metrics for our personalization strategy vs the click sorted ranking
scheme 
   

learning when to personalize

we quickly realized that when personalizing every query  we were
taking more losses than gains against the click sorted scheme and
hence  the overall gain by our scheme was negative  hence  we tried
to learn when to personalize a query and when not to  however  as
we have not modeled queries in our algorithm  we tried to learn
which serps should be personalized and which should not  we
used a c svm      with a radial basis kernel function on the
training data which represents serps using the following features 
   total number of clicks on any document of the serp   an
indicator of how popular a query is
   fraction of results in the serp with any clicks  indicator of
navigational queries
   mean  standard deviation of overall clicks of the results in serp
with clicks  indicator of click distribution
   average click position on the serp defined by
p
poverall clicks result i  
ii
overall clicks result j  
j

   

model groups of users

we first try to find groups of users with similar interests based
on the profiling we described above  having clustered users into
groups we can rerank the test serps based on the response of the
peers of the user to each document 

   total number of clicks by the testers cluster on any document
of the serp   an indicator of how popular a query is in the
testers circle
   ratio of features   and    an indicator of how authoritative the
testers cluster is on this kind of serp
   fraction of results in the serp with any clicks by testers cluster

fi   mean  standard deviation of clicks from testers cluster of the
results in serp with clicks
   average click position by testers cluster on the serp defined
p
by testers  circle result i  
by i i  pclicks
clicks by testers  circle result j  
j

    a measure of how tight assignment of the testers cluster is  
centroid of tester   s cluster 
max distdist tester cluster
p
max distdist tester cluster centroid i 

we generated training data on the validation set described earlier under our reranking schemes and evaluation metrics and trained
the svm  we selected the model parameters c and  using a grid
search on the validation set  results showed us that we were not
attaining very good accuracy rates  the learning curve shows both
higher training and test errors which are flat with increase in training set size indicating an underfitting and the need of better features 

  

results

in this project we provide comparison between our approach  the
yandex ranking  popular strategy of ranking based on click sorting
and a randomization personalization strategy  it should be noted
that there is an inherent bias of the user to click on the results at
top of the serp and we will evaluate assuming the user scanned
through all search results before clicking on the document for test
queries 
unless explicitly stated  we report the results for m          
users  max iterations       number of clusters k       number
of queries for training svm         number of test queries        
rank scoring avg  rank
yandex
      
     
      
     
our approach
click sorting
      
     
random
      
    
varying the number of clusters used for clustering k  we get the
following end to end numbers for our user cluster based approach 
k
  
  
  
  
  
  
   

rank scoring
      
      
      
      
      
      
      

avg  rank
     
     
     
     
     
     
     

  

conclusion

we are successful in achieving results better than the click sorted
ranking scheme  however  we are still much behind the yandex
scheme of ranking 
we have a couple of ideas that may be used next to improve on
the system  
   in this model  we represented user by the set of document he has
clicked  as a bit vector   we would like to also incorporate the
number of clicks made by the user on a particular document into
our model as a document which is visited by user repeatedly has
more to say about the user than other documents 
   our model is a click based model that models users by their
click histories and hence trying to optimize clicks  however  if
we look at the results obtained above  it looks like the average
rank for the baseline  yandex  ranking is      while evaluation
we did not take into account the fact that the clicks made by the
user can be very biased by the ranking itself i e  user may click
on top results even if they do not find it useful  so in a model
based on click events  this plays to our disadvantage  we would
like our model to incorporate dwell time of the user on a clicked
result to identify the actual document that satisfied the user and
evaluate based on dwell time and not on click position 
   as evident by the learning curve of the svm  more work needs
to be done in designing better features for learning when to
personalize 

references
    craig silverstein  hannes marais  monika henzinger  and michael
moricz  analysis of a very large web search engine query log  sigir
forum             september      
    zhicheng dou  ruihua song  and ji rong wen  a large scale evaluation and analysis of personalized search strategies  in proceedings of
the   th international conference on world wide web  pages        
banff  alberta  canada        acm 
    uichin lee  zhenyu liu  and junghoo cho  automatic identification
of user goals in web search  in proceedings of the   th international
conference on world wide web  pages         chiba  japan       
acm 
    a  pretschner and s  gauch  ontology based personalized search 
in tools with artificial intelligence        proceedings    th ieee
international conference on  pages              
    xuehua shen  bin tan  and chengxiang zhai  implicit user modeling
for personalized search  in proceedings of the   th acm international
conference on information and knowledge management  cikm    
pages         new york  ny  usa        acm 
    paul alexandru chirita  wolfgang nejdl  raluca paiu  and christian
kohlschutter  using odp metadata to personalize search  in proceedings of the   th annual international acm sigir conference on research and development in information retrieval  sigir     pages
        new york  ny  usa        acm 
    glen jeh and jennifer widom  scaling personalized web search  in
proceedings of the   th international conference on world wide web 
www     pages         new york  ny  usa        acm 
    jaime teevan  susan t  dumais  and daniel j  liebling  to personalize
or not to personalize  modeling queries with variation in user intent  in
proceedings of the   st annual international acm sigir conference
on research and development in information retrieval  sigir    
pages         new york  ny  usa        acm 
    https   www kaggle com c yandex personalized web search challenge 
data 

figure    learning curve
the learning curve of the c svm is shown is fig   

     jian tao sun  hua jun zeng  huan liu  yuchang lu  and zheng
chen  cubesvd  a novel approach to personalized web search  in
proceedings of the   th international conference on world wide web 
www     pages         new york  ny  usa        acm 

fi     john s  breese  david heckerman  and carl kadie  empirical analysis of predictive algorithms for collaborative filtering  in proceedings
of the fourteenth conference on uncertainty in artificial intelligence 
uai    pages       san francisco  ca  usa        morgan kaufmann publishers inc 
     feng qiu and junghoo cho  automatic identification of user interest
for personalized search  in proceedings of the   th international
conference on world wide web  www     pages         new
york  ny  usa        acm 
     chih chung chang and chih jen lin  libsvm  a library for support vector machines  acm transactions on intelligent systems and
technology                     software available at http   www 
csie ntu edu tw cjlin libsvm 

fi