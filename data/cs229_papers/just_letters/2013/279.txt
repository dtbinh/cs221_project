 

learning multi label topic classification of
news articles
zach chase
nicolas genain
orren karniol tambour
abstractwe consider the problem of learning to classify the topic of news articles for which there are multiple
relevant topic labels  we analyze the shortcomings of a
number of algorithmic approaches  including naive bayes 
and develop two alternate approaches to solving the
problem  in particular  we assess the performance of a
binary classifier approach in which we learn a set of oneversus all naive bayes binary classifiers  one for each label
class  we also develop and analyze the performance of two
novel algorithms derived from the popular tf idf weighting
scheme  and motivated by the goal of constructing a
learning model that is more similar to the way human
readers may classify article topics 

i  t opic c lassification of n ews a rticles
classifying the semantic content  or topic  of text
is one of the critical problems in natural language
processing  information retrieval  artificial intelligence
and machine learning more broadly  newspaper articles
provide a particularly good opportunity for learning such
classifications  as the semantic content of articles is
generally coherent  and large  open source corpuses of
labelled news articles exist and are easily accessible 
there is also a fair deal of interest in classifying
news article topic for specific applications and research 
news article topic classification can enable automatic
tagging of articles for online news repositories and the
aggregation of news sources by topic  e g  google news  
as well as provide the basis for news recommendation
systems  more broadly  given the social and political impact of news and media  communications specialists and
other social scientists   including our collegue rebecca
weiss at the stanford communications department  who
suggested this project to us   are particularly interested in
analyzing news data programmtically to uncover patterns
and biases in news production  content and dissemination 
a complicating factor is that news articles often fall
under multiple topic labels  an article about a transfer
in ownership of the chealsea football club  for instance 
might be labelled under sports  business  and world
news  humans can recognize and correctly provide
multiple relevant labels for an article  but can a machine
learning system get similar results 

ii  data
the new york times has made a large corpus of
its archive publicly available  with   years of articles
hand tagged for various attributes of an article  each
article is provided along with a set of relevant taxnomic
classifiers  which are essentially content labels  we chose
to focus on learning only a small subset of the labels 
  in total  corresponding to a number of major news
topics  business  arts  technology  style  books  home
and garden  sports  science  and health  even when
considering only    of many labels  most of the articles
in our dataset had multiple tags  and some had many  the
average number of articles per tag was       while the
max was    note that we also found that a fair number of
the articles in the corpus were mislabelled   see analysis
for more detail 
iii  t he m ulti  l abel p roblem
a  does it make sense to use naive bayes 
consider the following corpus
corresponding to the following priors 
label
   
   
       

article content
dog dog cat
animal object
dog vet

of

articles 

priors
p       
p       
p       

obviously  we have that p      p      p       
since our sets are not mutually exclusive   so computing
class priors using niave bayes will not work  one
solution to address this problem might be to use the
exclusion inclusion principle in order to make all our
class sets mutually exclusive  by creating new classes 
we can create a representation of our data as as a set
of non overlapping sets  this will allow us to have a
set of class priors that both sum to   and represent
the world faithfully  however  while this solution will

figure    using the exclusion inclusion principle

allow us to model the world accurately  the introduction
of additional classes and priors represents a significant
increase in complexity  for our case of only   categories 
we will already have       classes to consider  i e 
just over     different class priors to compute   so
this algorithm runs in exponential time  additionally 

fi 

because the increase in label classes effectively splits
the dataset across the set of new priors  we are providing
far fewer training examples to each of the new mutually
exclusive priors when compared to the old ones   so
this approach will also require far larger data sets to
train on 
a common alternative approach to solving the mutual
exclusivity problem is to learn independent binary classifiers for each class of labels in a dataset      we now
turn to an analysis of this approach 
iv  o ne versus all naive bayes classifiers
in the binary classifier approach  a binary classifier is
learned for each class of labels  and overlaps between
labels are essentially ignored  each binary classifier
constructs a prior on the relevant class it classifies 
and posterior conditional probablities for each word are
computed for two classes each time  corresponding to the
probablity that a word was drawn from an article from
class a  or from any article strictly outside the class 
when presented with a new test article  the system runs
each classifier and decides class by class if an article
belongs to it  or not  the following chart provides an
illustration of the approach used for three class labels 
since learning each binary classifier is an independent

figure    one versus rest naive bayes classifiers principle

task  the binary classifier approach is computationally
scalable  it also produces fairly accurate results  the
table below summarizes the classification error of the
binary classifiers on three feature sets  full article text 
lead paragraph  and article headline  the models average labelling error across classes for each feature 
respectively  was              and       interestingly 
the binary classifiers are fairly accurate at predicting
the correct labels even when presented only with the
headline of an article 
while the binary classiffiers yielded fairly robust
results  we found two primary limitations of the approach that led us to explore an alternative model 

figure    performance of binary classifiers on three feature sets  full
article text  lead paragraph  and article headline 

first  the binary classifiers cannot be directly modified
or improved  and an improvement of the model would
likely have required us to instead implement an svm 
second  and more critically  we wondered if it might be
possible to construct a learning model that more closely
approximates the way human readers may perform a
similar classification task 
v  s olving the problem the way human
readers do

how do human readers quickly and accurately classify
the content of an article  our own introspection suggests
that one way readers do this is by scanning an article
and picking up on tip off words  words that are
highly indicative of the article belonging to a particular
topic  as a simple example  if a quick scan of an article
returns the word obama  a human reader might think
the article relates to politics  but have somewhat low
confidence in that classification  if the scan also returns
the words policy and congress  the reader is highly
likely to classify the article as relating to politics  and
moreover  to be fairly confident of that classification 
this idea and the notion of tip off words suggested to
us that fairly robust multi label classification should be
achievable with only a limited set of high information
words  and moreover  without access to any explicit
priors on class labels  consequently  we attempted to
develop a model that could find such a set of highinformation words and use it to classify multiple topic
labels 
vi  a derivative of the t erm f requency i nverse d ocument f requency model
a  a standard implementation of the model
since we are looking for high information words 
we turned to information retreival and search for
tools  topic classification can easily be thought of as
a search information retreival problem  given a query

fi 

 in our case  an article   which result  in our case 
topic label  is most relevant to the query  a common
weighting scheme used in search and information
retrieval is term frequencyinverse document frequency
 tf idf   a numerical statistic that reflects how important
a word is to a document in a collection or corpus  it
is particularly used in web search to rank pages by
keyword  we construct a simple variant of this scheme
for our problem 
the first element is the term frequency  tf   i e  the
number of times that token w occurs in an article a 
summed across all the articles in a particular class 
pn
 a 
x
j     w   xj  
w  tf  w   
pn
 a 
articles a
j   xj
intuitively  because we are summing over all the
articles in a given class  the tf score captures both the
frequency of a word in each article and the frequency
of a word across articles in a given class  words that
appear with high frequency across many articles in a
class will be assigned particularly high tf scores  next 
the inverse document frequency  idf  is a measure of
whether a particular term is common or rare across the
whole corpus of articles  it is obtained by dividing the
total number of words in the corpus by the count of the
instances of the particular word in the data  and then
taking the logarithm of that quotient 
p
 a   
articles a  words j xj
w  idf  w    log
p
 a 
articles a xw
intuitively  words that occur frequently in a specific
class but infrequently in the corpus in general constitue
high information words for a given class  while those
that appear often across the corpus are less informative  multiplying the tf score of a word by its itfscore allows us to take both aspect into consideration 
thus  we the compute for each token the tf idif score 
w  tf idf  w    tf  w   idf  w  
for each class we short listed the     most relevant
words   the highest information words for each class and used only them to score our testing examples  for a
given testing example  we compute a score per category 
each time a token in the testing article also appears in
the short list of the category  we add the score of the
word to the total score for that category 
x
score category c   
tf idf  w 
word in w

figure   shows a plot of the top     tfidf values for
business  the shape of the function reflects the intuition

that one can capture very high information about a class
with only a few words   and in fact the plot of the
next     words shows a further exponential drop in tdidf
values 

figure    top     tfidf values for the business category

b  learning a threshold
we now have a final score per category for our test
article  but we still have to make a decision on whether
it belongs to each class or not  for this we can use two
different machine learning techniques  kmeans  which
we implemented  and logistic regression  which we did
not but describe briefly below 
   threshold with k means  the result of the scoring
of a testing article often looks like this 

figure    idealized example of learning a selection threshold with
k means

our goal is to cluster these points in two different
categories  high scores and low scores  for the high
scores  we will predict    meaning that the article belongs
to those classes  and for the low scores we will predict   
meaning that the article does not  an advantage of the kmeans approach is that since threshold selection for each
article is independent  we are able to select a threshold
and make a reasonable prediction from the very first article we score  this feature of k means is also satisfying
from the perspective of finding a learning method that is
more similar to the way human readers classify   we can
predict scores immidiately and independetly of previous

fi 

thresholds for other articles 
a problem with this method is that the ranges of the
scores across topic categories are often not on the same
scale  categories with a large number of articles tend to
have higher tfidf values than categories with a smaller
number of articles  since we are summing the tf scores
for each word over every article in each class  thus  the
tfidf score for classes in which the number of articles
is a few times larger are often significantly higher  this
jeopardizes the underlying assumption of k means  that
the scores are comparable  this also explains the relative
magnitdue of false positives our system generated for
larger categories such as business  sports  and arts see results section for more detail 
   threshold with logistic regression  here we take
a very different approach  instead of learning a selection
threshold over tfidf scores for each class  article by
article  we instead learn over a great number of training
examples a threshold per category over which we decide
a label  i e  a prediction of y    needs to be applied 
this threshold can be learned using logistic regression 
one of the problems with this method is that the tfidf
scores are dependent on the size of the article  the longer
the article  the higher the score  consequently  using
logistic regression to learn a threshold would once again
require some kind of normalization of our computed
scores  lastly  a downside of logistic regression is that it
potentially requires exposure to a very large number of
articles before we can start making meaningful threshold
predictions   such that we lose our ability to mimic the
capacity of human readers in classifying new articles
indepedently of old ones 
c  results
our tfidf model had overall worse performance on
calssifying topic labels than did the binary classifier
approach  the table below shows the classification errors
produced for each class  broken out into false positives cases in which we mistakenly predict a label   and false
negatives  or cases in which we neglect to predict a label
for a given article 
interestingly  virtually all of our errors turned out to
be false positives  and were highly concentrated in three
classes  business  arts  and sports  our analysis of the
tfidf values in the false positive cases showed that the
relative size of the classes was resulting in very large
tf values in comparison with other classes  and thus
degrading the efficacy of k means in learning a selection
threshold 
we explored two methods of fixing this problem 
based on two sources of the error  our first approach

figure    error determined using top     td idf words for each class 
and tested on     articles

was to attempt to normalize the scores by dividing the
tf score for each class by the number of articles in that
class  this actually resulted in worse performance  so
we tried a different normalization scheme and instead
divided the tfidf score for each category by the max score
observed for that category  such that we could map tfidf
scores for each category to a normalized scale ranging
from   to    this too produced worse performance 
through this trial and error process  we realized that
normalizing the class sizes was actually a mistake   the
difference in class sizes captured through the summation
over all the articles in each class in some ways also
captured something akin to a prior on each class  and
k means needs a meaningful difference between outputs
to learn a good selection threshold 
our second method focused on trying to eliminate the
impact of some of the noisier terms in our top tfidf scores
for the biggest classes in particular  words that were very
common across our corpus and had very low idf scores
were still showing up in the top     tfidf words for large
classes   see figure     because they were still appearing
in a very large number of articles for the biggest classes 
so in particular  we tried to come up with a scheme
which would increase the relative weighting of the idfscore component relative to the tf componenet of the
tfidf score  which led us to a variation on our origional
model 
d  a variation on tf idf
a closer look at the top     tfidf scores for the three
largest classes indicated that at least a large part of
the false positive classification error was caused by the
persistence of high frequency but low information words
in our top words list  figure   shows the top    words
for the business class by tfidf score  note that while
most of the words are extremely high information and
very relevant to the class   words such as company 
market  and share   a number of words  marked
in read  are frequent but not particularly indicative of
business articles  the extremely high tfidf scores of

fi 

words such as year and month turned out to be largely
responsible for the high rate of false positives  indeed 
if one of these words appear in the article  the article is
very likely to be tagged business whereas the presence
of this word actually doesnt mean much 
because we wanted to avoid removing these words arti 

figure    error determined using top     td idf words for each class 
and tested on     articles

formal equation 









w  idf  w    exp   p


 
 a 


articles a words j xj
 a 

p
articles a

xw

 a   
articles a words j xj
p
 a 
articles a xw

p
log

   

near    the term inside the exponential determines the
shape of the funcion  while near    the term inside
the log is prevalent  this approach yielded the following
results 

figure    top    tfidf words and values for the business category

ficially from our top     tf idf lists and were concerned
that other low value words might take their place if we
did  we devised a scoring scheme that would place a
heavier emphasis on the idf score of a word such that
words with low idf scores would be unlikely to have high
tf idf scores  in the original idf model  many of the high
tfidf but low information had extremely low idf scores 
reflecting their generally high frequency across the corpus so we needed to modify the tfidf function such that
words with low idf values would be mapped to very low
overall tfidf scores  on the other hand  we wanted an idf
function that ensured that words with high idf values
stayed in o log  inverse document f requency   
we handcrafted the following function with the desired
properties  the resulting model is expressed by the

figure    error determined using top     td idf words for each class 
and tested on     articles

the results are better on average  but the errors are
now evenly distributed across the classes  nevertheless
the results are still far from the performance of naive
bayes  which leaves us the opportunity for further investigation 
on the whole our research validated the common
approach of using binary classifiers to learn multi label
topic classifications for new articles  the tfidf approach
captures some interesting aspects of the intuition behind
how people may classify news articles  but we were
not able to lower the error produced by the tfidf model
sufficiently to make it practically competitive with the
binary classification scheme  future research might look
into alternate methods for scoring functions based on
tfidf and the notion of finding high information words to
classify multi label articles 

fi 

r eferences
    rong en fan and chih jen lin  john w  dower a study on
threshold selection for multi label classification  technical report  national taiwan university       
    arzucan ozgur  levent ozgur  and tunga gungor  text categorization with class based and corpus based keyword selection 
proceedings of the   th international symposium on computer
and information sciences  springer verlag         pp          
e  h  norman

fi