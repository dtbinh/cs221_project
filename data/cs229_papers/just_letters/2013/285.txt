lane markings from satellite
danjie wenren  tianxin zhao  and kunming qu
in this project we attempt to apply techniques from digital image processing and machine learning
to extract lane marking information from the satellite images obtained from google maps  edge
detectors are used to reduce the amount of pixels that need to be examined  histogram of oriented
gradients are used as our feature descriptors and hough transform is used to obtain the final
marking of lanes 

i 

introduction

autonomous driving technology has advanced remarkably during the past few years  it has not  however  become practical due to the high cost of its major components  one approach that could significantly lower the
cost is to purely use computer vision technology to detect
the real time driving environment for autonomous vehicles  an important issue such kind of technology needs
to solve is to detect lane markings  with which the vehicle
can adjust its direction 
most work in the literature at the moment is on the
real time detection      and references therein   where
lane markings are identified using the images taken by
the vehicle  the techniques developed in such ways already have a very high detecting accuracy  however  they
might not provide the detecting results fast enough in
real time due to their computational complexity in examining one frame of image  this problem is even more
severe when the vehicle is moving at a high speed 
the goal of this project is to build a machine learning
system that could generate lane markings from satellite
images  the images we will use are taken from google
maps  with such a system  we can then build a database
of various properties of lanes  such as latitude longitude 
or the types of lanes  etc  tools that could map the
latitude longitude information of lane points into points
in a vehicles real time vision have been made  and the
complexity of such a mapping is expected to be relatively small  therefore given such a database of the lane
markings  a vehicle can identify its nearby lane markings
rather quickly 
at the current stage of the project  we implemented a
support vector machine  svm  to identify the white lane
markings  which separate lanes along the same direction 
for this purpose  a two class off the shelf svm package
is sufficient  specifically  we used the liblinear package
      
many features can be used to classify whether a point
is on a lane or not      uses both the local features 
such as the color and intensity of the point  and the
spatial context features of the point  such as those ob 

 sunet

id  djwenren
id  tianxin
 sunet id  kunming
 sunet

tained by applying a haar like filters  in this work  we
use the histogram of oriented gradients  hog       as
our features  adding local features of a point can also
increase the accuracy of the svm  as the svm trained
using purely the hog may mistakenly identify some of
the non lane marking points on the color changing edges
as lane marking points  however  at this stage of the
work  we have not added such features  as we will show
in the follows  even purely using the hog feature  our
technique already has a remarkable accuarcy 
the support vector machine trained as above can examine the image pixel by pixel  a layer of hough transform is added afterward  which further extracts lane patterns from a bit map generated by the svm  where  
means the svm thinks the point is on lane and   otherwise  at the moment  we only extract the straight lane
patterns  to reduce the amount of pixels the svm will
need to examine  a layer of edge detection is added before
the svm 
in section ii  we will give a brief overview of the digital image processing techniques we will use  section iii
will explain our supervised learning process and how we
selected models  in section iv we will show some detail
of how a lane marking are generated for a satellite image
using our technique  some results are also provided  we
conclude our current stage of work in section v 

ii 

overview of techniques

in this section we briefly introduce the techniques from
digital image processing that we will use  we will mainly
focus on the role they play in our technique of extracting
lane markings 

a 

edge detection

in the context of this work  edge means the set of points
in a digital image where the color vector  r  g  b  changes
significantly  this could be used as a primitive feature of
an image 
due to the high color contrast between the lane markings and the pavement around them  it is almost always
the case that there is a color edge surrounding the lane
marking  in specific  we use the canny detector       to
locate the edges of the satellite images 

fi 
b 

histogram of oriented gradients

histogram of oriented gradients       are strong feature descriptors for detecting objects in images  originally developed for the purpose of pedestrian detection 
it actually performs very well for other purposes  such as
detecting lane marking points 
this technique divides the image into small regions 
termed cells  and compute the histograms of binned gradients for the cells  the idea behind it is that local objects can be described by the distribution of color gradient and edge directions  the technique further organizes the cells  and their histograms  into a larger group 
called block  to improve detection accuracy  it contrastnormalizes the histograms of the cells inside the same
block  the normalization can reduce the effect of different illumination and shadowing  it maintains an invariance against geometric and photometric transformations 
the histograms of the blocks are then concatenated
to form a feature vector for the entire image  which can
effectively describe the content of the image  the length
of the feature vector can be determined as the follows 
let the size of the image be nx  ny and the side length
of a cell be c  then there would be roughly  nx ny  c   
cells in the image  in each block there are b  b cells
and in each cell  there are b bins in the histogram  due to
the overlapping of the blocks  each cell is roughly counted
for b   times  therefore there are approximately
 
 
  bnx ny
o b
   
c 
features for the image 
in the context of our work  the image that we use to
generate a hog feature vector is the patch around some
pixel we examine  whose size is roughly         the side
length of a cell is set to be   and there are      cells in
a block  assume the number of bins for each cell is    
then the length of the feature vector for a point is around
    
  
      
        
   
 
the exact parameters  such as patch size or cell size etc  
will be selected using ten fold cross validation later 
c 

hough transform

hough transform is a standard technique used in computer vision and digital image processing to extract
line pattern from an image  in the current status of
our project  we only used hough transform to extract
straight line patterns from the bit map image generated
by the svm  this works as follows 
a straight line in an  x  y  space can expressed by
 
 
r
cos 
x 
 
   
y  
sin 
sin 

fig     the training process 

where the    r  fixes the line  for a particular point
 x    y    on a line parametrized by    r       can also be
written as

r   x  cos    y  sin    x     y   sin        
   
where     arctan x   y     we can treat r in     as a
function of  for fixed  x    y     this gives a sinusoidal
curve in the  r    space  each point on the curve represents a straight line through  x    y    in the original space 
given a set of candidate points in the  x  y  space 
we can compute the sinusoidal curve r   for each point
 x  y   the weight of a point in the  r    space is the
number of such sinusoidal curves through that point 
therefore if there are n candidate points in the  x  y 
space on the straight line parametrized by  r     then
the weight of point  r    is n  thus the most weighted
points in the  r    represent the most likely straight line
patterns in the original  x  y  space 

iii 

training

the supervised learning process can be summarized by
fig    the training set is generated by manually selecting points from satellite images obtained from google
maps  in the current stage of work  we have only generated a training set of white lane marking points without
touching other type of lane points  such as the yellow
ones  in order to better train the support vector machine  we selected many more points on the color changing edges than those not on edges  the ones on the edge
are more important because they are more likely to be
on the decision boundary  since those non lane marking
points on the edge will look very alike with the lanemarking points  we need to provide the support vector
machine with more such points in order for it to learn
better  in other words  in doing so  we are providing
more support vectors and the decision boundary can be
better tuned 
for each training point  we pick a patch of size ps  ps
and use it to generate a hog feature vector for the point 
the length of the feature vector can be estimated using
     which is typically of order o        in order to have
a uniform size of patch and thus length of feature vector 
we impose a periodic boundary condition for patch generation  this might have a negative impact on labelling
points on the boundary of the satellite image  however
it is not likely that those edge cases would have an important effect on the entire labelling process  especially

fi 

fig     examining process for a satellite image  the bit map
is a matrix where   means the svm classifies the corresponding point as a lane marking point and   otherwise 

fig     the ten fold cross validation rate as a function of
patch size and number of bins used to generate hog features 
purely from the perspective of cross validation accurarcy  it is
indeed better to choose large numbers for patch size and number of bins  but large numbers also make the computation
expensive 

when there is a hough transform layer after the pixelwise labelling 
then the hog feature vectors and training point labels are fed into a svm to generate a model  in our
work  the training set consists of      points taken from
the el camino real near redwood city and ca     near
the page mill road  of which     are positive samples
and the other      points are negative  the setting of
the svm is to use l  regularized l  loss support vector
classification 
to select a better model  we use ten fold cross validation  the model space we scan through is where ps goes
from    to    and b  number of bins in the histogram of
a cell  goes from    to      other factors such as block
size and cell size are not expected to be important  in
our work  we set cell size to be   and each block consists
of      cells  the result is shown in fig    the plot
shows that it is indeed true that the larger the patch size
and number of bins  the better the cross validation accuracy  however  the improvement is marginal while the
cost of computation time is high when both numbers are
large  as shown by eq      the feature vector length is
o bps     classification with large values of b and ps can
be computationaly prohibitive 
therefore we choose to work with the model with patch
size    and number of bins     whose cross validation
accuracy is         there are     support vectors for
this model out of the      training points  for such a
model  the length of the hog feature vector is       
which is the same with the one given in eq     because
   is not a multiplier of   while    is     is rounded to
    

fig     the original satellite of the example  this image
showing a region along the el camino real near red woodcity is obtained from google maps 

iv 

marking lanes

having trained a support vector machine as described
in the previous section  we can then use it to extract
lane patterns from satellite images  this process can be
summarized as in fig    an example is shown in fig   
     and   
the step of edge detection can be regarded as a preprocessing step  the total number of pixels in an satellite
image can be large  a typical image from google maps is
                    examining every pixel on the image can take a long time  however  as argued in section

fig     the result after the preprocessing step to the satellite
image shown in fig    the white points are the candidate
points that will be further examined by the support vector
machine 

fi 

fig     the bit map generated by the support vector machine
after examining the candidate points as shown in fig   

fig     the final result after applying a hough transform to
the bit map as shown in fig    the green lines are the lane
markings identified by our technique 

ii  the number of points we need to examine is actually
relatively smaller  since it is almost always the case that
a lane marking is surrounded by a color edge  therefore adding a layer of edge detector before examining the
pixels using the support vector machine can significantly
reduce the processing time  for the example we use  the
original image to examine is of size                   
after applying the edge detector  the amount of pixels
we need to examine reduces to       
the number of candidate points can actually be further
reduced by applying another layer of simple classification
according to the local property of a pixel  the lane marking points typically have a clear white or yellow color  as
illustrated by the example in fig   and    a large portion
of the candidate points after the edge detection step will
drop out according to such a classifier  in our current
stage of work  however  we have not implemented such a
step 
the support vector machine as trained in section iii is
then applied to examine the candidate points  the features are again the hog features  generated using the
parameters selected in section iii  one example of outputs of such a step is shown in fig    it shows that svm

fig     another result from examining a region along ca    
the green lines are the lane markings identified by our technique 

can identify the lane marking points pretty accurate  although there are still some outliers 
we then apply a hough transform to the bit map generated by the svm and look for the peaks in the  r   
space  as there are misalignments between the short
lane markings that are supposed to be along the same
lane and lane markings have a width itself  we set the
resolution of r to be    that is  lines with a difference of  
pixels in r are regarded as the same line  we find all the
lines whose intensity in the  r    space is greater than
or equal to     of the maximum intensity  the result is
shown in fig   
as one can see from fig    our technique can identify
the lanes quite accurately  although there is one short
false positive in the middle of the image out of all the
true positives  another example is shown in fig   
at this stage it appears difficult to us to run error
analysis beyond the pixel by pixel level  since the training
set is constituted by the labellings at the pixel level while
our final result is given in the form of lines  one might try
to run such a diagnostic for the bit map result given by
the svm  indeed there are misclassified points as in fig   
those points  however  do not appear in the final result
due to the hough transform  also the cross validation
accuracy can already be viewed as a good proxy for the
test error  a better idea would be to manually take all the
lane lines for some maps and then test the results given
by our algorithm against those lines  we leave designing
such diagnostics to future work 

v 

conclusion and future work

in this work we applied three standard techniques from
digital image processing to develop a machine learning
based technique of identifying lane markings  parameters for the support vector machine model is selected
using a ten fold cross validation  using the training set
of      points we generated by hand  the cross validation
is         the performance of the technique is shown in

fi 
section iv  with a relatively small training set  manually
generated within half an hour by one person   it can already accurately identify almost all of the lane markings 
it is also worth noting that the lane marking we
found also contains the latitude longitude information 
as mentioned earlier  the goal of project is to produce
lane marking information for a vehicle to use in realtime  with the latitude longitude information of the lane
markings  the vehicle can use a gps and other relatively
simple programs to compute its location with respect to
the its nearby lanes 
there are also some interesting future directions we
can follow  the most straight forward extension is to
parallelize our technique  at the moment  our implementation is single threaded  as a result  it takes a relatively
long time to finish examining one image  since we basically do the same thing for every pixel and the work
done for each pixel does not depend on the work done
for the other pixels  it is very natual to parallelize the
process  we expect a large boost in run time efficiency
when applying gpu computation to our technique 
another extension would be to generated more training data  we will need to collect training samples of
other types of lane markings such as the singe or double
solid yellow lines  it also came to our attention lately

that an svm trained using horizontal or diagnoal lanes
does not perform very well for identifying vertical lanes 
therefore training set with different lane orientations is
in need  a larger amount of training sample from images
with diverse photometric conditions is also expected to
increase the quality of our technique 
the images we currently use are those taken by satellites  however  there are cases where such images are not
available  such as the roads inside tunnels  in those cases 
we can still apply our technique by first taking images on
the ground along with the relevant gps information  we
expect our technique to work for those images at least as
well as the satellite images  since in a real time image of
a road  there are typically less color edges that look very
like  loosely defined  lane markings but are actually not 

    r  gopalan  t  hong  m  shneier  r  chellappa  a learning approach towards detection and tracking of lane markings  intelligent transportation systems  ieee transactions on  volume      issue                  
    liblinear  a library for large linear classification 
http   www csie ntu edu tw  cjlin liblinear 
    dalal  n  triggs  b   histograms of oriented gradients for

human detection  computer vision and pattern recognition        cvpr       ieee computer society conference            vol   
    canny edge detector  http   en wikipedia org wiki 
canny edge detector

acknowledgments

we thank tao wang for providing the project topic
and helpful discussion  and prof  ng for giving such a
nice course  we also appreciate the hard and helpful
work done by the tas 

fi