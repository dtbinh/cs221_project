cs     project report  extracting vital signs from video
d deriso  n  banerjee  a  fallou
abstract
in both developing and developed countries  reducing the cost of medical
care is a primary goal of science and government  in this project we seek to find
and extract information from a video of a human that tells us the pulse rate and
the oxygen level of the blood  with the eventual aim to create a virtual pulse
oximeter  features to be extracted were chosen to be related to the three color
channel intensity values  with the idea that changing color of the video would
relate to blood flow around the body  extensive pre processing was required
on both the video data and the pulse oximeter data to enable training  early
results showed that feature selection was vital in reducing the mean squared
error of the output  at the end of this report  we outline further work to be
done 

 

introduction

cardiovascular health is the sin qua non of human life  early detection of cardiovascular
disease is of paramount importance in public health  this project aims to develop a method
to visualize the perfusion of blood through the skin via pulse oximetry  pulse oximetry is
a technique that exploits the fact that oxygenated and deoxygenated hemoglobin changes
the color of red blood cells  the technique maps these changes in rgb color of the visible
skin to the invisible presence of oxygenated vs deoxygenated blood in the local vasculature
underneath the skin 
our goal was to develop a process to obtain the pulse oximeter  spo   signal from a
webcam  ordinary webcams have limited spatial  temporal  and color resolution  that may
make it difficult to detect the subtle changes in color necessary for accurate pulse oximetry 
furthermore  factors outside the webcams limitations  including between subject variations
in skin pigmentation and lighting conditions  introduce noise to the signal acquisition process  to overcome these obstacles  we focused on engineering rich features that could be
used in standard learning models  the task was therefore to learn which combination of
features best represented the weak spo  signal 

 

eulerian video magnification

a paper     by wu et al  detailed a process known as eulerian video magnification evm  
whereby previously imperceptible signals were amplified such that they became visible to
the naked eye  for example  by amplifying the red color channel in a          hz band 
evm allows seeing the periodic blood flow on the face of a person in the frame  however 
potential issues appeared when performing evm on our own videos  we had time periodic
artefacts showing color fluctuations in unexpected regions  for example  part of the ceiling

 

fid deriso  n  banerjee  a  fallou

 

figure    obtaining ground truth estimates from spo  values per image
in the video would show a pulsating red color change at the frequency of the persons
heart rate  our pursuit of optimal features led us to extract the most relevant aspects
of their pipeline  which included frequency selection and parallel treatments of different
color channels  moreover  the evm process stipulates that the parameters for the color
amplification had to be pre determined  and we believed that would not play out well with
our goal of being robust to lighting conditions and camera settings  we therefore wanted
to relax the process such that those parameters did not need to be set manually 
the evm code provided convincing evidence that there exists information in a video
from which a pulse signal can be extracted  we therefore decided to base our feature
extraction techniques on those used in evm  further down the line  we hope to incorporate
evm more substantially into the project  we aim to map out the blood flow across the
whole human body by amplifying the right color frequencies  furthermore  we could use the
spatial amplification of the evm to show the physical motion of the skin as blood travels
under it  the potential impact of early identification of poor blood circulation is large 

 

preprocessing

video data
the three color channel intensity values through time  ir  t   ig  t   ib  t  were converted
into a four dimensional matrix of pixel location x and y  color channel and time  a fourier
transform was performed on the time course of each pixel  this ft was then binned to
reduce the dimensionality of the features 

pulse oximeter data
pulse oximeter data was collected using an arduino and a pulse oximeter connected to a
laptop  a program was written that recorded the spo  data  simultaneously taking pictures
every       ms on a webcam  this gave the spo  data corresponding to the image video
data  thus we had many images taken over small time intervals with a corresponding pulse
oximeter values  figure    
further processing had to be done because the pictures were not taken uniformly in
time and so computing a fourier decomposition of the pixels taken from each image would

fid deriso  n  banerjee  a  fallou

 

not be correct  an interpolation was needed for images  to create a set of images with
uniform time between them  and also for the pulse oximeter data to corroborate with the
images 
in order to accurately train our model  we also needed to bin the pulse oximeter values
and be able to recreate the signal from the binned values so that they remained true to
life 

 

results and discussion

initial results
at first we took    bins over a  hz interval of the fourier transform of each pixel  we
outputted a binary vector  with a   if the binned value exceeded a threshold and a  
otherwise  the binning involved with our initial results provided a coarse model and was
in fact a very poor representation of the data  in particular  for each pixel the binary
vector consisted of                  which is exactly the same distribution we would expect
for noise  thus our weight matrix contained predominantly zeroes  as we were training to
a predominantly zero vector 
to increase the predictive power of the feature set  we increased the number of bins
in the fft  although limitations in our computational power meant that we were restricted
to maximum    bins over the  hz interval  this applied to both the spo  value and the
pixels fourier transform  we also included the phase terms and the pixel locations as
further features  figure    
our feature matrix  x  which contained the features for every training example  gave
a matrix x t x with a very high condition number  this meant the normal equations were
unusuable and so stochastic gradient descent was used 

results
features were extracted from each pixel over time  and included the pixels  i k  location 
the fft of the pixels time course binned to   buckets per frequencies    hz  fq   fq       
fq     and phase  ph   ph        ph     linear least squares regression models were trained
on the combination of features listed in table   
these results suggest that each of the features  frequency  phase  and pixel location 
play a role in the prediction  furthermore  the least error was obtained when all three
features were used  mse            followed by just frequency and pixel  mse          
and pixel location  mse          as expected  for a single video  with numerous pixels
serving as training examples  the residuals were low 
the main limitation on our method is the encoding process used for reducing the
dimension of the training data into features  as can be seen in figure    bottom graph 

fid deriso  n  banerjee  a  fallou

 

figure    the pre processing steps
reconstructing a given signal from its feature set is a lossy process  this in turn increases
the noisiness on our predicted signal  figure    

 

conclusions
 we built a data collection program that recorded a series of images and spo  readings
for those images 
 using a binned fourier transform  we could efficiently reduce the video data to a
finite dimensional feature space and perform regression on it 
 increasing the variety of features included in the video reduced our mean squared
error in the linear regression 

fi 

d deriso  n  banerjee  a  fallou

pixel location
x
x
x
x




phase
x
x


x
x


frequency
x

x

x

x

mse
      
    
      
    
     
    
     

max cross correlation
      
      
      
      
      
      
      

table    results of different feature selections with corresponding mean squared error
between predicted and input signal and maximum cross correlation

figure    the predicted signal in bold and the actual signal in grey

 

further work

we hope to incorporate evm more broadly into the project and use more robust features 
using short time discrete wavelet transform the acquisition window can be shortened such
that we can create a real time application 

references
    hao yu wu  michael rubinstein  eugene shih  john guttag  fredo durand  and
william t  freeman  eulerian video magnification for revealing subtle changes in the
world  acm transactions on graphics  proc  siggraph                    

fi