move ranking in arimaa
abstract

arzav jain  neema ebrahim zadeh  vasanth mohan  vivek choksi
stanford university

in this paper  we describe our work on ranking moves in the game arimaa  we first discuss the various models
that we usednaive bayes  an l  regularization l  loss svm with a linear kernel  and l  and l  logistic
regressionin order to rank moves based on expertness  this was done with the goal of pruning an
exploration of the game tree  we found that the svm model  on average  ranked     of expert moves within
the top     of all possible moves  other models exhibited comparable performance  while these preliminary
results are promising  the models all suffered from high bias  probably due to a limited feature set  the paper
ends with future approaches to improve our existing models 

i  introduction
arimaa is a two player board game played on an  x 
grid  with players controlling    pieces each  similar to
chess   for more details on arimaa gameplay  see the
rules   the game was designed to be difficult for
computers to play but not  particularly  difficult for
humans to learn and play   this human bot discrepancy
stems in part from the games enormous branching
factor  researchers have estimated an average of      
distinct legal moves per turn  as well as an average total
of    turns per game   the game tree complexity is
estimated to be on the order of
 compared to
in chess and
in go    as a result  brute
force game tree traversals are severely limited in terms
of depth of exploration 

ii  related work
much of the prior work on building ais for arimaa
finds optimal moves using game tree search algorithms
 for example  alpha beta search and monte carlo tree
search    however  to date  there has been only one
documented major effort to apply machine learning to
arimaa  this work  presented by researcher david wu
as his honors thesis at harvard  applies machine
learning to rank all possible moves given a board state 
and serves as the foundation for our project 
david wus model scores possible moves based on an
evaluation function  as such  it implements move
ordering rather than move classification  moves are ranked
by expertnessi e  the likelihood that an expert
would play the moveand the model uses this move
ranking to prune the exploration of the search tree  so
instead of searching the game tree for all possible
moves that can be played  his model does the
following 
  
  
  

order all possible moves by expertness
select the most expert  for example      of all
possible moves
search the game tree only for those top    of
moves using alpha beta pruning

while our machine learning approach draws from
david wus work  our code is built upon an existing
arimaa bot  bot clueless  developed in java by jeff
bacher   the starter code provides functionality to
interpret game boards  manage updating boards with
moves  and generate all possible moves from a given
board state 

iii  data management
since       more than         games have been
recorded on the arimaa website  all in a parse able text
format   this format works well for linear scans of all
the data but is cumbersome for more complex queries
 such as filtering for games in which both players are
experts   for ease of querying  we parsed and loaded
the game data into a mysql database  enabling us to
easily execute arbitrary queries 
we hosted the mysql server on amazons rds so
that parallel jobs on multiple machines could freely
access the game data 

iv  scalability
computation time  we ran multiple evaluations of
our model using training sets of different sizes  and
each run took around   minutes per game  to speed up
these evaluations  we parallelized our tasks using
stanfords farmshare computing resources  corn and
barley  
memory  when training the svm model  all feature
vectors are required to be held in memory  because of
the large branching factor in arimaa  each trained move
corresponds to thousands of training examples and
resulting feature vectors    for the expert move and on
average        for non expert moves  this resulted in
about   gb of text data for every    games  despite a
sparse representation of feature vectors  loading these
into memory translated to approximately       gb of
ram for every    games when running the c version
of liblinear   since a typical laptop does not meet
these ram requirements  we used stanfords barley
computing machines to allow us to evaluate training set
sizes of up to     games 

 

fiv  implementation of features
the features implemented are inspired by david wus
work on arimaa   in order to characterize the
expertness of a move  the resulting board is mapped
onto a feature space composed of features of the
board  these features were chosen to correlate with
how strong a move is 
in order to reduce redundancy in our feature set  we
exploited the left right symmetry of the arimaa board to
cut the number of location based features in half
 giving only    mirroring locations instead of     
furthermore  we denoted a pieces type as the number
of stronger opponent pieces on the board  since this is
a more meaningful encoding than absolute piece
strength   we have implemented the following feature
classes 
  
  
  
  
  
  
  

position and movements
trap status
freezing status
stepping on traps
 goal threats
 capture threats
 correlation with previous moves

vi  naive bayes model
in order to quickly implement a baseline and gain
some insight into the problem  we built a variation of
the naive bayes classifier  we used a multivariate
bernoulli event model coupled with laplace
smoothing 

methodology
our implementation slightly modified the traditional
naive bayes classifier because we are dealing with
move ordering rather than move classification  as such 
instead of classifying a given move  denoted by feature
vector   as expert or non expert  
or
respectively   our naive bayes model output the log of
the posterior odds of   as shown below  we used this
value as a score for a move and ordered all possible
moves according to this score  in descending order  
the ordering function is given by
 
 

   
 
   

 

during the training phase  we performed the following
algorithm  written below in pseudocode  
for each game in the training data 
for each board position in the game 
   generate all possible legal moves  including the
expert move actually played in the game
   extract feature vectors for all of these moves
   update a table that holds the frequency of
occurrences for each feature  for
and
 

testing 

for details on each feature  please refer to david wus
paper  

 

training 

we then converted these frequencies into loglikelihoods  which we used in the testing phase 

due to impractically long computation times  the
starred     features were eventually not considered
when training and testing our learning models  for
future work  optimizations  involving significant
rewriting  could be made to bachers game logic code
to make computing these features feasible 

   

in order to evaluate our model  we used crossvalidation by training on     of the data and testing on
     in order to train only on expert human moves 
we only considered games in which both players elo
ratings were above        this still left       of the
        total games as potential training candidates  

we used the following two metrics to evaluate the
success of our model on the training and testing data
sets 
  

  

the average percentile of the expert move
among all possible moves after ordering  this
describes the average percentage of moves
that were ranked below the expert move 
the proportion of expert moves that rank in
the top x percent of all possible moves  for
different values of x 

we trained and tested our model on randomized
example sets of different sizes  we calculated the first
metric on both our training and our testing sets in
order to generate learning curves 

results and discussion
figure   shows the naive bayes models learning
curves for the first of our metrics  we tested our
 
hypothesis four times on each of  
games to produce the trial averages shown below 

 

 

fibeginning game than for the end game  features not
considered  such as testing for goal and capture
threats   which come into play later on in the game 
might improve the middle  and end game performance 

figure    these curves follow the expected behavior
for a high bias model  we see that these plots will
converge to an average percentile of      we will
need to implement more features to decrease bias 

in order to measure not just the average percentile but
also the consistency with which the model ranks expert
moves highly  we plotted the histogram shown in
figure    the histogram shows expert move percentiles
along with an added dimension  move number within
the game  the plot was generated by running   naive
bayes trials  each of which was trained and tested on
    games   we see that the naive bayes model ranks
the expert moves more highly in the beginning of the
game  for about the first    moves marked in dark
green  than it does for the middle  and end game 
where the distribution flattens 

another possible contributor to the poorer
performance on end game moves could be the
underrepresentation of these moves in the data set  as
the move number within a game increases  fewer and
fewer games actually contain data for these points
 many games end before  say  the   th move   this
means our model has more data from which to learn at
the beginning of the game  this may partly explain the
models stronger performance on early moves in the
game 

vii  liblinear models
given the high bias evident in the naive bayes
assumption  we wanted to evaluate the performance of
other models 

methodology
we trained svm and logistic regression models  in
particular  we compared   different models  l regularized l  loss svm  l  logistic regression  and l 
logistic regression 
we also tried to compare svm with different kernels
using libsvm   but due to our large training set size 
the training time for libsvm was orders of magnitude
longer than for liblinear  e g   over   days for
libsvm versus         minutes for liblinear   as
a result  we chose liblinear 
training 
in generating svm and logistic regression models  we
addressed the following three concerns 
performance  memory use and computation time   while our
feature extraction and evaluation harness code is in
java  we used the c version of liblinear for model
generation to improve performance 

figure    this plot compares the number of moves
played within a game and the percentile of the
expert moves vs  the proportion of expert moves 
we discretize the number of moves played into
buckets of    moves  we also discretized the
percentile in buckets of      where the displayed
percentile is the average value of the bucket 

we hypothesize that the features implemented tend to
capture the qualities of a good move more for the

high ratio of negative to positive training examples  due to the
high branching factor in arimaa  this ratio is on the
order of        non expert moves to   expert move 
to help address this imbalance and to extract features
from expert and non expert moves more equally  we
randomly discarded     of all non expert moves  this
improved performance and allowed us to train and test
on more games 
tuning model parameters  we cross validated different
values of the svm parameter
 
   observing similar results
for
 
  and poorer results as was
increased above   we also examined different
weights for the expert and non expert classes to further

 

fiaddress the disproportion of non expert moves 
different weights produced very similar results to
liblinears default weight ratio of     
testing 
in computing our ordering of moves  we used the
margins for svm and probabilities of the sigmoid
function for logistic regression 

results and discussion
we see in figure   that after we randomly discard    
of the non expert moves  the models converge to
around the   th percentile after about     games 
interestingly  without discarding any non expert moves 
the models converge to the same percentile but after
    games  not shown here  

figure    the svm and logistic regression models
had similar performance  both faring moderately
better than the naive bayes  not shown  model 
they both ranked     of expert moves in the top
     whereas naive bayes ranked     of expert
moves in the top     

figure   was generated by running   trials  training on
    games and testing on     games  though the plot
was generated and displayed only for the svm model 
it was very similar to that of the logistic regression
model 

figure    the above learning curves show that the
svm and logistic regression models similarly
suffer from high bias  the average percentiles of
the expert moves converge to about      only
marginally better than the naive bayes average of
    

in terms of the number of feature vectors considered
before reaching convergence  discarding     requires
fewer vectors  this permits shorter computation times
to attain similar results  with the caveat of requiring
more games in the database 
for analytical purposes  we also plotted the proportion
of expert moves that were evaluated above a given
percentile  this creates a plot  see figure    that reads
very similarly to a cdf  in other words  the  value
corresponding with  for example 
represents the percentage of expert moves that our
model classified in the top     of our move ordering 
one takeaway from this analysis is that  if we limited a
search of the game tree to the top     of the move
ordering  then we would examine an expert move    
of the time  when using svm or logistic regression
models  

figure    similarly to naive bayes  there is a trend
that expert moves closer to the beginning of the
game are ranked more highly   in general  the
svm model outperforms naive bayes  

similarly to the naive bayes histogram  we see that the
proportion of expert moves ranked highly is largest for
the beginning moves of the game  this reinforces our
hypothesis that the features currently implemented
capture essential qualities in early game moves 

 

fiviii  future work
hard negative mining
in deciding our training set of negative examples  we
have two objectives 
  

  

minimize
memory
requirements
and
computation time by considering only a
subset of negative examples at a given point in
time   currently  we are discarding     of the
data in order to boost svm training speed  

works cited
  
  

  

retain useful information in negative
examples 

hard negative mining can potentially achieve these
dual objectives  one could first pick a random subset
of the negative examples and run a model such as
svm  the model would then be retrained on the
negative examples classified most poorly along with an
additional random subset of the data  this step wise
training could be repeated until convergence without
particularly high memory demands 

  
  

time based features
as we hypothesized from the move vs  percentile plots 
adding more features to capture qualities of end game
moves might be helpful  however  it could also be
interesting to see what features are relevant based on
the number of moves currently made in the game  for
example  looking for goal threats may not be as
insightful at the beginning of the game as it would be at
the end of the game  in order to learn which features
are important at each time step of a game  one could
perform feature selection specific to each time step and
choose the most relevant features accordingly 

acknowledgements

  

  

  

arimaa com  arimaa game rules  retrieved
from
http   arimaa com arimaa learn rules pdf
arimaa game archive           data file  
retrieved from
http   arimaa com arimaa download gamed
ata 
chih chung chang and chih jen lin 
libsvm   a library for support vector
machines  acm transactions on intelligent
systems and technology                
         software   available at
http   www csie ntu edu tw  cjlin libsvm
haskin  b          specifications for the
arimaa engine interface  aei   retrieved
from http   arimaa janzert com aei 
syed  o         may      please say more
about the design decisions   msg     message
posted to
http   arimaa com arimaa forum cgi yabb 
cgi board talk action display num        
     
wu  d  j            march   move ranking
and evaluation in the game of arimaa 
harvard college thesis  retrieved from
http   arimaa com arimaa papers davidwu
 djwuthesis pdf
bacher  j           march   bot clueless  a
sample bot written in java   software  
available from
http   arimaa com arimaa bots 
r  e  fan  k  w  chang  c  j  hsieh  x  r 
wang  and c  j  lin  liblinear  a library
for large linear classification  journal of
machine learning research              
         software   available at
http   www csie ntu edu tw  cjlin liblinear

we would like to thank the cs    teaching staff  and
especially sameep  for their help and guidance
throughout the project  in addition  we would like to
thank david wu for his valuable support and insight 
we are also grateful for stanfords farmshare
computing resources  which we used to train and test
our learning models 

 

fi