pedestrian detection using structured svm
wonhui kim
stanford university
department of electrical engineering

seungmin lee
stanford university
department of electrical engineering

wonhui stanford edu

smlee    stanford edu

   introduction
with the advent of smart car and even driverless cars  the
importance of intelligent drivers system has been rapidly
growing  accordingly  drivers vision has become one of
the most popular issues and especially detecting some obstacles and pedestrians on the road are at the center of the
vision problem in order to prevent accidents  motivated by
the importance of such topics  we implemented the human
detector in the project 
our approach is based on deformable part model    
one of the most powerful method for object detection  in
the learning part of the system  we applied structured svm
 ssvm  instead of latent svm  lsvm  which is used in
     the major goal of this project is not only to understand
how differnt types of svm can work on the detection problem but also to apply ssvm on our pedestrian detection
problem 

figure    overview block diagram 

during the whole procedure  we do not use raw images
but instead use transformed images into hog feature space 
since our approach is mainly based on the window scanning  hog feature pyramid with different levels is constructed for each image 
the model mainly consists of root filter and part filters
which should be obtained after the completion of the learning process  root filter is trained with the coarse resolution
whereas part filters are trained with finer resolution  using
the ssvm learning algorithm and given annotation files for
the training data which contains ground truth bounding box
coordinates  the optimal root filter and part filters can be
obtained 
with obtained root and part filters  the scores for each
test image are calculated by taking the convolution between
the filters and the hog feature pyramid of an image  then
we will determine whether some parts of image are desired
objects or not based on the given threshold  finally  we
will use precision recall curve and average precision ap 
to evaluate our model 

related work
dalal and triggs    have developed the idea of histogram of gradient and have achieved excellent recognition
rate of human detection in images  they used the concepts
of hog and designed a baseline classifier using a linear
svm  after a few years  felzenszwalb et al      introduced
the deformable part model applying latent svm  the performance of the detector has been significantly improved
by combining hog feature pyramid with deformable part
model  deformable part model has been applied in various papers and it is considered as the most general framework for object detection in  d image  in      the concept
of structured svm first introduced  whose major difference
from previous ones is the structured vector form of the output and the loss rescaling in the constraint inequality  theoretical background of our project is mainly based on those
works 

   deformable part model
     learning
a model is defined as  f    p         pn   b  which consists
of a root filter f    n numbers of part models p         pn   and
the real valued bias term b  each part model pi consists
of a part filter fi   the location ui relative to the root filter

overview
our detection method is summarized in two phases  the
learning phase and the detection phase 
 

fi   structured svm

and the coefficients vector di for evaluating the deformation
cost  the ultimate goal of learning is to find the optimal parameters vector w    f    p         pn   b   more details of
parameter settings are in      the primal optimization problem of latent svm with soft margin can be simplified as
follows 
m
x
 
i
min kwk    c
w   
i  
s t  i           m 

both linear svm and latent svm are binary classifiers
where target variable y is binary  rather than predicting
a binary label for each input  ssvm predicts structured
responses  given m training examples   x i    y i     for
i      m  where x denotes the feature vector extracted from
ith training image and y is the structured output  the ssvm
optimizes w by minimizing a quadratic objective function
subject to a set of linear inequality constraints 

i    

m

min

y  i  hw  x i        i

w 

c x
 
kwk   
i
 
m i  

s t  i           m  

y  y  yi   hw  i  y i    yi   y   i

where y  i           it looks identical to the linear svm
but the difference is in the definition of hypothesis function
which involves some latent variables 

there are m  y       numbers of inequalities where w
is a parameter vector  y  yi is the set of possible outputs
excluding yi and i is a non negative slack variable for ith
example  i  y     xi   yi     xi   y  where  x  y 
represents some combined feature representation of inputs
and outputs and   yi   y  is a loss function 
with the parameter vector w obtained  we can make a
prediction by maximizing the score function f over the response variable for a specific given input x as follows 

hw  x    max wt  x  z 
zz x 

z x  denotes latent domain of valid placements for the root
and part filters specified by x  latent variable z  z x 
contains latent information about the relative part locations
and the whole configuration   x  z  is the concatenation
of features for the root filter  part filters  deformation cost 
and the constant   for the bias term 

hw  x    argmax f  x  y  w 
yy

where f  x  y  w    hw   x  y i

     detection

one of the major advantages of applying ssvm is tunability to specific loss functions  we call this margin rescaling  creating larger margins for the classes of most desirable
misclassification  by defining the loss function   yi   y  as
any appropriate form that is in general proportional to the
dissimilarity between two outputs  we can give flexibility to
the inequality thereby performing better training compared
to the case when just using a constant loss 

a model obtained through training is defined as
 f    p         pn   b  where f  is a root filter  pi is the i th part
model and b is a scalar bias term  each part model consists
of a part filter fi   the relative location to the root filter ui
and the coefficient vector for evaluating a deformation cost
for each possible placement of the part 
with learned filter parameters  f    p         pn   b  and the
feature pyramid which is calculated with a new input image x as a part of scanning window approach  we can now
implement the detection by evaluating their dot product as a
score  by thresholding the scores for all root filter locations 
we can finally detect people in a test image 

   experiment
before implementing our human detector  many things
must be decided such as features  parameters  loss functions
for ssvm  optimization algorithm  training dataset  and so
on  in this section  we focus more on practical issues such
as how we specified some important variables and look into
the details for the implementation 

     multi component model
in practice  there are some variations in human images
due to different poses  directions and actions  therefore 
defining only a single model for the human detector would
prove ineffective for such images  instead of constructing
a single model  we split the whole positive training images
into n groups according to aspect ratio  the ratio between
the width and the height of bounding boxes  and then construct models for each group 
in this project  we trained models for both   component
and   component cases since human images do not contain
much variations compared to other objects 

     data selection
pascal voc      dataset which contains       
training examples with complete annotations is used for the
project  for each image  xml file is provided  which contains class label and ground truth bounding box positions
but not for part locations 
it also has images for testing but does not contain a complete set of data labelling files  so we evaluated our system
using       test images from pascal voc      dataset 
 

fi     feature selection  hog descriptor

when performing the coordinate descent  we first find
the latent variable z  i  for each training example  which
maximizes the score calculated with the fixed parameter
vector w  that is  for every m training examples  find root
and part filter locations z  i  around x i  having the maximum score 

the accuracy and the effectiveness of hog feature for
human detection has been verified in many works and is
currently accepted as one of the most appropriate and generalized feature  we also use hog feature for this project 
more details are in     
when applying hog feature transformation to an image 
we obtain    transformed images for each gradient orientation and normalization  due to the window scanning approach applied in this project  we use the concept of hog
feature pyramid instead  with various resolutions of an image  we calculate hog features for each level of resolution 

z  i    argmax wt  x i    z 
zz x i   

after the completion of the first step  we find the parameters vector w using the stochastic gradient descent 
when updating the parameters vector  we can apply the loss
function when checking the satisfiability of inequality constraints 
as for the negative training examples  it should be carefully chosen for the parameter update  since there are a
huge amount of possible negative examples  we perform
datamining hard negatives which are relatively close to the
score of positive examples so misclassified as positive but
actually they are negative 
the real implementation does not exactly follow the definition of ssvm  for positive examples  instead of updating the parameter vectors for all the possible locations of
bounding boxes  we first choose z  i    the latent variable
which maximizes the score  with calculating its overlap area
 i 
o z  i    yb   because otherwise the computation is too expensive  then  we perform learning with such optimal z  i 
by checking whether the constraint satisfied or not accord i 
ing to the value of o z  i    yb   

     parameters setting
before applying ssvm algorithm to our problem  input
and output vectors and also the parameters vector should be
clarified  the two most distinctive characteristics of ssvm
is the flexibility in choosing loss functions and the form of
outputs which can be a structured vector form  we choose
the output vector as y    yl   yb   where y l         and
y b is a four dimensional bounding box labels vector 

     the loss function
we can simply choose the loss function for this y and its
ground truth vector y  i  as follows 
 i 

  y  y  i         o yb   yb  

if

 i 

yl   yl

  

 i 

where o yb   yb   is the fraction of overlap area defined by
two vectors  overlap area is computed by dividing the area
of intersection as the union of two vectors 
as a possible output y approaches the true output y  i   
 i 
o yb   yb   gets larger thus the loss decreases  with lower
values of loss  it would become easy to satisfy the constraint  thus  the flexibility of the loss function increases
the probability to satisfy the constraint for outputs that are
close to the ground truth output  on the other hand  if y
and y  i  do not overlap  the loss is maximized with value   
since the bound of inequality constraint is more strict  it becomes more likely to violate the constraint  thus  the flexibility of the loss function decreases the probability to satisfy
the constraint for outputs that are far from the ground truth
output 
for negative images  y does not have ground truth
bounding boxes  hence we just use   for the loss  in the
code implementation  we do not face with the case where yl
 i 
and yl are different  so we do not have to define the loss
more in specific for such cases 

   results
     trained model
we constructed both one and two component models for
human detector  figure   and figure   shows the resulting
models learned on pascal voc      dataset    parts are
used when learning  but we can see that one of them does
not take the important role in the person model 

     evaluation
since pascal voc      dataset does not contain a
complete set of data labellings  we evaluated our system
using       test images from pascal voc      dataset 
the dataset specify ground truth bounding boxes of human
location for each image  based on the calculated scores for
each image  we can evaluate the precision and the recall 
the precision is the number of true positives divided by the
total number of elements labeled as belonging to the positive class  and the recall is the number of true positives
divided by the total number of elements that actually belong to the positive class  in other words  the precision is
the fraction of the reported bounding boxes that are correct

     implementation detail
as in      we train the ssvm using the coordinate descent approach together with the datamining and gradient
descent algorithm 
 

fifigure      component person model obtained by ssvm  this single model cannot generalize various shapes of person in random
test images 

figure    comparison of precision recall curves between the models obtained using lsvm and ssvm  the more the curve is placed
on the top right side of the plane  the better the detector is 

figure      component person model obtained by ssvm  upper
model showing fat shaped person seems to represent those who
are sitting down  bottom model shows normal shape of person 
figure    comparison of lsvm and ssvm with average precisions  n is the number of components of the model  and test  and
test  use slightly different algorithm to decide the final bounding
boxes position  regardless of which test used  ssvm always gives
better performance than lsvm 

detections  while recall is the fraction of the objects found
correctly 
figure   shows the precision recall curves for four different learning procedure  as we can see from the figure  the
curves resulting from ssvm is closer to the top right side
of the plot than those from lsvm  more specific values are
in figure   

   conclusion
in this project  we have applied ssvm to the human
detection problem based on deformable part model  the
optimization problem for ssvm is solved though coordinate descent technique  which involves datamining hard
negatives and stochastic gradient descent  as a result  we
achieved roughly    of performance improvement for the
  component human detector  that is because ssvm gives
flexibility to choose the loss function  making the constraint
tough for examples far from the ground truth one while
make it loose for those close to the ground truth vector thus
raising the possibility to satisfy the constraint 

depending on the determination method for final bounding boxes  we have two kind of measures  while test  column indicates the result only considered root location  test 
column shows the result considered both root and part locations  average precisions ap  resulting from ssvm learning are greater than those from lsvm learning for both  component and   component models  especially as for the
  component model  we have achieved roughly    of the
performance improvement compared to the original human
detector based on lsvm learning algorithm 
 

fi    b  pepik  m  stark  p  gehler and b  schiele  teaching
 d geometry to deformable part models  cvpr       
    m  blaschko  c  lampert  learning to localize objects
with structured output regression  eccv       
      c  desai  d  ramanan  c  fowlkes  discriminative
models for multi class object layout  iccv       
      n  dalal  b  triggs  histogram of oriented gradients
for human detection  cvpr       

figure    detection examples using deformable part model learned
by ssvm  it is actually hard to detect the difference between resulting images from lsvm and ssvm through the eye  ssvm
shows better performance  images on the left column shows root
bounding boxes together with each part  and images on the right
column shows the final bounding boxes 

   future work
due to the heavy load of computation  especially during the learning procedure  we only performed the detection
for human  however  our approach can be generalized for
other object classes as well  such as vehicles  animals and
so forth  in such a case  however  another type of features
instead of hog feature might have to be chosen 
in addition  it would be possible to apply the complete ssvm learning which exactly follows the optimization problem mentioned in section   in the implemenation
procedure  in this project we only focused on the loss
rescaling of ssvm and defined the loss function in a really simple form  but there might be more effective way
to design the structured output vector y at the expense of
heavier computation  so we are now planning to design the
learning parameters in a different way that leads to better
performance 

references
    p  felzenszwalb  d  mcallester  d  ramanan  a
discriminatively trained  multiscale  deformable part
model  cvpr       
    p  felzenszwalb  r  girshick  d  mcallester  d  ramanan  object detection with discriminatively trained
part based models  pami       
    i  tsochantaridis  t  joachims  t  hofmann  y  altun 
large margin methods for structured and interdependent output variables  jmlr       
 

fi