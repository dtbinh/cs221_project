supervised learning methods for vision based road detection

vivek nair
nikhil parthasarathy

vnair      stanford   edu
nikhilp   stanford   edu

abstract
one of the most important problems in the development of autonomous driving systems is the detection of navigable road  this paper explores a
formulation of this issue as a supervised learning
problem  given highway video taken by a frontal
camera  a naive method for generating positive
and negative test images is proposed in order to
implement binary classification  two promising classification systems are implemented and
compared  the first uses a linear svm to classify image sections featurized by segment based
fractal texture analysis  sfta   this approach
is compared to supervised learning via a multilayer convolutional neural network  cnn   both
methods achieve very high accuracy but the cnn
is shown to perform slightly better due to higher
specificity 

   introduction
with the advent of environment aware automobiles  e g 
adaptive cruise control and googles self driving vehicle  
developing cheap and efficient algorithms for detecting
road will be crucial in making the latest ai technology accessible to the average car owner  in particular  road detection is complicated by different obstacles such as road
markings  e g  lane dividers and car pool signs  and light
differences  e g  trees casting shadow onto the road   for
this project  we want to answer the following question  can
we accurately detect road on a highway  even given the
presence of various obstructions 
     related work
in recent years  there has been increasing work done in the
area of drivable road detection  given the large number
of negative examples that span an extremely large set of
categories  vehicles  pedestrians  barriers etc   and the difficulty of obtaining labeled training examples  early vision 

based road detection systems avoided supervised learning
models for road detection  instead much of this early work
implemented unsupervised image segmentation using basic color  edge features  and other rules hu et al        
these unsupervised learning systems often created complex appearance models for road detection by segmenting
and clustering individual pixels from many positive road
examples alvarez et al          methods have also been
explored to improve the robustness of such models by specific feature engineering to capture lighting invariance alvarez   lopez        
outside the realm of unsupervised classification  there has
been research into self supervised online learning to continuously update a classification model  such as an svm 
for road detection zhou et al          purely supervised
approaches have also been implemented  but these scene
segmentation algorithms are usually trained on general
datasets such as labelme and then applied to the specific
domain of road detection  alvarez et al        specifically
attempts to learn from noisy machine generated labels with
a convolutional neural network 
     objective
as mentioned above  the methods for road detection mostly
focused on unsupervised and self supervised models  even
the self supervised systems were trained either on small
sets of manually labeled examples or on general datasets
that are not domain specific  the goal of this study was
to turn the problem of road detection into a completely
supervised learning task  the rest of this paper is structured as follows  in section    the dataset used is defined  along with an explanation of a process used to generate positive and negative labeled training examples  section   details the different feature encodings and classification methods that were implemented  section   discusses the performance of all implemented systems and
specifically compares the results of the two most promising approaches  segment based fractal texture analysis
and convolutional neural networks   section   discusses
the limitations of this work and suggests areas for improvement and future work 

fics    final project

   the dataset
tao wang  phd student in stanford ai labs  sail   provided us with    hours of highway driving recordings to
train  validate  and test our models  all of the recordings
were taken on highways     and      which span large areas of the bay area 
     generating labeled training examples
generating labeled examples for road detection is a difficult problem for many reasons  in particular  hand labeling
thousands of negative examples can take a considerable
amount of time investment  as a result  most vision based
road detection systems are not completely supervised  we
wanted to explore the performance of a supervised system  given a naive method for generating significant labeled
training examples 
we generated our positive examples by always assuming
that the lower cross section of the image is road  this is a
reasonable assumption made by many studies that attempt
to perform similar road detection on images  in figure   
for example  this cross section area is defined by the red
rectangular box  unlike many other studies  however  we
utilized a similar idea for negative examples  we generated our negative examples by taking cross sections of the
image that do not overlap with the positive cross section
area  as defined by the rectangular box above   a negative
cross section example is shown in figure    while this negative example generation is not perfect  we found that this
approach provided a reasonable dataset to use for training
at a fraction of the time 
another issue in road detection is the fact that perspective
changes the texture and look of the road across the image 
in order to account for this  we took various subsections
from the original cross sections  and resized them to a fixed
input size  these multiple resizings are a very simple approximation for the perspective differences within the image 
for this study       training examples were used  evenly
distributed between positive and negative examples  the
test set was composed of      examples  evenly distributed
between positive and negative examples  in order to make
the training and test sets as different as possible  we used
images taken on highway     for training and used images
taken on highway     for testing 

figure    example highway image taken with positive example
bounding box

figure    example highway image taken with negative example
bounding box

   methods
     baseline soft margin svm classifiers
in order to obtain a simple end to end system  we implemented three svm classifiers  encoding the images in three
different naive ways 
   we computed the average r  g  and b values for
a given image and used those three values as a  dimensional feature vector 
   we computed the average r  g  and b values for every
    pixels in an image    feature values per     pix 

fics    final project

els   given that each image has dimensions      by
     each image is represented as a                
feature vector 
   we first ran k means on each image to normalize for
rgb discrepancies and then applied the same batch
averaging as in the second encoding 
we then ran a soft margin svm on these three different
constructed feature vectors 
     segment based fractal texture analysis  sfta 

     convolutional neural networks  cnns 
the above methods all center around the idea of obtaining the right feature representation for an image and then
applying a standard classifier such as an svm to classify
the data based on these input features  in this section  we
describe an approach that does not require specific feature
engineering but rather uses a multi layer network to automatically obtain higher order features that are used in classification  this method is based on convolutional neural
networks  lecun   bengio         the basic idea behind cnns can be seen in the figure below  our cnn im 

throughout our project  we researched numerous texture
classifications processes to capture the intrinsic properties
of road  e g  gravel patterns  non metallic surfaces   we
found that analyzing the fractal dimension of a certain texture  essentially how the detail of a texture pattern changes
with the scale of the pattern  could potentially yield high
accuracy classifications 
specifically  we researched and implemented the segmentbased fractal texture analysis algorithm  which decomposes images into various thresholded images using several
sets of lower and upper threshold values  our implementation was based on the implementation in costa et al        
the two threshold segmentation was applied using the following representation 

    tl   i x  y    tu
ib  x  y   
   
 
  otherwise
these thresholded images are used to extract the fractal dimension  since images with more jagged edges and prominent color differences tend to have higher fractal dimension  images with more uniform texture properties  in this
case road  will have closer fractal dimension 

figure    diagram of the cnn model

plementation utilized the theano python library for deep
learning and was based on the lenet cnn that was first
used for detection of handwritten digits  the input to the
cnn was a    x    fixed input image  this image was
featurized by converting each images    x    array into
a     x  vector  the implementation that we used consisted of two alternating convolution subsampling layers
 with max pooling  followed by a logistic regression output layer  the learning rate was decayed from an initial
     with a       decay rate 

   results
     overview
the results of the three baseline models  sfta  and cnn
are summarized in the table below 
table    accuracies of all implemented systems

model
svm rgb average over full image
svm rgb batched rgb average
svm with k means normalized images
sfta texture classification
cnn classification

figure    diagram of the sfta algorithm

prediction accuracy
     
     
     
     
     

as expected  the three baseline classifiers had high testing
errors because of the naive methods that were used to featurize the images  in contrast  both the texture analysis and
the cnn implementations achieved high performance  the
specific results for each of these methods and further anal 

fics    final project

ysis is provided in the following sections 
     sfta results and discussion
using these extracted features from the sfta algorithm 
we ran regular soft max svm with no kernel  the rbf kernel  radial basis function   and a quadratic polynomial
kernel on the constructed feature vectors with different box
constraint parameter values  our sfta algorithm achieved
optimal performance at c     with the regular linear order features  this shows that the texture feature dataset
is best modeled by basic linear decision boundaries rather
than complex polynomial models 

figure    thresholded images for sky and road

figure    sfta accuracies for different svm kernels

     failure cases and potential issues
there were two main issues with the sfta texture classification algorithm  primarily  the system classified many
false positives for areas of the image that had relatively low
fractal dimension  specifically  if the image section had
very few edges and was relatively uniform in texture  e g 
sky   sfta misclassified the section as road  to see an illustration of this issue  consider the resulting thresholded
images for a certain section of sky and road  the resulting
thresholded image yields fractal dimensions that are relatively close  this can be seen in fig      to see a specific
example of this issue we took a single image and created
sliding windows across the image  each window was classified using the sfta algorithm and a heatmap was generated and overlayed on top of the image  see fig      indicating our predictions  while the algorithm successfully
classified road sections and obstacles  it also classified the
sky as road 
to combat this issue  we hope to encode more rgb features into the sfta vector to bias the classification to color

figure    heatmap of a single image classified using sfta

properties and not just texture  we also hope to incorporate
more training examples with just sky because many of our
negative examples were not solely sky 
conversely  the system classified many false negatives for
road image sections that had significant amounts of visual
noise  e g  large carpool signs  lanes  and cast shadows
from buildings   for an example  see   in most cases  however  we found that the density of road that was classified
correctly around our false negatives mitigated the misclassification  nonetheless  in order to improve our accuracy 
we hope to use contrast normalization techniques on our
examples to reduce the sharpness of road markers and cast
shadows  for positive examples with significantly high
color and texture variance  bridge shadows   we will need
to use more sophisticated models that gain context from

fics    final project

previous images 
     cnn results and discussion
using the resized    x    fixed input images  the cnn
was run on the dataset described in    the best model converged after    epochs with the learning rate defined earlier  the model achieved the best performance of any of
the systems we tested  with       accuracy  the cnn and
sfta systems had similar performance so we decided to
look at their respective results more closely  the corresponding sensitivities and specificities of each model are
summarized in the following table 
table    sensitivity and specificity of sfta and cnn
model sensitivity  tp  tp fn   specificity  tn tn fp 
sfta      
     
cnn
     
     

in general  the cnn had similar failure cases and issues as
those mentioned above for the sfta algorithm  however 
there were some important differences  the cnn actually
had a lower sensitivity or more false negatives  this difference could be due to many reasons but no pattern was observed when looking at the additional failures  the higher
accuracy of the cnn though  can be attributed to the much
higher specificity  this indicates that the cnn had less
false positives  this result seems to make sense because
the cnn takes into account color information  as opposed
to grayscaled images  and is not susceptible to the same
fractal dimension issues that sfta had 

   conclusions and future work
currently  we achieve high performance with both sfta
        and cnn          both models suffer from similar limitations  however  namely with images that have
shadows cast from bridges and roadside buildings  such
an example is given below 

classification in the third image  much of our future work
will involve using sequential images to increase our confidence in road detection at later segments in the video  from
an implementation perspective  we can quantify this confidence  derived from a fixed number of prior images  and
use this value as an additional feature in both sfta and
cnn  additionally  as mentioned earlier  we hope to use
color information to help improve the sfta model  we
also hope to optimize the cnn and perhaps use it for not
only supervised classification  but also unsupervised learning of new features 

   acknowledgements
we would like to thank our mentor tao wang for providing
us with the dataset and guidance throughout this project 

references
alvarez  j  and lopez  a  road detection based on illuminant invariance  ieee transactions on intelligent transportation systems       
alvarez  j   salzmann  m   and barnes  n  learning appearance models for road detection  in ieee intelligent
vehicles symposium  pp               
alvarez  jose m   gevers  theo  lecun  yann  and lopez 
antonio m  road scene segmentation from a single image  in fitzgibbon  andrew  lazebnik  svetlana  perona 
pietro  sato  yoichi  and schmid  cordelia  eds    european conference on computer vision  eccv       
volume      of lecture notes in computer science  pp 
        springer        isbn                   
costa  alceu ferraz  humpire mamani  gabriel  and
traina  agma juci machado 
an efficient algorithm for fractal analysis of textures         th sibgrapi conference on graphics  patterns and images 
              issn            doi  http   doi 
ieeecomputersociety org         sibgrapi         
hu  m   yang  w   ren  m   and yang  j  a vision based
road detection algorithm  in proceedings of the     
ieee conference on robotics  automation  and mechatronics  pp              

figure    bridge failure sequence

in this sequence of images  the bottom black section of the
third image is classified incorrectly  so the question is  can
we use the previous images in the sequence to inform our

lecun  y  and bengio  y  convolutional networks for images  speech  and time series  in arbib  m  a   ed    the
handbook of brain theory and neural networks  mit
press       
zhou  s   gong  j   xiong  g   chen  h   and iagnemma 
k  road detection using support vector machine based
on online learning and evaluation  in ieee intelligent
vehicles symposium  pp              

fi