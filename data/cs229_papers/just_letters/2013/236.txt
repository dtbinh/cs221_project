composer style attribution
kevin laube
kevlaube stanford edu

naroa zurutuza
naroas stanford edu
cs     final project
december         

abstract
our project was done in conjunction with
the stanford music departments josquin
research project  josquin was one of the
most famous composers from the early renaissance era  and his works were so popular that others put his name on anonymous
pieces  most likely in an attempt to boost
sales  as a result  over     works have been
attributed to him  although the true author of

many of the pieces is disputed  recent challenges have been made to the true authorship
of the pieces  mostly on grounds of stylistic
features or manuscript format 
our goal was to apply artificial intelligence and machine learning techniques to
quantify josquins style and make predictions
about the true author of the disputed set of
scores 

task definition

the problem of choosing a consistent set of
features that can distinguish between scores
of different composers seems much harder 
using too few features would lead to an inability to express the music in a manner that
would allow machine learning methods to distinguish between scores  while too many features could lead to overfitting and similar issues distinguishing between composers  ideally  the music would be converted to set of
features that causes scores by different composers to cluster  another issue is the feasibility of representing music in the manner
described  while it seems intuitively possible
to do it  and others have had reasonable degrees of success attempting similar projects 
to resolve the dispute we would need features
resulting in a classification accuracy in the
high    percentile range 

music classification can be a very challenging task  and is one most humans struggle to do with high accuracy  however  this
is in large part to a general inability of humans to track a la rge number of subtle  infrequent patterns that are stylistic marks of
most composers  ideally  a computer could
run an unsupervised learning algorithm to extract any recurring feature from a composers
pieces  but this style of pattern recognition is
currently beyond anything we have currently
been exposed to  this limited us to defining
a set of features that we thought would be
relevant across all the pieces in our training
dataset  which spanned   different composers 

our first goal was to decide on features to
use for a model  we suspected this would be
the most challenging aspect of the project  especially given the fact trained musicians have data description
not been able to decide on the real author of
music can be represented as an audio file
the josquin pieces  while many trained ears or in a numerical format  and the types of
are able to distinguish between two pieces  analysis that can be done differ based on
 

fiwhich type of file is used  we used a notearing 
ray program formatting  which takes   kern
     scores by josquin
files and extracts useful information into a  
    scores by johannes ockeghem
dimensional matrix format  this results in
a matrix with a few columns for each voice 
    pieces by marbrianus de orto
one containing note information and the oth     pieces by pierre de la rue
ers containing auxiliary information  each
     scores attributed to josquin but
new row indicates a movement by one voice
with disputed authorship
in the score  which results in a variable number of rows between songs  an example for
feature selection
one voice is shown below 
our features were chosen by a combination of researching what stylistic elements
vary the most between composers  and examining what seemed reasonable to extract
given the format we had access to 

number of notes in piece
this feature was simply the total number
of notes in the song 

sequences of notes
 this feature consisted of all sequences
of notes of a selected length in a song 
we tried several different sequence extraction methods  including
 all sequences of length k  for
k                 i e   k takes
on one value   our optimal result 
measured by maximizing classification acccuracy  from this selection was for k     
 all sequences of length k  for k in
a range of values from   to    however  this resulted in lower classification accuracy 

in the example above  the column with
numbers above     is the most significant 
this shows the exact pitch values for each
note being played  where negative values indicate the note was sustained to the next
timestep  the notearray format we chose
uses the base    numbering sytem  which is
an efficent method for representing diatonic
pitches 
the dataset  which is available online
at jrp ccarh org  contains     pieces written
during josquins period  divided into   main
categories 

in the end  we decided to use all sequences of
length    which empirically gave us the highest classification accuracy  we also excluded
any sequences containing a rest 

intervals between notes

this feature was calculated by examing
     works by known composers  includ  the difference between pitches of consecutive
 

finotes  we considered both individual intervals and sequences of intervals  but found empirically that we acheived higher classification
accuracy when considering individual intervals  thus  for each score we created a list of
the frequency of all the intervals it contained 

vector machine or neural network  which require fixed input lengths  the easiest solution
to this was to trim the weight vectors learned
by the one vs all classifier and take the most
heavily weighted features  the intuition being
that these features were the most indicative of
the score being by a specific composer  each
of these features could then be added to the
note length
for this feature we calculated the mean feature vectors used by the svm and neural
note duration in each score  as well as the network 
variance 
models

pitch frequency

we tried a few different models  and found
a high variation in classification accuracy between them  initially  we tried multi class
classification schemes for our models  in an
attempt to accurately predict from   composers  the intuition here was to maximize
prediction accuracy with these models and
find a set of features so that the data would
cluster in the higher dimensional feature vectors  which would only increase classification
accuracy when we reduced the classification
problem to a binary one  josquin or nonjosquin   we abandoned these models once
we had decided on our features  and moved on
to binary classification to see if we could apply any other optimizations towards our final
goal of classifying josquin pieces accurately 

the base    numbering system takes on
   values  which are multiplied by their octave to get the final value  thus  to get the
correct pitch we calculated the pitch value as
pitch   note       then we added a feature
for each pitch  and normalized by dividing the
number of occurences of each pitch in a song
by the number of notes in the song 

octave frequency
to calculate the octave of each note  we
calculated floor octave      then we added
a feature for all possible octaves and normalized by dividing the total number of occurrences of notes in each octave by the total
number of notes in the song 

average movement in piece

one vs all classifier

for this feature  we looked at whether the
pitch increased or decreaesd between all sequential pairs of notes  and then added features for mean and variance of the movement
of the notes for each song 

first we implemented a one vs all classifier  which had a weight vector for all features
from josquin scores and one for all features
from non josquin scores  for this model  we
used sequences of notes and intervals between
notes as our features  this classifier ended
final feature comments
of the features mentioned above  se  up being fairly accurate  which confirmed the
quences of notes and intervals between notes  belief that recurring sequences of notes are a
created variable length feature vectors  while major stylistic mark of a composer 
the rest created a constant length feature vec  naive bayes
tor  this was fine for a one vs all classifier 
going off the fact that sequences and inwhich associates a weight with each feature tervals seemed to be fairly accurate features 
after training  but was not ideal for a support we decided to try naive bayes  this was very
 

fistraightforward to implement  and we used
sequences and intervals as our only features 
naive bayes ended up being slightly more accurate then the one vs all classifier  and was
overall our most accurate 

mentation provided by pybrain  the neural
network proved very inconsistent  acheiving
anywhere from    to    percent accuracy on
a separate training set  the variation in accuracy most likely came from the random elements included in the testing set  which we
k means clustering
after naive bayes  we decided we had discuss further below 
reached a limitation on the accuracy that
could be achieved through our current fea  results
tures  and expanded our feature set to use testing methodology
we performed the majority of our trainthe rest of the features described above  this
ing
using the full set of scores with known
required trimming the weight vectors learned
from the one vs all classifier to include the composers  and removed        of the scores
most naive bayes  once we had the feature each time to use as a separate testing set 
vectors in place  we ran a k means cluster  we also made a testing set containing    
ing algorithm to see if the data was cluster  songs by josquin and     by the other three
ing  we initialized one cluster for each com  composers  the intuition behind this being a
poser  and ran the classifier  unfortunately  larger number of training samples from nonwe barely beat random chance  achieving a josquin composers would skew the prediction results away from josquin  additiontesting accuracy of     
ally  when selecting the testing set we split
support vector machine
it evenly between josquin and non josquin
our next choice in a model was a support
scores  given the small number of available
vector machine  and we used an implementascores  we experimented with    fold cross
tion provided by the sci py library  we had
validation to improve our results  unfortuhigh hopes for the svm  with the intuition
nately  this didnt affect our results signifithat if we chose the right features we could
cantly  our classification accuracy is reported
represent the scores in a manner that would
below  for the neural network  we reported
allow them to cluster in the feature space
the    fold cross validation results since there
and be linearly separable  while the svm
was a significant variation between consecuacheived     accuracy on the training set 
tive attempts 
we were unable to get it to perform well on
the testing  despite tweaking the regulariza  testing set accuracy
tion parameter and exploring different kernels
a fair amount  the high training accuracy
does suggest promise for the svm  however 
so given more time we would have liked to experiment with different kernel functions and
different training parameters 

neural network
our final attempt was a neural network 
as we see above  we were unable to
we used a feed forward network with back
propagation for training  we used an imple  do much better then     accuracy  how 

fiever  this significantly outperforms randomly rate features  given more time we would have
guessing  and suggests there was a reasonable spent all of it researching better features 
degree of significance in the features we chose 

conclusions

while we were unable to make predictions
on the testing set with enough accuracy to begin making predictions on the set of controversial songs  we were still able to glean a few
useful insights into the problems of selecting
features and models 
in terms of features  we found sequences
of notes to be one of the best predictors
of which composer a piece is written by 
this makes sense  given many composers are
known to repeat similar patterns or sequences
in a large portion of their scores  after sequences  we found intervals and sequences of
intervals between notes were also very indicative of style  pitch frequency was also a significant indicator  and after that our features
dropped off in relevance 

error analysis

the majority of our errors clearly resulted from not choosing meaningful features 
while we were unable to decide on features 
one addition we would have liked to make
would be more research into significant sequence and interval patterns in josquins
work  our approach was probably aimed a
bit too generally at choosing a more universal set of features that would distinguish between any of the composers  but we probably
could have honed in on more specific markers
of josquins style 
in terms of models used  we also think we
could have acheived better accuracy with the
neural network and svm  for the svm we
were worried about overfitting and changed
to a linear kernel in hopes of achieving better references
results  and reduced our regularization con we would like to thank the stanford
stant when we were still unable to attain reamusic department for making all the
sonable accuracy  given the black box nature
song files we used available  specifon svms and neural networks  we were unically  we would like to thank jesse
able to tune the parameters further to fit the
rodin and craig sapp for providing
data better 
both musical and technical advice 
neither one of us has much of a musi notearray manual page
cal background  so our approach may have
extras humdrum org man notearray 
missed several higher level features of music
that we could have looked at  in particular 
 music style attribution  kranenburg
counterpoint  which describes the movement
and backer      
of different voices in conjunction  and harmony between voices were two features that
 scipy for an implementation of an svm
are very apparent in the music when listening
and k means clustering algorithm
to it  but proved too difficult for us to successfully quantify and extract  given the level
 pybrain for providing a neural network
of difficulty of the problem of choosing accuimplementation

 

fi