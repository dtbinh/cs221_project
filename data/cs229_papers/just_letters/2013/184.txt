cs     final project  agarwal  v  and odgers  d   autumn     

predicting semantic features from ct
images of liver lesions using deep
learning
vibhu agarwal and david odgers
stanford university  school of medicine
department of biomedical informatics
vibhua stanford edu  djodgers stanford edu
abstract
driven by the technological advancements in imaging  the usage of medical imaging data is also increasing
in research as well as in the clinical setting and is resulting in an increased burden on radiologists who
wish to interpret and make use of this data  the wealth of information contained in this data is likely to
have novel uses in diagnosis and care  if we are able to structure the information  machine learning offers
some hope of coming up with an efficient way to deal with this rapidly increasing burden as well as for
structuring this information based on content  recently  there has been interest in discovering hierarchical
learning models that can simultaneously learn concepts at multiple levels from image data      such an
algorithm could potentially learn useful high level features from a data set of related  unlabelled images 
key challenges in scaling the technique to handle biomedical images involve addressing the issues of high
dimensionality and translation invariance 
we attempt to implement a convolutional deep learning network to predict semantic features from
images of liver lesions and gain insights into the conceptual and practical challenges involved in such an
approach  we also have an opportunity to compare our results with those obtained from an earlier study
that takes a classical machine learning approach to this problem 

 

introduction

l

esion types differ in how they are irrigated by blood vessels  as a consequence  they appear different during different phases of the circulatory cycle  using
contrast enhanced ct imaging a trained radiologist is able to differentiate between lesion
types that can give rise to different diagnoses
and outcomes  figure     traditionally  the practice of radiological observations is based on
annotating a region of interest  roi  using a
controlled vocabulary  radlex       these annotations  also referred to as semantic features  
while of value to clinicians are susceptible to
human variability and may not be useful features for carrying out similarity searches on a
database of ct images  researchers in com special

puter aided diagnostics have investigated the
approach of using computationally derived features of ct images  as predictors of these semantic annotations        such a technique can
improve computer aided diagnoses of lesions
and alleviate issues related to human variability  in a recent study by giminez et al      a
classical machine learning approach was taken
to train logistic regression models on a    dimensional feature vector of computationally
derived features  the output variable was a
pruned list of the standard semantic annotations for each ct image  since annotation of
image data requires the expertise of a trained
radiologist  obtaining large labeled data sets
for training machine learning algorithms can
be a challenge  in such a situation  unsupervised learning approaches can be an attractive

thank you to francisco gimenez for aiding in a follow on study to original work

 

fics     final project  agarwal  v  and odgers  d   autumn     
alternative to sourcing labeled training data 
figure    sample ct scan images with associated clinical diagnosis

in the training set  a feature selection technique to pick the most informative features is
required  since we wanted to compare our results with the results obtained in the earlier
study  we decided to adopt the same feature
selection method as used in the earlier study    
this was based on selecting features with the
highest binary entropy value  the binary entropy of a feature was calculated as 
h  x   

 

data

we were able to obtain     de identified ct
images showing liver lesions in the portal venous phase  these were provided by the rubin
lab  department of radiology  stanford university  for the purpose of this study project 
each image represents the axial slice showing
the largest area of the lesion  in images with
multiple lesions        additional lesions in addition to the main lesion were marked using
the e pad software  giving a total of     lesion
images  as it has been reported that training
on image patches leads to better feature extraction in bio medical images      we decided
to use randomly sampled image patches for
pre training the image filters  a total of     
image patches each    pixels by    pixels  were
sampled randomly from the available lesion
images  out of the total set of images    images were available with labels  where each
label consists of a list of    yes no values each
corresponding to a radlex descriptor 

   

pre processing

since all the feature labels are not equally informative  it is necessary to have a pruned list of
features so as to not have degenerate features
 

p log    p 

  

p  log    

p     

applying this feature selection criterion 
gave us a subset consiting of the top    features
 figure    for training our system  segmentation of lesion images was done on the basis of
the region of interest  roi  coordinates available in the image meta data  each segmented
image was scaled to a    pixels by    pixels
size using the  default  bicubic interpolation
method in matlabs imresize function  scaling
was done by the largest dimension so as to preserve the aspect ratio of the images  padding
was done using a reflection of the rows about
the center line for the dimension that scaled to
size less than     all pixel values were scaled
to lie between   and   

 

methods

our strategy was to implement a stack of two
auto encoders to learn features from the randomly sampled image patches  figure     these
pre trained filters are then arranged within a
neural network consisting of convolution and
dense layers and fine tuned using back propagation  since the optimization function in
deep neural networks could be non convex 
pre training the filters greedily allows a way
to trick the optimization objective by starting
from a point that is likely to be closer to the
optima  the selection of network configuration
parameters  number of hidden layers  depth
of the network  convolution and pooling parameters etc   seems to be a somewhat ad hoc
process with a scientific approach for selecting
these parameters  a subject of active research 

fics     final project  agarwal  v  and odgers  d   autumn     
we decided to experiment with a few different
network configurations to get a sense for the
implementation complexity and performance
trade offs associated with different configurations 

figure    convolutional deep learning network   configuration  

figure    the input to the auto encoder   consists of the
  x   randomly sampled patches

    configuration  
our second attempt was based on a smaller network  consisting of just a single hidden layer
doing pooling and convolution  as shown in
figure    we also adjusted the value of the pooling dimension to mean pool a larger number
of units 
figure    convoutional neural network   configuration
 

   

configuration  

our first configuration consisted of a network
with   hidden layers comprising of the pretrained filters and connected to a dense output
layer as shown in figure    the first layer in
the network is a convolution and mean pooling
layer  the second hidden layer is also sparsely
connected and forward feeds into the output
layer  the output layer is dense  all input units
connect into all nodes  and uses logistic regression to compute a probability value for each
of the semantic labels being associated with
the representation of the input image that is
produced by the preceding two layers  the network was fine tuned using    training images
at a time  in each iteration of a    fold cross
validation loop  the starter code provided in
the ufldl tutorials    was helpful in working
out the details of writing out the cost and gradient functions and using the lbfgs routine
to find the optimal parameters 

 

results

    configuration  
the classifier has very high test error  while it
has zero training error  this is on account of
the high sample complexity of the algorithm 
 

fics     final project  agarwal  v  and odgers  d   autumn     
from vapniks theorem  training and generalization errors will be close provided m  the
number of training data points  is o d   however  in configuration   the number of parameters is much larger            compared to the
number of data points        the over fitting
that we observed is as one would expect based
on learning theory 

   

configuration  

the results from a ten fold cross validation
on configuration   are as shown in figure   
for comparison  results from the earlier study
that used logistic regression on hand crafted
features are also indicated alongside 

 

discussion

the results from configuration   show that the
classifier was able to learn features after fine
tuning of the pre trained filters  the feature
wise aucs are similar to the results obtained
in the prior work  this was validated using a  
sample t test that gave a p value of       rejecting the null hypothesis   we believe that with a
sufficiently large unlabeled data set  it should
be possible to improve the learning and bring
down the generalization error  with sufficient
data to support a deep learning architecture 
features learnt with larger data sets may be as
good or better than hand crafted features 

figure    area under the roc curve values for convolutional neural network and logistic regression on hand crafter
features  the    semantic features are on the x axis 

pooling helps make the system resilient to
small linear translations at the expense of some
information  however  for features that are related to the image texture  mean pooling may
lead to some loss of information required to
separate the data  max pooling may be a bet 

ter choice for such features but may have an
adverse impact for features that are based on
image contrast  while our choice of the pooling dimension and technique was motivated
by considerations of simplicity of implementation and achieving a smaller sized network 

fics     final project  agarwal  v  and odgers  d   autumn     
the choice of a pooling technique is an important one for designing convolutional neural
networks that work with biomedical images
and requires further investigation as well as
ingenuity 

   

takeaways and future work

we could obtain a practical appreciation of how
convolution and pooling can provide a way
to represent relevant features in large images
with a relatively smaller number of parameters
and thus mitigate the risk of over fitting  we
could also understand the details of back propagating errors in a convolution neural network
which were not intuitive at a first glance 
we would like to improve our understanding of convolution neural network design and
develop at least heuristic guidelines for sizing

such neural nets  we also wish to experiment
with pooling techniques and observe how these
impact the quality of the extracted features 

 

acknowledgments

we would like to expressly thank dr daniel rubin  francisco giminez  assaf hoogi  sameep
tandon  brody huval and andrew mass for
helping us learn about a topic that was challenging and was new to us  and for helping
us stay motivated as we worked through the
challenges 
we would also like to thank the team of people maintaining the ufldl tutorials for providing an excellent resource to those interested
in learning deep learning and unsupervised
feature learning techniques 

references
    giminez  f   et al   automatic anotation of radiological observations in liver ct
images   amia annu symp proc                       
    jamieson  andrew r   karen drukker  and maryellen l  giger   breast image
feature learning with adaptive deconvolutional networks   spie medical imaging 
international society for optics and photonics       
    langlotz  curtis p   radlex  a new method for indexing online educational
materials   radiographics                         
    lee  honglak  et al   convolutional deep belief networks for scalable unsupervised
learning of hierarchical representations   proceedings of the   th annual international
conference on machine learning  acm       
    manay  s   et al   integral invariants for shape matching   ieee transactions on
pattern analysis and machine intelligence                         
    ng  andrew  jiquan ngiam  chuan y  foo  yifan mai  and caroline suen   ufldl
tutorial   ufldl at stanford university  n d  web     dec       
    zhao  cheng  et al   liver ct image retrieval based on gabor texture   engineering in
medicine and biology society        iembs az      th annual international conference
of the ieee                   

 

fi