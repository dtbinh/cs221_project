cs       final project

baena  chen

author gender identification of english novels
joseph baena and catherine chen
december         

 

introduction

machine learning algorithms have long been used in studies of authorship  particularly in
order to identify the author of a disputed work out of a group of possibilities  in this study 
our aim was to classify the authors of a large selection of   th century american and british
novels based on gender  since the goal was to classify the texts into two large groups  rather
than to perform a more granular authorship test  this problem closely resembles that of
spam email classification and other similar binary classification problems than the canonical
studies of literature authorship  in attempting to classify novels by gender overall  we assume
that there exists a significant difference between male and female writing in   th century
novels that is persistent despite variations in individual style and novel genre  we believe
that this question is interesting and relevant because differences between male writing and
female writing can reveal more fundamental facts about the role of these sexes within these
societies  the   th century western literary world is an interesting example due to the
societal pressures preventing women from publishing and the prevalence of female authors
writing under male pseudonyms  the same methods may be extended to investigate other
societies and time periods  in addition to other types of writing outside of novel 

 

data collection and methodology

we began with a set of text files of selected complete novels from the   th century english
corpus and relevant metadata including author gender  provided to us by the stanford university literary lab  the literary lab had used optical character recognition  ocr  to
scan the novels and save as plain text files  and as a result some of the words were not read
in properly  our first step of data processing was filtering out the files with ocr accuracy
below     
in order to perform our statistical analysis on the novels  we first wrote a java program
that calculated the frequencies of words within each text file and created a sparse matrix
in which each row represented a novel  each column represented a word  and each entry
represented the words frequency in the novel  in obtaining word frequencies  we ignored
words that appear fewer than three times in the novel  as done in glenn fungs      paper
the disputed federalist papers  svm feature selection via concave minimization  with
 

fics       final project

baena  chen

these frequencies  we were able to select words on which to focus our machine learning
algorithms 

lexicon of        english words
for our first attempt of feature selection  we found the frequencies of words appearing in a
comprehensive lexicon containing over        english words of at least   letters in length 
for the analysis  we created four training sets of size                 and       each of
which consisted of male authored works and female authored works evenly  we then ran the
training and testing sets through a naive bayes classifier with    laplace smoothing using
a multi variate bernoulli event model 
our attempt to classify the novels by gender based on the large lexicon was relatively unfruitful  the naive bayes classifier achieved an accuracy of less than     when trained
on the training set of     novels  accuracy did not scale with larger training sets  after
learning from our largest training set  the naive bayes algorithm mis classified over half of
the works  this result suggests that when considering the entire lexicon of over        english words  machine learning algorithms are unable to notice a notable difference between
male and female writing  we believe this is a reasonable conclusion since there is such a
large variance in style and diction among different authors  regardless of gender  further
investigation revealed that the algorithm was overfitting to the training set  since many of
the words appeared only in one or two of the training examples and not at all in the testing
set  for instance  the words that were most indicative of male writing  as defined by the
probability of the work being labeled male given that the word was used  were words that
appeared in a single work that was written by a man  the sparseness of useful features in
this model led us to believe that we needed to modify our lexicon  following the example of
prior work in authorship studies  to consist of a smaller set of more common words 

lexicon of    gender specific words
given the dearth of productive learning with our previous choice of features  we set out to
improve the accuracy of our models by limiting the feature space to include words that would
be used more frequently by multiple authors  we were inspired to create a small lexicon by
the research of bosch and smith  who used a set of    function words   in particular  widelyused pronouns  articles  and prepositions   as their feature space to classify the federalist
papers by their authors  since our study was focused on gender  we believed that using
explicitly gendered words might be more indicative than ordinary function words 
for our second analysis  we used a lexicon that contained only twelve words  he  his  him 
man  male  men  she  her  hers  woman  female  and women  we again classified the works
using the multi variate bernoulli naive bayes classifier  as well as the support vector machine  svm  with a linear kernel 

 

fics       final project

baena  chen

lexicon of    words chosen by forward search
hoping to improve the classification accuracy of our models  we developed another lexicon by
studying the     most common english words  as presented by the oxford english corpus 
these consisted largely of function words  along with select nouns  verbs  and adjectives 
we implemented forward search feature selection using    fold cross validation on the naive
bayes algorithm to determine the most predictive features out of the     most common
words in the english language 
with    fold cross validation  the data is equally divided into    sets  for each of the subsets
of features  we train on   of the sets and test on the remaining data set  we repeat this
process a total of    times and report the mean classification error  through this process  we
are able to determine which subset of words in the lexicon have the lowest empirical error and
provide the most information for the classification algorithm  using forward search feature
selection  we obtained the following set of    words  when  can  no  because  case  bad  her 
so  which  a  that  not  and he 

 

results and findings

using the lexicon consisting of    strongly gender specific nouns  pronouns  and adjectives 
we obtained the following results with the naive bayes classifier and the svm with a linear
kernel 
training set size naive bayes accuracy svm accuracy
   
     
     
     
     
   
     
     
    
    
     
     
as the above table illustrates  there is a slight increase in accuracy as the training set size
increases for both naive bayes and svm  but the marginal accuracy gain is not very significant  and in some cases  there is actually a drop in accuracy when the size of the training
set increases  we believe these to be idiosyncratic results due to some aspect of the specific
works chosen for the training sets  nevertheless  the accuracies obtained by the two learning algorithms were relatively consistent  the svm consistently outperformed naive bayes
which was not surprising given the relatively aggressive optimization in the svm process 
as an additional data point  we filtered our novel data to include only those written by
female authors under male pseudonyms  which we were able to do from the metadata that
provided us the name used for publication associated with each novel  our largest training
set yielded a       accuracy on this set of works  when we tested set with the same number
of works from a random combination of male and female authors  we obtained an accuracy of
      although the sample was relatively small at    novels  the fact that the naive bayes
classifier was able to detect    of the works authors as female suggests that these women 

 

fics       final project

baena  chen

who attempted to hide behind male identities  still wrote in a fashion that was somehow
inherently female 

figure    relative usage frequencies of the    gender specific words among male and female
authors of the   th century 
from the aggregate frequencies  we observe the relative frequencies of usage of the    gendered words  illustrated in figure    as the plot shows  male authors use he and his
much more often than female authors  and the reverse is true for words like she and her 
finally  using the lexicon of    words chosen by forward search feature selection  we obtained
results that represent a notable improvement from the earlier naive bayes results  more
closely resembling the svm accuracies  the classifier with only the    features selected
from forward search achieved the following accuracies 
training set size naive bayes accuracy
   
     
   
     
    
     
    
     

 

fics       final project

 

baena  chen

conclusions and further work

the promising results of our study suggest that machine learning can indeed be used to
determine the gender of a novels author  we found that the choice of words to analyze is a
very important factor in the accuracy of the naive bayes and svm classification algorithms 
smaller lexicons were much more effective in predicting in author gender than the large 
comprehensive lexicon  additionally  the choice of specific words included in the model had
a large impact on the classification accuracy  the results from our hand picked lexicon of
gender related words indicate that male authors are more likely to use male pronouns  such
as he and his  than female authors  in a similar fashion  female authors are more likely
to use female pronouns  such as she and her  than male authors  this conclusion is
further supported by the fact that the set of    words out of the     most common english
words found via the forward search feature selection algorithm include the words he and
her 
our research in automatic author gender classification through machine learning techniques
is a stepping stone for further research in the field  one avenue of research is further refining
the choice of words to analyze in the texts  we believe that experimenting with other methods
of feature selection  for instance  can further refine the accuracy of gender prediction in a
variety of classification algorithms  another direction for research is to investigate other
properties of writing style aside from word frequency  such as phrasing  sentence structure 
and the names of main characters  in the case of fiction novels   it would also be potentially
interesting to see whether training on a data set from the   th century has the same level
of performance when testing on more modern works of literature  or to conduct the same
study on literature in other languages with explicitly gendered nouns 

 

acknowledgements

we would like to thank professor andrew ng and the entire cs     course staff for their
guidance during the course  we are also very grateful to ryan heuser  amir tevel  and the
stanford literary lab for providing the   th century english novel corpus for our research 

 

references

bosch  robert a  and smith  jason a separating hyperplanes and the authorship of the
disputed federalist papers  the american mathematical monthly   vol       no     aug 
  sep          pp          
fung  glenn  the disputed federalist papers  svm feature selection via concave minimization     oct      

 

fi