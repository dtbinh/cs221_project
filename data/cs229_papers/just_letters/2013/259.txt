probabilistic record matching
robert raviv murciano goroff

   introduction
a common problem when utilizing multiple datasets from disparate sources is linking
observations about the same entity when unique identifiers are unavailable  this challenge
arises when amazon determines if two product listings are for the same item  when google
books merges library catalog listings  or when hospitals link health records using only patient
names and attributes  the process of creating such a bridge  known as record linkage  is
challenging for deterministic programs as typographical variations and data errors can make
even matching records appear dissimilar 
one task for which record linkage has been applied is finding citations to the same publication across multiple bibliometric databases      citations to articles and books often include
similar information  such as author names  publication titles  and publication year  but
variations in even these few fields are common  for example  names  such as steve  stephen 
and stephen  are often misspelled  while titles from foreign language publications can be
translated or transliterated with variations  even a numeric field such as the publication
year for a journal can be recorded differently when  for example  a winter issue of a quarterly publication spans both december and january  these challenges are representative of
issues that come up in many other databases  and would require intractably lengthy code
enumerating all possible variations to be solved by a deterministic matching program 
supervised classification methods from machine learning provide a means for implementing probabilistic record linkage that can both handle these challenges and scale for use on
large bibliographic databases  in this paper  i demonstrate and evaluate three classification
methods for uniquely matching articles indexed in the pubmed medline and web of science
 wos  databases  these two databases contain overlapping information  such as article titles 
journal names  and author listings  they also contain complimentary data  medline contains
research funding information not found in wos  while wos tallies forward citations unavailable in medline  thus  in order to analyze the costs and benefits of research work  one must
link the corresponding data between these two datasets  unfortunately  the databases do not
have a single identifier for linking articles present in medline and wos  logistic regression 
gaussian discriminant analysis  and support vector machine classifiers are evaluated for
their ability to predict matching versus non matching articles  because of stark differences
in the patterns of matched and non matching article records  logistic regression proved to
be the most efficacious  finally  the effects of missing data and heavily weighted training
datasets are discussed as implementation challenges for scaling this classifier 
   data
web of science  wos  and medline are large bibliographic databases of scientific articles 
maintained by the national library of medicine at the national institutes of health  medline
comprises over    million citations for journal articles and books related to the biomedical
 

fi 

robert raviv murciano goroff

field
mutual information score
title
      
volume
      
issue
      
begin page
      
end page
      
figure    mutual information scores for used features

sciences      web of science  an online database maintained by thomson reuters  contains
the articles of approximately        of the highest impact journals published across a wide
variety of scientific fields     
the two databases have overlapping coverage  but also subtle differences  while many
journals are indexed by both bibliometric products  medline is not a proper subset of wos 
thomson reuters focuses on capturing only high impact and primarily english language
journals  while medline includes a wide variety of international  transliterated  and translated
articles  furthermore  because some articles are indexed using optical character recognition
 ocr  technologies on the printed journals  even articles contained in both databases can
vary in the spelling of article titles and author names  additionally  approximately a third
of articles have missing data fields in one or both databases 
in order to develop a model for linking publication citations available in both databases 
i constructed a training dataset of examples of matched and unmatched articles  from
research papers published in the year       i extracted citations with complete article titles
and page numbers as well as journal volume  issue  and international standard serial number
 issn  information  in total  the subset included         medline articles and          
web of science articles  since the databases do not have a means of linking all matching
articles  i only used records from the extract with listed digital object identifier  doi 
numbers  a means of uniquely identifying documents posted online  doi numbers on scientific
publications are not very common  only        articles  about a quarter of the medline
articles without missing fields from this publication year  have corresponding articles in the
wos with the same doi number 
while these articles with corresponding doi numbers provide examples of matching articles  in order to train a classifier  i also required examples of non matching articles  by
cross joining matched article pairs appearing in the same journal  i created an additional
        pairs of articles with non matching doi numbers  these served as the training
examples of non matched article pairs 
   method
the overarching strategy for linking citations was to create similarity profiles of superficially similar articles from the respective databases  using the similarity profiles of known
matches and non matches based on the doi numbers  a classifier could then be trained to
recognize and predict whether a computed profile was the product of a matched pair of
references to the same article or a non matched pair of references to distinct articles  in
particular  using a parametric modeling technique  such as logistic regression  enables this
classifier to scale up for use on large bibliometric databases since relatively few parameters
need to be stored 

fiprobabilistic record matching

    

 

forward feature search test errors
false positives
false negatives

    
    
    

articles

   
   
   
   
   
   
   
title

volume

issue

begin page

end page

figure    forward search

after considerable data cleaning  all available features were extracted for the         pairs
of matched and non matched articles  because most fields useful for comparison  such as
article titles  issue numbers  and author names are textual data fields  a number of string
comparison methods were tested for assigning scores of text similarity  ultimately  using
the levenshtein distance metric for shorter string fields  jaccard comparison for longer text
fields  and soundex on titles provided discernible advantages during cross validation 
prior to running any classifiers  features were pruned using mutual information scoring as
well as forward searches  first  the correlation of each available feature with the label of
training examples was assessed  titles showed promise as strongly differentiating examples 
the soundex similarity of titles has a        correlation coefficient with the match labeling 
and indeed         of matched articles had a soundex score of   for their titles  while
only        of non matched articles achieved this high value  volume and issues are a less
robust field and contain many variations and typos  their levenshtein distances had lower
correlations with the labels and provided less discerning information  the distance between
the listings for the volume field had a coefficient of a mere         
using logistic regression  i also ran a forward feature search in order to assess the incremental value of each additional comparison metric being included in the model  most surprising
was the seemingly low value to utilizing measures comparing author names between articles 
the author names data are replete with differences in spelling  even after manipulating the
author name fields such that medlines utf   could be compared with woss ascii names
as well as using soundexs liberal distance metrics  both the low mutual information scores
and forward search cross validations indicated that this field would provide little support to
the classification system 
with the features selected  i ran and evaluated three supervised classification systems 
gaussian discriminant analysis  logistic regression  and support vector machines  svm  
   results
because most matched and non matched pairs have extremely contrasting features  i anticipated that gaussian discriminant analysis  gda  would provide the strongest results 

fi 

robert raviv murciano goroff
 
 
 
support vectors

   
   
   
   
   
   
   
   
   
 

 

   

   

   

   

   

   

   

   

   

 

figure    svm with polynomial kernel for title and end page features

            
            
figure    diagnostic table for logistic regress

after implementing a k fold cross validation procedure  however  gda proved to be the lowest performant  on its best iteration  gda correctly binned        of all test examples
and        of non matched articles  while a considerably high proportion of the data  the
need to store and provide gda with lots of training examples makes this less attractive than
logistic regression 
on the same data  logistic regression had significantly higher performance  through k fold
analysis  on each of ten iterations the classifier achieved a rate of correctly categorizing       
of the test examples  the classifier also provided even higher predictive value          for
identifying positive matches  given the speed  efficiency  and parametric nature of logistic
regression  this classifier seems apt for applying to citation record linkage problems 
since the features of matches and non matches need not be linearly separable  i also
implemented and tested svm using a quadratic kernel and smo optimization      because
both gda and logistic regression had already shown extraordinary accuracy and recall  and
because svm is considerably more computationally expensive  i had hoped for svm to
have significant advantages over the previous two methods  while the correct categorization
rates did peak at        with balanced performance on both matches and non matches  the
data is not separable and the karush kuhn tucker  kkt  conditions had to be violated
during the optimization stage  indeed  only by allowing    of the examples to violate
the kkt conditions would smo even converge within        iterations  with the speed
and efficaciousness of logistic regression  svm seemed useful for batch processing of small
datasets  but perhaps impractical for larger databases and more frequent matching 

fiprobabilistic record matching

 

   conclusion
supervised learning as a tool for record linkage problems on bibliometric datasets is highly
effective  by compiling a large number of similarity profiles for both known matched and nonmatched citations  even a basic classifier such as logistic regression can provide exceptional
accuracy in predicting if previously unseen articles refer to the same document 
when thinking about the applicability of logistic regression and svm for large scale usage
on more years of data or even larger datasets  a number of practical challenges must be
dealt with  first  the training examples are heavily biased  because doi numbers have
been relatively rarely used in the past  the cross join technique to construct non matching
examples will always heavily weight the training set with profiles of mismatched citation
pairs  this bias can cause problems in interpreting the accuracy of a classifier  since even a
classifier that defaulted to labeling all test examples as non matches could still have unusually
high performance  thus  while the optimization techniques of these classifiers still provide
excellent accuracy for both matched and non matched test pairs  their performance must be
measured against the baseline distribution of examples in the training and test sets 
second  when applying these mechanisms to most citation databases  thoughtful consideration will have to be given for how to deal with missing data fields  my tests indicated
that performance would not degrade significantly if missing fields were interpolated with the
average of non missing fields 
finally  after examining the learning curves of these classifiers for increasingly large training
set sizes  i found that they potentially suffer from bias  since despite tens of thousands of
training examples  the test and training errors remained somewhat apart  an obvious fix
would be to provide more or better features for the classifiers  this would likely require
further manipulation and cleaning of the original data fields  for example  comments and
replies to articles are often published alongside the original scholarly research  thus  in the
database  these comments appear with the same title  journal information  and even page
number as the records of the original article  thus  two records in the database may appear
almost identical yet have different doi numbers  perhaps these more subtle and problematic
cases could be differentiated by isolating a discriminating feature and giving it more weight
in the classification model 
despite these minor concerns  supervised machine learning remains an efficient  highly
accurate  and scalable means of performing record linkage across citation databases 
references
    rong en fan  kai wei chang  cho jui hsieh  xiang rui wang  and chih jen lin  liblinear  a library for large linear classification  journal of machine learning research 
                 
    hanna pasula  bhaskara marthi  brian milch  stuart j  russell  and ilya shpitser  identity uncertainty and citation matching  in nips  pages                
    thomson reuters 
web of science fact sheet 
     
url
http   thomsonreuters com products ip science        web of science fs en pdf 
    u s  national library of medicine 
medline fact sheet 
http   www nlm nih gov pubs factsheets medline html 

     

url

fi