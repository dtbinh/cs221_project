cs    course project

machine learning techniques for
quantifying characteristic geological
feature difference
xiaojin tan  wenyue sun
stanford university
xtan  stanford com wenyue stanford com
abstract
this paper presents a novel methodology of quantifying the model mismatch part in the bayesian framework for reservoir model inversion  during model inversion  the updated models are required to obey
the prior characteristic geological information  which poses the issue of violation quantification  recent approaches for this penalty normally require covariance matrix of model parameters  which are often
impractical for three reasons     they require gaussian assumption and    the computing of the inverse
of the covariance is very time consuming or the approximation of the covariance skews the estimation
of the uncertainty     quite large amounts of models are required to achieve a stationary covariance estimation  in this paper  we propose an alternative approach that while circumventing the computing or
approximation of the covariance  can provide a reliable estimation on the model misfit penalty as well as
relax gaussian assumption  in order to render the model misfit quantitative  it is argued that this paper
relies on a statistical learning for two totally different sets of models  prior models and reference models 
after defining within model distance and between model distance  misfit between any two models can be
trained through machine learning technique  svm algorithm is used in this paper and turns out to be
very effective in quantifying the similarities with respect to both the number of training models required
and relaxation of the gaussian assumption of the model 

i  introduction
il companies often need to make predictions on oil gas productions for further marketing decision making  and
this will involve three steps  reservoir characterization  modeling  flow simulation  and future model updating  for the modeling part 
normally we are able to generate lots of reservoir models that follow the prior information
 usually represented through some characteristic geological features  gotten from the characterization stage  but during the model updating step  however  there is no guarantee
that the updated posterior model will follow
the prior information  thus one of the most
critical problems for model updating is that
we need a reliable method to quantify the violation of updated models to the prior characteristic geological feature 
in a general sense  model updating is a

o

typical inverse problem  which is ill posed if
only historical production data  which is the
output from the simulation over our generated reservoir models  is considered  additional information  usually prior knowledge about
the reservoir  is required to constraint the solutions  tikhonov regularization is one popular
method in which the problem is reformulated not only to match the production data  but
also our prior knowledge about the reservoir
 which well refer as model mismatch part later on  
there have been some works from literatures in approaching this problem on the
model mismatch part  most of them  however  normally require gaussian assumption on
the model  which is quite impractical for most
of the cases  at the same time  they require inverse of the covariance matrix  which is used
to describe the two point statistical behavior
of the reservoir  for real cases often involving
 

fics    course project

models of over millions of grid blocks  which
can be considered as the number of freedoms  
the requirement for inverse of the covariance
is usually infeasible given nowadays computational power 
in order to circumvent the computation of
the inverse of covariance matrix and  most importantly  to relax the requirement for gaussian assumption  in this paper  a machine
learning based methodology is proposed that
allows quantifying model mismatch part regardless of the nature of the reservoir models  namely  whether they are gaussian or nongaussian  discrete or continuous  have small or large grid dimensions  our method starts with a definition of prior and reference
models  the prior models are those we generated during the reservoir modeling part to
represent our prior understanding of the reservoir  which is the one that we want to match
with  the reference models are those we generated purposely with different geological features from the prior  then a machine learning
technique  svm is used in this paper to give
an estimation about the distance between updated models and prior models  and this distance turns out to be able to act as the model
mismatch term naturally 
while one can debate the particular subjective choices about the reference models are
made in the presented methodology  the variety of examples illustrate that the results obtained from this methodology are consistent
with expectations  it should be understood
that we are not seeking the best reference models that should be created  but an reference
model thats able to match our demands here 
which is to estimate the relative model mismatch between different updated models and
the prior models  however  there is no doubt
that better reference models may improve the
overall reliability of this method  thus future
work may be interested in this part 

ii  methods
support vector machine learning algorithm is
one of the best  off the shelf  supervised learn 

ing algorithm  in this paper  svm is used
to quantifying the violation level of a specific
model to prior models  fig   shows a reservoir model  each block contains a value indicating the permeability at that location  that
follows the prior information we specified  for
which a    degree long correlation trend is
observed  fig   shows one reference model 
which has the same histogram with the prior
model but a different long correlation trend  
in this paper  well use svms to quantifying
the difference between a set up updated models and the prior model  for details about how
svm algorithms works  we refer to         here
we label all prior models as    and reference
models     the training data is a single column composed of permeability at all the blocks 
this can be easily extended to other types of
data  like porosity or z transmissibility  since
we can generate multiple prior and reference
models easily using research software gslib
     training data sets can be easily achieved 
we use the same amount of training data for
prior models and reference models respectively  and for prediction stage  we used three testing models which we know to be clearly different from the prior models  for each test model  we generate multiple realizations that share
the same geological feature  then these testing models are used to test and the reliability
of svm algorithm for quantifying geological
feature difference  in this report  we only use
linear kernel instead of higher order kernels 
the reason is that even linear kernel turns out
to be quite effective  and using higher order kernel doesnt improve the performance significantly  however  for larger and more complex
models  higher order kernels might be interested  also  kkt violation is allowed to alleviate
the influence of casual outliers 

fics    course project

 
 
   
 
 
 

   

 

 

  

   

  

 

  

   

  

 

  

   
 

 

 

 

  

  

  

  

and    where   means its classified as closer
to prior model  and   closer to reference model  the function margin for each model here is
simply treated as the average of all of the realizations  which intrinsically indicates how confident we are in making that prediction  and
this margin can act as a measurement of the
model mismatch term 

  

figure    a prior reservoir model

 

 

 
 
 

 

 
   

 

 

 
 

 

   

 

 

  

   

  

  
 

  
  

 

  
 

  
  

 

  

   

  

 

 

 

 

 

 

  

  

  

  

 

 

 

  

  

  

  

  

figure    test model  

  

figure    a reference reservoir model

iii  results

 

   

 

 
   

 

 
 
   

fig      gives three test cases we generated 
from which we can see that test model   is
closer to prior model  whereas test model  
and   are closer to the reference model  table
  shows the results of classifying and quantifying model difference using svms  the training data contains    prior and reference models respectively  the testing data set contains     realizations for each model respectively 
since we know that these     realizations follows the same geological feature  thus taking
the mean value of them is reasonable  the prediction results are the average of those for each
type of model as shown in table    model  
and   in the table are simply the prior and reference models we used to train the algorithm 
and the reason to test them is to check the selfconsistency of this algorithm  which partially
used the idea of  cross validation  
the prediction data in table   is between  

  

 

  

   

  

 

  

   
 

  

   
 

 

 

 

  

  

  

  

  

figure    test model  
 
 

   

 

   

 

   

 

   

  

   

  

   

  

   

  

   
   

  
 

 

 

 

  

  

  

  

  

 

figure    test model  

 

fics    course project

table    prediction using svm

prediction

margin

 
 
 
 
 

    
    
    
    
    

     
    
     
    
    

    

margin

model

mixed model
   

   

    

   

the last important issue left is to test
whether the functional margin can provide
a reliable  stable  estimation about the mismatch term  given the observation that model
  is closer to model   compared with model
   we can use the following algorithm to generate a set of mixed gaussian model as testing
models 
   

 i  

mmixed  

   

m      i   m 
      i  

where  i          i 

the superscript for m    m  means the realization we choose from model   and model
    is a set of coefficients ranges from   to
     which stands for a linear combination coefficient for mixing model   into model    as
expected  the larger  is  the more dissimilar
the mixed model will be with the prior models  thus the margin value should be able to
change smoothly with respect to  within a
certain range  which is required for stable estimation 

   

 

 

 
   
 
 
  
   
  
 
  
   
  
 

  
 

 

 

 

  

  

  

  

  

figure    mixed model at       

 

   

   

   

   

   


figure    margin value for mixed models

figure   shows a mixed gaussian model
when         from which we can clearly see
that not only a obvious    degree trend observed  but also a     degree trend observed
at the upper left corner  which is the effect carried by mixing model    figure   gives the
margin value as a function of  

iv  discussion

i                 

 

    
 

in table    the first two is accomplished by performing cross validation  using selected prior
models and references models as test set  the
prediction for them are      and      respectively  which means that for prior models as
test model  the probability of getting correct prediction is about      and for reference
model as test model  the probability is about
     both of them gives very good predictions  also  we can view this from the averaged
functional margin value  support vectors have
margin value to be   all the time  for prior
models regarded as test models  we have averaged margin value about    absolute value  
which is considerably larger that    this judgement is quite obvious if we assume that the
feature vector follows gaussian distribution  
model    which is generally closer to the prior
models as observed from figure   and figure
   is predicted to be prior model     the time 
and for those predicted to be    the function
margin value is about      which  as illustrated  shows how closer model   is to model   
also  the algorithm gives bigger margin val 

fics    course project

ue of model   compare with model    which
is reasonable in the sense that prior models
are always the closest to themselves  similarly  model   is predicted to be reference model
    of the times  which again is as expected
once comparing figure   with figure   
the most interesting results are for test
model    which is clearly a non gaussian model  comparing figure   with figure   and   
we find that model   is definitely closer to reference models since they both have a     degree oriented correlation feature  but on the
other side  unlike model   and model    its
not largely closer to reference model than it
is to the prior model  the reason is that if we
take a walk at a    degree direction  we will also see a long correlation of the color  here color represents permeability of that block   thus
what we should expect is that svm may have
low prediction error  but also with a relatively
lower margin value  which is exactly what we
observed in table   for the value corresponding to model    svm predicts correctly     of
the time  but on the other size  the margin value is only about       which is relatively lower
than that for model   
from figure    we observed that the margin
value is a smooth function of the  value  and
the absolute value of the margin tends to decrease as  increases  this indicates that as we
add more     degree trend features  the mixed
model violated more with respect to the prior    degree trend feature  which is as expected  thus the margin value predicted can potentially act as a measurement for the model
mismatch term 

ological feature difference  which gives relatively good results  the following conclusions
can be made from this report 
   even though the reservoir model can
have large dimension  not too many
training models may be required for
svm algorithms  in our particular case 
the model dimensions are over      but
   number of training sets can already
give great results based on the high prediction accuracy of model   and model  
in table   
   for models of different geological features compared with the prior models
and reference models  svm method can
also give quite good prediction results 
   function margin varies smoothly with
changes of test models  and captures
the change of mismatch correctly  which
proves its potential to act as an effective
tool for quantifying the model mismatch
term in the inverse modeling formulation 

references
   

deutsch  c  v  and journel  a  g         
gslib  geostatistical software library and
users guide   nd edition  new york  oxford university press

   

vapnik  v         the nature of statistical
learning theory  springer verlag  new york

   

vapnik  v         statistical learning theory  john wiley  new york

v  conclusions
in the report  we initiated the usage of machine learning technique in quantifying the ge 

 

fi