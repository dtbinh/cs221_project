collaborative filter pre processing for improved corrupted image classification
lucas finn
abstract
this paper investigates the effects of collaborative filtering on the classification of corrupted digit images  several
experiments were carried out using the mnist digit dataset by applying a corruption model to the original images 
two reconstruction algorithms  and an svm classifier to measure classification accuracy at each stage of processing 
the results demonstrate that collaborative filtering  when properly fit to the data  achieves higher accuracy than not
filtering or using a gaussian filter  and retains high accuracy even up to     image corruption  the experiments
also show that classification performance drops precipitously when the collaborative filter is allowed to over fit the
training images during reconstruction 
introduction
collaborative filtering is widely known as the winning algorithm of the netflix challenge for its ability to predict
user preferences given highly sparse data      more generally  it can be applied to matrix completion problems     
this paper investigates collaborative filtering as it relates to digit image classification on corrupted images using a
support vector machine  with corruption simulating the sparse matrix completion problem 
original
corrupt corrupted
mnist digit
digit images
images

svm
classifier

svm
classifier

filter

filtered
digit images

svm
classifier

figure    experimental setup for assessing svm classifier accuracy on corrupted and reconstructed images 

figure   shows the experimental setup  the mnist digit image dataset is taken as input  and contains       
images of digits  each     pixels      each digit has been centered and normalized  but the dataset contains multiple
handwriting styles  digits can be written multiple ways  e g    with or without a loop   example digits are shown
in figure    left   using the raw images  an svm was trained and tested  and the confusion matrix was computed as
well as the mean digit classification accuracy  this provided a baseline accuracy for comparing other classifiers 
a corruption algorithm was then applied to the mnist images resulting in degraded image quality  figure   right  
the svm classifier was run to compare the mean classification accuracy of digits  the final processing step applied
two filtering algorithms to reconstruct the missing pixels  with the goal of improving svm classifier accuracy 
from these experiments  the effect of corruption and reconstruction was measured having isolated the individual
algorithms 

figure     left  example digits from the mnist dataset   right  the same digits with     of the pixels removed 
simulating sparse data  note that some digits remain human recognizable  but others do not 

methodology
first  it is interesting to note that while the mnist dataset appears to have a large number of features  one feature
per pixel          total   these features are largely redundant  for instance     of the pixels are always set to zero 
as can be seen in the heat map of unique pixel values  figure   left   moreover  pca indicates that    out of    
features in the eigenbasis capture     of the variation in the dataset  figure   right   therefore  it is reasonable to

page  

fiexpect that a lower dimensional image representation would retain a classification accuracy similar to the original
high dimensional representation 

   
y  pixels 

   
   
   
  

cumulative variance

unique pixel values

 
   
   
   

          
dimensions
figure     left  a heat map of the number of unique values in the mnist dataset indicates that    of pixels are not used 
 right  pca shows that a low dimensional feature space captures much of the normalized variation in the dataset 

x  pixels 

 

several corrupted datasets were created from the original mnist images by setting a fraction of the pixels to zero 
simulating a sparse representation  the corrupted pixels were randomly chosen in each image  not uniformly over
the entire dataset  figure    right  shows the result of corrupting     of the pixels in the left image set  note that
some digits are not human recognizable confidently  the corruption fractions tested were                              
and       the randomization was expected to make svm classification more challenging because each pixel could
indicate the correct value  or a zeroed value containing no discriminating information 
three filtering algorithms were then applied to the corrupted mnist dataset to reconstruct the original images 
collaborative filtering  gaussian filtering  and no filtering  as a reconstruction algorithm  gaussian filtering was
chosen to provide a comparison to collaborative filtering      while collaborative filtering exploits the entire
available dataset  gaussian filtering applies to one image at a time  a sigma value of     was chosen by visual
inspection  and simply serves to smooth the information contained in uncorrupted pixels to neighboring pixels 
given a data matrix d with dimensions
  where   the number of samples  images   and is the number of
features  collaborative filtering factors the data matrix
     the factors and have dimensions
and
  respectively  the resulting data representation is sparse if
  with m       and n      the
reduction in dataset sizes created in this paper are k    yields        k    yields        and k    yields       

figure     left  collaborative filtering with k    with no pixel corruption   right  collaborative filtering with k    and
    pixel corruption  note that several digits become much more human recognizable  compare with figure    

the implementation of collaborative filtering used was alternating least squares  als   and minimizes the
normalized pixel root mean square error  rmse         this performs linear regression alternating between rows
and columns using the uncorrupted information  the results of collaborative filtering on the images in figure   can
be seen in figure   with different corruption levels  the parameters for collaborative filtering were chosen by
testing several combinations and examining the training rmse over pixels 
the collaborative filtering algorithm requires two parameters  the number of features in the sparse representation  k 
and the regularization parameter  l      figure   measures the pixel rmse between the training dataset and the
low dimensional reconstruction when no image corruption is applied  low rmse can be achieved by choosing a
larger k  at the expense of increased model complexity and the danger of over fitting  the regularization parameter
did not significantly affect the rmse  and so initially k    and l      were used  at high pixel corruption values 
k    and k    were also used  it turns out that tuning collaborative filtering parameters on uncorrupted images  and
then applying it to corrupted images resulted in an over fit  this was remedied by experimenting with lower k 
page  

fifigure    collaborative filtering normalized rmse as a function of number of features  k  and regularization parameter
 l  on the no pixel corruption dataset  note that the training rmse decreases with larger k and increases slightly with l 

training and testing error were measured on the output of collaborative filtering by computing the rmse between
the original data and the reconstructed pixels      the training error is the normalized rmse between the original
data and the uncorrupted pixels  the testing error is the rmse between the original data and the corrupted pixels 
the als algorithm terminates when the training rmse falls below a small tolerance  execution took anywhere
from five minutes to twelve hours using a     ghz cpu with matlab 
the corrupted images were collaboratively filtered in two ways      the entire dataset simultaneously  and     the
svm training and svm testing images separately  in the former case  collaborative filtering built a single
representation  in the latter  one representation was created for the svm training data  another for the svm testing
data  between these two datasets  the effect of joint versus separate collaborative filtering can be measured  note
that collaborative filtering is unsupervised  so label information is not leaked from testing data into model formation 
table    collaborative filtering training and testing tables  left and right tables  of pixel normalized rmse versus the
pixel corruption fraction  note the decreasing difference between training and testing errors as k decreases 

   
   
   

cf  
   
   
   

cf  
    
    
   

cf  
    
    
    

cf  
    
    
    

cf  
    
    
    

cf  
    
    
    

table   shows the collaborative filtering training and testing errors for high pixel corruption for k        and    on
the entire dataset simultaneously  note that these represent image reconstruction error  not classification error using
the svm  as the fraction of pixel corruption increases  k    appears to over fit the data       training error and
      testing error   while the over fit is somewhat less for k    and k    
the r language kernlab implementation of a multi class svm with regularization  ksvm  was used to classify each
image dataset      this library builds a multi class svm using the one against one algorithm  the ksvm radial
basis kernel was chosen due to its historically high performance on the mnist dataset      in addition  ksvm
automatically estimates the hyperparameter of the radial basis kernel using the sigest feature      this leaves the
remaining hyperparameter c  the cost of violating constraints  the default value c   was chosen  though future
work could estimate this parameter empirically 
training and testing these svms was computationally and memory intensive  requiring two to twelve hours of cpu
time several gigabytes of ram to complete  these experiments required several hundred total cpu hours and were
carried out on a machine with    cpus with a clock speed of     ghz and    gb of memory over several days 
results
table   shows the mean classification error for each svm in a series of experiments with image corruption and
reconstruction  each row denotes the percent of pixels corrupted per image  the left table denotes the svm training
error  and the right table denotes svm testing error  the four columns in each table are     no filtering     
gaussian filtering      collaborative filtering the entire dataset  and     collaborative filtering the svm training
images separately from the svm testing images 
page  

fitable    svm training and testing error tables  left and right tables  for  no filtering  gaussian filtering  joint and
separate collaborative filtering versus pixel corruption fraction 

  
   
   
   

nf
   
   
   
   

gf
   
   
   
   

cfj
   
   
   
   

cfs
   
   
   
   

nf
   
   
   
   

gf
   
   
   
   

cfj
   
   
   
   

cfs
   
   
   
   

with zero percent of the pixels corrupted  the off the shelf svm classifier achieved      error  which is slightly
higher than state of the art      however  because the dataset was divided       training and testing images instead
of the standard        the comparison is not strictly speaking appropriate  for collaborative filtering  there was only
a minor difference in accuracy when the training and testing images were jointly filtered versus separately filtered 
gaussian filtering performed worse than collaborative filtering  especially as corruption levels approached     
table   shows the mean classification error for each svm at high levels of image corruption  the left and right
tables are training and testing errors as in table    the columns are     no filtering      gaussian filtering     
collaborative filtering with k         k    and     k    
table    svm training and testing error tables  left and right tables  at high pixel corruption values demonstrates that
the lower order k    model outperforms several others  including higher order models 

   
   
   

nf
   
    
    

gf
   
   
    

cf  
   
   
    

cf  
   
   
    

cf  
    
    
    

nf
    
    
    

gf
    
    
    

cf  
   
    
    

cf  
   
   
    

cf  
   
    
    

up to     corruption  the k    experiment outperformed all others  but the error rate rose sharply at     and    
corruption  in fact  k    performed worse than no filtering at all  this is likely due to overfitting  the collaborative
filter trains on a specific pixel corruption pattern and not the underlying digit  as before  gaussian filtering
continued to perform better than no filtering  at high levels of corruption  it seems that a lower order model  k   
and k     outperformed the other filtering methods  in fact  at     corruption  it is reasonable to conclude that the
correct model complexity is approximately near k    and k    
figure   shows the confusion matrices for two experiments with high image corruption and collaborative filtering
applied  the quantity
is shown in decibels to accentuate misclassifications  the off diagonal yelloworange values   denoting the probability that an image was declared to be digit
given that the image actually
represents digit   as expected  the digits      and   were confused rather often  as were      and        from
table    the mean svm classification error for these experiments is      and       

figure    example confusion matrices in db   left  collaborative filtering with a high order model k    at     image
corruption  and  right  a low order model k    at     corruption confuses similar looking digits 

page  

ficonclusions
there are several interesting results observable from these experiments 
    the baseline svm classifier achieved high mean digit classification accuracy  but was slightly worse than stateof the art  this is likely due to training the svm with a       data split  to keep more images for collaborative
filtering instead of the standard       split  future work might compute the accuracy on the       split 
    when properly tuned  collaborative filtering provides both a low order reconstruction of the corrupted data set
and improves overall svm classification accuracy across a wide range of pixel corruption fractions 
    at even modest amounts of corruption  gaussian filtering improved mean svm classification accuracy     
compared to not filtering  likely because it smoothes out the irregular information contained in the randomly
corrupted pixels  the smoothed data more naturally admits an svm separating hyperplane 
    at corruption values      collaborative filtering with the relatively high order model k    achieves higher
accuracy than gaussian filtering or not filtering at all  moreover  it is highly interesting that collaborative
filtering the training testing images separately or jointly did not affect the svm classification accuracy  which
indicates that the training image dataset size is sufficiently large for the model 
    at corruption values      collaborative filtering indicates that the high order model k    over trains on the
training dataset  and is reflected in low training error and high testing error in both collaborative filtering and
the svm classifier  this can be remedied by choosing a low order k    or k    model  and results in high
accuracy even at pixel corruption fractions up to      future work might include     or     corruption 
    as the fraction of corrupted pixels increases  the size of the collaborative filtering training dataset decreases 
and therefore it makes sense to simultaneously lower the collaborative filtering model complexity  in these
experiments  this was accomplished by lowering k  but future work could investigate retaining a high k while
simultaneously increasing the regularization parameter l  additionally  the svm hyperparameter c  the cost of
violating constraints  may be tunable to increase svm accuracy 
    as the fraction of corrupted pixels increases  whether or not collaborative filtering is trained on the joint svm
training testing images begins to affect the svm classification accuracy  the joint collaborative filtering
achieves a higher svm accuracy than separately collaborative filtering the data  likely because the available
dataset of uncorrupted pixels is relatively small 
references
    carlos guestrin        collaborative filtering matrix completion alternating least squares  retrieved from
http   courses cs washington edu courses cse   c    wi slides matrix factorization sgd nmf pdf 
    xiaoyuan su and taghi m  khoshgoftaar        a survey of collaborative filtering techniques  adv  in artif 
intell        article    january           pages  doi                     http   dx doi org                    
    jianchao yang  jianping wang  and thomas huang        learning the sparse representation for classification 
multimedia and expo  icme   doi          icme              
    alexandros karatzoglou  alex smola  kurt hornik and achim zeileis        an s  package for kernel
methods in r  journal of statistical software           
    michael curtis et  al        a collaborative filtering model  statistical properties of alternating least
squares  umbc review  journal of undergraduate research              
    ming wu and zhen zhang        handwritten digit classification using the mnist data set  retrieved from
http   www stt msu edu  zhangz   index files files cse   report pdf
    thomas funkhouser        image sampling and reconstruction  retrieved from
http   www cs princeton edu courses archive fall     cs    lectures sampling sampling pdf
    yann lecun  corinna cortes  christopher burges        the mnist database of handwritten digits  retrieved
from http   yann lecun com exdb mnist
page  

fi