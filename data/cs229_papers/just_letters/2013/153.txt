composer style attribution
jacqueline speiser  vishesh gupta
introduction
josquin des prez             is one of the most famous composers of the renaissance  despite his fame  there
exists a significant debate over which of his works are actually his and which have been misattributed to him  there
are     pieces attributed to josquin between      and the early   th century  a period extending far beyond his
death  unfortunately  there are very few surviving manuscripts from late   th century france  so most pieces do
not have an exact historical record of when and where they were composed  this difficulty is compounded by the
fact that josquin reached the peak of his fame later in his life and after his death  at the same time that music
was beginning to be printed more widely  as such  we cannot determine which works are his by the time of their
publishing 
the josquin research project in the stanford music department has a large collection of music from the early
renaissance  including both verified and unverified works by josquin and his contemporaries  there are    works
identified through manuscript sources that are nearly guaranteed to belong to josquin  and the remaining works
range from known misattributions to likely to be by josquin 
the goal of this project is to analyze the music of josquin and his contemporaries  johannes ockeghem and
pierre de la rue  to find a model that can classify the unknown works as josquins or not  in doing so  we hope to
shed light on some of josquins controversial pieces and provide renaissance music scholars with paths for further
investigation 

data
our data set was provided by the josquin research project  and can be found online 
of the verified works in our data set      were by josquin     were by ockeghem      were by la rue  there were
    unverified works by josquin  of these  professor rodin identified    examples as being most probably written
by josquin  and    as being most probably not written by josquin  these    examples became our test bench  by
which we evaluated the performance of different models and sets of features 
from here  we will go through each step of our processing pipeline and explain why we made the decisions we
did  then discuss the results of the classification problem 

initial thoughts
before beginning to talk about the various feature extraction methods  there are many aspects of the project that
deserve mention as they separate it from seemingly similar classification problems like genre classification  composer
attribution in other periods of classical music  modern popular music  or across genres 
first  harmony  and specifically chords and their usages is a common metric used in later periods of music 
however  in the late   th century  when josquins music was popular  functional harmony as it is interpreted and
used now had not been invented yet  composers rarely thought vertically about the music they were writing  and
felt that each voice had to have enough variance and color to it that it would be pleasing to listen to by itself  this
though process is quite different from modern music  where especially the bass holds one note as a pedal for multiple
measures  or employs ostinato for rhythmic effect 
second  renaissance music was extremely strict in its control over the use of intervals  the rules of counterpoint
severely limited the range of a composers artistic freedom  as compared to the almost limitless possibilities of
todays music   its fascinating that composers managed to create such beautiful music even in within the structure
of counterpoint  but it makes telling apart two composers of the time period very difficult  even for a human being 
finally  music is an incredibly dense informational system  a lot happens within one bar of music  and the
simplest of analyses has hundreds  or even thousands of features  compounded to this fact is that composers write
for different modes  each with its own characteristics  we only have a few hundred examples  so the danger of
over fitting is quite acute in this classification problem  the works themselves also tend to be shorter  unlike the
symphonies and operas of later times  leading to more variance in the data  and very  very sparse features 
 

fifeatures
after some debate  we decided to pose the problem as two independent problems  as we felt each composer was
distinct enough that grouping them together would only dilute any hypothesis our learning algorithms would make 
so  we had two classification problems  josquin vs ockeghem and josquin vs pierre la rue 
with the knowledge that we had to keep our feature vectors relatively small  we decided to limit the extraction
to four categories  frequencies of the individual notes  frequencies of pairwise interval combinations between each of
the voices  markov transition matrices for the rhythms of the pieces  and markov transition matrices of the pitches
in each piece  effectively  these can be though of as   order and   order markov chains of pitch and rhythm events
in the pieces 
one difference in our frequency histograms from most of the literature we found was that rather than consider
the number of attacks of each note  i e   count the number of times it appears in the music   we used the percentage
duration of that pitch in the piece as our feature  we felt this corrected for the variance caused by different themes
in a piece  which would highlight different notes   and generally said more about the sound being utilized by a
composer than the number of appearances did 
when comparing josquin and ockeghem  the pitch histogram had     features  the interval histogram had     
and the markov rhythm matrix had      the markov pitch features had      features 
as the music of the renaissance followed strict rules  many of our extracted features were virtually the same
across composers  for example  its simply a rule that the  th tone of the scale always resolve to the tonic  this was
reflected in the data as p tonic  th      for all composers  markov pitch feature   the goal  then  was to find the
features that best separated josquin from his contemporaries 

feature processing

figure    top  raw scores  bottom  pca scores

in order to discover which features were the most relevant in
telling apart josquin and his contemporaries  and to reduce the
number of features we needed to consider  we set up a heuristic to
score all      of our features  our choice of heuristic was the mutual
information of each feature and the class    or     there was one
slight twist   each x i  fell into more or less an exponential distribution  being a normalized percentage  since having a high percentage
of the note g precludes the presence of any other note  similarly 
transitioning from quarter note to whole note more often automatically means theres less transitions between quarter note and half
note  furthermore  being a percentage  each x i  was continuous 
rather than fit a gaussian function to the   and   classes and integrate over them  we decided to discretize the distribution by binning
using the value of sqrt x  rather than just x  in order to make the
bins a little more even 
after running feature selection  and using the top    features  we
just picked this number  no fancy cross validation involved  yet   we
saw that the top    features were full with rhythmic movement of the
bass voice  so markov transitions of rhythm of the bass voice  and
intervals between the bass and the soprano  or in other words the
melody   our findings with regards to the most important features
leave much analysis and investigation to be desired   theres a lot
of intuition to be gained from what the computer thought the most
important aspects of the piece were 
running gda with feature selection gave us     training error
and      wrong on the test bench  note  this was a post process run 
an ablative test of sorts  the later pca results compare to before

 

fiwe implemented the entire pipeline  
at this point  principal components analysis seemed like the next step   theres a natural dependency and
correlation between most of the features we extracted  and pca tries its best to remove those dependencies and
present uncorrelated  independent features  we ran pca and selected the top    features  pca gives us features in
order of maximum variance   the benefits of pca are very visible upon viewing figure   
the pca algorithm rotates the features so that the best scoring features are now present in the top     furthermore  while only a few of the top features break the      boundary in feature analysis  points in the pca space break
even     or       which is a     score increase  given that overfitting is a critical issue  this feature condensation
was extremely beneficial  upon performing pca analysis  our error dropped from        to         the full results
are detailed in the next section 

algorithms and cross validation
our initial learning algorithm was naive bayes  since it was easy
to implement  however  naive bayes exhibited about        training error  which was unacceptable  however  the results arent surprising  since the independence assumption is horrible for something
so interdependent as music 
to select the best model to represent our data  we used   fold cross validation on both the support vector machine  svm 
gaussian discriminant analysis  gda  learning algorithms  the
models with the best training error were used to calculate testing
error and run on the unknown data  we chose to use svm with a
gaussian kernel because the distribution of the features tended to be
gaussian after pca analysis  see figure     we generally thought
that the support vector model would be a good way to separate
figure    the  th highest variance feature the two composers   looking for a subset of the pieces that were
blue josquin  red la rue
difficult and then forming a margin between them would ignore
the extraneous outliers in the feature set  gda seemed natural
considering the shape of the features 
our algorithms training errors are detailed in the following tables 

 b  ockeghem training error

 a  la rue training error

the results seem very promising  if a little confusing  detailed here are the values of error obtained by running
the frequency histograms  first column  on ockeghem and la rue  respectively  and the error values obtained with
the first order markov transitions along with the frequency histograms  the significance of both of these composers
is as follows  ockeghem is a composer from the time period before josquin some aspects of the results are baffling  

 

fifor example adding markov transition features improved the results for ockeghem  but hurt the results for la rue 
part of the inconsistencies in behavior can be attributed to the fact that we only took the top    variance features
from pca  and not the top    scoring features 
testing benchmark results
we ran the algorithms on the    pieces provided by professor rodin 
when trained on la rues data 
gda correctly labeled the    incorrect examples as incorrect  however  it classified   of the    examples that were
probably josquins pieces as being josquin  in all cases  gdas decisions were very heavy handed  the probabilities
with which the decisions were made were either         josquin or         not josquin 
svm actually performed the exact same classifications as gda  but didnt output any probabilities  we assume
that the three pieces both algorithms were getting wrong constitute irregularities of some kind  either way  they
deserve investigation 
when trained on ockeghems data 
gda got   of the not josquin examples wrong  and svm got   of them wrong  the probabilities were closer
to the middle and more varied  indicating the algorithm isnt as sure about its decisions  not surprisingly  gda
and svm actually classified all but   of the josquin examples as being josquin  however  this isnt surprising 
as ockenghem was very different from josquin and any classifier with only knowledge of pieces that came from a
previous time period would be much more aggressive about classifying something as josquin 
although not perfect  the results inspire confidence in our choice of methods  we think with a little more coaxing 
machine learning could prove to be useful tool in deciding which composer wrote which renaissance piece 

future steps
one thing that would be simple to implement and add to the pipeline would be feature selection after pca  while
the top    pca points have on average high scores  it would be much more beneficial to choose the    highest scoring
pca variables  pca only increases the variance of the variable as a whole  and disregards the distance in between
the two gaussian functions of the variables  its pretty clear from the graph  which we unfortunately generated much
later than we should have  that the top    variance    top    scores 
alternatively  it may have been a better idea to run pca on only the training features  then recover the original
vectors  and perform the same transformation on the test data set  its unclear whether maximizing the variance of
the test set helped us distinguish the unknown pieces 
then  we could have run the svm with some play  as shown in class by adding a constant  so that outliers
would be ignored  however  it didnt seem prudent to start there  since we know of only     verified josquin sources 
and they all should be classified as being josquins  even if they are outliers  it was also difficult to know that any
outliers existed or that they should be labeled as such given the complexity and variance of pieces produced by any
one composer 
on the features side  other papers on similar subjects have achieved good results using  rd order markov transitions
of pitch and rhythm considered together as opposed to separately  however  the number of features this generates
is absolutely astronomical and the authors of that paper did a lot of work to trim down the number of features they
were dealing with  this extended treatment of the subject was outside the scope of a one quarter class  but deserves
future investigation 
also  professor craig sapp has a method of storing the counterpoint transitions between each set of intervals
in a melody  again  this method has been shown to provide great insights into the structure of renaissance music 
but also makes for an extremely large amount of features  and it wasnt clear wed have the time to implement the
processing tools to trim down those features in time  also  we felt that the insight gained from these simple features
was a little more tractable   the frequency of g makes more sense than the probability of the chain  m   p   m  
p   the latter is a little harder to make sense of 

 

fiacknowledgments
wed like to thank the stanford ccarh center and the josquin research project for their support throughout
this process  from giving us the data and initial insights about the pieces we needed to culling an appropriate set of
scores as a good test bench  professors jesse rodin and craig sapp were instrumental in the success of this project 
wed also like to thank professor andrew ng and the cs    staff for an enriching quarter  and for giving us the
toolset to accomplish so much in such a little time  we never thought wed have the knowledge to figure out which
renaissance composer wrote which piece in only    weeks of exposure to the material 

sources
rodin  j   n d    josquin and epistemology 
wolkowicz  j   kulka  z     keselj  v   n d    n gram based approach to composer recognition 
liu  y  w         june   modeling music as markov chains  composer identification 

 

fi