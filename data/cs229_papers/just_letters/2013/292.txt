object detection using convolutional neural networks

jim reesman
stanford university
jreesman cs stanford edu

shawn mccann
stanford university
sgmccann stanford edu

abstract
we implement a set of neural networks and apply them to the problem of object classification using
well known datasets  our best classification performance is achieved with a convolutional neural
network using zca whitened grayscale images  we achieve good results as measured by kaggle
leaderboard ranking 

introduction
note  this project was originally conceived as a vehicle detection in roadway images problem  we were not successful in processing the raw dataset sufficiently to allow meaningful results using the techniques described in this paper 
as a result  weve focused the paper on our successful implementation of neural networks for object detection using
known good datasets  on advice from sammy  weve submitted the paper with the same title used for the milestone
report for compatibility with the submission system  but have changed the title internally to reflect the modified scope 
our primary interest in this project was to gain experience implementing deep learning techniques 
deep learning refers  loosely  to representational techniques that learn features in layers  learning higher level features
as functions of lower level features learned from data  deep learning techniques are used in many problem areas 
including object classification      speech recognition      and nlp     
we approached the project as a sequence of independent steps  we first implemented a simple multi layer perceptron
with features learned in one case by stacked autoencoders and in once case by stacked sparse autoencoders  using
the mnist dataset  this allowed us to validate basic capabilities  our ability to get gpu based code running on the
computing systems available to us  and achieve an understanding of standard datasets 
then we moved to implementing a convolutional neural network  and applying it to a multi class classification
problem using known datasets  mnist  cifar      we submitted our results to two different kaggle contests  and
include our results 

background and related work
there are many examples of work on the general problem of object classification  for example  the pascal visual
objects challenge  voc  website lists    publications that use the voc dataset specifically      the classification
of objects in small images using deep belief networks based on restricted boltzman machines  rbms  is discussed
in      the use of gpu systems to scale object detection performance is described in      an analysis of feature
representations is presented in      techniques for improving feature representations by denoising specifically for
improving the performance of stacked autoencoders are discussed in      recent work showing very high performance
uses convolutional neural networks  cnn  for object classification     

classification using the mnist dataset
the first phase of the project focussed on developing a neural network classifier  we made use of the deeplearning net tutorial and the stanford ufldl tutorial         implemented a number of different network architectures and
compared the results using the mnist dataset     
 

fi a  features learned by the stacked au   b  features learned by the denoising
toencoder
autoencoder

figure    learned features

the mnist data consists of        training images         validation images  and        test images  each image is
a   x   pixel grayscale image 
multi layer perceptron
for the multi layer perceptron  the initial architecture we tested consisted of an input layer of size     pixels    x    
one hidden layer of size     units and an output layer of size    units  one for each digit type  
autoencoders
once the multi layer perceptron was working  the next step was to incorporate an autoencoder into the network
to support feature learning  we used both denoising autoencoders and sparse autoencoders  in the case of sparse
autoencoders  we used two techniques for imposing sparsity  restricting the size of the hidden layer      units  and
implementing the sparsity parameter as described in the ufldl tutorial  kl divergence  
figure  b shows an image of the features learned by the denoising autoencoder  using a corruption factor of      
these results compare favourably with those in vincent     
while figure  a shows an image of the features learned by the sparse autoencoder using a sparsity factor of      
for natural images  the tutorials indicate that we should expect to see the network learning edge detector filters 
however  it is our understanding that in the case of a dataset like mnist  it is more common to see brush stroke
patterns emerging in the filters 
multi layer perceptron with autoencoder
our next step then combined the autoencoder with the multi layer perceptron  this configuration used three hidden
layers with           and     units respectively  as before  the output was a    unit softmax layer 
pre training was done on each of the autoencoder layers to allow it to learn relevant features in an unsupervised manner 
once the pre training was complete  a fine tuning step was done to train the network using supervised learning 
the stacked autoencoder exhibits different performance based on layer sizes and noise levels shown in table   
table    training time and test error   mnist data
hidden layer sizes
             
             
             

noise
               
               
               

system
corn
aws
aws

 

training time
    min
    min
    min

test error
     
     
     

ficonvolutional network
as a final step  we switched to a convolutional network and tested that on the mnist data  this network used
four layers where layers   and   were are convolutional  max pooling layers  and layers   and   form a multi layer
perceptron with     hidden units and    outputs  the details for the convolutional layers are given in table   
table    cnn architecture   mnist data
layer
 
 

filter
 x 
 x 

pooling
 x 
 x 

feature maps
  
  

output size
  x  
 x 

results
table   shows the training times experienced for each network  note that the testing was done on the rye machines
in the stanford computing cluster using the gpu optimized theano library  performance of the gpu optimized code
was found to be an order of magnitude faster than running on the cpu  corn machines  
table    training time
model
mlp
mlp   ae
pre training
training
cnn

epochs
    

training time
    min

   for each layer
  
   

   min
   min
   min

table   shows the testing error rates that were observed using the various networks 
table    performance   mnist data
model
mlp
mlp ae
cnn

test error
     
     
     

kaggle competition
as a test of our implementation  we wrote a custom classifier using the convolutional network and ran it on the dataset
for the kaggle digit recognizer competition  our network scored        accuracy which ranked  rd place on the
leaderboard 

classification using the cifar    dataset
once we had the convolutional network working on the mnist dataset  the next step was to adapt it to work with
imagery from the cifar    dataset  examples of the cifar    images are shown in figure   
since the cifar    data contains color images  whereas the mnist images were grayscale  we converted the cifar
images to grayscale for use with the convolutional network  the initial results with no pre processing gave us an
accuracy of around          error rate  and we see that the network learned a set of edge detector filters as expected 
preprocessing
to improve the results  we implemented zca whitening as described in the ufldl tutorial  rerunning the tests with
this modification improved the results to     accuracy      error 
examples of the conversion from rgb to grayscale images  and from grayscale to zca whitened images can be seen
in figure   
 

fifigure    cifar    image examples
however  one challenge that we found with the preprocessing was that the covariance
matrix  was computed on a batch of images instead of a single image  this caused
difficulties when testing the network as we were testing with smaller batch sizes     
images  than was used during training         images  which changed the covariance
matrix and resulted in degraded performance  our solution was to use the same batch
size for both training and testing  however further work is required to better understand
the whitening process and its associated constraints 
extending to multiple channels

figure    image preprocessing

to improve the results further  we extended the network to work with multiple channels so as to avoid having to convert the rgb images to grayscale  however  testing
of this configuration did not result in any improvement of the results  upon investigation  it was found that only a small number of useful filters were being learned by
the network  see figure      various experiments were run to try and improve the filter learning  different number of
feature maps  different filter sizes   but they all proved ineffective 

figure    features learned by rgb cnn
results
table   shows the validation and test error achieved with these models 
table    cnn performance   cifar    data
input
grayscale
grayscale  whitened

validation error
      
      

test error
      
      

we initially configured the training to run for     epochs  but eventually cut off training at    epochs  the error didnt
meaninfully decrease beyond    epochs 
figure   shows the confusion matrix resulting from testing with the grayscale cifar    images  the confusion matrix
is consistent with our intuition  showing that a common confusion is between auto and truck  and for example autos
are never confused with birds or dogs 
kaggle competition
as a test of our convolutional network  we ran it on the dataset for the kaggle cifar    competition and scored
        which put us in   th place on the leaderboard 
 

fifigure    cifar    cnn confusion matrix

conclusions
in this project we successfully implemented several neural network architectures  and applied them to the problem
of object classification in images  while we did not achieve the full results we had originally hoped for  we did
successfully implement multiple neural network architectures  including cnn  and successfully applied them to object
classification problems with good results 
our primary results are the kaggle contest results  shown in table   
table    kaggle contest results
kaggle contest
digit recognizer
cifar   

accuracy
      
      

place
 rd
  th

references
    ross girshick  jeff donahue  trevor darrell  and jitendra malik  rich feature hierarchies for accurate object
detection and semantic segmentation  arxiv preprint arxiv                 
    george e dahl  dong yu  li deng  and alex acero  context dependent pre trained deep neural networks for
large vocabulary speech recognition  audio  speech  and language processing  ieee transactions on          
         
    richard socher  yoshua bengio  and christopher d manning  deep learning for nlp  without magic   in tutorial
abstracts of acl       pages     association for computational linguistics       
    m  everingham  l  van gool  c  k  i  williams  j  winn  and a  zisserman 
the
pascal visual object classes challenge       voc      results 
http   www pascalnetwork org challenges voc voc     workshop index html 
    alex krizhevsky  learning multiple layers of features from tiny images  masters thesis  university of toronto 
    adam coates  paul baumstarck  quoc le  and andrew y ng  scalable learning for object detection with gpu
hardware  in intelligent robots and systems        iros       ieee rsj international conference on  pages
          ieee       
    adam coates  andrew y ng  and honglak lee  an analysis of single layer networks in unsupervised feature
learning  in international conference on artificial intelligence and statistics  pages              
    pascal vincent  hugo larochelle  yoshua bengio  and pierre antoine manzagol  extracting and composing
robust features with denoising autoencoders  in proceedings of the   th international conference on machine
learning  pages           acm       
    theano development team  deep learning tutorials  http   deeplearning net tutorial contents html 
     a  ng  j  ngiam  c y  foo  y  mai  and c  suen  ufldl tutorial  http   ufldl stanford edu wiki index php 
     yann lecun  corinna cortes  and christopher j c  burges  the mnist database of handwritten digits 
http   yann lecun com exdb mnist index html 

 

fi