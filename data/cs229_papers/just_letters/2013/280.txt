real world material recognition for scene understanding
sam corbett davies
department of computer science
stanford university
scorbett stanford edu

abstract
in this paper we address the problem of recognizing materials in consumer photographs  while material recognition isnt a new problem  the introduction of the opensurfaces dataset      allows it to be studied at a new scale  in
particular  the dataset provides materials in a huge variety
of real world environments  with dramatic appearance and
shading differences within each a material class  we propose a discriminative learning framework for the per pixel
classification of materials in an image  huge appearance
variation makes classifying some material classes extremely
challenging   our method achieves only       classification
accuracy  however  we show that even this weak material
signal can be valuable for scene understanding  we use the
output of our classifier as a new feature in a recent rgb d
scene understanding algorithm  we improve this state ofthe art scene understanding method by      

figure    an example of a situation where material recognition would be valuable  the three bottles  while similar in
shape  have vastly different physical properties  which can
be inferred from their material composition 

investigated  and no other dataset achieves the quantity of
real world scenes that opensurfaces does  for instance  in
    sharan et al  present a dataset of     flickr images for
each of    material categories  in contrast  opensurfaces
has        scenes with over         segmented materials
in    classes 
we hope that an understanding of the material composition of a scene will aid in the scene understanding problem 
which requires the semantic labeling  ie sofa  chair  tv etc 
of each pixel in an image to be determined  for this reason  our approach seeks to determine per pixel material labels  while sharan et al      and subsequent works on their
dataset     only determined the dominant material in an image 
our method builds on the framework developed by
ladicky and torr for scene understanding         the underlying method is a conditional random field  crf  over
the image with higher order potentials to ensure segments
are smoothly and consistently labeled  but we will only consider the unary potential in this paper  materials are classified with a random forest that uses four features  sift     
color sift      linear binary pattern  lbp       and textons       these features are described in more detail in
section     
the rest of this paper is organized as follows  section
  surveys existing material recognition methods  section  
describes our machine learning approach  with the features
detailed in section     and the algorithm used described in
     in section   we present out results for material classification on the opensurfaces dataset  then in section   we
incorporate our classifier into an existing scene understand 

   introduction
the material of an object has the potential to be a very
salient piece of information for the understanding of scenes 
from a simple visual examination of an object  humans are
often able to judge its weight  texture and function by estimating its material composition  consider the bottles in
fig     a good object detector would most likely label all
three as bottles  however  by judging each bottles material composition  a human could sort the bottles by weight 
determine which would break when dropped  or even determine which would be best to hold very hot liquid  knowledge of such properties would be crucial for a personal
robot  making material recognition a very interesting direction for scene understanding research  despite this  material
properties have been scarcely explored in the existing scene
understanding literature 
this work is motivated by the introduction of new largescale database of materials in real world environments by
bell et al  called opensurfaces      the dataset contains
tens of thousands of flickr images  with each surface segmented and annotated with surface normal  specularity  diffuse color  roughness  and scene context information including the associated object and scene type 
while other datasets have been developed for texture
recognition         material recognition in the wild  as opposed to under controlled conditions  has only recently been
 

fiing framework  improving its overall accuracy from      
to        finally  we discuss our findings and draw conclusions in section   

   related works
the seminal work considering texture for computer vision was done by dana and ginneken      where they presented the curet dataset  their thorough investigation of
the visual properties of surface texture prompted early texture recognition approaches such as       who developed
the texton feature for this purpose   however this dataset
was generated in a controlled environment and only contained planar texture patches  and as a result it was far too
easy to achieve good results on       demonstrated over
    classification accuracy on the curet dataset  but only
    accuracy on the flickr dataset of real world materials
introduced by     
with the focus of material recognition shifting to realworld examples  recent research has shown promising
progress on this challenging task      developed a number
of new features for classifying materials  including computing hog features    along and across image edges  these
features were quantized into visual words using k means
clustering  and a bayesian model was learned to combine
them into a classifier  this approach achieved     accuracy on the flickr image dataset  but only allowed for a single material per image  so it is not directly applicable to
scene understanding 
     improved on the performance of liu et al  on the
flickr dataset  achieving     classification accuracy  this
was done using the kernel descriptors developed in      
they develop more expressive features by realizing that
popular image descriptors  sift  hog  can be generalized
as kernels over image patches  they also quantize their
features into visual words  but using large margin nearest
neighbor instead of k means  again  this approach predicts
only the principal material the is present in an image 

   method
our approach is built on the publicly available ale
framework for scene understanding      which uses a crf
model  in this paper we focus on only the unary potential 
which is a discriminative algorithm for classifying the material of each pixel  the crf model also contains higherorder potentials to smooth the pixel wise classification result  but they are not explored in this project 

     features
our learning algorithm determines the material of each
pixel as a function of four feature vectors  these are sift 
color sift  textons and lbp  each feature is described in
more detail below 

     

sift and color sift

sift     was developed by lowe over ten years ago and remains the most popular image descriptor in computer vision
research  only keypoints that persist at different scales are
used  making the descriptor scale invariant   and the local
image gradients around these points computed  by binning
the gradient orientations relative to the dominant orientation  the descriptor is also rotation invariant  the result is a
    dimensional feature vector 
color sift     is an adaption of the sift descriptor that
includes color invariants to make it more robust to colour
changes in an image  while sift computes gradients in
a grayscale image  csift computes gradients in this color
invariant space  we compute sift and csift features at  
scales using   gradient orientation bins 
     

textons

textons were one of the first feature descriptors developed
explicitly for texture recognition       the term texton was
originally coined in           as the unit of pre attentive
human texture perception  leung et al  attempted to develop a computer representation of this concept by convolving an image with a bank of n filters  the original work
used     we use      resulting in a n dimensional vector
of responses for each pixel  these vectors are quantized using k means clustering into visual words  with each pixel
mapped to its nearest neighbor to generate a texton map  in
this work we used     clusters 
     

local binary pattern  lbp 

the final feature we use was introduced by ojala et al  in
     and provides another way to represent the image structure around a pixel  for each pixel in the local region around
a point  an   bit vector is computed to record which of the
pixels   neighbors has a smaller intensity  these vectors
are collected into a histogram for the local region  which is
the lbp feature vector  again  we quantize the lbp vectors
by performing k means clustering on the vectors computed
for all images 

     training
we use the random forests learning algorithm in this
work  introduced by       this algorithm has demonstrated
good performance on tasks involving real world data  including human pose classification      and edge detection
      the algorithm learns a set  forest  of decision trees 
each of which is trained on a random subset of the training set  at each node in a tree  the feature that best splits
the data is chosen from a randomly selected subset of the
features  the leaf nodes of each tree contain distributions
over the class labels  at classification time the pixel feature

ficeramic
glass
metal
paper  ssue
cardboard
brick
carpet
concrete
laminate
leather
stone
fabric
plas c   clear
plas c   opaque
painted
granite marble

 a 

figure    training and test accuracy for forests of different sizes and depth  in general  accuracy on both training
and test sets increases with forest size and tree depth  but
tree depth is the more important parameter  deeper forests
tend to result in overfitting  with test error increasing only
marginally with tree depth 

 b 

figure    confusion matrices for a random forest with   
trees of depth     columns correspond to predicted labels
and rows to ground truth labels  with the cells colored depending on the proportion of classifications in each ground
truth prediction pair   a  confusion matrix for training set 
 b  confusion matrix for test set  overfitting is evident 

vector is classified by each tree  which votes on the label
distribution of the pixel  these distributions are averaged to
find the final classification probability  a single tree often
suffers from high variance  but this can be decreased with
only a small increase in bias by adding trees to the forest 
in this project we experiment with forests of different sizes
and depths during our analysis of the learning algorithm 
while there are    material labels in the dataset  a number of them are badly defined  such as the multiple materials and i dont know classes   some are not commonly
present in scene understanding datasets  animal fur and
skin   and some contain very few examples  we narrowed
these classes down to    with the highest quality examples       images per category were randomly selected 
each cropped tight around the material of interest  material
samples that were very small  fewer than    pixels on either side  were rejected  leaving       samples remaining 
half forming the training set and the other half left for the
testing set  features were evaluated at each pixel  but were
subsampled in a  x  grid for training 
to give the reader an idea of the size of the training set 
the training algorithm initially failed because the number of
data points  ie features  subsampled image pixels  overflowed a    bit integer  however  there is likely to be a lot
of redundancy in these data points  as pixels from the same
material image will be very similar  especially if the material lacks visual texture  

forest     trees to a depth of     took approximately a
week on a    core machine  while training a single tree of
depth    took over    hours  before we gave up   consequently  computation constraints prevented us from trying
larger trees 
figure   shows the classification confusion matrix for the
most accurate forest on the test set     trees    deep   this
algorithm achieved a test set accuracy of        while the
training accuracy was        the large disparity between
the two accuracies suggests that overfitting is present 
fig    shows how training and testing accuracy changed
with forest size and depth  using forests with a depth of  
both training and testing accuracy are low for forests of all
sizes  indicating the algorithm is limited by high bias  using deeper trees causes both training and test accuracy to increase  but training accuracy increases much faster  this is
a curious observation  the algorithm is generalizing better 
even while it increasingly overfits the training data  essentially what is happening is that the majority of the variance
added by increasing the depth of the trees is contributing
to overfitting  but some is extracting valuable information
from the features and improving the overall performance of
the classifier  in addition  this observation may be partially
caused by others terms in the crf smoothing the random
forest output and mitigating some of the increased variance
introduced by deeper trees  we would have liked to use even
more data to try and decrease this overfitting  but the aforementioned computation constraints prevented this  figure  
shows that increasing the number of trees in the forest has
a much smaller but equally consistent positive effect on accuracy 

   results

   scene understanding

we trained random forests containing               
and    trees  each       or    nodes deep  training random forests is approximately linear in the number of trees
but exponential in the depth of the tree  training the largest

our reason for developing this material classification algorithm is to improve scene understanding  to achieve this
we use the output of our most accurate random forest as
additional features to a recent rgb d scene understanding

fifigure    examples of per pixel material classification on images in the nyu v  scene understanding dataset  some materials are classified correctly  but as expected the classifier struggles with textureless materials  often mistaking cardboard 
painted surfaces  opaque plastic and laminate for one another  
algorithm presented by ren et al        this scene understanding approach determines the semantic labels of superpixels in a tree of segmentation layers using a linear svm 
our random forest outputs a per pixel probability distribution over the    material types for that pixel  which can
be thought of as a    dimensional feature vector  we augmented the existing feature set with these material features
and retrained the algorithm on the nyu v  rgb d dataset
     
figure   shows the classification accuracy at each layer
of the segmentation tree  and when all layer are combined 
by introducing material features we improve the test set accuracy of the semantic labeling from        to        
for comparison  this improvement is approximately the
same as was achieved in      by introducing a novel way
to combine segmentation layers  although this is a small
improvement  it illustrates the value of even relatively poor
material labels for improving scene understanding  figure  
shows the most likely material label for a number of nyuv  images  as determined by our classifier  the effect of
the higher order crf terms can be seen  as superpixels in
each image take the same label 

   discussion and conclusion
on face value our results might seem disappointing  but
it must be stressed how challenging it is  even for humans 

segmenta on level
 
ren et al 

 

 

 

 

 

combined

                                         

      

with material
                                         
features

      

figure    semantic labeling accuracy for the scene understanding approach by ren et al   showing how adding our
material features improve scene understanding  we improve accuracy on each segmentation layer by an average
of        and by      when these layers are combined 

to determine material exclusively from local appearance
features  for example  consider the three material samples from the opensurfaces dataset shown in fig     there
is nothing discriminative about their appearance   without
knowledge of the object they belong to or the context the exist in  we cannot determine their material types  this is why
our algorithm does much better on stone and brick  which
has distinctive appearances  than on plastic and laminate 
in general  it is not clear how much a humans ability to
recognize materials in objects is a result of our amazing object recognition ability combined with strong priors on the
material composition of objects  for example  we know that
most coffee mugs are ceramic  so we might not be recognizing the ceramic material so much as recognizing the coffee

fi a 

 b 

 c 

figure    cropped samples of   different materials from the
opensurfaces dataset  illustrating how challenging it is to
determine material type visually  without the use of context 
 a  is opaque plastic   b  is laminate and  c  is painted 

cup and making an inference about its material  while i
believe there is room for improvement in appearance based
material classification  for example by introducing some of
the features used in        i believe such improvements will
be marginal  and real progress towards solving this problem will require material and object type to be considered
jointly in a scene understanding framework 
the development of such a framework for material and
object recognition would allow prompt exciting advances in
robotics  for example  a robot could be taught to avoid  or
move cautiously near  objects that could be sharp  ie metal 
or fragile  ie glass or ceramic   this would be a step towards the safe collaboration between robots and humans in
a kitchen or home 
our algorithms performance can be evaluated by considering the flickr image dataset  for which state of the art
accuracy is           however  the opensurfaces dataset
is qualitatively much more challenging because the flickr
dataset contains hand picked images of single objects  so
there is no clutter or shadowing from other objects that
is present in the opensurfaces images  in addition  because material classification was done image wise rather
than pixel wise  it is possible that this approach learned a
primitive object detector to aid classification  the opensurfaces dataset is very new  so we dont know of any methods
directly comparable to ours 
in conclusion  this paper has presented a material classification algorithm trained on a large scale  real world
dataset  our final test accuracy was        and we show
that augmenting an existing scene understanding method
with this material information improves its accuracy by
     

references
    s  bell  p  upchurch  n  snavely  and k  bala  opensurfaces  a richly annotated catalog of surface appearance  in
siggraph conf  proc   vol      no            
    l  sharan  r  rosenholtz  and e  adelson  material perception  what can you see in a brief glance  journal of vision 
vol     no     pp                    

    k  j  dana  b  van ginneken  s  k  nayar  and j  j  koenderink  reflectance and texture of real world surfaces 
acm transactions on graphics  tog   vol      no     pp 
               
    c  liu  l  sharan  e  h  adelson  and r  rosenholtz 
exploring features in a bayesian framework for material
recognition  in computer vision and pattern recognition
 cvpr        ieee conference on  ieee        pp     
         
    p  kohli and p  torr  robust higher order potentials for enforcing label consistency  international journal of computer vision  vol      no     pp                    
    l  ladicky  c  russell  p  kohli  and p  h  torr  graph cut
based inference with co occurrence statistics  in computer
visioneccv       springer        pp           
    d  g  lowe  distinctive image features from scale invariant
keypoints  international journal of computer vision  vol     
no     pp                   
    a  e  abdel hakim and a  a  farag  csift  a sift descriptor
with color invariant characteristics  in computer vision and
pattern recognition       ieee computer society conference on  vol     ieee        pp                
    t  ojala  m  pietikainen  and t  maenpaa  multiresolution
gray scale and rotation invariant texture classification with
local binary patterns  pattern analysis and machine intelligence  ieee transactions on  vol      no     pp         
          
     t  leung and j  malik  representing and recognizing the
visual appearance of materials using three dimensional textons  international journal of computer vision  vol     
no     pp                  
     m  varma and a  zisserman  a statistical approach to material classification using image patch exemplars  pattern
analysis and machine intelligence  ieee transactions on 
vol      no      pp                   
     d  hu  l  bo  and x  ren  toward robust material recognition for everyday objects  in bmvc        pp         
 
     l  bo  x  ren  and d  fox  kernel descriptors for visual
recognition  in advances in neural information processing
systems        pp           
     b  julesz  textons  the elements of texture perception  and
their interactions  nature  vol       no        pp       
mar         
     l  breiman  random forests  machine learning  vol     
no     pp              
     j  shotton  t  sharp  a  kipman  a  fitzgibbon  m  finocchio  a  blake  m  cook  and r  moore  real time human
pose recognition in parts from single depth images  communications of the acm  vol      no     pp               
 
     p  dollar and c  l  zitnick  structured forests for fast edge
detection  in iccv         
     x  ren  l  bo  and d  fox  rgb  d  scene labeling  features
and algorithms  in computer vision and pattern recognition  cvpr        ieee conference on  ieee        pp 
           
     n  silberman  d  hoiem  p  kohli  and r  fergus  indoor
segmentation and support inference from rgbd images  in
computer visioneccv       springer        pp     
      

fi