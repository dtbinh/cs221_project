reinforcement learning for adaptive routing of
autonomous vehicles in congested networks

jonathan cox
aeronautics   astronautics
stanford university

brandon jennings
mechanical engineering
stanford university

steven krukowski
aeronautics   astronautics
stanford university

abstract
the authors present a reinforcement learning approach for routing autonomous
vehicles in a dynamic network with congestion  the policy is an extension of
q routing  a technique originally developed for packet routing in communication
networks  the proposed algorithm is shown to perform as well as individual shortest path planning in static conditions and far outperforms shortest path planning
in scenarios with road congestion 

 

motivation

cooperative routing has received significant attention due to its wide range of application in the
control of unmanned aerial vehicles and distribution of packets in communication networks  this
paper describes the application of a novel technique inspired by reinforcement learning to the cooperative control of a multivehicle network that outperforms shortest path algorithms in dynamic
environments 
optimal path planning for a single agent has been studied extensively in     and      these algorithms provide superior performance in static networks with multiple agents but have limitations in
dynamic networks  where the reward function at each state is either time or state dependent 
the authors investigate the taxi routing problem  where each taxi is represented as an agent originating at some network node with the goal to traverse the network and arrive at a destination node  the
state model was developed under the following assumptions     there is a non trivial ratio of autonomous agents  taxis  relative to independent agents  other vehicles  such that the time to traverse
each edge in the network is dependent upon the number of autonomous agents in the immediate
vicinity of that node and    the contribution to the state model by the independent agents can be
represented as a static function dependent only on network location  these can be interpreted as a
congestion model  where    is a base level of congestion due to the independent agents and    is the
contribution to congestion by the autonomous agents 
in the spirit of reinforcement learning  the authors assume no prior knowledge of the congestion
model  in this way  the routing algorithm is robust to sharp changes in congestion  traffic accidents 
etc   and can be applied to a new city network with no alteration 

 
   

q routing
basic update

the inspiration the for approach used by the authors is named q routing due to its similarity to the
reinforcement learning technique q learning      the q function is a matrix mapping states and
actions to rewards s  a   r  the q matrix holds at each entry qx  d  y  the time estimated for
 

fian agent to traverse the network from node x to node d by way of neighbor node y  upon traversing
from node x to y  the agent updates qx  d  y  as follows 
qx  d  y     qx  d  y     s   t  qx  d  y  
d   destination node
x   current node
y   neighbor node of x
   learning rate
s   travel time between nodes x and y
t   minz neighbors of y  qy  d  z 

   

when a taxi arrives at a node  it immediately uses the information about the length of time on that
leg of its trip to update the previous nodes estimate qx  d  y   a table of estimates is kept for each
node and turn direction to each possible destination node  after the update is applied  the next action
is determined by finding the optimal decision at that node  argminyneighbors of x qx  d  y  
   

extended update

the authors propose an extension to q routing  where each taxi stores its path history in memory
and uses this information to update previous nodes  this memory is cleared when the taxi reaches its
destination and the process repeated  the goal of this extended update is to accelerate convergence
to an optimal policy in static conditions 
when a taxi arrives at a node  each node in its history is updated based on the current estimate of the
travel time to destination node from that node in the taxi history  the time it took the taxi to get from
that node to the current node  and the estimated time to go from the current node to the destination 
qxi  d  y i      qxi  d  y i      pi   miny neighbors of

xj   qxj  d  y 

 qxi  d  y i   

   

i   element in path history  i           j 
j   last element in path history
pi   travel time between nodes i and j
a comparison of q routing  the proposed extended q routing  and the shortest path algorithm a 
for moderate congestion is shown in figure   
  

astar
extended
basic

average travel time  min 

  

  

  

  

  

  

  

  

 

   

   

   

    

    

    

    

    

taxi  

figure    comparison of q routing basic and extended

 

simulation

a simulation was developed to test the performance of the algorithm  the test map is a small representation of the city of manhattan  appropriately named mini manhattan  see figure     minimanhattan is a       node network with two missing nodes to account for central park  each
 

fiedge  or road connecting nodes  was chosen to be one mile for simplicity  the maximum velocity
allowable on each road  or speed limit  was chosen to be either    mph  light green      mph  dark
green  or    mph  yellow  based on characteristics of real new york city streets  customers are
assumed to be picked up at street corners  nodes   the locations of taxis are propogated based on a
finite time step  where the velocity is assumed to be constant for that step  when a taxi arrives at a
node  it decides which direction to turn based on its current routing algorithm 
the q matrix is initialized at every entry to the manhattan distance between nodes  in this way  the
taxis have only information regarding road geometry and must learn the speed limits through trial
and error 

figure    mini manhattan test map

   

congestion function

many models have been developed to relate traffic and vehicle throughput  yet no single model has
been proven to accurately depict this relationship for all road types and geometries      the authors
utilize a modified sigmoid function to represent the relationship between number of vehicles on a
road and mean velocity
v  x    vmax

     e   eax  
    ex

   

where x is the number of cars on a road and  and  are constants 
this representation is advantageous in simulation because it satisfies the conditions v       vmax
and limx v  x       the minimum velocity was bounded to ensure that every vehicle completed
its route in a finite time 
the choice of congestion function is not critical to demonstration of the performance of the algorithm  rather  the difficulty in deriving a meaningful relationship between distribution of vehicles
and mean velocity for every road type and geometry is a motivating factor for use of a learning
algorithm 
   

a  search

the a  search algorithm was used as a baseline model against which to evaluate the performance of
q routing  a  is used for finding the shortest path between two points in a node network with edge
costs  it is an extension of edsger dijkstras      algorithm     that achieves faster performance
through the use of heuristics 
in the baseline scenario  a taxi calculates its a  path from origin to destination upon receiving a
customer  this process is done independently  based on knowledge of the speed limits and road
 

figeometry  the taxi then stores this path in memory and follows it to the destination  in the baseline
scenario  the taxis are given knowledge of all static parameters of the system  but not the locations
of other taxis or the congestion function 

 
   

results
test case    no congestion

we considered three test cases to show the superiority of the proposed algorithm to shortest path
planning with a   in the first case  both algorithms are run on the test map with no effect on
velocities due to congestion  figure   shows that after an initial learning period  q routing average
travel times converge to those of a   the taxi network running the q routing algorithm is able to
learn the speed limits through trial and error 
  

average travel time  min 

qrouting
astar
  

  

  

  

 

 

 

  

  

  

time  hr 

figure    test case    average travel times

   

test case    unidirectional travel

in the second test case  taxis pick up customers at the six southernmost nodes on the map and
deliver them to the most northeast node  this is a reasonable model for morning or evening traffic 
as commuters travel to and from work  figure   a  shows that the taxi network running q routing is
able to outperform the taxi network running a  in average travel time 
a primary concern in using this algorithm for vehicle routing is sacrificing individual performance
in order to minimize group travel time  it is unrealistic to expect a single taxi to vastly increase its
own travel time in order to save a small fraction of time for many taxis  figure   b  shows that no
taxi increases its own travel time by more than    percent after the initial learning period in this
scenario 
   

test case    game day

in the third test case  the base customer arrival and destinations were randomized and arrival rate
set constant  in hour     the arrival rate was doubled  with half the arriving taxis traveling to one
node  this scenario simulates a sporting or other large event that causes an influx of traffic  figure
  shows the average travel times for this case  q routing average times increase at the start of the
traffic influx but quickly adjust to outperform those of a  

 

conclusion

an extension of q routing was shown to outperform a  in multivehicle routing on a traffic network
with congestion  the algorithm is ideally suited to solution of this problem due to the dynamic
nature of traffic and difficulty of modeling congestion on roads 
 

fi   

   

percent improvement in travel time

qrouting
astar
average travel time  min 

   

   

  

  

  

  

 

 

 

  

  

   

   

  

 

  

   

  

 

 

  

time  hr 

  

  

time  hr 

 a  average travel times

 b  improvement in travel time with q routing

figure    test case  
  

qrouting
astar

average travel time  min 

  
  
  
  
  
  
  
  
  
 

 

 

  

  

  

  

time  hr 

figure    test case    average travel times
several simplifying assumptions were made in this analysis  adding variation to road geometry
and allowing customers to arrive at edges would result in a more realistic simulation  although the
authors submit that these changes would only prove to highlight the benefits of q routing 
the trade off between individual performance and overall system performance is a topic that warrants further exploration  in the results presented in this paper  there was not a significant degradation
in individual travel times to achieve shorter average travel times  however  a metric that quantifies
this trade off is important to avoid the sociological implications of passengers never reaching their
destinations 
a downside to this solution approach is that q routing suffers from the curse of dimensionality  the
q matrix grows at o n    with number of nodes  an approach to remedying this is to partition a
large city into subspaces  such that the q matrix contains travel time information for every node in
its subspace and from its own subspace to others  the authors intend to explore this approach in
future work 

references
    on a routing problem  r  bellman        quarterly of applied mathematics          
    a note on two problems in connexion with graphs  e w  dijkstra        numerische mathematik           
    packet routing in dynamically changing networks  a reinforcement learning approach  j  boyan
and m l  littman        advances in neural information processing systems           
    traffic stream characteristics  n h  gartner  c j  messer and a k  rathi        traffic flow
theory  united states federal highway administration 
 

fi