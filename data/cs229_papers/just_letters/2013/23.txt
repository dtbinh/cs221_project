project report
ranking web search results using personal preferences
shantanu joshi
stanford university
joshi  cs stanford edu

pararth shah
stanford university
pararth cs stanford edu

december         

abstract

in section    we lay down some prelimnary definitions and formalize the search personalization problem
which we address in this paper  section   presents a
study of recent work in this domain  in section   we
explain the crux of our approach  followed by section  
where we describe our experiments on the dataset the
next section provides a summary and evaluation of our
results and we conclude with a discussion on possible
extensions to our work 

the diversity of content on the web has exploded exponentially  while our vocabulary to parse it remains at
a relative plateau  it is increasingly difficult for search
engines to understand what the user really wants by
considering only the query terms      for instance  a
wildlife photographer searching for jaguar is probably looking for information on the animal  while an automobile enthusiast is probably looking for the sports
car  in this paper  we present a study of algorithms for
personalizing search results based on the users search
history 

 

 

problem formulation

although web search personalization is a well known
problem  there are multiple variations depending upon
what is included in the scope of personalization  for
example  having demographic information about the
user would help in personalizing based upon the gender  age group  country  etc of the user  similarly  having access to the text of the indexed webpages enables
clustering the urls based on keyword similarity and
giving higher ranks to urls that are closely related to
the urls that were previously clicked by the user 
however  in this paper we focus only on re ranking
based on the click history and dwell time of the user 
without assuming that we have access to any demographic information of the user or the text of the result pages  we define dwell time of a particular url as
the time difference between the click on that url and
the next click  for urls that form the last click of a
search session  we assume that the user found the url
of their interest  hence the dwell time should be infinity   in our experiments we cap this to the maximum
dwell time of the data set   we describe our problem
formulation in the rest of this section 

introduction

one of the challenges faced by search engines is to identify when personalization is useful and when it is not 
personalisation works best on queries that have a large
entropy  continuing our example from above  personalizing search rankings for queries like jaguar is a
good idea but is not required for queries like google 
another important factor is the difference in a users
long term and short term search history  where short
term implies the current query session  and long term is
the aggregate of all the query and click history of that
user  they are useful at varying times and modeling
this correctly can significantly increase the relevance of
the search results      for example  users often issue the
same query with slight variations in a search session 
as they refine their search for a particular resource     
the authors of     do not prescribe a silver bullet for
the search personalization problem and instead suggest
and evaluate different approaches which are useful in
different contexts  for example  they show that click
based methods work best for repeated queries but modeling a users profile along with a groups preference
works better in tackling queries that are not present in
that users search history 

   

formal problem statement

suppose a user u posts a query  q    q       qk   to the
search engine  where the qi  s are terms of the query 
 

fiand the resulting set of urls returned by the search
engine is  d    d       dn    with the urls ordered according to decreasing relevance to the query  our goal is
to re order the urls to  d     d        d n   in order of their
relevance to the user  we define the relevance of a url
to a user for a given query as follows 

such queries are found where in both the previous cases
the user clicked on the same link then the current query
is deemed to be a personal navigational query whose
prediction is that the user will click the same url as the
previous two occasions 
in     the author proposes a modification to the
widely used lloyds k means algorithm which addresses
the short comings of k means with regards to latency 
scalability and sparsity commonly found in todays userfacing web applications  the sailent modifcation which
we wish to highlight here is that the proposed algorithm
takes small randomly chosen batches of the dataset
for each iteration  instead of iterating over the entire
dataset  from  here the algorithm proceeds as usual by
assigning a cluster to each point in the dataset  which
are refined with each new batch iteration through the
dataset thus  the centroids get updated much faster
than the regular k means update  like k means  the
new mini batch k means algorithm suffers from the
problem of getting caught at a local optimum 

 relevance     highly relevant   if the user clicked
on the url with the last click in the session  or
spent more than     time units  perusing the url
 relevance     relevant  corresponds to links with
click and dwell time between    and     time units
 incluscive 
 relevance      irrelevant  corresponds to documents with no clicks or those with clicks and dwell
time strictly within    time units 

 

relevant work

the authors of     state that all queries to a search engine can be broken down into three categories  transactional  informational and navigational  the authors
focus on the last category and present a new algorithm
that correctly predicts which links a user will click on
for    of all queries 
first  the authors cite a large body of work which
supports their claim that navigational queries make up
a large amount of the traffic handled by search engines 
the solution to the navigational problem is not a one
size fits all kind of solution and thus lends its self perfectly to re ranking of results served by the search engine  the authors of     use bing    the authors propose a very simple yet effective algorithm which predicts the links that will be clicked on by a user for a
given query with a decent level of accuracy  the authors provide a method of computing the entropy of
a query and label queries which have a very low click
entropy as navigational queries 
in order to avoid outliers and false positives they
stipulate that each navigational query must have occurred atleast       times in their logs and must be accompanied by atleast       clicks on the serp     this
constraint effectively prunes against queries which have
a low entropy because they occur very infrequently  e g 
health coverage  or because the query is answered on
the serp page itself   e g  define schadenfreude  
having pruned the data they look at the query submitted by the user  try and find two successive queries
by the same users that match the current query and if
 
 

 

core algorithm

as mentioned before  our approach is to develop a
piecewise algorithm that targets different use cases  in
the rest of the section we describe two important parts
of our algorithm  handling navigational queries and
modeling user preferences 

   

handling navigational queries

in our literature survey we observed that the problem
of efficiently dealing with repeated query terms to find
the same resources had a significant benefit and thus
we can get significant gains for personal navigational
queries by taking into account only the search history
of the current user  the algorithm was outlined in
section   

   

modeling user preferences

the second part of our algorithm focuses on a more
general form of personalization which is more broadly
applicable to other types of queries as well  in this
algorithm we generate a user profile vector for each
user  the user profile vector spans over the space of
all the domains encountered in our training set  in
this setting  each domain name is associated with a
score depending upon features like click rate and dwell
time  having assigned a score to each domain for every
user we end up with a sparse matrix x  u sers x domains 
where  u sers  and  domains  represent the number of
users and domains respectively  as a user can only

kaggle and yandex will not release the length of   time unit
search engine results page

 

fi   million search sessions 
we parsed the dataset to compute the distribution of
dwell times of each click  in figure    we have plotted
this distribution for a subset of   million queries  note
that the last click of every session is given a dwell time
as the maximum dwell time in the dataset  the lone
data point in the top right area denotes that majority
of search queries resulted in only a single click  which
was assigned the maximum dwell time 

   

this algorithm is a simple way of providing the search
engine with memory to remember a users favorite
link s  for repeated queries  if for example  a user u
enters a query q and chooses the document d which the
search engine has ranked as the  th most relevant for
him  if the user repeatedly exhibits identical behavior
then from the third time q is issued our algorithm will
have learnt his preference for d and it will be shown as
the top result 
in figure   we have plotted the number and count
of the navigational queries for the entire dataset of   
million queries  the graph shows that a large number
of queries occur only a few times        but we exploit the long tail that any power law distribution has
and thus the graph in figure   makes concrete the impact of adding personalization excluscively focused on
navigational queries 

figure    frequency distribution of the dwell time of
each click 
visit a small number of domains x is a sparse matrix 
the next step is to run k means clustering on x in
order to find similar user profiles  the optimal value
of the number of clusters will have to be determined
emprically  once  in a cluster  the scores associated
with each domain will be an average of the scores associated with each domain for each user profile vector
belonging to the cluster  with this method we will be
able to incorporate the preferences of a large number
of similar users and leverage this to make better recommendations  finally  in order to arrive at the best
re ordering of the search results we will identify the
cluster to which the user belongs and re rank the links
in order of the most helpful domains as represented by
the associated averaged user profile vector 

 

   

dataset

the dataset used in our experiments is provided by the
search engine yandex  as part of the personalised web
search challenge on kaggle      the dataset includes
user sessions extracted from yandex logs  with user ids 
queries  query terms  urls  their domains  url rankings and clicks  the user data is fully anonymized and
includes only meaningless numeric ids of users  queries 
query terms  sessions  urls and their domains   

   

k means

after constructing the matrix x  explained in section
   we ran a naive implementation of k means on the
matrix hoping to extract the user clusters  however 
since x has slightly more than     million rows and    
million columns the algorithm was painfully slow and
did not scale to such a large dataset  this was when we
decided to adopt the mini batch k means mentioned in
   

experiments

   

personal navigation

   

mini batch k means

mini batch k means is a highly scalable algorithm that
can provide very good results for unsupervised clustering over very large and sparse datasets like the one we
have  the algorithm takes as input the number of centroids k  the batch size b and optionally a parameter
that specifies the maximum number of iterations over
the dataset after which the algorithm stops irrespective of other conditions  the formal specification of
mini batch k means as illustrated in     is shown in
algorithm  

key statistics

the dataset contains about    million unique queries 
    million unique urls    million unique users and
 

yandex has permitted the use of this dataset for academic
research 

 

fialgorithm   mini batch k means
   k  n umberof centroids
   b  batchsize
   x  givensparsem atrix
   limit  n umberof iterations
   k  randomly choose k rows from x
   v    
   for i     to limit do
  
m  b rows randomly chosen from x
  
for all x  m do
   
distance x   distancetonearestcenter x 
   
end for
   
for all x  m do
   
c  d x     get the nearest center from x
   
v c   v c        count of x per center
 
   
  v c 
  learning rate per center
   
c       c   x   gradient descent update
   
end for
    end for

figure    plot above shows that navigational queries
obey the power law with a slope of       a point on
this graph tells us the number of navigational queries x
that occur y times

 
batchsize
     
     
     
     
     
     
      
      
      
      
      

k
  
  
  
  
   
  
  
  
  
  
   

fraction in largest cluster
    
    
     
    
     
    
     
   
    
    
    

evaluation

the results of our alogrithms were evaluated using
ndcg  normalized discounted cumulative gain     
measure  which will be calculated using the ranking of
urls for each query in the test set  and then averaged
over all queries we used the kaggle interface to submit
our predictions on the test set 

   

evaluating mini batch k means

while intuitively  it feels wrong that a good clustering
of the users would involve a single very large cluster we
ran mini batch k means on those cases as well as the
ideal ones to verify our intuition with numbers  the
results are summarized in table   
to put our scores in context  the non personalized
baseline i e the score for the current output of the yandex search engine is          looking at these scores 
we thought a possible reason for k means doing worse
than the base line was the large number of test queries
it modified  over       thus  it was our hypothesis
that mini batch k means was suffering from overfitting  the personalizations it got wrong were hurting our score more than the personalizations it got
right  hence  we felt that adopting a more selective approach to applying the recommendations of mini batch
k means might counter the overfitting 
the idea that we came up with was to only change
the top   links and leave the rest as they are  this
would minimize the magnitude of the changes the algroithm made while ensuring we could still benefit significantly from the personalization recommended by

table    clustering results for different values of the
parameters

the quality of results obtained by this algorithm is
largely dependent upon the values for b  batch size 
and k  number of centroids  provided the number of
iterations has been set to a relatively high value     
in this case   we ran many simulations for different
values of the parameters in order to find a good clustering  our aim was to choose values of these parameters which avoid overly large   and as a consequence
extremely small  clusters  table   shows the results of
our experiments
an analysis of the results in table   reveals that increasing or decreasing one parameter alone has no verifyable trend and that both the batch size and number
of centres need to be varied to find the sweet spot which
gives rise to the best clustering 
 

fibatchsize
      
      
      
     

k
  
  
  
  

largest cluster fraction
    
    
     
    

score
       
       
       
       

mance  in this paper we have investigated the impact
of k means and mini batch k means on search personalization  applications of other clustering algorithms like
means shift  spectral clustering and hierarchical clustering could be explored in the future 

table    results for mini batch k means used to personalize links over the test set

references
    feng qiu and junghoo cho  automatic identification of user interest for personalized search  in
proceedings of the   th international conference on
world wide web  www     

our algorithm  the last row in table   shows the result
of applying this change 
our hypothesis was proved right and there was a
significant jump in our score from      to      

   

    zhicheng dou  ruihua song and ji rong wen  a
large scale evaluation and analysis of personalized search strategies in proceedings of the   th international conference on world wide web  www
   

personalizing navigational queries

this algorithm provides deterministic results and in
contrast to k means changes only a small fraction of
the queries        however  we can be confident that
any change advocated by this algorithm will be a positive one  as expected this algorithm performed much
better than the baseline and scored          propelling
us to our highest ranking of   th out of the     teams 

   

    milad shokouhi  ryen w  white  paul bennett 
and filip radlinski  fighting search engine amnesia  reranking repeated results  in proceedings of
the   th international acm sigir conference on
research and development in information retrieval
 sigir    

combining k means and personal navigation

    jaime teevan  daniel j  liebling  and gayathri
ravichandran geetha  understanding and predicting personal navigation  in proceedings of
the fourth acm international conference on web
search and data mining  wsdm    

the final step in our investigation of mini batch kmeans and personalizing navigational queries was to
combine the two algorithms  we did this by feeding
the results of k means as input to the personalization
algorithm  our resulting score for this algorithm was
        which is slightly better than the result of running a selective version of k means but still worse than
the navigational algorithm alone  on closer analysis
this result is not suprising as personalizing navigational
queries on the output of mini batch k means can only
improve the result obtained by k means but provides
no guarantees on improving the result of applying just
the alogrithm used to personalize navigational queries 

 

    yandex personalized web search challenge on
kaggle  data https   www kaggle com c yandexpersonalized web search challenge data
    kalervo jarvelin  jaana kekalainen 
cumulated gain based evaluation of ir techniques 
acm transactions on information systems       
             
    sculley d web scale k means clustering  in proceedings of the   th international conference on
world wide web  www    

conclusion and future work

from our results above it is clear that k means and
personalizing navigational queries are most useful in
personalizing search engine results when they are used
as two distinct algorithms instead of being merged into
one  the former algorithm tackles the case when a
user issues a query that he has never used before while
the latter leverages an users search history to provide
better results when an user inevitably repeats a query 
the clustering algorithm to deal with unseen queries
can be expanded further to provide even better perfor 

fi