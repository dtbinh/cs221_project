final report

using machine learning to teach a computer to
play backgammon
david molin   viking flyhammar and saman bidgol

abstractthis paper presents two methods to teach a computer to play backgammon  both methods are based on neural
networks which are trained by playing games against itself until
reaching convergence  the first method uses an approach similar
to td gammon to train a neural network while the second
method uses a bayesian approach to train a neural network 
based on the results  it is concluded that both methods succeed
to improve its performance after training  the network generated
by the bayesian method is shown to be superior to network
created by the approach similar to td gammon 

i  i ntroduction
the analysis of board games has become an increasingly
interesting field for researchers and engineers  the theory
in machine learning such as neural networks has made it
possible to make computers play board games better than ever 
beating the best professional players in the world 
the first strong computer player was bkg      written by
hans berliner     p        it managed to beat the reigning
world champion in backgammon back in       becoming the
first computer program beating a world champion in any board
game  berliner states it was largely a matter of luck because of
more favorable rolls of dices  in the late     s backgammon
programmers explored an approach using neural networks 
the most notable papers in this area were published by g 
tesauro in          and                describing how to
make a computer play backgammon using a neural network 
the new approach resulted in the computer program called
td gammon playing equal level or above of the best human
players 
a  the rules of backgammon
backgammon is a board game for two players  backgammon is played on a board with    triangles  called points 
where the players can move their checkers in a specific direction  see figure     each player has    checkers  depending
on the outcome of the two dices the player decides how to
move his checkers on the board  the opening move cannot be
done with two identical rolls  one of the most basic rules  and
also one of the most important rules in backgammon is that it
is possible to hit an opponents checker if it is left alone at a
specific point  if this is the case  that checker will be moved
outside the board and placed at the bar  located in the middle
 davmo stanford edu
 vikingf stanford edu
 bidgol stanford edu

of the game board  the next move for the opponent is to get
his hit checker back into the game before he can continue to
play  also  a player can block a point by having at least two
checkers at that particular point  which means that the other
player cannot move his checkers to that point 
when a player has moved all of his    checkers to the last
six points  he can start removing checkers from the board 
when this is the case  a roll of one may be used to remove a
checker from the   point  a two from the   point and so on  a
die may be used to remove checkers from a lower numbered
point if there are no checkers on any higher points  i e  if
a player rolls a six and a five  but has no checkers on the
  point  but two checkers remaining on the   point  then the
rolls must be used to remove the two checkers from the  point  the first player to remove all of his checkers wins the
game  backgammon is not a deterministic game in the sense
that dice rolls determines how the checkers may be moved 

b  goals
the objective of this project is to explore how to use a
bayesian approach in order to train a neural network to play
backgammon 

c  scope of the project
in this project the approach to teach a computer to play
backgammon is to find a function which maps a certain state
of the board to the probability that a player wins the round 
once the neural network is trained  the moves that generates
the highest probabilities to win are picked 
the main objective of backgammon is to score as many
points as possible by winning the game in different ways 
however  these rules are out of the scope of this project 
therefore  only the basic rules and the win loss ratio are
considered in this project 

ii  t heory
define s  rn as a state vector that represents a specific
game board  and also define y  r to be the probability
to win the game from a given state  furthermore  let the
function h  s    rn   r be the hypothesis that estimates
the probability to win from a given state  h  s  is the output
of a neural network where the last layer activiation function
is a sigmoid function 

fifinal report

equation     implies

a  modelling of the neural network parameters
in td gammmon the weights are updated using
t     t    yt    yt  

t
x

tk  yk  

fi


fi
p  i    fi i    e i   c i 
   

k  

 
since the case where     lends itself to the interpretation
t     t    j 

   

where j is the square error of the difference between h  s 
and yt     for this reason this case is explored in this paper 
however  since the outcome of a game is bernoulli distributed
rather than gaussian distributed the cost function used in this
paper is
j   h s y     h s   y  
   
since there are too many states in backgammon to store
the value function  v  s  explicitly for each state  v  s  is
approximated with a neural network h  s    the goal is that
this network will output the probability that black wins given
the current state and that it is blacks turn   the weights of this
network is denoted  in this paper 

 
exp    i      i   t  e i   c i      i      i         
 
furthermore  equation     and equation     used together
imply
fi


fi
 
p  i    fi i    e i   c i   n
  s  y 
fi


fi

fi
 
p  i    fi i    e i   c i p y fis    n

   

thus the update rule is
fi


fi
 
 i       arg max p  i    fi i    e i   c i   n
  s  y  

   



e  i         e  i    c  i         n  h    
   
fi

where h is the hessian of log p y fis    n     lastly ci is
assumed to be proportional to   i    i       

b  a bayesian approach
another method explored in this paper was using a bayesian
model to update   the prior is assumed to be gaussian  the
mean is initialized to small random values to avoid issues
with symmetry in the parameters  the posterior given one
observation is assumed to be gaussian with a mean which is
the maximum a posteriori and the covariance is the hessian of
the log of the posterior evaluated at the maximum a posteriori 
this procedure is used in     p        this posterior can then
be used to create the prior in the next estimate of   the mean
prior in iteration i will be denoted  i  and the covariance will
be denoted ei  
using the prior from step i it is possible to create a training
set by letting the computer play against itselfp
and for every visited state assigning the value y  i    maxa s  psa  s   v  s    
where v is the estimated value given the prior  the theta
which minimizes the cost function for this training set as the
size of the training set goes to infinity will be denoted  i     
but the state transition given an action is deterministic  thus
psa will be degenerate  the relation between  i    and  i 
is assumed to be
 i       i    n     c i   

   

which means that the difference between  i    and  i  is
white noise  this assumption is made because when the prior
estimate is close to the optimal set of parameters the new
information from one more iteration should not change the
value of  i  much 
the noise in the estimates are assumed to be white gaussian
noise with variance n   this implies
fi

 
p y fis    n   exp     h  s   y     
 n

   

iii  m ethod
this project explores two different approaches to the problem of finding a neural network which plays backgammon  the
first approach uses gradient descent in order to update the parameters  this approach is called the td gammon approach in
this paper  although this is a misnormer since the td gammon
derived by g tesauro is not identical to this approach  while
the second approach uses the bayesian approch described in
section ii  this approach is called the bayesian approach 
a  defining the feature vector
in order to apply machine learning to this problem  it is
necessary to calculate a feature vector  the feature vector used
in this problem represents the current game board  thus the
feature vector is the state vector described in section ii  where
n       the first    elements represent the    points on
the game board while the last two represent if a checker is
hit and placed outside the game  the value for each element
in the state vector represents the number of checkers each
player has at the actual points  positive integers represent the
current players checkers while negative integers represents
the opponents checkers  for example  the initial game board
shown in figure   has the following state vector
s                                       
                                          

    

where the representation is counter clockwise and starts from
the top right corner  the positive integers represent the black
players checkers and the negative integers represent the white
players checkers 

fifinal report
 

 

 

 

 

 

 

 

 

 

 

 

 

 

  

  

  

fig     the gui used for testing 
fig     the initial game board setup 

b  calculating all possible states
given two dice rolls and the current state vector  an algorithm calculates all the possible state vectors by using recursive
formula  each possible state vector represents a possible move
for a specific player from a given state and two dice rolls 
c  calculating the gradient of a neural network
the modeling of the probability to win in a given state is
done by a neural network  the neural networks in this project
have    hidden nodes  since this network has to be updated 
the gradient with respect to the weights in the neural network is
calculated  this is done by forward  and backward propagation
through the network 
d  generating a training set
in order to update the weights of the neural network training
data is generated  this is done by letting the computer play
against itself  at the end of every game a training set is
generated by assigning a target variable  y to each game state
visited during the game  the last game state is assigned the
target variable    in other words  the probability to win from
the last state is assumed to be    for the other states the target
variable is the probability that black wins from the following
state according to the neural network  once this training set
is generated the neural network is updated with respect to it 

rolls
   
   
   
   
   
   
   
   
   
   
   
   
   
   

opening move
          
        
         
         
        
        
         
          
           
          
           
         
         
         
table i

optimal
yes
yes
yes
yes
yes
yes
no
no
no
no
no
no
no
no

t he opening moves made by the final bayesian neural network  
s everal moves are optimal compared to moves made by the
professional backgammon players      t he opening moves are
described as from   to  

to find a local optima  this local optima is then approximated
by the result of two iterations of newtons method  calculated
with the approximation of the hessian described earlier 
f  backgammon gui
to know whether the algortihm plays correctly and to
visualize the game  a simple gui is created in matlab  it
plots a backgammon board and the associated checkers  the
gui is visualized in figure   
iv  r esults

e  assumptions to speed up computations of the bayesian
model
in order to reduce the computational complexity of the
bayesian approach described in section ii  and thereby speeding up the simulations  certain approximations are made  one
such assumption is that the hessian of the cost function with
respect to the weights is h   h     h  h  h  t    
p        another assumption is that the covariance of the
posterior is diagonal  the main reason for this assumption
is to speed up computations since even for small networks the
number of parameters grow quickly and computing inverses
of large matrices is time consuming  since the optimization
problem in neural networks are nonconvex the step of finding
the argmax with respect to the weights need to be simplified

the bayesian approach and the td gammon approach have
been trained for           games each  figure   and figure  
show percentages of games won against neural networks which
have been playing fewer games  opening moves of the final
bayesian neural network is presented in table iv  furthermore 
figure   shows the win ratio of the bayesian approach against
the td gammon approach 
v  d iscussion
as shown in figure    the bayesian model indicates convergence after approximately           games played  while the
td gammon model indicates convergence after approximately
        games played as seen in figure    both models
indicates an improvement of the game play as the number

fifinal report

 

percentages won

   
   
   
   
   
 

   
 
   
games trained by opponent neural network

 
 
x   
fig     win ratio of the final bayesian neural network  trained          
games  the number of games the opponent has played ranges from zero
 random neural network  up to           games 

 

percentages won

   
   
   
   
   
   
 

   
 
   
games trained by opponent neural network

 
 

x   

fig     win ratio of the td gammon neural network trained           games
playing against different trained td gammon neural networks  the opponent
neural networks range from zero  random neural network  up to          
games 

 

percentages won

   
   
   

a  future work
at this stage of the project it is not verified whether the
bayesian approach plays well against human players  therefore  further studies could include developing a gui to make
this possible 
since many assumptions are made about the noise in the
bayesian model  additional studies on how the noise behaves
in practice is of great importance for further improvement of
the model  another intresting thing to explore would be to see
which parameters of the bayesian neural network has a low or
high variance  respectively 
vi  c onclusion

   
   
   
 

of games played increase  there are two indicators of how
well they play  one indicator is how well they play against
each other  indicating which approach is the best of the two 
another one is studying the opening moves of the model 
by analyzing figure   it is easily seen that the bayesian
neural network is superior to neural networks created by the
td gammon model  although this result seems promising
the td gammon model in this paper differs from the tdgammon approach developed by g tesauro
the optimal openings done by the bayesian model are
compared to the best openings considered by the professional
backgammon players  these moves are considered to be a part
of the opening moves that maximizes the probability to win
given a throw of two dices      the bayesian model succeeds
to do      of the optimal opening moves which indicates
that the model plays good  however  the non optimal moves
are in some sense good because the bayesian model manages
to move one checker optimally  the reason why the final
bayesian network does the non optimal moves are because it
seems to favor moving a checker to point three on the home
board  in order to be able to secure this point on the next turn 
since the performance seems to converge  but the performance
it converges to does not seem to be optimal  it should be
possible to archieve a higher performance by increasing the
number of hidden nodes in the neural network 
in addition the final bayesian neural network also demonstrates a tactical game play  such as blocking the opponent
player from reentering the game if the opponent player has a
hit checker  furthermore  the neural network also demonstrates
a defensive play style  e g  avoids to be hit by the opponent
player 

   
 
   
 
games trained by tdgammon neural network  
x   

fig     win ratio of the bayesian neural network trained           games
playing against different trained td gammon neural networks  the tdgammon neural networks range from zero  random neural network  up to
          games 

due to the test results and the improvement in the bayesian
neural network as the training increases and the way of playing
it is concluded that the algorithm plays well  this project
also shows that a bayesian approach to reinforcement learning
problems are viable 
acknowledgement
special thanks goes to prof  andrew ng and the tas for
showing the thruth and beauty of machine learning 

fifinal report

r eferences
    e  a  berliner  hans  backgammon program beats world champ  acm
sigart bulletin  vol  issue     january      
    g  tesauro  temporal difference learning of backgammon strategy  in
proceedings of the ninth international workshop on machine learning 
ser  ml    san francisco  ca  usa  morgan kaufmann publishers
inc         pp           online   available  http   dl acm org citation 
cfm id              
      td gammon  a self teaching backgammon program  achieves
master level play  in neural computation  ser  vol     no     mit press  
      pp           online   available  http   www mitpressjournals org 
doi pdf         neco             
      temporal difference learning and td gammon  in communications
of the acm  march        vol      no            pp       
 online   available  http   www informatik uni osnabrueck de barbara 
lectures selforganization papers tdgammon ps gz
    c  bishop  pattern recognition and machine learning 
 st ed  springer       
    t  keith  how to play the opening rolls  http   www bkgm com 
openings html  viewed             

fi