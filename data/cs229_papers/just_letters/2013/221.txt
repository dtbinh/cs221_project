ensemble optical character recognition systems
via machine learning
zifei shan  and haowen cao
department of computer science  stanford university
 zifei caohw  stanford edu

abstract

keywords

    different ocr systems make independent mistakes  based
on studying the outputs of three open source ocrs on processing
geo science papers  we found an interesting fact that they seldom
make same mistakes  instead  they fail on different word  for example  cuneiform is bad at recognizing cases that all characters
are upper case  while tesseract can give correct outputs in this
case  another example is that tesseract often read fi as    while
cuneiform doesnt 
    if the output does not exist in a knowledge base  it can
hardly be correct  the ocrs we use sometimes generate words
that does not exist in dictionaries or web pages  to generalize  if the
sentence cannot be mapped into a correct grammar  it is also likely
to be a mistake 
these observations inspire us with the following ideas  what if we
combine these ocr systems together and use them to correct each
other  can we give suggestions to achieve the correct output even
when all ocrs fail  can we further combine semantics information
to do a better job  can we use domain knowledge of the corpus to
improve the results 
the core idea of our work is following  we treat each ocr system
as a black box  which takes images as input and generates text as
output  instead of understanding what is happening inside these
black boxes  we directly use their outputs to train a classifier that
selects among their outputs 

machine learning  optical character recognition  ensemble learning

  

optical character recognition  ocr  systems are widely used to
process scanned text into text usable by computers  we observe
that current ocr systems have bad performance on domain specific
papers  even generating lots of incorrect words  besides  different
ocr systems make relatively independent mistakes  based on
these observations  we train an ensemble system from multiple
open source ocr systems  which chooses outputs from candidates
generated by each ocr  and train the system with machine learning
techniques  we implement softmax regression and multi class
svm  our system achieve over     accuracy selecting between
different outputs on our training set of       words  we further
explore ways to improve the performance by suggesting new options 
and use domain knowledge to improve its performance 
our contribution lies in following aspects      we show the great
potential of treating ocr systems as black boxes and correct their
outputs from each other      our system build on best open source
ocrs and achieve significant improvement on their accuracy     
moreover  our work explore the possibility to make use of rich
semantic knowledge to craft a better ocr system  and cast insight
to a general approach to ensemble systems as black boxes 

  

introduction

optical character recognition  ocr  is a common technology
to convert scanned images of handwritten or typewritten text into
machine encoded text  it is widely used in digitizing books and texts
so that they can be used in electronically search  machine translation
and text mining  usually ocr will do pre processing  character
recognition and post  processing 
tesseract     is a well known open source ocr engine that was
developed by hp between      and       tesseract assumes that its
input is a binary image with optional polygonal text regions defined 
tesseact processing follows a traditional step by step pipeline  it
includes connected component analysis  recognition and resolving
fuzzy spaces  it is the first ocr able to handle white on  black text
trivially 
cuneiform     is another powerful open source ocr software
that we use  the algorithms used in cuneiform come from the rules
of writing letters and do not require pattern recognition learning 
it can recognize more than twenty different languages including
english  french  russian and etc 
in the usage of these two systems  we found following interesting
observations that inspire our work 

related work

ensemble learning     is a popular machine learning method 
which aggregates a set of individually trained classifiers  and make a
combined prediction  previous research has shown that an ensemble
is often more accurate than any of the single classifiers in the ensemble  our system is like this  to combine the two results of ocr
together and make one decision 
as a result of ensemble learning  ensemble systems  or known
as multiple classifier systems  have shown to produce favorable
results compared to those of single expert systems for a broad range
of applications under a variety of scenarios  in      it tells specifically the conditions under which ensemble based systems are more
beneficial than their single classifier counterparts  ensemble based
systems have advantages in statistics  large data utilizing  dividing
and conquering  etc 
in our case  different ocr softwares have different complex
algorithms  and it is impossible to merge them from inside  treating
them as white  boxes  however when we treat them as black boxes
and learn a ensemble system based on their outputs  we have a
significant chance to achieve an efficient error correction rate  thus
improving the overall accuracy of ocr 

  

model

fitable    error analysis
ocr
tesseract
tesseract
tesseract
tesseract
tesseract
tesseract
tesseract
cuneiform
cuneiform

figure    example of a word in the document

   

problem definition

to craft an ensemble ocr system  we start by modeling the ocraggregation task as a classification problem  for each word in the
document  ocrs will give options to this word  we can further
suggest more options by other means such as spell check tools  as
options as words can be in infinity space  we extract features from
all these options to serve as inputs for this word  denote k as the
number of options for a word  and treat k as constant  then we have
the following classification problem 
p roblem    documents  d  consist of words  w    for each
word w in w   k options are given by outputs of k ocrs 
each word has n features extracted from all its options  denote
n as the number of features  x    x    x            xn   is a set of features 
which is the input of the classifier 
our classifier outputs a label y      k      for each word  class
y   i  i      k   means that the ith option is the correct output for
this word  and y   k     means that none of the ocr outputs are
correct 
for example  for a word in the document shown in figure    our
option set is  pataeoctimatology  palaeoclimatology   where the
first option is given by cuneiform and second given by tesseract 
y     is the correct output label 

   

dataset selection

now that we have the classification problem  we need a dataset
to work on  however  getting accurately labeled scan of documents
for training is not trivial  we looked into iam dataset      which is
an labeled english handwritten collection  we tried to use our ocr
systems on these datasets  however we found that these open source
ocrs do an extremely bad job in handwritten images 
to better fit in our use case  we craft our own dataset by picking
three        words in total     pages each  geology papers and
hand  labeling them 

     

   

occurrence
  
  
  
 
 
 
 
  
 

feature design

recall that we have mapped the problem into a classification problem by extracting features of all options  the selection of features
is critical  we conduct an error analysis on our dataset  comparing
what errors do ocrs make independently  to indicate what features
are useful in the classification 

     

initial error analysis

in hand labeling process  we are able to analyze the errors that
ocrs individually make 
we output all the cases that ocrs give different answers  and list
the major ones in table   

     

features

based on errors in table    we design following features for
classification  note that these features are adopted to each option 
e g  dictvalid    and dictvalid    are two different features 
 w l i   word length 
 weboccur i   number of search result on internet 
 dictvalid i   whether option i is valid in dictionary 
 u pperpunish i     x x      where x is upper case percentage in the option 
 lowertou pperchange i   how many times in the option is
a lowercase character followed by an uppercase character 

data preprocessing

we managed to run a complex pre processing alignment algorithm to align each word in output of two ocrs  based on geometric
position  boxes  of words on documents  given by ocr systems 
after alignment  our dataset contains       words that are correctly
aligned 

     

error case
recognize fi as  
recognize fl as  
recognize rn as m
recognize rm as nn
recognize l as  
recognize j as  
recognize   as  
fail on all uppercase words  
recognize e as c

 count of each character occurrence  cntx  i   where
x   a  b  c          z  specialchars   and specialchars is characters like                  etc 
 count of occurrence of two consequent character  cntxy  i  
where x  y   a  b  c          z  specialchars  

hand labeling assumption

for most of aligned words  options given by tesseract and cuniform agreed with each other  we looked through them and cannot
find any error in them  to make sure  we checked the dictionary for
word correctness  and output the cases where words do not exist in
dictionary  however  we found that words outside dictionary are
actually valid words in geology domain  and are actually correct on
papers 
based on above observation  we make an assumption before handlabeling  outputs that are agreed by two ocrs are correct  this
dramatically reduces our workload to only      words  where ocrs
give different results 
this assumption also helps us in the classification task  for words
that options agree  we directly give the agreed output  only for
words that options do not agree  we run the classifier to judge which
options to output 

this gives us more than       features  which is larger than our
training set  to reduce the number of features  we only pick cntxy  i 
where combination xy appears in our error analysis  specifically  we
pick xy in fi  fl  rn  nn  rm 

  

algorithms

given the problem model and the feature set  we now have a
multi class classification problem  we try two learning algorithms
to achieve an ensemble system  softmax regression  and multi class
support vector machine 
to select most useful features and prevent overfitting  we implement a feature selection algorithm based on a forward search with
k fold cross validation 
  for

example  recognize eocene as eocene 

fitable    results of different classifiers and parameters
classification method
softmax  learning rate        
softmax  learning rate         
softmax  learning rate          decay         
svm  linear kernel   feature      
svm  polynomial kernel  degree       feature      
svm  polynomial kernel  degree       feature      
svm  gaussian kernel   feature      

            

accuracy
      
      
      
      
      
      
      

table    definite accuracy of different classifiers in terms of
output text
classifier
ensemble
cuneiform
tesseract
neither
total

figure    foward search result

table    most useful features
rank
 
 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  

   

feature
cnt     
cnt    
cnt rn    
cnt nn    
cnt nn    
cnt v    
weboccur   
weboccur   
cnt     
upperpunish   
cnt     
cnt rn   
cnt d   
cnt b   
cnt     
cnt q   
cnt     

feature selection

originally we set    features for classification  but too many
features cause overfitting and have high variance  to fix the variance 
we implement a forward search to select the most useful features 
we use k fold cross validation on the svm with linear kernel 
on a dataset of      examples  to greedily choose one feature with
most gain in accuracy in each iteration  figure   shows the result
of the forward search  we see that when    features are used for
svm instead of    features  we can get a higher accuracy of       
under svm with a linear kernel 
we list the most useful features for svm linear kernel  in table   
based on the order they are selected by the forward search  these
results are in accordance with our initial error analysis and our
feature design  e g  weboccur  upperpunish     cnt       cnt rn 
   are quite expected 

  

evaluation

in this section we evaluate the performance of our ensemble
system  we conduct softmax regression and multi class support
vector machine to train our classifier  on the dataset of      examples 
we use a k fold cross validation  and pick k      where each
partition contains     examples 
we choose different parameters on the two training algorithms to
experiment on  for softmax  we use different learning rates and also

 correct
   
   
   
   
    

accuracy
      
      
      
      
    

table    class distribution for softmax
data predicted
 
 
 
        
           
 
                  
 
     
           

observe what influence will be if we use the l  regularization on
the classification  for the support vector machine  we use different
kernels to test its result 
in table   we can see that different learning rates have some
influence on the softmax  while different kernels has small influence  l  regularization does not give us a good performance  and
different kernels has small influence on the accuracy of the cross
validation  among them  the support vector machine with the linear
kernel has the highest accuracy  and in conclusion  the accuracy
of support vector machine is apparently higher that the softmax
regression 
for softmax  we use all    features  for svm  we use the selected    features  decay refer to weight decay parameter in l 
regularization  in table   and table    we list the class distribution
for softmax and svm   row i  column j  stands for times when
data with real label i is has predicted label j  results show that
both system seldom have false positives in class    however  each
system has a relatively high number of false positives in class   
when one ocr has the right answer  class is   or     svm can
achieve a total of        precision  this exciting result indicates
that our system have quite high confidence of choosing the correct
output among two ocrs if one of them is correct  and the other is
incorrect  
another indicator shown in table   is that we have a total correction rate  definite accuracy  of         which means  the chance
that our system output the correct word  when two ocrs differ 
is over      while for two single ocrs  this chance is respectively
       and           these results show that our ensemble system
achieves significant improvement over the single systems 

  

improvement by suggestions

  note

that this accuracy do not count class   

fitable    class distribution for svm
data predicted
 
 
 
        
           
 
                  
 
     
           

table    class distribution for svm with   suggestions
data predicted
 
 
 
 
 

 
   
  
 
 
  

 
  
   
 
 
  

 
 
 
 
 
 

 
 
 
 
 
 

 
 
 
 
 
  

we further study ways to make suggestions to ocrs  to improve
the classifier granularity  previously when neither options are correct  the example is in class    with suggestions  the system may
have a better chance to give a right answer  and improve the overall
correction rate as shown in table   
for each word  its m suggestions are chosen from words appearing in our corpus      documents   according to the edit distance
    from options  and its word frequency in the corpus  suggestions
are different with each other 
the features for suggestions are 

   accuracy when choosing among three classes  cuneiform 
tesseract  and asserting neither of them is correct  is        
   output accuracy when two ocrs disagree with each other is
        while tesseract is         and cuneiform is        
our contribution includes  demonstrating the power of ensemble
ocr systems to significantly improve individual ocr quality  building on best open source ocrs and potentially creating a better
software for users  exploring the possibility to make use of domainspecific knowledge to craft a better ocr system 

acknolwegement

 corpusoccur  word frequency in corpus   this feature is
using the domain knowledge  

the authors would like to acknowledge professor andrew ng for
teaching the skills of machine learning and encouragements for the
projects  thanks to the teaching assistant kyle anderson for the
detailed feedback and useful advice of our proposal  thanks to
professor christopher re for providing us the data to enable this
work 

we create a labeled dataset of     examples with labels y      k  
m      and m      we train svm with polynomial kernel with
degree     using     features  it achieves        accuracy in cross
validation 
we further plot the class distribution in table    since our dataset
is relatively small in terms of class   and    there is inevitably
some overfitting  with a larger dataset  we can expect a better
performance 

future work

we want to study how to leverage domain knowledge to help our
task  currently we have studied a set of additional features with
domain knowledge  number of occurrence of option in the entire
corpus      documents   yet they do not increase the accuracy on
the basis of    selected features 
in the future  we are more interested to explore how to use domain
knowledge  can we have lexical and syntactical features using nlp
techniques  can we have semantic features using relations in the
domain knowledge base  can we use learning models with higher
expressiveness  such as statistical inference on factor graphs     
to model dependencies of predictions  in addition  we want to
automatically generate training silver rule examples using distant
supervision      making use of word level and sentence level rules 

  

   whole document output accuracy is         while tesseract
is         and cuneiform is        

 dist i   edit distance from each option i 

 w l  weboccur  dictvalid  as defined in section       

  

each other they should be correct  therefore our ensemble system
chooses among options when ocr results disagree with each other 
we select the known best open source ocr systems  cuneiform
and tesseract  we run these ocrs on our data corpus of     scanned
geo  science papers  align them word by word  and craft a handlabeled dataset of       words where outputs of ocrs disagree  out
of        aligned words 
we implement softmax regression and multi class svm to approach this classification problem  we conduct feature selection
with a forward search  and pick    best features for svm with linear
kernel  in our evaluation  we found that svm outperforms softmax
by about     
for a detailed performance of svm with    features 

conclusion

we study the methodology of ensemble learning on ocr systems 
by adopting learning algorithms on aligned output  our work is
based on the observation that open source ocr softwares make
independent errors  we assume that when ocr outputs agree with

  

references

    m  i  jordan  graphical models  statistical science  pages
             
    r  maclin and d  opitz  popular ensemble methods  an
empirical study  arxiv preprint arxiv                 
    u  v  marti and h  bunke  a full english sentence database for
off line handwriting recognition  in document analysis and
recognition        icdar    proceedings of the fifth
international conference on  pages         ieee       
    m  mintz  s  bills  r  snow  and d  jurafsky  distant
supervision for relation extraction without labeled data  in
proceedings of the joint conference of the   th annual
meeting of the acl and the  th international joint conference
on natural language processing of the afnlp  volume
  volume    pages           association for computational
linguistics       
    r  polikar  ensemble based systems in decision making 
circuits and systems magazine  ieee                  
    e  s  ristad and p  n  yianilos  learning string edit distance 
pattern analysis and machine intelligence  ieee transactions
on                     
    r  smith  an overview of the tesseract ocr engine  in
document analysis and recognition        icdar       ninth
international conference on  volume    pages         ieee 
     
    c  technologies  cuneiform ocr  http   en openocr org  

fi