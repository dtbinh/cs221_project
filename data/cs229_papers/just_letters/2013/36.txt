automatic colorization of grayscale images
austin sousa
rasoul kabirzadeh
patrick blaes
department of electrical engineering  stanford university

  introduction
ere exists a wealth of photographic images  from antique photography to low resolution video  which
lack color information  assigning color to a black and white image is a highly ill posed problem  given a
certain image  there is often no correct attainable color  for example  a red balloon is indistinguishable
from a blue balloon when photographed in black and white  due to the indeterminate nature of the
problem  image colorization techniques currently rely heavily on human interaction  several vintage
movies have been colorized entirely by hand  requiring every single frame to be inspected at great
financial and time cost     here we present a method  using machine learning techniques  to assign
aesthetically believable colors to black and white photographs  using a colormap selected from a similar
training image  e applications of such a method allow for a new appreciation of old  black and white
photographs and cinema  along with allowing better interpretation of modern grayscale images such as
those from cctv cameras  astronomical photography  or electron microscopy 

  description of method
current literature suggests two classes of colorization methods  one in which a color is assigned to an
individual pixel based on its intensity as learned from a color image with similar content  and another
in which the image is segmented into regions  each of which are then assigned a single hue  our
method uses the former approach  we analyze the color content of a provided training image  and
then attempt to predict colorization for a single target grayscale image on a per pixel basis  while
segmentation techniques have intrinsic appeal  and could result in more consistent colorization  these
methods rely on accurate image segmentation  which can be thrown o by shadows  texture  or color
gradients  furthermore  methods require subsequent manual identification of the objects in a scene 
couch  chair  etc   for which training color sets are then selected 
figure   shows block diagrams of the training and colorizing processes  training consists of  a 
transforming and discretizing the color space   b  selecting a subset of pixels to train on  c  extracting a
set of features from each pixel using the luminescence channel  and  d  training a set of binary classifiers
 one per each color  subsequently  colorizing a grayscale image consists of  a  extracting the same set
of features from each pixel   b  estimating the probability for each color at each pixel  and c  selecting
the color with the highest likelihood 
once probabilities have been assigned to each pixel  we then apply a graphcut algorithm  which
attempts to align color variation to intensity boundaries  we then apply a simple smoothing function
to further reduce color discontinuities  finally  the colormap is transformed back into rgb space 
resulting in a final image 
our method is implemented in python      using the numpy  scikit learn  and opencv libraries 
each of the processing steps is described below 
 

fitraining

training image
color space
conversion quantization
 k means 

extract features
at n random pixels

train svms
   vs  all 

colorized output

input image
extract features at
each pixel

colorization

pca

pca

svm
margins
for each color

graph cut
optimization

sobel filter

image edges

colormap

figure    here we show flowcharts illustrating the steps taken in our training and colorization pipelines 

   

color space discretization

each image in the set of training files is converted to the lab  luminance  a  b  color space  is
is used over rgb because euclidean distance in lab is more similar to how humans perceive color
dierences  e luminance channel becomes the grayscale image from which features are extracted 
color information is represented via the two   bit values  a b   allowing for      possible hues  we
then reduce the color space via k means to a manageable subset of colors  typically ranging between
  and     and store this color mapping for use by the final output step  once the reduced colormap
is selected  we quantize the training image or images  and randomly select a subset of training pixels 
typically      pixels from each    x    pixel image  or about      

   

feature extraction

at each pixel  we extract three parameter classes  surf  speeded up robust features   fft  and
localized mean and variance  surf descriptors for each pixel are extracted over three octaves  using a
  x   window  to this we add the magnitude of the  d fft over the same   x   grid  finally we
compute the mean and variance  resulting in an unwieldy     point feature vector  when training  we
then reduce the set of features from     points to    via pca 

   

classification

our classification system consists of a set of support vector machines  one per each bin of the discretized
color space  using a gaussian kernel  is array of svms performs a binary classification for each color
bin  predicting whether a pixel is or is not the corresponding color  is classification style is known as
 

fione vs  all multilabel classification  it should be noted  however  that in colorizing  we do not use the
simple true   false output of the svms  due to the inherent possibility of selecting more than one color 
or no color at all  instead  we use the margin of each svm as a proxy for the probability of each color
being the true color  ese probabilities are then used in post processing by the graphcut algorithm 

   

colorization process

colorizing begins by computing the same     point feature vector for each pixel in the grayscale image 
ese features are then projected onto the lower dimensional basis computed using pca in the training
step  each reduced feature vector is then passed to the set of svms from which we obtain the geometric
margin of the feature vector for each possible color  ese margins are used as a proxy for the conditional
probability of a given color given the local features  in order to include more global information  we
model the image as a markov random field in which nodes are given color labels and edge weights are
proportional to the image gradients  e graph cut algorithm is used to find the minimum energy
pixel labeling according to the following energy function at each pixel i
ei   



scj  vi    

j



gj   ci  cj    

jn  i 

in the first summation  scj  vi   is the geometric margin of the feature vector at pixel i  vi   for color
classifier cj   e second summation is over all neighbor pixels of i and includes the euclidean distance
in color space and gradient magnitude gj   is has the eect of snapping colored regions to edges in
the image  we used the graph cut implementation provided by the authors of      a median filter is
then used on the output to remove small patches of outlier colors in the image 

   

parameter optimization

for most images  there is a continuum of equally appropriate colors  as such  it is dicult to develop
an error metric that accurately indicates a pleasing image from an ugly one  for purposes of parameter
tuning  however  we incorporate a simple metric based on an images true color  we begin by converting
a color image to lab  and quantize its color channels using the k means color map selected in training 
we then predict a new colormap via our algorithm  and define the colorization error as the average
euclidean distance between the predicted and quantized true color colormaps  several parameters were
considered to be optimized  the number of color bins  the number of vectors kept by pca  the standard
deviation of the gaussian kernel and svm regularization parameter  the number of training examples 
and the surf window size  we performed several grid searches on various test images  using a compute
cluster and mpi  in most cases the minimum colorization error seemed to agree with the best looking
case  however the selected parameters varied from image to image  and failed to show obvious trends 

  results
our algorithm performs surprisingly well given the ill posed nature of the problem  figure   shows
example runs of the algorithm for dierent images  e general colors of the objects are all present  and
shows promise that realistic results are achievable  however  numerous improvements can be made 
currently our algorithm does reasonably well based on the features obtained from localized information surrounding individual pixels  however  aside from graphcut minimization  we have not
 

fiexplicitly used any features that contain global information about the image  e algorithm therefore
cannot distinguish between pixels that locally look similar but globally are from dierent objects  for
example  in the landscape scene   figure  c  our algorithm had diculty dierentiating flat mountain
faces from sky with slight clouds 
a simple way to incorporate global features would be to segment the image into broad regions such
as foreground and background  and then include this assignment as an additional feature  alternatively 
each segmented region of the image could be colorized independently  recombined  and processed via
graphcut 
for video colorization  we can provide a training image to the algorithm for the first shot of the
video  and then propagate colors to the subsequent frames  our initial attempts show promise  however
the algorithm lacks consistency from frame to frame  an improvement would be to incorporate some
regularization between adjacent frames  similarly  to limit the propagation of the errors to subsequent
frames  we could retrain the algorithm on some time interval  or when the scene changes 

  conclusion
our method shows promise in accurately applying color to grayscale images  and could likely be expanded to assist in the colorization of black and white films  e entire process of training and colorizing an    x    image takes between    and    minutes on a modern single core processor  since
much of the processing is independent for each pixel  the algorithm could easily be parallelized to run
on a compute cluster 
our project code is available here  https   github com prblaes imagecolorization

references
    y boykov  o veksler  and r zabih  fast approximate energy minimization via graph cuts  pattern
analysis and machine        
    a bugeau and v t ta  patch based image colorization  pattern recognition  icpr        
    a bugeau  v t ta  and n papadakis  variational exemplar based image colorization  pages    
march      
    g charpiat  machine learning methods for automatic image colorization  pages      october
     
    a delong  a osokin  h n isack  and y boykov  fast approximate energy minimization with
label costs  in computer vision and pattern recognition  cvpr        ieee conference on  pages
               
    s liu and x zhang  automatic grayscale image colorization using histogram regression  pattern
recognition letters       

 

fi 

 
 a 

 

 
 b 

 

 
 c 

 

 
 d 

 

 
 e 

figure    some select examples using our colorization method  panels  a   c  show reasonable performance on landscape scenes  we see  however  that in regions with few texture features such as the
mountains in  c   the algorithm becomes confused and colors them as if they were part of the sky  panel
 d  shows good performance on animal subjects  finally  in panel  e  we colorize a grayscale version of
the same image that was trained upon  we see almost no error in this case even though we only trained
on    of the pixels 
 

fi