a supervised approach to musical chord recognition

pranav rajpurkar
brad girardeau
takatoki migimatsu
stanford university  stanford  ca       usa

abstract
in this paper  we present a prototype of
an online tool for real time chord recognition  leveraging the capabilities of new web
technologies such as the web audio api 
and websockets  we use a hidden markov
model in conjunction with gaussian discriminant analysis for the classification task 
unlike approaches to collect data through
web scraping or training on hand labeled
song data  we generate symbolic chord data
programmatically  we improve the performance of the system by substituting standard
chroma features with a novel set of chroma
dct reduced log pitch features to push test
accuracy on clean data to         we finally propose a set of modifications to have
the system predict with speed and accuracy
in real time 

pranavsr stanford edu
bgirarde stanford edu
takatoki stanford edu

other machine learning tasks  the tasks of identifying
a song from its waveform data  and of classifying its
genre can be linked to finding the chord progressions
underlying its harmonic content  hand labelling chord
names and marking chord changes in a song takes a lot
of manual time and effort  an automated tool for this
process saves time  and allows the development of new
musical tools and research 
there has been progress in chord recognition research 
a few have built real time systems that have shown
to achieve promising results  fujishima        cho  
bello         however  these have not leveraged the
web to make a chord recognition system accessible online  we build a real time online chord recognition
system that makes use of modern html  capabilities
such as the webaudio api and websockets  and detail the offline training strategies and online challenges
posed by the novel adaptation 

   data generation
   introduction
there is significant value in an automated tool to determine chords from audio  knowing the progressions
of chords underlying the melodies is an essential part
of understanding  playing  and building on the music 
to a curious learner of music  such a tool creates the
opportunity to play a new pop song without meticulously hand labelled chord tags  equally useful to
a learner is being able to receive feedback concerning
the accuracy with which a chord was played  making
such a system a good automated feedback tool  capable of being plugged into an online music course  to a
song writer  the system is useful for exploring chords
supporting the melodic content of a song 
furthermore  the use of such a system extends into

chord prediction is a multiclass classification task  in
music  a chord is a set of notes played simultaneously 
we choose the minor and major chords  the two most
common sets of chords in popular music to classify on 
using the traditional twelve pitch scale  c  c   d 
d   e  f  f   g  g   a  a   b   we have    such
distinct chords 
there are different ways of playing the same chord 
the c major triad  for instance  is the set of three
notes c  e  and g played simultaneously  on a piano 
these chords can be played on different octaves  for
example  c major in the fourth octave would have the
notes c   e   and g   each chord also has inversions
defined by the lowest note of the chord   e   g   and
c  make up the first inversion of the same c major
chord  and g   c   e  make up the second inversion 
to train the system  we generate training data programmatically  this has been found to have advantages over hand labelling song data in its ability to

fia supervised approach to musical chord recognition

generate sufficient training data  k  lee         we
generate midi files for each of the    chords  taking
into account   octaves  and   inversion forms  to generate a total of     midi files  we then use an audio
synthesizer timidity   to convert the     generated midi files  in conjunction with   soundfonts for
piano  guitar  and violin  to generate a total of     
audio files in wav format 
in musical chord recognition  feature extraction operates over frames  the generated wav files  which
are an average of   seconds in length  are first split
into frames of window size    ms each  and an ndimensional feature vector is extracted for each frame 
we label each frame with the label of the chord on its
corresponding sound file  to generate        examples 
we use     of the data as our training set  and    
as our testing set 

table    accuracies for mfcc and chroma on the binary
classification task of distinguishing between major and minor chords
features
mfcc
chroma

test accuracy
     
     

features for the frames  muller   ewert         figure   shows the extracted chroma features for the c
major chord  the energy spikes at c  e  and g  the
notes constituting the c major chord  supporting the
idea that chroma features encode the harmonic content of a chord 

   paralleling speech recognition
the pipeline of a chord recognition system is similar
to that of a speech recognition one and relies on techniques that were originally applied to speech recognition tasks  the use of the hidden markov models
 young         and the division of a sound file into
frames on which the prediction task is performed  are
two such techniques which have been reproduced in
identifying chords  however  the task of finding chords
is also different from speech tasks in a few ways  and
these differences can be exploited to specialize a system in the task of chord recognition 
     feature extraction
one important difference between the two surfaces in
the choice of features for the tasks  mel frequency cepstrum coefficients  mfcc  have been the dominant
features in speech recognition systems  these represent the short term power spectrum of a sound  it has
been found that mfccs are closely related to timbre
  a characteristic that captures the quality or tone of
sound  e g   the tonal difference between an oboe and
a cello  since they discard the pitch content of the
sound  mfccs have traditionally been seen as poor
features for chord recognition  but are useful in setting a baseline benchmark for such a system 
chroma features are commonly used for chord recognition tasks  fujishima         it is a representation
in which the the entire spectrum of sound frequencies
is distributed into    bins representing the traditional
twelve pitch scale  an advantage of chroma features is
that they are invariant to octaves and inversions  we
use the matlab chroma toolbox to extract chroma

figure    chroma features for c major in various octaves
and inversions

to test the performance of chroma features against
mfcc features  we start with a binary classification
problem of distinguishing major chords from minor
chords  an svm with rbf kernel
k x  z    exp kx  yk   
is trained  with regularization and kernel parameters
      and c         table   summarizes the results 
and confirms that chroma features are much better
suited to the task of chord recognition than mfccs 

   initial models
     frame model
with chroma established as good features for the
chord recognition task  we can now extend to the multiclass classification problem of determining the exact

fia supervised approach to musical chord recognition
table    softmax regression frame model train and test
accuracies
set

accuracy

traning
testing

     
     

table    comparisons of accuracies of mixer models with
softmax frame model
figure    bayesian network of independence mixer model
model
middle frame
max count
independence mixer

test accuracy
    
     
     

chord played  we first use multinomial logistic regression  also called softmax regression  as our initial frame
model  the frame model is responsible for making predictions on individual frames  table   shows the accuracies achieved by the softmax classifier on the training
and test set 
     mixer model
our frame model outputs a prediction for each frame 
our final classification task  however  is on an audio
file  which consists of a sequence of f frames  let us
first make the simplifying assumption that a test sound
file consists of a single chord being played 
we now define a mixer model  which is a model for
collecting and using the results on individuals frames
outputted by the frame model  a simple mixer model 
the middle frame model  outputs the result for the
entire file based on the frame models output for middle frame in the file  another simple model  the
max count model  counts the most frequent prediction made across all of the frames 
consider another such model  we call the independence mixer model  which assumes that the prediction on each frame is independent of the prediction on
other frames  the probability that chord y is the single
chord played in the file is calculated by considering the
probability that y is the chord played at each frame 
for a test example  our predicted output is yp  
qf
argmaxp y x    p y x    x       xf     i   p y xi   
y

note that each p y xi   is given by our softmax frame
model  the accuracies achieved with different mixer
models are summarized in table   

table    gda frame model accuracies
set

accuracy

traning
testing

     
     

   improved models
     improved frame model
softmax regression is a learning algorithm that models
p y x   the conditional distribution of the chord given
the extracted frame features  we now look at a frame
model that tries to model p x y  and p y   gaussian
discriminant analysis  gda   jiang et al          we
assume all of the gaussians share the same covariance
matrix  x y   i  n  i      furthermore  since we
aim to make the system independent of any specific
genre  we model p y          a model in which all
chords are equally likely  table   summarizes the classification accuracies 
     improved mixer model
earlier  we had imposed the constraint that chords
could not change in a wav file  our next model allows us to drop that constraint  we now use a hidden
markov model hmm  to predict the chord sequence
in sound files  allowing us to determine chord changes
in a file  a  sheh        
firstly  we use our our gda frame model to model the
emission probabilities p x y  for the hmm  while state
transitions for the hmms are usually learned in chord
recognition tasks  k  lee         since each genre of
music has a different distribution of transitions  assuming uniform state transitions allows us to remain
flexible to any genre of music  we determine the most
likely state sequence by viterbi decoding  table  
summarizes the accuracies achieved by the improved

fia supervised approach to musical chord recognition

figure    hidden markov model to determine most likely
chord state sequences

table    hmm accuracies training and testing on different
data sets
training data
piano
piano
piano
all

testing data

accuracy

piano
guitar
violin
all

      
      
      
      

mixer model trained and tested on different sets of instruments 
figure   shows the confusion matrix for the mixer
model trained and tested on generated piano audio 
the most common misclassifications are ones between
major chords and the corresponding minor chords 
this is explained by the fact that a major and a minor
chord of the same key have two out of three notes in
common 

   improving features
chroma features  in their invariance to octave and inversions  make good features for the chord recognition
task  to boost the accuracy further would require features invariant of instruments  crp  chroma dctreduced log pitch  has been recently introduced as
a chroma based audio feature that boosts the degree
of timbre invariance  jiang et al          the general
idea is to extract chroma features  and then discard
timbre related information similar to that expressed
by mfccs  in effect leaving the information related
to pitch  table   summarizes the accuracies achieved
by the new crp features in relation to the chroma
features 

figure    confusion matrix for hmm training and testing
on piano

table    new scores after replacing chroma with crp
training data

testing data

accuracy

piano
guitar
violin
all

      
      
      
      

piano
piano
piano
all

   live system considerations
our real time system makes use of the web audio api
to capture live audio  every    ms  we encode the
audio in wav format  and transfer it to a server using
websockets  we then extract features for every    ms
frame in the wav file  and predict the most likely
chord sequence in the    ms using the hmm 
     handling noise
a live online system  while pushing the extents of possible uses of the system  presents new challenges for
chord recognition  one of the most important considerations for a live system to take into account is noise 
it is ideal for a system to not predict any chord in
when there are no chords being played 
once the hmm returns that most likely chord sequence  we are able to determine whether the    ms
segment is a noise or a chord  using the knowledge that it usually takes a few seconds before chords

fia supervised approach to musical chord recognition

els  technical report  labrosa  columbia university       
cho  t  and bello  j  p  real time implementation
of hmm based chord estimation in musical audio 
technical report  music and audio research laboratory  new york university       
fujishima  t  realtime chord recognition of musical
sound  a system using common lisp music  in proceedings of the      international computer music
conference  icmc        pp               
jiang  n   p  grosche  v  konz  and muller  m  analyzing chroma feature types for automated chord
recognition  technical report  saarland university
and mpi informatik       
figure    crp vs  chroma features for different instruments  note the invariance of crp to instruments 

k  lee  m  slanley  automatic chord recognition from
audio using a supervised hmm trained with audiofrom symbolic data  technical report  ccrma 
stanford university       

change  we can then post process the output by looking at the number of times chord changes were predicted by the hmm in the    ms segment  if any
chord lasts for more than    ms in the prediction  then
we output the chord as our prediction for the    ms
segment  otherwise  we understand that segment of
sound as consisting of noise 

muller  m  and ewert  s  chroma toolbox  matlab
implementations for extracting variants of chromabased audio features  in proceedings of the international conference on musical information retrieval
 ismir        

   ms was found to be the optimal time interval over
which to process the audio  increasing the interval for
collecting the recording from    ms was found to create a noticeable delay in the live system  on the other
hand  reducing the window time not only decreased accuracy  but also made it harder to distinguish between
noise and chords 

   conclusion
in this paper  we present an implementation of an online  real time chord recognition system using modern
web technologies  we show the effectiveness of hidden
markov models with gaussian emissions in classifying
chords  furthermore  we show how timbre invariant
crp features can improve robustness compared to
chroma  finally  we detail a strategy for noise detection to create an effective live recognition system 
with this system  we improve the feasibility of live automatic chord recognition  and pave the way for making this technology more accessible to the public 

references
a  sheh  d  p w  ellis  chord segmentation and
recognition using em trained hidden markov mod 

young  s  j  the htk hidden markov model toolkit 
design and philosophy  technical report  entropic
cambridge research laboratory  ltd       

fi