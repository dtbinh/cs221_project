yelp food recommendation system
sumedh sawant

gina pai

stanford university
sumedh stanford edu

stanford university
gpai stanford edu

abstractwe apply principles and techniques of recommendation systems to develop a predictive model of customers
restaurant ratings  using yelps dataset  we extract collaborative and content based features to identify customer and
restaurant profiles  in particular  we implement singular value
decomposition  hybrid cascade of k nearest neighbor clustering 
weighted bi partite graph projection  and several other learning
algorithms  using root metrics mean squared error and mean
absolute error  we then evaluate and compare the algorithms
performances 

i 

i ntroduction

a vast database of reviews  ratings  and general information
provided by the community about businesses  yelp provides
consumers with a myriad of options and information even
when searching for an especially specific service or goods
niche  however  although all required information may be
present to make an informed choice  it is often still difficult
by just looking at the raw data  reading all the reviews of
a single business alone is time consuming and requires more
effort than the average user is willing to expend  as a result 
we believe users could greatly benefit from a recommendation
system 
recommendation systems have historically been created
for various machine learning applications in numerous disciplines  one such example is social networking sites such
as facebook that utilize recommendation systems to suggest friendships to users  music and media applications such
as itunes and spotify also utilize similar machine learning
and recommendation logic to suggest various songs  videos 
movies  etc  to users based off their previous choices and
taste  given this general theme  our project focuses on creating
a recommendation system for yelp users in application to
potential food choices they could make 
the rise of the popular review site yelp has led to an influx
in data on peoples preferences and personalities when it comes
to being a modern consumer  recommendation systems that
can identify a users preferences and identify other similar
users and or restaurants that match his her preferences can
make this problem easier  specifically  we aim to build a recommendation system that will enable us to make sophisticated
food recommendations for yelp users by applying learning
algorithms to develop a predictive model of customers restaurant ratings 
we begin by providing a brief explanation of the dataset
we used while creating our recommendation system  we follow
this with an explanation of the performance metrics we used
to evaluate our results  we provide an explanation of our
baseline algorithm and its performance  the algorithms we implemented  and the processes we used during our development 

finally  we conclude with a discussion of future work that
could be explored 
ii 

dataset

our primary dataset is the yelp dataset challenge data
 http   www yelp com dataset challenge   that contains actual
business  user  and users review data from the greater phoenix 
az metropolitan area  after filtering the data for food related
businesses and reviews  there remain          businesses 
           reviews  and           users who gave food
reviews  by using and combining various data fields  we
identify both similar businesses and users to aggregate the
likely sparse ratings per average user 
iii 

e valuation m etric

after researching the kinds of evaluation metrics prevalently used to evaluate recommendation systems  we chose
to evaluate our system based on the root mean square error
 rmse  and the mean absolute error  mae  metrics through
k fold cross validation  as the microsoft research paper    
on evaluating recommendation systems argues  both root mean
squared error and mean absolute error are popular and highlyaccurate metrics historically used to measure the performance
of a recommendation system that aims to predict the rating
   to   stars in yelp  that a particular user would give to an
item  just as the     states  during our performance evaluation
we assume that our system will generate predicted ratings rbuf
for a particular user u and food restaurant location f from our
training set s of data  where we know what the actual ratings
ruf are   given this  rmse error is given by 
rmse  

s

x

 
 s 

 b
ruf  ruf   

 u f  s

also  mae error is given by 
s
x
 
mae    s 
 b
ruf  ruf  
 u f  s

iv 

baseline

for our baseline  we adopted a similar approach to the
at t collaborative filtering paper     in particular  we predicted the rating rbu f of a particular user u for a restaurant f
as rb      bu   bf where  is the average rating of restaurants
by all users  bu is the difference of user us average rating from
  and bi is the difference of restaurant f s average rating from

fi  in order to make baseline recommendations we calculate rb
in this manner for all of the restaurants that a user has not
reviewed  sort the ratings from greatest to least and output the
top     
v 

s ingular value d ecomposition

we applied singular value decomposition    as suggested in
the recommender systems article     to reduce dimensionality
of the feature space and make predictions  svd is a technique
used to factor some matrix x into three matrices u    v t
where  is a diagonal matrix with the singular values of
x on its diagonal and u and v are orthogonal  formally 
svd factors x   u v t   following the approach from     
we created design matrix x where each row represented a
user  each column a business  and each entry the rating the
user gave the business  for empty entries with no ratings  we
populated it with the average rating for the particular business
represented by the column  we then ran svd on this matrix
b to
x to get u    v t and reformulated an approximation x
x by keeping only the first k singular values in   made it
k by k and modified u and v t accordingly  and computed
b   u v t   our predicted rating rbu i was the corresponding
x
bu i  
entry in the matrix x
vi 

h ybrid c ascade of k nn

a  k nearest neighbors clustering on businesses
the sparseness of ratings per user user makes it very
unlikely that any two users had rated the same restaurant  as
a result  calculating similarities based solely on shared ratings
would likely result in severe over and under estimations  thus
in order to account for this issue and build a reasonably
accurate prediction algorithm  we first clustered the restaurants
using knowledge technique  first we formed a category hierarchy by specificity using our understanding of the topics
in order to cluster businesses using only its most specific
categories  general categories such as ethnic food are located
at the top of the tree and are parent to those of more specific
categories such as falafel at the bottom of the tree  here is
a sample of the category hierarchy we generated 

initial clusters  we ran k nearest neighbor clustering algorithm
with    fold cross validation using a combination similarity
function of number of users who rated both businesses and
the similarity of those ratings 
b  k nearest neighbors clustering on users
using the results from knn clustering on restaurants  we
changed  and slightly reduced  the feature space of our users
by mapping each feature that they had that was specific to a
business to a particular business cluster  this enabled us to
ensure that a majority of the possible pairs of users had some
common particular business cluster that they had both rated 
ultimately allowing us to more accurately calculate similarity
between users  thus once we had created this new input feature
space of users  we ran k nearest neighbors with    fold cross
validation on the users to group them into clusters of similar
users using a similarity function based on the similarity of the
ratings 
once using hybrid cascading to create the similar user
clusters  to predict a rating rbu f of a particular business f
for a user u  average together all of the clusters ratings
for the business cluster  first we mapped the business to its
specific cluster cf   next  we checked which users in the cluster
cu of user u had rated food from businesses in cluster cf
and averaged together all of the ratings  this served as our
predicted rating for user u for the business f  
rbu f  

 
 rcu  cf  

x

k

krcu  cf

in the expression above  rcu  cf is the set of all ratings by
users in cu of businesses in cf   the results of implementing
this prediction system are given below in the results section 
to generate recommendations for a user using this final
model  predict ratings in a similar fashion on all businesses
the user had not reviewed yet and output the ones that yield
the highest rating  
vii 

w eighted b i partite g raph p rojection

by utilizing our representation of the yelp dataset as a
weighted bipartite graph where edges from user to business
are weighted by rating  we posed the recommendation problem
as graph projection by using the same novel network basedinference collaborative filtering algorithm that was proposed
by     and originally created by      more specifically we followed a network based resource allocation process to produce
similarity measures  which can be thought of as weights in
a bipartite graph projection  between every pair of users and
every pair of food businesses  which are then used to produce
predicted ratings and recommendations 

using our understanding of the category semantics  we next
grouped the food categories by theme  dietary restrictions 
asian  etc   and clustered businesses by the group they share
the most number of categories with  after forming these

we used a neighborhood based collaborative filtering approach with our novel similarity function based off network inference in order to make predictions  we chose to only explain
the user based approach to neighborhood collaborative filtering
here since the food business version would be mathematically
equivalent  thus  our user based collaborative recommendation
approach aims to calculate some similarity metric between all

fipairs of users and then predict a particular user us rating for
a food business b by collecting and processing the ratings for
b of us neighborhood  all the other users with high similarity
as compared to u   formally  we first calculated and stored
the value of some similarity metric between any two pair of
users  and then computed the prediction of the rating of user
u towards a food business b by computing a weighted average
of us neighbors ratings of b  the weights are the similarity
between u and each neighbor  this is expressed as       

rbu b   ru   

n
x

sim u  j  rj b  rj  

j  

ru  

 
bu

x

ru j

jbu

here ru is the average rating given by user u  bu above is
the set of food businesses on which user u voted   sim u  j 
is the similarity measure between user u and user j   is a
normalizing factor so that the absolute values of the similarity
metrics sum to    and ru b is the actual rating given by user
u to business b  note that this is different from rbu b which is
the predicted rating  
we defined a new sim x  y  function called recommendation power  as     states  the weight wij in a weighted
bipartite graph projection can be thought of as how important
node j is to node i  thus wij   wji does not always hold  
we can intuitively think of this as each user giving his or
her neighbors some amount of recommendation power that
they in turn can use to recommend food businesses  the more
recommendation power that a user has  the more powerful
or influential his or her recommendation is to the original user
who gave them that power 
in order to formalize this notion of distributing the recommendation power  or resource   as done in     we can
consider a   step random walk on the yelp bipartite graph
where we walk   steps starting from some user node  going to a
business node  and coming back to a different user node  each
step that we take has some transition probability of occurring 
intuitively  for the first step in this process we can think of a
user as being more likely to give a particular food business
some of his or her resource if the user rated that business
highly  thus we can think of the probability of the transition
r
where ru b is the
from user u to food business b as being ru b
u
rating that user u gave food business b and ru is the sum of
ratings that user u ever gave  similarly  we can think of a food
business b as being more likely to give a user v some of the
resource it received if user v rated food business b highly  thus
we can think of the probability of the transition from business
r
b to user v as being rv b
where rv b is the rating that user v
b
gave business b and rb is the sum of ratings that business b
r
rv b
ever received  thus the value ru b
is the probability of a
u rb
transition from user u to a particular food business b and back
to user v  and thus the amount of recommendation power or
resource that user v receives from user u through business b
in the network   since user u distributes resource to all of the
r
rv b
represents the amount
businesses and the expression ru b
u rb
of resource user v receives from user u from one particular
food business  we can sum over all businesses to get the total

amount of resource that user v receives from user u  thus we
have that
rp u  v   

x ru b rv b
ru rb

bb

thus  substituting into our formula from above for collaborative filtering  a prediction rbu b of a user
xus rating for a food
business b can be made as rbu b   ru  
rp u  v  rv b  rv  
x
vu
ru b   also notice that      in the forwhere ru   b u
bbu

mula since

x

rp u  j      due to the probabilistic properties

vu

of rp u  v   we used this approach to make recommendations
for our system 
viii 

c lustered w eighted b i partite g raph
p rojection

while the weighted bipartite graph projection algorithm
above improved our prediction accuracy  our dataset suffered
from a sparseness problem  in essence  the bipartite graph representation did not have many scenarios where two users had
rated the same food business  the weighted bipartite graph
projection algorithm was not robust to this and ultimately
lost some accuracy since the similarity measures it calculated
depended on the dataset having many scenarios where two
users had rated the same business  in order to improve upon
this and the general accuracy of the algorithm we created an
experimental learning algorithm algorithm that is an extension
called clustered weighted bipartite graph projection 
  

use the k means clustering algorithm using
the recommendation power metric as similarity
difference  instead of the norm  to partition the users
into a set cu of k  user clusters and partition the
businesses into a set cb of k  business clusters 

  

construct a compressed version g  of the original
bipartite graph g by creating a set of nodes
representing each cu user cluster and a set of nodes
representing each cb cluster  an edge from a node
representing cluster cu to a node representing cluster
cb exists if any user from cu ever rated a business
in cb  

  

run the same weighted bipartite project algorithm
from     on the compressed graph g  and predict the
rating that a user u would give a business b by simply
considering the rating that the node cu would give
the node cb in the compressed graph 

in this experiment  we found that with the right amount of
clustering on the dataset  the intolerance to sparseness by the
weighted bipartite graph projection algorithm above could
be combated by essentially transforming our sparse dataset
into our own non sparse definition through some similarity
mapping and grouping  once we had a non sparse dataset 
the weighted bipartite graph projection algorithm above
worked just as it should and gave very accurate results 

fiwe experimented with the values k    k    which were the
number of user clusters and business clusters respectively 
when we had a really few amount of clusters  we were not
capturing enough of the differences between each of the users
 or businesses  and thus underfit the data  as we created more
and more clusters by increasing k    k    we captured more
and more of the datas specifics and thus were able to make
better recommendations  eventually we reached some critical
point where we had created the optimal number of clusters
to drive down the error  if we created any more clusters than
the optimal amount  we approached the scenario where the
clusters were so small that we started to capture the really
minor differences between the users and treated them as huge
differences in making recommendations  thus by making more
than the optimal amount of clusters  we overfitted the dataset
and started to increase the error metric  the user cluster
amount k  had a higher optimal value than the business cluster
amount k  because there were more users than businesses
in the dataset and there was more variance in the type of
user  thus we needed more clusters to optimally capture the
different types of users than we did to optimally capture the
different types of businesses 
ix 

m ulti  s tep r andom walk w eighted b i partite
g raph p rojection

the weighted bipartite graph projection algorithm that
we use in this paper was derived from using a   step random
walk on the bipartite graph to allocate the recommendation
power of a user u to another user v  however instead of
just using a   step random walk  in this experiment we
used a summation of the results of multiple random walks
   step    step         k step where k is an even number greater
than    where the starting point of each walk is always a
particular node u and the ending point of each walk is always
a particular node v  each walk contributes a little bit of
recommendation power to v from u   thus mathematically
we had 
 x r

x ru b rv b
u b  rk   b  rk   b  rv b 
rp u  v   
 
 
ru rb
ru rb  rk  rb 
b   b  b
 xbbr

u b  rk   b  rk   b  rk   b  rk   b  rv b 
 
 
ru rb  rk  rb  rk  rb 
b   b  
b
x
rk  b rv bn 
ru b  rk   b 
        n
      n  n
ru rb 
rkn  rbn
b       bn b

note that in the equation above n   k       also
k            kn represent arbitrary users in our network  also   is
a decaying factor that
xis applied to the result of each random
walk to ensure that
rp u  j       using this new definition
vu

of rp u  v  as our new similarity function  a prediction rbu b
of a user us
made as
xrating for a food business b can be x
rbu b   ru  
rp u  v  rv b  rv   where ru   b u
ru b  
vu

bbu

because the multi step random walk approach involved the
summation of the results of multiple random walks  it was
extremely inefficient to compute  looking at the mathematical

expression for the recommendation power between two users
 or equivalently food businesses   we can see that a k step
random walk involves a summation over k      different
combinations of user  or food business  variables  making its
time complexity o nk      since we need to iterate over the
entire set of users  or businesses  for every variable in the
summation bounds  this can be extremely expensive on large
datasets  in essence  we wanted to avoid having to calculate
random walks for large values of k for our yelp dataset  thus
we simply looked at the value of k on the graph above where
the error started to converge and used that value of k as our
most accurate k value  we ran several trials of these multistep random walks  each with a different value of k  to make
recommendations and measured the rmse and mae error  we
found that the error values dropped and tended to converge
after about k      iterations  so when we actually ran this
algorithm and displayed its results below  we used a value of
k      
x 

c ascaded c lustered m ulti  s tep w eighted
b i partite g raph p rojection

we also implemented a hybrid version of the previous two
mentioned algorithms by trying to take advantage of both types
of strategies for making the weighted bipartite graph projection
algorithm better  thus we proceed as follows 
  

use the k means clustering algorithm using
the recommendation power metric as similarity
difference  instead of the norm  to partition the users
into a set cu of k  user clusters and partition the
businesses into a set cb of k  business clusters 

  

construct a compressed version g  of the original
bipartite graph g by creating a set of nodes
representing each cu user cluster and a set of nodes
representing each cb cluster  an edge from a node
representing cluster cu to a node representing cluster
cb exists if any user from cu ever rated a business
in cb  

  

run the multi step random walk based algorithm
from above on the compressed graph to make predictions 

when implementing this algorithm  after we had generated
the compressed graph  we ran several trials of the multi step
random walks  each with a different value of k  to make
recommendations and measured the rmse and mae error 
we found that the error values dropped and tended to converge
after about k     iterations  so when we actually ran this
algorithm and displayed its results below  we used a value
of k      this algorithm was more accurate than either
of the individual algorithms it was based on since we took
advantage of the fact that the compressed graph accounts
for the sparseness of the graph  and consequently that the
similarity measure between two entities on the compressed
graph means more than it did with the original graph  because
of this  as we continued to improve the similarity measure
to be more and more accurate on the compressed graph by
using the combined results of multi step random walks  we got
recommendations that were even more accurate than before 
effectively combining the sparseness fighting effects of clus 

fitering and the similarity precision of multi step random walks
in order to collaboratively create a very accurate prediction
model 
xi 

r esults

here are the results from running each implemented algorithm on our dataset  as mentioned above  we used k fold
cross validation to evaluate the error of the recommendation
system for each algorithm in terms of rmse and mae 

to make accurate predictions 
xii 

f uture w ork

in the future  we would augment the current analysis to
include review text and user rating evaluations  whether other
users thought a particular users review was funny  useful 
or helpful  as features in the prediction model  we would
also explore further hybrid approaches and evaluate their
performances 
r eferences
   
   
   
   

   

   
   

   

as we can see from the results  the cascaded clustered
multi step weighted bipartite graph projection algorithm
performs the best of all the algorithms  both combating the
sparseness of the dataset and utilizing network based inference

burke  r   hybrid recommender systems  survey and experiments 
 http   josquin cs depaul edu  rburke pubs burke umuai   pdf  
gunawardana a   shani g  evaluating recommendation systems 
 http   research microsoft com pubs        evaluationmetrics tr pdf  
wikipedia  singular value decomposition   http   en wikipedia org 
wiki singular value decomposition  
recommender systems  dimensionality reduction and the singular value decomposition   http   www cs carleton edu cs comps      
recommend recommender svd html  
koren  y   factorization meets the neighborhood  a multifaceted collaborative filtering model   http   public research att com volinsky 
netflix kdd  koren pdf  
zhou  t   et al   bipartite network projection and personal recommendation  physical review e                  
shang  m   fu  y   chen  d   personal recommendation using weighted
bipartite graph projection  apperceiving computing and intelligence
analysis        icacia       international conference on   vol   no  
pp                dec      
breese  j s   heckerman  d   kadie  c   empirical analysis of predictive
algorithms for collaborative filtering   http   research microsoft com 
pubs       tr       pdf 

fi