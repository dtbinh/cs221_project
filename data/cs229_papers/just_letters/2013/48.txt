using low cost remote sensing data to detect
building collapse in post earthquake environments
cs     final project report

shaun benjamin

 

henry corrigan gibbs

steven wong

introduction

the scale and suddenness of natural disasters
render post disaster relief efforts difficult 
for
earthquakes in particular  being able to map the
distribution of damage quickly and with confidence
can help channel appropriate aid to the most severely
impacted regions  accurate mapping can also aid
in determining whether citizens can return safely to
their homes  so as to prevent casualties from delayed
building collapses 
there are generally two broad types of postdisaster damage surveys for earthquakes  field based
surveys and remote sensing based surveys  fieldbased surveys involve having experts physically visit
each individual building to assign it a damage level 
field based surveys are thus time consuming and
resource intensive  in contrast  remote sensing based
surveys usually involve a panel of experts looking over
aerial or satellite imageries to estimate if buildings in
the images have collapsed or not  remote sensingbased surveys thus save time but have a greater
degree of error 

figure    a topographical map of haiti with the
geographical areas included in our data set marked
in black 

 

data sources

the      earthquake in haiti devastated the areas in
and around the haitian capital of port au prince  in
the wake of the earthquake  disaster relief agencies
collected extensive data on building collapse and we
have obtained two such data sets from colleagues
at stanford  these data sets divide the affected
geographical area into geograhpical grid cells  and
the data tables contain information on the fraction
of buildings in each cell which collapsed in the
earthquake 

in this project we attempt to use machine learning
techniques to identify collapsed buildings in satellite
photos by applying supervised learning techniques
to improve remote sensing damage estimates  our
target variable is the field based damage assessment 
and the features are the satellite based damage
assessment combined with relevant external data
 e g   earthquake epicenter  elevation  population
density  per capita income  

one data set contains information drawn from
the expensive field based damage survey  another
using the machine learning techniques we develop data set contains remote sensing data derived from
here  future disaster relief professionals might be able satellite imagery 
these two data sets contain
to use a more limited field based damage assessment  information on a total of        geographical cells 
in combination with remote sensing based data  to with each cell measuring    meters     meters 
identify highly damaged areas more quickly and at since the field based and remote sensing data sets use
lower cost 
slightly different grid layouts  we had to merge the
two disparate data sets into a resized geographical
grid  which left us with        adjusted grid cells 

 

fifigure   shows the geographical areas of haiti covered
by our data sets  which are also the areas most
affected by the earthquake 

latitude  degrees 

soil capacity    excellent    limited 

in addition to these closed source datasets  we
collected features on haitis physical characteristics
and on seismic measurements from the     
earthquake event 
from the world bank 
via haitidata org      we obtained estimates of
the probability that the peak ground velocity
 earthquake intensity  will exceed a given level within
the next    years  in other words  this data set is an
estimate of the earthquake risk of each geographical
grid cell  based on the path of fault lines and other
geological features  e g   figure     we also collected
data on the soil capacity  level of ground erosion 
flood potential  and geomorphology for each area
of our geographical grid  from the u s  geological
survey      we collected measurements of the actual
peak ground velocity and acceleration during the
     haiti earthquake 

    
    
    
    
  

    

  

    

  

    

longitude  degrees 

latitude  degrees 

 

 

 
 
 
 
peak ground acceleration  g 

 

 

    
    
    
    
  

    

  

    

  

    

longitude  degrees 

latitude  degrees 

   

   

   
   
distance to road  meters 

   

   

    
    
    
    
  

    

  

    

  

    

longitude  degrees 

standardizing these disparate data setseach
of which uses different formatting conventions 
geographical projections  and cell sizestook much
longer than we had anticipated  we used esris
arcmap software package to approximate their
spatial relationships between the different grid cells
and to spatially join their values  in particular  we

  

   

   

   

figure   
soil capacity  top   peak ground
acceleration  middle   and distance to nearest road
 bottom   as recorded in our data set
that support vector machine  svm      and random
forest  rf      classifiers would both be applicable
algorithms  these two algorithms are particularly
convenient to use because there are a number of opensource svm and rf implementations which are easy
to integrate into our matlab application in an offthe shelf manner 

   scaled and translated the imported data
cells coordinates to approximately match our
coordinate system  and
   matched imported rows to the nearest training
example  geographical grid cell  in our data set 

our experiments used the built in matlab svm
classifier  the libsvm     classifier  and the
randomforest matlab     classifier  to tune the
parameters of our classifiers  we used hold out cross
after combining our closed source data set obtained
validation  we trained the classifier on roughly    
from colleagues at stanford with open source
of our examples and tested on the remaining     
geographical data sets available online  we imported
the harmonized master data set into matlab for we also experimented with using pca and ica
to reduce the dimensionality of our examples to
analysis 
improve the performance of our classifiers 
to
we expected the labels of our data set to have a nonimplement pca and ica  we used the matlab
linear relationship with many of the features  for
pca implementation and the fastica     ica
example  the probability that a particular grid cell
toolkit 
contains a collapsed building dramatically increases
when conditioned on the fact that the cell lies inside since our data set actually contains the number of
of port au prince  though the relationship between collapsed buildings in each geographical grid cell 
we converted these multi class labels into binary
grid latitude and collapse probability is non linear 
labels by marking geographical cells with at least
since we wanted to perform supervised learning on
one collapsed building with a   and cells without
a data set with many non linearities  we concluded
any collapsed buildings with a    since some

 

methods

 

fiof our geological features used numerical codes to
indicate enum like values    grassland    forest 
  urban  etc    we converted each of these features
into an array of binary indicator values  i e  
  not grassland    grassland   finally  to speed
up the training and testing process  we removed
cells from the data set that were so far from the
earthquake affected area that they could not possibly
have sustained damage from it 

   
libsvm test
libsvm training
msvm test
msvm training
rf test
rf training

   
   

error

   
   
   
   
   

 

 

results

    

    

              
training set size

    

    

    

figure    training and test error of the classifiers
when trained on a varying number of examples and
tested on the remaining examples 

this section summarizes the results of the experimental evaluation of our classifiers 

support vector machines versus
random forests

   
train test time  seconds 

   

 

   

libsvm
msvm
rf

we first compare the two svm classifiers  libsvm
   
and matlab  and the random forest classifier 
since we expect that many of our features will have
   
have non linear correlations to our labels  we chose to
use a gaussian kernel with the svms  for the sake
   
of completeness  we also experimented with using a
linear kernel  but found that the svm classifier often
 
 
    
    
    
    
failed to converge upon a feasible decision boundary 
training set size
even when using a relatively aggressive soft margin
classifier 
figure    running time for each of the three
figure   shows the training and test error of classifiers as training set size increases 
our three classifiers when trained on a varying
number of the examples in our data set  selected svm algorithm exhibits a dramatic slowdown
at random  and when tested on the remaining taking more than   as long to run than the random
training examples  even after tuning the parameters forest classifier an more than   as long as the
of both svm algorithms  the built in matlab libsvm classifier 
svm implementation consistently outperforms the
since the random forest classifier performed the
libsvm implementation by roughly      the
best in terms of both test error and running time 
random forest classifier outperforms the matlab
we provide an additional analysis of the how the
svm classifier at all training set sizes by slightly over
random forest parameters affect the accuracy of the
    at the largest training set size        examples  
classifier  figure   demontrates how the test error
the test error of the random forest classifier is just
of the classifier varies as the number of trees in the
under      though in some cases the error of the
forest and the number of splitting features used at
random forest classifier dipped down to closer to     
each tree node vary  as the number of trees and
figure   demonstrates the performance of each of splitting dimensions increases  the marginal benefit
the three classifiers  as measured by the time taken of increasing these parameters decreases and the
to train on the given number of rows and to test running time increases  we set both values to     as
on the remainder of the data set  at training set a compromise between training speed and classifier
sizes of under       examples  the matlab svm accuracy 
outperforms both classifiers  as the training set
table   summarizes the best observed performance
size increases past       examples  the matlab
of each of the three classifiers  the random forest

 

fitest
training

   

   
    
   

error

splitting dimensions

   

 
 
 
  
  
  
   
   
   
    

   

    
 

 

 

   

                        
number of trees

   

figure    test error while varying the number of trees
and number of features used to split at each tree node 
classifier
nave remote sensing
libsvm
matlab svm
random forest

accuracy
     
     
     
     

 

advantage
  
     
    
    

 

 
 
number of features

 

  

figure    test error on a fixed size subset of the
data set while performing forward search to identify
a useful subset of features 
   

table    summary of accuracy of the classifiers used
in this study 

    

classifier achieves an    improvement over using only
remote sensing data to predict building collapse 

   

 

ica error
pca error
unmodified

error

   

feature selection

    
   

    
we implemented forward search to select a subset of
features which has the greatest impact on test error 
   
figure   shows that using a single feature  the number
 
  
  
  
  
  
  
of buildings collapsed as detected by the remotedimensions components
sensing based survey  the classifier is able to achieve a
test error of just above      the subsequent features figure    test error while varying the number
which reduced the test error the most were  in order   of components used to train the classifier  the
unmodified line shows the baseline error without
   soil quality 
pca or ica 

   the dense forest indicator variable 
and thus  the data set contains many training
examples  for example  a          kilometer region
with grid cell resolution of    meters would have
            grid cells 

   distance to the nearest road  and
   geology types 
since the classifier performance was acceptable when
using all    features  and since using all features
slightly reduced the test error  to nearly       we
decided to train on all features 

   

figure   shows how the test error when using
a random forest classifier trained on     of the
data set which is preprocessed using pca or ica
with a varying number of dimensions components 
applying either pca or ica reduces the accuracy
of the classifier by roughly    relative to using no
preprocessing 

pca and ica

we investigated using pca and ica for improving
the performance of our classifier in case it were to
be used on a much larger data set  such techniques
might be useful for post earthquake analysis of an
area in which high resolution grid data is available

however  using pca and ica to reduce the
dimensionality of the data does improve performance 
as figure   demonstrates  the running time of the
classifier is roughly linear in the number of features
 while holding all else constant  so using pca or
 

fidifference between remotesensingbased survey
and fieldbased surveys    m x   m cells 
latitude  degrees 

ica
pca
unmodified

  
  
  

    
    
    
    
  

    

  

    

  

    

longitude  degrees 

  
 

accurately predicted

 

  

  
  
  
dimensions components

  

  

actual

figure    pca timing
predicted
false true
false
true

    
   

inaccurately predicted

difference between predicted result  random forest 
and fieldbased surveys    m x   m cells 
latitude  degrees 

running time  seconds 

   

    
    
    
    
  

    

  

    

  

    

longitude  degrees 

   
    

accurately predicted

inaccurately predicted

figure    damage estimates using only remotesensing data  left  and using our classifier  right  

table    results of one run of our classifier when
trained with      randomly selected examples and
tested on      examples 

to incorporate available data sets  especially those
known empirically to be correlated with damage
ica to reduce the number of features does offer a severity  that said  we do not claim that disaster
performance improvement in terms of running time  response teams can abandon field based surveys
entirely  rather  by highlighting areas of likely
damage  the classifier can help relief workers channel
time sensitive aid more efficiently  and to reduce the
    asymmetric error analysis
overall amount of field based survey required 
so far we have measured the performance of our
classifier by the test error  but in reality  false
positives and false negatives might have dramatically references
different costs in a real world post earthquake
scenario  for example  if our classifier does not detect
    fastica package for matlab 
http   
a set of collapsed buildings  false negative   relief
research ics aalto fi ica fastica  
workers might not be dispatched to that grid cell
https   code google 
and people in need of help might not get it  in     randomforest matlab 
com p randomforest matlab  
contrast  the cost of false positives might be relatively
low  since relief workers arriving at a scene without
    the world bank  haitidata  http   haitidata 
collapsed buildings would quickly see the lack of
org  
damage and move on to another site 
    leo breiman  random forests  machine learning 
table   breaks classifier error into false positives
                
and false negatives  when using the random forest
classifier  the number of false positives and false     chih chung chang and chih jen lin  libsvm 
a library for support vector machines  acm
negatives is nearly equal 
transactions on intelligent systems and technology                    

 

conclusion

    corinna cortes and vladimir vapnik  supportvector networks  machine learning           
          

in the event of future earthquakes  this classifier can
be used in conjunction with remote sensing based
survey for rapid disaster response  in particular 
this classifier could enable disaster relief teams

    u s  geological survey  shakemap us    rja  
http   earthquake usgs gov earthquakes 
shakemap global shake     rja   
 

fi