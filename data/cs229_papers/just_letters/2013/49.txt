optimizer for floating point unit generator
cs     final writeup

jing pu  mingyu gao  tai guo

  introduction
nowadays digital circuits become more and more complex  and keep requiring higher performance
and lower cost  to design a digital circuit  such as a floating point unit  fpu   usually needs to
explore a huge design space to optimize speed  power and area  however  there exists a fundamental tradeoff between these three metrics  and usually people want to find the pareto optimal
configurations called the design tradeoff curve 
our project focuses on a fpu generator  fpgen      which integrates a set of configuration
parameters and generates the corresponding fpu circuits  in order to find the pareto optimal
designs  currently fpgen just does brute force sweeping in the whole design space  which usually
contains more than    thousands design points  it costs a huge amount of time since evaluating each
design point needs hours of synthesis 
the goal for our project is to build an optimizer for fpgen using machine learning algorithm to
save design time significantly  here we focus on the delay and energy tradeoff of the circuit  the
optimizer is expected to predict the pareto optimal configurations smartly based on a small set of
synthesis data generated by sparse sampling on the design space  the accuracy of this predication
should be close to that of the original approach 

  data study and acquisition
in the design procedure of a digital circuit  the designers need to make decisions on many design
choices  which are usually called features in the machine learning terminology   while some of
these features  e g   the sizes of transistors  can be easily modeled as continuous variables  the others
are discrete  including integer variables  e g   the number of pipeline stages  and categorical variables
 e g   which topology or structure to use   while modern computer aided design  cad  tools can
optimize many low level features for us  we still need to make the decision for the high level integer
variables and categorical variables  the fact that the feature space has very high dimension and
contains multiple types of components makes the modeling extremely difficult 
the features fall into three categories  see table   
device level features                 s    these features are those that can be handled by the cad
tools  thus we dont include them in our model  but just leave them to the tools 
circuit level features                 l    these features can be modeled based on the circuit theory 
architecture level features                 n    changing these features often results in totally different structures  so they cannot be covered by the circuit model  and are very difficult to
model 
for our data acquisition  we used fpgen from stanford vlsi group     for hardware generation
and design space exploration  we use   nm bulk silicon technology from tsmc as our process

 

ficategory
device level
circuit level

architecture level

table    features
name

fpgen fma pipelinedepth
top vt
top voltage
fpgen fma enablemultiplepumping
fpgen fma mulshift mul  boothtype
fpgen fma mulshift mul  treetype

range

                   
lvt svt hvt
           
yes no
       
wallace zm os  array

technology for mapping hardware to the physical designs  and then we evaluate the electric characteristics  such as the delay and the power consumption for each physical design using the cad tool
from synopsys called design compiler 
in order to gain more confidence in the training and validation phases  we gathered as many data
as possible in the limited amount of time  the design space we explored is the cross product of a
set of features  so far  we have obtained more than    thousands data points  each of which takes
about    min    hours of cpu time 

  model
    mathematical abstraction
given all the design features         the delay d and the energy e of the circuit are
d   d       

e   e      

   

e finding the the minimal energy e and the
our goal is under a certain requirement of delay d  d 
high level design features      corresponding to it  or vice versa   the device level features  are
left to the design tools 
the circuit theory tells us that when  and  are given  there exists trade off between d and e
when we optimize   we model these constraints as
e        f   d       

   

here f  is a function that is monotonically decreasing  the curve given by f  is often called the
pareto optimal curve  or energy efficiency curve 
now we can express our optimal problem as
min e
 

subject to e  f   d 
e
dd

   

we will first model the constraint functions f  and fit them into the training data set  and then
do optimization to solve the best design  more details are explained in section   

    circuit level model
as we said in section    the circuit level features  can be modeled theoretically based on circuitlevel model  given a circuit design       the trade off between d and e by changing   a k a  f   
is given by the following model    
e         f   d         

k    
  e      
d        d      

 

   

fiwhere d        e       and k     are fitting parameters that depends on  and  
in our circuit level model      vdd   thl  p   in which vdd is the supply voltage  thl is the
threshold voltage level  and p is the number of pipeline stages  the circuit delay and energy now
can be written as the following with respective to these three features explicitly    
  

ad   
 
d   vdd   thl  p     
  bd   p vdd  vdd  vt  thl   von  d  d    
p
  
e   vdd   thl  p      a e      b e   p vdd
 e    
   
where a d   a e   b d   b e are parameters that depend on the architecture   and d   von   vt are independent with   d     and e     are functions of   modeling the dependency on the device level
features 
from      we assume that d   d  e   e  and k  de  so the circuit model for these
parameters are


ad   
  bd   p vdd  vdd  vt  thl   von  d
d     vdd   thl  p   
p
 
edyn      vdd   thl  p     ae      be   p  vdd


ak   
 
 
  bk      ck   p   dk   p vdd
 vdd  vt  thl   von  d
k   vdd   thl  p   
p
   

taking     into      we can represent the model explicitly with     vdd   thl  p  and parameters
that only depend on  

    dealing with architecture level features
ideally  after section      we should continue to model the relationship between the parameters
and  explicitly  however  the effects of different  are usually unrelated  for example  using two
different topology or algorithm will normally result in totally different performance  currently no
simple and accurate model can describe the effects of the architecture level parameters 
considering these difficulties  we dont make up a model without solid physical explanation 
but try to bypass them by utilizing the freedom to control the sparse sampling  we require that
the input training set must cover all the architecture level features so we can learn the parameters
depending on  separately  since the architecture level feature space is not big  this is not a very
strong requirement  and the designer can still reduce a large number of simulations by sampling
sparsely in the lower level design spaces of  and  

  methodology
figure   shows the methodology we use  given a small training set from sparse sampling  we first
fit     to get d    e  and k  then  considering the difficulties that     is non linear and there are
both kinds of parameters that depend and do not depend on   we try to use two step fitting for the
parameters in      we first deal with the factor that doesnt depend on  by factorizing the equations
and dividing the data from each other  then we use these results to fit the factor depending on  
after that  we calculate d        e        k     and obtain the pareto optimal curves f  for all
      finally  we solve the optimization problem     by simply picking the minimum e over all
      and give the calculated optimal d and e 
to increase the accuracy  ideally we should feed the calculated optimal configurations back into
the synthesis tool and get their actual delays and energy costs  but due to the limited amount of
time  another simpler method is used here  instead of re synthesizing the calculated configurations 
we use     to get the actual energy e of a certain configuration      under a given d  where
the parameters of     are learned from the complete data set  we call these result the predicted
optimal d and e  and treat them as the final output of our model 

 

fifor each    in the input data  fit the equations for             and
   
fit the circuit model parameters in two sub steps by factorization
fit  thl and  by cancelling out the
parameters depending on 

fit the parameters depending on  using the
results from step  a

calculate             and     to predict energy vs  delay curve for
all valid   
solve the optimization problem

figure    methodology

  results
    relative error of    
first of all  we evaluate the accuracy of our simpler method of back synthesis  the difference
between this simpler method and the real synthesis should be evaluated carefully  to do this  we
use a relative error calculated as the root mean square  rms  of the relative difference of e between
    and the real data
v
u

m 
u  x
ei pred  ei real  
 t
   
m
ei real
i  

in our experiments  this value is         thus we conclude that the error of     is small enough 
and it can be used for our evaluation purpose 

    errors for different training set sizes
our primary purpose is to reduce the number of necessary syntheses to get the pareto optimal
curve  in this section  we evaluate the errors for different input training sets  the error is calculated
as the average distance between the real pareto optimal curve and the predicted optimal curve from
our model  in our experiments  we reduce the training set size in different dimensions in the feature
space        and see the different results 

  

 

unused samples
used samples
pareto optimal curve
calculated opt d  e
predicted opt d  e

   

  
energy pj

error

   

   

   

 
 

   
    

    

    

                   
number of training samples

    

    

 

     

 a  errors for different training set sizes

 

   

 

   
delay ns

 

   

 

 b  an example with      training points

figure    results

 

fifigure   a  shows the error vs  the training set size  we can see that generally smaller training
sets have larger errors  as we use more and more samples  the error will converge to a stable value 
however  to our surprise  even some very small training sets are able to predict the pareto optimal
curve with fairly small errors  but the error will vary a lot if we use different training sets  in
section    we try to summarize some insights on how to reduce the training set size efficiently 
to present an example  we choose a point in figure   a  with      training points and error equal
to       and show the d e plot in figure   b   the three lines in the figure shows the real pareto
optimal curve  red   the calculated optimal configurations  blue   and the final output predicted
optimal configurations from our model  green   the error is the distance between the red line and
the green line  we can see that even with this small training set  about     of the entire data set  
the predicted pareto optimal curve is very close to the real one  meaning that this is an efficient
reduction of the training set size 

  discussion
an interesting question to ask is how to choose a efficient reduction of the training set but still
keep high accuracy  here are some guidelines summarized from our experiments 
   make sure that the training set covers all   this is because we dont model the architecturelevel features in the model  as stated in section     
   reduce but keep a certain value  about   to    for the number of samples with same    but
different   also it is better to sample uniformly along the curve  i e   synthesize designs with
very large and very small target delays respectively  this will affect the fitting quality for     
   reduce but keep a certain value  above      for the percentage of samples that share the
same  and cover all the combinations of vdd and thl  this will affect the fitting quality for
those parameters in     that do not depend on  
   reduce but keep a certain value  about   to     for the number of samples with different
pipeline stages p  this will affect the fitting quality for those parameters that depend on  

  conclusion
in this project  we characterize the fpu design space and classify the design features into three
categories  using both theoretical and empirical methods  a model is built to capture the effects
of different features  the model is quite helpful to reduce the number of necessary syntheses  by
applying our model  we are able to predict the pareto optimal curve with similar accuracy to the
original approach  but using only      of the original data set  that means a saving of     circuit
synthesis time 

references
    o  azizi  a  mahesri  j p  stevenson  s j  patel  and m  horowitz  an integrated framework for
joint design space exploration of microarchitecture and circuits  in design  automation test in
europe conference exhibition  date         pages              
    sameh galal  ofer shacham  john s  brunhaver ii  jing pu  artem vassiliev  and mark horowitz 
fpu generator for design space exploration  computer arithmetic  ieee symposium on         
     
    t  sakurai and a r  newton  alpha power law mosfet model and its applications to cmos inverter
delay and other formulas  solid state circuits  ieee journal of                     

 

fi