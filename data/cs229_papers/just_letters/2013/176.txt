stanford cs      fall     

 

activity classification with smartphone data
matt brown  trey deitch  and lucas oconor
abstractwe present analysis of several methods for classifying activities  such as walking up stairs or standing  using
data from a gyroscope and accelerometer  results are shown for both a processed dataset and raw data  analysis is
informed by a visualization of the data  we analyze the error due to differences between users and present a potential
solution to this problem 

f

 

i ntroduction

operate on the raw data  finally  we present
further analyses of our classifiers  which in turn
ver     of the u s  population owns motivate our suggestion for future work 
a smartphone      which increasingly include accelerometers and gyroscopes  we hope
that a successful activity classifier will enable   dataset
a new class of user mobile interactions  for
we drew our data from a prepared dataset
health reasons  some people are interested in
     which includes labeled data collected
tracking the amount of time they spend sitting
from    subjects who engaged in six differdown or the number of stairs they climb each
ent activitieswalking on flat ground and up
day  for home automation  walking up stairs
and down stairs  sitting  standing  and lying
or sitting on a couch could trigger the lights or
downall while wearing a smartphone that
television to turn on  phones could also react to
recorded accelerometer and gyroscope readtheir environments  for example by switching
ings at a rate of    hz  one portion of the
into car mode when they detect that a user
dataset contains the raw gyroscope and acis driving or airplane mode when on an
celerometer readings  which we call the raw
airplane  on a larger scale  understanding the
data  the other portion consists of vectors
activity patterns of populations has implicathat each contain     features and represent
tions for transportation and urban design 
     seconds of time  each vector encodes charprevious experiments required too much acteristics such as the triaxial average  maxitime and data     or used complex dedicated mum  and minimum acceleration and angular
sensors       further  they frequently relied velocity over the given interval  as well as
only on accelerometer data  while today many more complex properties such as the fourier
mobile phones contain gyroscopes as well  transform and autoregressive coefficients  we
therefore  our research focuses on developing call this portion of the data set the processed
a fast classifier that operates on accelerometer data or preprocessed data  we used this
and gyroscope data from mobile phones 
data to train and test all of our classifiers 
in this paper  we present our efforts to develop an effective activity classifier  we first
exposit our dataset  which contains both raw   a pproaches
and preprocessed versions of the same data 
next  we present several classifiers that oper      preprocessed data
ate on the processed data and analyze their as a starting point for our project  we trained
effectiveness  we then provide motivation for and tested naive bayes and gaussian discrimworking with raw rather than processed data  inant analysis classifiers on the preprocessed
and develop and analyze several classifiers that data  we then applied a hidden markov model

o

fistanford cs      fall     

 

classifier to our gda classifier  using the activi  are fairly well grouped  even in two dimenties as the states and the outputs of our gda as sions  this helps explain why gda works so
the emissions  our goal in adding an hmm to well on the processed data 
our gda classifier was to capture time based
relationships in the data which the static gda
classifier failed to use  a technique which has
been used successfully in the past          
      results
algorithm
naive bayes
gda
gda   hmm

accuracy
   
   
   

      analysis
the accuracy of the gda model was much
higher than that of the naive bayes model
because naive bayes makes the assumption
that the features are independent of one another  which is far from the truth in the case fig     accuracy vs feature space dimension
of our data  for example  average acceleration
is dependent on minimum and maximum acceleration for a time window  but our data
lists all of these properties separately  therefore
naive bayes is a bad fit for our data set  the
suitability of gda to the preprocessed data can
be inferred from the pca projection in figure   
in which there are clearly visible clusters corresponding to each activity  adding the hmm
improved performance further  which is not
surprising given the heavily time dependent
nature of our data 
      pca
in order to better understand the processed
data set  we performed principle component
analysis  figure   shows the training and
testing accuracy of gda as a function of
the dimensionality of the feature space  note
that many dimensions can be removed without drastically affecting performance  however  these dimensions are linear combinations
of the original features  so this analysis is not
particularly useful for reducing the number of
features used in the model  because the data
only varies greatly in a few dimensions  we
can use pca to project the data onto the plane
of maximal variance and visualize the data 
figure   shows this projection  with activities
distinguished by color  note that the activities

fig     processed data projected onto plane

   

raw data

the next problem we looked at was classifying the raw data  while we achieved very
good performance using the processed data 
there are a few advantages to using raw data 
each processed data vector is created using
     seconds of raw data  which means the
maximum precision of the classifier is limited
to one estimate per      seconds  additionally 
some of the features in the preprocessed data
might be difficult to generate in real world settings  especially given the memory  processor 
and battery constraints of multitasking mobile

fistanford cs      fall     

 

devices  in such cases  a classifier based only
on raw data would be a good alternative 
to establish a baseline  we first applied the
same gda model that we used for the preprocessed data to the raw data  we then decided
to apply a hidden markov model approach
where our states were the activities that the
subject was performing at a given time step 
using the baum welch algorithm to estimate
the probabilities of transitioning between states
and the probabilities of emissions at each state 
and the viterbi algorithm to predict the series
of underlying states for a given test sequence
of emissions  the observables in our data were
the continuous raw data readings  but we used
a discrete emissions model hmm for simplicity 
in order to convert our data points into discrete
values we tried three approaches 
   using the gda classification of the data
point as the emission 
   finding the centroids of the data points
corresponding to each activity in the
training set and using the nearest centroid
to each data point as our emission 
   running k means with different numbers
of clusters on the entire training set and
using the nearest cluster centroid to each
data point as the emission 
      raw data results
algorithm
gda
hmm   gda
hmm   activity centroids
hmm   k means     clusters 
     

accuracy
   
   
   
   

analysis

the gda approach did poorly because its
method of fitting a single gaussian to each
activity was unsuited to the raw data set  this
is visible in the pca projection in figure   
which shows that the data points for each example were either evenly distributed in space
or arranged into multiple clusters  there was a
significant amount of overlap for the distributions of data points for each user and activity 
making the prediction task extremely difficult 
the gda approach was also weak because
it only looked at a single time step rather than

changes over time  time dependent information is very valuable in the multiple activity
context  consider how a transition from standing to walking is much more likely than one
from laying down to walking   the hmm approach allowed us to take into account changes
in the readings over time by treating the data
points as a sequence rather than just individual
examples and estimating the transition probabilities between the hidden states 
hmm   gda and hmm   activity centroids did much worse than hmm   k means
because the former two involve fitting a single
cluster or distribution in order to characterize
an emission while the latter involves using
multiple clusters to characterize the emissions 
as can be seen in figure    a given activity
can have data points clustered around several
distinct centroids  so using k means clustering
and allowing multiple centroids per activity is
better suited to the nature of the data than
using one centroid per activity  the accuracy
of hmm  k means improved as we increased
the number of clusters until we encountered a
memory error after    clusters 
to further analyze the hmm   k means
model  we computed the testing and training
errors as a function of training set size  figure  
shows little gap between training accuracy and
testing accuracy  both of which are lower than
the baseline accuracy established by running
hmm gda on the processed data  this indicates that our classifier has high bias     
and confirms our suspicion that moving from
the processed data to the raw data reduces the
complexity of the model  which isnt surprising
since the processed data has     dimensions
and the raw data has only   
      pca
we performed principle component analysis
on the raw data to provide insight into its
structure  because the raw data comes from
independent sensors  we expected the variation
in all dimensions to be fairly significant  and
indeed that is the case  shown in figure   is
a two dimensional projection which is useful
for understanding the general nature of the
data  but there may be structure lost in the
projection  there are several visible clusters of

fistanford cs      fall     

 

single subject and the training set consists of
data from other subjects  we performed this
new user cross validation on the hmm kmeans classifier  our most successful raw data
algorithm   as shown in figure    the average
cross validation accuracy was relatively low
      and the variation in error between users
was high  this tells us that it may be necessary
to incorporate each users individual data into
the model to achieve high accuracy  in contrast 
figure   shows the results of running new
user cross validation on the processed data 
here  the cross validation errors are lower and
fig     training and testing error vs  size of
are more consistent from user to user  we can
training set
conclude that the processed data forms a more
general model for each of the activities that
points corresponding to activities  namely ly  new users will tend to fit 
ing  sitting  and standing  the cluster of standing points appears in the middle of a cloud
of walking upstairs  downstairs  and walking 
this seems consistent with an intuitive view
that standing is somehow in the middle of
walking  both of which are fairly distinct from
lying and sitting 

fig     accuracy of gda on preprocessed data
for each new user

fig     raw data projected onto plane

 

n ew u ser c ross   validation

fig     accuracy of hmm with k means on raw
data for each new user

if any of these classifiers are to be used in prac  f uture w ork
tice  it is very likely they will be used by someone on whom the classifier was not trained      real time k means adaptation
therefore  we are interested in the testing er  to improve accuracy by adapting the model to
ror where the test set consists of data from a individual users after training  we propose a

fistanford cs      fall     

modification to k means as the emission model
in an hmm  previously  we used k means
to cluster the training data and recorded the
cluster centroids  then we treated the closest
centroid to each data point as an emission of
an hmm  we propose that once the algorithm
is deployed  the cluster centroids should be
moved slightly in the direction of each new
point to which they are closest 
for every new data point x and cluster
centroid cj with weight wj
cnew
  wj  cold
j
j  x

 

a faster  more efficient classifier  a hidden
markov model proved useful in capturing information in the transitions between activities
and the time history of the estimate  k means
clustering worked well as the emission model
for the hmm because it allowed multiple clusters per activity  more work is needed so that
this method generalizes well to new users  and
shifting the centroids to better fit each user is
one promising way to achieve that 

r eferences
   

wjnew   wjold   
this method was motivated after inspecting
pca projections of multiple users  and noticing
similar but distinct clusters for a given activity 
figure   shows data taken for two different
subjects while sitting  note the similar  but
approximately translated groups of points  if
the cluster centroids were trained using the
green subject and then run on the blue subject 
this algorithm would slowly move the centroids toward the centroids of the blue clusters 
creating a better fit for that subject 

   

   
   

   

   

   

   

   

fig     sitting data for two different users

 

    

c onclusion

we created a classifier that is very accurate
on processed data and relatively insensitive
to new users  however  the feature vectors
are computationally expensive to generate and
only give an activity estimate every      seconds  we transitioned to raw data to make

    

    

mobile majority  u s  smartphone ownership tops     
nielsen  june         http   www nielsen com us 
en newswire      mobile majority  u s  smartphoneownership tops     html 
kwapisz  jennifer r   gary m  weiss  and samuel
a  moore  activity recognition using cell phone accelerometers  sigkdd explorations                  
bao  ling and stephen s  intille  activity recognition from
user annotated acceleration data       
casale  pierluigi  oriol pujol  and petia radeva  human
activity recognition from accelerometer data using a wearable device       
cho  yongwon  yunyoung nam  yoo joo choi  and weduke cho  smartbuckle  human activity recognition
using a   axis accelerometer and a wearable camera 
proceedings of the  nd international workshop on systems
and networking support for health care and assisted living
environments       
lee  seon woo and kenji mase  activity and location
recognition using wearable sensors  pervasive computing                 
parkka  juha  miikka ermes  panu korpipaa  jani
mantyjarvi  johannes peltola  and ilkka korhonen  activity classification using realistic data from wearable
sensors       
ravi  nishkam  nikhil dandekar  preetham mysore 
and michael l  littman  activity recognition from
accelerometer data  in proceedings of the seventeenth
conference on innovative applications of artificial intelligence iaai        
anguita  davide  alessandro ghio  luca oneto  xavier
parra  and jorge l  reyes ortiz  human activity recognition on smartphones using a multiclass hardware friendly
support vector machine  vitoria gasteiz  spain  international workshop of ambient assisted living  iwaal
       dec      
lester  jonathan  tanzeem choudhury  nicky kern  gaetano borriello  and blake hannafor  a hybrid discriminative generative approach for modeling human activities  proc  of the international joint conference on artificial
intelligence  ijcai        
yin  pei  irfan essa  thad starner  and james m  rehg 
discriminative feature selection for hidden markov models
using segmental boosting       
ng  andrew  advice for applying machine learning  http 
  cs    stanford edu materials ml advice pdf 

fi