reminiscing through personal email
mikhail sushkov

john doherty

stanford university

stanford university

msushkov stanford edu

doherty  stanford edu

abstract

   preprocessing

personal email stores a wealth of information about our
actions and thoughts through the years  providing rich
material for reminiscence  however  browsing through
thousands of messages is tedious and impractical without
a proper summary of the data  we present a system that
gives a high level overview of an email archive by
extracting the underlying topics of the emails and
presenting the user with a series of messages that best
represent these topics  topics are found using latent
dirichlet allocation  lda   and the representative set of
emails is extracted by modeling the set of email
messages as a factor graph and solving a constraint
satisfaction problem  csp  over the set 

the data is cleaned through the following preprocessing
steps  conversion to lowercase  removal of terms with
under   characters  removal of rarest   terms and most
frequent    terms  removal of messages with less than  
words  stop word removal  tokenization  apache lucene
is used to perform these steps      after preprocessing 
the data set contains        messages 

   introduction
the stanford mobisocial group has developed a
program called muse      which analyzes personal email
archives to label outgoing messages according to
common emotions and sentiments      users are
presented with a timeline over their years of email usage
illustrating the trends in emotions and life events 
providing the opportunity for reminiscence and
recollection of past occurrences  while classifying email
messages according to a set of emotions provides
interesting insights for self reflection  it is beneficial to
also explore the underlying semantic structure of a
personal email archive to extract information about the
evolution of topics through time  this would give users
an alternative view of their emails  and would provide
information about their communication patterns and
trends  this project aims to extend the current system to
perform summarization of a users email archive  and
then to use the learned topics  along with email metadata 
to find a set of important events in the users life  the
final output will be a set of emails determined to be most
representative of the messages within a particular topic 

   data
the training data used is the corpus of sarah palins
emails released in       the data set contains over
       email messages from sarah palins time as
alaska governor  the emails range in dates from
december      to september      

   summary extraction
   

initial approach  clustering

k means clustering is applied as a first attempt at
extracting summary information from the messages 
emails are converted into vector space by computing tfidf scores for each word and storing them as sparse
vectors      then  messages are clustered using kmeans    with cosine similarity as the measure of
distance between emails         the k means  
algorithm differs from traditional k means only at the
initialization step  and has been shown to find a more
optimal solution      the apache commons java
implementation of k means   is used for this step     
for computational efficiency  each email is represented
as a vector of terms with the top     tf idf scores 

      

clustering results

to evaluate clustering performance  a random sample of
   email pairs was chosen  and each pair was manually
labeled as   or      if the messages were judged to
belong to different clusters  and   if the messages were
judged to belong to the same cluster   the judging
criterion was the perceived overlap between terms 
clustering performance was evaluated by checking
whether each of the    pairs of emails was placed into
the same or different clusters  fig    summarizes the
results for different values of k  the number of clusters 
k

error rate

runtime  s 

 

    

   

  

    

   

  

    

    

figure    clustering performance on labeled test set 

figiven the user facing nature of this system  the above
metric is insufficient by itself to judge clustering
performance  a better evaluation metric is to examine
the set of terms that each cluster represents  and to
evaluate whether the given clustering of terms makes
sense  fig    presents the terms with the highest tf idf
scores for each cluster center  for several clusters after
running k means   with k      
 alerts  business  center  education  fish  gov state ak us  http 
important  law  letter  mail  national  policy  research  spam 
states  web  webmail  wiche  writing 
      agia  bill  budget  comment  dnr  energy  gas 
gov state ak us  juneau  personal  phone  pipeline  press 
privileged  project  public  sharon  staff  work 
 comment  concerns  dear  gov state ak us  govweb alaska gov 
important  mail  mailto webmail  opinions  person  received 
respond  reviewed  staff  suggestion  unable  valuable  web 
webmail  writing 
 aces  business  cavuto  conf  economists  featured  gas  goofy 
ill  natural  oil  pipeline  pis  project  show  speakers  sponsor 
support  understanding  women 

figure    terms describing several representative cluster
centers after running k means   with k      

it is clear that the terms given by the cluster centroids are
noisy and do not do a great job of summarizing the data
set  giving somewhat ambiguous results  moreover  the
runtime of nearly    minutes for k      makes this
approach prohibitively slow  thus  it is necessary to
explore more sophisticated techniques to summarize
email archives 

   

topic modeling

much recent work has been aimed at extracting
information from text corpora using topic modeling     
this approach assumes that a collection of documents
can be represented by a few underlying themes  or
collections of terms  one of the most well known topicmodeling techniques is lda      lda is a generative
model that assumes that for a collection of documents  a
mixture of topics produces the words in the documents
with some probabilities  fig      the goal is to find the
set of topics most likely to have generated the given set
of documents       thus  running lda on the training
set will generate a set of topics that best summarize the
email corpus 

     

lda results

lda outputs a set of topics  represented by terms in the
corpus  and each message has a probability distribution
over all topics  for example  a particular message could
come from topic   with probability      topic   with
probability      and so forth  most email messages in the
data set come from a single topic with a high probability
 greater than       and from other topics with much
lower probabilities  thus it is reasonable to think of each
message as originating from a single topic  this allows
us to compare the performance of clustering and lda by
evaluating lda using the same test set of    emails used
to evaluate k means    a pair of emails labeled   would
be correctly separated with lda if the highestprobability topics for the messages are different 
similarly  a pair of emails labeled   would be grouped
correctly by lda if the highest probability topics are the
same  fig    summarizes these results when running the
mallet implementation of lda on the sarah palin
data set with    topics      
number of
topics

error rate

runtime  s 

 

    

  

  

    

  

  

    

   

figure    lda performance on labeled test set 
 military  national  service  page  security  army  day  support 
soldiers  august  guard  veterans  home  department  air 
family  september  honor  allen  policy 
 court  law  states  people  federal  u s  united  case 
government  rights  president  republican  party  supreme 
attorney  campaign  general  national  amendment  mccain 
 gas  oil  energy  pipeline  tax  project  natural  north 
companies  million  resources  development  costs  plan  cost 
year  production  alaskans  line  years 
 hunting  game  moose  fish  wildlife  property  area  year  hunt 
wolves  control  people  years  subsistence  quot  page  bears 
hunters  board  wolf 
 health  care  public  services  department  benefits  safety 
insurance  federal  program  section  medical  change  climate 
act  provide  system  hss  mental  programs 

figure    terms describing several representative topics after
running lda on the sarah palin data set with    topics 

similarly to the case of clustering  it is difficult to judge
the quality of the results without examining the terms
that represent each topic  fig    lists the top   
representative terms for topics learned from running
lda on the data set  with    topics  and fig    shows the
evolution of the topics military and court through time 
figure    generative process visualization  with probabilities
of each document being drawn from each topic      

fiarity potentials connected to every email in the graph 
there are three potentials  the constraint restricting the
size of the subset  the potential for the average topic
probability  and the potential for time spread  fig     
these factors are presented for conceptual purposes
because in reality  scores are just computed over emails
in the subset and never over all the emails in the factor
graph 

figure    trends in selected topics from figure   

the results are less noisy and more coherent than those
obtained through clustering  the keywords that
represent each topic are clearly related  and the topics are
distinct from each other in terms of their keywords 

figure    factor graph for subset extraction 

moreover  the error rate of      and runtime of under  
minutes for the best performing run of lda  with   
topics  significantly outperforms the error rate of     
and runtime of nearly    minutes for the best performing
run of clustering with k      

given this model  the next step is to choose an algorithm
to find an optimal solution  while it would be possible to
use a library or generic algorithm for this purpose  it is
easier and more efficient to modify a traditional factor
graph algorithm for the purposes of this problem 

   representative topic emails
while it is informative to view the summary topics of an
email archive  users may want to drill down into the
specific emails that produced a particular topic  thus  it
is beneficial to extract several messages that best
represent each topic  the goal is to take a set of emails
from a topic and find the messages that are both strongly
related to the content of that topic and offer a snapshot of
the topic over time 
to find an optimal subset of representative emails 
several data points are available  topic probabilities
 from lda   and email timestamp  from email
metadata   the topic probability is the probability of the
email being associated with a given topic  as determined
by lda  the optimal subset is the group of emails that
maximize both the average topic probability and time
spread  time spread is a measure of how well the time
distribution of a subset of representative emails matches
the time distribution of the whole set of emails in that
topic  and will be explained in more detail below 
a variable based model can be used to solve this
problem  in this case  the problem can be modeled using
a factor graph and solved using constraint satisfaction
problem  csp  algorithms 
to model this subset selection as a factor graph  each
variable in the graph is associated with an email and has
a binary domain representing whether or not it is
included in the solution  additionally  there several high 

the specific algorithm used to extract the email subset is
based on local search  since the size of the representative
subset remains constant  it is reasonable to start with a
completed assignment and modify it to find a maximumweight assignment  the algorithm is as follows 
findsubset emails  subsetsize  iterations  
sort emails by topic probability
subset   emails    i  subsetsize 
loop for iterations 
loop over    i  subsetsize 
subset i    argmax e  emails score subset  e 

score subset  is a scoring function to evaluate the
current partial solution  it is based on average topic
probability and time spread  average topic probability is
a straightforward evaluation metric  but time spread is
more ambiguous  time spread is evaluated by splitting
the time range of the email set into subsetsize number of
buckets  the time range spanned by each bucket is based
on the density of emails in that time range  for example 
in fig      the algorithm would attempt to place more
buckets in regions of frequency spikes  additionally 
buckets placed within one of these spikes would cover a
smaller time range than those placed outside of the
spikes  with the time range divided into these intervals 
time spread can be evaluated by computing the number
of these buckets that would be filled by emails in subset 

   

email extraction results

the algorithm is effective at choosing emails that span
the time range while also maintaining a high average

fitopic probability  to check the accuracy we compare the
results to other possible approaches  for example  a
naive approach to would be to form a subset out of the
emails with the highest probabilities for a topic  while
this would give the result with the best average topic
score  it says nothing about the distribution of emails in
time  this can be seen in fig     here the blue line
represents the frequency of emails over time in a single
topic  the bottom light blue dots show points in time
where the naive approach extracts emails 
on the other hand  the factor graph approach finds the
emails represented by the dark blue dots  clearly these
emails are better spaced in time and the density of the
emails tends to line up with the spikes of the frequency
plot  in addition to producing a superior time spread  this
approach also maintains a high average topic probability 
while the naive approach will always produce the
maximum average topic probability  the factor graph
approach is only     worse on average over    topics 
fig    illustrates the representative set extraction for an
example topic in the training set  it is clear that the
representative emails extracted for the given topic are
very relevant to the topic itself  and represent the
progression of the topic in time 

  

evaluation  enron emails

to further evaluate the performance of the system  the
pipeline was run on a subset of the enron email corpus 
after the preprocessing steps described in section    the
data set contained        messages 
fig     illustrates the topics extracted from the enron
data set using lda  and fig     illustrates the time
spread for representative set extraction and average topic
probability  fig     illustrates the representative set
extraction for an example topic in the enron email set 
 market  year  companies  million  stock  trading  investment 
buy  financial  price  high  earnings  billion  capital  report  long 
investors  money  term  week 
 travel  net  fares  hotel  rates  miles  travelocity  specials  city 
hotels  sheraton  san  book  fare  deals  hilton  car  visit  airport 
offers 
 intended  recipient  database  data  corp  error  confidential 
dbcaps  sender  alias  privileged  unknown  prohibited  contract 
delete  distribution  strictly  attachments  disclosure  named 
 management  group  services  risk  trading  president  power 
market  industry  team  markets  development  program  global 
director  technology  work  office  conference  provide 
 image  click  free  price  link  online  cgi  unsubscribe  save 
bin  view  list  address  web  order  site  offer  special  service 
home 

figure     terms describing several representative topics after
running lda on the enron data set with    topics 

figure    example of time spreading using csp approach 
line shows frequency of emails in example topic and dots
show emails extracted using naive and csp approaches 
topic   gas oil energy project agia pipeline laa senator bill rep natural 
subject  halcro took a shot at me on his blog today date          
conoco blows hot air about gas production by ivy frye the alaska
gasline inducement act  agia  remains the subject debate
alaska  s first  process for building a natural gas pipeline
subject  kensington gold project date           
also use the existing water treatment facility which has been shown
to be effective in meeting state and federal water quality standards
subject  fw  legislative action alert  date           
fewer permitting obstacles in canada   and  as an independent
pipeline company
award of an agia license to tc alaska allows the state to assist
smaller pipeline projects that can provide gas

figure    example emails extracted from the topic gas using
the csp approach 

figure     csp email extraction gives a much better spread
over the time range for two topics from the enron corpus 

fitopic   enron s stock billion trading financial credit dynegy
dow jones shares market million investors year companies debt
price news corp percent week copyright earnings investment
company s 
subject   blank  date     august     
with the u s  dollar weaking  continue to do so   which is clearly
helpful to enron while we try to sell international assets 
subject  enron date     september     
 as an employee and a stock holder of enron  i m very concerned    i
know you can t tell me where the stock will be in    to    months
subject  enron receives dynegy     b cash infusion tues 
date     november     
   dynegy inc   dyn  provided enron corp   ene  tuesday with the
     billion cash infusion envisioned in the companies  merger
agreement  a dynegy spokeswoman said   
subject  good news date     november     
   enron gets extension on      mln note due next week  update  
   enron corp   whose shares had dropped    percent 

figure     representative emails extracted from the topic
enrons stock 

the keywords that represent each topic for the enron
data set are clearly related  and are significantly different
from the keywords of another topic  a clear trend in the
topics in fig     can be seen  the first topic is financerelated  the second is travel related  and so forth 
the representative set of emails for the topic enrons
stock represent the topic very well  and are far enough
apart in time to represent the development of the
performance of the companys stock  the representative
emails provide the user with a sort of topic storyline 
which allows for better understanding of what happened
to enrons stock throughout       extracting this
representative set clearly helps the user to drill down into
the topic beyond just the summary keywords 

   

extending email extraction

the factor graph approach to extracting representative
emails is powerful  but only uses a fraction of the
available data  the current implementation of this
algorithm scores subsets of emails on just their average
topic probability and time spread  but the algorithm does
not take into account the people tied to the emails or any
of the other metadata  using the communication graph
could help find even more relevant emails  another
extension would be to use the topic probability
distributions given by lda  the current algorithm
associates an email with its most probable topic  but in
lda emails are assigned a probability distribution over
all topics  a similar factor graph algorithm could be used
to find trends between topics 

  

references

   
   

http   mobisocial stanford edu muse
hangal  sudheendra  monica s  lam  and
jeffrey heer   muse  reviving memories using
email archives   proceedings of the   th annual
acm symposium on user interface software
and technology  acm       

   
   

http   lucene apache org 
ramos  juan   using tf idf to determine word
relevance in document queries  proceedings of
the first instructional conference on machine
learning       

   

arthur  david  and sergei vassilvitskii   kmeans    the advantages of careful
seeding   proceedings of the eighteenth annual
acm siam symposium on discrete algorithms 
society for industrial and applied mathematics 
     
dehak  najim  et al   cosine similarity scoring
without score normalization techniques   proc 
odyssey speaker and language recognition
workshop       
http   commons apache org proper commonsmath 

  
discussion
in this paper we presented a system for reminiscing
through personal email  which builds upon the existing
muse project  the underlying topics of an email archive
are extracted using lda  and then a representative set of
emails is found using the factor graph model 

   

the system was trained on the corpus of sarah palins
emails and produced clear and useful results for both the
topics learned and the representative email set for each
topic  furthermore  the system was evaluated against the
enron data set  with good results 

   

blei 
david
m 
 probabilistic
topic
models   communications of the acm     
              

   

blei  david m   andrew y  ng  and michael i 
jordan   latent dirichlet allocation   the
journal of machine learning research  
                 

    
    

http   blog echen me            topicmodeling the sarah palin emails 
steyvers 
mark 
and
tom
griffiths 
 probabilistic topic models   handbook of
latent semantic analysis                       

    

http   mallet cs umass edu 

  

future work

   

more preprocessing

the following preprocessing improvements will further
reduce the noise of the data  spelling correction  named
entity recognition  and semantic expansion 

   

fi