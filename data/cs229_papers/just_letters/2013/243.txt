bartok  music time period classification
daniel chiu  derrick liu  yushi wang
cs    final project

abstract
previous work has high classification accuracy
when classifying music genres that are very
different      e g  rock vs  pop  jazz vs  classical  
but little machine learning research has been
done to classify music by subgenres within a
larger genre that describe temporally and
stylistically similar music  in this paper  we
apply machine learning to classify classical
music by time period  to do so  we used
supervised learning algorithms  nave bayes
and svm   unsupervised algorithms  k  nearest
neighbors  
and
ensemble
algorithms
 adaboost  on a uniformly distributed data set 
comprised of over       midi files extracted
from an online collection  we then analyze and
discuss the performance of our classifier 

introduction
the ability to classify music has many
applications  from automatic organization of
musical databases to music recommendation
systems  however  even to a trained human ear 
differentiating between similar subgenres of
music can be extremely difficult  as a result 
there are rarely clear distinctions between
similar genres  in particular  subgenres within
music are often blurred 
despite these difficulties however  song
classification by musical style has potential 
previously  cataltepe  yaslan  and sonmez were
able to achieve close to      accuracy when
classifying midi files into pop  jazz  and
classical categories      in this paper  we focus
on the problem of classifying music by
subgroups within a specific genre in hopes of
gaining insight into the limits of music
classification 

data collection
we collected our data from a single  large
source of classical music midi files called the
classical midi connection      from this source 
we drew classical music from   time periods 
renaissance  baroque  classical  romantic  and
  th century 

the classical midi connection does not have
any public api for use  so we spent a substantial
amount of time writing a python scraper to
download the midi files for each time period 
due to the lack of structure in the websites
html markup  we could not quickly capture
these midi files with straightforward html
parsing tools  instead  we needed to apply
manual parsing techniques  e g  document tree
traversal  to the webpage in order to effectively
locate and download all available midi files 
here is the breakdown for the number of songs
we collected per time period  after filtering out
bad data  
baroque
classical
renaissance
romantic
  th century

    
   
   
    
   

features
for each song  we parsed a variety of features
to train classification algorithms against  to
decide what features to train against  we
researched the characteristics of the different
time periods of classical music  noting that the
key  dynamics  rhythm  instrumentation  and
musical progression tend to define a period s
style     

parsing
we used a python library from mit called
music        using this library  we were able to
convert each midi file into a music   stream of
events  each midi stream contains information
about the key and time signatures for a song 
as well as a list of notes and chords  in
chronological order   after conversion  we used
music   modules to extract the song data and
metadata 
we defined song metadata to be information
contained in the song that does not require an
analysis of the underlying song structure  and
song data to be information specifically
conferred by a songs note and chord structure 
more specifically  we extracted time and key
signatures  average tempo  and longest
   

fibartok  music time period classification

sustained tempo from each songs metadata 
for the note data itself  we first used music  
to transcribe each song into its respective
neutral key signature  a minor or c major  to
normalize the notes  then extracted histograms
the song s pitches  chord bases  and intervals
between consecutive notes or chords from the
song 
we created a self contained python object to
store the features for each file  thus  parser
module outputs a single song data object per
file  running the parser on each file in the
collected songs list resulted in a set of objects
that each correspond to a collected song 
in order to efficiently process this
computationally intensive workload  we used
the joblib python library to effectively
parallelize   worker threads on our set of songs 
we further separate the set of songs into small
chunks to reduce memory consumption per
worker thread  each worker thread would run
the parser module on its subset of the data  and
a final worker thread would coalesce the results
at the end of parallelized computation 

preprocessing
while each of these song objects contain useful
information  the raw objects could not have
been used to train our machine learning
algorithm  all of the classification algorithms
we utilized train classifiers on numerical
vectors  so we needed to determine a scheme
to compose such a vector from the various data
contained in these song objects  we finalized a
scheme to convert non numerical  negative 
and non vector data  and used that scheme to
translate song objects into vectors that could
be directly input into our classification
algorithms  data that was already in numerical
format  e g  time signatures  were simply
coalesced into a vector format  to store the
more complicated features such as the note
and chord histograms  we flattened each
complex feature structure into a single
numerical vector per feature  finally  we

concatenated many vectors to form one overall
numerical feature vector per song 

learning algorithms and processes
we exclusively used scikit learn as the
machine learning library in our project 
scikit learn
provides
extensive
classification algorithm flexibility  metrics
functionality  and cross validation support     
which proved to be valuable throughout the
development and assessment of our projects
performance 

multinomial nave bayes
we started out with nave bayes from the
scikit learn module to establish baseline
performance      nave bayes makes the
assumption that features are independent 
which is likely not a very good model for music 
ultimately  nave bayes gave us an accuracy of
just over      this was far more accurate than
randomly choosing a category  but it did not
perform nearly as well as an svm 

svm
we later chose to test with svms because
svms are a popular and effective algorithm and
we knew that it would provide more robust
classification than nave bayes  we also
expected svm s to work better with our
relatively large feature set  we experimented
with an svm with two different types of kernels 
a linear kernel and a radial basis function  rbf 
kernel      in scikit learns implementation 
an rbf kernel is functionally representative of a
gaussian kernel  we found that the rbf kernel
performed slightly better than the linear kernel
due to the fact that the data was almost
certainly not linearly separable 
later on  we found that svms worked better as
a whole when we switched from an svm that
was solving the dual problem to an svm
solving the primal problem 

k nearest neighbors
for variety  we also tried a k nearest neighbors
classifier on our data set to compare the
   

fibartok  music time period classification

performance of unsupervised learning with
more
traditional
supervised
learning
algorithms  we found that the classifier worked
best when we set it to look at the   nearest
neighbors  but that it did not perform as well
as an svm  especially when the svm was
initialized with tuned parameters and kernels 

adaboost
after using the four algorithms mentioned  we
decided to try running adaboost  short for
adaptive boosting  adaboost is a weighted
ensemble algorithm that repeatedly fit a
sequence of weak learners to our data      the
rationale behind this was that such a boosting
algorithm would naturally be very flexible  due
to the large number of classifiers hidden
behind the algorithm  furthermore  it s very
resistant to overfitting  and requires no
knowledge of the weak learners while
providing decent theoretical guarantees on
accuracy     

cross validation processes
we trained these classification algorithms on
stratified   folds of preprocessed data vectors 
we chose to use stratified k folding to
minimize overfitting to a training set  while
maintaining that the proportion of data
represented in each fold is the same as the
proportions of actual data 

design decisions
we initially decided to utilize a multinomial
nave bayes classifier to provide us with
general insight into the strengths and
weaknesses of our data set  feature selection 
and implementation  we reasoned that
multinomial
nave
bayes
is
simple 
straightforward  and easy to use  starting with
it would allow us to quickly iterate and improve
our project 

average accuracy of     over   folds of   
examples each 
fold number

accuracy

mislabel
 
total
fold  
        
       
fold  
        
       
fold  
        
       
fold  
        
       
fold  
        
       
we also generated and plotted training test
accuracy  which revealed that multinomial
nave bayes was experiencing both high
variance and high bias  this prompted us to
expand our number of training examples  and
the feature set that nave bayes was being
trained on 
to address the lack of training examples  we
expanded our data collection parameters to
include composer specific pieces provided on
the classical midi connections website 
including these composer specific pieces
quadrupled our training set size  from      to
     examples  training the same nave bayes
classifier with these new data practically
eliminated the high variance experienced
earlier when plotting training test errors 
originally  we had six categories  baroque 
classical 
renaissance 
romantic 
impressionistic  and   th century  we noticed
that our classifiers were getting confused
between impressionistic and   th century
more so than between other time periods  to
resolve this  we decided to fold these two
categories together since the impressionistic
movement occurred during the   th century 
and can be considered a subset of
contemporary music  after making this change
our accuracy increased from        to        

in this initial multinomial nave bayes round 
we trained the classifier with     examples and
three initial features  note histogram  key
signature  time signature   and achieved an
   

fibartok  music time period classification

results
our final results were better than we expected 
if we were to randomly choose between
categories we would expect     accuracy 
using our best classifier  we were able to
achieve        accuracy  this is a drop of   
compared to the     accuracy for identifying
pop from jazz from classical in exchange for
having songs that are far more similar to each
other 
adding in all of our new features and new data 
the performance of our initial nave bayes
increased from     to      this was the least
effective of the five things we tried 

multi nb
knn
       
      
      

linear svm
adaboost

             
      

rbf svm

             

      
      
     
figure    cumulative overview of final music classification mean
accuracies

svm performed even better  achieving       
accuracy with a linear kernel and       
accuracy with an rbf kernel  for the linear
kernel  we found that we achieved about   
higher accuracy when we switched from a
kernel that solved the dual problem to one that
solved the primal problem  since       
accuracy was the highest accuracy we found
out of all the algorithms we tried  we have also
provided some graphs visualizing the rbf svm
confusion matrix and training vs  test error  see
figure     from this matrix  we note that
confusion between time periods often occurs
when the periods are adjacent to one another 
for example  in the above figure  baroque
pieces are often confused with renaissance 
since baroque pieces likely draw influences
from pieces written during the renaissance
period immediately preceding 

k 

nave bayes performed the worst among our
classifiers  this is probably due to the
complexity of the features and the simplicity of
the algorithm itself  which allows for speed  but
also larger errors 
overall  for supervised algorithms  svms
performed the best among all the trained
classifiers by a significant margin  with the
nonlinear  rbf  svm slightly edging out the
linear svm  possibly due to common musical
influences  as mentioned above 

figure    confusion matrix and training test accuracy plot
from svm classification  with rbf kernel

nearest neighbors supports two separate
   

fibartok  music time period classification

weighting modes  distance  in which the
weighted influence of a point is a function of its
distance  and uniform  in which all points are
weighted equally regardless of distance  we
found that using the distance weighting mode
worked best  additionally  k nearest neighbors
supports several different distance metrics
including manhattan     distance and
euclidean     distance  manhattan     distance
yielded the best results  we also found that the
algorithm produced the highest accuracy when
we set       with these parameters  our knearest neighbors classifier was able to achieve
       accuracy 
finally  adaboost achieved a somewhat
disappointing       accuracy  we found that
we had the highest performance when we used
    estimators with a learning rate of      since
two songs from different time periods might be
more similar than two songs from two different
time periods  significant noise could be present
in the training data  boosting algorithms like
adaboost are susceptible to noise  which might
explain adaboosts poor performance     

conclusions and future work
although the time periods in classical music are
very similar  machine learning was able to
provide relatively accurate period classification 
we observed how svms  with their propensity
for high dimensional features  were able to
dominate other classifiers  meanwhile  we also
observed how adaboost  while very useful in
other fields  was seemingly unsuited for music
classification 
further research could improve bartok  and
might include 





using principal component analysis to
reduce feature noise and bloat
more complex features  e g  chord
progression  to potentially improve
accuracy
expanding input to also include audio files
and other types of musical notation



application to music domains outside of
classical music to tackle different genres or
any other form of music

acknowledgements
first and foremost  we would like to thank
andrew ng for his invaluable lectures and
machine learning advice  and the entire cs    
staff for their support throughout this quarter 
we would also like to thank windows azure 
which provided computational credit for our
project  we decided to use azure because it
provided
dedicated
high
performance
computation and a central platform for project
development 

references
    mckay  cory and fujinaga  ichiro 
 automatic genre classification using large
high level musical features   in proceedings of
the international conference on music
information retrieval        pp          
http   citeseerx ist psu edu viewdoc summary 
doi                
     classical midi connection   classicial midi
connction 
accessed
  
oct 
     
http   www classicalmidiconnection com classi
cal html 
     music    a toolkit for computer aided
musicology   music    aug        accessed   
oct        http   web mit edu music    
    scikit learn  machine learning in python 
pedregosa et al   jmlr     pp            
     
    langlois  jeffrey b   musical styles   music
anthology     june        accessed    oct 
      http   www musicanthology org  p   
    freund  yoav  schapire  robert e         
a decision theoretic generalization of on line
learning and an application to boosting 
citeseerx                
   
andreas
mller
       
kernel
approximations for efficient svms  and other
feature extraction methods 

   

fi