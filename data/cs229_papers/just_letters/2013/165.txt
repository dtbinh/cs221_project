guiding wind farm optimization with machine
learning
bovet  charles
bovet stanford edu

iglesias  ramon
rdit stanford edu

december         

 
   

introduction
motivation

wind farm micro siting is a complex process that requires multidisciplinary
analysis and optimization  the problem consists not only of positioning the
wind turbines in the locations within the site that have the most wind energy
potential  but also it has to minimize wake interference between turbines  this
means that usually the sum of the expected isolated turbines is less than the
actual performance  additionally  cost of turbine installation varies with the
terrain and there is significant cost of road and collection system installation 
additionally  wind farms are increasingly large and complex  constraint wise 
making inefficient optimization algorithms impractical  all these different parameters add up to the complexity of micro siting wind farms  however  the
performance of the wind farm will largely depend on it 

   

background

current industry practice uses gis based software to estimate the energy capture given turbine siting and meteorological conditions  an example of this is
openwind by aws truepower  openwind uses gis file formats to develop a
model and simulate wind farm performance including wake effects  additionally 
it offers an optimization module that is mostly based on gaussian movements
of the individual turbines   however  the optimization is too inefficient for large
wind farms  on the order of     s of turbines  
on the other hand  academics have tackled the problem with a variety of approaches from standard genetic algorithms  ga   particle swarm optimization
 pso  to covariance matrix adaptation based evolutionary estrategy  cmaes  and morphogenetic engineering  me       in general  these approaches
tend to either find excellent solutions but are highly costly computation wise or
find decent solutions with decent  openwind  or excellent  me  computation

 

ficosts  additionally  with the exception of the openwind optimization  most
studies run on simplified models 

   

objective

thus  our objective is to improve current optimization practices with machine
learning algorithms  our hypothesis states that with the tremendous amount
of iterations that are run through evolutionary algorithms  the data produced
should be useful for doing better decisions when updating our candidate solutions  in this sense  there are two approaches that can be taken  first  we can
run an off the shelf ga and tweak it such that as more and more information is
available  the subsequent populations are created based on a learning algorithm 
similar to the learnable evolution model  lem       the second approach  is to
take the morphogenetic engineering approach and train an agent  representing
an individual turbine  to populate a given terrain after several iterations  however  because our intent is to be able to use openwind simulation capabilities to
estimate the fitness function and openwind currently does not support variable
number of turbines when used externally  we will stick to the first approach 

 
   

methodology
input and output data

different to most machine learning approaches  our problem setup requires us
to generate our data in the fly  we will achieve this by using openwind as the
fitness evaluation  but running the optimization algorithm outside of it  in this
setup  the algorithm produces several candidates with specific feature values
 the positions of the turbines  and receives from openwind a fitness value for
each of them that the algorithm uses to learn  there is precedent of algorithms
that attempt to tackle optimization problems in a similar fashion  in particular  a specific area of evolutionary algorithms called estimation of distribution
algorithms     use the same update generate loop to guide the optimization 
using this background study and our knowledge of machine learning  we decided that the problem at hand closely resembled the spam filter problem  in
our case  a discretized grid of  x  y  points can be expressed as a binomial vector
v with each of its entries representing a specific combination of x and y and the
values of its entries being   if it contains a turbine and   if it does not  once
we obtain the performance of each set of positions  we rank them and take top
    as high performing  thus  each sample is given a value of w     if they
are on the top five  and   otherwise  using this two transformations  we have
our sample data  v  i    w i    for each loop that will feed our learning algorithm 
given the level of similarity with the spam filter problem  we decided to use
naive bayes as our learning algorithm  finally  once our algorithm has learned
the parameters  it uses that same distribution to generate  new individuals
that are fed to the openwind instances 

 

fifigure    summary of the optimization loop

   

results and discussion

after running the optimization for      generations we got a decent overview
of our performance  the following paragraphs summarize our findings 
solutions and performance as seen in figure    the solution improved
rapidly on the early iterations  as it is in most optimization processes   however  it suffered of diminishing returns  it is interesting to note  however  that
the mentioned figure presents the results as a fraction of the distance between
the theoretical maximum  when all turbines absorb the full potential  and an
approximated minimum  where all the turbines are clustered together as close
as possible   in that context we see that our algorithm finds a very good solution  similar to the fractions presented at wilson et al          for the ga   but
at a much higher level of computational expense     k simulations vs    k  
average error as a sanity check to see the validity of our algorithm  we
estimated the average error of the naive bayes on each generation via crossvalidation  as can be noticed in figure    the average error of each generation
oscillates around      being much higher than what we had anticipated  we
believe that perhaps using algorithms that take the structure of the relationship
of the features in to account could be more effective 
final distribution as an additional exploratory endeavour  we compared
the final distribution of the parameters and the performance of the turbines
in the best solution  we can see in figure   first that  as expected  the best
solution has turbines where the distribution expects them to be and additionally 

 

fifigure    improvement on the best solution 

figure    average error by generation 

 

fithe performance of the turbines are generally higher where the probability of
being selected is higher 

figure    final distribution of the parameters compared to the best solution 
note that the vertical axis represents performance for the best solution and
probability for the distribution 

 

conclusion

while the optimization did work  the performance is no where near to our
expectations  to achieve similar results as in previous papers we needed much
more simulations that are not feasible for our intentions  we believe that a big
improvement could be done by using a structure inferring model  like bayesian
optimization algorithm  that can detect the subtle influence that each turbine
has on the rest  an additional step could be using the performance of the
individual turbines as well as the whole  in this fashion  we could probably give
preference to higher performing turbines over just turbines that tend to appear
in multiple good solutions  finally  our method used

references
    wilson  dennis  awa  emmanuel  cussat blanc  sylvain  veeramachaneni 
kalyan  oreilly  una may  on learning to generate wind farm layouts 
proceeding of the fifteenth annual conferenc on genetic and evolutionary
computation conference  pages          acm new york  ny       
    michalsk  ryszard s  learnable evolution model  evolutionary processes
guided by machine learning machine learning  pages       acm       
    larranaga  pedro  a review on estimation of distribution algorithms  in estimation of distribution algorithms  pp           acm  i springer us       

 

fi