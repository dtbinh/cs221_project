optimizing hotel ranking for higher purchase rates

zahid hossain
computer science
stanford university
zhossain stanford edu

michael kun yang
mathematics   statistics
stanford university
kunyang stanford edu

khaled alturkestani
computer science
stanford university
khaled stanford edu

abstract
the challenging problem of smart recommendation engines is constantly being investigated  a more
specific subset of this problem that we investigate in this paper is the ranking of a small set of items
based on limited information about user preferences  in this paper we present two models that we
implemented for ranking result sets of hotels returned by expedia com in response to user submitted
search queries  the first model impelements a regularized linear regression algorithm  and the second model is a modified naive bayes algorithm  we trained both algorithms on around    million
datapoints then made predictions on smaller subsets of the training data 

 

introduction

the goal in ranking is to order a set of inputs in accordance with the preference of an individual or a population  in this
project we consider the ranking   or sorting   of the set of hotels returned by an online travel agent  ota  in order to
maximize purchase rates  hotel inventory is very important since users easily jump from website to website  as such 
having better rankings of hotels for specific users with the best integration of price competitiveness gives an ota the
best chance of winning the sale  the challenge of this project is to sort hotels according to the likelihood of a user to
eventually book a room  more specifically  given a search query performed by a user on expedias hotels database and
the returned result of up to forty hotels  our task is to sort the hotels according to the likelihood of the user booking a
hotel 
one of the most common and effective models used in building e commerce recommendation engines is collaborative
filtering  skkr     in fact  there have been several impelementations of collaborative filtering based hotel recommendation engines  wl     ws     since a collaborative filtering method requires a lot of data points for each user to make
good predictions by comparing users preferences to each other  we decided to not pursue this direction in our projec 
in addition  collaborative filtering has been explored many times before  and we wanted to explore other models 

 

dataset

we were provided with a training dataset of around    million data points and a testing dataset of around     million data
points  each data point has    fields  which represent information about the search query that the user performed and
one of the returned hotels  in other words  each search query is represented by up to forty data points  where each data
point contains information about one hotel  moreover  fields in the each data point have information about the search
query  such as when it was performed  duration of the stay  and the number of people staying  information about the
user  such as the average star ratings they have previously assigned to hotels and the average of their pervious spending 
and information about the hotel  such as its star rating and price  and its price that is provided by up to five other expedia
competitors 
 

fiour first task was to parse the data  discretize some variables  and transform the data points into meaningful vectors  for
instance  a date field was discretized by month  where a date is represented by a twelve field boolean vector with the
value   assigned to the corresponding month  similarly  a country field was discretized into a     field boolean vector 
as a result  our original    field data points were transformed into     field x feature vectors 

 

methods and results

this section describes the two main methods that we investigated     a regularized linear regression model and    a
modified naive bayes model 
   
     

regularized linear regression
model

our first attempt was to regress the feature vector x against the response y  where y is the measure of the users preference
to book or click the hotel described in x  specifically  y is defined as
y  

 
    booking bool     click bool
position

where position   the position of the hotel w r t  the result list of hotels  booking bool     if the user booked the hotel 
click bool     if the user clicked on the hotel  and    and  are assigned weights  note that the way we modeled y
is such that it is higher if the user clicked on the hotel link  the user booked it  and or it was listed higher in the search
result  thus  the higher the value of y  the more likely that a user will book the hotel 
we used a regularized linear regression model where our  x  y  pairs are defined as mentioned above and in the data
section  our squared error loss function is defined as follows 
x
loss    
 yi  t xi      t 
i

where x  r    and    penalizing coefficient 
given the large size of our dataset      million data point   we implemented our learning model to run on an apache
spark zcf      distributed system on eight cores  running this code generates a   given the  value  we use matlab
to make a prediction 

     

measure of error

to compute our training error  we measure the deviation of our predicted ranking for a set of n hotels that were returned
for a certain search query from the actual ranking that was placed by expedia and was included in the training set  more
specifically  for the set h    h         hn   of returned hotels  their corresponding ranks r    r         rn   within the result
page  and the predicted ranks r     r          rn    by our model  our error  is defined as
pn
pn
 ri  ri   
 r  ri   
i  
i  
 i

   pn
 
n  
i    i   n      i  
 b n  
  c nb   c
note that the denominator represents the deviation measure of the worst case ranking where the hotels are completely
inverted with respect to the actual ranking 
     

results

after computing our  vector  we used it to make a prediction over a sample of         data points from our training
dataset  using the error equation above  our computed error was       moreover  figure   shows the q q plot of
residues  note that the heavy tail on the left is reasonable because of many missing values  when the hotel ranking
within a result set is missing from the training data  we set the position value when computing the score y to a large
number  say           which results in y being very small 
 

fiqq plot of sample data versus standard normal
   

quantiles of input sample

 

   

   

   

   

   
 

 

 

 
 
 
standard normal quantiles

 

 

 

figure    q q plot of residues  where the heavy tail on the left is expedted due to missing hotel position values from
the training set that result in very small y values 
   

modified naive bayes

in this section we describe an alternative  approach based on a modified version of naive bayes to address the hotel
ranking problem  a search query yields a list of candidate hotels which we label  denoted by y  with one of the three
classes  i e  booked  clicked and none     the goal is to predict the probability of a hotels true label given
a feature vector x 
   

model

we make the following modifications to the traditional naive bayes model to lift off the strong assumption of feature
independence for some selected features 
 there were features in a search query item that were clearly correlated  e g the price night  hotel   of the
hotel in the search result and the average price night  user price y   that a user has paid in her history  we
combined these two features into one by modeling them as a gaussian distribution on the difference  i e 



 
user price y   user price y  hotel  n user price y   user price y
one would expect that this distribution  given the user has booked a hotel  would have hu     unlike other
labels  in other words  a user would most likely book a hotel that agrees with the price range that she has spent
in the past 
 the rating  a number that varies from   to    of a hotel hotel and the average rating of the hotels that a user
has booked in the past user rating y are also combined similarly into a gaussian distribution of the difference 
i e 



 
user rating y   user rating y  hotel  n user rating y   user rating y
 
booked  user ends up booking the hotel  clicked  user clicks on the hotel but does not book it  none  user neither
books not clicks on the hotel 

 

fi finally we suspect that some hotels might be more popular during one part of the year instead of all year round 
therefore  taking only the date into account  we could make reasonable predictions on which hotel is more
likely to be picked by the user  towards this end we modeled the date as a floating number that denotes the
rank of that date within a year  e g        denotes   th april at       pm of any year because its the    th
day of a year and the fractional     captures the fact that its in the middle of the day  we learned a probability
distribution of this date given a hotel and a label y assuming its a gaussian  i e 
 
p  date hotel  y    n  date hotel y   date hotel y
 

since there are finite number of hotels  in our case         and three possible labels we have to learn a table
 
of size             sizeof float   mb for all the date hotel y and date hotel y
this way we model dependancies within some selected features  we construct our feature vector x to be a concatenation
of a set of continuous and a set of discrete random variables selected from a search query item like the following 
x    c    c        ca   d    d        db   

x  ra b

where ci are the continuous variables and di are the discrete variables  all the continuous
variables are modeled using

gaussian and all the discrete variables using some multinomials  i e  ci  n i   i  and dj  multinomial  j    note
that we do not put the feature date in the vector x but deal with it seperately as discussed in the following paragraph 
given a vector x we compute the probability of the hotel taking a certain label in two separate steps and combine them
assuming each step is an independent event  in the first step we compute the following probability
q
q
p  y  i p  ci   j p  dj  
p
q
q
p  y x   
y p y 
i p  ci  
j p  dj  
next  we compute the probability of the same label but using date and a given hotel by the following
p  date hotel  y p  hotel y p  y 
p  y hotel  date    p
y p  date hotel  y p  hotel y p  y 
we combine these probabilities assuming these two are independent events by simply taking a product 
p  y x  hotel  date    p  y x p  y hotel  date 
finally  given a list of hotels for a search query  we compute the above probability for a certain label and sort all hotels in
the decreasing order of probabilities  since the labels that are relevant for sorting are only booked and clicked
we only consider these two labels for the final result 
   

measure of error

to benchmark our algorithm we computed a normalized discounted cummulative gain  ndcg   jk    for a given
search query that consists of multiple hotels as potential candidates  we used hold out cross validation to compute
ndcg and repeated the process while increasing the training set size but keeping the test set fixed to obtain a learning
curve as shown in figure  
   

results

as shown in figure   the performance of naive bayes model plateaus out after a certain training set size which suggest
that it has a bias issue  apart from the strong assumptions of naive bayes model about feature independence  this is
quite expected  even with our modifications  because of the following reasons 
 our feature vector size  which is     is not as large as what typically has been seen to work very well with
naive bayes model 
 for every continuous variable in the feature vector we assumed a gaussian distribution which fails to capture
any multi modality that might be inherent in the dataset 
we also noticed that the best result was obtained when the hotels were sorted using only the probabilities of the
booked label while we did try to take some combination of booked and clicked probabilities too 
 

fi   

ndcg  normalized discounted cummulative gain

    
    
    
    
   
    
    
    
    
   

 

   

 

   

 
   
 
log dataset size 

   

 

   

 

figure    learning curve of our naive bayes model  each curve shows how ndcg varies with respect to the training
set size  in log   scale   the black curve is our naive bayes model  the red curve is generated when we sort hotels
randomly while the blue curve is generated when the hotels are sorted in the worst possible manner  i e  the most likely
hotel to be booked is listed at the end 

 

conclusion

we implemented and regularized linear regression model and a modified naive bayes model to rank a set of hotels
returned to a user for a given search query  where the objective was to sort the hotels according to the likelihood of the
user booking one and  as a result  increase overall purchase rates  the linear regression model had a high error of      
and the naive bayes model performed better than random ranking  we think that further investigation is needed since
our results are preliminary  for instance  in the linear regression model there are many ways of computing the score
y other than the one we used that might yield better predictions  another modification to the model would be to train
it over hotels using a subset of the feature vector x  train it over users using another subset of the feature vector  and
then combining the two models to predict a final score y  moreover  the naive bayes model could potentially be more
intelligent  and less naive  by combining different features that are correlated 

references
 jk   

kalervo jarvelin and jaana kekalainen  cumulated gain based evaluation of ir techniques  acm transactions on information systems  tois                      

 skkr    badrul sarwar  george karypis  joseph konstan  and john riedl  analysis of recommendation algorithms
for e commerce  in proceedings of the  nd acm conference on electronic commerce  pages        
acm       
 wl   

gao hu ming li wei li  hotel recommendation system based on collaborative filtering and rankboost
algorithm  microcomputer information               

 ws   

qinzhu wu and william wei song  a computational model for trust based collaborative filtering       

 zcf      matei zaharia  mosharaf chowdhury  michael j franklin  scott shenker  and ion stoica  spark  cluster computing with working sets  in proceedings of the  nd usenix conference on hot topics in cloud
computing  pages            

 

fi