cs     final project

generating sheet music from audio
files
jan dlabal and richard wedeen
stanford university
jdlabal stanford edu  rwedeen stanford edu

december         
abstract
this paper describes a method for using supervised learning to generate sheet music from audio files of
single instrument melodies  support vector machines were used to detect the presence of up to    notes
with one versus all classification  we also outline preliminary steps toward transcribing a whole melody
by using a sliding window to detect note changes in an audio sample 

i 

introduction

any amateur musicians would like to
be able to play popular songs  such as
those they have in their itunes library 
however  the only way to obtain sheet music
for a song is to buy professionally made copies 
which are often either expensive or unavailable 
this creates a barrier for people to truly enjoy their music and confines them to listening 
instead of playing  the songs they love 

m

to solve this problem  we explored using
supervised learning to generate sheet music
from audio files so that musicians can obtain
sheet music quickly and cheaply  we focused
on generating sheet music for single instrument melodies by breaking the problem into
three stages  single note classification  transition probability markov models  and notechange detection 

ii 

i 

data

we generated individual notes and major minor chords from midi files  computer
representation of sheet music  using an assortment of    soundfonts 

 a  time domain

single note classification

in single note classification  we trained multiclass svms with gaussian kernels in oneversus all classification for checking whether
a given note is present in the input  which included single notes and major minor chords 

 b  frequency domain
figure    fft of the raw input data

 

fics     final project

a soundfont is a file that a synthesizer uses
to generate actual raw samples from the midi
files giving the notes that should be played 
this gave us around      wav files each for
single notes  major chords  and minor chords 
figure  a shows an example of a generated wav file from the combination of a sound
font and a midi file representing a single note 
we then applied a fast fourier transform to
each sound file  see figure  b   this was then
binned to reduce overfitting  bins grouped
multiple adjacent frequencies as shown in figure   below  these binned frequency vectors
were then used as learning features 

figure    binary vector representation of a c major
chord

we then trained svms for every note with
the training data  for example  the svm for
middle c was trained to predict whether or not
a sound file contained middle c  this means
that it should predict a   even if it was fed an
a minor chord  because that chord consists of
the notes   a  c  e  which contain c 

iii 

figure    binned fourier frequencies

finally  we randomly separated the input
data into a training group and a testing group
that contained     and     of the data  respectively 

the negative class of our svm corresponded to
an input that contained the note  and the positive class corresponded to an input that did not
contain the note  to classify a new note  the
svm with the most negative score was selected 
this corresponds to picking the lowest possible
  xnew   as the most probable note  where xnew
is a new example 

iii 
i 

ii 

training

each sound file was labeled as a binary valued
vector with ones indicating which notes were
in the file  for example  a c major chord starting on middle c  i e   the set of notes  c  e  g   
would be a vector containing  s at indexes    
    and     see figure     similarly  c minor
would contain  s at indexes         and     finally  a wav file containing only c would be
represented by a   only at index    
 

classifying a single note

note change detection

data

we generated single instrument wav files of
melodies from midi file soundfont combinations 

ii 

method

note change detection aimed to find the points
that notes changed in a melody  the goal was
to produce equal note intervals in the sound
file that could be fed into the single note svm
classifier 

fics     final project

to detect note changes  a sliding window
was used to sweep across the melody audio
file  at each instant  single note detection was
applied to the window and the functional margins from the svm were recorded  the minimum of these margins corresponds to how
confident the svm was in predicting what
the note was  windows that contain more than
one note value will cause the svm to be less
confident  and output a minimum margin
value that is greater than the minimum margin
of a window that contains only one note value 

 a  single notes and major minor chords

 b  just chords
figure          cross validation errors

single note classification on a melody line
with pre specified note change values yielded
    accuracy 

ii 

figure    minimum margin values

if the minimum margin value at a window
value was less than the previous  then it was
deemed to be more confident than the previous and our algorithm marked the window
value as a new note 

iv 
i 

note change detection

running note detection  identifying equal note
windows  and performing single note classification on a melody genererated from a midi
file yielded a sequence of notes that shared a
longest common subsequence around     as
long as the original  correct  sequence of notes 
different sliding window lengths yielded different accuracies  but they were all around this
value  see figure    

results

single note classification

the cross validation test errors on the test set
 single notes and chords  are displayed below
 figure     the test error for note j corresponds
to the percentage of sound files that the svm
correctly predicted whether or not it contained
note j  figure   a  corresponds to the test error when using svms that were trained on all
combinations of major minor chords and single notes  whereas figure   b  corresponds to
training only on major minor chords with the
testing is still done on per note basis 

figure    note change detection accuracy on melody

the final results are summarized in the table below  isolated corresponds to the case
 

fics     final project

where the note changes were pre specified 
melody corresponds to the unspecified case 
table    accuracy of melody detection

method

accuracy

isolated
melody

   
   

v 

discussion

the single note classification performed surprisingly well on the given dataset of a wide
variety of electronic instruments  this could be
attributed to the fact that there was no noise
present to corrupt the data  something that
would be common in a real world example 
we suspect that the classifier peformed better on the lower range notes  see figure    because some instruments were incapable of producing these low registers and consequently
these svms could tailor more specifically to
this smaller subset of instruments 
note change detection worked reasonably

 

well given the simplicity of the method  it
might be improved by noticing that in its current state the method is susceptible to false
positives since random fluctuations may cause
a margin minimum to be less than the previous 
signalling a change  a similar approach worth
exploring would be to check if the minimum
has dipped below a certain threshold to signal
a note change 

vi  conclusions and future work
overall  this approach provides a good start
to generating sheet music from audio input 
however  it only considered the case of a single
instrument and avoided the much hairier problem of separating out multiple instruments 
for audio files with sufficiently different leftright stereo output  the separation task can be
simplified by performing independent components analysis  unfortunately this will only
simplify a small subset of music files 
future work should focus on this problem
as well as testing how well this method works
when the signal to noise ratio is low 

fi