classification of mobile device accelerometer data for
unique activity identification
kai kuspa  tony pratkanis
december         
abstract
accelerometer datasets from    smartphones were analyzed in order to distinguish
between different user activities  training data from jogging  walking  standing  stair
climbing  ascending and descending  and sitting were collected for each device at a sampling rate of   hz  the spectrogram for each activity was transformed using pca to
reduce the dimensionality of the dataset  and the eigenvalues of three dimensions  x  y 
and z coordinates of the accelerometer  were used as inputs for gaussian discriminant
analysis to label the recorded activity  kwapisz et  al  explored the possibility of using
accelerometer data to classify user activity  and achieved a     success rate in their classification  using our methodology  we achieved a global success rate over      however  our
results are generated using a direction agnostic approach which increases the practicality
of such a system for real world use 

 

introduction

the increasing prevalence and diversity of sensors in smart mobile phones provides exciting
new opportunities to collect and analyze continuous sensor data  data mining information
from cameras  microphones  accelerometers and other sophisticated sensors could provide advantageous feedback informing the mobile device about the users daily activities  providing
context aware information to the user could further enrich the experience and utility of owning
a smart device  in this paper we describe a new application of machine learning algorithms
that aim to classify physical user activities such as running  walking  and standing based on
accelerometer data  an accurate system such as this could be used to create context sensitive
mobile applications that provide content and direct device alerts based on the users actions
 e g  sending calls to voicemail if the user is jogging   further  this information could be used
to provide data for quantified self applications  in which people utilize data analytics in an
effort to track individual health habits such as measuring the users daily amount of exercise 

 

previous work

there has been a diverse history of previous work in the field of activity recognition  many
methods involve specialized devices that are not general purpose mobile devices  these devices
 such as fitbit  are expensive and represent an extra burden to the user who is often already
overwhelmed with information  therefore  work has been directed to accomplishing similar
results with general purpose devices such as phones and music players  kwapisz et al  and
saponas et al  are examples of schemes for activity recognition  however  these schemes are
deficient because they are sensitive to the way in which the phone is affixed to the user  making
them impractical for real world scenarios  despite this  commercial systems are available for
both ios  moves  and android  provided by google   these commercial systems also offer
reusable apis for development of applications on top of these classifiers  however  they suffer
from a limited range of activities recognized and they are cloud services  leading to privacy
concerns  these deficiencies motivated us to create an improved mobile device based activity
recognition system 
 

fi 

methods

our general methodology was to take samples of accelerometer data from users phones and
attempt to predict the activity  the general expectation of the workflow of our project is that
the user will first use a graphical interface to train their phone by specifying what activity
they are undertaking  once this training process is completed  the system will be able to
automatically detect the current activity  we decided  in agreement with kwapisz  et  al  
to employ    second windows of data in order to gather enough data to successfully classify
activity without greatly inconveniencing users  we also believe that this window contains
enough time for activities with periodic repetitions  e g   footsteps  to become evident  we
then took these windows and fed them through various algorithms to generate a feature space
and then classified based on this space 

   

wisdm actitracker dataset

the actitracker dataset is a high quality dataset produced
by kwapisz  et  al   at the university of fordham  the
actitracker dataset consists of over   million data points
from    different users  the data is further subdivided into
six labels  walking  jogging  sitting  standing  upstairs  and
downstairs  the data consists of raw time series data with
time  x  y  and z for each data point  the x axis represents side to side  across the hips   the y axis represents
the vertical axis and the z axis represents front to back motion  the phones were placed in the pockets of the participants pants  but carefully oriented such that the axis labels
always held  further  the data was sampled at a constant
figure      seconds of raw acfrequency of    hz  so the resulting    second windows had
celerometer data for a user
    measurements 
in addition to the advantages of being highly controlled
and labeled  this dataset has the advantage of having a performance benchmark in that
kwapisz  et  al  used this dataset to achieve      correct behavior prediction rate  the
approach used was a multilayer perceptron algorithm using an ad hoc feature set from each
of the windows  including average acceleration  standard deviation  peak to peak time  and a
histogram of the data 
we had to modify the actitracker dataset slightly for
our purposes  first  we found some issues with duplicate
data  as well as obviously irrelevant data  data with  
timestamp   this data was removed  second  we split
the dataset into separate data series  by user and then by
activity  finally  we split each of these separate datasets
into a train section  the first half of the file  and a test
section  the second half of the file  

   
figure    dimensionality reduced
plot of the   direction agnostic features  pca eigenvalues and length
statistics   black represents standing  the blue walking  the red upstairs walking  the green downstairs walking  and the cyan jogging 

pca based system

as stated previously  our algorithm took raw time series
data and converted it to feature space  we initially did
this using principal component analysis  or pca  on the
raw values of the multitude of     sample windows  we
used the eigenvalues and eigenvectors from this process
as features for the classifiers  in an attempt to improve
classification  we attempted to add other features  such
as the products and sums of the eigenvalues  however we
concluded that this was ineffective in improving classification  yet greatly slowed the classification process  therefore we deemed this ineffective 
 

fi   

ad hoc features and spectrograms

in attempt to add more features  we added four ad hoc features to our classifier  first  we
considered the lengths zero meaned accelerometer vectors and created a feature for the mean
and standard deviation of this value  second  we created similar features from the raw lengths
of the vectors  these four features were direction agnostic and easily calculated 
we also extracted features from a fast fourier transform  spectrogram  of each of the individual accelerometer data series  for each of these axes  we found average of the most prevalent
frequency at every point in time  the calculation of these three features involves a great deal
of additional computation 

   

direction agnosticism and training methodology

in selection of features  we considered two variables in addition to efficacy  computational complexity and directionagnosticism  obviously  it is important that the features
not be too complex to evaluate otherwise that they would
tax the device and thus shorten battery life  direction
agnosticism is important because the user may place the
phone in their pocket in any orientation  it is important to
note that these direction agnostic features are not invariant
to all rotations of the phone   during the    second window
rotations may still impact the feature values  however  if
the phone is rotated for the whole window then the feature
values will not be changed  the direction agnostic features figure    spectrogram of one axis
consist of the pca eigenvalues and the length values  the of accelerometer data
pca eigenvalues are direction agnostic because pca eigenvalues are invariant under rotations of the initial dataset  while the length values are direction
agnostic because of basic geometry 
given these criteria  we split our data into   sets of features  the simple direction agnostic
features  pca eigenvalues and the lengths   the simple direction dependent features  pca
eigenvectors   and the fft features  we ran the classifiers on each of these categories but
included features from the less burdensome categories as well  additionally  we trained the
classifiers in two approaches   in one case  we trained a classifier for each user and in the other
case we trained one classifier for all users  thus  we had a total of   trials for each classifier
for a total of    trials between the svm classifier and gda classifiers 

 

results

we present our results in terms of tables for success of the various classifiers on our dataset 
split up as     train and     test 
name
gda  non directional 
gda  directional 
gda  spectrogram 
svm  non directional 
svm  directional 
svm  spectrogram 

individual
       
       
       
       
       
       

global
       
       
       
x
x
x

individual simplified
       
       
       
       
       
       

global simplified
       
       
       
x
x
x

table    this table shows the percent of test cases correctly identified by each of the classifiers
in each of the datasets  the individual columns mean that the classifiers were individually
trained for each user while the global columns mean that the classifiers were trained for all
users  we found that a common source of confusion was the upstairs and downstairs results  so
the simplified columns represent the case where such misclassifications between downstairs
and upstairs are ignored  an x represents that classifier failed to converge in this case 

 

fidownstairs
jogging
sitting
standing
upstairs
walking

total
      
     
      
     
      
     

downstairs
     
     
     
     
     
     

jogging
     
     
     
     
     
     

sitting
     
     
     
     
     
     

standing
     
     
      
     
     
     

upstairs
     
     
     
     
     
     

walking
      
     
     
     
      
     

table    confusion matrix for the non direction individually trained svm          overall
success rate   the percentages represent the percent of misclassified events labeled as a given
row misclassified as a give column  the total column is the sum of all columns  

 

conclusion and future work

we successfully developed a high performance classifier for recognizing mobile device user
activity  the classifier achieved good results except in the case of confusing upstairs and
downstairs  and to a lesser extent stair walking and level walking  despite being directionagnostic  the classifier performed similarly and even better than direction dependent classifiers 
in addition  our classifier is efficient as the pca and related features consist of very few
operations  in addition  our svms generally had very few support vectors  on the order of
        meaning that applying the svm classification is efficient and maybe possible in real
time 
to improve the system accuracy  we hope to develop a system to distinguish stair walking
and normal walking  based on previous experience of the author  we believe that the integration
of accelerometer data fused with magentometer and gryo data  standard on modern mobile
devices  can predict elevation change over the course of a window  this would improve our
results  unfortunately this is not possible with the current dataset because it does not contain
gryo or magnetometer data 
in order to continue this project  we must actually develop an application for mobile devices
 as all our testing was performed off line  and actually attempt to recognize activities  we
also hope to experiment with different phones  users and additional activities  such as biking 
driving  and riding public transportation  finally  we would like to distribute this codebase as
a library for other developers to use in their applications 

references
    jennifer r  kwapisz  gary m  weiss  samuel a  moore  activity recognition using cell
phone accelerometers  sigkdd explor  newsl         march              
    t  scott saponas  jonathan lester  jon froehlich  james fogarty  james landay  ilearn
on the iphone  real time human activity classification on commodity mobile phones 
cse tech report uw cse         
    moves  protogeo  http   www moves app com  
    recognizing the users current activity  google 
http   developer android com training location activity recognition html 

 

fi