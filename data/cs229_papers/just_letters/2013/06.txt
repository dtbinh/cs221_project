 

predicting flight on time performance
arjun mathur  aaron nagao  kenny ng

i  i ntroduction
time is money  and delayed flights are a frequent
cause of frustration for both travellers and airline
companies  after just a few minutes delay  the
consequences range from economic  missed connections
and cancellations  to environmental  wasted fuel  and
social  loss of productivity and airport congestion  
thus  we used flight arrival and departure data to
classify whether a flight would be on time  so that
airlines can learn which features predict delays and
work to mitigate them 

ii  data c ollection and f eaturization
our dataset consists of flight information sent by
major airlines to the u s  department of transportation 
and collated for the american statistical associations
     data expo      for delayed flights  airlines report
what caused their delays  summarized in the table below
    
aircraft arriving late
air carrier delay
weather
volume

      
      
      
     

our dataset contains features that are related to these
causes  including previous flight information  air carrier
 airline   and origin destination airport  so we expect it to
be predictive  we supplemented our dataset with airplane
age information and weather information obtained from
scraping weather underground 
to obtain the airplane age  we looked up the plane
tail number for each flight in the federal aviation
administration  faa  database using a simple get
request  to mine the weather data  we first filtered the
training and test examples for all unique dates and airport
locations  then  we used the requests and beautifulsoup
python packages to download the weather data for each
unique date at each airport and parse the data to csv
format  and finally  leveraging pythons shelve library
and the pytz package  we matched each flight example to
weather data recorded within half an hour of the flights
scheduled departure time and created the following new
features  temperature  fahrenheit    visibility  miles  
wind speed  mph   precipitation level  binary indicating whether any precipitation presently   and weather

conditions  categorical   weather conditions  such as
freezing rain   thunderstorms  and patches of fog  were
ranked on a      scale depending on its impact on
flight delays  an example of the inutition is as follows 
thunderstorms have a lower rank than freezing rain since
freezing of any type has direct impact on the runways
 which leads to delays  whereas thunderstorms have no
effect on takeoff and do not affect the plane upon its
ascent above the trophoshere 
the carrier and origin destination airport were categorical  so we generated binary features for all   
airlines  the    highest traffic origin airports  and   
highest traffic destination airports      of flights did not
depart from these popular airports  so these examples had
  values for their binary features  some algorithms  e g 
svm with gaussian kernel  required the data to first be
standardized with mean   and variance    while others
 e g  random forest  did not 
the dataset is relatively large  so we randomly sampled      training examples and     testing examples to
use from each month in       for a training set of      
examples and a test set of      examples   plotting
bias variance learning curves confirmed that adding more
training examples would not improve accuracy 
for our project milestone  we had defined a flight
to be delayed if it had any positive delay  however 
because our prediction accuracy was low  we instead
use a different definition  a flight is delayed only if the
flight is      minutes delayed  which is the official
cutoff defined by the faa  notably  by the     minute
criteria      of flights were delayed  by the     
minute criteria  only     are delayed 

iii  m ethods and r esults
a  logistic regression
for initial testing  the matlab glmfit library was
leveraged to create a logistic regression model  a
bayesian regularized logistic regression model with
newtons method optimization was also created  cross
validation was used to optimize parameters for the
regularized map estimate  the following are our
results 

fi 

logistic
regression
maximum
likelihood
estimation
map
regularized 
      

accuracy

precision

recall

     

     

     

f 
score
     

     

     

     

     

distributions to independently fit the data  however  we
discovered vastly different results from the two different
distributions 

the following bias variance curve was plot to ensure
convergence and check for error properties 

from the learning curve of a naive bayes model
using a gaussian distribution  we see that the training
error is unacceptably high and there is a small gap
between training and testing error  which is indicative
of high bias 
the plot indicates convergence after       training
examples  furthermore there is low variance  logistic
regression achieved the best f  score of        
b  naive bayes
for classification with naive bayes  we used the
supervised learning methods from matlab s statistics
toolbox 
initially  in our naive bayes classifier  we attempted
to fit a gaussian distribution to all the features 
however  for some training samples  mainly small
sample sizes   the variance of certain features was
zero  which resulted in a degenerate normal fit   this
signaled that some of our features may not necessarily
follow a normal distribution  specifically  we realized
that    of the features are continuous whereas the other
   features  created from the non numerical data for
weather conditions  airline carrier  airport origin  airport
destination  and previous flight delay  are categorical 
then  in order to create a naive bayes model that takes
into account both continuous and categorical data  we
considered the following methods      independently fit
a gaussian naive bayes model on only the continuous
part of the data and fit a multivariate multinomial
naive bayes model on only the categorical part of
the data  transform the entire dataset by taking the
class assignment probabilities as new features  and
fit a new gaussian naive bayes model on these
new feature  or     transform all continuous features
into a categorical representation by binning  at first 
we attempted the former method by using different

however  from the learning curve of a naive bayes
model using a multivariate multinomial distribution  we
see that there is high variance  or overfitting  
since high bias can be remedied by introducing a
larger set of more predictive features  this further tells
us that either the continuous features are relatively insignificant or that these features do not follow a normal
distribution  thus  we opted to follow the latter method
and transform all the continuous features to categorical
representations 
to transform from continuous to categorical  we
computed percentiles for each continuous feature  then 
we binned the continuous features using the percentiles
as bin boundaries and domain knowledge  and intution 
about flight delays  for example  scheduled departure
and arrival time was binned into early     and late    
flights and visibility was binned into no visibility     
low visibility      and okay visibility     since anything

fi 

above low visibility is deemed okay to fly by the
national weather advisory   after transforming all the
features into categorical representations  we plot the
following bias variance learning curve 

 especially delayed examples   at the expense of having
a more complex decision boundary 
svm

accuracy

precision

recall

f 
score

gaussian 

      

    

    

     

      

    

    

    

           c  
    
gaussian 
           for
each class
ci  f req i  

our results from the various distributions and features
experimented with for naive bayes classification is
summarized below 
naive bayes

accuracy

gaussian
distribution  only
continuous
features 

     

multivariate
multinomial
 only categorical
features 

     

multivariate
multinomial  all
features 

     

precision
     

recall
     

f 
score
     

plotting bias variance learning curves showed that the
gaussian kernel had       accuracy on the training
set but was less accurate on the testing set  indicating
high variance  thus we also used a linear kernel  to
optimize the regularization parameter c  we again used
grid search and stratified    fold cross validation 
svm

accuracy

precision

recall

f 
score

linear  c       

      

    

    

     

linear 
ci  f req i  

      

    

    

     

the linear kernel generally performed better than the
gaussian kernel 
     

     

     

d  multiclass classification
     

     

     

from our results  we have that the multivariate multinomial naive bayes model  both subset and entire set of
features  performed the best  and about equal   achieving
an     accuracy and a f  score of        indicating
both high precision and high recall 
c  svm
for the svm  we used the python library scikit learn 
which wraps liblinear and libsvm 
initially we used a gaussian  rbf  kernel 
k x  z    exp   x  z       to optimize the gaussian
kernel parameter  and the svm regularization constant
c  we used exhaustive grid search with exponential grid
spacing  each    c  pair was evaluated using stratified
   fold cross validation  where stratified means that
each fold contained the same proportion of late and
non late examples as the complete set  we found that
higher values of c worked best  which means that the
svm aimed to classify all training examples correctly

we also ran multiclass classification because only
one previous project tried it  to do so  we split our
late class into two classes  class   between    and   
minutes late  and class   for      minutes late  an
svm with linear kernel and one vs  all strategy almost
never predicted class    so we used an svm with a
gaussian kernel and one against one strategy  create
one svm per pair of classes  and to predict  the class
which receives the most votes is selected  
confusion matrix 

actual

 
 
 

predicted
 
 
 
         
        
  
    

overall accuracy was         recall for class   was
only       but recall for class   was higher at       this
is because our classifier predicted class       more
often than class    despite the fact that more flights
are actually class    this suggests that class   flights
 between    and    minutes late  do not have strong
distinguishing characteristics in the dataset  compared to
class   flights 

fi 

e  random forests
after performing parameter optimization on the
number of trees in the forest  and the size of the random
subsets of features considered when splitting a node 
we found that a random forest classifier with     trees
considering     features had        accuracy      
precision  and      recall  we confirmed that more trees
is better only up to a certain critical value 

iv  a dditional m ethods
a  feature selection

 

  m   
alternatively  we also used fishers ratio   m
 v   v     
where m  and m  are the means of our two classes  delayed or not delayed  and v  and v  are the variances  to
measure the discriminating power of each feature  once
again  after previous flight delay  the most significant
features are weather conditions  feature indices       
and          and arrival and departure times  feature
indices       
finally  forward search on logistic regression was
performed  the algorithm chose the following features
 in order       is previous flight delayed      departure
conditon level      departure time      arrival precipitation      departure wind speed      departure visibility 
    arrival condition level      origin airport      destination airport  overall both feature selection algorithms
showed that weather information  departure time  and
previous flight delay were the most important features 

b  precision vs  recall

first we performed filter feature selection to measure
how informative each feature was  the score metric
we used was the p value from a univariate statistical
test  by far  the most important feature was whether
the previous flight was delayed  next were the weather
features we added to the dataset  see high scores for
features          specifically the precipitation and
the condition level  e g  partly cloudy  at both the
departure and arrival airports  the other important
features were the scheduled departure time and arrival
time  see features    and    

because only     of flights were       minutes 
delayed  our dataset was skewed  so it was important
to study precision and recall rather than just accuracy 
this graph shows a precision recall curve when varying
the decision threshold of the hypothesis function  for
a linear svm  we also varied svm parameters to
optimize either precision or recall  refer to svm results
above   achieving an f  score of       

v  c onclusion
overall  accuracy from our algorithms were relatively
good  all algorithms were about     accurate  however  there is still room for improvement in recall  our
multiclass classification      min       min  showed
that flights between    and    minutes late do not have
strong distinguishing characteristics in the dataset  so
better features might improve recall 

fi 

the results from both our feature selection methods
revealed the following as the most predictive features 
the previous aircraft arriving late  weather  and departure time  these features matched air carriers reported
causes of delay 
in addition  more complex network based algorithms
may show significant improvement  often  when a
few flights are delayed early in the day  this causes a
domino effect that delays later flights  our model started
to capture this effect with our previous flight delay
feature  but network algorithms that fully represent this
structure may improve performance 

vi  r eferences
    the data  american statistical association  data
expo     
 http   stat computing org dataexpo      the data html 
    flight delays by cause  bureau of transportation
statistics
 http   www transtats bts gov ot delay ot delaycause  asp 
    flight standards service civil aviation registry
 http   www faa gov about office org headquarters offices avs offices afs afs     
    historical weather  weather underground
 http   www wunderground com history 
    how flightcaster squeezes predictions from
flight
data
 http   www datawrangling com howflightcaster squeezes predictions from flight data 

fi