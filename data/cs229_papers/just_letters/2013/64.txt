 
dense stereo matching using machine learning
nattamon thavornpitak

pallabi ghosh

introduction
many researches in computer vision have been focused
on developing algorithms to accurately determine depth maps  in
stereo vision  a pair of cameras at two different locations capture
a left and a right image which are slightly different images of the
same scene  due to different locations of the cameras  a  d point
will show up at different pixels in each image  to perform stereo
matching is to map a pixel in the left image to the pixel in the
right image that is corresponding to the same  d point  the
difference of locations of matched left and right pixel is called
disparity  disparity is inversely proportional to depth  an image
can have only a finite number of objects and hence a finite
number of disparity values  many algorithms such as sift have
been developed to perform sparse matching  which produce
matches for only a few keypoint pixels  however in some
applications such as robots navigation  it is better to have
disparity value and depth for every single pixel in an image  in
this project we explore an application of machine learning in
performing dense matching which will produce matches for all
pixels in the images 
background
sparse matching technique
sparse matching algorithms produce disparity values for
keypoints  there are many sparse matching techniques such as
matching by using scale invariant feature transformation
 sift   in this project  we use the algorithm developed by
geiger et al  to produce disparity values for keypoints  which will
be used as our training data     geigers algorithm first
preprocesses images by filtering input images with  x  blobs and
corner mask and then applying non maximum  and nonminimum suppression     speed up robust features  surf 
descriptors of each pixels are computed and the descriptors are
passed to a sobel lter  for a given keypoint pixel in the left
image  sum of absolute differences  sad  between its filter
response and the filter response of every pixel in the right image
are computed and the pixel of the right image that produces the
smallest sad is picked as the match 
daisy
daisy
is
a
computationally efficient dense
descriptor  in this technique
initially the gradient at each
pixel location in different
directions is calculated 
this can be represented by
go u v 
 
max  i o     
where o is the direction of the
gradient  and i is the intensity 
next we convolve this with
gaussian kernels of varying
image from    
standard deviation ie   in one
layer  a layer is a group of
circles with center equidistant from the pixel in consideration 
around each pixel and   in another layer and so on  we use a  
layered version of daisy as shown in the figure  same as used by

ayesha khwaja

the developers of daisy  e tola  v leptit and p fua in their
paper         in the figure  the gaussian smoothing is
proportional to the circle radius  also this entire figure computes
the daisy parameters for the central pixel  the overlapping circles
result in smooth results 
overview of our approach
we explore applications of learning algorithms
including multi class support vector machine svm  and k mean
clustering algorithm  we use geigers matching algorithm to
generate disparity values for keypoint pixels  these pixels and
their corresponding feature vectors are used to train our
algorithm  the disparity values for rest of the pixels in the image
are calculated using our trained model  our approach is justified
since for a given image  the number of disparity values is finite 
which would most likely be covered in one of the training pixels 
we initially use daisy parameters as our feature vector  later on
we add the normalized pixel location x  y coordinate  to the
daisy features  in addition  to generate some training examples in
smooth regions  we performed pixel padding according to a
heuristic that nearby pixels are likely to have the same disparity
value  finally  we try increasing the training size by finding the
disparity values of edge pixels using correlation based matching 
multi class support vector machine
our approach is to use geigers matching algorithm to
generate disparity values for keypoint pixels  these disparity
values are used as class labels  target variable   each keypoint
pixel in the left image of a given pair of images is a training
 
example  for a training example i in the training set of size m
we have a feature vector x and a class label c   the pixels
disparity value calculated from geigers algorithm  we use these
keypoints pixels and their disparity values to train our multi class
svm model  our algorithm extracts features from each of the
remaining pixels in the left image  and uses the trained svm
model to predict the disparity value  in this report  non keypoint
pixels in the left image are referred to as pixels in a test set or test
pixels  in this project  two sets of features are used and
compared  while the first set of feature consists of     daisy
descriptors of a pixel  the second set uses both daisy descriptors
and the normalized x and y coordinates denoting the location of
 i 

 i 

the pixel  let n be the length of each feature vector then x is
a n x   vector  therefore  a training set consists of a m x   label
vector c and a m x n feature matrix x  
 i 

 
c    
 

t

c    

c         c  i 
     t
  x
  x    t
 
   
x    
  x  i t
 
      t

   x   m 

 

    c   m 
 
 

 
 
 
 
 
 
 
 
  

the training set is input to multiclass support vector
machine available at http   www csie ntu edu tw  cjlin liblinear  

fi 
the test set consists of m non keypoint pixels of the left image 
to produce a dense map  we calculate feature vector x  i  for all m
test pixels and use the trained model to predict the disparity
value  c  i  of that pixel 
modified k mean clustering algorithm
in this approach  we modify k mean clustering and
apply it to our data  k mean clustering algorithm is a learning
algorithm for unlabeled data  however  in our scenario  pixels in
the training set are labeled with disparity values  but test pixels
are not  for each training example in the training set of size m  
 i 
 i 
we have a feature vector x and a class label c   which is a

the disparity value calculated from geigers algorithm  we
modify the algorithm as follows
initialization   number of clusters  k is the number of
distinct disparity values in the training set  the initial centroid
for the jth cluster is the average of features vectors of all pixels in
the training set that are labeled as the jth class 
for each class j   j   the initial centroid of the jth class is
m

j  

   c   j  x
   c   j 
 i 

i  
m

 i 

 i 

i  

iterations  
step    for each pixel in the test set  compute euclidean
distance between x  i   feature vector of the pixel and all cluster
centroids  j   assign the pixel to cluster c  i  that has the smallest
euclidean distance 
for all pixels in the test set  determine c  i 
c  i    argmin x  i    j

 

j

step     update the cluster centroids by averaging the
feature vectors of all pixels in the cluster include both pixels in
training and the test set  
for all clusters 

j


 

m

m

  c  i    j  x  i       c  i    j x  i 

i  



m

i  
m

  c  i    j       c  i    j 

i  

i  

  a  is an indicator function which is equal to   if the
statement a is true and is equal to zero otherwise  both steps are
repeated until the locations of cluster centroids converge  that is
when the norm of the change of cluster centroids of two
successive iterations is smaller than some tolerance value tol 
note that unlike k mean clustering algorithm  the labels for
pixels in the training set do not change 
pixel padding
motivation
it is likely that all pixels that belong to the same object
have the same disparity value since disparity values are
proportional to depth and all pixels in an object are likely to have
approximately the same depth  in addition  it is very likely that
the size of an object is larger than one pixel  therefore  if a given
pixel has disparity value c  it is likely that the pixels next to it has
the same disparity value since the next pixels probably belong to
the same object  in addition  consider a scenario that a pixel a
has a disparity value c and another pixel b  which is a few pixels
apart from a  has the same disparity value  in this case  it is
probable that the pixels in between a and b have disparity value
c 

a b
fig  
pixel padding
sparse matching algorithm produces matches for only a
few keypoint pixels  these keypoints are mostly edges and
corners  yellow dots in fig    are keypoint pixels detected by
geigers algorithm  keypoint pixel a is said to be adjacent to
keypoint pixel b if pixel b is the closest keypoint pixel there is
no keypoint pixel in between them on the same horizontal line  
note that pixel a and b are not next to each other but they are
the closest keypoint pixels  the trick is that if any two adjacent
keypoints have the same disparity value  it is likely that pixels
that lie between the two keypoint pixels are from the same object
and they should have disparity values c  we can assign all inbetween pixels to have the same disparity value c  however  if we
do that we will be relying on the assumption that all pixels
between a and b are in the same object  if a and b are very far
apart then the assumption may not be valid  therefore  every
time we have adjacent pixels that have the same disparity values
c  we first check the distance between the two pixels  for
example  if the distance is smaller than dmax     pixels  we will
assign a label c to in between pixels that are not further than
lmax   from either a or b  fig   demonstrates this trick 
keypoint pixels are shown in yellow and non keypoint pixels are
shown in white  for a pair for adjacent keypoint pixels a and b
that have the same disparity value c and are fewer than dmax
pixels apart  we assign disparity value c to pixels c  d  e  f and
g which are in between a and b and are within lmax    pixels
from a  similarly  we also assign disparity value c to pixel
j k l m and n since they are in between a and b and they are
with lmax   pixels from b  note that pixel h and i are not
assigned the disparity value c because they are further than lmax
pixels from both a and b 

fig  
by applying this trick  we can generate some examples
of pixels in smooth regions 
correlation based matching
in order to generate a relatively larger training size  we
use correlation based matching to generate more training
examples  we use block by block correlation based matching on
the edge pixels  we use the canny edge detector to get the edges

fiin the stereo pair  for each of the edge pixels  we search for a
small patch of area around that pixel in the left image and try to
match it to a similar patch around different pixels in the right
image along the same horizontal line  the sum of norm square of
the difference in the intensities of each pixel in the left patch and
its corresponding pixel in the right patch  i e   the correlation
between the two patches  gives us a measure of correspondence 
we calculated the correspondence between the patch in the left
image to different patches in the right image  the pivot pixel of
the patch in the right image with the maximum correspondence is
our closest match to the given pixel in the left image  once this is
done  difference between these pixel locations gives us the sparse
disparity map  extra training examples generated by correlation
based matching are appended to the training set 

 
the right column is the result obtained by kmean algorithm  the
second row is the result generated when neither pixel location
nor pixel padding is used  the third row is the result when pixel
padding is used but not pixel location  the last row is the result
when pixel location is used but pixel padding is not used 

results
the following images are results obtained by using
svm classification and modified k mean clustering algorithm
along with other techniques presented above  please note that in
an image  the same shade represents the same disparity value
 white means the object is the closest and black  the object is
farthest   parameters  as in described in our approach section 
used to generate these images are  image size     x      tol   
dmax     lmax  

fig    demonstration of the effect of using correlation
based matching to generate more training examples  the first
row is the image and groundtruth  the left column is the result
from svm classification and the right column is the result from
k mean clustering algorithm  the middle row is the result
obtained when pixel location and pixel padding is used  the
bottom row is the result obtained when pixel location  pixel
padding and correlation based matching is used 
fig      are results obtained using svm and k mean
clustering algorithm  the top row is the image and groundtruth
and the bottom row is disparity value obtained from svm left 
and k mean clustering algorithm right   for svm  we used pixel
location  pixel padding and correlation based method  for kmean algorithm  we used pixel locations feature vectors  in
addition to daisy  but not pixel padding and correlation
techniques 

fig    demonstration of the effect of using pixel
location and pixel padding  the first row is the image and the
groundtruth  the left column is the result obtained by svm and

fig   

fifig   

fig   

fig   
discussion
the first problem that arises in both svm and k mean
clustering algorithms is that we fail to accurately determine

 
disparity values of smooth regions  the reason is that all sparse
matching features look for detectable positions in the images that
can be exactly matched for stereo correspondence  so they detect
edges and corners  therefore  we do not have enough training
examples in these smooth regions  to address the problem  we
use the pixel padding trick which helps generate some training
examples in smooth regions  for svm  the trick improves the
quality of dense map in smooth region  but it does not get rid of
the problem see fig     the third row   however  k mean
clustering algorithm does not incorporate the extra information
provided by these pixels well  therefore  for k mean algorithm 
the trick does not improve the result  to make these statements 
we have applied pixels padding to several images and compared
the results   however  due to page limit  those results are not
shown here  
in addition  we use pixel location as well daisy
descriptors as features  in the case  when our algorithm needs
extra information apart from daisy descriptors in order to
accurately find the best match  adding pixel locations helps
improve the results  as shown in fig    for both svm and kmean algorithms  pixels locations do mitigate the problem but
does not solve it  therefore  in future research we would suggest
adding other features that are correlated with disparity values and
studying the effect of those extra features more carefully 
another modification we have tried is adding training
pixels obtained by correlation based matching technique  for
svm  we have obtained a better disparity map  see fig      this
is because we have a larger training set  again  k mean
clustering algorithm does not incorporate the extra information
provided by these pixels well  so this modification does not
improve the results 
for multi class svm algorithm  another issue is the
smoothness of a resulting disparity map and noise  depth and
disparity values of all pixels that belong to the same objects
should either be the same or change gradually  therefore  we
expect the disparity map to have some sharp edges corresponding
to boundary of each object and some smooth regions inside an
object  however  we observe that disparity maps produced by
our svm algorithm are quite noisy and edges are not sharp 
compared to disparity maps returned by svm  maps
produced by modified k mean clustering algorithm have sharper
edges and smoother regions inside each object  however  there
are three major issues  first  k mean clustering algorithm does
not accurately predict disparity values when images have a lot of
details such in fig     consider fig    the background is a
bookshelf and a board which both have the same disparity value
but quite different daisy descriptors due to different color 
intensity etc  since the k mean clustering algorithm classifies a
pixel based on euclidean distance between a feature vector
 which includes daisy parameters  of a given pixel and cluster
centroids  it is more prone to this kind of error than the svm 
fig   shows that in this case  the svm algorithm does a lot
better  the second issue for k mean clustering algorithm is how
to weigh each attribute  k mean clustering algorithm relies on
the calculation of euclidean distance  which depends on how
much weight is given for each entry of a feature vector  for
example  in a feature vector  we can scale all daisy parameters
by a factor of   and that will give more weight to the daisy
parameters and change euclidean distances  in this project  for a
feature vector we use the ratio x w and y h coordinate which
indicates location of a pixel  x and y denote horizontal and

fivertical location of a pixel and w and h denote the width and the
height of an image  daisy parameters are scaled such that the
average norm of daisy vector of all examples in the training set
is    the same scaling is applied to pixels in the test set  the
issue of scaling each attribute requires a more careful study 
which we plan to do later  the last issue is that when we perform
pixel padding and adding the results of correlation based
matching  k mean algorithm does not incorporate this extra
information well  this is due to simplicity of k mean clustering
which makes decision based on euclidean distances 
one important observation is that the performance of
our algorithms depends on the quality of the training set  similar
to all machine learning algorithms  if training examples are noisy
and we do not have enough training examples  the learning
algorithm cannot perform well  however  this issue should not be
a problem since nowadays there exist various algorithms that can
efficiently and accurately determine sparse matching  in addition 
due to advances in computer vision technology  various
algorithms such as geigers algorithm can produce sparse
matches with larger number of keypoints 
suggested future works
in this section we suggest some modifications that will
potentially improve the performance of the stereo matching
algorithms  we plan to implement these algorithms later  first  to
solve the smooth region problem  some computer vision
techniques may be used to detect smooth regions and these
regions can be handled separately  another way is to use some
computer vision techniques to calculate an indicator  which
indicates that a given pixel belongs to one of the smooth regions 
and use this indicator as one of the attributes in the feature
vector  this indicator should enrich the information in feature
vectors that are used to predict disparity values 
the second modification is to modify the algorithms to
exploit information from the right image  sparse matching
algorithms take pixels values for both left and right image to
predict disparity value of all keypoints  our algorithms use
disparity values of these keypoints and features extracted from
keypoint pixels in the left image as a training set  information of
pixels in the right image is not used in our algorithms  therefore 
the algorithm should be modified to take into account
information from the right image  one possible way to do this is
to classify a pair of left and right pixel as a true match or a
false match  given a pixel in the left image  instead of using its
feature to predict a disparity value  we can pair this left pixel to
every right pixel  for each pair  we extract feature from both left
and right pixel and from this feature we classify whether or not
the pair is a true match  which means they are corresponding to
the same  d point  the feature vector of a pair of pixels can be
either daisy descriptors of both left and right image together with
pixel location or norm of difference of daisy parameters  by
formulating the problem this way we can exploit the information
from right image pixels  however  in this case we will have to
search for other learning algorithms that are suitable for the new
problem  for example  we should find an algorithm that picks the
match that minimizes the difference between daisy parameters of
left and right 
conclusion
we have presented various ways in which machine
learning can be applied to perform dense stereo matching  the
error of the disparity results obtained by these methods were
calculated as the percentage of pixels differing from ground

 
disparity values by more than     after leaving out some border
pixels and occluded regions  the error percentage ranged from
       for svm and        for k means  the main problem
of our algorithm is smooth regions  although our algorithms still
have some issues  we have shown that machine learning is a
potential way of performing dense stereo matching
acknowledgement
we would like to thank tao wang for his advices and
data 
references
    a  geiger  j  ziegler and c  stiller  stereoscan  dense  d
reconstruction in real time  in intelligent vehicles symposium
 iv       
    a  neubeck and l  v  gool  efcient non maximum
suppression  in icpr       august       in press 
    e  tola  v  lepetit  and p fua  daisy  an efficient dense
descriptor applied to widebaseline stereo   in ieee transactions on pattern analysis and
machine intelligence 
vol      pp           may      
    program is developed based on daisy code http   cvlab ep ch software       
    d  g  lowe  distinctive image features from scale invariant
keypoints   in international journal of computer vision  vol     
pp          nov      
    d  scharstein and r  szeliski  a taxonomy and evaluation of
dense two frame stereo correspondence algorithms   in
international journal of computer vision  vol      pp       apr june      
    d  scharstein and r  szeliski  high accuracy stereo depth
maps using structured light   in ieee computer society
conference on computer vision and pattern recognition  cvpr
       vol     pp           june      
    images used in this project have been downloaded from the
website http   vision middlebury edu stereo 
    svm code  http   www csie ntu edu tw  cjlin liblinear 
    sparse matching code 
http   www cvlibs net software libviso sparse matching

fi