cs     final project december     

investigating the variables that influence online
learning
peng hui how  pak tao lee
stanford university
phow  stanford edu ptlee stanford edu
abstract
our project aims to explore a dataset that logs students behaviors in solving mathematics exercises that are hosted on the khan academy  
platform  we aim to pinpoint the significant factors  out of a pool of given factors  that suggestively predict students engagement with
solving problems and their learning gains  and to investigate the accuracy between several classical machine learning techniques in predicting
students performance 

  

introduction

    

variables

within the last    months  online educational technology star  there are    variables in the dataset  those that match our pertups organizations such as khan academy and coursera have tinent interest to measure factors that help in online learning
been offering learning experiences like massive open online include the following 
   break variable 
courses  moocs  to millions of users  this is just an iceberg of
 identity  userid of the student  may appear multhe huge impact of online education on the humanity  in gentiple times in the dataset
eral  online education promotes educational equality   people
   mediation variable 
all around the world are now granted convenient access to high
 alternative  enumerated from   to    the message
quality education  an effective model that governs the success
type displayed on the problem attempted
of online learning  as measured by the learning progress of

exercise type  enumerated from   to    pre   durthe students  is therefore in dire need  our ultimate goal is to
ing  and post  close intervention
discover the underlying factors that affect students absorption
 exercise  a node on the khan academys knowlof knowledge  which has practical implication for provider of
edge map  indicating an exercise
online education and the broader teaching community 
   possible predictors  indepedent variables  
 num coaches  number of instructors  constant as
   dataset
per user id
 hints  number of hints employed by the student
     overview
for a question  range differs for each question
 topic mode  binary variable         whether or not
our current dataset consists of         tuples  each of which
the problem was attempted under topic specified
represents a single question attempted by a student with a
condition
unique user id  taken as a subset of our preliminary data 
 review mode  binary variable         whether or not
which was collected from an experiment that ran on khan
the problem was attempted under review condition
academys platform for a month  with         students    
 proficiency  binary variable         depending on
topics    types of message statements   the overall dataset is
whether or not this problem was awarded a profiorganized in a hierarchical structure  in which each problem
ciency  indicating the problems difficulty level
belongs to   of the    possible topics  e g  algebra   this is not
 time taken  time taken for the students to finish a
explicitly stated in the dataset   instead  the dataset indicates
particular question
the specific subtopic within the main topic  hence we need to
 problem number  the problem number assigned in
insert an additional column for this to facilitate future analysis  
the particular exercise
and is being categorized under one of the various subtopics
 problem order  generated variable  the order of
under a single topic  for identification  problem number  the
the problem attempted for the particular student 
sequence in which the problem appears  in a single topic   is
distinct within the same userid
also available 
  www khanacademy org

 

fics     final project december     

   performance metric  dependent variable  
we identify them by plotting bell curve and reading the cumu correct    or    whether or not this question was lative frequency table   for the variables that have no theoretical
correctly answered
upper bound  delete the   or     at the extreme right of the
bell curve  procedurally  on each of the dependent variables 
our resulting dataset has        out of the original       
     analysis
tuples  keeping the vast majority         of the dataset while
given that the   classes of specially designed statements dis  greatly reduced the variation  as detailed below 
played aside of the questions were factored into the dataset 
mean
std  dev 
we roughly analyzed the significance of these statements  tabubefore after
before after
lating count  mean and standard deviation gives the following  variables
hints
                   
      
time taken
     
     
     
     
statement
mean s d 
frequency l h 
num coaches     
    
     
     
control statement
    
             
l
science statement
    
            
l
as an example  the graphical illustration of the distribution
positive statement
    
            
h
of
the
variable time taken before and after condensation is as
no header
    
             
h
followed 
growth mindset
    
            
h
growth mindset   link     
            
h
total

    

     

       

with the exception that science statement apparently gives
rise to a performance slightly poorer than average  the other
  statements inserted performed almost equally well  as the
variation of mean and standard deviation across all conditions
is insignificant  we have decided not to factor it into our further
analysis 

  

figure    time taken count  before condensation

figure    time taken count  after
condensation

methods

the grouping process that transforms the dataset from
before plunging into the analysis  we preprocessed the dataset problem based to student id based has turned some discrete
by doing the following 
variables into continuous ones  a very huge potential problem
causer in future analysis  therefore for each of the variables 
     grouping by id and variable transformation we come up with a discretized copy of itself 
the dataset given is grouped by problem instead of student
id  thus there might be multiple problems done by a single
student across the dataset  assigning equal weight to each
tuple in the dataset might result in the apparent pattern generated to be biased towards that of the students who do more
problems  thus skewing the analysis result  to tackle this  we
grouped the dataset by student id  followed by taking means
for all the corrseponding variables  we have also replaced
problem order with the new variable num problems  taking
the largest value of num problems within each id  indicating
the number of problems done by the student 

    

anomalies detection and deletion

at times  small amount of outliers are able to distort the entire
distribution of the dataset  resulting in erroneous conclusion 
 

    

variable discretization

we discretized the continuous variables into several        
discrete portions  to facilitate the calculation of mutual information  m i   values and naive bayes 

    

feature selection

     

mutual information

to identify the variables that play the most significant role in
predicting the students performance measure  we calculate
their mutual information  m i   values  where 
m   xi   y    

p  x   y 

  p xi   y  log p x ii  p y 
xi yi

fics     final project december     

  on the discretized variables  as detailed in the previous sub  across the dataset  in order to concretely visualize the trend
section  the result we obtained is as follows 
across this new dataset  and to discretize this new correct
value to its original property  i e  a binary variable  it is necessary for us to assign a threshold between   to    and set
variables
m i 
those above it to be   and the rest to be    to do this  we
review mode
       
create   new variables correct   x  x          and perform
proficiency
      
both logistic regression  we change the regression threshold to
      
hints
match the corresponding threshold  and naive bayes on this
topic mode
      
newly structured dataset 
num problem       
time taken
      
remark  for the rest of the report  t n   f n   f p   and t p 
     
num coaches
represents true negative  false negative  false positive  and true
time done
     
positive respectively 
in this stage  we eliminate num coaches and time done 
two variables having the lowest m i  values  this makes sense       logistic regression
especially for the latter  matching our intuition that the date since correct is a binary variable  it makes sense to consider
when the students do the problems has no significant influence logistic regression to predict our results  the model is as
towards the performance 
follows 
 
y   h   x    
t
    e x
      correlation measure

 

time taken
    

    

 

      

     

      

     

     

      

 

      

     

     

     

     

      

 

      

     

      

      

     

      

 

      

      

     

     

     

      

 

hints
hints
time taken
topic 
mode
review mode
proficiency
num problem

     

review mode
     

proficiency
      

num problem
      

topic 
mode

running logistic regression with different cutoff points
ranging from     to     gives the following results   
threshold

t n 

f n 

f p 

t p 

precision

   
   
   
   
   
   
   
   
   

    
    
    
    
     
     
     
     
     

   
   
    
    
    
    
     
     
      

     
     
     
     
     
     
     
     
 

      
      
      
      
      
      
      
      
   

           
           
           
          
           
           
           
           
           

table    results of logistic regression

    

naive bayes

another method that can be applied on a classification problem is the narve bayes  method  we will predict correct
in this stage  we eliminate the variable proficiency 
using these three variables  with a model similar to the email
we now proceed to our data analysis with the   selected fea  spam classifier problem we saw in lecture  where for j         
tures  i e  review mode  hints  topic mode  num problem  p y   j   x   is 
time taken  num coaches  and time done  using logistic regression and naive bayes  these classifications method are
 in   p  xi   y   j   p y     
n
chosen as our dependent variable  i e  correct  is originally a
 i   p  xi   y   j   p y         in   p  xi   y   j   p y   j 
binary variable  valued at         
as the dataset is being grouped by student id  the varirunning naive bayes with different cutoff points ranging
able correct at each row is now the average score of the user from     to     gives the following results 
  precision
  in

   t p  f n    the size of the dataset 
our case  n      we are also assuming that the features we used are conditionally independent given y 

 

fics     final project december     

threshold

t n 

f n 

f p 

t p 

precision

   
   
   
   
   
   
   
   
   

    
    
    
    
    
    
     
     
     

   
   
   
   
    
    
    
     
      

     
     
     
     
     
     
     
     
  

      
      
      
      
      
      
      
      
    

           
           
           
           
           
           
          
           
           

table    results of naive bayes

  
    

results

roc curves   threshold selection

in order to maxize the true positive rate  tpr  and minimize
the false positive rate  fpr   we plot the receiver operating
characteristic  roc  curve  a plot of tpr against fpr  at different cutpoints of our binary classification tests 

using threshold       as suggested  referring to table   and
table    the precision of logistic regression and naive bayes
are       and       respectively  thus logistic regression
performs notably better than naive bayes 

    

what logistic regression suggests

hints
time taken
num problems
topic mode
review mode
constant

beta 
      
      
 
     
     
     

s e  
     
 
 
    
     
     

from the table  we interpret that logistic regression with    
threshold suggests that
p
log   p                 hints         time taken
    num problems          topic mode          review mode
  where p   p correct      

    

interpretation of the results

in addition of these coefficients  we can also interpret in a very
rough sense that the students tend to perform better when 
   the topic is specified in the question  variable 
topic mode   or
   when they are doing review  variable  review mode  
figure    roc of the class of logistic regressions 

while performing poorly when 
   many hints were requested  variable  hints   or
   longer time is taken  variable  time taken  
moreover  the total number of problems  variable 
num problems  has very insignifant influence on the students
results 

  
figure    roc of the class of naive bayes 

    

evaluation

cross evaluation on logistic regression

interpolating from the roc curves  we observe that for performing   fold cross evaluation on logistic regression with
both analysis  threshold       gives rise to the largest gradient     threshold  we obtain accuracy of       and       respecon the roc curves 
tively on the training set and the test set respectively 
 

fics     final project december     

    

alternatives to logistic regression

as shown in the previous subsection  despite the discovered
fact that logistic regression performs remarkably better than
its quick and dirty counterpart  i e  naive bayes  it might not
be the most accurate model to predict the dependent variable 
as a quarter of the predicted value is false  an explanation for
this might be that the data might not be structured linearly to tackle this  we might want to try support vector machine
 svm  with nonlinear kernels  another explanation might be
that students perform differently across different exercises 
and this is not factored into our analysis   to tackle this  we can
make use of the hierarchical property of the exercises  exercise
 exercise type  problem number of mixed model analysis 
or include the exercise properties as predictor features in our
regression 

   incorporate the significance of problem order into the
analysis  there might be underlying patterns that plays
important role in data prediction
   use mixed effect model to take care of the hierarchical
structure of the dataset  after giving appropriate treatment to the raw data
   use pricipal component analysis for more accurate feature selection
   locally weighted logistic regression instead of the usual
logistic regression
   use support vector machine   this is good since kernel
can be selected precisely  as we face underfitting problem
with current set of methods

our work in this project will also be presented to the graduate school of education for the educ    x seminar in the
in the context of our experiment  we assume that the   selected winter quarter 
variables are conditionally independent given the students
performance  this is a rather hasty assumption  as an exam   acknowledgement
ple   hints and time taken might be correlated  given that
it takes time for the students to read the hints content  this we would like to express our utmost gratitude towards prof
results in the low accuracy rate for naive bayes analysis 
andrew ng and all the teaching assistants of cs     who
provided valuable feedback to the project along the way  we
would also like to dr  joseph jay williams from the graduate
     intrinsic skewness within the dataset
school of education for his continuous high level guidance on
there are less than     of the students who did more than the project 
   questions in the given dataset      of which did only  
note  one of our members  peng hui how is enrolled in
question  giving a rather skewed dataset 
the educ    x seminar this quarter and is using this work
for the class 

    

the flaws of naive bayes

    

conclusion

the variables that are the most useful in predicting stureferences
dents performance are review mode  hints  topic mode 
num problem  time taken  num coaches  and time done   mansinghka  mansinghka  v k   shafto  p   jonas  e   petschulat  c   gasner  m   tenenbaum  j b   accepted pending
between logistic regression and naive bayes  logistic regresrevision   crosscat  a fully bayesian nonparametric
sion with threshold     is the best model  therefore  we
method for analyzing heterogeneous  high dimensional
conclude that we would use logistic regression with threshdata  journal of machine learning research study 
old     on review mode  hints  topic mode  num problem 
time taken  num coaches  and time done to predict future
 idre  institute for digital research and education  ucla 
students performance given the sets of features in the dataset 
annotated spss output   spss http   www ats ucla 
edu stat spss output logistic htm

  

future work and vision

to perform more accurate analysis  there are several methods pertaining to our dataset that we can possibly employ  as
follows 

 ics  donald bren school of information and computer
sciences  uci  decision theory  naive bayes  roc
curve http   www ics uci edu  welling teaching 
ics   awinter   decth   awinter   pdf

 

fi