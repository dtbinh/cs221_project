modeling function word errors in dnn hmm
based lvcsr systems
 melvin

jose johnson premkumar   ankur bapna and  sree avinash parchuri
 department

of computer science
department of electrical engineering
stanford university
 melvinj ankurbpn aparchur  stanford edu


abstractdeep neural network  dnn  based acoustic models produces significant gains in large vocabulary speech recognition  lvcsr 
systems  in this project  we build a dnn acoustic model and analyze the
errors produced by the system  specifically the ones due to function words 
we analyze the class variances of the frame data depending on whether
they belong to the set of function words or not  we experiment with
different ways of modeling the errors produced due to function words 
two different ways of modeling the function words in the neural network
were tried and the results have been reported  we have obtained gains
in the frame accuracy of one of the systems compared to the baseline  in
future  we plan to build a complete system and look for improvements
in the word error rate  wer  

i  i ntroduction
automatic speech recognition  asr  aims to convert a
segment of spoken language audio  known as utterances 
to a corresponding accurate transcription  figure   provides
a brief overview of the architecture of a typical speech
recognition system  it can be seen to consist of four main
components  feature extraction  acoustic model  decoder 
language model 
a  feature extraction
during feature extraction  windows of raw pcm audio
samples are transformed into features that better represent the
speech content of the signal within that window  the most
popularly used feature representation is mel frequency cepstral
coefficients  mfccs  
b  acoustic model
an acoustic model serves to map the extracted features to a
sequence of likely spoken sounds  namely phonemes  this is
usually done by using a phone likelihood estimator which can
be a gaussian mixture model  gmm  or an artificial neural
network  ann  to estimate the likelihood of each phone  this
is then coupled with the pronunciation lexicon which maps
words to phone sequences  a hidden markov model  hmm  is
used to model the durational and spectral variability of speech
signals 
c  language model
in an asr system  the language model provides the probability of a particular sequence of words  in other words  it
tries to capture the properties of the language  it is used in the
decoding phase along with the acoustic model to generate the
word sequences for the audio signals 

d  decoder
the acoustic model provides a distribution over all possible
phonemes for each individual frame and the language model
provides the prior probability of the word sequence being
sensible  using these two probabilities the decoder generates
the most likely word sequence for the given audio input 
the rest of the report is organized as follows  in section
ii  we provide a brief overview of our experimental setup 
section iii discusses our baseline system and various other
experiments performed on it  in section iv  we present our
experimental results  section v provides discussion and
analysis on our experimental results  we finish with the
conclusion and future work in section vi 

ii  e xperimental s etup
the experiments were conducted using a variant of the
open source kaldi toolkit      neural network training was
done using python scripts which took advantage of gpu
processing capabilities through the use of the gnumpy and
cudamat libraries 
the data set used for these experiments was the
switchboard   release   corpus  ldc  s     which is
a collection of about       two sided telephone conversations
among     speakers  the data set was divided into     files 
each representing about an hours worth of conversation 
the neural net is trained using the frame data  in the
form of mel frequency cepstrum coefficients  and the
senone labels  currently  we input    frames of mfcc
data to obtain senone labels  from among      possible
senone labels  for the current frame  the other    frames
provide context   we use the alignment files  ali  txt   key
files  key  txt  and the feature files  feat  bin  generated
by kaldi as input to the dnn  for evaluation  we use
scripts that perform a feed forward on the neural network
and output the most probable senone for the given input frame 

fifig    

asr system architecture

table i
error analysis   baseline
 wrds

 frames

 errors

  
   
   
   

     
     
     
     

     
     
     
     

frameacc   
 top   
     
     
     
     

frameacc   
 others 
     
     
     
     

iii  baseline s ystem
a  performance of current system
table    shows the percent of frames containing the top
n words  along with the contribution of the top n words to
the frame classification errors  as well as the frame accuracy
for the top n words and the rest of the words  as it can be
seen  the percentage of errors made on the top n words is
larger than the percentage of frames that they are present in 
additionally  the frame classification accuracy for the top n
words is significantly lower than that for the rest of the words 
b  top    words in the phoneme space
we used t distributed stochastic neighbour embedding
 t sne      to visualize the top    words from the corpus
in the senone space  t sne is a technique for dimensionality
reduction that is well suited for the visualization of highdimensional datasets 
figure    shows the top    words in the corpus  plotted
in the senone space after using t sne to reduce the data to
two dimensions  words occurring close to each other in this
plot are often confused for each other 

for the current frame and neighboring    frames on each side
to predict the senone labels for the current frame  we would
expect these data vectors to have a much higher variance
for content words when compared to function words  since
function words have a much smaller subset of words which
get repeated often while content words have a large number
of infrequent words 
our expectations are corroborated by our experiment results 
we computed the class covariance matrices for the data
vectors corresponding to the senones for the top    most
frequent words and the set of content words and evaluated
the eigenvalues of these matrices  to determine the gains in
directions of maximum spreads   we found that the   largest
eigenvalues for the content words are more than double those
of the top    words  table      this indicates that the data for
a particular senone is more spread out if that senone belongs
to one of the content words rather than the function words 
table ii
covariance calculations
function words
value 
value 
    e    
    e    

content words
value 
value 
    e    
    e    

besides  from our experiments on the current system  table
    we also find that the function words contribute to more
errors when compared to content words  this is also observed
in      it was observed that during speech  function words
are much less emphasized  around      when compared to
content words which are stressed almost     of the time 
it was also observed that words which are stressed during
speech are much less likely to get mis recognized 

c  confusion matrix for senones
figure    shows the confusion matrix for the first    
senones in the baseline system  it can be seen that there are a
lot of confusions between the senones and hence they require
special attention 

previous work by goldwater et al      revealed that there
was a significant increase in the number of errors dealing
with short and frequently used words  usually function
words  in gaussian mixture model   hidden markov model
 gmm hnn  based asr systems  our analysis on the
dnn hmm based asr system revealed similar trends 

d  motivation to model function words
as observed by our results on the current system  function
words form a bulk of the speech corpora  all the words in our
list of top    words by frequency are function words  content
words are much less frequent  our system uses mfcc labels

since the senone data for function words is much less
spread out and function words still contribute to a larger
share of errors  we try to model their senones separately
in an effort to reduce the errors produced by the speech

fifig    

fig    

top    words in the senone space

confusion matrix for first     senones in the baseline system  the colormap has been restricted to the          range to help legibility 

recognition system while working with function words  we try
two different approaches to model the function words senones 

iv  e xperimental r esults
a  details of the neural networks

in our first method  we try to create separate classes for
all senones corresponding to a particular function word 
this enables the system to learn from context when dealing
with a function word senone  secondly  we create a separate
cluster of classes  one for each senone  this cluster is used
to classify the senones corresponding to function words 

the current system consists of a neural network that can
be trained on the mfcc labels obtained from the speech
data frames  the input to the neural network consists of
the mfcc data from the current frame and from    frames
on each side of the current frame to provide context  it
outputs the probabilities of the current frame corresponding
to each of the possible      classes  currently  each class
corresponds to a senone  triphone   the neural network can
consist of a variable number of hidden layers  depending on

fitable iii
experimental results

the experiment being performed  the frame predictions of the
neural network can be fed to a hmm that has been trained on
the word dictionaries  this hmm produces the sequences of
phonemes which are then weighted by the language model 
after experimenting with many configurations  we finally
decided to use a neural network with   hidden layers with
    units in each layer  the input layer consists of    frames
of mfcc labels and the output layer consists of varying
number of neurons depending on the type of system used  a
standard system takes close to   hours to train on a gpu and
more than    hours to train on a cpu 
in the first system  functionwordclasses  we implement 
we try to model the function words as separate classes 
we define    new classes in the neural network  each
corresponding to all possible senones for a particular function
word  our system can successfully read data from the
available binary files and train the new neural network on the
training set and produce the senone or class labels as its output 
in the second system  splittwoclasses  we implement 
we try to model the function word senones differently from
the content word senones  we create separate classes for
all the senones that occur in any of the function words 
this creates low variance classes for the new function word
senones  our system can successfully read data from the
available binary files and train the new neural network on the
training set and produce the senone or class labels as its output 
b  implementation details
the neural network code was adapted from the stanford
variant of the kaldi toolkit  we wrote new data loader
instances which parsed and modified the training data as
required by our models  by substituting the original senone ids
assigned to frames with the ids generated by our models 
a test harness was written to test the trained neural
network using the development set  recording statistics such
as frame classification accuracy  contribution of top n words
to the frame classification error  and the frame classification
accuracy for the top n words and the other words separately 
additional python scripts were written to generate
confusion matrices from the trained neural network and
to plot these matrices using matplotlib  similarly  scripts
were written to generate the phone to word and senone toword mappings and to visualize them using t sne for analysis 
v  d iscussion and e rror a nalysis
table    gives the comparison between the baseline system
and the two models built by us  it can be seen that the
functionwordclasses model wherein a new class is created
for each function word outperforms the other two models

system
baseline
splittwoclasses
functionwordclasses

frame accuracy    
     
     
     

table iv
error analysis   funcwordclasses
 wrds

 frames

 errors

  
   
   
   

     
     
     
     

     
     
     
     

frameacc   
 top   
     
     
     
     

frameacc   
 others 
     
     
     
     

in terms of frame accuracy  the poor performance of the
splittwoclasses model can be attributed to the fact that
creating two versions of the same senone creates sparsity
issues since we are essentially doubling the number of
possible outputs  another possible reason would be that
this new scheme does not provide the context information
between the senones of belonging to a single word as
provided by the fucntionwordclasses model  we refer to the
fucntionwordclasses model as new sys and perform further
analysis on it 
table    gives our analysis on the new sys similar to
the one in table      it can be seen that the percentage of
contribution to the errors by the top n words has significantly
reduced compared to the baseline system  a significant
increase in the frame accuracy of the top n words can also be
seen  this shows that the new sys model with separate classes
for each function word has been successful in modeling the
errors generated due to these words 
figures    and    represent the confusion matrices of the
top     senones of the baseline and the new sys  figure   
gives the confusion matrix for the newly added classes for the
function words in the new sys  it can be seen that the new sys
has much less confusions than the baseline  this bolsters the
results seen in table     it should also be noted that the new
classes created in the new system are pretty well distributed
and have comparatively lesser confusions as seen in figure
   
vi  c onclusion and f uture w ork
in this project  we aimed to model the errors caused by
function words in a dnn hmm based asr system  we
experimented with two different ways of modeling the errors 
our best system provides a significant improvement in the
frame accuracy compared to the baseline system  however 
these numbers are not comparable across the systems since
they use different architectures  hence  we perform a thorough
analysis on both the baseline and the new system in terms of
the percentage contribution of errors of the top    function

fifig    

confusion matrix for first     senones in the new system  the colormap has been restricted to the          range to help legibility 

fig    

confusion matrix for new    classes  the colormap has been restricted to the         range to help legibility 

words  we noticed a significant drop in the percentage of
errors due to the top    function words in the new system 
in the future  we would like to integrate our best neural net
with the complete asr pipeline  i e  editing the pronunciation
dictionary  altering the hmm model and retraining it to
obtain wer  we would then like to compare the wer
of our system and the baseline  we would also like to
try other methods of modeling the senone errors like datadriven clustering and check for improvements in performance 
vii  acknowledgement
we are very thankful for all of the guidance  support and
resources that andrew maas and awni hannun have provided
us through this process 

r eferences
    daniel povey  arnab ghoshal  gilles boulianne  lukas burget  ondrej
glembek  nagendra goel  mirko hannemann  petr motlicek  yanmin
qian  petr schwarz  jan silovsky  georg stemmer  and karel vesely  the
kaldi speech recognition toolkit  in ieee      workshop on automatic
speech recognition and understanding  ieee signal processing society 
december      
    sharon goldwater  daniel jurafsky and christopher d  manning  which
words are hard to recognize  prosodic  lexical and disfluency factors
that increase speech recognition error rates  speech communication
                    
    andreas stolcke  srilm   an extensible language modeling tooklit 
in proc  intl  conf  spoken language processing  denver  colorado 
september      
    alex waibel  kai fu lee  readings in speech recognition  morgan
kaufmann publishers       
    l j p  van der maaten and g e  hinton  visualizing high dimensional
data using t sne  journal of machine learning research   nov                 
    l j p  van der maaten  barnes hut sne  in proceedings of the international conference on learning representations       

fi