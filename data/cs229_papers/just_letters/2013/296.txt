final report

christopher ho

does mma math work  a study on sports prediction applied to mixed martial
arts
introduction
sports have been a part of human civilization since even before the classical period  but just as
sports were invariably a part of society  so too was the desire to know about the future  the ancient
greeks had their olympics  but they also had their seers  desiring to know the future of sports is just a
natural consequence of these two mainstays of human civilization 
predicting the outcome of sporting events make for an interesting and not altogether trivial ai
and machine learning problem  in spite of the popularity of both ai and sports  most applications were
of unsupervised learning to discover interesting new structure in sports  of sports predictors  there has
only been a single paper written  mymait  which used neural networks to predict rugby results  this
system achieved     accuracy on its initial run  and after    years of additional data  this accuracy has
increased to     
the lack of work done in this area is a shame  as many modern sports have a glut of statistics for
each event  making for an innumerable amount of data with which to predict  unfortunately sporting
events are also very stochastic by nature  someone might break an arm  someone might have a bad day
and the list of valid ifs go on  modern mixed martial arts  mma  is a sport that takes this randomness
to an extreme 
in mixed martial arts  as in boxing  it is widely said that when a fighter is completely outmatched
on paper  he or she has a punchers chance  that statement alone describes not only what makes the
sport so exciting  but also what makes it so random for the purposes of prediction  at any given moment
in the fight  it only takes a single punch  or slip up to get knocked out or submitted  anyone can win at
any time  it is because of this that it is widely ascribed among fandom that mma math doesnt work 
just because fighter a beat fighter b and fighter c lost to fighter b  it does not necessarily mean that
fighter a beats fighter c  that math  however  is a simple inequality that does not characterize many
aspects of the sport  in this project  we will attempt to make mma math work 
challenges
sports are all about the human element  in this statement lies the majority of the challenge for
this problem  a number of factors contribute to human performance at any given time  and nearly all of
these factors are hidden from us  some are unquantifiable  such as emotional or mental state  and
others are simply uncharacterized by the available data  such as number of broken bones  or time since
last concussion  the vast amount of unmodeled dynamics in sports contribute to a great deal of
randomness in the problem  and extremely noisy data 
predicting the winner in mixed martial arts competitions as a problem suffers from these issues
more strongly than other sports  where in traditional sports  a last minute comeback from behind is a
rare  memorable event  in mixed martial arts  where it takes only a single mistake to turn the tides of a
match  such comebacks are not uncommon  this contributes to more outliers and randomness in the
data  further  where combine stats or rushing yards would be in the discussion for nfl players 

fiintangibles such as heart or chin  ability to take a punch  are often central in discussions about mixed
martial artists  while these attributes of a fighter are difficult to characterize by data  they are
undoubtedly important factors in determining the winner  this too contributes to the randomness of
the problem  finally  it is important to note that where in other sports an athlete might compete once a
week during a season  you would be hard pressed to find a mixed martial artist who competes more
than   times a year  overall giving less data per fighter 
approach
to produce quick results  a simple baseline nave bayes classifier  p a b   based on win loss
records was implemented  here  a was the state of a fighter winning  given b  the record of the fighter 
and the record of his opponent  the prior  p a   then is simply the win rate  while p b  is the probability
of their records  given as the local probability of the win loss at that point in either fighters career  e g 
p bi    p fighter a wins and opponent loses  or vice versa  given that both events have to occur   p b a 
was a recalculation of the probability of a fighters record given an extra win on his record 
it is worthwhile to make a digression about the data structure required to make many aspects of
this project work  in brief  a lattice structure was created in which there were n   instances of a given
fighter  where n is the number of fights the fighter has had on record  each instance of a fighter would
correspond to the record and career statistics of the fighter after a given fight  and vice versa  each fight
object contains pointers to the fighter objects containing the statistics of the fighter before the fight 
and pointers to fighter objects for the statistics of each fighter after the fight  similarly  each fighter
object has a pointer to his or her last and next fight  this data structure allows us to move backwards in
time to characterize a fighter by who he or she has fought and how well he or she has done against
given opponents 
while the data was not linearly separable  making the perceptron algorithm a relatively poor
choice  it was an excellent starting point to test out a richer set of features  the basic set of features that
laid the groundwork for all later variants were statistics culled from fightmetric com  height  weight 
reach  age  wins  losses  striking accuracy  striking rate  striking defense    of opponents strikes that
miss   and so on  the training and development error was found by averaging the error over different
partitions of the data  and taking a subset of each partition to provide error vs  examples  this provides
us with a much more reasonable baseline than the nave bayes classifier which simply showed that the
problem was tractable 
a number of variations of this feature set were attempted  such as averaged relative stats 
which took   

   
 fffi 

 
   
 fffi 

as its features  where aij was the jth statistic of fighter a i   fights ago 

and bij was the jth statistic of as past  or current  opponent i   fights ago  the intention behind this
experiment was to attempt to characterize a fighter by his or her past performance relative to his or her
opponents  other features were also used  such as including the specific stats of each fighters last fight
 the fighters previous fight day performance  
continuing on with this theme of modifying the feature space  we also attempted to use kernels
to better fit the data  using kernelized perceptron  and the one class svm  using libsvm  to classify the
data  while only a simple  nd order polynomial kernel was used for the perceptron  a number of
different built in kernels were used for the svm  ranging from linear and polynomial  to radial basis and
sigmoid of different degrees 

fibecause mixed martial arts is a sport with two agents  we also attempted to pose the match as
an adversarial game with random elements  this was accomplished by following each fighters action
 strike  takedown  submission  with a dice roll which would bring the game to a new state based on each
fighters prior statistics  greater rewards were given for definitive wins such as by knockout or
submission  lesser rewards were given for a decision win  which was determined as who had the greater
weighted sum of successful strikes and takedowns at a given depth in the game tree  the victory metric
was the expectiminimax value of the game  where a  the max agent  would be predicted if the value of
the game was positive  and b otherwise  this game value was used not only as a standalone metric  but
also as a feature in the classifier  it is important to note that each ply of the game consisted of four
layers  as max node  as dice roll  bs min node  and bs dice roll  where each step had a branching
factor of about    this meant that even with alpha beta pruning  it was only reasonable to run up to a
depth of   plies  roughly corresponding to the three rounds in a typical fight  the significant depth
limitations of the adversarial game motivated the next experiment 
the initial incarnation of the game only allowed a single action per turn  it was clear that it
would be more informative if each ply of the game represented a unit of time  over which each fighter
would attempt so many of instances of an action based on their striking takedown submission attempt
rate statistic  while more representative of what might happen in a real fight  this design limited a
fighter to only a single action over a   minute round  where in reality a fighter could do any combination
of the three actions 
taking this concept to its logical conclusion  we first examined the accuracy of predicting the
winner of each fight using a posteriori fight data  that is  data from the fight itself known after the fact 
because we achieved good results from this      accuracy over all types of finishes with perceptron  
we then used simple linear regression to predict each of these fight day values using our basic features 
and then trained the perceptron algorithm using these estimates as features 
results
the nave bayes classifier that was first implemented did not work well  for a small sample of
tests  it predicted the winner correctly approximately half of the time  however  when fed fights
considered to be among the biggest mismatches in ufc history  via an online article   it predicted the
correct result at a much higher rate  with a much larger margin than before  showing some validity to
the classifier  in all  it is clear from this simple example that a fighter cannot be characterized
probabilistically by their win loss record alone  thus motivating our later experiments 
the perceptron with basic features achieved fair accuracy  ranging from     to     accuracy on
the development sets  averaging to approximately     after training on the full training set  while these
results are not especially informative alone  we can use this as a fair baseline  and compare it to the
literature baseline of      it is important to note that the data is very clearly not linearly separable  nor
does it have large margins  as such  the perceptron algorithm is not especially well suited for this task  in
spite of this  it does an admirable job  this motivated the use of liblinear which can handle both
smaller margins and inseparable data  furthermore  it is also worth noting that when testing accuracy
was plotted against training set size  as seen in figure    the data varied wildly and a weak linear trend 
indicating that the error was dominated by bias  or poor model selection  this result motivated the
experiments with different feature sets 

fiperceptron   avg rel  dev err
perceptron   avg rel  test err
perceptron   naive test err
perceptron   naive dev err
svm   naive test err
svm   avg rel  test err

   

    

  error

   

    

   

    

 

  

  

  
  training set

  

   

   

figure    error of different classifiers
experiments with different feature sets proved to be a futile gesture  using averaged relative
features achieved similar  but slightly lesser accuracy than the basic features  attaining approximately
    accuracy  while we were operating with slightly more informative features  it is likely that dividing
noisy data by more noisy data amplifies the influence of noise significantly  further  it is worthwhile to
note that where each feature was divided by the same feature on the opponents side  e g  a striking
accuracy   b striking accuracy   it may have been more informative if these quotients were mixed in a
more meaningful way  such as pairing offensive statistics with defensive statistics  e g  a striking
accuracy   b striking defense   using each fighters performance from his or her last fight did not
appreciably affect the testing accuracy 
both svm and the kernelized perceptron had very poor results  averaging around     accuracy 
oddly enough  hand coding in basic features raised to any power also significantly decreased
performance  this is most likely because taking the data to any power other than one would cause large
numbers to blow up and small numbers to shrink  vastly increasing the effects of noise on already noisy
data  failing to preprocess the data also likely contributed to these effects 

fimodelling the fight as a game simply did not work  achieving an accuracy of approximately     
because of the branching factor of         for each ply  it became prohibitively expensive to compute
the expectiminimax value of the game tree beyond   plies  three actions per agent is very clearly
nowhere near enough to characterize a fight where on average action sequences are of length     
similarly  it was clear that the completely inaccurate game expectiminimax values were not
especially informative as a feature  this was similarly reflected by an unchanged training accuracy when
including the game value as a feature  examining the flaws in this approach  however  motivated the
separate paradigm that achieved better results 
using linear regression to estimate fight day performance  and running the perceptron
algorithm with those estimates as features achieved     accuracy  while this performance does not
seem especially good  it is important to note that our upper limit  using a posteriori data on the
perceptron algorithm  was an accuracy of      factoring in the error in the regression gives us our final
accuracy of      because very simple algorithms used to estimate the fight day data  and to classify the
winner  there is significant room for improvement in this approach  both by improving the regression
estimates  and by using a classifier that can better handle smaller margins and nonseparable data 
these results are summarized in table   
table    classification accuracy of different techniques
classifier
training accuracy
nave bayes
 perceptron  basic features
   
perceptron  averaged relative features    
perceptronfight day estimates
   
kernelized perceptron
   
game
 linear classifier  liblinear 
 svm
   
conclusions

testing accuracy
   
   
   
   
   
   
   
   

the     accuracy rate obtained with the linear classifier  was a fair result  while not especially
good in the broader realm of classifiers  compared to the one example in literature  mymait  which
achieved a        accuracy using more sophisticated neural network techniques on arguably less noisy
data  this classifier does a commendable job 
future work
in the future  more sophisticated machine learning techniques will be used  neural networks
appear to be the most promising solution given the relative success of using regression to estimate
fight day stats for a classifier  which was essentially a poor mans neural network  further  it will be
worthwhile to normalize the data to make the effects of kernelization more tractable  another
promising direction to take this project is to use factor analysis or mixture of gaussians to handle the
unmodeled effects inherent in the problem  in all  predicting the outcome of mixed martial arts matches
is an interesting and difficult problem that we have only scratched the surface of 

fi