tf idf chat user clustering
kevin malinak  jonathan swenson
malinak  stanford edu  swensonj stanford edu
suid                    
dec         

introduction
our project applies a k means clustering algorithm to pair users on chatous  a randomized chat site  the
user pairing system currently in place utilizes a weighted randomized algorithm which takes into account
given profile information about the users  including age  sex  region  and interests  however  the algorithm
overlooks a wealth of information inherent in the actual raw text of the chats  by analyzing the past chat
history of a certain user  we can provide a cluster of users that share similar lexical characteristics  and we
expect that pairing users who user similar vocabulary will improve overall chat quality 
input data
the founders of chatous have provided us with a dataset of around   million chats between users with
some metadata about each chat  such as which user disconnected  the number of chats that each user sent 
whether or not the chat was reported and who reported it  the time that the two users spent chatting as
well as whether or not the chat was reported  as chatous is interested in protecting the privacy of their
users  they have redacted the actual text of the chat  but simply left us with the word frequencies for the
chat where each of the words has a global unique id that they can use to look up words if we need them
to 
model
we implement a tf idf  text frequency   inverse document frequency  approach to weight a users
vocabulary according to a global vocabulary   with this model  we can examine how frequent certain
words appear in a users vocabulary and can determine what may be important to that user  to do
this  we form a feature vector of the users vocabulary and then weight each of the features dierently
with a tf idf model  which gives a high weight to words that are used frequently by the user  but not
used as frequently overall  over all the users vocabularies   this weighting allows us to emphasize more
individualized linguistic choices  as opposed to universally used words such as and  the  and you  etc 
 http   nlp stanford edu ir book html htmledition tf idf weighting   html
 

fitf idf chat user clustering

 

to define in specific terms  in our input data we are given conversations between two users  each
conversation contains user  s id  user  s id  and a set of words and the frequency of each word used
by each user in that conversation  first  for each user  we sum the word frequencies over all documents
associated with that user  this results in a vocabulary for each user which maps a word to the users
total frequency of that word  then  we calculate the document frequency dft   which denotes the number
of documents in which the word t occurs  this helps us compute the inverse document frequency  which is
defined  idft   log

n
 
dft

where n is the total number of documents  finally  for each user  we iterate through

their used words and multiply their frequency  denoted tf   by their respective idf values  thus  our final
model consists of a feature vector
the ith element is the tf

 x  for each user  where x is the input data and

 x  is a vector where

idf weight of that word 

algorithm
basic structure
the basic structure of the algorithm that we are implementing is the k means clustering algorithm as
given to us in class  we use the weighted feature vectors as calculated in the above model and cluster them
around k centroids  however  we deviate from the standard k means in the objective function which we
wish to optimize  instead of measuring and minimizing the euclidean distance between a feature vector and
the centroids  we instead attempt to maximize the cosine similarity of the vectors  that is  we maximize
the function cos  where  is the calculated angle between the feature vector and the centroid vector   since
our feature vectors are in positive space  ie  words cannot be used negative times   this becomes a useful
metric  as the outcome is bounded in         the cosine similarity also has an advantage over the euclidean
distance because if two particular users have similar vocabulary  but use the words in significantly dierent
frequencies  we want them to be placed in the same cluster  however  the euclidean distance function would
potentially place them in dierent clusters 
parameter selection
we optimized our algorithm by varying the following parameters until we converged towards an optimum 
 the number of clusters  k       with fewer clusters  we found that super clusters formed  which
could be further separated with increasing performance  because we found several sub clusters
which contained relatively little inter cluster conversations  the super clusters  with more clusters 
however  our algorithm resulted in sub clusters which could be coalesced  again with increasing
performance 
 the size of the training and testing datasets  n             we need only consider a subset of
the   million chats to test the accuracy of our algorithm  furthermore  due to the inherently large
dimension of our feature vector  representing the entire vocabulary of a single user   the runtime
 http   pyevolve sourceforge net wordpress  p     

fitf idf chat user clustering

 

becomes unmanageably long  for the purpose of testing our algorithm           conversations
presents a sucient clustering to achieve reasonable results 
 the number of k means iterations  i       we found that  given randomized initial centroids  our
algorithm tended to converge after a maximum of    iterations 
pm
 
 centroid initialization  i   m
j   j  x   as an initial guess for the centroids  we randomly

select m       feature vectors and set i equal to their average  this results in decreased runtime 
as our initializations are presumably closer to their true values than if we had set their values
completely randomly 

results and analysis
evaluation metric
the metric by which we judge the success of our algorithm is the ratio of average conversation length
within a cluster  intra cluster  to the average conversation length between clusters  inter cluster   we chose
this metric because we set out to increase conversation quality  and it is safe to assume that two people who
are enjoying a high quality conversation will tend to have longer conversations  our clustering algorithm
is then successful if it discovers clusters of users whose intra cluster conversation length is high  but intercluster length is low  this signifies that users within a cluster tend to have higher quality conversations
with other users in that cluster  as opposed to users in other clusters 
analysis
by the metric of conversation lengths  our algorithm was successful in increasing chat quality over the
clusters  we first trained our clusters on a randomly selected subset of          conversations  then  using
the resulting centroid values  we clustered a mutually exclusive test set of          conversations  in both
the training and test sets  for each cluster we calculated the average conversation lengths within itself
 intra cluster  and from itself to each other cluster  the results  given in table   and table    demonstrate
a significant increase in intra cluster conversation length versus inter cluster conversation length over all
the clusters  and in both the training and test sets  through clusters      the increase in conversation
length can be seen clearly over the given users  however  cluster   presented a more interesting case  which
we will address in the following section  additionally  the test data produced two clusters    and    which
had no intra cluster conversations  this is to be expected  as cluster   has   user  and thus cannot have
a conversation with itself  and cluster   has   users  and it is entirely possible for two randomly selected
users to not have had a conversation yet  
the outlier cluster  cluster     despite the clear improvement in conversation length in the other
clusters  we encountered a cluster which did not match the others and therefore presented a contradiction
to our theory  cluster   contained a very large number of users who had relatively low conversation lengths 

fitf idf chat user clustering

 

table    k means clustering results on train data
cluster

number of users per cluster

intra cluster conversation length

average inter cluster conversation length

 

     

     

     

 

   

      

     

 

    

      

     

 

   

      

     

 

  

       

     

 

    

     

     

 

    

      

     

 

   

       

     

 

   

       

     

 

  

      

     

average

    

      

     

table    k means clustering results on test data
cluster

number of users per cluster

intra cluster conversation length

average inter cluster conversation length

 

     

     

     

 

   

      

     

 

   

      

     

 

   

      

     

 

 

n a

     

 

    

     

     

 

   

    

     

 

   

       

     

 

 

       

     

 

 

n a

     

      

     

average

more importantly  this cluster exhibited a lower intra cluster conversation length than inter cluster length 
in laymans terms  we found a cluster of users who did not like to talk to other users in the same cluster 
but liked to talk to users outside of that cluster  our first hypothesis for this phenomenon was that this
cluster was comprised of male or female users who did not want to talk to the same sex  or that it was
comprised of users from a specific region  however  an analysis of the metadata showed that neither of these
cases were true  we compared cluster   to cluster    which we decided to be roughly indicative of the
other clusters  and found that the distributions of gender and region were roughly similar  see tables  
and     thus  a deeper analysis of the cause of cluster  s characteristics is needed  unfortunately  due to
the fact that the original words used by our users has been redacted  it is dicult to produce meaningful
results  however  our prevailing hypothesis is that cluster   contains users who are shy and do not tend
to initiate conversations  when two shy users are placed in a chat  they wait for the other user to reply 
when they do not  they cancel the conversation and move on  however  when this user is paired with a user
from a dierent cluster  they will tend to carry on a longer conversation 

conclusion
we present a finalized process for pairing users using the k means clustering system 

fitf idf chat user clustering

 

table    comparison of cluster   and cluster   by gender
training data

test data

cluster

  male

  female

  not specified

  male

  female

  not specified

 

      

      

     

      

      

     

 

      

      

     

      

      

     

table    comparison of cluster   and cluster   by region
training data

test data

cluster

  us

  india

  uk

  canada

  other

  us

  india

  uk

  canada

  other

 

      

      

     

     

      

      

      

     

     

      

 

      

      

     

     

      

      

     

     

     

      

    train the clusters using the k means algorithm with cosine similarity on a subset of the dataset 
    given a new user  calculate the closest centroid using cosine similarity 
 a  if the user conforms to the outlier cluster  pair with a user from a dierent cluster 
 b  else  pair with another user from the same cluster 
using this process  we have empirically shown an increase in conversation lengths over the given dataset 
users will tend to have longer conversations  which is correlated with higher chat quality and a better
overall experience with the chatous application 
future analysis
as noted  the redaction of used words in the dataset prevented us from a deeper analysis of our results 
with this extra information  we may be able to classify and generalize each cluster based on the used
words  for instance  the most frequently used words for each cluster could possibly correlate with topics of
the conversations within that cluster  or we could determine the root cause of the outlier clusters appearance
in the data  furthermore  access to true user vocabulary could help to determine bots spamming the site
 a user spamming a url or a particular product name is much more likely to be a bot 

fi