musical instrument extraction
through timbre classification
sang hyun park
nvidia corporation
santa clara  ca      
email  andyp nvidia com

abstractcontemporary technological advancement of internet and online servers allows many musical pieces to be readily
available to the users to enjoy  the users may listen to the
music  share with friends  or create another musical piece by
either remixing or sampling  one may desire to simply play the
music as it is or sample just one instrument out of the music 
however  this task can be challenging due to the complexity of
the modern musical pieces  a musical piece may contain multiple
musical instruments and this require the user to distinguish the
instrument from the others in order to play the correct part of
the music 
in this paper  a machine learning approach is presented to
extract a musical instrument from a complex music using timbre
classification 
index termstimbre recognition  timbre classification  machine learning  instrument recognition  instrument extraction 

i  i ntroduction
human ears possess an ability to distinguish musical colors 
we can easily distinguish the sound of piano from the sound
of guitar because they have different feeling or color in their
sound  when required training is processed  human ears can
extract a certain instrument using the knowledge of timbre of
the sound of the specific instrument  various audio features
are used in recent researches in order to achieve automatic
timbre recognition system using machine learning algorithms 
recognizing audio features can be a challenging problem since
it is a continuous task unlike descrete data  image or text
recognition  acquisition and recognition need to be in sync
of time frame in order to achieve correct predictions 
in order to achieve a correct set up for the recognition 
we need to explore more about the musical charactersitics 
timbre  then  we represents the audio features that we use in
this project 

adds that  timbre depends primarily upon the spectrum of
the stimulus  but it also depends upon the waveform  the
sound pressure  the frequency location of the spectrum  and the
temporal characteristics of the stimulus   american standards
association           
due to many attributes of sound are required to recognize
timbre  it is necessary to acquire features that are objective
rather than subjective  j  f  schouten suggested the following
five acoustic parameters to be considered related to timbre 
   the range between tonal and noiselike character
   the spectral envelope
   the time envelope in terms of rise  duration  and decay
 adsr attack  decay  sustain  release 
   the changes both of spectral envelope  formant glide 
and fundamental frequency  micro intonation 
   the prefix  or onset of a sound  quite dissimilar to the
ensuing lasting vibration
using the five parameters presented above r  erickson
presented a table of subjective experience to objective characteristics as shown on table   
although timbre is decided with multiple aspects of acoustic featurs  spectrum of audio seems to be most affected
feature 

ii  t imbre
timbre can be a set of subjective opinions of individuals
toward a sound that is independent from the frequency  pitch 
or the amplitude  loudness   timbre is also known as color
or tone of sounds  unlike frequency to pitch or amplitude
to loudness  there is no dominant attributes to timbre and
this limitation makes the definition of timbre to vary and
subjective 
the american standards association definition      of
timbre describes it as     that attribute of sensation in terms
of which a listener can judge that two sounds having the same
loudness and pitch are dissimilar  and a note to this definition

fig     octave  g on piano

figure   shows the spectrum of a sound of piano at the
frequency of octave  g  the color shows the amplitude of
the the corresponding frequency  white is the strongest  red 
blue  gray are in order 
we can see how the different timbre shows different spectrum when we compare piano  guitar  and vibe  features
related to spectrum should be sufficient to recognize different
timbre to a certain extent 

fitable  
subjective experience

subjective experience to objective characteristics of timbre
objective characteristics

tonal character  usually pitched
noisy  with or without some tonal character 
including rustle noise
coloration
beginning ending
coloration glide or formant glide
microintonation
vibrato
tremolo
attack
final sound

periodic sound
noise  including random pulses characterized by the rustle time
 the mean interval between pulses 
spectral envelope
physical rise and decay time
change of spectral envelope
small change  one up and down  in frequency
frequency modulation
amplitude modulation
prefix
suffix

   ceptral coefficients to represents mfc  hanning weighting
window to apply before fft     mel filter banks of    
     hz   kb block size and    b step size 
b  spectral shape statistics

fig     octave  g on guitar

fig     octave  g on vibe

this statistics includes the following four separate attributes 
centroid  spread  skewness  and kurtosis 
pn
i
n   fk  ak
i  
pn
n   ak
centroid    
q
     
spread  
skewness

 

kurtosis

 

             
 
sw
 
                   
 
 
sw

this features uses four consecutive frames of audio data to
achieve the above characteristics  in this research  we used
hanning weighting window to apply before fft   kb block
size and    b step size 

iii  f eatures e xtraction
features are collected using yaafe  yet another audio
feature extractor   the software produces many acoustic
features in easy and efficient ways  although there are   
features that we can get with the current version of yaafe 
we are only using few of the features in order to simplify the
beginning research process  we choose some of the features
that are related to spectrum  features that are acquired and
used for this project are described in the following subsections 

iv  data s et
audio data set for this project is produced by me using
the electronic keyboard which can make piano sound and
some other instruments such as guitar  vibe  etc  i was able to
achieve all scale of notes for each instruments but this method
is limited due to the limitation of the number of instruments
that i can produce with my keyboard 
v  m achine l earning a lgorithm

a  mfcc
mel frequency ceptrum coefficients feature is used broadly
in acoustic  sound  and speech related research areas due to
its compactibility to represent mfc which becomes the short
span of spectrum of an audio frame  in this research  we used

a  svm
since we have the label specifying if the given audio is
piano or not  we can use supervised learning on this  we used
svm with linear kernel to simplify the work for now 

fir eferences

b  knn
even if we have label  we can disregard the label and make
group of similar sounds using knn  then  label the group
using the majority label for the corresponding group  this may
not be allowing wrong placements of dataset but it is similar
to how human would process 
vi  r esults
using separately recorded notes as test sets  we were able
to achieve the below results for deciding if a note is played
by the piano or others 
ml tool
svm
kkn

accuracy
     
     

vii  c onclusion
we were able to achieve some functionality to distinguish
piano sound from the other sounds using the machine learning
algorithm  however  the accuracy is not good enough to be
used in real life yet  there are two potential optimizations to
be made in order to increase the accuracy 
a  features
the usage of the extracted features were not clear  in order
to make sense of the features and correctly use them  knowledge of acoustic and speech studies seems to be required  this
project can be rerun with the full fleged feature list and usage
in future 
b  machine learning algorithm
due to the time and member limitation  we did not extensively use svm and other algorithms  this is a must for next
engagement with this project in order to use more advanced
and known good algorithms 
c  dataset
since the dataset i acquired from my electronic keyboard
may suffice for current limitation in the project but this is still
limited since the world has so much more timbre to consider 
next time this project should be done with more various sound
sources 
d  future work
this project has a small scope where we only find a short
frame of sound is from piano or not  the first goal will be
properly achieve the mentioned task  then  we can diverge to
three different paths  one is to distinguish more instruments
from the given sound  another is to detect piano in a frame
where more instruments than piano are played at the same
time  the other is to implement continuous recognition and
detection in a long audio stream  when these three can be
achieved  we can finally meet the last goal which is to extract
a specified instrument from music  this project will be the
starting point to achieve the goal 

    t  h  park  towards automatic musical instrument timbre recognition  ph d  thesis  princeton university       
    x  zhang  z  w  ras  analysis of sound features for music timbre
recognition  ieee cs international conference on multimedia and
ubiquitous engineering  mue        april        seoul  korea  pp      
    b  mathieu  s  essid  t  fillon  j prado  and g  richard  yaafe  an
easy to use and efficient audio feature extraction software  proc  of
the   th ismir conference  utrecht  netherlands       
    d  k  fragoulis  j  n  avaritsiotis  and c  n  papaodysseus  timbre
recognition of single notes using an artmap neural network  proc 
of the  th ieee international conference on electronics  circuits and
systems  paphos  cyprus       
    r  loughran  j  walker  m  oneill  m  ofarrell  musical instrument
identification using principal component analysis and multi layered
perceptrons  ieee international conference on audio language and
image processing  shanghai  pp                
    s  b  davis  and p  mermelstein  comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences  ieee transactions on acoustics  speech  and signal processing 
       pp                
    o  gillet  and g  richard  automatic transcription of drum loops 
ieee transactions on acoustics  speech  and signal processing  montreal  canada       

fi