waiting for a sign  an unsupervised pipeline for sign
language recognition
dan sakaguchi
stanford university
dsakaguc stanford edu

abstract
our research presents an unsupervised
method of retroactively labeling gestures
 taken from american sign language  in an
unlabeled video dataset  given an estimate
for the number of gestures  temporal
motifs  contained in the video  our program
attempts to categorize the gestures  as well
as estimate their starting times within the
video  the model uses low level graphical
features extracted from the video to
determine significant information  repetition
of full or partial gestures  without temporal
dependence  through probabilistic latent
semantic
analysis
 plsa  
plsa
additionally
acts
to
reduce
the
dimensionality of the large dataset  
gestures and their starting times are then
found by probabilistic latent sequential
motif  plsm  analysis on the compressed
information determined by the plsa  once
the gestures are categorized and their
starting times are determined by the plsm
analysis  a simple retroactive labeling of
each found gesture results in an accurate
labeling of the entire video data set 

introduction
in the field of gesture identification  there
exists much work on the recognition and
classification of sign language  american
sign language  asl   in particular  several
successful models have been proposed for
identifying static signs  e g   signs of the
alphabet           despite this  there is
relatively little work focused on the
recognition and classification of dynamic
signs  signs for which the motion is not

jacob waggoner
stanford university
jacobw  stanford edu

separable from the meaning   to date  one
of the only successful studies produced    
accuracy after    hours of exposure to
dynamic  supervised signs      very few  if
any  studies have approached the problem of
dynamic sign recognition with an
unsupervised model  initially  we planned to
use a supervised model using labeled sign
data  however  it was not readily available 
this  in combination with the notable
absence in the field on unsupervised
approaches  motivated our interest in
developing a means of identifying repeated
signs without supervision in order to learn
what a sign looks like  in theory  then 
given an internal representation of what a
sign looks like  our algorithm would   
allow the video to be accurately labeled at
the substantially reduced cost of labeling
each of the representations  and    given a
metric and probability threshold  allow
identification of a new sign as either a
particular sign in the built up vocabulary  or
a new sign
in a generalized context  this problem has
been referred to as temporal motif
discovery      most recently  emonet et al
developed a method for extracting temporal
motifs from video of a traffic intersection
 e g   identifying a right turn  a left turn  a
crowd crossing the sidewalk  etc       
because of its success  as well as the
analogy between finding temporal motifs in
traffic video and in video of signs  we
sought to apply their model to our problem
by adapting it to fit the setting of sign
language  our treatment of the problem is
thus broken down into four primary

ficomponents  feature extraction  feature
dimensionality reduction  motif extraction 
and validation 

model overview
the two primary algorithms utilized in our
study were probabilistic latent semantic
analysis  plsa  and probabilistic latent
sequential motif  plsm  analysis  the first
was used to reduce the dimensionality of the
data  low level graphical features  passed to
the second  while the second incorporates
temporal information to determine temporal
motifs  both algorithms operate primarily on
data in the form of a bag of words  a
matrix storing counts of words in
documents      these counts are then used
to generate probability distributions of latent
variables  the number of which is specified
by a parameter  over the data with the
estimation maximization algorithm  in the
plsa  the words are the low level graphic
features described below  the documents are
the spatio temporal boxes containing those
features in bins  the latent variables are
components of signs  segments of motion
that are repeated throughout the video  but
not necessarily whole signs   and the
generated distributions are p w z  and p z d 
where w refers to the words  z to the latent
variables  and d to the documents  in the
plsm analysis  the words are frequency
counts estimated by the plsa  the
documents are video segments  the latent
variables are signs  temporal motifs   and
the generated distributions are p z d  
p ts z d   p w z   and p tr w z   where w  z 
and d are as before  ts is the starting time of
the sign within a document  and tr is the
relative time within a sign  ie  tr     with
respect to latent variable z refers to the start
time ts  of that variable z   these processes
are described in greater detail below 

feature extraction

in        emonet et al proposed the use of
low level graphical features  ie  video frame
pixel by pixel  such as optical flow and
spatio temporal location  coordinate  w  h 
f  where w and h represent a pixel position
in a frame  and f is a frame  to serve as the
words for the plsa      we created
documents from these features by dividing
the video into    x    x   boxes  with  
frame of overlap between documents  over
which we binned the flows into four motion
categories  left  right  up and down  a
manually determined threshold was used to
eliminate pixels without significant motion 
to these bins  we elected to add additional
features derived from the edges of our
images  similarly to optical flow  we binned
the edges into four categories  horizontal 
vertical  and two diagonal categories    
degrees off of the horizontal and vertical 
respectively   these were appended as
additional features after testing on artificial
data  which indicated that the plsa might
require improved features 

dimensionality reduction
the features above contain an enormous
amount of data  for a five minute video of
signs  the main video file is a matrix of
approximate size     x     x   x      
given our resources  processing matrices of
this size was not realistic or time efficient
because of the computational expense  thus 
we analyzed the features from above using a
plsa in order to reduce the amount of data
that the motif finding algorithm  plsm 
needed to process  this analysis uses em
maximization to maximize the joint worddocument log likelihood probability
distribution in order to generate locally
optimal multinomial distributions for worddocument co occurrences  we additionally
attempted to perform this reduction step
with latent dirichlet analysis  but found that
it was too computationally expensive for the

fiquality of video      x      and frame
sampling rate     fps  we desired 

model
the model that we use for the temporal
motif finding  plsm analysis  is a
generative one  it is summarized as follows
    






draw a temporal document d with
probability p d 
draw a latent motif z from p z d 
draw the starting time ts from p ts z d 
draw a word and relative time pair  w tr 
from p w tr z 
set the absolute time in the document to
the starting time plus the relative time

this process is also illustrated in figure  
below      generally  as with plsa  it uses
em maximization to produce locally
optimal multinomial distributions on the cooccurrence of words  sign segments found
from plsa  and documents  video
segments   specifically  tz is a specified
maximum sign length  in frames   ta is a
time  frame  occurrence  ts represents a
starting time  frame  of a sign  and tr is the
relative time given a sign  number of frames
from ts   the algorithm itself is outlined in
figure       
figure    taken from    

figure    equations for plsm em maximization
e  step   p z  ts   w  ta  d   

nz tds
p w  ta  d  z  ts 
where  p w  ta  d     p w  ta  d  z  ts 
p w  ta  d 
z   ts  

tds tz  nw

m  step   p z   d      n w  ts   tr  d p z  ts   w  ts   tr  d 
ts   tr   w  
nw tz 

p ts   z  d     n w  ts   tr  d p z  ts   w  ts   tr  d 
w   tr  
d tds

p w  tr   z    n w  ts   tr  d p z  ts   w  ts   tr  d 
d   ts  

n d  ta  w   



 wy

 
 n dta    p    y 
n dta     

synthetic data
figure    synthetic data in a   a  with noise added
in b

a 
b 
we first demonstrate the temporal motif
extraction algorithm on the artificial count
data in figure  b  were this data not
synthetic  it would represent the counts
matrix calculated by equation   in figure   
figure  a shows the data before gaussian
noise  mean    standard deviation    was
added  it contains three different motifs  as
shown in figure  a c  comprised of five
words  motif components   of different
lengths        and    at random positions in
the     frame document  the results of
plsm analysis with a maximum motif
length of   and an estimated number of
motifs     are shown in figures      figure  
d e represents the estimated motifs  and
figure   represents the estimated starting
times of the motifs  as is clear from
comparing figures  a c and  d e  the model
yielded estimated motifs that are identical to
the synthesized motifs  moreover  in
visually comparing figure  a with figures
 b d  the ith row in  a corresponds to the ith
image beneath  a  the rows represent
motifs  the columns represent starting times 
also note that some scaling differences
arose in formatting the image  and that the
times do  in fact  correctly line up   it is clear
that the model is most strongly weighted

fitowards the correct motifs at the correct
times  this serves to demonstrate the
robustness of the model given noisy data 

figure    image of the sign for help

figure    true and learned synthetic motifs
a c 
d f 
figure    true and learned motif starting times for
the synthetic data

a 
b 
c 
d 

real data collection
originally  we intended to use microsoft
kinects depth sensor in conjunction with
rgb video to collect the data for this study 
after observing that the depth information
did not have the granularity to substantially
contribute to the model  we elected to use
only rgb video and extract features using
optical flow and edge detection  as described
previously  the preliminary results
presented here were recorded with the
kinect camera    fps   in the video  we used
the signs for help  want  hello  and
please  intentionally selecting a diverse
vocabulary to strain the model  although we
recorded the data ourselves  we consulted a
professor of sign language at stanford
university for her expertise in signing prior
to collecting the data  figure   shows a still
image of the sign for help 

real data
after extracting features from the video of
signs  one result of which is shown in figure
  from the video  original image  optical
flow overlay  and edge overlay   we
analyzed the videos with plsa  figure  
shows one component of a sign  the sign
help  found by the plsa on the second
video  generally  the result of feature
extraction and plsa were qualitatively very
similar to these images  in that they were
consistently correctly and identifiably
associated with a sign 
results
we only qualitatively compare the estimated
starting times for the found motifs and the
true starting times  these results are shown
in figure   with a  corresponding to the true
times  and b  corresponding to the estimated
times  as can be seen by comparison of the
images  where row represents a sign  and
column represents a starting time  our
pipeline was able to identify  with     
accuracy  the signs for want  hello  and
please  finding one false positive  bottom
left corner  on the sign for want  the sign
for help was correctly identified     of
the time  also note the weak  but significant 
probabilities in the first row of each figure 
with the exception of two starting times
predicted for the sign for please  all of the
estimated start times align with the true start
times  this can perhaps be explained by the
fact that the sign for please is

fiapproximately     times the length of the
others  and so may vary more 
figure    true and learned motif starting times for
the real data

a 
b 
figure    original image  optical flow
and line features for a learned plsa topic

    varadarajan  j   emonet  r     odobez  j m 
        probabilistic latent sequential motifs 
discovering temporal activity patterns in video
scenes  idiap research institute  retrieved from
http   publications idiap ch downloads papers      v
aradarajan bmvc          pdf
    kharbat  m          horn schunck optical flow
method  mathworks file exchange  retrieved from
http   www mathworks com matlabcentral fileexchan
ge       horn schunck optical flowmethod content hs m
    hofman  t           probabilistic latent semantic
analysis  plsa   oxford visual geometry group 
retrieved from
http   www robots ox ac uk  vgg software 
    farrell  j   atwood  j     atwood  j 
        american sign language recognition system  
informally published manuscript  department of
mechanical engineering  carnegie mellon
university  pittsburgh   

discussion
in the preliminary video  comparison of the
learned and true labels suggests that our
procedure was effective in determining both
the identity of the gestures and their starting
times throughout the video  examination of
the learned patterns shows that these motifs
do indeed correspond with the intended asl
signs with high accuracy  despite these
promising indications though  the algorithm
appears to have assigned unacceptably low
probabilities to several instances of the
help sign  which could have resulted from
the low fps of the collected video or the low
dynamic content of the sign itself  future
work will take advantage of the nonoverlapping nature of asl signs to increase
sign fidelity 

references
    varadarajan  j   n d    retrieved from
http   publications idiap ch downloads papers      v
aradarajan thesis      pdf

    sole  m     tsoeu  m              sign language
recognition using the extreme learning machine  
ieee africon        the falls resort and conference
centre  zambia 
    rehg  j   essa  i   hamilton  h   starner  t    
yin  p          learning the basic units in american
sign language using discriminative segmental feature
selection  informally published manuscript  school of
interactive computing  georgia institute of
technology  georgia institute of technology 
atlanta  ga 
    sarrahfzadeh  m   amini  n     vahdatpour  a 
       toward unsupervised activity discovery using
multi dimensional motif detection in time series 
informally published manuscript  department of
computer science university of california  los
angeles  university of california  los angeles  los
angeles  ca 
    barras  c                 computer learns sign
language by watching tv  new scientist  retrieved
from http   www newscientist com article dn     computer learns sign language by watching tv html

fi