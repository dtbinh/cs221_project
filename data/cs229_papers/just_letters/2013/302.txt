supervised classification based stock prediction and portfolio
optimization
cs     project milestone report
fall     
sercan ark    burc erylmaz    and adam goldberg 

introduction

we reduce the problem to a classification problem since
that makes it easier to evaluate our approach  we examine a variety of supervised learning techniques and find
that using stock fundamentals is a useful approach for
the classification problem  when combined with the high
dimensional data handling capabilities of support vector
machines  the portfolio our system suggests by predicting the behavior of stocks results in a    larger growth
on average than the overall market within a   month
time period 

as the number of publicly traded companies as well as
the amount of their financial data grows rapidly and
improvements in hardware infrastructure and information processing technologies enable high speed processing of large amounts of data  it is highly desired to have
tracking  analysis  and eventually stock selections automated  machine learning has already attained an important place in trading and finance  one currently major area is high frequency trading  there are many techniques in the literature and applications to predict shortterm movements based on different stochastic models of
temporal variations of stock prices                 such
approaches generally rely on treating individual stock
data as a time series without analyzing correlations and
patterns between different companies  mainly because of
the limitations of processing very large data sets at very
high speeds  another major application is valuation of
the market based on economic parameters               
               for most of these applications the amount
of data processed is limited and most do not drill down
to the granularity of individual companies               
               few works which studied portfolio optimization on individual company level focused on very small
number of financial parameters      
a very large portion of the finance industry is comprised of mid  to long term portfolio construction and
is still mostly performed by hedge fund managers and
financial analysts based on analysis and decision processes using company fundamentals  considering the entire new york stock exchange  nyse  stock market
between the years      and      there are more than
      stocks  and that number grows almost everyday
with new initial public offerings   since this number is far
larger than a human could manually handle  automation
of financial analysis and investment decisions by modeling company fundamentals is a clear need 
in this project  we use machine learning techniques
to address portfolio optimization  our approaches are
based on the supervision of prediction parameters using company fundamentals  time series properties  and
correlation information between different stocks  rather
than focusing on indicators of the overall economy  we
focus on individual company data for the training phase 

normalized ibc  a u  

  

research data

   

normalized oiadp  a u  

   

goog
ksu
axll
orbt

 a 

  
 
   
                             
year

  
  
  

goog
ksu
axll
orbt

 c 

  
 
   
                             
year

normalized act  a u  

  

soarik stanford edu    eryilmaz stanford edu  and   agoldberg cs stanford edu

   
   

normalized recch  a u  

 

  

goog
ksu
axll
orbt

 b 

  
  
  
 
                             
year

  
  

goog
ksu
axll
orbt

 d 

  

 
   
                             
year

fig     example financial parameter values for two
bullish stocks  goog and ksu   denoted with green
circles  and two bearish stocks  axll and orbt   denoted with red squares  financial parameters represent
 a  income before extraordinary items   b  total current
assets   c  operating income after depreciation  d  accounts receivable decrease 
after a financial literature review and availability
search  we pick    fundamental financial parameters to
sufficiently represent the business fundamentals of each
stock  as well as the general situation of the entire financial market and us economy  all of the financial parameters are taken with annual period  although their announcement date demonstrate almost uniform distribu 

fi  

 

 

   

   

   

   

ordered company index

feature value  a u  

fig     market capitalization of the companies in the
data set in ranked order  the companies shown in pink
are discarded 
we initially consider all available nyse stocks that
have at least     of the analyzed financial parameters
available  among the entire set of stocks  we eliminate
the ones that are not currently traded due to bankruptcy
or acquisition  since we need to be able to analyze temporal characteristics of stock behavior  we discard stocks
with less than    years of financial data for the sake of
completeness  combined with the these limitations  we
gather a data set comprising      stocks  as can be observed from the market capitalization values in fig    
there are more than four orders of magnitude difference
between the financials of large and small companies  the
behavior of the stock prices of extremely small companies typically do not have a pattern that can be modeled analytically  the trend of their stock prices are often
dominated by speculations barely dependent on financial
fundamentals  hence  for more robust implementation of
the supervised learning techniques  we further eliminate
    companies with the smallest market capitalization 
  

    

idct

 

 

  

 

 

rect  filter

  

processing is critical for the efficiency and accuracy of
the learning and prediction techniques  in this section 
we describe the data preprocessing approaches we use
before application of supervised classification 
firstly  the financial data set of     companies include
missing and errorenous values for some financial paremeters  we address this problem in two steps  firstly  we
eliminate financial parameters with a fraction of missing data larger than a certain threshold  note that this
is different from eliminating some stocks explained in
research data section  where we eliminate stocks that
are missing data more than a threshold   conservatively
setting this threshold to    for the years between           we eliminate    out of    features from our financial data set  and are left with    financial parameters  secondly  we perform imputation by assigning the
mean  averaged over all stocks within the given year  of
that given financial parameter to the missing data entry 
which we dont believe skews our feature distribution as
few values are missing after our aforementioned company
and feature selections 
as the relative change of a financial parameter rather
than the monetary value itself is more important for the
performance  we normalize each parameter with respect
to its value at the beginning of the financial data time
frame  similar to fig      then  we normalize each distribution to zero mean and unit variance for a given
feature  across all stocks in the given year   since the
supervised classification implementations we use are optimized for this normalization 

dct

market capitalization  a u  

tion throughout the year  as representative examples 
four financial parameters  income before extraordinary
items  total current assets  operating income after depreciation  and accounts receivable  among these are displayed in fig    for four stocks  goog  ksu  axll
and orbt  between the years      and       as formulated in section    our classification approach is based
on determining the annual performance of a stock compared to the average annual market performance  which
is quantified with respect to the nyse composite index   we define bullish as yielding positive gains with
respect to market and bearish as yielding negative gain
with respect to market and use them as our classification labels  in fig     there are examples of   bullish and
  bearish stocks defined for the year       individual impact of various financial parameters might not be very
discriminative when considered individually  however  as
will be shown  financial parameter data becomes very
useful when considered collectively and when combined
with the flexibility and data handling capabilities of support vector machine classifier 

  dct coefficients
  dct coefficients
  dct coefficients
  dct coefficients
    

    

    

    

    

    

         

year index

fig     the feature value over time for different values
of dct coefficients  inset  block diagram of the filtering
operation 
for robustness of the classification  we consider two
smoothing strategies  most of the financial parameters
do not have a smooth variation from one year to another 
but rather have an abrupt change over the years  see fig 
    to filter out this high frequency volatility  we apply
filtering in the discrete cosine domain  we consider filtering using an ideal rectangular discrete filter which is
equivalent to setting a particular number of high order

data preprocessing

given the large size                       data points
in total  of the entire set of financial parameters  pre 

ficoefficients to zero in discrete cosine domain  the discrete cosine transform  dct  of a discrete time domain
signal f  n   n           n   is 
r
f  k   

n
x

 
     k  
f  n  cos
n
n  



  n     k    
 n

is formed as 

xt    
 xt     


xt        
    




xt  n 

 
where

   
where  k           n   and  k  is the dirac delta function 
the filtering operation with rectangular filter with width
h yields 

fg
 k   

f  k  for k           h 
  for k   h           n 




xt  i    


x t  tl    i 
x t  tl    i 
  
 

   

fg
 n   

k  

 
     k  fg
 k  cos
n

  n     k    
 n



y      t    
y      t    
  
 

   












    
 y  t  m   




  
yt   
 
 


 y  n   t     


 y  n   t     




  


 
 n 
y  t  m  

 

   
fig    exemplifies the impact of the rectangular discrete
filter width h  or the number of non zero dct coefficients  on smoothing  based on our empirical observations  we choose a rectangular filter width of   for all of
the variables in our financial data set  lastly  we consider
smoothing based on principal component analysis  for
robustness of the supervised classification  we eliminate
the smallest     principal values  which are computed
using singular value decomposition 
  



 


and the vector of corresponding known labels  determined by the relative market performance in that given
time frame  of past m years are 






x tm  tlm   i 

finally  the filtered signal is transformed back into the
time domain applying inverse dct 
n r
x

   

   

after applying all of the pre processing operations  we
end up with k      features as explained in the previous section  our observations suggest that both financial
parameters and stock performance in the past beyond a
particular time frame have negligible effect on the current performance  hence  we make choices of m    
years and l     years  to further narrow down the problem  we limit the performance metric to the time frame
of   months after the announcement date of financial parameters  e g  y  i             if the stock i outperforms
the market at the end of the three months after the accouncement of financials of the year      

stock prediction with supervised learning

minimum learning error rate    

the rationale of our stock prediction technique is based
on determining classification parameters using the relationships between the past financial parameters and
their impacts on the past performance  in this section 
we first formulate the general approach and then specifically describe the techniques used in this paper 
let k be the number of features  for a stock with index
i     i  n   let the feature vector x i   t   rk denote
the corresponding financial parameters of year t after
pre processing  let the label y  i   t              denote
the relative market performance  i e  either bearish or
bullish  of the stock i in a given period of time after
the announcement date of financial parameters of year t
 t                          the goal is to predict y  i   t 
for each i using the financial parameters of past l years 
i e  based on the feature vector 
  i 

x  t    
 x i   t     


x t  tl   i    
   
 
  


 
x i   t  l 

  
  

  
  

  
  

 
  
  
  
  
   
cardinality ratio of training subset    

fig     minimum learning error rate vs  cardinality ratio
of training subset  obtained using svm classification as
explained in the test  

for supervision of the learning parameters  known performances of all of the stocks in the data set of past m
years are used  the corresponding training data matrix
 

fiwe partition the entire training data set of size m  n
into two subsets and partition xt and yt accordingly 
we use the first subset to determine the classification
parameters and the second subset to test the training
accuracy of the classification obtained by the first data
set  this also allows us to consider different subsets of
the training set to optimize the learning performance by
reducing the impact of speculative companies or abrupt
changes on supervision  fig    shows the the impact of
the cardinality ratio of the first subset on the training
error rate  to have low enough prediction error rate while
having a reasonable number of elements in the testing
data set  we fix this cardinality ratio to     for the rest
of the results  since consideration of all combinations
with the given cardinality ratio have prohibitively high
computational complexity  we only consider a particular
number of random realizations for training 
we initially consider supervised classification using
decision trees  k nearest neighbors  naive bayes and
support vector machine  svm  techniques  our results
suggest that svm outperforms the other three classification techniques with more than    prediction accuracy 
provides more robustness to the changes in the training
data set  and is more computationally efficient for large
data sets  therefore  in this paper we focus on stock
prediction using svm based classification  other studies                    also show svm is well suited for financial applications with its capability to model high dimensional feature spaces since financial parameters can take
very different functional forms  see fig    for example  
we perform optimization of several svm parameters
for the highest prediction accuracy by exponential grid
search  we choose the gaussian kernel based on the motivation explained above  that is also motivated in the
literature to work well for problems involving time series
analyses       we choose a box constraint parameter of
     we allow up to     of the support vectors to violate
karush kuhn tucker  kkt  conditions considering the
nature of the problem such that lower prediction accuracy values are acceptable  because of the convergence
issues of commonly used sequential minimal optimization based updates  least squares based parameter updates are applied 
  

 b  prediction

 a  training
  

  

actual bullish
actual bearish

  

 

 

  
  

actual bullish
actual bearish

  
  

  
 

bullish
predicted

bearish
predicted

 

bullish
predicted

bearish
predicted

fig     average confusion matrix values  bars in each
plot show the ratios of true positive  false positive  false
negative  true negative respectively  in  a  training and
 b  prediction 

  

 
 

average return of
bearish stocks

distribution

  

average return of all
stocks

  

 

 
  
  
average   month return in         

average return of
bullish stocks

robustness of the technique even more noisy stocks are
included in the training data set 

  

fig     distribution of average   month return of the
portfolio obtained by uniform weighing of bullish labeled stocks  shown with bars   average return of all
stocks  black dashed lines   average return of all bearish stocks corresponding to    prediction accuracy  red
dashed line   and average return of all bullish stocks corresponding to      prediction accuracy  green dashed
line  
as a more meaningful metric  we evaluate the performance of the portfolio comprised of the bullish classified companies by the proposed classification technique 
we simply assume an equal share allocation among the
bullish classified companies   share allocation optimization can yield higher returns and is further discussed
in future work   fig    shows the distribution of the
returns of the portfolio obtained over     random relatizations  as well as the average return of all stocks and
average returns of actual bullish and bearish stocks  as
can be observed  market outperformance is obtained for
all of the random realizations  the average   month return of the the optimized portfolio is approximately   
higher than the market average 

results

fig    depicts the accuracy of the classification in both
training  for the partitioned data set as explained in previous section  and prediction  for the entire data set
corresponding to year        error values are shown
separately for bullish and bearish labeled stocks  averaged over     random realizations of training and prediction  in training  the average true classification ratios
are       for bullish stocks and       for bearish stocks 
and in prediction the average true classification ratios are
      for bullish stocks and       for bearish stocks 
moreover  for all random realizations the prediction accuracy is found to be greater than        suggesting the

  

conclusions and future work

in this paper  we realize an supervised classification
based predictor for mid  to long term portfolio construction  since our analyses suggest that svms give better
 

fiperformance over other supervised learning techniques
 such as naive bayes and k nearest neighbors   to minimize prediction error rate  we focus on svms to further
optimize our classifier  having determined a set of financial parameters after an extensive literature review 
we develop data mining techniques to effectively collect
them for the time period of interest  we apply stateof the art statistical data analysis tools  discrete cosine
transform and principal component analysis  to smooth
the information content of the stock fundamentals data
and reduce dimensionality  we find that using several financial parameters for all the companies in the dataset
collectively while utilizing the high dimensional feature
space handling capabilities of svms is very effective to
discriminate between bullish and bearish stock growth
for portfolio optimization  to further increase the success rate of prediction of our classifier  we choose optimal values for several svm parameters  the portfolio of
companies predicted to be bullish by the classifier yields
   more return on average over a   month period than
the nyse composite index  this is a significant step towards realizing an automated stock picking algorithm
using the principles of artificial intelligence and machine
learning 
we believe there are important fundamental open research problems and room for improvement in this area 
from a machine learning perspective  it will be useful
to study the performance of our classifier for a broader
range of different kernels and optimization techniques
such as adaptive simulated annealing and the fourier
kernel        this will allow us to see any overfitting or
underfitting issues that might be occurring in our classifier  in addition  we can try a modified version of svm
as suggested in      where the data closer to the present
time is assigned more importance  from a finance perspective  the empirical distributions of financial parameters and their impact on stock performance are actively
studied and hinder the application of machine learning
techniques based on a priori statistics  the portfolio we
build in this work assigns equal weight for each stock predicted to be bullish  an important future goal is to develop a model to set a price target for the chosen stocks in
the portfolio  that will allow optimization of the amount
of each stock in the portfolio  in order to make this work
more practical and application specific  we can also construct a portfolio based on a risk parameter according to
user needs  and determining the weights of each stocks
in the portfolio accordingly  correspondingly  we are currently examining various regression techniques that can
be generalized for our problem  as well as hybrid classification and regression approaches  we are also investigating efficient modeling of the temporal correlations of
the financial parameters in order to effectively model the
impact of the past years data to improve learning  potential approaches we are considering are spectral classification based on fast fourier transforms or optimized
filtering techniques 

references
   dempster  michael alan howarth  et al  computational learning techniques for intraday fx trading using
popular technical indicators  neural networks  ieee
transactions on                      
   budish  eric  peter cramton  and john shim  the
high frequency trading arms race  frequent batch
auctions as a market design response  manuscript
       
   hendershott  terrance  and ryan riordan  high
frequency trading and price discovery  manuscript
       
   huang  wei  yoshiteru nakamori  and shou yang wang 
forecasting stock market movement direction with support vector machine  computers and operations research                         
   zhai  yuzheng  arthur hsu  and saman k  halgamuge 
combining news and technical indicators in daily stock
price trends prediction  advances in neural networks 
springer berlin heidelberg                         
   kim  kyoung jae  financial time series forecasting using support vector machines  neurocomputing      
               
   lu  chi jie  tian shyug lee  and chih chou chiu  financial time series forecasting using independent component analysis and support vector regression  decision
support systems                        
   ou  phichhang  and hengshan wang  prediction of
stock market index movement by ten data mining techniques  modern applied science       p          
   yu  lean  et al  evolving least squares support vector
machines for stock market trend mining  manuscript 
university of california  berkeley                      
    quah  tong seng  and bobby srinivasan  improving returns on stock investment through neural network selection  expert systems with applications              
       
    stefan  ruping  svm kernels for time series analysis 
proc  of tagungsband der gi workshop woche         
    tay  francis eh  and l  j  cao  modified support vector machines in financial time series forecasting  neurocomputing                      

 

fi