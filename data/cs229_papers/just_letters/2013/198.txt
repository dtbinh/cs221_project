title  genome wide predictions of transcription factor binding events using multidimensional genomic and epigenomic features
team members  david moskowitz and emily tsang
background
transcription factors  tfs  regulate gene expression by binding to specific sequences of
dna  this drives disease progression and differences between cell types  biologists can elucidate
tf binding sites using a technique called chip seq  although sensitive and specific  chip seq can
only provide information for a single tf per experiment  because there are hundreds of tfs
expressed in each cell  compiling an exhaustive set of tf binding sites for even a single tissue is
prohibitively expensive and time consuming  here  we discuss applying machine learning to an
expansive set of genomic features to predict genome wide binding  simultaneously for all tf of
interest  in a cell type for which chip seq data may be unavailable 
many of our features are from sequencing based assays that probe different characteristics
of the cell  sequencing of dna or rna gives hundreds of millions of short sequence strings  a
typical workflow involves aligning these strings to their original location in the genome and further
steps specific to the particular assay  for example  dnase seq probes dna openness by only
sequencing dna that is accessible and can be cleaved into short reads  most dna is tightly coiled 
preventing proteins like tfs from binding there  we are therefore restricting our analysis to open
sites  which constitute       of the genome in our cell lines of interest 
we used publicly available data to build our feature set and training examples for several
different cell lines  as our use case  we assume that a given cell type has dna accessibility
information  but no chip seq data  we want to use the data compiled for other cell lines to predict
binding events in the tissue of interest  to simulate this situation  we evaluated different multi class
classification methods on this data set via leave one out cross validation with respect to cell line 
with small adjustments  we get average cross validation accuracies of       we then explored
using a smaller or less comprehensive training set  and smaller feature sets  finally  we simulated
prediction for a factor for which there are no training data to see whether our approach can learn
general features of tf binding 
labels and features
most experimental data we used were from the encode project   this included assays of
several cell specific features such as rna seq  chip seq of both activating and repressing histone
modifications  chip seq for several tfs  and dnase seq  we also built features from cell typeindependent data such as genomic conservation  ht selex scores  and distance to the nearest
gene  we chose five cell lines for which all the data listed above were available  gm       h 
hesc  hela s   hepg   k     we decided it would be best to restrict the tfs for which we were
making predictions to ones that had ht selex scores as well as chip seq data for all five cell
lines  this left us with five transcription factors  ctcf  mafk  max  nrf   and rfx  
we combined information from chip seq  dnase seq  and ht selex to define the class
labels  chip seq reveals where specific proteins  such as tfs  are bound by selectively sequencing
the dna with which they interact  the assayed protein is putatively bound within regions enriched
for chip seq reads  these regions are broad       base pairs each   so we restricted them in two
ways  this is needed because the majority of sites in those regions are actually unbound and thus
the features therein would not be characteristic of tf binding  first  we postulated that tfs cannot
interact with highly condensed dna  so we intersected the chip seq with the dnase seq peaks 
which mark accessible dna regions  we then use ht selex scores to pinpoint the most likely
binding site  ht selex  is a technique used to find motifs to which tfs bind  we devised a means

fiby which this can be translated into the likelihood with which a tf will bind at a given locus 
  where n is the motif length  cij is the count  in the ht selex
data  of base j  in  a c g t   at the ith position in the motif  and the indicator function is   if the
genomic base gi is equal to the current base  the site with the highest ht selex score within each
restricted chip seq peak is labeled as bound by the tf 
the number of training examples for each tf was                                   and
       for ctcf  mafk  max  nrf   and rfx   respectively  the number of bound instances
per cell line was                                  and        for gm       h  hesc  hela s  
hepg   and k     respectively  for each cell line  we randomly selected an equal number of
unbound sites within dnase regions as negative examples  maintaining a balanced class ratio to
diminish classification biases 
when building our feature vector  we used the idea that a small number of bases on either
side of a tf binding site are informative  therefore  we created a     base pair  bp  window
centered on the current prediction site  for each site within that window  we include the phylop
score for that site as well as indicators for activating and repressing histone marks  phylop  is a
metric of genetic conservation between species  the idea is that more highly conserved sites are
likely functional  on the other hand  histone modifications hint at the activity level of a site 
histones are proteins around which the dna wraps and the location of those with particular
modifications can be identified by chip seq  we intersected the chip seq peaks for six marks of
active sites to get an indicator function for activating histone marks at each site  we use the peaks of
the single repressing histone mark assayed to define the second indicator function 
in addition to the features in the window mentioned above  we incorporate the distance to
the nearest gene  the expression level of that gene and the ht selex scores of the five tfs of
interest at the prediction site  we determine the location of the nearest gene using the gencode
gene annotations  and calculate its expression level based on the rna seq data  to get the
expression level of each gene  we first counted the number of rna seq reads that overlap gene
annotations using htseq   then normalized these raw counts with deseq   which accounts for
variability in the number of reads in the different cell types and individual gene lengths 
with conservation  and two indicators for histone modifications at each position in a
window of     base pairs  five ht selex scores  and two gene related features  we created a total
of     features per prediction site 
methods and results
classification using entire training set
after the creation of the feature vector and the attribution of class labels  we investigated
several methods for predicting the tf binding events  using liblinear   we applied an svm with a
linear kernel using l  regularization  the same type of svm on scaled data  multinomial logistic
regression  and multinomial logistic regression using l  regularization  additionally  we evaluated
the robustness of our model by down sampling our training set and by performing forward selection
on our features  finally  we quantified cell specific and transcription factor specific effects by
repeating the classification on different training and test sets 
in our first attempt at classification  we applied liblinear to train a linear kernel svm with
l  regularization  with five fold cross validation  leaving out one cell line in each iteration  we
obtained an average accuracy of just over      table    column     when we visualize the
accuracy  distinguishing between classes  we find that the svm is performing reasonably on
unbound cases  but only modestly for each tf  fig   a   however  we still viewed this as
promising  since  in six class classification  this performance is significantly above random 

fiin evaluating our method  we realized that our features were drawn from widely varying
distributions  we became concerned that those with greater ranges  such as gene expression  might
be overpowering the signals from features with more confined ranges  such as genetic conservation 
thus  we decided to scale each feature independently to a range of          we then reran the svm
and found our accuracy had improved to      for all cell lines  table    column     visualizing
these results  we find that most errors arose from misclassifying bound versus unbound  and that
bound classes were rarely confused  fig   b   because the scaled data set produced such a marked
improvement over the unscaled  all subsequent analyses were also performed on the scaled data 
we attempted to further increase our accuracy by empirically searching different penalty
parameters in the error term of the svm optimization problem  however  we found that this
increased our accuracy by only        while increasing our run time by    x  and thus decided to
abandon this approach 
however  we were still lacking a quantitative assessment of our confidence that each locus
belonged to a particular class  by instead running multinomial logistic regression  which offered a
slight increase in accuracy  table    column     we found that the distributions of probabilities
varied greatly between correct and incorrect classifications  fig   c   specifically  when an instance
is correctly classified  the associated probability is generally high  fig   c  black curve   when an
instance is misclassified  the confidence is substantially lower  fig   c  blue curve   indeed  for
misclassified instances  the probability given to the correct class is often nearly as high as that given
to the assigned class  fig   c  red curve   this implies that with minor improvements we could
further boost our accuracy  since the classifier  even when mistaken  is typically already
determining that the actual class is almost as likely as the predicted class 
finally  we reapplied multinomial logistic regression  this time with l  regularization  to test
whether any of our features were superfluous  overall  this produced a slight dip in accuracy  table
   column     in none of the five cross validation folds was more than a single feature given zero
weight  indicating that the features we used are informative with respect to tf binding 
model and feature evaluation
having verified via l  regularization that our features were informative  we evaluated their
combinatoric performance  as measured through forward selection  because we are performing
multinomial classification  and the ht selex scores are the only tf specific features  we first
included the ht selex scores as the baseline  with the ht selex scores alone  we achieved an
average accuracy of      fig   b   we then tried running the model with each feature in
combination with the ht selex scores and found that adding the expression of the nearest gene
improved the mean cross validation accuracy the most  bringing it to over      subsequently
adding activating histone marks improved the average accuracy slightly to      but further feature
addition after this point resulted in very little gain in prediction accuracy  interestingly  using only
ht selex scores with distance to the nearest gene gave an average accuracy of      this is
exciting because it means that with a single experiment per cell line  dnase seq  we can get
reasonable predictions  therefore  we can apply our method to the multitude of cell lines which may
have dnase data  but lack the other experimental data types we also used as features 
after establishing the minimal set of features required for accurate classification  we
investigated the lower bound on the number of training examples needed  through down sampling 
on average  a tf will have tens of thousands of bound sites per cell type  offering a large pool of
examples on which to train  however  lowly expressed tfs or those with unusual motifs may only
have hundreds of bound sites in a given tissue  we found that we reached saturation after including
only        training examples per tf  far fewer than is typically available  fig   a   to our
pleasant surprise  we observed that  even with only a few hundred examples for each tf  accuracy

fisuffered a drop of only        this demonstrates that  even when a chip seq experiment produces
only a small number of peaks for a particular tf  computational inference is still effective 
extension of classification to under sampled tfs
following our determination that tf binding can still be effectively predicted with orders of
magnitude fewer training examples than present within our data set  we sought to answer whether
we could also decrease the number of cell lines in the training set without substantially diminishing
performance  specifically  we reassessed the performance of the svm after training on a single cell
line  we found that this impacted accuracy  on average  by only a few percent  table     because
there are many tfs that have not had chip seq experiments performed on them in multiple tissues 
this represents a common use case for tf binding prediction  our results indicate that the
predictions generated are valuable even for under sampled tfs 
next  we evaluated the predictions on tfs for which no chip seq data exist  this 
unfortunately  is an extremely frequent circumstance  as a proxy  we removed from our training set
all examples of ctcf  then  for the remaining bound instances  we removed the ht selex scores
for the four tfs that were not bound at that position  at unbound positions  we set this score to   
we next composed a test set solely from ctcf bound and unbound loci  and included ht selex
scores for only ctcf  on this training and test set  we applied standard logistic regression  this
was intended to replicate the scenario where  lacking training data for a particular tf  we instead
use a general set of training examples comprised of other tfs bound loci  if the features that enable
binding prediction are relatively consistent across tfs  this workflow would be expected to be
effective  the rocs for the novel factor classification  figure    had aucs of                  
                           for gm       h  hesc  hepg   hela s   and k     respectively 
interestingly  in all five cases  every instance misclassified by the algorithm is a false positive  the
regression never assigns greater than     probability of being unbound to a bound position 
overall  this suggests that existing data might be sufficient for general tf binding prediction  even
for tfs that have not yet been characterized directly through chip seq 
conclusions and future directions
our goal was to improve on the state of the art in tf binding prediction by leveraging
publicly available data from the encode project and other sources  using multi class svm and
logistic regression on scaled features  we offer a solution that can generate predictions genome wide
simultaneously for all tfs  we incorporated     features  and were able to obtain classification
accuracies of      for   tfs  in   cell lines  across         sites  we further established that
having only one cell line for training does not significantly reduce the power of our inference  and
that binding sites for novel tfs can also be predicted extremely effectively 
in the immediate future  we plan to test the predictive power of other features  including
methylation  which we excluded due to large amounts of missing data  and dnase seq read
distributions  we also aim to expand the number of classifiers applied so we can assess the relative
advantages and disadvantages of each  we attempted to run both the glmnet and randomforest r
packages  but terminated them after they had run for several hours without finishing  because we
have determined that down sampling the number of training examples by two orders of magnitude
still produces comparable results  we will re evaluate these methods on data sets of reduced size 
we are particularly interested to see whether the feature weights produced by lasso via glmnet are
in concordance with the weights given by liblinear or our results from forward selection 
it is our hope that  with minor adjustments to our feature vector and algorithm  we can
achieve near perfect classification of tf binding  we can then apply our method to unexplored
tissue types to offer novel insight into the cells underlying regulatory processes 

fib

c

density

a

probability

figure    svm and logistic regression prediction
accuracies   a  b  heat maps for svm of actual  rows 
and predicted classes  columns   for no scaling and scaling
        respectively   c  multinomial logistic regression
predicted class probability distributions for correct
predictions  black   incorrect  blue   and the correct class
when an incorrect prediction was made  red  

 
 

no
scaling 
gm              
h  hesc         
hela s          
hepg  
       
k    
       

scaling
       
       
       
       
       
       

mean cross validation accuracy

                             

a

logistic
regression 
       
       
       
       
       

logistic  l 
regularization 
       
       
       
       
       

b










 
table
   performance of various classifiers
broken down by cell line  five fold crossvalidation accuracies for  svm with no feature
scaling  svm with features scaled        
multinomial logistic regression with l 
regularization  and multinomial logistic
regression with l  regularization 



















 

htselex
active histone
conservation
repressive histone
expression
distance to gene

 

 

 

number of features added

figure    svm performance with fewer training examples
or features   a  depiction of forward selection process
starting with inclusion of ht selex scores   b  cross
validation accuracies given increasing training set size 
gm     
gm     
h  hesc
hela s 
hepg 
k   

      
      
      
      

h 
hesc
      
      
      
      

helas 
      
      
      
      

hepg 
      
      
      
      

k   
      
      
      
      

figure    predictions for novel tf  roc
curves for prediction of ctcf binding sites
using logistic regression  without training on
ctcf examples  details of procedure in text 
overall
      
      
      
      
      

table    performance of svm
trained on a single cell line 
accuracies for training on one cell
line  rows  and testing on others
 columns  

    encode project consortium et al         nature      jolma  a   et al         cell      siepel a  et al         recomb     
harrow  j  et al         genome research      http   www huber embl de users anders htseq doc  overview html     simon anders
and wolfgang huber        genome biology      fan  r  e  et al         journal of machine learning research 

fi