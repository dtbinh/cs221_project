deep learning lane detection for autonomous vehicle
localization
joel pazhayampallil
kai yuan kuan
december         

 

introduction

autonomous vehicles for consumer use on public roadways are an active area of research and
development by various academic and industry groups  one approach to this problem  taken by
google for example  involves creating a   d high resolution map of the desired route  so the vehicle
has full awareness of all static features of the route  when autonomously driving this route  the
vehicle employs a high precision lidar sensor to generate a   d point cloud of its surroundings 
which is then used to localize the vehicle on the high resolution map and detect dynamic objects 
such as other cars and pedestrians  this approach has proven to be very successful  but it relies on
mapping all desired routes before hand  it requires an expensive lidar sensor  and performance
suffers when the mapped environment changes  due to construction or snow for example 
an alternative approach would be to gather all necessary inputs to complete the autonomous
driving task on the fly  however  this requires more sensing capability and sensors that are robust to
changes in the environment  an approach taken by many auto manufacturers is to limit autonomous
driving to highway only  as this provides a structured environment that reduces the sensing requirement  additionally  vision sensors are preferred over lidar due to cost and maintenance  current 
vision systems for vehicles provide lane estimates but performance can degrade due to poor quality
lane marks  difficult lighting conditions  and poor road conditions 
in this project we use a deep learning based lane detection algorithm to identify lanes from a
vehicle mounted vision sensor  this lane information is then used to localize the vehicle onto a lane
level map with a particle filter 

 

setup and data

the test vehicle is equipped with forward facing cameras  high precision gps  and an inertial
measurement unit  imu   the data collection system records a camera frame  gps position  and
vehicle motion data at    hz  data was collected on several drives on highways in the san francisco
bay area  these data sets were restricted to single lane highway driving  as the main objective
is lane detection during typical highway driving  to generate the training data  a lane detection
algorithm using conventional computer vision techniques is used to label the lanes in the camera
images  this method of lane detection works well under ideal lighting conditions and at close range 
but performance degrades quickly otherwise  these lane labels are then correlated with the gps
information to generate a  d map of the lane  the total dataset represents approximately     km
of highway driving 

 

fi a  sample image from data collection with detected
lane overlay 

 b  sample map overlay of data collection drive 

figure    data collection

 
   

localization
hidden markov model and particle filter for state estimation

vehicle localization can be modelled as a hidden markov model in that the vehicle state is never
directly observed  gps measurements provide an estimate of the state but contain both systematic
and random errors  additionally  lane measurements only provide the lane position from the current
state  rather than the state itself 
a particle filter attempts to produce the maximum likelihood estimate of a systems state by
approximating the posterior probability as a finite set of random state samples drawn from this
posterior distribution  the basic algorithm maintains a set of particles  xt    x i        x n     where
each x i  is a state estimate  at each time step  xt  p  xt  ut   xt     a new set of particles is
sampled from the previous set of particles given the input ut to the system and a probability
distribution describing the state transition probability  then  for each particle an importance factor
 i 
 i 
wt   p  zt  xt   is calculated that represents the likelihood of the current sensor readings zt given
 i 
the state estimate provided by particle xt   finally  xt is generated by sampling from xt with
 i 
the probability of sampling each particle given by the importance factors wi   the resulting set of
particles represents the state posterior distribution given the inputs  sensor readings  and previous
state    

   

implementation

the map is generated from the lane positions transformed from gps polar coordinates to a locally
accurate cartesian plane  the state vector is defined as  x    x  y   t   where the elements are the
 d cartesian position and yaw angle of the vehicle with respect to the map  the particle filter is
initialized with     particles from a gaussian distribution with mean given by the gps position
and heading angle with variance of  m in position and   degrees in heading  at each time step  the
particles are propagated according to the vehicles longitudinal and lateral velocity and yaw rate given
by the imu with added gaussian noise  for the sensor measurement step  both gps measurements
and lane detection measurements are available  for the gps measurement update  the particles are
scored by a gaussian probability distribution with mean given by the gps measurement  for the
lane detection update  the lane position given by the map with respect to the state of each particle is

 

fi a  map reprojection with lane measurements 

 b  map reprojection with gps measurements only 

figure    reprojection of the lanes in the map given the particle filter state estimate  green points
show lane detector output  blue points show map lane reprojection  and yellow points show ground
truth lane labels 
projected onto the camera image  then the the difference between the detected lane pixel locations
and the pixel locations of the lane given by the map is used to score each particle  the particles are
then resampled after each gps update and lane detection update  the state estimate is given by
the mean value of all the particles 

 

lane detection

the deep learning lane detection system acts as a primary input to the localization algorithm 
the detector is implemented as a   layer convolutional neural network with rectified linear units as
the non linear activation function  this is followed by a final set of softmax classifiers which predict
the pixel locations of the lanes at   fixed distances ahead of the vehicle  the pixel locations are
discretized into    classes for both horizontal and vertical dimensions  the entire network is trained
through back propagation using the training lane labels described above  the lane detector was
developed by the autonomous driving group in the stanford ai lab and is outside the scope of this
project 

 

results

the quality of the localization algorithm is quantified by a squared pixel location error metric
between the ground truth lane labels in the test set and the projected map lane labels given the
state estimate of the localization algorithm  first  the baseline error is established with the pixel
error with only gps measurements  this gives the simple case where the vehicle state is assumed to
be given directly by gps measurements  while gps gives a good estimate of the vehicles general
location  it is insufficient for localization due to biases in the gps measurements between the same
location at different times  as seen in figure    these gps errors can change over the course of a
drive as well as between drives over the same location  measurements can be improved to an extent
with differential gps but are still subject to precision loss through satellite occlusion  which is a
common occurrence in urban highway environments 
as seen in figure    with the lane detector providing additional measurements  the pixel error
drops by over    times compared to gps measurements alone  the lane measurements help correct

 

fi   

   

 

   

   

 

squared pixel error

squared pixel error

 

   

 

   

 

   
   

 

 

  

   

   

   
   
   
sample frame

   

   

   

 

   

 

  

   

   

   
   
   
sample frame

   

   

   

   

 a  initial small pixel error increases as gps measure  b  consistently high pixel error due to gps measurements drift 
ment bias 

figure    pixel error with only gps measurements 

   

   
only gps
lane detection

only gps
lane detection

   
squared pixel error

squared pixel error

   

   

   

   

   

   

 

  

   

   

   
   
   
sample frame

   

   

   

   

 a  performance comparison to figure  a

   

 

  

   

   

   
   
   
sample frame

   

   

   

 b  performance comparison to figure  b

figure    pixel error with lane detector measurements on log scale 

 

   

fithe gps errors with respect to the vehicles relative lateral position and yaw angle to the lane 
however  lane geometry is typically constant during the majority of the drive  for example  roads
are typically built in constant straight sections or constant curved sections  therefore  given a
measurement of the lane in front of the vehicle  there is ambiguity in the vehicles longitudinal
position along the lane  in this dimension  the lane measurements do not provide any localization
benefit over gps measurements  except for in cases where the lane is transitioning from a straight
section to a curved section or vice versa  however  in the context of highway driving  the effect
of longitudinal error relative to the lane is small because highways are built in constant curvature
sections  therefore the observed lateral lane position error will be small compared to the longitudinal
error  this issue can be addressed by using a map containing individual lane markings and roadside
objects  essentially a more feature rich map  and a feature detector than can report the positions of
these individual features 

 

further work

in further work  the lane detection accuracy could be improved by finer discretization of pixel
locations and the system will need to be trained on a much wider variety of highways and road
conditions  additionally  improving the accuracy of the ground truth lane labels in the map will
aid localization as well as with training the lane detector  but will require improved sensing such as
a lidar  to generate the map  further on  the lane detection  localization  and a control system
will be integrated into a real time system based on the ros platform to implement hands free
autonomous highway driving 

 

acknowledgements

this work was greatly supported by sameep tandon  who provided the vehicle data  data collection
and visualization software  and guidance for this project  additional support from tao wang 
who developed the deep learning lane detector and assisted with the integration of the localization
algorithms  finally  all the above work was supported by the deep learning group led by prof 
andrew ng at the stanford ai lab 

references
    s  thrun  w  burgard  and d  fox  probabilistic robotics  intelligent robotics and autonomous
agents series  mit press       

 

fi