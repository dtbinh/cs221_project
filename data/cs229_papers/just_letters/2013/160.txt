building fast performance models for loop free    bit x  
code sequences
final project report
cs     machine learning  autumn     
stanford university
negar rahmati

jessica su

judson wilson

stanford university

stanford university

stanford university

rahmati nr gmail com

jtysu stanford edu

judsonw stanford edu

   introduction
ever since the advent of the compiler  computer scientists have
striven to improve the efficiency of their resulting programs  superoptimization is an active research area in this field  where researchers seek methods of finding optimal instruction sequences
to achieve arbitrary tasks  researchers schkufza and aiken have
proposed a method called stoke  or stochastic superoptimization  that uses a markov chain monte carlo method as the basis
of the optimization algorithm      the method requires predicting
runtimes of many alternative instruction sequences to search for
possible improvements 

at random     of the dataset to use as training data  and     for
testing 
as a starting point  we chose a large subset of the available instructions  with the notable exception of operations that branch  our
dataset contains     different instructions  we also chose to limit
the operands to registers and literal values only  to prevent behavior related to external memory access  the dataset was designed to
narrow the problem down to an investigation of the interaction of
instructions proceeding linearly through the program  it is free of
external factors with large influence on the runtime 

determining the relative efficiency of various code sequences is a
nontrivial task  modern x   processors have very complex architectures with hundreds of instructions  to boost performance  processors incorporate many hardware optimizations such as pipelining  adding alus  register renaming and out of order execution
     the machinery is quite complicated  and while the operation of
the machine is deterministic  to an observer the operation exhibits
unpredictable  but repeatable  performance depending on the sequencing of the instructions and the beginning state  to accurately
predict execution time would require analysis of proprietary engineering information  or prohibitively complex brute force testing
and modeling 

the runtimes were calculated by placing the sequences in a program that looped over the sequence     times and compared the
timestamp at the start and end  the programs were run in a linux
environment  and the timestamps were calculated relative to the execution time of the process  excluding time spent in other threads 
the measurements include the runtime of the looping instructions 
as well as a series of nop instructions that were used to help reduce
any interaction between the loop instructions and the instructions
under test  we model the effect of these loop and nop instructions
as a constant offset across all test results  we measured this value
by testing zero length instruction sequences  and subtracted it from
the runtimes 

in this paper we use machine learning techniques to create assembly instruction runtime prediction models  we experiment with different features and algorithms  including linear regression  support
vector regression  and gradient descent  the goal is to produce
a more accurate model for stoke that maintains high prediction
speed  the purpose of the model is to gauge relative performance
between code sequences  such that a set of possible alternative code
sequences can be generated  estimation methods that produce results with higher accuracy at the expensive of speed can be used to
refine the resulting set  a topic beyond the scope of this paper 

in order to extract the dependencies between instructions  a topic
discussed later  we used the x  asm library  x  asm is a c     library by eric schkufza for working with x      assembly that provides a parser  an in memory assembler  and primitives for building
data flow analysis  the library includes tools for extracting the read
and write register dependencies for instructions and their operands 
we wrote a program to generate a derived feature set from the set
of instruction sequences 

   methods
    data collection
the main data set we used was provided by eric schkufza  our
collaborator at stanford university  he generated instruction sequences for an intel nahalem family processor  measured runtimes
on a processor in this family  the data consists of randomly generated instruction sequences of length   to     it contains       
sequences of each length  together with their runtimes  we chose

   

models and learning algorithms

all the models we used are linear predictions  where various features contribute to the predicted runtime linearly  the measured
runtime of a code sequence  or program  is represented by y  and
our prediction is represented by yb  the prediction is the linear combination of features x and their associated runtime contributions  
yb   xt 

for all models we used least squares regression to find the values
of parameter  that minimized the sum of squares of error for the

fitraining data set 

   

specific methods of solving the regression problem are discussed
with each model 

a logical method of improving the static model is to add some dependence between neighboring instructions  for example  perhaps
if instruction i follows j the processor can use some optimization to reduce the execution time  such as performing two multiplications in parallel  there are many ways to accomplish this goal 
but perhaps the simplest is to count the occurrences of ordered pairs
of instructions in the sequence 

opt   arg min   y  x    


in addition to least squares regression  we also attempted to use
support vector regression  using the libsvm software package     
the hope was that it would provide the ability to use non linear
functions of our features  however  we found the software to be
much too slow to be useful for our dataset 

pairwise neighbors feature model

 p i    

x i 
m n  

x

 i 

 i 

  pk   m  pk     n  

k  

    model notation

let the feature vector x contain all the static terms from before  and
 i 
all  i   features xm n  

the aim of this project is to model the runtime of arbitrary sequences of machine instructions  or programs  let program p be
an ordered set of program lines  p    p    p            pk    where each
line of the program p specifies an instruction from the instruction
set i                       and associated operands  denote the
length of a program p by  p  

this model proved to be too memory intensive for matlabs matrix left divide operator  although sparse  the model introduced
          new features  an iterative approach was needed  note
the normal equations can be formed into a standard solution of linear equations problem 
 x t x    x t y

let x i  be the feature vector derived from the ith program p i   
our target variable y  i  is the measured runtime of     iterations of
p i    because the program runtime may change with cpu register
data and other conditions  and because the test measurement system
is not perfect  p i    p j  does not necessarily imply y  i    y  j   

    static feature model
we started with the natural approach  replicating the model used by
schkufza and sharma  this static feature model assumes the runtime of a line pj is a static property of the corresponding instruction
  independent of the operands  the processor state  or other program lines pk   k    j  therefore  the runtime of a program p will
be the sum of the runtimes of the instructions  assigned to each
 i 
line pj   we define feature xj as the number of times instruction
 i 
j appears in program p  

ax   y

 

a    x t x 
x   
y   x t y

this can be solved using various algorithms  we chose the biconjugate gradient stabilized method  bi cgstab      special care
must be taken to ensure sparsity is preserved  x t x is not necessarily a sparse matrix  it is likely a         by         dense
matrix   so x t xz should be computed by multiplying the sparse
matrix x t with the vector xz 
in general  this method proved to be more practical than matrix
left division  so it was used for all further models       iterations
of bi cstab were used unless the software detected that further
progress was inhibited by numerical precision 

 p i   
 i 
xj

 

x

 i 

  pk   j  

k  

this model would accurately describe a simple computer that lacked
hardware optimization  where resource access times are constant 
and the instruction set is very simple 
the original example runtimes y  i  include a very large amount of
overhead for looping that are not a property of the program under
test  p i    we model this time as a constant offset to the runtime  because it is a consistent sequence of instructions meant specifically
to not interact with the program p  we measured this time directly
with a zero length program  and found the results to be consistent
across many tests  we found that calculating the value using an
intercept term in our model did not meaningfully change the test
error  therefore we subtract the empirical offset from the runtimes
y  i  for this and all subsequent models to reduce computation complexity 
the runtimes j for each instruction were learned using least squares
regression  we solved the least squares error minimization problem
arg min   y  x     using the matlab matrix left division operator  which is only possible for our dataset by taking advantage
of the sparsity of x  in our dataset  only    of the     features can
be nonzero 

   

two stage regression by variance class

the pairwise neighbors feature model introduced         new
features to the model  and as a result suffered from overfitting  as
will be discussed in the results and discussion section   upon inspecting the behavior of various examples from our dataset  it was
determined that the presence of some instructions lead to larger observation variance than others  and thus increase the susceptibility
to overfitting 
by inspecting various programs of length    it was observed that
some instructions tend to have a predictable runtime with variance much smaller than the mean  similar to a narrow gaussian
or poisson distribution  other instructions tend to exhibit strange
runtime distributions  many appeared bimodal or exponential in
nature  literature suggests that some of the bimodal time instructions may be explained by error conditions that trigger on bad input
data  other distributions may be due to instructions that perform
calculations with iterative algorithms  such as instructions that calculate a square root  as such  we will classify the instructions as
 low variance  and  high variance  for this model 
ideally we would normalize the data in such a way to produce a
blue estimator  but that would require detailed variance measurements  modeling the variance of every instruction is in general

fia difficult problem  and modeling the variance of each instruction
when combined with other instructions may not be possible 
number of instruction types

   

in the interest of simplicity  the parameters and examples were partitioned by their variance class and regression was used to solve
for the parameters of the two classes in two stages  consider replacing our original error minimization problem with the following
equivalent formulation  permuting the columns of x and rows of
 according to some classification lv  low variance  and hv  high
variance   and then splitting their product 
x    xlv  xhv    

    lv   hv  

   

   

   

   

   

  

arg min   y  xlv lv   xhv hv     
lv  hv

 

then permute the rows of x and y identically to produce the following form 




xlv 
 
y 
  x 
y 
y 
xlv  xhv 
this formulation suggests a method for decoupling the low variance
and high variance instructions  such that the high variance terms do
not dominate the low variance terms 
lv   arg min   y   xlv    


hv
  arg min   y   xlv  lv  xhv    


 
this is a two stage optimization problem  first solving lv   then hv
the first stage estimates only the low variance feature parameters 
by exploiting training examples that do not involve high variance
features  the second state solves for the high variance feature parameters by minimizing the error of the remaining examples  whose
variance is likely dominated by these terms 

 

   

 

   

 

   

 standard deviation of y     mean of y 

figure    relative variance histogram

   

dependency graph based features

the designs of modern x      processors contain elaborate hardware to locally parallelize instruction sequences  using techniques
such as register renaming  where general registers are used to create
an instance of a register used in a program   multiple independent
subsequences of code may be computed at the same time  this
technology is called out of order execution      clearly such behavior is non linear with respect to the feature sets defined thus far 
listing   a toy program
  
  
  
  
  

movl
rclw
movl
movl
movl

 eax   ebx
  x    ax
 ebx   ecx
 ecx   edx
  x     ecx

finally  to implement the model requires a method of classifying
features as low variance or high variance  to do this  a relative
measure of variance was developed for the underlying instructions 
for the set of single line programs p     p i     p i           sets
of runtime samples for each instruction j were collected 
 i 

yj    y  i    p    j   p i   p   
then the relative variance of an instruction j was defined as the
ratio of the standard deviation of yj to the mean of yj   a histogram
of the relative variances of all instructions appearing in p  shows
a bimodal distribution with a large gap  see figure    a threshold
of     was chosen from this gap to serve as a classifier  where an
instruction is considered high or low variance if its relative variance
is above or below this threshold  respectively 
extending the definition from instructions to the static features is
straightforward  a feature xj is low variance if j is low variance 
and high variance if j is high variance  the classification of the
pairwise neighbor features is slightly more complex  xi j is highvariance if i or j is classified as a high variance instruction 
otherwise it is low variance   relaxing this definition to dependence on strictly i or strictly j may be an interesting area for
further investigation   note that this definition rules out a large
number of rows for inclusion in xlv   because the probability of
an n instruction program not having any high variance instructions
decays with n   where  is the bernoulli probability of an instruction being low variance  as a result  the testing and training set
xlv tend to have a sampling bias towards shorter programs  and
xhv towards longer programs  custom datasets could be generated
to account for this 

figure    dependency graph
we experimented with a few new feature sets with the hope of capturing some of this behavior in a linear model  to do this  we
created a new model of the processor such that it parallelizes and
schedules all instructions to execute as quickly as the required register state is valid  including those registers named in the operands 
and those not named in the operands  such as flag registers   for
example  in the toy program listed in listing    instruction   must

fimodel   features
baseline  y     
static instruction features
static   pairwise inst  features
  stage static   pairwise
static   unweighted height
static   weighted height
static   longest path static inst 

table    training and testing errors for models tested 
training error
test error
test error
number
all programs
all programs
single line
of
programs
feat 
rms
rel
rms
rel
rms
rel
           
           
           
 
             
                                  
                                                    
                
                                  
 
            
                                  
             
                                  
 
             
                                  

be executed after instruction    since both instructions use register
 ebx  so instruction   depends on instruction    however  instructions   and   do not affect any of the same registers  so they can be
executed simultaneously 
to represent these dependencies  we used an idea proposed by eric
schkufza  we draw a dependency graph  figure     where  i  j  is
an edge in the graph if instruction j depends on instruction i  we
conjectured that the following features might affect the runtime of
the program  starting with the simplest 

     

unweighted dependency graph height

we define a feature equal to the height of the unweighted dependency graph  plus     i e  the number of instructions on the longest
path  in figure    this feature would be    corresponding to the
longest path             this number is a single additional feature used along with the static features described previously  this is perhaps an overly simple model  but we believe the
feature is informative and thus may lead to better predictions 

     

weighted dependency graph height

we define a feature equal to the sum of the runtimes of the instructions on the longest running path  i e   the path with the greatest
total runtime  in figure    this feature would be      ns  and the
longest path would be       we describe this as a weighted path 
where each instruction node is weighted by the static runtime of
the instruction  we estimated these instruction runtimes using our
results from the static feature model  this method assumes that
execution times of the instructions themselves do not change based
on ordering of the instructions  we view this as an enhancement
to the simple unweighted height feature just described  for a processor that acts as our model predicts  we would expect that this
feature would contribute greatly to the runtime  and would predict
perfectly if the runtime for each instruction were known perfectly
when creating the feature 

     

longest dep  graph path static inst  features

we define one feature per instruction in i  equal to the number
of times each instruction appears on the longest running path  in
figure    the movl feature would have value    the rclw feature
would have value    and all other such features would have value   
this model extends the previous model by not assuming we know
the runtime for each instruction  except for the purpose of identifying the longest path during feature calculation   i e  it is possible
that a wrong estimate will choose feature values corresponding to
the wrong path   for a processor that follows the model  assuming
we have properly determined the longest path  this model should

test error
low variance
only
rms
rel
         
 
              
              
              
              
              
              

learn the runtimes for each instruction  the static features described earlier were also included  for consistency  in the ideal case
the static feature parameter would be zero  and these new longestpath static feature parameters would be the average runtimes for
each instruction  this model is the natural extension of the static
feature model to the case of perfect out of order execution 

  

results and discussion

for each model  we measure the prediction error on the training
and test sets  for further insight  we also calculated the prediction
error on two subsets of the testing data  the examples that contain
programs of length    and the examples whose programs contain
only the low variance instructions  as described in section       we
define the error in two ways  the first is the rms error 
v
u
m
u  x
erms   t
 y  i   yb i   
m i  

where m is the number of data points  the least squares objective
of linear regression  as used for all of our models  equivalently minimizes this error  we also used a form of the average relative error 
for ease of reading 
fi
m fi
  x fifi y  i   yb i  fifi
erel  
fi
m i   fi
y  i 
the results for the various models described above are listed in
table    we have also included an absolute error of a prediction of
yb     to serve as a baseline to compare to the rms error of each
model 

   

static feature model analysis

in terms of rms error  the static instruction features proved to be
a better predictor of runtime than the baseline  as one would expect 
least squares regression directly reduces this cost  thus the model
has made a small improvement  further  the training and testing
error for the  all programs  subsets are nearly equal  suggesting
that overfitting is not a problem  the relative errors are all either
multiples larger than    or nearly    suggesting that the least squares
objective may be weighting outliers too high for some purposes 

   

pairwise neighbors model analysis

the addition of the pairwise neighbors features reduced the training error  however  the rms and relative test error increased for
all test sets  clearly the addition of this large number of features
is causing overfitting  somewhat amazingly  the relative training
error was reduced by two orders of magnitude  this suggests that
there are relatively small number of statistical outliers that are severely

fiaffecting the rms error  due to the squaring effect  that said  overfitting is a real issue  so this result is only mildly useful  these
observations led to the development of the two stage regression
algorithm  introduced in section     

if using the same example data  the next steps are to explore the
possibilities of removing examples with instructions that are problematic  similar to what was done in two stage regression  but focusing the analysis on these well behaved instructions 

    two stage regression analysis

if more data can be generated  one could attempt to derive more
information related to the mean and variance for each instruction
in isolation  and more closely examine the behavior of relatively
short programs with only low variance instructions  this may yield
clues about the performance of the models 

two stage regression produced slightly increased training error
over standard regression results for the static and pairwise model 
but this was also expected because the standard least squares regression solution is the minimizer  by definition  so if there is any
improvement  it would be in the test error 
the method produced similar results to the static instruction features model for all three types of rms test error  the relative error
was significantly different  notably lower for the low variance and
single line program subsets  this is likely due to the first optimization step which minimizes prediction mean square error on
the low variance training set 

    dependency graph related results
all three models using the dependency graph related features produced results nearly identical to the static instruction features model 
with slightly increased test error for the longest dependency graph
path static instruction features model  this model doubles the
number of features over the static instruction features  and thus
the result appears to suffer from overfitting 

to reduce the noisy nature of the dataset  a different approach could
be used to generate examples  high level tools exist to give heuristic prediction data for program runtimes  such as the intel architecture code analyzer tool  these tools are too slow to use in the
stochastic optimization setting  but could be used for model generation  instead of running the instructions many times in a loop
to measure runtime  one could generated example runtimes using
one of these tools  the resulting examples could potentially yield
better results when learning the parameters of the models discussed
in this paper  assuming the tools yield data that is more consistent
for constant input 

  

acknowledgments

we would like to thank eric schkufza for the project idea  for
generating the dataset and providing useful tools and information 
and for providing the basic underlying idea behind our dependency
graph models 

   conclusions and future work
generalizing the results  none of the models made a worthwhile
improvement over the static instruction features model  the twostage regression method applied to the static and pairwise neighbors
feature model may have yielded some improvement  but at the cost
of adding several orders of magnitude more features  it remains
to be seen if the result is real  and if the added complexity will
make the improvement useful for the intended purpose   producing
a model that can rapidly estimate runtime 
it is likely that applying the two stage regression technique to the
other feature sets may yield similar improvements in terms of some
of the test sets  the initial optimization step tends to more tightly
fit the low variance instructions  and should reduce testing error on
subsets with fewer high variance featured programs  performance
on the full test set will likely change little  as the high variance
instructions  which likely dominate error  should be little affected 
this theory suggests that  in general  more information about the
variance of the data is needed to make improvements  the variance
likely has links to the individual instructions  as well as to their interactions  and the initial data in the registers when the execution
time test is run during dataset generation  with adequate knowledge a blue estimator could be deduced  on the other hand  perhaps the high variance instructions could simply be removed  to
reduce skew caused by outliers  in fact  the two stage regression
techniques could be extended to multiple stages  and a new dataset
could be generated to provide the desired number of examples for
each stage 
it is somewhat interesting that the dependency tree based models
did not yield improvement  the authors believe the models should
yield better results  it is unclear whether the models are flawed  or
if there are problems in the test data  the feature generation  or the
regression solver 

  

references

    c  c  chang and c  j  lin  libsvm  a library for support
vector machine 
    r  s  e  schkufza and a  aiken  stochastic superoptimization 
    d  c  eric sprangle  increasing processor performance by
implementing deeper pipelines  computer architecture  pages
     
    h  a  van der vorst  bi cgstab  a fast and smoothly
converging variant of bi cg for the solution of nonsymmetric
linear systems 

fi