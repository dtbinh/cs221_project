d ecember         
preprint typeset using latex style emulateapj v          

accurate redshift estimation from photometric colors
c hristopher davis    d evon p owell    t ony l i 
  kavli

institute for particle astrophysics and cosmology  physics department  stanford university  stanford  ca        usa
slac national accelerator laboratory  menlo park  ca        usa 
cpd stanford edu  dmpowel  stanford edu  tonyyli stanford edu

 dated  december          

   introduction

accurate distance measurements are vital to observational
cosmology  when we detect an object like a galaxy  a common proxy quantity for its line of sight distance  as well as
look back time  from us is its cosmological redshift  the
shifting to redder wavelengths of the electromagnetic spectra
of very distant objects  often galaxies  due to the expansion of
the universe as light travels toward us    theoretical cosmological models make specific predictions about the large scale
structure and statistical properties of galaxies as the universe
evolves  so precisely testing these models requires measuring
the redshifts of a large population of galaxies 
to clarify the language used in this paper  redshift values
are conventionally labeled z  and the higher an objects redshift is  the farther away it is from us  or alternatively  the further back in time we see it   an object observed at redshift
zero  z      is seen in the nearby universe  or very close to
the present day  while an object at z    is seen in a universe
that is approximately half its current age 
the most straightforward type of redshift estimate is spectroscopic redshift  one observes the objects detailed spectrum
and measures the wavelength offset of recognized emission or
absorption lines  unfortunately  this is prohibitively expensive and time consuming for large galaxy surveys  which will
catalog billions of galaxies  these surveys instead perform
photometry  which measures the objects total brightness in
several broad bands of the electromagnetic spectrum  necessarily losing detailed spectral information  see figure   for
an illustration   however  by comparing photometric measurments to known spectra  one can determine a probability
distribution for the redshift of individual objects  redshifts
thus estimated from broad band color information alone are
termed photometric redshifts  commonly referred to by the
shorthand photo z  machine learning  ml  methods are indispensable in obtaining such estimates with sufficiently low
variance and bias 
an important note on units  brightnesses in astronomy are
quoted in a reverse logarithmic measure called magnitudes 
higher magnitudes m in a given photometric filter correspond
to logarithmically dimmer brightnesses  specifically  for two
objects a and b with observed fluxes fa and fb
ma  mb       log    fa  fb  

   

so if a has a higher magnitude than b by    object a is in fact
  redshift is a more directly observable quantity than distance or lookback time  because the exact conversion from redshift  which we observe 
to distance  which we infer  depends on the cosmological model of the
universethe current rate of cosmological expansion  the universal proportions of dark matter and dark energy  etc  these parameters are estimated and
well constrained  but not known exactly 
  more precisely  if an object emits light at wavelength  which is then
i
observed at a longer wavelength  f   its redshift z is defined by  f   i      z  

f ig      illustration of the redshift of a galaxy spectrum  each panel shows
the simulated spectrum  black  of a galaxy observed at increasingly higher
redshifts  z                 also shown are the windows for five broadband
photometric filters  which integrate out the detailed features present in the
true spectrum  the goal of photometric redshift is to recover the redshift of a
complicated galaxy spectrum from only the broadband data  i e  one number
per filter   from padmanabhan et al         

dimmer by a factor of         while archaic  magnitudes are
standard within the field and will be used in this study 
   data set

we use a mock galaxy catalog            objects  generated from the aardvark simulation  one of several cosmological simulations run in preparation for the dark energy survey
by the slac national accelerator laboratory  this catalog
includes simulated galaxies expected to be probed by the full
depth of the dark energy survey   r band magnitude of    
and covers roughly a quarter of the sky         square degrees  
for each galaxy  magnitudes are provided in   broad wavelength bands  g  green       nm   r  red       nm   i  z 
and y  infrared              and       nm respectively 
bands  together  these magnitudes comprise a   dimensional
feature space  but because various systematic errors in photometric quantities can be ameliorated by considering the difference between magnitude bands  called color   we actually
 

http   www darkenergysurvey org 

fi 

davis  powell  li
     spectral connectivity analysis
this method uses a diffusion map to transform the training data from the raw color space into a space which encodes more relevant information through the diffusion distance  hence  connectivity analysis    this is done by finding m principal eigenvectors of the p  p gaussian kernel
matrix  for p training samples  and forming transformed coordinates in rm   because the method relies on the eigendecomposition of a large matrix  it is necessary to estimate
the eigenvectors using the nystrm method  cf  press et al 
       freeman et al         show that this method  combined
with a weighted linear regression model  compares favorably
to other ml techniques for photo z estimation 

f ig      the distribution of objects on the sky  in mollweide projection 
each aardvark data file corresponds to one    square degree pixel on the sky 

use a   dimensional feature space comprising of the differences between wavelength bands   g  r  r  i  i  z  z y    r   
from these  we ultimately wish to estimate a single value for
each galaxy  the photometric redshift zphoto  
we use a small subset of galaxies selected to simulate a
spectroscopic mini survey of the des footprint    after applying reasonable magnitude and error cuts  we are left with
         galaxies      are used to train and develop the various models  while the remaining fraction are saved to test the
estimations 
   methods

we apply the following machine learning algorithms to our
data set with the end goal of performing a comparison between them  further information on these techniques and others are reviewed in zheng   zhang         although various
authors have applied these techniques to different data sets 
we feel it is useful to have an apples to apples look at the
relative performance of these methods on the aardvark catalog 

     k nearest neighbors
the k nearest neighbors technique is an interpolation
scheme between training data  the estimated redshift of a test
data point is formed as a weighted sum of known redshifts
from the k nearest training examples  here   nearest  is intentionally left ambiguous  as it is possible to define different
distance measures based on different  possibly nonlinear  coordinate transformations of the data space to find an optimal
interpolation 
     support vector regression

the application of support vector machines  svms   a classification algorithm  to the linear space of photometric redshift estimates requires generalization to regression problems
 see smola   schlkopf       and is termed  support vector
regression   svr   analogous to the concept of support vectors in classification problems  the model produced by svr
only depends on a subset of the training data  because the cost
function for building the model ignores any training data that
is close to the model prediction  this method was first applied to redshift estimation by wadadekar         who noted
that svr is only useful when large training samples are available  which unfortunately is often not the case 

     sed template fitting  non ml technique 

we first digress to comment on an extremely common nonml technique for estimating photometric redshift  spectral
energy distribution  sed  templates estimate photometric
redshifts by fitting some known model for an object type  i e 
quasar vs  elliptical galaxy vs  spiral galaxy  to the broadband spectral magnitudes of an observed object  while sed
templates are not strictly a machine learning technique  they
merit a mention here because they can be used to divide data
into subsets based on object type  giving bayesian priors for
ml techniques  due to scope and time constraints  we will
not use them in this project 
     polynomial regression

polynomial regression is a very basic technique which fits
polynomial coefficients in rc  the color space of c spectral
magnitudes   polynomial regression models of varying complexity  polynomial order  weighting scheme  have been applied since connolly et al         with limited success 
 

it is very important  however  to point out that any such spectroscopic
survey will use a different instrument  possibly at a different site  the biggest
consequence is that the population of galaxies from which the spectra are
measured may in reality be significantly different from the photometric population   this remains an issue even if one chooses for which galaxies to
measure spectra   we bypass this issue here 

     artificial neural networks
loosely categorized  various artificial neural network algorithms have also been successfully applied to estimating photometric redshifts  as with svr  a number of studies  collister   lahav       firth et al        abdalla et al       
have noted that neural networks performed most competitively with other standard methods  such as sed template
fitting  when a large representative training set was available 
generally at mid range redshifts  where a given section of the
sky contains such a sample but is not too dim to be detected 
zhang et al         and vanzella et al         both included
other object features  such as galaxy morphology  type classification  and size into their algorithms to yield increasingly
accurate and computationally efficient estimates  although
naturally incorporated into their algorithms  the inclusion of
additional such discriminating features will probably be beyond the scope of this project 
     random forest decision tree regression  rfr 

each decision tree recursively partitions the training space
such that samples with similar labels are grouped together  a
each tree in the random forest is built from a bootstrapped
sample of the training set  each partition is chosen to be the
best partition of a random subset of the features in training

fi   

   

   

   

   

   

   

   

   

   

   
   

photometric redshift

   

photometric redshift

   

   
   

   

   

   

   

   
   
   
   
   
   
   
   
   
      

   
   
   
   
   
   
   
   
   
      

   
   
   
   
   
   
   
   
   
      

   

           
true redshift

   

   

   

residual

   

residual

   

   

   

   

           
true redshift

   

   

   

   

   

   

   

   

   

   

   

   

   

   

photometric redshift

   

photometric redshift

   

   

   
   

   

   

   

   
   
   
   
   
   
   
   
   
      

   
   
   
   
   
   
   
   
   
      

   
   
   
   
   
   
   
   
   
      

   

   

   

residual

   

           
true redshift

   

   

           
true redshift

   

   

   

   

           
true redshift

   

   

   

   

   

           
true redshift

   

   

   

   

   

   

   

   

   

   

 

   

   

residual

residual

photometric redshift

residual

photometric redshift

accurate redshift estimation from photometric colors

f ig      estimated photometric redshift vs  true redshift  as obtained from the   methods presented in this study  perfectly estimated redshifts would
correspond to all points lying along a diagonal one to one line  note the kink in the data around z       which has a physical interpretation  see   for further
discussion  top  left to right   annz  pr  and svr  bottom  left to right   sca  rfr  and knn 

space  the estimated redshift is then the average of the decision trees  similar methods have been implemented on real
survey data using boosted decision trees  gerdes et al        
   results

figure   displays our main results for each of the   methods
we tested  for each method  we have plotted the photometric
redshift estimate against the true redshift  as well as the residual  photometric redshift  true redshift  
polynomial regression and support vector regression are
the most nave models we applied  yet they show quite good
agreement between true and predicted redshifts 

the change of basis introduced in the spectral connectivity
analysis appears not to have improved the errors on predicted
redshift compared to vanilla knn  this suggests that the photometric data lack sufficient latent connectivity to make a diffusion map useful for determining photometric redshifts 
k nearest neighbors was nominally the best performing
method we applied  however  this may have been due to
the abundance of training data        training testing   giving a very well filled parameter space with which to predict
the redshift of test data
the artificial neural network was the worst performer  we
tried several different neural net architectures  but failed to

fi 

davis  powell  li
   discussion  extensions  and conclusions

   

test
train
knn
rfr
annz
svr
sca
poly

   

n z 

   
   
   
   
      

   

   

   

   
z

   

   

   

   

f ig      pdfs of photometrically estimated redshifts vs  the true distribution  note the bias around z       due to the       break 
z

method
artificial neural network  ann 
polynomial regression  pr 
d  
support vector regression  svr 
spectral connectivity analysis  sca 
        m    
random forest decision tree regression  rfr 
k nearest neighbors  knn 
k     

      
      
      
      
      
      

table  
m ethods used and rms errors  

generate results competitive with our other methods  however  this method may still be viable given time to explore
more complex architectures that can more robustly reproduce
the regression model needed for redshift estimation 
at its heart  random forest decision tree regression is
similar to knn  since it behaves like a kd tree in color space  
so it is unsurprising that it performs comparably to knn 

there is a very apparent kink in our results around redshifts of z       which has a physical explanation  here 
photometric redshift predictions are relatively poor because
a prominent spectral feature  the so called       break
          m   quite literally falls through the cracks between the adjacent g and r filters  resulting in a degeneracy in
color redshift data  while other such degeneracies are present
at higher redshifts  when the      feature falls between
other filters  the design of the instrument is such that the gap
between g and r filters is largest 
because the growth of structure  manifested in the number
distribution of galaxies as a function of redshift  is strongly
affected by the underlying cosmology of our universe  it is
useful to check the photometric redshift distribution against
the spectral redshift distribution  we do so in    noting that
the       break causes a significant bias at z       while
the neural network suffers the least from this bias  it instead
significantly biases galaxies to higher redshifts 
the data set we applied these ml techniques to is quite
optimistic in the context of real galaxy surveys  there is a
selection bias towards bright galaxies at low redshift which
makes obtaining sufficient training data for high redshift objects  which are of most interest for constraining cosmological
paramters  difficult  an additional benefit of our using simulated data is that we were able to use a       training testing
split  so that we have a large sample of data that is independent of the training  this is in large part responsible for the
success of our photometric redshift estimates 
the main problem with photometric redshifts in the context of machine learning is that the training data exhibit very
large noise  a huge boon for future redshift estimation techniques will be to improve the reparameterization of photometric information into optimal forms for machine learning
algorithms  in addition  improvements to the fidelity of the
training set  reducing incompleteness  noise  and misclassification  will greatly improve the accuracy and precision of
photometric redshifts 
a possible future direction for this project could be to develop a model generative machine learning approach which
would produce a joint probability distribution in color magnitude  redshift space  this would be extremely useful  as
it would allow for selective filtering of photo z data in order
to minimize uncertainties on constrraints of cosmological parameters 
we thank prof  risa wechsler and carlos cunha for helpful
discussions which guided the direction of this project  and we
thank michael busha for providing access to the aardvark
des mock galaxy catalogs 

references
abdalla  f  b   banerji  m   lahav  o     rashkov  v        mnras      
    
collister  a  a     lahav  o        pasp          
connolly  a  j   csabai  i   szalay  a  s   et al        aj           
firth  a  e   lahav  o     somerville  r  s        mnras           
freeman  p  e   newman  j  a   lee  a  b   richards  j  w     schafer 
c  m        mnras           
gerdes  d  w   sypniewski  a  j   mckay  t  a   et al        apj          
padmanabhan  n   schlegel  d  j   seljak  u   et al        mnras          

press  w  h   teukolsky  s  a   vetterling  w  t     flannery  b  p       
numerical recipes in c  the art of scientific computing
smola  a  j     schlkopf  b        statistics and computing         
vanzella  e   cristiani  s   fontana  a   et al        a a          
wadadekar  y        pasp         
zhang  y   li  l     zhao  y        mnras          
zheng  h     zhang  y        in society of photo optical instrumentation
engineers  spie  conference series  vol        society of photo optical
instrumentation engineers  spie  conference series

fi