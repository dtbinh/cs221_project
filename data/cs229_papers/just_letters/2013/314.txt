how does he saw me 
a recommendation engine for picking heroes in
dota  
kevin conley

daniel perry

stanford university
email  kcon stanford edu

stanford university
email  djperry stanford edu

abstractin this paper  we present a hero recommendation
engine for the popular computer game dota    we detail previous
efforts at hero recommendation  building on these to provide
a more complete exploration of machine learning algorithms
applied to this problem 
in addition to discussing the details behind the machine
learning algorithms we use  we also provide insight into our
method of data collection and feature selection  in doing so  the
outcome of our efforts is two fold  first  we provide the first
public survey of machine learning algorithms applied to dota
 in the process gaining further insight into the algorithms we
explore  second  we provide a tool that we believe will be useful
for both the casual and competitive sides of dota  s   million
unique player base 

project is to recommend heroes that will perform well against
an opposing team of heroes 
this fits as a classic machine learning recommendation
problem  but what piques our interest is the sheer volume of
the solution space  with     heroes to choose from and five
heroes per team  we are attempting to find the best five heroes
for any given matchup  which results in over eight quadrillion
possible team combinations  on a deeper level  recommending
heroes using machine learning is challenging because it tries to
capture via raw data what professional players have developed
a gut instinct for through hundreds of thousands of hours of
play time 
ii 

i 

i ntroduction

dota   by valve is a popular computer game with a player
base of   million unique users  while many of these users play
casually  there are also professional players that participate
in dota   tournaments with massive monetary payouts  for
example  valves recent dota   tournament  the international
   had a prize pool of over      million     
each dota   match consists of two teams of five players
pitted against each other  before a match begins  each player
selects a character to play as  known as a hero  from a pool
of     different heroes  once a player chooses a hero  no other
player can select that hero for the same match  heroes have a
wide range of characteristics and abilities that  combined with
the massive hero pool  make each match unique 
an interesting aspect of the game is that in choosing a hero 
players must keep in mind not only the individual strengths
and weaknesses of each hero  but also how the strengths
and weaknesses of that hero interact with the heroes already
chosen by other players  an effective hero pick is one that
synergizes with the heroes chosen by teammates  and both
exploits the weaknesses and minimizes the strengths of the
heroes chosen by the opposing team  assuming equally skilled
teams  the ramifications of hero selection can be so staggering
that well devised hero choices can implicitly give a team a
large advantage before the match even begins  the goal of our
how does he saw me  is an infamous quote from dota   sportscaster
david luminous zhang  who abandoned english during a particularly
exciting dota   match  http   www youtube com watch v bac b z m s t 
  m s

r elated w ork

dota cp     is a web application developed with a similar
aim of recommending heroes for dota   matches  given two
teams of five heroes  the author reports a     accuracy of
predicting the winning team  although the author does not
release source code for his algorithm  he states that dota cp
models hero selection as a zero sum game for which it learns
the game matrix by logistic regression  when suggesting hero
picks and bans it assumes that teams are min max agents that
take turns picking one hero at a time  while dota cp is a great
first effort at a hero recommendation engine  we believe we
can improve on its results by exploring other machine learning
algorithms 
dotabuff     is a website that provides detailed dota  
statistics  dotabuff uses the same web api that we do to
collect data  and it allows the user to visualize statistics in
an organized manner  while the website currently makes no
effort to provide hero recommendations  we found it helpful
in verifying the data we collect 
iii 

dataset

we used valves steam web api     to pull data for      
matches between november   and december    our data
satisfies the following requirements 


the game mode is either all pick  single draft  all
random  random draft  captains draft  captains mode 
or least played  these game modes are the closest
to the true vision of dota    and every hero has the
potential to show up in a match 

fi

the skill level of the players is very high  which
corresponds to roughly the top    of players  we
believe utilizing only very high skill level matches
allows us to best represent heroes at their full potential 



no players leave the match before the game is completed  such matches do not capture how the absent
players heroes affect the outcome of the match 

the data for each match is structured as json and includes
which heroes were chosen for each team  how those heroes
performed over the course of the game  and which team
ultimately won the game  we stored the json for each match
in a mongodb database during data collection 
we exported     of the matches from our database to form
a training set of        matches  we exported the remaining
    of our database to form a test set of       matches 
iv 

m ethodology

in this section we describe the algorithms we used in
developing our recommendation engine  we used the scikitlearn python library to implement our algorithms 

fig    

  

a  feature vector
in dota   matches  one team is called the radiant and
the other team is called the dire  these terms are roughly
analogous to home and away  as they only determine the
starting point of each team on the game world map  which is
roughly symmetric 
there are     heroes in dota    as of writing   but the
web api uses hero id numbers that range from   to      two
hero ids are not used   so for our algorithms we used a feature
vector x  r    such that 

  if a radiant player played as the hero with id i
xi  
   otherwise

  if a dire player played as the hero with id i
x    i  
   otherwise
we also defined our label y  r to be 

  if the radiant team won
y 
   otherwise
b  making predictions
since our dataset contains information about heroes on
teams in specific radiant vs  dire configurations  simply running
our algorithms on each match in our dataset does not fully
utilize all of the data 
instead  we make predictions using the following procedure  given a match feature vector  which we call
radiant query 
  
  

run the algorithm on radiant query to get
radiant prob  the probability that the radiant
team in radiant query wins the match 
construct dire query by swapping the radiant and
dire teams in radiant query so that the radiant
team is now the bottom half of the feature vector and
the dire team is now the top half of the feature vector 

  

  

logistic regression learning curve

run the algorithm on dire query to get
dire prob  the probability that the radiant team in
radiant query loses the match if it was actually
the dire team instead 
calculate the overall probability overall prob as
the average of rad prob and     dire prob  
 
overall prob   rad prob   dire prob 
 
predict the outcome of the match specified by
radiant query as the radiant team winning if
overall prob       and as the dire team winning
otherwise 

this procedure accounts for matches in our dataset that
might not have the team configuration of a given query in one
direction  e g  radiant vs  dire  but may have the configuration
in the other direction  e g  dire vs  radiant  

c  logistic regression
logistic regression is a model that predicts a binary output
using a weighted sum of predictor variables  we first trained
a simple logistic regression model with an intercept term to
predict the outcome of a match  the feature vector and label
we used is decribed in part a of this section 
   learning curve  a plot of our learning curve for
logistic regression is shown in figure    the training and test
accuracies are quite close together  indicating that our model
does not overfit the data  the test accuracy of our model
asympotitcally approaches       at about an        training
set size  indicating that        matches is an optimal training
set size for our logistic regresion model 
   analysis  we believe that this logistic regression model
shows that hero selection alone is an important indicator of the
outcome of a dota   match  however  since logistic regression
is purely a weighted sum of our feature vector  which only
indicates which heroes are on either team   logistic regression
fails to capture the synergistic and antagonistic relationships
between heroes 

fik nearest neighbors is a non parametric method for classification and regression that predicts objects class memberships
based on the k closest training examples in the feature space 
we used a custom weight and distance function and chose
to utilize all training examples as nearest neighbors  our
polynomial weight function described below aggressively gives
less weight to dissimilar training examples  the feature vector
and label we used is described in part a of this section 
we chose to implement k nearest neighbors in order to
better model the relationships between heroes instead of simply
taking into account wins when a hero is present  at a high
level  we continue to focus on wins and the hero composition
of teams  however with k nearest neighbors  we have an
avenue to weigh matches according to how similar they are
to a query match we are interested in  for example  if we are
interested in projecting who will win a specific five on five
matchup  our query match   a match with nine of the heroes
from the query match present will give us more information
on who will win the query match than a match with only one
hero from the query match present 

k fold cross validation accuracy of weight dimension values
    

    
accuracy

d  k nearest neighbors

    

    

 

fig    

   choosing an optimal weight dimension  to choose the
optimal d dimension parameter described above  we used kfold cross validation with k     on        matches from our
training set and varied d across otherwise identical k nearest
neighbors models 
since k nearest neighbors must compare the query match
to every match in the training set and compute weights and
probabilities  this process was quite slow and took about ten
hours  due to time constraints  using more folds or more
matches would have taken too long to finish 

  

  

  

  

choosing an optimal d dimension for our weight function

k nearest neighbors learning curve

accuracy

    
    
    
    

the function is normalized to be between   and    and
it gives more weight to matches that more closely resemble
the query match  to do this  the function compares the query
match vector to the training match vector and counts every
instance where a hero is present in both vectors 
a larger d will result in similar matches getting much
more weight than dissimilar matches  alternatively  a low d 
for example d      will result in each match being weighted
solely by how many heroes in common the match has with
the query match  stated another way  a high d will choose
to put more emphasis on the synergistic and antagonistic
relationships between heroes  while a lower d will put more
emphasis on the independent ability of a hero 

  

d

   calculating weights  the following equation represents
a combined distance and weighting function used in our knearest neighbors simulations 
p   
 i 
j   an d qj   xj   d
wi    
 
n u m in qu ery
the d parameter represents the polynomial scaling of the
weight function  x represents the feature vector for training
match i and is compared by the logical and operator to
query vector q  index j represents the hero id index of each
respective vector  num in query represents the number of
heroes present in the query vector 

 

    
 

 

 

 

number of training samples
fig    

 
   

k nearest neighbors learning curve

a graph of the accuracies achieved when varying the
weight dimension for a k nearest neighbors model trained
on our training set and evaluated on our test set is shown
in figure    we found the optimal weight dimension to be
d      which achieved a mean accuracy of        during the
k fold cross validation 
   learning curve  a plot of our learning curve for knearest neighbors is shown in figure    the test accuracy of
our model monotonically increases with training set size up to
nearly     for around        training matches  because we
do not see the learning curve level off  this may imply that
more data could further improve our accuracy 
e  recommendation engine architecture
we recommend heroes for a team using a greedy search
that considers every possible hero that could be added to the

firecommendations  we see that by choosing a moderate d value
we can achieve an appropriate balance between recognizing the
individual skills of heroes as well as factoring in the synergistic
and antagonistic relationships between them  our results also
suggest that using more data could improve our k nearest
neighbors results further 
vi 

fig    

screenshot of web interface for recommendation engine

team and ranks the candidates by probability of the team
winning against the opposing team if the candidate was added
to the team 
our recommendation engine is modular so that either of
our algorithms could be used to recommend heroes  given the
id numbers of the heroes on both teams  the recommendation
engine proceeds as follows 
  
  
  

  

create a feature vector for the match as described in
part a of this section 
create a set of new feature vectors  each with a
different candidate hero added to the original feature
vector 
run the algorithm to compute the probability of victory with each feature vector from step    averaging
the probabilities of the team winning in both radiant
and dire configurations as described in part b of this
section 
sort the candidates by probability of victory to give
ranked recommendations 

f  web interface
to facilitate the use of our recommendation engine for
users  we adapted the data entry interface from the dota cp
website so that the user can easily input heroes by typing the
first few letters of a heros name  choosing the desired hero
from a list of auto complete suggestions  and pressing enter 
we connected this web interface to our recommendation engine
using the flask python web application library  a screenshot
of our web interface is shown in figure   
v 

c onclusion

in this paper we present a survey of machine learning
algorithms applied to the challenge of building a hero recommendation engine as well as predicting match outcomes for
the game dota    we apply logistic regression and k nearest
neighbor models to these challenges and achieve promising
results 
given our logistic regression results  we conclude that
solely looking at the hero composition of a team and whether
or not that team was victorious can provide a useful model
for match outcome prediction and as a result  hero recommendation  additionally  utilizing a k nearest neighbors approach
with custom weight and distance functions opens up another
path towards achieving successful match predictions and hero

f uture w ork

despite the high accuracy of our k nearest neighbor model 
the performance was quite slow  the five data points we used
in our learning curve took about four hours total to calculate 
and the k fold cross validation used to find the optimal weight
dimension took over    hours 
we believe that the performance of our k nearest neighbor
model could be improved in a number of ways  first  the
binary feature vector used could be stored as an integer
in binary representation to improve memory usage  second 
the calculation of weighted distances could be parallelized
across multiple cpu cores  third  a gpu could be utilized
to vectorize the weighted distance function calculations 
although the version of the game did not change during
the time we collected match data  a new patch is released for
dota   every few months that dramatically changes the balance
of the game  therefore  we believe that a sliding window of
match history data that resets when a new patch is released
could help maintain data relevancy  for this reason  it would
be useful to find if there is a training match size for which
performance levels off so that we could collect only as much
data as is needed 
finally  we could experiement with a different search
algorithm for our recommendation engine such as a  which
would account for the opposing team picking heroes that could
counter our initial recommendations  however  due to time
constraints we were not able to implement a  search for our
recommendation engine 
ultimately  we believe there are many promising directions
which future explorations in this area could take 
r eferences
   

dota  counter pick  dota  counter pick  n p   n d  web     nov 
      http   dota cp com  
    dotabuff   dota   statistics  dotabuff   dota   statistics  elo
entertainment llc        web     nov        http   dotabuff com  
    the international interactive compendium  dota   official blog  valve 
      web  http   www dota  com international compendium 
    webapi  official tf  wiki  valve     sept        web     nov       
http   wiki teamfortress com wiki webapi 

fi