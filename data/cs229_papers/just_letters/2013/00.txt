predicting user quality in anonymous chat networks
claire negiar and dhruv amin
stanford university  department of computer science

   introduction and prior work

   data

online social networks like facebook and twitter have
been multiplying over the past few years  along with the
amount of data that these sites handle and process  a lot
of work has been done to optimize the quality and
informativity of the data that reaches their users  such as
facebooks edgerank newsfeed calculation  or friend
and follower suggestions  however  little such analysis
and optimization has been done for less conventional
platforms such as anonymous chat networks  which have
much to gain from this kind of work  in particular  being
able to predict users of poor quality is of paramount
importance as they rarely have long conversations and
are therefore over represented in the matching queue 
which in turn affects the conversation quality of a large
set of users  past attempts at anonymous social networks
 i e  chatroulette  etc   have failed because of this very
problem  as users of high quality leave the network after
repeated interactions with suboptimal users  offering a
better filter of users would allow anonymous networks
to create sub queues  or queues populated almost entirely
of one type of user  enabling a better user experience and
higher activation rate 

chatous is a text based    on   anonymous chat network
that was used as the basis for exploration into user
quality  users can create a profile that contains a screen
name  age  gender  location  and a short free form  about
me  field  after clicking the  new chat  button  users are
matched up with one another in a text based
conversation  interactions on chatous include
exchanging messages  sending accepting a friend
request  reporting an abusive user  and ending a
conversation 

while many attempts have been made to predict optimal
matching between pairs of users in network settings 
little work has been done on classification of users based
upon their own features  most work on the topic has
focused on the edges of the graph  in this project we
hope to classify users simply by examining features of
the nodes  on most networking platforms  the process of
identifying malignant users or content is tedious 
requiring user participation to report those that abuse the
community  our goal in this project is therefore to
explore different representations of the chat networks
users that are effective at separating users  or subsets of
users  ultimately  we wish to isolate groups of good
users so that they can be placed in a prioritized sub
queue  these good users would talk exclusively with
other users from this sub queue  yielding higher average
conversation lengths  better matching  and ultimately
better retention rates on the site 

in order to extract relevant features for our work  we
operated on all data collected from two weeks of user
activity on the chatous platform  which consists of
approximately        users and   million conversations 
the data was initially formatted in a graph structure 
with users as the nodes and conversations as weighted
edges with length as weight  we were also given access
to profile data relating to these nodes  screen name  age 
gender  location and about me  and meta data
surrounding the edges  person to disconnect
conversation  time started  time ended  friendship status 
and word frequency vectors of the conversation with the
underlying words anonymized by numeric ids   from
this conversation data for two weeks  we transformed the
graph structure into a schema with the user as opposed
to the conversation as the atomic unit  users were
mapped to their entire conversation history  profile
information  and meta data surrounding their
conversations  in order to increase efficiency  we select
at random        of these users to serve as a training set
for our exploration  finally  a gold set of      users
was labeled as belonging to the categories clean 
dirty or bot based on a human examining their
conversation history and making an intuitive decision on
the nature of the user 

   quality metric
in defining what it meant to be classified as a good or
bad user  we decided that two key metrics could be

fiused to evaluate the performance of our algorithms 
average conversation length of the user across all
conversations and accuracy predicting the labels of the
gold set  in past versions of the chatous platform  users
had been required to rate each conversation and this
rating was collected as conversation meta data  this
rating requirement was dropped when it became clear
that it directly correlated with length of conversation 
thus  we could consider one definition of suboptimal
users as those for whom the average lengths of the
conversations they are a part of is lower than the mean
conversation length       lines per user   yet another
definition of user quality relies not upon the length of
conversations  but on the type of conversations the user
engages in  users that harass or use a higher proportion
of vulgar words are labeled as dirty in the human
created gold set  while there is some dependency
between the two metrics  monitoring how our algorithms
perform on both metrics provides a qualitative measure
on how successful it is at determining which users are
optimal  ultimate choice of algorithm depends on which
metric the reader desires to improve 

   data model

  
our method of representing a user evolved as we began
to understand the problem more  initially  users were
treated as a vector of behavioral features that tried to
capture how the user interacted on chatous generally 
when this approach ultimately failed to capture the same
information as our human labeled gold set  we modified
our approach to defining users based upon the terms in
their conversation history   
  
     behavioral  feature  set    
  
originally  we hypothesized that clean and dirty
users would interact with the chatous platform in
fundamentally different ways  therefore  we started with
a set of features that we believed would capture these
differences in behaviors and inform proper labelings 
feature
num of long conversations
num of short conversations
avg conversation ratio
num reports generated against
user
num reports generated by user
num of friendship
num conversation zero length
num conversation user finishes

motivation
better users will have longer
conversations
better users speak evenly with
partner
harassing users are reported
users may abuse reporting
system
better users have more
friendship establishing convos
sign the user has high churn
user is the cause of churn

num profiles used
num times gender changed
num times location changed
num times age changed
num times username changed
variance in word history 

users changing their
representation flagged
gender change should be rare
location change should be rare
age should not change if true
user changing representation
bots and harassing users tend to
say similar phrases in all convos

  
      logistic  regression  
  
training a random selection of        users from the
chatous dataset  we attempted logistic regression on the
behavior features in order to see if these could accurately
predict on the gold  human labeled data set of     
dirty and clean users  in training our logistic
regression  we initially used the users average
conversation length as the deciding factor on whether or
not they were clean  however  using the average
length of conversation as a proxy training label ends up
being suboptimal        as best accuracy rate  
suggesting that the human labeling cannot be reduced to
average conversation length despite the fact that the
metric holds for judging individual conversation quality 
we therefore performed holdout cross validation using
the smaller  hand labeled dataset with      users  the
decision boundary created by the logistic regression
procedure ends up labeling all of the users as clean
since this is the value that maximizes the accuracy for
these features  yielding a        accuracy  this
boundary occurs because the actual ratio of clean to
dirty users is in fact approximately             we
performed tests on every possible subset of features to
find the set of features that best separates our data 
however  no subset of our features was able to achieve
over        accuracy  with the lowest barely achieving
    
      k    means  clustering  
given that logistic regression failed to create a
separating bound  we decided to move to an
unsupervised algorithm to detect patterns in our data 
our hypothesis was once again that through clustering
our data on similar behaviors  we could isolate pockets
of users that were in fact of the same type  the ultimate
goal changed to create cluster centers that grouped users
of the same type together  or at the very least  improved
upon the true distribution of           clean to dirty
users  this result would allow us to realize our goal of
sub queuing on the live site 
                                                                                                                
   average squared euclidean distance between all unique combinations of a user s
  

fiour gold labeled dataset contains     dirty users and
    clean users      dirty   we ran a k means
clustering algorithm for all k between   and   and
achieved the following results 
cluser   size
  dirty users

   users
   

cluser   size
  dirty users
cluser   size
  dirty users

   users
      
   users
      

cluser   size
  dirty users
cluser   size
  dirty users
cluser   size
  dirty users
cluser   size
  dirty users

   users
      
   users
      
   users
   
   users
   

k  
cluster   size
  dirty users
k  
cluster   size
  dirty users
cluster   size
  dirty users
k  
cluster   size
  dirty users
cluster   size
  dirty users
cluster   size
  dirty users
cluster   size
  dirty users

    users
      
    users
      
    users
     
    users
      
    users
      
    users
      
   users
      

given that our goal was to find clusters with more
heavily skewed distributions of dirty and clean users
than in the labeled data  our algorithm achieves
moderate success  in the k   scenario  one cluster
attains       of users dirty  a       increase in the
ratio of dirty users from the original dataset   with
higher numbers of clusters  the algorithm continues to
polarize the distribution  indicating that behavior
captured by many of the clusters is more extreme  for
instance  in the k     scenario  the best cluster posts a
    increase in the proportion of dirty users  as well
as two clusters with a     and a     increase in the
proportion clean users  respectively  however  these
three clusters only represent       of our data  and the
remaining       of the data is not differentiated  this
observation led us to reconsider whether behavioral
features were in fact differentiating 
for each of our behavioral features  we examined the
potential distribution of the feature as if it were drawn
from a gaussian distribution   the following means and
variances were plotted for each behavior 
clean mean
clean var
clean mean
clean var
clean mean
clean var

avg length conversation
    
dirty mean
    
dirty var
percent long conversation
 
dirty mean
 
dirty var
percent short conversation
    
dirty mean
    
dirty var
avg speaking ratio

                                                                                                                
 

this is a simplifying assumption that is only useful for comparison  true
distribution across all users for each feature is of course unknown 

   
   
 
 
 
 

clean mean
clean var
clean mean
clean var
clean mean
clean var
clean mean
clean var
clean mean
clean var
clean mean
clean var
clean mean
clean var
clean mean
clean var
clean mean
clean var
clean mean
clean var
clean mean
clean var
clean mean
clean var

   
dirty mean
    
dirty var
avg num reports against
   e  
dirty mean
   e  
dirty var
avg num reports filed
   e  
dirty mean
   e  
dirty var
percent friendship conversation
  
dirty mean
   
dirty var
percent zero length
   
dirty mean
   
dirty var
percent user finished
   
dirty mean
   
dirty var
number of profiles used
   
dirty mean
  
dirty var
number of gender changes
    
dirty mean
   
dirty var
number of age changes
  
dirty mean
   
dirty var
number of location changes
  
dirty mean
   
dirty var
number of username changes
   
dirty mean
   
dirty var
conversation history variance
  
dirty mean
   
dirty var

a few examples of the gaussian plots 

    
   
   e  
   e  
   e  
   e  
   
   
   
   
   
   
  
   
   
   
   
  
   
   
   
  
   
   

fithe striking aspect of these results is that the variance in
the set for the labeled clean users is almost always
relatively large compared to the dirty users  in a few
select cases  average conversation length  speaking
ratio   the variance in the dirty users encompasses the
range of clean behaviors  as a result  the two
spectrums of behavior almost always overlap in some
form to the point that they are almost indistinguishable 
thus  few features in the behavioral feature set carry
informative value when trying to separate the two labels 
finally  in order to confirm that no subset of features
would be more informative than the aggregate  we tested
k means and logistic regression on all subsets  plotting
features against one another yielded the same conclusion
as above  it is difficult to separate users based upon
behavioral features into the labels clean and dirty 

logistic regression accuracy       suffers since data is inseparable 

best performance when all points labeled the same is an indication
that few data axes spread the data 

  
     conversation  history  feature  set  
  
given that the gold set of data was created based upon
a human examining users conversations to assess
whether a users conversations tended to be dirty or
clean  the final approach we considered was clustering
based on upon the textual similarity of users

conversation histories  as the proportion of vulgar
words is much higher in dirty users conversations  the
assumption in this model is that it should be possible to
separate the two into clusters based upon this difference
in their word usage 
  
      tf idf  document  clustering  
  
for   each   user    we   generated   a   document   of   the  
users   entire   conversation   history    tf idf  which is
defined as 
wi j   tfi j   log  n   dfi 
where tfi j is the number of occurrences of the word i in
document j  dfi is the number of documents containing i 
and n is the total number of documents  is used to
generate a representation of each term wis importance
to dj  the document it is contained within  in this
situation  the document is the users entire conversation
history  due to the sparse nature of the data  the tf is
normalized by dividing by the max frequency of any
term in a given document  using tf idf allows us to
vectorize a users conversation history and then use the
cosine similarity  which is defined as 

to determine how similar two users are in terms of the
words theyve used   in order to normalize the lengths of
the vector representations of the two conversations being
compared  elements of the vocabulary that were not
observed in a document were set to    finally  in order to
further de emphasize words that did not create
differences between user conversations  we identified
the     most frequently used words  or stop words  and
removed them from every users conversation history 
given that our objective function is non convex  we are
subject to finding local optima depending upon our
starting conditions  in order to account for this  we ran
the algorithm over many iterations with random starting
points until we attained a sense of the global clustering 
in order to determine k  we determined the median
distribution over    runs of the algorithm for each value
of k from   to     the median clustering is determined
by ranking the outputs of the algorithm in terms of
which increase the skewed nature of the data the most 
                                                                                                                
 

we also briefly experimented using squared euclidean distance as our distance
metric  square had the benefit of emphasizing any difference between the two
histories but it underperformed cosine similarity as it over emphasized word
frequency differences as opposed to word type differences 

  

fiultimately  the clustering that achieved the best
performance had k     cluster centers and created a
slight improvement over the typical ratio of clean to
dirty users  since some users conversation histories
consisted entirely of stop words  these users were not
considered in determining the cluster centers  cosine
similarity undefined for   length vector   therefore 
these users were separated out and placed in their own
undetermined cluster  median results of k     below 
k        
cluster       

size  
   clean  
   dirty  

cluster       

     
        
        

size  
   clean  
   dirty  

     
        
        

cluster  undet   

size  
   clean  
   dirty  

     
     
     

  
      expanded  stop  word  set  
  
during the first attempt of k means on history document
vectors  we eliminated     of the most commonly used
words on the chatous network as these words were not
informative as to the difference between any two
documents  seeing how this improved performance  we
tried to find more words to eliminate so as to increase
the separation between dirty and clean users  the
finding that in our data  on average      of the words in
conversations of above average length are said only once
further validated this potential approach as it indicates
that a word form occurring at all is more important than
differences in frequency  we were able to construct
vocabularies vc and vd for each individual set of users 
where   vc           and   vd           over the     
users  we hypothesized that variations in the word forms
used is more informative of the difference between two
users than the variation in the frequencies of words used 
we considered expanding our stop word set to all words
found in the intersection of vc and vd  which was vi  
      with this dramatically increased stop word set  the
median clustering of    iterations of k means  at the
optimal value of k      yielded the following results 
k         expanded  stop  words  
cluster       

size  
   clean  
   dirty  

     
        
        

cluster       

size  
   clean  
   dirty  

     
      
    

cluster  undet   

size  
   clean  
   dirty  

     
        
        

the most encouraging result is that this approach is able
to identify clusters of entirely one type of user no matter
the value of k  we tested from k     to k       or starting
initialization of the clustering  although the number of
users thrown out in the undetermined cluster has
increased by      the number of users that this
algorithm can classify correctly with a high degree of
confidence represented     of our test data  which

could be used to satisfy our ultimate goal of sub
queuing 
  
    analyses  and  further  work  
  
ultimately  our approach of clustering was in fact able to
make modest progress towards our goals of creating
clusters of one type of user  however  by expanding the
stop word set  there is a potential impact on the
generalizability of this approach  especially if words in
the intersection of clean and dirty users are not found
in the training data  therefore  we investigated the
percentage of our vocabulary we were capturing and
found that the size of the vocabulary of the cluster
training set of      human labeled users was     of the
size of the vocabulary of the larger group of       
users        vs        distinct word  respectively   this
result indicates that the approach has the potential to
scale but more research needs to be done on the
scenarios under which these conditions hold on the live
chat network 
as a next step  we intend to run our results on the live
chatous platform and analyze the performance  given
that roughly     of our users are placed in the
undetermined cluster due to stop word conversations 
one suggestion would be to look into ways to classify
these users  we were surprised by the conclusion that
behavioral features failed to separate between our
labeling  even in the clustering scenario  we recognize
that one assumption we made was to use a hard
clustering algorithm  users either belonged to one cluster
that represented a labeling or they did   not    given   the  
variance  in  behavioral  features   our  next  step  will  be  
to  change  the  underlying  model  to  a  softer  notion  of  
clustering    such   as   the   gaussian   mixture   model  
optimized  with  expectation  maximization   in  order  to  
see   if   we   can   achieve   better   performance   when   we  
simply   try   to   compare   probabilities   some   user   x  
belongs  to  some  cluster  y     
  
in   our   dataset    we   did   not   have   access   to   the  
underlying   words   of   our   word   frequency   vectors   
given   that   the   conversation   history   approach   has   had  
limited   success    yet   another   next   step   is   to   do   more  
natural   language   processing   to   factor   in  
considerations   such   as   parsing    grammatical  
processing    relating   concepts    extracting   topics    etc   
ultimately    the   initial   success   realized   through   our  
project   in   finding   clusters   of   similarly   typed   users  
suggests  sub  queues  can  be  established  automatically  
using   machine   learning   in   order   to   dramatically  
improve  the  anonymous  chat  network  experience     

fi