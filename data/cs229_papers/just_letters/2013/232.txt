sentiment analysis of app store reviews
chirag sangani
csangani stanford edu

abstract  analyzing user sentiments towards apps
through their review comments and ratings can be
economically profitable to app developers  we propose
a system that provides a many to many mapping from
reviews to topics of interest  and a list of reviews for
each topic that are representative of user sentiment
towards that topic 

  

introduction

developing an app in today s smartphone ecosystems is
easier than ever   the barrier of entry is low enough that
a single developer can write a commercially successful
app  the ios app store is reported to have reached the
one million apps mark      as of october         b
apps have been downloaded from the app store     
furthermore  revenue earned by developers from the
ios app store have been over     b in          
customer interest in apps is evident  top apps in the
google play app store have over  m reviews 
as a developer  it is essential to stay on top of your
game  i e   keep your app updated with the most
requested features and bug fixes  however  most app
stores provide only an average rating  out of    for each
app  consequently  it is difficult to identify why people
like or dislike a particular  we aim to solve this problem 
section   talks briefly about related work  section  
outlines our methodology in detail  in section    we
analyze our methodology in light of experimental
results  finally  we conclude in section   with a mention
of potential improvements to be explored in later work 

  

related work

a number of articles have been published on the
sentiment analysis of movie     and product     reviews 
with elaborate consideration towards natural language
processing and understanding  subjectivity detection
and opinion identification  feature selection and
extraction  classification  language models  etc      a
subset of these articles focus on topic considerations 
i e   determining the topic of a document  this issue
bears relevance to our system  which is essentially a
ranked topic classifier      enumerates a number of prior

sundaram ananthanarayanan
sananth  stanford edu

work on this topic using varied approaches in section
      

  

methodology

our methodology is a multi step process that addresses
two tasks  the identification of topics  and extraction of
opinions associated with these features  consequently 
our methodology is a multi stage process consisting of
the following steps 
   
   
   
   
   
   

creating a repository of reviews 
creating a corpus of subjective words 
identify topics of interest 
identifying topics in a review 
ranking topics in order of relevance  and
identifying representative reviews for a topic 

   

creating a repository of reviews

      downloading reviews
to create a sufficiently large dataset  we scraped
reviews for popular apps off the google play store  we
were assisted by android market api      an
unofficial java library that allows for direct access to
googles official android market servers for
information 
android market api
relevant services 

provides

the

following

a  querying for app ids based on search queries  and
b  downloading reviews for apps based on app ids 
due to googles anti spam  anti ddos policies  there
are certain limitations on harvesting data 
a  not all apps show up when querying for app ids 
for example  querying for angry birds does not
return results for the popular angry birds game
series 
b  only a maximum of      comments can be
downloaded for any app 
we collected reviews for the following apps  audible 
flixster  jewels  opera mini  pandora  soundhound 
and yelp 

fi      processing reviews
a review consists of the following relevant data 
a  a unique author id 
b  review creation time
c  rating  ranging from   to   
d  review text
we normalize the ratings to a scale of       

expectedly  not all reviews possess perfect grammar or
punctuation  rendering preprocessing a must  to begin 
text for each review is transformed to lowercase 
subsequently  emoticons are converted into symbols 
emoticons can potentially prove to be strong indicators
of opinion  and thus  are valuable  now  exclamation
marks are transformed into symbols  since we believe
that they  too  can prove to be strong indicators of
opinion  finally  the review text is stripped of
punctuation  and replaced by whitespace 

   

creating a corpus of subjective
words

we hypothesize that the opinion of a review is indicated
by the presence of subjective words  for example  a
review is more likely to complain about crashes  and
have a low rating  if it contains the word crash  thus 
we intend to create a corpus of such subjective words 
we also hypothesize that a subjective word is indicative
of a high or low rating  for example  a review with the
word crash in it is likely to have a low rating  whereas
one with stable in it is likely to have a high rating 
consequently  we extract subjective words from
reviews by analyzing their power to predict the rating of
a review  specifically  we apply logistic regression to
review ratings 
for each review   the set of features    is the set of
all unigram features extracted from the review text  we
used presence as a feature rather than frequency  that
is  a feature value is   or   if the related word  or pair 
is present or not  as an optimization  we omit common
stop words  obtained from     
the hypothesis function is the sigmoid function  that is 
given a feature vector    and weight vector   our
prediction     of the normalized rating of  is 
            

 

        

the weight vector  is learnt using stochastic gradient
descent 
                     

here   is the learning rate 

the error for the set    test  training  is defined as 
   

 
 
           
  


we perform stochastic gradient descent for multiple
passes until 
           

to summarize  there are three parameters to our
algorithm     and  

once convergence is reached  we dump the weight
vector  to a file  this vector is a map on words to scalar
values  and is interpreted as a list of words sorted on
rating influence  the top few words indicate a positive
rating  and the bottom few words indicate a negative
rating 

   

identifying topics of interest

from the previous segment  we have a list of subjective
words that indicate a positive or negative opinion  in this
segment  we will map these words to topics of interest 
given that we lack a database of semantic knowledge
that maps a subjective word to a relevant topic  and our
inability to use nlp techniques to infer topics from
sentences  see         we decided to make use of
wordnet     
wordnet allows us to group words into synsets  each
synset is a group of synonymous words  we hypothesize
that words that are synonyms represent the same topic 
hence  a topic is but a set of synonyms 
we use the following algorithm to compute topics  
synonym sets 
     


         
for all  in  
for all  in  
if  in    
          

fi        
return 

here   is the set of all unigram features obtained from
    

   

identifying topics in a review

given a review text  a list of subjective words  and a list
of topics that each subjective word corresponds to  the
topics addressed by the review are the union of topics
for each word in the review 

   

ranking topics
relevance

in

order

of

given a list of topics  and a list of reviews associated
with each topic  one can compute various metrics for
each topic  such as average rating  number of reviews 
etc  consequently  one can rank the topics in order of
relevance to a single or hybrid metric  for example  a
hybrid metric that ranks topics in increasing order of
average rating and decreasing order of number of
reviews provides a list of topics that customers are most
unhappy about  similarly  hybrid metrics can be
designed to provide topics that customers are most
happy about  or write the longest reviews about  etc 

   

identifying representative reviews
for a topic 

for each topic  we identify a list of representative
reviews that summarize public sentiment on that topic 
this is achieved by ranking all reviews relevant to a
topic according to some metric and picking the top   
we chose a metric that ranks reviews in proportion to
the number of times a word from the topic set appears
in the review  and inversely proportional to the squared
distance of the reviews rating from the average rating
for that topic 

  

analysis

   

algorithmic complexity

the first step in our pipeline is linear regression on
unigram features  this step is trivially    where 
is the number of reviews  and  is the average length of
each review  for a fixed learning rate 
in the next step  we compute a list of topics from word
synsets  assuming that it takes constant time to compute
word synsets  the time complexity is     where  is

the number of synsets and  is the number of unigram
features 
the remaining two steps are mere rankings  computed
in linear   polynomial time  hence  our pipeline is
algorithmically efficient 

   

output

      creating a corpus of subjective words
the first step in our pipeline  linear regression  gives
us the basic ability to predict the sentiment of a review 
this is useful to identify features in a review that are
good indicators of sentiment 
our values for the parameters of linear regression were 
                      is the presence indicating
feature vector of all unigrams with stop words filtered
out  finally  our training set was     of all reviews in
the repository  and the test set was the remaining     
with these values  we reached convergence in
approximately    iterations  and our test   training set
error was       
the top    positive words were 

love  great  good  awesome  best     excellent  app  nice 
game  browser  cool  fast  easy  works    and
variants   fun  amazing  movie  opera  addictive 
perfect  music  movies  awsome  super  helpful 
fantastic  better  jewels 
the top    negative words were 
update  work  open  sucks  will  phone  uninstall  ads 
play  bad  songs  books  poor  crap  book  crashes 
useless  screen  uninstalled  force  terrible  download 
   load  horrible  uninstalling  start  takes  waste 
annoying 
subjectively  it is obvious that the top    positive words
indeed convey a positive sentiment  whereas the
bottom    words convey a negative sentiment 
once we obtained the requisite features  we mapped
them to topics  previously  we included a step where
features whose weights were    were removed using kmeans clustering  since these features had poor rating
predictive power  however  this does not necessarily
mean that these features are irrelevant  they could be
indicative of mixed opinion  and are just as valuable 
additionally performing this step led to an insufficient
number of topics left for the remaining steps 

ficonsequently  we decided to leave them in  and filter
out stop words using a fixed dictionary 
      identifying topics in a review
topic inference in a document is a well studied task 
however  most approaches assume a structured
document with well formed grammar and only the
occasional error  however  most reviews we
encountered showed poor structure  spelling and syntax 
this
rendered
nlp
techniques
impossible 
consequently  we fell back to a simple technique 
finding a group of subjective words with similar
meanings in a review  and interpreting this set of words
as a topic of discussion 
we considered mapping each such set of words to a
hand picked list of super topics manually  however 
this proved too arduous  and defeated the purpose of our
efforts to automate everything  hence  this technique
was discarded 
using our technique  we obtained an average of     
topics per app  note that this list contains a large
spectrum of all possible topics  ranging from ads 
bug or crash all the way to fine  okay  etc  in
the next step  we rank topics according to their
relevance 
in our results  we noticed that not all topic sets are
obviously a set of synonyms  for example  the set
  bring    bringing    brings    brought    play    played  
 playing    plays    work    worked    working    works  
does not obviously contain pairwise synonymous
words  however  one must realize that a word can be
used in many senses  and can imply different meanings 
in the absence of contextual meaning of a word  one
must assume every meaning to be possible  leading to a
certain level of ambiguity  this might also lead to two
or more independent topics fused together under the
same topic  however  this issue is not prevalent or
alarming  the example above is the worst case scenario 
another issue we noticed was some topics were similar
for the most part  except for one or two words  and hence
appeared together in rankings everywhere  however 
this issue was not too prevalent either  and hence  was
deferred 
      ranking topics in order of relevance
the relevance of a topic depends on the desideratum of
the developer  a developer may desire to look at topics
with negative sentiments  positive sentiments  or topics
that are popular  or any other metric 

we defined metrics for some such use cases  for
example  topics with negative sentiments can be
obtained by ranking them proportional to the number of
relevant reviews  and inversely proportional to the
average rating  this metric is not entirely statistically
sound  any topic that has enough reviews will have a
mean close to the average rating  however  it works
well in practice 
for pandora  the top negative topics we found were 
  garbage    refuses      pathetic    poor      email  
 emailed    emails    etc 
in practice  we found another heuristic extremely
effective  topics ranked such that they are far from the
extremes in terms of ratings  and are far from the app
average  and have a sizeable number of reviews  provide
an alternate view of the public sentiment that is fairly
critical and insightful  for example  for pandora  the top
topics according to this metric were    play    played  
 playing    plays       ad    ads    advertisement  
 advertisements    advertising    adverts      call    song  
 songs    etc  we believe that this metric provides good
results because 
 a  most reviews that provide a   star     star rating do
so without providing any insightful criticism  on the
other hand  reviews with     star ratings provide
more detailed criticism  one can hypothesize that a
    rating indicates the author put thought into the
rating before choosing an outright good bad
 leading to a     star rating respectively  distinction 
and this same thought is usually reflected in the
review itself 
 b  if the average rating is high  as is the case with all
the apps we happened to choose   then most reviews
close to the app average  again  fail to criticize the
app properly 
other means of ranking topics could be conceived of 
such as measuring the insightfulness of a review  and
computing the average for a topic  however  such
avenues were deferred  additionally  we would like
replace the use of a heuristic with that of a learning
technique  however  in the face of lack of labeled data 
we are unable to do so 
     

identifying representative reviews for a
topic
to identify reviews that are most representative of a
topic  we use the tf idf  term frequency  inverse
document frequency  metric for all terms in a topic 
combined with a metric that ranks reviews in order of

fitheir square distance from the topics average rating 
note that for any topic  the document frequency for a
term is constant for all reviews  so only the term
frequency in a review is helpful 
using this metric  we get fairly accurate results for the
following topics for pandora  in processed form  
  play    played    playing    plays    
absolutely love it but the widget never loads anymore
and sometimes it will stop in the middle of a song and
go to the next song without me doing anything or else it
will play an ad while one song is playing and another
song will start playing on top of that another problem is
that the app played   different songs at one time  x in  
hour not sure whats going on
  ad    ads    advertisement  
 advertising    adverts   

 advertisements  

indecent inappropriate ads  i like the application
however there needs to be a way to opt out of your ads
that contain sensual provocative advertisement for
social related content because of the nature of your ads
your application needs to be rated for adults only your
ads are inappropriate for children and minors
subjectively  one can conclude that these results are
fairly relevant to the topic at hand  this is because the
metric ensures that the representative review is one that
talks most about the topic at hand  finally  one can argue
that the review is representative since it has a rating
close to the topics average rating 

  

conclusion

to summarize our work  we started out with the goal of
providing a more detailed analyses of the reviews of an
app to a developer  beyond an average rating  we are
able to provide a list of topics that are relevant to the
manner in which the developer wishes to interpret the
reviews  an average rating that conveys general
sentiment for that topic  and representative reviews that
give insightful criticism regarding the topic 
there are a number of avenues available for improving
our methodology  we can improve the manner in which
we infer topics from a review by applying nlp
techniques on structured data  and the manner in which
we signify relevance of topic or representativeness of a
review using labeled data  we would like to
acknowledge dr  andrew ng  instructor  cs       dr 

percy liang  instructor  cs       the assistants for these
courses  and our course mates  for their help  guidance 
and feedback 

  

references

    c  jones   apple s app store about to hit  
million apps                online   available 
http   www forbes com sites chuckjones         
   apples app store about to hit   million apps  
 accessed             
    r  baldwin   apple hits    billion apps served  
  
  
     
 online  
available 
http   www wired com gadgetlab         applehits    billion served    accessed             
    canalys       quarterly growth in downloads for
leading app stores                online  
available 
http   canalys com newsroom   quarterly growth downloads leading app stores 
 accessed             
    l  zhuang  f  jing and x  y  zhu   movie review
mining and summarization   in proceedings of the
  th acm international conference on
information and knowledge management  cikm
      acm  new york  ny  usa       
    h  tang  s  tan and x  cheng   a survey on
sentiment detection of reviews   expert systems
with applications  vol      no     pp              
     
    b  pang and l  lee   opinion mining and
sentiment analysis   foundations and trends in
information retrieval  vol     no       pp        
     
     android market api                online  
available 
http   code google com p androidmarket api  
    ranks nl 
 english stopwords  
 online  
available 
http   www ranks nl resources stopwords html 
 accessed             
    princeton university   about wordnet        
 online   available  http   wordnet princeton edu 

fi