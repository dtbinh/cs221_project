cs    final project
sentiment analysis of tweets  baselines and neural network models
kai sheng tai
 advised by richard socher 
 dated  december          
social media sites such as twitter are a rich source of text examples expressing positive and
negative sentiment  in this project  we investigate the classification accuracy achieved by a range
of learning algorithms on a twitter sentiment dataset  we evaluate the performance of a neural
network classifier over bag of words features in relation to simpler linear classifiers 

this is a joint project with cs   n 

i 

introduction

the goal of sentiment analysis is to classify text samples according to their overall positivity or negativity 
we refer to the positivity or negativity of a text sample
as its polarity  in this project  we investigate three class
sentiment classification of twitter data where the labels
are positive  negative  and neutral 
we explore a number of questions in relation to the
sentiment analysis problem  first  we examine dataset
preprocessing specific to the natural language domain of
tweets  we then evaluate a number of baseline linear
models for sentiment analysis  finally  we attempt to
improve on the performance of our baseline models using neural networks initialized with linear model weights 
all the algorithms we consider in this project are supervised methods over unigram and bigram features 

ii 

honey badger and jordan jefferson both got arrested
for pot possession for the  rd time  hes out for good
 fuckkkk  herbaddiction

dataset collection

we evaluate the performance of our classifiers on a test
set derived from two hand labelled twitter sentiment
datasets   i  the semeval      task   b dataset       
examples         and  ii  the sanders analytics dataset of
product reviews on twitter        examples        from
the combination of these two datasets  we hold out a test
set of       tweets  the class distribution in the test
set is     positive       neutral and     negative  the
remaining tweets from the combined dataset are used as
a training set  which we refer to as the base training
set 
to study the effect of additional training data on performance  we create a second  augmented training set
by combining the base training set with labelled data
from both in domain and out of domain sources 
 the stanford sentiment treebank data         
examples   a sentiment dataset consisting of snippets from movie reviews     
 tweets from news sources         examples      
 tweets from keyword search         examples      

yay     rt kellymonaco   excited to interview the new
cast of dwts tonight for e news  they have no idea
what their in for   
i went to the marijuana march  but i do not remember
what happened there 

fig     sample tweets from base training set 

protesters  anti riot police in egypt clash near a cairo
university  http   t co ohvtgqijre  ns
breaking  us national hurricane center says
tropical storm raymond has formed in pacific south of
mexico 
oklahoma city thunder will rebuild school basketball
courts in moore  okla   devastated by tornado 
http   t co cngfapdytz  ss

fig     sample tweets from news sources  labelled neutral  

in total  the augmented training set contains        
examples  the first three datasets contain labelled positive  neutral and negative examples  we assign all examples drawn from news sources a neutral label  the tweets
retrieved from search queries with positive polarity are
labelled positive  and the tweets retrieved from search
queries with negative polarity are labelled negative 

iii 

preprocessing

we first investigate the effect of various preprocessing on classification accuracy  the baseline preprocessor strips all nonalphanumeric characters from the text 
we test the following additional preprocessing steps in
a cumulative fashion   i  preserving punctuation symbols  deduplicating and adding whitespace around punctuation   ii  preserving emoticons and adding whites 

fi 
v 

rt  deaddollsclub  things look seriously delicious
down here   kimchi  amazing  galbibros
http   t co fcgqziaexf
tickets go on sale in    mins    hardwell
 fingerscrossed  awesome  needneedneed
http   t co jkztryeury
im about to smash my phone up  mattyotbc style
 angry  needupgrade  pieceofshit

fig     sample tweets from keyword search  labelled based
on polarity of search term  

base
 punct special
 emoticons
 urls
 numbers

train
    
    
    
    
    

test
    
    
    
    
    

change
   
    
    
    
    

table i  effect of preprocessing on classifier accuracy

pace around punctuation   iii  replacing user references
with a generic token   xyz  huseri    iv  replacing
urls with a generic token   v  replacing numbers with
a generic token   vi  using stemmed tokens 
for each additional preprocessing step  a logistic regression classifier  with regularization parameter c  
     is trained on the bigram features derived from the
preprocessed text  the preprocessing steps that yielded
improvements on test accuracy are listed in table i  user
reference replacement and stemming yielded lower test
set accuracies  the improvement realized by the emoticon handling step is reflective of the importance of emoticons as lexical features in this domain  in the subsequent
analysis  we use the full set of preprocessing options that
yielded improvements in accuracy 

iv 

model evaluation

we use two performance metrics for model evaluation 
 i  the percentage of correctly labelled examples  and  ii 
the average of the f  scores for the positive and negative
classes  f    fpos   fneg      where as usual fc is the
harmonic mean of the precision and recall for class c 
note that even though this f  score is only an average
of the f  scores for the positive and negative classes  an
incorrect labelling of a neutral example will still hurt
the precision of the positive or negative class  and would
therefore impact the overall f  score of the classifier 

baseline models
a 

linear models

we set performance baselines using the following algorithms  logistic regression  logreg   multinomial naive
bayes  mnb   support vector machine  svm  with the
linear kernel  and the naive bayes svm  svm       for
these algorithms  we let c  r denote the inverse l 
regularization strength 
we now give a brief description of the naive bayes
svm algorithm 

b 

naive bayes svm  nbsvm 

the naive bayes svm is a simple but surprisingly effective method for text classification  achieving state ofthe art performance for a two class sentiment classification task on a large dataset of   k imdb movie reviews
    using only bigram features      in      a version of the
nbsvm for two class classification is described  here
we give a natural generalization of the method to the
multiclass case   
   classes  
let f  i          v   be the binary feature occurence
vector for the ith example  where v is the set of fea i 
tures and fj     iff feature vj occurs in the example  forpeach class c  define the count vector pc as
pc     i y i   c f  i    where  is the laplace smoothing
parameter  for the mnb and nbsvm algorithms  we
take       for each class c  define the log likelihood
ratio vector rc as 

rc   log

pc  kpc k 
   pc  kpc k 


 

   

for each class c  train a one vs rest linear svm sc  x   
wct x   bc on the set of feature vectors  f  i   rc    where
wc is the weight vector for class c  bc is the bias term 
and  denotes the elementwise product  following     
we interpolate between mnb and svm for each class 
w  c        wc   wc  
b c   bc

   
   

where wc   kwc k    v   is the mean magnitude of wc  
t
and           let s c  x    w  c x   b c   given example x  the nbsvm classifier returns the prediction
y   arg maxc  s c  x    we also consider the possibility of
omitting the bias term by training svms that do not fit
an intercept  for this version of the nbsvm  omit the
terms bc and b c in the above description 
in our experiments  we use         

fi 

output  

 

each i      g  and j         i      the weight of the con c 
nection between hi and the input unit x i  is given

 

j

by  wc   i    in other words  connect each input unit
j

  hidden unit
per class
per group

hidden

input
random partition into feature groups

fig     example neural network structure for   classes   
features and   feature groups per class  bold nodes and connections correspond to one feature group  connections with
weights that are initialized to zero are omitted from the illustration but are not constrained to remain at zero 
vi 

neural network models with
linear model initialization
a 

b 

description

neural networks initialized using weights derived from
linear models have been shown to exhibit good performance on a variety of classification tasks  often improving on the linear model on which it is based      here we
give a description of this class of neural network models
which  in effect  act as meta algorithms over their base
linear models 
  

structure

let n be the number of classes and let g       v    be
a parameter that denotes the number of feature groups
per class  the number of hidden units is given by the
product gn  and the number of output units is n  the
output of the network for an input x is 
s x    wo tanh wh x   bh     bo  

   

where wo is a ngn matrix  wh is a gn v   matrix  bo
is a vector of dimension n and bh is a vector of dimension
gc  s x  is a vector of scores for each class for a given
example x  let sc  x  denote the score assigned by the
network to class c for the example  the predicted class
y is y   arg maxc sc  x  
  

to each of the n hidden units corresponding to its assigned feature group using the weight assigned by the
linear model  the remaining input hidden weights are
initialized to zero 
the connection between each hidden unit and its corresponding output unit is initialized with weight   g 
the hidden biases bh are initialized with the the intercept terms fit by the linear model divided by g  if the
linear model has no intercept terms  then this is initialized to zero   and the output biases bo are initialized to
zero 
for logistic regression  svm and nbsvm  the weights
are initialized using the raw linear model weights  for
mnb  we stack the weight vectors rc   then subtract the
mean and normalize by dividing by the component with
the largest absolute value 
in our experiments  we use g      

initialization with linear model weights

let  w            w v     be a set of weight vectors derived
from a linear model  let                   g    be a random
partition of the set of feature indices                 v    into
g equally sized groups 
the initialization scheme is illustrated in fig     for
 c 
 c 
each class c  associate g hidden units  h            hg    for

  

training

gradient descent methods

the neural network is implemented using the theano
library in python      neural networks trained on the
base dataset are optimized using minibatch sgd  batch
size     with adagrad     and an initial learning rate
of        for networks trained on the much larger augmented dataset of     k examples  we use minibatch
sgd with a fixed learning rate of      in the interest of
computational speed 
we use the multiclass hinge loss as the cost function 
m

j wh   wo   bh   bo    

  x
max   y  i     c 
m i   c

   

sy i   x i      sc  x i     

   

backpropagation training is performed for    epochs 
and the highest test accuracy over these epochs is reported 
  

feature dropout

random feature dropout     during training has
yielded significant improvements in neural network performance in several classification tasks by preventing
overfitting on groups of features  though dropout training yields improvements for some text classification tasks
     for this sentiment classification problem we did not
observe any gains from input or hidden layer dropout
during training  the following results are derived from
networks trained without random feature dropout 
we conjecture that feature dropout does not help
much in this task since the feature representations of

fi 
base
augmented
method
accuracy f  accuracy f 
logreg
           
           
mnb
     
     
     
     
svm
     
                 
     
     
     
     
nbsvm  
nbsvm
                 
     
nn logreg
     
     
           
nn mnb
     
                 
                 
     
nn svm
nn nbsvm      
     
     
     

positive neutral negative accuracy    
positive    
   
  
    
neutral    
   
  
    
  
   
   
    
negative
table iv  confusion matrix for nn initialized with mnb
weights  rows are labeled with gold labels and columns are
labeled with predicted labels 

vii 
a 

table ii  results on twitter sentiment test set  the top
result from each column is underlined  and the secondhighest result is in bold  all classifiers use bigram features  logreg  c      svm  c         nbsvm 
c                  nbsvm    nbsvm without intercept
fitting  nn  neural networks initialized with linear model
weights  using g      feature groups per class  nn logreg 
c       for logreg classifier  nn svm  c       for sv m
classifier  nn nbsvm  c                
positive neutral negative accuracy    
positive    
   
  
    
neutral    
   
  
    
negative
  
   
   
    
table iii  confusion matrix for logistic regression  rows
are labeled with gold labels and columns are labeled with
predicted labels 

tweets are already extremely sparse in the feature space
induced by the very large augmented training set  so
that overfitting due to feature co dependence is already
unlikely 

c 

results

the results of our experiments are listed in table ii 
after a few rounds of backpropagation training  the nns
initialized with mnb and nbsvm weights achieve accuracies that improve significantly on the accuracy of
the linear classifiers  though a nn initialized with
nb weights and trained on the augmented training set
achieved the highest test accuracy  logistic regression still
achieved the highest f  score  our experiments indicate
that with proper tuning of the regularization parameter  logistic regression offers a combination of speed and
good classification accuracy in this task when compared
to other classifiers using bigram features 
tables iii and iv show the confusion matrices for the
logistic regression and nn mnb classifiers trained on the
augmented training set  we can see that the distributions of predicted labels are similar for the two models 
notably  both models perform very poorly when classifying negative examples  with a tendency to classify
them as neutral 

discussion

limitations of bigram features

bigram features fail to capture the sentiment expressed by semantic information in the text beyond
individual word or individual bigram polarities  for example  both the logistic regression and nn mnb models predict that the following example is negative  the
correct label is positive  
idc if tomorrow decides to be a shitty day im
gonna make it the best goddamn day ever   determined
the word best slightly biases this example towards
positive  both models assign positive a higher score
than neutral   but this is presumably outweighed by
the negative polarity of shitty and goddamn  the
key to this example is to recognize that the structure  i
dont care  if     negates the negativity of shitty day 
but neither model is able to take this information into
account 
an interesting path of further investigation would be
to assess the performance of compositional distributional
semantic models  cdsms         on this dataset  these
models are able to capture compositional semantic phenomena such as amplification  attenuation and negation
of sentiment due to modifying adjectives and adverbs 
we expect that these models should perform better on
hard cases such as the example given above 

b 

ambiguity of aspect specific examples

our classifiers also have difficulty with examples that
express conflicting aspect specific sentiment  for example  the following example  again positive mislabelled
as negative  expresses conflicting sentiment regarding
pcs and macs 
so  i am using my work pc  never ever  to
get a feel for it  it has the worst speakers ever   apple
you have spoiled me    imamac
both classifiers assign extremely high scores to the
negative class for this example and fail to recognize

fi 
the positivity expressed with respect to apple products 
this is probably due to the ambiguity of spoiled and
the failure to understand the out of vocabulary token
imamac  a complex task that requires both morphological parsing and understanding of the expression im
a mac  
another misclassified example with conflicting aspectspecific sentiment is the following 
max might have to get put down tomorrow    
absolutely heart breaking if i have to see my puppy
go  love you maxy x pic twitter com lyhvhl f
here the confusion is due to the word love  which
has a positive polarity that should be negated by the
context 

c 

out of domain data yields improvements

recall that we augmented our base training set of
tweets with     k example from the stanford sentiment treebank dataset  even though this dataset was
derived from a corpus of movie reviews  its inclusion
in the training set still yielded improvements in clas 

    s  wang and c  d  manning  in proceedings of the
  th annual meeting of the association for computational linguistics  short papers volume    association
for computational linguistics         pp       
    a  l  maas  r  e  daly  p  t  pham  d  huang  a  y  ng 
and c  potts  in proceedings of the   th annual meeting
of the association for computational linguistics  human language technologies volume    association for
computational linguistics         pp         
    r  socher  naive neural networks for very fast and accurate text classification  private communication        
    j  bergstra  o  breuleux  f  bastien  p  lamblin  r  pascanu  g  desjardins  j  turian  d  warde farley  and
y  bengio  in proceedings of the python for scientific
computing conference  scipy          vol    
    j  duchi  e  hazan  and y  singer  the journal of machine learning research                     
    g  e  hinton  n  srivastava  a  krizhevsky 
i  sutskever  and r  r  salakhutdinov  arxiv preprint
arxiv                  

sification accuracy on the test set  the improvement
is significant  a logistic regression classifier trained on
the augmented training set with treebank data excluded
achieves a test accuracy of         while the test accuracy achieved after training on the entire augmented
training set is         an improvement of       training on the treebank data alone gives a test accuracy of
        so it is indeed the combination of the datasets
that yields the observed improvement 

viii 

conclusions and further work

we find that a complex neural network classifier
achieves only modest improvements over logistic regression and a linear svm  with each tweet represented
as an extremely sparse feature vector  it appears to be
the case that neural network models are not well suited
to classifying short text samples using bag of words features 
a clear avenue for further investigation is to compare
the methods discussed in this project with the parse treebased models described in           and      these models
should be better able to leverage semantic information
in classifying difficult cases such as those described in
sec  vii a 

    t  nakagawa  k  inui  and s  kurohashi  in human language technologies  the      annual conference of the
north american chapter of the association for computational linguistics  association for computational linguistics         pp         
    r  socher  j  pennington  e  h  huang  a  y  ng  and
c  d  manning  in proceedings of the conference on empirical methods in natural language processing  association for computational linguistics         pp         
    r  socher  a  perelygin  j  y  wu  j  chuang  c  d 
manning  a  y  ng  and c  potts  emnlp        
     http   www cs york ac uk semeval      task  
     http   www sananalytics com lab twitter sentiment 
     http   nlp stanford edu sentiment treebank html
     from the following sources  ap  bbctech  bbcworld 
reutersbiz  reuterslegal  reutersscience  reuterssports  ftfinancenews  nytimes  nytimestech 
     from search queries for pre selected keywords with positive and negative polarity 

fi