predicting malicious users on anonymous chat
networks
tsung chuan chen  chieh ho and augustus hong  stanford university
abstract malicious users on chat network systems would
reduce the willingness of benevolent users to chat on the same
network  thus it is often desirable to classify malicious users
based on their personal profile and chat contents  in this study 
different algorithms including naive bayes  svm  decision
table  multilayer perceptron  and logistic classification are
applied on the dataset from an anonymous chat network
chatous  it is found that by using both empirical features and
chat word features together with the svm algorithm  the best fscore achieved is        this result shows the possibility of
classifying malicious users from benevolent users on a chat
network and may lead to chat quality improvement such as by
restricting malicious user from chatting with benevolent users 
keywordsmalicious users detection  word feature extraction 
support vector machine  machine learning  chat network 

i  introduction
chatous is a text based    on   anonymous chat network
that has seen     million unique visitors from over    
different countries  users can create a profile that contains a
screen name  age  gender  location  and a short free form
 about me  field  interactions on chatous include exchanging
messages  sending accepting a friend request  reporting an
abusive user  ending a conversation  since the network is
consisted of completely anonymous users  it is therefore
important to be able to distinguish between different kinds of
users 
some users come to chatous to find friends and have
quality conversations  while others might try to use the
platform in a way that violates its policies  malicious users
might verbally harass other users  or try to steal other users
personal information  and thus identifying such users can
greatly improve the user experience of the chat
network  machine learning techniques will be used to classify
benevolent and malicious users based on the data set that is
provided by chatous  and with the developed models 
malicious users can be identified based on his her chat
contents  age  conversation length  and many other attributes 
ii  data sets
the dataset provided comes in two parts  the first part is
  million conversations and the second part is     million
profiles  preprocessing has been done on these input files to
extract features  and the attributes of the datasets are listed in
table i 
but since there is no actual answer to who the malicious
users are  different methods are used in labeling benevolent
and malicious users  one point to note in this dataset is that
there are two different base entities  one is the user id and the

other one is profile id  each user can have multiple profiles
to chat with different people  while they can only have one
user account  say  user id  it is found that the accuracy of
detecting against bad profiles is significantly higher than
detecting against bad users 
the approaches taken to label malicious and benevolent
users include      label all user id which has been reported
once as malicious users      label all profile id which has
been reported once as malicious profiles      label all profile
id which has been reported more that the average number of
reports as malicious profiles 
table i
datasets
chat data

user profile data

chat id

profile id

profile id

location

timestamp

profile introduction

user id

age

reported id

gender

disconnected person
word vector

iii  approaches
a  features selection methods
the provided data sets are as described in ii  and two set
of features will be selected using the empirical features
selection method and the word vector processing features 
    empirical feature selection
several features are obtained from the two databases 
profile and chat heuristically  and the selected features and
how they are selected are both described in table ii 
    word vector processing features
to get a deeper understanding about the difference of
specific words used between malicious and benevolent users 
the word vectors of all chats are examined  in particular the
word frequency method  which is similar to the document
frequency  df  method      is used to extract this feature 
word frequency is the number of tokens that occurs in all
chats  specifically in this method  all stop words are excluded
in the word vector since they wont provide meaningful
information  then it counts the frequency of occurrence of
every word  and the basic assumption is that the fewer times

fitable ii
empirical features
features
age

raw data given from profile dataset

gender

raw data given from profile dataset

profile length
number of chats

the length of about me section
the total number of chats of the user

total word vector length

the total words that the user has typed
throughout all conversations

total disconnected
number

the total number that the user actively
disconnected the chats

total line number

the total lines that the user has typed
throughout all chats

total min
percentage of
disconnected

average words per
minute

the average words per minute of the user

average words per chat

the average of words of a chat of the user

prediction by naive bayes
the total distinct words that the user has
typed throughout all conversations

percentage of the most
frequent word

the times the most frequent word occurs
divided by total words

difference of frequent
word

the difference between the most frequent
word and the second frequent word

the word occurs  the fewer information of classification the
word could offer  in the subsequent experiments  the top     
         frequent words are selected as the features
respectively 
b  classification methods
    support vector machine
support vector machine  svm  is known as a non linear
classification method by using kernels to map data with finite
dimension of features to higher dimensional feature space 
and the primal optimization problem of an svm can be
modeled as 
     



   

    nave bayes
in addition to svm  malicious and benevolent
profiles users are also classified with the naive bayes event
model with laplace smoothing  with the naive bayes model
as the baseline  one will be able to see how well other
algorithms are doing  the word vectors in the conversations
are used as classification features  and the models are trained
with our own implementation of naive bayes algorithm in
python  as well as using the off the shelf implementation in
weka      both models have converged to similar result 

the percentage of chat with different
gender user

word real length

 

 where
is the bandwidth of the kernel  by using the
gaussian kernel  the features are mapped to infinite feature
dimensions space  the value of gamma should be carefully
tuned  if overestimated  the exponential will behave almost
linearly and the higher dimensional projection will start to
lose its non linear power  on the other hand  if underestimated 
the function will lack regularization and the decision boundary
will be highly sensitive to noise in training data  and the
libsvm library     is used for implementing svm in this
study 

the percentage of chat that is actively
disconnected by the user
the average of lines of a chat of the user

naive bayes

 

the total minutes of all chats of the user

average lines per chat

different sex percent

  where c is the soft margin parameter  the parameter c can
also be a regularization term  which provides a way to control
over fitting  as c becomes large  it must respect the data so as
to reduce the cost of reducing the geometric margin  when it
becomes small  it is easy to account for some data points with
the use of slack variables and to have a fat margin placed so it
models the bulk of the data 
there are generally three types of kernels  which are the
linear kernels  polynomial kernels and the gaussian kernels 
in this study  the gaussian kernels are chosen for the
malicious users classification problem  the gaussian kernel is
defined as 

descriptions

   

    multilayer perceptron    
a multilayer perceptron  mlp  is a feed forward artificial
neural network model that maps sets of input data onto a set of
appropriate outputs 
    decision table    
decision tables  like decision trees or neural nets  are
classification models used for prediction  they are induced by
machine learning algorithms  a decision table consists of a
hierarchical table in which each entry in a higher level table
gets broken down by the values of a pair of additional
attributes to form another table 
    logistic regression
logistic regression is an algorithm that utilizes the
logistic function and a bernoulli random variable to classify
input samples 
c  experimental setup

fithe system block diagram of this study is shown in fig    
the results are as shown in fig    from the figure  the
after labelling the data  the performance of different feature profile based labeling is better than the user based labeling by
selection methods and learning algorithms will be evaluated 
      this improvement might result from that users may
have different behaviors when chatting with different profiles 
if the labeling method is user based  a lot malicious profiles
may be counted that dont perform malicious behavior but still
be marked as malicious profile just because the user has one
other profile classified to be malicious one  hence  it may be
more accurate if determining with respect to profiles  on the
other hand  the f score improves    when the threshold of
reported time based on profiles is set to more than the average
reported times  approximately        this significant
improvement may due to the reason that when setting the
threshold to be larger than the average reported count  the
likelihood of a labeled user being an actual malicious user
increase  nevertheless  it should also be noted that if the
threshold for reported times is set too high  some malicious
users may not be identified correctly 
as a consequence of this result  the malicious users will
be defined as profiles with reported times larger than the
average reported times        in subsequent experiments 
fig    the system block diagram

 

iv  results
for all experiments  f score is chosen to assess the
performance of different learning algorithms and feature sets 
where f score is defined as 

f score is preferred to the accuracy since it is equally
important in this problem to have high recall and precision
rates  also  the f score are examined using cross validation
method with the fold number being    in all experiments 
a  comparison of different labeling approaches
one of the ambiguities in this data set is that there is no
gold standard for the labeling of data  therefore a few
labeling methodologies are proposed to address this issue 
first  as suggested by the provider of this dataset  the report
count could be an efficient indicator for labeling  users who
were reported often by other users are more likely to be
malicious users  second  on the chatous network  one user
may own more than one profile and can use different profiles
to chat with other users  and thus the reported times can be
counted either with respect to the users or to the profiles 
therefore  the performances of setting different thresholds for
the report count based on either users or profiles are evaluated 
specifically  there are three different labeling settings in this
experiment  which are reported at least once based on user id 
reported at least once based on profile id and reported more
than the average times based on the profile id  where the
average reported times is approximately       and since this
experiment focuses on the comparison of different labeling
approaches  only the svm algorithm with empirical features
is used in this study 

   
    

f score

   

svm  profile id  reported times   average
svm  profile id  reported times    
svm  user id  reported times    

    

   
    
   
    
   
    
   

 

    

    
    
training set size

    

     

fig    the result of using different labeling approaches

b  nave bayes and svm classification using word features
in this experiment  naive bayes and svm classification
are implemented to classify users by their chat contents 
nevertheless  since the total number of words in chats
approaches several tens of thousands  learning with all the
words as features would be inefficient  as a result  feature
selection is needed to reduce the total feature number  for
both the naive bayes and the svm method  the word
frequency  wf  method is implemented to select a subset of
word vectors  which appear more frequently  as the features 
    naive bayes chat classification
naive bayes text classification is implemented to classify
the word features of chats in order to determine whether the
user is malicious  the features number are set to be         
and     using wf method for feature selection  and the
training set sizes for each feature numbers are            
     and      respectively 

fithe results of the naive bayes chat classification are
shown in fig    it can be seen from the figure the best
achieved f score is       with feature number equal to    
and with      training sets  and the f score is affected by
changing the training set sizes  however  the total numbers of
features have limited effects on the results from the figure 
    svm chat classification
svm classification is implemented to classify the word
features of chats in order to determine whether the user is
malicious  the features number is set to be          and    
using the word frequency method  and the training set size for
each feature numbers are                  and     
respectively 
   
nb  feature number      
nb  feature number      
nb  feature number      

    

besides using the word vectors as features  empirical
features are calculated as described in ii b  additionally 
different learning algorithms are implemented with these   
empirical features  the learning algorithms include naive
bayes  decision table  multilayer perceptron  and logistic
classification  and it is found that the svm algorithm has the
best performance         for this learning problem  the
performance of the decision table algorithm  which is       
is also comparable to that of the svm algorithm  despite that
the result of the naive bayes algorithm decreases to be lower
than      the svm  multilayer perceptron  decision table
and logistic algorithms all have f score larger than     
which are better than the result of classification using the chat
contents as in iv a 
d  different learning algorithms on empirical features
combined with word features
in this experiment  the empirical features and the word
features are combined together for user classification  it is
found that the performance for the combination of two kinds
of features is better than using either of the two kinds of

   

f score

c  different learning algorithms on empirical features

    

   

    

   

 

    

    

    
    
training set size

    

    

    

fig    naive bayes classification by using word features

the result of svm text classification is shown in fig   
the best f score is       when the feature number is     
which is      higher than the best result of naive bayes  it
can be seen from fig   that the f score for all training set size
ranges from     to        as opposed to the results of using
naive bayes  the f score increases as the feature number
becomes larger  this difference may be due to that the svm
has mapped the original feature space to higher dimension 

fig    result of different learning approaches

 
svm  feature number      
svm  feature number      
svm  feature number      

    
   

f score

    
   
    
   
    
   
    
   

 

    

    

    
    
training set size

    

    

fig    svm chat classification with selected features

    

fig    result of combination of empirical features and word
features

fifeatures alone  the best performance it can achieve is      
with training set size being         however  the difference of
adding the word features to the empirical features is slight 
one possible reason for this result is that the empirical
features have already contained similar information in added
word features 
the summaries of the all the experiment results are
shown in table   
table iii
summary of results
method

feature sets

f score    

nave bayes

    word features

    

svm

    word features

    

nave bayes

   empirical features

    

logistic

   empirical features

    

multilayer perceptron

   empirical features

    

decision table

   empirical features

    

svm

   empirical features

    

svm

   empirical features
and     word features

    

v  discussion
the labeling method used for malicious users depend on
the reported counts of users  the reported count is thought to
be a good measure to separate different kinds of users because
it is a measure of how malicious a user can be  even if the
reported count doesnt directly reflect who the malicious users
are  it is still considered reasonable to separate those who are
more prone to be reported with those who are not  the
significant improvement in f score when the labeling method
is switched from one report count threshold to average report
count  also shows that the selected features have a high
correlation to the reported counts  one way to improve the
accuracy of classifying malicious users is increase the report
threshold  but if the report threshold is increased too much 
actual malicious users may be omitted when during
classification 
one possible reason why the chat content classification is
not effective may result from that the word features are sparse 
that is  not all the chosen word features would occur in the
chats of users  additionally  natural language processing
algorithms are not yet used to investigate the relationship
between word vectors  only the statistics of word features is
taken into consideration  thus  the performance of chat
content classification may be limited  another reason that this
approach is ineffective might be due to that a lot of profiles in
the given dataset dont even have a chat with others  thus
when classifying those profiles word vectors wouldnt supply
enough information 
in the study  it is found that the empirical features are
very effective even without additional word features  this
may due to that the empirical features selected have already
contained the information of the word vectors  the other
possible reason may be that its already become a high

variance problem  so that adding more features may not
improve the result  one possible solution to this problem
would be trying to increase the training set sizes 
there are many possible variations of this study that can
be explored to seek performance improvement  natural
language processing algorithms could have been applied on
the word vectors to extract more meaningful features  also
treating the profiles users as nodes in a social graph might
provide more insight to the relationship between benevolent
and malicious users 
vi  conclusion
in this study  different algorithms and features sets are
evaluated for the classification problem of the users in the
chatous network  it is found that the empirical features
combined with word features selected by the wf method with
svm learning method can give the best prediction result for
chatous network 
since current chatous network system randomly pair the
users for chat  one possible application of this result may be
using the method to classify malicious users and benevolent
users and pair only the benevolent users together to improve
the chats qualities  and this approach may be used by other
random chat systems as well 
vii acknowledgement
we want to thank kevin kuo from chatous for providing
us the dataset as well as giving us guidance on how to
interpret the data 
viii  reference
    chih chung chang and chih jen lin  libsvm   a library for support
vector machines  acm transactions on intelligent systems and technology 
                    
    mark hall  eibe frank  geoffrey holmes  bernhard pfahringer  peter
reutemann  ian h  witten         the weka data mining software  an
update  sigkdd explorations  volume     issue   
    yang  yiming  and jan o  pedersen   a comparative study on feature
selection in text categorization   icml  vol           
    gardner  m  w   and s  r  dorling   artificial neural networks  the
multilayer perceptron   a review of applications in the atmospheric sciences  
atmospheric environment                            
    becker  b   research report  visualizing decision table classifiers  
information visualization           

fi