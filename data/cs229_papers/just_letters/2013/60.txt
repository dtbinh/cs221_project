rank restricted full configuration interaction
nick f  settje and james w  snyder jr
i  introduction
configuration interaction is a widely used method in electronic structure theory for optimizing a
wavefunction by minimizing the energy of the time independent electronic schrdinger equation  which
is the standard way to determine the energy of a quantum system  the wavefunction  which determines
all properties of a quantum system  can be expressed as 
   

      
 

which is a linear combination of n electron configurations  or determinants  with coefficients equal to    
the components    form an orthonormal basis of the wavefunction  the determinants are the set of
features that comprise the wavefunction  so we can optimize them by minimizing the electronic energy 
to determine the energy of the wavefunction c  the schrdinger equation in matrix form reads
h    
where h is the hamiltonian matrix with elements             e is a vector containing the energy of
each configuration  and c is the vector containing the ci coefficients  a detailed account of the origin of
the determinants that comprise c as well as that of the hamiltonian operator    are beyond the scope of
this paper  however  it is important to note that each matrix element of h is an integral that can be
readily computed 
if the above expansion includes every possible configuration of electrons allowed given a basis
set of finite size  then this is known as full configuration interaction  fci   fci is the best possible
approximation to the schrdinger equation  as the number of determinants approaches infinity  fci will
approach the exact solution to the schrdinger equation  because one must compute every possible
configuration of electrons  the above eigenvalue problem scales as      since there are n 
configurations of n electrons  this means fci is intractable for anything besides trivially small systems 
for additional information on the fundamentals of electronic structure theory  refer to     and     
for a thorough treatment of fci  consult     
ii  solving full ci by gradient descent
our implementation of fci is based upon the graphical unitary group approximation for string
based fci      the full details of this implementation are largely beyond the scope of this paper  in
simple terms  the standard method is to compute various integrals  build the matrix elements of our
hamiltonian h  evaluate the product hc  and iterate over this procedure until convergence of the c vector
for each eigenstate of h  because h is a matrix of dimension       we build hc implicitly without ever
representing h  even without these extra storage requirements  fci remains exceedingly expensive 
luckily  optimization of the fci wavefunction benefits greatly from machine learning
algorithms  the wavefunction coefficients can be optimized using gradient descent  since the objective
of fci is to minimize the electronic energy of the wavefunction  the gradient descent rule for fci is
            
where

fi 

      

    
 
            

if one takes the gradient with respect to    
      

   

    

            
      

      

    
      

  
 
   

  

   

     

    
 

c        
   
   

where      this gives us the update rule 
       
since

 
   

  
  
   

  

c        
   
   

 

   for a normalized wavefunction  this update rule can be rewritten as
       

  

c    
 

   

  
 


where n is the number of eigenstates being solved for  the update rule only depends on c and   so this
method does not require extra memory beyond what we would already use to represent these vectors  this
is especially beneficial because of the difficult scaling of fci  where extra intermediates simply would
not fit in core for larger molecules 
admittedly  better methods for converging the c vectors exist than simple gradient descent 
however  all of these methods introduce extra structure into the c vectors after each iteration  as they
involve diagonalization of sub hamiltonians in subspaces of the set of determinants  this makes no
difference in regular fci  but it can cause problems if we try to factor our c vectors to reduce the scaling
of the problem 
iii  rank restricted full ci
we justify the use of gradient descent by observing that the converged c vectors for fci are
exceedingly sparse  this motivates exploiting the string based method for writing c vectors as matrices
indexed by   up spin  and   down spin  electrons  as
shown in figure    the relative sparsity  percentage of
non zero matrix elements of c compared to the set of
determinants with the densest c matrix  of such
matrices decreases as the size of c increases  in this
plot  we see a sharp drop in non zero elements near the
phase transition  
the sparsity of such a matrix allows for a
cholesky like decomposition 
    
fig     logistic fit of relative sparsity for increasing
number of determinants in fci for h   the sudden
drop in non zero elements motivates factorizing c 

       
 

where       for molecules with the same number

fiof  and  electrons  c is a square matrix  thus  the schrodinger equation becomes
        
effectively  this factorization asserts that the structure of c must depend largely on only a small
number of rows or columns  which we write as the rectangular d matrices  in the language of machine
learning  rank restriction is feature reduction  we assert that the bias introduced from considering a subset
of the features is negligible with respect to the accuracy of the factored model  fortunately  the structure
of the c matrices allows for decomposition without sacrificing much accuracy  this now motivates us to
derive some iterative scheme for converging d instead of c  since we require that d obey certain
structure  we want an algorithm that offers control over the imposed structure after each iteration 
gradient descent is just such an algorithm 
in terms of d  we write
 

      

       
 
            

where
        
given this  the gradient descent rule for low rank fci can be written as 
            
because this takes the exact same form as the full rank gradient descent rule  the solution is evident upon
inspection 
       

  

d         
 

   

      
 


these two iterative update algorithms constitute a set of machine learning algorithms  although
these algorithms specifically optimize the wavefunction to minimize the energy of the system  the
molecular wavefunction actually contains all information related to a molecular system  subsequent to
performing this optimization  it is possible to predict a variety of properties  from the dipole moment to
the ionization potential  using the set of optimized determinants  which are the features used to optimize
the energy  from the decomposition of c  we can write the full energy in terms of 
                   
so we only have to square the reduced energy to recover the energy of the full system 
iv  results
in order to perform rank restricted fci  it is necessary to select a value for  for use in building
  the goal is to choose a value of p large enough to capture almost all of the non zero elements of c but
small enough to give a significant speed up in calculation  as a rough measure of the information content
of c  we perform singular value decomposition on the c matrix and retain only as many rows or columns
of c as the number of singular values above some threshold  as shown in figure    the percentage of nonnegligible singular values decreases rapidly as the number of determinants increases  to determine the
extent to which this decreases the number of matrix elements we need to retain  we calculate the reduction
factor as the percentage of important singular values  this is the factor by which the number of
determinants would be multiplied to find the total number we need to retain  as figure   shows  the

fireduction factor reduces quickly as the number of
determinants increases  this means that we must retain
a smaller fraction of the determinants as their number
increases 
in order to determine the extent to which these
factorizations affect the energy  we compare the
energy of the rank restricted calculation to that for the
full rank computation  since we are interested in the
effect of restricting the size of d on the total error  a
natural measure of the efficacy of our model is the
fig     logistic fit of percentage of non negligible absolute error between the full and restricted models
singular values as number of determinants increase in divided by the reduction factor
fci for h   the sudden drop in important values
further motivates factorizing c 

   

              
 

where  is the reduction factor  intuitively  this
measures how well our model does as a function of the
rank restriction  this is apparent when we notice
lim     lim       

  

  

because d approaches c as the number of rows
retained approaches the entirety of c  which means that
the reduction factor approaches    since there is no
reduction in the number of matrix elements retained 
fig     logistic fit of percentage of matrix elements this means that we are minimizing the cost function
that probably must be retained as number of j p  as well as the reduction factor 
determinants increase in fci for h   the sudden drop
in number of retained elements further motivates
factorizing c 

p   argmin    s t       

where p  is the optimal p for reducing the number of
matrix elements retained and approximating the total
energy with the best accuracy  the constraint on p
follows from the fact that c has n  matrix elements  so
d has n p elements  so the total reduction factor is
 
     
 
as shown in figure    the absolute energy
difference per reduction factor j p  decreases as the
number of determinants increases  this means that the
rank restricted approximation has smaller error per
reduction for larger matrices that capture more of the
fig     logistic fit of error per reduction as number of
electronic
energy  the phase transition  is a lower
determinants increase in fci for h   the phase
transition gives a lower bound on the value of p   the bound on p   because of this  we expect to factor more
error decreases suddenly and approaches zero for large aggressively starting at calculations using more than
enough sets of determinants 
      determinants  this is rather small considering
that modern calculations use more than     determinants 
since on average we use roughly the square root of the number of determinants for a given
factorization  the scaling of the fci algorithm becomes      for approximations to within the
convergence tolerance of the full rank algorithm  this scaling may still seem rather abysmal  but in the

ficontext of chemistry it is the difference between calculating on water and calculating on the active site of
a biologically important protein 
v  future work
the results of this study focused on fci calculations of the small test molecule h   the most
important result to check now is whether the phase transition of factorization is independent of the
number of electrons  this is most easily accomplished by repeating this analysis for a larger set of
molecules with more electrons  such as the traditional test set of hf  bh  h o  and ch   if the
factorization approaches the same optimal value of p for all systems  this method would be extremely
useful for calculating fci like energies for molecules that are too large for regular fci 
since gradient descent requires a large number of iterations to converge  it is somewhat slow for
running rank restricted calculations  future implementations of rank restriction might consider choosing a
newton raphson update of the form
     

     

      

    

        
 e

since the hessian adds extra information about the topology of the energy surface without introducing
unwanted structure or reducing sparsity in the updated vectors  in some sense  the factor appearing before
the gradient is the optimal learning rate  so the curvature of the energy surface determines the speed with
which the algorithm converges 
moreover  factoring c into two d matrices is the simplest rank restriction but it may not be the
most accurate or the fastest to converge  future studies might consider other decompositions such as
ldl  in which the c matrices become
 
 
                   

    
   

   
         

 
   

where l is lower triangular and d is diagonal  though we must now optimize two matrices at the same
time  it may be that we must store and calculate fewer matrix elements overall to approximate regular fci
to high order 
vi  references
    szabo  a  and ostlund  n  s  modern quantum chemistry  introduction to advanced electronic structure
theory  mineola  dover publishing inc        
    helgaker  t   jrgensen  p     olsen  j  molecular electronic structure theory  chichester  wiley       
    sherrill  c  d  and schaefer  h  f  the configuration interaction method  advances in highly correlated
approaches  advances in quantum chemistry  academic press        volume     pages         
    turney  j  m   simmonett  a  c   parrish  r  m   hohenstein  e  g   evangelista  f   fermann  j  t   mintz  b 
j   burns  l  a   wilke  j  j   abrams  m  l   russ  n  j   leininger  m  l   janssen  c  l   seidl  e  t  
allen  w  d   schaefer  h  f   king  r  a   valeev  e  f   sherrill  c  d   and crawford  t  d  psi   an
open source ab initio electronic structure program  wires computational molecular science        
       

fi