what will be your favorite song 
let me tell you 
clement ntwari nshuti

steven soria  jr 

stanford university
cntwarin stanford edu

stanford university
ssoriajr stanford edu
abstract

previous efforts at predicting song popularity have often focused on music analytic features  such as properties of the waveform 
number of beats  etc   or on nlp analytics such as lyrics  sentiment  and keyword frequency  recent resurgence in related
research has shown some success  with conferences and challenges generating interest in applying machine learning strategies 
in this project  we explore combinations of both music analytic and qualitative features  as well as unsupervised feature
selection techniques  to improve upon prediction success  can the intrinsic properties of a song  such as frequent beats and
higher decibel levels  inform popularity  or are more qualitative features  such as danceability and similarity to other popular
songs  sufficient to produce a hit single  with our best feature set  the answer seems to be the latter  most effective were
features correlating current songs with other similar songs  and their respective popularities  using a weighted linear
regression model against the million song dataset  combined with a distortion matrix  we were able to achieve a final root
mean squared error  rmse  of       

  

introduction

ur motivation stems from the broader challenge
of predicting hit songs for some future time period  developing an understanding of how
predictor features themselves change over time with
respect to contemporary hit songs may drive models
that move beyond song prediction  and into forecasting
evolving genre preferences and musical tastes  the first
step  however  must be to build a reliable model for
predicting popular songs with features that provide insight into the notion of popularity itself  thus  we focus
on predicting song popularity through a combination
of supervised and unsupervised learning techniques 
to develop novel feature sets which attempt to exploit
the nature of what makes a  hit song  
an example of recent prior work  hit song once
again a science     also attempts to predict popularity 
but its focus is on united kingdom song data using
primarily music analytic features     popularity ground
truths are based on uk top    singles chart data    
for united states based data  we relied primarily on
the million song dataset  msd   like the prior citation 
this dataset also incorporates music analytic features
from the echo nest     however  the msd does not
directly include us sales data  which is more difficult
to obtain from public sources  rather it provides a  hotness  metric  which we use instead as our ground truth 
whereas the cited work predicts popularity for a specific year  our focus is on predicting popularity  period 
of which year is but a single feature  other compar 

o

isons  such as performance  are difficult due to lack of
specific metric details in the cited work 

  
    

methodology

data

the million song dataset specifies  for each song spanning from              such qualitative features as
artist familiarity  artist popularity  danceability  energy 
and song popularity  and quantitative features such as
artist location  year  loudness  and music analytic array features for bars  beats  segments  sections  tatums 
and so on  we developed a matlab infrastructure to
parse the one million msd data files into a feature
matrix  since our goal was to predict song popularity  within the broader motivation of modeling temporal changes  we filtered the data to ensure that both
year and song hotttnesss  hotness  features were strictly
greater than    the specifics of the hotness metric
are opaque  with msd providing real valued numbers
in         with only this filter applied  the number of
usable samples dropped to       
the msd has spawned a significant number of
derivative projects  last fm provides sqlite databases
which correlate msd songs with similar artists  a similarity score  and genre tagging data     we utilized the
mksqlite    extension to read sqlite data directly from
matlab  and correlate it with msd data  our infrastructure allowed us to interchange models  generate
features from database data as well as msd file data 
 

fiplot results  easily turn on off features of interest  and
track results from different test runs 
just as msd had proven to be sparse when filtering
for year and hotness  many other qualitative features
were also too sparse to be usable  we therefore had
to eliminate features such as artist latitude and longitude  energy  and danceability  samples were chosen
to equalize representation across the hotness spectrum 
into    bands of      increments  this was to ensure
adequate learning for all gradations of hotness  the
msd did not include songs with hotness less than      
and samples were sparse for hotnesses of      we allowed hotnesses of     anyway  with the intuition that
we might learn strongly associated features  the resulting feature matrix was then normalized  from this  we
randomly sampled our training and test sets according
to an       split  with the ability to re use the same
permutation from prior runs  to fairly compare performance among subsequent runs  the final sample size
for our best feature set was       

    

algorithms

weighted linear regression
in the early phases of our work we considered linear
regression and logistic regression  that choice was motivated by the fact that these two regression methods
allow to quantify the relevance of each feature through
a statistical analysis of the relevance of the parameters 
however  due to their poor performances  with rmse
of          we decided to use weighted linear regression instead  during our experiments  as described in
section   we saw that the results of weighted linear regression could be improved by introducing a distortion
matrix m in the computation of the weights  specifically for a test sample x and training sample x  i  we
compute the weight as follows  

  x  x  i     t m t m   x  x  i    
w i     exp 
   

 
 

   

by introducing the distortion matrix m  our goal is
to have distorted samples x   mx and x  i    mx  i 
such that if x is close to x  i  then their corresponding
hotnesses are also close  the learning of the optimal
distortion m was done using weinberger and tesauros
metric learning algorithm      motivated by our intuition that songs released in the same year have the
same hotness model  we also tried a modified weight
 i  

w i     w i    xyear  xyear  
 

where xyear is the release year of the song x and
         is a decay parameter optimized through
cross validation 

    

evaluation method

we considered two metrics for the evaluation of our
results   the root mean squared error  rmse  and accuracy  acc  defined as
acc      p  y  y        
i e  the probability of having an estimate y of the hotness that lies within     of the true value 

  

experiments

our experiments fell into two main categories  features
engineering and metric learning  for features engineering  substantial effort went into unsupervised feature
selection for music analytics  but the primary driver
of results improvements were from supervised feature
selection for mostly qualitative features 

    

features engineering

supervised
our first choice of features were simply the realvalued features from the msd for each song  artistid  sample rate  artist familiarity  artist hotttnesss  duration  end of fade in  key  key confidence  loudness  mode 
mode confidence  start of fade out  tempo  time signature 
time signature confidence  year  for the music analytic
array features  bars  beats  sections  segments  tatums 
terms  we simply converted them into a simple count
where  for example  the beats array size represents the
number of beats in a song  following this example 
even though we were unable to use the energy feature
due to sparsity  the number of beats in a song might infer an energy level  we reasoned that more beats might
imply a faster pace  and hence a more energetic song 
that perhaps was more appealing to a consumer than 
say  a slower song with fewer beats  as expected  this
initial  naive choice of features performed poorly  with
an rmse of       per sample  we also iterated over several choices for  and found that        consistently
provided the best results throughout the remainder of
our experiments 

fifigure    plot of predicted hotnesses for    test samples from our
baseline and best feature set  note how our best feature
set results in a curve which more closely follows the
actual curve 
   

actual
baseline
best

 
   

song hotttnesss

   
   
   
   
   
   
   
   

 

 

  

  

  

  

  

  

  

  

  

samples

the most substantial improvement came from the
intuition that  at any given time  popular songs tend
to be similar to each other  while song popularity can
vary by genre  the most popular songs tend to be of
student version of matlab
the same genre  using the last fm data
set  we extract
similar songs for a given song and correlated this with
the msd to get the artist  artist familiarity  and song
hotness for each similar song  typically  songs with
the highest similarity scores were by the same artist 
we allowed this since an artist with a hit song is likely
to generate additional interest as a result  increasing
the likelihood that existing songs in the artists catalog
might benefit from this exposure  as well as influencing listener acceptance of new songs by the artist  we
also selected the most similar song and its hotness
from a different artist  in the hope of capturing additional insight into popularity offered by this new artist 
generally  similar songs from unique artists had lower
similarity scores and so these features did not improve
results  however  using the song hotness from the top
two similar songs improved rmse substantially  by
      to       
we experimented with many different features  primarily qualitative  since music analytic features were
largely driven by unsupervised feature selection  as explained in the next section  such features included the
number of years an artist was represented from among
our usable sample set  the idea being that artists with
greater staying power in the industry were likely to
produce a higher number of popular songs  from this 
we also considered the total number of hit songs produced by an artist  where  hit song  was iteratively
defined as a hotness value greater than or equal to    
        and    percent  similarly  we defined features

that counted the number of unpopular songs as well 
where hotness was iteratively less than or equal to    
    and    percent  among music analytic features 
we considered the idea that many consumers decide
whether or not they like a song from    second preview
clips  therefore  whereas we had primarily worked
with total counts initially  we looked at first    second
counts instead  similarly  we looked at the sum of max
loudnesses across song segments from the first    seconds  as well as the average loudness over that same
   seconds  most of these features degraded rmse 
with some resulting in changes that were negligible 
among the permutations  we also tried removing our
best features  to see if the remaining features would
become more important  possibly yielding lower rmse 
they did not  with rmse returning to near baseline
levels 

unsupervised
the challenge with the array features in the msd
dataset is that they are of varying length for each
song  we focused our efforts on the loudness pitches
and timbre array features because of their close relation
to the musical content of the song  the loudness of
each song was interpolated on     equally spaced time
instants over the normalized song duration interval
        in order to reduce the dimension of the pitches
and timbre features  pca and k means clustering was
performed for these features on each song  specifically 
we computed the    principal components for each of
these features  tiled them by decreasing eigenvalue and
used the resulting vector as a feature  the choice of
   principal components was based on the result that 
on average     eigenvectors are necessary to describe
more than     of the energy contained in these array
features  additionnally we also computed    centroids
for the same features and tiled by decreasing order of
cluster density  the choice of    centroids was made
using sugar and james information theoretic approach
to unsupervised k means clustering     

    

metric learning

by using distored samples mx  i  we get a correlation
between    m  x  i   x   j     and   y i   y  j      see figure
   that was not as significant as in the non distorted
case  see figure     this resulted in a slight improvement of the performances as described in section   
 

fito the model  both resulted in worse performances 
figure     d histogram of the pairwise distances between songs
and the corresponding pairwise hotness differences  before distortion  there is no significant correlation between
   x  i   x   j     and   y i   y  j     

table    to try to reduce the high bias of the baseline system  we
investigated adding several features  the best improvements were seen after adding the hotness of similar songs
 sim hot  and introducing an optimal distortion matrix
 sim hot   dist  

baseline
sim hot
sim hot   td
sim hot   array features
sim hot   dist

rmse

acc

     
     
     
     
     

     
     
     
     
     

figure    adding the hotness of similar songs as a feature  sim
hot   decreased the rmse from       for the baseline to
       our interpretation is that this feature allowed us
to capture some part of the decision processes of the user
that are not solely based on the songs intrinsic musical
properties  these could be  for example  related to how
an artist markets their music  we can also see in this
figure    thanks to the distortion matrix m  a correlation befigure the slight improvement gained by using an optitween    m  x  i   x   j     and   y i   y  j     appears  this
mal distortion matrix m  which allowed us to decrease
slightly improved the performances of the wlr  as we
the rmse to        sim hot   dist  
will see in section   

  

results

as described in section    we considered two improvements from the baseline  first of all  due the high bias
of our baseline  see figure    the best fix was to find
additionnal features  we began by adding the hotness
of the two most similar songs as features for a song 
this resulted in a substantial improvement as summarized in table    row  sim hot    time decay   sim hot
  td   and the additionnal array features were added
 

time decay degraded the performance due to the
strong  and apparently incorrect  assumption that it
made on the model  as for the additionnal array features  we suspect their negative impact to be the result
of the curse of dimensionality  indeed  after adding
these features  we had a total of     features for approximately      samples  dimensionnality reduction
through pca only allowed us to reduce the number of
features to      the final improvement attempted was

fito introduce the distortion matrix described in      this
resulted in only a slight improvement to the rmse of
     
several other features were considered  as described
above  however their impact was insignificant 
the results of our best performing system are summarized on figure    it illustrates perfectly on one
hand the reduction in bias from the introduction of
the hotnesses of similar songs  and on the other hand
the slight improvement due to the introduction of the
distortion matrix 

  

the api set is relatively inefficient  given our time constraints  for mass feature generation and correlation of
results 
our ability to deliver substantive improvement over
initial results shows that there is still progress to be
made in song popularity prediction  given the availability of data sets from a variety of music projects 
finding insightful features that exploit both the structure and semantic of music itself  have the potential to
extend models like ours into more abstract and powerful machine learning systems that may someday tell us
what our favorite songs will be 

conclusions and future work

while our objective was to find a novel mix of qualitative and music analytic features that together improved
song popularity prediction  it turns out that our best
result is based on comparing popular songs to other
popular songs  one might consider this analogous to
looking for new songs by browsing the itunes  top 
lists  our best feature set  combined with a distortion
matrix  yielded an accuracy of        several percentage points higher than our baseline results 
despite the lack of contribution from the music analytic features we attempted  several data sets spawned
from peripheral msd projects have far extended that
variety of such data  an energy and danceability metric
might yet be created based on mining results from these
various data sets  indeed  the prevalence of data sets
focusing on specific areas of machine learning tasks for
music often had pieces of data that might have been
useful  but was infeasible given our time constraints 
other ongoing work is in sentiment classification of
songs themselves  primarily based on lyrics and title 
but some based on music analytic features as well  this
adds a unique dimension to the notion of popularity 
and how it might be informed by sentiment  or more
straightforward keyword and genre tagging features 
other data sets purport to include listener play counts
from sources such as itunes and online streaming sites 
though  a first glance at this data seemed too sparse
to be usable at this time  sources of error primarily
stem from use of the msd  derived from the echo
nest     the msd was created in december      and
has not been updated  its possible that mining the
echo nest directly  through its online api set  would
have reduced the sparsity problem  however  use of

references
    thierry bertin mahieux  daniel p w  ellis  brian
whitman  and paul lamere         the million
song dataset  in proceedings of the   th international
society for music information retrieval conference  ismir             
    tristan jehan and brian whitman  et al  the
echo nest  http   the echonest com   november      
    martin kortmann welcome to the project mksqlite 
http   mksqlite berlios de   august      
    yizhao ni  raul santos rodriguez  matt mcvicar 
tijl de bie        
hit song science once
again a science 
in proceedings of the
 th international workshop on machine learning and music  learning from musical structure
 mml       http   www tijldebie net system 
files mml     final pdf       
    yizhao ni  raul santos rodriguez  matt mcvicar 
tijl de bie  score a hit  http   www scoreahit 
com        
    kilian q  weinberger gerald tesauro         metric learning for kernel regression  in proceedings
of the eleventh international workshop on artificial
intelligence and statistics  aistats      puerto rico
    catherine a  sugar and gareth m  james        
finding the number of clusters in a data set  an
information theoretic approach  journal of the american statistical association     january          

 

fi