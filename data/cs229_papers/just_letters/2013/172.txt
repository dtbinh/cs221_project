classification of procedurally generated textures
emily ye  jason rogers
december         

 

to parse xml file   as an example  to generate a liquid looking texture you may use a perlin noise node
to specify the general shape and another its color and
combine them into a single image 

introduction

textures are essential assets for  d rendering  but they
require a significant amount time and artistic ability
to create  procedural texture generation has been a
mainstay tool often reached for by content creators to
mitigate this expensive task  these tools however  are
art forms in and of themselves and require a substantial
skillset to create  making these resources available to
a wider community requires an efficient way to catalog
and search existing and newly created textures  to aid
in such an endeavor  the ability to automatically classify and tag textures becomes an especially desirable
feature 

an unbounded number of textures  rich in complexity
and variety  can be described in such a manner  although beyond the scope of this project  automatically
tagging textures based solely on the nodal attributes
in the filters hints at exciting possibilities of employing
genetic algorithms to evolve textures in an evolutionary
manner without having to render them  which currently
is very time consuming  

our project investigates automatic image annotation
as applied to procedurally generated textures  unlike
other similar image classification projects  ours looks
not at the features of the resulting image but instead
focuses on the features used to describe its generation 
by having the ability to classify and tag texture generation feature sets  called filters from here forward  we
attain the ability to not only classify filters extremely
quickly but we are able to classify them before they are
rendered 

 

background

although there are several means of generating textures  one of the more common and most flexible is
a node based approach  in this scheme  nodes are chosen to transform  generate  or combine some aspect of
the image  color  height  alpha  reflectivity etc  and
then chained together into a tree or mesh like structure  fortunately  we found a popular texture creation
tool called filterforge tm that has open filter format
and several thousand community donated filters 

figure    an visual representation for each node  in
the filterforge editor gui

filterforge tm defines a collection of node types  on
the order of fifty consisting of mathematical operations 
perlin noise generators  ramps and patterns  and various transforms and blends   these nodes can be connected in a gui and saved as a filter  a somewhat easy

 

data collection

we began by downloading and rendering the entire community library of over      filters available for the filterforgetm
 

fiapplication  we created a website and database to help
parse the filter files  randomly generate the nodal parameters  and then invoke the command line renderer 
in concert with rendering  we extracted the chosen feature set from the xml file  normalized  and stored in our
database 

we then used our web interface to tag each image  we
entered     word descriptions for the first      organic
filters  using adjectives like colors or textures  and types
of objects  such as stone  wood  or liquid  these
tagged feature sets were used as our primary dataset
for training testing our classifiers 

feature selection filterforgetm allows for an unlimited number of nodes each with a wide variety of attributes and user tweakable controls  choosing  and
extracting  features proved to be both the most challenging and the most critical aspect of the project  in
the end  we utilized a method similar to that of text
classification in that we began with a simple count of
each node type in the filter  we then expanded the
features to include rendering hints  average color  and
some seemingly important features of the more common node types  our final feature set is as follows 

 

methodology

we approached image annotation as a multi label classification problem  in which input x  x  the set of all
input texture images  is mapped to n labels from a set
of disjoint labels or tags t   this is an expansion on
a multi class classification  which takes training input
marked with one label t  t where  t        and assigns
test input each with a label from t   the common binary classification model is a specialized case for t
    and n      we thus could divide our problem
into smaller multi class problems  and furthermore into
binary classification problems for simple but effective
modeling  we used a one vs all classification method 

 the total number of nodes
 the total number of each type of node for types 
 color  rgb  gradient
 perlin noise
 curves  levels  shapes 
 average roughness perturbation of noise
 average surface color
 lighting
 reflectivity metallic measures
these features were the most consistently varied and
valued  not just    among the textures  in addition  we
felt that they were a good approximation for the level
of complexity of each texture and averaged contributing values well 

figure    organic  artificial  other filters  left to right 

annotations  filter classification was done in two
manual stages  first  we simply segregated textures
into three primary categories  organic  defined as useful for texturing things which are not man made  stone 
earth  grass  dirt  etc   artificial  things such as cloth 
metal  upholstery   and finally other which were textures that did not appear to be useful for applying to
 d objects 
in all  we ended up with about      organic       artificial  and      other  because the next stage was
to manually tag each texture with a short description
we selected only the organic textures for consideration 
however  we used these overall classifications in our
analysis in order to determine a baseline feature set to
use 

light  grey  stone

water  streaked  rippled  blue

cracked  brown  stone

green  grass

figure    examples of tagged filters

 

ficreate  t   binary classifiers  one for each tag t  t   and
divide the dataset into  t   label sets of length  x   for
each tag  the set of labels has positive labels for images
with that tag  and negative for all the other tags 
we applied these methods to a simple multiclass problem and then a multi label problem in succession 

 precision  the percent of true positives divided by
all positive labels guessed
 recall  the percent of true positives divided by
true positives and false negatives
 hamming distance error  the percent of incorrect labels assigned  true all assigned   smaller
values are better

   classify an image as organic  artificial  or
other

initially  we had very low accuracy   either our classifiers were very inaccurate or had a deceivingly high
precision but also high hamming error  as our classifiers were labeling every image as   for the less common
tags and assigning most of them to the highest count
tag  to compensate  we weighted each classifier by the
percentage of images it labels  this parameter adjusts
the cost for mislabeling for a particular tag  we saw
a expected drop in accuracy and recall as more labels
were assigned  but our average hamming distance is at
a very low           we used n fold cross validation
with n            and     to examine our model and
averaged an average accuracy of        each time  for
precision recall hamming error we trained on     of
the class and ran our results on the other      measurements we took are summarized below 

   assign a set of tags to each image 

 
   

one vs all
multi class  single label

our first task was to look at the dataset as a whole and
our initial classification of organic vs artificial  this
set was used to determine the feasibility of our feature
set and the project as a whole  utilizing libsvm     we
trained larger and large sets and averaged training error
per label classifier 

table    comparison for tag classification
model
svm  unweighted
svm  weighted
figure    organic artificial other   average training
error per classifier

recall

hamming
error

       
       

      
     

      
       

we also analyzed each classifier for our most frequent
tags to determine how well our model fit data  as these
tags would be the most likely to emulate real performance of our model on a larger dataset with more of
each type of tag 

our training and test errors appeared to trend towards
convergence  slowly  indicating our svm model was
feasible  however  our accuracy was lower than desired
as was our learning rate leading us to reevaluate and
eventually select a broader feature set  in the end  our
feature set provided convergence approaching     accuracy which was borderline acceptable  unfortunately 
it also showed that we would have trouble getting accurate predictions on our more specific classifications as
the number of textures in each classification was much
lower than this general taxonomy 

   

precision

one vs all   tagging images

we then applied our model to the broader set of classifications we created and the same svm  we first define
a common set of metrics    to describe the accuracy of
our multi label classifier 

figure    accuracy on the ten most common tags

 

fi 

auto tagging results

 

the final output of our program was an auto tagging
feature implemented in php which annotated filters with
tags predicted by the model  some of the results are
displayed above with their generated tags 

improvements

no attempt was made to distinguish between nodes that
controlled surface features such as height and reflectivity and those that controlled color  this distinction had
a dramatic effect on the visual aesthetics of the resultant image  we believe including this distinction would
add the most value to our model  parsing complexity
hindered our efforts in this regard 

as you can see  the tags it applies are mostly relevant 
they even appear to be more correct than the accuracy
indicates  this is likely due to the subjective nature of
tagging and that we generally only notice incorrect tags
and not the absence of correct ones 

no attempt was made to map out relationships between nodes  features such as connectivity between
nodes  branch depth  and fanout warrant exploration
but would require substantially more effort in xml file
parsing 

tags that performed well were not surprising  colors 
as their features were easy to pin down  as well as shiny
and dark for similar reasons  what is promising is that
bumpy and rippled appear in germane locations lending
weight to the validity of the scheme  it should be noted 
that the current tagging scheme has a propensity for
stone 

 

conclusion

we judge our results to be moderately successful  in
this case of image classification we are attempting to

 

fijudge things that not only have not been rendered but
are not images of objects with strictly definable features  our results demonstrate that convergence to an
    solution  given enough data and enough control
over the feature set  should be achievable  while this is
a low number for many applications it is quite adequate
for the largely subjective nature of this problem 

references
    powers  david m w  evaluation  from precision  recall and f factor to roc  informedness 
markedness   correlation        journal
of machine learning technologies             
http www bioinfo inuploadfiles                jmlt pdf 
    tsoumakas  grigorios  ioannis katakis  multilabel classification  an overview
    c  c  chang and c  j  lin  libsvm  a library for
support vector machines       

 

fi