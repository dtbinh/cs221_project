chatous   predicting the quality of users in anonymous chat
team  deepank gupta  aaron li  and simon zhu

   introduction
chatous is a text based    on   anonymous chat network that has seen     million unique visitors
from over     different countries  users can create a profile that contains a screen name  age 
gender  location  and a short free form  about me  field  after clicking the  new chat  button 
users are matched up with one another in a text based conversation  interactions on chatous
include exchanging messages  sending accepting a friend request  reporting an abusive user 
ending a conversation 
one key challenge in anonymous chatting social network is to predict the user quality and
likelihood to hold long conversation  based on the user quality  chatous can further generate
better matching algorithms to pair people up in the anonymous conversation  in this report  we
will use the datasets provided by chatous including the user profile information and past
conversation log to predict the quality of users and helps in predicting a better matching
algorithm 
   raw data analysis
there are two datasets provided by chatous 
       million user profiles including the following properties 
 user id   location   location flag   age   gender   time created   about   screen name 
   logs of each conversation in chatous platform containing the following information
 friendship status   chat created date   chat finished date  disconnector  reported user
id   reason for reporting   first user profile id   second user profile id   first user id 
 second user id   chat id   length of chat 
these two datasets include granular information about the quality of a conversation  e g  length
of a chat   demographic information of the chatter  e g  age  gender and location   and
information about the underlying network  they also contain the user profile id  which makes it
possible to run a panel data analysis to control users heterogeneity  a key metric for chatous is
the intention to talk  which can be measured approximately by the number of lines in a
conversation  lines   by comparing the number of lines of two users we can infer which user has
more intention to talk  the goal of this analysis is to build a model to make the prediction  based
on the demographic information of the users 
we ran a k means clustering algorithm on the profile data keeping age and gender as variables
and summarize the statistics in table   
 

fitable    user clustering statistics keeping age and gender as variables
cluster size

medium age

gender

      

    

female

      

    

male

      

    

female

      

    

none

      

    

female

specifically males outnumber females in the network and the demographics also point to more
teenage boys than girls in the networks 
some other statistics about the user profiles based on their country are shown in figure   

figure    user profile statistics based on country

   model
    user classification
we got a hand made manual set of      users which were classified as either clean  dirty or bot 
using this data set and dividing it into training and test set  we tried to apply various
classification algorithms in order to find out if we could learn to predict dirty bot users and
penalize them in the chat matching algorithm  we tried various different algorithms including
   k neighbors
   multinomial nave bayers
 

fi   pipeline using feature reduction using linear support vector followed by random forest
classification 
   support vector machines using exponential kernel 
in the data set  the distribution is quite skewed  so instead of using the normal accuracy measure
for calculating an algorithm s effectiveness  we used the precision recall curves  we calculated
the following metrics for every algorithm 
   precision recall curves
   number of false positives  false negatives  true positives  true negatives
   precision  recall and f score 
the auc curves for various classification algorithms are shown in the figure   below 

 a 

 b 

 c 

 d 

figure    auc curves for various classification algorithms   a  k neighbors   b  multinomial nave bayers precision
recall   c  pipeline precision recall  and  d  svc precision recall 

from the figures above  we see that multinomial nave bayers precision recall has the highest
auc  comparison of the detailed metrics for various algorithms is shown in table   below 

 

fitable    comparison of classification algorithms
multinomialnb

svc

kneighborsclasifier

pipeline

auc

    

    

    

    

precision

    

    

    

    

recall

    

    

    

    

f score

    

    

    

    

true positives

  

 

 

 

false positives

 

 

 

 

true negatives

  

  

  

  

false negatives

 

  

  

  

    user quality regression
besides the user classification  another key parameter in matching users is the quality of the user 
which is defined as the average length of conversations that a user holds  if the user starts and
maintains longer conversations  the user will get a better score  when we predict the quality of
the users  we eliminated those who have not held a single conversation yet and we were thus left
with       users 
the parameter that we used for learning was the word vectors that the users had spoken till now 
based on the word vectors of their previous conversations  we tried to train a model with     of
the user set and then use that to predict the quality on the rest of the     user base  we tried
three different models 
   linear regression
   linear support vector machine
   non linear support vector machine with an exponential kernel
the results were pretty much as expected that the non linear support vector machine with
exponential kernel performing really well  the results for the regression are shown in table  
below 

 

fitable    comparison of regression algorithms in predicting user quality  length of conversations 
linear regression

linear svm

nonlinear svm

mean absolute error

     

     

     

r  score

      

      

     

mean squared error

        

        

       

explained variance score

      

      

    

   analysis of results
using the various machine learning algorithms  we can build a better model which results in
better matches by suggesting users with other higher quality users for chatting  we did two types
of analysis      classify users as legitimate clean users and     measure the length of conversation
a user has as a proxy for user quality 
for the classification case  a hand made dataset was used  as the dataset was small  algorithms
like svm which require a large dataset did not even perform as well as naive bayes algorithm
 as mentioned in table     the ones that did the best were naive bayes and feature selection
followed by random forest technique  however  if we had larger dataset  we could do much
better than the current estimations 
in the regression case  we obtained good quality estimates using non linear exponential kernel
for svm  we also tried other models such as linear regression and linear kernel svm but they
did not perform as well as the exponential kernel for svm  with the regression model  we could
predict how likely a user is to keep up a conversation based on his her earlier conversations  the
dataset was again extremely sparse with nearly     of the sample users having done just   chat 
   conclusion
using machine learning algorithms  we are able to get accurate interpretation on the
demographics of the users with clustering  also with the help of curated data sets  we built a
convincing model to predict whether a user is clean or not  the regression model also helped
predict user s inclination to talk based on their past conversational models even though the
conversation logs are very few and feature space is very sparse 
appendix  all the code for various algorithms can be retrieved in the following location 
https   github com deepankgupta chatous
 

fi