cointerpretation of flow rate pressure temperature data
from permanent downhole gauges
cs     course final report
chuan tian
chuant stanford edu

abstract
this report documents how we developed appropriate
features and applied different algorithms to interpret flow
rate  pressure and temperature data from permanent
downhole gauges 

 

radial flow and reservoir boundary can be detected from
pressure derivative plot

however  well operation includes multiple transient  flow
rate changes   and the pressure response is a convolution
function of these transients p  t  

introduction

permanent downhole gauges  pdgs  have been installed
in modern oil wells to provide a continuous record of flow
rate  pressure and temperature  q p t  during production 
the frequency for data recording could be as high as once
per second  after years of operation  one pdg stores
millions of data  which provides us rich information about
the reservoir  however  currently this data is still primarily
used for well monitoring due to the following difficulties in
pdg data interpretation 


yue li
yuel stanford edu

deconvolution

in traditional well testing  the flow rate is carefully
controlled  usually constant or zero over time   and the
pressure response is recorded  the derivative plot of the
pressure   t dpdt   can be used to calculate reservoir
parameters such as wellbore storage  reservoir permeability
and boundary  figure    



    

        

a real data set from pdg shows the complex rate and
pressure history 

figure    real pdg data  left  flow rate  right  pressure 

to extract the reservoir model from this complex pressure
signal  deconvolution is needed  but the solution is usually
subject to pathological mathematical instability 


breakpoint detection

to analyze multi transient signal  we usually need to break
it into individual transient  the quality of the interpretation
is very sensitive to the accuracy of breakpoint detection 


volume of data

traditional well testing normally lasts for several days 
while data recorded by pdgs covers years of production
history  this requires a computationally efficient method
for data interpretation 


figure    pressure and pressure derivative plot corresponding
to constant flow  reservoir behaviors  e g  wellbore storage 

noise

noise is commonly seen in pdg data  and makes it
challenging for us to discover the real reservoir model
behind the noisy data 

fisome previous work has been done to interpret p q data
from pdgs using convolution kernel method  yang liu 
       but therere certain limitations about incomplete
interpretation  wellbore storage missing  and computation
efficiency  in this project  we tried to develop the features
to cover all reservoir behaviors  and applied different
algorithms to solve the p q deconvolution problem on large
volume of noisy data  we also tried to recognize the
patterns between p t data  this could be used to construct
pressure history based on temperature records  when
pressure gauge is not available 

since we calculated             for every j before
query point i  we treated every point as a breakpoint
 though it doesnt have to be  e g         this frees us
from the inaccuracy in breakpoint detection  the weight
function was used to represent the significance of different
features in constructing p at different flow regimes 
since different flow regimes are dominated by different
features  figure    

hypothesis 


 

methodology

    p q interpretation
regularized kernel method  convolution kernel method and
kernel svm were used for p q interpretation 

     


  

 

 

 

  

 

 

 

 

background work

both synthetic data and real data from pdgs are used in
this project  p q synthetic data is generated by using
pressure generator from supri d research group in
stanford university  it takes flow rate history and reservoir
properties as input  and generates pressure response as
output  t p synthetic data is generated by kappa rubis
reservoir simulator  the real pdg data is also from
supri d  necessary preprocessing  e g  sampling  is
applied on the data before using 

 

algorithm



regularized kernel method

feature selection
  

training set 
target 

feature 

  

  

 

  

where   

 

 

  

         

       

 
         



          
   
           


      


   

weight function



 

 

    

           

  




   

 

 

these features were selected based on the physical
behaviors of p as a convolution function of     
represented wellbore storage  
 represented radial
flow  and   represented reservoir boundary effect 

objective       



closed form solution 



  

    


 

  

  



we expect the close form solution to be an efficient
method that can be applied to large volume of pdg data 


workflow
tests

input

output

training

noisy q   p 

parameter

denoising

clean q 

prediction p 

deconvolution

constant q 

prediction p 

performance
q 
prediction p 
table    workflow for p q interpretation
denoising test used the same flow rate history q  as
training step but without noise  to test if the algorithm is
able to distinguish noise in data  deconvolution test used
constant rate history q  as input to deconvolute pressure 
the derivative plot of p  can be used to diagnose reservoir
parameters  performance test used a flow rate history q 
that the algorithm has never seen before to test its
performance on a new rate input  for all these tests  the
pressure predictions were compared with the pressure
generated by the pressure generator  denoted as true data in
the plots  

ficase    synthetic data    nd order kernel

case    synthetic data   linear kernel

  in this case 
we used  nd order kernel          
the results for most tests remained the same except for the
performance test 

figure    flow rate input and pressure prediction of case  

figure    flow rate input and pressure predictions of case  

we used linear kernel        
in this case  the two
plots in the first row represent the data used for training
 noise not shown here  and denoising test  clean data
shown   the plots in the second row represent
deconvolution test with constant rate input  the plots in the
third row represent performance test with a different
variable flow input from training flow history 
for all the three tests  the pressure predictions  red dots 
matched fairly well to the true pressure  blue curve   the
pressure derivative plot with constant rate input clearly
showed wellbore storage  unit slope   radial flow  flat
region  and constant pressure boundary  downwards  
these were exactly the reservoir properties we used in the
forward model to generate the pressure data  this showed
that our algorithm was able to recognize the reservoir
model from given p q data  define error as 
  p
training 
      

test   

p

 p
test   



it showed a larger error compared with case    we also
tried to user even higher kernel order  but mismatch still
existed  the intuition is that higher order kernels brought in
unnecessary features  making the problem over fitted 
case    synthetic data   gaussian kernel
in this case we chose the gaussian rbf kernel defined as
        exp 

  

 

the choice of
and
greatly influenced the data fitting 
we selected these parameters using simple cross validation 
which randomly takes out     of the training data as
testing sets  and pick the optimal
and
that gives the
least testing errors  as shown in figure 

figure    gaussian kernel parameters selection

test   

      
      
      
table    training and test errors of case  

the errors were pretty stable for different tests  again  this
showed an appropriate selection of features 
one defect of this case is that there was a mismatch
between prediction and true data in the transition of
wellbore storage and radial flow  t   hr on pressure
derivative plot   this is might because we dont have well
defined features for the transition zone  thats why we
decided to increase the kernel order to put more features
into the system 

again  the results by using gaussian kernel didnt show a
big difference to linear kernel  and the mismatch in the
transition zone still existed 
the performance by different kernel methods showed that
linear kernel might be a reasonable approach  if we were
able to define the features appropriately based on our
understanding of the problem  more complicated kernels
gave us more features  but may also make the problem
over fitted 
case    real pdg data   linear kernel
given the performance of different kernels  we chose linear
kernel for the interpretation of a real pdg data set  in this

fi       
      
              

case  we dont know the underlying reservoir model in
advance so theres no true pressure to compare with 

minimizing the  intensive loss function is equivalent
to penalizing errors that are greater than a threshold   the
above optimization problem can be solved efficiently by
solving its dual problem  which gives the solution
    

figure    flow rate input and pressure predictions of case  

the pressure prediction matched well with the training
pressure  the derivative plot corresponding to constant rate
showed wellbore storage  unit slope  and radial flow  flat
region   this realized the objective of this project to
deconvolute multi transient pressure signal  while in
traditional well testing  people usually have to shut in the
well  zero flow rate  to manually deconvolute pressure
signal  which brings in additional operation cost 
besides  about      real pdg data points were used in this
case  and it only took less than a minute  this gave us the
confidence to apply this method on even bigger pdg data 

     

convolution kernel method

 
another issue with higher order kernel          
is that kernel function comes after convolution 
  
 
          
 
but physically  the inner product of  
doesnt
represent reservoir behaviors  we should use kernel
function to construct features first  and then apply
convolution 
   
 
namely  
 
where

  

 

   

 



  

 

   

though the convolution kernel method is more physically
reasonable  its results were quite similar to what we got by
using regularized kernel method 

an alternative solution can be given by svm regression 
we adopt the  svm regression approach that minimizes
the  intensive loss function
min    

   



  subject to



           

 



where
is the number of support vectors 
kernel function we have introduced before 


is the

the solution given by svm is greatly affected by the
choice of the parameters c   and the kernel parameters 
parameter c determines the trade off between model
complexity and the data misfit  which functions similarly
as the  in ridge regression  select an infinitely large c is
equivalent to minimizing the empirical risk only  maybe
the most appealing feature of svm is that it can give a
sparse solution  in which case the number of support
vectors selected is only a small set of the data set  the
larger   the more data fall within the  insensitive zone
 which gives them a zero empirical error   the fewer
support vectors used in the regression function 
we further investigate the effect of the number of support
vectors on the training errors  by reducing   in other
words  decreasing the number of svs in the regression
function  the training error gradually decreases  however 
adding the first    training data sets constitutes        of
the error production  and add the following data sets from
   hour to     hours contributes another      of the error
reduction  this suggests that by capturing the early time
behavior in each pressure transient that immediately
follows the flow rate change  one can predict accurately the
reservoir response  running kernel svm provided us a
deeper understanding of the p q problem 

    p t interpretation
regularized kernel method was used for p t interpretation 


      kernel svm



feature selection
  

training set 
target 

  

 

  

 

 

  

         

       

fifeature 

  

 
   


        
  
    

 upwards   this showed that the algorithm was able to
capture the overall reservoir model based on given p t data 
we still need to have a deeper study on the feature selection
to get a better match 

       

physically  well downhole temperature is a function of
pressure and flow rate                   we did it
inversely from p to t  because t data is more accessible
than p and p is more widely used for analysis 
this inversion also brought in challenges for feature
definition  we first tried the polynomials of t based on
intuition from the shape of p t curve 


algorithm

the same as p q interpretation  using closed form solution 


workflow
tests

input

output

training

noisy t   p 

parameter

denoising

t 

prediction p 

deconvolution

t 

prediction p 

performance
t 
prediction p 
table    workflow for p q interpretation
the workflow was similar to p q interpretation  for the
deconvolution test  the temperature input corresponded to a
constant flow rate 
case    synthetic data   linear kernel

in practice  the availability of different data is      
a direct application of this method is to construct pressure
data from distributed temperature sensor  dts  while
distributed pressure sensor not commonly seen due to cost  
if we have one pair of p t sensors in a reservoir  we can
use this method to learn the pattern between p t  then
given temperature data from dts  we can construct the
pressure map for the reservoir  which can provide crucial
information for reservoir development and management 
moreover  if we were able to correctly construct temperate
data corresponding to constant flow  then we can interpret
the generated pressure signal to get reservoir properties 
just like what we did in p q interpretation 

conclusion
in this project  we developed appropriate features and
applied different learning algorithms to describe the
patterns of p q t data from pdgs  the results showed that
our method was able to recognize the underlying reservoir
model by solving the devonvolution problem  this work
provides a way for us to better utilize data from pdgs 

acknowledgement
we would like to express our gratitude to prof  roland n 
horne  professor from energy resources engineering
department  for his advice on this project 

references
    horne  roland   listening to the reservoir interpreting data from permanent downhole gauges  
journal of petroleum technology                     
    liu  yang  and horne  roland   interpreting pressure
and flow rate data from permanent downhole gauges
by use of data mining approaches   spe journal     
              

figure    temperature input and pressure prediction of case  

for all the tests  it showed a reasonable match between the
prediction  red dots  and true data  blue curve   the
pressure derivative plot clearly showed wellbore storage
 unit slope   radial flow  flat region  and closed boundary

fi