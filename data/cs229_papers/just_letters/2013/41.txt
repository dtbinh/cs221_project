 d visualization of high dimensional molecular
data from single cell mass cytometry
yishun dong  diana wan
email   ydong   jdwan   stanford edu
cs     final project

i  i ntroduction
a  background
emerging single cell technologies have provided rich  high
dimensional datasets  analysis of single cell data has shed light
on various different cellular processes      these data have
proved to be particularly useful in many important medical
applications  one of the most prominent applications is to
detect cancer tumors  these datasets from single cell mass
cytometry often come in the form of large matrices  where each
column represents measurements of some parameter of interest 
such as the expression level of certain protein  we can treat
these measurements as realization of some random variables
 up to    variables   therefore  these matrices represent data
from some very high dimensional space  while these datasets
are of great interest to the cancer community  the challenge
comes to developing efficient tools algorithms that can represent
these high dimensional data into lower dimensional subspace
   or   dimensions  where human can digest and visualize
effectively  traditionally  these single cell datasets have been
examined in two dimensions at a time in the form of a scatter
plot and inspected gated by human expert  however  as the
number of parameters increases  the number of pairs becomes
overwhelming  in addition  a pairwise viewpoint often misses
the biological meaningful high dimensional relationships among
these datasets     
various algorithms have been proposed to address this
problem  examples of such algorithms include t distributed
stochastic neighboring embedding  t sne           spanningtree progression analysis of density normalized events  spade 
         elastic embedding  ee   etc  these stochastic neighbor
embedding  sne  and many other related non linear manifold learning algorithms have achieved reasonable quality lowdimensional representations of these data by optimally preserving the pairwise euclidean distance in their original highdimensional space      in this project  we will examine these
algorithms and compare them with the dimensionality reduction
algorithm we learned in class   pca  furthermore  we explore
several meaningful extensions base on the rich single cell data
we have at hand 
b  goal and outline
the goal of this project is to apply existing low dimensional
visualization algorithms to the rich single cell mass cytometry
datasets obtained from a healthy donor  the data was made

publicly available by bendall et al      see next section for more
description on the structure of the datasets   we will both use
code provided by max vladymyrov  uc merced  and written
by ourselves to transform the high dimensional data into two
dimensions in the form of a scatter plot  the resulting two
dimensional scatter plots will be shown and compared visually
to see how well cells from different populations  cell types 
are separated  at the same time  we will develop our own error
metric to quantitatively compare how well separated are the data
in two dimensions  the algorithms that will be used include
the generic principal component analysis  pca   elastic embedding  ee   t distributed stochastic neighboring embedding
 t sne  and symmetric stochastic neighboring embedding  ssne  
due to the richness of the datasets provided by      there are
many interesting extensions possible for this project  we will
explore a few  in particular  the    to    or so parameters in
the original dataset can be roughly divided into two classes  for
the purpose of this project   one class of variables represents
the protein expression levels of some surface markers  whereas
the other class of variables represents the expression level of
some intracellular markers  one way to refine the dimensionality
reduction algorithm and potentially getting better classification
results is to use     only the surface markers      only the
intracellular markers      both surface and intracellular markers 
and compare the results from these three sets  in addition to
having data from different cell types available to us  we also
have the data with different conditioning  in this project we will
explore the basal  nothing added  condition versus the pvo 
condition  from a biological point of view the pvo  condition
will not have any effect to the parameters corresponding to the
surface markers  but for intracellular markers pvo  condition
is expected to produce some effect to the data  so we will see
how pvo  condition affects our classification results 
c  data
the data for this project were downloaded from the publicly available cytobank website  https   www cytobank org 
cytobank experiments      illustrations        when downloading data files  there were various settings we needed to
select  first of all  we can select conditions to be applied to
the cell populations  in this project  we selected the basal
condition and the pvo  condition  as their effects will be
compared later  we use cell data coming from the same individual subject in this project  we selected a set of    cell

fipopulations to be studied in this project  due to the speed of
some embedding algorithms  we will only train on a subset of p
populations among these    populations to obtain a common  dimensional subspace  furthermore  when we make the scatter
plot and examine classification results  we will only scatter plot
a subset of these p populations to see separation and how well
classification is done  for a fixed individual  condition  and
cell population  there is a single corresponding  fcs file  which
consists of a data matrix of the form 


 
 
ac p   a     an 
   
 
 

transformation as follows 
x

 i 


  arcsinh

x i 
 


   

this transformation is very standard when researchers deal
with data from flow cytometry  the main reason for this
transformation is to reduce the distortion caused by outliers
while emphasizing the distances around origin  in short  this
transformation makes it easier to compare distances 
     normalize the data   since we are using dimensionality
reduction algorithms here  as pointed out in the course lecture
note on pca  we need to first normalize the data to have zero
mean and unit variance  for the other algorithms  we perform
similar normalization so the data are on the same scale  this
allows us to see the intrinsic variability among different cell
types rather than simply look at the noise 

where c   basal  pvo    p                  is the population
identifier  each column aj  rmc p   where mc p is the number
of samples for that particular cell type and condition  usually
about             n is the number of parameters in the dataset
 about      the parameters are also selectable when downloading the data  in short  ac p contains the high dimensional data
we would like to reduce and visualize 

b  error metric
in this project  we are mainly dealing with supervised learning  since we know the class label  cell type  ahead of the time 
after the high dimensional data is reduced to two dimensions  in
addition to scatter plotting the data and visually seeing how well
separated different types of cells are  we establish the following
metric for computing the fraction of misclassified cells 
step    compute the centroid of each cluster

ii  r esults and d iscussion
a  preprocessing

m

in the data section  we described the form of the data
matrix  in this section  we will outline the preprocessing we
performed on the data matrices that are used in the subsequent
sections  these preprocessing are very important in order to
obtain meaningful results 
     extract relevant columns   each data matrix downloaded
contains    columns  but not all of them contain relevant
information  in particular  there are    columns containing either
information irrelevant to classifying cell types  such as time 
event number  etc  or duplicated information  redundant data
that are summarized by other columns   so these    columns are
completely ignored  for the rest    columns  they can be divided
into two classes  one class consists of    columns containing
measurements from surface markers  while the other class consists of    columns containing measurements from intracellular
markers  for example  in the subsequent sections  when we
perform training algorithm on surface markers only  we mean
that we only use the    columns of the data corresponding to
the surface markers 
     data subsampling   due to the difference in the abundance
of different cell types in the subject  distinct cell types have
vastly different sample sizes  i e  mc p   in order not to let certain
cell type dominate the training  it makes sense to fix an m  such
that we take m samples  randomly  from each cell type  one
drawback of this preprocessing is that the sample size m is
limited by m  min mc p   as it turns out  even the smallest

  x  i 
z
j  
m i   j

   
 i 

where j is the index for the cell type being clustered  zj 
r  is the low dimensional representation of the original high
 i 
dimensional data xj  rn  
step    relabel each cell to the nearest centroid
 i 

 i 

yj   argmin   zj  j      

   

j 

 i 

here j is the original label  yj is the new label 
step    count the fraction of cells being mislabeled
m
o
  x n  i 
j  
  yj    j
m i  

   

intuitively  the higher fraction the cells being misclassified 
the poorer are the data being separated  however  this error
metric does not capture all the information about how well
separated the data are  therefore  we still show most of the
scatter plots for visual comparison 
c  linear algorithm   pca
the first algorithm comes to mind for dimensionality reduction is the principal component analysis  pca  we studied in the
class  matlab has built in function princomp for pca  which
is what we will use in this project  as a starting point  pca
provides a simple first pass to address this problem  and will give
and confirm intuition on the appropriate parameter sets to use 
figure       shows the resulting low dimensional scatter plots
of the high dimensional preprocessed datasets using only the   
surface markers  only the    intracellular markers  and all   

c p

mc p is on the order of hundreds  so we still have a total of a
few thousands of data to train  which seems to be enough for
this project 
     arcsinh transform data   after extracting relevant columns
and a subset of rows  the data first go through an arcsinh
 

fisurface and intracellular markers  respectively  as expected     
the intracellular parameters do not provide useful information
about different cell populations and it is the surface markers
that really distinguish different cell types  visually  figure  
shows that using just the surface markers  the five populations
separate reasonably well under pca  whereas after adding the
intracellular markers  which seem to be purely noise here   the
resulting datasets do not separate nearly as well  see figure    
this is further quantitatively confirmed in table i using the error
metric we established earlier  we see that the misclassification
error increased for all five cell populations after intracellular
markers were added 

fig     use principal component analysis  pca  to reduce dimensionality of
cell data using parameters from both surface and intracellular markers 
table i
c lassification e rror using pca

cell type
cd  bhi monocyte
cmp
mature cd   t
mature cd  mid b
naive cd   t

surface markers only
    
    
    
    
    

all markers
    
     
     
     
     

d  other algorithms   t sne  s sne  ee

fig     use principal component analysis  pca  to reduce dimensionality of
cell data using parameters from surface markers only 

it can be seen that pca provides reasonable separation and
is a reasonably effective algorithm for reducing the dimension
of high dimensional single cell cytometry data  however  it
has been pointed out that for high dimensional flow cytometry
datasets  linear methods such as pca fail to capture the high
dimensional relationship among the cell datasets      therefore 
many non linear methods have been developed for this purpose 
and we shall explore them in this section 
we discovered that data from intracellular markers are pretty
much just noise from the pca results  they cause worse
separation when they are added  therefore  in studying the
effectiveness of the other three algorithms  we show only the
scatter plots of low dimensional representation of data from
surface markers only  figure         it can be seen visually that
all three algorithms give very good separations  numerically 
table ii shows that they all give smaller  in fact  close to zero 
misclassification error than pca  visually  it looks like the most
cutting edge          tsne is the best among all four algorithms 
followed by ssne and ee giving roughly the same performance 
whereas pca is slightly worse than the three algorithms in this
section 
e  conditions   basal vs  pvo 

fig     use principal component analysis  pca  to reduce dimensionality of
cell data using parameters from intracellular markers only 

in this section  we explore how the four algorithms perform
when different conditions are applied  in particular  we examine
 

fifig     use elastic embedding  ee  to reduce dimensionality of cell data using
parameters from surface markers only 

fig     use t distributed stochastic neighbor embedding  tsne  to reduce
dimensionality of cell data using parameters from surface markers only 

table ii
c lassification e rror using four different algorithms on
surface markers only

cell type
cd  bhi monocyte
cmp
mature cd   t
mature cd  mid b
naive cd   t

pca
    
    
    
    
    

ee
    
    
    
    
    

ssne
    
    
    
    
    

tsne
    
    
    
    
    

compare the scatter plots when the algorithms are applied to all
markers   if we still want to think of intracellular data as some
kind of noise  then we can think of different conditions will
cause some systematic shift in the noise such that we expect
them to affect the resulting scatter plots of the  d representation
of data from all markers  

fig    
use symmetric stochastic neighbor embedding  ssne  to reduce
dimensionality of cell data using parameters from surface markers only 

figure   shows the resulting scatter plots for basal condition 
and figure   shows the resulting scatter plots for pvo  condition  interestingly  we see the shapes of the clusters formed
by different cell populations are indeed quite different for basal
 round  and pvo  condition  banana shape   numerically from
table iii  it looks like pvo  condition gives uniformly worse
average classification error  but we believe that is just due to the
nature of the shape of the clusters  as round shape clusters are
naturally less likely to be misclassified compared to longer and
more stretched clusters as in the pvo  case  visually  we see
that the three algorithms  ee  ssne and tsne  still give quite
good separation even using data from all markers  in contrast 
the result for pca shows much poorer separation  the errors
are in the range of            this shows these modern nonlinear methods are more robust against error in reducing cell
cytometry data compared to the generic pca 

what happens to the cell cytometry data when basal  no condition  and pvo  condition are applied to the cell being measured 
from a biological point of view  the measurements corresponding to the surface markers should not change in a fundamental
way  i e  the random variable remains the same  when different
conditions are applied  but the measurements corresponding to
the intracellular markers will change fundamentally depending
on which condition is applied  therefore  if we only look at the
scatter plots corresponding to surface markers  as we did in the
previous section   we will not get meaningful results  since we
will just be looking at two different sets of realizations of the
same random variables  on the other hand  based on the pca
results  we expect the two dimensional scatter plot of just the
intracellular markers to be a complete mess that only resembles
some random noise  therefore  it makes sense to examine and
 

fitable iii
c lassification error using four different algorithms on all markers with basal c ondition and pvo  c ondition

cell type
cd  bhi monocyte
cmp
mature cd   t
mature cd  mid b
naive cd   t
average

pca
basal
pvo 
     
     
     
     
     
     
     
     
     
     
             

ee
basal
    
    
    
    
    
     

pvo 
    
     
    
    
    
     

ssne
basal pvo 
    
    
          
    
    
    
    
    
    
           

tsne
basal pvo 
    
    
    
    
    
    
    
    
    
    
           

plot  we observed that all four algorithms give very good
separation  hence low dimensional representation  when only the
data from surface markers are used  we found out that data from
intracellular markers are mainly just noise in separating different
cell populations  among the four algorithms  we conclude that
tsne gives the best performance followed by ee and ssne 
the generic pca seems to perform poorer and is less robust
against noise in comparison for this application  nonetheless 
as a quick and dirty first pass to the problem  pca performs
reasonably well  finally  we examined what happens to the
cell cytometry data when different conditions are applied  we
conclude that the different conditions cause systematic shifts in
the data from intracellular markers  as a consequence  when  d
representation of high dimensional data from all markers were
scatter plotted  the clusters from different cell populations form
clusters with different shapes 
fig     dimensionality reduction on all markers with basal condition using
all four algorithms  pca  ee  ssne  tsne 

acknowledgement
we give special thanks to karen sachs and andrew gentles
for giving us an interesting and approachable project to work
on and providing us helpful suggestion and guidance throughout
the project  we would also like to thank max vladymyrov  uc
merced  for sharing and allowing us to use his matlab code for
efficient non linear methods in this project 
r eference
     amir e a   davis k l   tadmor m d  et al  visne
enables visualization of high dimensional single cell data and
reveals phenotypic heterogeneity of leukemia  nat biotechnol 
                   
     vladymyrov  max and carreira perpinan  miguel a 
partial hessian strategies for fast learning of nonlinear embeddings  icml        pp           edinburgh  scotland  jun    
  jul         
     bendall  s c  et al  single cell mass cytometry of
differential immune and drug responses across the human
hematopoietic continuum  science                     
     qiu  p  et al  extracting a cellular hierarchy from highdimensional cytometry data with spade  nat  biotechnol     
               
     laurens van der maaten  geoffrey hinton  visualizing
data using t sne  journal of machine learning research   
                 

fig     dimensionality reduction on all markers with pvo  condition using
all four algorithms  pca  ee  ssne  tsne 

iii  s ummary and c onclusion
in this project  we applied four dimensionality reduction algorithms to the high dimensional single cell cytometry datasets
so that we can visualize the data in the form of a  d scatter
 

fi