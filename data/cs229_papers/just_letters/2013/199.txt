hit or flop  box office prediction for feature films
december         

dan cocuzzo

stephen wu

dcocuzzo stanford edu

shw stanford edu

this project is an investigation of the effectiveness of various machine learning techniques on
the prediction of success for feature films  as measured by their gross earnings and average
user rating  data for approximately       feature films was used to train two distinct models 
and overall classification results and performance analysis are reported here  the code for this
project may be found at https   github com shwu imdb project git 

introduction
feature films are a multibillion dollar industry  given
the sheer number of films produced as well as the level of
scrutiny to which they are exposed  it may be possible to
predict the success of an unreleased film based on publiclyavailable data  a large amount of data representing feature
films  maintained by the internet movie database  imdb  
was extracted and prepared for use in training several machine learning algorithms  the goal of this project is to build
a system that can closely predict average user rating and degree of profitability of a given movie by learning from historical movie data  since there is a strong correlation between a
films budget and the gross us earnings  predicting raw gross
earnings is not particularly indicative of a films success  instead  we transform the gross earnings of a film to a multiple
of its budget  which is a much more meaningful indicator of
a films success 
data
movie data is drawn from the internet movie database
 imdb   found at http   www imdb com  
access
imdb makes its data publicly available for research purposes from which a local  offline database can be populated 
ftp servers sponsored and maintained by imdb contain
stores of flat format  list files that contain the same information found online through imdbs web interface  for
this project data access and preparation was facilitated by the
help of two existing software systems  sqlite and imdbpy 
sqlite is a widely used sql implementation supporting
all standard sql constructs and can be used to query all
information found in the database in a high level  declarative manner  imdbpy is a freely available python package
designed for use with the imdb database that implements
various functions to search through and obtain data  python
scripts were devloped to automatically pull the required feature data from the local sqlite database 

pruning
the full database contains nearly   million titles  of which
roughly         are feature films  many of the titles found in
the database contain incomplete information or are inappropriate for the scope of this investigation  thus  in an attempt
to both decrease training time and increase the accuracy of
the prediction  the full title list was pruned using a series of
sql queries  the criteria by which imdb titles were omitted
are as follows 
 titles which are not movies  e g  tv  videogames  etc  
 adult films
 films missing budget data in us dollars
 films missing gross earnings data in us dollars
 films missing user rating data
 films not released in the united states
after pruning the entire database of nearly   million entries  only      titles remain  less than        of the original database   while this quantity is a tiny fraction of the
overall database  the pruning constraints enforced are justifiable for the purposes of this prediction system  the pruned
titles include films which are not released in major theater
circuits  films we cannot generate labels for  and films not
released in the us 
note that gross earnings reported in us dollars  our focus here  correspond to earnings from us theaters only  and
therefore the financial based metrics for film success are
strictly an indicator domestic performance 
features
currently  the following features are drawn from each
training film 







cast list
director s 
producer s 
composer s 
cinematographer s 
distributor s 







genre s 
mpaa rating
budget
release month
runtime

fi 

autumn     

several prediction models were implemented to learn
from these features and make predictions on the success of
films drawn from a test set  the prediction comes in the form
of two primary success metrics 
ratings prediction  many of the movies listed on
imdb contain an average user rating on a scale of   to   
which corresponds to public opinion of that movie  the rating values exposed by the imdb are rounded to a single decimal point  in this analysis we have rounded rating values to
the nearest integer  thus  the system predicts rating rounded
to the nearest integer  turning a regression problem into a
classification problem with    effective classes representing
the integers      inclusive 
gross earnings prediction  since the magnitude of
gross earnings is not necessarily representative of movie success  especially if the movie had a large budget  the system
predicts gross earnings of movies as a multiple of their budget  or bmult  we label the bmult of each of movie into
the following bins                                     as
with rating predictions  this significantly simplifies the models by reducing the space of output classes  note that bmult
is a rough approximation of a films of return on investment 
where bmult greater than   corresponds to a profitable movie 
methods
nave bayes
under the nave bayes assumption  a movie can be represented as an independent combination of its associated personas and attributes  as denoted by the features described in
the introduction  in this case  we have
p rating   r movie   p movie rating   r p rating   r 
where p movie rating   r  is the product of the individual conditional probabilities for each persona  e g 
p actori  rating   r   p directori  rating   r   etc   and attribute  e g  p genre j  rating   r   p mpaa rating   r   etc  
associated with the given movie  laplace smoothing with
     was also used to account for sparsity in the dataset
to avoid zero valued probability estimates in the empirical
training data  this is a required procedure since it is unreasonable to assume that each actor in the database possesses
a filmography containing all possible ratings and all possible
bmult bins  furthermore the cast list for each film is limited
to a tunable parameter  max actors  since actors with more
screen time are more likely to contribute to a films success 
using a larger value for max actors may improve prediction performance due to the addition of information at the
cost of increasing model complexity  the appropriate choice
of the value of max actors is discussed further below in the
section titled parameter tuning 

training  the multi variate bernoulli event model is
used  that is  the assumption is that all actors  directors  genres  etc  are drawn independently from the same distribution s   training this nave bayes model involves calculating
the probability that each persona or attribute exists in an arbitrary movie  conditioned on the particular output bin we wish
to find the likelihood for 
prediction  classification is performed by caculating
the posterior probabilities of the output bins for each test
movie  that is  the maximum likelihood prediction of
p rating movie  and p bmult movie  is used to classify a
given test movie 
support vector machine
the goal of the svm formulation is to generate separating
hyperplanes in the feature space which allow us to classify
input movies  in class  we typically saw examples of svm
for binary classification  in this case  multiclass prediction is
done using the one versus one method  where a binary classifier is generated for every pair of possible output labels 
and the predictor outputs the class selected by the greatest
number of classifiers 
we choose the radial basis function kernel  since it is an
oft recommended default kernel for nonlinear models  the
rbf kernel is defined as 
k x  z    exp kx  zk    
where  is a free parameter 
training  libsvm is a library which implements various svm classifiers with user definable parameters  we use
python to interface with this library to train predictors 
feature vectors and output labels are generated for each
movie in the training set  unfortunately  the pruned dataset
contains over        different personas  actors  directors 
producers  etc    since we base our features on inclusion
 binary features  this would lead to a vector with a length
of nearly        features  additionally  performing normal forwards backwards searches on this feature set would
have required a prohibitive amount of time and processing
power due to the number of training examples in conjunction
with the overhead of accessing a single movie from the local
database 
the imdb database assigns unique ids to each persona 
thus we might consider features of the form  director id  or
 actor    id   however  there is no logical ordering of these
personas in the database  and certainly no predictable relation
between a persons id and his her proclivity towards working
on a successful film  thus  the svm formulation considers a
limited feature vector which includes budget  genre  mpaa
rating  runtime  and release  all of which are enumerable except for genre  these feature vectors are normalized and used
to fit the svm model  see parameter tuning for a discussion
of the parameters used in this model 

fi 

cs     machine learning

prediction  prediction is performed by using the builtin libsvm prediction function  applied to the previouslyfitted model 
parameter tuning
nave bayes
cast list length  the max actors parameter determines how far the model looks down the cast list in order
to train predict on an example  it is reasonable to assume
that the most important actors  i e   the ones which receive
the most screentime and publicity  tend to appear high on
the cast list  increasing this parameter improves accuracy
locally  but in the long term will lead to increased computational and storage complexity since we must store conditional probabilities for a greater number of actors  additionally  the nave bayes classifier is not cognizant of the
cast list ordering since it predicts based only on inclusion 
this means that extremely high values for this parameter will
cause minor cast members to heavily sway the prediction 
several values of max actors were used to train and test
on the dataset  see table        was chosen as it yielded an
acceptable balance of prediction accuracy and complexity 
output bin boundaries  output bins for budgetmultiple were selected such that the distribution of movies
within the bins is relatively uniform  see figure   for the
resulting distribution  this decreases the chance that a large
budget multiple prior dominates the prediction  for example  using bins of size      leads to a relatively high prior for
the          budget multiple bin  i e  films that tank tend to
tank badly  causing most predictions to be placed into this
bin  while this performs respectably in terms of error rate 
this result is not very enlightening and leads to a high false
negative rate for strong movies 
since the ratings prediction contains more bins  we did
not carry out this procedure for that model  as the resulting
gains would both be smaller and also render the output less
readable  e g   it may not make sense to have a         rating
bin   note that this means good movies tend to be underrated by the prediction system  and bad movies tend to be
overrated  we deemed this acceptable  as particularly strong
or weak movies will still stand out in the predicted ratings 
support vector machine
there are two parameters to be chosen  c  the svm
penalty parameter  and   the rbf kernel parameter  a gridsearch was performed on these parameters  varying them independently and exponentially from    to      from this 
 crating   rating   and  cbmult   bmult   are chosen to minimize
prediction error  see figure   and figure   for the results
of this sweep  the values  c                were found to
work well for both predictive models 

results
the predictors performed moderately well on the test data 
qualitatively  many of the rating and bmult predictions were
exactly correct  while ones that were incorrect were  close 
in the sense that the predicted value bin was typically adjacent to the actual value bin  for instance  an incorrectly
predicted movie with a true average user rating of   is most
often a rating of    figures          and    show the confusion
matrices of rating and bmult prediction results to illustrate
the distribution of misclassifications for rating and bmult  we
not only report absolute error  correct or incorrect classification  for each test sample  but also the error as a measure of
absolute distance from the true value  the absolute distance
error of rating and bmult predictions are a valuable indicator
of our systems performance  especially when misclassified
test samples are close the to true rating or bmult bin 
note that this is similar to the approach taken by typical
regression problems  in which mean absolute error or mean
squared error is often the quality metric of choice  indeed 
since our classification bins have a natural ordering for both
average user rating and bmult gross earnings  such a metric is
likely to be more accurate that a simple measure of error  if
not for the issues described earlier in constructing a meaningful svm feature vector  it is likely that a regressive approach
may have yielded similar results 
nave bayes
the distribution of absolute distance error of average user
rating predictions is shown in figure    and distribution of
absolute distance error of budget multiple gross earnings
predictions for is shown in figure    both figures report error for a         holdout test  these figures also report the
priors for both problems  though conditional probabilities for
the personas attributes are omitted for brevity 
a    fold cross validation was performed across the entire set of       movie titles  and the test error rates for rating
and bmult predictions along with random prediction performance are shown in figure     a summary of testing and
tuned parameters is provided in table   
support vector machine
alongside nave bayes model performance  figures  
and   show the distributions of absolute distance error of average user rating predictions and budget multiple gross earnings predictions respectively for a         holdout test 
   fold cross validation was also performed for svm  the
results of which are shown in figure    
discussion
a few general points to take away from the results of this
experiment 

fi 

autumn     

the results of nave bayes parameter tuning suggest that
varying the value of max actors has little impact on prediction performance  intuitively  it would seem that using
information about a greater number of actors per movie for
training would improve prediction performance  however 
the vast majority of actors collected from the training set appear in one or very few movies  so often the actor probabilities conditioned on rating and bmult contribute negligible
information 
the confusion matrices reveal that movies are overwhelming predicted to have a rating of   or    though the system
is still able to distinguish between good and bad movies  the
range is extremely compressed  fixing the rating bins in the
same way as bmult bins may alleviate this problem  svm
performed slightly better at this task  despite having a more
limited feature vector 
both classifiers are excellent at finding highly unprofitable
movies  the error for movies earning back less than half of
their budget was under     in both cases  however  table   
reveals that the nave bayes model is superior for these two
particular prediction tasks given the constraints imposed  we
posit that svm performance may improve dramatically after
performing sufficient feature selection extraction and training with a larger sample set  this would be a suitable path for
futher exploration on this project 

figure    svm parameter selection for bmult prediction

figure    distribution of movie ratings

figure    distribution of test  error  in rating predictions

tables and figures
table  
nave bayes parameter selection
max actors

rating error

bmult error

 
 
 
 
 
  

     
     
     
     
     
     

     
     
     
     
     
     
figure   
earnings

figure    svm parameter selection for rating prediction

distribution of movie budget multiple gross

fi 

cs     machine learning

figure    distribution of test  error  in bmult predictions

figure     confusion matrix for svm bmult prediction

figure     cross validation  nave bayes test error rate
figure    confusion matrix for nb rating prediction

 
figure    confusion matrix for svm rating prediction

figure    confusion matrix for nb bmult prediction

figure     cross validation  svm test error rate

table  
example test results        holdout validation

max actors
c

rating error rate
mean  ratingerror 
bmult error rate
mean  bmulterror 

nave bayes

svm

  
n a
n a
     
     
     
     

n a
   
   
     
     
     
     

fi