emily doughty
rachel goldfeder
cs     final report

characterizing and diagnosing hypertrophic cardiomyopathy from ecg data
background
hypertrophic cardiomyopathy  hcm  is a heart condition defined by a thickening of the heart
muscle  this thickening makes it harder for the heart to pump blood throughout the body and
also causes disturbances in the electrical functions of the heart that may lead to an arrhythmia 
approximately   in     people in the general population are affected by this condition     
unfortunately  one of the potential symptoms of hcm is sudden cardiac death  in fact  hcm is a
leading cause of sudden cardiac death in young athletes      risk factors for this disease include
family history of sudden cardiac death  personal history of cardiac arrest  and tachycardia  people
with these risk factors are screened for hcm  however  as the first symptom for hcm could be
sudden cardiac death  early and accurate detection is critical  if hcm is diagnosed early 
interventions such as alcohol septal ablation  destruction of the heart muscle  and septal
myectomy  removal of part of the septum  can help reduce thickening of the heart  pacemakers
can also be implanted to control and regulate electrical signals     
hcm is typically diagnosed using an echocardiogram  which allows the physician to measure
heart wall thickness      however  echocardiograms are expensive and require interpretation by a
certified clinician  hcm diagnosis with a cheaper and more portable device that can be
automatically interpreted  such as an electrocardiogram  ecg   would be a useful diagnostic tool
in the clinic  ecgs noninvasively measure electrical activity of the heart over a period of time
and produce data that can be mined for patterns  we hypothesize that the patterns of electrical
activity recorded from a patient with hcm will be different from controls such that these
patterns can be used to diagnose hcm 
currently  the ecg features specifically associated with hcm are not well defined  in
collaboration with dr  marco perez and the ashley lab at stanford university  we obtained ecg
records from patients diagnosed with hcm along with ecg records for controls  in this work 
we compared five machine learning algorithms on the task of classifying an ecg record as
hcm or non hcm using standard ecg measurements as input features 
data   methods
a  data
  lead ecg data
this dataset contained     patients with hcm that were diagnosed by a physician at
stanford hospital and      controls without hcm  the ecg analysis software 
cardeascreen      outputs     standard measurements from   lead ecgs  which were the
attributes included in our dataset  these standard measurements include amplitudes  slopes 
and lengths of various waveforms from the ecg 
   lead ecg data

fithis dataset contained     patients with hcm  a subset of the patients with   lead data  that
were diagnosed by a physician at stanford hospital and      controls without hcm  the
analysis software outputs     standard measurements from    lead ecgs  which were the
attributes included in our dataset  similar to the   lead measurements  these standard
measurements include amplitudes  slopes  and lengths of various waveforms from the ecg 
it must be noted that the   lead and    lead datasets did not contain exactly the same
individuals  there were a total of     hcm patients and      controls  most individuals had
  lead and    lead ecgs  but some only had one type of ecg 
preprocessing for both datasets included subject  hcm patients and controls  and feature
removal  we removed features that did not provide any data  i e   where all values of a given
feature were missing or contained the same value  and subjects where the records were
missing measurements  after this preprocessing  the   lead dataset contained     hcm
records  there are some patients with multiple records        athlete records  and    
standard measurements to be used as features and the    lead dataset contained     hcm
records       control records  and     standard measurements to be used as features 
b  methods
   evaluation of five machine learning algorithms on full data  we performed a   fold cross
validation to evaluate the performance of random forest  support vector machines  svm  
adaboost  k nearest neighbors  knn   and nave bayes in differentiating between ecg
records from hcm patients and athletes  we performed our analysis in r  for random forest 
we used the package randomforest     with      trees and mtry   square root of the
number of features  for svm  we used the package e         with a linear kernel with a cost
of constraint violation equal to    for knn we used the package e     with k    for nave
bayes we used package e      for adaboost we used package ada     with    boosting
iterations  we averaged the following values across all folds  training error  test error 
accuracy  sensitivity  precision  f measure  and specificity 
   feature selection and evaluation of machine learning algorithms  we implemented feature
selection using the mean decrease in gini index from random forest  specifically  we trained
a random forest classifier on all of the data and iteratively removed the least important
features  for each feature subset  we repeated the above analysis for the other four
algorithms 
results
the results are summarized in tables   and    with bolded values representing the algorithm that
performed best for that metric  random forest  svm  and adaboost had the best performance
across all metrics  ppv        accuracy        sensitivity         for this application 
minimizing false negatives is more important than minimizing false positives  as improperly
classifying a record from a person who truly has hcm could result in death  for this task  svm
had the best performance in terms of sensitivity  knn performed the worst across all measures 
in particular  knn had the highest test error and lowest sensitivity  both of which are key for this
application  another important metric for this application is specificity  if we were to screen an
entire population  we would want to minimize the number of people coming back to the clinic
for additional testing  for example      specificity with     healthy individuals would yield

fionly three individuals returning for an unnecessary echocardiogram  however  if the total number
of healthy individuals was     million  three million individuals may need to return to the clinic
for an unnecessary and expensive echocardiogram  in our analyses  adaboost performed the best
with a specificity of       for the   lead data  knn had a specificity of       for the    lead
data  but with a sensitivity of        knn is not a useful method for this application area  
table        fold  cross  validation  results  for    lead  data 

table        fold  cross  validation  results  for     lead  data 

the top    features from random forest are depicted in figure   a and b for the    and     lead
data  respectively  for both datasets  the top    features were involved in the t wave  for
example  in the   lead data t  represents the largest t wave amplitude from v  lead and
tavrm measures the t wave amplitude from the avr lead  in the    lead data sti   measures
the st interval from lead v  and st  avr measures the st interval from the avr lead 

variable name 

random forest variable importance 
   lead data 
   
   
   
   
  
  

s
st ti i 
i a
vr
ta  
vr
 
st
 i 
st ti 
i v
st   
 
st v  
i a
ra vl 
vl
 
st a 
 v
  
t
ra v  
vl
 a
 
tv
st   
i v
st   
 a
vr
 

mean decrease gini 

   
   
   
   
   
  
  
ta ti 
vr
m
 
st
ax i 
i sr
 
tv
  
tx
st  
v 
ax  
ist
 
st
ix
de  
fy
  
tv
  
st
ra v  
m
p
qr y 
sd
 
qt
c 

mean decrease gini 

random forest variable importance 
  lead data 

variable name 

figure    important features from random forest for the    and    lead data 
using the ordered top features based on gini index from random forest  we calculated all
measures described above for the remaining four algorithms and for each subset of features for

fithe    and    lead data  the impact of feature selection on sensitivity  specificity  and ppv are
shown in figure   for the   lead data  the    lead data showed similar trends but are not shown
due to space restrictions  svm reached maximum sensitivity at    top features  at greater than
   features  knn performed significantly worse than svm  adaboost  and nave bayes with
regards to sensitivity  thus  knn is not a useful method for this task even with selected features 
with regards to specificity  all four algorithms perform well             specificity  until   
features are included  where nave bayes began dropping in specificity  feature selection
showed greater variability on ppv than on sensitivity and specificity  adaboost stayed relatively
constant for all amounts of features included  while the other three vary as the number of top
features change  this shows that as the number of included top features increases  the false
positives have a greater impact in relation to the true positives than the true negatives  as shown
by specificity  
a

b

c
figure    impact of feature selection on
sensitivity  specificity  and ppv  results not
shown for    lead data due to page limit 
discussion
from this work  we    provide evidence that machine learning algorithms can accurately
differentiate hcm from non hcm ecg records and    provide clinicians with new features that
are important for diagnosing hcm from ecgs  the algorithms performed better on   lead data
than    lead data  this result was surprising since the    lead data is the known standard  while
  lead is thought of as an approximation for the    lead data  although the additional features
provided by the    lead data may be useful for clinicians  it seems that the additional information
is not informative for the machine learning algorithms 
with this idea in mind  we hypothesized that the algorithms may perform equally as well or
better with fewer features  to test this  we reduced the dimensionality of the feature space by
transforming the initial datasets  both   lead and    lead  separately  using principal component
analysis  we used four principal components to transform the data after reviewing the scree plot 
we repeated our previous analysis and found that the algorithms performed significantly worse
across all measures  all values decreased  with sensitivity having the most dramatic decrease
between full data and reduced data for both    and    lead  across all algorithms  the maximum
sensitivity for the dimensionality reduced data was       which is not acceptable for this task
 results not shown due to space restrictions   since pca did not work well  instead  we decided
to implement feature selection using the k most important features calculated by random forest 

fithis analysis showed that sensitivity  specificity  and ppv stay the same or increase for svm 
adaboost  and naivebayes even when using fewer features  this indicates that the rest of the
features do not add useful information for the classification task 
we compared five algorithms in this analysis  however  in practice  a physician is likely to
only use one algorithm when trying to diagnose a patient  to recommend one algorithm to use
for this task  we can look at the metrics we used for evaluation  e g   sensitivity  specificity 
ppv   however  while a classifier that can predict hcm is useful in and of itself  availability of
interpretable information about the features that lead to a given prediction is key for clinical
utility  in particular  svm and knn lack interpretability  which may lead to limited clinical use 
thus  even though some of these classifiers may have high performance  e g   svm   they may
not be the best choice for a clinical task  using a classifier with interpretable information about
how predictions were made can lead to a greater understanding of the disease  for instance  the
most important features identified by random forest  i e   the amplitude of the t wave and st
interval from lead v  and lead avr  give dr  perez new criteria to pay attention to when trying
to use an ecg to determine if a patient has hcm 
conclusion
in this work  we compared and contrasted the performance of five machine learning algorithms
at the task of classifying ecg records as coming from a person with and without hcm  we
found that svm  random forest  and adaboost performed the best across nearly all metrics 
furthermore  all methods performed better on   lead data than on    lead data and performance
is not decreased when only including the top    most important features  the algorithms have
high enough sensitivity and specificity to suggest that ecgs can be used in place of
echocardiograms for diagnosing hcm  this has a significant impact on clinicians ability to
screen for hcm and reduce the occurrence of sudden cardiac death  in conclusion  we have
identified new electrical patterns that characterize hcm and shown that machine learning
algorithms can accurately differentiate between patients with hcm and controls using ecg data 
contributions
emily  rachel  and dr  perez conceived the project  emily and rachel performed all analyses  wrote the paper  and
conveyed results to dr  perez 

references
    maron  b j   et al   prevalence of hypertrophic cardiomyopathy in a general population of young adults 
echocardiographic analysis of      subjects in the cardia study  coronary artery risk development in
 young  adults  circulation               p        
    maron  b j   hypertrophic cardiomyopathy and other causes of sudden cardiac death in young competitive
athletes  with considerations for preparticipation screening and criteria for disqualification  cardiol clin 
             p           vi 
    maron  b j   hypertrophic cardiomyopathy  a systematic review  jama                 p          
    wigle  e d   et al   hypertrophic cardiomyopathy  the importance of the site and the extent of hypertrophy  a
review  prog cardiovasc dis               p       
    https   www cardeascreen com    product html
    liaw  a and wiener  m  classification and regression by randomforest  r news              p        
    dimitriadou  e  et al    e      misc functions of the department of statistics  e       tu wien       
available  http   cran r project org package e     
    michailides g  johnson k  culp m  ada  an r package for stochastic boosting  j stat softw              

fi