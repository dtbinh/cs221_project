predicting how many citations an academic paper
will receive
kyler siegel
december         

 

introduction

the goal of this project is to determine to what extent an academic papers success  as
measured by the number of citations it receives  can be inferred solely from the papers bibliography  i e  its list of references and the number of citations each reference received  the
basic intuition is that perhaps high caliber papers tend to have high caliber bibliographies 
or perhaps there are certain non obvious signatures of a bibliography that are characteristic
of well cited papers  we attempt to train a supervised machine learning algorithm on a
large set of paper citation data  if successful  one could feed any papers bibliography  along
with appropriate citation data for each reference  which is generally available through online
databases  into a previously trained machine learning algorithm to get a good prediction of
how successful the paper will be  without ever actually reading the paper 

 

the data

we gathered academic paper citation data from the online database scopus  for each of
       papers we formed a feature vector which includes the number of times each reference in
the bibliography was cited  along with the year of publication and general subject category of
the paper  the papers were taken from the broad categories of arts and humanities  biology 
psychology  mathematics  and physics  for each subject we gathered data for papers from
      top journals  dating from the nineties to the present  the data was scraped from
the web using a fairly simple python program involving the module mechanize and regular
expression functionality  we removed from the dataset any paper which either received
  citations or had   references which received citations  the logic being that these papers
probably represented incomplete or inaccurate citation data  after this removal the dataset
contains        papers  since different papers can different numbers of references  we padded
each paper by zeroes so that all the vectors have the same length  the largest number of
references turned out to be     so after padding all vectors have this length 

 

fi 

running machine learning algorithms

with the data in feature vector format  we ran various machine learning algorithms for
regression on the data set  the algorithms we used  primarily adapted from the sklearn
python module  are as follows 
 linear regression
 ridge regression  a generalized linear model 
 lasso regression  a generalized linear model 
 elastic net regression  a generalized linear model 
 support vector regression wth linear kernel
 support vector regression with radial basis function  rbf  kernel
 random forest regression
 support vector machine for classification with the y values discretized into   parts 
using medians to assign values to each part of the resulting partition
 same as above  but with   parts
 same as above  but with   parts 

 

results

in order to evaluate the success of each algorithm  we used ten fold hold out cross validation 
namely  we randomly divided the data into    parts and tested the algorithms on one of
the parts after training on the union of the other   parts  to measure the test accuracy  we
used two measures  r  and the average absolute fractional error e  here r  is defined by
p
p
ssres
  where sstot   i  yi  y     ssres   i  yi  fi      with yi the observed values  fi
 
sstot
the corresponding predicted values  and y the mean of the observed values  moreover  we
 fi  yi  
define e to be the average over all test points of
  the average absolute fractional
 yi  
error has the advantage of being scale invariant and easy to interpret  with a larger value
indicating larger average percent error  however  it does not it does not account for variance
in the data  namely  i the yi are closely concentrated near y  it is easy to achieve a small
value for e simply by picking all the fi s to be y  on the other hand  r  accounts for this
by taking into account the variance of the data  at the cost of being slightly more difficult
to make intuitve sense of 
the resulting accuracy data is as follows 

 

fir
e

 

lr
     
     

ridge
     
     

lasso
     
     

en
linear svr
           
           

rbf svr
     
     

rf
svm   labels svm  
           
     
           
     

in terms of r    the generalized linear models perform the most accurately  with the
random forest regressor performing almost as well  in particular  lasso performs the best 
the support vector machine based algorithms performed considerable worse  on the other
hand  with respect to e the discretized support vector machine algorithms performed the
best  followed by support vector regression  whereas the generalized linear models have much
larger e values  in terms of e the discretized support vector machine with   labels performs
the best 

 

conclusion

unfortunately  the largest r  value of any of the machine learning algorithms we tested is
       which is probably not large enough to make any reliable predictions in most applications  this likely indicates that the citation number of a paper is not easily predicted
in terms of the papers bibliography  and indeed one should actually should the paper to
better judge its quality  on the othe rhand  it is also possible that gathering more data may
improve the learning algorithms  in particular  since our data was mostly gathering from
high end journals  we may have missed parts of the feature space containing journals with
lower impact factors 

 

svm  
     
     

fi