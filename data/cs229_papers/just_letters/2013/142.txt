a predictor for movie success
jeffrey ericson   jesse grodman
cs     stanford university

  introduction
what makes a movie successful  the right combination of talent  chemistry  and timing  all with some
good luck  consider the shawshank redemption and gigli  the former a flop at the box office  overshadowed
at the      academy awards by forrest gump  and ignored for many years   until its rise from a cult hit to one of
the most revered movies of all time  the latter was poised for success  with ben affleck and jennifer lopez costarring at the height of their popularity  yet the film became a poster child for movie disasters  though there are
many factors that comprise a movies success  and it is not always clear how they interact  this paper attempts to
determine these factors through the use of machine learning techniques 
we predict five different measures of success  based solely on what we know about a movie before its
debut  many attributes reveal themselves after a movie premiers  but our input features include only that which a
producer can influence during planning and production  our measures of movie success are diverse enough to cover
a variety of perspectives  from popular review to critical review to gross profit 

  data
    data collection
the first step was to collect data  there was no pre existing dataset with the movies and features we
wanted  so we collected data from multiple sources and merged it  our main sources of data are imdb  rotten
tomatoes  and wikipedia  the mechanism through which each of these sites makes their data available varies everything from an api  thank you  rotten tomatoes  to messy space delimited text files  we need to talk  imdb  
from imdb  we obtained for each movie  movie title  imdb rating  plot description  budget  box office
gross  and opening weekend gross  from rotten tomatoes  we obtained critic score  audience score  runtime 
mpaa rating  studio  theater release date  dvd release date  list of genres  abridged list of cast  and abridged list of
directors  from wikipedia  we obtained the number of academy awards that actors and directors in each movie had
won prior to that movie  and also the number of best picture films that actors and directors in each movie had been
involved in  also prior to that movie  we collected the same data from the golden globes  in order to stay true to our
goal of only considering factors known before a movies release  we considered only awards that had been received
prior 
using python and javascript to extract  parse  and clean up what we retrieved  we had our data   albeit
unmerged  we removed rows from each table that did not have a complete tuple of information  in particular  rotten
tomatoes often had important attributes missing about less popular movies  like runtime or studio   to merge the
files  we keyed on a combination of two fields  normalized movie title and release year  to normalize movie titles 
we uppercased all titles and stripped all non alphanumeric characters  finally  we loaded each table into a sqlite
database and joined all three tables  leaving us with a data set of movie information with       movies  our data
made sense  the highest rated movies across imdb and rotten tomatoes include the dark knight and the
godfather and the lowest rated movies include justin bieber  never say never and from justin to kelly  alas 
maybe the best classifier predicts that if a movie title includes the word justin  it is destined for failure 
our data set represents many features as bit vectors  some features have been parsed into other features 
such as splitting the release date into bins by month and bins of five years  we also added a feature for whether a
movie came out on a popular weekend  like the fourth of july or christmas   and included a feature for whether a
movie was a sequel  third installment  or later in a series  our final input feature vector contained     features   
pertaining to bit vectors for mpaa rating    for movie runtime     pertaining to bit vectors for movie studio     for
release month    for popular weekends    for year bins    for budget    for awards  one for each of the following for
both academy and globe  sum of all award winners among the cast  director  and those involved in a best picture  
   pertaining to bit vectors for genre     pertaining to bit vectors for the most popular words in a movies plot
description  after removing stop words and words that seemed unrelated to movie content   and   bit vectors for the
movies place in a series 

fi    data cleaning and improvement
after some preliminary runs of our machine learning algorithms  we had decent results  but felt we could
do better if we cleaned up the data  each imdb rating comes with both a numeric rating and the number of votes
cast  concerned that less well known movies with fewer votes would be unreliably rated  we plotted the number of
votes vs  the rating  and what we found was interesting 
movies with more than     votes trend
towards a higher rating with more votes 
however  with fewer than     votes  there is
little structure to the data  based on this  we
removed all movies with fewer than    
votes from our dataset 
we noted that we had three
monetary attributes  budget  us gross profit 
and us opening weekend profit  in order to
maximize the utility of these fields  we
accounted for inflation and population
growth  for the budget  we accounted only
for inflation  since the population has no
direct relation to it 
for us gross profit and us opening weekend profit  we accounted for both inflation and population
growth  using the following calculations 
budget    budget    usd in          usd in year of movie 
us gross profit    us gross profit    usd in          usd in year of movie     us population in        us
population in year of movie 
us opening weekend profit    us opening weekend profit    usd in          usd in year of movie     us
population in        us population in year of movie 

interestingly  after accounting for these factors  all three fields are fairly constant over the last    years 

fi  machine learning techniques
    locally weighted linear regression
we chose locally weighted linear regression as a first approach  since it is easy to implement and makes
few assumptions  additionally  it seemed natural that we should weight success of similar movies more heavily  we
implemented the algorithm in matlab  making sure to normalize our input vectors  very important since our input
features are on widely different scales        for runtime minutes  but millions for budget  
intending to next run a classification algorithm and desiring to directly compare the performance of the
two  we discretized the output space and ran it as a classification algorithm  we did this by measuring the median
for each output value and predicting outputs as usual with locally weighted linear regression  we classified the
prediction as a success if the predicted and actual values were either both above or both below the median 
we measured the accuracy rates on all five outputs for various values of tau  we did this using       holdout cross validation  training on     of our data  and testing on the remaining     

critic score
audience score
us gross
us opening
imdb rating

t       
      
      
      
      
      

t       
      
      
      
      
      

t      
      
      
      
      
      

t      
      
      
      
      
      

t      
      
      
      
      
      

t      
      
      
      
      
      

     was found to be a reasonable value of tau   below it  performance dropped rapidly  it is interesting to
note that the performance decreases as tau increases  this indicates that there is some merit to the use of locally
weighted linear regression  as opposed to standard linear regression  if locally weighted linear regression provided
no benefit over linear regression  there would be no decrease in performance  and perhaps even an increase in
performance  as we increased tau  making the algorithm more and more similar to linear regression 
    svm  support vector machine 
the second machine learning technique we applied was svm  with svm  we could use all     of our
input vectors and then pare down the space by use of filter feature selection  which uses the forward search
paradigm to choose a subset of features with which to make predictions  as with locally weighted linear regression 
we predicted whether a movie performed better or worse than the median found across our entire dataset for each
output feature  we asked the following questions  based on the medians  
   does a movie have a rotten tomatoes critics score above     on a scale to      rotten tomatoes labels a movie
either fresh with a     score or rotten with a score below     
   does a movie have a rotten tomatoes audience score above     the median value  also on a scale to      
   did a movie gross over      m in the united states  the median  
   did a movie gross over     k in the united states its opening weekend  the median  
   did a movie have an imdb score of     or above  the median  on a scale to     
for each output feature  we performed a separate filter feature selection  we grouped bit vector features
that were from the same category  for example  our dataset has    bit vectors to represent a movies genre
categorization     total genres   we grouped these    features together when performing filter feature selection 
we ran svm with a linear kernel because it was the only one that both converged and had a classification
rate substantially above      also  we used l  regularization  with the slack penalty c set to       this value was
a good compromise that caused the algorithm to converge after a reasonable number of iterations without allowing
for too many misclassifications  c is rather low  but this is not surprising given the huge variety in movies  it made

fisense not to employ a heavy penalty  but instead to fit a decision boundary to the majority of movies and accept the
misclassification of movies that do not fit the general trend 
filter feature selection provided us a list of features ranked by score  which was the test success rate from
cross validation   with ranked features  we then performed hold out cross validation  again         training test 
for each of the top k features  in practice  we tested k from   to      we chose k based on which k had the highest
test prediction rate  or equivalently  the lowest test error rate   while this method does not provide optimum results 
it provides a good heuristic  we arrived at   different subsets of input features for predicting each of the   output
features  for each of the   subsets  the optimal value of k was somewhere between   and     this was one of the
motivations for extending our testing of k to     
the   subsets had many input features in common  each contained the features pertaining to genre  mpaa
rating  runtime  and studio  however  budget was meaningful for critic score  box office gross  and opening
weekend gross  but not audience score or imdb rating  by meaningful  we mean that the smallest cross validation
test error was realized without this input feature   number of awards won by cast members  both academy awards
and golden globe awards  was only a meaningful feature for audience score  box office gross  and opening
weekend gross  release month was a meaningful feature for box office gross and opening weekend gross  but not
for any of the ratings  of all the words used in movie plot descriptions  most were not meaningful  four that were
include life and story which were not meaningful for box office gross or opening weekend gross  but the former
was meaningful for all the ratings and the latter was meaningful for all the ratings except the audience score  the
other two words were find and must  which were meaningful only for both box office gross and opening
weekend gross 
below are the resulting prediction rates for cross validation  whether a sample from the test dataset was
correctly predicted as being above or below the median for the particular output feature  using the top input feature
subsets for each of the   output features 

success rate
for critics
score

success rate
for audience
score

success
rate for us
gross

success rate
for open
weekend
gross

success rate
for imdb
rating

feature set for critics score

       

       

       

       

       

feature set for audience score

      

       

       

       

       

feature set for us gross

      

       

       

       

      

feature set for open weekend gross

       

       

       

       

      

feature set for imdb rating

       

      

      

       

       

we achieved roughly a     success rate for each of the rating outputs and     success rate for each of the
monetary gross outputs  using a group of features was an improvement over using any one feature category  even
though some single feature categories were indeed highly correlated with outputs  from our filter feature selection
scores  the most correlated feature category for us gross was studio        and for us opening weekend  it was
genre        the most correlated variable for ratings was always genre      for critics score      for audience
score  and     for imdb rating  thus  the gain from including multiple features was least realized in predicting
critic score  which we would have been nearly as successful doing by just considering genre 
it is interesting to note that the feature set for each output feature did not necessarily achieve the highest
success rate for that feature  for example  consider imdb rating  the success rate was actually highest using the
input feature set for audience score  this is not overly surprising  since the rates are close  the feature selection
algorithm is greedy  and does not promise to find the best possible set of features  also  we measured these rates
using one pass of       cross validation  which is likely to introduce some noise 

fito measure the balance between bias and variance  we plotted a learning curve where we trained on     
          and     of our samples  the plot below uses the input features set found for critic score  and measures
the classification success of critic score 

as we see the success rates approach one another at      we can infer that we do not have a problem with
high variance  it seems reasonable that we might achieve a success rate above      so perhaps we have high bias 
and a better model exists for the data  we noted that having more input features can help lower bias  so this was one
of the points at which we both gathered more data and cleaned up our existing data  as we discussed in the data
section above  in fact  our initial data collection contained about      movie samples  while our final dataset has
over        with many more features 
the classification rates we achieved with svm are higher across the board than with locally weighted
linear regression  the main reason for this is likely that we were able to use many more input features  as locally
weighted linear regression is a regression algorithm  we could not use input features that do not have a natural
numeric representation  like genre or mpaa rating 
  conclusion
using svm  we achieved classification rates well above     for each of our output features  while the
success rates are perhaps not ready for use in financial analysis  our results provide insight into what makes a movie
successful  for instance  it was revealing that movies with the words life or story in the description have higher
ratings  we verified that these input features correlated with movie success  not failure  and the words find and
must correlate highly with positive box office gross 
one self imposed limitation in our approach is that we allowed ourselves only to consider as input features
those which are known about a movie pre release  for example  we could surely have achieved higher success rates
if we considered the awards that a movie would go on to win  but this did not seem very insightful  our dataset was
also heavily skewed to movies post       as many before that do not have accurate financial data 
while a near perfect predictor some day would be a machine learning triumph  it could also lead to an
overly algorithmic approach to movie planning  studios may be less willing to take risks  and outliers are often some
of the most exciting products of hollywood 
references
cs    course notes
www imdb com
www rottentomatoes com
www wikipedia org
www usinflationcalculator com

fi