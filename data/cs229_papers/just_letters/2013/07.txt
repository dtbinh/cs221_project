cs    final report

mohammad muneeb sultan

feature selection in
biological models
mohammad muneeb sultan  stanford university

olecular dynamics md  of biophysi  cal simulations 
cal systems suffer from a lack of systematic way in understanding the resulting trajectories in this project  i show methods
that the combination of supervised and unsupervised learning on md data allows us the methods employed in this paper can be sumto gain both holisitic and atomistic insight marized as follows 
about the dynamics of the system 
 generation of the data running the md engine on the protein to generate the trajectories 
introduction

m

one of the most difficult problems with running
classical newtonian simulations of large biophysical systems is the lack of a systematic way to
understand the resulting trajectories  most common approaches include viewing the trajectories
or plotting some key parameter as a function of
time  this methodology works because in most
biological systems  only a few things change when
going from inactive to active regimes 
however  the question arises  how do we know
what features degrees of freedom are relevant
within in the system and more importantly how
can we objectively ensure that we do not miss
anything  this problem is a variant of feature
selection and decision boundary identification
within machine learning literature and has been
significantly studied in the past under the umbrella of supervised machine learning  in this
project  i intend to show that the gini importance used in building decision boundaries for
tree classifiers can also be used to efficiently find
important features degrees of freedom in biologi 

 application of unsupervised k means learning algorithm to generate protein clusters
from the trajectories 
 vectorized representation of training and
test conformations poses of the protein in
desired feature space 
 supervised learning on the features for importance ranking 

details of each of these steps will be presented
in the following subsections  a key point here is
that we are using the rmsd for the unsupervised
learning algorithm but are using dihedrals as the
features  for the supervised portion  the idea
being while rmsd can cluster the data efficiently 
it lacks the ability to provide atomistic detail and
while dihedrals can provide atomistic detail but
are not able to cluster the data properly  this
would in theory allow us to explain very high
dimensional clusters via only a few key degrees
of freedoms  a variety of supervised learning

page   of  

fics    final report
algorithms were employed although ultimately 
the decision tree classifier was unmatched in
terms of accuracy and relative ease of understanding the resulting model  only the results of the
decision tree will be given in this project  all
unsupervised learning algorithms were employed
using the msmbuilder software    and supervised
learning algorithms were used from the excellent
scikit learn python library    

newtonian dynamics
newtonian dynamics on alanine dipeptide  figure
   were run using the amber   sbildn potential
energy function      individual trajectories with
an average length of    nanoseconds were generated  for the second test case the ubiquitin
enzyme  longer trajectories          seconds 
were run but with the same potential energy function the data for the second protein enzyme was
obtained from a colleague in the pande lab 

mohammad muneeb sultan
alanine peptide as shown in figure    the unsupervised algorithm created divided the data along
natural boundaries 
similar approach was used for the ubiquitin
enzyme but with k   the results from the unsupervised learning were again obtained from my
colleague gert kiss 

feature vector generation
after this initial step  each alanine conformation
was expressed as a vector using    features  the
first two were the actual protein backbone dihedrals  which we would like to be identified as being
important  while the last   were random gaussian noise  which should ideally be ignored table
  contains   training examples without the   normally distributed noise columns   the aim of
this was to find out if an algorithm could find
the right features that can explain the data while
ignoring random noise  for the ubiquitin test

table    example of vectorized representation of
conformations for alanine dipeptide

index





 
 

          
            

label
 
 

figure    the alanine dipeptide molecule with its two case  each conformation was expressed using the
backbone dihedral that totaled to     dihedrals
main degrees of freedom     

 i e      features   again  only a few dihedrals
are likely to be important in this dataset 

unsupervised learning

supervised learning   feature
selection

supervised machine learning requires that we
have labeled training data that can be used to
train a predictive model  but  the concept of
a label in a biological system is difficult to define  in order to generate these labels  a trick
was employed  state models for the protein simulation data were built using an unsupervised
k means  k    learning algorithm  these models
were built using the root mean squared deviation  rmsd  of the heavy atoms for each of
the        poses conformations adopted by the

the primary aim of this paper was to identify a
fast method for feature selection in simulation
data  for this purpose  feature selection via decision tree classification was employed  such
methods have been used in the past and have
gotten quite excellent results    moreover  tree
classification was used because of its ability to
handle various kinds of data binary continuous 
and the simplicity of the resulting model these
trees present a very natural way of looking at
simulation data where  often  a few key degrees

page   of  

fics    final report

mohammad muneeb sultan

of freedoms contain bimodal or trimodal distributions and the aim of the classifier is to find the
decision boundary capable of dividing the data
along these lines efficiently  for example the 
distribution in alanine dipeptide has a bimodal
distribution around      and     degrees which
divides the data along states     and     
decision trees find boundaries in data by selecting the best feature capable of distinguishing
between the output classes  at each node    the
optimal split is one that maximizes the information gain at that node via a reduction in the gini
impurity of the subnodes  this is done by calculating the gini impurity for a node n and then
calculating the gini impurity for each sub nodes
after a split if made eq     the information gain
for each feature   is then the weighted gain in
information for that feature at that node eq    
for the simplest binary classification model  this
can be represented as follows 

giniimpurity       g        

 
x

alanine dipeptide
as it can be seen in figure   the alanine dipeptide is a very simple molecule with two main
degrees of freedom characterized by the backbone  and  dihedrals  the molecule is free
to rotate around these bonds but its dynamics
are limited by the interaction of the side chain
atoms  running the newtonian dynamics and
clustering the resulting data using rmsd identifies chemically well known   macro states of
the alanine  these   states correspond to the
low energy basins in our high dimensional manifold figure      using the vectorization scheme

 p  k     

k  

   
nl
nr
inf gain   ig     g     g l   
g r  
n
n
   
x
giniimportance   ig     
ig    
    figure    results from the unsupervised learn

where nl is the number of training examples in
the left node nr is the number of training examples in the right node  k is the summation over
all the target classes  and  is the summation
over all the times that a particular feature was
used to split the data  features that are selected
more often or can cause a higher reduction in the
impurity of the data have a high gini importance 
thus  a feature  s importance is the normalized
total reduction in the impurity brought upon by
that feature  i e if a feature such as  in alanine dipeptide  can divide the data up better
than other features  then it would have a higher
gini importance  in order to avoid over fitting 
cross validation with         of the data was performed  in both cases  the generalization error
was less than     indicating that the resulting
trees were generalizing quite well 

results   discussion

ing using the rmsd metric  on the dynamics of alanine dipeptide molecule projected onto its two main degrees of freedom
    

detailed above  a training set was fed into the
a decision tree classifier  the aim being to find
the features capable of distinguishing between
the different macro states  cross validation using
    of the original data was performed and the
results projected back onto     dihedrals are
shown in figure    as show  the decision tree was
able to learn the boundaries in our data quite
well even though it was never given the rmsd
as an input feature 
more importantly  the gini importance correctly identified the     as being the only two
features out of ten  as being important in explaining the variation in the data  more importantly 
the random gaussian noise features are being
completely ignored 

page   of  

fics    final report

mohammad muneeb sultan
  the  helix kinks back down locking the loop
in place 

figure    results from feeding     of the dataset into
the trained classifier  the decision tree
algorithm correctly identifies the boundaries
in the high dimensional dihedral space and
figure    the ubiquitin enzyme with representative
correctly assigns the macro states despite
structures from the three states identified via
not being given the rmsd for each case the
unsupervised learning  the system moves
test classification error was less than    
from red to white to blue and its dynamics
in this particular case 
are characterized by the movement of turn
and the  helix 

but again  we are lacking important atomic level
information about this movement  similar to the
alanine dipeptide  the conformations in ubiquitin were represented as a     dimensional vector
consisting of the backbone dihedrals of the proteins         of the data was then fed into a
decision tree classification system followed by
cross validation on the remaining       the gini
figure    the gini importance of each feature in the importance of each of those dihedrals was then
case of alanine dipeptide  as it can be see calculated and plotted figure    
supervised learning correctly identifes the
    as being the most important features the value of  is less than that of 
because of the difference in the number of
training examples 

ubiquitin enzyme
for the next test  the dynamics of the ubiquitin
enzyme were broken down via this analysis  clustering the ubiquitin enzyme trajectories led to
the   macrostates as depicted in figure    visual
inspection of the clusters reveals that the system
figure    gini importance for the backbone dihedrals
follows a three step model in locking the turn 
  the  helix kinks up and towards the left 
  while the  helix is up  the loop moves down 

in the ubiquitin enzyme  the  th  corresponds to the loop movement and the   th 
corresponds to the  helix kinking up and
down 

page   of  

fics    final report
as shown above  the entire ubiquitin motion
can be broken down using the  th  and   th   
the former corresponds to the loop moving down
while the latter explains th helix kink  a time
average of these two dihedrals figure    confirms
what was already suspected from the looking at
the macrostate models namely the three step process  however  the advantage of this analysis is
that we can now systematically eliminate features
that do not meaningfully explain the data 

mohammad muneeb sultan
receptors gpcrs  

acknowledgments
the author would like to thank his colleague
gert kiss for providing the trajectories and the
unsupervised clustering results for the ubquitin
test case 

references
    ka beauchamp  gr bowman  tj lane  l
maibaum  is haque  vs pande  jctc      
msmbuilder   modeling conformational
dynamics at the picosecond to millisecond
timescale
    scikit learn  machine learning in python 
pedregosa et al   jmlr     pp            
     

figure    moving average plot for the dihedrals identified in figure   these plots follow what
we observe via visual inspection  namely
that the helix purple  kinks up followed by
the loop green  moving down and the helix
moving back to lock the loop in place 

    tahir  n m   hussain  a   samad  s a  
ishak  k a   halim  r a   feature selection for classification using decision
tree  research and development       
scored        th student conference on
  vol   no   pp               june      doi 
        scored             

conclusions
the aim of this project was to develop a method
for feature selection in md trajectories  to
accomplish this  a two step process was employed the rmsd of heavy atoms was used to
generate high dimensional clusters via the kmeans algorithms  these cluster labels were then
used in supervised learning and feature selection
steps  to this end  cross validated decision trees
were trained on the vectorized representation of
these trajectories and the gini importance of the
resulting features was used as a feature selection
criterion in understanding these trajectories the
two test cases alanine dipeptide and ubiquitin 
highlighted the strengths of this approach and
its ability to break down very high dimensional
and highly correlated data  future work will extend this method to larger and more complex
systems such as kinases and g protein coupled

page   of  

fi