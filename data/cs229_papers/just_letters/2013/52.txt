predicting texas holdem hand strength
james bensson  alex eckert  maxwell wu
december         

 

motivation

it all comes down to this  you are in the final
round at the texas holdem world series of poker
championships  just two people remain  you
and jack manningham  the river runner  who
just went all in  what should you do  call him
and try to end the game  or play it safe and let
him steal the pot  dilemmas similar to this constantly plague texas holdem players and in order
to help answer this question we developed models
figure    example hand rank
to predict a players hand strength based on their
betting behavior 
features

 

initially  we used the following feature set for each
player 

variable formalization

this paper will assume some basic knowledge of
texas holdem terminology  we were first presented with a large amount of unformatted data
and had to decide on what to extract for use 






number
number
number
number

of
of
of
of

checks before the river
bets before the river
calls before the river
raises before the river

target variable   hand rank  hr 
as we progressed in our analysis we chose more
hand rank is defined as the percentage of other robust feature sets 
combinations of two hole cards that a players
current two hole cards will beat in hand strength 
 value of bet compared to the current pot
hand rank does not take into account future examount
pectations  since poker hand rankings are lin number of bets in certain ranges compared
ear  a higher hand rank strictly implies the hand
to the current pot
will win versus another hand of lower hand rank 
 ratio of aggressive  bet raise  moves to pasknowing an opponents hand rank on the river
sive  check call  moves
would thus allow a player to play with perfect
 average bet in the round compared to the
information 
pot size
figure   shows an example of a hand with a hand
 number of actions in a certain round
rank of       although the player paired with the
highest card on the board will beat many other   data
hands  there are still many hands that can beat
the players hand  such as two pairs  triples  and we initially leveraged an online poker framestraights 
work to generate player data  which allows users
 

fi a  actions vs  hr

 b  bet size vs  hr

figure    feature correlations
best results on our dataset  note that we are
using the feature set defined above 

linear regression

figure    data parsing pipeline
to create their own poker robots  alter existing
poker robots  and play different robots against
each other  the main benefit of initially using
bot generated data was transparency  no matter
what happens in a round  we see the bots hand 
using bot data allowed us to get a sense for which
algorithms would work well  but was ultimately
not too interesting and did not accurately mimic
real world poker conditions 

to motivate linear regression  we first checked
for a correlation between our chosen features and
hand rank  as shown in figures   a  and   b  
each feature is indeed correlated with hand rank 
four of the five features  bet size  amount of bets 
amount of checks  and amount of calls are positively correlated with hand rank and the amount
of checks is negatively correlated with the hand
rank 

we switched to using a dataset of human poker
games  provided by the university of alberta
poker research group  the data set is of poker
games played over irc  by humans  and each
player has a limited amount of chips  because
there is a scarcity of chips  players play to maximize their winnings and their behavior mimics
that of real life poker 

with the evidence for feature correlation in hand 
linear regression was a natural algorithmic choice 
to perform linear regression we first expanded
our feature set by incorporating not only a
players total game actions  but their individual round actions  the thinking here is that a
check during the flop may be weighted differently
than a check during the river when trying to predict the river hand rank  furthermore  we added
more features by fitting each action and amount
with a fifth order polynomial  to determine the
most important features of our algorithm  we conducted a forward search through the feature set 
shown in figure   a   as more and more features
were added  the error of the predicted hand rank
dropped 

the data was initially stored as individual
databases  each database was organized in the
relational model  with a table of hands  a table
of rosters and a table of player actions for each
player  getting the data into the form we wanted
was difficult and the pipeline we used for parsing
our data is depicted in figure   

there were a number of different types of hand
the most important features were found to be 
databases stored overall  we chose to learn on no
the amount bet during the river  turn  post flop 
limit  holdem tournament data 
and pre flop  next  to determine if we were overfitting or underfitting the data  we generated a
  models
learning curve  shown in figure   b  
we decided to try a few out of the box learning since the training error and test error converge
models in order to see which algorithms have the in the learning curve  we concluded that we were
 

fiunchanged when locally weighted regression was
run on the clustered dataset 

naive bayes

 a  error vs  features

our goal with our naive bayes analysis was to
predict hand rank given classes of hands that a
player might have at the river of a poker round 
we reasoned that 

 b  learning curve

figure  

players will not change their betting patterns
based on exact hand rank  instead  they will usually change their betting patterns based on general types of hands  i e  bluffing hand  medium
strength hand  made hand  straights  flushes  full
houses  etc   or the nuts  best hand possible  
certain bet sizes are more likely to indicate certain types of hands earlier in the poker round  for
example  we reasoned medium sized bets might
be more indicative of a decent or very good hand 
while players may make more small bets when
they are waiting for a card to complete their
hand 
types of actions on each round may indicate different hands  for example  someone who is callunderfitting the data  unfortunately  due to a ing in earlier rounds but raising in later rounds
shortage of any more features  we could not min  may mean they had a weak hand at first but a
imize our error any further  we calculated our strong hand after a certain card 
final average predicted hand rank error on a set we decided on using six bins  we wanted enough
of         games where we trained on     and bins to make the information useful and applicatested on      the average hand rank error was ble  but not so many that players would have the
        this result was roughly unchanged when same behavior over different bins 
linear regression was run on the clustered dataset 
choosing bins and features for naive
locally weighted regression
bayes
figure    error vs  

another approach we took to predict player hand
rank was locally weighted regression  we used the
same feature set with fifth order polynomials as
used in linear regression  since locally weighted
regression is more computationally expensive  we
only examined      games  training on     and
testing on      shown in figure    we minimized
the hand rank error by varying the bandwidth
parameter   

because naive bayes is a classification algorithm 
we had to transform our continuous hand rank
and bet sizing features into discrete bins  we
found that having different bins for these greatly
changed the results  so we strived to have a bin
distribution that was both logical and produced
good results  we started the models with even
bin distributions for both hand rank and bet sizing  but in the end we decided to primarily change
the hand rank bins due to the nature of hands and
hand rank distribution on hands that get to the
river  see figure   for our final hand rank bin
distribution 

the error minimizing  was found to be     
the minimum hand rank error was found to be
        about    greater than that generated
by linear regression  this result was also roughly
 

fifigure    final bin distribution

figure    distortion vs  k
differently  unlike our naive bayes and linear
regression  we could use all the data we had to
determine how aggressive a player is  it was no
longer necessary that we actually saw the players
hand at the end of the round  for clustering we
used two features 

figure    error rate improvement
results for naive bayes
when we first ran our naive bayes analysis with
a simplified feature set  the results were underwhelming on the human data set and mediocre
on the poker bot data  as we added in bet sizing
features and more sensible hand rank bins  our
results greatly improved to almost perfect on the
bot data and about     exact bin prediction on
human data  lastly  predictions using clustered
data input improved the human data prediction
rate to over     with a      average bin error 
figure   shows our results as we iterated on our
model 

 

features 
 aggressionf requency  

bets raises allins
allactions

 avgroundsp layed   avg    of rounds before the user folds
our idea was to cluster the data into k clusters
and then partition our original dataset so that we
train on each type of player instead of the entire
dataset  the question then became  how many
types of players are there  or more formally  what
is the best value of k  figure   plots the average within cluster variance  distortion  vs  the
number of clusters 

clustering player types

from figure    we can tell that there is not strong
clustering in the data and also no clear choice for
k  we tried      and   and found that   clusters
worked the best when we partitioned the data
and retrained our models  after running k means
 with k       our final clusters are depicted in
figures   and     these diagrams are dependent
on what threshold we placed on the number of
player actions we had to see to cluster them 

the next idea we had was to model different types
of players differently  anecdotally  there are a
number of different types of poker players  for
example  there are aggressive players who bet and
raise often  and there are also more risk averse
players that fold readily when they dont have
a winning hand  we would expect a risk averse
player and an aggressive player to bet very differently given the same hand  but there is nothing in
our model that captures this  for this reason we
decided to use k means clustering on all player
data in order to model different types of players

partitioning the data and training on different
models helped our naive bayes model jump approximately     in accuracy 
 

fi 

conclusion

in conclusion we used a players actions and betting patterns to predict their hand rank  using three machine learning algorithms  linear and
weighted regression  naive bayes  and clustering 
we were able to improve our hand rank predictions quite drastically 
our final naive bayes algorithm on clustered data
was able to predict the exact bin  out of    that
a poker players hand was in     of the time and
on average the prediction was off by less than one
bin  at first  we thought that predicting human
trends would be extremely hard due to the nature
of poker  with humans trying to trick each other  
but we ended up with an algorithm that could
perform well without extensive data on a specific
player 
one issue we had in our human data was that
it was incomplete due to the nature of our data
source  we hope that our algorithms could perform better with complete information of every
hand instead of only certain hands  which could
be explored in the future 

figure    clusters        actions seen

 

references

    tefilo  l  f   reis  l  p        identifying
players strategies in no limit texas holdem
poker through the analysis of individual
moves 
    computer poker research group  university of
alberta        web    dec       
 http   poker cs ualberta ca   
    poker academy pro  the ultimate poker
software       
 http   www poker academy com 
    open meerkat poker testbed       
 http   code google com p opentestbed 

figure     clusters         actions seen

 

fi