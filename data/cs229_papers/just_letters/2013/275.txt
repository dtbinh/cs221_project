automatic grouping for social networks
cs    project report
xiaoying tian

ya le

yangru fang

statistics  stanford university

statistics  stanford university

statistics  stanford university

abstract
social networking sites allow users to manually categorize their friends  but it is laborious to construct and keep updating
those categories when a users network grows  leskovec et al      defines an unsupervised model to identify a users social
circles  however  in real life users have personal preferences about how to group their friends  indeed  it is possible that two
users have exactly the same social networks but categorize their friends differently  in such case  unsupervised methods will
fail to capture such personal preferences as they dont incorporate information about what kinds of social circles the user
finds valuable  in this paper  we develop a supervised model for detecting social circles that combines network structure as
well as user information  experiments show that our model achieves significantly higher accuracy than k means and naive
bayes  and has comparable overall performance to that in leskovec et al s work with lower computational complexity  our
method also turns out to have best performance on relatively small networks 

   introduction
as social network sites get bigger and more cluttered 
categorizing friends into different social circles becomes
a major mechanism for users to organize their social networks and cope with overwhelming volumes of information
generated by their friends  users in major social network
sites  e g  google   facebook and twitter  categorize their
friends either manually or simply by grouping friends sharing a common attribute  the goal of our project is to set up
a system which automatically categorizes a users friends 
we incorporate concepts from social network analysis into
machine learning techniques to solve the above problem 
research has been done on this topic via both conventional machine learning approaches such as decision trees
 baatarjav et al        and also social network techniques
 leskovec   mcauley       leskovec et al      proposed
an unsupervised method to tackle this problem  we propose
a new model that uses this method as a component 
given a single user  a network is formed by his her
friends  following      we refer to this user as the ego and
this network as its ego network  in our project  we formulate this problem as a supervised learning problem and take
into account both the profile information and the network
structure 
our method also differs from conventional clustering
methods in the sense that the clusters can overlap with each
other  we introduce a discriminative model to identify social circles based on the fact that circles tend to be densely

figure    sample circle diagram

connected with members sharing some common traits  with
maximum likelihood estimation  our algorithm can learn the
structure of the social circles as well as common features
within each circle  additionally  we compare our algorithm
with both the k means algorithm and naive bayes as baselines 

   dataset description
the dataset we used is the facebook dataset in      which
contains   ego networks comprised of      users and an
undirected social network with       friendship connections  the profile information is collected in    categories 
including languages  hometowns  birthdays  locations  etc 
social circle labels were obtained by asking the   egos to
 

fifigure    test error v s number of preassigned centroids
figure    feature space diagram

manually identify all the circles to which their friends belong  on average  there are    circles in each ego network
with an average size of    friends 

   feature construction
the profile of a single user can be represented as a tree
where each level encodes increasingly specific information 
 see figure     we construct the feature space by aggregating all the user attributes in a ego network and represent a
single users profile information as a binary vector  where
  indicates the user has this attribute  for example  figure     user x has profile  gender  male  education  degree  undergrad  education  school  stanford  education 
major  cs  education  major  math  language  french  
then his profile vector is                                       
note that such profile vectors are defined per ego network 
for example  although thousands of companies exist in the
whole facebook network  only a few appear among any particular ego network 
let t x    t x           tnx   denote user xs profile vector 
we define the difference vector lx y    tlx   tly    as an indicator of whether the two users x and y differ at feature l 
we define sx y       x y as the similarity vector  suppose the ego user is x    we construct the following two
features  one associated with nodes and the other associated
with edges   x    sx x    the similarity vector between
user x and the ego only and also  x  y    sx y   pairwise
similarity vector between x and y 

figure    number of resulting centroids v s k

only and let the preassigned number of clusters range from
  to     figure   shows that as the preassigned clusters
number increases  the test error increases as well  notably 
k means works the best in the degenerate case where there
is only one cluster  this indicates that k means is not the
right model for this problem and or featurization 
another issue with k means is that the number of resulting centroids may be less than k because some of the clusters merge  in this problem  we observe this as we increase
the parameter k   see figure    this indicates that a lot
of the clusters formed are garbage clusters  and increasing
k hurts accurate prediction  this situation occurs because 
first  the feature vector for each user is sparse with binary
outcome  as opposed to continuous outcome which is more
appropriate for the k means method  and second  in reality  the social circles in a social network do overlap  thus a
clustering algorithm is not proper here 

   methodology

     naive bayes

     k  means

we implement naive bayes with feature map  x  as our
supervised baseline model  recognizing that social circles
may overlap  we encode the social circles to which a user x
belongs as cx    cx            cxk   where cxl is a binary variable
indicating whether user x is in circle cl   and k is the total

we use the k means method as our unsupervised baseline model to detect social circles in the facebook data  we
implement the algorithm using the feature mapping  x 

finumber of circles  for each circle cl   we use cxl s as classification labels  and perform the naive bayes algorithm for
this particular circle  in this way  we obtain k classifiers
 h            hk    with hl denoting the classifier for circle cl  
the algorithm yields an average test error of         the
high test error is the result of some particularly big circles
in the network  some circles cover up to     of the users 
naive bayes is very likely to identify these circles while
ignoring other smaller circles  in some extreme cases  the
algorithm will assign users apparently at random to each
circle according to their size in the training data  regardless
of the users feature vector 

let l denote some trade off parameter which will be explained later  our algorithm will yield l   l by maximizing
the following log likelihood 
l       log p c  g         
  log p c    p g c         

   

the log likelihood consists of two parts  the first part is
the likelihood of the circle label c based only on the node
features  x   and the second part is the likelihood of the
edge set e based on the edge features  x  y  and the different circles c  since the circles cl and the edges e    x  y 
are generated independently  we will have 

     our model
in this section  we improve the featurization and propose
a more sophisticated model to better solve the problem 
     

l    log p c    
m
y
  log
p c i    x i      
i  

featurization

   feature space dimension reduction
both the previous two algorithms suffer from highdimensional feature spaces  noticing that similarity
vectors are sparse and that each entry of the vectors
corresponds to a leaf node in the profile tree  figure
    we address the issue by summing up the entries
belonging
p to the same category  more specifically 
sx y
  lchildren p  sx y
p
l   where p denotes category
p  this achieves a reduction in feature space dimension from over     to    for the facebook data 
   network structure
at this point  we have only used  x   the profile information for each user as our feature vectors  however 
we would also like to take into account the similarity
between the users to improve our model  more specifically  we will also incorporate the similarity vector
 x  y  between two users x and y to explore the network structure  as members of the same social circle
tend to be densely connected  this will provide important information about the social circle formation 

 

k
m x
x

 i 

log p cl   x i     l  

   

i   l  

l    log p g c       
y
y
  log
p e  e c       
p e 
  e c       
ee

 

x

ee
 

log p e  e c       

ee

 

x

log p e 
  e c       

   

ee
 

we use the logistic regression model to form the like i 
lihood of the circle labels  i e   p cl      x i     l    
t
 i 
g l  x     where g is the sigmoid function  for the likelihood of the edge set e in the graph  we observe that an
edge between x and y is likely to form if they belong to the
same circle cl in which case lt  x  y  tends to be high 
     thus the probability of e    x  y   e is 
p e  e c   e      
x
 exp 
lt  e  

x

l  lt  e  

cl   x y  cl

cl   x y cl

   
     

proposed model

we propose a discriminative model which considers both
the profile information and the network structure in order
to identify the social circles  the input to our model is an
ego network g    v  e   along with the feature vectors
 x  and  x  y  and circle labels  v and e denote the
node set and the edge set of the ego network  suppose the
users are  x              x m     with corresponding circle labels
 c              c m     we denote the feature vectors of all users
as  and   for each circle cl   let l denote the parameter
vector associated with shared features within the circle and

where l determines the amount we penalize if x  y   cl  
also let 
dl  e      x  y   cl    l    x  y    cl  
d e   

k
x

lt  e dl  e 

   
   

l  

then with the fact p e  e    p e 
  e       we got 
p e  e   

ed e 
    ed e 

p e 
  e   

 
    ed e 

   

fiby plugging eq    into eq     we get
x
x
l   
d e  
log      ed e   

   

ev v

ee

both l  and l  are concave  thus we are able to optimize
l   l    l  through gradient ascent  the update rule goes as
follows 
m

l     x  i 
 
 cl  g lt  x i      x i   
l
i  
 

x

dl  e  e  

x
ev v

ee

ed e 
dl  e  e 
    ed e 

figure    accuracy comparison

   
l    
 
l
 

x

lt  e   x  y    cl  

ee

x
ev v

ed e 
t  e   x  y    cl  
    ed e  l
    

we randomly select     of the users in an ego network
as our training data and obtain l  s and l  s by maximizing eq   using the gradient ascent update rules defined
above  to predict the circle labels of some user xi in
the test dataset  we compute the likelihood of p xi 
cl   g       for each circle cl   where g is the new network after adding xi   then xi is predicted to belong to the
top j circles that have the largest likelihoods  our results
show that j     usually gives very good predictions  while
one can also select j via cross validation 

     evaluation metrics

   experiment   results

we evaluate our method by examining the differences between the circles our algorithm selects
c    c            ck   and the true circle labels c  
 c            ck    we adopt the balanced error rate  ber 
as a difference measure between the two circles      and
take the average ber of all the circles as our error rate 
ber c  c   

   c c   c c 
 
 
  
   c 
 c 

    

for unsupervised learning methods like the k means algorithm  we dont know the correspondence between the
circles in c and c  as a matching heuristic  we align the
circles of these two types by minimizing
f  i    argminj    i  j       

figure    i for circle   in ego network  

    

where i and i are the centroids of ci and ci respectively 
therefore f defines a correspondence between c and c  i e  
cf  i  is the corresponding circle for ci  

during the implementation  we anneal the learning rate
 to accelerate the learning speed  the comparison of the
three methods we implemented is shown in figure    as expected  we observe that the k means method performs the
worst  and our method outperforms the naive bayes method
for   ego networks out of   
figure   plots the parameter vector   for circle c 
in ego network    the  th    th     th and   th entries in the
vector are significantly larger than the other entries  we further examine the corresponding categories in ego network  
and find that those entries correspond to education  school 
education  type  gender and locale  i e  location   which
are important features for social network detection  we also
plot the prediction results of a circle on ego network   as in
figure    in the plot  densely connected nodes form a cluster  the result shows that our model successfully detects
almost all the members of the circle 

fi    m  handcock  a  faftery  and j  tantrum  model based
clustering for social networks  journal of the royal statistical society  serires a       
    j  yang and j  leskovec  defining and evaluating network communities based on ground truth  in icdm 
     
    t  hastie  r  tibshirani  and j  friedman  the elements of statistical learning  springer series in statistics springer new york inc   new york  ny  usa      
    j  a  hartigan and m  a  wong  a k means clustering
algorithm  journal of the royal statistical society  series c  applied statistics   vol      no     pp          
     
figure    prediction graph on ego network  

   conclusion and future work
we introduce a way of combining the user profile information and the social network structure to detect the social
circles to which a user belongs in an ego network  as a supervised model  our method captures ego users personal
preferences in grouping their friends  and it also outperforms the methods which only consider the user profile information  also  it is reasonably common that users in the
same social circle are also friends with each other  which
will result in interesting graph structures that we can take
advantage of in circle detection  for prediction we now pick
the top j circles of the highest probabilities as the circles a
user belongs to  in order to improve the model  we can use
cross validation to decide the number of the circles each
user belongs to  also we can boost the efficiency of the
algorithm by eliminating the irrelevant features in feature
space reduction 

references
    e  baatarjav  s  phithakkinukoon and r  dantu  on
the move to meaningful internet systems  otm     
workshops lecture notes in computer science  vol 
      pp                
    j  mcauley and j  leskovec  discovering social circles
in ego networks  arxiv                 
    y  chen and c  lin  combining svms with various feature selection strategies  springer       
    j  friedman  stochastic gradient boosting  computational statistics   data analysis       

fi