classification of electrocardiogram anomalies
karthik ravichandran  david chiasson  kunle oyedele
stanford university
abstract

based on conversations with health care professionals 
there are several aspects of the ecg trace which are
particularly helpful in diagnosing anomalies  these consist of morphology  frequency response   heart rate
 bpm   regularity  and second moment   existence of
wave segments and relative amplitudes  p qrs t   timing intervals p q  p r  qrs  s t   normalized energy in
a a beat  evidently  various segments of the beat correspond to pumping action of various chambers of the heart 
and in a way  the abnormality can be localized 

electrocardiography time series are a popular non invasive
tool used to classify healthy cardiac activity and various
anomalies such as myocardial infarction  cardiomyopathy  bundle branch block  myocardial hypertrophy and
arrhythmia  while most ecgs are still read manually 
machine learning techniques are quickly being applied for
diagnosis due to the advantages of being quick  cheap  and
automatic as well as the for the ability to examine features
not obvious to the human eye  in this paper  a binary classification algorithm is implemented  and it reports a classification accuracy of        the heart beats are analyzed 
and a prediction is made to mark the beat as normal  abnormal  four major classes of features are   morphological 
global trend prediction  regularity  and beat energy  the
classifier is based on support vector machine algorithm 
and learning is optimized by feature selection  random
forest   dimensionality reduction  pca   and kernel optimization 

 

medical professionals adopt a systematic approach to interpreting an ecg  which consists of observing various
aspects of the ecg trace and asking certain questions 
the steps are     
 analyze the rate of atria and ventricles   is the rate
between    and     
 analyze the rhythm   is the rhythm regular or irregular  and is it regularly irregular or irregularly irregular 
 analyze the axis   is there a left or right axis deviation 

ecg overview

an electrocadiograph  also known as ekg or ecg  is a
graph showing the electrical impulses of the heart over
time  a single pulse consists of three major section called
the p wave  the qrs complex  and the t wave as shown
in figure     

 analyze the p r interval   is the interval between normal parameters and length  i e  less than     sec  
 analyze the p waves   are there p waves  is there a
p wave for every qrs complex  is there a qrs complex for every p wave 
 analyze the qrs complex   is it wide or narrow  is
there a q wave  is there a delta wave 
 analyze the st segment t wave is there st elevation
or depression  are the t waves inverted 
 overall interpretation

 

data source

the data used to train our algorithm and perform tests
were obtained from the venerable mit bih arrhythmia
database     with    half hour excerpts of two channel
ambulatory ecg recordings  the recordings were digitized at     samples per second per channel with    bit
resolution over a    mv range  two are more cardiologists
independently annotated the beats and classified into one
of    cases  the distribution of beats is that       
of the beats are normal  here  we just deal with two
classes  normal or not   and it is not difficult to extend this
project to a multi category classification problem 

figure    a single ekg pulse example    
 

fi 

preprocessing

each beat and its label were extracted from individual patient records  and our database consisted of        beats 
the beats are then temporally normalized  to ease feature
extraction  each beat now is interpolated or decimated to
    samples  and this number corresponds to a    beats
per minute heart rate        hz  several beat information
such as maximum  minimum  mean  median amplitudes 
instances of  r  peaks of the current beat and its neighbors  before normalizing temporally  the beat duration is
stored as well  the data is then normalized in amplitude so
as to avoid amplitude variations affect the features  various features are calculated in a local window  say    beats
on either side   and local amplitudes such as local mean 
and median are computed to predict the global trend of
the heart activity  unorthodox beats are handled appropriately 

 

figure    wavelet approximation

feature extraction

our four classes of features were intuitively reasoned and iii p r interval
are independent of amplifier gain  filter response  and
pr interval quantifies the electrical conduction of the
other hardware dependencies 
heart from atrium to ventricles 

 a 

morphology

iv

these set of features quantify the shape and structure of
a beat 
i

instantaneous bpm

at every beat  we calculate the instantaneous bpm  beats
per minute   by computing the ratio   t   where t is the
distance between previous and next beats 

wavelets
wavelet coefficients are used to represent the overall morphology of a beat  we used matlabs wavelet decomposition toolbox  and observed that the number of coefficients  maximum  required to faithfully define a beat
was    out of     coefficients  this decomposition filters
the signal by removing high frequencies  a debauchies  wavelet was used for a   level decomposition  in fact 
maximum two numbers can satisfactorily describe the signal as in figure      wavelet coefficients are computed by
correlating the wavelet at every time instance  and varying
the scale of the wavelet at all points  these measurements
do not occur at zero bandwidth like in a fourier transform  wavelets exploit the uncertainty in time frequency 
and each measurement provide something from both the
temporal and frequency domains  to satisfactory accuracy 

ii

 b 

energy in a beat

to characterize the pumping power of various segments 
the normalized areas of p segment  pre peak   qrs complex  peak   and t segment  post peak  are computed 
the points of splitting is chosen by finding a weighted
mean of the maximum and the mean points in a beat 
 figure      

 c 

regularity

this is one of the novel features of this work  when the
temporal instances of a maxima of a periodic waveform
 like that of a healthy heart  is fitted against a monotonically running uniform index  we get a linear fit  here  we
perform linear regression to fit a line to the peak instances
in the entire patient record  and calculate the residues
 outliers  for every beats peak 

beat segment characteristics

this can quantify the regularity of the heart beats for a
record  and a second moment can predict if the beats are
four features are extracted here to depict the relative
regularly irregular  or irregularly irregular  we see two
properties of p wave  qrs complex  and t wave  p wave
other variants of the features in the next section on global
characterize the pumping activity of the atrium  qrs  the
trends 
ventricles  and t wave   the re polarization of the ventricles  these create a cycle  and the absence or malfunction a small disadvantage of this method is that  we assume
of one can seriously affect the circardian rhythm  so  the that holistically healthiness of the record  global rhythm
features are amplitude ratio of qrs p  qrs t  temporal  not subtle  will be considered separately as a global feature  so  overlooking this fact is tolerable  a  ve residue
 duration  ratio of qrs p  and qrs t 
 

fia near zero importance  as will be seen from the feature
selection routine 
other predictors that are used are variance in beat duration  with respect to the global mean of the record  this
characterizes the regularity of the entire beat  and here
too  we assume a healthy bpm globally  other ratios such
as  min max    max local mean   and  max local median  are calculated as part of morphology with respect to
a local window 

 e 

although we dont incorporate global features in this work 
any useful decision about the record can be made by utilizing other global features apart from the beat labels 
we observed few of these to provide information such as
health of global rhythm  beat duration  and bpm  fft of
beat temporal behavior  and distribution of each class of
beats 

figure    a beat with its norm areas
characterizes a slower beat  while a  ve residue implies a
faster beat 

global features

 

classification

the following sections report our flow to optimize the
learning process  the steps can be in any order  obviously  this flow could be iterated until necessary performance is attained 

 a 

data sampling

we sampled        beats  arbitrary  and computationally
easy  from our database of        beats  the sampling
has to be uniform to preserve the normal beats distribution
at        

 b 

we use a svm based classifier  to generate support vectors  which are then used for classification  we chose svm
due to its obvious advantages  such as   its effectiveness in
high dimensional spaces  the versatility with various kernels  etc 

figure    regularity and residues

 d 

we initially used    of the described    features  a classifier was built      and the testing revealed       accuracy  all features were normalized  and standardized  zero
mean  unit variance   ten more features were added to
reach    and the accuracy improved to        here 
a polynomial  rd degree  optimum currently  kernel was
employed 

global trend

it is inevitable to include features  besides that of beats 
that tend to predict the global trend of the record  it is 
of course  not useful to incorporate a global feature here 
as it gets redundant when we have too many beats from
a single record  two such trend predictors are computed
from the regularity residues  a local residue measure is
calculated by summing over residues over a local window 
regularly irregular rhythm has near zero value as the
 ve  and  ve residues tend to cancel out  whereas  sum
of many  ve  or many  ve depicts a potential irregular
irregularity  the second feature is the sum of squares
of residues over a local window  this can quantify the
irregularity in that window  apparently  this feature has

support vector machine

 

feature selection

to improve performance  we calculate feature importance
using an ensemble learning method random forest     
here the algorithm constructs levels of decision trees  and
the output is the mode of the classes output by individual
trees  each tree fits the data to a randomized subspace 
by perturbing and conditioning the node independently 
 

fiit accumulates a bunch of estimates  the motive is that 
given a large number of nodes  the errors tend to even
out 
here  we obtain the feature importance vector  that quantifies the weight of each feature  from the performance
plot figure     we choose the top    features  even
though  there are lower feature size with comparable error  being generous with the choice here may avoid under
fitting in the subsequent stages  note that the training
error falls and saturates after some point  so    is not a
bad choice as the data has not been over fit yet 

figure    training size optimization
    gives useful insights on the trend  note the training error fall over fit  and rise bias  again  the test error minimum occurs at    dimensions  and the training error is
not too high nor low  and the test performance is      
 

figure    random forest selection
now  the performance is       on test  and       on
training sets 
we also explored two other classes of features selection 
filter feature selection attempts to evaluate the helpfulness of a feature independently of the algorithm which
will ultimately be used to generate a hypothesis  then 
we used mutual information as our scoring metric 

 

training size

now  the classifier  svm  rd order is now iterated to find
the optimal training size  figure    shows that the test
error doesnt improve after       samples  note the
training error falls below  over fit        and over       
so the size               seems to be perfect size for the
classifier  so we retain our training size of       

figure    dimensionality reduction

 

kernel selection

till now  we have been using a third order polynomial
kernel  on iteration  we find that  th degree polynomial
gives a maximum performance of       figure      note
we now use principal component analysis to find a rethe training error is zero over degree    which is clear overduced subspace  we compute the top few eigen values 
fitting  and note high bias at low degrees  the possibility
and corresponding eigen vectors to linearly combine the
of this optimal point to be local is really high  given the
vectors to create new feature matrix 
arbitrariness in the design flow  however  the improveto find the optimal number of dimensions  we iterate the ments in a different classification loop will be trivial for
classifier with    features over a pca routine  and figure the given set of features 

 

dimensionality

 

fiit is important to have a set of global features compliment
the decision  as local beat behavior may not satisfactorily
imply the global health  clearly  there is immense scope
to improve the feature extractions  and selections 

references
    m 
k 
slate 
      
ekg
interpretation 
coursematerial     pdf   online   available 
http 
  www rn org courses 
    j  m  prutkin         ecg tutorial 
basic
principles
of
ecg
analysis 
 online  
available 
http   www uptodate com contents 
ecg tutorial basic principles of ecg analysis
    a  goldberger  l  amaral  l  glass  j  hausdorff 
p  ivanov  r  mark  j  mietus  g  moody  c k  peng  and h  stanley         physiobank 
figure    a single ekg pulse example    
physiotoolkit  and physionet  components of a
new research resource for complex physiologic
signals   online   available  http   www physionet 
the kernel intercept is chosen to be     after optimizing
org physiobank database mitdb 
that over a set of values in            
    f  pedregosa  g  varoquaux  a  gramfort  v  michel 
b  thirion  o  grisel  m  blondel  p  prettenhofer 
r  weiss  v  dubourg  j  vanderplas  a  passos 
   results
d  cournapeau  m  brucher  m  perrot  and e  duchtable     provides the performance at every stage of the
esnay  scikit learn  machine learning in python 
learning process 
journal of machine learning research  vol      pp 
               
   the top four features are  st wavelet coefficient  prepeak  p wave  energy   nd wavelet coefficient  and     l  breiman  random forests  in machine learning 
amplitude ratio of qrs p 
      pp      
   the final confusion matrix elements are        true
positive         true negative       false positive 
and       false negative  for a distribution of       
normal beats 
   few  performance    of top features  tuples are
                                 and         
step
initial
add f eatures
random f orest
t rain size
p ca
kernel select

f eatures  
  
  
  
  
  
  

t raining p erf ormance   
  
    
    
    
    
     

table    performance at every stage

  

conclusion

the above procedure was tested on multiple test data 
each with              samples  and the results closely
match in all training sets to the order of      
in practice  the testing beats are not sampled from various records  but the learning algorithm must be run on a
single record  and predictions must be made  that case 
 

t est p erf ormace   
    
    
    
    
     
    

optimum



     

p oly  

fi