 

assessingopinionmininginstocktrading
sathishnagappan srn  govindadasu gdasu 
i introduction
wehypothesizethatmoneyshouldgowherethepublicwantsandneedsittogo andthefirmthatisthebestandfastestat
determiningthesehumandemandswillyieldthehighestpercentagegrowth totestthishypothesiswesetuptwopredictors    the
firstpredictorconsideredonlynumericaldatasuchashistoricalprices ebitda andperatio and   thesecondconsideredhuman
newsandopinionsoncompanies theirproducts andtheirservices thefirsttaskwastoderiveanaccuratefirstpredictor asour
baselineweusedsvrwithrbfkernel whichledtosgdwithvariousiterationstobetterapproximatetherbfkernel after
implementingthisbygroupingallstocksfrommajorindices werealizedthatweshouldconsiderstocksindividuallyandtakeinto
accounttimeseries thisresultedinthearimaxmodelwithaicbackwardssearchselection predictor   next wemovedto
predictor  weaddednlpfeaturesforeachcompanysuchasindicatorsofspecificngramsthatgiveinsightintothepositivityofthe
streamofrelevanttextaboutacompanysproductsandservices ultimatelythisledtoarimaxwiththesenlpfeaturesand
combinationfeatureselection predictor   thisallowedustocomparetherelativesuccessesofthemodelwithandwithoutnlp
features 
ii dataandcrossvalidation
thenumericaldatawasobtainedfrombloombergandtheheadlinedatafromfactset weretrievedalistofallstocksfromthes p    
russell     andnasdaq    eachtrainingexamplewasindexedbycompanytickeranddateandhad  featuressuchasperatio 
ebitda price andvolatility thetargetforeachtrainingexamplewastheonedaypercentchangeinclosingprice weretrieved m
trainingexamplesfrom    topresent ourmethodofevaluationcomesfromtheconceptofscoredefinedasfollows 
m

m

i  

i  

score         y i true  y i predicted      y i true  y i true mean  



perfectpredictionyieldsascoreof  lessoptimalpredictionswillbelower evenarbitrarilylargenegativenumbers weusedavariant
ofholdoutcrossvalidationwetestedourmodelsonthelast monthsandtrainedusingtheremainderofthedata dueto
computationalcomplexity forourinitialalgorithm wetrainedonthefirst   yearsof        andtestedonthelast months 
totaling   ktrainingexamples forourlateralgorithms wetrainedonthefirst   yearsof        andtestedonthelast months 
randomlyselectingasubsampletocrossvalidatewouldyieldanunrealisticandunfairadvantagesincewewouldbeusingfuture
pricestopredicttomorrowsprices inaddition marketdatabutnotcomputationalpowerwasabundant justifyingtheuseofholdout
crossvalidationasopposedtokfoldvalidation blumet al       
iii baselinesystem
literaturesuggestedthatsvmswithrbf radialbasisfunction kernelarenaturalchoicesforthestocktradingproblem baoet al 
     and lee       
svrwithrbfkernel sincewearedealingwithregression outputofpercentchangeinstockprice  weexploredsvr support
vectorregression  wequicklyfoundthealgorithmwastoocomputationallyexpensiveforour  mbmemoryec instance the
implementationofsvrinscikitlearniso n m   whichwasnotscalablegivenourlargedataset wewereonlyabletoefficientlylearn
on  ktrainingexamples asmallfractionofour   kexamples tocombatthisissue wesubsampled  ktrainingexamplesoverthe
years         althoughouralgorithmwasnowexecuting weranintoavarianceproblemourtestscorewas       andour
trainingscorewas        itwasclearweneededacomputationallysimplerapproachsowecouldmakethemostoutofallofourdata 
iv stochasticgradientdescent sgd 
weproceededthroughanumberofiterationstoimproveourbaselinesystem 
sgdwithrbfapproximation weimplementedsgdwithshufflingandusedanrbfapproximationtokernelizetheinput our
literaturereviewsuggestedthatthiswasagoodapproximationforsvrwithrbfkernel hazanet al       weapproximatedtherbf
kernelusingnystromsmethod nystromsmethodisparameterizedbythenumberofmontecarlosamples n whichcorrespondsto
thedimensionsofthefeaturevector rahimiandrecht       weimplementedamodelselectionschemetoloopthroughn       
and       wheretheupperboundonnandlowerboundon parameterforrbf weresetduetomemoryconstraints andwe

fi 
achievedunsatisfyingresultsoftestscore      e andtrainingscore      e withoptimalvaluesof   andn    interestingly 
theparametervalueshadanegligibleimpactonourresults itbecamecleartousthatnystromsmethodwasnotapproximatingwellfor
ourdataset affandiet al       
sgdwithrbfapproximationwithkmeans toimproveourapproximationoftherbfkernel wedrewinspirationfromzhanget al
       intheirpaper theydescribeamethodofusingtheclustersfromkmeansasthebasisfornystrom weimplementedthis
algorithm weachievedbetterresultsoftestscore      e andtrainingscore      e withoptimalvaluesof   andn    
kmeanswascomputationallyexpensivesowecouldonlycomputeamaximumofn    whichcorrespondstothenumberofclustersin
kmeansandmontecarlosamples encouragingly however asweincreasedn unlikeinthepriorcase ourpredictionaccuracy
improvedasexpected drineaset al       thisledustobelievethatweneededamoreefficientwaytocomputekmeanssothatwe
couldoperateonhighernvalues 
sgdwithrbfapproximationwithkmeansminibatch taskedwithtryingtocomputekmeansmoreefficiently wefoundthe
resultsfromscully       theauthorproposedakmeansminibatchalgorithmwithcomplexityordersofmagnitudelowerthanthatof
theoriginalkmeansalgorithm thissignificantlyboostedthevaluefornthatwecoulduse weloopedthroughn       and 
      wheretheboundsweresettoparalleltheoriginalsgdalgorithm andweachievedsignificantlybetterresultsoftestscore
      e andtrainingscore      e withoptimalvaluesof    andn    
failurepoints althoughourresultsforthekmeansminibatchalgorithmweresignificantlybetterthanouroriginalattempt our
resultswerestillunsatisfying ourmodelsufferedfromabiasproblem andtheproximityofthetestandtrainingscoresverifiedthat to
solvethisbiasproblem weneededtoimproveourfeaturesetbyaddressingthreeflaws lackoftimeseries technicaltrading and
collectivepredictions ourmodelhadnonotionoftime everytrainingexample regardlessoftheday wastreatedequally current
markettrendsandpreviousdaypriceshaveasignificantimpactonpredictingpricesfortomorrow lebaronet al       asaresult we
investigatedtheautoregressiveintegratedmovingaverage arima model secondly technicaltradingdoesnotyieldgood
predictionresultsbecauseweareonlytakingintoaccountthequantitativeandnotqualitativefactorsthatinfluencestockprices
 brownandcliff       tothisend webuiltasentimentanalyzer finally wegroupedallthestockstogethertomakepredictions we
feelwewouldgetbetterresultsifwelookateachstockindividuallyasexplainedbyatsalakisandvalavanis       
v predictor  arimaxwithaicbackwardssearchselection
wereplacedsgdwiththearima autoregressiveintegratedmovingaverage modeltotaketimeseriesintoaccount byusing
arima wetakeintoaccountthefactthatfinancialstocksarebestmodeledasweaklystationarystochasticprocesses paiandlin 
      inotherwords financialstocksmovefromonepricetoanotherwithsomeprobabilitywhichisgivenbysomeunderlying
probabilitydistribution thefollowingistheequationforthearmamodel 
m

n

i  

i  

y t     a i   y t  i     b i   x t  i 
thefirstsummationrepresentstheautoregressive ar componentandthesecondsummationrepresentsthemovingaverage ma 
component themacomponentisafunctionoftheinputsx ti  moreover x ti  theinput isinturnafunctionofthewhitenoise
ofourstochasticsystem inthisway thewhitenoiseispassedthroughbotharecursive ar andnonrecursivefilter ma  
weusedthearimaxmodelwhichisageneralizationofthearmamodel thearimamodelsincludesanintegratedcomponent 
andthearimaxmodelallowsmultipleexogenousvariables theorderisgivenby p d q wherepisthearterm distheintegrated
term andqisthematerm 
webuiltourmodelaroundasinglestock thecomingsectionswillprovideanindepthanalysisonthegooglestock goog  note
however wedidnotobservesignificantdifferencesbetweenthestockswechose attheend wewillpresentfinalresultsfortwoother
stocks abbottlaboratories abt andgeneralelectric ge  wechosethesethreestockssincetheyareinthreedifferentindustries 
wetrainedonthefirst   yearsof        andtestedonthelast months 
orderselection todeterminetheorderofourarimamodel weusedgridsearchon    p  d  q    andweachievedanoptimalorder
of  p  d  q               encouraginglythiswasconsistenttotheresultsfoundbynelsonforassetreturns       toverifythatthisorder
accuratelyrepresentedthedataandwasnotanartifactofgridsearch weusedtheanalysisandtechniquesfromozaki       ozaki
describesamethodofusingautocorrelationsandpartialautocorrelationsforselectingorders wedidpreliminarycalculationstoverify

fi 
thatourcalculatedorderwasreasonable unfortunately despitethis ourcomputedscorewasworse wegotatrainingscoreof
       andtestscoreof        thediscrepancybetweenthetrainingscoreandtestscoreledustobelievethatweweresuffering
fromavarianceissue 
featureselectiononoriginalfeatures tocombatthisvarianceproblem wedecidedtousefeatureselectiontoremoveunnecessary
features sincewehaveareasonablysmallfeatureset weusedthebackwardssearchalgorithm toevaluateourmodels weuseda
similarapproachtothatoftsay      andusedakaikeinformationcriterion aic  aicisacommonlyusedmetricforarimamodel
selectionandrepresentsatradeoffbetweenthefitandmodelcomplexity thisapproacheliminatedsixfeatures bidprice    day
movingaverage   daymovingaverage highprice dilutedeps andtotalsharesoutstanding interestinglyfeatureselectiondecided
toremovemovingaveragewhichwasacoreproblemofthesgdwithkmeansminibatchalgorithm thiscouldbeduetothefactthat
arimainherentlytakesintoaccountmovingaveragesothesetwofeaturesareunnecessary ourscore trainingscore andaic
valueswere              and      respectively weachievedalmosttwoordersofmagnitudeimprovementfromsgdwithrbf
kernelapproximatedwithkmeansminibatch 
vi predictor  systemwithopinionminingandcombinationfeatureselection
weimprovedthearimamodelsfeaturesetbyimplementingopinionminingontrendingnewsheadlinesandfilingsforpublic
companies weselected stocks goog abt andge torunourimprovedsystemonandtreatedthestocksseparately notallowing 
say jpmorgansdatatoinfluenceourpredictionsongooglesstock the  additionalfeaturesthatweintroducedwere 
 indicatorsofwhetheraparticularheadlinehadinstancesoftheentirecorpuss  mostcommonunigrams bigrams
andtrigrams weightedbytheinversedepthofthengramintheparsetreeoftheheadline 
 thelengthofaheadline
 themaximumparsedepthofaheadline
 theproportionofthewordsoftheheadlinethatwereadjectivesandadverbs
selectiononnlpfeatures thearimamodelontheoriginalplusnlpfeaturesyieldedascoreof       andtrainingscoreof
        thelargedifferencebetweenthetestscoreandtrainingscoremadeitclearthatweweredealingwithavarianceproblem we
quicklyranintoaproblemwithouraicbackwardssearchalgorithmthisalgorithmiso n  timecomplexityandthelargeincreasein
featuresmadeitunusableforourproblem wefirsttriedprincipalcomponentanalysis pca  thisdidnotworkforusaswegot
negativetrainingandtestscores wedidresearchandfoundtheresultsofhuangandtsai       theyimplementedafilterbased
featureselectionalgorithmthathadpromisingresultsforstockmarketpredictions wereferthereadertohuangandtsaispaperfor
detailsonthealgorithm theiralgorithmtoo however yieldedevenworseresultsthannofeatureselectionalgorithm itwasclearwe
neededabetterwaytoselectfeatureswhichledustoournextalgorithm 
pcaandfilterbasedfeatureselectiononnlpfeatures tsaiandhsiaoresearchedwhetherusingmultiplefeatureselection
algorithmstojointlyprovidepredictionswouldprovidebetterresultsthanusingasinglefeatureselectionalgorithminthecontextof
stockpredictions       theirbestperformingmethodusedpcaandgeneticalgorithms ga  theyusedunion intersection and
multiintersectionapproachestoselectfeatures itisfruitlesstoreproduceallofthedetailsandtheoryoftheirprocedureinthispaper 
andwereferthereadertotsaiandhsiaospaperfordetails weimplementedavariantofthismethod weusedpcaandhuangand
tsaisfilterfeatureselectionmethod thisalgorithmimprovedourresultsdramaticallyweremoved  featuresandourtestscorewas
      andtrainingscorewas       
vii opinionminingdiscussionerroranalysis
thebiggestquestionofourprojectwaswhetheropinionminingwouldhaveasignificantpositiveeffectonstockpricechange
predictionsandourresultsansweraresoundingyes theadditionof  nlpfeatures top  unigrams top  bigrams top  
trigrams proportionofadjectivesandadverbs headlinelength andheadlineparsedepth improvedourscorefrom       to
       whichisa    improvementduetoopinionminingandcombinationfeatureselectionasdescribedabove 
effectoffeaturizingngramdepth notethatweembeddedinformationaboutparsetreedepthinourfeaturizationofngramsforeach
headline inordertotestwhetherdepthinformationactuallyhadaneffectandmoreoverapositiveeffectonourgeneralizationscore 
weranonetrialonthegoogstockwhereweremoveddepthinformationandsimplystoredindicatorfeaturesofwhetherornotcertain
unigrams bigrams andtrigramsoccurredinatrainingexample wecalledthisourdepthlesssystem thedepthlesssystemreporteda
generalizationscoreof       andtrainingscoreof        whichmeansthataddingdepthresultedina    improvement sowe
concludedthatfeaturizingdepth particularly  depth ontopofunigrams bigrams andtrigramswasjustasimportantasindicating

fi 
whetherthoseunigrams bigrams andtrigramsoccurredinthefirstplace thisgoestoshowthatthelocationofparticularngramsin
thestructureofaheadlinehasasignificantimpactontheoveralllabelfortheheadline 
effectofheadlinelengthfeature theheadlinelengthfeaturehadasmallpositiveeffectonthescoreprovidinganimprovementof
     e or        
effectofadjective adverbproportionsfeature consistentwithliterature thisfeaturehadasignificantpositiveeffectonthe
generalizationscoreprovidinganimprovementof     e or        
effectofheadlineparsetreedepthfeature theheadlineparsetreedepthfeaturehadasmallpositiveeffectonthescoreproviding
animprovementof     e or        
viii finalresults
method

testscore

trainingscore

baseline svrwithrbfkernel

      e 

      e 

sgdwithrbfapproximation

      e 

      e 

sgdwithrbfapproximatedwithkmeans

      e 

      e 

sgdwithrbfapproximatedwithkmeansminibatch

      e 

      e 

arimaonoriginalfeatures

      e 

      e 

arimawithaicbackwardssearch

      e 

      e 

arimawithoriginal nlpfeatures

      e 

      e 

arima nlp combinationfeatureselection

      e 

      e 

aspromised herearefinalresultsforabtandge 
method

testscore

trainingscore

abt arimawithaicbackwardssearch

      e 

      e 

abt arima nlp combinationfeatureselection

      e 

      e 

ge arimawithaicbackwardssearch

      e 

      e 

ge arima nlp combinationfeatureselection

      e 

      e 

thefinalandbestmodelsarebolded noticethatthereweresimilarfactorsofimprovementbetweenallthreestocks weachieveda
significantimprovementfromourbaselineof      e forgoog 
ix futurework
althoughweachievedverypromisingresultswithourfinalmodel wefeelthereareadditionalimprovementswecouldmake inallthree
stocksweachievedsimilartrainingandtestscoreswhichimpliesbias thus plausiblenextstepswouldaddressimprovementsto
arimaoralargerordifferentsetofnlpfeatures thesuggestionsbelowaddresstheseaswellasadditionalconsiderations 
tradingstrategy ourproblemconcernedwhetherornotwecouldaccuratelypredictpercentchangeinpricesofstocks itdoesnot
dealwithanactualtradingstrategy forexample ifourmodelweretopredicta  increaseinprice onewouldwanttoinvestmore
thanifourmodelweretopredicta   increase apossiblenextstepwouldbetodeviseatradingstrategytomaximizereturnswiththis

fi 
model 
arimagarch thearimaxmodelrepresentstheconditionalmeanofaprocesswhereasthegeneralizedautoregressive
conditionalheteroskedastacity garch modelrepresentstheconditionalvariance thesetwomodelscanbeusedinconjunctionto
formthearimagarchmodelwherearimamodelsthemeanandgarchmodelsthevariance awartaniandcorradididan
interestinganalysisforpredictingthevolatilityofthes p   usingvariousgarchmodels       whichwefeelwecanadapttoour
problemforbetterresults 
classesofstocks ourmodelisbasedonasinglestock inatradingsetting itmaybearduoustohavetocomputeamodelforevery
singlestock onepossibilityistoresearchstocksandcategorizethembasedonsomefinancialratios then similartowhatkendalldid 
wecangeneralizeourmodelandbuilditoneachofthesecategories      asopposedtoasinglestock thiswouldmakeourmodel
morepracticallyusable 
nlpfeatures intermsofnlp wewouldliketoimplementrichardsochersrecursiveneuraltensoralgorithmtounderstandthe
structureofheadlinesratherthansimplyrecordthedepthofngramsinheadlines also wewouldliketolookintoremovingirrelevant
wordsandincreasingthenumberoffeaturesto    kratherthan     
x conclusion
forpredictor  wedevisedthearimaxwithaicbackwardssearchselectionandforpredictor  wedevelopedarimaxwith
combinationselectionthatconsiderssentencestructure ngramdepth andproportionofmodifiers adjectivesandadverbs as
features wefoundthatopinionminingdoesindeedhaveasignificanteffectonthestockpredictingproblemwith    improvement 
moreover predictor outperformsourbaselinesvrbyascoreof      e forgoog theseresultsareverypromising andfuture
researchshouldbegearedtowardsimprovingthemodelthrougharimagarchandneuraltensorsandtheusabilitythroughtrading
strategiesandstockclassification 
xi references
   alirahimi benrecht      randomfeaturesforlargescalekernelmachines    kaizhang ivorw tsang jamest kwok      improved
nystromlowrankapproximationanderroranalysis    d scully      webscalekmeansclustering    eladhazan tomerkoren nathansrebro 
     beatingsgd learningsvmsinsublineartime    petrosdrineas ravikannan michaelw mahoney      fastmontecarloalgorithmsfor
matricesi approximatingmatrixmultiplication    rajahazaandi alexkulesza emilyb fox bentaskar      nystr
omapproximationfor
largescaledeterminantalprocesses    yukunbao yanshenglu jinlongzhang      forecastingstockpricesbysvmsregression    mingchilee 
     usingsupportvectormachinewithahybridfeatureselectionmethodtothestocktrendprediction   blakelebaron w brianarthur richard
palmer      timeseriespropertiesofanartificialstockmarket     gregoryw brown michaelcliff      investorsentimentandthenearterm
stockmarket     richardsocher alexperelygin jeany wu jasonchuang christopherd manning andrewy ng christopherpotts      
recursivedeepmodelsforsemanticcompositionalityoverasentimenttreebank     avrimblum adamkalai johnlangford      beatingthe
holdout boundsforkfoldandprogressivecrossvalidation    seleneyuexu stockpriceforecastingusinginformationfromyahoofinanceand
googletrend     pingfengpai chihshenglin      ahybridarimaandsupportvectormachinesmodelinstockpriceforecasting     shiladitya
sinha chrisdyer kevingimpel noaha smith      predictingthenflusingtwitter     bopang lillianlee shivakumarvaithyanathan      
thumbsup sentimentclassificationusingmachinelearningtechniques     soominkim eduardhovy      crystal analyzingpredictive
opinionsontheweb    bopang lillianlee      opinionminingandsentimentanalysis    lunweiku hsiuweiho hsinhsichen      
novelrelationshipdiscoveryusingopinionsminedfromtheweb     anndevitt khurshidahmad      sentimentpolarityidentificationin
financialnews acohesionbasedapproach     tonymullenandnigelcollier sentimentanalysisusingsupportvectormachineswithdiverse
informationsources inproceedingsoftheconferenceonempiricalmethodsinnaturallanguageprocessing emnlp  pages       july     
posterpaper     caseywhitelaw navendugarg andshlomoargamon usingappraisalgroupsforsentimentanalysis inproceedingsoftheacm
sigirconferenceoninformationandknowledgemanagement cikm  pages       acm          danielb nelson      conditional
heteroskedasticityinassetreturns anewapproach     t ozaki      ontheorderdeterminationofarimamodels     rueys tsay      
orderselectioninnonstationaryautoregressivemodels    chenglunghuang chengyitsai      ahybridsofmsvrwithafilterbasedfeature
selectionforstockmarketforecasting     chihfongtsai yuchiehhsiao      combiningmultiplefeatureselectionmethodsforstockprediction 
union intersection andmultiintersectionapproaches     g atsalakis k valavanis      surveyingstockmarketforecastingtechniquespartii soft
computingmethods     b awartani v corradi      predictingthevolatilityofthes p   indexviagarchmodels theroleofasymmetries     
g kendall      amultiagentbasedsimulatedstockmarkettestingondifferenttypesofstocks 

fi