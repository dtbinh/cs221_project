predicting daily incoming solar energy from
weather data
romain j uban  patrick q uach
stanford university   cs    machine learning

december         
being able to accurately predict the solar power hitting
oklahoma state and has been collected everyday from
the photovoltaic panels is a key challenge to integrate more
     to            days  for the training dataset and
and more renewable energy sources into the grid  as the total
from      to            days  for the testing dataset 
power generation needs to match the instantaneous consump   daily incoming solar energy data  as the total daily intion load  the solar power coming to our planet is predictable 
coming solar energy at    oklahoma mesonet  sites  difbut the energy produced fluctuates with varying atmospheric
ferent from the grid points of the weather data from     
conditions  usually  numerical weather prediction models are
to      
used to make irradiation forecasts  this project focuses on
machine learning techniques to produce more accurate predicwith the weather data from      to       for the    
tions for solar power  see figure    
gefs  grid points  we want to predict the daily solar energy
our strategy to make this prediction is 
at the    mesonet sites  as shown on figure   
  collect  understand and process the weather data 
  perform different machine learning techniques to make the
prediction 
  perform some feature engineering aside of the forecast features 
  analyze the results and discuss them 

figure    the weather data is known at the gefs sites  blue   while
the solar prediction needs to be done at the mesonet sites  black  

 
figure    distribution of the annual insolation at the mesonet sites
 training data  

 

gathering the data

the data  in netcdf  format  very popular to manipulate
weather data  has been downloaded from the kaggle website 
provided by american meteorological society    in several
files 

adapt the data to our needs

for each mesonet site  we have identified the four closest
gefs weather sites  as shown on figure    there are then two
possible methods to use the data  for each mesonet site  we
can either interpolate geographically the weather data from the
grid to the mesonet site  or factor all the features in our algorithms to make a prediction 

   

first attempt  interpolate weather data
from the grid to the mesonet sites

for this  we have different options of spatial interpolation to
   weather data  as the values of    weather parame  estimate the value of each weather data from the four gefs
ters  such as precipitation  maximum temperature  air stations to the mesonet site  see figure     we chose the inpressure  downward upward short wave radiative flux      verse distance weighted average  with the distance being calforecasted at   different hours of the day and provided
  http   www mesonet org 
by    different ensemble forecast models  this data is
  global ensemble forecast system
forecasted for a uniform spatial grid         centered on

ficulated between two points on a sphere from their longitude     verdict
and latitude  harvesine distance   for each weather data type 
after training our models with these two methods  we obx
wk
served that pre algorithm interpolation gave much inaccurate
 i 
 i 
 xk
xm esonetj  
p 
predictions with training and testing errors both unacceptably
 
w
 
k
k   
kgef s
high compared to the unaggregated model  while being much
with wk     dk   distance m esonet  gef sk  
faster to process  the data handled was then   times smaller 
after this step  we could have weather predictions at our    which is significant when the lower bound for the total data
mesonet sites and could perform supervised learning methods  loaded is around  gb  
knowing the daily incoming solar energy at those sites  the
therefore we decided to go on with an unaggregated model 
main challenge was the very large cpu time needed to run the at this stage  we have weather data for     sites   stations
interpolation task  but it was performed only once for all 
     days   hours    parameters    models  plus the
distances between the mesonet and each of the four closest
gefs sites 

 

because of the multiple dimensions of the weather data available  we have decided to make some grouping for the data  as
the output should be the daily expected solar power  for each
day  site and weather model  we have composed an array of the
   weather parameters  taken for the   different timestamps of
the day and the   closest stations  which gave an array of    
predictors for each given day  site and weather model 
after that  we we able to run algorithms on the data for each
day  site and model  in the weather prediction industry  these
models are usually equally weighted when running forecast
softwares  so  we have decided to average the power forecasts
from the different models to estimate their combined prediction  however  all the weather parameters are forecasted using
the same model  so  not to loose the correlation that we have
within the same model     models      predictors   we could
not work simultaneously with all the models together       
predictors   therefore the steps chosen to run the algorithms 

figure    an interpolation of the weather data from the gefs sites
to the mesonet site is needed 

we were afraid that this pre algorithm interpolation would
turn out to be inconclusive as the aggregation of data would
reduce the information we eventually had for the predictions 
for example  correlations between the features within each
weather station would be lost 
so  we decided to try another method by keeping the interpolation for later in the analysis  for each mesonet site  we
would treat all the data available from the four closest weather
stations 

   

selecting the predictors

   take the average of each parameter on the    models
   train one model over all the days and sites

second attempt  factor weather data from
the four nearest gefs grid points as features for each mesonet site

   for each site day  estimate the incoming solar energy

at this stage  we had weather data for     sites      days
   
     parameters  distance mesonet gefs    stations 
for each mesonet site  we then had the four sets of data from
this
boils down to              features  and           
the gefs stations  two ways were then possible  we could
      
samples  for                 predictions to make 
use the four sets of data to make one solar prediction for each
of them  four in total  and then interpolate them to the mesonet
site  or we could make a single prediction for the mesonet site
  understanding the data
from the four stations 
here again  there may not be a direct relationship between before running any algorithm on the massive dataset  we
the incoming solar radiation at the weather stations and the one wanted to get a grasp on the kind of influence some of the feaat the mesonet site  that is why we opted for the most con  tures had on the output  so  we took the weather parameters
servative method  the interpolation would be indirectly done that seemed the most meaningful to us and plotted heat maps 
by adding predictors such as the distance between each station on figures   and    we can qualitatively distinguish the areas
and the central site 
where there is more clouds from those having clearer skies 
and also where the solar flux is the highest  naturally  when

 

fioverlapping figure   and figure    we can notice that shortwave
flux has a great impact on the eventual output  it is not the
only factor though  the west east distribution of clouds with
the clouds being more frequent in the east  will also probably
have high negative correlation with the output  we will verify
later these correlations 

figure    the scatterplot provides us a way to use our scientific
intuition 

figure    the cloud cover varies a lot along the west east  clearcloudy  direction 

the mean absolute error is commonly used by the renewable
energy industry to compare forecast performance  it does not
excessively punish extreme forecasts 

   

simple linear regression

we started with a simple linear regression to make our first
predictions  hence the forecasted daily incoming solar energy
for each day and mesonet site was 
 i 

fm esonetj  

figure    the downward short wave radiation flux represents the
radiation coming from the sun 

   
x

 i 

k  xj k

k  

to determine the coefficients k we have trained our model
by minimizing

then  we also wanted to have some more quantitative preanalysis  by measuring the correlation between the factors and
the response  scatterplots were useful in giving a visual estimate of the kind of correlation between them  linear  polynomial  inverse    for example  on figure   we can observe that
when there have been more than a certain amount of clouds
in a day  then the solar energy is very low  this relationship
is unlikely to be only linear  but it could be linear piecewise
 solar energy decreasing until zero  

rss    

       
x  i 
x
 i 
 fj  oj   
j   i  

to assess the bias variance trade off  we have divided the
training set into two subsets  the first one with the data from
     to          years  used as the training set  and the other
one with the data from      to         years  used as the
validation set  we have trained different models by varying the
size of the training dataset and computed the corresponding
cross validation error on the validation test  then  we have
  regression methods
plotted both the training and test mae of each model to show
the learning curve  on figure   
to be able to compare our approach to others  kaggle leaderthe learning curve for the linear regression model shows the
board   we have used the mae  formula to calculate the error  evolution of the learning and testing errors  for     predictors 
the sample does not seem to be large enough below    years 
   n
  x x  i 
 i 
from    to    years of training samples  for a testing set of
 f  oj  
m ae  
  n j   i   j
  years  maes converge and it seems that we train a model
without too much bias nor too much variance  so  it seems
  mean absolute error
that    years of data should be enough to train a model of    
features 
 

fi   

then  we wanted to try more complex methods that could handle the large number of features and the highly non linear and
complex relationship between the features and the response of
the data  that has been observed during the first visualizations
of the data  tree based methods  decision trees  seemed to be
a good match 
random forests builds a large number of decision trees by
generating different bootstrapped training data sets and averages all the predictions  but when building these trees  each
time a split in a tree is considered  a random sample of m predictors is chosen from the full set of p predictors  the classifiers may be weak predictors when used separately  but much
stronger when combined with other predictors  randomness
allows weak predictors to be taken into account and uncorrelates the trees 
two tuning parameters are needed to build a random
forests algorithm  the total number of trees generated and
the number of features randomly selected at each split when
building the trees  to determine optimal values for those two
parameters  we have run several cross validation models and
selected those which gave us the best results  we have started
with values around those given in the litterature     typically

a good value for m is p which is around    in our case  and
explored the different learning curves given by models  eventually  we ran our random forests algorithm with    predictors on      trees 

figure    learning curve for a simple linear regression  training set
within              to    years   testing set from      to        
years  

we could then apply our model to the full training set to get
predictions for the kaggle testing set  it took about    minutes
to run on the corn stanford edu machines  with the first submission  we reached the   th      position in the competition 
if we did not have the test error calculation module provided
by kaggle to evaluate our next models  we would have calculated the evolution of the test learning curve for the different
models adopted  on figure    we can see that the models get
more and more accurate with an increasing sample size 
and then  we have tried to use other more advanced models 

   

random forests

lasso and ridge

as an alternative to a simple linear regression  we can fit
a model using techniques that shrink the coefficient estimates
towards zero  reducing their variance and making more stable
predictions  we have selected two different methods  ridge
and lasso  ridge regression minimizes
rss     

   
x

k 

k  

lasso regression in addition to constraining the coefficient estimates  performs feature selection by setting certain coefficients exactly to    it minimizes
rss     

   
x

figure    learning errors  mae  for different models 

   

 k  

k  

models comparison

on figure    we can see that the most successful models are
 is a tuning parameter that controls the shrinkage of the co  given by using random forest methods     more accurate
efficients  the optimal value of shrinking was obtained by than linear regression    th on the kaggle board  
cross validation on the training dataset 
 

fi 

additional features

the prediction of solar power can be less accurate in wet climates  such as the east of oklahoma  due to the higher varito help our predictions  we have tried other features  as en  ability of weather  clouds  precipitation   than for arid clivironmental engineers  we know that the incoming solar ra  mates  such as the west of oklahoma  
diation to the earth heavily depends on two main parameters 
the time of the year and the location  but we have also added
other parameters 
   time  the incoming solar energy high relies on the spatial
position of the sun  which depends on the seasons  so we
have added a categorical feature to factor the month of
the prediction day 
   location  the solar incident varies with the latitude  but we
have also added the longitude of the mesonet site as we
figure     relative mae plot for each site
have observed graphically that the irradiation also relies
on the longitude  even though this may not apply to other
our last task was about identifying the main features of the
places  see figure   
model  it turned out that the upward solar flux features were
   altitude  we have found a high correlation between lon  much more informative than the downward ones  indeed  the
gitude and altitude  and irradiation  in oklahoma  so we upward flux directly reflects the amount of energy that is rehave also added the altitudes of the sites and gefs sta  flected back to the atmosphere  that is a fraction of the incident
irradiation that actually hits the ground 
tions 

 

conclusion

this machine learning project was our first hands on experience with real big data  the project was about data preparation for a big part  it involved data understanding  sorting
and reframing  then  we had to think about ways to run our
algorithm  as we needed machines capable of handling about
 gb of input data at once  it was challenging  but that made
us really think about ways to save time and resources  how to
reduce the computational load of our code  how relevant it is
to make backups of intermediate files  how useful it is to run
calibration test algorithms before launching codes that would
run for tens of hours 
it was definitely challenging to work with this big data  we
have also learnt a lot about implementing algorithms in real
life  as we were not working in a fully academic environmental
figure    average monthly insolation
anymore 
and finally  as we tried to understand the different correla  results analysis
tion relationships between the parameters and the forecasts  we
with these additional features  we have submitted another pre  surprisingly also got a better understanding of solar prediction
diction file to kaggle  it reduced our mae by       th from an energy engineer point of view 
on kaggle   compared to predictions made by the random
forests algorithm on the raw data alone 
on figure     a visualization of the relative errors shows an references
accuracy of our predictions of   to      which is quite satisfy    ams
         
solar
energy
prediction
ing  we can notice that the error values tend to be larger on the
contest 
http   www kaggle com c 
eastern part of the plot  whereas the smallest error values are
ams      solar energy prediction contest  
located on the western side  keeping in mind the   hour sampling of the weather data  very sudden changes in the weather     james  g   witten  d   hastie  t   tibshirani  r        an
parameters cannot be noticed in averaged datasets  therefore 
introduction to statistical learning  springer  pp          

 

fi