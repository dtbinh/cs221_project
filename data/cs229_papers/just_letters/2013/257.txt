upset prediction in college football

jeffrey d  sinsay
department of aeronautics and astronautics
stanford university
stanford  ca      
sinsay stanford edu

a  santiago padron
department of aeronautics and astronautics
stanford university
stanford  ca      
padronas stanford edu

 

introduction

the last few decades have seen the rise of more advanced statistical approaches to looking at sports 
many of these approaches build on the methods of baseball sabermetrics  famously advocated for by
bill james     similar ideas have been extended to american footbal by carroll et  al      interest
in these methods has grown as they have shown themselves to be good predictors of team and player
performance  useful information for franchise management  fantasy leagues and sports betting  in
recent years  the use of machine learning to develop models for the prediction of football game
outcome at both the college and professional level has been considered        in the project we seek
to extend these ideas by applying machine learning algorithm for the prediction of upsets in college
football  we feel that an approach which modifies the problem of predicting game outcomes to one
focused on identifying cases were other prediction models have higher probability of incorrectly
labeling outcomes presents several novel opportunities to exploit 

 

data collection

data for ncaa football bowl series division teams from the      season was used to train and
test our prediction models  the features used in our model are summarized in table    the website
cfbstats com was used to gather in game statistics for each team for weeks   through    of the
season  using traditional football statistics  a set of seven team on team performance features were
created  these were based on taking a differential statistic between opposing teams  e g  difference
between underdogs average offensive rushing yardage per and favorites average defensive rushing
yardage allowed per game   the teams statistical performance was recalculated for each week
of the season using only games previously played at that point in the season  betting spread and
ranking information was also considered  these essentially represent input of expected outcome
and team strength from other models  which we treat as black boxes  the betting spread data was
scrapped from the betting website donbest com  for the rankings of the college football teams  we
considered the foxsports rankings found in cfn scout com  the data was collected and processed
into text feature and results files using a set of python scripts we developed for this project 

 

methods

our basic approach to identifying upsets was to classify them using a number of supervised learning
algorithms  we looked at two basic types of upsets  one where the team favored by   or more points
loses  and a second  major upset  where the team favored by a touchdown    points  or more loses 
of the     games analyzed we found     upsets        of which          were major upsets  this
indicates a significant skewing of the classification groups  particularly for the major upsets  given
the nature of our problem  we are therefore particularly concerned with making type i errors in
which we incorrectly classify a game as an upset  we examined the models precision and recall as
 

fifeature
home team favored 
average points scored differential
underdog offensive rush differential
underdog defensive rush differential
underdog offensive pass differential
underdog defensive pass differential
underdog turnover margin
underdog time of possession margin
game spread
underdog rank
favorite rank

source
cfbstats com
cfbstats com
cfbstats com
cfbstats com
cfbstats com
cfbstats com
cfbstats com
cfbstats com
donbest com
     cfn rankings
     cfn rankings

table    features used by models in predicting upsets 

 a 

 b 

figure       fold validation averaged results   a  testing error  b  f score 
captured by the f score
f   

precision  recall
 
precision   recall

   

where 
precision  

tp
tp   fp

and

recall  

tp
 
tp   fn

   

the rate of improvement of the f score started to level off as we increased the number of games considered to include all the games of the season  fig  b   also  the testing error achieved reasonable
level of convergence  fig  a  for all of the four learning algorithms we considered  logistic regression  lr   naive bayes  nb   svm with linear kernel  svm linear  and svm with gaussian
kernel  svm rbf   for all the learning algorithms we used the versions of them found in matlab
and its toolboxes 
to test the algorithms and for all of the following results we used k fold cross validation  k      
on our entire data set 

 

results

figure   shows the distribution of upsets by spread  upsets are significantly more common when the
spread is low  as would be expected  since closer spreads indicate more evenly matched teams  the
more games an algorithm correctly predicts as an upset  the more it also mislabels upsets  this trend
is even true  when we considered the heuristic of always picking the highest rank team to upset 
we were surprised to find out that pretty much all of our models  except svm linear  dont make
predictions for the higher upsets  we explored lowering the confidence needed for the algorithm to
predict to encourage the algorithm to pick upsets  for our logistic regression model we changed the
decision boundary by changing the probability above which an upset is predicted to explore its effect
on precision and recall  fig      we found that increasing the number of correct upsets we predict
 

fi recall   comes at the expense of misclassifying games as upsets when there are not  thus sacrificing
precision  this behavior is unacceptable since taking actions based on the misclassification of a
game as an upset  will have significant more cost than failing to identify an upset and the resulting
lack action 

figure    frequency of upset and predictive accuracy of algorithms examined versus spread  difficulty in predicting major upset and unfavorable labeling of false positives by some algorithms is
evident 

figure    trade off in precision and recall for the logistic regression algorithm 
we further explored the tendency of the models to not predict major upsets by performing a principal
component analysis  pca  of the season data  from figure   we see that it would be difficult to
separate upsets and especially major upsets  the pca also corroborates the trend shown in the
recall precision diagram  fig     and in the histogram  fig     that if you want to predict more
upsets correctly you will inevitably incorrectly predict a large number of upsets 
 

fifigure    principle component analysis of our    features showing the difficulty in separating upsets 
particularly major upsets  out from other games 

 

fi 

conclusions

error analysis of the methods we attempted showed that our learned models had great difficulty in
predicting upsets when one team is favored by a touchdown or more  adjustment of the decision
threshold  while increasing the number of true positive cases identified  came at the significant expense of additional false positives  principal component analysis indicates that this is likely due to
the fact that we have yet to identify a set of features which clearly separates out upset games  particularly when a team is favored by a touch down or more  aside from the relatively poor performance
of the svm with linear kernel  the algorithms investigate appear to give similar performance 
several different approaches for improving the features used exist and deserve further investigation 
by constructing the problem as an upset prediction labeling it is possible to take as feature input a
more rich set of prediction information from other models  looking at the variance of team ranking
and spread accross more external computer models than the two we used as data sources may provide
a good feature for identifying games with higher uncertainty on the outcome  additionally  while
not presented here  we did investigate breifly the use of expert opinion  in the form of sports writers
game picks for a subset of games  these expert opinions potentially provide a way to capture unique
facts related to injuries  momentum  weather that might be cause of a team to perform dramatically
different in a game  an experiment including expert opinion on a subset of pac    games did show
promise  unfortunately gathering and standardizing this data is significant task  and we ultimately
abandoned it as infeasible for the current project  work in modern football game statistics also
indicates that looking at statistics in a more complex fashion  in particular the interrelationship
between various raw statistics could be powerful 
defining an algorithm to systematically explore combinations of the above features in more complex
ways than afforded by an svm or similar learning algorithm could provide significant pay off 
neural networks    and genetic algorithms with variable length chromosomes       have shown
promise for feature selection in other applications  and may be appropriate here 

references
    sabermetrics  in encyclopedia britannica       
    b  carroll  p  palmer  and j  thorn  the hidden game of football  warner book  new york 
ny       
    b  liu and p  lai  beating the ncaa football point spread  december      
    m  bookman  predicting fantasy footbal  december      
    r  setiono and h  liu  neural network feature selector  neural networks  ieee transactions
on                    
    d  e  goldberg  b  korb  and k  deb  messy genetic algorithms  motivation  analysis  and first
results  complex systems                    
    r  srikanth  r  george  n  warsi  d  prabhu  f e  petry  and b p  buckles  a variable length
genetic algorithm for clustering and classification  pattern recognition letters                 
     

 

fi