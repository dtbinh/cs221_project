image  classification  
megan  schoendorf   megan  stanford edu   
christian  elder   celder stanford edu   

objective   
we  explore  several  algorithms  to  classify  images  in  the  cifar     data  set   there  are  
approximately          labeled     x   pixel   rgb  images   each  has  one  of      labels   
cat   dog   horse   etc   depending  on  the  subject  of  the  image     
  
summary   methods  and  results  
after  normalizing  the  data  to  have  zero  mean  and  unit  variance   we  used  pca  or  k 
means  for  feature  extraction   followed  by  gradient  descent   neural  networks   or  
nave  bayes  for  classification   we  found  the  best  combination  was  k means  for  
feature  extraction  and  gradient  descent  with  a  logistic  loss  function  for  
classification   which  gave  approximately       testing  error  with  all      labels   































  
data  preprocessing  
we  initially  experimented  with  compressing  the  rgb  values  of  each  pixel  to  single  
luminance  value  with  the  following  equation   
                          

however   this  step  did  not  improve  testing  error   so  we  removed  it      
  
instead   we  calculated  the  per pixel  mean  and  variance  and  removed  them  so  that  
our  data  had  zero mean  and  unit variance   this  preprocessing  had  a  small  positive  
   
impact  in  our  testing  error   in  the  following  equations       is  the  jth  pixel  of  the  ith  
image   
      

 
 

 
 
    

                                                                            

 
 

    
   
 
                     
     

   

       

finally   we  patched  the  image   dividing  the  image  up  into  patches  of  size               
or      pixels  on  a  size   stacked  those  patches  into  a  vector   and  lined  those  vectors  up  
into  a  matrix  of  size   patch  size   number  of  patches    this  is  the  data  that  we  used  
for  feature  extraction   

fi  
feature  extraction   k means  and  pca  
pca  
for  pca   instead  of  using  the  patched  data   we  stacked  the  images  into  vectors  and  
created  the  matrix  x  with  each  column  corresponding  to  one  image   we  then  used  
pca  to  reduce  the  dimensionality  by  creating  a  feature  vector   y   
        

       
  

       

where      is  the  i th  principle  component  of  the  covariance  matrix  of  the  data   we  
used  the  number  of  eigenvalues  greater  than     as  our  value  k   we  experimented  
with  using  this  method  before   after   and  instead  of  k means   
    
k means  
k means  clustering  is  an  unsupervised  learning  algorithm  that  groups  the  data  into  
clusters  about  k  centroids   minimizing  the  distortion  function   
 

           

        

 

  

   

where          is  the  cluster  centroid  to  which  the  i th  sample  has  been  assigned   we  
accomplished  this  by  repeatedly  assigning  the  points  to  the  nearest  cluster  and  
moving  the  clusters  to  the  centroids  of  those  assigned  points   for  the  final  feature  
extraction  step   we  had  two  methods   in  the  first  we  created  a  vector  of  size  
 number  of  patches     number  of  clusters       where  each  entry  was  the  distance  
between  a  patch  and  a  cluster   in  the  second   we  used   s  and   s  to  indicate   for  each  
patch   which  cluster  was  closest   we  tuned  the  patch  size   the  number  of  clusters   
and  the  number  of  iterations  to  optimize  the  testing  error   
  
classifiers  
gradient  descent  with  regularization   perceptron   hinge   and  logistic  
image  classification  was  initially  attempted  using  a  one  vs   all  classifier  trained  
using  stochastic  gradient  descent  with  one  of  three  loss  functions   perceptron   
hinge   or  logistic   for  each  label   a  binary  classifier  is  trained   and  an  image  is  
classified  as  the  label  corresponding  to  the  largest  score            to  train   we  are  
using  the  standard  stochastic  gradient  descent  update   
            

        

 

  

 

   

where      is  the  loss  function   the  parameters  of  gradient  descent  include  the  
number  of  training  iterations  and  the  learning  step      after  each  iteration  through  
all  the  data   we  added  a  regularization  step     
           


  


  
nave  bayes  
we  paired  this  algorithm  with  k means  and  the  nearest  centroid  indicator  for  
feature  extraction  so  that  the  feature  vector  would           we  calculated  the  
conditional  probabilities  of  p xj y   and  the  margin  p y    
  

fi               

 
     

   

 

  

 
     

  

 
     

           





 

 

 

       

      

   



  

  

  
we  modeled  x  as  binomial   so  to  calculate  the  p x y    
 

        

                                     
   

  
and  finally   for  the  prediction   we  choose  the  label  that  gave  the  maximum  
likelihood  estimate   
                         

  
neural  networks  
a  neural  network  with  one  hidden  layer  was  also  implemented  for  comparison  with  
the  previous  classification  algorithms   once  the  feature  vector  is  extracted  from  the  
input  data   it  is  fed  into  the  neural  network   which  propagates  the  data  through  the  
hidden  layer  nodes  to  the  output  nodes  via  the  following  equation   
         

              
 

where        is  the  weight  associated  with  the  edge  connecting      from  the  
previous  layer  to      of  this  layer   and  g  is  the  activation  function  of       we  
used  the  sigmoid  function  for  g   
  
the  weights  are  trained  by  propagating  the  error  at  the  output  nodes  back  through  
the  network   weights  between  the  output  layer  and  the  hidden  layer  are  updated  via  
the  following  equations   
                           
     

 

           

              
 

the  weights  between  hidden  layers  and  the  input  layer  are  updated  via   
                             
      

           
 

         
 

the  parameters  of  neural  nets  include  the  number  of  training  iterations  and  the  
learning  step      
  
  
procedure  and  results     
we  found  the  best  combination  of  algorithms  were  feature  extraction  by  k means  
with  distance  to  centroid  and  classification  by  gradient  descent  with  a  logistic  loss  
function   in  our  milestone   we  showed  the  effects  of  turning  the  k means  
parameters  and  found  the  best  were   x   pixel  patch  sizes       centroids       k means  
iterations   learning  rate  of     and  no  regularization   however   because  we  
implemented  all  of  these  algorithms  ourselves   speed  and  memory  were  an  

fiimpediment  to  running  the  tests  with  more  than   x   pixel  patches  and          total  
images     
  
figures     and     below  were  created  using       images  per  label  and  the  average  of     
runs  per  test   figure     gives  a  comparison  of  the  different  classification  algorithms   
showing  that  logistic  performs  the  best  for  the  majority  of  numbers  of  labels   figure  
   compares  different  feature  extraction  algorithms   none  at  all   just  vectorize  the  
image    pca   and  k means  with  distance  to  centroid   we  tested  with  both  logistic  
and  perceptron  loss  functions  and  found  that  in  both  cases   k means  performed  
better  than  the  other  two  feature  extractors   for  figure      we  found  a  learning  curve  
using  all  ten  labels   as  expected   the  testing  error  decreases  with  number  of  training  
samples   figure     shows  the  effect  of  training  iterations  of  gradient  descent  on  the  
training  and  testing  error   
  
  

            
figure        using  k  means  feature  extraction  

  
figure     

  

            
figure       using  k  means  feature  extraction  and  
gradient  descent  w ith  logistic  loss  function       
labels  

  
  
  

  
figure       using  k  means  feature  extraction  and  
gradient  descent  w ith  logistic  loss  function       
labels  

fi  
  
  
discussion  
in  our  initial  data  from  the  milestone   we  found  that  with  proper  parameters   all  
algorithms  would  yield  a        training  error   yet  the  testing  error  never  went  
below        we  suspected  over fitting   and  explored  a  few  solutions  including  
regularization   early  stopping   and  feature  reduction   regularization  and  pca  both  
hurt  our  classification  error   see  figure     for  pca  results    but  tuning  the  number  of  
training  iterations  proved  to  be  very  important     in  particular   the  number  of  
training  iterations  until  convergence  changed  drastically  with  the  number  of  
training  samples  and  finding  the  perfect  number  proved  challenging   
  
the  two  parameters  that  had  the  largest  effect  on  our  classification  error  were  
training  iterations  and  the  feature  extraction  method   it  is  interesting  to  note  that  
once  all  the  parameters  were  turned   all  of  the  classification  algorithms  performed  
roughly  equivalently   this  seems  to  suggest  that  it  was  not  the  classification  
algorithm  that  needed  optimizing   but  the  feature  extraction  algorithm   varying  the  
parameters  of  the  feature  extraction  algorithm  had  a  much  larger  effect  on  the  
testing  error   for  k means   the  number  of  centroids  and  patch  size  together  
determines  the  dimensionality  of  the  feature  vector  to  which  each  input  patch  is  
mapped   the  number  of  centroids  chosen  must  be  high  enough  to  distinguish  
dissimilar  images   but  low  enough  to  avoid  over fitting  the  data  or  slowing  down  the  
algorithm  too  much   
  
the  importance  of  differing  feature  extraction  is  corroborated  by  several  papers   
which  espouse  classification  accuracy  upwards  of             one  feature  selection  
technique   made  public  by  the  originator  of  the  cifar     dataset   involves  training  a  
neural  network  variant   convolutional  neural  networks        however   cnns  used  
for  this  purpose  tend  to  be  several  layers  deep   requiring  computational  power  
beyond  our  capabilities   for  reference   the  state of the art  cifar     classifier  
incorporates  a  four layer  cnn  feature  extractor  which  requires  industrial grade  
gpus  for  reasonable  training  time        as  such   exploring  more  exotic  and  
computationally expensive  feature  extraction  methods  was  deemed  beyond  the  
scope  of  this  project   
  
references  
    benenson   rodrigo   classification  dataset  results   cifar      last  modified  november       
       
http   rodrigob github io are we there yet build classification datasets results html        
    d       
    krizhevsky   alex   ilya  sutskever   and  geoff  hinton    imagenet  classification  with  deep  
convolutional  neural  networks    in  advances  in  neural  information  processing  systems       pp   
                   
    wan   li   matthew  zeiler   sixin  zhang   yann  l   cun   and  rob  fergus    regularization  of  neural  
networks  using  dropconnect    in  proceedings  of  the    th  international  conference  on  machine  
learning   icml       pp                      

fi