extending cancer cell drug response models

wei zhou

bill evans

paul butler

weiz  stanford edu

bill evans post harvard edu

paulgb stanford edu

abstract
this project examines methods for predicting the degree to which various drugs inhibit the
growth of a range of cancer cell types  data consist of over        features for each of    
cell lines and cell growth inhibition measurements for    drugs  the high dimensionality of
this data raises challenges that are addressed through elastic net parameter tuning  we also
investigate principal component analysis and the use of principal components as features
to reduce dimensionality without compromising accuracy  finally  we explore support
vector regression and random tree models for this data 

 

background

in recent years  the study of cancer and cancer genomics has been supported by the development of openlyavailable research data sets  these include the cancer genome atlas  tcga   the wellcome trust sanger
institutes catalogue of somatic mutations in cancer  cosmic  database  sangers genomics of drug sensitivity in cancer  gdsc       and the broad institutes cancer cell line encyclopedia  ccle      
the ccle seeks to address the challenges associated with the systematic translation of cancer genomic
data into knowledge of tumour biology and therapeutic possibilities       it does this by bringing together
drug response data  cell line phenotype data  and genomic data 
the feature data contains        features for each of     cell lines  the features are grouped into three categories         features representing gene expression         features representing copy number variation 
and       binary features indicating the presense of oncogenes 
the response data consists of a    x   matrix in which each data point represents the ic   inhibition dosage 
of a single drug for a given cell line  this structure lends itself to predictive modeling in which a single column
vector  i e   the drug response data for a single drug across all     cell lines  is employed as the response
variable for the feature data  alternatively  the entire response matrix can be modeled simultaneously in a
multitask model 

 

preprocessing of data

   

normalization and imputed values

continuous valued and discrete non binary  gene expression and copy number variation  respectively  valued
feature data were scaled  binary valued data  oncogene indicator variables  were not altered 
a portion of the response variable matrix contained missing values  in the ccle data set      of       
 approximately       of response values were missing  a regression based model  elastic net cannot fit
missing values  this necessitates imputation of response data  comparative evaluation of imputation methods
allows for more robust estimation       we employed svd  k nearest neighbor  knn   regression  and
 

this is the amount of the compound required to inhibit the cell growth by half 

 

fisvt  each imputation method was scored using leave one out cross validation in which a single known
value was removed from the model  those known values were then imputed using each of the methods under
consideration 
rmse for each method was calculated as the difference between the known  held out data and the imputed
data  four methods  knn  lm  mean value  svd  and svt  were fully evaluated  the optimal imputation method  svd  had an rsme of     compared with worst case performance for svt  rmse       
svd imputed response data were employed in the modeling throughout this project to ensure comparability
between results from models which do not handle missing data and those that do  missing values were not
imputed for test data  in order to avoid misstatement of the validity of the model that could result  
   

feature selection methods

the dimensionality of cell line genetic data exceeds the number of observations by more than     fold 
feature selection is necessary in order to enhance model prediction  by identifying and excluding features
that lack significant explanatory power  and to improve the training run time performance 
studies of cell line genomic and drug response data include elastic net regression            automatic
variable selection accomplished with elastic net lends the model naturally to the high dimensionality of
genetic data     
pearson correlation of features with response variables has been utilized for feature selection   i e  
only features with a pearsons coefficient above a
specified threshold are included in the model       
while feature reduction is achieved  this approach
relies on an arbitrarily established cutoff 
as an alternative  we employed pca for dimension
reduction and then model the principal components
as features  we established the relationship between
the variance captured by pca and model error for
a given number of principal components  the first
    principal components capture more than    
of variance in the original data  this decrease reduces model training latency dramatically with only
modest increases in elastic net rmse 

 

figure    principal components were used as features
of elastic net regression  in the plot on the left  the
rate in decrease in rmse slows sharply near     principal components  similarly      principal components account for approximateley     of the variance
in the feature data  the red dot marks these points in
each graph respectively 

methodology and results

we first performed elastic net regression individually on single drug response vectors  later  we compared
this result to multitask elastic net  in which the complete response matrix is utilized in a single predictive
model  finally  we explored support vector regression  svr  and random forest models with a view on
the tradeoff between model training performance and model error 
   

elastic net

elastic net is a regularized regression model that combines lasso and ridge regression l  and l  norms 
   argmin ky  xk      kk      kk   

   



the lasso penalty tends to select individually correlated predictors and discards the others while ridge
shrinks them towards each other      the elastic net penalty mixes the two while also overcoming a limitation
faced by lasso  namely its inability select more features than there exist observations in the dataset 
in the above equation    and   correspond to the ridge and lasso penalties  respectively  elastic net has
the capacity to select groups of correlated variables     ideally suiting it to genetic data in which genes are
believed to interact in causative networks 
 

fifor each compound we first searched for the pair of parameters      
which achieved the lowest r  on a holdout set  we experimented with
coordinate descent  but found grid search over a small grid to be faster
because it could be easily parallelized  however  grid search necessarily
discretized the search ranges of   and     to address this  once having
completed the grid search for each elastic net regression on individual
drug response data  using python scikit learn       we employed the r
glmnet package to select   over a continuous range 
figure   shows the results of the grid search for one compound  nutlin  
 note that axes are labeled using scikit learn parameter names  in which
l  ratio               and alpha             the l  regularization
and alpha with     
in this way cell line response to each drug compound was examined in
isolation  however  we observed that several compounds have highly correlated response variables   see figure     modeling compounds in isolation  while reasonable  failed to exploit this characteristic 

figure    best parameter search
results for one compound  nutlin 

in order to take advantage of correlations in compound response we implemented multitask elastic net 
which models the interaction as a multivariate gaussian  rmse for multitask elastic net using all zero
values assigned to missing response variables in the training dataset yielded an rmse of      on the test
dataset  and an rmse of      was achieved on the test data set when using svd imputed response training
data 
these results from multitask elastic net underperformed the average result of individual elastic net regression  which had an average rmse of       because the multitask model can make use of additional
information  i e   the correlation among different response variables   we anticipated a performance improvement 
a total of     features        of the original feature set  were active variables in multitask elastic net  this warrants additional investigation 
   

support vector regression

we investigated the support vector regression  svr  model to explore
the comparative runtime performance of the learning algorithm and its
accuracy on highly dimensional data 
svr parameter tuning was performed using python sklearn gridsearchcv with   fold cross validation  rbf kernels were tuned over
a range of values for kernel parameter                       and the
parameter c                     was tuned in both linear and rbf figure    correlation matrix of
models using rmse to score model prediction  given a training set compound response data 
s     xi   yi    i           m   the lagrange optimization for svr     with
slack variables i and  precision is given by 
m

minimize 

x
 
kwk    c
 i   i  
 
i  

   


yi  hw  xi i  b     i
subject to hw  xi i   b  yi     i

i   i   
rbf tuning parameter 
k x  z    exp kx  zk    
 

   

fikernel parameter selection varied across the respective search domains  however  selection of the optimal
kernel was nearly uniform with all but three models performing optimally using a rbf kernel  in three
cases  a linear kernel outperformed rbf  indicating a possible difference in structure in the data as well as
the underlying biology for these drug cell line pairs 
   

random forest

we implemented the random forest model to establish its comparative performance on a wide feature matrix  the random forest model is an ensemble of a set of regression trees 
in addition to constructing each tree using a different bootstrap sample of the data  random forests added an additional
layer of randomness by splitting each node using the best
split among a subset of predictors randomly chosen at that
node       the random forest training algorithm complexity is
o m  mn log n    with m      the number of trees  m       
the number of observations  n         the number of original
figure    rmse for svr  random forest 
features  
and individual elastic net for all    drugs 
the random forest was built with the randomforest package in mean rmse was             and      for
r v       due to the complexity of computing a forest on all svr  rf  and elastic net respectively  red
features  a single random forest was built using the first     asterisk indicates selection of linear  as opprincipal components  instead of the original feature vector   posed to rbf  kernel in svr regression 
each random forest was built by   regression trees using     of
the features  figure   compares random forest performance to svr and elastic net 

 

data extensions  padel dataset

other research has investigated the degree to which chemical
features can of themselves be used as model features in biological data sets  these experiments rely on software that produces
a feature set that describes the physical structure of a chemical
agent 
menden  m  et al      describe a method for modeling predictions on the gdsc cell line data by adding chemical descriptors to the genetic feature data      a neural network and
random forest were trained on the resulting feature set  we
were not able to find research that makes use of gene data
alongside chemical descriptors in an elastic net regularization
framework 
we collected smiles     files for    of the    compounds represented in the ccle data from pubchem  the structure for
one chemical  lbw     was not in the database and so was
omitted from our dataset  these smiles files were used as
input to padel      a program which converts molecule representations into a variety of numeric properties describing the
underlying chemical structure  the resulting output created
    features that we added to the ccle feature data 

figure    integration of padel data with
ccle dataset  prior to adding padel compound data  cell line features appear in a
single row vector  after adding padel data
for each compound  each cell lines feature vector is repeated  once for each response compound pair 

incorporating padel data required a transformation of the feature and response matrices  the ccle data contains    response variables for each feature vector  to add
the padel compound data  we exploded the response vector into individual values spread over multiple rows
as shown in figure   
 

fithe resulting dataset was fed into vowpal wabbit       a highperformance implementation of gradient descent learning  we
used a subset of its features equivalent to elastic net regression 
the addition of padel data did not result in improved performance  rmse was      with an r  of      worse performance
than multitask elastic net for the base ccle data  a comparison of included  versus excluded  features did not yield insight
into the reduced in performance that resulted from padel data 

 

conclusion

figure    predicted versus actual ic    drug
we propose to explore the addition of gene network informa  response using padel data in multitask
tion to the model  whereby the known biological association elastic net 
between genes  amplification  silencing  etc  is utilized  it
would likewise be interesting to explore feature selection methods with padel data included  possibly making use of information about the biological relevance of particular physical chemical features to enhance the selection process  separately  we would like to further investigate the degree to which elastic net is able to predict gene
associations using this data through a measure of similarity in regression coefficients 
while our models cannot replace lab experiments  we have established a baseline for multitask modeling 
this information may be help guide compound cell line combinations that merit laboratory investigation 
acknowledgments
we would like to thank david knowles for his support and for providing the cell line data used in this project 
references
    barretina  j  et al         the cancer cell line encyclopedia enables predictive modelling of anticancer drug sensitivity  nature             
    zou  h  and hastie  t         regularization and variable selection via the elastic net  j  royal  stat  soc  b 
              
    garnett  m         systematic identification of genomic markers of drug sensitivity in cancer cells  nature 
          
    smola  a  and scholkopf  b         a tutorial on support vector regression  statistics and computing           
    yang  w  et al         genomics of drug sensitivity in cancer  gdsc   a resource for therapeutic biomarker
discovery in cancer cells  nucleic acids research    d    d   
    pedregosa et al         scikit learn  machine learning in python  journal of machine learning research            
    yap cw        padel descriptor  an open source software to calculate molecular descriptors and fingerprints 
journal of computational chemistry             
    menden  m  et al         machine learning prediction of cancer cell sensitivity to drugs based on genomic and
chemical properties  plos one      e      doi         journal pone        
    weininger  david         smiles  a chemical language and information system  journal of chemical information
and modeling          
     langford  l  et al  vowpal wabbit http   hunch net vw 
     l  breiman  random forests         machine learning          
     hastie  t et al  imputing missing data for gene expression arrays  technical report  division of biostatistics 
stanford

 

fi