cs     final project  autumn     

 

predicting the major league baseball season
randy jia  chris wong  and david zeng

abstractthis paper attempts to predict the outcome
of games from the      major league baseball season 
sporting events are very important to many people  and
professional leagues are worth billions of dollars  baseball 
in particular  is not only one of the most popular sports in
the united states  but the vast amount of recorded data
and statistics made publicly available also lends itself well
to machine learning  realizing that baseball games are
quite noisy  in our prediction  we hope to predict games
with sufficiently high accuracy and to unveil information
about what makes a winning baseball team  a feature set
was carefully chosen  and both classification and regression
techniques were implemented  the performance of the
algorithms were tested on a recent season and the results
showed a small degree of success  but also confirmed the
suspicion that baseball games are very hard to predict
based off statistics alone 

i 

measure and analyze any results  we defined two target
prediction rates based on     predicting the home team
wins every game  and    using the predicted winner
according to betting odds and spreads from las vegas
sports books 
month
apr
may
jun
jul
aug
sep
avg
table i 

home team
      
      
      
      
      
      
      

las vegas
      
      
      
      
      
      
      

b enchmark p rediction accuracies

i ntroduction

porting events are deeply integrated in many
peoples lives  in the united states  baseball is one of
the most popular sports  the highest level of play occurs
in major league baseball  mlb   a professional league
worth billions of dollars  from television contracts alone 
mlb earns      billion each year from domestic viewers
     it is important for a baseball team to win games
because it will attract higher fan attendance  television
viewership  and  perhaps most importantly  revenue 
predicting the outcome of baseball games is an even
more lucrative field  cnbc estimates that over        
billion is wagered on games every year      luckily 
mlb games lend themselves well to machine learning
because of the vast amount of data that is recorded for
each game  a downside  though  is that baseball itself
is quite noisy and thus difficult to predict with high
accuracy  any player having a good day can hit a home
run  and this action alone can allow for a lesser skilled
team to defeat a better team  after all  if it were that
easy to predict the winning team for each game  then why
even play the games at all  nevertheless  we will explore
machine learning algorithms using data from recent mlb
seasons and try to predict the      season as accurately
as possible 

s

ii 

b enchmarks

before we collected  tested  or trained any data  we
established benchmarks so that we would be able to

las vegas betting and prediction data was taken from
sbrforum      a website which aggregates spreads and
odds from many popular sports books  data files were
not readily available  so we scraped and interpreted raw
html from many webpages  for our work  we only
used the betting information that predicted which team
was going to win  we did not use more detailed data such
as run spreads or money lines  which we will discuss later
as possibilities for future work 
if our results better these benchmarks  especially the
percentages from las vegas sports books  then our ma 

fics     final project  autumn     

chine learning processes could potentially have tangible
and monetary significance  throughout this paper  we
will italicize the las vegas benchmark percentages and
will bold any results that surpass them 
iii 

m achine l earning a pproach

the simplest way to predict games is to implement
a learning algorithm that classifies games as either a
win or a loss  this approach can be achieved using
popular machine learning algorithms such as logistic
regression  svms  logistic boost  and adaptive boost  the
classification approach  however  does not indicate the
nature in which a game was won or loss  it does not give
any information regarding how many runs were scored or
by how much a team won  therefore  we also implement
a regression approach  which predicts how many runs are
scored by each team  hence  we can determine who won
by a simple comparison of runs scored 
iv 

f eature s election

because of the sheer quantity of different numbers
that baseball statisticians record  it is important to identify which features are the most important in deciding
victories  to do this  we must determine which features
have the greatest impact on the number of runs scored 
thereby determining the winner and loser of a game  we
evaluated many of the popular statistics used by baseball
statisticians and narrowed down a feature set we believed
correlates most to scoring runs 
batting


batting average  ba   number of hits divided by
number of at bats
 slugging percentage  slg   number of bases
divided by number of at bats
 runs batted in  rbi   number of runs a batters
team scores by virtue of a hit
 on base percentage  obp   how often a batter
reaches a base per at bat
 walks drawn  wb   number of times a batter
reaches a base on balls
pitching
 earned run average  era   earned runs per  
innings pitched
 hits allowed  h   hits allowed to batters
 bases allowed  b   bases allowed to batters
 strikeouts  k   strikeouts per inning pitched
 walks thrown  wp   number of times a pitcher
allowed a base on balls

 

team stats
 errors  e   number of fielding errors committed
by team
 past head to head matchups  record of past
games between the two teams
 left on base  number of batters that reach a base
but never score a run
 win percentage  win    current season win percentage
data was readily available for us to download for free
from retrosheet      the files contained detailed pitchby pitch logs of all mlb games for each completed
season  with records going as far back as the late     s 
to ensure the completeness and integrity of the data 
we decided to consider only games from      to      
the first step of our project was converting the csv
play by play data files from retrosheet into much more
accessible forms  such as an sqlite  database  data from
the years      to      produced about   million rows of
play by play data from which we aggregated box score
summaries for each game  we wrote java programs to
query our database and calculate game by game data for
the statistics listed above  this in turn allowed us to build
new csv files that were much more useful for our feature
selection process  there are over      mlb games per
season  and so the large sizes made this process very
challenging 
using our box score summaries of each game  our
goal was to find which subset of statistics were most
indicative of producing a win  from this vast feature set 
we utilized feature selection to select the ideal features of
choice  first  we ran a best subset feature selection on the
features in each of the three categories  batting  pitching 
and team stats  however  best subset can sometimes
overfit the data  so we also decided to run both forward
and backward selection to account for this possibility 
the following table displays the results of our feature
selection 
selection
algorithm
best subset
best subset
best subset

features
considered
batting
pitching
team statistics

forward

all

backward

all

table ii 

most important
features
rbi  ba
era  h
e  win 
e  rbi  ba 
era  h
e  rbi  obp 
era  win 

f eature s election a lgorithms

fics     final project  autumn     

from our feature selection analysis  we decided on
ba  rbi  obp  era  h  e  and win  for each team 
preliminary tests indicated that these are the more important features  and adding other features did nothing
to improve the prediction 
v 

p rediction m odel

along with these features  we must also consider the
time frame from which we derive our baseball statistics
 e g  the current season  last   seasons  a players entire
career   while the easiest approach would be to just use
a players career statistics  we believe that statistics from
the current season        are much more significant than
those from previous seasons  in other words  previous
season performance is not the best indication of current performance  factors such as injuries  suspensions 
trades  experience  improvement  and health issues can
create high variance in each seasons performance for
a significant number of players  therefore  we decide to
put most of the weight on performances from the current
season  and much less weight on past performances  the
drawback with this approach is that predicting games
from the first   weeks of the season will prove to be
difficult because of the small sample size of current
season data  we will address prediction accuracies for
different portions of the season later 
thus  we use the      season as our test data and the
previous five seasons as our training data  the hope is
that we can predict the      games with accuracy as well
as baseball games can be predicted  the challenge lies
in the fact that baseball games are inherently very noisy 
and the better team is not always guaranteed to win 
so it is unreasonable to expect a very low error rate 
to predict the winner of a game  we consider the
players that comprise the starting lineup of both teams 
  batters and   pitcher  to predict game n of a season 
we accumulate the statistics for the past n    games
of the season for each player on the starting lineup 
these cumulative statistics are the particular games
features  our machine learning algorithms will then try
to determine how the differences in the features between
the two teams indicated a win or a loss 
vi 

c lassification a lgorithms

we first trained a logistic regression model and svm
on the           seasons and classified the      season 
the svm was implemented with a gaussian radial basis
function  rbf  kernel and a cost parameter  as the
data is most likely nonseparable  the value of this cost
parameter was determined by picking the best parameter
value from a set of predetermined values ranging from
     to    using a validation set approach 

 

we also decided to try a boosting approach  with
classification trees as weak learners  we performed
boosting in the form of adaboost  adaptive boosting 
and logitboost  logistic boosting   boosting utilizes a
number of weak classifiers and creates a single strong
classifier  as such  boosting reduces bias because of the
large number of weak classifiers  here  the number of
iterations controls how many weak classifiers there are 
if this parameter is too small  however  the data may be
underfit  on the other hand  if it is too large  the data
may be overfit  as a result  we perform    fold cross
validation beforehand on our training set to obtain an
optimal number of iterations 
algorithm
benchmark
logistic regression
svm  rbf kernel  cost    
adaboost     iterations
logitboost     iterations
table iii 

accuracy
     
     
     
     
     

r esults of c lassification a lgorithms

we see that svm  adaboost  and logitboost achieve
an accuracy of almost      indicating that baseball is a
rather difficult sport to predict  we have  though  cleared
our benchmark with three of the four algorithms  to see
if better results can be obtained  we also try a regression
approach 
vii 

r egression a lgorithms

we fit both a linear regression model and a random
forest model  for the random forest model  the number
of predictors to be considered at each split in a tree was
determined via a validation set  in each model  we predict
the runs scored for each team in each game  reporting
both the test mean squared error  mse  for run differential and the classification accuracy after comparing the
two teams scores 
algorithm

test mse

benchmark
multiple linear
regression
random forest 
  predictors

 

classification
accuracy
     

     

     

     

     

table iv 

r esults of r egression a lgorithms

we see that while the classification accuracy was
competitive with the classification methods described

fics     final project  autumn     

 

earlier  the mse was substantially large  leaving us to
conclude that regression is  overall  not an accurate path
to consider  in both our regression algorithms  however 
we surpassed our benchmark 
viii 

t ime  based p redictions

to uncover the issue of different parts of the season
being harder to predict  we decide to partition our test
data into months  april to september  for each algorithm 
dividing the test data set in this manner allowed us to
confirm our belief that games earlier in the season are
harder to predict  the following shows that this is indeed
true 
month
apr
may
jun
jul
aug
sep
table v 

benchmark
     
     
     
     
     
     

logistic
reg 
     
     
     
     
     
     

adaptive
boost
     
     
     
     
     
     

random
forest
     
     
     
     
     
     

m onth by m onth accuracy of various
l earning a lgorithms

ix 

first heuristic benchmark that navely picks the home
team to win every time  this supports the hypothesis
that baseball is a very noisy sport and difficult to predict 
however  we believe we can continue to do better  we
believe one major cause for poor accuracy is that the
early part of the season is more difficult to predict  there
have not been enough completed games to determine how
well a player is likely perform for the rest of the season 
it is also possible that players are not in shape at the
beginning of the season and their performance deviates
greatly from their true skill level 
regardless of the reason for inaccuracy  the small
amount of highly variant statistics for early season games
results in our prediction rates being relatively low  many
algorithms fail to meet the las vegas benchmark for the
first three months by wide margins  this suggests that
real world knowledge and intangible factors  such as a
player being in shape  may have a greater significance
on these first few games  within our work  we did not
have statistics to measure these details  but oddsmakers
can certainly take these into account 
for games in the later half of the season  our results are
nearly     better than those from the earlier half  thus 
we can see that it is likely that baseball games have some
degree of predictability  the cumulative season data that
we use as features for each game stabilizes as each player
and team adjusts to the season  indeed  many of our
algorithms surpass our las vegas benchmark  implying
that it is possible to use statistics as one of the better
predictors of the game 
throughout our results  we see that our machine learning algorithms have outperformed a significant benchmark  the las vegas oddsmakers for the      mlb
season  note  however  that this does not necessarily
mean that we can win large amounts of money by betting
based off of statistics  for one  we have only tested our
algorithms on one season  and each season as a whole can
have intangible variabilities that may or may not apply
for any particular one  additionally  our interpretation of
the las vegas benchmark is a highly simplified model of
how betting actually works  often times  one cannot just
bet on the winner of a baseball game  usually  one must
bet on a run spread or money line  the intricacies of
betting are outside the scope of this paper  but it should
be realized that a greater number of predicted games
may not directly lead to gambling winnings  of course 
though  it is a good start 

d iscussion

the accuracy achieved is not what one would hope
for a prediction if  say  one were to bet on a game  our
prediction accuracies were only slightly better than the

x 

other attempts at i mprovements

upon analyzing our learning methods  we realized that
our feature set still seemed to be nonideal  either from

fics     final project  autumn     

improper selection or simply that baseball statistics do
not provide a good prediction for the outcome of games 
to address this  we attempted to include polynomial
and interaction terms of the features  but many different
combinations of these terms did not help the prediction
accuracy at all 
we also ran principal component analysis on the
feature space and limited ourselves to varying numbers
of principal components  however  this did not improve
accuracy  in fact  the performance was actually worse  
running svm with different kernels  such as a polynomial kernel  also did not improve results 
an indication that our learning algorithms were not
performing as well as we desired was the values of the
training error  in most cases  the training error matched
the test error  this indicates possible underfitting of the
data  however  any attempts to remedy this  such as
tweaking parameters  failed to improve accuracy  while
we still hope to do better  the noisiness of the data and the
unpredictability of baseball itself are major roadblocks in
achieving this 
xi 

f uture w ork

despite our results  we cannot say for certain that the
upper bound for predictions rates of baseball games is
        we have not considered all feature sets and
learning algorithms  this work can be built upon  and
hopefully improved  by possibly expanding the feature
set or creating a baseball statistic more indicative to
winning baseball games  for example  one could analyze
the data at a more granular level to include a specific
batters record against a specific pitcher  one might also
consider the difference in playing style from the national
league and the american league  perhaps one might
even consider quantifying intangible factors such as how
experts feel about a particular game or how physically
ready a teams players are  it may also be interesting to
try another learning algorithm such as neural networks 
we see area for future work in accurately predicting
the playoffs  since these games occur after the regular
season  our results suggest we should be able to predict
them with higher accuracy  the playoffs are an important
time of the season since it is when the baseball champion
is crowned  a distinction driving all of these billion dollar
franchises  however  the caveat is that playoffs games
only involve the top teams  and the games are in general
much closer and competitive in terms of statistics  it
would be interesting to see how accurate our proposed
machine learning algorithms are then 
finally  there is also work to be done on the comparison between machine learning predictions and las
vegas betting  the highly simplified binary classification

 

model can be changed to incorporate run spreads and
money lines  perhaps giving a more accurate picture of
how statistics stand up to human intuition  instead of
predicting only a win or loss  the algorithms must
be fine tuned to predict a better run differential or the
probability that one would win a given bet  in the future 
an advantageous model against las vegas sports books
may be uncovered 
xii 

c onclusion

we spent a great deal of time organizing our data and
carefully choosing our features  however  we ultimately
were only able to predict under     of games correctly 
compared to our heuristic benchmarks  we conclude that
baseball games are very noisy and difficult to predict
based on statistics alone  however  we were able to
increase this percentage to upwards of     near the
later portion of the season  indicating that there is some
predictability in the games  for earlier games  though  it
is difficult to determine outcomes from so little data  by
using the simplified classification model for betting  we
also see that there is potential for using machine learning
and pure statistics to advantageously bet on baseball
games  with a little more adjustment  our machine learning models may obtain great financial significance 
one last comparison we can make with our work is
the      film moneyball      which details the statistical
analysis that went into building the      oakland as
roster  curiously enough  the two statistics focused on
by the team management  obp and slg  actually
turned out to be rather weak features in our feature
analysis  note  though  that while our goal was to predict
team wins regardless of player salaries  the goal of these
statisticians was to find the most salary efficient players 
so  perhaps they focused exactly on statistics that were
known to be not as highly valued  that same year  the
oakland as made the playoffs  showing that there is
indeed merit in using machine learning approaches to
characterize americas favorite pastime 
r eferences
   

shactman  brian a  big moneyball for major league baseball  cnbc com  n p     oct        web     dec       
 http   www cnbc com id           
    mlb odds   live mlb odds  sbrodds com  sbrforum 
      web     dec         http   www sbrforum com bettingodds mlb baseball   
    retrosheet  retrosheet  n p         web     dec       
 http   www retrosheet org  
    moneyball  dir  bennett miller  perf  jonah hill and brad pitt 
universal       

fi