predicting tags for stackoverflow questions
sebastian schuster
wanying zhu
yiying cheng
 sebschu wanyingz yiycheng  stanford edu

abstract
we present a system that is able to automatically assign tags to questions from
the question answering site stackoverflow  our system consists of a programming language detection system and a
svm using content based features  when
testing on an unseen test set  we achieve a
mean f  of      on this task 

 

introduction

the question answering site stackoverflow allows users to assign tags to questions in order to
make them easier for other people to find  further experts on a certain topic can subscribe to tags
to receive digests of new questions for which they
might have an answer  therefore it is both in the
interest of the original poster and in the interest
of people who are interested in the answer that a
question gets assigned appropriate tags 
stackoverflow allows users to manually assign
between one and five tags to a posting  users are
encouraged to use existing tags that are suggested
by typing the first letter s  of a tag but they are
also allowed to create new ones  so the set of possible tags is infinite  while the manual tagging by
users generally works well for experienced users 
it can be challenging for inexperienced users to
find appropriate tags for their question and by letting users add new tags it is likely that different
users use different orthographic versions of tags
that mean the same thing such as php  and php   for these reasons it is desirable to a have a system that is able to either automatically tag questions or to suggest relevant tags to a user based on
the question content 
in this project we are developing a predictor that
is able to assign tags based on the content of a
question  more formally  given a question q containing a title consisting of n words a         an and

a body consisting of m words b         bm   we want
to assign    k    tags t         tk from a limited
list of tags t  

 

related work

   

automatic content tagging

there has been some work done on automatic tagging of web content  mei et al   mei and zhang 
      trained language models using web document content and tag logs to suggest tags to users
of the social bookmarking service del icio us 
sood et al   sood et al         developed a tag
suggestion system for blog posts using information retrieval methods that was based on finding
similar blog posts and suggesting some of their
tags  liu et al   liu et al         modified the ibm
model   word alignment algorithm that is predominantly used to train machine translation systems
to generate alignments between short descriptions
and texts and used this information to suggest new
tags  stanley et al   stanley and byrne       
propose a bayesian probabilistic model to predict
tags for stackoverflow posts  for each tag they
compute an activation score given the words in
the title and the body that mainly depends on cooccurrence statistics 
   

programming language detection

very little work has been done so far on the
automatic detection of programming languages 
github developed a library  that is able to detect
programming languages but it mainly relies on the
file extension and only uses a probabilistic model
for ambiguous cases such as files ending in  h
that could be c  c   or objective c header files 
instead of using a multi class naive bayes classifier  klein et al   klein et al         collect some
specific statistics of code in different languages
such as statistics on certain keywords or punctu 

https   github com github linguist

fi 

methods

   

evaluation

we evaluate our system by computing the mean
recall  mean precision and mean f  over all documents  i e  we compute recall  precision and f 
for every document and then take the mean of all
these values 
   

figure    distribution of the number of tags per
document
ation marks to predict the used programming language 

 

data

as a baseline  we implemented a naive bayes
classifier trained on the words in the title of a question  we tokenize the title using the sentimentaware tokenizer by christopher potts  that is well
suited for tokenizing web text with a lot of punctuation  for new questions  we assign the    the
median number of tags per question  most probable tags  by doing that we get a precision of     
and a recall of      
   

we use the data provided for the kaggle competition on the automatic tagging of stackoverflow
posts    the data set consists of           stackoverflow questions  each question consists of a
title  the html markup of the question body and
the tags of the question  as working with such a
huge data set entails many computational limitations  we decided to use only a subset of the data 
first  we reduced the tag space by only considering documents tagged with the most       frequent tags  from this data  we sampled        
documents for our training set        documents
for our development set and       documents for
our final evaluation set 
table   shows the most frequent tags in our corpus  here we can see that the most common tags
are almost all names of programming languages 
figure   shows the distribution of the number of
tags per post  here we can see that more than    
of the posts have either two or three tags 
c   java  php  javascript  android  jquery  c   
python  iphone  asp net  mysql  html   net  ios 
objective c  sql  css  linux  ruby on rails 
windows
table       most frequent tags

 
http   www kaggle com c facebook recruiting iiikeyword extraction

baseline

programming language detection

motivated by the observation that a lot of posts
contain code snippets and that the programming
language is often used as a tag  we implemented
a programming language detection system  we
identified a list of    very common tags referring to programming languages  then  we went
through our training data and considered all questions with exactly one of these tags  code snippets
are encapsulated in specific html markup so it
is easy to extract only code snippets from a question  we tokenize these snippets by splitting on a
character level for all non alphabetic strings and
on a word level for alphabetic strings  so the string
int count   would be split into int  count 
      then we filter out all tokens that occur less than    times in our corpus based on
the assumption that these are variable or function
names or parts of comments that contain little information on which programming language was
used  the remaining tokens are then used to train a
multinomial naive bayes classifier that can return
the most probable programming language given a
code snippet 
   

content based classifier

as a second system  we implemented a svm
based classifier  we treat our problem as a binary
classification problem that predicts for each tag
t  t whether it is a tag for the given document
 

http   sentiment christopherpotts net 

fi exact title  is the tag one of the words in the
title 

    

f 

    

    

    

    

learning curve

    

train

    

dev

    

or not  we construct our training examples the
following way  for each observed tag document
pair  we compute a feature vector and use these
examples as positive training examples  additionally  we sample for each document x random tags 
where x is the number of tags assigned to the document and compute again a feature vector for each
of these tag document pairs and use them as negative training examples  by doing that we get the
same number of positive and negative training examples  these examples are then used to train a
linear svm classifier    to assign tags to a new
document  we go through all tags and for each tag
we compute the tag document feature vector and
let our classifier determine whether the given tag
is a tag for the document or not  in case more than
n tags get assigned to a document  we assign the
n ones having the highest decision function value 
we treat n as one of our hyperparameters 
we preprocess all documents by    stripping
the code fragments and any html code from the
question body and    by tokenizing the title and
body  in order to tokenize we use a modified version of the sentiment aware tokenizer that does not
split frequent tags such as c   c   or  net 
we implemented the following six features for
a document tag pair 

  

  

   

   

    

    

     

training examples

figure    learning curve on training and development set 
likelihood estimates of the training data  in
case we did not observe a certain documenttag pair  we set its pmi to   
   

hybrid system

finally  we combine the two described systems
to create a hybrid system  for the hybrid system
we predict the programming languages of all code
snippets in a question  if there are some present 
and up to n tags using the svm described above 
the output of the hybrid system is then the union
of the two tag sets that were output by the respective systems 

 exact body  is the tag one of the words in
the body 

 

 relaxed title and relaxed body  are all tokens that are obtained by splitting tags at hyphens contained in the title resp  body   e g 
the tag machine learning would be contained
in which machine learning algorithm should
i use  

given that we have a model with only six features 
we assumed that we need only a small fraction of
the training data to obtain a good model  figure  
shows the learning curve of our model  we can see
that our assumption was right and by using only   
training examples we already get our highest f score on the development set  for this reason we
use only    training examples for all further experiments  note that while we use only    training examples to train our svm  we still use the
entire training set to train our code classifier and
to estimate the pmi values 

 title pmi and body pmi  we loop over all
words in the title resp  body and compute
the sum over all pointwise mutual information  pmi  values for a word tag pair  pmi is
defined as following 
p m i t  w    log

p t  w 
p t p w 

we estimate the probabilities needed to compute the pmi by computing the maximum
 

we use the linearsvc implementation in scikit learn 

   

   

results
training set size

maximum number of tags

we observed that in many cases our predictor predicted too many tags  as described above  we use
the n tags having the highest decision function
value  figure   shows the influence of varying n
on the mean f  on the development set  as we can

fifigure    influence of the maximum number of
predicted tags on the performance of our model
on the development set 

see in the figure  we get the best results by setting
n to    why we used this parameter for all further
experiments 
   

feature selection

in order to check whether all our features actually
improve our system  we did an ablation test on the
development set  we noted that leaving out any
feature lowered the f  score  for this reason we
included all our features in our final model  for
the sake of brevity  we omitted the exact results of
the ablation test  but it showed that especially the
pmi title feature was very important as leaving it
out led to a drop of      of the f  score        vs 
      
   

final results

figure   shows the results of all our models on the
held out test set  we can see that in terms of precision all our models outperform the baseline  we
can also see that the programming language predictor is able to predict a tag with a remarkably
high precision  in terms of recall our svm based
model and our hybrid model outperform the baseline and in terms of f  we see a clear improvement of using our svm based and an even further
improvement using our hybrid system  our test
results are also comparable to the results on our
development set suggesting that we chose reasonable values for the hyper parameters 

figure    results of the different models on the
held out test set 

 

discussion

we presented a fairly simple model that is able to
predict stackoverflow tags  while a f  of around
    indicates that there is still a lot of room for
improvement  our hybrid system clearly outperforms our naive bayes baseline and also the solely
content based or the solely code based systems 
one very nice property of our model is that it requires very little training data compared to classical text classification models and we only need one
model compared to a model for every tag if we did
a one vs all classification for all tags  however 
one major drawback we noted is that we need to
compute a feature vector for each document tag
pair  so given our tag set size of       we have to
compute       feature vectors to make one prediction which turns out to be very slow compared to
one feature vector needed for a classical one vs all
text classification model that uses the same bag ofwords or tf idf feature vector for all       classifications  nevertheless  we only use   features and
a very simple model which at least results in very
fast predictions once we computed all the feature
vectors 
by varying the number of predicted tags as
shown in figure   we also showed that by only
predicting    tags for each question we achieve a
recall of around      considering that one possible
application of our system is providing tag suggestions to a user  this indicates that our model would
be very well suited for that task as choosing between    suggestions seems to be easily accomplishable by users 
compared to the current leaderboard on the
kaggle competition  our results seem to be very

fibad  as other teams seem to achieve f  scores beyond       however  we noted that around     of
the test data are also contained in the training data
so one could easily achieve a mean f  of      by
just looking up the questions in the training data 
as we split the original training data into nonoverlapping train  development and test sets  our
numbers should give a better estimate on how well
such a model actually performs on unseen data 
   

error analysis

given our results  it is clear that there are still errors that remain  we identified the following three
common error categories 
 our system predicts too many too few tags 
this problem is caused by the fact that our
svm tends to predict too many tags and we
use a cut off for the maximum number of tags
that get predicted  as a user can choose between   and   tags and we typically predict
  tags and potential programming languages 
we only get that right in the majority of the
cases  but not if the user specified less or
more tags  an alternative to using a fixed
number would be to predict tags whose decision function value is above a certain threshold  but by examining some examples  there
does not seem to be a threshold that would
give an improvement over predicting a fixed
number of tags 
 predicted tag is contained in the title or body
but is not a real tag to the question 
in some cases we observed that the tag is
contained in the question title or body but
the user did not assign that tag  this error
seems very hard to fix  as generally this feature is a good indicator for a tag document relation  however  it seems that in many cases
the wrongly assigned tag is actually a valid
tag for the document and it is just the case
that the user did not use it  thus it is still a
valid prediction although it does not conform
to the gold standard 
 the detected programming language is not a
real tag 
this error occurs quite frequently  as people
often use more specific tags such as jquery
compared to javascript  however  if we assume that the number of tags is not limited 

then assigning this additional tag should not
harm the user experience as if the used programming language is really javascript  then
this seems to be an appropriate tag 
   

conclusion and outlook

in this paper we described a simple classifier that
has the capability of predicting tags to stackoverflow questions given only the question title and
body  besides engineering more sophisticated features  future work should focus on optimizing the
runtime of our model  as it is currently too slow to
be used in practice  we also assume that incorporating more data to estimate the pmi values  could
further improve recall as it seems that our model
heavily relies on that feature  further  one might
want to investigate whether co occurence statistics
of tags could further improve the model  as there
are a lot of tag pairs such as javascript and jquery
that co occur very often 

references
david klein  kyle murray  and simon weber       
algorithmic programming language identification 
corr  abs           
zhiyuan liu  xinxiong chen  and maosong sun       
a simple word trigger method for social tag suggestion  in proceedings of the conference on empirical methods in natural language processing  pages
          association for computational linguistics 
qiaozhu mei and yi zhang        automatic web
tagging and person tagging using language models 
in advanced data mining and applications  pages
        springer 
sanjay sood  sara owsley  kristian j hammond  and
larry birnbaum        tagassist  automatic tag
suggestion for blog posts  in icwsm 
clayton stanley and michael d byrne        predicting tags for stackoverflow posts  in proceedings of
iccm      

fi