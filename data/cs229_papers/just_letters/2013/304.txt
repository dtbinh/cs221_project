whose book is it anyway 
using machine learning to identify the author of unknown texts
sean stanko  devin lu  irving hsu
computer science department
stanford university  stanford  ca      
 ststanko  devinlu  irvhsu  stanford edu

abstract
in this paper  we present an implementation of a new method for text classification that achieves
significantly faster results than most existing classifiers  we extract features that are
computationally efficient and forgo more computationally expensive ones used by many other text
classifiers  most notably n grams  contiguous sequences of n words   we then analyze the feature
vectors through a hybrid svm technique that sequentially classifies them with a one versus all
classifier and a sequence of binary classifiers  our overall method finishes execution within seconds
on large novels  with accuracy comparable to that of standard classifiers but with a significantly
shorter runtime 

   introduction
identifying the author of a text is a real  and recurring  problem that reappears again and again
across many different fields  archaeologists and historians regularly recover and attempt to identify
unattributed texts  academics are constantly on the lookout for plagiarism  author attribution even
appears in popular culture  as with the cuckoo s calling incident this summer  when the author
robert galbraith was revealed to be a pseudonym for j k  rowling 
naturally  this is a very active  and lucrative  field of machine learning  part of the reason for its
activity is that it is  unsurprisingly  both a difficult and somewhat open ended task  with numerous
approaches and success rates 

    approach
in relation to this field of study  we will create a machine learning system that will attribute a
provided text to one of a series of known authors  more specifically  we will be attempting to do so
with novels  based on existing literature and own personal experience in the field  text analysis
often has less than stellar runtimes      to this effect  we also plan to design our classifier to
complete with a reasonably fast runtime 

 

fito go about this  we plan to use a combination of shallow text analysis and supervised machine
learning  our algorithm will be a two step multiclass svm  which performs a series of one versusall svms on an input and then a second runoff series of binary classifiers on all possible positive
labels from the one versus all  with our inputs potentially having large feature vectors  specifically 
    features each   and the need to run several instances of binary classification  the svm s ability
to efficiently perform classifications via the kernel trick is ideal for this scenario 
we will be parsing our input texts as  txt files  courtesy of project gutenberg  www gutenberg org  
the text analysis  as well as the construction of feature vectors  will be done in python and then
saved to a second  txt file  finally  training and classification using these features will be performed
in matlab 

   text analysis feature extraction
    overview
one of our first  and key  observations we made about our training set of novels is that they are
generally long  and likewise have rich vocabularies and styles  from this  we then made our key
assumption for our training algorithm 
each author has a true  statistically representable style that their works are slight variations on 
with these observations and this assumption in mind  we researched existing literature for leads on
potential methodologies  almost immediately we came across  and chose to pursue the statisticallybased shallow text analysis approach  as opposed to the more semantically based deep text analysis 
     as it is well aligned with our assumption of a statistically based author style and  more
importantly  is significantly less expensive to compute  further research into shallow text analysis
suggested three main approaches 
token based  word level features such as word length and n grams 
vocabulary based  vocabulary richness indicators  such as the number of unique words 
syntactic features  sentence based features  such as parts of speech and punctuation 
each of these feature approaches have their benefits and drawbacks  token level features are easy
but  especially in the case of n grams  contiguous sequences of n words   slow to compute 
vocabulary features are both fast and easy to compute  but can have a high variance and are thus
inaccurate for small texts  approx       words or less   syntactic features share many of their
qualities with vocabulary features  but can be quite complex to compute     

    language model
with our goal of achieving a fast runtime  we decided to take an original approach to our language
model  given the long nature of our sample texts  most books run at least         words in length  
we opted to forgo computationally expensive features  such as n grams  altogether and instead
focused on easily computable features  particularly those pertaining to vocabulary and syntax  just

 

fias the long lengths of our texts make the expensive features unappealing  they also make the
cheaper ones powerful  as mentioned  vocabulary and syntactic features scale in accuracy and
precision with text size 
the legomena and richness rates are standard
vocabulary indicators  and word and sentence
lengths are both standard  easily computed token
and syntactic features      we decided to look at
nominative pronouns and conjunctions as they
both have small word pools  but are still powerful
in determining sentence structure  representing
subject and clause shifts respectively 
our final feature vector design treats each book as
an individual training example and consists of    
features split across the seven categories listed in
table    note that  aside from a check against a
small pool of conjunctions and pronouns  we do
not consider the semantic meaning of any
individual word  we are only concerned with a
words length and uniqueness  this enables us to
achieve a very low runtime in our feature
extractor  of approximately    seconds for   
books     million total words  

table    summary of features used in the language
model  all distributions are represented as counters for
values      and an additional value for     
feature

description

hapax legomena 

number of words that occur
exactly once 

dis legomena 

number of words that occur
exactly twice 

vocabulary
richness 

total number of unique words 

sentence length
distribution 

lengths of sentences in the text 

word length
distribution 

lengths of the words in the text 

pronoun
distribution 

occurrences of nominative
pronouns per sentence 

conjunction
distribution 

occurrences of conjunctions per
sentence 

mark twain sentence distributions

dis legomena

  of total sentences

legomena rates for single genre authors

sentence length

hapax legomena

figure    legomena rates for a subset of our authors  note that 
as in our governing assumptions  the values for various works
appear to be tightly clustered around an average for that author 
 

normalized by number of unique words 
normalized by number of words 
 
normalized by number of sentences 
 

 

figure    sentence distributions for select works by
mark twain 

fi   classification methodology
once the features were extracted  we executed a hybrid multi classification strategy to determine the author
of each test sample  the test classification proceeded in two steps  first  for each author k a one versus all
classifier that could test whether a given example was written by that author was created  each classifier was
created by training an svm on the entire training set with training examples given a positive label if they
were written by author k and a negative label otherwise  a test sample was run through each of these
classifiers  and if exactly one classifier returned a positive result the test sample was assigned the
corresponding author 
if the one versus all classification resulted in zero or more than one positive results  we moved on to a series
of binary classifiers  a binary classifier for authors n and m was created by training an svm on the training
examples of authors n and m for all distinct pairs  n  m   the test sample was then run through each of these
classifiers  if the test sample was attributed to a certain author i against all other authors j  i  then it was
assigned to author i  note that because of the symmetry of binary classification  this procedure can produce
at most one assignment  if neither of these procedures resulted in an assignment for the test sample  then it
was left unattributed 

   results and analysis
we tested our method on two training test sets  a set of longer works  full length novels   which included   
training examples and    test examples from   separate authors  and a set of shorter works  the federalist
papers   which included    training examples and   test examples from   separate authors 
our method resulted in approximately     true positive classification for novels and approximately    
true positive classification for the federalist papers  in general  the multi class step was less likely to
successfully attribute a test sample  but was also less likely to incorrectly attribute a test sample 
our method saw a considerable performance loss with shorter works  as it achieved only     correct
classification out of a universe of three authors  however  with longer works  our method performed quite
well  achieving a     correct classification with a universe of eight authors  this is slightly worse than
typical classifiers that include n gram features  which typically have a test accuracy of approximately    
     however  our method demonstrated a substantial advantage in runtime  we trained and tested all of our
novels in approximately    seconds  and the training and testing for the federalist papers was too fast to
meaningfully measure  this contrasts with runtimes that are on orders of minutes or hours for typical n gram
classifiers used on novels 
shorter works  the federalist papers  

longer works  novels  

     

     

    
    

    

    

    

    

    

    

    

    

     

    

    
    
    

    

    

     

     

    

     

    

     

    

    

    

    

    

   

   

a er mul class 
correctly classied 

a er mul class 

a er binary 

incorrectly classied 

correctly classied 

unclassied 

a er binary 

incorrectly classied 

unclassied 

figure    hybrid multi classification results for both short works  the federalist papers  and long works  novels  
 

fiin general  adding training examples quickly reduced the number of unclassified test examples to zero 
furthermore  adding more training examples tended to decrease our testing error  this suggests that we are
not overfitting our model  in fact  further performance improvements may be attained by including more
training examples 

   conclusion
overall  we are satisfied with the results of our
classifier  while our accuracy is slightly below that
of other attribution systems  it is still well within an
acceptable range and more than makes up for any
shortcomings with its phenomenal runtime 
furthermore  we suspect that  given a few slight
improvements  we can increase our accuracy without
changing the speed or computationally efficient
nature of our algorithm 

correct classica ons as a func on of training examples 
    
    
    

rate 

    
    
    
    
    
    

the most obvious step for further work is to find
  
  
   
   
   
   
   
   
   
   
   
additional training examples  we were constrained
training examples 
by the works that could be found on project
correct classica on 
unclassied 
gutenberg  and as such some authors  such as
tolstoy  had an insufficient number of training texts 
our learning curve suggests that acquiring additional figure    learning curve corresponding to the percentage of
training data will produce positive improvement 
correct classifications as a function of the number of training
examples 

additionally  since there is little evidence of overfitting and our runtimes are very low  expanding the feature
vector could produce gains  our feature extractor is a linear parser  it linearly scans each text for the given
features   so it should be possible to introduce more easily computable features with minimal risk of
introducing overfitting or significantly hindering our runtime 

   acknowledgements
the authors would like to thank professor andrew ng and the cs    course staff for their teaching and
support in this class and on our project  we would also like to thank the developers of the python regex
library and the liblinear svm library for greatly simplifying the process of implementing a sentence
parser and svm  respectively 

   references
    sagae  k  and lavie  a  a classifier based parser with linear run time complexity  language technologies
institute  carnegie mellon unviersity        http   www cs cmu edu  alavie papers iwpt   sagae pdf
    luyckx  k  and daelemans  w          shallow text analysis and machine learning for authorship attribution  in
proceedings of the fifteenth meeting of computational linguistics in the netherlands 
http   citeseerx ist psu edu viewdoc download doi                 rep rep   type pdf
    fan  r  e   chang  k  w   hsieh  c  j   wang  x r   and lin  c  j  liblinear  a library for large linear
classification  journal of machine learning research                     software available at
http   www csie ntu edu tw  cjlin liblinear

 

fi