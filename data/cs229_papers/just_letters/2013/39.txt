classification of fine art oil paintings by semantic category

william kromydas
kromydas stanford edu

abstract
in this paper we explore supervised learning techniques that are able to classify fine art paintings by the
general subject matter of the painting  e g   landscape  people  seascape and still life   classifying art
paintings by semantic category may pose unique challenges because art is subjective and highly interpretive  state of the art feature extraction and encoding techniques used for object and scene recognition in
photographic images are evaluated for their potential use for classifying art paintings  in this work we
evaluate several types of features individually and also in combinations to reveal the benefit of complimentary information  feature ranking techniques are implemented as a means for identifying the most
important features between any two labels in the data set  in order to compute a final ranking of the
most relevant features for all class labels  a metric is proposed using the principal components of the
combined feature vector to prioritize the final ranking of the top k features across all class label pairs 
classification algorithms used for evaluation include a soft margin linear svm and l   regularized logistic regression  experimental results show that several feature classes can be successfully used to classify
art paintings with improved accuracy when multiple features are combined  ranked and prioritized to
form a final feature vector 

 

introduction

classification of art paintings by semantic content has many applications for art historians and museums in support of image
acquisition  managing large digital libraries and follow on applications that would support the varied missions of educators 
there are many ways that paintings can be classified  much of the current research is focused on classifying paintings by
style  genre  or for performing artist identification or authentication  however  the research for classifying paintings by
semantic category is relatively thin compared to the vast amount of work in the field of computer vision for classification of
photographic images  classifying images of paintings may pose unique challenges due to the highly interpretative nature
of art  the wide range and selective use of color  variation in style  soft  loose  edges of forms  texture  center of interest 
and interpretation are examples of how such images might differ from photographic scenes 
scene recognition is a fundamental research area in computer vision and has lead to many new approaches in recent
years  including the use of multiple feature classes  new encoding techniques  and the incorporation of spatial information
 e g   sky on top  ground on the bottom   in this work we evaluate several state of the art feature extraction and encoding
techniques for suitability to classifying images of art paintings  experimental results will show that some features are
complimentary and provide increased performance when combined  due to the large number of feature elements considered there is also a strong tendency toward over fitting which leads to high variance  with this in mind we pursue feature
ranking techniques and also propose a metric for how the final feature vector should be allocated in a multi class problem 
a leading edge diagnostic and visualization capability is also investigated for use with hog features      which provides
insight into why certain images may be misclassified 

 

related work

with respect to research in classifying paintings  the work of a  blessing and k  wen     identified the key features and
classification algorithms that lead to successful artist identification for seven painters from the   th century  hog x 
features were highlighted as the top performer from the    feature sets considered as identified in       more generally 
significant progress in image classification has been made in the last decade  and specifically with respect to feature extraction and encoding algorithms  as described in       large scale scene recognition is accomplished by developing a
weighted sum of svm kernels from    different feature descriptors to obtain a final classification score  hybrid methods
that combine proven feature representations such as hog x  with follow on  bag of words   spatial pyramid  pipelining have demonstrated improved accuracy      improved encoding and advanced frameworks have also emerged        
as described by khosla      as an extension to      the full processing pipeline begins with local feature extraction in a
bag of words manner from various patches of the image  followed by dictionary learning using k means  llc coding is
applied to soft encode each patch to dictionary entries and maximum pooling is then used with spatial pyramids to obtain
the final feature vector  the advantage of llc coding is that it is designed to work with linear classifiers  and has been
shown to outperform non linear models      inspired by the success of these advances we pursue the use of this processing
pipeline for classifying art paintings and seek to determine which factors lead to the most robust performance 
 

fihighly sophisticated diagnostics are also being pursued  as documented in     researchers have developed visual representations of extracted features that are highly illuminating regarding the misclassification of image samples  as a preview of
this capability  code was obtained from     to produce the following images referred to as inverse hog  ihog   which
are much more revealing to researchers versus the standard hog glyph  shown at the far right in figure   for comparison
to the adjacent image   all four of the images below were classified as paintings with people in all testing conducted
during this study  three of the images contain figures  people  and one does not  highlighting the difficultly in resolving
certain labels   the corresponding data samples from the test set are revealed in section   

figure    ihog representation of four test images  hog glyph on far right 

 

approach

   

data collection

the data for this project consists of     images of fine art oil paintings that were selected from over    different artists 
representing a wide swath of individual style ranging from period paintings from the late   th century to current day
representations  the style of the paintings considered is loosely based on impressionism and contains images in four
categories  landscapes  paintings with people  not necessary portraits   seascapes and still life  the minimum image
resolution considered was     x     pixels  however a significant percentage of the data set is well over     x     pixels 
    images were randomly selected for training and the remaining     were reserved for test  the breakdown by category
is shown in table   below 
table    training and testing samples by class

landscape
p eople
seascape
still lif e

   

t raining set

t est set

   
   
  
  
   

  
  
  
  
   

system design and tuning

initial experimentation started with a k nearest neighbor classifier for evaluating individual feature classes and to develop an
appreciation for which images in the test set scored closest to those in the training set  using code provided by khosla      
the remainder of this study used linear svm and logistic regression classifiers  one vs all binary classifier models were
employed using probability output from the model to make the prediction of the class label  the selection of regularization
parameters for both logistic regression and the svm was accomplished using    fold cross validation on the full training
set      samples   initially some experimentation was performed with non linear kernels but there was essentially no
benefit from their use  not a surprising result given the use of llc coding for most features and a relatively small data set  
initial testing of individual features showed that a relatively small dictionary size of    in combination with three pyramid
levels offered the lowest overall test errors  dictionary sizes from    to     were considered with pyramid levels of      and
   this processing pipeline applied to the following features  color names    hog x   hog x   and sift  linear binary
patterns  lbp  also incorporated spatial pyramids    levels  but does not extract features in a bag of words manner and is
therefore not in the processing pipeline above  gist was also considered as a feature class  also not in the pipeline above  
for hog x  and hog x  it was discovered that performance actually improved when used with lower resolution images
 about     improvement in classification performance with     pixel versus     pixel images   the implication  though
not proven   is that higher resolution data for gradients creates opportunity for predicting labels that are unrelated to the
 

using    colors versus    colors as specified in    

 

ficenter of interest in the painting  lower resolution images may offer a smoothing affect to temper otherwise extraneous
information  the use of diagnostics like ihog are likely to be very helpful in studying these affects more closely  based on
these initial findings  all images were resized during feature extraction to be no greater than     pixels in either dimension 
figures   and   below show the test errors for each feature class considered using both linear svm  libsvm v      and
logistic regression  liblinear v      classifiers  there was no appreciable difference between hog x  and hog x  based
on initial testing and therefore only hog x  was considered for the remainder of the study  all the results below were
created using    fold cross validation with feature ranking  as expected  the error rates between these two classifiers are
comparable and therefore only the results for the svm model are presented in the remainder of this paper 
logistic regression    fold cv with feature ranking 
    

    

    

    

    

    

    
test error rate

test error rate

svm    fold cv with feature ranking 
    

    
    
    
    
    
    
    
 

    
    
    

color
gist
hog x 
lbp
sift
  

    
    

   

   

   
   
training set size

   

   

    
 

   

figure    svm test errors
   

    

color
gist
hog x 
lbp
sift
  

   

   

   
   
training set size

   

   

   

figure    logistic regression test errors

feature ranking metric

the method for ranking features starts with a feature ranking function based on two class labels and uses a wilcoxon
statistic as the basis for ranking the most important features as discriminators for the two classes  other statistics were
considered  kullback leibler divergence and t test   but wilcoxon proved to be the most reliable indicator for feature
importance  this ranking process is repeated for each pair of class labels  and in this case results in six ranked lists of
prioritized features for the four class problem  in order to obtain the final feature vector for classification these lists can be
uniformly merged  with duplicate features removed   that is  the reduction in features by some factor is uniformly applied
to each list  the resulting lists are merged  duplicates are removed  and a short iteration ensues to add additional features to
fill the gap left by duplicate removal  when tuning the system a regularization parameter is derived from cross validation
followed by reduction in features to reduce variance to acceptable levels 
the method described above works quite well to reduce system variance in a robust manner  while pruning of features
randomly resulted in an increased test error of about      compared to feature ranking   to further improve upon this
ranking a more effective approach is proposed for merging the ranked lists of features from each class pair  rather than
a uniform ranking applied to each list  a metric is computed by which each list is weighted prior to merging  with higher
weights taking a greater proportion of the features to be allocated in the final feature vector  the approach for developing
the weights starts with the observation that each pair of classes do not necessarily have the same level of separability 
which is highlighted in section    based on this observation  the following metric is proposed as a means for computing
weights for each ranked list  for the training data  the principal components of the full feature vector are computed  the
mean and variance for each class label is then computed as shown below  up to some number of principal components 
np   the corresponding metric is then used as a weighting component for each class pair to determine the percentage of
features that should be allocated to the final feature vector from that class pairs ranked list  more formally  in the equations
below  k represents
class pair

  a class and l represents a unique

   with p and q indicating class indices   for a training set
x            x m    x i    n   with class labels y             y  m    and principal components of the combined feature vector
p c  i    np   the weights w l           for each class pair are computed as follows 
 
pm   i 
  k p c  i 
i     y
 
pm   i 
k  
 k
i     y

k 

pm
 

i  

 

 
  y  i    k k  p c  i  
 
pm   i 
 k
i     y
 

   

   

fi 

r l p  q  

kp  q k
p    q 

pl

j  

w l   

   

r j 

   

r l 

the weights have the intuitive interpretation for giving the most weight to class label pairs that have close cluster centers
and large variance  for the training data  the principal components of the full feature vector are computed and the weights
are calculated using the equations above  up to some number of principal components   in this study  the first    pcs were
used but testing indicated that as few   or    may be adequate for the purpose of this metric 

 

analysis and results

after initial evaluation of individual features was conducted  combining features was pursued to understand which pairs
might represent complimentary information  this was also an opportunity to test feature ranking and prioritization under
more challenging conditions  for a dictionary size of    and three pyramid levels  color  hog x   and sift all contain
     elements in the final feature vector  without pruning   lbp and gist have a lower amount       and     respectively   combining features through simple concatenation to form a combined feature vector results in even more features 
highlighting the need to perform feature ranking and pruning  table   below shows the test errors for several pairs of
feature vectors  these test errors are reported for the full test set      samples   based on    fold cross validation of each
model using     training samples  the added benefit from applying the prioritized weighting scheme described in section
  is also reported which shows an average reduction in test error of       the number of features in the final ranked feature vector for the cases in table   ranged from     to       elements  a significant reduction from the original combined
vectors  
table    feature ranking weighting comparison  test errors 

lbp   hog x 
lbp   color
lbp   sif t
lbp   gist
sif t   color
sif t   hog x 
hog x    color
sif t   gist

u nif orm

p rioritized

benef it

     
     
     
     
     
     
     
     

     
     
     
     
     
     
     
     

    
    
    
    
    
    
    
    

after additional testing with more than two features it was determined that combining lbp   hog x    color yielded the
best overall performance as reported in table   below  achieving just over     classification accuracy across the entire test
set  the ten mis classified samples are highlighted in red in the confusion matrix  table   also shows the corresponding
weights that were used for each class pair in computing the final feature vector with the highest weight        corresponding
to the class label pair  still life   people   combining all three features offers additional capability in a region that had proved
difficult for any two features alone  the number of features used in this case was        an     reduction from the original
feature vectors from all three feature classes   it is interesting to note that color alone has poor accuracy as shown in
figures   and    section       but when combined with either lbp or hog x  as shown in table   above  value is added 
this combination of features incorporates texture  lbp   gradients  and color which are also intuitively complimentary 
table    confusion matrix and weights  lbp   hog x    color     fold cv with feature ranking 

ls
landscape
p eople
seascape
stilllif e

  
 
 
 

count
p p ss
 
  
 
 

 
 
  
 

sl

ls

 
 
 
  

     
     
    
    

p ercentage
pp
ss
    
     
   
    

    
    
     
    

sl

ls

    
    
    
     

    
    
    

w eights
pp
ss
    
    

    

sl
 

the corresponding pca plots for this final case are shown in figures   and   below  figure   shows the principal components of the full  combined  feature vector from     training samples  and figure   shows the same plot for the top
ranked       features from the test set  the correlation between the pca plots and the confusion matrix in table   is clear 
seascapes are never confused with people or still life  while still life and people are the most difficult labels to resolve 
 

fithe pca plots provide a convenient backdrop to help visualize class separability  even if only in   dimensions   figure  
shows the learning curves for this final test case which shows a significant reduction in test error compared to the single
features in figures   and    finally  in figure   we see the actual art images that correspond to the ihog images presented
in section    this figure highlights the difficulty in resolving paintings with people versus still life  the still life in the
 nd panel has elements that resemble people and was never correctly classified as a still life in any testing performed 
understanding misclassifications is an important research topic and this new capability     offers a glimpse at the leading
edge work in this area  recommendations for future work include in depth investigation into why samples are misclassified
and how that may be impacted by feature selection  more specifically  a better understanding is sought for the extent to
which misclassified labels are predicted based on ancillary elements in the painting versus the center of interest and how
the center of interest can be represented through features for more robust classification 
 

 
landscape
people
seascape
stilllife

   

   

   

   

   

   

 

 

   

   

   

   

   

   

   

   

 
 

   

   

   

   

 
pc 

   

   

   

   

landscape
people
seascape
stilllife

   

pc 

pc 

   

 
 

 

figure    pca of training samples

   

   

   

   

 
pc 

   

   

   

   

 

figure    pca of test samples after ranking

test and train error rates  svm  lbp   hog x    color 
    
test
train

    
    

test error rate

    
    
    
    
    
    
    
    
 

  

   

   

   
   
training set size

   

   

   

figure    learning curves

figure    ihog images with paired samples

references
    a  blessing  k  wen  using machine learning for identification of art paintings  cs    final project       
    k  chatfield  v  lempitsky  a  vedaldi  and a  zisserman  the devil is in the details  and evaluation of recent feature encoding
methods  british machine vision conference      
    n  dalal and b  triggs  histograms of oriented gradients for human detection  cvpr      
    a  khosla  j  xiao  a  torralba  a  oliva  memorability of image regions  nips       
    s  lazebnik  c  schmid  and j  ponce  beyond bags of features  spatial pyramid matching for recognizing natural scene categories 
in cvpr  volume    pages            ieee       
    t  ojala  m  pietikainen  and t  maenpaa  multiresolution gray scale and rotation invariant texture classification with local
binary patterns  pami       
    c  vondrick  a  khosla  t  malisiewiecz  and a  torralba  hoggles  visualizing object detection features  iccv       
    j  van de weijer  c  schmid  and j  verbeek  learning color names from real world images  cvpr       
    j  wang  j  yang  k  yu  f  lv  t  huang  and y  gong  locality constrained linear coding for image classification  cvpr       
     j  xiao  j  hays  k  ehinger  a  oliva  and a  torralba  sun database  large scale scene recognition from abbey to zoo  cvpr 
     

 

fi