learning to play like an othello master
cs     project report
shir aharon  amanda chang  kent koyanagi
december         

fics     project report

 

shir aharon  amanda chang  kent koyanagi

abstract

this project aims to train a machine to strategically play the game of othello using machine learning  prior
to each match  the machine is trained with data sets obtained from professional matches  during each turn 
the machine is given a list of its legal moves and selects the one that most closely reflects a move made by
an othello master 

 

introduction

the game of othello is a popular  two player strategy board game in which players take turns placing their
pieces on an   by   board  the game pieces are colored white on one side and black on the other  and each
player is assigned one of the two colors  if a newly placed disk bounds the opponents disks in a straight
line  the bounded pieces are to be flipped  adding to the players piece count  the game ends when all of the
positions of the board are all occupied  and the player with the higher piece count is the winner 
since the   by   version of the game has yet to be solved mathematically  othello has been a topic of
interest in the field of artificial intelligence  typical othello ais use static evaluation functions to assign
scores to different board configurations  which include properties such as the number of pieces each player
owns or the positions of every piece on the board  these properties can be used as features in machine
learning algorithms  which enables the machine to learn the combination of features that allows it to win
with a higher probability 

 

background

due to the games complex nature  it is difficult to create an othello ai that is both fast and powerful 
in general  othello ais strive to maximize a board score function while minimizing the number of possible
moves the opponent can make  the reason is that a high score generated by a good score function correlates
with a winning board position  and limiting the number of moves for the opponent forces them to make a
bad move  common implementation approaches that achieve this goal include a combination of alpha beta
pruning  minimax  and opening book strategies 
it is also possible to create a powerful othello ai using machine learning  rather than hard coding
features such as the board score  this approach allows the ai to recognize and make winning moves based
on the data with which it was trained 

 

training set

the data set is taken from the world othello federations archive of championship matches for the years
           which provides a total of      moves made by othello masters     games that each contains   
moves   in the training set  these moves are considered as the correct moves while the available moves that
were not chosen by the masters are considered as the incorrect moves  since on average  there are     
possible moves per turn  this creates a training set of over       examples  from these examples  duplicate
feature sets  i e  situations that are identical under the current feature set have only one copy kept  marked
as correct if any were correct   additionally  as othello has four rotational symmetries  each feature is
repeated under each rotation  this is done to minimize the noise in the training set and to eliminate the
favoring of any specific rotation 
using this data set  two subsets are prepared  the first is the full set of data that contains the moves
from all games  and the second is a reduced set that only contains the moves from one game      examples
before duplicates and symmetry   the smaller set was useful in initial debugging and testing  but also shows
how little data is necessary to learn well by some learning models 

 

fics     project report

 

shir aharon  amanda chang  kent koyanagi

methods

the following five feature sets are used to train machines using the algorithms discussed in     

   
     

feature sets
feature set    

the first feature set contains several simple properties of a players turn  the turn number  the number of
white pieces on the board  the number of black pieces on the board  the number of empty positions  the
simple board score  and the complex board score  the number of white and black pieces are included because
even though the greedy strategy is ineffective in othello  these properties give a sense of which player is in
the lead  the turn number is included because the playing strategy changes depending on the phase of
the match  in general  an othello match can be decomposed into three phases   early  middle  and late 
the simple score is calculated using a board weighting that follows basic othello strategies  similarly  the
complex score is calculated by accounting for special scenarios involving the boards corners and edges  note
that scores are always calculated relative to the current player  i e  higher is supposedly better  
     

feature set    

this feature set is identical to the first feature set  but rather than tracking the number of white and black
pieces  it tracks the number of the players pieces and the opponents pieces  these board properties are
more useful because the ai could play either color 
     

feature set    

this feature set includes all features in the second feature set  along with a feature that tracks the state of
all    positions on the board  by accounting for the state of every board position  this feature set aims to
allow the ai to learn the special situations on its own 
     

feature set    

the fourth set of features is equivalent to the second feature set  but has the complex score split into
multiple components for each special condition location pair  it also adds the number of possible moves for
the opponent 
     

feature set    

feature set    contains the simple score  the multiple components of the complex score  and the number of
valid moves  these are reasonable properties to use because they are the same properties used to implement
basic  hardcoded othello ais  such as the one matched against the machine learning ais  

   

algorithms

the feature sets described above are used to train the machine using four learning algorithms  naive bayes 
decision tree  support vector machine  svm   and linear regression 
     

naive bayes

the advantage of naive bayes is that it is simple to implement and does not require a large data set for
training  in addition  its results are insensitive to irrelevant features  allowing for an iterative approach to
find an effective feature set  the downside is that it assumes independence of features and that the margin
of error is larger than that of more complex methods 

 

fics     project report
     

shir aharon  amanda chang  kent koyanagi

decision tree

the decision tree algorithm is robust  performing well even when the model does not follow the assumptions
made by the algorithm 
     

svm

svm is well suited for modeling complex data sets that contain many attributes  its disadvantage  however 
is that training is significantly slower than the other algorithms  since the runtime is prohibitive for large
data sets  it did not use the full data set for feature sets   and   
     

linear regression

conceptually  linear regression mimics the linear combination of individual scores that most hardcoded ais
use  it is both simple and the most intuitive of the considered algorithms 
     

linear regression with lookahead

this is the only algorithm that uses techniques from both machine learning and traditional othello ais  it
uses both linear regression and a three step lookahead to select a move out from the list of possible moves 

 

results

figure   and figure   show the total training errors  which are calculated using the k fold cross validation
algorithm with k      

total error for one game training set
    
   

    
   
    
 
linear regression

nave bayes

feature set  

feature set  

svm
feature set  

decision tree
feature set  

zero
feature set  

total error for all games
training set
    
   
    
   
    
 
linear regression

nave bayes

feature set  

feature set  

svm

feature set  

 

decision tree

feature set  

zero

feature set  

fics     project report

shir aharon  amanda chang  kent koyanagi

once the machine is trained on all combinations of learning algorithms  feature sets  and training set
sizes  the effectiveness of each training is measured by matching the machine against three types of othello
ais  the random ai randomly selects a valid move  while the simple and complex ais select the valid move
that generates the highest score using the corresponding weighting function  note that due to imperfect
weights  the simple ai is generally better than the complex ai   this is illustrated by figures   and   below 
winning percentage for one game training set against various ais
 
   
   
   
   
   
   
   

   
   
 
simple ai complex ai random ai simple ai complex ai random ai simple ai complex ai random ai simple ai complex ai random ai simple ai complex ai random ai
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   

linear regression

nave bayes

svm

decision tree

lr look ahead

winning percentage for all games training set against various ais
 
   
   
   
   
   
   
   
   

   
 
simple ai complex ai random ai simple ai complex ai random ai simple ai complex ai random ai simple ai complex ai random ai simple ai complex ai random ai
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
 set   
linear regression
nave bayes
svm
decision tree
lr look ahead

 

analysis

overall  all of the machine learning algorithms for all three feature sets have success rates greater than    
against the random ai  however  the learning algorithms do not perform well against the simple ai  on
the other hand  against the complex ai  the results seem to vary depending on the selected feature set  note
that due to suboptimal configuration  the simple ai actually performs better than the complex ai  contrary
to expectations  
the machine that uses the decision tree algorithm learns almost perfectly as its errors are   for both
training set sizes  to   digits   however  based on its poor performance against the hardcoded ais  it appears that the algorithm suffers from overfitting  the machine trained using svm also seems to suffer from
overfitting  and is slow to training on larger feature sets 
even though the naive bayes machine generally performs decently well against the hardcoded ais  its
errors are larger than those of the constant zero prediction  indicating that othello does not follow the
assumptions made by the model  compared to naive bayes  linear regression has lower errors  but has

 

fics     project report

shir aharon  amanda chang  kent koyanagi

the best performance of all of the algorithms  the inherent underfitting in linear regression prevents the
machine from selecting a move that is specific to the situations that the othello masters have encountered 
but rather one that better reflects an optimal move 
overall  regardless of the algorithm  the ais that learned from moves made by the masters did not perform
well against the hardcoded ais  one approach to improve performance is to select a more appropriate feature
set  of the prepared feature sets  feature set    has the highest performance  this is most likely the result
of including just enough features without introducing noise from the states of all board positions  however 
even with feature set     the trained machine does not consistently win against the hardcoded ais 
another approach is to add more correct moves to the data set  by doing so  the training set encompasses a wider range of othello game positions and the noise in learning specific situations is lessened 
from an entropy point of view  each correct move has some information on ideal game play independent
of the specific case  and lessens the incorrect moves that are good but less optimal this is challenging
because the size of the data set is limited and it is non trivial to otherwise evaluate the moves given a large
enough training set  feature set     which includes all board positions  should have allowed learning the
game structure and resulted in an excellent ai  but was impractical 
the third approach is to vary the model depending on the phase of the game  early  middle  or late   as
gameplay strategy differs significantly between the three phases  feature sets      had the turn number as
a feature  but this method forces the way in which the machine learning algorithm utilizes the turn number 
it also limits applying learning from one phase to another  i e  a high board score is likely to be good in all
phases  
overall  the above results may suggest that effective ais cannot be implemented solely by mimicking
moves made by the masters  on the other hand  combining methods from both machine learning and traditional othello ais may create powerful othello ais  in fact  the machine trained using linear regression
with lookahead on feature set    has a      winning rate against all three hardcoded ais  it is also interesting to note that even after training on only one games worth of data for feature set     and to a lesser
extent      linear regression plays incredibly well as indicated by its win rate against the random ai  this
indicates that training on additional games adds very little useful information 

 

future work

future work will primarily focus on improving the performance of the pure machine learning algorithms  as
mentioned in    this will be done by adding relevant features to the feature set while removing extraneous
ones  by adding more correct moves to the training samples  and by varying the model depending on the
phase of the game  ideally  these improvements will allow the trained machine to consistently win against
the hardcoded ais while maintaining low error and bias 
additionally  the effectiveness of combining machine learning with traditional ai techniques will also be
explored  for example  the linear regression with lookahead can be improved by incorporating alpha beta
pruning for deeper lookahead  the machine learning component can be used to tune the parameters in
evaluating board positions  but an accurate board evaluation as a single step ai will still be extremely
complicated 

 

fi