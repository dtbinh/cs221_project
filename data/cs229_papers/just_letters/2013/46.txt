classification of hand written numeric digits
nyssa aragon  william lane  fan zhang
december         

 

objective

the specific hand written recognition application that this project is emphasizing is reading numeric
digits written on a tablet or mobile device  we were interested in two goals  first of all  we wanted to
build a model that can classify a hand written digit on a tablet with high accuracy  second of all  we
were interested in how training on a specific set of users will improve the predictions of digits written
by those users 

 

data

the primary dataset used is the pen based recognition of handwritten digits data set from the uci
machine learning repository      this dataset is produced by collecting roughly     digit samples
each from    writers  written on a pressure sensitive tablet that sent the location of the pen at fixed time
intervals of     milliseconds      each digit is written inside a     x     pixel box  and then was scaled
to an integer value between   and     to create consistent scaling between each observation  spatial
resampling is used to obtain   regularly spaced points on an arc trajectory 
the data can be visualized by plotting the   sampled points based on their  x  y  coordinates  along with
lines from point to point  because the tablet sensed the location of the pen throughout time  the order
of the points gives the direction that the pen was moving 
the data set contains the x and y coordinates of each of the   points  for a total of    integer variables
ranging from   to      there are      test data points and      training data points 
table    number of digits used

training
test

 
   
   

 
   
   

 
   
   

 
   
   

 
   
   

 
   
   

 
   
   

 
   
   

 
   
   

 
   
   

total
    
    

the training set consists of samples written by    writers and the testing set consists of samples written
by    writers  the models were evaluated based on the performance on the testing dataset after being
trained on the training dataset  we also explore the difference between errors when the training and
 

fi a  sample points w  ordered line segments    

 b  sample points w  ordered line segments    

figure  
testing sets are sourced from separate writers and when the training and testing sets have some writers
in common 

 

model

after using various supervised learning techniques  the optimized error for each approach is shown in
the table 
table    error rates over diverse classifiers

test error

svm
      

knn
      

random forest
      

softmax
    

k means
    

the support vector machine and k nearest neighbor models perform the best  the data  which consists of    x  y  coordinates is perhaps not surprisingly most responsive to euclidean distance based
classifiers 
the svm model is implemented using the e     package in r      the one against one approach
is used to extend binary classifying svms to multiclass predictors  meaning a series of svms for each
pair group of the digits are created  the class probabilities for each test observation are computed using
quadratic optimization  the digit with the highest probability is chosen as the prediction  following
the idea that a prediction made with low probability may be a weaker prediction  the data is separated
into two groups  one group has a predicted digit with probability above the threshold of        another

 

fiwith a predicted digit with a probability under the threshold 
table    error rates grouped by probability threshold

svm pr        
svm pr       

   

svm test error
      
      

knn test error
      
      

primary model

the main model capitalizes on this relationship  predictions based on the svm model is used where
the probability of the prediction is above the threshold  while predictions based on the knn model is
used where the probability of the svm prediction is below the threshold  the value of the threshold and
the cost parameter for the svm regularization is chosen based on which values give the lowest error 
with the threshold at       and the cost parameter at      
the model combining svm and knn models gives a final test error rate of         error rates in range
of       are considered competitive for this dataset     

   

sampling from the whole dataset

the previous models were evaluated based on the error classifying the test set of    writers  after being
trained on the training set of    independent writers  because an individual may exhibit unique patterns
when writing a digit  it is supposed that the correlation between two samples of a specific digit written
by one individual is higher than the correlation between two samples of a specific digit written by two
separate individuals  one of our motivations was to learn how much continuous learning on a tablet
would improve the predictions  in order to gain insight into this problem  we remove samples from
the test data and augment them into the training set  then find the error on classifying the remaining
test data  in order to train on a representative sample of the test writers digits  we randomly selected
a portion of the test data to migrate to the training set  increasing this proportion by    each time
until we are training on half of the test data and predicting on the other half  this simulates a situation
where specific users gradually feed the learning system a number of their own inputs with the correct
labels  the results show that as the model receives more and more input from the set of test users  the
model performs better and better with a minimum error rate of just under     on the whole  svm still
outperforms knn 
additionally  we compared the error based on training and testing data come from separate sources to
the error based on a   fold cross validation  using the primary model found in section    the error is
found using a   fold cross validation where the three sets are randomly sampled from the combined test
and training datasets  a   fold cross validation gives test and training sets of approximately the same
size as the original sets  when the training and testing sets do not come from separate writing sources 
the error reduces from       to       

 

fifigure    error  percent misclassified  by test users input

 

fiusing the same model that produced the optimal error of the isolated test dataset  the cross validation
error is         when the training and testing sets do not come from separate writing sources  the error
reduces from       to       

 

conclusion

the supervised learning techniques that performed best with this data were support vector machines
and k nearest neighbor  our final model was one that used svm predictions when the svm was
confident and knn predictions when the svm was less confident  the models performed better when
it was trained on samples from the same writers who wrote the test samples  indicating that a model
that continues to learn to a specific tablet user will better predict that users writing 

references
    bache 
k    lichman 
m          uci
machine learning repository
 http   archive ics uci edu ml   irvine  ca  university of california  school of information
and computer science 
    i  s  dhillon  d  s  modha  and w  s  spangler  class visualization of high dimensional data
with applications  august       pg     
    david meyer  evgenia dimitriadou  kurt hornik  andreas weingessel and friedrich leisch
        e      misc functions of the department of statistics  e       tu wien  r package
version        http   cran r project org package e    
    venables  w  n    ripley  b  d         modern applied statistics with s  fourth edition 
springer  new york  isbn              
    keysers et al  deformation models for image recognition  ieee transactions on pattern analysis and machine intelligence  vol      no     august       pg       

 

fi