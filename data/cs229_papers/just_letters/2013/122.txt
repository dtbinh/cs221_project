deep learning for depth learning
cs     course project       fall

enhao gong  electrical engineering  stanford
hang qu  electrical engineering  stanford
song han  electrical engineering  stanford

abstract
extracting  d depth information from images is
a classic problem of computer vision  traditionally image depth could be extracted by techniques such as stereo camera or images from
multiple views  in this project  we are trying to
recognize the depth information by using a single
still image from single camera  which has great
potential applications in vision and recognition 
to learn the complex relationship between single rgb image with its depth information  we
chose to use deep learning algorithms  to learn
the multiple level features and corresponding different levels of abstraction  the main goal of the
project is to train a deep network that is able to
extract local and non local features and predict a
depth map given a still image  in addition  implementation of other learning algorithm  kernel
based  dictionary learning  was also conducted
for comparison 

   introduction
     depth information
extracting depth information from  d images is a basic
topic in computer vision  traditional methods can work on
binocular vision given by stereopsis cameras  scharstein  
szeliski         or uses multiple images taken for the similar scenario  stereopsis camera can take two images for
the same scene and the relative camera attitude of the two
images is fixed and known  this further simplifies the algorithm because it is possible to match the feature points
between the two images  multiple images with closed relationship can also help with extracting depth information 
such images might come from motion  ponce et al        
or from defocusing  das   ahuja         the tightly cou 

cs     project final report

enhaog   stanford   edu
quhang   stanford   edu
songhan   stanford   edu

pled images offer rich information to reconstruct depth information  however estimating depth from a single monocular image is still difficult  because only limited information is contained in a single image 
     potential applications
there are a lot applications possible based on this projects 
our main task is similar to  saxena et al          in addition  the depth information can also be widely used for
category and instance level recognition to get much better
accuracy  possible application can be done using depth information with deep network  besides  the  d information
of the depth is also necessary for multi view synthesizing 
to tackle depth estimation in a single monocular image 
existing successful methods fall in two groups  first  by
putting constrain on the reconstruction environment  an algorithm can get prior knowledge about the scene  and thus
achieves reasonable performance  such prior knowledge
includes the distance of an outstanding object  michels
et al          the shape and texture of outstanding objects
in the environment  nagai et al          background color
and texture  etc  gini   marchi         the algorithms
are mostly designed based on the given constrain  and construct depth information based on it  with prior knowledge
of outstanding objects  an algorithm can identify the objects and simplify the depth estimation  with background
color and texture  an algorithm can easily distinguish between objects and background and thus make better estimation  second  some algorithms make no assumption about
the environment  and thus work on unconstrained environment  this is a more realistic assumption but introduces
more challenges  for example   saxena et al         uses
markov random fields to capture the global structure of
the image that depth information is continuous  and gets
good results without prior knowledge of the image itself 
     brief reviews of deep learning and related learning
algorithms
in the class  we learnt about basic neural network algorithm  but in deep learning  one would usually build neu 

figong qu han  deep learning for depth learning  cs     project report

   methods
     data and pre processing
in the project  we were using the washington rgb d object dataset and the nyu depth dataset  silberman   fergus         for washington dataset  they are mainly intended to be used for object recognition  the rgb d
kernel descriptors and hierarchical matching pursuit were
proposed by the group to achieve state of art feature extraction for recognition  which can be used directly with linear
svm  the nyu dataset  are mainly for indoor segmentation  there are two set of data and toolbox is available for
extracting raw data and visualization  for nyu dataset 
  http   cs nyu edu  silberman     we loaded
the labeled dataset and undersampled the image frames to
reduce the size of data used  the      images and depths
maps were resampled from    x    to    x    which
does not terribly affect the quality of the image based on
visualization 

figure    review of previous algorithm 

ral networks with other architectures  including neural network with multiple hidden layers  given increasing computation power  training such a complicated model is no
longer unfeasible  introducing a multi layer neural network
can certainly increase the expressiveness of the model  but
might increase kl dimension of the hypothesis set and
more likely to cause overfitting  so sparse autoencoder
 lee et al         is introduced to solve the problem  an
autoencoder neural network is an unsupervised learning algorithm that applies back propagation  setting the target
values to be equal to the inputs  it is used for learning efficient feature coding  that is  to learn an effective feature for
a set of data  it is quite similar to pca for dimensionality
reduction  and the autoencoder neural network has to satisfy the requirement that the number of hidden units should
be small  but even when the number of hidden units is
large  we can still discover interesting structure  by imposing sparsity constraints on the hidden units of the network 

figure    samples of the rgb image  the raw depth image  and
the class labels from the dataset 

     implementation of previous algorithm for
comparison

     feature extraction reviews
to solve this problem  feature extraction using convolution
is a good method of achieving this  natural images have
the property of being stationary  meaning that the statistics
of one part of the image are the same as any other part  this
suggests that the features that we learn at one part of the image can also be applied to other parts of the image  and we
can use the same features at all locations  more precisely 
having learned features over small  say  x   patches sampled randomly from the larger image  we can then apply
this learned small feature detector anywhere in the image 
specifically  we can take the learned  x  features and convolve them with the larger image  thus obtaining a different
feature activation value at each location in the image 

 

ashutosh et al   saxena et al         used discriminativelytrained markov random field  mrf  and designed feature
convolutors that incorporates multi scale local  and globalimage features  and models both depths at individual points
as well as the relation between depths at different points 
we implemented similar idea for feature extraction  the
features chosen to capture the local cues are texture variations  texture gradients  and haze  images are also transformed to ycbcr color space to get a robust representation
of the intensity which is more robust for texture feature extraction  the total features number is      including   
convolutors    resolution scales    neighbour patches and  
vertical patches  we used support vector based regression
as a model to fit the depth information from the extracted

figong qu han  deep learning for depth learning  cs     project report

features  to train a model with support vector based regression  we randomly sampled the train image  processed
the feature convolutor and constructed train data matrix 
after training the model  it was applied on each pixel in the
testing images  the depth map is computed and smoothed
to get the results  different from the referenced paper  we
also implemented pca to reduce the dimension of the features  the results shows that actually there are great redundancies in features and we reduced the dimension from    
to      covering    percent of energy  

figure    illustration of two patch sampled in images to generate
larger dataset and change the problem to   simpler learning problems 

algorithm   train deep network with patch based resampling and sae
input  image data i  size m  n  depth groundtruth d 
size m  n
 size m   n   
re sample  patch image i 
patched depth d  size m   n    m    m  n    n
whitening using pca zca
train 
un supervised train wsae  
supervised train wouput  
initialize wn n   wsae  
supervised train wentire    wn n   woutput   
output  deep network weights wentire

figure    method related figures from saxena nips       feature
convolutor  multi scale feature setting  pca results  from left to
right  

     building deep network
       r e   generate larger dataset
the nyu labeled dataset we were using contains      labeled rgb d images  however  the samples are far from
enough to train a complex deep network mapping    x   
image to its corresponding depths map  to solve this problem  we proposed several possibilities 
first  the solution we will show in this manuscript is to
modified the learning target and to use patch based resampling to create larger dataset  in order to learn a global
high resolution depth map  we re designed the learning target to    to learn a low resolution global averaged depth
map     to learn a high resolution local relative  mean extraction  depth map  both of these two problem will require
smaller input and output data size  in addition  for the modified learning target  we can use sampling local and global
patches       patches per image  and adding noises to significantly improve the available labeled data 
second  as inspired by wei song who was also working
on similar topic  we can map the output depth map to
its sparse representation using dictionary learning  with
ksvd algorithm etc   which can also greatly decrease the
output data size and the difficulty of the learning problem 
in this manuscript  we chose the first approach  and
achieved      times more samples  the   x   local
patches were sampled from    x    images  while   x  
global patches were sampled from    x    images and
then down sampled to   x   by taking the average  then
we used pca zca whitening to remove the redundancy 

       c reate sparse coding deep network
we have tried  stacked auto encoder sae   lee et al  
      and convolutional neural network  cnn   lee
et al         and deep brief network initialized multilayer
neural network  taking sae initialization as an exampled 
we trained the sae    layer with     node  to learn relative and averaged depth information from local and global
patches respectively  the output layer used logistic regression and the groundtruth was re mapped to       before
training  the stacked auto encoders were trained in succession with self taught pre learning on each layers and supervised training was for the regression output layer  then
the stacked auto encoder was used to initialize the deep
network and we than use supervised fine tune on the entire
network 
       r econstruct depth   map from learned
patches

 

from learned patches  the full scaled global depth map
can be reconstructed by fusing the results of local relative

figong qu han  deep learning for depth learning  cs     project report
table    depth map recovery accuracy using conventional  kernel
based  algorithm and deep network based algorithm 

table    parameter of different deep network architectures used 

a rchitecture

h idden l ayers

d etail parameters

a lgorithm

 
 
 

        
  c   p    c   p
        

k ernel based
cnn
sae nn
dbn nn
dbn nn dl

sae nn
cnn
dbn nn

algorithm   dictionary learning based performance enhancement
input  rgb image sample srgb  
corresponding depth samples sdepth
learn dictionary  joint dictionary djoint
djoint    drgb ddepth     argminksrgb 
drgb xk     ksdepth  ddepth xk     kxk 
estimate sparse representation coefficient from estimation 
x   argminkirgb  drgb xk     kidepth 
ddepth xk     kxk 
output  enhanced estimation of depthmap with weighting
idepth         idepth   ddepth x

rmse t rain

rmse t est

    
     
    
    
    

     
     
     
     
     

based algorithm  the final depth map for the deep network
based algorithm was synthesized from two part of the learning result for local relative depth map and global averaged
depth map shown in figure   

depth map and global averaged depth map  for the testing 
patches are sampled with overlap and the final depth map
was generated by taking the mean of the summation of averaged depth and relative depths 

figure    result comparison

       p erformance improvement using
     performance analysis

dictionary learning

dictionary learning was proposed and applied widely in
computer vision problems such as super resolution  here
in this project  dictionary learning can be used to reduce the
output dimension by train the network to learn the sparse
representation coefficients of depth map dictionary instead
of the absolute depths map  in addition  we were also trying to use  pair based  dictionary learning to improve the
sparse encoding dictionary  coates   ng        to improve
the reconstructed depth map 

here we compared the performance of algorithms using
different algorithms  including using conventional kernel
based algorithm  deep network  cnn  sae initialized nn 
etc    the criteria of root mean square error was used
and shown in   the rmse using deep network based algorithm has advantages compared with traditional kernel
based algorithm 

       p latform

we realized traditional and deep network based algorithms
to decode  d information from still  d images 
in order to overcome the problem of data limitation  we redeisgned the learning target into two separate problems  to
learn global averaged absolute depth and to learn local relative depth  given these learning targets  we designed patch
sampling strategy to greatly improve the labeled data size
and improve the performance  the performance of recovering high resolution depth map can be further improved
by using convolution  pooling and dictionary learning 
also we took a look at the weight learned and from the

   discussion

our current platforms are mainly matlab and python  while
we are also start using gpu to accelerate the training larger
networks with parallel computing 

   results
     result comparison
figure   provide an example of the learning algorithm output for the kernel based algorithm and the deep network

 

figong qu han  deep learning for depth learning  cs     project report

tization  in proceedings of the   th international conference on machine learning  icml      pp         
     

results shown in figure    we thought the learned features
contained both local and non local information that contributes to the reconstruction of depth map 

das  subhodev and ahuja  narendra  performance analysis
of stereo  vergence  and focus as depth cues for active
vision  pattern analysis and machine intelligence  ieee
transactions on                        
gini  giuseppina c and marchi  alberto  indoor robot navigation with single camera vision  in pris  pp       
     
lee  honglak  ekanadham  chaitanya  and ng  andrew 
sparse deep belief net model for visual area v   in
advances in neural information processing systems  pp 
             
lee  honglak  grosse  roger  ranganath  rajesh  and ng 
andrew y  convolutional deep belief networks for scalable unsupervised learning of hierarchical representations  in proceedings of the   th annual international
conference on machine learning  pp          acm 
     

figure    visualize the weight in network

michels  jeff  saxena  ashutosh  and ng  andrew y  high
speed obstacle avoidance using monocular vision and reinforcement learning  in proceedings of the   nd international conference on machine learning  pp         
acm       

in addition  we are starting but not finished the work using gpu to train larger network  high performance and
parallel computation is necessary for higher dimensional
input and larger dataset  current result on small scale network has proved the concept  moreover  it has advantages
in training efficiency  minutes v s  days   more suitable
for tuning the algorithm parameter and architectures  and
is able to do on line training 

nagai  takaaki  naruse  takumi  ikehara  masaaki  and
kurematsu  akira  hmm based surface reconstruction
from single images  in image processing        proceedings       international conference on  volume   
pp  ii     ieee       

   conclusion
we realized traditional and deep network based algorithms
to decode  d information from still  d images  results
show the advantages of deep network based algorithm  undergoing work using high performance computation and
larger dataset potentially will result in better performance 
this project has great this project has potential application
in  d vision  tracking and recognition  which we would
like to keep exploring 

ponce  jean  forsyth  david  willow  equipe projet 
antipolis mediterranee  sophia  dactivite raweb  rapports  inria  logo  and alumni  inria  computer vision 
a modern approach  computer              

acknowledgments

scharstein  daniel and szeliski  richard  a taxonomy and
evaluation of dense two frame stereo correspondence algorithms  international journal of computer vision    
                

saxena  ashutosh  chung  sung h  and ng  andrew 
learning depth from single monocular images  in advances in neural information processing systems  pp 
               

thanks a lot for the instruction from professor andrew ng 
the ideas and guidance from brody huval and other tas 
as well as the discussion with wei song who was working
on the similar project topic 

silberman  n  and fergus  r  indoor scene segmentation
using a structured light sensor  in proceedings of the international conference on computer vision   workshop
on  d representation and recognition       

references
coates  adam and ng  andrew  the importance of encoding versus training with sparse coding and vector quan 

 

fi