deep learning benchmarks
mumtaz vauhkonen  quaizar vohra  saurabh madaan
in collaboration with adam coates

abstract  this project aims at creating a benchmark for
deep learning  dl  algorithms by identifying a set of basic
operations which together account for most of the cpu usage
in these algorithms  these operations would then be
standardized into an api  similar to blas or linpack 
decoupling their implementation from the dl algorithms
themselves  the goal here is to facilitate optimization of dl
algorithms for supercomputing and hpc experts by boiling
them down to these simple operations  to this end  we have
implemented   algorithms covering different aspects of dl    
sparse auto encoder  ae  for mapping input to useful features
   convolutional neural nets  cnn  for supervised
classification  and    fast iterative shrinkage threshold
algorithm  fista   an optimization algorithm for sparse
coding  these algorithms were implemented and tested in
python and matlab  reference implementation of the api was
created using numpy and theano  with gpu support   our
results show that api implementation using theano gpu
performs   to    times faster  depending on the algorithm 
than the one based on numpy  this validates the usefulness of
our api with respect to optimization 

readers who are familiar with these algorithms may skip over
to the section ii 

introduction

section i  algorithms implemented

there have been many efforts in trying to improve the
efficiency of deep learning algorithms  for instance  coates
et  al  have shown that deep learning implementations based
on high performance computing  hpc  can train large
networks using fewer machines      however  performance
benchmarks for deep learning algorithms using hpc are
lacking 

sparse auto encoders  ae   sparse auto encoders are used in
mapping input data to a set of useful features  e g  edges at
different orientations in an image which are useful in image
recognition tasks  the set of useful features could be very
large  but only a small subset of these features are typically
present in a real life data sample  e g  an image patch  hence
a sparse combination of these features is required to
represent the input data  to capture this sparsity property 
aes are modeled as   layer neural networks with the middle
layer generating the useful features  to model sparsity  the
optimization problem consists of a sparsity penalty  for more
details  please refer to      the input of the middle layer can
be fed into cnn to achieve greater training and run time
efficiency as input data has already been mapped to features
that are useful to the task of classification performed by cnn 
some of the most expensive operations for auto encoders
involve matrix multiplications  transpose and computing the
sigmoid function on large matrices  this covered in section
tbd in more detail 

our project aims to develop benchmarks for deep learning
algorithms in the context of high performance computing
 hpc   at the start  this benchmark will cover   algorithms
from different areas of dl  these algorithms  cnn  ae and
fista  were selected by our collaborator and are introduced
in corresponding sections below  to simplify the adoption of
these benchmarks in the hpc supercomputing world  we
have identified a small set of optimizable operations by
profiling our code in matlab and python and abstracted them
into an api  this decouples their implementation and finetuning from the implementation of the dl algorithms
themselves  the operations are simple matrix manipulations
and are easy to understand as opposed to the dl algorithms
themselves  the supercomputing hpc experts can focus on
optimizing this api as opposed to expending their energy on
understanding the deep learning algorithms  this is depicted
in figure    subsequently  our project collaborator  adam
coates  will use this implementation to create benchmarks on
a supercomputer 

convolutional neural neural networks  cnn   cnns are
inspired by visual cortex  each neuron in the cortex layer is
activated by only a small subregion of the input image  these
neurons are tiled together in a such a way as to capture the
entire image  activations from these are further pooled and
fed to higher level neurons  several activation and pooling
layers could be stacked to form a hierarchy  at each level  the
property of only connecting to spatially local neurons at the

filevel below is preserved  layers closer to and including the
visual cortex recognize very basic and locally correlated
features like edges while layers at higher level have a more
global view of the input and recognize complex  non linear
features  the last layer is a classification layer like softmax
which is fully connected to all the neurons in the previous
layer  for a detailed explanation of cnn please refer to    
cnn consists of   basic operations  convolve and pool  and
upsample during backpropagation   these operations are the
most expensive in terms of cpu usage and form the most
important part of our api
fast iterative and shrinkage algorithm  fista   fista is an
iterative algorithm  similar to gradient descent  for optimizing
sparse coding  sparse coding  much like ae maps input to a
set of hidden features  the difference lies in it applying the
feature matrix w in the reverse order compared with ae 
here instead of multiplying w to input x  we have to solve the
system of equations given by ws   x  where s is the sparse
code vector  during the training process for finding w from
input x  estimation on w and s are iteratively optimized in  
separate but dependent steps  once w is trained  production
data is still mapped to s using an iterative algorithm like
fista  fista optimizes on   components  just as in ista  it
performs a gradient descent on reconstruction penalty   ws
 x      and applies a shrinkage function on s  to minimize the
sparsity penalty  s    fista uniquely adds a momentum
component based on the previous   value of the sparse
codes  for more details  refer to     

section ii  implementation details
our methodology initially involved getting familiar with the
ufldl tutorial in matlab by implementing the required parts
of the cnn  ae and sparse coding  the following steps detail
the methodology and figure   represents our workflow 
 prototype and test the ufldl exercise
implementation of the algorithm in matlab
 convert these implementations into python using
numpy
 profile the python implementation to identify a set
of optimizable operations
 define an api consisting of optimizable operations
 create reference implementation of the api using
numpy and theano
 test the implementations with and without gpu
 analyze and compare performance of
implementations

figure    project workflow

the code can be found in a github repositary at     

implementation issues  the following list while not
complete gives a flavor of some of the implementation issues
we faced 
choosing dimensions in cnn  we found the cnn operations
involving convolve and up sample can be exposed in the api
as either   d or   d operations  even though we felt that   d
operations are easier to understand in the context of an api 
we chose to expose them as   d operations as that allows
better control over optimizing these algorithms  we
implemented the same operations in   different ways 
   as   d by looping over image and filter dimension
   as   d by flattening from   d to   d
   as   d
option   gave us the greatest performance  the second
option was better than the first but it was worse than the last
as it required reshaping operations 
incompatible  d operations  some of the operations e g 
kron   had   d versions which were not compatible with
cnns requirement of upsampling  for those we had to be
creative by flattening to   d and doing a bunch of shape
manipulations and that gave us an order of magnitude
improvement in performance 
memory allocation  to ensure that intermediate results
across multiple operations are not shunted between gpu and
host we wanted to provide greater control over memory
allocation  placement and disposal  we havent fully explored
this issue  based on our early understanding  we have
provided operations like zero   and rand initialize   which can
be used to both initialize and control how memory is
allocated and placed 
array ordering and indices  we realized that the ordering of
array dimensions and indices in matlab was reverse to that of
numpy  this naturally brought up the question of which order
to follow in our api  we have used the matlab or fortran
order as suggested by our collaborator  to the end we had to
right a bunch of wrappers to map from one order to the
other 
   matlab follows fortran indexing  leftmost index
closely packed 
   numpy follows c indexing  rightmost index closely
packed 
theano constraints  not all operations were adopted for gpu
usage  e g  pool and rotate operations  because they were
not directly accessible in theano  theano likes us to construct
algorithms like cnn as one large symbolic expression which it
then converts to a graph and optimizes internally  this
approach is not directly amenable to our api which likes to
break a large algorithm into small state change operations 
for such operations we intend to write c cuda or py cuda
implementations in coming weeks 

fisection iii  results
cnn
the figure and the pie charts below identify the most
expensive operations in our api for cnn  figure   highlights
the most important operations in the cnn api and their
location in the cnn pipeline  the pie chart in figure  a  b and
  shows the   most expensive operations for cnn in numpy
and theano  with gpu  respectively  when we started with
numpy  cnn would take    minutes to train over the mnist
dataset of   k images over   epochs  using mini batching
with     images images in each batch and going through all
the images in an epoch   convolve used in filter convolve and
grad convolve was the most expensive operation taking
almost     of the total time  moving to theano and using  d version of convolve in theano  we get a speedup of    
times with gpu  and   times without gpu   the time taken by
convolve itself was now insignificant  next we optimized

figure    convoluted neural networks

figure  a and  b   time distribution by functions for cnn

upsample by creating a  d version  by flattening the array
into  d and using a bunch of reshaping   this provided an
overall speed up of    times with gpu  and     times without
gpu  compared to numpy 
the dominant time is spent in the rotation operation used in
filter convolve and grad convolve    and it accounts for
about     of the cpu  another     is accounted by pool and
upsample operations  the reshaping operation in the
upsample being the dominant contributor   once we
implement these   operations in c cuda  we expect to see
an even larger gain in performance  figure   gives a run time
comparison of cnn across numpy  theano  no gpu  and
theano with gpu  the speedup we obtain in the last case
validates the usefulness of the   most important api
operations we have identified with respect to optimization 

fifigure     cnn implementation comparison for numpy  theano and theano with gpu

sparse auto encoders  the figure and the piecharts below identify the most expensive operations in our
api for ae  figure   highlights the most important operations
in the ae api and their location in the ae pipeline  the piechart in figure  a   b and   shows the   most expensive
operations for ae in numpy and theano  with gpu 
respectively  in the ae context  theano with gpu performed
  times faster than theano without gpu and     times faster
than numpy  we optimized all the   operations to use gpu in
theano and got descent performance gain  now significant
time is spent in transferring data between host and gpu  we
still havent figured out a clean way of forcing results of
intermediate operations to stay on the gpu in theano  once
we achieve this  or implement these operations in c cuda or
py cuda  we expect to see better resultsimplement these
operations in c cuda or py cuda  we expect to see better
results 
figure   sparse auto encoders

fifigure  a and  b  time distribution by functions for ae

figure   implementation comparison for numpy  theano and theano with gpu

conclusion
we have completed the implementation of autoencoders
and cnn in matlab and python  we have identified a small
set of basic operations which account for most of the cpu
usage  these operations have been abstracted into an api 
reference implementations for this api were created using
numpy and theano  the test results show that theano on
gpu performs   x faster than numpy  thus validating the
utility of our api for optimization  highly optimized
implementation of these operations will allow deep learning
algorithms to be benchmarked for high performance
computing 

references
   http   www stanford edu  acoates papers coateshuvalwangwu
ngcatanzaro icml     pdf
    http   ufldl stanford edu tutorial index php ufldl tutorial
    http   mechroom technion ac il  becka papers       pdf
    https   github com quaizarv deeplearning benchmark

fi