predicting movie box office gross
jason van der merwe
jasonvdm stanford edu

bridge eimon
beimon stanford edu

cs      cs      stanford university
december         

abstract
predicting movie box office gross is an application of machine learning that has been tackled
by very few people  our experience with the project revealed several key insights into how
well movies make money in the box office  we applied two different algorithms  linear regression and logistic regression generalized for multiple labels  and saw that logistic regression
was the more accurate approach  to increase our accuracy  we applied k means clustering
on titles and complimentary features  we ran diagnostics to determine the fail points of our
algorithms and where we should seek to improve them  finally  we analyzed our results to
draw insight into future work 

introduction

million  after plotting the data points box
office gross  we noticed a nearly exponential
scale  figure     so  we decided to split our
data labels into   logarithmic scale buckets
to linearize the data 

famous blockbuster movies of the past ten
years have included epic films such as the
avengers  lord of the rings  avatar and the
dark knight series  all these movies made
over      million in the box office  however 
these films had massive budgets to match
their returns  which required investors with
deep pockets  our project aims to assist
investors in valuing the future return of a
movie 

data
to begin  we acquired a text file representation of every title in imdbs database  then 
we queried the rottentomatoes api with
these titles  limiting our search to movies
from      and later due to a of lack information available for earlier movies   each data
entry included a movie id  the director  title 
genres  rating  runtime  release date  actors 
studio and rottentomatoes url  our final
dataset contained      data points  ranging from movies which grossed      to     

methodologies
feature extraction
we are representing the feature vector as a
sparse vector  which allows us to have   as
the value for many features  the feature vector looks like this 
 

fi














act or   bradp itt    
direct or   jamescameron    
releasem on t h         
act or   owenw ilson    
act or   gen re  
owenw ilson   romance    
 
 
 
















linear regression
our fist learning algorithm was linear regression  we used least mean squares  specifiwhere an element is   if that actor  director  cally stochastic gradient descent  to learn the
release date etc  is present in the example weight vectors  our update rule was as foland   if it is not  the weight vector allowed lows 
us to score individual elements of a feature
ji    ji    y i  h  x  xij
vector for a proposed movie  we used single features  such as actor  director  release
h  x    t x
month  length of the movie and rating  pg   etc   we also implemented complementary
features  such as director and actor  actor and we ran lms until convergence  meaning  ungenre  we also including a k means score for til the difference in the weight vector between
titles  which is explained further in a later two iterations was very small  this took over
        iterations because the feature space
section 
was so large  thousands of unique actors and
directors   unfortunately  our results with
baseline system
our baseline system split our data into     linear regression were poor  only     of our
training data  and     testing data  we cat  predictions on our test data  data split      
egorized box office income into buckets  by again  were within a predetermined margin
sections on a logarithmic scale       k     k  of error        from the actual result  af m   m   m    m    m     m  b   b    to ter examining the predictions  we realized
classify  our baseline system returned the la  that the range of box office numbers is too
bel that appeared most often in the training high  for instance  the lowest grossing movie
data    m    m  running this baseline sys  made       while avatar made      million 
tem  we achieved        accuracy on the test this range made it extremely difficult to imdata  not only was our accuracy low  but ob  plement linear regression  so we decided to
viously  our model didnt generalize or gain explore other options 
insight into the factors that affect movie box
logistic regression generalized for
office income 
multiple labels
since linear regression did not work as well as
 

fidesired  we decided to use the bucket system
we identified in the baseline system  each
bucket represents an earnings range based on
a logarithmic scale  our classification process involved assigning a score to each label
classification for a given movie  the label
that has the highest score will be predicted
to be the best match 

rithim is defined in the functions below 
initialize centroids              k  rn
for each i set ci    argminj k xi  j k 
pm
i ci   j xi
for each j set j    pi  
m
i
i   i c   j 

results

logistic regression was the most effective althe logistic regression function is defined gorithm  ultimately  we achieved     acas 
curacy  the percentage accuracy for each
iprediction   argmaxi g it x 
bucket can be seen in the figure including kmeans  compared to random choosing of a
where i is the weight vector learned for the bucket    buckets  so the percentage chance
ith label  which we predict  iprediction is the you guess right is          our model is over
score given to that label  to do this  we used three times more accurate  our first iteraa binary classifier for each one versus all la  tion of linear regression achieved only    
bel  in simple terms  we would calculate the accuracy  the addition of complementary
score of a movie that  for example  was either features increased accuracy to around     
in the bucket of   m    m or not in that additionally  the elimination of single actors
bucket  we repeated this for every bucket and directors inceased our accuracy by a couand return the highest score 
ple points to     accuracy 
k means clustering score for titles
in order to include the movie title in the feature vector  we needed to give a movie title
a score  this is one of the issues we ran
into as we werent sure how to assign a score
to a title for a movie  but we wanted to include the title since the title of a movie does
have an effect on the movies success  to
accomplish this  we have decided to utilize
k means clustering  k means is a powerful
unsupervized learning algorithm which clusters similar data based on inputted feature
vectors  we are including in our feature vector the following features  length of the title 
number of words  occurence of numbers  and
individual substrings  k means outputs a
cluster number which is the cluster that the
title is assigned to  the perceptron will then
learn which clusters do better  or if there is
any significance at all  the k means algo 

when we implemented k means clustering
on the titles  we increased this accuracy to
    
we also implemented loocv  leave one out
cross validation  and applied this technique
to a smaller dataset of     samples  we ran
loocv without k means and achieved    
accuracy  which was impressive on a small
data set  however  loocv took so long on
 

fithe small sample size that it was not feasible
to run loocv on the full data set contain  feature weights analysis
ing      entries 
we wanted to see which features were
weighted the heaviest  so we ran a script to
sort the weight vectors for each label  what
we found was very interesting  below are the
top five features for the label     m  b 
 studio sony pictures         
 actor anne hathaway         
 studio warner bros  pictures 
village roadshow         
 director peter jackson         
 studio lions gate         
overwhelmingly  the studio made the biggest
difference in every single label category  another observation found was that all bollywood movies were classified in the      m
range  this was evident by the fact that in
the      m range  the most weighted features were an indian bollywood production
company and indian actors  this was very
intriguing  we also found that the horror
film genre had a large impact in the       m range  after some research  this seems
to be because horror films have a cult following and are cheap to make  so they are made
often 

analysis
feature extraction
the one issue we ran into was that our feature space was too large  because of the
abundance of actors and directors  our feature space had tens of thousands of entries 
not only did this hurt our accuracy but it
also slowed our algorithms considerably  to
account for this  we eliminated any actors or
directors that only appeared in one movie 
this made sense because these actors and
directors  presumably  wouldnt be valuable
in any other films because they had yet to
prove their worth  this sped up our learning process considerably  this increased the
speed of the algorithms dramatically  as well
as increasing the accuracy  the increase in
accuracy confirmed our suspicions that these
directors and actors were weak indicators of
movie box office success 

the previous figures show the prediction
accuracy for each bucket  our model is
very accurate for the       k and        m
ranges  we believe this is the case for the
      k because the actors  directors and
studios producing the indie films wont make
much money because they are indie films 
plus  since they have low budgets  theyll
very rarely include big name actors  so the
model easily predicts correctly  many box
office movies fall into the        m range 
they may include one or two big name ac 

we decided to implement complementary
features because it is common for actors to
specialize in a genre  or for directors to always pick the same actors  these features
had a dramatic impact on our accuracy 
 

fitors  but never very many  this is the typical
range for the average movie  so our model
predicts this range easily  we have around
a     accuracy rate with the      m range 
probably because of the presence of bollywood films 
k means
the previous figures also show the difference
between the accuracy of the model with and
without k means  k means increased the
overall accuracy by     but it also evened
out the accuracies for individual labels  the
more accurate labels became slightly less
accurate  however  labels which were very
inaccurate became more accurate  we believe that the presence of kmeans gave more
weight to movies which were sequels  one of
the kmeans features was the number of occurences of numbers in the title   length
was also a feature  which gave more weight
to movies that may have been in a series  like
lord of the rings 

tor  were rated higher for the blockbuster
range      m  b   however  the biggest difference was the studio  columbia pictures 
they have a weight of      for the       m range  but only a     weight for the
blockbuster range  again  this supports our
hypothesis that the studio makes the biggest
difference in the monetary success of the film 

we also predicted one film  the other side
of heaven  incorrectly by a huge margin  in
the box office  it only made     m  but we
predicted       b  at first  we were very confused by this result  but then discovered anne
hathaway starred in the film  her weight feature for movies in the      m range is negative          because she is very rarely in
these films  but her weight for movies in the
blockbuster range is extremely high        
the movie was also released in april       
a couple months before the princess diaries 
hathaways first breakout role  so at that
point in her career  she wasnt as valuable 
none of the other actors were in any other
analysis of incorrect predictions
films  so they were not in the feature space 
yuvvraaj was a movie that we predicted in  but since anne hathaway carries such weight
correctly  our model predicted the      m  see the feature weights analysis above   the
label  presumably because this was a bolly  prediction was for the blockbuster range 
wood film  the director was subhash ghai
and the two main actors were anil kapoor future work
and zayed khan  the movie actually made we plan on continuing to iterate on this
    m and underperformed most bollywood project  we recently learned of an easy way
films  so although the prediction was incor  to get budget data and plan on including the
rect  it makes sense that the prediction was budget of a film as an additional feature  we
for      m since the film was from bolly  believe that this will increase the accuracy
wood 
dramatically  the project was enjoyable and
many of our friends enjoyed hearing about
xxx was another movie we predicted incor  different predictions  so we plan on turning
rectly  our model predicted        m  but this into a website where people can input
the actual was     m  while the movie in  their dream films and see how much they
cluded famous actors such as samuel l  jack  would make  we believe that this project
son and vin diesel  jackson was weighted shares valuable insights into the factors which
heavier for movies in the        m range  determine the box office success 
but vin diesel and rob cohen  the direc 

fi