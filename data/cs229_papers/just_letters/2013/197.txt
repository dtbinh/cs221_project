identify keywords for stack exchange questions
cs    final project
guoxing li  guoxing stanford edu   chi zheng  zheng   stanford edu 

its mathematical logic and in detail explain the way it has been
i 

abstraction

applied to our task 

the purpose of this project is to build a keyword identification
system for questions in major stack exchange websites to

i  learning techniques
   number of tags prediction

improve the efficiency of question answer cycle 
we leveraged a wide range of knowledge in machine

to predict tags for a certain question  we first need to predict

learning and information retrieval to develop a robust

the number of tags  we select feature by constructing a

keywords identification system  in particular  we adapted the

vocabulary from training set with each word as an entry  for

tf idf    heuristic for feature selection  investigated linear

a training example  we then convert raw text to an array that

regression  logistic regression  and svm for predicting

contains the number of occurrence for each word in the

number of keywords  tags   and also implemented naive 

vocabulary  which is used as input in our predicting model 

bayes  labeled latent dirichlet allocation l lda    

we investigate a number of commonly used approaches to

algorithms

varies

build our predictor  including both regression  linear

experiments  we analysed the results and derived conclusions 

regression  and classification methods  logistic regression 

for

identifying

keywords 

after

svm   for classification method  the range of number of tags
ii 

introduction

is the range seen in the training set  we also tried regression

i  stack exchange websites

method since theres no hard limit on the number of tags for

stack exchange is an emerging network of over     question

each question 

and answer sites that cover a wide spectrum of topics ranging

we make a further improvement on the features used 

from cooking to traveling to software programming  aiming

intuitively  a word occurs multiple times in a question doesnt

to establish a valuable knowledge network  it offers high

mean the question should have multiple tags  so instead of

quality answers to critical questions in diverse fields 

using the number of word occurrence as features  we clip the

ii  motivation

number to a binary value indicating whether a word occurs or

the question volume of stack exchange websites increases

not 

drastically with the popularity of internet  an automatic key

   naive bayes for tags prediction

words identification system will benefit both the people who

we choose naive bayes as our first attempt to solve the tags

asked the questions and those who answered them  the

prediction problem  because of its simplicity and wide use

system can generate automatic tags for questions to better

case in text classification  specifically  we train a collection

categorized questions  this process simplifies the process to

of multinomial naive bayes classifiers with laplace

match people with right knowledge to specific questions 

smoothing using training set provided 

iii 

experimental methods

in this section we will discuss the key challenges we face and
the corresponding machine learning methods we applied to
solve those challenges  for each methods  we will introduce

similar to the number of tags prediction  we construct a
vocabulary

and

convert

input

correspondingly 

the

vocabulary is selected using the approach described in
feature selection and noise reduction section  to predict

fidec      

identify keywords for stack exchange questions

pg   

different tags using naive bayes  we construct the following

all the topics provided in the training set  each document is

algorithm 

broke down into a distribution of all topics  by selecting the



topics with highest probabilities  we are able to select the top

construct a tag set by collecting all tags in the
training set  the tags predicted will be within this tag







set 

ii  feature selection and noise reduction

build a vocabulary by selectively taking words from

applying machine learning techniques to text based data is

training set  details in feature selection and noise

challenging partially due to the large noise within the data 

reduction section  

factors such as typos  inconsistency usage of capitalization

train a naive bayes classifier for each tag in the tag

and grammar mistakes drastically increase the data noise 

set using the vocabulary  the classifier for each tag

specifically  text in questions at stack exchange can be even

tells the probability of a question having this tag 

noisier as it may contain a large amount of code snippets 

before feeding our training data into classifiers  we

which includes unwanted words like variable names  different

pre process input text using the same filtering

syntax  etc  however it is undesirable to simply take out code

method used as feature selection so that words in

snippets from question body as it may drop some

input can be best matched with corresponding entries

language technique specific keywords  as a result  we

in the vocabulary 

adapted a series of approaches to remove noise by

we also train a model discussed in previous section
to predict the number of tags for each question 



tags 

to predict  given a testing example  we run all
classifiers on the example  and choose k tags with
the highest probability  where k is determined by our
number of tags predictor

the time complexity of our approach is o       
where  is the size of training set   is the size of tag set  and

standardizing words and filtering out undesired words  the
techniques we used here not only sanitize the input data  but
also dramatically decreases computation time by shrinking
the size of vocabulary  especially for nave bayes approach  
word purification we try to reduce noise originates from
different forms of a word by lowercasing all characters 
ripping out certain punctuations  and using word stemming 
note that we dont rip out all punctuations since that will
make it harder to differentiate words like c    c  and c  

 is the size of vocabulary  given that there could be millions
of questions  thousands of tags and thousands of entries in the
vocabulary  the nave bayes approach we used here is rather
time consuming 

tf idf to filter out undesired words  a common way is to
filter out a list of stop words  e g  the  and  you 
what   the simple approach is not good enough in our case 
since it doesnt remove those words with really low frequency

   labeled latent dirichlet allocation  l lda 

 e g  variable names   therefore  in addition to that  we utilize

labeled lda is a supervised topic model generated from

the state of the art tf idf weighting heuristic  okapi bm     

lda    for credit attribution in multi labeled corpora  we

to discover meaningful words in each training  note that a

believed l lda is a good fit as our task is very similar to the

good vocabulary needs to be small while contain as many

one in the paper that introduced l lda 

meaningful words as possible  the heuristic takes both word

in this model  a document is viewed as a combination of
topics  each of which consists of a word distribution  in our
case  the topics are labels in the training set  through the
training process  the algorithm build the word distribution of

frequency in particular training example and its appearance in
corpus into account to assign a score that reflects its overall
expressing power 

fidec     

identify keywords for stack exchange questions
     log

          

          
        
             

  
                  
 


pg   

the tags  ranging from one to five depends on the question 
are the keywords or summary of the content  the training set
is of size      gb  the testing set      gb 
due to the large size of the dataset and high computation

in the equation above   is the document     is the

complexity of our algorithms  its impractical to train and test

number of times qi appear in the whole corpus      

with all of the data  as a result  we only conduct our

computes the word frequency of  in document     and 

experiments with a relatively small data set 

are tuning parameters 

ii  evaluation

we control the size of vocabulary by specifying the

our experiments are designed to tackle the following three

percentage    of words selected for each question  for a

major challenges we faced in developing the keywords

question with  number of words  we select    words

identification system      find the optimal method to predict

with the highest score to construct vocabulary 

the ideal number of tags for a specific question      find an

title body separation when think about the essence

optimal learning techniques to predict tags      discover

underlying question title and question body  we realize that

feature selection schemes to improve the learning methods

title serves as a summarization of the question people want to

accuracy and efficiency  in the following sections  we will

ask  and body describes the question in more details  so given

discuss our approaches that address these challenges in detail 

the same amount of words  its generally true that title is more

by analysing the results of these experiments  we are able to

informative than body  therefore  for the nave bayes

derive a best model 

approach  we tried to leverage this property by prepending

   predict number of tags

title  with title words  and body  for body words to
separate title and body words when constructing the
vocabulary  however  that didnt work as we expected  the
result is worse than the one without separation   which we
think is because that the approach leads to over fitting
problem  we then tried another method  which is to select
more words in title than those in bodies by assigning a higher
tf idf score to title words  this method gives us slight
performance improvement under certain circumstances
 especially when training set is small   but is still

to find the optimal methods for predicting number of tags
given a specific question  we experimented different methods
including linear regression  svm and logistic regression 
we developed two versions of each method  one with
clipping  where we clip number of words occurrence to binary
value  and one without clipping  for each method  we varies
the number of words used as features and recorded the
corresponding mean square error  mse   both our training
and testing set have      examples  the experiment results
are shown in figure   

outperformed by the model without separation in general 
by analysing the figure  we drew the following conclusions 
iv 

results

i  data set
the data set is directly taken from the open challenge posted
by facebook  inc at kaggle com      each entry in the training
set corresponds to a question posted by users in stack
exchange websites  it consists of four fields  question
identification  title  content and actual tags  in contrast  each
entry in the test set contains all fields except for the ideal tags 

we discovered logistic is the most effective method with
small number of features while svm being the most effective
one overall  least mse   this result aligns with the fact that
svm tend to have better performance compared to logistic
regression when the data dimension is high  as the number of
features increases  the mean square error of our experiments
decreases  the error drops drastically when the number of
features used is smaller than       but much slower after that 

fidec      

identify keywords for stack exchange questions

pg   

finally  our experiments indicates that methods with clipping

selection  mitigates l ldas advantage in topic discovering 

outperforms their counterparts without clipping  this suggest

in most cases  each topic contains less than ten words 

that duplications of words in a single question didnt carry

however  l lda outperforms nave bayes in computational

additional information  in fact  the duplication will increase

efficiency by roughly   times  as number of training tags

error of prediction  besides  the minimum mse we have is

increase  we expect l lda to be a more optimal algorithm

around    which is not quite satisfying 

from a computation efficiency perspective 
baseline

l lda

nave bayes

precision

    

    

    

recall

    

    

    

f  score

    

    

    

table    different learning methods
   discover feature selection mechanisms
to improve the accuracy and efficiency of the learning
method we discovered in the previous section  we conducted
experiments to discover the most optimal feature selection
mechanisms  to test the power of tf idf  we implemented a
figure    number of tags prediction
   find optimal learning method

nave bayes model that constructs vocabulary by selecting
words with top frequency while filtering out stop words  we
trained our nave bayes model with      questions on   

to find an optimal learning method  we compared nave
bayes and l lda using precision  recall and f  score as our
error metrics  we compared these methods to our baseline
method in which we assign each tag a probability of
occurrence that is proportionally to its number of occurrence
in the training set  given a question  we randomly predict the
tags based on their assigned probability  our experiments are

most frequent tags  we test the classifier with     examples
whose actual tags are within the training tag set  to eliminate
other factors  instead of using our model to predict number of
tags  we always choose k tags where k is the actual number of
tags for a specific testing example  we used f  score as our
measure and plot it against the number of words used as
features with different feature selection techniques 

conducted with      training questions  to reduce
computation time  we only consider    most frequently
appeared tags  note that since theres no way for our
algorithms to predict a tag that was never seen before  we only
tested on     examples whose actual tags are within the   
tags we selected  we always choose   tags for each testing
example  and pre process input using the same technique to
eliminate other factors 

from figure    we observed that basically for all
classifiers  the score increases as the number of features
increases before it reaches       and decreases thereafter 
when the feature number is relatively small  less than       
as the number of feature increases  our classifiers get more
information  under fitting   however  once the feature
number surpass       noises in the additional feature
outweighs the information they provide  over fitting  

as shown in table    both l lda and nave bayes
significantly outperform the baseline method  in this
experiment  nave bayes outperforms l lda  we think this
is because the limited number of words  especially after

therefore we concluded that      is the optimal feature
number for this experiment setup  the title and body context
separation methods doesnt live up to our expectation  failing
to outperform the one without separation  this might due to

fidec     

identify keywords for stack exchange questions

pg   

the fact that tf idf heuristic already selects the meaningful

of the questions have less than   tags  we test and show the

words for the classifier  selecting more words from title by

  tags predictor mainly because its extraordinarily high recall

manually assign a higher value for title words may

suits fine in a real world use case  note that this project can

inadvertently lose some information from body given the

provide a great way to recommend tags for questions  its

same amount of features used  model without tf idf and

important that the recommended tags contain the ideal tags 

purification has a much lower score compared with the full

which can greatly improve user experience by saving users

model  which shows the effectiveness of these two

effort on typing in those tags manually  as a result  high recall

techniques  furthermore  though not shown in the figure  the

is desired in this specific use case 

classifier with tf idf heuristic significantly reduces the
computational complexity as it reduce feature size    to   

v 

conclusion

in this project  we explored a number of techniques to best

times 

identify keywords in stack exchange questions  the project
is basically divided into two parts  namely predicting number
of tags  and identifying ideal tags  we conducted various
tests  and finally found that the combination of svm numberof tags predictor and nave bayes classifier gives us the best
result 
we realize that our method is by no means perfect  there are
two major constraints  which are its high time complexity and
its limit on not able to predict tags never seen before 
however  if its released to real production  the algorithm can
be run using a cluster of powerful computers  which will make
it usable in real time  training can be done constantly without
figure    feature selection comparison

influencing user experience   also  by training on a larger tag
set  the model will be able to capture most of the tags  since 

iii  final result

though the tag set is not fixed  its not actually changing

by combining the best number of tags predictor  svm  and

frequently 

the best tags classifier  nave bayes   we derive the final
result on the same training and testing set 
k tags predictor

  tags predictor

precision

    

    

recall

    

    

f  score

    

    

table    testing result of best model
in table    k tags predictor is utilizing svm with clipping
to predict number of tags  where   tags predictor is always
predicting   tags  it should be not surprising that   tagspredictor has a higher recall and a lower precision since most

references
    jones ks          a statistical interpretation of term specificity
and its application in retrieval   journal of documentation        
      doi         eb       
    blei  david m   ng  andrew y   jordan  michael i  january
        latent dirichlet allocation   in lafferty  john  journal of
machine
learning
research
 
     
pp         
doi         jmlr                
    ramage  d  hall d  nallapati r  and manning  c  labeled
lda  a supervised topic model for credit attribution in multilabeled corpora 
    http   en wikipedia org wiki okapi bm  
   
https   www kaggle com c facebook recruiting iii keywordextraction

fi