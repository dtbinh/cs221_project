a kernel of truth  december     

a kernel of truth
keenon werling
stanford university
keenon stanford edu
abstract
this paper first proposes a  to the authors limited knowledge  novel extension to the openie paradigm 
to allow the expression of recursive relations  and presents a fully implemented extension to the exemplar system  uncreatively referred to as recursive exemplar  to extract recursive n ary relations
automatically and with very high precision  it then explores the possibility of a  concept kernel  over the
output of recursive exemplar to allow arbitrary learning over the ideas expressed in raw text inputs 
and discusses computational considerations 

i 

introduction

pen information extraction  banko and
etzioni        is an attractive paradigm 
because it frees us from the burden of
manually describing every relation type we
want to extract with large quantities of labelled
training data  at the same time  it is notoriously difficult to use as input to higher level
ml tasks  because current state of the art systems ignore many important limitations on the
quality of their extractions 
primarily  this is because related extractions
are not linked  for example   the prime minister proposed that women ascend the throne 
would be extracted traditionally as two seperate relations  proposed prime minister   ascend women  throne   this repsentation suggests that  women ascend the throne  is already a fact  and doesnt give us any information on what the prime minister proposed  we
could instead extract the recursive relation proposed prime minister  ascend women  throne   
this recursive representation has the benefit
that limitations on truth that go beyond the
complexity of basic prepositional relations are
easily represented  and objects that are more
complex than single phrases can still be linked
without loss of information  the relative reliability of a speaker can be factored into the quality of an extraction if the speaker is known  and

o

 many

temporal and spatial limitations are still easily extracted from prepositional attachments at
any point in the recursive relation  a method
will be proposed in the second half ot the paper theoretically capable of learning these relationships automatically  though computational
limits prevent a full experiment 

ii 

related work

openie has seen an explosion of methods in
the last few years  with varying degrees of
accuracy and computational cost  briefly summarized  they fall into   classes  reverb  fader
et al        and sonex  merhav et al        
using only shallow syntactic information like
pos tags for their extractions  the syntactic
parse openie systems  patty  nakashole et
al          ollie  mausam et al        use regular expressions over parse trees  treekernel
 xu et al         uses an svm with a kernel
over sub tree similarity to classify whether or
not a relation is present between two named
entities  extremely computationally expensive
methods using a semantic parse as input also
exist  and achieve competitive results  but are
prohibitively time consuming 

thanks to gabor angeli  and the stanford nlp lab in general  for data and advice

 

fia kernel of truth  december     

iii 

failed methods

prior to considering a rule based approach  several methods for the automated training of
a recursive openie systems were attempted 
hill climbing over the regex rules used to extract fully formed relations was implemented 
an improvement on the methods in ollie  but
could not get above     precision on the available dataset  application of an svm to the role
labeling step in recursive exemplar  in a similar way to the work in treekernel  xu et al  
       using the efficient tree kernels presented
in  moschitti        found that altough it could
get some things right on test data  its errors
were easily corrected by the application of a
rule based system  the working hypothesis
is that inability to get competitive results with
machine learning systems is due to the inability
to grammatically consistently hand label enough
data to train the systems  at the beginning of
the project      sentences were carefully handlabeled  which took   hours  and it was discovered that a baseline system that used every pattern it found in the hand labeled data to make
new extractions achieved a     precision     
recall on unseen data  the underlying structure just wasnt dense enough to be learned
from such a small amount of data  so  for now 
rule based systems rule the waves 

iv 

original exemplar

a recent paper  mequita et  al        did a fair
comparison of several leading methods  and
proposed an elegant and relatively computationally efficient method for openie with the
highest accuracy of any of the measured systems  exemplar  the two major innovations
represented in the design of exemplar are
   the ability to extract relation phrases independently of their arguments  like a
semantic parse based system 
   the return to a rule based approach as
a solution to a general lack of sufficient
labeled data 
 

the system presented in this paper builds
directly upon exemplars innovations to
achieve a system for extracting n ary  recursive
relations with state of the art accuracy 

v 

design of recursive exemplar

the recursive exemplar extraction system
works in a series of deterministic steps  repeatedly applied until no new information can be
gained from data  then post processing is applied across the extracted relations  and the
results are returned  the general algorithm is
as follows 
function extractrelations s 
p  stanfordparser s 
e  namedentities  p 
r    
while true do
t  detecttriggers  p  e  r 
rnew  detectroles  p  e  r  t  
rnew  filterrels  p  rnew  
if   rnew        then
return postprocess  r 
else
r  merge  r  rnew  
end if
end while
end function
named entities are detected using the
stanford ner system  detecttriggers   
detectroles   
filterrels   
and
postprocess   will be explained in subsequent sections  the major change in the design
of recursive exemplar over exemplar is
the use of a loop to detect new relations given
old relations  instead of a single pass to detect stand alone relations all at once  and a
final postprocess   step to use parse data to
make relations as easy to use as possible for
other applications  the necessity for the loop
design will become clear in the discussion of
detectroles   

vi 

detecting triggers

the brilliant leap in the design of the original
exemplar was to detect  triggers   defined

fia kernel of truth  december     

to be words that indicate the presence of a
relation  seperately from their arguments  exemplar identifies   kinds of triggers  verb 
copula noun  and verb noun  recursiveexemplar adds the recursive trigger  conjunction  their relative frequencies  automatically collected from      random sentences
from wikipedia  and       sentences from
nyt are as follows 
table    wikipedia trigger frequencies

trigger type

freq 

verb
verb noun
copula noun
conjunction

     
     
     
    

avg  sentence
    
    
    
    

table    nyt trigger frequencies

trigger type

freq 

verb
verb noun
copula noun
conjunction

     
     
     
    

avg  sentence
    
    
    
    

the striking distributional similarity between the two sources suggests that the types
of extractions made by recursive exemplar
across varied english sources will be balanced
between different tree structures 

vii 

recursive exemplar adds one more feature
to rules  rules may be marked  recursive 
or  non recursive   a rule marked recursive
is only applicable to words that are already
within an argument or trigger for an n ary
relation extracted in a previous round  and
then the entire n ary relation is taken as the argument  rules marked non recursive can only
be applied to words that are not yet contained
in any argument or trigger 

detecting roles

once a list of triggers is collected  the next
step assigns arguments to the triggers  which
become preliminary n ary relations  each argument is given a weight of preference  and
only the single highest preferenced subject and
direct object relations are allowed  the classification process is entirely rule based  rules
take the form of simple dependency patterns
from a trigger  with restrictions about what
trigger type is applicable  verb  verb noun 
etc   and what trigger pos is applicable 

viii 

post processing

for the convenience of users of the output of
recursive exemplar  a few post processing
steps are done once the algorithm has returned 
   an attempt is made to collapse  that  relations  if the subject of the  that  relation
has no direct object  then the direct object of the  that  relation is made in the
direct object of the subject of the  that  
and the original  that  is deleted from the
output  to clarify that horrible sentence 
using our running example   the prime
minister proposed that women ascend
the throne  extracts that proposed prime
minister  ascend women throne    which
is reduced to proposed prime minisert ascend women throne   
   coreference is applied to all arguments
that contain pronouns  because extractions containing  he  and  she  are totally
useless for some higher level applications 
coreference is not applied in general  because it tends to reduce the accuracy of
the extractions  since any coreference system is imperfect 

ix 

results

results are measured against wikipedia articles and nyt seperately  for each corpus i
hand labeled     flat extractions  and     recursive extractions as correct or incorrect  i
measured these two groups seperately because
 

fia kernel of truth  december     

i am primarily interested in the recursive extractions  and since they are far less frequent 
measuring together would mean that i would
have a label many more flat extractions in order to get a reasonable sample of recursive
extractions  the relative frequency of recursive
extractions  as a percentage of total extractions 
is noted in the first numeric column 
table    hand labeled precision scores

corpus

rec  freq 

wikipedia
nyt

     
     

flat prec 

rec  prec 

     
     

     
     

these numbers are limited to precision only
 no recall values  because it proved impossible to label consistent n ary extractions from
a body of sentences in the time provided for
this project  a reasonable lower bound on
recall is possible  however  since the original
exemplar paper measured recall at      and
the additional rules can only have increased
recall  while potentially lowering precision  
empirically  precision was not lowered  but
increased  having measured precision on both
nyt and wikipedia  the recursive extraction
rules presented here are highly precise 
below are some examples of the recursive
extractions produced by recursive exemplar
on the test set during the labeling run to generate the precision numbers you see above 
   attorneys for the plaintiffs contended
that exxon bore responsibility for the accident because the company  put a drunk
in charge of a tanker in prince william
sound  
because 
bore exxon  responsibility  
put company  drunk 
 in object charge 
 
contended 
attorneys 
bore exxon  responsibility 
 

 
   the edsacs memory consisted of     
locations  though only     locations were
initially implemented 
though 
consisted edsac memory 
 of object      locations  
implemented passive 
only     locations 
 
   popular opinion holds that longer scale
length contributes to greater amplitude 
holds 
popular opinion 
contributes longer scale length 
 to object greater
amplitude 
 
   the economy of the city of cordova 
alaska was adversely affected after the
spill damaged stocks of salmon and herring in the area 
after 
affected passive  economy  
damaged spill  stocks 
 in object area 
 

x 

the promise of concept
kernels

what good can recursive first order logic do
for machine learning  one possibility is the
opening up of knowledge locked away in text
as input to learning algorithms  as a concrete
example  imagine a system that reads the news
for structured extractions  and then applies
a non linear classifier over its extractions to
find a relationship between ideas in the news
and stock prices  this is deeper than just a
word counter  since algorithms can be run over
structured representations of ideas  instead of
bags of tokens  this is theoretically possible

fia kernel of truth  december     

with recursive exemplar  though it is very
computationally intense  the recursive n ary
relation extractions my system produces can
be seen as trees  with labeled nodes  many different  kernels   not mercer kernels  really just
similarity measures  exist for measuring the
similarity between recursive structures without
labels  moschitti         and with slight modifications they can take into account semantic
similarity information between nodes 
the major unsolved problem 
the simple concept kernels this paper explored
used    dimensional word representations to
measure semantic similarity  in practice  this
led to a very large represenational capacity 
because a small extraction with   nodes has
roughly the same representational capacity
as an     dimensional real numbered vector 
thus  an svm required a lot of data to collect
enough support vectors to make reasonable
estimates  on the other hand  an svm is very
computationally expensive to use  and even
more so because the kernel computations are
quadratic in the size of the concept trees  with
large constant factors  an svm was run using
a concept kernel on a dataset of extractions
from a month of nyt articles  and compared
against fluctuations in   year t bills  with a
binary up down classification over the next
time period 
table    computation v  accuracy

  extractions

prec 

      
       

    
    

hours to converge
 
  

extractions improved with sample size 
but computational limits prevented increasing
data size  more data is available  recursiveexemplar was able to mine    million extractions from a   year newswire corpus  future
research will explore a large scale run  and find
if concept kernels work in practice to allow machines to learn patterns in arbitrary human
ideas 

references
 dan klein and chistopher d  manning       
accurate unlexicalized parsing  proceedings of the   st annual meeting on
association for computational linguistics
  volume    acl    pages         
stroudsburg  pa  usa  association for
computational linguistics 
 silviu cucerzan        large scale named entity disambiguation based on wikipedia
data  proceedings of coreference on empirical
methods in natural language processing and
computational natural language learning 
emnlp conll    pages         
 anthony fader et al         identifying relations for open information extraction 
proceedings of coreference on empirical
methods in natural language processing 
emnlp conll   
 mausam et al         open language learning for information extraction 
proceedings of coreference on empirical methods in natural language processing and
computaitonal natural language learning 
emnlp conll   
 moschitti        efficient convolution kernels for dependency and constituent syntactic trees ecml       ecml      
pages        
 ndapandula nakshole et al         patty  a
taxonomy of relational patterns with semantic types  proceedings of coreference on
empirical methods in natural language processing and computaitonal natural language
learning  emnlp conll    pages           stroudsburg  pa  usa  association
for computational linguistics 
 ying xu et al         open information extraction with tree kernels  proceedings of
the      conference of the north american
chapter of the association for computational
linguistics  human language technologies 
pages          atlanta  georgia  june  association for computational linguistics 
 

fi