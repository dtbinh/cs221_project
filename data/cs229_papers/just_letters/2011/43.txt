audio sources separation by clustering techniques
wei fang

 abstract 
this project tries to present a method to distinguish different components in a piece of audio signal without prior
knowledge of instrument types and number of instruments  spectrum analysis plays a major role in this method 
clustering techniques are applied to eliminate duplicated audio sources 
 background 
audio sources  including human vocal cords and musical instruments usually are based on a harmonic oscillator
that produces vibrations on a series of integer multiples of a base frequency  the base frequency defines the pitch
of the sound produced  due to different characteristics of these sources  even if we have   sounds from   different
sources whose base frequencies are the same  their power distributions over these harmonics are different  we
human ears can identify the differences in the distributions and tell that the instruments produce different
timbres  to us  timbres are signatures of sound sources  however  these signatures are not that straightforward to
computers  since these signatures are described in the spectrum domain  my starting point to tackle this problem
is from the spectrum of audio signals 

figure    spectrum calculated from a segment of a song

 proposed method 
   onset detection
timbres are most distinguishable when the notes are just set  for example  when the little hammer strikes a string
inside the piano  or when human produces a consonant before a vowel  these make the sound much more
distinguishable  thus  onset detection is my first step here 

fifigure    detected onsets and corresponding spectrums
there are many sophisticated onset detection methods  here i incorporated a simple one  capturing sharp
increases in spectral energy 
   generalize models from the above onset positions
in this step  i want to obtain models of audio sources  these models are described by amplitudes and phases on
higher order harmonics referencing to the base frequency  for each identified sound source  this step will fill up a
table like table   
base freq 

 st harmonic

 nd harmonic

 rd harmonic



amplitude

 

amp 

amp 

amp 



phase

 

phs 

phs 

phs 



table    model generalization
     perform short time fourier transform
in order to calculate spectrum of the input signal at a given time spot  short time fourier transform is carried out 
it is done by taking out a short segment  for audio signal sampled at      hz       samples would be
appropriate since this will allow an identification of frequency as low as   hz  the lower limit of human hearing 
from the original signal at the given time  windowing it by a gaussian window  so that consecutive measurements
will be smoother   performing zero padding at both left and right side tails of the signal  so that it offers better
frequency resolution after the fourier transform   and performing fourier transform 
     take the maximum frequency response  find out its harmonic resonances
     normalize the amplitudes of the resonances  note them down as a basis
this is essentially filling up the form table   for the current signal model being processed 
     subtract the just obtained basis from the current set of frequencies 
     do     to     until energy left in the fourier transform is reasonably small 
the effect of these steps is illustrated in figure   

fifigure    signal before and after obtaining significant bases
   combine bases that probably come from the same instrument
since the model generalization is performed on every onset position  there should be plenty of similar models in
the set of models obtained  these models can be represented as points in cn space  where n represents the number
of harmonics being considered in the models  to simplify the problem  i only took the first   harmonics  which are
usually more significant than the others   and only consider their amplitudes  this reduces the problem into a r 
space clustering problem 
different from the clustering problems described in class  this is a clustering problem with an unknown number of
clusters 
the first method i considered is mean shift clustering  perform gradient ascent to move the mean to the center of
one cluster  subtract points belonging to that cluster and perform gradient ascent again  but later on  i discovered
that the points in r  are quite sparse  under this condition  the problem might be easier solved by judging the
distances between points  a distance map showing euclidean distances between points is generated 
     cluster the bases generated in   by the distance map
     replace bases in a cluster with the mean of the cluster
in these steps  a metric of being similar is defined as the euclidean distance between points  similar models are
combined  the effect of this step is shown in figure   and figure   

figure    distances between bases before combining similar bases

fifigure    distances between bases after combining similar bases
   recover signal from the bases representation
in this step  i will generate audio signals with specific models being removed  short time fourier transform is
applied again on the signal  this time the transform is performed periodically  from the beginning through the end
of the input signal 
     identify frequency components that are similar to the model  remove them 
this step is again done by the distance map based clustering  several models are identified from the segment of
input signal  and they are being compared with our selected model  if they are similar  the frequency components
are removed from this segment of input signal
     perform inverse short time fourier transform to get the time domain signal back 
in this step  the segments of signal are transformed back into time domain signal  overlapping parts of the
segments are properly weighted so that the output signal is a smooth one 
 experiments and results 
experiments showed that the generalized model can properly represent the components in the input signal  figure
   figure   and figure   showed models being generated from different types of input signals  which matches the
fact 
however  the model removal is not that effective  though the models are already clustered  they still seem not
powerful enough to express a sound source completely 

figure    models generated from a piano violin piece of music

fifigure    models generated from a solo piano piece of music

figure    models generated from a song from a female singer with accompany by a range of instruments
 future work 
a better metric to combine models should be developed 
the current algorithm is well adapted to audio sources that put most of their power on the base frequency 
however  there are instruments that put their peak of energy on one of their higher order harmonics  there should
be ways to deal with this 

fi