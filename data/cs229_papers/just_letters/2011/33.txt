predicting preferences
analyzing reading behavior and news preferences
soravis srinawakoon potcharapol suteparuk
advised by richard socher

  introduction
news reading has gradually become a significant activity in our daily life as the world is saturated with
new information  we consume so much information every day that it becomes extremely difficult to filter
and extract only the interesting and relevant news to us  to improve readers experience  we need to be able
to accurately predict the new stories that are most probable for them to read  this reduces to predicting
preferences which is a common problem of finding out which items are most relevant to each user and
essentially rank or feed them to tailored users  in our study  we in particular look at the stories users click
and read previously in a news reading mobile application pulse in order to predict which stories users are
most likely to read in the next few days 
similar challenge has been recently tackled by researchers in data mining and natural language processing
because its implications can be applied to other popular areas such as search engine recommendation system 
this paper considers applying different machine learning algorithms in the realm of supervised learning and
unsupervised learning in attempt to predict the news stories that each user are most likely to read from a set
of all available stories  which are much too large for the average users to parse and find the most relevant ones 
in particular  using users click and read history  we explore text categorization algorithms by comparing the
accuracy of several supervised learning methods such as a simple naive bayes  l  norm regularized logistic
regression  and l  norm regularized logistic regression with lasso algorithm  we then move on to investigate
common unsupervised learning technique such as k mean clustering of users and a simple implementation of
collaborative filtering 

  dataset and text representation
given three set of input data from pulse         available stories at a given period  all stories read from a
sample of       pulse users  and all click through stories from the sample sample of       pulse users during
the given period  we extract and represent all the available stories as feature vectors x    x i    where x i 
corresponds to each storys input features  we represent this input feature using a simple form of tf idf
term weight  term frequency times inverse document frequency  where x i   rn   n    w   is a total number
of distinct terms appeared in all document  as a starting baseline  we represent each document using only
its title and feed title so  w   is total number of distinct words appeared in all title and feed title  this gives
term j in document i a tf idf weight of
 
 
if a i  j     
 i 
xj  
 s 
  otherwise 
     ln a i  j   ln  a j 
where a i  j  is the number of occurences of term j in a document i  a j  is the number of avalaible stories
that contain the term j  and  s  is total number of avalaible stories 
later  we will explore a subset of our available data and represent each document by its title and its
content  we will make a slight adjustment to our tf idf term weight by adding a cosine normalization to
our feature vectors which has shown a significant improvement in prediction for large document size as it
reduces the impact of document length     
thus  the final normalized weight is 
 i 

 i 
xj

non  normalized xj
qp
 
 i 
n  i 
j   xj    xj  

where we sum over all the terms j in the denominator but we denote it with j   to avoid confusion 

 

fi  methodology and classifier
in this part  we present all of the method and classifier used  the result of each will be present in part
four where we evaluate each classifiers performance by measuring its rmse  precision  recall and f measure 

    features selection
our data set and in general the text categorization data are very sparse with unclear relationship between
input features and class labels  therefore  we try to select features that are most relevant using typical text
preprocessing methods such as stop words removal  singletons removal  and stemming using stanford java
nlp library      unless otherwise stated  we will treat our data set as the combined data set of users read
stories and click through stories 

    naive bayes
naive bayes classification assumes that each feature in our data set is conditionally independent to each
 i 
 i 
 i 
other  that is  for each feature x  i     x    x            xn    which has a given label y  i           we can
assume the following
y
 i 
p  x  i    x y  i    r   
p  xj   xj  y  i    r  
i

apply this assumption to make our hypothesis as followed 
h  x    argmaxr

y
p  x y   r p  y   r 
  argmaxr
p  x   xi  y   r p  y   r  
p  x 
i

in our model  we use the above formula to classify whether a specific user of the application is likely to
read the given story  x   whose title includes words x    x    x          etc  based on the training data  we can
calculate the conditional probability that each of these words occurs in the stories that the user read  y     
and did not read  y       the product of these conditional probabilities times the prior probability gives
each classification its likelihood for x  our hypothesis outputs the class that has the higher corresponding
likelihood 

    logistic regression
the first baseline of our prediction is by using logistic regression to classify our data  this model is the
special case of generalized linear models  glms  for bernoulli variable  the idea is to parameterize our
hypothesis with the sigmoid function 
p  y x       h  x  y     h  x  y   h  x         e

t

x  

 

 

in our case  x represents the stories with title words as their features  h  x  is our hypothesis and the
probability of x being labeled    i e  read   and hence the equation above  we then can use the training
data set to train our parameters  by minimizing the negated log likelihood
l     

n
x

ln     e

t

x i  y  i 

 

i  

which we will use later in part     and    

    l  norm regularized logistic regression
taking our two data sets into account  we minimize a cost function that incorporates logistic regression for
users read stories  logistic regression for users clickthrough stories  and a penalty l  norm of the differences
between r and c found by training logistic regression with read stories and clickthrough stories respectively 
 

fiformally  we want to fit our parameters  to classify whether the users read the stories and whether the users
perform a clickthrough  and thus we want the two s to be a close approximation of each other  thus we
l  regularize our dataset and  can be found  using gradient descent  by minimizing
l     l r     l c       r  c   
where  controls the relative weighting between trying to minimize the first two negated log likelihood and
of ensuring that the parameters found are as close to each other as possible  we chose  to be mallows cp as
it has been demonstrated to be a good regularized parameter that addresses the issues of overfitting which
is our main concern when developing our classifier     

    l  norm regularized logistic regression with lasso algorithm
next  we l  regularize our data set by using the well known lasso algorithm which has shown to be
powerful in solving text categorization problem      we thus find lasso by minimizing
x
l lasso     l     
 j  
j

where    cp again controls the degree of regularization 

    k mean clustering
now  we switch to unsupervised learning by using k mean clustering  specifically we group users and
make predictions based on users being in the same cluster using cosine similarity  now  the chosen k value
is critical as the number of groups can significantly affect the accuracy result  we repeatedly tried various
value of k until we settled with k       this value can also be seen as a rough representation of number of
topics or category in our news 

    collaborative filtering
widely used technique in suggesting news based on other users who have read similar articles  this simple method yet effective have been implemented extensively for example on netflix for movie suggestion and
amazon for product recommendation  it indirectly takes into account a correlation between reading similar
articles between users  though simple  this approach capitalizes on a topic model by a nave assumption that
if two users read something in common in the past  they should read something similar in the future 

  results and conclusions
to compare our testing result  a simple accuracy percentage is useless because our data is very sparse
so that a simple classifier that predicts zero all the time would achieve     accuracy  instead  we measure
our result by comparing its rmse  root mean square error   precision  recall and f measure to get a better
predictive indication  see table    
algorithm
naive bayes
logistic regression
l  norm logistic regression
l  norm logistic regression
k mean clustering
collaborative filtering

rmse
    
    
    
    
    
    

precision
      
      
      
      
      
      

recall
      
      
      
      
      
      

f measure
      
      
      
      
      
      

table    rmse  precision  recall  and f measure for different learning algorithm

surprisingly naive bayes performs better than our simple logistic regression  this is possibly because the
way we incorporate the feed title into our title when we train and test our classifier as this has shown a slight
 

fiimprovement in our algorithms  since feed title does give a good indication of particular topic as some feed
are really specific to one news category   our logistic regression could not take into account the feed title as
well because it merely tries to separate data in the feature space so it does not consider the distinction of
each feed as well as naive bayes  l  norm lr performs a little bit better but again the model suffers from
almost the exact same reason  l  norm however outperforms every algorithm and by far produces the best
result  this makes sense because here we take into account the distinction between users read stories and
click through stories and it turns out that click through stories provide a better indication of what users are
likely to read in the future 
unsupervised learning noticeably produces much worse result than supervised learning algorithms  conceivably  k mean clustering does not produce a good result because there is not really a direct relationship
between tf idf and the group that it belongs to because the feature space we consider does not really
model the topic model even if the cosine similarity implies that they belong to the same group  similarly 
our collaborative filtering uses tf idf to group similar users together but the tf idf does not provide a
good insight about each topic model thus two users reading different topics that contain similar words will
be grouped together  also  because our algorithm only consider a pair of users each time  it is much harder
to come up with a good match with only       users with more than        available stories  the number
of users does not scale well with number of stories 
note that it turns out when we probe through    stories  it already takes too long to crawl the website
and extract the word so we can only use a small subset for testing  only produce a slightly better result than
using stories title and feed as our news representation so we dont consider this approach here since    is too
little to conclude anything 

f measure compared between different learning algorithms

l  norm regularized logistic regression

k mean clustering
 

fif measure plot against the number of training day using l  norm regularized logistic regression  left 
and k mean clustering  right   each black line represents each user for a sample of    users  while the red
line shows the average f measure  some irregular patterns arise because some users read only at the certain
period of a month so increasing the number of training days only changes f measure slightly  for example 
the graph on the left shows that some users read a lot of stories in the beginning  a sharp rise in f measure
which allows us to accurately predict his her top stories later on  these irrigular patterns also show that
our classifiers predictive ability also relies on the structure of the stories each user read because if the users
read randomly  clearly the classifier will perform poorly whereas users who read a lot of repetitive stories will
allow our classifier to perform well  we present here the contrast between two algorithms for comparison and
clearly l  norm regularized logistic regression performs much better than k mean clustering  again  this
is perhaps due to the underlying structure of our feature space that does not correlate well with clustering
algorithm 

  future works
further application of predicting news preferences can be far reaching and significant as this essentially
reduces to a problem of finding preferences and recommending particular group of similar items based on
past input  based on our observation thus far  the model we use did not achieve a considerably practical
result perhaps because it does not directly link words  features  to its actual topic so the next reasonable
step to take is to consider a model that takes topic and word clustering into account  latent dirichlet allocation which gives a topic model that cluster words with similar things can be explored  additionally  we
did not have enough time to incorporate automatic relevance determination     and named entity recognition
which classifies words with similar spelling but different semantic differently based on the context  these
pre processing on the feature space should relate our feature space closer to its actual topic model  based
on our result  it can be seen that some of the output articles contain similar words but these words can have
different meaning so this system can improve our classifier as the best existing ner system  muc    has
shown     recall and     precision with errors lie mostly in the entries that lack obvious english rules or
condition of context      we should also look into how to incorporate our click through data into our classifier
model so that it generates a more meaningful data rather than something similar to read stories as it has
been shown to produce good result with text classification     

  references
   salton  g  and buckley  c          term weighting approaches in automatic text retrieval  information processing and management              
   stanford corenlp tools version               sep      retrieved from
http   nlp stanford edu software corenlp shtml 
   genkin  a   lewis  d  and madigan  d         sparse logistic regression for text categorization 
   tibshirani  r   regression shrinkage and selection via the lasso  journal of the royal statistical society 
series b  methodological                       
   liitiainen  e          automatic relevance determination  in finland  retrieved from
http   www cis hut fi opinnot t         presentations s   presentation elia pdf 
   black w   rinaldi f   and mowatt d   facile  description of the ne system used for muc    department of language engineering umis   retrieved from
http   www nlpir nist gov related projects muc proceedings muc   proceedings facile muc  pdf 
   joachims  t   optimizing search engines using clickthrough data  in  proceedings of the eighth acm
sigkdd international conference on knowledge discovery and data mining  kdd   pp        
       

 

fi