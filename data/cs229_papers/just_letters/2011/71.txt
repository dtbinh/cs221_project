cs      autumn     
modeling the stock market using twitter sentiment analysis
team members  daniel debbini  philippe estin  maxime goutagny
supervisor  mihai surdeanu  with john bauer 
 

introduction

this project is based on bollen  mao and zengs twitter mood predicts the stock market  which
shows that sentiment extracted from twitter tweets can be used efficiently to enhance forecasts on
the direction of stock market moves in the short term      they claim an       accuracy in
predicting stock market moves  up or down   our objective will thus be to implement a trading
mechanism based on twitter data and past stock price time series  and to compare the performance of
twitter enhanced strategies with more traditional algorithmic strategies 
 

data

courtesy of jure lescovic  we have a sample of c      million tweets from june      to december
          each individual tweet is composed of three items  the time stamp of the tweet  the user
who posted the tweet  and the text body of the tweet  further  we have time series data of the dow
jones industrial average  djia   the s p      and individual stock prices during the second half of
      provided by our supervisor  
 

trading strategies

below  we consider three traditional trading strategies 
   x filter rule  if the price closes at least x  up  the strategy consist in opening a long position
 buy  and hold until the price moves down at least x  from a subsequent high  in this case 
you go short  sell  and maintain the short position until the price rises at least x  above a
subsequent low  moves of less than x  in either direction are ignored 
 
   moving average rule  let mat  
   use the strategy to buy if pt   mat and to sell if pt
  
  mat  the optimal l needs to be determined 
   resistance support rule  buy if pt   max  and sell if pt   min   

each of these strategies relies on a parameter  we considered a set of parameters  fit each model to a
training set  djia prices from january      to october       and tested on a test set  djia prices
from november      to december        the results of the best training fit are in the table on the
next page  table     correlation between the training performance and the test performance is low 
this could be due to the non stationarity of the djia process and suggests that we may benefit from
a twitter enhanced strategy using additional information 
table    traditional trading strategies  best fit over training set and test performance 
t r a d i n g   ss t r a t e g y  
p a r a m e t e r   a n n u a l   p
p e r f o r m a n c e    
a n n u a l  
t r a i n i n g  
p e r f o r m a n c e     t
t e s t  
x filter 
      
      
      
moving average 
lag     
       
        
resistance support 
lag     
      
       

fi 

initial attempt

in bollen et al   two sentiment analysis tools are applied to tweets      the first is called
opinionfinder which is designed to identify whether sentences are emotionally positive or negative 
the second is called gpoms  which attempts to measure   mood dimensions  calm  alert  sure  vital 
kind  and happy 
as a first try to capture the sentiment of our tweets  we used alex davies twitter sentiment analysis
word list      for two sentiments  happy and sad  the word list gives the log probability of the word
and the sentiment  more formally  for each word  we have an estimate of 
log    

 

              

then  davies proposes a method for estimating the probability that the tweet is happy given the
words of the tweet  assuming the prior probabilities of each sentiment are equal      see below  
under nave bayes  assuming a tweet t is composed of words w 
    

    
     
 
  
             

                           

    exp  



 

    

     

thus  using the twitter sentiment word list  we can compute the probability of each tweet being
happy or sad using the above formula  we can then threshold this probability to determine if a tweet
is happy  sad  or neutral 
tweets are split into words  or tokenized  by separating white space  in this way  we still preserve
emoticons such as    and     but tokens like happy and happy  are different 
using the strategy above  we parsed the tweets and then performed sentiment analysis using a
threshold of      e g  if p t  happy         classify t as happy   an excerpt of our results is shown in
table    on the next page   it seems using the current word list  we are classifying almost the same
fraction of tweets per day as happy sad  the numbers dont add to      because some tweets are
composed of words not found in our dictionary  and were designated neutral   we also tried using
different thresholds  e g        but the results were extremely similar 
table    sentiment analysis performed on a sample of tweets using alex davies sentiment word
list  showing the djia return and a flag showing whether the market went up  threshold probability 
    

d a t e  

          
          
 

p e r c e n t a g e   p e r c e n t a g e  
o f   h
h a p p y  
o f   ss a d  
t w e e t s  
t w e e t s  
       
       
 

n u m b e r  
o f  
t w e e t s  
   
                  
                     
   

d j i a  
r e t u r n  

       
       
 

fi          
          
          

 

tokenization

       
       
       

      
                
                
                

       
      
       

the first step in extracting better information from twitter was to improve the parsing of tweets  or
tokenization  using advice from christopher potts sentiment tutorial      we improved the
tokenizer by recognizing the following special character strings 










phone numbers
emoticons
html tags  entities
twitter usernames and hashtags
websites
words with hyphens  dashes  apostrophes  or underscores
ellipses
decimals and fractions
words in all capital letters

some of the above special cases are worth discussing below  hashtags in twitter are words
preceded by   which mark keywords or topics in a tweet  words in all capital letters usually
convey heightened emotion  and thus we preserve words in all capital letters 
one final preprocessing step we used per christopher potts was to recognize lengthening by
character repetition      from potts  lengthening is a reliable indicator of heightened emotion
sequences of three or more identical letters in a row are basically unattested in the standard lexicon 
so such sequences are very likely to be lengthening  thus  we mapped sequences of length   or
greater to sequences of length    for example 
yaaaaaaaaaaaay
hahahahahaha
lololololololol

becomes yaaay
becomes hahaha
becomes lololol

we did not shorten punctuation that was lengthened  e g  five multiple exclamation marks in a row
were treated as five distinct tokens  
using a tokenizer with the above competency  we parsed all tweets between july      and december
      the next step is to extract features from these tokens so that we may fit a model to predict
stock market moves 

fi 

feature selection and mutual information

rather than relying on pre trained lexicons  our method aimed at selecting tokens that have impact
on the stock market in a natural and automatic fashion  for each day  we compute the occurrences
of every token over the two previous days  a token is said to have been frequent over the past two
days if it is in the top       occurrences in the past two days  furthermore  for each day we compute
the daily return of the djia  a day is said to have large variation if the absolute djia return on
that day is greater than or equal to     define the indicators 
             large variation 
  



              

we can then compute the mutual information  mi  between xj and y     
     
mi        
     log
    
        

the probabilities in the above formula can be estimated according to their empirical distributions on
the training set 
when fitting models to predict the djia move  up or down  on day i  the feature associated with a
token is the frequency of that token over the past two days  number of occurrences divided by total
number of tokens over the past two days   however  since we have such a large number of tokens 
we will only consider the tokens with the top k mutual information scores  see below for the selection
of k  
 

models and results

using the features described in the previous section  we use both logistic regression and a support
vector machine  svm  to predict the djia move  up or down       the training set was the first   
trading days between june and december       the test set was the last    trading days  for the
svm  we used the gaussian kernel shown below 
      exp 

  
  



  exp    



the only parameter for logistic regression is k  the number of features used  see previous section  
we chose k based on   fold cross validation  k          yielding k       for the svm  the
parameters to fit are   c  and k  gamma    parameterizes the kernel and c is the cost parameter
associated with the regularization of the svm  the results are shown in the below figures and table 
figure    sample tokens used in final svm model  separated by commas        new  cant  win 
amazing  lmao            money  god  facebook  bad  friends   iranelection  summer 
hahaha  news  home  business  love  job  times  game  off  nice  stop 
we see on the graph at the right that on the test set  nov  dec        the logistic regression strategy
is superimposed with the dow jones  while the svm strategy performs better 

fifigure    performance of svm and logistic regression models
   
   

table    performance
t e s t   ss e t     
 
 
 
t r a i n   t e s t   a n n u a l i z e d  
 
e r r o r   e r r o r  
r e t u r n  
 svm       
     
    
l r  
     
     
    
 

   
   

   
   
   
  

dow  jones
svm
logistic  r eg 

  

conclusions and future work

twitter is a treasure trove of information  with millions of users posting tweets every second  there
are opportunities to capture public sentiment confidence anxiety  while the svm performance     
accuracy on the test set  is not as impressive as in bollen et al       the annualized performance of the
svm is strong      annualized return   the number of tokens used in the model      is reasonable 
it is yet to be determined if our accuracy can be sustained over a longer period  our test set is larger
than bollen et al s one  two months against    days  but the significance of the results would benefit
from being extended to at least a year  moreover  the dow jones performed well in the second half of
      the strategy should be tested in stress times as well  we hope our framework can be extended
to make more complex predictions about the djia instead of a binary up down decision  using
softmax regression and or a multi class svm  furthermore  we wish to integrate the twitter data
with other more traditional statistical features into one model  e g  contrarian strategies with twitter
information   additionally  work needs to be done to analyze the effect of transaction costs and
mistiming of trade execution  e g  we may not be able to buy the djia during the open at yesterdays
closing price  
 
   
   
   
   
   
   

references
bollen  mao  and zeng  twitter mood predicts the stock market  journal of computational
science         march      
j  leskovec  j  yang  temporal variation in online media  acm international conference
on web search and data mining  wsdm            
alex davies  a word list for sentiment analysis of twitter  web     november     
 http   alexdavies net         word lists for sentiment analysis of twitter   
christopher potts  sentiment symposium tutorial  web     november      
 http   sentiment christopherpotts net  
andrew ng  cs    lecure notes  regularization and model selection  web     december
       http   cs    stanford edu notes cs    notes  pdf  
chang  chih chung and lin  chih jen  libsvm  a library for support vector machines 
web     december        http   www csie ntu edu tw  cjlin libsvm   

fi