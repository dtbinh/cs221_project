what it takes to win 
a machine learning analysis of the college football box score
john hamann
most advanced analysis of sports focus on predicting the results for the next game based on the results of previous
games  for college football  the value of prediction extends beyond gambling due to the post season format 
college football has a large number of teams that play very few games  and this sparsity causes interesting
problems for quantitative analysis  in addition college football is the only sport in the world in which six
computer algorithms help determine who plays for the national championship    
past stanford projects have focused on using regular season games to predict the bowl games     predicting bowl
games is particularly difficult  because bowl games occur four weeks after any other game  occur between
relatively well matched teams  and occur between teams in different conferences  another project focused on
betting against the spread     betting against the spread is difficult  because the spread is set by professionals who
have a financial interest in understanding college football by any means including advanced statistical techniques 
the computer rankings at the heart of the bcs also operate fairly efficiently as predictors with a     success rate
in all games and a     success rate in games expected to be close    
this project goes in a different direction and decides to take an a posteriori approach to college football  the
analysis looks at the box score  statistical information  for an individual game without respect to any other games
or outside factors  team rankings  past performance  home field advantage  and predicts who won the game  how
much underlying variance remains even if you know as much as possible about what happened in the game except
the score  the difference between this approach and past approaches is the difference between estimating the
current symbol from a noisy observation  n xn   and predicting the next symbol based on the past  n yn   xn    
the data set
this project was inspired by the ungodly amount of college football data posted on a blog     the data set is
humongous with every game from            the      games since      have    box score stats apiece for the
home team and visiting team  many of these statistics can indirectly give you the final score  points per play 
rushing touchdowns  safeties  field goals  and extra point attempts  and need to be removed  the second cut
removes duplicates such as receiving yards which is the same as passing yards  the third step is to trim some of
the more esoteric data such as punt return yardage  kickoff return yardage  fumble return yardage  and yards per
punt  this step tosses some very good information because the stats are difficult to handle intelligently  for
example      punt return yards on   punts strongly implies that the punt returner either scored or got very close to
the goal line which is valuable 
this led to the trimmed feature set  this trimmed feature set was still a little unwieldy for the machine learning
algorithms  the final feature set removed features that could be derived from other features and features where
the additional information was small  when evaluating the algorithms  some of these features were added back in 
but they did not significantly improve performance  the final feature set had    features that can be found for any
football game and capture the core of the game  rush yardage  pass yardage  rushing attempts  pass attempts  pass
completions  first downs  punts  penalties  fumbles and interceptions 
algorithms and results
the problem as stated is relatively straight forward  it is a binary classification problem with    features per team 
for this project i applied some of the simpler machine learning algorithms to this problem to see how well the box
score predicts who won the game  where necessary  the classifiers set aside     randomly for training and    
for testing  since the feature set is drawn from a single game rather than cumulative season totals  causality is not

fia problem  and the games can be drawn independently across all weeks and seasons  for this problem  the data set
was large enough that over fitting was not an issue  table   shows the error rates for the various algorithms 
turnover margin classifier
the turnover margin classifier says that the team who had
the fewest turnovers won the game  if both teams had the
same number of turnovers  then the team with the most
yardage won the game  this incredibly simple classifier
correctly identified the winner     of the time suggesting
that turnovers are a major factor in the outcome of a
football game 

algorithm
error rate
turnover margin classifier
     
handpicked weights
     
nearest neighbor
     
nave bayes
     
logistic regression
     
perceptron algorithm
     
table    algorithm error rates

handpicked weights classifier
the simple weights classifier used weights guessed by hand to predict who would win the game  it applies the
weights to the difference between the stats of team a and team b  the same weights are applied to both team a
and team b  since the outcome should be symmetric  for this project there is no intercept term  since it is a zero
sum game  it is guaranteed that half will win and half will lose  this simple weight with no additional tweaking
led to an     error rate 
 
nearest neighbor
i ran the standard nearest neighbor algorithm for a variety of distance measures and values of k  euclidean
distance between normalized features and majority vote of the    nearest neighbors gave     error 
nave bayes
nave bayes had an error rate of about      for a few of the features  such as yardage  where the number of
possible values was large  i discretized to a smaller number of bins 
logistic regression
i ran standard logistic regression with adaptive gradient descent to solve for better weights than those i picked by
hand  the value of  was decremented by an order of magnitude every       iterations starting at       and
ending at           this converged to a set of weights with     error 
perceptron algorithm
the perceptron algorithm ran under the same problem set up as logistic regression with a hard decision rather than
the soft decision allowed by the sigmoid function  the algorithm normalized the weights after each iteration for
slightly better performance  once again the value of  was decremented by an order of magnitude every      
iterations starting at       and ending at           this led to an error of     
evaluation of classifier results
the logistic regression and perceptron algorithm converged to similar values for the weights  table   shows the
weights that the perceptron algorithm derived and applies them to the box score of the      rose bowl national
championship game between texas and usc  texas outperformed the trojans in all but net passing yardage
with the lone usc interception being the primary difference in the game 
the final numbers give an error of about      there are certainly more advanced machine learning algorithms
that may give better results  however  the window for improvement is not particularly large  and i expect that
advanced algorithms will not offer a major advantage  this section evaluates what the resulting classifiers imply
about what it takes to win football games 

fifeature
net rushing yards
net passing yards
rushing attempts
pass attempts
pass completions
first downs
number of punts
number of penalties
fumbles lost
interceptions thrown

weights
texas
        
   
        
   
         
  
         
  
        
  
        
  
         
 
         
 
         
 
         
 

usc
   
   
  
  
  
  
 
 
 
 

texas
       
       
        
        
       
       
        
        
        
       

        
classifier  texas
  
result  texas
table    sample box score and classification

usc
       
       
        
        
       
       
        
        
        
        
        
  

since the error rate was      this means that what happens in between the goal lines provides a fairly accurate
observation of the final result  if the statistics collected did not lead to a good prediction of the final result  then
that would suggest the game has significant latent randomness and that more descriptive statistics are needed 
the weights conform very nicely to conventional football wisdom  and both methods converged to very similar
values  table   gives the weights for both algorithms and the weights for when first downs were removed from
the list of features  the most important fact is that turnovers are incredibly costly  an interception is worth
approximately     passing yards  punting is about half as costly as a turnover  penalties are a surprisingly
negligible component of the statistics 
the value of a yard is the same whether it is passing or rushing  the difference is that a pass has a higher
risk reward component since passes frequently fall incomplete for zero yards  the weights can also verify whether
a single play or sequence of plays was successful  for example a   yard rush on third down leads to a first down
and increases the net margin over the other team by        an unsuccessful rush on third down and subsequent
punt decreases the net margin over the other team by       

net rushing yards

perceptron
algorithm
        

logistic
regression
        

perceptron without
first downs
        

net passing yards

        

        

        

rushing attempts

         

         

         

pass attempts

         

         

         

pass completions

        

        

        

first downs

        

        

n a

number of punts

         

         

         

number of penalties

         

         

         

fumbles lost

         

         

         

interceptions thrown

         

         

         

table    weights for various algorithms and feature sets

when first downs are removed from a feature set  it is easy to calculate the number of yards needed for an average
rusher or passer to increase the margin over his opponents if you ignore the costs of turnovers and penalties  if
first downs are included  then each run has a potential to be a first down depending on the situation  so the

ficalculus becomes more difficult  the      yards per carry average agrees with conventional wisdom that a
running back needs to average   yards per carry to be successful  the      yards per passing attempt also agrees
with conventional wisdom of what a quarterback needs to achieve to be considered successful  these numbers
allow one to evaluate the performance of running backs and quarterbacks 
 

 

 

 

 

 

 

 

 

 

 

 

 

 

evaluation of errors
there are a couple of possible explanations for where the     error rate comes from  part of the     may be due
to luck in realms that we are not allowed to see  for example  the difference in a game between two perfectly
matched teams may be a missed    yard field goal  another part of the error may be due to extrinsic data about
the game and the teams involved such as home field advantage and talent level  the classifier does provide a
method to say which team statistically played better and compare that to who actually won the game 
the misclassification errors are scattered fairly uniformly across games  figures     illustrate that the error rate is
relatively consistent across weeks  years and conferences  figure   shows that when the game was competitive
 margin of victory was small  the classifier made a lot of mistakes  as the margin of victory increases  the games
become less competitive statistically  and the classifier makes fewer mistakes  figure   shows that errors increase
slightly as time passes perhaps due to the fact that conference play is more evenly matched and competitive 

figures      probability of error given season  week  conference and margin of victory

fiif one team is more skilled than another  then it seems reasonable that they would be more likely to win close
games  table   shows the probability that team a beat team b given that team a outplayed team b
statistically  even if an fcs team has a better statistical outing and outplays a bcs team  they still only win    
of the time  this compares poorly to the expected     record  this gap could be due to the differing levels in
talent  coaching or home field advantage  table   shows the value of home field  when the home team plays
better than the visiting team  they win     of the time  when the visiting team plays better than the home team 
they only win     of the time  as might be expected  playing a close game at home is a significant advantage 
team b

team a

bcs
bcs
mid major
  aa fcs

mid major

  aa fcs

better team

accuracy

      

      

home

      

      
      
      
      
table    talent disparity

      
n a

neutral

      

away

      

      

table    home field advantage

conclusion
the non scoring statistics do a remarkable jump of capturing who won a football game  with    basic features for
both sides  a football fan can predict who won the game with     accuracy  most of the errors occur in the very
close games where it is difficult to state with certainty which team had the better game  the accuracy is
remarkably consistent over weeks  seasons  and conference  home field advantage allows home teams a better
chance to win the game despite being outplayed  teams in bcs conferences have better talent and coaching
which may explain why they perform better at closing out games against lesser opponents and winning games in
which they were outplayed 
the weights in the linear classifiers offer some insight into what wins football games  offensive turnovers can
only be overcome by forcing defensive turnovers or through complete domination in other facets of the game 
yardage counted the same no matter where it came from  the difference between rushing and passing is due to the
mechanisms of attempts and completions  testing with additional statistics provided very little gain in
performance  but there were a few statistics that were not included  sacks  tackles for loss  quarterback hurries 
and passes broken up are a few defensive statistics that might be useful 
the weights may have some value in predicting future games  they can provide a quick way to incorporate a
variety of features into a single number  i tested a quick predictor which applied the weights to the cumulative
season statistics and had     accuracy on the back half of games for the      season 
while prediction has value for fans and bettors  post game classification has value for coaches and players  the
weights allow coaches to examine the performance of the passing offense separately from the performance of the
running game  defenses can be compared across teams with a more efficient measure than yards allowed  this
project has shown that the non scoring statistics in football have a high descriptive capability of who won the
game 
references
    the bcs formula   http   www bcsknowhow com bcs formula 
    a better bcs  rahul agrawal  sonia bhaskar and mark stefanski   cs     fall      
    beating the ncaa football point spread  brian liu and patrick lai   cs     fall      
    the bcs system  rate not  lest ye be rated  tom brennan   posted             
  http   barkingcarnival fantake com            the bcs system rate not lest ye be rated  
    an ungodly amount of college football data   updated            
 http   thenationalchampionshipissue blogspot com         ungodly amount of football data html  

fi