box office prediction for upcoming films 
final report 
ruixue yanlinchen

  introduction 
in this project  we apply machine learning algorithms including multiclass nave
bayes and svm to predict box office for movies  in our model  the predicting problem is
converted into a multiclass classification problem rather than predicting the exact value
of box office  firstly  we collect movie information from the internet  and use nave
bayes as our prototype model for training and testing data  given the feedback  we
improve our feature selection by varying the training data size  lastly  we compare two
different techniques  nave bayes and svm  giving birth to the final feature and model 
the method and results are detailed in the following sections 

  data collection and feature generation  
    how we get the original data  
we write some python script to grab all the us film information from      to     
from internet movie database  a k a  imdb  http   www imdb com   and there are more
than       films and only around     films have some box office income  so we choose
those     films as our training   testing set 

    features for upcoming films 
from the imdb  for each film  there are a lot of features  but for an upcoming film 
the number of features is quite limited  here are the features we choose 
important features  director  writer  actors  genre  release date  estimated box
office  yes  there is estimated box office  but it has never got the correct estimation  
production company 
less important features  title  aspect ratio  color company  duration  language 
filming location  sound 
useless features  meta score  news count  photo count  rating  rating count 
review count  video count 
the useless features are mainly because it is either untreatable  e g  rating and
reviews  or they are hard to get as training data  for example  it is impossible to know the
news count before the film the social network was released now  so we will not use
the useless features in our machine learning progress 

    feature generation 
the types of the input features include contiguous values and discrete values  the
main idea is to reduce the number of values for each feature  and we also drop some of
the features that all the films almost share the same value  such as color company and
aspect ratio 
here is the table of each feature input and how we generate final training   testing
features 

fifeature

type

number
of values

how to reduce
number of value

the

directors
writers
actors
production
company

discrete
discrete
discrete
discrete

    
    
     
    

use the number of
google search result to
classify how famous this
name is 
 famous  normal  not
famous 

genre
release date

discrete
discrete

  
       

estimated box

contiguous

infinite

duration

contiguous

    

final output
number of
values
 

we use months  jan dec 
 same as box office
classification in part   
 very long  long  normal 
short  very short 

 
  
  
  
 

note  we merge the directors  writers and actors to be the names feature to reduce the number of
features 

  method 
to solve this classification problem  we consider using two major method including
   multiclass nave bayes and    multiclass svm 

    multiclass nave bayes  
d class nave bayes have the similar model as the binary one 

arg max  j   p   x   y      p   y  yi     y    y    y        yd  
j
n

yi

we apply the multiclass nave bayes algorithm with laplace smoothing to train the
data  and obtain the parameters using maximum likelihood estimates as the following
formula 

yl    y    y        yd     tk   y  y

l

    x

  y
m

nti

i  

j  
m

 i  
tj

 i  

i  

where t indicates the t

th

 k  y  i    yl    

 yl  nti  vt

type of feature  each feature has k dimensions and vt is the

th

dimension of t feature  and similar to binary nave bayes 

y y

l




m

   y   i    yl  

i  

m

    svm 
super vector machine is inherently binary classifier  however  it can be extended for
multi class classification  the two major strategies   one against all  and  one against
one   both try to decompose the multi class problem into several two class sub problems 
and use standard svm to solve each binary problem  with the result from the paper by
c  w  hsu and c  j  lin        we choose one against one to decompose our problem 
assume that we have k classes  the one against one method constructs k k     

ficlassifiers  each of which is trained on data from two classes  say the ith and the jth class
is chosen to construct the svm  then we have to solve the following problem 
m
  ij t ij
w
w

c
 tij
min
 
 

wij  bij   ij  
t  

s t 

  w ij  t    xt    bij      tij   if yt  i 
  w ij  t    xt    bij      tij   if yt  j 

 tij     for i         m
where the training example is   x i   y i    i        m   the kernel is used to transform data
from the input sample to the feature space by kernel function k xi  xj   xi t  xi  
there four common kernel options 
xi t x j  
linear
 t
d
polynomial
  x i x j      
k  x i   x j    
 
radial basis function
exp   x i  x j        
 tanh  x t x  c    for some     and c     sigmoid
i
j


in our model  linear kernel has lower test error rate that any other three common
kernels  so linear kernel is used 

  feature selection 
    models 
our feature dimension is now reduced to    degrees as model i  the features are
from directors  actors  writers  company  duration  estimated budget  genre and release
date  firstly  we reconsider the discretization of release date  we reduce the discrete value
for release data from years and months to   seasons  meanwhile reduce the duration
bucket from   to    obtaining the feature with degree of    as model ii 
we have the model iii with a feature degree of    which does even have movie
duration as our feature  lastly  we have model iv with a feature degree of    that reduce
the release to date to only two values  hot time or not hot time  plus reduce the number of
bucket for estimated budget 

    cross validation 
our data sets      movies  are divided into training and test set with each percentage
    and     correspondingly  by using cross validation  we not only experiment on the
four models to compare them with each other for feature selection  but also compare
multiclass nave bayes and multiclass svm 

    estimated box office classification 
in our experiment  we are solving ten classes classification problem  the ten buckets
of estimating the box office is listed in the following figure 

fi    k

    k

  m

  m

  m

   m

   m

   m

    m

    m



    error evaluation 
the original error is   h x     y   this function needs to be improved  if the actual
box office is             then error of a prediction of             is very different from
a prediction of             in calculating error  we only allow one class mismatch  for
example  if the real value is between  m  m  then we think the following three classes
are all proper estimation  no error      k  m   m  m and  m  m 

  results 

training size
test error
training error

model i  feature    
multiclass nave bayes
multiclass svm
  
   
   
   
  
   
   
   
                                                       
                                                   

training size
test error
training error

model ii  feature    
multiclass nave bayes
  
   
   
   
  
                                  
                           
     

multiclass svm
   
   
   
                    
                   

training size
test error
training error

model iii  feature    
multiclass nave bayes
  
   
   
   
  
                                  
                           
     

multiclass svm
   
   
   
                    
                   

training size
test error
training error

model iv  feature    
multiclass nave bayes
  
   
   
   
  
                                  
                           
     

multiclass svm
   
   
   
                    
                   

from the four tables  we can draw the conclusion that model ii overcomes with the
rest three in generalizing the test error rate  secondly  svm often produces a better
estimation that nave bayes 

fimulticlassnavebayes

multiclasssvm
   

   

   
testerrorrate

   

testerrorrate

   
   
   
   
   

   

modeli

   

modelii

   

modeliii

   

modeliv

   

   

   
 

   

   

   

   

 

   

trainingsize

   

   

   

trainingsize

the above two figures clearly illustrate our choice  model ii and svm as our
multiclass classifier  the final feature list 
feature type

no  of values

possible discrete values

actor director writer popularity
company value
release date
genre
estimated budget
duration

 
 
 
  
  
 

high  medium   low
high  medium  low
spring  summer  fall  winter
action  adventure        western
   k      m
long  medium  short

  prediction for upcoming films  in us    

moviename
thegirlwiththedragontatoo
mission impossibleghostprotocol
theadventuresoftintin
thedarkesthour

predictionusingnavebayes
    million
    million
    million
  million  million

predictionusingsvm
 million million
    million
 million million
  million  million


andletsseehowourpredictionworks 


  acknowledgements 
we gratefully acknowledge professor andrew ng and tas of cs     s instructions and
assistance in our project  we also acknowledge c c  chang andc j  li for using their
libsvm 


fi