interpreting american sign language with kinect
frank huang and sandy huang
december         

 

introduction

accurate and real time machine translation of sign language has the potential to significantly improve communication between hearing impaired people and those who do not
understand sign language  previous research studies on computer recognition of sign language have taken input from technology including motion capturing gloves and computer
vision combined with colored gloves  these projects commonly apply hidden markov
models or neural network systems     
we created a system that recognizes american sign language  asl  using the microsoft
kinect sensor  in particular its skeletal tracker  such a system has the additional benefit of
extending the kinect to be a platform for people to learn and practice sign language  the
kinect sensor is an exciting device to use for human gestural applications because of its
ease of use  it does not require gloves or special markers for tracking  it does not require
a background image or room calibration  it works well even in low lighting  and it is also
quite inexpensive 
we were able to train a single sign recognizer to recognize ten asl signs with a crossvalidation accuracy of      using libsvm      we also developed a basic way to segment
a sequence of signs  in order to translate an entire sign sequence 

 
   

methodology
training data

we recorded training data for    different asl signs with the kinect sensor  using the
microsoft skeletal tracking solution  training data is in the form of pre segmented single
signs  we have about     training examples     each from two people  for each of the
ten signs  baby  day  drive car  i me  past  now  sleep  tonight  wash 
 

fiand with  the signs we chose involve arm movements  rather than individual finger
movements  since the kinect sensor does not resolve the hands or fingers clearly at typical
skeletal tracking distances    ft      
for each sign in our training set  a sequence of skeleton frames  composed of    joint
positions per frame  defined by x  y  and depth coordinates  is saved  each signs frame
sequence contains on average    frames  making for around        frames in total  joints
are normalized relative to the hipcenter joint  their positions are relative to that joint 
while the hipcenter joints position is absolute  data is captured at    fps  although
frame skipping sometimes occurs due to processing load 

   

single sign classification

our single sign classifier takes as its input a sequence of frames that compose a single sign
already segmented out of a full sequence  and predicts which sign it is  to achieve this  we
first train an svm  using libsvm  on the individual frames of the training data  e g  a
drive sequence becomes around    frames which are all labeled drive   using a set of
frame dependent features determined by feature selection  when the classifier is asked to
predict on a test sequence  it classifies each frame separately  the result is then selected
by simple majority  the classification with the most frames assigned to it 
we pre processed the individual input frames into feature vectors suitable for entry into
libsvm  creating a library of almost     features that includes 
  x  y  depth  of  right  left   hand  wrist  elbow  shoulder  position
  x  y  depth  of separation between right and left  hand  wrist      
  x  y  depth  of  right  left   hand  wrist       velocity  computed from neighboring
frames 
for example  one specific feature was the x coordinate of the right hand position  for
improved accuracy  we selected a subset of features from this set by running an automated
feature selection process  using filter feature selection      since our feature values were continuous  we elected to use the correlation between feature values and class labels for feature
selection  in order to fit this multi class case  for each feature we computed    correlation
values  its correlation with each of the    class labels  we then computed the variance of
this set of values and picked the k features with the highest correlation variance  the
intuition being that these features capture the differences between the labels 
to select k for the above process  we used model selection by running    fold crossvalidation using the top k features  varying k  ultimately we found that k      gave
the best classification performance  figure    

 

fifigure    frame classification accuracy for varying values of k 

   

segmenter

we also worked on a system to solve the second problem in real time recognition  segmentation  after some experimentation  we decided to use the following approach  the
segmenter keeps track of a sliding window of k frames  through experimentation  we chose
k        as frames are read from the input stream  the segmenter runs the svm classifier
on each frame to produce a frame label  the sliding window contains the last k frames
seen  and the simple majority of these k labels is taken  if the majority label changes  the
segmenter reports that a new sign has begun 

 

results

our single sign classifier achieves sign classification accuracy of     on pre segmented
signs when running    fold cross validation on our training data  as mentioned  sign
classification involves running the classifier on each individual frame of the sign sequence 
and then taking the simple majority of the class labels to determine the overall label for
the sign  the accuracy of our model in classifying individual frames was about     
some of the top features selected by feature selection included 
 r wristl elbow depth difference     other similar differences 
 r wrist depth position     
 r wristl shoulder depth difference     

 

fi r wristl hand y difference     
 l hand x position
we chose the following sign sequences to test our segmenter  i wash baby tonight  i
wash car past  today i drive with baby  and i sleep now   note  today in asl is
signed by now followed by day   these sequences cover all ten signs  our approach to
segmentation produced recognizable but noisy results  i e  the classifier reported incorrect
signs between the ground truth signs   even after some filtering in the segmenter 
ignoring the first few frames in the input  not allowing for segmented sequences that are
too short  and so forth  there was still a considerable amount of noise in the segmenter
output  we conclude that a more sophisticated segmentation approach would be necessary
to achieve realistic accuracy for a real time sign language translator 

figure    confusion matrix generated from cross validation of frame classification with
svm  the left axis corresponds to indices of correct labels  and the right axis to indices of
predicted labels  the mapping from label to index is as as follows  past     wash    
tonight     sleep     baby     now     with     drive     me     day   
based on the confusion matrix generated from cross validation of the svm classifier  figure

 

fi    we found the signs now and with were frequently mis classified as drive  in the
future  features describing the correlation of joint velocities  e g  whether two joints are
both traveling in the same direction  will likely reduce this mislabeling 

 

conclusion

the high accuracy of our single sign classifier shows it is possible to classify asl signs
with only joint position data  many asl signs involve gestures using the arms  and the
kinect is designed to capture large body movements such as these  however  using skeletal
data from the kinect to recognize signs has limitations  in particular  the inability of the
kinect to detect hand shapes and finger movements makes it difficult to interpret certain
asl signs  especially letters  which involve small and subtle finger motions 
our greatest challenge was solving the segmentation problem  similarly to speech  asl is
not signed with obvious pauses in between signs  nor do fluent signers return to an easilyrecognizableneutral pose in between signs  consequently  to people unfamiliar with asl 
it can be difficult to recognize where one sign ends and another begins  in order for our
asl recognizer to be effective in real time  it will need to be able to segment a series of
signs 
the advantage of using the kinect rather than other technology to capture signs is that
such a system has the additional benefit of extending the kinect to be a platform for people
to learn and practice sign language 

 

references

    parton  b  s          sign language recognition and translation  a multidisciplined approach from the field of artificial intelligence  journal of deaf studies and deaf education 
               
    chang  c  c     lin  c  j          libsvm  a library for support vector machines 
acm transactions on intelligent systems and technology                    
    yin poole  w          source  ms quadrupling kinect accuracy  eurogamer  retrieved
from http   www eurogamer net articles            source ms quadrupling kinect accuracy
    ng  a          cs     lecture notes  regularization and model selection  cs     machine learning  retrieved from http   cs    stanford edu notes cs    notes  pdf

 

fi