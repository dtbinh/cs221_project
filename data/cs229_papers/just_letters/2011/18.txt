klearn  stochastic optimization applied to simulated robot actions
final report
kevin watts
willow garage
menlo park  ca
watts willowgarage com

abstract
machine learning techniques and algorithms are prevalent in robotics  and have been used for computer vision 
grasping  and legged walking  reinforcement learning approaches have been developed over the past    years  with
modern techniques using continuous action spaces for various robotic applications  policy gradient learning allows
various optimization techniques to quickly optimize robotic
tasks  but gradient based optimization can suffer from problems with stochastic objective functions  klearn uses a
stochastic optimization system to optimize the mean of the
objective function  the optimization algorithm is applied to
a simulated robot 

   introduction
reinforcement learing  rl  has been used to control
robot actions and teach robot behaviors for tasks such as
walking        playing pool and grasping  one approach
to optimizing various robotic behaviours is to use policygradient learning  using gradient ascent to optimize a value
function in policy space  for systems with stochastic output  it can be difficult or impossible to correctly determine a
gradient  in this project  i have developed a novel stochastic
optimizer which can be applied to reinforcement learning
and applied it to an application with a simulated robot 
a stochastic optimization system has many uses in reinforcement learning  some robotics applications may have
process noise or unmodeled variables  in other cases  the
observations may be noisy  for this problem  numerical stability in the robotics simulator introduces process noise into
the system  optimization methods designed for deterministic systems  such as the conjugate gradient method  do not
converge for this problem  using an optimization algorithm
designed for stochastic inputs allows us to avoid sampling
our objective function many times to find an average estimate of the value 

the stochastic optimization system has been applied to
the example problem of rolling a ball across a table using
a simulated pr  robot  figure     the remainder of this
paper describes prior work in reinforcement learning and
stochastic optimization  system architechure  the optimization algorithm  and the application results 

   prior work
reinforcement learning traditionally describes an agent
attempting maximize a value or reward function by choosing actions  the environment or world can be represented as
discrete states  with a markov process controlling transition
probabilities between different states  research areas can
include exploration versus exploitation tradeoffs and value
function convergence     
more recent reinforcement learning work involving
robots has combined learning from demonstration and reinforcement learning to teach new tasks to robots  the reinforcement learning framework no longer uses discrete state
spaces  but may use policy gradient learning        recent
work  from iros       uses previous sensor data as direct
feedback to robot commands  allowing for robust grasping

figure    pr  ready to roll a ball in a simulated world  re running
the simulation with identical control inputs can give very different
results 

fiin the prescence of poor object detection     
stochastic function optimization has been studied by
many authors since the     s        in       robbins and
monro introduced a root finding algorithm for the expected
value of a stochastic function        they proved convergence  with a given probability  for a bounded  monotonic 
differentiable function  and used a decreasing step size 
later authors noted improved convergence by changing the
learing rate      
in       kiefer and wolfowitz introduced a method for
optimizing stochastic functions that used a gradient method
to optimize        like robbins and monro  it used a learning rate that slowly anneals  kiefer and wolfowitz proved
convergence of their algorithm for a concave function with
a unique maximum 
for this project  i chose not to use the kiefer wolfowitz
algorithm because i wanted to try an algorithm that used
variance information from neighboring points  and use expected improvement  or more than just mean estimation  to
determine the next sample point  future work in this area
could compare a kiefer wolfowitz approach with the optimization algorithm used in this project 
an algorithm we studied in class  stochastic gradient
descent        would not be appropriate for this application 
stochastic gradient descent uses the approximate gradient
for each training sample to approach an optimum value  although that may give interesting results for this problem 
it could also be confused by function noise from a single
function evaluation  an approach that may be promising is
modifying the algorithm to use a small subset of training
data  instead of a single sample  or to account for a likelihood based on the estimated variance of the function 

   stochastic optimizer
optimization algorithms like the conjugate gradient
method do not converge for stochastic functions  as a replacement  im using a novel stochastic optimization algorithm  in designing this algorithm  i assumed that my function had random output independent of parameters  but that
neighboring points would be close in value to their neighbors 
repeat
sample values around point p
for pi near p do
evaluate function at point
end for
for pi near p do
calculate expected improvement
end for
set p to pi with best expected improvement
until converged

values around point p are chosen using all  n points
which are  away from p along the coordinate axes 
therefore we have  n     function evaluations for each iteration  in this implementation  i allow the function to be
evaluated multiple times at a single point  multiple evaluations give us more confidence in our mean and variance
estimates 

     expected improvement
to calculate the expected improvement near any point  i
use the sample mean and variance of the function near that
point and calculate the expected improvement by assuming
a gaussian distribution  similar to the gaussian processes
method of frean and boyle       equation   gives us the
expected improvement at a point pi above value v given the
mean and variance of our equation at that point 

u  


 



 

ei

 

v

u
 
erf           
 
 
 
u 
 exp   
 
 
 u    

   

     mean and variance
mean and variance are calculated at the point p using
the weighted average point all function evaluations at that
point  with neighboring points weighted less  variance is
 
averaged with a high base variance  base
  which penalizes having few samples of a function at a particular point
 this value must be set higher than the function variance  
the weight of the base variance versus the sample variance
is determined by   and  determines the relative weight of
the nearby samples when calculating our sample mean and
variance  see equation   
for this problem   was set so points  away from our
test point counted half as much as samples at the point  and
 was set such that   samples at a point gave a variance
weighted evenly between the base variance and the sample
variance 

fi 
       pi  p     
pm
w i xi
pi  
  
m
wi
pmi  
w  x    
 
i  
pmi i
local
 
i   wi
m
x
 
wlocal   exp 
wi  
 i  
wi

 

 

 
 
  wlocal base
      wlocal  local

   

     termination
the algorithm terminates when one of the following conditions are met 

figure    quadratic function with added gaussian noise 

max iterations configured through a user specified max
functions parameter 
no improvement neighboring points do not have better
expected improvement than our starting point 
similar values using the kullbeck leibler divergence 
the observed mean and variance of p and the last value
of p are compared to see if we have plateaued 
this stochastic function optimizer conducts a local
search  so it can get stuck in a local minimum  one significant downside to this optimizer is that it travels slowly
from test point to test point  only moving by  each time 
if the optimizer was modified to use gradient information
to jump farther to the next test point  it could converge
faster  this is an opportunity for future work 

figure    optimizer function evaluations for stochastic quadratic 
optimizer path is in blue  green points are evaluated when neighboring points are checked  function level curves are in red 

     sample optimization problem
the optimizer was applied to a sample optimization
project for verification  in this case  the utility function
was a two dimensional quadratic bowl  with gaussian noise
added  the unmodified quadratic is quite easy to optimize 
from figure    we can see the optimizer starts out at
       and approaches the origin  the optimization algorithem does not reach the true minimum  since it is confused
by function noise  in this case  the difference between the
final value and the true minimum is one quarter of the standard deviation of the noise 

   simulation system architecture
klearn uses the gazebo        robot simulator to model
the willow garage pr  robot  the gazebo robot simulator
provides instrumentation for the the world  so the algorithm
can use ground truth information about object pose and velocity data directly in the utility function 

the pr  robot is almost fully simulated in gazebo 
mechanism kinematics and dynamics data are taken directly
from design documents  and all cameras and laser sensors
are simulated  at a    hz physics update rate  the simulator can get relatively good convergence for simple rigid
body dynamics  such as grasping a cup on a table 
the simulated world has a ball resting on a table  directly
in front of the simulated robot  the ball mass is    kg 
compared with roughly    kg for the simulated pr   the
robots arm is commanded to stay fixed during ball contact 
when using the simulator  function noise comes from
numerical instability and timing jitter  despite hours of
work and significant experience with the simulator  i was
not able to eliminate the process noise from the system 
the optimization framework optimized the robot actions
in the simulator  the optimizer was written in python  and
ros was used for interprocess communication 

fifigure    utility function visuals for ball trajectory 

figure    optimizer utility with each iteration  green points are
all function evaluations  including gradient points around our test
point  blue line is function evaluations at each test point 

   robot learning approach
the optimizer was applied to a simulated robot pushing
a ball across a table  the robot was commanded to push
the ball by only moving the base of the robot  with the arm
holding still  the simulation environment was reset after
every trial 
robot velocity commands were sent every    ms for
   time slices  robot velocity commands were bounded
to    m s  which is the maximum allowable speed of the
pr   velocity commands were only sent for the forward direction  the initial base velocity was    m s for every time
slice  slowing down by    m s per slice for the last three
slices 
penalty utility output description 
hitting the table hitting the table with the robot will
cause a significant penalty  making any parameters that
cause the robot to hit the table infeasible 
ball trajectory angle the angle of the ball trajectory
from straight 

figure    optimized policy and the initial policy for robot base
trajectory 

   conclusion
this project demonstrated the application of a stochastic optimization algorithm to a simulated robot application 
the optimizer works for noisy     dimensional systems 
the stochastic optimization algorithm almost doubles the
achieved utility in the simulated robot application 

     future work
ball velocity utility function increased with ball velocity
forward 

   results
as we can see in figure    the optimizer evaluated the
function over     times  at    function evaluations per iteration  for checking neighboring points   this works out to
over    cycles through our optimizer main loop  for our   
dimensional problem  this is less than  n iterations and   n
evaluations 
our optimized policy  in figure    shows that the robots
base velocity reaches the maximum of    m s at timestep
   right at ball contact  the policy then ramps down the
robot velocity quickly  to avoid hitting the table 

future work can involve improvements to the optimizer 
one possible improvement to this algorithm  not explored
here  is to iterate the optimizer many times near the optimal
point to get better estimates for mean and variance  this
can help reduce tail risk in any optimized solution  solutions near an optimum may also be near a constraint  and
for some applications it can be important to guarantee  to
with some probability  that the solution will be feasible or
within some range 
the optimization algorithm in this problem works for
the examples of the stochastic quadratic and the simulated
robot  it would be worth comparing the algorithm to that
method of keifer wolfowitz  or similar modern methods 
applying a learning rate to vary the step size  used in the
keifer worfowitz algorithm  could improve convergence

fidramatically in cases where the initial guess is far from the
optimum 
lastly  the learning approach needs to be tested on a
real world robotics problem  we would need to determine
whether it is necessary to model real world problems as
stochastic  or whether the observed noise works with the
developed optimizer 

references
    m  kalakrishnan  j  buchli  p  pastor  m  mistry  and
s  schaal  fast  robust quadruped locomotion over
challenging terrain  in robotics and automation  icra       
ieee international conference on        pp           
 online   available  http   www clmc usc edu publications 
k kalakrishnan icra     pdf
    l  kaelbling  m  littman  and a  w  moore  reinforcement
learning  a survey  in journal of artificial intelligence research                   may      
    p  pastor  m  kalakrishnan  s  chitta  e  theodorou  and
s  schaal  skill learning and task outcome prediction for
manipulation  in robotics and automation  icra       
ieee international conference on  may       pp       
     
    p  pastor  l  righetti  m  kalakrishnan  and s  schaal  online movement adaptation based on previous sensor experiences  in intelligent robots and systems  iros       
ieee rsj international conference on  sept        pp     
    
    wikipedia  stochastic approximation  wikipedia  the
free encyclopedia         online  accessed    dec       
 online   available  http   en wikipedia org w index php 
title stochastic approximation oldid          
    h  robbins and s  monro  a stochastic approximation
method  in the annals of mathematical statistics  vol     
no     sept       pp           
    b  polyak and a  juditsky  acceleration of stochastic approximation by averaging  in siam journal on control and
optimization  vol      no     july      
    j  kiefer and j  wolfowitz  stochastic estimation of the
maximum of a regression function  in the annals of mathematical statistics  vol      no     sept       pp           
    wikipedia  stochastic gradient descent  wikipedia  the
free encyclopedia         online  accessed    dec       
 online   available  http   en wikipedia org w index php 
title stochastic gradient descent oldid          
     m  frean and p  boyle  using gaussian processes to
optimize expensive functions  in proceedings of the   st
australasian joint conference on artificial intelligence 
advances in artificial intelligence  ser  ai     berlin 
heidelberg  springer verlag        pp           online  
available  http   dx doi org                           
  
     w  garage         november  gazebo robotics simulator 
 online   available  http   www ros org wiki gazebo

fi