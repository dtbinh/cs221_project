a hard science is good to find
textual similarity as a measure of scientific paradigm
development  a preliminary investigation

susan biancani
stanford university school of education
stanford  ca      
biancani stanford edu

abstract
the notion of a hierarchy of sciences  in which academic fields can be ordered from hard to soft  is an old
one  however  efforts to develop a measure of hardness of a fieldthe fields level of paradigm developmentto
date have not been highly successful  here i explore the possibility of using a text based similarity measure to
quantify the extent of consensus in a field  which is theorized to correlate with hardness 

 

i n trod u cti on

thomas kuhns      the structure of scientific revolutions advances the notion that a scientific field is
characterized by a paradigma guiding set of assumptions  methods and values that shape how research in the field
is conducted and evaluated  and what constitutes appropriate objects of study     kuhn argues that different fields
are characterized by different levels of paradigm development  in low paradigm fields  little consensus exists on the
important questions in the field or the best methods with which to investigate them  research proceeds in fits and
starts  and new findings may not build directly on prior findings  this description tends to fit fields in the social
sciences  by contrast  high paradigm fieldsoften those in the natural sciencesshow much greater agreement on
methods and research questions  there is often a race to publish important results  out of fear of getting scooped 
new findings build directly onor challengeprior findings  allowing knowledge to accumulate rapidly  highparadigm fields have elsewhere been described as high consensus  rapid discovery  and progressive    
sociologists of science have attempted to characterize fields according to their level of paradigm development  but
many efforts to date have not been satisfying  here i explore the use of a text based similarity metric as a measure of
the level of cohesionand thus paradigm developmentin a field 

 

pri o r work

auguste comte first advanced the notion of a hierarchy of sciences in the nineteenth century  since then  much
work on this question has come from the field of bibliometrics  derek de solla price developed an immediacy
index  which showed faster rates of obsolescence of findings in the natural sciences than in the social sciences     
however  this metric was later shown to be an artifact of the differing volumes of work produced in a given time
interval in different fields      cole     summarized findings from seven different approaches seeking to find a
variable that reliably correlated with widespread perceptions of paradigm development  but found none that did  he
concluded  there are no systematic differences between sciences at the top and at the bottom of the hierarchy in
either cognitive consensus or the rate at which new ideas are incorporated  p       
one technique that has successfully distinguished low paradigm from high paradigm fields  and which has the
potential to be replicated automatically  is the measure of fractional graph area  fga   fga is a measure of the
total fraction of page space in a given article that is taken up by graphs  smith et al      hypothesized that papers
from higher paradigm fields would be characterized by higher fga  in doing so  they drew on latours assertion
that graphs distinguish science from non science      graphs are a highly encoded means of communication  they
can present a large amount of information in a compact form  because they build on a vast quantity of shared
knowledge between the writer and the reader  much information is embedded in a graph without elaborate
explanation  it is assumed that the reader has sufficient prior familiarity with the form of a graph to be able to extract

fithe new finding quickly  thus  the use of graphs captures much of the nature of a high paradigm field  in a random
sample of    articles from each of    journals  smith et al  found that fga does indeed correlate with scientists
perceptions of the level of paradigm development of seven fields  smith et al  relied on prior coding by william
cleveland     who measured the fga of the papers used in the sample  cleveland describes the process as detailed
and intensive        clearly  it would be useful to develop an automated measure of paradigm development 
in related work  scholars have used similarity at the level of journals to map the backbone of science  examining
citation flows between journals  but have not extended their approach to the paper level       additionally  hall et
al       use an lda model to compare topic entropy between different conferences in the same field  their approach
relies on training a single set of topics on the combined corpus to several conferences in the same field  it is unclear
how to extend it to make comparisons across academic fields  which may be represented by corpora of different
sizes and varying diversity 
here  i use the distance to a set of nearest neighbor papers as an indicator of paradigm  i hypothesize that in a highparadigm field  a paper will be close to its nearest neighbor  it speaks directly to them  and may share methods or an
empirical setting  in a low paradigm field  published papers may be less closely related to an existing literature 
thus  i expect that papers in harder sciences will be closer  on average  to their nearest neighbors than papers in
softer sciences 

 

data

i begin with a detailed study of a pilot dataset  and then apply selected methods to a second  larger dataset  which is
a super set of the first   the pilot study is based on a dataset collected at stanford university  covering the years
           the corpus includes        abstracts of all papers published by stanford faculty members  here  i
restrict the study to seven departments  physics  chemistry  biology  medicine  psychology  economics  and
sociology  multiple teams of researchers have found that these fields are widely perceived to be ranked for paradigm
development in the above order  with physics showing the highest level of development  and sociology the lowest
              
table    descriptive statistics for the dataset i 
department

people

publications
with abstracts

publications
with citations

keywords

  
  
  
   
  
  
  

   
     
     
     
   
   
   

   
     
     
     
   
   
   

  
  
   
   
  
  
  

physics
chemistry
biology
medicine
psychology
economics
sociology
department
physics
chemistry
biology
medicine
psychology
economics
sociology

vocab  size
     
     
     
      
     
     
   

vocab    abstracts
     
     
     
     
     
     
     

unique citations
     
     
     
     
     
     
   

papers
 
person
     
     
     
     
     
    
    

keywords
  paper
     
     
     
     
     
     
     

citations   publication
     
     
     
     
     
     
     

a few facts stand out about the distribution of papers in the corpus  first  the departments vary widely in size  both
in terms of faculty members and in output  second  higher paradigm fields tend to produce more papers per
number of faculty members  though this may be confounded by higher rates of multi authored papers  
 

note  the ratios reported are the total number of publications or keywords for the whole department  divided by the total
number of people or publications  in this respect  they give us a sense of the diversity or dispersion of the department  rather than
indicating how many keywords are typically associated with an article in a given discipline 

fihigher paradigm fields use fewer keywords to characterize their collections relative to the number of papers
in the collectionthan do low paradigm fields  this observation lends support to my contention that papers
in high paradigm fields have more in common than those in low paradigm fields  the vocabulary size in
each field also varies   note that very common and very rare words have been removed from the corpus   in
general  lower paradigm fields use more unique terms  relative to the size of the corpus  than do higher
paradigm fields  interestingly  medicine  which is rated in the middle on paradigm development  scores lower on
these measures than some higher rated fields 
the second dataset i use is drawn directly from the isi web of science database and includes all papers published
under a selected subject category  rather than solely papers by stanford professors   for this analysis  i selected
papers from four subject categories  sociology  psychology  biology  and physics  particles and fields 
department
physics
biology
psychology
sociology

 

table    descriptive statistics for dataset ii
publications
vocabulary
vocabulary  
with abstracts size
abstracts
       
      
     
      
      
     
      
      
     
      
      
     

measu ri n g pap e r s i mi l ari ty

for dataset i  i characterize each paper in two ways  according to the text in its abstract  and according to the
references it cites  in both cases  i use a tf idf approachgiving more weight to rare terms or to rare citationsto
generate a term or citation vector for each paper  i then compute the cosine similarity between all possible pairs of
papers in a given discipline  for each discipline  i report the average distance from each paper to each of its   
nearest neighbors 
for dataset ii  i repeat the tf idf similarity measure for abstracts  the corpora were too large to use in their entirety 
so i sampled at three sizes        papers         papers         papers  in order to test the role of corpus size  i
generated a random set of papers for each field  for each word  i randomly permuted the vector representing its
presence in the papers of the corpus  in this way  each paper was a random assortment of words and weights  i
sampled the randomized corpora at the same sizes as above i then used the randomized sample for each field to
normalize the observed results for that field 

 

resu l ts    ave rage s i mi l ari ty b y dep a rt men t

figure   shows the results from the tf idf analysis  a   and from citations  b  for dataset i  the tf idf analysis
shows the following ordering  medicine  physics   chemistry  superimposed   biology  psychology 
economics  sociology  the citation analysis shows  medicine  chemistry  economics  physics  biology 
psychology  sociology  it is surprising in both cases that medicine shows the highest similarity between
neighboring papers  its possible that this effect is in part driven by the vast size of this field relative to the
others  with more papers  theres a higher chance of finding a very similar one  the size of the medicine
corpus may also influence some of the measures discussed above  vocabulary size relative to output  relative
count of unique citations  and relative count of keywords 
figure    similarity to    closest papers using tf idf of  a  terms  and  b  citations 

fisimilarity to    closest papers  tf idf

similarity to    closest papers  citations

    

   

   

    

    

   

   

med
chem

    

    

econ

   

   

phys

    

    
   

   

    

    

 

bio
psych
soc

 
                                   

                                   

in neither case are the fields ranked in the predicted order  however  the tf idf similarity only deviates for medicine 
which it ranks highest  rather than  th as predicted  the number of papers in the field may play a confounding role 
medicine is by far the largest field  which may boost its rankings  moreover  we would expect this measure
similarity to the nearest neighborsto increase as more papers are added to a field 

 

resu l ts    ave rage s i mi l ari ty b y is i su b ject cat egori es

figure   shows the results from tf idf analysis of abstracts in the larger isi dataset  at three different sample
sizes  it is clear that increasing the sample size increases the similarity to the nearest neighbor  at all sizes  biology
shows the least similarity between closest papers  this may be due in part to the fact that it is the field with the
largest vocabulary         words  compared to               for other fields   by randomizing each corpus  as
described above  i can investigate the effects of both the number of papers in the corpus  and of vocabulary size 
figure    similarity to    closest papers using three sample sizes

sample        

sample         

sample         

   

   

    

    

   

   

   

    

    

    

   

   

   

    

    

    

   

   

   

    

    

    

 

 
                  

   
    
phys
bio
psych
soc

 
                         

                      

not all subjects finished running in time to report the results here  but figure   presents results for sociology and
psychology at three different sample sizes  the randomly generated psychology papers yielded results very similar
to the actual papers  the ratio was approximately        so the lines appear superimposed 
figure    at left  similarity of actual sociology papers  solid lines  and papers randomly generated from the
sociology vocabulary  dashed lines  at three sample sizes  psychology at right 

fisociology  true v  randomized

psychology  true v  randomized

   

   

    

    

   

   

    
   

    

    

   

   

    

    

     
      
      

   

   

    

    
 

 
                                 

                            

interestingly  the randomly generated sociology papers are  on average  more similar to each other than are the
actual papers  this is not the case for psychology  the results at a sample size of        are the most likely to be
informative  as the smaller sizes are likely not large enough to capture a representative sample of a field with       
or         papers  like biology and physics 

 

con cl u si on

text based and citation based tf idf similarity offer intriguing options with which to measure the level of paradigm
development of a scientific field  further work is needed to shed light on how the size of the corpus  both number of
papers and vocabulary size  representing a field influences my measures of interest  it would also be worth trying
some of the dimension reduction techniques we learned in class  in order to be able to run analyses on the complete
corpora for the larger fields   

 

ack n ow l ed gemen ts

this is paper relies on data collected by the mimir project  the mimir project is conducted at stanford university
by daniel a  mcfarland  dan jurafsky  chris manning  and walter powell  and has been generously funded by the
office of the president at stanford university and by nsf award           special thanks also to kurt thorn for
advice on high performance computing  and to the staff of stanford cs    for suggestions and feedback 

 

 

ref eren c es

note  i did try representing the papers in sparse matrix format  using the scipy sparse package   however  this led
to a profound slow down in running time  i projected that biology would take on the order of a month  rather than
on the order of a day  to calculate the distances between papers  it turns out that checking whether the value of an
entry is   takes much longer than doing floating point multiplication 

fi    kuhn  thomas        the structure of scientific
revolutions  chicago  the university of chicago
press 
    collins  randall        why the social sciences
wont become high consensus  rapid discovery
science  sociological forum                 
    de solla price  derek j        citation measures
of hard science  soft science  technology  and non
science  in carnot e  nelson and donald k  pollack
 eds   communication among scientists and
engineers lexington  ma  d c  heath       
    cole  stephen  jonathan r  cole and lorraine
dietrich        measuring the cognitive state of
scientific disciplines  in yehuda elkana  joshua
lederberg  robert k  merton  arnold thackray and
harriet zuckerman  eds   toward a metric of
science  new york  john wiley   sons         
    stephen cole        the hierarchy of the
sciences  american journal of sociology            
    susan e  cozzens        comparing the
sciences  citation context analysis of papers from
neuropharmacology and the sociology of science 
social studies of science                 
    smith  laurence d   lisa a  best  d  alan
stubbs  john johnston  andrea bastiani archibald 
      scientific graphs and the hierarchy of the
sciences  a latourian survey of inscription
practices  social studies of science                
    latour  bruno        drawing things
together  in michael lynch and steve woolgar
 eds   representation in scientific practice
cambridge  ma  mit press              
    cleveland  william s        graphs in scientific
publications  american statistician             
     boyak  kevin w  richard klavans  and katy
borner        mapping the backbone of science 
scientometrics                
     hall  david  daniel jurafsky  and christopher d 
manning        studying the history of ideas using
topic models  proceedings of the      conference
on empirical methods in natural language
processing  honolulu  hi  october       p        
     lodahl  janice beyer and gerald gordon       
the structure of scientific fields and the
functioning of university graduate departments 
american sociological review            
     biglan  anthony         relationships between
subject matter characteristics and the structure and
output of university departments  journal of
applied psychology             

     ashar  hanna and jonathan z  shapiro       
are retrenchment decisions rational  the role of
information in times of budgetary stress  journal
of higher education             

fi