cs    final project  autumn     

 

predicting dow jones movement with twitter
esther hsu  estherh stanford edu 
sam shiu  bwshiu stanford edu 
dan torczynski  dtor  stanford edu 
cs    final project  autumn       stanford university

abstractthe use of machine learning in the realm of finance
is becoming much more prevalent as algorithmic trading catches
on  similarly  online social networking data becomes more
valuable with new research in mining  the goal of this project is
to take the next steps in these directions  using different methods
to interpret twitter content  we hope to predict movement in the
dow jones industrial average  more specifically  we find the word
counts of our corpus of tweets using different word lists  calculate
high level features  and use machine learning techniques to see
whether a correlation with the stock market is likely to exist 

i  i ntroduction
predicting the seemingly unpredictable stock market has
always been a subject of study  factors like current events and
human emotion have been shown to play a role in the behavior
of the stock market  however  the difficulty in evaluating these
has prevented significantly accurate prediction  with the rise
of online social media  more data than ever is available for
analyzing the current state of the population  our aim in this
study is to make use of twitter content to find trends or
characteristics that could correlate with the movement of the
dow jones  each of our methods in extracting features begins
with counting the number of times certain words appear in
our corpus of tweets in the days leading up to the date for
which we are trying to predict  and developing higher level
features from these counts that we postulate could help predict
movement in the stock market 
ii  p rior w ork
our project began with a      study by bollen  mao and
zeng     their work was based on sentiment analysis of
twitter content to predict movement in the djia  using a
word list generated from the google profile of mood states 
they were able to describe each day as   different moods
as features  calm  alert  sure  vital  kind and happy  they
found that calm had high correlation with the stock market
and their predictions achieved       accuracy  although the
mood of the nation is almost certainly an indicator of economic
behavior  we felt that limiting sentiment analysis to gpoms
did not allow for full use of the data available  we hope
to explore more techniques to see what other ways twitter
content is predictive of the djia 
iii  dataset and r esources
our corpus of tweets comes from stanford snaps dataset
collection by jure leskovec      it consists of approximately
    million tweets  although we did not use the entire set 

from june          to december           we divided the
data into separate days  and used approximately     million
tweets per day  except for july             and october    
for which there was no data  
we used several different tools to implement our methods 
 svm  svm light  liblinear
 neural networks  fann  nnet r library
 recursive partitioning trees  rpart r library
iv  g eneral m ethod
to generate features for each day based on its tweets 
we would keep track of the number of times certain words
appeared that day  in some of our methods  we used these
numbers directly as features  sometimes normalized and sometimes not   while in others  we calculated higher level features
from them  therefore  the first step for each of method was
to create a lexicon of words of which we would keep count 
the second was to decide on how to interpret these counts 
obviously  in trying to predict the djia  we would in real
life only have information from previous days  therefore  the
features we assigned to day i were the word counts  or the
features derived from them  from days i     i    and i    
we included the djia from the previous days as features for
each model as well  generally  then  the features for day i for
each of our models would follow the format 
x i     di    di    di    fi    fi    fi   
where di is the djia of day i and fi is the vector of word
counts  or features derived from them  
our prediction labels were based on the djia close of each
day  specifically  we wanted to predict whether the close of
day t would move up or down from the close of day t    
we used different ways of interpreting dt  dt    where dt is
the djia of day t  as labeling schemes 
 binary     if dt  dt         if dt  dt    
 upper band     if dt  dt   b     if dt  dt   b
 lower band     if dt  dt   b     if dt  dt   b
the purpose of the upper and lower bands was to create a
band of width b     illustrated in figure    where b      so
that the predictor would to be able to detect large movement
in the djia  as opposed to small deviations  as this would be
important to know in actual trading 
our features and labels were generally plugged into a linearkernel svm  and sometimes a neural net or recursive partitioning tree if felt that the svm results were inconclusive  initially 

fics    final project  autumn     

 

this resulted in a lexicon of approximately      words 
or about       features per day  the normalized feature
corresponding to day i and word j was calculated as 
 i 

fj

  of times word j appeared on day i
 p
k   of times word k appeared on day i

b  results

fig     band with b       points inside the band represent
small changes in the djia  while those outside the band
represent more significant movement 

we attempted training on the first   months  june october  and
testing on the last two  november december   however  we
found that since november and december had mainly upward
movement  our results were difficult to interpret  we then
changed to training on the first   and testing on the last   
since the october labels had more variance to them 
we also took a different approach to reflect the dynamical
nature of the stock market  our data was divided into m
time periods of  almost  equal length  t    t       tm   then 
for testing on ti   we only used ti  for training  we varied
m but usually found that time periods of approximately a
month worked well  we felt that this helped to model the
ever changing tendencies of the stock market 
v  baseline
to act as a baseline  we put together as many low level
features as possible for prediction  we were mainly looking
to achieve slightly more than     accuracy  as an indicator
that there could be some set of higher level features to be
calculated that would perform even better 

when testing and training on different time periods  we
found that using the baseline features in a linear or polynomial
svm and different labeling schemes would result in entirely
   predictions  although this yielded a decent accuracy of
     the end of      consisted of mostly upward movement
for the djia   it was clear that always predicting upward
movement would be as inaccurate as random guessing  our
interpretation after seeing these results was that the baseline
data was too convoluted to separate  and therefore the model
would choose whichever label was more common  we also
found that although decision trees did not have this problem 
their results had very close to     accuracy  thus  our next
step was feature selection 
vi  h ighly correlation words
we hoped to improve from the baseline approach by cutting
down on the number of features and perhaps remove noise 
our approach was to choose a subset of the words that we
felt would be most predictive of the djia 
a  method
to reduce the number of features  we decided to keep
only the features corresponding to the words that were most
correlated with djia movement  correlation for word j was
 i 
calculated as the covariance of vector fj   where fj is the ith
entry  and vector d  where the ith entry is the djia for day
i  after calculating the correlation coefficient for each word
for the days in the training set  covariance matrix illustrated
in figure     we kept any word with correlation kj k       
this resulted in a subset of     words 
b  results

a  features
in light of the results of the previous      study  we wanted
to include words to reflect sentiment analysis  however  we
also wanted to expand the lexicon to find any other possible
connection between twitter words and the djia  accordingly 
we combined two lists 
   alex davies  specifically created for sentiment analysis
on twitter  this list consists of approximately      words
that with high probability was associated with the moods
happy or sad  note that although this focus on positive negative mood is different from poms sentiment
analysis  we felt the fact that it included very common
words was important in making the most use of our data 
   fiction  a list of approximately      of the most commonly used words in fiction  obtained from wikipedia 

our results for the correlation model ended up being almost
identical to that of the baseline  for each training set  svm
and neural networks predicted almost entirely    on the test
set  and decision trees were almost completely random  so 
our next approach was to develop fewer  higher level features
so that our data was less convoluted 
vii  poms s entiment a nalysis
a  model
the previous paper by bollen et al  claimed that the
sentiments of the usa as measured by twitter had predictive
correlation with the djia  in attempt to confirm or reject this
claim  a similar approach was attempted  from the original
   seed words of the poms      a new list of      words
was constructed using a thesaurus implemented by dekang

fics    final project  autumn     

 

expanded sentiment word list  not a thesaurus  second is that
we never identified a calm feature  and the original paper
could have constructed a more informative feature from a
combination of moods or another source altogether  finally 
we did not have as large a training set  their set consisted
of months february november  whereas we only had months
july november  consequently  our finding neither confirms
nor rejects the original claim  it does  however  suggest that
their claim might be slightly over exaggerated because while
not made explicit  it is likely one of our six features closely
matched their calm  in addition  if calm did have a correlation 
even though we used a smaller training set  we would have
expected to see a higher than     predictive accuracy 

fig     illustrated covariance matrix of baseline word list and
djia movement  the words with the highest correlation were
chosen as features for our second method 

lin      like the original    words  each of these     words
mapped back to one of six sentiments  the original paper said
that the sentiment calm was the correlated feature  without
explaining how they arrived at calm considering it was not
one of the original six moods of the poms  consequently 
our approach did not attempt to construct or interpret calm
from our data  but instead used the six poms sentiments in
their original form  the six moods were generated from the
twitter corpus  as can be seen below in figure    and used as
features for the svm 
fig     learning curve for svm using twitter poms features 

viii  svd g rouping

fig     twitter moods generated from      poms word list 
the six moods were normalized by the total number of tweets
of that day to isolate the mood change as a percentage of the
total populations feelings 

b  results
from figure    it appears that not only does the svm
not learn with more training examples  it also does not ever
have accuracy above      compared to the       claimed
by the paper  this could be for several reasons  first is that
the original paper used proximity correlation to build their

our last method uses a few  high level features  but still
makes use of all the word counts weve calculated  more
specifically  it uses singular value decomposition to find the
largest components in the word covariance matrix  instead of
having concrete groupings  like specific moods in sentiment
analysis  the motivation behind this was to find the most
significant groupings of words  we expect that these groupings
would correspond to sentiment and mood  but also to various
trends reflected on twitter 
a  features
in addition to the baseline lexicon  we also added a word
list developed from google ngrams      from a corpus of over
    tb of   word ngrams     gb were chosen at random and
used to construct a proximity list of about      extra words 
this proximity list consisted of words which were frequently
found in conjunction with the    seed words from the poms
as measured by the google ngrams  words with counts below
a threshold were discarded as well as common but meaningless
articles and prepositions 

fics    final project  autumn     

 

firstly  we took the svd of the word covariance matrix for
month long time periods in our training set  since covariance
matrices are positive semi definite  this is equivalent to eigenvalue decomposition  we found that these were quite similar
for each time period  we decided to use the decomposition
for the time period corresponding to june    july     the
groupings were then formed from the first   eigenvectors
 meaning  those eigenvectors corresponding to the largest
eigenvalues  
u      u         u   
each eigenvector corresponded to two groups  based on
the indexes of the positive and negative elements of the
eigenvector  we kept the most significant indexes  ignoring
elements in each u where        ui        to simplify
and eliminate noise  since the first eigenvector had only
positive elements  we were then left with    sets of indexes 
   

   

   

   

   

w    w    w    w    w

each w had approximately        non zero indexes  which
corresponded to the words in that group  feature i for day j
was then calculated as the number of times a word in group
i appeared on day j  we found that the groups had varying
degrees of correlation  as shown in figure   
fig     results of svm grouping  blue are the actual labels and
red is the predictions  top  m      where each time period
had    days      accuracy was achieved  the test period
corresponded to some time in october  bottom  m      where
each time period had    days      accuracy was achieved 
the test period corresponded to september december 

c  portfolio application

fig     illustrated covariance matrix of words  grouped using
svd  we postulate that these groups correspond to moods or
trends in twitter 

b  results
our results using svd groupings worked quite well  using a linear l  regularized l  loss support vector classification from liblinear  we trained and tested on time periods
t    t       tm of varying m  accuracy for band labeling with
b      was slightly above      with higher accuracy as m
became larger and time periods became smaller  although this
goes against the intuition that more training data is better  we
believe that it is indicative of the sporadic nature of the stock
market  the most recent data is the most important 

since svd grouping yielded such high accuracy results 
we decided to apply our predictions to an actual portfolio
simulation to see if we could make a profit  our trading
account was set up to employ a long trading strategy only 
ignoring short strategies for simplification  we also assumed
our account to be     margin able  since our results were
binary  we used the up band labeling scheme with b      
with    indicating a long signal 
the sell decision was more mechanical  when a trade was
committed  we let the market decide for us by simply looking
at the drawdown  the drawdown is a price reversal from its
highest point in a given period  thus  a    drawdown means a
stock price has moved up to its highest point in that period and
then drop    below the highest point  if the price pulled back
beyond    of the highest price achieved  we automatically
sold that trade 
our trading model only committed     of the portfolio
for each trading decision  our result indicates that different
drawdown percentages results in different holding periods for
each trade  a    drawdown provides a holding period of about
   to   days in our testing period  the simulated profit that
resulted was about    in    days  a     drawdown provides

fics    final project  autumn     

a holding period of about    to    days  and the simulated
profit was about     

ix  f urther r esearch
throughout our study  we felt that our analysis was slightly
wanting in the fact that we had a very limited data set to
train and test on  although the data itself was huge and preprocessing was arduous  it resulted in only about     days  it
was difficult  then  to state accuracy percentages when each of
our groupings was only about a months worth of days  ideally 
to confirm our results  we would have liked to train and test on
years worth of data  while the highest month accuracy of    
for a grouping of   is promising  it is important to note that
the average accuracy for this grouping of   is only      this
suggests that we have isolated an eigenvector that resonates
well with one particular group at one particular group sizing 
and does moderately well with the other groups at that sizing 
in addition  it is unclear whether this group sizing is optimal
and will hold up for additional months after december  with
our limited data set of only   months  it is hard to determine
a robust group sizing  and we leave this hypothesis for further
testing in subsequent research with larger data sets 
as the svd results returned the highest rates of accuracy 
we believe this method of feature extraction from twitter to
be the most promising  our study was only able to touch on
this technique  and so we hope to gain more insight to improve
on these features  for example  since the features were merely
unnormalized  unweighted sums of word counts  we speculate
weighing these numbers by their eigenvalues and eigenvector
elements could help 
we also thought that perhaps our method of data collection
could be improved upon  for example  instead of simply using
word counts  there are methods available that extract the most
significant words from a body of writing  this would remove
any noise that common or irrelevant words might cause 

x  c onclusion
in the end  we were able to achieve significant levels of
accuracy with svd grouping  this was perhaps due to the
fact that this model used a few high level features  as opposed
to the more brain dead approach of using a huge amount
of low level ones  it was clear that our baseline approach was
much too convoluted to make predictions that made sense 
the svd grouping made use of a large amount of data  but
had few features that were especially modeled to capture the
principal components of twitter and djia correlation  our
poms approach that was based on the      study was unable
to capture any useful features  which was perhaps because our
lexicon was build on heuristics instead of around the dataset 
in conclusion  we feel that the svd grouping method has
potential to give real results  ideally  we would have liked
a larger dataset for testing to confirm this  however  it is a
topic worth exploring and a step towards learning about the
connection between online social media and economics 

 

xi  acknowledgments
we would like to thank mihai surdeanu for all the advice
and help he provided through multiple meetings and e mails 
and of course professor andrew ng and the rest of the autumn
     cs    staff for their dedication to making machine
learning a fun and rewarding experience 
r eferences
    j  bollen  h  mao  x  zeng  twitter mood predicts the stock market 
journal of computational science  volume    issue    march       pgs
    
    j  leskovec  snap stanford edu  stanford large network dataset collection 
    a  davies  alexdavies net  a word list for sentiment analysis on twitter 
    m  lorr  d  mcnair  l  droppleman  profile of mood states  mult health
systems  inc 
    d 
lin 
dekang
lins
proximity
based
thesaurus 
http   webdocs cs ualberta ca  lindek downloads htm
    google ngrams  http   books google com ngrams datasets

fi