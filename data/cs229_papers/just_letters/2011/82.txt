indoor object recognition of  d kinect dataset with rnns
thiraphat charoensripongsa  yue chen  brian cheng

   introduction
recent work at stanford in the area of scene understanding has involved using recursive neural
networks  rnns   the basic idea behind rnn is that images can be thought of as being
composed by small units  and the relationship between the units can be modeled as a recursive
structure  according to socher et al       this concept has proven to be general in nature as it
can also parse natural language sentences achieving competitive performance  this algorithm
obtains a state of the art performance on the stanford background dataset 
recently a  d dataset of indoor scenes obtained using the microsoft kinect was released 
silberman and fergus     show that depth information gives a significant performance
improvement for indoor scene understanding  with the addition of depth information  we believe
that the performance of the rnn algorithm can be improved  in this study  we modified the
existing rnn algorithm to run on the new dataset  then we incorporate features extracted from
the depth information and investigate how it improves performance 

   the kinect  d dataset
the dataset we are using is provided by nyu and consists of a variety of indoor scenes
captured by the microsoft kinect      the kinect has a rgb camera and an infrared camera that
provides depth information  the dataset contains      frames across    indoor locations 
labeling was done manually through amazon mechanical turk  unfortunately  there was no
standard rule for grouping up similar objects which resulted in the problem of label
inconsistency  for instance  a book shelf is sometimes labeled as books cabinet  bookstand 
or even books   furthermore  rare objects such as roti maker or sewing machine account for
additional labels  the end result is that the dataset has more than      classes  which is
intractable for any model to learn  therefore  we resolve this issue by considering only the   
most common labels and relabeling the rest  including those previously unlabeled objects  as
the background class 
due to the relatively large size of the kinect  d dataset  limited computing power  and time
constraints for our experiments  we made a smaller dataset by randomly selecting     out of
     frames  we split the data into     frames and     frames for a training set and a test set 
respectively  while ensuring that frames from the same scene are not split over both the training
and the test set  table   and table   show the statistics of our dataset  from table    note that
we are given only one scene for class cafe so we include this in the training set 

   recursive neural networks
images often contain recursive structure  for example  a house can be recursively divided
into regions such as walls  windows  and roofs  which can be further divided into smaller
regions  the structure behind how all the regions are related is the basis behind classifying
images 

fiscene class
bathroom
bedroom
bookstore
caf
kitchen
living room
office
total

training
test
scenes frames scenes frames
 
  
 
  
  
   
 
  
 
  
 
  
 
  
 
 
 
  
 
  
 
  
 
  
 
  
 
  
  
   
  
   

table    scene statistics in our     frame
dataset 

object class
train    pixels 
test    pixels 
   background
     
     
   bed
    
    
   blind
    
    
   bookshelf
    
    
   cabinet
    
    
   ceiling
    
    
   floor
    
    
   picture
    
    
   sofa
    
    
    table
    
    
    television
    
    
    wall
     
     
    window
    
    
table    objects statistics in our    
frame dataset 

the rnn algorithm first splits an image into many segments  image segmentation is performed
by the edge detection and image segmentation system  edison       next  the algorithm
recursively combines pairs of segments into super segments to form a tree structure  where
nodes closer to the root represent larger regions of the image 
training data is used to teach the system how to predict trees accurately  each tree has a score
associated with it  a higher score means higher confidence that the tree structure is correct  the
learning algorithm uses training examples to obtain parameters that minimize a risk function     
the result is that a correct trees score is maximized while the highest scoring incorrect trees
score is minimized  to a certain extent  

   feature extraction
similar to socher et al       we oversegment an image into approximately     segments and
compute  d features for the segments  we investigate over a set of interesting features
including rgb and lab color  texture  and position features  furthermore  we focus on
developing features from depth information to incorporate with  d features 

    normalized depth feature
this feature simply normalizes the depth map to the range        and extracts a histogram 
mean value  and standard deviation of the normalized depth in each segment  its easy to
implement and provides a good indicator for certain classes  e g  wall   however  it is sensitive
to outliers and objects far away in the scene  if there is one pixel in the image that has a large
depth value  the normalized depth of the entire scene will be quite different than the same
feature calculated without that point  which will affect the prediction accuracy 
    normal vector feature
we try to explore the  d information provided by the depth map by incorporating the normal
vector of the corresponding object surface of each pixel  given the depth map  the normal

fivector of each pixel is computed by doing the cross product of partial derivatives along each
axis  tangent   this feature contains rich information about the  d geometry  and is helpful in
distinguishing between objects such as table  ceiling  and wall 

   experiments
we performed experiments with our modified kinect dataset  due to a highly unbalanced
number of objects  the pixel level accuracy is not a good measurement as one simple model
can obtain up to     accuracy by just predicting every object as a background  therefore  we
instead compute the accuracy by averaging the classification accuracy of all    classes and use
this measurement throughout this report 

     d features
we start off by considering a simple feature  lab color  and compute the accuracy as a
baseline  then we incorporate depth features  which are the normalized depth feature and
normal vector feature described in the previous section  from the result shown in table    we
have the highest accuracy over the  d features  lab   rgb   texture   position  combined with
our  d features  this gives us a performance gain of over     in accuracy compared to the
best result using  d features that we have experimented with 

feature
accuracy    
lab
     
lab   depth
     
all d
     
all d   depth
     
all d   depth   normal vector
     
table    a comparison of different set of features  we use the term all d for lab   rgb  
texture   position 
    unbalanced dataset
our indoor dataset is very challenging to deal with in that the total number of pixels for each
object class is highly unbalanced  as shown in table    in the training set  we have roughly    
labeled as background and     labeled as wall  while the rest of the classes can be as low as
    concretely  we have far fewer training examples for the classes bed  blind  and
television than for the classes background and wall  which results in fairly low accuracy for
those minority classes  furthermore  the model has a tendency to predict many segments as
wall and background  to overcome this problem  we reduce the population of majority classes
by randomly excluding some segments from training examples  we found that when some
background segments are excluded  the model will tend to classify more objects as wall  which
is the second largest class  resulting in a drop of accuracy by       however  we achieve better
accuracy after some wall segments are also excluded  the confusion matrices are shown in
figure    each entry  i  j  of the matrix is for predicting class j with true class i  and the values
are normalized such that the sum for each row equals one  the number at the top of the matrix
is the classification accuracy 

fifigure    a comparison of normalized confusion matrices  a result from the full training set
 left   excluding some background segments  center   and excluding some background and
wall segments  right   the accuracy is shown at the top of the matrix 
    error analysis
we are interested in the per class accuracy of the algorithm using different features  in general 
the model is relatively good at predicting the objects wall  floor  and ceiling  but it is difficult to
predict the objects bed  blind  television  and window as shown in figure    this poses a
very challenging problem of how can we improve the performance over those difficult classes
with very few training examples  additionally  it is interesting to see that we have a performance
gain over almost all the classes with the depth features 

figure    prediction accuracy for each class for different sets of features 
we also evaluate a frame level accuracy and discover that label inconsistency in the test set
can make the result inaccurate  figure   shows a specific scene where a vast majority of
objects are labeled inconsistently resulting in most of the image being relabeled to background 
it is obvious that all of the predicted objects of class table are all wrong because it does not
even exist in the ground truth labels 

fifigure    an example of inconsistent labeling in the dataset affecting our class accuracy 

   conclusion and future work
with the presence of depth information provided by the kinect dataset  we have introduced  d
features and incorporated them with  d features for use with the recently proposed rnn based
algorithm to classify objects in indoor environments  the results show that  d can improve the
accuracy by        however  the accuracy is largely affected by the problem of unbalanced
data and label inconsistency  in the future work  we should study how to effectively resolve
these problems  furthermore  if we are given more powerful computing resources  we would
like to experiment with a larger dataset and report the average accuracy over multiple folds 
acknowledgements
we would like to thank richard socher for providing useful advice for this project 

references
   socher  r   lin  c c   ng  a y   and manning  c d  parsing natural scenes and natural language with recursive
neural networks  proceedings of the   th international conference on machine learning      
   christoudias  c  m   georgescu  b   and meer  p  synergism in low level vision 
  th international conference on pattern recognition   quebec city  canada  august       vol  iv          
   silberman  n  and fergus  r  indoor scene segmentation using a structured light sensor   drr workshop 
iccv      

fi