predicting rating with sentiment analysis
jason jong
december         
however  yelps qualitative reviews
suffer from the fact that their
quantitative star ratings rarely provide
the most objective or the fairest rating 
in fact  most of the reviews on yelp are
skewed towards higher ratings  and
most of the stars are virtually
meaningless given that most range from
    to     stars  with very few below or
above  distinguishing these restaurants 
and giving them a proper ranking
system  becomes a major challenge 
we seek to turn words and reviews
into quantitative measurements  by
extracting satisfaction from this feature 
a text review will hold more quantitative
value than a star rating  once summed
together  a restaurants list of text
reviews will give a rich quantitative
measurement of the services satisfaction
rating 

abstract
from recent trends  many online
reviews include a numerical or star
rating that quantifies the satisfaction of
the reviewers experience  however  an
objective mapping of this quantitative
rating to the reviewers textual
description does not yet exist  in this
paper  we explore models ranging from
support vector machines to learning
word vectors that capture the sentiment
information of individual words in
relation to ratings of an entire
document  we use yelp reviews for
restaurants near particular universities
to predict corresponding star ratings per
review 

   introduction
more than ever before  peoples
judgments of what to do  or what to eat 
are governed by the opinions of other
people  the internet has become the
ultimate trove of the opinions of many 
many people  today  sites like yelp
have become a vast database for places
and restaurants that include reviews and
opinions written by everyday people 
this crowdsourcing method of
extracting satisfaction has currently been
a successful model for providing
accurate predictions of ones experience
for a certain service 

   yelp reviews dataset
we use yelps recently released
academic dataset  which provides over
one hundred fifty thousand reviews and
their corresponding ratings for
restaurants centered near many different
universities  the data also includes
other information collected by yelp 
including useful  funny  and cool
ratings that is specific to each review 
for the sake of training  we did not
consider correspondences between the
 

fiusers or the restaurants with reviews
because we wanted to provide a purely
objective analysis of semantic
information  we treated each review as
its separate document and assumed each
document corresponded to a single
review and its single star rating 
unfortunately  the star ratings were
just as vague as the star ratings on
yelps reviews  each rating was
rounded to a whole star  so the set of
ratings only included             and   
the average rating was about     
objectively  we decided to place all
ratings above this value into the pool of
positive sentiment responses  and all
the ratings below this value into the
negative sentiment response 

provides a solid beginning for our
semantic analysis 
first  we split the entire pool of
documents into their respective ranking
so the occurrence of certain words for a
certain star rating goes into the same bin 
after training every single word and its
likely occurrence in either a negative or
positive rating  we can test the resulting
words of an anonymous review for its
likely star rating 
this implementation is relatively
basic compared to other implementations
because it only measures the likely
occurrence of certain words within a
certain classification  for instance  it
completely disregards grammar and
word order  and it does not give a proper
measure of the likelihood of two word
similarities 

   comparison of models

    support vector machines

to capture the sentiments of our
reviews  we will model our data after
three different learning algorithms 
first  we implement a nave bayes
classifier  a model that analyzes the
bayesian probability of each word
occurring within each model  next  we
implement a support vector machine  a
model well known in the realm of
textual analysis  our last algorithm 
from the paper learning word vectors
for sentiment analysis  relies first on an
unsupervised learning algorithm to
capture word semantics      it then uses
supervised learning to capture word
sentiments 

next  we implement a support vector
machine  svm  that uses a linear kernel 
there is considerable belief that support
vector machines provide one of the best
models for predicting textual
information 
for instance  svms provide strong
responses to high dimensional input
spaces  which is the case with text
analysis  also  svms deal well with
the fact that document vectors are sparse
   

    nave bayes classifier

lastly  we will implement a learning
algorithm that is considerably more
advanced that our other
implementations  this involves two
processes  capturing semantic

    learning word vectors for
sentiment analysis  theoretical
background  maas et al        

we implement the multinomial event
model with laplace smoothing  this
relatively simple implementation from
the well known nave bayes models
 

fisimilarities and modeling after word
sentiment 

with this equation  you can capture the
sentiment of an entire document 

      capturing word semantics
we will first capture semantic
similarities between words      this is
done by relying on a continuous mixture
distribution over words indexes by a
multi dimensional random variable theta
that is specific to each document 
we assume that the probability
distribution will be conditionally
independent with respect to theta  thus 
the probability of the document is 

the sentiment analysis part of this model
is a supervised learning algorithm that
relies on the star ratings of past reviews
to capture the word vectors
representations 
finally  adding the two objective
functions together gives a whole
objective function for maximization 

   implementation
to model each word with respect to the
document variable theta  we will use a
softmax formula 

    details and design decisions
we objectively chose to level each
rating at the     level divide  such that
star ratings above this level would be
marked as    and star ratings below
this level would be marked as    with
our choice  we could demarcate at a
level that closely marked the median of
the data  however  in the end  there
were still slightly more high rated stars
than low rated stars  but this would not
skew the data given our chosen
weightings 
we were not able to directly predict
star ratings because most current models
rely on the choice between true and
false values  we generate our error
responses based on this denomination 
following our training of seven
different training set sizes  we tested our
data on the same data set size of twenty
thousand unique reviews 

simplifying  and taking the log of the
following  we will get 

      capturing word sentiments
to capture the polarity of sentiment
values  another term in our objective
function will capture the sentiments of
individual words within a document 
each word vector receives a sentiment
labeling with the following equation 

 

fibayes classifiers  but this may be
because of the smaller dataset we had to
deal with 

    nave bayes classifier
despite an absence of distinguished
semantics  nave bayes ended up
performing the best of the three
implementations  this may be the cause
of several reasons  for instance  nave
bayes may perform better with smaller
datasets  but deprecate in performance as
data values grow 
from the graph below  nave bayes
makes a significant jump towards the
beginning of the data set  but begins to
level off  almost proportional to the
amount of data available 
however  nave bayes still proves to
be a significant classifier despite
ignoring relative semantic and sentiment
features  it has proven in many cases to
provide a substantial model for
probabilistic text analysis 

support vector machine
a
c
c
u
r
a
c
y

                                  

training data size

   
naive bayes classifier
a
c
c
u
r
a
c
y

      
      
      
      
      
      
      
      
      
      
      
      

word vector learning with
sentiment analysis

lastly  we implement the most
significant model of our project that
involved sentiment analysis 
in order to implement this model  we
relied on the cvx matlab library for
convex programming for the continuous
optimization of this learning algorithm 
to optimize  we use coordinate
ascent because the word representation
variables  r  b  and psi  were nonconvex with respect to the theta values
of each document 
the program worked effectively  but
provided very  very slow responses 
either way  the results did not prove to
be better than svm or nave bayes 

      
      
      
      
      
      
      
      
      
      
                                  

training set size

    support vector machine
to train our support vector machine
model  we used ntus liblinear svm
library  which uses a linear kernel to
build the model  surprisingly  the model
does not perform better than nave

 

fiinitially  we had hoped to work towards
a model that allowed us to make an
entirely quantitative star rating measure
of a review  we can design our model to
better capture this information  we can
also include more data by factoring in
the three ratings per review provided by
yelp 

learning word vectors
a
c
c
u
r
a
c
y

      
      
      
      
      
      
      
      
      
      
      

   reference
    

    
    
    
training data size

    

    a  maas  r  daly  p  pham  d 
huang  a  ng  and c  potts       
learning word vectors for
sentiment analysis  the   th annual
meeting of the association for
computational linguistics  acl
      
    t  joachims        text
categorization with support vector
machines  learning with many
relevant features  proceedings of
the european conference of
machine learning  ecml  
    r e fan  k w  chang  c  j  hsieh 
x  r  wang  and c j  lin       
liblinear  a library for large
linear classification  journal of
machine learning research           
    r  socher  a  maas  and c  manning 
      spectral chinese restaurant
processes  nonparametric clustering
based on similarities  aistats
     

    overall results
the results proved to be much better
than expected  for opinionated texts 
there is usually a     agreement
between human raters  thus  our
models  which have accuracies around
and above      provide a very strong
model for sentiment analysis 
still  the future of opinion mining will
vary based specifically on the growth of
sentiment information from the last
model because  only then will machine
learning have a stronger objective grasp
of the sentiments of a document 

   future work
in our experiment  we mapped the star
ratings down to simplified   and  
values  to signify a sharp polarity
between positive and negative reviews 

 

fi