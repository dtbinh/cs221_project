ocr for telugu script
monis rakesh ajith
december         
abstract
the unavailability of an optical character recognition  ocr  scheme meeting basic standards has
been a major impediment in the digitization of telugu  the quest for an appropriate solution has been
elusive due to the inherently complicated nature of the script itself and partly to the lack of a concerted
effort  we propose a scheme based on k means and support vector machines that improves accuracy
of current implementations  we have performance tested against deliberately introduced sources of
errors which are known to cause performance issues while lacking robust solutions 
introduction
telugu script is an abugida written in syllables  each unit being a combination of at least one constant
and associated vowels being attached laterally attached vowels  each syllable is a combination of one
or more consonants and laterally attached vowels this contiguous nature of the script makes it
impractical to separate characters  consequently training the recognition algorithm to recognize a
larger set of symbols may be more robust rather than a messier approach requiring extraction of relative
glyph positions  different permutations of the    vowels and    consonants give rise to approximately
    unique glyphs  for this project we focus on the     most commonly used glyphs  despite its
popularity of use  over    million native speakers  there are no ocr schemes available which could be
deployed commercially 
rendering
stanford as rendered in telugu is depicted below  notice the rendered combination of a vowel and two
preceding consonants  with the vowel attached above and the second consonant below 

feature learning
when viewed through the lens of accuracy  feature learning is a critical aspect in any ocr algorithm
especially considering the low accuracy which was achieved by an artificial neural networks ann 
based implementation that we initially attempted  though this ann algorithm may not have been
accurate enough in itself  it did provide us with important insights into developing an accurate and
robust framework 

fiauto encoders are the method of choice for the reduction of higher dimensional pixel data to a lower
but much more tractable feature space  papusha and satheesh provide some novel ideas of extracting
features using k means  with results similar to auto encoding techniques while achieving much higher
agility in terms of both implementation and execution  eventually a support vector machine  svm 
based solution is seen to offer higher accuracy 
training and testing data 
glyphs rendered using the popular pothana font are stored as a single file with identity data and
location coordinates made available in a text file  features are extracted from these relatively pristine
digital renditions as part of data pre processing and are used to score images that need to be identified 
morphed versions of these digitally rendered images also form the base data set for training and testing 
to reflect real world data  randomly selected pixels are dropped from the image data  missing pixels  a
considerably complex issue that plagues ocr schemes  comparatively affects accuracy to a higher
degree than other issues like noise which may easily be resolved using standardized approaches  more
importantly it has to be handled as part of the ocr implementation itself while noise reduction  for
example  may be handled externally using robust algorithms available as free ware  up to   degrees of
tilt has been randomly introduced to simulate scanning issues that may occur with actual real world
data sources  ultimately each digitally rendered character is modified independently a total of ten times
with eight instances being used for training and two for cross validation 

original rendered image of letter a  as in the word apple  in pothana font along with three distorted
versions 

base algorithmic framework 
preprocessing 
step   
original input image data is scaled down to a size of   x   pixels 
step   
scaled images are consequently clustered and over        pieces of the script from various letters  this
is done in either of the two following ways  comparatively depicted in the
step  a 
a k means based clustering approach applied on each glyph 
step  b 

fieach of the glyphs are divided in to    over lapping pieces which are   x   pixels dimensionally 

step   
the  principal components  of the script are obtained from the above        pieces by another level of
clustering implemented using a k means based approach  in the     dimensional space  
the principal components that define the script  obtained using this approach are equivalent to finding
auto encoding blocks for the script  both euclidean and hamming distances are implemented  though
statistically significant differences in the accuracy between either implementation are not observed 
sixty four centroids which form the base features are extracted from the training data these are shown
in the image below 

fi   centroid or base features

feature extraction 
morphed versions of the digital renditions are used as the input data requiring classification which
would be obtained from scanned images in an actual application  these images are divided into four
blocks labelled as top right  top left  bottom right  and bottom left respectively  each of the four
split image part are processed and distance metrics from the    base feature or centroids are calculated 
this was done using three different measures  inner product  hamming distance or l  distance   any
measure may be used as each of the measures provides similar accuracy scores with no statistical
significance observed in the scoring accuracy differences between pairs of the three measures 
these are calculated by processing each scanned images   sub blocks against each of the    centroids 
thus for any given input image after pre processing    x   pixels   for every block    x   pixels  and
against each centroid    x   pixels  we record an average of the distance metric  or inner products  as
a vector denoted as the feature vector 
the feature vector length   number of centroids x number of split image blocks of the image
length vector       x         elements

the aspect ratio of the original scanned glyph is added as the last element that is the    th element of
the feature vector though this must be done before the down scaling of the glyphs image 
thus for each of the ten image per glyph we have a     element vector  training the lib linear svm is
done using   of these vectors  the remaining   being used for testing 

firesults
out of the nearly     test images      were misclassified  resulting in an accurate identification     of
the time  this is much better than the vanilla ann that was trained for the mid quarter milestone 
we hope to improve this accuracy by optimization over arbitrarily chosen parameters like block size
and features  or centroids  extracted 
an example of character miss classification is shown below to illuminate the difficulties that still need
to be overcome  understandably even we had a difficult time as children in being required to
distinguish them  our endurance gradually built up by repeated testing and training 
  confused png  

future work
there are several improvements that we hope to test in the near future in our quest to develop a robust
open source ocr scheme for telugu other than just optimizing over the number of features extracted
and image divisions mentioned above 
instead of averaging the distances  using the maximum along with its location in the sub image may
lead to an improvement in the accuracy 
leveraging the number and relative position of consonants and vowels in the image will narrow down
the number of centroids in the scoring set for each image  this would require classification of each
image on the basis of the number and position of vowels and consonants in the scanned image 
acknowledgements
this project builds on work done by sanjeev satheesh during fall       we are grateful for his advice
and his work provided the inspiration behind some of the aspects implemented specially in the case of
the photo ocr  we are also grateful to the people at lib linear 
last but not the least we would like to take this opportunity to acknowledge and thank the guidance
that was provided to us by prof andrew ng who not only pointed us in the right direction but also
provided a framework to work with in  and the spirit of innovation that is inculcated as part of the class 
references 
engineering dayalbagh educational institute  agra  india  a high accuracy ocr system for printed
telugu text 
sheetalashmi r  abnikant singh  department of electrical engg  iit kanpur  optical character
recognition for printed tamil text using unicode 

fir  jagadeesh kannan  rmk engg college  chennai  india  a comparative study of optical character
recognition for tamil script 
sang sung park won gyo jung young geun shin  dong  sik jang  department of industrial system
and information engineering  korea university  south korea  optical character system using bp
algorithm 
ahmad m  sarhan  and omar i  al helalat  arabic character recognition using artificial neural
networks and statistical analysis 
princess summaya university for science and technology  amman  jordan  online handwritten
character recognition using an optical backpropagation neural networks 

fi