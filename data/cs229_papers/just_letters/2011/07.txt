foreign accent classification
cs      fall     
paul chen
pochuan stanford edu

julia lee
juleea stanford edu

abstract
we worked to create an effective classifier for foreign accented
english speech in order to determine the origins of the speaker 
using pitch features  we first classify between two accents 
german and mandarin  and then expanded to a set of twelve
accents  we achieved a notable improvement over random
performance and gained insights into the strengths of and
relationships between the accents we classified 

   introduction
accented speech poses a major obstacle for speech recognition
algorithms      being able to accurately classify speech accents
would enable automatic recognition of the origin and heritage of a
speaker  this would allow for robust accent specific speech
recognition systems and is especially desirable for languages with
multiple distinct dialects  accent identification also has various
other applications such as automated customer assistance routing 
in addition  analyzing speech data of multiple accents can
potentially hint at common linguistic origins  when an individual
learns to speak a second language  there is a tendency to replace
some syllables in the second language with more prominent
syllables from his native language  thus  accented speech can be
seen as the result of a language being filtered by a second
language  and the analysis of accented speech may uncover hidden
semblances among different languages 
spoken accent recognition attempts to distinguish speech in a
given language that contains residual attributes of another
language  these attributes may include pitch  tonal  rhythmic  and
phonetic features      given the scale constraints of this project
and the difficulty of extracting phonemes as features  we start by
extracting features that correspond to pitch differences in the
accents  this is a common approach when it comes to speaker and
language identification and calls for feature extraction techniques
such as spectrograms  mfccs  and lpc 

   previous work
a previous cs    class project     experimented with hierarchical
temporal memory in attempting to classify different spoken
languages in transcribed data  they preprocessed their data using a
log linear mel spectrogram and classified it using support vector
machines to achieve above     accuracy  although their project
focuses on classifying completely different languages and we
would like to classify different accents  their results can serve as a
good frame of reference 
research presented in a paper by hansen and arslan     used
hidden markov models and a framework that they termed source

julia neidert
jneid stanford edu

generator which attempts to minimize the deviation of accented
speech from neutral speech  they used a large number of prosody
based features  in comparing accented speech to neutral speech 
they found that pitch based features are most relevant  their work
suggests that it is possible to classify accented speech with good
accuracy using just pitched based features 
a paper by gouws and wolvaardt     presented research that also
used hidden markov models to construct a speech recognition
system  their results elucidated some of the relations between
training set size and different feature sets  they showed that the
performance of using lpc and fbank actually decrease with
increasing number of parameters  while lpcepstra increased
and mfcc stayed the same  these results give us a better guidance
for our choice of feature sets and amount of data 
research by chen  huang  chang  and wang     used a gaussian
mixture model in order to classify accented speech and speaker
gender  using mfccs as their feature set  they investigated the
relationship between the number of utterances in the test data and
accent identification error  the study displays very impressive
results  which encourages us to think that non prosodic feature sets
can be promising for accent classification 

   data and preprocessing
all training and testing were done with the cslu  foreign
accented english v     dataset  linguistic data consortium
catalog number ldc    s         this corpus consists of
american english utterances by non native speakers  there are
     telephone quality utterances from native speakers of   
languages 
three independent native american english speakers ranked and
labeled the accent strength of each utterance  we used the hidden
markov model toolkit  htk  for feature extraction  matlab
for preprocessing  and libsvm and the waikato environment for
knowledge analysis  weka  for classification 
data points were taken from    ms clips of utterances and were
averaged over a window of multiple seconds to form features 
various preprocessing techniques were attempted  including
sliding windows  various window lengths  standardization  and the
removal of zeros from data points  the four second  non sliding
windows with standardization was chosen for use in further work
as it gave the best results on our baseline classifier 

fi   classifying two accents
we began by assessing feature set quality and classifier
performance based on classification accuracy between two
accents  aiming to select accents that are more easily
differentiable  we initially selected the mandarin and the german
accent  our initial feature sets were mel frequency cepstral
coefficients  mfcc   linear predictive coding  lpc   and
filterbank energies  fbank  features  as they were the most
frequently used features in other previous works  especially
mfcc and lpc  fbank features represent the prominence of
different frequencies in a sound sample  while mfccs normalize
these to take human perception of sound into account  lpc
features also represent sound as frequencies  but separate the
sound into a base buzz and additional formants 

    establishing a baseline

figure    significance of data set size 

for our baseline classification  we ran naive bayes  logistic
regression  and smo classifiers  each on fbank  mfcc  and
lpc feature sets for german and mandarin accented speech files 
for each pair of classifier and feature set we obtained the results
shown in table   
table    testing accuracy for baseline classifiers and features
zeror
nave bayes
logistic
regression
smo

fbank
     
     

lpc
     
     

mfcc
     
     

    

     

     

     

     

     

    assessing data quality
to determine whether insufficient data was causing poor
accuracy  we divided our feature data into a testing set       and
a training set        we measured classification accuracy for the
testing set when each classifier was trained on increasing fractions
of the training data  we observed that accuracy increased when
the classifier was trained with more data  but decreasing accuracy
gains suggested that insufficient data was not the primary cause of
poor accuracy  see figure    
we also tested whether the accent data was too subtle  as some
speech samples barely sound accented even to a human listener 
each speech sample was previously rated by   judges on a scale
from    negligible or no accent  to    very strong accent with
hindered intelligibility       so we extracted fbank features
 which produced higher baseline accuracies than mfcc and lpc 
from   different subsets of the more heavily accented data with
stronger accents and measured classification with our baseline
classifiers  specifically  we selected speech samples with average
ratings greater than     and greater than      however 
classification accuracy saw little improvement  perhaps due to the
effect of a reduced data set size  see table     consequently  we
continued to use all data available for mandarin and german
accented speech 

 

unless otherwise specified  default weka values were used for
classifier parameters 

table    classifier accuracies  using most heavily accented
data and fbank features
  
  
classifier  
zeror  
nave  bayes  
logistic  
regression  
smo  

accent  strength           accent  strength          
training  
testing  
training   testing  
accuracy   accuracy   accuracy   accuracy  
     
     
     
     
      
      
      
      
      
      
      
      
      

      

      

      

      

      

      

      

    improving feature set selection
next we considered the quality of our features and expanded our
mfcc feature set to include deltas  accelerations  and energies
 targetkind   mfcc e a d in htk configuration files  
this again achieved little improvement over mfcc  by plotting
training accuracy vs  testing accuracy  see figure     we observed
that training accuracy was also low  showing us that we were
under fitting the data  thus  we attempted to boost accuracy by
first over fitting our training data before trying any optimization 
we merged the individual feature sets  expanded mfcc  lpc 
and fbank  into a single set  but found that training error still
did not improve substantially  see table     we subsequently ran
feature selection algorithms  including correlated features subset
evaluation and subset evaluation using logistic regression and
smo  to try to remove all but the strongest features  this
improved the accuracy on the training data  but not the testing
data  which suggests that classifying on stronger accents using a
larger data set could help 

fifigure    classifier training and testing accuracies vs 
training set size 
table    accuracy of baseline classifiers on merged feature set
containing mfcc  lpc  and fbank features 
classifier  
zeror  
nave  bayes  
logistic  
regression  
smo  

training  accuracy  
     
       
       

testing  accuracy  
     
       
       

       

       

       

       

    selecting a better classifier
to improve training error  we tried using k nearest neighbors
 knn  as well as libsvm  knn performed poorly  but we
observed dramatic improvements in training set classification
accuracy using a libsvm classifier with a gaussian kernel  see
table    
table    accuracy of initial libsvm classifiers using
gaussian kernels 
feature  set  
fbank  
lpc  
mfcc  
 expanded   
all    

training  accuracy  
     
       
       

testing  accuracy  
     
       
       

       

       

       

       

although training accuracy increased significantly  we did not see
similar gains in testing accuracy  in order to boost testing
accuracy  we optimized parameters of our libsvm classifier  see
figure     optimizing gamma versus c  the coefficient for the
penalty of misclassification   we finally saw an improvement  we
achieved a testing accuracy of       with c     and gamma  
         as parameters of the gaussian kernel  we experimented
with sigmoid and polynomial kernels and various parameter sets 
but computing resources limited the range of parameters tried  so
we did not achieve better accuracy in our preliminary
optimizations 

figure    optimizing gamma and c parameters of the
libsvm gaussian kernel 
 

   classification across multiple
languages
we proceeded to process a dozen accents from our dataset 
choosing only ones that have at least     utterances  we obtained
a classification accuracy of        by reselecting parameters for
libsvm  which is a significant improvement over the baseline
accuracy of random guessing       further  the confusion matrix
across these twelve accents displayed interesting results  figure  
plots the percentage of cases in which each language on the y axis
was classified as a language on the x axis  while we do not see a
particularly distinct diagonal indicating correct classifications  this
plot does illuminate some interesting relationships in our accent
database 
the resulting figure shows that the cantonese accent is very
distinctive in our dataset and is easiest to classify with our
features  it suggests that our hindi accent samples share many
similar aspects with other languages such that many instances of
the other accents were classified as hindi  while the opposite is
true for german  this suggests that our initial choice of german
and mandarin for the two class problem may have resulted in
better results if we had chosen other accents 
this figure also hints at the similarity of accents from countries of
geographic proximity  for example  the german accent is most
frequently confused as the french and the swedish accents  and
the japanese accent was often confused with the cantonese and
mandarin accents  however  it also reveals that geographic
proximity does not absolutely determine accent semblance  for
example  the french accent is actually least likely to be confused
with the german accent despite the fact that france and germany
are bordering countries 

fifigure    confusion matrix for    way accent classification 
 

   future work

   conclusion

we tried many different approaches in order to arrive at the best
possible accent classifier using a set of features based solely on
pitch  in the end  our training error was still significantly higher
than our testing error  so these results might still be improved  to
do this  we would want to use a larger data set with stronger
accents  performing more intensive feature selection using subset
evaluation on libsvm  which was infeasible with our limited
computing and time resources  would likely prove helpful  as
would performing more intensive parameter selection for different
kernels 

there is much need for improvement before an accent classifier
could be used definitively in a speech recognition system  in our
work  however  we have made progress in this area and have also
uncovered insights into the relationships between accents and
their origins  this suggests that in the future  there is hope for
further improvement and an increased understanding of how we
speak and where we come from 

in addition  the accent classification problem could be
significantly different from other speech classification problems 
and thus  other feature sets might be more informative  at this
point  we would need to work with linguists and sociologists to
generate these relevant features from scratch 

thanks to andrew maas for his support and advice in this project
throughout the process 

altering the problem slightly  we could cluster accents from a
common geographic region and work to identify between those
groups  inversely  further analysis of our current classification
results and how those are correlated with geographic and
historical data could uncover or reinforce these insights into the
structures and origins of different languages and the histories of
different peoples 

   acknowledgments

   references
    t  chen  c  huang  c  chang  and j  wang  on the use of
gaussian mixture model for speaker variability analysis 
presented at the int  conf  slp  denver  co      
    e  gouws  k  wolvaardt  n  kleynhans  and e  barnard 
appropriate baseline values for hmm based speech
recognition  in proceedings of prasa  november      
pp        

fi    j  h  l  hansen and l  m  arslan  foreign accent
classification using source generator based prosodic
features  in proc  ieee int  conf  acoustics  speech  signal
processing  vol           pp         
    c  huang  t  chen  s  li  e  chang and j l  zhou  analysis
of speaker variability  in proc  eurospeech        vol   
pp                

    t  lander        cslu  foreign accented english release
     linguistic data consortium  philadelphia
    d  robinson  k  leung  and x  falco  spoken language
identifcation with hierarchical temporal memory 
http   cs    stanford edu proj     falcoleungrobinson pdf

fi