attentional based multiple object tracking
mark calafut
stanford university
mcalafut stanford edu

abstract
this paper investigates the attentional based tracking
framework of bazzani et al         and the general
performance of attentional based tracking systems using
different classification  prediction  and gaze selection
techniques  three object classifiers were implemented
using the knn technique  support vector machines  and
ada boosting to recognize digits from the mn ist dataset 
the performance of the classifiers was considered using
foveated and unaltered images as input  the different
classifiers  known collectively as the what module were
then integrated with a where prediction module to
determine gaze location  this module estimates object
state based on previous state history  using a traditional
kalman filter  gaze selection is then performed starting at
the expected object position and moving outward using a
randomized diamond shaped search pattern  the optimal
gaze location is selected and used to estimate track object
position  following completion of the tracking system  its
performance was evaluated using dynamic digit videos
generated from the mnist dataset  test videos included
four classes of randomly generated motion profiles and
varying degrees of in scene clutter  in general  the
performance of the algorithm was robust to changes in
motion profile and degree of clutter 

   introduction
object tracking is an important application in the fields
of machine learn ing and computer vision  however
despite the focus it has received  in practice auto mated
tracking systems can rarely meet the performance levels of
their hu man counterparts  research into the human visual
system has made it clear that humans effectively use
foveation and selective attention in the process of object
tracking  rensink         these techniques in conjunction
with the human ability to understand context in the
ongoing scenes may drive the difference in perfo rmance 
this paper attempts to replicate  with modification  the
general framework o f bazzani  et al         to build a
mu ltip le object tracking model that incorporates foveation
and selective attention  specifically the bazzan i  et al 
       model consists of a general classification module
 known as the ventral pathway  and an attentional or gaze
selection module  known as the dorsal pathway   bazzani

et al         imp lement a particle filter in the dorsal
pathway for state estimation but suggest a variety of
alternative approaches for prediction  gaze selection is
learned using the online hedging algorithm of auer et al 
        the corresponding ventral pathway performs
classification using the distance based appearance model
suggested by larrochelle and hinton         the
appearance model used is more expressive of shape than
conventional appearance models  overall the simultaneous
use of more advanced appearance models in the ventral
pathway combined with learning of gaze p lanning in the
dorsal pathway was expected to better mimic the tracking
of human observers and to lead to improved accuracy 
this work ad justs the general framework ment ioned
above  using a variety of different techniques  and tests
the performance of the developed techniques using the
mnist dataset  lecun and cortes   classification models
are trained using samples fro m the        m nist static
digit training cases  testing is performed using samples
fro m the        m nist static digit test cases  the gaze
selection module is tested by generating dynamic v ideos
fro m the mnist training set  digits are samp led rando mly
fro m the test set and placed as background clutter in a
static frame  dynamically a selected number of track
objects are moved throughout the scene  four motion
profiles of the track objects are available for testing of
combin ing classification and tracking system 

   classification model
the classification model or dorsal pathway is
implemented using three alternative methods  the first
two methods are implemented as baseline techniques and
the third technique incorporated a more flexib le object
representation in an attempt to improve performance  each
technique is tested using unaltered and foveated digit
representations  all static classification results are
presented in the follo wing section 

     baseline classification
dig it classification is performed using a k nearest
neighbor model  the k neares t neighbor model was
tested with different numbers of sample mnist digit
representations             and          with different
numbers of neighbors considered using majority rule       

fi     and using foveated test images and unaltered images 
both foveated images and unaltered images are stored and
tested as a feature vector     test runs were performed
with randomly selected samples over the test conditions
mentioned above and the results were averaged  the
results of the testing are summarized in tab les   and   
overall using k nearest neighbors the best results with or
without
foveation
occur
when
using
      
representations and a single nearest neighbor 
classification accuracy in this best case was
approximately     
in an attempt to minimize the effects of changes in digit
location within input images  a centroid adjusted knn
classifier was implemented  also using foveated inputs  
this alteration did not lead to a general increase in
classifier accuracy  the lack of improvement is likely due
to the small   x   sized p ixel patches used to represent
each digit  adjustment of a digit to place the digit centroid
at the center of the patch would often yield rollover of the
digit to the top or bottom of the patch  creating
disconnected patches on the image  th is technique was
discarded and its test results are summarized in table   
w o foveat 
    repre 
     repre 
      repre 

  neighbor
     
     
   

  neighbor
     
     
     

   neighbor
     
     
     

table    knn results over    runs with     samples
 unaltered inputs 
w  foveat 
    repre 
     repre 
      repre 

  neighbor
     
     
     

  neighbor
     
     
     

   neighbor
     
     
     

table    knn results over    runs with     samples
 foveated inputs 
w  foveat 
    repre 
     repre 
      repre 

  neighbor
     
     
     

  neighbor
     
     
     

   neighbor
     
     
     

table    knn results over    runs with     samples
 foveated inputs and centroid adjustment 
also  a two class svm rep resentation was implemented
to differentiate between a selected test digit     and all
other digits in the dataset  the svm was trained using
      t rain ing samples  the classification accuracy of the
svm was approximately the same using foveated inpu ts
and unaltered inputs and was greater than     
the results of lecun et al         suggest that these
baseline techniques could be further improved to    
accuracy with modificat ion to include deskewing and
training with more samples  

     finalized object representation
rather than maintaining comp lete raw pixel lists for
each patch  alternative object representations were
considered  follo wing in itial investigation  an ada boost
framework was selected and imp lemented for comparison
with the knn and svm baseline performances  a variety
of image p roperties were extracted fro m the train ing digit
images and stored in a feature vector including the euler
nu mber  orientation  extent  perimeter  area  convex
area  solid ity  minor a xis length  eccentricity  major
axis length  equiv diameter  min intensity  weighted
centroid  mean intensity  and filled area  these
properties were chosen experimentally and used to
represent training and test objects  after training they
functioned as discriminators for the ada boost weak
classifiers 
the ada boost algorithm was trained using the   
feature object vectors described above with        digit
training cases  the classifier was then tested using the
remain ing        d igit cases in the mnist database with
a two class classification    or not    accuracy of      
without foveation after algorith m convergence  requiring
approximately     boosting iterations   the accuracy of
the classifier using foveated images was        the
classification accuracy of the ada boost technique
exceeded the accuracy of the baseline methods
investigated in section      and the algorith m was
ultimately selected due to its significantly superior runtime
in co mparison to knn  a lthough the training period for
ada boost was significant        seconds on average
over the        case training database   the evaluation of
new test cases after the completion of training was very
rapid          seconds on average   this was
significantly shorter than the         second average
evaluation time for test cases using knn with       
representations  this speed increase in conjunction with
the slight improvement in classificat ion accuracy lead to
the selection of the ada boost technique as the primary
classifier 
other techniques were considered for object
classification and for reducing required data storage for
object representations  several of these techniques could
be explored in future work to expand upon this project and
to potentially improve performance  for example  an
informat ion
accumulation
technique
could
be
implemented using pca or ica  koster and hyvarinen 
      and pca techniques  in conjunction with quadratic
classifiers  have previously achieved accuracy in excess of
     another potential method for future explorat ion is
the use of shape context matched k nn as imp lemented
by belongie et al         with reported classification
accuracy in excess of     

fi   gaze selection
two steps are essential to the gaze selection process 
initially the current state of the track object must be
represented using descriptors such as location  orientation 
speed  scale  and appearance  second  following the
estimation of the object properties at the next time
increment  an optimal gaze location must be selected 
during the experimental evaluation of this project
sample dig its fro m the list of  s in the mnist dataset
were selected and used as track objects  more details on
this are provided in section     the appearance of track
objects was also maintained using a combination of
techniques  first  the classification algorith m described in
section      ada boost trained with        sample
digits  was used to determine whether or not foveated
gazes were similar in appearance to typical  s  this step
in the algorith m was essentially a sanity check  as any
specific   should generally resemble the class of all  s 
in addition to comparing gaze locations to generalized  s
using ada boost  foveated gaze locations were also
compared to the specific   track object in the particular
track video  in the first frame of each tracking experiment 
the foveated template representing the specific track  
was recorded  this template was then compared to
analyzed gaze locations using metrics such as correlation
 in conjunction with the weighted results of the ada
boost classifier  and an optimal gaze location was
selected  in general  it was expected that the combination
of the ada boost framewo rk and a generalized template
tracker would provide a high degree of confidence that
identified gaze locations depicted the true track object 

in each time step  the kalman filter was provided an
updated object location and estimated velocity based on
the selected optimal gaze location  these inputs were then
used to correct the previous state prediction of the kalman
filter  and fo llo wing the filter update a new position and
velocity prediction was made fo r the next time step 

     gaze selection
the gaze selection process was critical to the
performance of the tracking algorith m  the center of the
gaze search at each time step was the predicted object
location provided by the kalman filter  a diamond shaped
search pattern was followed  radiating outward from the
kalman selected midpoint 
the gaze search and selection process occurred in a
series of iterations  at each iteration  the search pattern
would be fo llo wed with    total gaze locations analyzed   
of these gaze locations were at the edges of the diamond
   at each edge  with the  th location was at the center of
the diamond  two sets of random values were added to the
  template search locations  yielding a total o f    disparate
gaze search points at each iteration  the size of the
diamond search pattern was init ialized as   p ixels  with a
total width of   p ixels fro m one edge of the diamond to the
other in its widest dimension   the added pixel shift
factors at each location were drawn randomly fro m the
range of    to    an examp le of the diamond search
pattern with randomization is shown in figure   belo w 

     state representation
a kalman filter was implemented to estimate the
position and speed of the track object in subsequent video
frames  the acceleration of the object was imp licitly
assumed to be zero and the velocity was used to estimate
the change in position of the track object  the following
state equations were used in the kalman filter 

x  ax  bu  w  w   n   q 
z  hx  v  v   n   r 
    t   
      t 
  h  i  b   
a  
        


        
the x variable refers to the predicted state  the z variable
refers to the observed state  the a matrix reflects the state
transition matrix for the dynamic system  and the
observation and process noise were modeled using the q
and r matrices 

figure   this image sequence depicts the spread of gaze
locations  shown as yellow xs  according to the
diamond template plus randomization  the
locations spread as a cloud and attempt to
identify an optimal foveated gaze  the last frame
shows the true object location  marked by a red
square  and the estimated location determined
by the algorithm after searching  marked by a
green square under the red square  

fiat each gaze location the ada boost classifier fro m
section     provided an estimate of how close the object
was to a typical   object  additionally  the correlation
between the extracted foveated object template and the
foveated gaze was determined  these metrics were
weighted based on performance and combined to estimate
the optimality of each gaze location  the optimal gaze
location is ultimately the location yielding the highest
value of this comb ined metric 
following the completion of an iteration of the gaze
search  the diamond shaped search pattern was expanded
by a constant factor of    x  additionally the random shift
factor was increased in proportion with the increase in the
search pattern size  during each search iteration  the
algorith m maintains the location of the optimal gaze
location found up to that point  the search continues for a
minimu m of five diamond step sizes  but will continue
until a reasonable steady state is achieved in the value of
the estimated maximu m metric at that time step 
at the complet ion of the gaze selection process  the
object location is recorded as an observation and passed to
the kalman filter state estimator  the gaze search pattern
and other parameters listed above were optimized
experimentally through testing in section   

   experime ntal results
the tracking algorith m was tested by generating videos
fro m the mnist dataset  clutter sources were rando mly
drawn fro m the test set and interspersed at random
locations in the scene  a test digit  fro m the list of  s 
was selected and moved throughout the scene using a
linear profile with varying step size  a linear profile with
added noise  a sinusoidal profile with noise  and a
complex profile incorporating noise and different
movement types varying over time  static digit
representations were used for initial classifier  ada
boost  training and all training and tested was performed
with uncluttered images prior to dynamic testing  videos
without clutter were used for in itial state representation
testing and to help select a gaze search pattern 
the tracking algorith m was tested using randomly
generated dynamic v ideos  with varying degrees of
clutter  of the types mentioned above 
testing was performed with            and    rando mly
selected clutter digits  placed at random locations  with
each of the four motion profiles  the tracking error
 euclidean distance between the estimated centroid and
the true centroid at each time step  was recorded over   
random video sequences in each setting and averaged  the
results  in average pixel error  are shown in table    for
context  digit sizes in the image were on the order of   
pixels in height and width  therefore an absolute error of
about    pixels in height and    p ixels in width would still
in general place a track point on body of the desired

object  for this reason  average tracking errors exceed ing
   were indicative of qualitatively poor performance and a
reasonable likelihood that the track point would be fu lly
separated fro m the track object for a period of the video 
motion pr 

  clutter
objects

   cl 
objects

   cl 
objects

   cl 
objects

linear

     

     

    

    

lin    noise

    

   

    

    

sin    noise

     

     

    

    

complex

     

   

    

   

table    pixel error with each motion profile clutter
object combination     test average value for
each entry  

   discussion
regardless of the motion profile being tested  the
algorith m was qualitatively and quantitatively effect ive in
tracking in all cases without background clutter  the
average percentage tracking error across all tests with no
clutter was        throughout test runs the algorithm
appeared to retain track almost perfectly at all times  in
general  the success in this base case provided confidence
that the algorithm functioned correctly 
as the level of clutter increased  the algorith m was
further stressed to classify objects seen at each gaze
location  with    clutter objects present  effective tracking
was still seen with all motion profiles  the average
percentage tracking error in these situations was       
qualitatively although the percentage error was slightly
higher for the linear plus noise motion profile and the
complex mot ion profile  this was likely attributable to
randomness in the type and location of clutter present in
the scene  the presence of many  s as clutter sources for
example tended to be more challenging for the ada
boost typical   classifier and would occasional yield
small increases in uncertainty in the    clutter object case 

figure    this image sequence depicts the successful
tracking of an object following a sinusoidal
motion profile through dense clutter     objects  
 track box  green  true location  red 

fihelped alleviate this uncertainty for short periods by
guiding the algorith m to most likely object locations  the
most stressing situations involved occlusion for very long
periods  or alternatively occlusion simultaneous with a
large and unpredictable change in direction of the track
object  

   future work
figure    this image sequence depicts the challenge of
tracking through dense clutter     objects   after
several frames of the track object moving behind
dense clutter  the state estimator begins to yield
inaccurate predictions   track box  green  true
location  red  linear   noise motion profile 
the    and    clutter object tests were more stressing
for the algorithm and demonstrated interesting aspects of
its performance  specifically the average percentage
tracking error in the    clutter objects test was       and
the average percentage tracking error in the    clutter
objects test was        in the vast majority of test cases
the qualitative tracking performance of the algorith m was
very good  shown in figure     in comparison to the lower
clutter cases  the track algorith m would often correctly
identify the target but have some small error      pixels or
around half of an object width  about its exact location  in
a smaller percentage of track cases  the track object would
be completely lost due to long term occlusion of the target 
these cases would occur irregularly based on the inherent
randomness of the clutter position and the motion profile
of the track object  in some of these cases   the clutter was
so dense that it was impossible for the hu man observer to
identify where the track object was located for a
significant portion of the video  during these long periods
of uncertainty  error accumulated in the kalman state
estimate and eventually led to loss of track  in these cases 
the only way for a hu man observer to regain the track
point was to scan the entire scene repeatedly for any object
movement  a frame to frame differencing technique could
be built into later versions of the algorith m to specifically
deal with these stressing cases  figure   below depicts a
situation where the track object was eventually lost while
moving through a    clutter object scene 
in general  the tracking algorith m was able to track
all motion profiles effectively  this indicates that although
the constant velocity assumption in the kalman filter was
violated  particularly by the complex and sinusoidal
motion profiles  the use randomization in the diagonal
search pattern provided enough variety of search points to
effectively identify the target  in addition  the combined
appearance metric was successfully able to identify the
target even with high levels of clutter  frequently the track
object would be occluded for significant periods of time 
yielding low confidence matches in the appearance metric 
in these scenarios  the use of the kalman state estimator

the general framework of attentional based tracking
provides for a wide variety of variation  bazzani et al 
explored different learn ing mechanisms for classificat ion
and gaze selection  aside fro m the algorith ms
implemented in this paper  there are a tremendous number
of alternative options that could be tested and compared in
performance using the mnist database for testing  a
focus could be placed on identifying other effective
algorith ms that can function in real time  additionally
limited testing was performed using mult iple test objects
in this paper  due to time constraints   future work could
specifically attempt to identify algorith ms with superior
performance in multip le object tracking scenarios using
the same framework presented above 

   references
auer p   cesa bianchi n   freund y   and
schapire  robert e  ga mbling in a rigged casino  the
adversarial multi armed bandit problem  technical report
nc  tr                
bazzani l   freitas n   larochelle h   murino v   and ting
j   learning attentional policies for tracking and
recognition in video with deep networks  proceedings of
the   th international conference on machine learning 
     
belongie s   jitendra m   puzicha j  shape maching and
object recognition using shape contexts  ieee
transactions on pattern analysis and machine
intelligence  vo l      no          
freund y  and schapire r  a short introduction to
boosting  journal of japanese society for art ificial
intelligence             
koster u  and hyvarinen a  a two layer ica like
model estimated by score matching  in international
conference of art ificial neural networks  pp          
     
larochelle h  and hinton g  learning to combine foveal
glimpses with a third order boltzmann machine  in neural
information processing systems       
lecun y   cortes c  the mn ist dataset 
rensink  ronald a  the dynamic representation of scenes 
visual cognition  pp              

fi