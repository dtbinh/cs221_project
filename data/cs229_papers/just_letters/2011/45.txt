scene segmentation of  d kinect images with recursive neural
networks
charles chen  jack chen   alex ryan
december         

 

background

segment  greedily selects the highest score  and
computes a feature vector for the new merged
segment  this discovers recursive structure for
the image segments  the rnn learns a representation for these super segments which allows it
to make better merging decisions than with just
the original vision features  we use a softmax
classifier on the semantic representation to classify the segments 

in this project  we study scene segmentation of
images from the microsoft kinect using deep
learning techniques  the kinect gives a depth
map of the scene in addition to a standard rgb
image  so we are extending methods for scene
segmentation and object recognition developed
by sochers group which were previously applied
to two dimensional images  sochers algorithm
parses scenes using recursive neural networks
 rnns  to discover recursive structure in the
image   with the availability of a large standardized data set gathered from the kinect by
researchers at nyu   a natural step is to extend
sochers code to apply the rnn based algorithm
to the three dimensional kinect images 
our algorithm starts by oversegmenting the
image based on rgb data with the edge detection and image segmentation  edison  system  we compute vision features in these superpixels and map these into a neural network
which outputs a semantic feature representation for the superpixels  the vision features that
we use involve both standard two dimensional
image features as well as features based on the
depth information gathered from the kinect  including measures of the distance and normal vector  the recursive neural network then computes
a score indicating whether pairs of adjacent segments should be identified as part of a larger

a paper originally accompanying the kinect
data set published by nathan silberman of
new york university et al proposed a different
method to accomplish a similar task  which involved the computation of location priors of the
object classes and different transition potentials
to run a crf algorithm  the method was not
incredibly accurate  citing a maximum accuracy
of around      citing the challenging nature of
the data  the model also seems hard to generalize because of the necessity for location priors 
as well as many tuned parameters and complex
feature interdependency 
however  part of the method proposed in the
paper is very relevant to our new approach  the
data collection method utilized by the kinect
has a few severe artifacts that require nontrivial preprocessing to overcome  the paper discusses the methods used to preprocess the depth
information  and this set of preprocessed data
is more tractable than the one containing severe
artifacts  this preprocessed data is used in our
project 

 
http   nlp stanford edu pubs socherlinng
manning icml     pdf
 
http   cs nyu edu  silberman site  page id   

 

fi 

method

pixels  we used   statistics calculated from the
co occurence matrix  namely the angular square
moment  the contrast  the correlation  the variance  the inverse difference moment and the sum
average  this was computed with adjacency defined in the  x direction and the  y direction
for a total of    features 

we started with a starter codebase provided by
richard socher which included a rnn implementation and an initial prediction algorithm
based on the average color of each segment in
both the rgb and lab color spaces  we augmented this with several additional features 

   
     

   

features

in order to meet memory constraints and improve performance  we reduced the number of
features by running principal component analysis on our feature set  after whitening and normalizing each feature to mean   and variance
   we reduced our feature count from     components to    components  we chose this number of components so that only components with
very small eigenvalues were discarded  we also
ran tests with varied number of post pca features to measure how pca affected the results 

depth features

although we were given a small set of test data
in our initial code  this did not include depth
data captured by the kinect  we extracted the
depth field from the nyu dataset and for each
segment  we use as features the mean and standard deviation of depth values in that segment 
along with a histogram of the depth values 
     

normal vector features

we also computed the unit normal to each segment as a feature  first  the depth field from
the kinect was convolved with a gaussian kernel in order to smooth out sensor noise  for
each point  we calculated the change in depth
along the x and y axes and used this to compute
the unit normal to the surface represented by
the depth data  this operation was vectorized
to run quickly in the image pre processing step 
for each segment  we computed the normalized
mean of these unit normal vectors as a segment
feature 
     

principal component analysis

   

reduced
backpropagation
common classes

on

in our initial results we found that segments belonging to the largest two classes in the data set
 background and wall  were predicted too often 
and the recall on the less common classes was
very poor  the largest two classes had a order of magnitude more segments than each of
the remaining classes  which may have drowned
out the information on the smaller classes during training  we attempted to avert this issue
by reducing the amount of backpropagation on
these classes during training 

haralick texture features

we added several texture features which were
first proposed by robert haralick based on features of a co occurrence matrix   the gray levels
in the image were discretized into   buckets and
a co occurence matrix g was computed with gij
as the number of pixels of value i adjacent to a
pixel of value j divided by the number of total

   

metric   preprocessing

accuracy is defined as the proportion of predicted pixels that match human labeled values 
in some ways this is a poor metric as confusion of
two closely related classes should be considered
 
at least partially correct  however  we preprohttp   dceanalysis bigr nl haralick  textural   features   for   image   classification pdf cessed our dataset to only use the top    classes
 

fifrom the dataset and the nyu group had already
unified similar labels with wordnet 

 
   

results   analysis
diagnostics   overfitting

we aimed to choose features that generalized to
different scenes and were therefore resilient to
overfitting to noise in each scene  still  we found
significant overfitting by testing predictions on
the training and test data  for pca to    components and full backpropagation  accuracy on
the training set was       while accuracy on the
testing set was        in addition  the confusion
matrices for training data show fairly high recall
on most classes  while the confusion matrices on
testing data show poor recall for all but the most
common classes  see figure    
we compared the results on training on different numbers of images  the test set was the
same in all runs   as we increased the training
set size  the train set accuracy decreased while
the test set accuracy improved  confirming that
the poor accuracy is a result of overfitting  see
figure    
we expect that the accuracy would have improved further by training on a larger data set 
but we did not have sufficient time to run training on more images 

   

figure    the confusion matrix of test data  top 
shows significantly weaker results than the confusion matrix of training data  bottom   suggesting overfitting 

quality of features

figure   compares the test accuracy with all the
features to the accuracy with a subset of the features  which indicates how much each set of features contributes  the depth and position features appear to contribute a small amount to the
accuracy  while texture features did not result in
any significant change  strangely  normal fea  figure    accuracy of test predictions using all
tures decreased the accuracy  this may be a re  features and    pca components with varying
sult of these features replacing more informative training set sizes 
features after running pca 
 

fi   

analysis of pca feature count

figure   compares the results of using pca to
reduce the feature space to various numbers of
dimensions  with a larger number of post pca
features  train accuracy was higher  a result of
increased overfitting  test accuracy increased
from    to     components  which suggests that
pca was removing too much useful feature information with just    components  but decreased
from     to      which suggests that any useful feature information in these components was
outweighed by the increased overfitting 

   

reduced
backpropagation
common classes

on

we varied the backpropagation weight on the
figure    contribution of individual features to two largest classes  while using our full feature
accuracy 
set  we found that accuracy on both the test
data and the train data did not increase substantially with decreasing backpropagation weight
and even decreased when weight was reduced to
     see figure     still  examining the confusion
matrices for the test data  we found that reducing the backpropagation weight did in fact improve predictions of classes   to     see figure    
however  because class   overwhelmed the other
classes in number of segments  the overall accuracy decreased  this is a flaw in the cost metric
we used in training our rnn  an alternative approach that may improve results is to modify the
cost function to increase the importance of recall
on the smaller classes 
note the slightly improved predictions of
classes   to    with reduced backpropagation
weight in figure   at the expense of slightly degraded class   predictions 

figure    pca components vs  accuracy for   conclusion
tests run with full backpropagation and all features 
we used a recursive neural network algorithm to
classify segments of images with a test data accuracy of        we ran our implementation with
more than    different sets of features and other
 

fiparameters to investigate the efficacy of our features and each part of our model  we would like
to acknowledge richard socher for providing us
with starter code and mentoring us on this challenging project 

figure    backpropagation weight of common
classes vs  accuracy 

figure    confusion matrix for backpropagation
weight of      top  and      bottom   each computed for all features and    pca components 

 

fi