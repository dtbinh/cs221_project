multiple feature learning for action classification
benjamin poole
computer science department  stanford university  stanford  ca
poole cs stanford edu

abstract
we investigate the performance of various features on
an action classification dataset  utilizing a variety of
feature combination techniques  we were able to achieve
near state of the art performance using simple classification techniques  we found that multiple kernel learning 
stacked feature representations  randomized pooling  and
simple cross validated feature selection all work well in
identifying discriminative features for action classification 

   introduction
traditional object classification datasets have focused on
objects that are substantially different in their visual characteristics  these datasets generally focus on objects that may
be of vastly different sizes  shapes  and colors  this focus
has led to the development of techniques that are successful at discriminating very different objects  but fail to discriminate similar objects or instances of objects  with the
exception of facial recognition  very little work has gone
into classifying similar objects such as different types of
dogs or cars  these classification tasks rely on very small 
fine grained differences in visual features  such as different
ears or tails in dogs  more recent datasets containing humans performing activities and playing instruments has led
to new classification techniques  however these techniques
tend to rely only on one type of feature 
in this project  we explore a large set of features for action classification  and identify feature combinations that
perform well on the pascal voc      action classification dataset  in particular  we evaluate sift  hog  lbp 
and color histogram features with a variety of different parameters  we explore a variety of techniques to combine
these features including multiple kernel learning  stacked
representations  and wta hash  we find that all these techniques work reasonably well and help to boost performance
over single features 

   related work
most approaches toward recognizing actions in still images have focused on pictoral part based models  e g     

figure    difficult images from the pascal voc      action
classification dataset   a  additional unlabeled people   b  occlusion   c  mixture of high and low quality images 

         these approaches introduce a complicated learning
procedure  and a much more involved detection and classification stage  in general  they attempt to identify the location
and orientation of the humans in a scene  and the overall
layout of the human body  to function well  these models
must have accurate estimates of location and pose  and thus
do not function well in high noise environments  to cope
with these problems  more discriminative models have been
developed recently that do not require explicit pose estimation  the work by yao et al         achieves state of theart performance using randomized forests  but only multiscale sift features  many of these action classification
techniques ignore other potential features due to the computational constraints involved in incorporating different features into their algorithms  here we investigate possible
feature combinations for action classification to determine
whether there exists computationally efficient but discriminative feature sets that can beat the typical standalone features 

   methods
     image representation
in our experiments  we use four different types of features  these features were chosen to provide a heterogeneous description of image attributes that is able to provide
information about shape  color  and texture  we considered 
    color histograms      local binary patterns          sift
with fixed spacing at   different scales      histogram of
oriented gradients     

fi     incorporating context
the dataset we were experimenting with includes bounding boxes to denote which person in an image we are classifying  these bounding boxes are somewhat noisy  and often
crop out parts of an activity that may be useful  to compensate for this problem  we adopt the foreground background
context model of      for each person in an image  we
rescale the bounding box by      and use a   level spatial
pyramid for features within that region  this allows us to
pick up finer grained spatial information in the foreground 
for the background  we compute a broad scale   level spatial pyramid over the entire image  given these two different regions  we end up with two different kernels  typically
these kernels are averaged  however we explore more complex techniques for combining this information 

     coding
we used locally constrained linear coding  llc  for
coding the hog  sift  and lbp features  llc has been
shown to outperform simple hard quantization when using
sift and hog features      
for each feature type  and each region  foreground and
background  we learned a different codebook of size      
for the color histogram feature we used a codebook with   
codewords  all codebooks were learned using k means   
a variant of k means with a smarter initialization procedure
to avoid local optimum     

     spatial pyramid matching
for all of our experiments  we compute a set of features
from patches sampled uniformly on different sized grids in
the foreground and background images  these features are
informative  but we need a method to pool over these features to reduce noise and incorporate invariance to scale and
translation  as noted above  we use spatial pyramids  which
divides an image up into hierarchical regions at multiple
scales and computes a histogram over features within each
region     

     combining kernels
the simplest method for combining multiple features is
to take the average across all kernels  weighting each one
equally  recent work on multiple kernel learning  discussed
below  has shown that average and product kernels work
quite well in practice     
to determine which features to use generally requires a
combination of brute force  trying many different kernels 
and careful manual selection  deciding how to weight and
combine different kernels into a single kernel   alternatively  we can automatically determine the weightings for
each kernel for each class using multiple kernel learning
 mkl   multiple kernel learning  allows for automatically

learning a linear combination of kernels that performs optimally     for each class 
adopting mkl instead will allow us flexibility in two
ways      we can weight different types of features differently for each class      we can weight foreground and background elements differently  being able to alter the weights
on the different feature types may be beneficial as certain
action classes may be better defined by texture than shape
or color  for this paper we used a variant of mkl called
lp  that learns the svm weights and kernel weights separately  first  an svm is trained for each kernel independently  then the weighting of each kernel    is learned
based on the output scores from the independent svms 
the final classifier is then given as the weighted sum of the
responses of each classifier  in this sense  the lp  framework resembles boosting  where each of the svms represents a weak classifier  and the  coefficients combine them
to create a strong classifier  the implementation we used is
from     

     stacking features
an alternative approach to mkl is to combine features
before coding  here we compute all our features over the
same grid  and simply form a new vector which is the concatenation of all of our features at each point  given this
stacked vector  we perform the same coding and pooling
as before  theoretically the stacking approach has the potential to encode more spatial information about the cooccurrence of features  thus for action classification  where
highly discriminative fine grained information determines
the class  being able to code these feature combinations may
boost performance 

     wta hash
instead of pooling over a fixed set of regions  i e  the
hieararchical quadrants defined by spm   we can pool
over random regions using winner take all  wta  hashing       this technique randomly selects k features  and
computes the index of the maximum  we repeat this process
for a large number of random selections  a k a hashes   and
were left with a new feature vector containing a concatenation of the   hot index vectors  this method is relatively
new  but has been shown to be quite effective and requires
extremely small computational cost 

     evaluation
to evaluate our results  we utilize the same metric as the
pascal competition  average precision  for each feature
combination method  we learn a classifier that outputs realvalued confidence estimates for each of the   classes  for
each class  we then compute the precision recall curve  and
find the area under the curve to get the average precision  to

fiquantify how well a technique performs across all classes 
we compute the mean average precision  which is just the
mean of the average precision over the   classes 

   experiments
     dataset
for all the experiments we use the pascal voc      action classification dataset
 http   pascallin ecs soton ac uk challenges voc   
this dataset contains images of people performing any
of   activities  phoning  playing a musical instrument 
reading  riding a bicycle or motorcycle  riding a horse 
running  taking a photograph  using a computer  walking 
every image  in both the training and testing set  includes
a bounding box around the person of interest  there are
approximately     total images  containing     labeled
people  these images are split evenly into a designated
training and validation set  there is also a test set  but the
labels are not publicly available  thus we treat the validation
set as the test set  and split the training set       to generate
a new training validation set  this dataset presents a
number of interesting challenges such as occlusion and
poor image quality as shown in figure   

     individual features
to determine a baseline to compare to later results  we
first looked at each type of feature independently  for each
feature  e g  dense sift with scale   px  hog  dense
sift with scale   px   we first computed a foreground and
background dictionary using k means    next we used
llc to encode the features  except for color histogram 
where we used hard vector quantization   and pooled using a spatial pyramid with   levels for the foreground  and  
levels for the background  the final kernel is given by computing the histogram intersection for the foreground  and
the background  and then averaging these two kernels  we
then train an svm using this kernel  this baseline procedure follows the one in     
we found that all the sift features performed comparably  with hog and color histogram doing substantially
worse  and lbp barely functioning at all  one of the limitations of the experiments here was that we only utilized
one patch size for hog      and one configuration for lbp
        with more scales of hog or lbp it is possible
that one of them could have matched the performance of
any of the sift features  another interesting property is
that any single feature type does not perform best for all
action classes  for example  color histogram was the best
for playinginstrument  and lbp significantly outperformed
all other features for takingphoto  this is likely due to the
scale of lbp matching up with the size of the camera in
most takingphoto images 

given that different features perform better for different
classes  we can simply take the best feature for each action 
and use that to train the classifier for that action  in this way
we use different features  but we still do not have to combine
them  to select the feature to use  we simply choose the
feature that maximizes average precision on the validation
set  using this method we were able to achieve a map of
      which is the best of all feature combination methods
 table    

     combining kernels
next we looked at the accuracy from average and product kernels  table     curiously  both the average and product kernels perform worse than the maximum feature classifier  in particular  the performance for takingphoto drops
off significantly  because we are weighting each feature
equally  and we have many scales of sift  it appears as
though sift is dominating the classification choices  in
particular the usefulness of lbp seems to have disappeared 
and the results for most classes resemble the single sift
features 
to cope with the unequal distribution of feature types
and to learn better weights we used lp   we found that
lp  did not suffer from all the same problems as the simple feature combination methods  in particular  it achieved
performance better than the maximum single feature for  
different classes  however  lp  was still not able to learn
the importance of the lbp features for the takingphoto action  this was unexpected  but may be due to the very
limited amount of positive training instances  only around
   action   the mean average precision was also extremely
competitive at       compared to      for maximum single
feature   comparing this result to the stacked feature vector  we found similar results  a map of        however the
stacked technique did not achieve the highest ap in any action category 
category
phoning
instrument
reading
ridingbike
ridinghorse
running
takingphoto
usingcomputer
walking
map

sift  
    
    
    
    
    
    
   
    
    
    

sift  
    
    
    
    
    
    
   
    
    
    

sift  
    
    
    
    
    
    
   
    
    
    

hog
    
    
    
    
    
    
    
    
    
    

table    average precision of individual features for each of the
  action categories  we removed the first two scales of sift features     and     for brevity  their map were      and      respectively 

color
    
    
    
    
    
    
    
    
    
    

lbp
    
    
    
    
    
    
    
    
    
    

fi  
phoning

playinginstrument

  

hi

reading
  
ridingbike

ridinghorse

  

running
  
takingphoto

usingcomputer

 

walking

usingcomputer

takingphoto

running

ridinghorse

ridingbike

 
reading

playinginstrument

phoning

walking

figure    top   objects with the highest score for each of the  
classes  each row corresponds to the top   objects for a different
action  the order of the actions is the same as in table    correctly classified objects are highlighted in green  while incorrectly
classified objects are highlighted in red 

figure    top   objects with the highest score for each of the  
classes  each row corresponds to the top   objects for a different
action  the order of the actions is the same as in table    correctly classified objects are highlighted in green  while incorrectly
classified objects are highlighted in red 

     wta hash
following the protocol described in the methods section  we computed random hashes maximizing over k    
random features from the stacked feature vector  we experimented with varying the size of the hashes  and found
that in general more hashes improves performance  going
from        to         hashes  the mean average precision
went from      to       wta hash also had the best performance for phoning  ridinghorse and walking  furthermore  this technique is extremely fast as we do not have
to compute quantizations  llc  or spatial pyramids  however  wta underperformed on the difficult takingphoto action  most likely because it did not randomly sample enough
from the subset of lbp features  overall  wta hash provided good performance with little computation  and is a
promising approach for action classification 

     qualitative evaluation
to gain a better understanding of the flaws in our approach  we performed more analyses on the results of the
maximum single feature technique  in figure    we show
the top   objects for each of the   classes  for the phoning  running  walking and riding a horse classes we do quite

well  however for many of the other classes we make a few
mistakes even in the top   objects  for example  two women
on phones are confused for playing an instrument  probably
due to their stance and attire  the classifier seems to pick
out more of the stance of the person and less of the object
that is involved with the action 
to get a slightly more quantitative look at these results 
we computed the top    objects for each action  and then
looked at the distribution of true labels for these objects 
this yields a confusion matrix in figure    where each row
represents the distribution objects that are classified as belonging in that row  here we see that ridinghorse  running 
and walking are mostly along the diagonal  but phoning is
often confused to be using a computer or playing an instrument  these results again seem to reinforce the notion that
were picking out more pose based features and less objectbased features 

     comparison to state of the art
although the results for performance on the validation
set were not released on the pascal voc      website 
they do release the testing performance  if we assume the
validation set and testing set are similarly distributed  then
it is likely that our performance on the testing set would
only increase as we would have more training data  however  this assumption may not be true thus these comparisons should be taken with quite a few grains of salt  the
results we are comparing to can be found here 
http   pascallin ecs soton ac uk challenges voc voc     results index html

in   out of   categories we do substantially worse than
state of the art for all methods  however for reading  our

fibest performance is       while the competitions best is
      our results for ridinghorse are also competitive  we
had      compared to       for walking we again beat the
competition with      compared to       thus despite the
naive and simple techniques we use  along with the relatively small variety of features  we are still able to achieve
reasonable results  most of the models in the competition
utilized either pose estimates or part based models  these
structured models can tremendously boost performance as
shown in             

references
   

http   www vision ee ethz ch  pgehler projects iccv    

    t  ahonen  a  hadid  and m  pietikainen  face recognition with local binary
patterns  pages              
    d  arthur and s  vassilvitskii  k means    the advantages of careful seeding 
in proceedings of the eighteenth annual acm siam symposium on discrete algorithms  soda     pages           philadelphia  pa  usa        society
for industrial and applied mathematics 
    f  r  bach  g  r  g  lanckriet  and m  i  jordan  multiple kernel learning  conic
duality  and the smo algorithm  in proceedings of the twenty first international
conference on machine learning  icml     pages    new york  ny  usa 
      acm 
    n  dalal and b  triggs  histograms of oriented gradients for human detection 
in in cvpr  pages              
    v  delaitre  i  laptev  and j  sivic  recognizing human actions in still images 
a study of bag of features and part based representations  in proceedings of the
british machine vision conference  bmvc         updated version  available
at http   www di ens fr willow research stillactions  

   conclusions
we explored a variety of feature combination techniques 
and found that we could achieve good performance on
action classification without explicitly modeling poses or
parts  by incorporating a variety of different features  we
were able to boost performance on an action classification
task with little additional computational cost  furthermore 
we believe that utilizing randomization techniques  such as
wta hash  can help to automatically identify regions to
pool  and reduce the computational overhead of quantization and classical spatial pooling 
in the future  action classification models should incorporate multiple features to help boost performance 
whether the techniques described in this paper can be applied depend on the particular application  but we believe
that incorporating multiple feature types should boost performance on a variety of datasets  future work should
address this question in a concrete setting by evaluating
whether incorporating any of these techniques into existing
single feature type architecture  such as in       improves
performance 
table    average precision     for all techniques for each of the  
action categories  bolded entries indicate the largest value in the
row 

category
phoning
instrument
reading
ridingbike
ridinghorse
running
takingphoto
usingcomputer
walking
map

maxfeat
    
    
    
    
    
    
    
    
    
    

avg
    
    
    
    
    
    
   
    
    
    

prod
    
    
    
    
    
    
    
    
    
    

lp 
    
    
    
    
    
    
    
    
    
    

stacked
    
    
    
    
    
    
    
    
    
    

    v  delaitre  j  sivic  and i  laptev  learning person object interactions for action recognition in still images  in advances in neural information processing
systems  nips        
    p  v  gehler and s  nowozin  on feature combination for multiclass object
classification  in ieee international conference on computer vision  iccv  
     
    s  lazebnik  c  schmid  and j  ponce  beyond bags of features  spatial pyramid matching for recognizing natural scene categories  in proceedings of
the      ieee computer society conference on computer vision and pattern
recognition   volume    cvpr     pages           washington  dc  usa 
      ieee computer society 
     s  maji  l  bourdev  and j  malik  action recognition from a distributed representation of pose and appearance  in ieee international conference on computer vision and pattern recognition  cvpr        
     j  wang  j  yang  k  yu  f  lv  t  s  huang  and y  gong  locality constrained
linear coding for image classification  in cvpr  pages                
     j  yagnik  d  strelow  d  a  ross  and r  s  lin  the power of comparative
reasoning  csutorontoca       
     b  yao  a  khosla  and l  fei fei  combining randomization and discrimination for fine grained image categorization  in the twenty fourth ieee conference on computer vision and pattern recognition  colorado springs  co  june
     

   appendix
this project is also my course project for cs   a as well as
my rotation project with prof  li  the computer vision component
focuses on manually selecting good features and developing the
baseline classification algorithms  the machine learning component is focused on utilizing mkl and wta hash and comparing
to the manually chosen features 

wta  k
    
    
    
    
    
    
   
    
    
    

wta  k
    
    
    
    
    
    
   
    
    
    

wta   k
    
    
    
    
    
    
   
    
    
    

fi