supervised link prediction by geographic and social attributes

wonhong lee
department of computer science
stanford university

wonhong stanford edu

s  jun yu
institute for computational   mathematical engineering
stanford university

abstract
in this paper  we employ learning algorithms
to develop an efficient link prediction model
based on geographic and social attributes 

   introduction

sjyu stanford edu

scellato  noulas  and mascolo     is to incorporate geographic features such as physical distance and checkin data  this is a promising approach which demonstrates how features other than network topology and
social attributes can be relevant in link prediction  we
believe that there are new ways to render such geographic information to improve prediction results 

link prediction in complex network is an active area of
research in network analysis  this task is complicated
by the fact that shape dynamics of the network is constantly changing  and it is difficult to define which inherent factors drive this change  in this paper  we will
complement an existing algorithm by considering social  geographic  and demographic features to enhance
the performance of link predictions 

     problem formulation

     related work

as mentioned above  however  it is difficult to make
predictions for newly formed nodes by solely analyzing
the network topological properties  we run into similar obstacles when predicting possible links between a
pair of nodes with distance greater than    it is easy
to see how notions of topology defined for immediate
neighbors might be insufficient for a meaningful prediction  to address such limitations  we complement
topological features by employing new features of social  geographic  and demographic flavor 

backstrom and leskovec     devised a link prediction
model based on features involving personal attributes
and network topology  this algorithm  however  may
be infeasible in many cases due to limitations in gathering personal information  with a heightened awareness towards privacy issues  it has become more difficult to collect these data 
the model introduced by liben nowell and keinberg
    predicts possible connections between nodes in a
social network by using graph theoretic features  although this algorithm is effective in making predictions
for existing nodes  we do not have the same assurance
for newly formed nodes since they do not hold any
network topological information 
the main idea in the prediction model proposed by
keywords  link prediction  supervised learning 
this project was carried out in collaboration with jeongjin
ku from the department of computer science 

we want to develop a robust algorithm that can
make accurate predictions for both existing and newly
formed nodes  some graph theoretic features  such as
the adamic adar score  play a crucial role in link prediction  and they often yield outstanding results for
existing nodes  we will certainly incorporate these
features in building a new prediction model 

     heuristic overview
we consider three types of data sets      s    topological features are meaningful      s    topological features
are unmeaningful  and     s   newly formed nodes 
then we define features which are classified into three
cateogires         topological features        geometric
features  and       social features  the basic idea is
to train the prediction model on        and     
separately for each data set  and see how performance
is improved with the addition of each feature class 

fisupervised link prediction by geographic and social attributes

   data rendering
we consider two types of data sets      social network data obtained from gowalla  an online locationbased social network owned by facebook  and     demographic data based on the      united states census which consists of demographics for each zip code
area 
     social network data
for the first data set  we have friendship snapshots
taken at july of      and october of       and public
check in history on february of      and october of
     for users worldwide 
not only is the size of the first data set massive  but
the demographic information from the second data set
is restricted to the united states 

cent to both u and v  the distance between u and v
is written as d u  v  
the set of all check in locations for both time frames
will be denoted by   hence  we do not distinguish between check in points visited in different time frames 
we also define  u  to be the set of all check in locations of u  a  note that  is the disjoint union of
 u  for all u  a 
furthermore  we select subsets of a  a from which
we plan to build the training examples  first  let
s      u  v   a   a    d u  v      with u   v  
many graph theoretic features are meaningful for this
data set  similarly  we define
s      u  v   a   a    d u  v      with u   v  
observe that topological features defined for immediate neighbors are not useful in this case  finally  the
data set for newly formed nodes is given by
s     u  v   a   a    u  v  
by testing the prediction model on these classes of
training examples  we hope to demonstrate social  geographic  and demographic features significantly improve the accuracy of link predictions 
     demographic data

we therefore extract information on the set of users
with at least one check in point in the united states 
the following table shows the size of reduced data set 
time of snapshot
july of     
october of     

number of nodes
      
      

number of edges
       
       

as for the check in history  there are           locations for the two time frames combined 
for simplicity  let t  and t  denote the time  in
chronological order  at which friendship snapshots
were taken  we will also refer to users as nodes  each
node is uniquely assigned to a nonnegative integer 
since the adjacency matrix for the reduced data set is
extremely sparse  we only consider the set a of nodes
incident to an edge that is present at t  but not at t   
in other words  a consists of active nodes  we further
define a  as the subset of a with nodes present only at
t    and set a    a   a    hence  a  is the set of newly
formed nodes  note also that a  and a  partition a 
let u  v  and w be nodes in a  the degree of u is
denoted deg u  we write w   u  v  when w is adja 

the second data set consists of    fields representing
various demographical attributes  the following table
lists some of these features relevant to link prediction 
zip code
population
population density
geographic area
race
age
education
household income
per capita income
house value
housing density

area code
total population
population per unit area
urban  suburban  farm  non farm
white  black  asian  indian  hawaiian  other
age groups
education level of population over   
median household income
median income per person
average value of homes
number of houses per unit area

for consistency  the check in locations in the first data
set are converted into an area code by using the geopostal service provided by nuestar 
in order to take full advantage of the second data set 
we must first deal with the missing values  let d denote the entire demographic data set  where each element is a row vector ri for the ith area code  we
also write ri  to denote the truncation of ri   where the
entry with the missing values are simply deleted  we
can also form a column vectors cj for the jth field  and
define its trucation c j in a similar fashion  note that
the size of ri  may vary for each i  and the same is true

fisupervised link prediction by geographic and social attributes

of c j   furthermore  we let i and  i denote the sample of the entries of ri and ri    respectively  as for the
sample covariance matrix  let  correspond to rows
and columns of the observed entries  while   corresponds to the rows of missing entries and the columns
of the observed entries  we employ the expectationmaximiation algorithm to estimate the missing values 
algorithm     expectation maximiation 
initialization
 a  set zij   j and            and choose      
 b  set i                   and         
e step
 c  set  i    i        ri  i   
 d  set                 ri  i  t    ri  i    log     
 e  set i   i      and if i   n  then go to  b  
m step
 f  set    arg max     
 g  if                 then go to  b   otherwise  break 

note that  to get faster convergnece  we initialize the
missing values by the sample mean of the observed
entries in the corresponding column vectors 

   filter feature selection
we define and classify various features  and then run
a feature selection algorithm to eliminate the insignificant ones 

the adamic adar score a of u  v  a is given by
a  u  v   

x
w u v 

 
 
log  deg w 

we employ this feature to downgrade the effect of common nodes with higher degree since users corresponding to these nodes are more likely to be friends of a
large group of users 
we also define the preferential attachment p of u  a
and v  a as
p  u  v    deg u  deg v 
this feature captures more active users corresponding
to nodes with higher degree 
     geograhpic features
we now define a set of geographic features based on
the check in history  each check in point is a physical
location which can be written in the geographic coordinate system  that is  for x   u  for some u  a 
p  x         
where  and  are the latitude and longditude of x u  
respectively 
the mode m of u  a is given by
m  u    arg max p x u   
x u 

     topological features
the topological features are by far the most important
features as they retain information on the graph theoretical properties of the network  the most natural
topological feature is the number of common nodes 
denoted n   that is  given u  a and v  a 
x
n  u  v   
  w   u  v   

that is  the check in location of u that occurs most
frequently 
similarly  the sample mean s of u  a is defined in
the usual way as
p
x u  x
p
s  u   
 
x   x   u  

w u v 
 

observe that this feature does not take into account
the fact that users corresponding to nodes with higher
degree are more likely to be friends with a larger group
of users 
the cosine similarity c of u  v  a is defined as
c  u  v   

n  u  v 
 
deg u  deg v

by incorporating this feature into the prediction
model  we lend less significance to a pair of nodes with
higher degree since users corresponding to these two
nodes are more likely to have many common friends 

that is  the arithmetic mean of the check in locations
of u 
we would also like to define a feature that captures
the intuition of communities within a network  to do
this  we repeatedly apply k means clustering to form
a binary decision tree  we proceed as follows 
algorithm     modified k means clustering 
 a 
 b 
 c 
 d 
 e 

set k     and choose        
for u  a  set        u   and        u     
for        run k means clustering to get   and    
if var           then         otherwise       u  
if var           then         otherwise       u  

fisupervised link prediction by geographic and social attributes
 f  set              and if         then go to  c  
 g  set         and        and go to  c  

the elements of   u  for u  a in algorithm   are
precisely the leaves of the binary decision tree for u 
we now let  u  denote the mean of the cluster in   u 
with the largest number of check in points 

finally  the urban population density u of u  a is
defined as
u  u 
u  u   
 
n  u 
where u  u  is the population living in urban areas
within the area code for u 
     mutual information
we now compute the kullback leibler divergence for
each feature  and eliminate features with low scores 
feature
n
c
a
p

mi score
      
      
      
      

feature
p
m
s
c

mi score
      
      
      
      

feature
h
w
p
u

mi score
      
      
      
      

among the    social features  many of which are not
listed in the table above  we eliminated the ones with
scores below       for instance  f   the population
density of farmers had the lowest score of           
the figure above shows the result of applying this algorithm to a user living in california  now the clustering
distance between u  a and v  a is defined as
c  u  v    k u    v k   
that is  the euclidean distance between the mean of
the largest clusters in   u  and   v  
     social features
although    social features are considered in the prediction model  we only discuss a few of the important
ones as the rest are defined similarly  we write n  u  to
denote the total population of the area code for u  a 
we define the housing density h of u  a as
h  u   

h u 
 
a u 

now among the selected features  we let      and 
denote the set of topological  geographical  and social
features  respectively  for s    by training on sets
x    s     x     x     x      x     
we hope to observe how the addition of  and  enhance prediction outcomes  as for  s    we consider
x    s    p    x     x     x      x     
note that we only include p from  as this is the only
topological feature relevant to link predition for s   
similarly  we define the training sets
 
  
 
x   s   p    x
  x    x
  x


for s   we expect  and  to play an even bigger role
in this case 

   supervised learning algorithms

where h u  is the number of houses in the area code
for u 

we carry out three different learning algorithms on
each training set defined in section     

the density of white population w for u  a is

     ridge logistic regression

w  u   

w  u 
 
n  u 

where w  u  is the white population of the area code
for u 

we first implement the ridge regression      where we
want to find the maximum likelihood estimator  for
m
x
 i 
 i 
     
log h x i   y     h x i     y   t  
i  

we write the per capita income p of u  a as
i u 
p  u   
 
n  u 
where i u  is the net income of residents in the area
code for u 

where h for parameter  is given by
h x     

 
 
    et x

note that we have added the l   norm of  as a penalty
term to the log likelihood function   

fisupervised link prediction by geographic and social attributes

     naive bayes classifier
given a new example with feature x  we have that
p x y   

n
y

p xj  y 

j  

by the naive bayes assumption  we use the parameters
 
 
 
e xi     i  
x y     p xi   x y        p
 i 
 
 
 
e xi     i  
x y     p xi   x y        p
 
 i

along with
y     p y      
to estimate the posterior probability of a new example
with features x as
p x y   k p y   k 
p y   k x   
 
p x 
where k         
     soft margin support vector machine
we apply the  soft margin classifier     with parameter         where we minimize
m

  t
  x
w w    
i
 
m i  
subject to the constraints
yi  wt xi   b     i   i     and    
for    i  n  the parameter        is a lower
bound on the fraction of support vectors  note that
we have an additional variable   where upon setting
i     for    i  n  the separating hyperplane is
given by   wt w 
     prediction results by cross validation
for each of the learning algorithms  we carry out the
k fold cross validation for l models as follows 
algorithm     cross validation 
 a 
 b 
 c 
 d 
 e 
 f 
 g 

randomly partion s into s         sk   set i      j     
train mi on p  j sp to find hypothesis hij  
test hij on sj to find ij   set j   j     
if j   k  go to  b   else if  go to  e  
set i   k   jk ij   i   i      j     
if i   l  go to  b   else if  set i   arg min il i  
retrain model mi on s to find hypothesis h 

here  ij is the training error  we used k      with
l     corresponding to naive bayes  logistic regression 
and soft margin classifiers 
the following table shows the f  scores when the classifiers are trained by the set of features built on s   
classifier
naive bayes
logistic regression
support vector machine

x 
    
    
    

x  
    
    
    

x   
    
    
    

since all three classifiers perform similarly  the k fold
cross validation is not very meaningful in this case 
although  alone return high f  scores  it is evident
that  and  significantly enhance the accuracy of link
predictions 
as for the set of features built on s    the k fold cross
validation selects logistic regression as it returns the
higest f  scores for each training set 
classifier
naive bayes
logistic regression
support vector machine

x 
    
    
    

x  
    
    
    

x   
    
    
    

observe that all three classifiers experience a steep
learning curve despite the low f  scores for x    in
this case   and  play a crucial role in improving the
performance of all three classifiers 
we now look at the f  scores corresponding to the set
of features built on s  
classifier
naive bayes
logistic regression
support vector machine

x
    
    
    

 
x
    
    
    

  
x
    
    
    

as with the previous cases  we see an overall improvement with the addition of  and  into the feature
set  the naive bayes classifier has a slightly higher f 
  
than the other two 
score for x
references
   l  backstrom  j  lescovec  supervised random walks  predicting and recommending links in social networks  in
proc  acm wsdm        
   s  le cessie  j  van houwelingen  ridge estimators in logistic
regression  appl  statist     no           
   d  liben nowell  j  kleinberg  the link prediction problem
for social networks  in international conference on information and knowledge management        
   d  liben nowell  j  novak  r  kumar  p  raghavan  a 
tomkins  geographic routing in social networks  pnas
               
   p  chen  c  lin  b  scholkopf  a tutorial on  support vector machines  applied stochastic models in business and industry           
   a  narayanan  v  shmatikov  de anonymizing social networks  in proc  of ieee symposium on security and privacy 
      
   s  scellato  a  noulas  c  mascolo  exploiting place features
in link prediction on location based social networks  in
proceedings of   th acm international conference on knowledge discovery and data mining        

fi