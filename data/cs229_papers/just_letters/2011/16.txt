design space characterization in
micro architecture design and implementation
john brunhaver

haowei zhang

stanford university
jbrunhav stanford edu

stanford university
zhanghw stanford edu

abstractmodern vlsi designs contain both microarchitecture parameters and implementation parameters  these
can be used to facilitate verification and relaxed design specifications  we concentrate on extending prior work in understanding
design parameterization and using those design knobs to make
global optimizations 
this paper discusses the application of machine learning
techniques to improve the efficiency and quality of the design
space characterization and optimization  specifically  we propose
improvements to the circuit energy vs delay characterization 

i  i ntroduction
in this report we will discuss the contribution to numbers
made this quarter as a part of our cs    project 
   we built a framework to query the design parameters in
order to map its full design space 
   we used non linear least squares regression to characterize the energy delay trade off of circuits  this
characterization reduced the design space parameters
into a single pseudo parameter representing a design
trade off in energy and delay 
   we examined the training and test error rates required
for effective fitting of theses functions 
the trend in micro architecture design over the past decade
has been to increase the number of parameters specifying the
delay  composition  data structures  algorithms  and protocols
of the hardware description language  hdl  blocks  much
of this has been a function of increasing pressures from
verification and late design specification  combined with the
large number of implementation  synthesis  and place n route
parameters the design space is significant  the opportunity
here is to capitalize on the design parameterization to provide
optimized designs without requiring significant engineering
effort 
this design space optimization problem     can be described
abstractly as a three step problem  first  sample portions of
the design space  second  given these samples characterize
the design parameters affect on design cost and performance 
third  using this characterization and a set of constraints 
optimize the design parameters for a given cost function 
unfortunately generating design space samples can be quite
expensive 
for example generating one sample for a simple microprocessor execution core through the simulations and synthesis
would be measured on the order of days  for a deeply

parameterized design with a complicated feature space could
take many months to brute force generate the cost  performance  parameter pairs required to build a low error analytic
expression 
our optimization framework extends prior work developing
methodologies to guide the design of highly parameterized architectures      our goals are to both build design optimization
into this methodology  genesis  and to improve the methodology through a better understanding of the requirements for
optimization 
our approach has been guided by prior work optimace
     one of our goals is to integrate many of the optimace
strategies into genesis  specifically  we adopt the approach
of building analytic characterizations at the leaf nodes of the
design hierarchy and then lifting these characterizations up
into the circuit independent evaluations of the parent nodes 
in the case of our microprocessor execution core this would
mean developing analytic expressions to describe floating
point units  register files  caches  etc  each of these smaller
units may only take hours to build reasonable analytic models
for their performance  cost  and parameters  fast simulation
also measured in hours can be used to build a cost performance model for the architecture independent of the circuit
parameters  the two sets of models can be combined later to
provide the full estimation required 
our goal is to alter genesis to include a design space
exploration component  numbers   numbers should start
by integrating the optimace into the configurable design
framework  numbers will focus on providing the physical
part of the co design optimization problem  the architecture
part exists as a later extension to this project 
numbers should provide  circuit energy vs delay regression  the circuit energy and delay vs design parameters regression  and the architectural performance and costs regression 
additionally numbers should provide a sampling function
to facilitate the generation of new sample points for improved
characterization or optimization speed and quality 
numbers however must be design agnostic  and capable
of building these models based on deep parameterizations
without a full understanding of the underlying architectures 
this is a departure from optimace  which focused on lightly
parameterized microprocessors  for example  one of the target
designs is an asic that implements the processing required
for aperture radar 

fiin this report we will discuss the contribution to numbers
made this quarter as a part of our cs    project  additionally 
we will discuss some future work  possible optimizations  and
project goals as this report doubles as a milestone report for
a three quarter project 
ii  p rior w ork
current approaches to vlsi design are currently migrating
from a set of fixed design choices towards flexible designs
which encode designer intent      the approach we take for
our designs is to leverage the elaboration and generation
engine genesis      this provides a framework in which
the design elaboration and parameterization is specified in perl
code mixed into the hdl  the generator evaluates these hdl
designs and extracts xml configurations briefly describing the
topology and parameters of the design 
our goal has been to take this framework and incorporate
both architectural optimization knowledge        and circuit
optimization        to build joint architectural and circuit
optimizers           
o  azizi created an integrated optimization framework that
performs a co exploration of architectural and circuit level
design spaces            in this framework  large architectural
design spaces are modeled with statistically sampling and
regression  the underlying circuits are characterized using
stratified sampling and regression to create a circuit library 
then a joint architecture circuit model is created by linking
these two design spaces with a regression based on posynomial
functions  geometric programming is then utilized to evaluate
the posynomials and minimize a given cost function  using
this framework  various architectures including single issue inorder processor and quad issue out of order processor have
been compared  this comparison led those authors to suggest
a strategy to achieve the high energy and area efficiency
microprocessors      
our work for cs    sought to improve the circuit models
from o  azizis work in order to deal with deeper design
hierarchies and slightly more complicated design spaces 
while we did not have an opportunity to evaluate these
machine learning approaches due to limitations in infrastructure and time  we believe that many of the machine learning
approaches to combinatorial optimization may be useful in
increasing the efficiency of our flows           additionally 
we expect that it will be useful to evaluate the accuracy
interval of many of estimates as function of the domain      
these intervals can be used both as a constraint in minimizing
characterization error   sampling rates would dynamically vary
with the complexity of the underlying design space  and
in minimizing optimization error   recursive characterization
would be required in regions where optima are expected to
exist  
iii  n umbers   c ircuit c haracterization f low
in order to get a single design point representing the energy
cost of a given circuit parameterization at a specific delay  each
parameterization has its own continuous function describing a

trade off in delay and the energy required for that operation  
we must run elaboration  simulation  synthesis  place  and
route  we examine energy and delay pairs as these can be
incorporated into the architectural model to find performance
per watt and similar metrics used for system optimization 
elaboration accepts the parameters and produces and a fixed
hdl design for those parameters  simulation evaluates both
correctness and performance in the hdl simulator while
extracting the toggle rates for accurate energy estimation in
later stages  synthesis maps the hdl to a gate level netlist
and sizes the gates to minimize an expected delay  place and
route determines the physical location of these gates and the
wires that connect them  we did not run place and route as it
nearly triples data collection time and disk space  
to build the characterization of a circuit for a given function
we have a wrapper for the elaboration tools to extract the
parameterization space from genesis  this is required as
the design space has been encoded into the hdl but it has
not be explicitly stated  instead the design space exists as a
set of parameter evaluations that must be executed in order to
understand their extent 
given a set of energy delay pairs we need to preprocess the
data to find the pareto points  unfortunately  because the tools
produce noisy results we cannot reject all non pareto points 
we should keep points that have a sufficiently high probably
of being a design which exists on the true pareto frontier but
is simply perturbed by noise  we use a manually tuned relative
threshold to nearby points in order to achieve this affect 
with the pareto frontier we would like to create an analytic
function for optimization and interpolation  our basis function
is a shifted and scaled hyperbola 
e  i   

 
   
   d i 

   

these can be grouped piecewise to describe discontinuous
functions  to do this we fit k piecewise elements to the pareto
frontier where k is the number of piecewise elements that can
be supported by the data  we felt that one piece for every   
data points was reasonable  though this wasnt well explored 
we split the domain into k probable pieces  including empty
pieces  and fit single shifted and scaled hyperbola to that
portion of the space  as least squares minimization of a nonlinear function is non convex  and subject to local optima  we
initialize the parameters with estimates for the two asymptotes 
additionally we constrain the solution to make sure that the
asymptotes occur to the left and below of the actual data   to
guarantee that singularities do not occur in the domain  and
that the scale factor is positive to guarantee the knee shape 
this process is repeated to encompass all possible partitions 
   generate energy delay pairs across parameter space 
   prefilter design points for probable pareto designs
   k piecewise hyperbola regression
a  for each possible partitions of the function domain
i  estimate initial parameters algebraically
ii  calculate parameter constraints

fipartial product multiplier designware   b

iv  r esults

cmp  designware   b

  

    

optimal frontier
piecewise fit
oldfit

optimal frontier
piecewise fit
oldfit

    

  
   

    

eng  pj 

eng  pj 

  

  

  

    

    

    

   

  
    

  

 

 

 

 
del  ns 

 

 

    

 

 

   

 

 a  multp

   
del  ns 

 

   

 

 b  cmp 

multiplier designware    b

add designware    b

  

 

optimal frontier
piecewise fit
oldfit

  

optimal frontier
piecewise fit
oldfit
   

  
   

  
eng  pj 

eng  pj 

   

  

   

  
   

  

   

  

  

 

 

 

 
del  ns 

 

 

 

 

   

 

 c  mult

   
del  ns 

 

   

 

 d  add

fig     energy vs delay pareto frontier fits for a    bit partial
product multiplier     bit six function comparator  a    bit
multiplier  and a     bit adder  with the exception of the
comparator these units generally compose a floating point
multiply accumulate unit  new fits represent our method and
old fits represent a fit using   piece 

figure   provides four examples of piecewise fits on a large
number of data points and compares them to a fit using only
one hyperbola  visually the curves adhere well to the data 
there are some unfortunate discontinuities in the curve fit
that should be resolved in order to increase the utilities of
these fits in later optimization stages that expect monotonically
decreasing functions  note that this is one of the better cases
as there is a relatively large amount of data relative to the
curves 
figure   shows the training and test error for these points 
note that the extent of the x axis represents that total number
of points available  each point was evaluated     times using a
random stratified subsample of the pareto frontier  the training
error and test error results are quite noisy and seem to be
accurate to about an order of magnitude  both approaches
should have about the same error around      samples as this
will be the region that our algorithm uses one hyperbola to the
data  we expected a similar drop around     but did not see
one  we suspect that the fitting algorithm tends to favor only
two hyperbolas  in any case it appears that about    points is
required in order to achieve mean errors of     in terms of
automation this means that we can stop filling in the pareto
frontier after seeing about    well stratified points 
v  f uture c ircuit c haracterization w ork

fitting error adder dw

 

  
training error new
test error new
training error old
test error old

 

  

 

 

  
mean relative error

mean relative error

training error new
test error new
training error old
test error old

 

  

  

 

  

 

 

  

 

  

  

 

 

  

  

 

  

fitting error icmp 

 

  

 

 

  

  

  

  
sample count

  

  

  

  

  

 

  

  

 a  add 
fitting error multiplier dw

 

  

  
sample count

  

  

  

  

 b  cmp 
fitting error adder sklansky

 

  

  

training error new
test error new
training error old
test error old

 

  

training error new
test error new
training error old
test error old

 

  

 

  
 

mean relative error

mean relative error

  

 

  

 

  

 

  

there are a number of optimizations left that could be done
to further optimize the characterization of circuit delay and
energy 
a better pareto pre filter could have a small but helpful
impact on the quality of the results  with a greater number
of points available for fitting the fewer total simulations are
required  to improve the filter we suspect that a probabilistic
filter based on a characterization of the design tool noise would
be more robust than a simple relative threshold 
while the scaled and shifted hyperbola provides both the
general shape we are looking for and the asymptotic energy
and delay behavior  it isnt clear that it captures behavior
like linearly increasing dynamic energy with delay and sharp
knees  providing other functions as a basis may be useful  for
example 

 

  

 

  

 

  

 

 

  

e  i   

 

  

 

  

  

  
sample count

 c  mult

  

   

   

  

 

  

  

  

  
sample count

  

  

  

  

 d  add 

fig     training error and testing error for the one piece and
a general k piece wise fit  the average relative error seen for
    stratified random samplings consisting of the number of
samples indicated on the x axis  note that the data is fairly
noisy and is only accurate to an order of magnitude 

iii  fit each piece individually against its portion
of the domain 

 
   
    d i    

   

the current algorithm for selecting the best separations in
the piecewise function is often arbitrary using random initialization and iteration to converge to local minims  however
these separations are  visibly  likely to occur near places where
the second discrete derivative is high  this might provide more
robust convergence and significantly reduce the runtime of the
current algorithm 
currently we utilize the squared error of the data  however 
this isnt quite the error that we are actually attempting to
minimize  we are interested in the maximum relative error to
the nearest point on the fitted function  additionally  we are
more interested in the fitting that occurs at the extremes of the

fimemcache       way   bit normal  banks vs memcache       way   bit normal  banks vs

memcache       way   bit normal  banks
memcache       way   bit normal  banks

  
  

dynamic energy  pj 

 
 
 

acknowledgments
 

thank you to ofer shacham and omid azizi for providing
some great problems to work on and some great advice along
the way

 
 

r eferences

 
 
    

     

    

     

    
     
delay  ns 

    

     

    

functions  near the minimum delay  minimum energy  and the
knee of the function 
finally  we would like to include many of our insights here
into fitting functional parameters that are exposed to upper
levels of the hierarchy 
for structure such as caches and buffers  delay and energy
also depend on the storage capacity  to capture this dependency in circuit library  a more complex fitting function is
needed  this could be done by first starting with basic tradeoff curve  then parameterize each of the fit parameters with
monomials 
where the primed variables and various bs are new fit
parameters  in this way  a new function is produced that defines
the cost as the joint function of its size and delay 
generally  creating fitted energy models as a joint function
of size and delay can be harder to produce than with the simple
energy delay trade offs since there are more data points that
need to be simultaneously captured  to achieve acceptable
accuracies in the cases of caches  ranges of sizes are often
restricted to a limited set of values 
vi  r esearch q uestions




   we built a framework to query the design parameters in
order to map its full design space 
   we used non linear least squares regression to abstract
implementation parameters from the energy delay pareto
frontier of leaf cells in the design hierarchy 
   we examined the training and test error rates required
for effective fitting of theses functions 

is it possible to derive analytic expressions of higher levels of the hierarchy in terms of lower level characteristics
of the design   ie would it be effective to sample sparsely
at high levels in the design and densely in lower levels
of the design to build characterizations of   
these new piecewise functions introduce a non convexity
into the original formulation  how do we deal with this
in a way that doesnt require increased simulation or
computation 
vii  c onclusion

thank you for the cs    experience  we learned a lot and
feel like we have a good start on a bigger project 
for cs    we 

    o  azizi  design and optimization of processors for energy efficiency 
a joint architecture circuit approach  ph d  dissertation  stanford university       
    o  shacham  chip multiprocessor generator  automatic generation
of custom and heterogeneous compute platforms  ph d  dissertation 
stanford university       
    o  shacham  o  azizi  m  wachs  w  qadeer  z  asgar  k  kelley 
j  stevenson  s  richardson  m  horowitz  b  lee  a  solomatnikov  and
a  firoozshahian  rethinking digital design  why design must change 
micro  ieee  vol      no     pp        nov  dec       
    t  stanley and t  mudge  systematic objective driven computer architecture optimization  in advanced research in vlsi        proceedings   sixteenth conference on  mar       pp          
    e  ipek  s  a  mckee  r  caruana  b  r  de supinski  and m  schulz 
efficiently exploring architectural design spaces via predictive
modeling  in proceedings of the   th international conference
on architectural support for programming languages and operating
systems  ser  asplos xii  new york  ny  usa  acm        pp     
      online   available  http   doi acm org                        
    b  lee and d  brooks  illustrative design space studies with microarchitectural regression models  in high performance computer
architecture        hpca       ieee   th international symposium
on  feb        pp          
    a  hartstein and t  r  puzak  the optimum pipeline depth for a
microprocessor  sigarch comput  archit  news  vol      pp   
    may        online   available  http   doi acm org                
      
      the optimum pipeline depth considering both power and
performance  acm trans  archit  code optim   vol     pp     
     december        online   available  http   doi acm org         
               
    m  h  dinesh patil  joint supply  threshold voltage and sizing optimization for design of robust digital circuits  tech  rep 
     o  azizi  a  mahesri  s  j  patel  and m  horowitz  area efficiency
in cmp core design  co optimization of microarchitecture and physical
design  sigarch comput  archit  news  vol      pp        july
       online   available  http   doi acm org                        
     j  a  boyan and a  w  moore  using prediction to improve combinatorial optimization search  in in proc  of  th intl workshop on artificial
intelligence and statistics       
       learning evaluation functions for global optimization and
boolean satisfiability  in in proc  of   th national conf  on artificial
intelligence  aaai  aaai press        pp      
       learning evaluation functions to improve local search 
     a  s  weigend and d  a  nix  predictions with confidence intervals
 local error bars        
     d  l  shrestha and d  p  solomatine       special issue  machine
learning approaches for estimation of prediction interval for the model
output  neural netw   vol      pp          march        online  
available  http   dx doi org         j neunet            

fi