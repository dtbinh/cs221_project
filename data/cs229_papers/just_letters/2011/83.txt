creating a better above the fold experience  predicting news article
preferences
anil das
walter mostowy
december         

 

background

news article preferences provide a ripe area for learning  readers have differing  and sometimes complicated 
preferences  while it is reasonable to assume that a readers indicated past history is correlated with
future preferences  preferences are likely somewhat variable depending on  e g   the time of day  editorial
responsibilities aside  a good algorithm would save users time by directing them to exactly what they want
to read  or perhaps an algorithm more tuned to editorial oversight could pop the filter bubbles by gently
introducing readers to different  edifying topics 

 

problem domain

we would like to predict users interest in arbitrary news articles  more specifically  presented with a
particular article  we would like to predict whether a particular user will interact withthat is  read or
click through tothat article  metadata available to us include the articles headlines and rss source feeds 
we also consider the timestamps at which the user interacts with the articles  in this paper  we describe a
learning model used to make useful predictions given these metadata 

 

method

we were provided with a full months  august       worth of data on      users from the pulse app
for mobile devices     which presents the user with news stories he might be interested in  we trained and
experimented on     of these users  we discuss the resulting scores on the remaining     users in the results
section 

   

preprocessing

after cleaning the data by removing corrupt records  we converted each story title to a vector of word stem
counts  stemming was done using the porter stemming algorithm     though we discarded stems with fewer
than three characters  we also converted each stem count vector to a tf idf vector    using the tf idf formula 
tf idf   tf log

 d 
idf

where  d  is the total number of titles  idf is the number of titles in which the stem occurs  and tf is the
number of times the stem occurs in the title in question 
 

fi   

baseline

as a preliminary baseline for purposes of comparison  we constructed logistic regression models and support
vector machines against our processed design and target matrices  if one were to naively measure the
predictive power of these models without looking at the confusion matrices  one might conclude that their
achieved     accuracy rates were very good  however  one must consider the fact that no user can ever
interact with more than a very small fraction of possible stories  a trivial model which always guesses in
the negative would do just as well  therefore  in order to more meaningfully measure the success rates of
our models  we used the f  score calculated from the confusion matrix 


precision  recall
f     
precision   recall
our preliminary f  scores were measured to be very low  averaging about      
there were several reasons for this low score  perhaps the most obvious reason is that the the number
of negative instances in the target vector vastly exceeds the number of positive ones  because the data
is necessarily noisy  the success of correctly classifying many negative examples overwhelmed the noisy
successes of correctly classifying the positive ones  resulting in a poor hypothesis fit  in addition  we only
included stems from story titles and ignored other important signals  the remainder of this paper describes
how we addressed these issues 

   

algorithm and model selection

we tested logistic regression  linear svms using the liblinear library  and svms with a kernel of k u  v   
 ut v   r d using the libsvm library  we implemented one using the limited memory bfgs algorithm in the
minfunc    optimization library  we empirically found the degree d     to be optimal for libsvm models 
however  we achieved our greatest f  scores using our logistic regression model 
because we saw high variance when inputing normalized tf idf features into logistic regression  we searched
for a regularization parameter to decrease variance  to this end  we used the regularized logistic cost function
x

c          
y log g t x        y  log    g t x  
where  is the regularization parameter  g is the sigmoid function  and y is an element of the target bit vector 
we empirically found           to be the best model 
however  the training and testing errors remained quite high due to the aforementioned overabundance
of negative examples in our data  in order to alleviate this  we adopted an algorithm to split the negative
training data into disjunct subsets  iteratively  a logistic regression model would be trained against all of
the positive examples and one subset of negative examples of about the same size  passing the resulting
parameter  as a guess for the next iteration  once the algorithm iterates through all the negative examples
in this way  a final learning phase would train on all the positive examples and an equal number of negative
examples which were the most likely to be misclassified during iterated learning phases  the hypothesis
obtained from this final phase would then be used for making the desired predictions 
using this iterative logistic regression  we were able to fit a very good separating plane between the entire
set of positive and negative training examplesreaching a mean f  above      see figure  b   testing f 
scores improved  as well  see figure  a  
     

stem vector representation

we also considered presenting the features as stem counts  tf idf or normed tf idf to our algorithms and
models  we found the normalized tf idf design matrices to be the form producing the best results 
 

fi a  test scores

 b  train scores

figure    iterative logistic regression

     

cross validation

we conducted    fold cross validation by training on the first d days and testing on the remainder  for this
purpose  the preprocessed data were split into separate matrices  one for each day  so that for an arbitrary
day d  we could more easily train on the first  d days and test on the remaining days  we also set aside all
the data for a group of     users for final validation 

   
     

feature selection
feeds

we found the rss source feed for a story to be an important signal  taken over the aggregate  we could
approximate the set of feeds to which a user subscribed  this was useful to us because users are only
presented articles from the feeds to which they are subscribed  we used this feed information to mark stories
that would not be available to a user as negative  thus bypassing the logistic learning model   we then
conducted training and testing only on the remaining stories 
we also added the feeds from which a story was available as a bit vector feature to the design matrix
rows 
     

time of day

we conducted an error analysis on a selection of the users that were giving low prediction scores  from
this analysis  we found that users had different temporal patterns of activity  and in particular  users tended
to be wholly inactive for large parts of the day  further  these patterns were distinct from the aggregate
temporal pattern of activity  to take advantage of this data  we added as features to the design matrix the
hours of the day at which users interacted with a story 
with these feed and hour data added  see figure     our mean f  improved to      

 

fifigure    scores for the model with feed data and hour data

     

clustering of users

we hypothesized that users can usefully be grouped into clusters of similar interest  if true  whether a peer
group already interacted with a story would be an important signal  to convert this idea into a feature  we
took the set of stories that the user read in the training set as a bit vector  and using euclidean distance
measurements  we clustered the users using k means algorithm into    clusters  then for each story in the
design matrix  a feature was added showing what fraction of the people in a users cluster interacted with
the story on previous days  data from the current day was not included  because such data might include
data about the user himself  i e  the event we are trying to predict 
using this approach  our mean f  scores improved to      and training scores remained high at     
     

feature culling with mutual information

in order to reduce variance  we culled our word stem vectors using mutual information measurements  figure
  shows  for    randomly selected users  the mutual information for all features  where the features have
been ranked by mutual information 
one can see that the mutual information measurement rises from the baseline only for a very few features 
typically less than      we used this fact to select only features that showed a high mutual information
value for some user  this reduced our feature vector length from approximately        to around       
however  the resulting improvement to mean f  scores was minimal  about      

 

results

for each of the    days  excluding day     of data  we trained and tested a model for each of the      users 
the training design matrix consisted of all of the data for all days up to the current day  the resulting
model was then tested against the data for the remaining days of the month  this resulted in a mean f 
score of about      the f  scores for the holdout set of     users were very close to that of the initial set of
    on which we developed our model 

 

fifigure    mutual information

figure    the scores resulting from our final learning model and algorithm

 

references

    http   pulse me 
    http   tartarus org martin porterstemmer 
    sparck jones  karen  a statistical interpretation of term specificity and its application in retrieval
       
    http  www di ens fr mschmidt software minfunc html

 

fi