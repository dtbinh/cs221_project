finding structure in cytof data
or  how to visualize low dimensional embedded manifolds 

panagiotis achlioptas
panos cs stanford edu 

general terms
algorithms  experimentation  measurement

keywords
manifold learning  dimensionality reduction  flow cytometry  cytof

  

introduction

high dimensional data are notorious for the difficulties that
pose to most of the known statistical procedures that aim
to manipulate the data in a meaningful and enlightening
way  the so called phenomenon of the curse of dimensionality has a severe negative impact to our current methods
for various reasons  the size of the considered space grows
exponentially as the number of dimensions increases  meaning that for instance solving a density estimation problem
in such a space requires exponentially many samples  if no
further assumptions are made   single cell mass cytometry  cytof  is a recently introduced technique      that is
anticipated to revolutionize the field of hematology and enhance our general understanding about the cells of living
organisms  a main obstacle towards these goals is going to
be the analysis of the produced  high dimensional  data 
how are we going to deal with data that live in an ambient space of e g      dimensions  definitely  without any
further assumptions  our task will be difficult  hopefully 
as with many other real life produced datasets we expect
that cytof data will be governed by only a few degrees
of freedom  such a scenario is possible when for example
the data lie on a  non  linear manifold of low dimensionality  embedded in a higher dimensional space  this kind of
data is said to have a small intrinsic dimensionality and
various techniques have been produced in order to discover
the essential forces that shape the data  leading to various
dimensionality reduction schemes  
in this article  we will make the first move by showing that


computer science department  stanford university 

data produced by cytof are indeed intrinsically low dimensional and we will apply to them various state of the
art techniques in order to get a concrete visual representation of them  the remainder of this article is organized as
follows  in section   we begin by giving a brief description
of the kind of data produced by cytof along with some
notational conventions  next  in section   we thoroughly
introduce three popular techniques for estimating the intrinsic dimension of a data set sampled from a manifold  in
sections         we describe the algorithms and the strategies we used for discovering the non linear  low dimensional
embedding of cytof data  instead of describing the experimental component of this article in a separate section 
we explain our findings along with each technique used  we
make our final conclusions in section   

  

cytof data

the cytof data at hand  are composed by measurements
of    humans cell characteristics  varying from the diameter
of a cell  to its various proteins abundances  though   
dimensions used for describing the state of each cell are few
compared with the number of dimensions produced in other
instances of the problem  e g a      pixel photograph lives
in the      dimensional space   still  having for example a
visual representation in the    dimensional space  is far from
easy  also  we anticipate that in the near feature cytof
will be able to measure up to a hundred features of a cell 
giving further importance to this first exploratory analysis 
on top of this  instead of having a single  static  snapshot for the characteristics of the analyzed cells  cytof
generated different snap shots over   different time periods 
the data is organized in xt  n  d  matrices  where n is the
number of analyzed cells  up to many thousands   d     
is the ambient  high  dimension and t                 varies
over the different time periods  finally  we mention here 
that for many evaluation benchmarks the data behaved very
similarly over the different time points  in these cases  for
reasons of space saving  we present the experimental findings
only for a single point in time t   c  for the rest of this
article  xi  rd will represent the i th analyzed cell and
yi  rd its counterpart in the low d dimensional embedding 

fi   estimating intrinsic dimension
thresholding principal components
given a set sn    x            xn    xi  x  i              n of data
points sampled independently from a manifold m   probably
the most obvious way to estimate the intrinsic dimension 
dintr   is by looking at the eigenstructure of the covariance
matrix c of sn   in this approach  dpca is defined as the
number of eigenvalues of c that are larger than a given
threshold  this technique has two basic disadvantages  first
it requires a threshold parameter that determines which
eigenvalues are to discard  in addition  if the manifold is
highly nonlinear  dpca will characterize the global  intrinsic  dimension of the data rather than the local dimension
of the manifold  dpca will always overestimate dintr   the
difference depends on the level of nonlinearity of the manifold 
luckily  our data suggest a very clear threshold  as seen
in figure   the three largest eigenvalues capture more than
    of the total variance  while the elbow between the
third and fifth eigenvalue indicates the sharp decrease of the
captured variance  thus  we can be confident that dintr
with high probability will be less than   and it seems that
even a meaningful   dimensional embedding of the data
exists  in order to enhance our reasoning for the existence
of a low dimensional embedding we estimate dintr with two
more statistics 

correlation dimension
the second approach to intrinsic dimension estimation that
we used is based on geometric properties of the data and
requires neither any explicit assumption on the underlying
data model  nor input parameters to set  it is based on the
correlation dimension  from the family of fractal dimensions
and the intuition behind its definition is based on the observation that in a d dimensional set  the number of pairs
points closer to each other than r is proportional to rd  

definition    given a finite set sn    x            xn   of a
metric space x  let
cn  r   

n
n
x
x
 
i   xi  xj      r 
n n     i   j i  

where i is the indicator function  for a countable set s  
 x    x             x  the correlation integral is defined as
c r    limn cn  r   if the limit exists  the correlation
dimension of s is defined as
dcorr   lim

r 

log c r 
 
log r

since  for a finite sample the zero limit cannot be achieved 
we instead used the scale dependent correlation dimension of a finite set  this is defined as
definition   
log c r     log c r   
dcorr  r    r     
 
log r   log r 

in our experiments instead of measuring dcorr for some constant  small values  r    r    we defined them to be the median
and the maximum distance  respectively   among the distances defined by the k nearest neighbors of each datapoint 
thus  for each datapoint we computed a separate dcorr and
our final estimate was their average value  we noticed our
results to be very robust under different values of k 
unfortunately  it is known that dcorr  dintr and that
dcorr approximates well the dintr if the data distribution
on the manifold is nearly uniform  our approach of using different ri s is not enough to circumvent this   we deal with
the known non uniformity of the cytof   by using our last
estimator  this of packing numbers     we avoid giving a detailed analysis of this recently introduced technique  intuitively it tries to efficiently estimate the number of minimum
open balls whose union covers the space s  this technique
was shown to not be dependent on the data distribution of
the manifold 

intrinsic dimension of cytof data
as seen in figure   cytof data  xt    for all the different
time points seem to lie on a low dimensional manifold  the
principal components and the correlation dimension bound
dintr between   and        for estimating dcorr we used
the distances of the k      nearest neighbors of each datapoint   supported by these results  we turn to our next
goal which is to find a meaningful visual representation of
the data 

  

the globally linear case

if we knew that the our data lived on  or very close to  a
linear subspace  a d dimensional hyperplane embedded in
the ambient space  then pca would be the tool to use  it
would perfectly discover the embedded hyperplane  since
this would be the hyperplane spanned by the d eigevectors
of the empirical covariance matrix that would have non zero
 or very close to zero  eigenvalues 
but what if the data live on a more complex micro world 
like a non linear manifold  we will describe and use   different techniques to deal with such a scenario  lle  isomap
and t sne 

  

locally linear embedding

locally linear embedding      or lle  is based on the idea
that over a small patch of a smooth manifold  its surface
is approximately flat  thus  it proposes to use the expected
local linearity of the manifold in order to find a linear weightbased representation of each point from its neighbors  characterizing in this way the local relative positioning of each
neighborhood in the high dimensional space  by using this
local parameterization one can look for a new set of points
in a lower dimension which preserves  as closely as possible 
the same relative positioning information 

the first step of lle is to solve for the weights that best
characterize the points relationship in rd  
 

apart from the experimental results which were supporting
it  we had prior knowledge for the existence of small  distinct
cell sub populations 

fiw   arg min
w

n
x
i  

 

x

  xi 

   estimate the geodesic distances  shortest curved distances  among the data points in rd  

wij xj   

   

wij    

   

   use mds to embed the data points in a low dimensional
space that best preserves the estimated geodesic distances 

jn  i 

s t 

i

x
j

where n  i  is the neighboring points of xi  the neighborhood
of each point can be calculated with various means  e g 
based on the k nearest neighbors or by some local sphere
of radius  around xi    the size of the neighborhood is a
compromise  it must be large enough to allow for a good
reconstruction of the points  it must contain at least dintr
points   but small enough for not violating the locally linear assumption  with the normalization requirement added
the produced weight based representation will be invariant
to any local rotation  scaling  or translation of xi and its
neighbors 

the second step is to find the embedding y which best preserves the previously found local configurations 

y   arg min
y

n
x
i  

s t 

x

  yi 

wij yj   

 

   

jn  i 

y        

y y t   in

   

under the above constrains  the problem is well posed and a
unique globally optimal solution can be found analytically 
by reformulating it as a quadratic program 

   

lle in practice

we tried lle with a varying number k for the nearest neighbors of each data point  measuring their distances under the
euclidean norm  a meta parameter of lle   we found the
algorithm to perform extremely poorly when we used as its
input the entire analyzed cell population of any given time
period  see figure  a    the reason behind this failure is explained graphically in figure    here we we have plotted the
percentage of cells captured by the two largest connected
components of the  disconnected  neighborhood graph 
under different values of k  in other words  the raw high
dimensional data even for k       the ambient dimension 
do not form a strongly connected neighborhood graph 
in  b  we used a value of k      and the algorithm considered      of the cell population  the cells that form the
largest connected component  the rest    of the cells were
completely ignored  treated as very noisy observations  a
justification for this stems from the fact that this    was
scattered through roughly     different unconnected components  resulting in a lots of very small      cells each  groups
of unrelated data 

  

isomap

isometric feature mapping  or isomap     may be viewed
as an extension of multidimensional scaling  mds   a classical method for embedding dissimilarity information into
euclidean space  isomap consists of two main steps 

for the first part of isomap  we appeal again to the local linearity of the manifold  if our data are sufficiently dense  then
there is some local neighborhood in which the geodesic distance is well approximated by the naive euclidean distance 
taking this local distances as trusted  farther distances may
be approximated by finding the length of the shortest path
along trusted edges 

   

isomap in practice

for the approximation of the geodesic distance to be accurate  among distant points  the prerequisite of dense data
is essential  a simple way to achieve this would be to use
the neighborhood graph resulted by some large value of k 
on the other hand  such an attempt with high probability
would suffer by what is know in the literature as short circuit distances  which can lead to drastically different  and
incorrect  low dimensional embeddings  k      was found
to be the golden ratio in our empirical results as it managed
to give a good balance in the trade off between the fraction
of the variance in geodesic distance estimates which are not
accounted for in the euclidean  low dimensional  embedding  and the fraction of points not included in the largest
connected component  see figure    

  

t sne

t distributed stochastic neighbor embedding      works under a different vain  it was developed to address the problem of visualizing the high dimensional data  aka it works
for embeddings with d    and its not appropriate for arbitrary dimensionality reduction  its basic idea is to describe
the similarities between data points  e g  their euclidean
distances  as conditional probabilities and then try to minimize the  kullback leibler  divergence of these probabilities
as they were captured in the low and the high dimensional
space respectively  in a sketchy description  t sne works
as follows 
    xi in the high dimensional space let pj i to be proportional with the density of   xi  xj    drawn from a
gaussian xi     
    yi in the low dimensional space let qj i to be proportional with the density of   yi  yj    drawn from a
students t distribution with   degree of freedom 
   use a gradient descent
to minimize the
p p like method 
pij
the kl p   q    i j pij log qij
the success of this method  as also revealed in the cytof
data  is that it effectively copes with the crowding problem     this problem in simple words stems from the fact
that the area in two  or three dimensions that is available to
accommodate moderately distant points  in the high dimensional space  will not be nearly large enough compared with

fithe area available to accommodate nearby points  thus  if
we want to model the small distances accurately in the low
dimensional space  most of the points that are at moderate
distance from point i will have to be placed much too far
away from it  the way t sne achieves this in an effective
manner comes from the use of the heavy tale t student distribution for modeling the distances in the low dimensional
space  comparing it with the probabilistic setting of sne
or lle  where every pairwise distance can be regarded as
having being generated under a gaussian distribution  with
mean equal to one of the two points   the t distribution
makes it much more likely for   points to be embedded far
away from each other  thus as seen  also in our experiments
 see figures         t sne produces less compact and thus
cleaner results  for all our experiments with t sne we
used gradient descend for      iterations and with    different re initializations  in most cases we manage to converge
to a local minima pretty quickly 

  

   

references

    sean c  bendall et  al  single cell mass
cytometry of differential immune and drug
responses across a human hematopoietic
continuum  science       
    sam roweis  lawrence saul  nonlinear
dimensionality reduction by locally linear embedding 
science                            december      
    laurens van der maaten  geoffrey hinton
visualizing data using t sne  journal of machine
learning research       
    balazs kegl intrinsic dimension estimation using
packing numbers nips       
    j  b  tenenbaum  v  de silva and j  c 
langford a global geometric framework for
nonlinear dimensionality reduction science     
                      december      

conclusions

the most important result which stemmed out from this
project is that we now have more experimental evidence that
cytof data are likely to be governed by very few degrees
of freedom  also  regarding the methods used  we can now
make some statements about their performance in this kind
of data  by visual inspection t sne outperformed all the
other methods  in order to boost this evidence  we have
measured the following type of error that each method introduced in its low dimensional embedding  for every xi   let
pi  m  be the value the i th cell has in its m th dimension
in the high dimensional space  figure      plots the sum of
the squared distances between every embedded cell and its
  nearest  embedded  neighbors  as these are formed under
the dimension of the original space pi  m  with the maximum
variance 
 the two dimensions that with maximum variance in the
original space  were those measuring the cd  and cd  
protein abundances of the cells  these   protein abundances
were used to give color to all of our plots  by coloring every
cell with an intensity proportional to its original cd  or
cd   abundance  

figure    percentage of variance as captured by an increasing number of  decreasingly sorted  eigenvalues   t      

in figure   we see the   dimensional embedding resulted
by pca  interestingly enough  it manages to separate the
data  colors  to a large extent  some results from the use
of isomap  who found to perform slightly better than lle 
are shown in           finally  in figure      one can see the
kind of the   dimensional embeddings that a k means like
algorithm could produce for this data  clearly  the manifolds
learners used outperform such an approach 

  

acknowledgements

the author would like to thank prof  daphne koller who
served as his rotation advisor in stanford and gave him the
opportunity to play around with the cytof data  also 
manfred claasen  who was an invaluable source of inspiration and help  the materials written by lawrence cayton
and alexander ihler  available online  helped him a lot in
demystifying non linear manifold learners  finally  the publicly available code of laurens van der maaten was a great
help 

figure    three estimators of the intrinsic dimension for all
the   different time periods 

fifigure    percentage of cells in largest and second largest
connected components of the neighborhood graph  t      

figure    isomap  d embedding  t       cd  cell abundances used for coloring 

 a  lle only cc

 b  lle all cells

figure    lle  d embedding  k        in  a only the
cells in the largest connected component were considered
by lle  in contrast at  b   lle was applied to the whole
cell population  the difference in the embedding is pretty
dramatic  both experiments are at  t      and for coloring
use cd   cell abundances 

figure    isomap  d embedding  t       cd  cell abundances used for coloring 

figure    trade off between the fraction of the variance in
geodesic distance estimates not accounted for in the euclidean    d  embedding and the fraction of points not included in the largest connected component 

 a  t    

 b  t    

figure    a  d embedding constructed by projecting the
cells on the   larger eigenvectors  colors resulted by cd 
cells abundances 

fifigure    t sne  d embedding  t       cd  cell abundances used for coloring 

 a  cluster  

 b  cluster  

 c  cluster  

 d  cluster  

figure     a  d embedding as considered by the k medians
algorthim  with k      for each cluster we have plotted
the colors resulted by cd   cells abundances  the relative
inner cluster  grid  positions of the cells are random 

figure     t sne  d embedding  t       cd  cell abundances used for coloring 

figure     comparison of methods as captured by the average difference between each embedded data point and its
  closest neighbors under their l  distance in feature cd  

fi