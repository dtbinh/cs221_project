node classification in multirelational information networks
rick barber  mirela spasova
december         

 

problem background

our goal will be to predict the types of entities in a large multirelational information network  in
particular  if we suppose we are given a graph g    v  e   a hierarchy of types t   and an observed
labeling function l which for each node gives a path beginning at the root of t   called the type s 
of the node  our goal will be to learn l the true labeling function of the nodes

 

data

wikipedia contains a large amount of unstructured information  infoboxes  however  are a mechanism used by the site to package many prominent features of a given wikipedia entity into a
structured summarysee below 

 

firick barber  mirela spasova

project milestone

cs    

the dbpedia dataset is a post processed version of wikipedias infoboxes  and it will be the data
set in our study  dbpedia contains more than     million entities among which there are almost
    millions directed relations 
dbpedia includes a type hierarchy of     types and gives a set of type labels for most nodes in
the network  however  a cursory look at the dataset will reveal that the set of types if often far
underspecified  obama is labeled as a thing  person but not a politician or president for instance 
and dbpedias own website claims that they have over a million entities which arent classified
beyond thing which is the root level of the ontology 

 
   

method
data generation and model

some of the parsing machinery was written in joint work with klemen simonic and rick barber
advised by jure leskovec in august of this year 
dbpedias data is available in raw form in three files  the ontology file  the properties file  and
the types file 
the ontology file is an xml file describing the hierarchy of dbpedia types  the root node is
 

firick barber  mirela spasova

project milestone

cs    

thing since all entities in the dataset are assumed to be things  we parse the xml  and store
the data as a tree structure on which a number of queries can be efficiently performed 
the properties file is a list of relations represented as triples  s  p  o  where s is an infobox entity
that we call the subject  p is the name of a relation we call a predicate  and o is either a literal
value or another entity which we call the object of the relation 
an example is given below
 http   dbpedia org resource aristotle   http   dbpedia org ontology influenced 
 http   dbpedia org resource ptolemy   
we represent this data as an actual graph  for example  with the above line we will ensure that
there is a node corresponding to aristotle and ptolemy in our graph and we will add an edge with
label influenced between these two nodes 
the types file is a list of triples  e  n  t  where e is the name of an entity and t is a type of the
entity and n is a constant we ignore 
an example is given below
 http   dbpedia org resource autism 
 http   www w  org            rdf syntax ns type 
 http   dbpedia org ontology disease   
 http   dbpedia org resource autism 
 http   www w  org            rdf syntax ns type 
 http   www w  org         owl thing   
this says that the dbpedia labeling function assigns labels disease and thing to the entity
autism  of course  we cant be certain that the true  onobserved labeling function labels autism
in exactly the same way  but we will try to use the signal of the observed labeling function to
learn the true labeling function  which we will detail later  we parse this file and store the type
information in dictionaries to query later 

   

classifiers and training test data

for our first task  we have trained binary one vs all classifiers for various entity types and for
various subsets of the data 
we use logistic regression throughout  the l   regularized version for liblinear  to be exact  in
order to easily intepret the results of our prediction probabilistically  which will be important in
the final classifier 
 

firick barber  mirela spasova

project milestone

cs    

for instance  dbpedia has a comedian type which corresponds to entities in the dataset who are
comedians  this will be our running example 
     

protocol    uniform sampling of negative examples

here we randomly sample m   p comedians and m   p non comedians from anywhere in the type
hierarchy and retain the labels of m for training purposes while hiding the labels for p for testing
purposes 
we used this protocol as a proof of concept to get us started and it served to show that we could
differentiate types on dbpedia 
     

protocol    sampling from neighbor types

here we sample positive examples as before  but for negative examples  we from types which are
sibling types of comedian in the hierarchy  we follow this procedure because our final  holistic
classifier will need to be able to differentiate between neighbor types 
     

the holistic classifier

we trained a classifier for each of the     types following protocol   above 
our procedure for making a prediction on a new input x is as follows 
 
 
 
 
 
 
 
 
 
  
  
  
  

predict  x   type tree  
lastpredict   thing
candidates   thing   children
type   add   lastpredict  
while   lastpredict not null and not leaf  
lastpredict     arg   max    c   in candidates   g    theta c   t x  
if g    theta    lastpredict    t x       
lastpredict   null
else
type   add   lastpredict  
candidates   lastpredict   children
return type

what this says is that we let all of the classifiers in the subtree of the last predicted type vote on
whether they think x is of their type or not  and we take the most confident yes vote to make a
subprediction and proceed all over again with its children as candidates 
 

firick barber  mirela spasova

project milestone

cs    

the returned type variable will indeed be a path to the root in the type tree  which is to say it
follows our definition of a labeling function 

   

features

our feature set consists of features of three distinct types  we have a set of features called the
node local features which correspond to network features like in degree  out degree  total degree 
and clustering coefficient  we have another set of features called the edge type features which
are a vector of counts of the types of edges leaving and entering the node in question  referring
to our earlier data triplet  aristotle will have at least one edge of type influenced leaving his
node while ptolemy will have at least one edge of type influenced entering his node  finally 
we will use the count of types of adjacent entities in the graph as a feature  for instance  from
the triplet above we know aristotle has at least one neighbor of type mathematician  person  and
thing namely ptolemy 

 

results

the results of attempting to fully label      randomly drawn dbpedia entities is below 
depth
depth
depth
depth

 
 
 
 

precision
    
    
    
    

recall
   
    
    
   

accuracy
    
    
    
    

we seperate our results according to the depth in the type tree at which the subprediction was
made 
at a given sublevel suppose the true label is l  if our subprediction at this level is l then we record
a true positive for class l  if our subprediction at this level is s    l then we record a false negative
for class l and a false positive for s  if our classifier prematurely stopped making predictions  we
count the subsequent true types as false negatives  and if we make too specific a prediction these
are counted as false positives for the labels actually predicted 
but since our dbpedia data is known to be incompletely specified in terms of types our results
should be read as having better precision than is indicated because we cant actually count the
dbpedia data as being the full truth  indeed  as we noted before  the barack obama entity is
specified to have type thing and person in the dbpedia network  but our classifier predicts obama
as being a thing  person  politician  president  by our evaluation standards this prediction would
reduce the depth   and   precision even though we see that our prediction is actually more credible
 

firick barber  mirela spasova

project milestone

cs    

than the correct prediction according to the data 
we output these spurious predictions to a file  and many but not all of them were of this nature 

 

summary

even though our training data was not of perfect quality  we were able to perform reasonably
well for a     class classification problem  given that dbpedias types were originally annotated
fully by crowd sourcing  our results could represent significant time savings over a purely manual
effort  furthermore  our results were obtained with a static dataset of a predetermined quality 
we belive that if instead of tasking dbpedias contributors with randomly assigning types to
the entities in their network  they answered yes or no classification questions corresponding to a
learning algorithms predictions  the training data and classifier quality would iteratively improve
to nearly converging with what should be the true labels of the data 

 

fi