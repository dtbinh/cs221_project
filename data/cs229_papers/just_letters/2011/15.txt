personalized news prediction and recommendation
abhishek arora
arorabhi stanford edu
dept  of electrical engineering
stanford university
abstract  there exist many web based news provider
applications  e g  pulse news reader application for
iphone ipad and android platforms  that gather news articles
from the myriad feeds the user is subscribed to and displays
them with in each feed category  a feed refers to a stream of
news articles that may represent a news category  e g 
gadgets  technology  sports  etc   or may be very general
 e g  rss feed provided by some newspaper for top articles 
etc    in this project  we analyze and develop machine learning
techniques for personalized feed based news prediction and
recommendation 
keywords  natural language
retrieval  machine learning 

processing 

preyas shah
preyas stanford edu
dept  of mechanical engineering
stanford university
activities of      users for the month of august       we
have three types of files available 

information

    introduction 
of all the things people read these days  news has a large
effect on their opinion formation regarding different issues 
also  newspapers and news services may manipulate the
general mood of the people by showing them more sad news
or happy news  apart from opinion formation  one would also
be interested in showing the reader the kind of news she is
most interested in  unlike conventional newspapers  which are
same for all   the internet has revolutionized the information
flow and access in user specific manner  now  there exist
many news services like pulse application for iphone ipad that
can provide personalized user experience by giving the users
freedom to subscribe to the feeds  news sources  they are most
interested in  most of these services have the same set of news
articles for each user in a particular feed 
thus  one level of personalization is where each user sees
articles from a certain set of feeds that she can subscribe to
 figure     while articles in each feed remain same for all
users  we propose a further level of personalization in which
news articles in each feed are also personalized according to
the user s interest 
in order to accomplish this  we apply natural language
processing and information retrieval techniques to extract
features about the news articles and use these features in a
machine learning setting to learn user behavior and interests 
 

data

the dataset comes from a local startup  alphonse labs  the
developers of the pulse application  the data consists of the

figure    a sample snapshot of pulse application 

   stories  this consists of all the news articles  stories 
available for reading with the following information 
article url  article title  feed url  feed title  timestamp of first
read  a proxy for when the article appeared in the feed   there
were circa          unique stories       unique feeds  a story
is identified by the  article url  feed url  tuple 
   useractivity  this consists of the stories the users have
read  with the following information 
user id  story url  story title  feed url  feed title  timestamp
when user reads
   clickthroughs  this consists of the stories that users read
in the web mode  usually  users see stories in text mode in the
app  a click through event is defined as clicking a link to view
a story in web mode that may indicate a higher user interest
for that story  we have the following format for each entry in
this file 
user id  story url  story title  feed url  feed title  timestamp 
    curing the data 
the first version of the dataset provided didn t have the
timestamp information for  stories  file  thus  we had no
information about when that story became available  this

fiinformation is required to determine which stories the user
might have seen  but not read   this is important for
constructing the class labels    read    unread   on our
request  the time stamp information was incorporated 
we also faced problem of ambiguous results and realized after
four weeks that the data provided to us had malformed feedurls  significant number of feed urls in the file  useractivity 
did not match the corresponding feed urls in the file  stories  
we again had to request for the corrected data 
also  lot of entries in the files had malformed format  e g 
different number of columns  bad time stamp  a lot of
duplicate entries just differing by timestamp for a given user
on a given day   so  we had tough time dealing with the data 
    data organization
we hashed feed urls and article urls using md  algorithm to
reduce memory requirements and for fast access  the data was
then organized as 
 new stories arriving on each of the    days 
 stories read by each user on each of the days 
 stories each user saw  read not read  for each day 
we assume if a user views a story from a feed  he has
looked at all the stories from that feed  also  a user
does not necessarily read stories from all the feeds
she is subscribed to 

document relative to the other documents in the collection  in
our case  document refers to the article title 
     
lsi  latent semantic indexing   lsi uses svd to
identify the relationship between the terms and concepts
contained in an unstructured collection of text  lsi essentially
tries to identify the similarity between the words based on the
context  it is similar to pca in the sense that it projects the
features into a lower dimensional space yet improves
information retrieval 
     
lda  latent dirichlet allocation   lda is an
example of topic modeling  it assumes that the set of
documents belong to a small set of topics and the words
appearing in the documents are generated on the basis of the
underlying topics  we can specify the number of topics  a
new document is represented by the probabilities of each topic
occurring in the document 
we have used the above three techniques to extract the
features from the title text  also  we preprocess the text by
removing stop words  considered stemming the words 
removed less relevant words parts of speech by tagging the
article title  using pos taggers like the stanford pos tagger
or a nltk penn treebank tagger   replaced catchy symbols
like      three dots        that invoke curiosity among the readers 
with fixed labels 
    the view of an article from other user s perspective

 

feature extraction

we characterize a user s reading habit behavior as the one that
has two components to it 
   the user specific component that captures the sole
user s intrinsic behavior
   the influence  trend of the other people who have
similar interests as the user  this captures how much
the user is influenced by the trends in his
community 
the first component is estimated by extracting the features
from the articles the user reads  ref  section       the second
component is estimated by clustering all the users to apply
collaborative filtering techniques  ref section       we then
add these two components to the features of each article 
note that not all articles in a feed are new arrivals  all the
features for a given story that is available for reading in a feed
 today  are constructed by looking at only the history of what
has happened till today 
    text feature extraction
as we can see from figure    user first sees the title of the
article  thus  we extract the text based features from the title
of the article  there are many standard techniques available
for text feature extraction  some examples are 
     
tf idf  term frequency inverse document
frequency  vector formulation  tf idf score of a word for
a document tells us the importance of the word for that

in this section  we try to estimate how likely a general user
would read a given article 
we also try to estimate how likely is the user to read the
article  given the information of how likely other similar users
are to read the same article 
     

general article popularity

a given article has some prior probability of how likely a
random user may read it  we estimate this probability as 
   
thus  when constructing this feature for an article for a given
user  we see how many people have seen and read this article
until the present day  since  not all articles in a feed are new
arrivals  an older article may give us much better estimate of
this probability 
the question is how to detect whether a user has seen the
article but not read it  we assume that all the articles in a
given feed has been seen by an user if he she has read at least
one article from that feed on the day for which we are
constructing the features 
     

collaborative filtering

we do three types of clustering using k means  we cluster the
users based on the     number of times the user has opened
each feed till the present day      the number of articles from
each feed the user has read till the present day and     kind of

fifeeds the user is subscribed to till the present day  figure  
shows the number of users in each cluster for the three
techniques  cluster indices for the three techniques have no
correspondence   with reference to fig     we can see that
techniques   and   show single high peak    relatively large
number of users in one cluster  while technique     shows a
roughly equal distribution of users across the clusters  the
concentrated high peaks for techniques   and   may be due to
the fact that some feeds are very viral  a lot of users are
subscribed to them  and they fetch most user activity  the
clusters having the peaks may be attributable to these viral
feeds 
the score for a given article a for a given user u is calculated
in the following two ways 
s  u a   

   

s  u a   

   

where
represents the cluster set of user u  
is the
cosine similarity between user u and user i  and
is
the indicator function of whether user i has read the article a 
we calculate these scores for all the three clustering
techniques 

we form feature vectors for each article using techniques in
section    and use these feature vectors in a logistic regression
classifier 
   

metric for performance evaluation

note that the problem is highly unbalanced  we have lot more
 s than  s as a user normally reads around       of the
articles of what she sees in the feeds  thus  we cannot use
accuracy as our measure for even a default   prediction has a
good accuracy  therefore  we are interested in precision and
recall  for recommendation of articles  we would like to
recommend the user k articles and would want that we have
good precision and recall for this set of k articles  thus  we
can plot precision recall curves and calculate area under the
precision recall curve  a higher area implies better
performance  also  we can use f  score as metric for
performance evaluation as it captures both precision and recall
by giving equal weights to them  we can also use f  score if
we want to give more weight to recall than precision 
precision recall curves  for plotting precision recall curves 
we sort the testing samples with the decreasing order of the
class   classification probability  we then pick top x samples 
and calculate precision and recall in this sample set  as we
vary x  we get different precision recall values on the plot 
   

optimal model parameters

since the problem is highly unbalanced  if we simply use
classification model with equal weights to classes   and    we
would obtain almost all  s as the predicted output since the
classifier optimizes the accuracy by default in most of the
packages available  in order to account for the unbalanced
nature of the problem  we give more weight to class   than
class    we penalize the misclassification of class   more
heavily than misclassification of class    but we don t know
what weight  w  we must give to class    also  we must
choose optimal regularization parameter  c  with the f score
as objective  to find optimal w and c  we do grid search in the
grid 
figure    number of users in each cluster  k    in k means  for
the three clustering techniques on day    

  

supervised learning model

certainly  this is a binary classification problem where for a
given user  class   represents that the user has not read the
article  but has seen it on the feed   while class   represents
that the user has read the article  we can in fact define a third
class  class   indicating that the user has not seen the article
yet  that is  she has not read any article from the feed but has
subscribed to it   we just keep two classes for simplicity  it
also makes sense to predict which articles a user reads given a
feed rather than also predicting which feed a user will read
from  for there is no fixed behavior behind not choosing to
read from a particular feed for a given day  it also depends on
in what order the feeds appear in different pages of the app 

w x c                                x                         
we choose the combination that maximizes the required
metric  section      by doing   fold cross validation on the
training data 
   

training and testing methodology

we fit the classifier for each user  for training till day n  we
start from day   and proceed day by day by including the
samples on each day until we reach day n  in the process  for
each day  we consider only the feeds from which the user has
read at least one article  articles read have label   while other
articles in the considered feed have label    we dont just
include articles from all feeds the user is subscribed to 
because those articles were not seen for more reasons that just
one  not enough time to read through all feeds  not wanting to
read anything else on  that  day  only more interested in page 
feeds but not uninterested in page  feeds  etc  so  not reading
any article from a feed doesn t necessarily mean that all the

fiarticles in that feed don t capture the user s interest  hence  we
don t include these feeds  for accounting them lead to having
labels   for the articles in these feed and we would be
counting these articles as un interesting articles in the training 
also making the problem more unbalanced 
for testing  we just test on n   to n   days  i e  next   days  
we choose next five days for testing because for
recommendation purpose  we would be interested in
recommending articles in the near future  within   days  and
user s interest may change over time  so  a   day window
seemed reasonable  while testing  we again just include those
feeds from which the user has read at least one article  this is
because we are building feed based recommendation system 
for a given feed  our model will recommend articles in that
feed  hence  if we do well in predicting what articles user will
read given a feed  we are doing a good job  other option is to
include all the feeds the user is subscribed to  for testing  this
is also a possible new direction  as now we will also need to
consider feed preferences for the user while building feature
vector and then predict what feed and what article in it the
user will read 

figure    precision recall curves when feature vector was
composed of tf tf idf only  different text processing tested 

   results
we plot the precision recall curve averaged over    random
users for whom we have enough training data  most of the
users don t use pulse app  daily and hence for them we have
little data and it makes little sense in predicting anything for
them  though we can still recommend and effectively
influence their reading habits 

figure    precision recall curves when feature vector was
composed of tf idf   tf 

    feature vector with just text features
in this section  we consider constructing the feature vector by
only using text based features from the article titles 
firstly  we show results by just including tf idf tf as the
feature vector  we see that the basic tf idf based model
performs better than the one with tf based  with different
types of text processing like stop words removal and
stemming  we plot the performance curves for the tf idf
based model  we saw that  ref  fig     there wasnt a
significant effect of stemming and stop word removal 

figure    precision recall curves when lda was implemented 

we then compared the performance of the tf and tf idf
based feature vector model  with model parameters  class  
weight w  and regularization parameter c   optimized for f 
and f  scores   ref  fig      we saw that the curves are better
for tf idf based model for both f  and f  as objectives  we
also see that the curves for f  and f  have the same behavior
for a given model  so we optimized c and w using f  score in
the plots thenceforth 
we then generated the precision recall curves for the case
where we implement lsi and lda on the document tf idf
features  ref fig         
we saw that for number topics in lda being     we got better
performance  ref  fig    
figure    precision recall curves when lsi was implemented 

fisince the best performance was seen for   clusters  use  
clusters and add the six features to the basic tfidf based
feature vector henceforth 

figure    precision recall curves comparison for lda  lsi and
just tf idf without any feature reduction 

we also saw that it did not make much difference by varying
the number of topics while implementing lsi  ref  fig     

figure    precision recall curves for different number of clusters

also  from fig     we can see that purely tf idf based model
performed slightly better than lsi lda  lsi and lda
applied on tf idf feature vector  model  this may be
attributed to the fact that despite topic modeling  there is
probably not enough topical content in article headlines and
more of proper nouns or ne  named entity  content  also  the
grid search based optimization brings up the performance of
purely tf idf based model to the same level of the other two 
we also saw that grid search did not affect the performance of
the other two models much  which supports the above
hypothesis 
since  just tf idf based feature vector does better than the
lda lsi models  we use just tf idf based features for the
discussion henceforth 
    collaborative filtering based feature vectors
we then tried clustering based on the three different
techniques as mentioned in section        for each technique 
we calculated the metrics s  u a   metric   and s  u a   metric  
and added these metrics as features to the basic tfidf based
feature vector  i e  we added    techniques  x    metrics     
more features  and plotted the performance curves for
different number of clusters  ref  fig      as we can see 
clustering significantly improved the performance  moreover 
number of clusters     seems most appropriate 
now  we try to evaluate which of the six clustering based
features contributes the most to the improvement  so  instead
of adding all the six features at a time  we add these features
 metrics for each technique  separately as an additional feature
to the basic tfidf based feature vector and plot the
performance curves  ref  fig      the technique  
 feedreadfreq based clustering  contributes the most to the
improvement followed by technique    feedopenfreq based 
and technique    feedsubscribed based   also note that both
metrics  s  and s   have similar effect for each clustering
technique 

figure    precision recall curves for different metrics and
different clustering models

we now check the effect of general article popularity  section
       when added as a feature to the tf idf based features 
note that we already have a plot for just a single cluster in fig 
   which captures general article popularity already  thus  the
general article popularity score doesn t make significant
contribution 
   

putting everything together

we finally plotted precision recall curves with   user clusters 
including the six clustering based features two metrics for
each of the three clustering techniques  with tf idf based
text features for different training durations                  
and      days  we test on next five days for each training
duration  these are average curves for    random users  since 
the purely tf idf based model is only slightly better than

filsi lda based models  we did not plot the same for the latter
  cases  ref  fig      

   acknowledgements 
we would like to acknowledge richard socher  head ta 
cs     stanford univ  fall       for giving us initial
directions and guiding us through the project 
   references 
    scikit  http   scikit learn org stable 
    gensim  http   radimrehurek com gensim 
    wikipedia http   www wikipedia com 

figure     precision recall curves for    random users with best
parameters and features

surprisingly  we don t see much effect of the number of
training days  we expect that as we include more training
examples  we will get improvement  this may be due to the
fact that the news habits of people change over time and hence
adding the past data is not very useful  rather could degrade
the performance as we can see  lower curve for training till   
day  training till    day seems most appropriate  
     extension
in the above analysis  we have not really used feed specific
information while constructing the feature vector  other than
in clustering techniques   one can think that a user has feed
specific article selection behavior  hence  one think of feed
specific classifiers for each user  since  it would be slightly
cumbersome to maintain a different classifier for each feed
and for each user  we can alternatively add feed specific
features  for example  we can add feed reading probability for
the user for each feed the user is subscribed to  and to which
feed the concerned article belongs to  as features   note that
feed is a categorical variable   we tried going in this direction 
but the results were not exciting 
   conclusion 
we have successfully applied natural language processing 
information retrieval and machine learning techniques in
developing a feed based personalized news prediction 
recommendation system  we observed that tf idf based
model performs slightly better than lsi lda models in the
present problem setting with the given data  as user clustering
shows significant improvement in the performance  it can be
said that similar users have a common view about a given
article  also  the complete user pool can be roughly divided
into seven to ten different communities representing news
genres categories 

    evaluation of text clustering methods ysing wordnet 
abdelmalek amine  zakaria elberrichi  michel simonet  the
international arab journal of information technology  vol   
no    october      
http   www ccis k org iajit pdf vol   no       final pdf
    probabilistic topic models  mark stevens  university of
california  irvine  tom griffiths  brown university 
http   www cs umass edu  wallach courses cs   ss readings s
teyvers  probabilistic pdf  lda 
    google news personalization  scalable online
collaborative filtering  abhinandan da  mayur datar 
ashutosh garg  www      track  industrial practice and
experience  ay             banff  alberta  canada 
http   www     org papers paper    pdf

fi