cs     project   improving on yelp reviews using nlp
and bayesian scoring
patrick bechon
pbechon stanford edu

  

lo grimaldi
yacine merouchi
leo grimaldi stanford edu merouchi stanford edu

introduction

yelp allows its users to share reviews of local businesses 
for each business  the reviews and star ratings are used to
display some key quotes from reviews  and an average star
rating  our goal in this project was to improve yelps user
experience  by finding a new way of summarizing the ratings and reviews of each business  for our experiments  we
used the yelp academic dataset     which contains the data
of the     closest businesses for    universities in the us 
this dataset includes user profiles  business profiles  reviews 
and the votes that users have given to other users reviews 
we used bayesian scoring to improve the global star rating of every business  and then two methods  tf idf and
expandrank  an algorithm derived from pagerank   to extract the keyphrases that best describe each business 

it is a positive review  with a star ranking between   and
   or a negative review  with a star ranking between   and
    we were able to compare the performances of supervised
learning algorithms using the two different stemming methods  figure   shows the evolution of the training error and
the testing error as the training set size increases  we chose
to use the porter stemmer as it outperforms the lancaster
stemmer on every test 
error comparison
  
  
  
  

data preprocessing

for bayesian scoring  we only need the star ranking of every
review  so  from the whole dataset  we extract a sparse  d
matrix whose element i  j is the ranking of user i for business j  one of the main characteristics of the yelp dataset
is that this matrix is very sparse  because many users only
submit a low number of reviews 
for key phrase extraction  we need to process the text of
each review  to do so  we split the text into sentences and
tokens  we remove all non alphabetic words  we set all the
characters to lowercase  we remove stopwords and we stem
each word to regroup words with the same root  for all
these operations  we use the nltk library in python   
among the different choices we had to make  the choice of
the stemmer is probably the most important  we considered two algorithms  the porter stemmer and the lancaster
stemmer  to choose between those two  we decided to test
them on a supervised learning problem  the spam classifier
of problem set   was our source of inspiration  by considering each review as a text and trying to predict whether
 
 

http   www yelp com academic dataset
http   www nltk org

error    

  

  

  
 
 
 
 
 
    

nb train error with porter
nb test error with porter
svm train error with porter
svm test error with porter
nb train error with lancaster
nb test error with lancaster
svm train error with lancaster
svm test error with lancaster
    

    

    

    
    
training set size

    

    

    

     

figure    comparaison of training error and testing
error on a      reviews test set  for two stemmers 
using svm and naive bayes

   bayesian rating
introduction
on yelp  reviewers can give a business an integer score between   and    star rating   then businesses can be ranked
according to their average star rating among reviewers  yet
the variance within these average ratings is not very high
and it is sometimes hard for users to pick their destination 
thus we want to come up with a better way of assessing the
intrinsic value of a business b  denoted b   that would have
a higher variance among businesses  while reviewers try
to estimate this true value with star ratings  they can be
inconsistent  while some tend to give all businesses a good
score  others may be very harsh with their rating  thus we
denote r the bias of reviewer r and use a model similar to
the one studied in problem set    the star rating given by
reviewer r to business b is denoted x br  and assumed to be

figenerated by a random process as follows 
y  br   n  b   b   
z  br   n  r   r   

and pre determine our model  in practice  we experimented
on  and   looking at the shape of the likelihood curve to
determine small values that would make sure the algorithm
converges over a finite number of iterations 

x br    y  br    z  br   n  y  br    z  br        
the variables x br   related to the business true value and
service consistency  and z  br   related to the reviewers bias
and rating consistency  are assumed to be independent while
the variables x br    y  br    z  br    for different business reviewer
pairs are also jointly independent  we are to train this model
on our dataset using an expectation   maximization  em 
algorithm 

em algorithm
e step  for each business reviewer pair  b  r   we used the
observed value x br  and the current set of parameters
 b   r   b    r      to compute

 br 

regularization
now the key difference with problem set   is that not all
reviewers reviewed every business  we are even far from this
ideal situation since each reviewer wrote less than   reviews
on average  thus for many reviewers  we dont have enough
data to estimate the many parameters properly  while overfitting is a concern  the lack of data leads to a more crucial
issue as the em algorithm may fail to converge  indeed 
because of the very few data points available for some reviewers  some of the variance parameters b   r     tend to
converge towards    these lead to degenerate gaussian distributions  singular covariance matrix  hence singularities
in the likelihood function  as the likelihood is no longer
smooth  the em algorithm is not guaranteed to converge 
in order to regularize the likelihood  we use map estimation with inverse gamma distributions as conjugate priors
on the variances of our models gaussian distributions 


b  r           b   x br   r  
 
 
 
 
 br 
r  b        r  x
 b  
    

         
b  r 
   b    r          b r    
 
 
b r
r  b        

y z x    b    r         
 br 

y z x

thus 
 br 

    invgamma    

 br 

qbr  y  br    z  br      p y  br    z  br    x br     n  y z x   y z x   
m step  denoting r b  the total number of reviews of business b  b r  the total
businesses reviewed by repnumber ofp
viewer r and n  
r b r  the total number
b r b   
of reviews  we used the quantities derived in the e step to
compute the updated values of the parameters 

b   invgamma    
r   invgamma    



b  

  x  br 
  x  br 
 y z x   
 y z x      r  
r b  r
b r 
b

 b     

 r     

   

  

p 
 br 
 br 
  y z x
r b   y z x   

  

r b           
   

p 
b

 br 

r   y z x   

 



 br 
  y z x

  

b r           


  
 t
x
 
 
 br 
  
 br 

     
   
x

y z x
 
n          
b r




 t x
 
 
 
 br 

 
 
y z x 
 
 
b r

figure    cdf of inverse gamma distribution for
different values of     
as we can observe in the following expressions  the parameters  and  can be simply interpreted as controlling the
number of virtual prior samples that we add to the data in
order to regularize the learning process  thus  and  must
be high enough to prevent the variance parameters from converging towards    but low enough not to take over real data

computation of the likelihood
 br 

 br 

using the distributions qbr  n  y z x   y z x   derived in
the e step  the lower bound
         b           r           b           r     
 
 z
 


fion the log likelihood of the parameters  abbreviated as   is
given  up to an additive constant  by
    
 t
  
t
  x
 
 
 
 br 
 br 
 br 
       
x

 
y z x
y z x
 
 
 
 
b r



  

x  
 br 
 br 

b   y z x      y z x
 
 b
  
b r
  
 
x   
 br 
 br 
r   y z x      y z x

 r 
  
b r

 x
 x
 
r b  log b  
b r  log r 
 n log    
 
 
  r
b


 x
 br 
 
log  y z x  
 
b r

       

x
b



log b  

x
x 
       
log r 
 
b
r

figure    reviewers bias  stanford 

b

x 

        log      
r 

b

this quantity was maximized in the m step to update the
parameters to     but we can also use this expression right
after the e step to compute the likelihood of the current set
of parameters  indeed  we know that the distributions qbr
computed in the e step ensure that this lower bound is tight
for the current set of parameters  

results

figure    bayesian vs average star ratings  stanford 

since our dataset is organized around major us universities  we first trained our model on the businesses around
stanford  after determining the regularization parameters
               we experimented with three different random
initializations for the em algorithm and picked the model
that gave the highest likelihood  first of all  people are

figure    top    comparison  stanford 

looks like people are very positive here in california 

figure    likelihood convergence  stanford 
overly positive  indeed the distribution of reviewers biases
range from    to     and is packed around     then we
can observe that among stanford businesses  the inferred
intrinsic mean values b have higher variance        than
average star ratings         to the readers appreciation  we
also extracted the top    businesses according to each score
 bayesian rating vs average star ranking   finally  we
learnt a similar model for each of the other    universities
from our dataset and compared peoples mood  reviewers
average bias  and the quality of surrounding businesses  average business intrinsic value  around each university  it

figure    ranking of us universities

fi   key phrase extraction
    models

difference between predicted reviews u f c score and best reviews u f c score
pagerank
tfidf

we consider the problem of extracting sentences that describe businesses  for this task  we use two popular methods available for extracting keyphrases  tf idf and expandrank  both these methods involve assigning scores to
words based on their importance  and then selecting sentences with the largest cumulative word scores  this task
can be formalized as a unsupervised learning problem  we
discuss these two algorithms and describe our evaluation of
the results 
the idea of tf idf is to measure the importance of words
relative to the documents in a corpus  we concatenate all
the reviews from a given business and consider this as a
document  and take only businesses from the same category
for the corpus  we then calculate the tf idf score of each
token relative to every business  and  for each business  we
select the sentence with the highest cumulative word score 
we eliminate sentences that are longer than seven words 
to avoid a bias towards longer sentences when comparing
cumulative scores and because we only want to display short
sentences for the user 
the second approach that we consider is the expandrank
algorithm  which was introduced in     using the example of
extracting keyphrases from news articles  the expandrank
algorithm works by selecting a small number of neighboring documents  assigning affinities to words by counting the
number of times they occur within a fixed distance  this
is similar to the pagerank algorithm  if we interpret every
word as a web page and co occurrence as the presence of a
hyperlink  instead of using a similarity distance as in      we
use the business metadata to select neighboring documents 
by restricting the businesses to a given category 

   

evaluation of results

   

relative error

  

  

  

 

 

 

 

 

 

business

figure    evaluation of key phrase extraction algorithms using cumulative scores of reviews
our first idea is that the expandrank or tf idf score of a
sentence might be correlated with the funny  useful and
cool votes associated with the corresponding review  we
compare the users votes on reviews that we selected as containing the best keyphrase with the top review from the
relevant business  and notice that there is no pattern  we
then calculate the total cumulative scores of reviews using
expandrank and tf idf  and find that these scores have
a weak positive correlation with the user submitted votes 
we also compare the results given by both algorithms on the
same businesses  given the same data  the two algorithms
usually yield different results  we present an example of the
results for five mexican restaurants 

correlation with useful   funny   cool scores
 
pagerank
tfidf
   

   

   

correlation

   

   

   

   

tf idf
   we were at lustre pearl last night  ready for some tacos 
   or me  the burrito ultimo is baja freshs only saving grace 
   chef jose garces doesnt disappoint with distrito 
   took forever for our drinks to arrive 
   casa moreno has the best house margarita ever 
expandrank
   might go back later at night for the food
   good fake mexican food 
   overall  good food  good drinks  and great ambiance crowd 
   do not expect a good mexican food experience if you go 
   do not order this dish unless you like spicy food 

   

   

 

 

 

 

 

 

business

figure    evaluation of key phrase extraction algorithms using correlation with review votes
having no gold standard keyphrases at our disposal  we consider two methods to try to evaluate the results 

in this example  as in other examples we have considered 
expandrank seems to yield more relevant keyphrases  the
word food also appears in every sentence with expandrank 
and we can verify that this word received a high individual
score  this is due to the fact that this word is one of the
most commonly used words in reviews of restaurants  the
last example also shows a limitation of this algorithm  even
the sentence is relevant  one needs more context to understand it  here the reviewer was talking about the chili verde  

  

conclusion

fithis project proposes two ways of improving the user experience on yelp  using bayesian rating to adjust star ratings
for the effects of user bias  and using keyphrase extraction
techniques to describe businesses concisely  we found that
the inferred intrinsic mean values can achieve a variance
among businesses more than twice the variance of the average star ratings  and that we could deal with data sparsity
providing a clever choice of prior on the model parameters 
we compared tf idf and expandrank in the task of selecting keyphrases from reviews and found that they tend
to provide different results  and only found a weak positive
correlation with users votes on relevant reviews 
bayesian rating proved to be an interesting approach and future work could look at live implementation  how to adapt
the algorithm for online update of the inferred grades at
minimal cost  that is every time a person writes a new review  the results of expandrank are encouraging and this
method should be tested on a large number of businesses
with hand selected keyphrases 

  

references

    x  wan and j  xiao  single document keyphrase
extraction using neighborhood knowledge  in
proceedings of the   rd national conference on artificial
intelligence   volume    aaai    pages        
aaai press       

fi