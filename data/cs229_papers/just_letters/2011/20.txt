neuron detection and decoding in fluorescence microscopy

tony hyun kim
kimth stanford edu

 

lacey kitch
ljkitch stanford edu

introduction

a central goal of neuroscience is to explain the observable actions of a behaving animal by the activity of neurons in the brain 
to accomplish this goal  scientists must      record the activity of individual neurons during behavior  and      correlate the
measured neural activity to animal behavior  the current project explores machine learning methods to facilitate both tasks 
one method for recording neuronal activity is fluorescence microscopy  in which neurons in the brain express a fluorescent
marker whose emission is modulated by the firing of the neuron  our work is based on the integrated fluorescence microscope
of the schnitzer group  gbc      which enables the acquisition of activity from large numbers of neurons in freely behaving
mice and rats  as shown in fig    a   the fluorescence microscope is surgically attached to the skull of a laboratory mouse 
fig    b  shows a typical microscope image with individually outlined neurons  in a prototypical experiment  the animal is
permitted to wander about its environment  while the microscope images the hippocampus  a region of the brain associated
with spatial representation 

interface to pc

    m

figure    fluorescence microscopy of a freely moving animal   left  a fluorescence microscope is surgically attached to the
skull of a lab mouse  which is free to move about in its environment  the microscopes interface to the pc is clearly visible 
 right  a typical view through the microscope  gbc       individual neurons are outlined and labeled 
our project is organized into two parts 
 in section    we present a supervised learning algorithm for the automatic classification of neurons from fluorescence
microscopy data 
 in section    we develop a supervised algorithm to predict  i e  decode  in the parlance of neuroscience  the position
of the mouse in its environment  based on hippocampal neural activity 

 

neuron classification

the first part of our project is to automate the identification of neurons in the calcium imaging data  essentially  the data from
the integrated microscope is a    minute long movie that shows a     m      m section of the brain  the desired machine
learning algorithm will identify which pixels of the microscopes field of view correspond to neurons  in a further automation
of the data processing pipeline published in ref   mns    
the microscope movie is preprocessed as follows  first  the dimensionality of the data is compressed and noise is reduced
by throwing out low variance components resulting from pca  second  ica is performed to identify independently varying
pixels within the movies frame  each resulting independent component  ic  is a matrix which gives a weight to each pixel
in the field of view  i e  a spatial filter  the filter is then applied frame by frame to the original movie to extract a temporal
fluorescence activity trace  the final preprocessed output consists of  spatial filter  activity trace  pairs as in fig    that must
 

fi   burst duration

 

 

filter  a u  

   

   spot size
 fwhm 

 

  

   burst count

 

y

   

y  pixels 

  

activity  a u  

   skew

   

x  pixels 

   

 

    

    

    

time  samples 

    

figure    extraction of the feature vector from a single ic  spatial filter  temporal trace  pair that was classified by the human
operator to be a valid neuron   left  from the spatial filter  we compute the spot size and the skew of the region of interest 
 right  from the temporal activity trace  we count the number of fluorescence bursts and the average duration of each burst 
be classified as valid  or invalid  neurons  the classification step has hitherto been performed manually by a human operator 
our machine learning algorithm seeks to automate this step  we do so by leveraging the existing database of thousands of
human classified examples 
   

feature vector definition

while it is in principle possible to feed the full spatial filter and the temporal trace into the learning algorithm  we have opted
instead to extract a small number of features from each ic pair  our feature definitions are inspired by the intuition of the
human classifier  and are as follows 
   spot size  from the spatial filter  we estimate the size  in pixels  of the region of interest  as shown in the inset of
fig    a   the region of interest may be determined by using a criterion such as the full width half maximum  fwhm  
   skew  we also consider the nonconcentricity of the spatial filter  as shown in fig    a   the skew may be measured 
for instance  by interpreting the spatial filter as a probability distribution and calculating the xy correlation 
   burst count  neuronal activity consists of short duration electrical impulses known as action potentials  and large
numbers of action potentials generate bursts of fluorescence in the experimental set up  hence  the presence of
bursts in the temporal trace is a natural indicator that the ic represents a neuron  as in fig    b   we count the number
of bursts in the temporal signal by establishing a threshold  e g  the standard deviation of the activity trace   and
subsequently counting the number of positive crossings over the threshold 
   duration of bursts  we also consider the duration of each burst  i e  the number of samples beyond the threshold
divided by the burst count   this feature roughly corresponds to the quality of the recorded bursts  an abnormally
short burst duration  for instance  may be caused by random optical scatterers in the microscope path 
   

details of experimental data

our training data consists of    datasets  each containing a few hundred labeled examples  of which     are positive on average   where a dataset represents one experiment on a single day  these datasets span    animals  one year of experimentation 
and several experimental set ups  thus allowing for a potentially large variation in the calculated features  we are interested
in an algorithm that performs robustly across datasets  i e  achieving high accuracy on a test dataset that is a distinct from the
training dataset  if our algorithm achieves such performance  it may perform neuron identification reliably across animals and
across experimental trials 
   

logistic regression

our original classifier is based on logistic regression  using the standard formulation  ng      and optimized with newtons
method  first  we trained the algorithm on one of our    datasets and tested pairwise on each of the others  the results
demonstrated excellent performance         on some test train pairs  good performance on most         but very poor
performance  as low as      on a few cases  the histogram is shown in fig    a  
 

fi 

  

    

test accuracy

number of test train pairs

  

  

  

 
   

   

    
single trial
average
worst case

   
   

   

test accuracy

   

 

 

 

  

  

size of training set    of datasets 

figure    summary of logistic regression performance   left  histogram of pairwise test errors   right  k fold cross validation
as the number of datasets in the training set is increased  red dots indicate individual test errors  the blue line shows the mean
k fold accuracy  and the horizontal axis indicates the number of datasets used to train the algorithm  corresponding roughly to
the number of training examples  
next  we trained the logistic regression algorithm on multiple datasets  and then tested its predictions against the remaining
datasets  despite the potential variations between experimental trials  we found that the mean accuracy generally rose as a
function of the size of training set and quickly saturated around      after about      total examples  as shown in fig    b  
the worst case performance  however  continued to rise as the size of the training set was further increased  this continued
scaling is fortunate  since we would like to guarantee a lower bound performance on any new dataset to be classified 
   

support vector machine  svm 

motivated by our observation that correct ic classification has a slightly nonlinear relationship to the features  we performed
classification using an svm with the gaussian kernel  we compared the k fold cross validation performance  k       of
svm  using the libsvm package  against logistic regression  both using all    datasets  we performed a grid search over the
regularization parameter c and the gaussian kernel prefactor  to minimize the cross validation error  and found a maximum
svm accuracy of       this performance is comparable to the      accuracy of logistic regression  thus  due to its
simplicity of implementation  logistic regression remains our preferred algorithm 
   

discussion of results

the accuracy of our machine learning algorithm  when compared directly to the labels of the human classifier  is      beyond
this basic performance  we have performed manual inspection of the incorrectly labeled examples in order to identify possible
biases in the machines  or the humans  classification  particularly interesting is the case of false negatives  i e  examples where
the machine algorithm predicted no neuron while the human classifer specified neuron  we were motivated to investigate
this case after we were informed by the human classifier that she tended to be generous in granting the neuron label  and that
she tended to de emphasize information from the activity trace in her classification decision 
indeed  upon closer inspection  we found that the false negatives generally possess significantly fewer fluorescence bursts in
their activity trace  over     of false negatives have fewer than half of the mean burst count of valid neurons  and      have
an insignificant number or no bursts  hence  we believe that many of our false negatives originate from the bias of the human
classifier  and the performance of logistic regression for correctly labeling neurons is greater than the reported     
finally  we have applied our algorithm for automatic neuron classification to other animals  e g  rats  used in the schnitzer
laboratory and found comparable performance to our mouse results without having to re code or even retrain the algorithm 
due to this demonstrated robustness and high performance  our algorithm will be used in the future by scientists in the schnitzer
lab for automated neuron identification 

 

movement prediction

the second part of our project aims to utilize machine learning techniques to predict animal behavior based solely on neural
data  in essence reading the animals mind  in a prototypical experiment  a mouse runs on a linear track of approximately
   cm in length  trajectory x j  of the mouse shown in top panel of fig      while the fluorescence microscope simultaneously
records the activity in the mouses hippocampus  a region of the brain associated with spatial representation  as shown in the
 

fiposition  x j 

   
   
   

cell index  i

 

   

   

   

   

    

    

    

   

   

   

   

    

    

    

   
   
   
   
  

time index  j

figure    the temporal pairing of mouse position with neural activity  dashed columns indicate the temporal pairing between
the mouses instantaneous position and the neural burst vector   top  a mouse runs back and forth on a linear track of
approximately    cm in length   bottom  fluorescence activity is segmented into a binary matrix b i  j           where
b i  j       denoted by a blue dot  indicates the presence of a fluorescence burst in cell i at time index j 
bottom panel of fig     fluorescence activity is segmented into a binary matrix b i  j           where b i  j      indicates
the presence of a fluorescence burst in cell i at time index j 
as shown by dashed columns of fig     the position of the mouse is temporally paired with a burst vector that indicates the
small subset of concurrently active neurons  the movement prediction algorithm will be trained on a set of such  position  burst
vector  pairs  the trained algorithm will then predict the position of the mouse based on its neural activity alone 
   

feature vector definition

naturally  the minimal set of features used for predicting position x j  is bj   the burst vector at time j  in our exploration of
movement prediction  however  we have found it important to consider 
   inclusion of past future burst vectors  empirically  we find that bj alone is insufficient to achieve acceptable error in
position prediction even for the training set  hence  in addition to bj   we allow the algorithm to utilize activity information from burst vectors in the vicinity of time j as in  bjn        bj    bj   bj          bj n    we parameterize
the inclusion of such past and future burst vectors by n   the half width of non present vectors used in the feature
definition  of course  increasing the dimension of feature vector this way could overfit the training data  thus  we
determine the optimal value of n with respect to test error 
   burst vector smoothing  as shown in fig     the nonzero entries of the burst matrix b i  j  are distributed rather
sparsely  the sparseness is partly a consequence of the segmentation process  in which b i  j      is assigned only
at the time index corresponding to the peak of a fluorescence burst  however  as discussed in our previous work on
neuron classification  the duration of a fluorescence burst typically extends many time samples  hence  we convolve
the burst matrix with a box shaped smoothing filter of length   m      in order to account for the extended duration
of each burst 
   

details of experimental data

each experiment is performed on a single mouse on a single day  and is separated into      trials where each trial consists of
a    minute sequence  we compute test error as the k fold cross validation
error among the trials  test error is cited in units

of centimeters  which is the square root of the mean square error   mse  between the predicted and actual positions in real
space  the full length of the track is    cm  due to differences in neural coding between animals  one cannot not train on one
animals data and then test on anothers  thus  our algorithm is evaluated on several  five  independent sets of train test data 
   

naive bayes prediction of mouse position

our movement prediction algorithm is based on naive bayes  the left panel of fig    shows test error as a function of the
number of past future vectors  n   and the size of the smoothing filter  m    it is readily observed that past future burst vectors
 

fi  
actual
decoded

  

  
  

filter size  m    

  

  

 

  

training error
test error

 

 

  

  

number of past future vectors

  

  

  
 

  

 
  

  

  
  
size of
smoothing filter  m

  

number of
past future vectors  n

error  cm 

test error  cm 

error  cm 

  

actual
decoded

  
  
  
 

filter size  m    
 

 

  

  

number of past future vectors

  

figure    results of the naive bayes movement prediction algorithm   left  one animals   fold cross validation test error as a
function of number of past future vectors  n   and the size of the smoothing filter  m    optimal performance is obtained when
 n  m              right  test and training error as a function of n for two different values of m   insets show the accuracy of
the decoded trajectory 
or burst vector smoothing independently
does not yield optimal performance  careful inspection of the test error surface shows

that optimal performance of mse     cm is obtained when  n  m              notably  the optimal size of the smoothing
filter corresponds to the typical duration of fluorescence bursts 
the right panels of fig    show the scaling of both training and test error as a function of n for two different values of m   as
previously noted  increasing n will eventually eliminate the training error  independently of m   as it permits overfitting of the
training set  on the other hand  the limiting value of the test error is highly dependent on m   the corresponding insets show
qualitatively the accuracy of the decoded trajectory 
   

discussion of results

with naive bayes  we achieved a baseline position decoding performance that is comparable to state of the art results using
electrophysiological methods  this is exciting because optical data  as compared to electrical recordings  has a much lower
temporal resolution and is  in general  a less direct indicator of neural spiking activity  for this reason  fluorescence based
decoding had not yet been demonstrated  thus  we have set a new benchmark  and shown that the information content in our
hippocampal imaging data is indeed sufficient for reconstructing spatial position very precisely 
acknowledgments
t h k  and l k  thank laurie burns for providing experimental data  for pre processing the data  and for having manually
classified thousands of neuron candidates  and yaniv ziv for performing the mouse experiments 

references
 gbc      kunal k  ghosh  laurie d  burns  eric d  cocker  axel nimmerjahn  yaniv ziv  abbas el gamal  mark j 
schnitzer  miniaturized integration of a fluorescence microscope  nature methods              
 mns    eran a  mukamel  axel nimmerjahn  mark j  schnitzer  automated analysis of cellular signals from large scale
calcium imaging data  neuron                   
 ng      andrew y  ng  cs     lecture notes   

 

fi