can twitter predict the stock market 
volodymyr kuleshov
december         

 

introduction

last year  in a famous paper  bollen et al         made the claim that twitter mood is
correlated with the dow jones industrial average  djia   and that it can be used to forecast
the direction of djia changes with     accuracy  besides its obvious significance in investing 
this surprising result challenges several fundamental notions in the social sciences  such as the
efficient market hypothesis   
in this project  i verify whether the surprising results of bollen et al  can be reproduced
and whether they can produce a profitable investment strategy  unfortunately  i find that
measuring twitter mood does not offer an improvement over a learning algorithm that only
uses past djia values 

 

background

bollen et al         measure twitter mood according to six dimensions  calm  alert  sure
vital  kind  happy  by counting how often people tweet certain words  these words are taken
from a popular psychometric test called profile of mood states  bipolar   poms bi   they
find that the mood dimension calm is correlated with the djia at p        and that a
self organizing fuzzy neural network  sofnn  that receives as inputs the djia and the
calmness scores for the past three days predicts the direction of change of the djia on the
following day with an     accuracy 

 

methods

i evaluate several approaches to using twitter mood for predicting the djia  including that
of bollen et al  i start with a dataset of about   gb of tweets from june to december      
i use august october     weekdays  for training and november december     weekdays  for
testing  the months of june and july are discarded because they contain much fewer tweets
that the later months  including several days with almost no tweets   using june and july
skews the normalization of inputs to the learning algorithms and results in significantly worse
performance 
i parse the data using a sentiment aware tokenizer that preserves twitter symbols       
smileys  and that turns into standard form repeated punctuation marks  e g        
 
the efficient market hypothesis states states market prices are nothing more than a rational aggregate of
factual information about a good 

 

fi   

reproducing the approach of bollen et al 

since  bollen et al  do not clearly describe their methods  i implement a close approximation
to their approach  the most important missing information is the the poms bi vocabulary
 only the regular poms vocabulary is publicly available   which forces me to define my own
word list  i perform a   step wordnet propagation starting from synonyms of calm and
excited and from poms  regular  words related to calmness and excitedness  i then discard
all words that do not describe mood to obtain two sets vc   ve of adjectives related to calmness
and excitedness  the two sets contain about    words in total  which is close to the number
that bollen et al  used in each mood dimension 
using vc and ve   i define for every day the following mood features  given a day i and
a vocabulary v   let pi  v   denote the percentage of tweeted words on day i that are in v  
also  let di denote the percentage change in djia on day
s i   djiai  djiai    djiai    to
every day i in the dataset  i associate the nine features i 
j i   dj   pj  vc    pj  ve    and a target
output of di  
in order to predict the djia percentage changes di   i use a neural net  nn  instead of
the sofnn of bollen et al  specifically  i train a perceptron using backpropagation for about
       epochs  roughly  until convergence   i also experimented with multi layer networks 
but they would usually overfit the training set  all inputs to the perceptron are normalized
to have mean zero and standard deviation one  like bollen et al   i train only on tweets that
include phrases like i feel  i am  etc  training on all tweets did not improve performance 
besides using a different vocabulary and and a different learning algorithm  the above
method completely replicates the approach of bollen et al 

   

svm classification

since the above method does not come close to achieving the desired     accuracy  i propose
and evaluate alternative ways of using twitter mood to predict the djia  first  i focus on
the simpler problem of classifying the direction of djia movements and use an svm as my
classifier  besides often working well in practice  svms admit regularization parameters that
can reduce the high variance i observed with neural nets  i use a gaussian kernel for the svm
and i select all hyperparameters through cross validation  i normalize all features so that over
the training set  they fall precisely in         i also measure sentiment over all tweets  focusing
only on tweets containing phrases like i feel did not produce better results 
i separate days into classes in two ways  into up down classes  and into up stable down 
where stable is defined as a percentage change of less than       there were about    stable
days in the test set 
finally  i collect and feed mood data into the svm using two methods 
     

vocabulary based

the first mimics the algorithm of bollen et al   except that it replaces the calmness and
excitedness vocabularies vc and ve by general vocabularies v   and v  of positive and negative
words  as before  the svm receives as inputs percentages pi  v      pi  v    for the past three
days  i try two approaches to constructing the vocabularies v   and v    greedy forward
model building and information gain 
 

fiin the greedy model building approach  i start with two larger sets s     s  of about    
terms each that i build using wordnet propagation  words in the sets s     s  are respectively
positively and negatively associated with either calmness or happiness  the two dimensions
that correlate with the djia according to bollen et al  based on s     s    i greedily build
v   and v  by iteratively adding to its corresponding set the word that produces the largest
increase in cross validation accuracy 
in the information gain approach  i associate to each word w  s    s  a variable xw
that takes one of   values  low  medium or high  the variable xw takes the value low  resp 
med   high  when the        normalized percentage of tweeted words on day i that equal w
falls in           resp                         to find words that correlate with djia movements 
i compute the information gain of sign djia  and xw   and define v     v  to be the sets of
words in s   and s  that have an information gain greater than some g      i experimented
with g                         
for up stable down classification  i calculate the ig between xw and a target variable
that can take the three possible class labels 
     

word based

the second approach is to directly feed the svm percentages pi   w   for all words w in a
vocabulary v   to obtain the vocabularies v   i use the the same methods as in the previous
section  in greedy model building  i iteratively add to v the word in s    s  that yields the
largest increase in cross validation accuracy  the information gain approach is identical to the
one outlined above 

   

svm regression

it is usually more important to correctly identify large djia movements than smaller ones 
since they produce high profits or losses  therefore it is worth trying to predict the actual
value of di   rather than only its sign  although neural nets have been applied to that problem
in section      i also consider predicting the di using svm regression  since that algorithm
allows for regularization and can be easily combined with my model selection techniques for
classification  i use the same inputs to the svm and the same model selection algorithms as
in the classification setting  see section     for details 

 
   

results
reproducing the approach of bollen et al 

the approach described in section     yielded a test accuracy of     on the direction of
djia movements  however  this is almost certainly due to overfitting  as i experimented with
slight variants  e g  a slightly different vocabulary  and none had a higher accuracy than     
moreover  training an svm on exactly the same inputs also resulted in only a     accuracy 

   

svm classification

overall  svm classification yielded accuracies of approximately      although this may seem
significant  this accuracy can be achieved simply by predicting up constantly  in fact  almost
 

fiall svm classifiers learned to do precisely that  and classifiers that scored higher than    
simply predicted one or two correct downs in addition to classifying everything else as an
up  most notably  an svm that received as inputs only the djia percentage changes for the
past three days would always learn to do precisely that  therefore  the results for classification
cannot be considered significantly better than this baseline approach 
     

vocabulary based approaches

the table below presents the accuracy of algorithms described in section        each cell
contains two numbers  the first is the cross validation accuracy  the second is the test set
accuracy  note that greedy model building clearly overfits the training set 

svm  u d 
svm  u s d 
     

greedy search
        
        

ig       
        
        

ig       
        
        

ig       
        
        

ig      
        
        

word based approaches

the table below presents the accuracy of algorithms described in section        the first
number in a cell is the cross validation accuracy  the second is the test set accuracy 

svm  u d 
svm  u s d 

   

greedy search
        
        

ig       
       
        

ig       
       
        

ig       
       
        

ig      
       
        

svm regression

overall  the regression problem proved to be at least as difficult as classification  since the
svm does not explicitly focus on predicting directions of change  the accuracy is somewhat
worse  also  i did not observe better accuracy on days with large djia changes  and so the
regression approach does not appear to be more promising than classification for practical
purposes 
the table below contains test set accuracies for regression svms that are based on the
vocabulary and individual word approaches mentioned in section     

voc  based
word based

 

greedy search
   
   

ig       
   
   

ig       
   
   

ig       
   
   

ig      
   
   

discussion

techniques very similar to those of bollen et al   as well as several alternative methods failed
to even come close to the     accuracy on the direction of djia movements described in the
bollen et al  paper  this raises doubts about their methods and the correctness of their claim 
a first hint at methodology problems comes from the     accuracy the authors obtain
using only the three previous djia values  it seems that for a problem this complex  such a
good accuracy is surprising given the simplicity of the inputs  perhaps the obscure learning
algorithm they use is overfitting the test set  since the authors do not explain how they chose
 

fithe   algorithm hyperparameters and never mention using a validation set  my first suspicion
is that these parameters were not chosen independently of the test set 
another issue with the papers methods is that they only report test set accuracies for the
eight models they consider  the correct approach would have been compute eight validation
set accuracies and report the test set accuracy of the model that performed best in validation 
otherwise  the     number may be due to luck  given enough models we will eventually find
one with a low test error  bollen et al  dont seem to realize this when they argue that an
unbiased coin is unlikely to fall on heads     of the time  in their case  they are throwing
eight such coins  one can check that if the coins are independent  the chance of that event
happening is about     
moreover  their baseline algorithm already has a     accuracy  and since their test set
has only    data points  a     improvement corresponds to only about   additional correct
predictions  it does not seem unlikely that out of seven algorithms one would make   additional
correct predictions purely by chance  especially since the accuracies of the other models seem
to be scattered randomly around       in fact  i was able to make two additional correct
predictions over my baseline by counting sentiment words with an ig of      or more 
one more subtle mistake bollen et al  make is to normalize the training and test set
simultaneously  since they perform a regression and not a classification  scaling the test set
outputs together with the training set outputs introduces additional information into training 
however  since they predict percentage changes  this may not be a big problem 
finally  in the granger causality analysis section  the authors again make the mistake of
not correcting for multiple hypothesis testing  although the probability of a given dimension
being correlated with the dow jones is small  the probability that one out of six is correlated
will be higher 

 

conclusion

given my results  the answer to the question of whether twitter can predict the stock market
is currently no  moreover  my algorithms achieve about a     accuracy by always predicting
that the djia will go up  and therefore obviously cannot be used for constructing a portfolio
that would outperform a financial instrument that follows the djia 
the methodology problems of bollen et al   and the fact that several groups were unable
to replicate their accuracy raise serious concerns about the validity of these authors results 
given the boldness of their claims  i believe they ought to either publish their methods and
their code  or withdraw these claims 

 

fi