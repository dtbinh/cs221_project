decoding visual stimuli from neural responses
niru maheswaranathan  benjamin naecker  hannah payne
cs      machine learning  fall     
abstract
a central question in neuroscience is how populations of neurons encode information about the external world and
how that information is transformed to drive behavior  here we apply machine learning approaches to shed light on
these questions  using data recorded from two brain areas  v   a visual processing area  and the frontal eye field  which
controls saccadic eye movements  in an awake behaving macaque monkey  we trained learning algorithms to decode
information about a visual stimulus or the location of a planned eye movement  the algorithms were quite successful 
indicating that both sensory information and motor plans may be read out effectively from multi electrode recordings 
furthermore  by performing feature selection  we are able investigate which channels encoded the most information
about the stimulus 

background
early studies of information processing in the brain characterized the response of individual neurons to sensory
inputs  advances in both recording and computing technologies now allow for examination of how populations of
neurons encode such information  machine learning algorithms ranging from support vector machines to gaussian
process factor analysis have been applied effectively to
the analysis of neural data            an important practical application of such algorithms is in the deployment of
brain machine interfaces  bmi   in which neural signals
are decoded to drive electronic devices and artificial limbs 
while early bmi efforts required that the human brain
learn what mental states drove certain actions  modern
bmi decodes the normal activity of the brain  other applications of machine learning to neuroscience include
analysis of functional brain imaging data  such as for lie
detection     or for decoding a visual scene      in addition  neuroscientists can also apply machine learning to
determine which features of neural activity carry the most
information about a stimulus or behavior  in order to gain
insight into how the brain efficiently encodes information 
our data was recorded from visual cortical areas of an
awake behaving macaque monkey  we focused on visual
areas because the areas are generally well understood 
and because stimuli are well defined which provides for
relatively easy incorporation into machine learning methods  visual processing begins in the retina  where precise
patterns of output signals   spikes   encode relatively simple visual features  such as luminance and contrast  this
information is then transferred to the visual cortex  where
it radiates out to many areas responsible for processing
specific types of visual information  area v  is one such
area  known to be selective for simple features  such as
orientation and basic shape  and modulated by top down
attentional control      in addition to recordings from area
v   we also analyzed data from an area of the frontal cortex known as the frontal eye field  fef   an area involved
in both attentional control and the planning of precise 
rapid eye movements known as saccades      figure  a

shows where these areas are in the brain  our data is
courtesy of nick steinmetz  from the tirin moore lab here
at stanford 
the activity in v  and fef was recorded with a linear
array electrode  which is able to record from    channels
simultaneously in an awake behaving monkey  for data
recorded from v   the monkey maintained fixation at the
center of a computer screen  on which an oriented grating
appeared in the region of space for which that particular
part of v  was most sensitive  figure  b   during recordings from fef  the monkey maintained central fixation
 target on  while a target in one of six trained locations
appeared for a short time  and then disappeared  target
off   the monkey then maintained fixation until they
were given a signal to act   go cue    at which time the
monkey made a controlled eye movement   saccade   to
the previous location of the target  figure  c   example
recordings for the v  and fef data are shown in figure  d and  e  respectively  these show the firing rates
recorded from two randomly selected channels as a function of time  note the subtle differences between the two
channels  which makes it difficult to analyze such data 
we trained a series of algorithms to predict from the
spiking neural data either the orientation of the grating
 for data from v   or the endpoint of the saccade trajectory
 for data from fef   we also performed a series of model
analyses to explore the robustness of our trained algorithms  our results indicate that support vector machines
consistently outperform other algorithms  in addition  we
found that despite having    separate channels of recordings  a small number of them usually proved far more
informative than the remainder  a final interesting result is that on trials for which our algorithms incorrectly
predicted the endpoint of the saccade  the animals reaction time was significantly longer than on trials that the
algorithm correctly predicted  suggesting that the neural activity on these trials was more noisy or somehow
sub optimal than on correct trials 

fidecoding neural activity

n  maheswaranathan  b  naecker  h  payne

fef

a

c
fef experiment  eye movements

v 

b
v  experiment  predicting orientation

d    

  sec
go cue

  sec

direction  
direction  

    
   

    
mean firing rate

mean firing rate

  sec
target off

e    
  
     

   

   
    

    
   

   

    

    

   

 
   

  sec
target on

 

   

   

   

   

   

    

   

 

time  s 

   

 

   
time  s 

 

   

 

figure    experimental setup   see text for description 

v  experiment
first  we looked at neural recordings from visual area v  
we pre processed the data by computing the average firing rate of the neurons recorded from a given channel over
the     s stimulus presentation  this left us with a data
set of    features  corresponding to each channel  and
around      examples  we randomly chose ten percent of
these to be testing examples  and used the rest as training
examples  we first trained three different machine learning algorithms to predict what orientation stimulus was
shown to the monkey based on of the activity in v   for
our support vector machine  svm  implementation  we
used a radial basis function  rbf  gaussian kernel with
parameters chosen via grid search and cross validation 
the results of the grid search are shown in figure  b 
figure  a shows comparison of the accuracy of these algorithms across three separate days of recording  we see
that the generalized linear model  glm  performs poorly 
while multinomial logistic regression  mlr  and the svm
perform reasonably well  since there are eight possible
stimulus orientations  chance accuracy corresponds to
       the large change in accuracy over different days
suggests that the electrode placement has a significant
impact on learning algorithm performacne  the electrode
is removed and re inserted into the monkeys brain each

day  thus  poor electrode placement is the most likely
reason for the varying accuracy 
figure  d shows that as we vary the number of training examples  the learning algorithm  mlr  performance
increases and saturates around      here      examples of data were randomly selected for testing  and the
number of selected training examples was varied  this
indicates that having more training data would not drastically improve performance  we also performed feature
selection to determine which channels were most important for the learning algorithm  figure  c shows these
results  all pairwise combinations of two channels  for
the third day of recording  since it performed the best as
shown in fig   a  were removed from the data set and the
accuracy of a mlr model was computed  color indicates
the accuracy with the given channels removed  we see
that channels    and    have the largest impact on performance  reducing accuracy by around     individually
and around     when both are removed  the linear array
electrode used for recording is inserted depth wise  perpendicular to cortex  therefore  channels    and    are
most likely picking up signals from the deeper layers of
cortex  layers       it would be interesting to test exactly
why these channels are the most useful  and if this is a
robust phenomenon 
up to this point  all of our analyses focused on using

  of  

fidecoding neural activity

n  maheswaranathan  b  naecker  h  payne

a

b
   

day  
day  
day  

  

  
 

  
  

    
  

   

  

log  c 

accuracy

    

  
  

    
  

 

    
   

  

  

 

    

 

  

accuracy

  

  
logistic regression

glm

   
 

svm

d

log  g 

 

 

channel

c

    
 

channel

figure     a  accuracy of each model   b  feature selection  red line indicates accuracy with all features included   c 
parameter search for radial basis function svm   d  accuracy vs    of training examples 

features generated by averaging over the entire stimulus
presentation      s   we wondered if by splitting the half
a second period into distinct bins  each of which is an
independent feature  we could improve the algorithms
performance  however  such an analysis is subject to overfitting  figure  a and  b show the training  dashed lines 
and generalization  solid lines  error as the number of
bins was increased  again with     of the data randomly
selected for testing  for mlr and svm algorithms  respectively  we see that the training accuracy quickly rises

to       while the generalization error drops off rather
quickly  this means that we are overfitting the training
data when splitting the recordings into discrete time bins 
which suggests that there is not much additional information contained by the temporal structure of the firing
rates  however  for the svm  figure  b   it appears that
splitting the data into a few bins       may help performance  although it is difficult to say for sure given our
error bounds 

fef experiment

lasted three seconds  therefore there was some overlap
between go cue and saccade aligned periods 
we applied several machine learning algorithms to
decode the desired target location from neural data  features were the average firing rate during each of these
four periods across all    electrodes  using these fea 

we next examined neural data from the frontal eye field
 fef  in macaque monkeys  we examined neural firing
rates aligned with the four phases  target on  target off 
go cue  and saccade  figure  c   the total experiment

  of  

fidecoding neural activity

n  maheswaranathan  b  naecker  h  payne

b
   

  

  

  

  

  

  

  

  

accuracy

accuracy

a
   

  
  

  
 
 
  

day    training 
day    training 
day    training 
day    generalization 
day    generalization 
day    generalization 
 

  
  
 

  

  
  

  
  

  

  

 
 
  

 

  

number of bins

day    training 
day    training 
day    training 
day    generalization 
day    generalization 
day    generalization 
 

  
number of bins

 

  

figure    generalization training error vs  bin size for mlr  a  and svm  b 

tures  the best accuracy was     using a support vector
machine with a gaussian radial basis function  figure
 a   since there are six possible targets  chance accuracy
would be        svm performed far better than both logistic regression      accuracy  and a generalized linear
model       accuracy   to optimize the svm  a parameter
search was used to find the best kernel width  g  and slack
parameter  c   figure  c  
interestingly  the monkeys reaction times were slower
on trials that were incorrectly classified by the learning
algorithm  figure  c   this difference was significant for
both svm  p         one tailed t test  and logistic regression  p           the fact that slow trials were harder
to classify could indicate that the neural trajectories on
these trials were less reliable than those with fast reaction times   if the monkey was not as confident in making
the saccade  this could be reflected in the neural response 
to investigate which phases of the experiment contained the most information about the target location 
we excluded each of the four phases in turn from the
analysis  not surprisingly  removing target on impaired
performance the most  reducing accuracy from     to
     removing saccade aligned information had the next
highest impact  followed by go cue and target off  interestingly  even though excluding target off data had
very little impact in the algorithms performance  the monkey clearly still remembered the target location during
this period  indicating that the memory was likely stored
elsewhere than fef  and that fef may play a larger
role in detecting the location of a new target  and later in
initiating a saccade to the desired location 
with further improvement in recording and feature

selection  svm should be a robust technique for decoding neural data  with applications in the field of neural
prosthetics  for example to decode desired movement trajectories  although machine learning algorithms do not
directly probe biological mechanisms  they can reveal interesting features  such as increasing reaction time with
variation in neural activity  which would not otherwise be
apparent 
conclusions
we have showed that it is possible to decode visual stimuli
using multi unit recordings from macaque cortex  using
feature selection  our algorithm gives evidence that information about a visual orientation is best encoded in deep
cortical layers  and that information about present and future saccadic eye movements is encoded in the frontal eye
field  fef   furthermore  for the v  experiment  given the
amount of data we had available  it appears as if training
algrotihms on the temporal structure of firing rates after
stimulus does not improve performance  finally  for the
fef experiment  we observe that the monkeys reaction
time is correlated with our machine learning algorithm
performance  suggesting that the motor regions responsible for coordinating saccadic eye movements depend on
robust encoding in fef 
acknowledgements
we would like to thank nick steinmetz for guidance and
supplying us with experimental data  we would also like
to thank the tas and professor ng for their support 

  of  

fidecoding neural activity

a

n  maheswaranathan  b  naecker  h  payne

b

c

figure    fef results   a  accuracy of each model   b  feature selection  red line indicates accuracy with all features
included   c  parameter search for radial basis function svm 

b

c

reaction times  s 

a

mlr

svm

figure    fef results   a  actual saccade trajectories   b  target classifications predicted from neural data   c  reaction
times slower on trials incorrectly classified by svm 

references
    c davatzikos  k ruparel  y fan  d g shen  m acharyya  j w loughead  r c gur  and d d langleben  classifying spatial
patterns of brain activity with machine learning methods  application to lie detection   neuroimage            no          
    arnulf b a graf  adam kohn  mehrdad jazayeri  and j anthony movshon  decoding the activity of neuronal populations in
macaque primary visual cortex   nature neuroscience            no           
    y kamitani  decoding seen and attended motion directions from activity in the human visual cortex  current biology           
no               
    kendrick n kay  thomas naselaris  ryan j prenger  and jack l gallant  identifying natural images from human brain activity  
nature             no             
    c j mcadams and j h maunsell  effects of attention on the reliability of individual neurons in monkey visual cortex   neuron   
        no           
    byron m yu  john p cunningham  gopal santhanam  stephen i ryu  krishna v shenoy  and maneesh sahani  gaussian process
factor analysis for low dimensional single trial analysis of neural population activity   journal of neurophysiology            
no           
    huihui zhou and robert desimone  feature based attention in the frontal eye field and area v  during visual search   neuron
           no            

  of  

fi