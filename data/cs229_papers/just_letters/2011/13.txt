acoustic features for multimedia event classification
stephanie pancoast
cs     project  final report
   introduction
because of the popularity of online multimedia videos  there
has been much interest in recent years in in multimedia event
detection  med  research  med requires a system that can
search user submitted quality videos  like those found on
youtube  for specific events  video features play a significant
role is determining the content for med tasks  however  the
audio component for a given video can also be critical  consider the case of detecting a home run in a baseball game video 
from the still frames  video researchers may determine that the
setting is a baseball game  but without the capability to detect
cheering in the audio  it would be difficult to discriminate between an uneventful game and one wiht a home run 
there are various possbile approaches for using the audio
component to better understand the video content  for my
project  i explored the method of representing a video files
sound track as a bag of audio words  common to document
classification  bag of words  and image classification  bag ofvisual words       the bag of audio words method has also recently been used for both audio document retrieval        and
med tasks      in this paper i first discuss the acoustic features extracted from the audio component of videos as well as
the bag of audio words method in more detail  my experiments
consisted of    binary classifications  this setup is presented in
section   and followed with the results and conclusion 

   methodology
a high level illustration of the classification system is presented
in figure   

figure    block diagram of the classifications system

for each video file  the mel frequency cepstral coefficients
 mfccs  are extracted from the audio file  a codebook  also
commonly referred to a dictionary  is generated using these
mfcc vectors  the original features are then mapped to the
nearest vector in the codebook  the file is then represented by
what i refer to as a word vector  the word vectors for each file
are then used as the feature vector for the classifier  all of these
system components are discussed in more detail in this section 
     features
the mel frequency cepstrum represents the short term power
spectrum of a sound  it is based on a linear cosine transform
of a log power spectrum on a nonlinear mel scale of frequency

and can be calculated using equation    the cepstrum can be
thought of as a spectrum of the spectrum and provides information on how the spectrum energy changes over time  the
mfccs are the coefficients that make up the mel cepstrum     
the mel scale on which the cesptrum is computed captures the
non linearity of human hearing  equation   can be used to
covert the typical linear frequency scale into the mel scale 
cepstrum    f log  f f  t         

   

f
 
   
   
mfccs are standard features used in many speech recognition tasks such as automatic speech recognition and speaker
identification      the features used in my experiments are are
computed for every   ms audio segment and are extracted using a hamming window with     overlap  the features consist
of    mfccs as well as the log energy of the segment resulting
in a    dimensional vector 
often mfccs  not including the log energy  are normalized within a given file so that the mean of each coefficient is
  across all vectors  this is used to compensate for channel
variability  for example  if one microphone tends to amplify
a certain frequency range  mfcc mean normalization will account for this  in the remainder of this paper i use the term
zero mean to indicate normalized mfccs and original mean to
indicate that non normalized mfcc features were used 
f reqmel       log       

     bag of audio words
as mentioned  written document retrieval commonly uses an
approach referred to as bag of words  since documents can
vary in length and classifiers often require fixed length feature vectors  bag of words resolves this issue by representing a
variable length document with a fixed length word vector  the
dimension of this word vector depends on the size of the codebook and each element i in the vector represents the number of
times the word wi appears in the given document  the wordvector can be thought of as a histogram or bag of words  as indicated by the methods name  as it does not capture the ordering
of the words in the document  in image research word vectors
represent the distribution of visual words rather than words from
a written language  each visual word is the centroid of a cluster 
the clusters are commonly created with the k means clustering
algorithm on the original visual feature space     
i chose to use a bag of audio words approach for the
project because my problem was similar to that of image and
document retrieval  i had an initial set of acoustic features
 mfcc vectors  and sought to classify a given document based
on these features  my algorithm for generating the bag ofaudio words involved the following steps 
   generate codebook
   quantize feature vectors

fi   replace features with codebook indices
   aggregate codeword distribution and use the resulting
word vector as the new feature for classifiers
the idea behind the codebook is to create a smaller set of
features that are representative of the data  here documents are
represented by a bag of audio words  where each audio word
 also referred to as a codeword  is the centroid of a cluster 
this process is illustrated in figure    i chose to use the kmeans clustering algorithm based on the square euclidean distance measure to generate the codebook  i used matlabs
implementation of k means for my experiments  across all
videos  my dataset contains over    million mfcc feature vectors  clustering all these vectors using the available computers
was computationally demanding so i sampled at random    of
the files with the idea that resulting clusters would still be representative of the sounds occurring in all the files  performance
of the overall system is dependent on the number of codewords
and therefore the number of clusters  k  is one of the parameters
i optimized for in my experiments 

here ci j is number of codeword j occurences in document
i  i is the average value of word vector elements for document
i  and i is the standard deviation of the codeword distribution
for document i 
the divide by max divides all of the word counts in a given
count representation vector by the maximum word count in that
vector  this is equivalent to dividing the word vector by the
value of the largest element and ensures that all the elements in
the vector are between   and    the z normalization approach
differs slightly by normalizing the word count distribution for a
file to the standard normal gaussian  mean    variance    

   experimental setup
     dataset
i ran my experiments on a subset of user submitted videos provided from nist  national institute of standards and technology  for the text retrieval conferences video retrieval evaluation      more specifically  i used      youtube quality videos
ranging from approximately   seconds to    minutes in length 
the audio component is sampled at   khz  figure   shows the
number of videos for each of the    event classes while table
    contains a mapping between the event ids and their description  events   and   contain slightly more instances of videos
and event   slightly less  but overall the the dataset is reasonably
balanced 

figure    system diagram of how the codebook was generated
from the audio 

the vector quantization  vq  step consists of finding the
codeword with the smallest distance to the original vector in
euclidean space and taking that codeword as the new feature
vector  the bag of audio words method uses the distribution
of codewords in the file  not the actual values of the codewords 
therefore i instead kept track of the nearest codewords index in
the codebook and from there generated a word vector to capture
the distribution  ideally  certain codewords would be more frequent in a given video event class and therefore a higher value
in the word vector for that codeword would be indicative of that
class  this approach allows the video file to be represented by
a single vector rather than a collection of mfcc vectors 
since the videos vary in length they also vary in the number of mfcc vectors and in consequence the number of audio words  without a normalization step  the magnitude of the
word vector would be proportional to the length of a file  since
the goal is to model the acoustic content  not the length of a
video  this variation needs to be accounted for  i explored two
different normalizing approaches which i refer to as divide by
max  and z normalization give by equations   and   respectively 
ci j   

ci j
maxk c   ck j  

   

 ci j  i  
i

   

ci j   

figure    data distribution

event id
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   

brief description
attempting a board trick
feeding an animal
landing a fish
wedding ceremony
working on a woodworking project
birthday party
changing a vehicle tire
flash mob gathering
getting a vehicle unstuck
grooming an animal
making a sandwich
parade
parkour
repairing an appliance
working on a sewing project

table    event ids with their corresponding descriptions

fi     classification
i chose to use a support vector machine  svm  based classifier with a linear kernel using the liblinear svm library
in matlab      svms have been found to perform well on
audio and multimedia classification problems and are therefore
commonly used in related research              
my experiments consist of    binary classification experiments  for each video event class  such as e     i generated
binary labels as either   to indicate the video file was in the
event class  or   to indicate it was not  this type of experiment is often referred to as verification or one against all    
and is helpful for providing insight into the system performance
for different event classes 
i chose to train on    of the data and test on      using the
same training and test set for all    binary classification experiments 
     performance metric
to measure the performance of the system  two metrics are
commonly used in document classification tasks  mean average
tp
precision  map   where precision is calculated as tp f
  prop
vides insight into the reliability of a positive     label  i used tp
to indicate the number of true positives  tn true negatives  f p
false positives  and f n false negatives  f measure  also referred
to as f score or f   is another metric and can be computed using equation    i used both of these metrics to measure the
performance of my system 
f score    

pr
p r

   

tp
here p is the precision and r the recall   tp f
   f measure
n
balances between measuring the reliability of a positive label as
well as how well the system is doing at capturing the positive
samples 

   results and discussion
there are many parameters in the bag of words classification
system that can be adjusted to seek optimal performance  in
this section i will discuss those that i explored in my project 
     front end features
as mentioned previously  i tried two different types of mfcc
vectors  one set of zero mean and one of original mean  when
averaging across all    binary classification results  i found a
map of       for mfccs with no mean normalization and
      for mfccs normalized to mean zero  these were computed holding the codebook size fixed at      and using divide by max normalization of the word vectors  although the
two results are similar  this indicates the channel variability is
somewhat correlated on the video event class  table   shows
the map for every experiment with a fixed codebook size 
interestingly  some one against all experiments showed
significant improvement with zero mean mfcc vectors while
for others the opposite was true for example  getting a vehicle
unstuck  e     map value improved by almost     with zeromean mfccs while various classes such as feeding an animal
 e     had map values decrease by over     when using zeromean mfccs  this suggests that channel variability is informative for some video classes  while not for others  this is not
so surprising  for example  e    may of the sounds occurring
are generated from wind  also common for many other event

classes such as changing a vehicle tire   therefore  normalizing
the mfcc vector would help eliminate this common factor and
place more emphasis on other more discriminative acoustics in
the videos  e    on the other hand generally has fewer sounds 
and those that are present do not span the entire video  therefore  discriminating between e    and other classes would be
easier with the original mfcc vectors  as all the other noisier
ones could be eliminated 
     codebook size
in the bag of visual words approach  the number of clusters to
be generated in the k means algorithm have varied from hundreds to ten thousands      however  the codebook size is a
tradeoff  when generating a small set of clusters  dissimilar
sounds  as modeled by the mfcc vector  can be grouped into
the same audio word and the codebook is therefore more general but not necessarily discriminative  on the other hand  larger
codebook sizes result in similar sounds being assigned to different audio words  resulting in a more discriminative but less
general vocabulary  further  the larger the codebook size  the
longer both the codebook generation and vector quantization
steps take  especially when clustering on over        vectors 
previous research using bag of audio words explored codebook sizes ranging from              so i also tried sizes in this
range  results are presented in figure    the plot shows the fmeasure  map  as well as average recall across all    binary
classification experiments  using original mean mfcc vectors
and divide by max normalization of the word vector  generating as many of      clusters from    thousand    dimensional
vectors was computationally demanding and the performance
for codebook sizes beyond      did not suggest there would be
improvement by trying larger values for k  so i did not explore
larger sizes  since      codewords showed the highest average
recall and second greatest map values  resulting in the highest f measure  i used      codewords for the remainder of the
experiments 
     word vector normalization
as described in section      i tried two approaches for normalizing the word vector  using original mean mfcc vectors and
codebook size       i found that the map calculated across all
   binary classification experiments was       for the divide by
max approach and       for the z normalization 

figure    f measure for various codebook sizes

fi     performance by event
in addition to optimizing performance across all experiments  it
is also interesting to look how the classification system does for
individual events  figure   shows the f measure for each of the
binary classification experiments for codebook sizes of     and
      original mean mfcc vectors and divide by max wordvector normalization was held constant 

figure    f score  or f measure  by event

some of the event classes such as landing a fish performed
poorly while others such as appliance repair best  likely videos
with little acoustic variety perform better with the bag of audiowords than others  for example  appliance repair videos are
generally instructional and predominately speech with little
background noise  therefore  the codewords modeling speech
would be very discriminative for this event class  landing a fish
videos  on the other hand  often contain sounds ranging from
loud wind to motor boats to people screaming  although these
trends changed slightly when exploring other mfcc normalization and word vector normalization techniques  the lowerperforming and higher performing events remained generally
consistent  as mentioned above  the results for all the mfcc
normalization and word vector normalization experiments are
presented in table  

   conclusion and future directions
my experiments provide initial insight into the performance of
using only the bag of audio words approach for med tasks  in
this project i have explored normalization of both the mfcc
vector as well the word vector representation of the audio file 
results on an event class basis indicate that certain classes perform better with the bag of audio words classification system
than others 
there are many possible variations that can be explored
to seek performance improvement  on the acoustic feature
level  mfccs velocity and acceleration coefficients are often
included in the initial feature vector so this would be one of
the first things to try  further  a different number of mfccs
could be extracted  both of these variations would result in a
larger initial feature vector and would likely have an impact on
the results  after exploring possible improvements on the bagof audio words approach  the word vector representation will
be able to be combined with visual features to further improve
med systems 
on the modeling side  the bag of words algorithm for document classification often incorporates a weighting scheme to
account for the fact that some words  i e  spam  httpaddr  unsubscrib for spam email detection  are more meaningful than

cbk norm
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
e   
average

orig 
divm
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     

mean
z
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     

zero mean
divm
z
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           
           

average
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     
     

table    map for each event with zero mean or original mean
mfcc normalization  and word vector divide by max  divm 
normalization or word vector z normalization  z   these were
computed for codebook size       the highest map value for
a given video class is shown in bold 

others  i e  the  a  and       since i generated my words with
a clustering algorithm  the audio words are more likely to be
evenly distributed  but this may still be an interesting approach
to explore  in addition  feature selection algorithms are often
used to eliminate codewords that are not discriminative  finally 
recent research has found improvement by modeling sequence
of audio words with n gram models      this approach exponentially increases the dimension vectors inputted to the classifier  thus requiring a smaller codebook size  but would better model the acoustics in the file and would therefore also be
a possibly beneficial technique to incorporate into future experiments  after exploring possible improvements on the bagof audio words approach  the word vector representation will
be able to be combined with visual features to further improve
med systems 

   acknowledgements
i thank murat akbacak and eric yeh from sri international for
their invaluable guidance in my project  akbacak provided me
with the idea to explore bag of audio words as well as taught
me the mfcc feature extraction process while yeh was very
helpful in suggesting classification and word vector normalization techniques 

   references
   

jiang  y  zang  x   ye  g    bhattacharya  s   ellis  d 
shah  m  chang  s   columbia ucf trecvid    
multimedia event detection  combining multiple
modalities  contextual concepts  and temportal matching       

   

j  yang  y  jiang  a  hauptmann and c  ngo  evaluating bag of visual words representations in scene classification  in proceedings of the international workshop on
multimedia information retrieval  pp                

fi   

g  checkik  e  le  m  rehn  s  bengio  d  lyon  largescale content based audio retrieval from text queries 
     

   

kim  s   sundaram  s  panayiotis  g  and narayana  s 
an n gram model for unstructured audio signals toward information retrieval multimedia signal processing  mmsp        ieee international workshop on   vol  
no   pp                   

   

trecvid multimedia event detection      evaluation 
http   www nist gov itl iad mig med   cfm

   

rabiner  l  r  and schafer r  w   introduction to digital
speech processing       

   

sanchez  m  h   nuisance compensation and prosodic
modeling on high level speech tasks  ph d  thesis 
stanford university       

   

gersho  a  and gray  r  vector quantization and signal compression  boston  kluwer academic publishers 
     

   

fan  r   chang  k    hsieh  c   wang  x   and
lin  c   liblinear  a library for large linear classification  journal of machine learning research  pp                   software available at
http   www csie ntu edu tw  cjlin liblinear 

fi