improving  response  modeling  with  facebook  
engagement  data  
  
introduction   

louis  lecat   suid   lecat   

predictive  modeling  is  now  a  proven  technique  for  marketing  optimization  and  is  
being  used  more  and  more  often  by  the  private  sector   the  data  sets  used  so  far  are  
mainly  customer  purchase related  data   and  sometimes  web  and  email  behavior   
  
facebook  has  totally  changed  the  online  landscape  over  the  past  few  years   and  
companies  are  now  trying  to  leverage  it  as  a  marketing  resource   spending  more  and  
more  resources  on  their  social  media  face   this  paper  intents  to  come  up  with  an  
original  way  of  measuring  the  impact  of  facebook  activity  on  a  companys  revenue   
and  how  companies  can  leverage  their  social  data  to  improve  predicting  modeling   
  
the  potential  of  this  project  is  huge  for  the  private  sector   thanks  to  this  brand  new  
social  data   companies  could  significantly  improve  their  revenue  by  effectively  
leveraging  high  purchase potential  customers   
  
data  
in  this  paper   we  will  intent  to  improve  the  effectiveness  of  response  modeling  for  
one  selected  company   due  to  privacy  issues  we  cannot  disclose  the  name  of  the  
company   and  we  will  refer  to  it  as  x comp   however   all  we  need  to  know  for  this  
study  is  that  x comp  is  a  retailer  with  a  strong  presence  on  facebook   
  
the  data  that  has  been  used  to  implement  the  models  is  of  four  types   
  purchase  data   all  data  relevant  to  x comps  customers  direct  interaction  
with  the  company   orders   order  dates   order  channels   orders  amount   
discounts   margins   product  types  and  categories   order  frequency   platinum  
memberships   etc   
  email  data   data  gathered  through  all  email  marketing  campaigns  such  as  
emails  clicked   opened   unsubscriptions   dates   etc   
  web  data   all  data  gathered  through  customers  interactions  with  the  website   
such  as  clicks   items  browsed   items  carted   visit  dates   etc   
  facebook  data   data  gathered  on  x comps  facebook  wall   i e   posts   
comments   links  and  likes  with  the  dates  and  attributes  associated   
  
data  collection  
this  research  project  was  realized  in  collaboration  with  a  marketing  analytics  
company   of  which  x comp  is  a  client   the  company  provided  access  to  the  purchase  
data   the  email  data  and  the  web  data  in  a  microsoft  sql  environment   these     types  
of  data  together  will  be  referred  to  as  standard  data  in  this  paper   
  

   

fifacebook  data   on  the  other  hand  was  not  available  and  integrated  with  purchasing  
data   it  was  gathered  using  a  crawling  engine  to  scrape  all  the  public  information  
available  on  x comps  facebook  page   note  that  even  though  most  facebook  users  
have  restricted  and  private  profiles   all  their  activity  on  a  public  facebook  page  such  
as  x comps  page  is  made  public   this  is  why  we  are  able  to  access  their  posts   
comments   links  and  likes  on  this  particular  page   
  
linking  facebook  data  to  purchase  data   method  and  success  
all  facebook  data  from  x comps  page  was  then  imported  in  our  sql  environment  
in  order  to  be  tied  to  the  standard  data   
  
the  next  challenge  was  to  accurately  link  users  id  from  the  standard  data  to  
facebook  user  ids   based  on  the  data  we  have  on  hand  from  facebook   first  name   
last  name   location  and  gender    we  computed  a  similarity  score  tying  facebook  data  
with  standard  data  for  each  customer   we  chose  to  take  into  account  only  the  
customers  presenting  a  similarity  score  higher  than        to  make  sure  we  did  not  
mismatch  any  customer   as  a  result   we  were  able  to  match  approximately       of  
facebook  users  to  existing  customer  ids  in  our  standard  data  database   
  
model   logistic  regression  
predictive  modeling  in  our  case  consists  of  evaluating  the  probability  of  a  customer  
to  place  a  purchase  in  the  upcoming  month   lets  consider  that  we  stand  at  t     t  in  
months    
t     

t     

  

  

  

  

space  for  training  set  features  

  

                t                          t          

space  for  
  
training  labels  

  t                                    time  

  

  
  
space  for  test  
  
space  for  test  set  features  
set  labels  
  
we  define  our  training  set  by  looking  at  past  data   for  a  given  customer  i   features  
are  calculated  over  a      months  period  of  time   between  t     and  t     and  we  
associate  him  the  label  y i         if  the  customer  places  a  purchase  between  t    and  t   
or  y i         if  he  does  not  place  a  purchase  during  that  month   we  will  then  use  the  
test  set  defined  in  green  above   shifted     month  forward   to  predict  whether  
customer  i  will  place  a  purchase  with  x comp  over  the  next  month  or  not   
  
our  two  best  options  to  compute  this  likelihood  are  logistic  regression  and  nave  
bayes   on  this  project   we  chose  to  work  with  logistic  regression   since  we  are  
unsure  of  features  correlation   we  inherently  need  to  test  the  model  on  several  
different  features  to  optimize  it   and  logistic  regression  allows  us  to  avoid  the  extra 

  

   

ficorrelation  induced  by  nave  bayes  if  we  select  a  large  number  of  features   e g   lets  
say  we  work  with  the  number  of  transactions  realized  over  the  past  year   the  
average  amount  of  these  transactions   and  the  total  amount  of  money  spent    
  
much  of  the  implementation  was  realized  through  sql   pre processing  of  data   
calculation  of  model  features   storage  of  those  in  appropriate  tables  and  
computation  of  the  features  and  labels  sparse  matrix   the  actual  logistic  regressions  
themselves  were  run  through  matlab  using  the  exported  sparse  matrix   once  
computed   coefficients  were  re imported  into  sql  to  make  our  predictions  on  the  
test  set   
  
model  validation  
a  good  model  is  a  model  that  the  company  can  leverage   here  is  the  method  we  used  
to  evaluate  the  quality  of  a  model   once  we  have  computed  the  likelihood  of  
purchase  for  customers     n  during  the  upcoming  month   we  rank  these  customers  
in  order  of  likelihood  descending   customers  are  then  assigned  to  response  buckets  
in  that  order   in  the  case  of  x comp       response  buckets  were  assigned  each  time   
where  customers  in  bucket     are  the  ones  with  a  high  likelihood  of  purchase  and  
customers  in  bucket      have  a  low  likelihood  of  purchase   
  
we  then  look  at  what  actually  happened  over  the  predicted  month  along  two  
metrics   
  how  many  customers  actually  placed  a  purchase  in  each  bucket  
  how  much  revenue  was  brought  by  customers  in  each  bucket  
  
a  good  model  is  a  model  in  which  most  of  the  revenue  and  most  of  the  customers  
placing  a  purchase  are  accounted  for  in  the  first  buckets   the  ones  for  which  we  
predicted  high  likelihoods    we  will  visualize  these  results  with  the  two  
corresponding  graphs   
  cumulative  number  of  customers  coming  back  against  response  buckets  
  cumulative  revenue  from  customers  coming  back  against  response  buckets  
  
implementation  and  feature  selection  
implementation  was  conducted  in  two  steps   first   we  used  the  standard  data  to  
implement  the  best  response  model  as  possible   many  iterations  were  conducted  by  
refining  our  feature  set  and  removing  some  of  the  features  presenting  a  high  
correlation  to  each  other   the  final  feature  set  was  selected  using  the  model  
validation  described  above   we  kept  the  model  scoring  above  all  the  others  on  both  
the  plots   
  
we  then  enlarged  our  feature  space  by  including  the  facebook  data   namely  number  
of  posts   comments   links  and  likes   and  filtering  them  out  by  the  selected  date  
ranges    using  the  same  feature  selection  method   and  iterating  as  much  as  possible   

  

   

fiwe  came  up  with  the  best  predictive  model  with  facebook  data   below  is  a  table  
showing  the  final  features  selected  in  both  cases   
  

selected  features  
standard  case  
log    platinumcustomer        
log    dayssince        
log    totalorders        
log    totalitems        
log    aov        
 returnorders   
 timesopened        
 view        
 itemsbrowsed   
 itemsbought   
 itemscarted   
 dayssincelastvisit   
    
    
    

with  facebook  data  
log    platinumcustomer        
log    dayssince        
log    totalorders        
log    totalitems        
log    aov        
 returnorders   
 timesopened        
 itemsbrowsed   
 itemsbought   
 itemscarted   
 dayssincelastvisit   
 posts   
 comments   
 links   
 likes   

results  
the  two  graphs  below  show  the  compared  results  of  the  two  models   a  first  
comment  is  that  we  did  not  get  any  huge  improvement  from  using  the  facebook  
data   on  the  cumulative  revenue  side   it  seems  that  we  get  no  improvement  at  all   
and  the  model  with  the  standard  data  seems  to  fare  slightly  better  on  the  top  
buckets   
cumulative  revenue  from  
customers  coming  back  

cumulative  number  of  
customers  coming  back  
        
       
       
       
       
       
       
       
       
       
      

        
       
       
       
       
       
       
       
       
       
      

purchase     fb  data  

purchase  data  only  

purchase  data  only  

                                           

                                           

response  buckets  

response  buckets  

  
  

purchase     fb  data  

  
   

fihowever   we  get  a  slightly  significant  enhancement  on  the  measure  of  customers  
coming  back   the  model  is  notably  more  accurate  at  predicting  repeat  purchases  on  
the  top      buckets   our  hypothesis  is  that  the  facebook  features  that  we  took  into  
account  in  the  model  really  make  a  difference  for  customers  who  are  heavily  active  
on  x comps  facebook  page   and  thus  much  more  likely  to  be  loyal  customers  of  x 
comp  and  to  fall  in  the  top      buckets   
  
to  double check  our  predictions   we  also  compared  movements  of  customers  
between  buckets  from  one  model  to  another   the  table  below  shows  these  
movements  when  we  assign  customers  to      different  buckets   instead  of        
  
  
  

  
buckets  

model  with  standard  data  only  
   

   

   

   

   

   

   

   

   

    

  
total  
customers  
      
      
      
      
      
      
      
      
      
      

   
                                                    
   
                                                      
   
                                                     
   
                                                      
model  
   
                                                      
with  
fb  
   
                                                      
data  
   
                                                      
   
                                                       
   
                                                     
    
                                                    
total  
                                                            
  
customers  
  

  
as  expected   customers  are  mostly  spread  on  the  diagonal   and  we  see  no  outlier  
movements  in  the  table   e g   no  customers  were  ranked  in  the  top  bucket  in  one  
model  and  the  worst  bucket  in  the  other  model    which  assures  us  of  the  
concordance  of  the  two  models   
  
improvements  and  conclusion  
even  though  the  use  of  facebook  data  is  crucial  for  companies   we  believe  this  
implementation  did  not  show  significant  enough  improvements  for  marketers  to  
start  using  it  on  a  permanent  basis  in  response  modeling   nevertheless  are  the  
results  on  repeat  customers  predictions  encouraging  and  we  believe  that  predictive  
modeling  will  benefit  from  facebook  data  in  the  future   some  areas  for  
improvement  of  the  models  are   
  constructing  more  features  based  on  the  facebook  data   thus  far  we  only  
looked  at  number  of  posts   comments   links  and  likes   but  included  nothing  
about  the  content  and or  the  quality  of  these   some  unsupervised  learning  
techniques  such  as  k means  could  allow  us  to  highlight  clusters  of  active  
versus  inactive  users  for  instance   
  including  more  data   we  could  only  use  public  data  from  the  companys  
facebook  page   getting  access  to  private  data  from  users  should  help   
  

   

fi