scaling for multimodal  d object detection
andrej karpathy
stanford
karpathy cs stanford edu

abstract
we investigate two methods for scalable  d object detection  we
base our approach on a recently proposed template matching algorithm     for detecting  d objects  first  we demonstrate that it is
possible to gain significant increase in runtime performance of the
algorithm at almost no cost in accuracy by quickly rejecting most
regions of the image with low resolution templates  second  we investigate an implicit part based model that uses fixed sized template
dictionary and a generalized hough transform framework to detect objects  we present results on two separate datasets that we
collected using the kinect sensor 

   introduction
real time object learning and detection are important and challenging tasks in computer vision  especially in the field of robotics 
there is a need for algorithms that can enable autonomous systems to
continuously learn to recognize new objects  for such time critical
applications  template matching is an attractive solution because
new objects can be easily learned online  in contrast to statistical
techniques that often require a time consuming training stage 
an efficient template based object detection algorithm has recently been proposed     that runs in real time  does not require a
time consuming training stage  and can handle untextured objects 
it is based on an efficient representation of templates that capture
color  gradient and depth modalities  however  the template based
approach scales linearly with the number of objects and views  making it difficult to use in an application that requires detection of many
objects and viewpoints  in this work  we use the same efficient feature extraction and matching algorithm  but address the scalability
issues in two separate ways  each with its own trade offs 
first  we explore a method of speeding up the template matching
procedure by pre filtering the image with low resolution versions of
all templates to quickly reject parts of the image that are unlikely to
contain objects of interest 
second  we show how to use use a fixed size dictionary of random templates to detect parts of objects in the image  this approach
is inspired by recent work      that suggests that even random filters
can give rise to responses that can be used in a discriminative setting  we use the generalized hough transform to accumulate votes

for object center from weakly detected parts to detect whole objects 

   related work
object detection is a widely studied topic in the literature  below
we briefly summarize the most common approaches to this problem 
template matching this technique is attractive due to its simplicity and its lack of assumptions about the background of objects 
there have been many attempts to addressing the scalability issues
associated with this method      optimizes the layout of features in
memory to minimize cache misses      speeds up template matching using distance transform that group templates together to avoid
matching all templates       uses image segmentation to avoid exhaustive matching  other approaches         utilize relatively cheap
root filters in a cascade detection framework  our first technique of
speeding up the template matching procedure draws mostly on these
ideas 
generalized hough transform models  hough transform    
is a classical computer vision algorithm that was originally used for
line detection  in recent years  hough based methods have been successfully adapted to problem of part based object detection  where
they constitute an implicit shape model                    the main
idea in these methods is to first detect parts of objects independently 
and then use the detected parts to cast votes for the object center in
the image  our second approach is similar to these methods  except
we use different features and matching algorithm to detect object
parts 

   approach
in this section  we first describe the multimodal feature extraction
and matching algorithms  these steps are similar to those described
in      we then discuss two approaches weve investigated that serve
to replace the naive  brute force template matching scheme in the
previous method 

     feature extraction and representation
the rgb image and a corresponding depth map are converted to
a set of three feature modalities   om  mm   here  m  m denotes
one of three modalities  gradient orientation  depth orientation  and
color  each modality is a discrete valued two dimensional array of
the size of the original image  gradient orientation modality is

fiwhere i p is the image downsampled by a factor of p  t p are the
templates downsampled by a factor of p  and  is a threshold value
that must be manually set  intuitively  a downsampled image is first
filtered with lower resolution templates and only positions that score
above the threshold  are further investigated as potential positives
using the full resolution templates 
figure    visualization of the features computed from an image  from left to
right  color image  depth image  color modality  gradient orientation modality  and depth orientation modality  a different color is used for every possibly value that a modality can take on  one of   to n    here n      is
used  

obtained from the rgb image by computing absolute value of the
orientation of the gradients at every pixel  locations with low gradient magnitude are ignored  depth orientation modality is identical to the gradient modality  except the gradients are computed on
the depth map  color modality is computed by first converting the
rgb image into hsv color space  and then keeping only the hue
component  locations in the image that have a very low gradient
magnitude or very low saturation are ignored  finally  all modality
maps are discretized into one of n  values 

     template matching
given a set of aligned modalities  om  mm   a template is defined as t     o mm   l   l is a list of pairs  r  m  where r is a
location of a feature in modality m  the similarity measure between
a template and an image patch is defined as 

e  i mm   t   c   

x 
 r m l


max fm  om  r   im  t  

tr c r 

where r c   r     c   r  t    c   r   t      c   r  t    c  
r   t    defines the neighbourhood of size t centered on location
c   r in the  input image im and the function fm  om  r   im  t  
computes the similarity score for modality m between the reference
image at location r and the input image at location t  thus  each
feature in a template is aligned locally in a small neighbourhood
to the most similar feature in the input image  this formulation is
therefore invariant to small changes in the input patch 
the similarity measure is used to perform template matching with
a simple sliding window approach together with non maximum suppression 

     template matching with root filters
in this section  we describe an algorithm to speed up the template
matching approach by quickly rejecting most parts of the image  we
re define the similarity measure as follows 
 
   e  i p  mm   t p   pc    
ep    i mm   t   c   
e  i mm   t   c   otherwise

     generalized hough transform for implicit part model
model  in the generalized hough transform framework  an object is detected through a consensus vote of local  independent and
weak object part detectors  each weak detector maintains a distribution of the location of the object center relative to its location  for
example  detecting a part similar to the top of a bottle can be an
indicator of a bottle present below 
concretely  we maintain a codebook c of size n   where each
element ci represents an object part  for every part there is an associated probability distribution p  on   x ci   over all objects on and
locations in the image  x that are represented in the local coordinate
system of the part  assuming that every parts prediction is independent and equally important  the probability of p  on   x  can be
obtained by simply adding the probabilities p  on   x ci   for each
detected part  offset by its location in the image 
the distribution p  on   x ci   is learned from training data by frequency counting  every time a part on is detected on an object 
the location of the object center relative to the part is recorded and
stored in memory  together  all records for a part represent a nonparametric model of the distribution that can be stored as a sparse
matrix 
part learning  we now describe the mechanism for learning
and detecting object parts in the image  each part ci is a vector
of responses for a set of m fixed  random templates ti   i      m 
ci    e it   t    ci         e it   tm   ci    where it is a training image of
one of the objects  and c is a location inside the mask for that object 
for efficiency  we only learn parts at sparse  repeatable locations on
the object  specifically  we choose to use harris corner keypoints
for this purpose 
detection  given a location l in an image i  we can similarly
form a vector of responses of every one of our random templates at
that location   e i  t    l        e i  tm   l   and match the responses
to those obtained during training using l  distance  we consider a
part to be detected at some location if the minimum l  distance is
below a threshold 
this method has several attractive properties  mainly  both learning and detection can be implemented very efficiently as they only
require us to increment appropriate variables  all distance calculations can also be implemented efficiently using approximate knearest neighbour techniques such as kd trees  efficient implementations exist     

   dataset collection
the data used in our experiments are collected using the microsoft kinect sensor  depth holes in the raw kinect depth map

fifigure    left  visualization of hough voting method  every black circle is a weakly detected part  and green lines indicate votes  the green lines meeting at
the center of the tea cup give rise to a noticeable peak in the response map for that object  center   right  visualization of the root filter template matching 
proposed locations are shown in green and filtered further  the black rectangle is a true positive match obtained from subsequent filtering 

figure    left  example of an image from the turntable dataset  center  example image from the in the wild dataset  right  the two bottles we attempt
to detect  the blue bottle is partially occluded by a yellow marker in the test set 

are inpainted using algorithm described in      
ten objects on turntable dataset is intended to test the discriminative power of the algorithm  it consists a set of    distinct household objects  book  four bottles  calculator  can of coke  coffee cup 
tea cup  bicycle helmet  and tea box  these objects were chosen
specifically to cover large variations in color  size  shape  and texture 
each object is placed on a turntable and rotated     degrees  the
kinect sensor is placed at the height of the turntable and captures
about    pairs of color and depth images  the ground truth mask
for each object view is computed using a manually chosen depth
threshold  examples of images obtained are shown in figure    we
also place a number of distractor objects in the background  which
can produce false positives for low detection thresholds 
objects in the wild tests the ability of the algorithm to detect
objects in a heavily cluttered environment from many viewpoints
and with some occlusions 
to collect training images we placed two of the objects on the
turntable in turn and moved the kinect freely around the object to
acquire many images from many possible views  scales  rotations 
out of plane rotations  and tilts  on the order of     such color 
depth  and mask images were obtained from this procedure for each
object  examples of acquired images are shown in    the precise
mask segmentation was automatically computed by calibrating the
camera using ransac with respect to a square calibration pattern
placed on the turntable 
to collect the test set we placed both objects in a cluttered environment and partially occluded one with a marker  we moved the
kinect freely around the table at different scales  tilts and rotations
while saving color and depth images 

   results
we compare the results of the proposed methods on the two collected datasets discussed above  all experiments were performed on
one processor of an intel core   quad core cpu at      ghz and
with   gb of ram 
     

turntable dataset

the images in the dataset are split randomly to     training and    
testing images  the performance is evaluated by changing the detector threshold during template matching  non maximum suppression
is performed on raw detection results such that any detection windows that overlap by more than a fraction of     with the intersection
over union metric are considered to be in conflict  and only the detection with higher score is retained 
for the hough voting method we use m       random templates
of size     for approximate nearest neighbor we use   kd trees and
    checks  after all votes are cast  we smooth the response map
using a gaussian with      
per class performance  the results are summarized in figure
   the root filtering approach can significantly improve the speed
    x  to about  fps  if one is willing to sacrifice a small amount of
recall  we explore this trade off further below 
the hough voting method achieves a lower performance  but
runs relatively quickly      x  about  fps   note that the method performs almost perfectly on some objects  and poorly on others  concretely  the two objects it performs worst on are tea and can  which
are the two smallest objects in the dataset  this suggests that these
objects had trouble accumulating votes for their centers  more gen 

fifigure    detection results on the turntable dataset  the original runs at     frames per second  root filtering    x faster  and hough voting     x faster 
left  average recall across classes  to the right  individual performances 

erally  from manual inspection it appears that this method performs
poorly when relatively few pixels in the image belong to the object 
such as when objects are viewed from the side  accordingly  future
work could potentially improve on these results by using a different
detection threshold for each object or view  or scaling votes based
on the size of each object  we attempted a few of these changes but
were unable to significantly improve the performance 
speed vs  performance  in figure   we explicitly investigate
the speed vs  performance trade offs for each method by fixing the
rate of false detections per image we are willing to tolerate to     
and plotting the average recall  to increase speed for the original
method  we monotonically downsample all images and templates 
to increase speed for the root filtering method  we monotonically
downsample both pre filtering and post filtering images by lower
increments  we only evaluate the hough voting method a single
time because it is not immediately obvious how one could go about
speeding it up  the figure shows that the root filtering approach to
template matching can retain most of the recall with significant gains
in performance  up to   x and more   the hough voting approach
is seen to be comparable with downsampling images and running
naive template matching 
     

objects in the wild dataset

the in the wild dataset consists of     views for two objects  and
    testing images that contain them both in a cluttered scene  template matching is done over   scales because the camera is not always at constant distance from the object  results of the root filtering approach are shown in figure    the   scales of the image can
be processed at about   frames per second per object  the blue bottle turns out to be harder to detect because it is smaller  less distinct
from its environment  and partially occluded  upon manual inspection  most false negatives can be attributed to motion blur  example
of these frames can be seen in figure   
we also investigate the usefulness of modalities towards the final
performance  as can be seen from the figure  including depth information significantly improves the performance of the detector  how 

ever  by itself depth performs on par with color and gradients  this
indicates that depth captures useful information about the object that
is orthogonal in nature to an ordinary image  to some degree  this is
merely a quantitative support of an expected result 

   conclusion
we presented two extensions of an existing template matching
scheme for  d object detection  the idea of conducting the template
matching procedure on two scales of the images for quick rejection
has proven to be significantly more efficient without much loss in
performance 
the approach that uses detection of parts in a generalized hough
transform framework was found to perform comparably to template
matching on low resolution images in both speed and detection performance  by manual inspection of the classification results we
speculate that this is in part because some views of objects  such
as a book viewed from the side  contain too little evidence to reliably detect object parts  while this is in principle an issue for the
template based method as well  it was not found to affect the performance to such a high degree 
future work could involve applying explicit part based models to
this problem  such as start shaped models or constellation models 
but question remains if these models can be adapted to compete with
the speed of root based template matching for rigid objects  an interesting direction would be to try to obtain additional speedups in
the root based template matching method by not only rejecting image regions  but also rejecting templates before they are applied  for
instance  one could use the similarity of templates to reason about
the correlation in their response values on a given patch  and potentially choosing to not apply a template if the expected response is
too low 

references
    l  bourdev and j  malik  poselets  body part detectors trained using
 d human pose annotations  in computer vision       ieee   th

fifigure    left  speed vs accuracy trade offs  right  performance of the root filtering approach on in the wild dataset 

figure    left  example detections using the hough voting scheme  top  a typical failure case  when not much of the object is visible  right  detections
in the wild  proposed detections by root filter are shown in green  from left  blue bottle correctly detected  yellow bottle correctly detected  example of
typical failure due to motion blur 

international conference on  pages           ieee       
    p  felzenszwalb  r  girshick  and d  mcallester  cascade object detection with deformable part models  in computer vision and pattern
recognition  cvpr        ieee conference on  pages          
ieee       
    j  gall and v  lempitsky  class specific hough forests for object detection  in computer vision and pattern recognition        cvpr
      ieee conference on  pages           ieee       
    d  gavrila  multi feature hierarchical template matching using distance transforms  in pattern recognition        proceedings  fourteenth international conference on  volume    pages         vol   
aug      
    s  hinterstoisser  s  holzer  c  cagniart  s  ilic  k  konolige 
n  navab  and v  lepetit  multimodal templates for real time detection of texture less objects in heavily cluttered scenes       
    p  hough  machine analysis of bubble chamber pictures  in international conference on high energy accelerators and instrumentation 
volume          
    b  leibe  a  leonardis  and b  schiele  combined object categorization and segmentation with an implicit shape model  in workshop on
statistical learning in computer vision  eccv  pages            

    s  maji and j  malik  object detection using a max margin hough
transform  in computer vision and pattern recognition        cvpr
      ieee conference on  pages           ieee       
    m  muja and d  g  lowe  fast approximate nearest neighbors with
automatic algorithm configuration  in international conference on
computer vision theory and application vissapp     pages    
     insticc press       
     a  opelt  a  pinz  and a  zisserman  a boundary fragment model
for object detection  computer visioneccv       pages        
     
     m  pedersoli  a  vedaldi  and j  gonzalez  a coarse to fine approach
for fast deformable object detection  in ieee conference on computer
vision and pattern recognition       
     o  russakovsky and a  ng  a steiner tree approach to efficient object
detection  in computer vision and pattern recognition  cvpr       
ieee conference on  pages            june      
     a  saxe  p  koh  z  chen  m  bhand  b  suresh  and a  ng  on random weights and unsupervised feature learning  in workshop  deep
learning and unsupervised feature learning  nips        
     a  telea  an image inpainting technique based on the fast marching
method  journal of graphics  gpu  and game tools                  

fi