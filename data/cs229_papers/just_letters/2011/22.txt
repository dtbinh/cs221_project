guided water rocket
gongmyung lee  jungbae sohn  daniel   kairen wong
i  introduction
the water rocket is a well known educational toy  a sealed soda bottle filled partway with water
is then pressurized with air  when the seal is removed  the pressurized air within the rocket quickly expels
the water inside  launching the rocket upwards  in our final report  we describe a simple yet successful
application of reinforcement learning to water rocket flight  particularly the stabilization of the craft
necessary for directed flight to take place  we also detail the design of our rocket  focusing on the
electronics that allow the rocket to transmit information to a wireless receiver  as well as the machine
learning algorithms applied to reduce noise during launch 
the appeal of the water rocket is twofold  first  it is simple to build and receives only one
thrust  simplifying the engineering process  second  the modeling process surrounding a water rocket is
complicated  we know that values such as the pitch  roll  yaw and location of the rocket can help us
determine where the rocket will be next  but the intimate control of fins required for such flight escapes us
and would require many hours of manual practice  biological reinforcement learning  with the controls 
though the water rocket has been quite thoroughly examined  in many cases allowing for detailed
simulators to be built  the application of machine learning algorithms to controlling its flight still has
greater implications  one imagines the exportability of a well designed algorithm to autonomous fixedwing aircraft and missiles 
ii  building the rocket
the rocket is divided in to two parts  the fuel tank and the payload  the fuel tank consists of an
intact soda bottle and four orthogonally placed stabilizer wings that will keep the rocket from spinning
too much and provide adequate drag so that the rocket can guide itself head first 
the payload stage contains of the brain and muscle of the rocket  the microcontroller  gps  xbee 
inertial measurement unit  and two rc servo motors serving as the control  the inertial measurement unit
is carefully collocated at the center of mass of the rocket when it is
empty to avoid unnecessary non linearity in measurements  three
gyros and one   axis accelerometer are fused together to give an
accurate measure of the rockets attitude  the   hz gps module from
sparkfun which uses uart to communicate with the microcontroller 
due to limited time constraint  a decision was made to use open source
gps parsing library from cornell  this module will provide altitude 
longitude  latitude  time  and crude measure of heading and velocity 
atmega     the microcontroller of the rocket  receives information
from the gps  imu inertial measurement unit   and pcs matlab via
xbee to calculate the appropriate control laws and move the two
canard fins appropriately using mini rc servos  the entire system
hardware  with protection fuses included  is complete and running with
a  v battery power supply the entire payload is housed in a styrofoam
box to absorb the shock of the impact  more sponge was added to fill the void between the soda bottle and
the styrofoam box to enhance shock survival 

fimost obstacles in this stage lay in the complete fail safe
assembly and integration of different software and hardware
modules  each with different interface protocols and operating
voltage requirements  made the hardware implementation a project
within a project  a couple of design flaws in circuitry  poor choice
of communications logic converting transistor burning itself
whenever the serial data rate goes up more than      baud rates 
were detected and debugged  unfortunate short circuits disabled
flight computer block   while block   was thoroughly burnt out by unexpected reverse current generated
by rc servo motors during the impact of landing  after a series of modifications  flight computer block  
was ready after the thanksgiving break to finally support machine learning  this version survived total   
head on landing impacts and is still running 
the rocket communicates to pc via wireless and matlab receives the serial data packets
containing pitch  roll  and yaw data real time  matlabs role was to compute and update the mdp and
sends simple two number commands to the rocket  left and right rc servo angle commands 
iii  filtering noise in sensor readings
since we expect the vibration of the rockets launch and the drift of the gyros to seriously corrupt
the attitude calculation  we use a discretized version of kalman filter that we derived by hand  given
and

  with v and w as distinct gaussian noise  we start out

to compute kalman gain k such that out end result of the calculation
optimal in the sense that the cost function
estimation   plugging in the defined values above to the cost function  we
get

is
is minimized  covariance of

by expanding and applying expectation operators  and noting that v and w are statistically independent
gaussian noise with zero mean  the cost function simplifies to 
where
  q is the system noise
variance and r is the measurement noise variance 
defining new variables l and m 
expansion  we eventually find that the cost function is 

and continuing the

since m is positive definite  the best choice of k must eliminate the first dominating quadratic term 
the cost was originally defined to be the covariance of estimation  with new optimal value of k 
 

fithus we derived the optimal gain k  estimation resulting estimation cov  p k     posterior estimation
x k    and have what we need for the next round of recursive kalman filter update 
in our implementation of the filter  the pitch and roll angles were the state space vector x  with
slight modification  our state transition equation became
with control
inputs  here  u k  will be our  axis gyro inputs  these are angular rates  that drift but are relatively
accurate in small time increment  hence an excellent choice for u t  control   what was originally the
system process noise would then becomes the gaussian noise of the gyros 
once the priori propagation of the state and covariance has been made  h x t   our prediction of
what angle measurements are going to be  according to our prediction  is compared against the
measurement of attitude calculated from the   axis accelerometer  this decision was made since the
accelerometer is very noisy in small time scale compared to the gyro but its gaussian noise is bounded
unlike the gyros  the kalman gain will reflect the propagation and the residual error  measurementprediction  accordingly to update the state  pitch  yaw  and roll  
then r is our covariance matrix for the accelerometer s gaussian noise  the constants r and q are tuned
by series of experiments recording the launch vibration of the rocket 
the result was very satisfactory  the filtered estimations were insensitive to launch shocks   nd
figure  while being sensitive to real rocket rotations   st figure  red is the kalman filtered roll  blue is the
actual angle measured  they are closely following each other   we now have reliable means to prepare
attitude reference for mdp update 

iv  rocket guidance
algorithm
we implemented an
reinforcement learning based
guidance system that
controlled the pitch  roll  and
direction of the rocket  for
proof of concept and due to
technical limitations in our
project  we wrote a separate
mdp algorithm to control
each of these features
individually  solving them
through value iteration 
given more time and
resources  these three
algorithms could be
combined into a single mdp
that would yield a
 
comprehensive guiding policy  alternately  we could seek to formulate a model for linearly combining
the results of the three separate mdps to best reach targets  the state discretization and transition actions
we used are described below 
 

several students who stopped by our project pointed out that a wing leveller serves nearly the same purpose as our
current pitch and roll stabilizing reinforcement learning algorithms  while this is true  we maintain that

fimodeling states 
in modeling states  we ran into a fundamental difficulty  without an accurate simulator  we were
unable to generate enough flight data to learn a comprehensive flight guidance policy  and given the time
limitations of the project  building a simulation from scratch was beyond our means  though we could
technically include in our states the pitch  yaw  roll  gps coordinates  velocity  and angular velocity in the
three dimensions  the exponential growth of the number of states would make it impossible for us to learn
the probability transition matrix p  since we were limited in learning these parameters through flight  
thus a linear regression of states  though mathematically rigorous  would in fact serve us poorly  we
would never be able to observe enough transitions to derive an accurate p  thus threatening the validity
learned values and actions 
due to this difficulty  we decided to first focus our efforts on stable flight  since during our test
launches we found that the rocket would always spin randomly due to aerodynamic instabilities in its
design  we divided states based solely on pitch  and then on roll 
shown to the left is a
visual representation of
the way we discretized
the roll and pitch of the
rocket  we divided each
of these up into seven
different states  with a
reward matrix of       
                
corresponding to states
     for pitch  we
dynamically adjusted the rewards based on distance to a target location   initially the reward matrix was
weighted highest at states   and    then as the rocket gets about halfway to the target  states         have
the highest rewards  and finally as the rocket gets close to the target states   and   receive the highest
weights 
while theoretically the servo motors can turn to any angle from        we had to limit the
transitional actions to as few as possible to facilitate efficient learning  for pitch  we had the actions up 
flat  and down  reflecting the overall angle of the wings  for example  at up  both wings were
angled upwards at    degrees  similarly  for pitch  we had the actions left  right and flat  signifying
the direction in which the rocket should roll given the wing angles  for direction  left  right and flat
were used again  but now only the outside fin was turned to the appropriate direction if necessary 
v  results
we found that control of the pitch over time  while useful  would be hard to test and yield
uninteresting results  since gravity determines a great deal of the rockets pitch in a flight  however  we
reinforcement learning as a complete model is more accurately suited to rocket flight  especially when considering
the variety of other tricks we could consider having the rocket do 
 

we had not only time limitations  but technological limitations  each flight threatened the life of our rocket  the
lifespan of the rocket is necessarily limited by the number of landing impacts it can take 

fidemonstrated significant improvement in the rockets roll during a launch  shown on the left below is a
graph of our change in transitional probabilities  p  over successive launches  the decreasing in
difference is encouraging  as it suggests convergence  in the middle  we have a graph of roll versus time
without controls  we can see that it is relatively random  on the far right  we have a graph of roll versus
time with controls  in red   and the actions  in blue  that the rocket performed  a value of     signifies
turning clockwise  a value of     signifies staying flat  and a value of     signifies turning
counterclockwise  we can see that when the red line rises above zero  the blue line quickly shoots to     
showing that the rocket seeks to level itself  when the red line falls below zero  the blue line shoots to
     showing that the rocket is orienting itself in the opposite direction  this is exactly as desired 

vi  further work
during this project we sent readings to computer running matlab to do computations  by
doing calculations directly on the flight computer  we could improve the action loop rate  speeding up our
reaction time to state changes 
with more time and a simulator  we could consider more states and more actions  instead of set
angles to turn wings  we could discretize the possible angles  and test out many more possibilities 
including variables such as velocity and angular momentum would make our states more accurate 
finally  a linear combination of the instructions outputted by each of our three mdps at a given
state would allow the rocket to reach a target while maintaining stability  learning these weights  or
redoing the mdp process with the states of each mdp combined achieves the broad goal we had in mind
when beginning this project 

fi