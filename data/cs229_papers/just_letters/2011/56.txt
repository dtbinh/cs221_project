music genre classification
michael haggblade

 

yang hong

kenny kao

introduction

music classification is an interesting problem with many applications  from drinkify  a program that
generates cocktails to match the music  to pandora to dynamically generating images that complement the music  however  music genre classification has been a challenging task in the field of music
information retrieval  mir   music genres are hard to systematically and consistently describe due
to their inherent subjective nature 
in this paper  we investigate various machine learning algorithms  including k nearest neighbor  knn   k means  multi class svm  and neural networks to classify the following four genres  classical  jazz  metal  and pop  we relied purely on mel frequency cepstral coefficients  mfcc  to
characterize our data as recommended by previous work in this field      we then applied the machine learning algorithms using the mfccs as our features 
lastly  we explored an interesting extension by mapping images to music genres  we matched the
song genres with clusters of images by using the fourier mellin  d transform to extract features and
clustered the images with k means 

 
   

our approach
data retrieval process

marsyas  music analysis  retrieval  and synthesis for audio signals  is an open source software
framework for audio processing with specific emphasis on music information retrieval applications  its website also provides access to a database  gtzan genre collection  of      audio
tracks each    seconds long  there are    genres represented  each containing     tracks  all the
tracks are      hz mono    bit audio files in  au format      we have chosen four of the most
distinct genres for our research  classical  jazz  metal  and pop because multiple previous work has
indicated that the success rate drops when the number of classifications is above        thus  our
total data set was     songs  of which we used     for training and     for testing and measuring
results 
we wrote a python script to read in the audio files of the     songs per genre and combine them
into a  csv file  we then read the  csv file into matlab  and extract the mfcc features for each
song  we further reduced this matrix representation of each song by taking the mean vector and
covariance matrix of the cepstral features and storing them as a cell matrix  effectively modeling
the frequency features of each song as a multi variate gaussian distribution  lastly  we applied
both supervised and unsupervised machine learning algorithms  using the reduced mean vector and
covariance matrix as the features for each song to train on 
   

mel frequency cepstral coefficients  mfcc 

for audio processing  we needed to find a way to concisely represent song waveforms  existing
music processing literature pointed us to mfccs as a way to represent time domain waveforms as
just a few frequency domain coefficients  see figure    
 

fito compute the mfcc  we first read in the middle     of the mp  waveform and take    ms frames
at a parameterized interval  for each frame  we multiply by a hamming window to smooth the edges 
and then take the fourier transform to get the frequency components  we then map the frequencies
to the mel scale  which models human perception of changes in pitch  which is approximately linear
below  khz and logarithmic above  khz  this mapping groups the frequencies into    bins by
calculating triangle window coefficients based on the mel scale  multiplying that by the frequencies 
and taking the log  we then take the discrete cosine transform  which serves as an approximation
of the karhunen loeve transform  to decorrelate the frequency components  finally  we keep the
first    of these    frequencies since higher frequencies are the details that make less of a difference
to human perception and contain less information about the song  thus  we represent each raw song
waveform as a matrix of cepstral features  where each row is a vector of    cepstral frequencies of
one    ms frame for a parameterized number of frames per song 
we further reduce this matrix representation of each song by taking the mean vector and covariance
matrix of the cepstral features over each   ms frame  and storing them as a cell matrix  modeling the frequencies as a multi variate gaussian distribution again compressed the computational
requirements of comparing songs with kl divergence 

figure    mfcc flow

 
   

techniques
kullback lieber  kl  divergence

the fundamental calculation in our k nn training is to figure out the distance between two songs 
we compute this via the kullback leibler divergence      consider p x  and q x  to be the two
multivariate gaussian distributions with mean and covariance corresponding to those derived from
the mfcc matrix for each song  then  we have the following 

however  since kl divergence is not symmetric but the distance should be symmetric  we have 

   

k nearest neighbors  k nn 

the first machine learning technique we applied is the k nearest neighbors  k nn  because existing
literature has shown it is effective considering its ease of implementation  the class notes on knearest neighbors gave a succinct outline of the algorithm which served as our reference 
   

k means

for unsupervised k means clustering to work on our feature set  we wrote a custom implementation
because we had to determine how to represent cluster centroids and how to update to better centroids
each iteration  to solve this  we chose to represent a centroid as if it were also a multi variate gaussian distribution of an arbitrary song  which may not actually exist in the data set   and initialized
the four centroids as four random songs whose distances  as determined by kl divergence  were
above a certain empirically determined threshold  once a group of songs is assigned to a centroid 
the centroid is updated according to the mean of the mean vectors and covariance matrices of those
 

fisongs  thus represented as a new song that is the average of the real songs assigned to it  finally  as
random initialization in the beginning and number of iterations are the two factors with notable influence on the cluster outcomes  we determined the iteration number empirically and repeatedly run
k means with different random initial centroids and pick the best  as determined by the calculated
total percent accuracy 
   

multi class support vector machine  dag svm 

a directed acyclic graph of   class svms
   

svm classifiers provide a reliable and fast way to
differentiate between data with only two classes 
in order to generalize svms to data falling into
multiple classes  i e  genres  we use a directed
acyclic graph  dag  of two class svms trained
on each pair of classes in our data set  eg f    x 
denotes the regular svm trained on class   vs
class         we then evaluate a sequence of twoclass svms and use a process of elimination to
determine the output of our multi class classifier 

neural networks

we tried neural networks because it has proved generally successful in many machine learning
problems  we first pre process the input data by combining the mean vector and the top half of the
covariance matrix  since it is symmetric  into one feature vector  as a result  we get             
 
features for each song  we then process the output data by assigning each genre to an element in the
set of the standard orthonormal basis in r  for our four genres  as shown in the table below 
genre
vector

classical
            

jazz
            

metal
            

pop
            

we then split the data randomly by a ratio of               of the data was used for training our
neural network      of the data was used for verification to ensure we dont over fit  and     of
the data for testing  after multiple test runs  we found that a feedforward model with    layers  see
figure    for our neural network model gives the best classification results 

figure    diagram of a neural network

 
   

results
music genre classification

classification accuracy varied between the different machine learning techniques and genres  the
svm had a success rate of only     when identifying jazz   most frequently misidentifying it
as classical or metal  the neural network did worst when identifying metal with a     success
rate  interestingly  the neural network only ever misidentified metal as jazz  k means did well
identifying all genres but jazz  which was confused with classical     of the time  k nn had
difficulty differentiating between metal and jazz in both directions  of its     failures identifying
jazz  it misidentifies as metal     of the time  similarly  k nn incorrectly predicted that metal
 

fipredicted

table    k means results
actual
classical jazz metal
classical
  
  
 
jazz
 
  
 
metal
 
 
  
pop
 
 
 
accuracy
   
       

pop
 
 
 
  
   

predicted

pop
 
 
 
  
   

table    neural network results
actual
classical
jazz
metal
classical
  
 
 
jazz
 
  
 
metal
 
 
  
pop
 
 
 
accuracy
   
        

table    k nn results
actual
classical jazz metal
classical
  
 
 
jazz
 
  
 
metal
 
 
  
pop
 
 
 
accuracy
   
       

predicted

predicted

table    dag svm results
actual
classical jazz metal
classical
  
 
 
jazz
 
  
 
metal
 
 
  
pop
 
 
 
accuracy
   
       

songs would be jazz in     of all its failed metal identifications  overall we found that k nn
and k means yielded similar accuracies of about      a dag svm gave about     accuracy and
neural networks gave     accuracy 

   

music to image mapping

figure    image accompanying lady gagas poker face

as an extension  we mapped images to song genres  we obtained     images  with    images
of similar type  i e  nature images for classical music  per music genre  for extracting a set
of features from the images  we used the fourier mellin  d transform  fmt   which is similar to
extending mfccs to  d      the main differences are that we binned the dtft according to a
non uniform logarithmic grid and then transformed from cartesian to log polar coordinates  keeping
the rest of the procedure more or less the same as mfccs   this makes the mellin  d transform
invariant to rotation  scale  and illumination  which is important in image characterization 
we then applied k means clustering to our feature matrices from fmt  using the frobenius norm as
our distance measure between images  lastly  we matched each of the resulting clusters to a genre 
such that given a song  we can map the song to a genre as well as to a random image in the associated
image cluster  our music to image mapper generated some fairly interesting results  for example 
our music classification correctly identified lady gagas poker face song as pop  when we then
mapped the pop genre to a random image from its associated image cluster  we received the image
in figure    a very reasonable matching 
 

pop
 
 
 
  
    

pop
 
 
 
  
   

fi 
   

conclusion
discussion

our algorithms performed fairly well  which is expected considering the sharply contrasting genres
used for testing  the simpler and more naive approaches  k nn  supervised  and k means  unsupervised   predictably did worse than the more sophisticated neural networks  supervised  and
svms  unsupervised   however  we expected similar performance from svms and neural networks
based on the papers we read  so the significant superiority of neural networks came as a surprise 
a large part of this is probably attributable to the rigorous validation we used in neural networks 
which stopped training exactly at the maximal accuracy for the validation data set  we performed no
such validation with our dag svm  most learning algorithms had the most difficulty differentiating between metal and jazz  except k means which had the most difficulty differentiating between
classical and jazz  this corroborates the idea that qualitatively these genres are the most similar 
our image matching results can be considered reasonable from human perception but due to the
subjective and nebulous nature of image to music genre clusters  we found roughly     overlap of
image types with any two given image clusters 
   

future work

our project makes a basic attack on the music genre classification problem  but could be extended in
several ways  our work doesnt give a completely fair comparison between learning techniques for
music genre classification  adding a validation step to the dag svm would help determine which
learning technique is superior in this application  we used a single feature  mfccs  throughout this
project  although this gives a fair comparison of learning algorithms  exploring the effectiveness
of different features  i e  combining with metadata from id  tags  would help to determine which
machine learning stack does best in music classification 
since genre classification between fairly different genres is quite successful  it makes sense to attempt finer classifications  the exact same techniques used in this project could be easily extended
to classify music based on any other labelling  such as artist  in addition  including additional metadata text features such as album  song title  or lyrics could allow us to extend this to music mood
classification as well 
in regards to the image matching extension  there is room for further development in obtaining a
more varied data set of images  instead of four rough image themes such as nature for classical or
pop artists for pop   although quantifying results is again an inherently subjective exercise  another
possible application of the music image mapping is to auto generate a group of suitable images
for any given song  possibly replacing the abstract color animations in media players and manual
compilations in youtube videos 

references
    chen  p   liu  s   an improved dag svm for multi class classification http   
ieeexplore ieee org stamp stamp jsp arnumber         
    marsyas  data sets http   marsysas info download data  sets 
    mandel  m   ellis  d   song level features and svms for music classification http   
www ee columbia edu dpwe pubs ismir   svm pdf 
    li  t   chan  a   chun  a   automatic musical pattern feature extraction using convolutional neural network  imecs       http   www iaeng org publication 
imecs     imecs      pp        pdf 
    fu  a   lu  g   ting  k m   zhang  d   a survey of audio based music classification and annotation ieee transactions on multimedia  http   ieeexplore ieee org stamp 
stamp jsp tp  arnumber         tag   
    cakir  s   cetin  a  e   mel  and mellin cepstral feature extraction algorithms for face
recognition the computer journal        http   comjnl oxfordjournals org 
content           full pdf 

 

fi