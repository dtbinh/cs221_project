identifying optical trap
yulwon cho  yuxin zheng
          

   background and
motivation
optical trapping  also called optical tweezer  is
widely used in studying a variety of biological
systems in recent years  in optical trapping a
focused laser beam provides an attractive or
repulsive force  typically on the order of piconewtons   depending on the refractive index
mismatch to physically hold and move microscopic
dielectric objects  a free microscopic particle in
fluid is doing brownian motion all the time while
the trapped particle has significantly lower
brownian motion and stay confined in the trap 
when the trap region is big and the trapping
strength is not strong multiple particles will
aggregate around the trap 
the goal of this project is to identify and locate
the optical trap based on the video clips of the
fluorescent particle doing brownian motion in
various fluidic environments with the possible
presence of other aggregation mechanisms such as
convection and thermophoresis  besides  the
particles are of different sizes  resulting in fast or
slow brownian motions  moreover  the particle
may stop moving by simply adsorbing to the
substrate  all of the above effects results in
patterns similar to optical trapping in some aspects
but not exactly the same and therefore can be
distinguished using appropriate machine learning
algorithms 
the data set collection is done by recording the
optical trapping experiments performed in our lab 
two distinct models are attempted in terms of data
processing and feature set design  the first one is

based on the tracking of individual particle motion 
the second approach is based on the principle
component analysis of the temporal correlation
map of each video  the algorithms we use are
bayesian logistic regression and svm  then we
compare the two in terms of accuracy and
computational efficiency  finally we combine some
of the features from the two models and achieve a
test accuracy
of       

fig    illustration of optical trapping  red cones are
focused laser light and blue spheres are trapped beads 

   data set gathering
we have made    video clips of from the
experiments in which half of them have optical trap 
the polystyrene particles are suspended in pure
water in various concentrations and their
diameters range from    nm to  um  each video is
recorded in ntsc format      frames   sec  for  
seconds and the frame size is    x     here are
some snapshots of the videos 
as can be seen from figure   in the next page  it
is not possible to identify optical trap based on a
single frame of the video  it is necessary to know
the motion of the particle  besides  the other nontrapping aggregation effects and various fluid
conditions make identification much more
challenging 

fitrapping cases 
 a 

 b 

design  this is an example plot of the trajectory of a
trapped particle 

 c 

fig    example trajectory of a trapped particle 
fig    trapping cases   a  trapping of multiple particles   b 
weak trapping   c  trapping of single particle

       feature exploration

no trapping cases 
 a 

 b 

basic feature set
we focus on three special particles which are
most likely to be optically trapped      the one with
smallest motion variance      the one with biggest
radius and     the brightest  for each of the three
particles we extract the motion variance  the radius
and the brightness to form   independent features

 c 

x j   j          

extended feature set
fig    non trapping cases   a  pure brownian motion   b  a big
particle at the center   c  heat induced particle aggregation

   algorithm design and
test results

     approach   
 particle motion tracking 
in the first approach  we extract features based on
the particle tracking results  tracking is done via a
free matlab particle tracking program written by
prof  e w  hansen from dartmouth university  since
our focus is on the machine learning algorithm

we added more features such as the square of each
basic feature elements and their product terms  our
initial insight was that nonlinear decision boundary
will be achieved by those extended terms  our
optical trapping examples have complicated
characteristics  for example  the particles that have
too low motion variance could be physically
stationary particles  which is not an optical trap  at
the same time  the particles with high variance could
also be non trap particles  therefore  by adding
square terms  we expected that when the value is
too large  the small and negative coefficient of
square terms will drive the final decision into nontrap  on the other hand  when the value is not large
enough  the coefficient of the  st order term is

fiexpected to be more influential  in addition  our
thermodynamic analysis suggests that the product
of variance  radius  and brightness has physical
implication to identify optical traps 

lastly  after we added the density based feature  x  
and x   are significant  so the training accuracy
increased to     and testing accuracy of     
basic feature set

density based feature set
we also consider the fact that the number of
particles in an optical trap will gradually become
larger as time goes on  actually  this feature turns
out to be effective to differentiate the optical traps
from stationary particles or heat induced
aggregation of particles  specifically  we divide the
whole screen into n by n grid areas  and take the
linear regression of density variance over time  as a
result  we obtain two more features c  and c  as
follows 

x   x 

variance  radius  brightness of the particle with
small motion variance

x   x 

variance  radius  brightness of the particle with
biggest radius

x   x 

variance  radius  brightness of the brightest particle
extended feature set

x    x  

square of basic features

x    x  

product of different basic features
density based feature set

density   x  y  t    c    x  y   t  c    x  y 
 t  frame number    x  y   position  

linear regression coefficients
x    x  
 density   x  time  x   

our close observation also found an interesting fact
that the distribution of

 c    c    for each example

has different but consistent shape  depending on
whether it is an optical trap or non trap including
stationary particles and heat induced aggregation 
thus  we extracted one more feature which is a
principal axis of the distribution 

x  

figure   shows the decision boundary projected on
 x   x   plane  and figure   shows the average test
error rate for each example when all the features are
added 

       feature selection

when we first tried the basic feature
set xi x j  i  j           only three features  x   x   x  are
enough to give the highest test accuracy of    
where x  is the smallest mean square variance of
motion and x   x  are the radius and brightness of
the same particle  respectively  and training
accuracy is      after we added the extended
feature set  one more feature which is the product of
x  and x  is significant  as a result  the training
accuracy becomes        and test accuracy is     

 
 
 
 
radius

totally  we have    feature candidates  then  we
perform logistic regression algorithm on those
features  at the same time  we use cross validation
and forward search technique to find the feature set
that has the highest test accuracy 

the principal axis of the distribution   x    x   

 
  
  
  
  
  

  

  

  

 
minrms

 

 

 

 

fig    data point and decision
boundary projected on  x   x  
feature subspace

fig    test error plot
generated by cross validation

       analysis of this approach
even though we achieved     training accuracy
by adding all these features while excluding useless
features  the test accuracy has been improved by
only a little  therefore  we analyze the original video

fidata that have the highest error rate  wrong labeling
in testing   we find that most of them are cases
where the trapping is weak or particles cluster and
adsorb to the substrate  in the first case the variance
of particle motion is not small enough to be
identified as optical trap  in the latter case  the
individual particle behaves just like it is optically
trapped  however  a close inspection reveals that
those similar cases actually have different spatial
pattern  for example  in weak trapping case  the
particles tend to move along a ring shape path
around the center of the trap  in the adsorption case 
particles adsorb all over the substrate  in short 
optical trapping could be more identifiable if the
spatial pattern is taken into account 

brownian motion suppression in optical trapping
and other aggregation phenomena  large magnitude
in the map indicates that there are particles
hovering around  some examples are shown below 

fig    optical trapping   a  snapshot of the video and  b  its temporal
correlation map

     approach   
 temporal and spatial
correlation 
in our second approach  we try to design features
that convey both temporal information and spatial
information  at the beginning  we simply make the
whole video a long vector which is a super high
dimension feature and feed it to svm  but we always
get      training accuracy and less than     test
accuracy  suggesting high variance in learning  so we
redesign the feature  we calculate for each pixel in
the frame the autocorrelation function 

g  i  j  m    f  i  j  k   f  i  j  k  m 

fig    thermal aggregation  no trap    a  snapshot of the video and
 b  its temporal correlation map

algorithm
firstly  we compute   i 

j   for all pixels  and find

the maximum  as a potential trapping location 
secondly  we take a smaller window    x    around
the selected location  and perform pca  principal
component analysis  to reduce the dimension of
feature  lastly  we feed this feature to svm 

k

result
where

f is pixel value  brightness    i  j  is pixel

position in the frame and m is frame number  then
we obtain the effective width of the autocorrelation
function of time to roughly represent the duration
for which the pixel remains bright 

  i  j   

 g  i  j  m 
m

max g  i  j   m 
m

thus   i 

j   is what we call temporal correlation

map  we have verified that it effectively captures

comparing with our initial svm scheme  the
dimension of the feature is reduced from        
 frame size  to     number of influential principal
components  
training accuracy of both schemes are       but
the test accuracy of the new algorithm using the   
eigen pattern is     whereas the initial svm
schemes gives less than     
if we use the   x   correlation map as a training
vector without performing pca  the test accuracy is
     however  when we choose    principal
components  the high variance problem is partly
fixed  so the final test accuracy becomes     

fia few eigenpatterns are shown below 

fig    examples of eigenpatterns generated by pca

feature set

training
accuracy

test
accuracy

basic feature set

   

   

  extended feature set

      

   

  density based feature set

   

   

  pseudo eigenpattern feature set

   

     

this is expected as the two methods capture
different aspects and are therefore complimentary 

discussion
svm algorithm using these features gives a test
accuracy of      again cross validation technique is
used to obtain reliable test accuracy  while this
method has similar accuracy to the previous one  it
is much faster than the other as it does not involve
tracking all the particles  when tested in our
computer  intel i  core     ghz   gb dram   this
method is roughly    times faster than the previous
method 

     combining of two approaches
finally  we have combined the two approaches by
adding a few more features to the first approaches 
in the second approach  we used    dimension of
vector as a feature for svm  however  instead of
using the full size of vector  we extracted the
following three distinguishing factors 




radius of potential trap regions
maximum 
the number of potential trap regions

after adding these three features  the training and
testing accuracy increased as follows 

   conclusion
we have applied different machine learning
algorithms to identify optical trapping effect in
complex environment where other similar
aggregation mechanisms can occur  one is based on
particle tracking and the other is based on temporal
autocorrelation of each pixel of the video  the two
modeling methods give comparable test accuracy
but the second one is more computationally efficient 
by combining the features of the two methods we
achieve a high accuracy of        last  this project
may be generalized and extended to identify various
physical  chemical or biological processes in more
complicated systems  which may be of more interest
in terms of applications 

fi