predicting movie revenue from imdb data
steven yoo  robert kanter  david cummings
ta  andrew maas

   introduction
given the information known about a movie in the week of its release  can we predict the total gross
revenue for that movie  such information would be useful to marketers  theater operators  and others in the
movie industry  but it is a hard problem  even for human beings  we found that  given a set of numeric  textbased  and sentiment features from imdb  linear regression outperforms class based logistic regression at
predicting gross revenue  however  neither gives sufficiently precise results to be used in practice 

   data and features
we collected data from imdb for      movies that were released from      to       among these movies 
we only selected the ones that were released in united states and are in english  in the anticipation that we
would be able to make more accurate predictions on these movies given that their reviews would also be in
english 
the features we used are listed in table   with examples  they are separated into three main sets of features 
simple  complex  and sentiment  simple is numeric only  complex is numeric and text based  and
sentiment includes all   sentiment scores are computed using the subjectivity lexicon obtained from the
university of pittsburgh opinionfinder project        to generate a sentiment score for a movie  we simply
take the sum of all sentiment scores for all words in the first weeks worth of reviews for that movie  some
examples of this lexicon are listed in table   with their score 
feature categories
numeric features

text based features

sentiment feature

features
days since january        
days since january   of that year
duration  minutes 
budget    usd 
aspect ratio  x   
average rating
user votes count
user review count
critic review count
mpaa rating
directors
plot keywords
cast
genres
sentiment score
table    features and examples

examples
      
   
  
         
   
   
      
   
  
g  pg  pg     r  unrated unknown
woody allen  steven spielberg
love  murder  friend  police  etc
samuel l  jackson 
robin williams  etc
comedy  romance  thriller  etc 
        

sentiment
sentiment score examples
polarity
  
beautiful
strong positive
  
trendy
weak positive
 
finally
neutral
  
dwindling
weak negative
  
awful
strong negative
table    sentiment scores and examples

fiin our experiments  we found
und that the budget is the strongest individual indicator of a movies eventual
gross revenue  the x y
y scatter graph of budget and revenue is shown in figure    we found their correlation
to be         accordingly  we used this correlation as our baseline result  all reasonable models should be able
to achieve at least a correlation of        

figure    correlation of budget with actual revenue

   model    linear regression
in our first model  we used a standard least squares
least squares linear regression  to do this  we used stochastic
gradient descent  which we implemented in c for efficiency  once we had trained a set of feature weights  we
could then generate gross revenue predictions
prediction as follows 
gross           f        f          n   fn
where i are the weights  fi are the features  and n is the number of features
to measure the goodness of our results  we looked at the correlation between our predicted revenue
values and the actual revenue values  as was done in other papers        as alternative measures to interpret
our results  we also considered other metrics such as mean absolute percentage error  mape  and symmetric
mean absolute percentage error  smape  
mape is not
ot the best metric for our work because the error is unbounded unbounded for instance  if we predict
revenue of            for a movie that grossed           then error would be       skewing any average we
would take over all test examples  in compensation to this 
this  we also tried smape  which returns error values
from   to       however  neither metric gave consistent  explainable results  and to our best knowledge there
are no other papers using these metrics for the same task  so we could not compare the results to others with
them 
below are the correlation results we found for each of our feature sets  using     of our data in training
and     in test 

test data set
training data set

simple features
complex features
       correlation
       correlation
       correlation
       correlation
table    correlation results

sentiment features
      correlation
      
       correlation

fiwe were only able to achieve a correlation of        on the test data set  while this is better than the
baseline result  i e           we do not consider it high enough
enough to be useful in practice  figure   shows this
result  comparing our predictions to the true gross revenues  additionally  these results also show that our
larger feature sets generally improved performance relative to the smaller feature sets 

figure   
  correlation of predicted with actual revenue
while we observed an increase in correlation with the addition of text based
text based features in the complex
feature set  the addition of sentiment scores did not significantly affect the correlation on the test
te or training
data  two factors can explain this  first  sentiment about a movie is already partially captured by the rating
feature  second  the gross for a movie is more directly related to the number of people who watch the movie
rather than how good people think the movie actually is  in fact  we saw that features such as the number of
user votes on a movies rating are actually more important than the average rating itself  for example 
transformers has a low rating  and bad reviews   but the actual
actual gross is high because many people watched
it 
in an attempt to counteract over fitting 
fitting  we terminate our stochastic gradient descent early  having noted at
the cross validation
validation stage that      iterations gave better results on test correlation than waiting
wai
until full
convergence 

   model    classification by logistic regression
as a second model  we also tried classification by standard l  regularized
l  regularized logistic regression  we chose
this method because it generated a multi class
multi class model with linear weights  most directly comparable to the
feature weights given by linear regression  to
to define our classes  we drew a histogram of movie revenues to
create   different buckets for prediction as shown in table     the first bucket includes the lowest     of the
gross distribution and the last bucket includes the highest     
buckets  classes 

bucket  

bucket  

bucket  

bucket  

bucket  

gross ranges   

  to    m

    to     m
   m

    m to     m

    m to     m
    

    m

table    bucket ranges for gross classification
the procedure for using logistic regression was fairly similar to that of linear regression  the difference
being that we now use labeled buckets as our y values
y
 instead of real valued
alued gross revenue numbers  and
pass the data to liblinear to build the model for classification  this model gave the following accuracy results
on our     test set 

test data set

simple features
complex features
      
      
table    accuracy
a
results on test data set

sentiment features
   
      

in general  none of these accuracy figures were as high as we had hoped  indicating that this kind of
classification was not the right approach to the problem 

fi   comparing performance
having developed these two different models  linear regression and classification by logistic regression  
we needed some way of comparing their results  for this project  we implemented two such methods 
in the first method  we map the results from linear regression into the five bucket classes from logistic
regression 
ion  to do this  we take the real valued
real valued outputs from our linear regression model  assign labels to them
according to the buckets into which they fall  and check whether these correspond to the same buckets as
those of the actual gross revenue  for this measure 
measure  we generated the following results on our different feature
sets 

test data set

simple features
complex features
      
      
table    mapped accuracy on test data set

sentiment features
 
      

these numbers decrease with additional features  likely because of increased variance
variance  that is  some overover
fitting on the training set   further discussion of this in the following section   however  all are roughly
comparable to the       
    accuracy achieved by logistic regression on the classification problem  showing
that linear regression
ession is almost as good at the task of classification as logistic regression  the algorithm
dedicated to classification 
in the second method  instead of mapping from real values to buckets  we map from our five buckets to real
values  to do this  we first
st find the average actual revenue of movies classified into each bucket in logistic
regression  then  instead of generating class labels from logistic regression  we can use the corresponding
averages instead  giving us real valued
valued output from the classifier 
classifier  the resulting correlation scores are shown
below 

test data set

simple features
complex features
       correlation
       correlation
table    mapped
m
correlation on test data set

sentiment features
       correlation

none of these approach the      range of correlation seen with linear regression  much less the     
baseline correlation using a movies budget alone  much of this has to do with the fact that logistic regression
can only generate one of five distinct values 
values  so we thought we might experiment with different numbers of
buckets  our expectation was that accuracy would consistently decrease as number of buckets increased  but
that correlation would have some optimal point where the  positive  granularity of having
h
smaller ranged
buckets balanced with the  negative  trend toward fewer training examples per bucket  we were surprised to
find that while accuracy decreased  correlation remained
remaine fairly constant  as shown in figure
f
  

ccuracy and correlation using different numbers of buckets
figure    accuracy

fiit appears that  in terms of the correlation measure  having fewer training examples per bucket was evenly
offset by the greater granularity of having smaller ranged buckets 

   conclusions
we framed this problem as both a regression and classification problem because we were not sure which
would provide a better result  as such  we implemented both and devised methods to compare them  in general 
we found that linear regression works almost as well as logistic regression for classification on our data  while
having a much better correlation with the actual gross revenues 
in general  we found that the features we used  simple numeric  text  and sentiment features  were
insufficient to make strong predictions of gross revenue  others have had greater success using additional
features such as number of theaters  marketing budget  etc   but since imdb does not contain such data  we
were unable to include them  for future work  besides using different feature sets  we might consider using
better regularization on linear regression in order to provide a more rigorous safeguard against high variance
models  as we consistently observed decreases in linear regressions test accuracy with increasing numbers of
features 
another  fundamentally different  data set that might be useful in predicting movie revenue would be social
graph data  using such data  we could analyze the characteristics of how a movies popularity propagates
through social networks  as well as characteristics of the propagation tree  such as its speed and extent over
time  the propagation speed of a movie would represent peoples expectation to see that movie  which we
expect will be directly related to its gross revenue 

   epilogue
for fun  we looked at our feature weights for text based features  and from them extracted the highest  and
lowest weighted features in mpaa rating  director  plot keywords  cast  and genre  for a guaranteed hit film 
we recommend a g rated animated family adventure about escape  prince  and vampire  directed by
steven spielberg and starring bill paxton and tom cruise  for a guaranteed flop  we recommend an r rated
mystery sci fi musical about vietnam  computer  and train  directed by stephen king and starring
giovanni ribisi and robin wright 

references
    m  joshi  d  das  k  gimpel  and n  a  smith  movie reviews and revenues  an experiment in text
regression  in proceedings of naacl hlt       
    w  zhang and s  skiena  improving movie gross prediction through news analysis  web intelligence and
intelligent agent technology  ieee wic acm international conference on                 
this paper use amape  adjusted mean absolute percentage relative error  for their measurement
    simonoff  jeffrey s    ilana r  sparrow  predicting movie grosses  winners and losers  blockbusters
and sleepers  chance magazine                     
    brendan oconnor  et al  from tweets to polls  linking text sentiment to public opinion time series 
proceedings of the international aaai conference on weblogs and social media      
    leonid velikovic  et al  the viability of webderived polarity lexicons  naacl       

fi