news recommendation system using logistic
regression and naive bayes classifiers
chi wai lau
december         

abstract
to offer a more personalized experience  we implemented a news recommendation
system using various machine learning techniques  we learned that logistic
regression worked a lot better than naive bayes  also surprisingly  for both
algorithms  more training data did not necessarily lead to better results  however 
the performance became better as the ratio of positive training samples increased 

introduction
most readers go through different
headlines just to identify the stories
that are truly interesting to them  if the
readers were getting their news from
online sources  we could easily follow
their reading patterns and thus offer a
much more personalized experience by
suggesting engaging news stories using
machine learning techniques 
given a reader and a story  our news
recommendation system would predict
the interest level of the reader towards
the story  to acquire a real world
training and testing dataset for our
system  we are in collaboration with
pulse  a local startup that offers a news
reading application for mobile devices 
we were given   sets of data captured

from      random users throughout
august      
 stories  all news stories that were
available
 impressions  stories that a user
accessed the summary
 click throughs  stories that a user
accessed the full article
to access the full article of a story  the
readers are required to perform   clicks
on the application  one for selecting a
story to view its summary and another
for accessing the full article  due to the
dual manual filtering  we believe
accessing the full article is a strong
indicator that the story is truly
interesting to the reader  based on that
assumption  we labelled clickthroughs as the positive samples and
impressions as the negative samples 

fiour samples would be represented via
a feature vector based on a dictionary
of words  to build that dictionary  we
extracted all alphanumeric title strings
from stories as our text corpus 
to evaluate the performance of our
algorithms  we ran tests using k fold
cross validation  due to the large
amount of data  we were only using  
folds  for each run  we computed
measurements such as accuracy 
precision  recall  and f score  the
better algorithm would have a larger
measurement values 

algorithms
naive bayes
the first algorithm we tried was naive
bayes because it has been used for text
categorization such as spam mail
filtering and it could take each readers
individual preferences for specific
features into account  moreover  it is
efficient and capable of scaling to
millions of readers 
we implemented a naive bayes
classifier based on the multivariate
bernoulli event model  we used only
the story titles and represented them
via a feature vector using the
dictionary generated from our corpus 
table   shows that the classifier had a

table    results for logistic regression and naive bayes
classifiers on unstemmed story titles

fairly good accuracy and very high
precision  but the recall and f score
were near zero  the classifier was not
good at recognizing interesting stories
and categorized almost everything as
uninteresting 
we implemented another naive bayes
classifier based on the multinomial
event model  the classifier ran much
faster because the algorithm takes o n 
time  where n is only the number of
words in the story title  as opposed to
the length of the feature vector   the
classifier did twice as good in recall
and f score  but it is still not good
enough for production use 
logistic regression
using the same feature vector  we then
tried to fit our training data with
logistic regression  which is also
widely used for text classification  we
trained our parameters using gradient

fidescent and the training time generally
took longer than the naive bayes
classifiers  the result classifier had a
lower precision due to the increased
number of false positives  but it had a
much better recall and f score 
tf idf
tf idf is a weight often used to
measure how important a word is to a
document in a corpus  the importance
increases proportionally to the number
of times a word appears in the
document but is offset by the frequency
of the word in the corpus      we precomputed the document frequency  i e 
idf  of each word from our corpus  for
each training story  we computed the
tf idf for each word in the title and
then use it as a local weight in logistic
regression to train our parameters  the

weighted classifier produced a slightly
better overall results  i e  lower
accuracy  constant precision  higher
recall and f score  
porter stemming
the feature vector we used above had a
length of        in an effort to make
our system run more efficiently  we ran
our text through the porter stemming
algorithm     to reduce the vector
length down to        stemming
seems to have a positive performance
impact on our classifiers  see figure    

conclusion
from our experiments  we learned that
the naive bayes classifiers did not
perform as well as the logistic
regression classifiers  as figure  

figure    impact of stemming

fifigure    f score vs the number of training samples

clearly shows  the f score of the naive
bayes classifiers with the multivariate
bernoulli event model remained near  
regardless how many training samples
it was given  it indicates that the model
is not very good at learning from our
data and thus is likely not the right fit
for our application  for the other
classifiers  the number of training
samples seemed to cause the f score to
vary  but opposite to the common
wisdom  we notice that more training
samples did not necessarily lead to
better results and we do not observe
any consistent patterns between f score
and the number of training data 
interestingly  if we plot f score against
the ratio of positive training samples 

we notice that f score did get better as
the ratio of positive training samples
increased  see figure     the pattern
tells us that the classifiers were biased
towards the negative samples because
they were more dominant in the
training dataset  to improve the
performance of our classifiers  we may
have to balance the distribution of
positive and negative samples 
in summary  logistic regression yielded
better results and the tf idf weights
offered a slight performance boost 
stemming seemed to be quite effective 
not only does it significantly reduce the
vector length for a better run time  it
also has a positive performance impact
on our classifiers 

fifigure    f score vs the ratio of positive training samples

references
   i 
paik
and
h 
mizugai 
 recommendation
system
usingweighted tf idf and naive
bayes
classifiers
on
rss
contents   journal of advanced
computational intelligence and
intelligent informatics  vol     no 
        
   m  f  porter  an algorithm for suffix
stripping  readings in information
retrieval 
morgan
kaufmann
publishers inc   san francisco  ca 
     

fi