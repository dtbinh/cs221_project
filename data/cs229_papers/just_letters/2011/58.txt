object classification and localization using surf descriptors
drew schmitt  nicholas mccoy
december         
this paper presents a method for identifying and matching objects within an image scene  recognition of this
type is becoming a promising field within computer vision
with applications in robotics  photography  and security 
this technique works by extracting salient features  and
matching these to a database of pre extracted features to
perform a classification  localization of the classified object is performed using a hierarchical pyramid structure 
the proposed method performs with high accuracy on the
caltech     image database  and shows potential to perform as well as other leading methods 

 

mapped to its visual word equivalent by finding the nearest cluster centroid in the dictionary  an ensuing count of
words for each image is passed into a learning algorithm
to classify the image 
a hierarchical pyramid scheme is incorporated into this
structure to allow for localization of classifications within
the image 
in section    the local robust feature extractor used
in this paper is further discussed  section   elaborates
on the k means clustering technique  the learning algorithm framework is detailed in section    a hierarchical
pyramid scheme is presented in section    experimental
results and closing remarks are provided in section   

introduction

 

there are numerous applications for object recognition
and classification in images  the leading uses of object
classification are in the fields of robotics  photography 
and security  robots commonly take advantage of object
classification and localization in order to recognize certain
objects within a scene  photography and security both
stand to benefit from advancements in facial recognition
techniques  a subset of object recognition 
our method first obtains salient features from an input
image using a robust local feature extractor  the leading
techniques for such a purpose include the scale invariant feature transform  sift  and speeded up robust
features  surf  
after extracting all keypoints and descriptors from the
set of training images  our method clusters these descriptors into n centroids  this operation is performed using
the standard k means unsupervised learning algorithm 
the key assumption in this paper is that the extracted
descriptors are independent and hence can be treated as a
bag of words  bow  in the image  this bow nomenclature is derived from text classification algorithms in
classical machine learning 
for a query image  descriptors are extracted using the
same robust local feature extractor  each descriptor is

surf

our method extracts salient features and descriptors from
images using surf  this extractor is preferred over sift
due to its concise descriptor length  whereas the standard sift implementation uses a descriptor consisting of
    floating point values  surf condenses this descriptor
length to    floating point values 
modern feature extractors select prominent features by
first searching for pixels that demonstrate rapid changes
in intensity values in both the horizontal and vertical directions  such pixels yield high harris corner detection
scores and are referred to as keypoints  keypoints are
searched for over a subspace of  x  y     r    the variable  represents the gaussian scale space at which the
keypoint exists  in surf  a descriptor vector of length
   is constructed using a histogram of gradient orientations in the local neighborhood around each keypoint 
figure   shows the manner in which a surf descriptor
vector is constructed  david lowe provides the inclined
reader with further information on local robust feature
extractors     
the implementation of surf used in this paper is provided by the library opensurf      opensurf is an
 

fiwords  experimental methods verify the computational
efficiency of k means as opposed to em  our specific application necessitates rapid training and image classification  which precludes the use of the slower em algorithm 

 

learning algorithms

naive bayes and support vector machine  svm  supervised learning algorithms are investigated in this paper 
the learning algorithms are used to classify an image
using the histogram vector constructed in the k means
step 

   

figure    demonstration of how surf feature vector is
built from image gradients 

naive bayes

a naive bayes classifier is applied to this bow approach
to obtain a baseline classification system  the probability
open source  matlab optimized keypoint and descrip  y c that an image fits into a classification c is given by
tor extractor 
m
  x
  y  i    c  
   
y c  
m i  

 

k means

additionally  the probability k y c   that a certain cluster
centroid  k  will contain a word count  xk   given that it
a key development in image classification using keypoints is in classification c  is defined to be
and descriptors is to represent these descriptors using a
m

p
bow model  although spatial and geometric relation i 
  y  i    c xk    
ship information between descriptors is lost using this as
k y c   i  
 
   
sumption  the inherent simplification gains make it highly
m
p
 i    c n
  y
 
n
i
advantageous 
i  
the descriptors extracted from the training images are
grouped into n clusters of visual words using k means  laplacian smoothing accounts for the null probabilities
a descriptor is categorized into its cluster centroid using of words not yet encountered  using equation   with
a euclidean distance metric  for our purposes  we choose equation    the classification of a query image is given
a value of n        this parameter provides our model by
 
with a balance between high bias  underfitting  and high
n
y
variance  overfitting  
arg max y c
i y c  
   
c
for a query image  each extracted descriptor is mapped
i  
into its nearest cluster centroid  a histogram of counts is
constructed by incrementing a cluster centroids number     svm
of occupants each time a descriptor is placed into it  the
result is that each image is represented by a histrogram a natural extension to this baseline framework is to invector of length n   it is necessary to normalize each his  troduce an svm to classify the image based on its bow 
togram by its l  norm to make this procedure invariant our investigation starts by considering an svm with a
to the number of descriptors used  applying laplacian linear kernel
smoothing to the histogram appears to improve classifik x  y    xt y   c 
   
cation results 
k means clustering is selected over expectation max  due to its simplicity and computational efficiency in trainimization  em  to group the descriptors into n visual ing and classification  an intrinsic flaw of linear kernels
 

fiis that they are unable to capture subtle correlations between separate words in the visual dictionary of length
n 
to improve on the linear kernels performance  nonlinear kernels are considered in spite of their increased
complexity and computation time  more specifically the
  kernel given by
k x  y        

n
x
 xi  yi   
i  

xi   yi

 

   

is implemented 
given that an svm is a binary classifier  and it is often
desirable to classify an image into more than two distinct
groups  multiple svms must be used in conjunction to
produce a multiclass classification 
a one vs one scheme can be used in which a different
svm is trained for each combination of individual classes 
an incoming image must be classified using each of these
different svms  the resulting classification of the image
is the class that tallies the most
wins  the one vs one

scheme involves making n  different classifications for
n classes  which grows factorially with the number of
classes  this scheme also suffers from false positives if
an image is queried that does not belong to any of the
classes 
a more robust scheme is the one vs all classification
system in which an svm is trained to classify an image
as either belonging to class c  or belonging to class c  for
m
the training data   xi   yi   i     yi          n   a multiclass
svm aims to train n separate svms that optimize the
dual optimization problem

max w     
a

m
x

i 

i  

figure    portrayal of one vs all svm  when query image
is of type a  the a vs all svm will correctly classify it 
when the query image is not of class a  b  or c  it will
likely not be classified into any 
the image correctly  and thus the overall output will place
the image into class a  when the query image is of a
different class  d  which is not already existent in the
class structure  the query will always fall into the all
class on the individual svms  hence  the query will not
be falsely categorized into any class 
it is important to reiterate that each multiclass svm
only distinguishes between classes c and c  a different svm is trained in this manner for each class  thus 
the number of svms needed in a one vs all scheme only
grows linearly with the number of classes  n   this system
also does not suffer from as many false positives because
images that do not belong to any of the classes are usually
classified as such in each individual svm 
the specific multiclass svm implementation used in
this paper was matlabs built in version as described
by kecman     

m
  x  i   j 
y y i j k x i    x j    
  i j  

   
using john platts smo algorithm      in equation   
k x  z  corresponds to one of the kernel functions discussed above 
a query image is then classified using
 m
 
x
 i 
 i 
sgn
i y k x   z   
   

 

object localization

the methods described thus far are sufficient for the role
of classifying an image into a class when an object is
where sgn x  is an operator that returns the sign of its prominently displayed in the forefront of the image  howargument and z is the query vector of bow counts 
ever  in the case when the desired object is a small subset
figure   represents this concept visually  when the of the overall image  this object classification algorithm
query image is of class a  the a vs all svm will classify will fail to classify it correctly  additionally  there is moi  

 

fifigure    results showing both image classification and
localization 

figure    visual representation of partitioning an image
into sub images and constructing the histograms 
tivation to localize an object in a scene using classification
techniques  the solution to these shortcomings is object
localization using a hierarchical pyramid scheme  figure
  illustrates the general idea behind extracting descriptors using a pyramid scheme 
first  the set of image descriptors  d  are extracted
from the image using surf  next  the image is segmented into l pyramid levels  where l is a user selected
parameter that controls the granularity of the localization search  each level l  has subsections    i    l    
where    l   l      at each level l  the entire set
of image descriptors  d  are segmented into a subgroup
d  d for section i which can be found as

the resulting effect is that pixel p is most highly influenced by the label of its lowest level containing subsection  in l    l      and less influenced by the label of its
highest level containing subsection  in l      the resulting label given to pixel p can then be calculated as
labelpix  p    arg max votemap c  
c

 

    

results and future work

figure   shows the classification and localization results
of our proposed algorithm on a generic image consisting
of multiple classes of objects 
 
 
  
a more rigorous test of our method was done using
p col   
p row   
l
a
subset
of the caltech     database      images falling
i   idiv
  idiv
          
c
r
l
l
into
the
four
categories of airplanes  cars  motorbikes  and
 
 
faces were trained and tested using our method  figure  
for a given pixel p  the notation idiv x  represents an shows the improvement in percent correct classifications
integer division operator  the symbols r and c are the in classification of naive bayes  linear svm  and nonlinmaximum number of rows and columns  respectively  in ear svm as the training set size increases 
the original image  then  for pixel p the votes at each
the f  score  computed using the precision  p   and relevel of the pyramid can be tallied into an n x  map com  call  r  of the algorithm by
puted using
 p r
f 
 
    
p  r
l 
x
votemap c   
 l    labelpyr  l  i    c  
    is perhaps a better indicator of performance because it
is a statistical measure of a tests accuracy  figure  
l  
 

fipercent correct vs  training set size

f score vs  training set size

  

 
naive bayes
linear svm
non linear svm
    

f score

percent correct

  

  

  

   

    
naive bayes
linear svm
non linear svm

  

   

   
   
training set size

   

   

figure    percent correct classifications of supervised
learning classifiers 

   

   
   
training set size

   

figure    f  score of classifications of supervised learning
classifiers 

shows a visible improvement in the f  score for all three
classification algorithms as the training set size increases 
the nonlinear svm maintains the largest f  score over
all training set sizes  which aligns with our hypothesized
result 
future work for this research should focus on replacing
k means with a more robust clustering algorithm  one
option is linearly localized codes  llc       the llc
method performs sparse coding on extracted descriptors
to make soft assignments that are more robust to local
spatial translations      furthermore  there is still openended work to be done on the reconstruction of objects
using the individually labeled pixels from the pyramid localization scheme  hrytsyk and vlakh present a method
of conglomerating pixels into their neighboring groups in
an optimal fashion     

opensurf html  retrieved            
    j  platt  sequential minimal optimization  a fast
algorithm for training support vector machines 
     
    v  kecman  learning and soft computing  mit
press  cambridge  ma       
    l  fei fei  r  fergus and p  perona  learning generative visual models from few training examples  cvpr 
     
    j  yang  k  yu  y  gong  and t  huang  linear spatial pyramid matching using sparse coding for image
classification  cvpr       
    t  serre  l  wolf  and t poggio  object recognition
with features inspired by visual cortex  cvpr       

references

    n  hrytsyk  v  vlakh  method of conglomerates
recognition and their separation into parts  methods
    d  lowe  towards a computational model for object
and instruments of ai       
recognition in it cortex  proc  biologically motivated
computer vision  pages            
    c  evans  opensurf 
http   www chrisevansdev com computer vision 

fi