a learned approach for lump identification
in soft tissue via palpation
kirk a  nichols
department of mechanical engineering  stanford university
kirk nichols stanford edu

abstract
with the increase in robot assisted minimally invasive surgeries 
restoring haptic information lost by the lack of the surgeons
direct contact with the patient is crucial  here i seek to restore lost
stiffness information by gathering force and position data taken
from a robot palpating an artificial tissue embedded with a stiff
object simulating a circular tumor  using machine learning
algorithms  i estimate the location and radius of the tumor  results
show that of the learning methods explored  the supervised
learning methods perform better than their unsupervised
counterparts  with an average error of false positives plus false
negatives of      however  the most robust method of these uses
a supervised learning algorithm to first threshold the palpation
data based on stiffness and then estimating the radius of the tumor
using a second machine learning algorithm  i intend to continue
and expand this work in the charm lab  pi allison okamura 
 

introduction

in the medical community  tactile sensations provide an array of
diagnostic capabilities  cancerous regions in soft tissues like in
the prostate and breast tissues  for example  typically manifest
themselves as hard lumps and are significantly harder than the
surrounding tissue  during open surgery  surgeons can directly
contact and palpate the tissue  minimally invasive surgery  mis 
and robot assisted minimally invasive surgery  rmis  are
becoming increasingly popular as they provide increased dexterity
and control for surgeons while reducing patient trauma     
however  the lack of tactile feedback limits surgeons capabilities 
and it has been shown that rmis presents with a greater
likelihood of leaving behind cancerous cells upon biopsy of a
diseased region      finding some method to convey the shape
and location of a suspected lump would restore some of the
information lost with the use of minimally invasive surgical
methods 
i investigated use of a robotic system with an attached forcetorque sensor to provide a data set from which machine learning
tools can identify the size and location of a lump in an artificial
tissue sample  section   describes the experimental setup used 
including the hardware and software methods used to gather data 
section   describes the experimental methods used  and
introduces five learning methods tasked with identifying the shape
and size of the lump in the artificial tissue  results are presented
in section   and discussed in section    future work and
conclusions drawn from the experiment comprise of sections  
and    respectively 
 

figure    experimental setup showing the phantom
premium  the nano    force torque sensor  and the
artificial tissue 

   
hardware
the hardware used for this project are a phantom premium    a
 sensable technologies  inc   haptic device and a nano    forcetorque sensor  ati industrial automation   the phantom
premium in its current configuration is a   dof desktop haptic
device  figure     the nano    force torque sensor measures
forces and torques along all three axes  however  for the purpose
of this project only the force along the z axis of the sensor
 pointing into the end effector of the phantom premium as
pictured in figure    was gathered 
   

artificial tissue

experimental setup

the setup of the experiment involved creating a platform where
upon palpating an artificial tissue  information regarding the
stiffness of the palpation location as well as the location itself can
be gathered 

figure    close up of
force torque sensor with
uncovered artificial tissue

figure    force torque sensor with
covered artificial tissue
 

fifigure    a typical force vs position curve collected from a single
palpation 
the artificial tissue sample consisted of a sponge with a hard 
circular object embedded inside  figure     circular objects are
commonly used to approximate tumors      this sample was
covered with a thin piece of packaging material to add more
variance between the stiffnesses of the embedded object and
surrounding sponge  figure    
   
data collection
the data sets were gathered by manually palpating the artificial
tissue with the robot arm  the robots encoders were used to
gather data about the position of the end effector  figures   and  
show the different sets of data varied with respect to the rotation
of the artificial tissue 
   
tumor registration
for a ground truth measurement of the location and size of the
tumor  the tumor shape was traced by the end effector of the robot
and subsequently registered  points within the registered shape
would be classified as part of tumor and points outside the
registered region would be classified as not part of the tumor 
 

experimental m ethods

five different methods were employed to predict the shape of the
tumor  the first three of these methods fall under supervised
learning  while the last two are unsupervised  although the fifth
method does utilize the notion of a training set  the labeling for
this set is constructed in an entirely unsupervised fashion 
for all the methods  an initialization step was first performed to
convert the force position data for each individual palpation into a
stiffness value that would associate with an xy location on the
sponge 
   

initialization

figure    training set used for all algorithms  stiffer points are
shown in red  while softer points are in blue  the black circle is
the trace of the circumference of the tumor taken during
registration 
for each palpation  the force position data acquired from the
nano   was fitted by least squares to a straight line  with the
assumption that the palpated environment can be well
approximated by a linear spring  this model was chosen for its
simplicity and it appears to capture the features of the resulting
force vs position plot well  figure     the slope of the line is the
stiffness value used for that individual palpation 
   
learning algorithms
driving the learning behind the various learning methods
described in this section are three different learning algorithms 
logistic regression  lr   gaussian discriminate analysis
 gda   and a support vector machine  svm   the convex
optimizer used to solve the svm with regularization equations is
a matlab toolkit developed by michael grant and stephen
boyd called cvx      the svm regularization weighting
parameter c was tuned by hand 
   
supervised learning training set
the training set used for all the learning algorithms is pictured in
figure    the data in this set was found to have the least training
set error among all the data sets acquired  note that in figure    a
data point is stiffer if its color is more towards the red color
spectrum of the scale  while softer points are depicted towards the
blue color spectrum  the three test sets are seen in figure   
   

stiffness learning followed by radius of tumor
learning
the first method used the training set to develop a threshold for
labeling a point as in the tumorous region or not in the tumorous
region based on the observed stiffness value  the resulting
threshold would take a data point in the test set and conclude that

 
 a 
 b 
 c 
figure    test sets used  note  the black circle  depicting the shape of the tumor  is what we seek to estimate  however theyre drawn here for
convenience  note that none of these sets share the same orientation 

fifigure    example of   dimensional threshold fitting  the
threshold is the black line  for the test sets  all datapoints right of
this line would be labeled as tumorous and all points to the left as
non tumorous 
if its stiffness was greater than the threshold  it would be classified
as belonging to the tumor  otherwise  the point would be
classified as not belonging to the tumor  see figure   for an
example of this   dimensional thresholding 
the threshold was learned using the three different learning
algorithms covered in section      logistic regression  gaussian
discriminate analysis  and a support vector machine  once the
palpation data was labeled given the learned stiffness threshold 
the supposed center of the tumor was calculated as a mean of all
the points classified as a tumor  this concluded the first learning
portion of the first method and estimated the center of the tumor 
however another learning iteration was performed to determine
the size of the tumor 
towards this end  the palpation data was then concatenated with
a new feature  the distance of the palpation point to the supposed
center of the tumor  the same three learning algorithms were
again utilized to threshold the likely radius of the tumor given our
 relabeled  dataset  the data would again be labeled according to
this new threshold 
     
labeling the test set
when implementing this first method on a test set  the stiffness
threshold would be used against the test data to provide an initial
labeling of the data points  the mean of the data points classified
as a tumor served to estimate the center of the tumor  after this
initial labeling  lr  gda  and svms were trained to learn the
most likely radius of the tumor  and the points were then relabeled
according to this threshold  in this method  the stiffness threshold
was learned from the training set  while the distance from center
of tumor threshold was learned and applied on the test data itself 
   

weighted clusters followed by radius of tumor
learning
the second method first estimated the center of the centroid
according to the weighted centroid calculation in equation   

 equation   
the parameters        seen in equation   were tuned by hand
and found to give acceptable performance on the training set
exhibited by the estimated tumor center being within  mm of the
actual center of the tumor 
once the center of the centroid was calculated  the palpation
data was concatenated with the distance of each palpation from

figure    example of a   dimensional threshold fitting  the
threshold is the blue line  which the support vector margins are
in green and red 
the supposed center of the tumor in the same way as in the method
detailed in section      this concatenated data and the labeling
provided by the training set were used to create a threshold using
lr  gda  and a svm  this threshold estimates the radius of the
tumor 
it is important to know that because this threshold is constructed
form the training set  it can only predict tumors of the same size as
the training set 
     
labeling the test set
the estimated center of the tumor was first calculated by equation
  then  each palpations data was concatenated with its distance
from the estimated center  finally  the points were labeled
according to the thresholds developed in training 
   

weighted clusters followed by radius of tumor
vs  stiffness learning
this method estimated the center of the tumor using the weighted
centroid calculation in equation    after the center was calculated
and the palpation data was concatenated with the distance from
the estimated center of the tumor  a   dimsional plot was created
using the data  with one axis being the distance from the estimated
center of the tumor  and the other axis being the approximate
stiffness observed from the palpation  lr  gda  and a svm were
again utilized to develop thresholds in this   d space  figure  
shows the threshold for the training set generated by the svm 
     
labeling the test set
the weighted centroid center location was first calculated for the
test set  followed by classifying the points based on the thresholds
derived in the training phase 
   
k means clustering
shifting away from supervised learning algorithms  this next
method of classification first calculated the weighted centroid
center location using equation    and generated the same  dimensional plot used in section      this method would then
implement k means clustering  labeling two clusters to segment
the data  the two clusters would classify points as tumor and
not tumor 

 

fifigure    results from a single trial of the method detailed in
section     using a svm for thresholding  the estimated tumor
is shown in magenta  the actual tumor is shown in black 
   

k means clustering and radius of tumor vs 
stiffness learning
this method id like to refer to as semi supervised  as it has the
notion of a training set but derives thresholds from this training
set based on an unsupervised labeling of the data  following the
same exact procedure as in     all the way through labeling the
two point classes  the set of data arbitrarily chosen as the training
set would be used to develop thresholds using lr  gda  and a
svm in a similar fashion to the method explained in section     
recall the training set didnt come with a ground truth labeling 
instead the threshold is developed from the k means clusters
labeling of the data 
     
labeling the test set
similar to the initialization of labeling the test set in section      a
  d plot was created with distance from the center of the
supposed tumor on one axis and stiffness on another  then  using
the thresholds generated form the semi training set  the data was
classified as part of the tumor or not part of the tumor 
 

results

   
tumor not tumor labeling
the three test sets averaged    different palpations apiece  the
training set has    different palpations 
figure   shows the result of one iteration of one learning
method graphically  in particular  this analysis was done using the
method detailed in section     and used a svm to generate all the
threshold values 
figure    displays the number of false positives plus false
negatives for all methods across all learning algorithms 
   
specific size and location data
the method described in section     estimated the center of the
supposed tumor to be approximately  cm away from the actual
location 
the methods described in sections         all use a weighted
centroid to approximate the center of the supposed tumor using
equation    the average error between the actual and estimated
center of the tumor was       mm  all the learning methods
appeared to predict the approximate radius of the tumor within
 cm 

figure     results indicating the number of false positives plus
false negatives against learning methodology  learning algorithm
 a  stiffness learning followed by radius of tumor learning
 note since this method labelled the test set points twice  i
included errors from both relabelings  
 b  weighted clusters followed by radius of tumor learning
 c  weighted clusters followed by radius of tumor vs 
stiffness learning
 d  k means clustering
 e  k means clustering and radius of tumor vs  stiffness
learning
 

discussion

   

number of false negatives plus number of false
positives
referring to figure     it appears that all the learning methods
presented in section   perform reasonably well  although the
supervised learning methods did outperform the unsupervised
learning methods  gda tended to be more conservative then lr
or a svm and chose less aggressive thresholds  we can see for  
of the   methods that compared the performance of lr  gda  and
a svm this conservatism resulted in lower average errors overall
 figure   a    c    e  
   
location of tumor
all the methods suffered a large error with respect to predicting
the center of tumor  this is due to two reasons  firstly  the
palpation data wasnt controlled to a specific resolution  so the
palpation locations werent uniformly distributed about the tumor
 useful for weighted centroid estimates  and not uniformly
distributed within the tumor itself  useful for all methods  
secondly  the method by which the force data was acquired is
too dependent on the configuration of the phantom robot and isnt
uniform over the workspace of the robot  in particular  i was only
reading the force data read from the sensor along one axis 
regardless of the orientation of the force sensor with respect to the
artificial tissue  towards the edges of the phantoms workspace 
the force sensor is tilted  and the force read by this tilted sensor
generated from a palpation normal to the surface of the artificial
tissue will not generate forces solely in the z axis relative to the
force torque sensor 
   
robustness
while all the methods did reasonably well at labeling the points in
the testing sets  a major flaw in most of the learning methods was
that they are specifically trained to identify a tumor of the same
size as the testing set  and are furthermore restricted to identifying
only one tumor per test set 
 

fithe first method  however  differs from the others in the sense
that it thresholds first on solely the stiffness information 
regardless of how many tumors are present or the size of tumors 
however  the second round of thresholding based on the distance
from the estimated center of the tumor assumes one tumor
present  despite this  the increased flexibility of the first method
with respect to size of the tumor makes it superior to the other
methods explored in this paper in light of this method exhibiting
no greater error than the other methods presented 
 

references
   

   

   

future work

   
hardware
the artificial tissue used was a sponge  not a phantom tissue as
is desired for palpation experiments  once a phantom tissue is
created  more accurate stiffness data can be attained 
   
data collection
there are two major areas of improvement for data collection  and
one minor  firstly  with an off the shelf path planning algorithm 
the phantom premium should be able to palpate the artificial
tissue autonomously  secondly  addressing the workspace
constraints of the phantom premium a more clever way of
gathering the force data for palpations taken at the edges of the
phantom premiums workspace needs to be utilized  this would
involve reading the forces on all three axis of the force torque
sensor and given knowledge about the configuration of the sensor
relative to the artificial tissue from the phantom premiums
encoders  transform these forces into the same cartesian space as
the artificial tissue  and record the force vector normal to the
surface of the tissue  additionally  using a non linear model for
tissue stiffness has shown to estimate data taken during palpations
of phantom tissues more accurately than the linear model
presented     

   

   

g  guthart and j  salsibury  j k  the intuitive tm telesurgery
system  overview and application  in ieee international
conference and robotics and automation  pages             
gwilliam  james c   zachary pezzementi  erica jantho  allison m 
okamua  and steven hsiao   human vs  robotic tactile sensing 
detecting lumps in soft tissue   haptics symposium         ieee
xplore  web     dec       
grant  michael  and stephen boyd  cvx  computer software  cvx 
matlab software for disciplined convex programming  vers 
      web     dec         http   cvxr com cvx   
s  b  williams  m  h  chen  a  v  d amico  a  c  weinberg  r 
kacker  m  s  hirsch  j  p  richie  and j  c  hu  radical retropubic
prostatectomy and robotic assisted laparoscopic prostatectomy 
likelihood of positive surgical margin s   urology       mar    
 epub ahead of print 
yamamoto  tomonori  applying tissue models in teleoperated
robot assisted surgery diss  johns hopkins university  baltimore 
      dissertations and theses  web 

   
learning algorithms
ideally  with the autonomous palpation goal mentioned in the
hardware section of future work  the learning would happen in
real time such that as the phantom premium palpates the artificial
tissue sample  it can learn where the tumor is likely located and
then gather new data near the thresholds of its     confidence
region to generate more accurate predictions 
 

conclusions

in summary  ive shown that with the data gathered from a forcetorque sensor and a robotic device  learning algorithms can be
used to estimate the size and location of a tumor like object
embedded into an artificial tissue  five different learning methods
were explored  three with supervised learning and two with
unsupervised learning  although all methods gave comparable
results  the first method proposed  one that relabels the test set
based on a stiffness threshold learned from the training set  and
then with this new labeling develops a threshold for the radius of
the is the most robust algorithm  and will be utilized in future
works  this work will be extended to include autonomous
palpation and real time learning algorithms 
acknowledgements
id like to thank allison okamura for her advice throughout this
project and trusting me to setup the hardware 

 

fi