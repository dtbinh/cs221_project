eyes around the world   learning to alert and cluster live
webcams
jee ian tam  jeetam   sean rafferty  seanraff 

 

introduction

there are a large number of public live webcams that are accessible over the internet  a variety of content and objects
from various places all around the world are being recorded by these webcams in real time  but it is not feasible for a
single person to browse through all of the webcams to search for content that is of interest  our project aims to use
machine learning algorithms to cluster and identify webcams of interest out of a large pool of webcams  this has
relevance to security  surveillance and exploration applications where there is a need to filter through a large number
of video streams to detect objects of interest 
the input to our system is a stream of images from multiple webcams  for each webcam image  we use a gaussian
mixture model to model the background image  use to background model to extract foreground objects from the
webcam image  and use a convolutional neural network to classify the detected objects  the output of our system
is a display list of the top   webcams as ranked by the scoring algorithm for the webcams  which can be changed
depending on the user input query  we also use k means clustering to explore the different categories of webcams that
exist in our dataset 

 

related work

several groups have previously looked at exploring and characterizing the network of webcams around the world  a
previous effort was made to discover and characterize the locations and categories of webcams     based on their geoip addresses and links from existing gis databases  our current work extends this effort to try to characterize webcams
where there does not exist clean metadata and descriptions of the webcams  there has also been work in the area of
image fusion     of webcam images with data from google streetview and google earth images to provide additional
context to existing images from a webcam  this was more aimed towards providing improved location based services
for mobile applications  whereas our work focuses on alerting webcams solely based off their data streams 
the closest and most relevant previous work is real time abnormality detection from multiple webcams      where
a nearest neighbor model is used to create an image abnormality classifier based on simple image features  the
distance similarity metric used for nearest neighbors clustering is based on outliers relative to a sample of past webcam
images from varying time intervals  and is primarily based on image quadrants in a picture  our work extends this
by showing that it is possible to use object tracking methods by working on a pixel level instead of a quadrant level
to detect objects  and our work differs in that our interest metric is primarily tied to the activity of a scene instead of
abnormality relative to past images 
other related work is person identification from webcam images via semi supervised learning      where facial features
are extracted from webcam images to locate track the position of people in those images  our approach differs from
this aspect in that we aim to track multiple kinds of objects instead  work has also been done in using webcams to
detect and monitor birds in the wild     using a median filter by defining the background as the median of the previous
n frames  our work uses a different method  model background as gaussian mixture model  for object detection
instead 

 

dataset and features

our data set consists of images logged from approximately      publicly accessible  non password protected webcams  where query urls were scraped from the website opentopia com      although we would ideally run our
algorithms directly on live webcam streams  the bandwidth required to simultaneously process a meaningful number
 

fiof webcams was prohibitively high  as a result  we logged images from those      webcams every   minutes over a
period of   week  and ran our algorithms on that dataset 
the raw webcam images vary greatly in resolution   from as low to     x     to as high as      x       we log
the webcam images in their native resolution for processing flexibility later on  and resize them to smaller resolutions
 typically     x      as input into our system  sample images from some webcams are shown below in figure   
the features varied for our initial attempts at clustering and in our main effort of classification  for clustering  we used
a bag of features model  akin to the bag of words model which is common in language   the seed of these features
are sift descriptors  we will go more in depth about how we generated these features in the methods section  for
classification  we used the patches of images containing moving objects found through background subtraction as our
features  these patches were rescaled to     x     before being passed to the network 
figure    sample webcam images

 
   

methods
webcam ranking

in order to rank webcams based on the activity of the objects recorded  it is necessary to separate foreground objects
from the image background  to do this  we use opencvs     backgroundsubtractormog    method to construct a
background model for each pixel  and use it to classify pixels as foreground or background  the method implements
the algorithm described in a paper by zivkovic     for background subtraction  the model is a generative model that
uses a gaussian mixture model  gmm  to model the background color distribution for each pixel 
let  x t  be the value of a pixel at time t  and let t be a time period over which samples are recorded  define the
training data set t     x t          x tt      t is updated with each new sample  an estimate of the background  bg 
and foreground  fg  distribution can be modeled by a gmm with m components  
p  x t   t   bg   f g   

m
x

 
m n   x  
 m   m
i 

   

m  

where 
         
 m are mean estimates and          m are variance estimates  m are the mixing weights that are nonnegative and sum to    given a new data sample  x t    the parameters of the model can be updated recursively as     
m  m    o t 
m  m  

   

 

 m  
 m   o t 
m   m  m

   

 
 
 t  
m
  o t 
m   m   m   m  

   
 t 
om

where      x  
 m    is an exponential decay factor such that     t to limit influence of old data  and
is
 t 
defined as the ownership  for a new sample  om is set to   for the closest component with largest m and others
are set to zero  where closest is based on the mahalanobis distance metric  the squared distance from the m th
 
t 
 
component is calculated as dm
  x t       m
m  m
 
 t 

foreground objects usually correspond to some additional clusters with small weights m   thus  the background
model can be approximated by the first b largest clusters
p  x   bg  

b
x

 
m n   x  
 m   m
i 

m  

 

   

fiwe use the background model to classify each pixel in the image as either being part of the foreground or background
to obtain a foreground mask  we then fit contours around the sections of foreground object pixels using opencvs
findcontours   method  the contours are filtered based on size   contours that are too small       of picture area  are
attributed to noise  contours that are too large       of picture area  are attributed to pixel changes due illumination
or webcam position  which are not of interest 
a webcams score is then calculated as the sum of contour areas as a percentage of the image size divided by the sum
of contour arc lengths  score   total contour area     total contour length  we maximize for contour area to be able to
show the largest   most number of objects after filtering  we minimize for contour length to reward convexity  as we
found that large noisy artifacts in the webcam images tended to be highly non convex in shape 
   

clustering

the most involved operation in clustering our webcams was extracting the features  we wanted to capture semantic
information about the webcams  and therefore needed features which captured semantic information from frames 
we decided to base our features off of sift descriptors       these descriptors are scale  translation  and rotation
invariant  furthermore  they are robust to lighting changes or slight deformation  these properties are desirable for
our application  as objects will appear under different conditions in our webcams  given an image  one can extract
multiple sift descriptors  each of which corresponds to some local feature of the image  each descriptor is a vector
in r     
with this machinery  we will illustrate a method for extracting features from each webcam  first  we generate the
visual vocabulary by first sampling random frames from every webcam and extracting sift descriptors  and then
clustering the descriptors using k means  the resulting cluster centroids are the words in our vocabulary  then  we
compute the feature vectors for each webcam by extracting sift descriptors fram a random subset of frames from
each webcam and computing a histogram of the closest vectors in the vocabulary to the descriptors we extracted  the
resulting histogram is the feature we use to represent the webcam 
finally  we cluster the webcams corresponding features using k means using initial clusterings chosen by k means  
      in k means    each initial cluster center is chosen from a weighted distribution over the dataset  where the
weight corresponding to a certain point is the squared distance between that point and the closest initial centroid we
have chosen so far  the first initial centroid is chosen uniformly at random from all of the points  the resulting clusters
are the different unlabeled categories for our webcams 
   
     

convolutional neural network
network

we used a modified version of the blvc reference caffenet       which is a slightly modified version of alexnet
      this network features around    million parameters and         neurons  there are five convolutional layers 
some of which are followed by max pooling layers  then two fully connected layers  and finally a   way softmax  the
only difference between our network and the blvc reference caffenet is that our softmax layer produces   outputs 
whereas theirs produces      
     

dataset

our dataset consists of hand labeled patches from a random subset found using our previously described moving object
detector  this dataset consists of      examples total               of which are humans               of which are
vehicles  and                of which are noise  we separated this into a training set and a testing set  the training
set consists of     examples randomly sampled from each class  and the test set consists of the remaining examples 
     

training

we fine tuned the pretrained blvc reference caffenet on our dataset  the model was pretrained on the ilsvrc
     dataset by jeff donahue  we then fine tuned the model on our dataset  using a base learning rate of       for the
original layers and a learning rate of      for the final softmax layer  we trained the network for a few hours using a
single     ti 
 

fi 
   

results   discussion
webcam ranking

we present   sample snapshot results of the top        webcams as ranked by our scoring algorithm in figure    the
webcam images with detected objects are shown on the top row  and the corresponding background images as learnt
by the model are shown on the bottom row 

figure    snapshot of top        webcams from run    left  and run    right 

we see that the algorithm returns qualitatively acceptable results   it is able to highlight clear changes and rise in
activity of webcams  such as people filling into a room  street lights being switched off and changes in weather or
traffic conditions 
even though we perform filtering on contours and on the scoring function to try to eliminate noise  there are still
occurrences where our algorithm is influenced by image  lighting or webcam noise and ranks certain webcam images
highly when there are no noticeable activity or changes  several examples of webcam images that were erroneously
ranked in the top        are shown below in figure    

figure    examples of erroneously highly ranked webcam images

   

clustering

the results of clustering were lackluster  we found that the number of clusters played a large role in the expressiveness
of the clusters  too many clusters produced overly noisy clusters  too few clusters produced overly broad clusters 
with a moderate number of clusters  we did see some meaningful categories  for instance  we produced an animal
cluster  which contained images of cats and dogs  however  this category was not exclusive  while it contained
a disproportionately large number of webcams featuring animals  it also contained unrelated webcams  while the
clustering did produce some clear results  we deemed them to be too noisy for useful categorization  figure   shows
an example of a cluster produced 
 

fifigure    cluster contents  all webcams are represented  animal webcams are highlighted 

   

cnn filtering

our filtering results were promising  we have three primary interests  first  we want to filter out as many noisy
detections as possible  secondly  since there are proportionally few examples of vehicles and humans  a high recall
percentage was desirable  third  we wanted to use the convnet for search and clustering  so precision was also
important  our cnn produced the following results on the held out test set 
class
human
vehicle
noise

precision
     
     
     

recall
     
     
     

percentage of dataset
      
      
       

percentage of filtered dataset
     
     
     

for our applications  these results are extremely useful  high precision and recall for objects of interest mean that
searching and clustering are possible  although an even higher precision is desirable  our current numbers are still
high considering the dataset makeup  furthermore  the filtered dataset only contains       noise  which is much
lower than the original dataset which was comprised of     noise  thus  the top   most interesting webcams are
significantly more likely to contain objects of interest when filtered 
our network produced the following confusion matrix 
predicted label
human
vehicle
noise

correct label
vehicle
   
     
     

human
     
     
     

noise
     
     
     

the confusion matrix tells us that incorrect predictions on humans and vehicles are generally not helpful  that is 
incorrect predictions usually lead to inclusion of noise rather than an object of interest of another class 

 

future work

one of the main bottlenecks to this project was the amount of gpu memory available to store webcam images  in
order to be able to detect objects reliably  it is necessary to have a minimum image resolution  however  the gpu
memory required to store the background model image for each webcam increases as the image resolution increases 
at an image resolution of     x      we were able to simultaneously process a maximum of      webcam images at
a time  given extra computational resources  we would apply our system to the all      webcams in the dataset 
there are a few avenues that we can take in the future with regards to the cnn  first  we could tweak the criteria for
selecting which label to predict based on the probabilities output by the network  this could lead to better precision
and recall  or a better tradeoff between the two  if so  we would shard our dataset so that we can dynamically choose
training  testing  and validation sets  allowing us to validate choices of different hyperparameters  furthermore  we
could collect more data as there are relatively few positive examples for both of our objects of interest  this would
give us better estimates of our metrics as well as better generalization  furthermore  we could support better clustering
as well as search by using the data filtered and labeled by the convnet 
 

fireferences
    jacobs  nathan  et al  the global network of outdoor webcams  properties and applications  proceedings of
the   th acm sigspatial international conference on advances in geographic information systems  acm 
     
    luo  jiebo  vision with a billion eyes  proceedings of the  nd acm international workshop on geotagging and
its applications in multimedia  acm       
    balcan  maria florina  et al  person identification in webcam images  an application of semi supervised learning         
    breitenstein  michael d   helmut grabner  and luc van gool  hunting nessie real time abnormality detection
from webcams  computer vision workshops  iccv workshops        ieee   th international conference on 
ieee       
    verstraeten  willem w   et al  webcams for bird detection and monitoring  a demonstration study  sensors
                       
    opentopia  opentopia  web     dec       
    bradski  gary  and adrian kaehler  learning opencv  computer vision with the opencv library   oreilly
media  inc        
    zivkovic  zoran  improved adaptive gaussian mixture model for background subtraction  pattern recognition 
      icpr       proceedings of the   th international conference on  vol     ieee       
    z zivkovic and f van der heijden  recursive unsupervised learning of finite mixture models  ieee trans  on
pami  vol      no         
     lowe  david  distinctive image features from scale invariant keypoints        
     arthur  david  and sergei vassilvitskii  k means    the advantages of careful seeding  proceedings of the
eighteenth annual acm siam symposium on discrete algorithms  society for industrial and applied mathematics       
     jia  yangqing  caffe  an open source convolutional architecture for fast feature embedding         
     krizhevsky  alex  imagenet classification with deep convolutional neural networks  advances in neural
information processing systems               nips       

 

fi