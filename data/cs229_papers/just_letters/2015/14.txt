using dna methylation to predict white blood cells frequencies in
tumor tissue samples
cs      final project write up  fall     
marcos m  prunello
biomedical informatics ms student
marcosp stanford edu

ying cheng chris lee
electrical engineering ms student
leechris stanford edu

abstract
large multi cancer data sets are available that profile the epigenome for tumor tissue samples 
however  such cancer samples are made up of a mixture of cell types and it is necessary to determine
to which extent the samples are composed by tumor cells or by other cell types  such as blood cells 
we built models that are able to estimate the frequency of different types of blood cells present
in brain tumor tissue samples using only dna methylation data registered on the samples  and
marked the most important genes for this task 
neighbors  support vector regression and regression trees
 basic trees  but also random forests  bagging and
boosting  

introduction
cancer refers to a group of diseases characterized by an
uncontrolled growth in cells which can extend to different
parts of the body  generally caused by changes in dna 
there are about      million new cases per year in the
world and it causes about       of all human deaths  in
the united states  the financial costs of cancer have been
estimated at       trillion dollars per year  there are
many different types of cancers  each with its own
subtypes 

related work
the use of methylation signatures to estimate the
distribution of blood cell types in a sample is called
deconvolution of dna methylation and it involves learning
the specific methylation signature of each cell type from a
set of samples of purified known cell subtypes
representing gold standard data  to later infer the type of
cells present in the target samples  some research in this
topic has been carried out lately  but it stills remains a
non trivial problem with no clear solution  houseman    
described a method which resembles regression
calibration  where a methylation signature is considered
to be a high dimensional multivariate surrogate for the
distribution of blood cells  jaffe     tailored housemans
method using a new reference set produced with    k
microarrays instead of   k that was published by reinius
    

the importance of epigenomics when studying cancer
cannot be understated  epigenomics is the study of
epigenetic modifications  which include all the variations
that affect gene expression without altering the dna
sequence  changes on top of dna have shown to activate
oncogenes or deactivate tumor suppressor genes  large
multi cancer data sets are now available that profile the
epigenome for tumor tissue samples  nevertheless  such
cancer samples are made up of a mixture of cell types 
mathematical approaches are needed to deconvolve
these mixtures and determine to which extent the
samples are composed by tumor cells or by other cell
types  such as blood cells 

in a first stage of our work we applied housemans
method in the same way as jaffe  since this method was
developed for dna methylation deconvolution in blood
samples but we applied it in tissue samples  we looked for
some way of validation of these results  we decided to
perform gene expression deconvolution on the same
samples with a well established and validated method 
cibersort      we found no match between our results
from the deconvolution of dna methylation and those
from cibersorts gene expression deconvolution  facing
these negative results  we decided to approach the
problem as described in the introduction  using the dna
methylation data to predict the frequencies of the
different blood cell types  using as ground truth the

dna methylation  an epigenetic process consisting of a
chemical modification of dna  is responsible for cellular
differentiation and hence can be used to distinguish
distinct cell lineages 
our goal in this project was to predict the proportion of
different blood cell types in tumor tissue samples  our
continuous response  using dna methylation data
measured for an extensive set of genes  our predictors 
also continuous   and to identify which are the genes  the
features  that are most important for this prediction task 
to achieve this  we tried several machine learning
methods  linear regression with penalization  k nearest
 

fifrequencies provided by cibersort through its gene
expression deconvolution 

samples with similar dna methylation levels  using an
expectation maximization algorithm for mixtures of beta
distributions  since beta values represent the proportion
of methylation   starting with a model with only one
component  a new beta mixture component is added
iteratively if it improves the fit of the model according to
the bayesian information criterion  bic  for model
selection  each of the final mixture components
represents a subset of patients with a common
methylation profile  a methylation state   secondly  for
each of these subgroups the difference between its mean
methylation and the mean methylation in normal tissue
samples is calculated and it is called dm value
 differential methylation   only those genes with
significant dm values are selected for the third step  in
which a linear regression is used to model the expression
of each gene by its own methylation  if there is a
significant negative association between methylation and
gene expression  the gene is finally reported as a
methylation driven genes 

data set and features
gliobastoma cancer data
we decided to focus our analysis in glioblastoma  gbm  
which is the most common and most aggressive malignant
primary brain tumor  we extracted methylation data for
gbm cancer samples from the cancer genome atlas
 tcga   illumina infinium humanmethylation   k were
used to produce tcgas dna methylation data  which is
quantified with beta values in a range from   to  
representing the proportion of methylation signal versus
total signal  values close to   represent high levels of dna
methylation and values close to   low levels  those cpg
sites with more than     missing values in all samples
were removed and    k nearest neighbor  knn 
algorithm was applied to estimate the rest of missing
values      tcga samples were analyzed in batches so we
used combat to adjust for this effect      we also
extracted matched gene expression data  produced with
microarrays technology  data was log transformed 
infinities were replaced with a low value and missing value
estimation and batch correction were applied as
described before  the final data set consisted of    
samples 

figure    representation of methylmix algorithm  this is a
methylation driven gene because it shows methylation states
that differ from variation in normal samples and also its
methylation profile has an effect in gene expression  each
sample receives a dm value  which is the difference between
mean methylation in its group and mean methylation in normal
samples 
met in normal samples

response features
frequency    samples 

in our prediction task  the response is the proportion of
seven different blood cell types in the tumor tissue
samples  d   t cells  cd   t cells  cd    nk cells  cd   
b cells  cd    monocytes  neutrophils  and eosinophils 
we generated our response features using cibersort     
an algorithm for gene expression deconvolution which
accurately quantifies the relative levels of distinct cell
types within a complex gene expression admixture  such
mixtures can derive from malignant or normal solid
tissues 

dm value

 

beta value  methylation 

 

predictors
gene expression

our predictors are the methylation measurements  beta
values  on a total of       genes for each of the    
samples  with this data set  we faced two challenges 
first  methylation data is known to be noisy  and second 
we needed to reduce the number of available features
 genes  though doing some sort of variable selection  we
decided to approach these two issues analyzing the set of
predictors with an algorithm called methylmix      which
identifies hypo  and hyper methylated genes in cancer
samples that are also predictive of transcription through
the following three steps  figure    

beta value  methylation 

applying this algorithm to the gbm data  from the original
set of       genes we identified     methylation driven
genes which constituted our reduced set of predictors 

first  for each gene a beta mixture model is fitted to the
methylation beta values to generate subgroups of
 

fifurthermore  each sample for each gene can be
represented by the dm value of the group to which
belongs  in addition to its original raw methylation value
 beta value   dm values were shown to perform better
than raw methylation in some scenarios  provided that
they constitute a less noisy version of the data      in this
way  we had two matrices of predictors  one with the
original methylation values and other with the dm values 
for each of the     methylmix genes  figure     we
trained our predictive models in both 

evaluated the performance with mean squared error
 mse   all the analysis were performed in r      in the
following paragraphs we described the methods that we
used  in
k nearest neighbors regression  knnr 
given a value for k and a prediction point  knnr identifies
the k training observations that are closest to the given
point and predicts its response with the average of the
response of the k closest data points  this is a nonparametric method  the optimal number k was selected
with    fold cv  this method was implemented with the r
package caret      

figure    heatmaps of the     samples and     genes for both
raw data and dm values
raw beta values

linear regression with l  norm penalization

samples

this method  also known as lasso  fits a penalized linear
regression model  where the coefficients are penalized
using l  norm  this forces some of the coefficient
estimates to be zero when the tuning parameter  is large
enough  hence  this model is in itself a variable selection
method  yielding a sparse model  very convenient in our
application provided that we have     predictors and    
samples  the objective function being minimized is 


 





                   
  

  

   

  

genes

we selected the penalization parameter  with    fold cv 
this method was implemented using the r package
glmnet      

dm values

support vector regression  svr 

samples

svr is an extension of support vector machines  svm  for
cases where the response is continuous instead of binary 
svr contains all the main features that characterize svm 
with a loss function that ignores errors situated within a
certain distance of the true value  this type of function is
often called epsilon intensive loss function  since a margin
of tolerance  is set  the dual representation of the model
is given by 




  

  

 
min                                
  

genes

   

such that                                  

where  is the upper bound for the cost parameter   is
an  positive semidefinite matrix    
                           is a kernel and 
is the number of observations  we implemented svr with
radial or polynomial kernel  but also with no kernel at all
 table     in each case  the required parameters were
selected with    fold cv  svr was implemented with the
r package e          

methods
we divided our     samples into one training set      
and one test set        we trained several machine
learning methods to predict the frequencies of each of the
  blood cell subtypes individually  using both the raw
methylation and the dm values training sets  we tuned
the parameters required for each method with    fold
cross validation  cv   and once selected the optimal
parameters  we refitted the model in the whole training
set  finally  we predicted the response in the test set  and
 

fitable    kernels applied in svr

kernel
linear
radial
polynomial

formula
 
 
exp         
   

it seems that the raw methylation data was enough for the
prediction task 

parameters
tuned with cv
  
    

table    top performing model for each cell subtype
subtype
b cells
cd 
cd 
eos
mon
neu
nk

      

tree based methods
tree based methods for regression involve segmenting
the predictor space into a number of simple regions and
using the mean of the training observations in the region
to which a point that we want to predict belongs  we first
fitted a basic regression tree and pruned it with    fold cv 
since basic regression trees do not always provide the
best results in terms of accuracy  we also applied bagging 
random forests  and boosting to improve the
performance  each of these approaches involves
producing multiple trees which are then combined to yield
a single prediction  bagging takes b bootstrap samples of
the training observations  fits several regression trees
then averages the predicted values  helping to reduce the
characteristic high variance in a basic regression tree 
random trees contributes to decorrelate the trees built by
bagging  by taking a random sample of some predictors as
split candidates each time a split in a tree is considered 
boosting is another which in the context of regression
trees involves growing the trees sequentially  each tree is
grown using information from previously grown trees  the
number of trees as well as other parameters like the
number of predictors chosen randomly in random forests
were optimized looking at out of bag  oob  error
estimates  we used the r packages tree      
randomforests      and gbm      

obs
mean
      
      
      
      
      
      
      

best model
raw   svr lin
raw   lasso
dm  rand forests
raw   boosting
dm   svr linear
raw   svr radial
raw   svr polyn

mse
test
      
      
      
      
      
      
      

mse
train
     
      
      
      
      
      
      

cor
test
     
      
      
      
      
      
      

cor
train
      
      
      
     
      
      
      

in terms of the models  different methods worked better
for different cell subtypes  but in   out of the   subtypes
it was support vector regression the one that achieved the
best results  for b cells and monocytes  the best model did
not require any kernel  whereas for neutrophils and
natural killers used a radial or a polynomial kernel 
respectively  for cd  and eosinophils  random forests and
boosting performed the best  they represent
improvements over the basic regression tree  since both
fit several trees  random forests takes random samples of
the predictors to make a final prediction using not very
correlated trees  and boosting in each new tree weights
more those points with bigger errors in the previous trees 
so it is reasonable to see that these methods worked
better than the basic regression tree  for cd   the best
performing model is lasso  nevertheless  results for cd 
should be interpreted with care  since the frequency of
cd  in the samples is very low and the response vector
consists mainly of zeros and some small frequencies  in
fact  calculating the ratio of the squared root of mse
 rmse  and the mean of the true observed frequency  it is
possible to see that among all subtypes  cd  is the one
with poorest performance  figure     knnr did not appear
in any case to be among the top performing models 
although this simple algorithm works well in some
contexts  it usually performs worse in very high
dimensional spaces with few samples like in our problem 

results
a total of     models were trained  given our   cell
subtypes    data types  and   candidate models  knnr 
lasso  svr with   different kernels and   tree based
methods   after optimizing the parameters for each
model with    fold cv  the model was re fit in the whole
training set and predictions were obtained for both the
training and the independent test set  then we calculated
different measurements to evaluate the performance of
the model but we used the traditional mean square error
 mse  on the test set to select the best performing model
for each subtype  table    

figure    root mean square error relative to mean value of the
response in the test set 

looking not only at the best performing model but also to
the top models for each cell subtype  we did not find that
either the raw methylation data or the dm values
outperformed the other data type in most cases  although
we hypothesized that the dm values could performed
better as they represent a de noised version of the data 

we also calculated the correlation between the predicted
values and the observed values for both the training and
the test set  the correlations in the training set are strong 
and some models not finally reported here presented
even higher correlations  however  in the test set they are
 

fiweaker  showing that there is room for improvement in
the predictions  even though we selected our reduced
feature set independently of the response  there might be
some overfitting in our models  considering as well that
the number of predictors is still high in relation to the
number of samples 

discussion and conclusion
in this project we built models that are able to predict the
frequency of   blood cell subtypes  d   t cells  cd   t
cells  cd    nk cells  cd    b cells  cd    monocytes 
neutrophils  and eosinophils  in samples from brain tumor
tissue using only dna methylation data  we applied an
algorithm which identifies methylation driven genes to
select a reduced feature space  and trained our models
with both raw methylation data and dm values  although
we suspected that the dm values would show a better
performance as they constitute de noised data  in   out of
the   subtypes  the best model used the raw data 

we identified for each subtype which were the most
important genes in the top performing model and we
report here the top    again  results for cd  should be
interpreted with care  since the performance was weak 
and also because the l  penalty of the lasso forces some
coefficients to be zero  and if there are some correlated
genes  arbitrarily one is kept as a non zero coefficient and
the others become zero  we intersected the top    genes
for each subtype and found that there were no genes
pointed as important in most subtypes simultaneously 

in relation to the performance of the models  support
vector regression performed was selected as the best
model for   subtypes  although with different kernels 
probably the ability of svr to work in high dimensional
spaces contributed to this outstanding performance  in
two cases the best model was a tree based method and in
one the penalized linear regression  knn was not picked
as one of the best models  this simple method is known
not to perform very well in highly dimensional spaces  and
hence our higher number of predictors than samples may
not be most adequate context for knn 

table    top performing model for each cell subtype 
subtype
b cells
cd 
cd 
eos
mon
neu
nk

hsd  b  
abca 
tnfrsf a
crybb 
klhl  
neto 
znf   

top   important genes
znf    pla r 
mt a
abhd  acaa 
acn 
klhl   psmb 
ctsz
ddx   c  orf   acsbg 
smoc  rdh 
cabyr
stag  me 
foxd 
bcl  a c orf   znf   

pdgfra
acot 
oas 
ankrd 
znf   
cthrc 
dusp  

from the inspection of the results  it is clear that there is
wide opportunity for improvement of the performance of
this prediction task  for example  our feature selection
with methylmix was carried out independently from the
response  a future modification should explore in more
detail the set of       genes with some variable selection
procedure that also involves the response  furthermore 
we did not account for the fact that our response was a
proportion  ranging from   to    and the addition of this
constraint may strengthen our models  for example  the
linear regression model which as it is can predict values
outside of the plausible range 

the resultant top frequency predictive genes suggests
some primitive principles  the fact that very few top gene
overlaps between different white blood cell types
suggests very differentiated activities between the cell
types  it is possible to see that each cell types  top genes
seem to showcase execute main and various biochemical
tasks known to be specific to that particular cell type  for
example  crybb  beta crystallin b  for eosinophils known
having crystalloid core  and others  on the context of gene
regulation  each cell types contain one top gene that is of
dna binding functionality  znf    for b cells  abca  for
cd   t cells  oas  for cd   t cells  ddx   for eosinophils 
znf    for monocytes  me   stag  and foxd  for
neutrophils  znf    and znf    for natural killer cell 
these might be of interest for implications on gene
regulations  on the context of possible tumor
immunological functions or apoptotic function  a few
genes stand out  tnfrsf a  tumor necrosis factor
superfamily  a for cd   t cells  ankrd   ankyrin repeat
domain containing protein   for eosinophils  stag  
cohesin subunit sa   for neutrophils  bcl  a  b cell
cll lymphoma   a isoform  for natural killer cells  these
may be of interest for implications on cancer
immnological functions  finally a few top genes appear to
be less annotated with gene ontology terms  c  orf   for
eosinophils  klh   for monocytes  c orf   and znf   
for natural killer cells  these might be genes with novel
implications 

other aspect of this problem that should be addressed is
the joint prediction of our   responses  and not
individually as we did  since the relative frequencies of
each cell subtype are related to each other  it seems
reasonable to predict all the frequencies together with a
multivariate response  also  we acknowledge that our
data set was rather small      samples divided into the
training and test sets  we would like to evaluate the
results of our work in larger data sets  from other types of
tumor as well 
even though this work can be further extended with the
suggestions previously mentioned  we were able to see
that dna methylation provides clear signal of the immune
composition of the tumor tissue and can be used to infer
the relative frequencies of different types of white blood
cells present in the samples 

 

fireferences
   
e  a  houseman  w  p  accomando  d  c 
koestler  b  c  christensen  c  j  marsit  h  h 
nelson  j  k  wiencke  and k  t  kelsey  dna
methylation arrays as surrogate measures of cell
mixture distribution   bmc bioinformatics  vol 
    no     p           
   
a  e  jaffe and r  a irizarry  accounting for
cellular heterogeneity is critical in epigenomewide association studies   genome biol   vol     
no     p  r         
   
l  e  reinius  n  acevedo  m  joerink  g 
pershagen  s  e  dahln  d  greco  c  sderhll 
a  scheynius  and j  kere  differential dna
methylation in purified human blood cells 
implications for cell lineage and studies on
disease susceptibility   plos one  vol     no     p 
e            
   
a  m  newman  c  l  liu  m  r  green  a  j 
gentles  w  feng  y  xu  c  d  hoang  m  diehn 
and a  a alizadeh  robust enumeration of cell
subsets from tissue expression profiles   nat 
methods  no  may       pp            
   
o  g  troyanskaya  k  dolinski  a  b  owen  r  b 
altman  and d  botstein  a bayesian framework
for combining heterogeneous data sources for
gene function prediction  in saccharomyces
cerevisiae   proc  natl  acad  sci    vol        no 
     pp                 
   
w  e  johnson  c  li  and a  rabinovic  adjusting
batch effects in microarray expression data using
empirical bayes methods   biostatistics  vol    
no     pp              
   
o  gevaert  methylmix  an r package for
identifying dna methylation driven genes  
bioinformatics  vol      no      pp         
     
   
o  gevaert  r  tibshirani  and s  k  plevritis 
pancancer analysis of dna methylation driven
genes using methylmix  genome biol   vol     
no     p           
   
r core team  r  a language and environment
for statistical computing  r found  stat 
comput  vienna  austria        
    
m  kuhn  caret package  j  stat  softw   vol     
no     pp            
    
j  friedman  t  hastie  and r  tibshirani 
regularization paths for generalized linear
models via coordinate descent   j  stat  softw  
vol      no     pp            
    
d  meyer  e  dimitriadou  k  hornik  a 
weingessel  and f  leisch  misc functions of the
department of statistics  e       tu wien  r
package version               online   available 
http   cran r project org package e     
    
b  ripley  tree  classification and regression
trees  r package version                
    
a  liaw and m  wiener  classification and
regression by randomforest  r news  vol     no 

    

 

   pp             
g  ridgeway  gbm  generalized boosted
regression models         online   available 
http   cran r project org package gbm 

fi