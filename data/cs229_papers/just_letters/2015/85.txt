cs   finalreport
markkwon hjkwon    minkim cs    



gimmefoodbytheyelpingstones
introduction
whenusingyelptoexplorenewrestaurantsaroundthearea weoftennoticedthattherewererestaurantswithhigh
ratingsthatwedidntparticularlylikeorfindthatarandomrestaurantweenjoyeddoesnthavesuchahighrating 
wewillusethedatasetfromtheyelpdatasetchallengethatconsistsofusersandrestaurantsdatawiththeirreviews the
intuitionbehindthisprojectisthatpeoplewithsimilartastetendtoagreeonwhichrestaurantsaregood ourfinalgoalwould
betorecommendrestaurantstousersbasedontheirpreviousreviews ratingstootherbusinesses toframethisintoa
machinelearningproblem recommendingrestaurantstouserscanbetranslatedintopredictingarestaurantsratingofa
user ifweareabletopredictausersratingtoaspecificrestaurant wecaneasilyrecommendrestaurantstotheuserbased
onthetopratedrestaurants 

dataset
 
dataseturl 
http   www yelp com dataset challenge
 
datawasprovidedasjsonfilesforbusinesses reviewsandusers sincethedatasetwastoolargetorundifferent
algorithms wereducedthesizeofthedatabyfilteringitdowntoameaningfulsubset  
wefilteredthebusinessesaccordingtoaselectedlocation thiswasbecauserecommendationshouldbebasedon
auserslocationandtheratingmatrixshouldnotbetoosparse therestaurantsinnorthlasvegaswereselectedand
onlythereviewsontheserestaurantswereselected accordingly weselecteduserswhohavemorethan  validreviews
onthefilteredrestaurantssinceweneedenoughreviewsperusertogetenoughdataabouteachuserspreferences 
originaldataset business       review         user       
northlasvegasdatatset business     review      user    
withthefiltereddata wecouldcreateareviewmatrix usersrepresentedasrowsandbusinessascolumns with
densityof    

relatedworks
theframeworkweusedfordevelopingapredictionsystemisgenerallyknownascollaborativefiltering inwhich
itemsarerecommendedbasedonthepreferencesofotheruserswhohaveratedtheitems 
   itemitemcollaborativefiltering neighborhoodmethod    


pu i isthepredictedratingforuseruanditemi  ru j istheratingforitemjbyuseru 
bu i isthebaselineratingfortheuser whichweusedastheaverageratingoftheuserinthetrainingdataset
s i  j  isthesimilaritymetricbetweenitemianditemj cosinesimilaritywasusedinourcase 

  

  

thisalgorithmfindsrestaurantstheuserhasratedalreadysimilartotherestaurantwhoseratingwearepredicting
andgetstheweightedaverageoftheratingsbasedonthesimilarity itemitemcollaborativefilteringwouldwork
betterthanuseruserfilteringifitiseasiertoidentifysimilaritiesbetweentheitemsthanusers businesseshave
moreoverlappingreviewsbetweenotherrestaurantsthanusershavewithdifferentusers 
userusercollaborativefiltering neighborhoodmethod    
thesameasitemitembutinsteadofusingsimilaritiesbetweenitems similaritiesbetweenusersarecalulatedand
ratingsofotheruserswhoratedtherestaurantsareused thiswouldworkbetteriffindingsimilaritybetweenusers
waseasierthanbetweenrestaurants 
matrixfactorization latentfactormethod    


q isthelatentfactormatrixfortheitems  p isthelatentfactormatrixfortheusers 
 istheregularizationparametertoavoidoverfitting  

thisalgorithmfindsthelatentfactorsthatdeterminetheusersratingonlyusingtheobserveddata thelatent
factormatrixfortheitemsandtheusersarecalculatedandtheratingmatrixisobtainedviathedotproductofthe
twomatrices althoughthisisamorecomplicatedalgorithmcomparedtotheneighborhoodmodels ittendstogive

fi  

betterresults anotherdrawbackforthisalgorithmisthatitisnonconvexsoevenafterconvergingitmightnotbethe
globallyoptimalsolution 
hybridrecommender   
becauseeachmodelhasdifferentstrengthsandweaknesses thepredictionscanbemixedtogetherbyaddingthem
upwithdifferentweights theweightswouldchangewiththedataset asthereviewmatrixgetsmoredensethe
similaritycalculationswouldbecomemoreaccurate 



models methods
weextendedthe collaborativefilteringalgorithmsto  modelsbymodifyingeachalgorithmswithadditionalfeatures 
   modelsusingitemitemsimilarity
 model  basicitemitemsimilaritywithratings 
 model  extendeditemitemsimilaritywithbusinesscategories
calculatesitemitemsimilaritywithbusinesscategories restaurantsthatcontainmorecommonkeywords
intheircategorydescriptionareconsideredmoresimilar 
 model  extendeditemitemsimilaritywithbusinessreview
calculatesitemitemsimilaritywithbusinessreviews restaurantsthathavemoreoverlappingwordsintheir
reviewsareconsideredmoresimilar 
 model  extendeditemitemsimilaritywithbusinessreviewswithspecifiedkeywords
calculatesitemitemsimilaritywithbusinessreviewswithwordsinspecificcategories thecategories
 service taste good bad price wereconsidered forexample forthecategorytaste wordssuchas
spicy deliciouswerecounted  restaurantswithsimilarcategoryfrequenciesareconsideredsimilar 
   modelsusinguserusersimilarity
 model  basicuserusersimilaritywithratings
 model  extendeduserusersimilaritywithusercompliments
calculatestheuserusersimilaritywithusercompliments usercomplimentsdescribeswhatkindofauser
heorsheisanduserswithsimilardescriptionareconsideredmoresimilar 
usercomplimentsexampleinyelpdataset 
 compliments    cute     plain     writer     note     hot     cool     more    
 model  extendeduserusersimilaritywithuserreviews
similartomodel butwithusersimilarity
 model  extendeduserusersimilaritywithuserreviewswithspecifiedkeywords
similartomodel butwithusersimilarity
   modelsusingmatrixfactorization
 model  basicmatrixfactorizationmethod
usesmatrixfactorizationwheremissingmatrixvaluesarenotconsideredduringtheiteration 
 model   matrixfactorizationwithinitializingmissingvalueswithuseraveragerating
modifiedversionofmodel toinitializemissingvalueswithuseraveragerating 
 model   matrixfactorizationwithinitializingmissingvalueswithrestaurantaveragerating
modifiedversionofmodel toinitializemissingvalueswithrestaurantaveragerating 
hybridmodel
thepredictionsfromthemodelswereblendedtomakethefinalprediction theweightsofthemodelstousewere
determinedbyusingmultivariatelinearregressionwithtwodifferentregularizationmethodstopreventoverfitting namely
lassoregressionandridgeregression 
lassowasthemoreintuitivewaysincelassocanzerooutweightswhicheliminatesvariablesthatdoesnthelpfitthedata
butwedecidedtousebothregularizationsandseehowtheyperformeddifferently 
testingprocess
i testinggroup
among   usersinourfiltereddataset wedesignated   ofthemtobeinthetraininggroupandtheother   tobein
thetestinggroup amongthereviewsoftheusersinthetestinggroup wedesignated   ofthereviewstobetesting
reviewsandtheywerehiddenfortesting theother   ofthereviewswereusedtocalculatethesimilaritybetweenthe
usersandpredictthehiddenratings 
fortestingthehybridmodel wetookthepredictionsfromthetestsetandused   fortrainingand   fortesting 
meansquarederrorwasusedforevaluatingthemodels 

fiii crossvalidation
crossvalidationwasusedtodeterminetheregularizationparametersformatrixfactorizationandlasso ridgeregressionthat
ledtothesmallestmse 

matrixfactorization
  foldcrossvalidationwasusedtorundifferentstochasticgradientdescentstofindthebesthyperparametersstep
size regularizationparameter andnumberoflatentfactors thebelowarelistsofvaluesexamined 
step size               regularization parameter                           number of latent features       
               

lassoregression ridgeregression
lassoregressionandridgeregressionweredoneusingthesklearnpythonlibraryfunctionslassocvandridgecv
whichhavebuiltincrossvalidationtosettheregularizationparameter   lassocvusescoordinatedescentand
ridgecvusesgeneralizedcrossvalidation gcv  whichisamoreefficientformofleaveoneoutcrossvalidation 
duringourresearch wecameuponthefactthatcrossvalidationoftheformofkfoldorleaveoneout
crossvalidationdoesntalwaysfindtheoptimalsolutionforlassoregression whichiswhyweusedthelassocv
functionwiththebuiltincrossvalidation 
iv optimizingmatrixfactorization
stochasticgradientdescentforthematrixfactorizationmodelfindsthelocalminimumpoint however itisnot
guaranteedtobetheglobalminimum thus inordertogetavalueclosetotheglobalminimumpoint weranmatrix
factorization  timesandusedtheonethathadthelowestmeansquarederror thiswasalsoreflectedinhybridmodels 
model       wereran  timesandonlytheoneswithlowesterrorwereconsidered 


results analysis
  testresultsfor  distinctmodels
thebelowisabargraphofmeansquarederror mse ofdifferentmodels mseofanaivealgorithmwhichratesany
restaurantastheusersaverageratingwasaddedforcomparison 



figure  testingerrorwithdifferentmodels

eachmodelperformedasexpected basicitemitemanduserusercollaborativefilteringperformedworsethanthebaseline
algorithmsincethedatawastoosparsetofindenoughsimilaritybetweendifferentusersandrestaurants fortheitemitem
collaborativefiltering therestaurantcategoriesseemedtobethefeaturethatwasthemosteffectiveinfindingsimilarities
betweenrestaurants model andmodel  whichusedthereviewsthatwereleftfortherestaurantsdidntworkwellwhen
findingsimilaritiesbetweenrestaurants however thesameapproachseemedtobeeffectiveforfindinguserusersimilarity 
theassumptionwasthatpeoplewhousedsimilarwordstodescriberestaurantshadsimilarcriteriaforjudgingarestaurant
andusingthatsimilarity model andmodel performedwell model  whichcharacterizesthetypeofuserthroughthetags
providedbyotherusers wasalsoeffectiveinfindinguserswithsimilarratings 

thelatentfactormodels models      asseenfromresearch performedbetterthantheneighborhoodmodels models 
    thebasicmatrixfactorizationmodel whichonlyusedobserveddatatominimizethemeansquarederrorperformed
slightlybetterthanthebestoftheneighborhoodmodels forthehyperparameters stepsizeof       regularization

fiparameterof     and latentfactorsworkedthebestforthebasicmatrixfactorizationmodelafterrunning  foldcross
validation themodifiedversionofthelatentfactorizationmodelbyfillinginthemissingdatawiththeuseraveragerating
 stepsize        regularizationparameterof   and  latentfactors turnedouttodoworsethanthebasicmodelbut
fillingitinwithrestaurantaveragerating stepsize        regularizationparameter     and  latentfactors turnedout
tobethebestmodelforpredictingtheratings theconstantstepsizeworkedbetterinourcase afterseeingusingstepsizes
suchas   numberofiterations or   numberofiterations ledtosignificantincreaseintheerrorrate fortestingfor
convergence westoppedaftertheerrorratestartedplateauing especiallysincewaitinguntiltheerrorratereaches would
overfitthemodeltothetrainingdata theerrorin
figure 
ismeasuredbythesumofthemeansquarederrorforall
considereddatainthematrix whichexplainsthelargevalue 


figure  matrixfactorizationerrorforiterationsformodel       wereomitted 

  testresultsforhybridmodels




figure  testingerrorwithhybridmodels


table  coefficientsforlassoregression left  alpha        ridgeregression right  alpha       

bothresultsforridgeandlassoregressionwereconsidered asexpected lassoregressionperformedslightlybetterthan
ridgeregressionbecauselassoregressiongotridofthevariablesthatseemedtointroducetoomuchbias forlasso the
modelsthatendedupbeingusedweremodel  basicuserusersimilarity  model  basicmatrixfactorizationmodel and
model   matrixfactorizationmodelwithmissingdatafilledwithrestaurantaverage  itwassurprisingthatthemodeldidnt
considerthemodelswithbettermeansquarederrorrates butconsideringthetestingratiowas       wasusedfor
training    wasusedfortesting itdoesntseemtobeaproblemwiththeevaluationprocess thealphavalueforlasso

fiwasdeterminedusingcoordinatedescent whichwasbuiltintothelassocvfunctionandthemeansquarederrorvaluesfor
thedifferentalphavaluesareplottedin
figure 
 unfortunatelyforridgeregression thecrossvalidationdatawasnot
availablefromthebuiltinridgecvfunction sotheplotisnotavailable 


figure  meansquarederrorplotfordifferentalphavaluesforlassoregressioncrossvalidation


conclusion futurework
usingthehybridmodel wewereabletoachieveameansquarederrorratecloseto  whichisafairlyaccurate
modelconsideringtheerrorsaresquared howeversincetheratingsarediscretevaluesintheinterval    themean
squarederrorwasabetterrepresentationoftheerrorsthanthel norm inmse twoerrorsof    differenceisconsidered
lessthanoneerrorof     therecertainlycouldbeimprovementsuponthismodel suchasusingfeatureweightedlinear
stackingforthehybridmodel   insteadoftheconstantweightsforeachofthepredictionmodels thebiggestchallenge
facedwasnothavingenoughinformationabouteachuserandrestauranttoaccuratelyfindsimilarratingsandthateachuser
showssignificantdifferenceinhowtheyraterestaurants thefeaturebasedweightingofthehybridmodelwouldbeableto
accommodateforthedifferentuserspreferences anotherwaytoimprovethismodelisgettingridoftherandomnessof
matrixfactorizationassuggestedinguaranteedmatrixcompletionvianonconvexfactorizationbysun r etal    matrix
factorizationisanonconvexproblemthatdoesntguaranteetheglobaloptimumsolutionevenafterconvergingwith
stochasticgradientdescent althoughweresolvedthatissuebystartingatmultiplerandompointsandgettingtheminimum
outofall thatdoesntguaranteetheglobaloptimumsolutionanditalsoreliesonluck 



references
   b m sarwar g karypis j a konstan andj reidl itembasedcollaborativefilteringrecommendationalgorithms in
acmwww   pp        acm      
   p resnick n iacovou m suchak p bergstrom andj riedl grouplens anopenarchitectureforcollaborativefiltering
ofnetnews inacmcscw   pp        acm      
   y koren factorizationmeetstheneighborhood amultifacetedcollaborativefilteringmodel proc   thacmsigkdd
intlconf knowledgediscoveryanddatamining acmpress      pp        
   ekstrand m   konstan j        
collaborativefilteringrecommendersystems
  nded  vol   pp        
foundationandtrends 
   koren y  bell r   volinsky c        matrixfactorizationtechniquesforrecommendersystems 
computer 
     
   matrixfactorization asimpletutorialandimplementationinpython  n d   retrieveddecember        from
http   www quuxlabs com blog         matrixfactorizationasimpletutorialandimplementationinpython
   sill j  takacs g   mackey l        featureweightedlinearstacking 
   sun r   luo z        guaranteedmatrixcompletionvianonconvexfactorization 

fi