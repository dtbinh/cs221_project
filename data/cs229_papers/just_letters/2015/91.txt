planet labels   how do we use our planet 

timon ruban
stanford university
timon stanford edu

 

rishabh bhargava
stanford university
rish   stanford edu

vincent sitzmann
stanford university
sitzmann stanford edu

introduction

accurate and up to date land cover classification data can be used for interesting applications in
different fields  by tracking daily changes of forest cover in areas of interest it is possible to quickly
detect illegal deforestation  environmental scientists can further explore the consequences of climate
change by measuring how fast ice cover is melting  urban planners can track city growth to better
anticipate future infrastructure requirements  with the ever increasing number of satellites with
image capturing capabilities  it has become progressively easier to observe and act upon the changes
that earths surface is undergoing  we use high resolution satellite images to classify the land visible
according to its cover such as forest  water or urban land  the input to our algorithm is a tile of
    by     pixels cut out from a satellite image  we then extract features like gabor filters and
histograms of the hsv  red edge and near infrared bands from the tile and use a random forest to
output a predicted land cover class 

 

related work

in recent years  several papers have discussed the use of machine learning approaches to the land
cover classification problem  support vector machines     have achieved        accuracy using
radial basis function  rbf  and polynomial kernels  other approaches have seen the use of decision trees       random forests     and artificial neural networks        employing a number of
different hyper parameters with very similar results  the maximum accuracy being       however 
the datasets used in all these papers tended to be much smaller than the ones we are using  some
papers     have argued for evaluation metrics other than accuracy  such as  error  in terms of choosing features  pixel values are commonly used  however  other important descriptors used are sift
and gabor filters      

 
   

dataset and features
dataset

since there is no dataset of geospatial images with corresponding land cover classification information readily available  we assembled our own  to this end we collected a dataset of        samples
consisting of pairs of image tiles of     by     pixels  input object  and labels denoting the true
land cover seen in that image  desired output  
we cut out the tiles from     rapideye satellite images  all depicting different areas in california 
the rapideye images are      by      pixels at a  m resolution and consist of five spectral bands
 red  green  blue  red edge and near infrared   we downloaded the imagery from the planet explorers
program      that the earth imaging start up planet labs has kindly given us access to 
to label the tiles we make use of the most recent national land cover database  nlcd           
it covers the entire u s   at a spatial resolution of   m  and uses a    class land cover classification
scheme adapted from the anderson land cover classification system      we further aggregated
these    classes into   important land cover classes and excluded wetlands  since we have almost no
data for this class  see figure    
 

fifigure    histogram of the labels of the tiles in our dataset 
most images are of cultivated land  as the pictures are all
from california  it is not surprising that almost no wetland
is found 

to obtain the label for a tile  we transformed the coordinates of its pixels
to the projected coordinate reference
system of the nlcd      and then
queried the nlcd      to get a label for every pixel in the tile  if
more than    percent of the pixels
belong to one land cover class  we
admitted the tile and its respective
land cover class to the dataset  we
used this    percent threshold to remedy the problem that the rapideye
images are more recent  from      
than the nlcd      dataset and the
land cover might have changed since
then  by only using tiles that are
dominated by one type of land cover
we are more confident that the land
cover type has remained unchanged 

after collecting the data we split it
into a test  validation and training set 
   percent of the tiles were used for
the training set     percent for the validation set used to select the best model and another    percent
for the test set used to report the final prediction accuracy of our method 
   

features

three major considerations dictated the feature selection  first and foremost  different land cover
classes differ in their color  to capture color information  we transform each tile to the huesaturation value color space and extract a    bin histogram per channel  yielding     features  the
hsv color space was chosen due to the robustness of the hue channel to lighting differences caused
by clouds or different angles of the sun  the second important differentiating factor of different land
cover classes is texture   for instance  water and forest generally have a much smoother texture than
urban landscapes  texture information was extracted by filtering each tile with    gabor filters  gabor filters are linear edge detection filters that have been proven to perform well for the purpose of
texture extraction in satellite imagery       after filtering  the mean and variance of each of the   
tiles was extracted as an indicator of the occurrence of the respective edge type in the tile  yielding
   features  lastly  the rapideye images also feature near infrared and red edge bands  chlorophyll
absorbs red edge light and reflects near infrared light      thus  another     features were dedicated
to two    bins histograms of the red edge and near infrared bands of the rapideye imagery 

 

methods and metrics

the methods and metrics used in this project are briefly explained in the sections below  our input 
a tile  is represented by x i    and its corresponding label is given by y  i    where i              m 
 we have m examples   here  x i   rn and y  i   r  let y  i  represent the predicted class from
our algorithms 
   

methods

logistic regression is a binary classification model  y  i           that assumes a hypothesis
 
h  x    g t x      e 
t x           the cost function to be minimised using gradient descent is given by the following  where the first term is the likelihood of the data  and the second is
the regularisation term 
m
x
 
l    
 y  i  h  x i          y  i       h  x i          p  
   
c
i  

 

fione vs rest classifiers  both models described above are binary classification techniques  however  we face a multi class problem 
this is addressed by training k models for a kclass problem where the ith model is given by
wi   and f  wi   x  is a measure of how likely it
is that an example belongs to the ith class  prediction is done in the following manner 
y   argmaxi     k f  wi   x 

   

random forests is a supervised ensemble figure    example of a tile filtered with four gamethod based on decision trees  a decision bor filters of different orientations 
tree divides the feature space into distinct  nonoverlapping regions  that are then used to predict the class of an input sample  growing a decision
tree for classification involves making recursive binary splits  where every split tries to minimize
the classification error rate of the tree until a specified depth or until every leaf is pure  fully grown
tree   random forests build a number of decision trees from new datasets that were sampled with
replacement from the original one  bootstrapping  and predict a class by taking the trees majority
vote  they also restrict the features considered in every split to a random subset of a certain size 
   

metrics

accuracy and error are given as follows 
m

accuracy

 

  x  i 
y    y  i 
m i  

   

error

 

   accuracy

   

precision and recall  for the k th class  precision and recall are given as
pm
 i 
  k    y  i    k 
i     y
pm
p recision  
 i    k 
i     y
pm
 i 
  k    y  i    k 
i     y
pm
recall  
 i    k 
i     y

 

   
   

experiments  results and discussion

we ran our experiments with the implementation of methods done using scikit learn     and
other python libraries  in most cases  all the features were used  colour and infrared spectra histograms and gabor filters  unless otherwise stated 
   

logistic regression

we began with implementing logistic regression with l  regularisation  this was our baseline
model  we trained our models on     of the total data  which comprised        images and  
classes  when we trained with all the possible features  we got a training accuracy of        and
a validation accuracy of        the learning curve associated with logistic regression is shown in
figure  b which demonstrates that this model has a high bias  we thus turned to a more flexible
model  random forest  rf  
   

random forests


the first random forest  rf  model  using     trees and a random subset of           features
considered at every split  gives us an excellent validation accuracy of        the learning curve
is shown in figure  a  demonstrating that the training error is    with a validation error of      
implying that this is a high performing  high variance model  the confusion matrix obtained from
 

fi a  learning curve for random forest model

 b  learning curve for logistic regression

figure    different measures for feature importance

figure    precision recall values for the different classes in the validation set 

figure    confusion matrix for random forest
validation set 

 a  variable importance found from our rf model b  drop in error as features are added sequentially in our rf model

figure    different measures for feature importance

this classification is shown in figure   and a plot with the corresponding precision recall values
for each class is given in figure    we find that herbaceous areas  or grasslands  are most often
misclassified  they are often confused with shrub or cultivated land   two very similar types of land
cover  even to the human eye 
we further tested the importance of the three sets of features  colour histograms  infrared histograms
and gabor filters   the same rf model was trained on the same tile data  but the different feature
sets were successively added  this gives us figure  b  demonstrating that all three sets of features
contribute significantly to the overall accuracy  this is further backed up by the importance of
different features extracted from the rf model with all three sets  which is shown in figure  a 
 

fi a  an original satellite image from rapid   b  the original image overlaid with our preeye
dicted class  using our rf model  

figure    this can be done for satellite images across the world 
by looking at misclassified tiles  we find that many incorrect classifications involve a disparity between the nlcd dataset and the recently taken rapideye images  an example is shown in figure   
there are a number of hyperparameters to tune  and
after computing validation errors for varying depth
of trees  number of trees and number of features per
split  we find that the best model has the following
hyperparameters      fully grown trees and     features per split  the final test error achieved is      
this shows that we have trained a model that generalises well 

 

conclusions and future work

in this project  we obtained high resolution satellite
images and predicted their land cover  we explored
a number of features related to colour  infrared reflectance and texture  and found all of them to be
relevant  random forests outperformed other models  achieving an accuracy of       on the test set 
figure    the image taken november   th 
      depicts the yolo bypass located in the
sacramento valley  the red box indicates
a tile  that our algorithm classifies as water  but the nlcd dataset says is cultivated
land  according to wikipedia  the entire bypass forms a valuable wetland habitat
when flooded during the winter and spring
rainy season  in the summer  areas of the bypass are used for agriculture       this is a
good example for a seasonal change that is
correctly detected by our algorithm  but not
by the nlcd dataset 

in the future  we would like to improve the granularity of our algorithm  by classifying images on a per
pixel basis  this would help us achieve long term
goals such as creating land cover databases for countries where this hasnt been done before  this would
be achieved in a fashion similar to figure    we also
want to look at temporal differences between images  which would enable the identification of illegal
deforestation and the tracking of urban land growth 

 

fireferences
    james richard anderson  a land use and land cover classification system for use with remote
sensor data  volume      us government printing office       
    blackbridge  the rapideye red edge band   online  accessed    december       
    daniel l civco  artificial neural networks for land cover classification and mapping  international journal of geographical information science                    
    rs defries and jonathan cheung wai chan  multiple criteria for evaluating machine learning
algorithms for land cover classification from satellite data  remote sensing of environment 
                   
    pall oskar gislason  jon atli benediktsson  and johannes r sveinsson  random forests for
land cover classification  pattern recognition letters                     
    collin homer  jon dewitz  limin yang  suming jin  patrick danielson  george xian  john
coulston  nathaniel herold  james wickham  and kevin megown  completion of the     
national land cover database for the conterminous united statesrepresenting a decade of land
cover change information  photogrammetric engineering   remote sensing               
     
    c huang  ls davis  and jrg townshend  an assessment of support vector machines for land
cover classification  international journal of remote sensing                     
    t kavzoglu and pm mather  the use of backpropagating artificial neural networks in land
cover classification  international journal of remote sensing                        
    planet labs  planet explorer program        url  https   www planet com explorers  
     shawn newsam  lei wang  sitaram bhagavathy  and bangalore s manjunath  using texture to
analyze and manage large collections of remote sensed image and video data  applied optics 
                   
     mahesh pal and paul m mather  an assessment of the effectiveness of decision tree methods
for land cover classification  remote sensing of environment                     
     f  pedregosa  g  varoquaux  a  gramfort  v  michel  b  thirion  o  grisel  m  blondel  p  prettenhofer  r  weiss  v  dubourg  j  vanderplas  a  passos  d  cournapeau  m  brucher  m  perrot  and e  duchesnay  scikit learn  machine learning in python  journal of machine learning
research                    
     wikipedia 
yolo bypass  wikipedia  the free encyclopedia       
https   en wikipedia org wiki yolo bypass 

url 

     yi yang and shawn newsam  comparing sift descriptors and gabor texture features for classification of remote sensed imagery  in image processing        icip         th ieee international conference on  pages           ieee       

 

fi