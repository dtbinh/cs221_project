predicting optimal game day fantasy football
teams
glenn sugar and travis swenson
department of aeronautics and astronautics
stanford university
gsugar stanford edu  swens    stanford edu

 

introduction

the popularity of fantasy sports has exploded in recent years  websites such as draft kings and
fanduel offer weekly competitions where people pay to build a fantasy team under a salary constraint for the chance to win money  each team must have one quarterback  qb   two running backs
 rb   three wide receivers  wr   one tight end  te   one kicker  k   and one team defense  d  
while machine learning has been applied to fantasy sports prediction  very little has been published
as these algorithms are usually proprietary      the goal of this project is to use machine learning
techniques to obtain positive expected returns when playing these games  in order to do this we
break our project into two parts  the first uses machine learning algorithms to predict the number
of points any given player will score in a given game  while the second uses convex optimization to
assemble teams with maximum expected return and minimum risk 

 

dataset and feature selection

in order to accurately predict the performance of every player  we naturally considered their individual histories  however  it is also important to consider the history of their opponents  as a player
is more likely to have a good game against a poor defense than against a good defense 
injuries also play an important role in predicting a players performance  if a star defensive player
is injured  the opposing teams offense is likely to perform better  if a wr is injured  other wrs on
the team might see more targets and their projected points might increase while the qbs projected
points might decrease  we quantify the impact of an injured player by creating features that contain
the total game averaged stats for all injured players  for example  if two wrs are injured and they
have averaged    and   targets per game respectively  all of their teammates would have    for the
injured targets feature 
we used the urllib and beautifulsoup python libraries to access and parse the data on pro footballreference and rotoworld for every game that active players have played since      and recorded
their performance  the injured players  and the opposing teams average performance        this
resulted in over    statistics for every active players performance in every game played since      
the statistics were grouped into   basic feature types  career features  current features  and recent
history  career features consist of running averages of player performance metrics over their entire
career  e g  average rush yards per game   current features give information about the game we are
trying to predict  e g  home vs away   recent history consists of performance metrics of the player
and their opposition in the n most recent games  e g  rushing touchdowns in each of the most recent
  games   this data could either be averaged or included as n individual features per statistic  we
then process the data so that each feature has zero mean and unit variance 
to select the optimal subset of features we used forward search selection to obtain the best feature
vector for each position  we also experimented with n  the number of games to consider in a players
recent history  n     gave the best results   we considered several machine learning algorithms 
 

fisee section    but found the optimal features were relatively insensitive to the machine learning
algorithm used  an example set of features selected using our forward selection algorithm is given
in table   
table    features selected for rb using forward search  colored boxes indicate the features used
for each feature type 
recent history

current game

career

fd points
targets
rush tds
receptions
reception tds
injured rush attempts
injured pass attempts
injured targets
defensive turnovers
game location
defensive points allowed
defensive rush yards allowed
opposition offensive points

 

model selection

initially we tried to train a hypothesis for each player individually  in the hopes of achieving the most
accurate predictions possible  unfortunately this resulted in high variance  and we were forced to
abandon this approach  instead we grouped the players by position  thus generating six hypotheses
for the six positions of the fanduel team  training and testing sets were created by randomly dividing every game played by every player into     training examples and     testing examples  where
a train test example is a single game  we experimented with many machine learning algorithms using the scikit learn python package and found ridge regression  bayesian ridge regression  and
elastic net gave the lowest root mean squared error  rmse      
   

ridge regression  rr 
minimize  xw  y         w    
w

   

the objective here is the same as linear regression  except for the addition of an l  penalty on the
feature weights  w  weighted by   we found        works well 
   

bayesian ridge regression  br 
p w     n  w      ip  

   

bayesian ridge regression is similar to ridge regression  however the weighting on the l  norm
is chosen based on the data supplied  thus it is more robust to changes in the feature vector  the
normalization coefficient is chosen using the assumed prior on w  given in equation   
   

elastic net  en 
minimize
w

 
     
  xw  y         w      
  w    
 m
 

   

en is similar to ridge regression  but includes an additional l  penatly  the parameters   and 
set the relative weights of the penalties  we found        and        works well 
 

fi   

bias vs variance
figure    test and training root mean squared error
 rmse  for the regularized
linear model using holdout
cross validation for rb     
of the data was used in the
test set 

in order to diagnose the role of bias and variance in our generalization error we ran our algorithms on
training sets of increasing size and recorded the resulting training and testing error  as can be seen
in figure    both errors converge to roughly the same value when using a large number of training
examples  indicating variance is playing a low role in our generalization error  instead  bias error is
limiting the performance of our algorithms  this indicates we must further improve our model in
order to reduce error 
   

final model selection

after running forward selection and using hold out cross validation  we selected the best models
and features for each position as given in table    for each position  we used the regressor and the
feature set  either all possible features or the features chosen by forward search  that gave the lowest
rmse for the test set used during cross validation 
table    the optimal model used for each position  note that limited features correspond to the
feature set selected in the forward search  while all corresponds to using all possible features 
regressor
features

 
   

qb
br
all

wr
br
limited

rb
en
all

te
br
limited

k
en
all

d
br
all

results
error comparison
figure    rmse comparison between our projections
and yahoos 

we evaluated the performance of our algorithms by comparing the rmse of our predictions with
the publicly available yahoo projections  yahoo is a multi billion dollar company that is active in
the fantasy football market  and therefore provides a good baseline for the state of the art in fantasy
 

fisports prediction  as can be seen in figure    our rmse values are only slightly worse for qbs 
wrs  and rbs               and      respectively   while we beat yahoo for te and k       
and       respectively   note that team defense is omitted due to difficulties in obtaining yahoo
defense projections  because our rmse values are so close to yahoos  and in some cases even
better  we consider our point predictor a success 
   

team optimizer

after computing the predicted points for every player  we can now construct the optimal team 
fanduel gives users a          salary to use when building a team of   qb    rbs    wrs    te   
k  and a teams defense  we can formulate the team selector as a binary linear program to pick the
team that will produce the maximum number of predicted points 
maximize f t x
x

subject to

xi          i              m 
ax   b

   

gt x  h
where fi is the predicted points for the ith player  xi indicates whether player i is chosen  b contains
the position requirements  aji indicates if player i plays position j  h is the maximum salary of the
team  and gi is the ith players salary given by fanduel 
many of the fanduel tournaments are structured such that the top     of entrants win a fixed prize 
and thus there is no incentive to do better than the winning threshold  in this case it makes more
sense to minimize risk  subject to the constraint that the winning threshold is met  fortunately 
fanduel published the average number of points required to win these leagues for the      season
        points       we use this threshold to solve the markowitz portfolio optimization problem
to construct a team with minimal variance     
the problem now becomes 
minimize
x

vt x

subject to xi          i              m 
ax   b

   

t

g xh
ft x  p
where vi is the variance of player i and p is the minimum number of total points for the team 
figure   shows the results from using both optimization methods on weeks     of the      season 
the team picked using equation   has a       winning percentage  while the minimum variance
team picked using p       had a       winning percentage  even though the sample size is small 
our point projections coupled with the team optimizer shows promise of providing positive expected
returns when playing fanduel games 
figure    the performance
of teams picked using both
optimization methods  maximum points and minimum
variance   the minimum
variance team was chosen to
have at least     total predicted points  the horizontal red line shows the average required points needed
to win a fanduel league 

fanduel points

optimized team performance
   
   
   
   
  
  
  
  
 

max points
min variance

 

 

 

 

 

week number

 

 

 

fi   

prediction improvement  clustering players

even with the encouraging results so far  it could be possible to improve our predictions by recognizing that there are subsets of players within a position  for example  some rbs are often utilized
as wrs  while others will rarely be targets for passes  by identifying and training on subsets of a
position  we should be able to lower our overall error and potentially beat yahoos prediction across
all positions  while we have not performed all of this analysis  we have investigated potential subsets in the wr and rb positions  note that this is a very preliminary analysis and there is much
work to be done 
because some players that are classified as wrs by fanduel are often utilized as rbs  and vice
versa   we looked for clusters within the wr rb set of players  first  we normalized the data to
have zero mean and unit variance for seven features per player  we then used principal component
analysis  pca  to extract the first   principal eigenvectors and projected the   dimensional rb and
wr scaled data onto the reduced   dimensional pca space  the left plot of figure     shows the
player classification used for our current predictions  and the right plot shows a new classification
using k means with k   
 

wr and rb before clustering

 
 
 
 
  

average rbs
star wrs
star rbs
backups
average wrs

 

pca dimension  

pca dimension  

 

  wr and rb k means clustring  k     

wrs
rbs

 
 
 
 

 

 

 

 

pca dimension  

 

  

 

 

 

 

 

pca dimension  

 

 

figure    initial wr and rb classification  left  and classification after k means clustering  right  
the dimensionality was reduced to   via pca for plotting purposes 
these plots have many interesting features  the distribution of wrs and rbs suggests that the xaxis roughly corresponds to a players receiving ability  while the y axis corresponds to their rushing
ability  the player with the largest x coordinate is odell beckham jr   and player with the largest
y coordinate is adrian peterson  these are arguably the best players at their respective positions 
the points around        correspond to both wrs and rbs that are not very active and have few
receptions and rushing attempts  these are mostly backup players  and their production is likely
to be affected by injuries much differently than a normal starter  this is because if a starter gets
injured  a backup player has a chance to start and have a drastic increase in points  whereas a starter
would not notice much of a difference if his teammate misses a game due to injury  because of these
differences  we can generate more effective subsets using clustering algorithms  furthermore  we
can do this without the risk of overfitting the models  figure   shows that we can reduce the training
sets by a factor of   without significantly increasing variance 

 

conclusion and future work

we have demonstrated a machine learning approach to predict fantasy football player performance
that is on par with state of the art methods  with our point predictions  we used a binary linear program solver to pick the optimum team given salary and position constraints  using these methods 
we obtained positive returns playing fanduel games in weeks     of the      season 
we also demonstrated a possible path to improve our point predictor by building models that use
player performance rather than their prescribed position labels  we used k means clustering to
obtain subsets of rbs and wrs that could produce better models than both yahoos and our current
predictor  more work needs to be done to explore the performance of new models that are trained
on the smaller player subsets  as well as how these subsets are generated via different clustering
methods 
 

fireferences
    dunnington  nathan  fantasy football projection analysis  honors thesis  university of oregon       
web   http   economics uoregon edu wp content uploads sites           dunnington thesis      pdf 
    pro football reference  sports reference llc   http   www pro football reference com   
    rotoworld  nbc sports digital   http   www rotoworld com teams injuries nfl all   
    pedregosa et al  scikit learn  machine learning in python  jmlr     pp                  
    gonos  david  fanduel nfl benchmarks  points to target in each contest type    aug       
web   https   www fanduel com insider            fanduel nfl benchmarks points to target in each contesttype   
    markowitz  harry  portfolio selection  the journal of finance                   

 

fi