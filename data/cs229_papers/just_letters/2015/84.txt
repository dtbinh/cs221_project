experimenting with algorithmic composition techniques

jessica kuo
jesskuo stanford edu

 

horia margarit
horia stanford edu

introduction

algorithmic composition  a form of artificial creativity  is not a new concept  music is arguably the most mathematical
art form in existence and since there has been music  composers have tried to develop processes to supersede the
human creative process  different structures were developed over time  notable examples include i  counterpoint in
the baroque era  which dictated strict rules for organized music writing  and ii  the ubiquitous sonata rondo form in
the classical era  which only supplied a high level structure for an overall piece 
pre computer examples that could be considered algorithms include the famous musikalisches wrfelspiel  musical
dice game  implemented by w  a  mozart  where the rolls of two six sided dice randomly selected small sections
of music that were then patched together to create a musical piece  this game was capable of producing       
                            different yet similar waltzes      music composition algorithms have evolved into three
main categories  i  aleatoric methods  e g  cage   ii  determinacy methods  where decisions over everything from
notes to dynamic markings were objectified to pre composed series and matrices of values  e g  schoenberg  webern 
and berg   and iii  stochastic methods  e g  xenakis  hiller   however  up to this point  the inputs still required manual
creative input from the composer 
   

motivation

in the computer age  researchers have employed markov models and artificial neural networks to further reduce the
level of manual input  the most notable software system was created by david cope  and is called experiments in
musical intelligence  or emi       emi uses a deconstruction method to first analyze existing pieces of music and
separate it into parts and then second  to recombine it into a novel musical composition in the same style  this and
other similar approaches have been criticized to only superficially manipulate or imitate the works of great composers
and often do not take into the more human aspects of music  such as spontaneous rhythms  harmonies  timbre  or
articulation  further  most only apply to intra genre mappings of musical sequences 
we intend to experiment with predicting the main key of a piece of music as well as the keys it may modulate to  in
music  modulation is the act of changing from one key to another within a piece  it adds interest by shifting the tonal
center  this may or may not be accompanied by a change in key signature  see figure     the structures and rules of
modulation vary greatly between genres and eras  with the exclusion of twelve tone and atonal music  knowing the
key a piece is written in is crucial for establishing tonality  which is the compositional foundation of all music  this
should assist us in overcoming some of the issues outlined above and help us further reduce the imitative processes
currently used in algorithmic compositions 

figure    excerpt from the third movement of mozarts piano sonata no      k      showing modulation

 

fi 

features

   

dataset

midi files carry event messages that specify features such as notation  pitch  and dynamics in numerical values  this
makes it easier for us to modify and manipulate music as data  another advantage of midi is that it is compact and
can be stored in a few kilobytes 
we selected     samples of music from the baroque and classical eras in midi format and manually loaded them
into fl studio  where we then checked them for accuracy and made edits wherever necessary  each sample of music
was then separated into its respective voices  e g    for keyboard fugues from the baroque era    for string quartets   
for certain keyboard pieces from the classical era where separating the data further beyond left hand   right hand may
impose sparsity  etc    this was a time consuming process as the harmonic lines oftentimes came very close to or even
crossed over one another  we ended up with a dataset of       samples 
   

features
 meta message key jk a  
 meta message time signature numerator   denominator   clocks per click   
notated   nd notes per beat   time   
 meta message set tempo tempo        time   
 meta message key signature key c time   
note on channel   note    velocity    time     
note off channel   note    velocity   time   
note on channel   note    velocity    time  
note off channel   note    velocity   time   
note on channel   note    velocity    time  
note off channel   note    velocity   time   
note on channel   note    velocity    time  
note off channel   note    velocity   time   

the above is an excerpt of features once again taken from the third movement of mozarts piano sonata k      after it
had been imported and converted in python  since the key signature by definition does not distinguish between major
and minor keys  we had to manually label the main key of each sample in our dataset for the purposes of error analysis 
the octave in which a certain musical note resides is irrelevant in evaluating the key and establishing tonality  therefore  to eliminate any extraneous noise that may result from notes that are spread out  we will normalize the note
data such that each musical note d is d  n mod     where n                        this is done so that our model will
recognize each note  whether high or low  as one of the    notes from middle c to b  after that  we will take the n
values and encode them as compressed sparse column matrices for input into our model 
the technical definition of our feature is outlined in section        
     

key

there are    major keys and    minor keys that music can be written in  the tonic note and chord of a piece of music
gives the listener a subjective sense of arrival and completion 
     

pitch

we represent the pitch of each musical note as a frequency data value d with respect to f   the frequency  where    
hz represents a concert a     


f
d           log 
    hz
 

fi 
   

methods
model

we have constructed a generative model defined by the process and parameters below  the random variable x denotes
the observed consecutive triplet of musical notes within any given sample with probability  and where x  i  is some
instantiation of x  encoded as a   of k columnar vector of dimension k with exactly one element of value   and all
other elements of value    further details are included in section      
                k    dirichlet   



fi
 i 
 i 
x  i  fi    x            xk  categorical    

 

 

k
k
y
y
 
j  
  


j j
beta   j   j
j  
k
y

 i 

xj

j

j  

   

deriving the conjugate prior

let x  categorical   with x i  being some instantiation of the random variable  encoded as a   of k vector such
that it is columnar with dimension k  has exactly one element of the value   with all other elements of value    this
allows us to write 






k
k
k
k
 i 
 i 
 i 
x
x
y
y
x
x
x
 i 
log j j    exp 
xj log j 
p x i       
j j   exp log
j j    exp 
j  

j  

j  

j  


this can be expressed in the general form of an exponential distribution  h x   exp  t t  x i     a   where
h x i          t   logt     t  x i      x i    and a       
 i 

now let   dirichlet   with any instantiation of the random vector  being a k dimensional vector of reals  such
that the j th element yields the probability of the categorical variable x taking on value j  the sum of an instantiation
of  is therefore always   
k
k
y
y
 
  
j  
j j


p      
beta   j   j
j  






k
k
k
x
x
y
  
  
log j j    exp   j     log j 
  exp log
j j    exp 
j  

j  

j  



k
k
x
x

  exp 
j log j 
log j    exp  t x
j  

j  

t

here  x    and  t   log    
now let us compute the joint probability using what we have derived so far 
m
m 



x
y

p x              x m          exp  t x
exp  t t  x i      exp  t x exp
 t t  x i   
i  

  exp 

t

x 

i  
m
x

  
 i 

t  x  

i  

  p    

m
x

i  

 
x

  p    

m
x

 i 

i  

 

 
 i 

t  x  

fibut observe that by bayes rule  the posterior p            x i              is proportional to the joint probability we just
calculated  they are in the same family and therefore  the prior and posterior are conjugate distributions  which makes
the prior a conjugate prior  note that updating the prior specifically amounts to the model updating its belief about
the distribution of  on every pass through of the data 
   

parameter estimates

we use the em algorithm on this model to compute the parameters of the latent variables 
     

e step
fi
fi

q  t    fi x i       p  fi x i     t  

     

m step
 t     arg max


 

m
k 
x
 fi

x
 i 
q  fi x i 
xj log j   j log j
i  

j  

conclusion

one of the biggest hurdles in our modelling came into play when we realized that our original dataset lacked the crucial
features for the learning algorithm we originally set out to build  the other big hurdle occurred when we attempted to
model the parameter of the categorical distribution over x as being dependent on the central key of the musical piece 
the dirichlet conjugate prior over the parameter of the categorical does not account for the hidden state  the central
key  when it updates the frequency counts for the  parameter  this entails that our model and em algorithm will
converge on the maximum incomplete log likelihood that satisfies any central key  intuitively  this maximum is less
than the maximum that would have been obtained if it were conditioned on the central key 
our current remedy to this problem is to use the fact that we arduously labelled the central keys of     musical pieces 
which enables us to group the labelled musical pieces by central key  then we could plate the graphical model  see
section       such that we run one instance of the model on each group of musical pieces  the end result  and the goal
of this entire endeavor  is to use em and bayesian inference to learn the optimal probability distribution of musical
notes  given a particular central key of the musical score  to conclude  this endeavor provides us with the ability to
run the model on data which is unlabeled and to select the central key under which the observed data is most likely 

 
   

appendix
deriving em
m
m z




y
y
 i 
log
p x
  log
p x i       
i  

i   
m z
y

 
p x i       

  log
q    x  
q    x i 
i   
 
z
m
 i 
x
p
x
 

 


 
log
q    x i   
q    x i 

i  
 
   
m
x
p x i       

 
log eq    x i   
q    x i 
i  
 
 
m
x
p x i       


eq    x i    log
q    x i 
i  
 

 i 

fi

the inequality above results directly from jensens inequality  setting q    x i     p    x i     results in equality
     we therefore have a lower bound on the incomplete log likelihood that is given by 

m
m z


y
x

p x i       
  log
p x i 
q    x i  log
 i 
q  x
i  
i   
by recognizing that the denominator of the term inside the log is not a function of any of the parameters  as it is held
constant during the m step  the overall expression to be maximized during the m step therefore reduces to 





z
m z
m
k
k
 fi


 x
 fi

x
x
x
 i 
q  fi x i  log p x i      p      
q  fi x i  log exp 
xj log j  exp 
j log j 
i  



i  

 

i  

j  



m z
x

 fi
q  fi x i 



k 
x

 i 

xj log j   j log j

j  



j  

since we will be taking the derivative with respect to   the integral cancels out and we end up having to maximize 
m
k 
 fi
x

x
 i 
q  fi x i 
xj log j   j log j
i  

j  

references
    zbikowski  lawrence m          conceptualizing music  cognitive structure  theory  and analysis  pp           new york 
oxford university press 
    cope  david         computer models of musical creativity  cambridge  ma  mit press 
    midi manufacturers association  midi tuning specification  retrieved from http   www midi org techspecs 
midituning php 
    ng  andrew         cs    lecture notes  the em algorithm  retrieved from http   cs    stanford edu notes 
cs    notes  pdf 
    marxer  ricard   purwins  hendrik         unsupervised incremental learning and prediction of music signals  sydney 
australia  isma 
    kosta  k   marchini  m    purwins  h          unsupervised chord sequence generation from an audio sample  porto 
portugal  ismir 
    marchini  marco   purwins  h          unsupervised generation of percussion sound sequences from a sound example  in
sound and music computing conference  vol       

 

fi