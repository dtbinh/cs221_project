machine hound   creating an artifical nose
jacques de chalendar  marguerite graveleau  clement renault
mentor  youssef ahres
december     

introduction

ertheless  neural networks might prove very efficient
on this kind of problem  and it could be interesting to
compare several techniques 

will a machine be able to follow an olfactory trail 
that is  after learning an odor  is a computer able
to recognize it  and predict the variation of its concentration  this challenge is offered on the website
tunedit org    with associated data 

this problem is analogous to invariant object recognition in clutter and background  however  in our
setting the object is a chemical signature detected by
the activation of an array of olfactory sensors across
which each odorant produces a distinct pattern 

the dataset represents object recognition in the olfactory domain  the testing data comprises the activity
of a simulated gas sensor traversing an environment
containing multiple odorant sources  as well as a persistent background odorant  in the training data the
sensor is traversing the environment with just one odorant source present in isolation at a time    the model
will have for objective to learn the signature of that
object during training  which is learned in mixture
with a background odorant that is different from the
background that will be present in testing   this task
is analogous to the capability of biological systems to
learn the smell of an object in one environment  and
recognize it in multiple different contexts 

an interesting application of this project would be the
application of sensory networks trained by this data to
enable neural sensorimotor control of the agent in the
virtual worlds 

 

study of the data

before conducting any regression or machine learning
algorithms  we want first to have a long look at the
data  and study its shapes and main variations 

the training datasets are comprised of values representing sensor activation  input features  and odorant
concentration  output  at      different timepoints 
the test is repeated for another machine  with the
same odor environment but with different sensors  
during the training recording  only one odor is present
at a time  with a noisy background  the response of
the sensors to a time varying concentration signal is
recorded for each odor  the testing set however  includes all   odors  the main challenge is therefore not
to classify each odor  but to be able to recognize the
concentration of each  we want to start off by trying
machine learning techniques taught in cs      nev 

   

output variables   concentration of
odorant

the output variables are the concentration of each
odorant  and the concentration of a background odor
signature  during the training recording  each odor is
present  but one at a time with the background  figure
 a   however the testing data is a mixed signal of all the
odors  figure  b   we have two sets of training testing
sensor activation  for two different machines which are
named t   and t    they are trained on the same
odor environment 

 jdechalendar stanford edu 

mgravele stanford edu  clementr stanford edu
http   tunedit org challenge artificialolfaction
  video demonstration  https   www youtube com watch v kcce  ompa 
  website 

 

fimost correlated with the response variables are also
correlated together  visually the shapes are extremely
similar and more specifically correlation of these sensors readings are greater than        it seems that
correlations are associative in this dataset 

 a  training set

it seems normal that some sensors are highly correlated  indeed they are activated by some kind of chemical molecules  if molecules specific to two sensors are
close to each other  these sensors will tend to be activated at the same time  however  with correlation
of almost    having those two features is not effective
for our model  it could be interesting later to consider
feature selection  forward or backward  which is likely
to only retain one of those highly correlated features 

 b  test set

figure    concentration profiles

   

activation of sensors

figure   describes the typical response of some of the
sensors to the training odors  some of the sensors seem
to have all or nothing type behaviors while others follow the odor concentration signal 

figure    activation of some of the sensors in t  
during the training

figure    correlation plots for odor  

 

as we can see in figure    we plot the signal from
   randomly chosen sensors   the activation of each sensor can almost be seen as binary  in presence of some
odors  they will or will not go above a threshold  which
is the same for each of them   however  they are mostly
not specific of only one odor  this kind of activation
behavior could lead us to try to implement a neural
network method later 

 a  training set

establishing a baseline

this preliminary work was done using r 

   

linear regression

we first applied simple linear regression to the training
set  in this model  each of the odor concentrations is
predicted separately using all the sensor signals as features  predicted versus true values are given in figure
  for odor    the results are similar for the other odors 

 b  test set

figure    sensors on the t   machine

   

figure    base case linear regression for odor  

correlation of sensor readings with
odor concentration

   

this study is mainly made using r  code is in appendix   in figure   we plot the activation of the  
sensors the most correlated with odor   in function of
the concentration of odor    we see that the   sensors

forward selection on  st order interaction terms

scott  james and ali  data analysis for electronic nose
systems  microchim acta                     give a
 

fireview of techniques used to analyze data from electronic nose systems  they emphasize that this problem
is ripe for the application of feature extraction techniques  there are     sensors in our dataset  a quick
look at the data shows that there are    duplicate
sensors  both in the training and test data sets   in
our preliminary modelling  we rejected the duplicate
sensors  other than that  we used the signals from the
sensors as features directly  we then moved on to trying to reduce the number of features we use as inputs 
using a forward selection algorithm 

this new model  just like we had done with the first
linear regression in      by comparing the regression in
figure  a and  b it is clear that feature selection leads
to much more accurate model  the spread around the
first diagonal is very low in this new model  indeed
comparing mean absolute error  mae  between the
model from      which has an mae of          and
the model with feature selection  which has an mae of
         we see that the mae has nearly been divided
by   

   

we performed this analysis for the concentration of
odor    the main findings here are that the interaction
terms seem to be important  indeed  if we consider
as features the input signals and first order interaction
terms between the signals  and apply forward stepwise
selection  we notice that out of the     first features
that are selected only   are sensor signals  all the others being interaction terms  this makes sense if we
consider the odor from a chemical perspective  the
chemicals activate the sensors  and looking at combinations of sensors tells us which chemicals were present 

although these results are very encouraging  one has
to keep in mind that the actual test set will be comprised of a background odor  and a combination of the
  odors  whereas the training and validation sets are
only comprised of the background odor  and one odor
at a time  this means that a combination of sensor
activations from different odors simultaneously present
may pose a bigger challenge to our models 

 

we plot the bic obtained for each model against the
number of features in the model in figure  c  we observe a u shaped curve with a minimum at     features
 we initially started with no feature and added one at a
time so that the extended model is as good as possible  

 a  base case

limits

reducing dimensionality
the input space

   

of

principal components analysis

the importance of interaction terms lead us to try out
a principal component analysis  we observe that indeed only the first   pc vectors explain more than    
of the variance 
by plotting the first   principal components we
can see that one seem to be specific of the bacjkgournd  and the   next are each specific of one odor 

 b  after forward selection

figure    variance explained in function of the
number of principal components

 c  bic curve for the forward
selection analysis

figure    linear regression results
once we found the best model using feature selection we predicted the concentration of odor   using

 a  training set

 b  test set

figure    plot of the first   pc in function of time
 

fi   

 

linear regression models on the
first principal components

   

independent components analysis

this problem is analogous to invariant object recognition in clutter and background  and called for an
independent component analysis with the   first principal components as inputs  we normalize our data   in
this particular study  lets notice that we dont use the
information of the output  the actual concentration  in
the training set  in order to get better results  we train
our model on shuffled data  we go through the data
randomly and not in function of time 

figure     classification using logistic regression

   

using the predictions

from the ica we can get the signal profiles  but since
ica is ambiguous with regards to the order of the
sources  we do not know which is which  using predictions from this model allows us to match the signals 

the assumption we are making in this model is that
the first   pcs are linear combinations of the odor
concentrations 

 
   

 a  training set

training a model

the problem can also concern only determining which
is the predominant odor  by opposition to outputting
each individual concentration of odorant   by training
a logistic regression on     of the dataset and validate
it n the reminder we obtain less that    on the classification error  figure    drescribes the results   the first
bar separates the data of he training from the data on
which we test the regression  the second bar gives the
output classification  

running a linear regression only on these   pc reduces
the dimension of our input by a factor of     and only
increases the mean squared error from       to       

   

predicting the dominant odor

possible future work
additional pre processing

applying further data pre processing techniques could
provide better results  ideas from the scott et al  paper mentions hierarchical clustering analysis for example  additionally  one of the difficulties of our data set
is the presence of a background odor  and the fact that
this background will be different in the training set 
so simply removing the background when training will
probably not be a great help  a baseline substraction
of the sensors could help us however 

 b  test set

figure    ica results   plot of the   sources in
function of time
for the training we clearly observe   trends specific
of each odor  it is not as clear on the testing set  however  by having a closer look  we can see that peaks
are well positioned   for example the orange curve here
represents the green odor of the testing set  it reaches
its maximums at the same time  and always varying the
same  increasing when the concentration increases   in
order to follow a trail we only need to capture the
variations of concentration  nevertheless  the relative
concentration of odorant are wrong  it may come from
the normalization of our data  but without it the results
are not conclusive 

   

time dependence of the signals

one aspect of the problem we have left to the side until now is the fact we are considering time series  we
have been considering that the concentration of each
odor can be predicted using the information from the
sensor array at the same time step  in the test set  the
variables are continuous  and a markov chain approach
could prove very efficient  note that this sort of time
dependence should be treated with caution  however  as
we could be looking at data where the sensor array is
 

fibrutally taken from one environment and plunged into
another 

   

selection or pca  is well adapted to our data because sensors share a lot of information and are
correlated by nature

neural networks

 after selecting the first   principal components
of the data  using an ica approach allows us to
recover signals that are visually close to the original ones  to resolve the inherent ambiguity of
ica  we dont know which odor is which   using
logistic regression type methods to identify the
dominant odor seems to work pretty well  the
main remaining weakness of this approach is that
the output signals are normalized and we lose the
possibility of predicting an actual concentration
value  depending on the exact nature of the problem we are trying to solve  however  this may not
actually be limiting 

given the shape of the activation of each sensor  being
activated or not by some odors  we would expect a neural network approach to give good results  this data
set actually comes from a challenge aiming to compare
the performance of ml algorithms against neural networks  we tried to rapidly implement a neural network
   hidden layer     neurons   and got good results on
the training set  but again on our testing sets the results were not conclusive  however our neural networks
model was very simple  and called a for further work 
one of the major difficulties of the data set seems to
be that the test set is very different from the training
set  not only in the shape of the signals but also with
regards to the background odor 

 the test set appears different from the training
set in two ways   a  the odors are mixed together
rather than separate  and their concentration is
often below that of the background  and  b  the
background odor is different  the second is one
of the constraints of the problem  however  using
acquiring a training set closer to the test in the
shape of the signals could help make predictions
on the test set 

conclusion
 simple linear regression models seem to give
pretty good results on a test set drawn randomly
from the training set
 dimension reduction techniques  through feature

 

fi