cs     machine learning  autumn          

predicting default risk of lending club loans
shunpo chang

simon dae oong kim

genki kondo

stanford university
shunpoc stanford edu

stanford university
simonkim stanford edu

stanford university
genki stanford edu

abstract
lending club is a peer to peer lending company  the largest of its kind in the world with       billion originated loans  it is an online
lending platform where borrowers are able to obtain loans and investors can purchase notes backed by payments based on loans  in this
paper  we will attempt to predict the expected returns for loans to a given borrower  since a loan default will result in a loss of both
principal and interest  we will attempt to maximize our returns by predicting the probability of default of the borrower so as to help avoid
investment in those high risk notes 

i 

introduction

he   year u s  treasury bond yield hovers below     so
lending club offers an attractive alternative to bonds
for steady investment income  lending club offers
loans of various grades they assign that correspond to specific interest rates for investors  the higher the interest rate 
the riskier the grade  the risk comes in the form of defaults whenever a loan defaults  investors end up losing a portion
of their investment  we believe that there is inherent variation between loans in a grade  and that we can use machine
learning techniques to determine and avoid loans that are
predicted to default 
the lending club dataset contains a comprehensive list
of features that we can employ to train our model for prediction  the dataset includes detailed information for every
loan issued by lending club from      to       including
a borrowers annual incomes  zip codes  revolving balances 
and purpose for borrowing  we will train and test a range of
models in an attempt to identify the best performing model 

t

the difference in types of model that they focus on  the prior
studies only used the out of the box dataset from kaggle or
lending club  but research like  the sensitivity of the loss
given default rate to systematic risk      has shown the linkage between default rate and macroeconomic factors  so we
have decided to add in census data  with info like regional
median income  to train our models on a more holistic set of
features 

iii 

data

the raw lending club data contains    fields for each loan
originated  however  not all of the fields are intuitively useful
for our learning models  such as the loan id and the month
the last payment was received  and thus we removed such
fields  we also removed fields for which greater than     of
the loans were missing data for  categorical features  such as
address state  for example  california   were expanded into
boolean columns  one column for each distinct value that the
feature could take  finally  we removed any loans that were
missing data for any field  around    of the loans in our
dataset  
ii  related work
to label the dataset  we classified any loan that defaulted 
prior projects like  predicting borrowers chance of defaulting were charged off  or were late on payments was classified
on credit loans      have set great examples of applying ma  as negative examples  while we classified any loan that was
chine learning to improve loan default prediction in a kaggle fully paid or current was classified as positive examples 
competition  and authors for  predicting probability of loan
default      have shown that random forest appeared to
iii i  feature expansion
be the best performing model on the kaggle data  however  despite of the early success using random forest for the lending club data contains a few fields which are not
default prediction  real world records often behaves differ  immediately usable in learning models  namely zip code and
ently from curated data  and a later study  peer lending loan description  since there are many zip codes  expandrisk predictor      presented that a modified logistic regres  ing them into boolean columns as we did for categorical
sion model could outperform svm  naive bayes  and even features will not be effective  instead  we joined census
random forest on lending club data  the fact that logistic data with the lending club data  the description of the
regression performance could be immensely improved by loan contains freeform text input by the loan requestor  and
simply adding penalty factor on misclassification gave rise to thus may contain keywords that correlate with defaulting or
our interest in fine tuning other not yet optimized models  in non defaulting loans 
particular  svm and naive bayes  to continue the search for a
for census data by zip code  we use the  median housebetter predictive model in the realm of loan default  besides hold income and mean household income             
 

fics     machine learning  autumn          

dataset      the dataset contains mean income  median income  and population by individual zip code  the lending
club data contains the first three digits of the zip code for
each loan  thus  we calculated a population weighted mean
and median for each three digit zip code 
for loan descriptions  we use tf idf  tf idf allows us
to determine any important words in each loan description
while taking into account the number of times a word appears in the corpus so that words that occur frequently in
general are weighted lower 

t f  t  d    f t d
id f  t  d     log

n
  d  d   t  d  

where tp is the number of true positives and fn is the
number of false negatives  sensitivity is the fraction of loans
that are actually positive  non default  that were predicted
as positive by the model  since the more positive skewed
the dataset the higher the sensitivity  we also need to look at
specificity  defined as 
specificity  

where tn is the number of true negatives and fp is the
number of false positives  specificity is the fraction of loans
that are actually negative  default  that were predicted as
negative by the model  in order to combine both sensitivity
and specificity  we will use the g mean     
g 

t f id f  i  d  d     t f  t  d   id f  t  d  
t f  t  d   or term frequency  is equal to the number of times
term t occurs in document d  id f  t  d    or inverse document
frequency  is equal to the log of the total number of documents divided by the number of documents d in the set of
all documents d that contains the term t  the tf idf score is
the product of the term frequency and the inverse document
frequency 
before running tf idf on the loan descriptions  we
removed any punctuation and html tags  tokenized and
stemmed the text using the porter stemming algorithm 
then removed any english stop words  we split the corpus into two groups  one for defaulting loans and one for
non defaulting loans  for each group  we determined the
unique words across all descriptions  calculated the tf idf
score for each word for every document  then summed up
the scores  since we are looking for terms that occur in either
defaulting or non defaulting loans but not both  we normalized the tf idf scores for each group and chose words with
the highest absolute difference in the normalized tf idf
scores between the two groups  the top   words were  bills  
 business   and  card   we chose the top    words  then created binary features for each of the words indicating whether
that word is present in the loans description 

iv 

methods

tn
tn   fp

p

sensitivity  specificity

also  for completion of performance metrics  we also
looked at accuracy and precision 
accuracy  

tn   tp
n

precision  

tp
tp   fp

to establish performance  we train each model with the
first     of the loans and test the trained models on the last
    of the loans in our dataset 
after selecting the best predicting model based on specificity performance to optimize the detection of high risk
loans  we will calculate return on investment  roi  by 
roi  

total payment received by investors
 
total amount committed by investors

v 

logistic regression

we try modeling with logistic regression with newtons
method to learn more about the data features and get the
basic performance of our prediction  to first get boundaries
of iterations needed for newton as well as understand predictive contribution from each data features  we trial trained
with a logistic classification on all features 

given an imbalanced dataset  such as the lending club
dataset where the rate of positive examples is about     
accuracy does not indicate the true performance of the model 
the accuracy will depend on the overall default rate of the
test data set  for example  in this case  a model that predicts
any example to be non defaulting would still achieve    
accuracy  furthermore  some models will bias toward classifications that occur more often  such as svm and logistic
regression  instead  we will look at sensitivity  defined as 
sensitivity  
 

tp
tp   fn

figure    training vs  test accuracy specificity by newton iterations

fics     machine learning  autumn          

the training and test converges to an optimal solution
within   iterations  and overall we reached a test accuracy of
      and a test specificity of       

specificity from       to       without hurting overall test
accuracy 
table    performance of logistic model with feature selection

v i 

bias vs  variance

to see how the logistic model can be further improved  we
ran a diagnostic by different sample size 

num newton
   iterations

accu
    

vi 

prec
    

sens
    

spec
    

g mean
    

naive bayes

we used a laplace smoothing factor of   and ran naive bayes
using gaussian  bernoulli  and multinomial probability distributions  for bernoulli naive bayes  where we require
boolean feature values  we binarized the features and values 
multinomial probability distributions take discrete feature
values  so we rounded any decimal feature values to the
closest integers 
table    performance of various naive bayes models
 a  training vs  test errors

distribution
gaussian
bernoulli
multinomial

accu
    
    
    

prec
    
    
    

sens
    
    
    

spec
    
    
    

g mean
    
    
    

gaussian naive bayes returns the most desirable performance on the test dataset  bernoulli and multinomial
significantly underperformed gaussian naive bayes 

 b  training vs  test specificity
figure    stats by training sample size

the test and training error converged quickly with a sample size           and we see that we may have a high bias
problem as increasing sample size still resulted in a     test
error  from the sensitivity chart  however  we see that sensitivity fluctuates with additional sample size  suggesting that
the default prediction might potentially benefit from filtering
on existing features even though test error has stabilized 

v ii 

vi i 

bias vs  variance

in order to determine whether we are seeing high bias or
high variance  we compare the training error to the test error
for each case of naive bayes 

feature selection

using ablative analysis on the logistic model  we found that
for prediction on default rate  specificity   the credit score for
the borrower is the most predicative of all features  followed
by borrower population  while interest rate has negative impact as the number was subject to sporadic adjustment from
lending club  and fields like loan description or borrowers
lower fico range  where there are a lot of zero values  would
worsen the default prediction  after we filtered out features
that decreased our test specificity  such as last fico range low
  installment  open acc  desc  int rate  we managed to bump

 a  gaussian nb training vs  test errors

in an effort to reduce the error rate for gaussian naive
bayes  an additional feature of median income by zip code
and descriptions was included in the dataset  the test error
for gaussian naive bayes decreased from       to        by
       however  specificity decreased from       to      
with the external dataset included 
 

fics     machine learning  autumn          

table    performance of gaussian naive bayes with external dataset

distribution
gaussian

vii 

accu
    

prec
    

sens
    

spec
    

g mean
    

support vector machine

since the training data is likely not linearly separable  and
not guaranteed to be separable even in higher dimensional
feature spaces  we will use l  regularization  soft margin
svm   for training data points   x  i    y i     the model is the
result of the optimization 

the baseline model is one which merely predicts every
loan to be non defaulting and will achieve an accuracy of
       which is the fraction of test data that are actually
positive  so we see that svm improves predictions 

vii ii 

bias vs  variance

we run svm with a linear kernel with variable number of
training examples  then compare the training error with the
test error to determine whether we are likely to be encountering high bias or high variance in our svm model with the
dataset that we have 

m
 
min w b   w      c   i
 
i   

s t  y i   w t x  i    b       i    i     i           m
we first normalize the features by scaling the values of
each feature to         using the same scaling factor for both
the training and test data  this is necessary to prevent features with greater absolute numeric values to dominate those
with smaller numeric values  also  since the kernel values typically involve the inner products of feature vectors  figure    training vs  test error for svm for various training set sizes
normalizing the values prevents numeric problems such as
overflows     
the test and training errors converge quickly relative to
the performance of an svm model depends on the ker  the number of training examples available  and the gap benel used  the parameters of the kernel  and the soft margin tween them is small  suggesting a high bias in the model 
parameter c  we will attempt to optimize each of these 
thus we will increase the number of features by expanding
zip code into census data  as well as identifying important
words in the loan title and description 
vii i  selection of kernel
adding median income  mean income  and population
fields
extrapolated from the zip code  we see a minute     
we investigate some commonly used kernels  linear  polyincrease
in precision and      increase in specificity  with
nomial  gaussian radial basis function  and sigmoid  and
all
other
performance metrics remaining the same  adding
compare performance  we used libsvm     with default
the
words
selected via tf idf as boolean features  we see
settings  c svc  c             of features  d       and
an
increase
across all performance metrics  including a     
trained the model with the first     of the loans and tested
boost
in
g mean 
the models on the last     of the loans in our dataset 

vii iii 

linear  k   x  z    x t z
polynomial  k   x  z       x t z      d
rbf  k   x  z    e   xz  

 

sigmoid  k   x  z    tanh x t z   d 

soft margin parameter

we experimented with different values of the soft margin parameter c  we ran linear kernel svm with c  
                             ultimately  we found that using
c     yielded the best performance 
table    performance of svm with various values of c

table    performance of svm with various kernels

kernel
linear
polynomial
rbf
sigmoid
 

accu
    
    
    
    

prec
    
    
    
    

sens
    
    
    
    

spec
    
    
    
    

g mean
    
    
    
    

c
   
   
   
 
   

accu
    
    
    
    
    

prec
    
    
    
    
    

sens
     
     
    
    
    

spec
   
   
    
    
    

g mean
   
   
    
    
    

fics     machine learning  autumn          

table    performance of svm with various optimizations

step
linear kernel
add features
tune c

accu
    
    
    

prec
    
    
    

viii 

sens
    
    
    

spec
    
    
    

g mean
    
    
    

results

from the comparison of each model  we found that naive
bayes with gaussian performs the best with default prediction        sensitivity   we speculate that naive bayes
with gaussian is slightly better than the other models for  
potential reasons 
 naive bayes model works well with independent feature sets      and the training features that we selected
are possibly either independent or have evenly distributed dependencies 

stock market or housing trend  so as to include more
macroeconomic factors into the models 
 not all default cases are the same  and some late payments could still be recovered later on  so instead of
a binary classification  multinomial predictions could
be employed to take into account the different types of
default so as to make a more granular prediction 

references
    liang  junjie   predicting borrowers chance of defaulting on credit loans  
    pandey  jitendra nath   predicting probability of loan
default stanford university  cs    project report jitendra nath pandey  maheshwaran srinivasan  
    tsai  kevin  sivagami ramiah  and sudhanshu singh 
 peer lending risk predictor  

 some of the key features that we used  like credit
scores and regional population  might be distributed in
gaussian  which would allow the gaussian assumption
model to perform better 

    caselli  stefano  stefano gatti  and francesca querci 
 the sensitivity of the loss given default rate to systematic risk  new empirical evidence on bank loans  
journal of financial services research                   

to get the final improvement on the return  we will calculate roi as mentioned in method section  for the current
return from lending club  the overall return received  including interest and late fee earned and principal recovered 
by all investors divided by their initial principal is       
and if we apply the model prediction to avoid investing on
the predicted to default note and calculate the return based
on only predicted positive loans  we can increase the return
of investment of the test set from       to over           
growth  

    university of michigan population studies center 
institute for social research  zip code characteristics 
mean and median household income  available at 
http   www psc isr umich edu dis census features
 tract zip index html  accessed december         

ix 

conclusion

from the comparison of multiple models  including logistic
regression  svm  and naive bayes and different fine tuning
mechanisms  we found that naive bayes with guassian performs the best at predicting default rate  optimizing specificity   and by applying our best performing model  we saw
that the investment return from lending club can potentially
grow by      some future work that could further improve
the prediction includes 
 svm has a degrading performance on highly imbalanced datasets       so we should experiment with
balancing the datasets as best as possible to improve
svm prediction 
 we see high bias problems across all models  so the
predictions could benefit from more features  such as

    m  kubat and s  matwin   addressing the curse of imbalanced training sets  one sided selection   in proceedings of the fourteenth international conference on
machine learning  morgan kaufmann        pp         
    chih wei
hsu 
chih chung
chang 
and
chih jen lin 
a practical guide to support vector classification        available at 
https   www csie ntu edu tw 
cjlin papers guide
 guide pdf
    chih chung chang and chih jen lin  libsvm
  a library for support vector machines  acm
transactions on intelligent systems and technology                     software available at 
http   www csie ntu edu tw  cjlin libsvm
    zhang  harry   the optimality of naive bayes   aa    
          
     he  he  and ali ghodsi   rare class classification by
support vector machine   pattern recognition  icpr  
       th international conference on  ieee       

 

fi