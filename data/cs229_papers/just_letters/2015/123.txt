from grayscale to color 
digital image colorization using machine learning
cris zanoci and jim andress
december         

 

introduction

image colorization is the process of adding colors to a grayscale picture using a colored image with similar
content as a source  colorization techniques are widely used is astronomy  mri scans  and black and white
image restoration  however  the colorization problem is challenging since  given a grayscale image  there is no
unique correct colorization in the absence of any information from the user  even though many implementations
require the user to specify initial colors in certain regions of the picture  our project focuses on automatic image
colorization without any additional input from the user 
in this paper we describe our attempt to solve this challenging problem  we take as an input a single
colored image to train on and a grayscale image of similar content which we will colorize  the algorithm begins
by creating a high dimensional representation of the textures found within the colored image  after training a
collection of svms on this input image  we then phrase the color transfer process as an energy minimization
problem  our approach strives to reconcile the two competing goals of predicting the best color given the local
texture and maintaining spatial consistency in our predictions 

 

related work

the idea of using machine learning to colorize images first became popular in the early     s  welsh
et al  began with an algorithm which transferred colors simply based on the value and standard deviation of
luminance at each pixel      although the algorithm runs quickly  the results we obtained by implementing their
method are far from optimal in that each prediction is purely local and that the feature space they are searching
over has only two dimensions  soon after  levin et al  took colorization in a completely different direction
with their reformulation as a global optimization problem over the image      unlike welshs technique  which
accepted a color image as training input  levins optimization algorithm accepted hand drawn scribbles of
color from the user which are then used as linear constraints for the optimization of a quadratic cost function 
this algorithm sought to label pixels the same color if they had similar luminance values  which is one of the
first examples of automatic colorization algorithms explicitly incorporating spatial coherency as part of their
classification 
irony et al  then improved the technique by incorporating a two phase voting procedure      in the first step 
pixels are independently colored based on their individual texture features  in the second  each pixels color
is replaced by a weighted majority vote over its neighboring pixels  the most confidently labelled pixels are
then fed into levins original algorithm as micro scribbles  noda et al  formulated the problem as bayesian
inference using a markov random field model of an image      this formulation naturally includes spacial
coherency considerations while computing the maximum a posteriori  map  estimate of the colors  finally 
one of the more recent takes on the colorization problem was presented by charpiat et al   on whose algorithm
ours is based      this technique involves solving an energy minimization problem  the details of which will be
laid out in section   

 

dataset and features

one key feature of our project is that it does not require a large corpus of training examples  rather  every
execution of our algorithm takes only one color image and one grayscale image as input  we used publicly
available pictures with a typical resolution of          pixels  although there is no constraint on the size of our
 

fiinput  because our algorithm will ultimately be applied to grayscale testing images  the features we extract
and learn upon must all be derivable from this type of image  in particular  none of the features can be based
on information from the color channels of the training input  thus  we attempt to match regions with similar
content in both images based on the similarity of the underlying textures in the luminance channel  in our
implementation  we use surf and fft descriptors to extract information about textures 
surf stands for speeded up robust features and was first introduced by h  bay et al  in           first 
it uses a blob detector based on an approximation of the hessian matrix to locate changes in the images
texture  these changes are associated with interest points  which identify the distinctive patters of the picture 
for every interest point  horizontal and vertical haar wavelet responses are computed in the sub regions of a
square centered at that point  these responses are then weighted and reduced to a lower dimensional space to
produce a     dimensional local descriptor  one important criterion for choosing surf is its invariance under
geometrical transformations  like scaling and rotation  thus the descriptor is consistent across different parts
of the picture and even across different pictures  moreover  computing surf features is relatively fast  which
allows us to apply it to all the pixels 
we also compute the fast fourier transform  fft  as part of our feature vector  fft represents the image
as a sum of exponentials of different magnitudes and frequencies and can therefore be used to gain information
about the frequency domain of our image  it is also useful for finding correlations between images because the
convolution function is similar to the correlation function     
for every pixel p in the training and testing images  we consider a        pixel window centered at p  the
dimension of the window was chosen so that it captures enough information about the neighborhoods of p but
doesnt slow down our implementation  by applying surf to this window and two blurred version of it  we
extract   surf vectors  which we then concatenate to form a     dimensional feature vector  to that vector
we add the     fft features as well as the mean and standard deviation of the luminance around p  we end
up with a     dimensional feature vector  which we further reduce to only    dimensions by applying pca 
although the dimensionality of the data has been significantly reduced  we found that these top    principle
components retain around     of the variance in the data  meaning that we are still able to richly describe the
image textures using this feature space 

 

methods

our colorization algorithm is as follows  we begin by discretizing the colors of the training image using
k means clustering  rather than running the k means over the three dimensional rgb coordinates of each
pixel  we instead convert the input images to the l color space  where l represents the luminance of a pixel
and    are the two components of its color  this space is specifically designed to match a humans perception
of color  which means that the centroids produced through clustering will represent a natural division of the
colors  for k means  we typically use    colors  by running our algorithm with various values of k  we have
found that using more than    colors does not improve the results 
next  we extract a feature vector at every pixel of the training image and use pca to reduce its dimension
as described in section    then we train a set of svms  one per discretized color  we use a one vs  all
classification procedure  which means that each svm predicts whether or not a pixel has its corresponding
color  to be less sensitive to outlier pixels  we employ    regularization 
x
 
min kwk    c
i
   
b w  
i

 i 

t  i 

s t  y  w x

  b      i   i              m
i     i              m

   
   

where c is a parameter that we can vary  we tried using two types of kernels  rbf and linear  and chose the
latter as it yields comparable results while also being significantly faster 
for testing  we read in the grayscale image  compute the feature vector at every pixel and project it into
the subspace determined by pca in the training step  at this point  it is tempting to simply run the svms
on each pixel and assign the color of the maximum margin svm  however  this would completely disregard
 

fithe spatial coherency element of image colorization  instead  we make the reasonable assumption that colors
are most likely to change where there are edges in the luminance channel of the image  we therefore use the
sobel operator to approximate the norm of the gradient of the luminance at each pixel  if we treat the image
as a graph with edges connecting pixels  then values computed by the sobel operator indicate how weakly a
pixel couples to its neighbors  after computing the svm margins and sobel edge weights at each pixel in the
training image  we feed all of this information into the energy minimization problem with cost function


x

sc p   p   

p

x
p qn  p 

kc p   c q k
  w p     w q     

   

here p is a pixel  n    represents a pixels eight neighbors  c   is the color chosen for a particular pixel  sc    is
the margin when the svm associated with color c is used to classify a pixel  and w   is the sobel edge weight
at a pixel 
although it seems like finding the color assignment which minimizes equation   would be difficult  in many
cases this problem is  in fact  np hard   we can use the boykov kolmogorov algorithm to efficiently compute
approximate solutions         this algorithm works by iteratively expanding the set of pixels given a particular
color by constructing a graph in which each pixel is connected to its neighbors  a node n  representing the color
being expanded  and a node n  representing all other colors  each with appropriate weights  by computing
a minimum cut of this graph  we are left with some pixel nodes connected to n  and some to n    but none
connected to both  we then expand the labelling so that the nodes connected to n  are given the color associated
with it and the others remain the same  this procedure is proven to converge to within a known factor of the
global optimum  and typically finishes in tens of seconds for images with          pixels 

 

results

one challenging aspect of this project is the fact that without additional constraints  the image colorization
problem does not have a unique correct solution  making it difficult to quantify the accuracy of our colorization 
this means that defining a metric to evaluate colorization results is of the utmost importance  we therefore
now describe the motivation behind our custom scoring function  first  note that in order to determine the
accuracy of a colorization  we must have access to the full color version of the testing image  because the
colors in the original test image are not discretized  it is impossible for our algorithm to reconstruct the image
with      accuracy  however  we can compute a best case colorization  in which the    channels of each
pixel in the full color test image are replaced by the values from the nearest of the    colors selected from the
training image  for each pixel pi   we then compute the norm of the difference between our colorization c pi  
and this best case colorization c   pi   in l space  the final score of a colorized image is the sum of these
norms divided by the number of pixels m  so that we can compare the scores across images of different sizes 
m

score  

  x
kc   pi    c pi  k
m

   

i  

a score of zero would indicate
that our colorization is as accurate as possible with respect to the original image 

whereas a score of             is the worst possible score  we choose to define our score function in this
way  in terms of the best case colorization  since it involves measuring our performance against an obtainable
goal 
having thus defined our score function  we are able to quantize the results of our colorization algorithm 
figure   shows our colorization results on two images drawn from the pasadena houses dataset  the colorization
shown in   b  received a score of      and the one in   e  received       figure   a  shows how the  parameter
in equation   impacts the score of the colorized image  if  is too low  the dominant term in equation   is the
right hand spatial coherency term  meaning that the algorithm tends to assign the entire image the same color 
if  is too high then the left term dominates  meaning that we lose spatial coherency and will have random
patches of color  we see that an  value around    seems to produce optimal results 
figure   shows another set of results from our algorithm  note that   c  demonstrates a colorization of an
image using the same image as the training data  understandably  this test achieves the lowest score weve seen
 

fi a 

 b 

 c 

 d 

 e 

 f  

figure    colorizations of house images   a  original image of first house   b  results from training on d and
testing on a   c  the accuracy of the predicted colors in b   d  original image of second house   e  results
from training on a and testing on d   f   the accuracy of the predicted colors in e 

 a 

 b 

figure    graphs demonstrating the effect that the  parameter in equation   has on the score of a colorization 
note that both graphs show that a value from    to    is optimal   a  the impact of  on the score when
colorizing figure   a    b  the impact of  on the score when colorizing figure   a  

 

fi a 

 b 

 c 

 d 

figure    colorizations of landscape images   a  original colored training landscape   b  original grayscale
testing image   c  results from training and testing on a   d  results from training on a and testing on b 
on any input       however  we can see that the algorithm performs almost equally well on novel testing data 
we unfortunately do not have access to the original color version of figure   b  and therefore cannot compute
a score for this colorization  nevertheless  the algorithms similar behavior on both testing and training data
suggests that we have been able to avoid overfitting while constructing our model  figure   b  shows the effect
of  on the score of the colorization in figure   c  

 

conclusions

in this paper  we have presented and implemented a method for automated image colorization that only
requires the user to specify an input training and test image  the proposed algorithm is based on minimizing
the cost function in equation    our approach takes into account both the best color assignment for individual
pixels  as given by the svm margins  and the color consistency within a neighborhood of each pixel  as indicated
by the sobel edge weight term  because it solves the colorization problem from a global perspective  our method
is more immune to outliers and local prediction errors  we have also shown that it is possible to make accurate
predictions about an images color solely based on the features extracted from its luminance channel 
as seen by our resulting images  our framework is applicable to a variety of inputs  the algorithm performs
well as long as the training and testing images have well defined  rich textures  however  our algorithm does
poorly on images with smooth textures  like those of human faces and cloth  in which it often attributes one
color to the entire image 
our approach can be further extended to accept multiple training images by taking the union of the
discretized colors and the union of the feature spaces of those pictures  it would be interesting to apply stateof the art computer vision techniques  like convolutional neural networks  to our colorization problem and see
whether the addition would further improve our results 
our algorithm was implemented in python     using the opencv       numpy       scikit learn       and
pygco      libraries  it generally takes around    minutes to train and test our algorithm on two         
pixel images  our code is available at https   github com jandress   cs    cris jim

 

fireferences
    t  welsh  m  ashikhmin  and k  mueller  transferring color to greyscale images  acm transactions on
graphics  tog   vol      no     pp               
    a  levin  d  lischinski  and y  weiss  colorization using optimization  in acm transactions on graphics
 tog   vol      pp          acm       
    r  irony  d  cohen or  and d  lischinski  colorization by example  in eurographics symp  on rendering 
vol     citeseer       
    h  noda  h  korekuni  n  takao  and m  niimi  bayesian colorization using mrf color image modeling 
in advances in multimedia information processing pcm       pp          springer       
    g  charpiat  i  bezrukov  y  altun  m  hofmann  and b  sch  machine learning methods for automatic image colorization  computational photography  methods and applications  crc press  boca raton 
pp               
    h  bay  a  ess  t  tuytelaars  and l  van gool  speeded up robust features  surf   computer vision
and image understanding  vol       no     pp               
    r  c  gonzalez and e  richard  woods  digital image processing  ed  prentice hall press  isbn                    
    y  boykov  o  veksler  and r  zabih  fast approximate energy minimization via graph cuts  pattern
analysis and machine intelligence  ieee transactions on  vol      no      pp                 
    y  boykov and v  kolmogorov  an experimental comparison of min cut max flow algorithms for energy
minimization in vision  pattern analysis and machine intelligence  ieee transactions on  vol      no    
pp                 
     g  bradski  the opencv library  dr  dobbs journal of software tools       
     e  jones  t  oliphant  p  peterson  et al   scipy  open source scientific tools for python       
     f  pedregosa  g  varoquaux  a  gramfort  v  michel  b  thirion  o  grisel  m  blondel  p  prettenhofer 
r  weiss  v  dubourg  j  vanderplas  a  passos  d  cournapeau  m  brucher  m  perrot  and e  duchesnay 
scikit learn  machine learning in python  journal of machine learning research  vol      pp           
     
     a  mueller  graphcuts for python  pygco       

 

fi