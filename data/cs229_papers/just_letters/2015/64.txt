photo aesthetics evaluation system  an application of
cnn and svm
chen qian
chenq stanford edu
abstractin this project  we applied two machine learning
techniques  cnn  convolutional neural network  and svm
 support vector machine  to build an image aesthetic evaluating
system  and we have achieved an   folder cross validation
accuracy of above     by using cnn implemented in torch 
in the introduction section  a brief background of the
problem and an introduction of our system are given  in the
dataset and features section  weve discussed how we generate
the training data and extract the input features for the machine
learning algorithms  and in the next two sections  methods and
experimental result  how we applied cnn and svm and the
performance of each algorithm have been discussed  the report
ended up with a conclusion section including the summary of
work and a list of future work 
keywordsimage classification  svm  cnn  machine learning

i 

introduction  heading   

every day we are collecting lots of photos either taken by
ourselves or from networks  some of them are in  good  quality
in an aesthetic sense while some of them are not that  good   in
this project we built a ranking system to automatically rank the
given photos for users in a similar aesthetic view of users   we
think it s useful for either classify photos w r t  photo quality or
use the system to guide user to take good pictures in real time
etc 
the input to our system is an image with specific
resolution  then we use our learning algorithms to evaluate the
quality of the input image as an integer ranging from      in
this project  weve implemented two main type of algorithms 
cnn  convolutional neural network  and svm  support
vector machine   and weve achieved an   folder cross
validation accuracy of above     by using cnn 
ii  related work
what we have done is actually a image rateing problem 
data set contain image and its aesthetics score and to predict
some other images aesthetics score  we are referring some
related work in academy  one important application is
handwriting recolonization done by yann lecunn from nyu 
corinna cortes from google labs and christopher j c  burges
from microsoft research  they used and compared several
machine learning algorithms  like svm  cnn  knn and so on

zhi li
zhil stanford edu

applied to handwriting digits recognition     they have achieve
    and above on    class classification accuracy by using
cnn  the mnist database has become a widely used
database for training and test in the field of machine learning 
there have been a number of scientific paperson attempts to
achieve the lowest error rate  one paper  using a hierarchical
system of convolutional neural networks  manages to get an
error rate on the mnist database of      percent    the
original creators of the database keep a list of some of the
methods tested on it    in their original paper  they use a
support vector machine to get an error rate of     percent    
cifar    and cifar     are another database that
widely used in academy  they are    classes and     classes
labeled images for objects recognition  it is done by
krizhevsky from university of toronto       
iii  dataset and features
in this section  we talk about our flow to get the dataset and
extract the manual features used by our learning algorithms 
figure   on the right gives you an overview on how the flow
works 
basically  we used the ava a large scale database for
aesthetic visual analysis  database in our project  it provides
a list of image ids under dpchallenge  with which we can
construct the corresponding urls  and counts of aesthetics
ratings in a range of       we then wrote a crawler to crawl
all the database           images with their average rankings
by online viewers  
after milestone  we did a better analysis on the data  and
found the ranking of our previous data is not evenly
distributed  this time we implemented a sampler to pick the
data uniformly distributed over the scaled ranking ranging from
     so we how has   class data instead of     we did this
because theres very little images range from     and       we
remarked images among     as   and      as    and relabeled
them as      thus  we have      images for each label class
from the output of the sampler 
these        images further went to manual feature
extractor and image resize engine  the manual feature
extractor extracts    features each from the original images 
thus outputs a             feature matrix  these features will be

fiused by svm algorithm only  please see method section for
details   well discuss each feature later in this section  the
image resize engine resizes the images into            
                    and         versions of the       
images  the            versions will be used by svm and    
        versions will be used by cnn 
both the feature matrix and the resized images went to the
datagen engine to generates the input files for libsvm used
as svm solver  and torch  the open framework for cnn 

   colorfulness  hasler and susstruck          suggested an
algorithm to measure image colorfulness 
f   color   var   r   g       var         r   g     b            e   r   g       e          r   g     b    

   sharpness  we used a simple way to measure image
sharpness using its gray scaled images gradient in matlab 

 gx   gy     gradient   gray   scale   image 
f   sharp  

 
 
 
  gxij
  g yij
 
mn i j
i
j

   blurriness  fred   thier           suggested a flow to
measure the blurriness of an image  and heres the flow chart 

fig     flow chart for measurement of blurriness

   edge detection  we define this feature as the percentage of
edge pixels  and the edge pixels are detected by using sobel
methods in matlab 

fi   edge  

  of   edge   pixels
mn

   rgb centroids  we calculated the normalized centroid of r 
g  b as our features  take r as an example 
fig     data generate flow

now lets talk a little bit details on the manually extracted
features  we think these features are typical to represent a
particular image  the first   features are  x  metrics and the
color centroid is a  x  vector feature  including one centroid
 x y  for r g b each  and here we assumes the image has
mxn pixels 
   contrast  here we used the rms root mean square 
contrast  calculated as follows 

i ij  

rij   gij   bij

i 

f   contrast  

 

 i
i

 
  xr   y r      
m

ij

i

j

ij

j

j

subject to 

i

j

ij

  i   

j

a  support vector machines
we used c support vector classification  c svc  
implemented by libsvm for svm  it solves the following
primal problem 
l
 
min wt w   c  xi
w   b  x  
i   

   i

ij

i

iv  methods

ij

mn

j

ij

i

j

 
mn

  i   r        j   r  
 
 
 r n  r

yi   wt f   xi     b       x i

xi     i     l   l

fiwhere

y  rl
yi        

in machine learning theory  convolutional neural network is
a type of feed forward artificial neural network where the
individual neurons are tiled in such a way that they respond to
overlapping regions in the visual field convolutional neural
networks are inspired by biological process and they are right
now  widely used in image recognition area 

where f   xi   maps xi into a higher dimensional space and
c     is the regularization parameter  duo to the possible
high dimensionality of the vector variable w  usually we solve
the following dual problem 

   different types of layers
a  convolutional layer will compute the raw pixel
values of the image 

subject to

 
min a t qa   et a
w  b  x  
y a   
   a i  c   i     l   l
t

where e              is the vector of all ones  q is an l by l
positive semidefinte matrix 
t

q  yi y j k   xi   x j  
k   xi   x j    f   xi  t f   x j  
is the kernal function 
l

w    yia i f   xi  
i   

after the dual problem is sovled  using the primal dual
relationship  the optimal w satisfies
and the decision function is
l

sgn  wt f   x    b    sgn  yia i k   xi   x    b 
i   

we store label names  support vectors  and other information
such as kernel parameters in the model for prediction 

b  sub sampling layer will perform a fownsampling
operation along the spatial dimensions  resulting in smaller
dimensions data 
c  fully connection layer will compute the class score 
result in a class size vector  x  in this report  
   architecture design
we designed   convolutional neural network architecture to
process   different kind of pixels image    x      x   and
   x    
  x   cnn architecture is shown as below input is  
channel  rgb  of   x   image  it go through a convolutional
layer which has  x  vertical and horizontal layer to produce
  x  x   feature map  next step is sub sampling which takes
max value of every  x  window to produce  x  x    and then
go through one more convolutional layer and one more subsampling layer  full connection layer is followed from the
image data   x x   to   classes which is the final output of
this classification 
  x  x  resolution image convolutional neural network
shares same architecture except the full connection layer input
is   x  x   due to larger image 
   x   x  resolution image convolutional neural network
use two more convolutional layers and subsampling layers  and
the full connection layer input   x x  

since in our problem  we are actually solving a   class
classification problem  what it does is to use one against the
rest mechanism to treat one class as labeled    and the rest
are labeled as     then we can apply the   class svm above 
for the input features  we did two major experiments  for the
first part  we feed the normalized image pixels as input
features  e g  for the     color image  it will has            
features 
for the second part  we used the manual extracted features
as inputs to compare the performance with the raw pixel
methodology 
the experimental results will be discussed in the next
section 
b  convolutional neural network

fig     convolutional neural network for   x  x    x  x  image input 

v  experiments  results and discussion

a  support vector machines
as discussed in the previous section  for the  st part of the
experiment  we used normalized image pixels as input

fifeatures directly  and we tried                         
dataset  we also tried   different kernels  the   folder cross
validation accuracy rate are listed in the following table 
test accuracy of   fold and   resolution

table i 

 x 

  x  

  x  

  x  

linear

      

      

      

      

polynomial

      

      

      

      

rbf

      

      

      

      

from the table  we see that the linear kernel performs best
generally  the       image set gives the best performance 
the result makes sense  since for low resolution images  the
information within the original images for telling its good or
not is lost  think about in a extreme way  when every image
becomes one pixel  its impossible to tell whether it is good or
not  and for high resolution images  then the features size will
become too large  and overfitting will happen  e g  for      
images  we have      features for each image  while we only
have      images for each label class 
then for the second part of the experiment  we decided to
use manual features extracted from the original data  and
heres the result 

table ii 

manual extraction feature result
manual extraction

linear

      

polynomial

      

rbf

      

test accuracy of   fold and   resolution

table iii 

k 

k 

k 

k 

k 

  x  

     

      

     

      

     

  x  

     

      

     

      

     

   x   

     

      

    

     

      

table iv 

run time of   fold and   resolution

k 

k 

k 

k 

k 

  x  

    s

    s

    s

    s

    s

  x  

    s

    s

    s

    s

    s

   x   

    s

    s

    s

    s

    s

on average  cnn achieve        accuracy on   x   pixel
input         on   x   pixel input and       on    x   
pixel input  and it takes       s to run   x   pixel image 
      s to run   x   pixel image and       s to run    x   
pixel image on mac pro     ghz intel core i  cpu  in cpu
mode 
the cnn experiment shows that accuracy would increase
when image resolution increase  if the image is more clear  it
is easier to predict test case score 
overall  the performance of svm to this problem is not that
good comparing with cnn algorithm 
vi  conclusion and future work
a  hybird of cnn and svm

from the second part we see that the accuracy lower than
using raw pixels  we think this is because only    features are
extracted and these    features are not guaranteed to measure
photo aesthetic metrics although we think they are important
features 
overall  the best accuracy we ve achieved by using svm is
       

cnn is designed to mimic biological neural network and
then applied in computer science  but in cnn  it did not
consider  at least we havent figured out  manually extracted
features such as contrast  brightness  rule of thirds and so on
while these features potentially contribute a lot to fthe aesthetic
rank of photos  it may help improve evaluation of photos 

b  convolutional neural network

b  cpu vs gpu run time comparison

we did   fold cross validation on total       image  they
are k   k   k   k  and k   and original image data set is
extracted as   type of resolution  low   x     medium   x   
and high    x     

we run cpu mode only before milestone  so we are
interested in how gpu perform and its comparison with cpu 
also the performance of parallel computing if neural network
is complex  and well run our algorithm on the the mobile
gpu board 

the   fold experiment accuracy and run time is listed in the
tables below 

fiacknowledgment

   

thanks help from ta albert haque who provide quick and
nice suggestion and explenation 

   

references

   
   

   

   

y  lecun  l  bottou  y  bengio  and p  haffner   gradient based
learning applied to document recognition   proceedings of the ieee 
                  november      
ciresan  dan  ueli meier  jrgen schmidhuber         multi column
deep neural network for image classification       ieee conference on
computer vision and pattern recognition

   

lecun  yann  corinna cortes  christopher j c  burges  mnist
handwriting digit database   yann lecun  corina cortes and chris
burges     august      
krizhevsky  a   sutskever  i  and hinton  g  e  imagenet classification
with deep convolutional neural networks
nips       neural
information processing systems  lake tahoe  nevada
alex krizhevsky  learning multiple layer of feature from tiny images 
    
hasler  david  and sabine e  suesstrunk   measuring colorfulness in
natural images   electronic imaging       international society for
optics and photonics       
crete  frederique  et al   the blur effect  perception and estimation with
a new no reference perceptual blur metric   electronic imaging      
international society for optics and photonics       

fi