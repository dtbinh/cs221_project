for tune teller
gerard touma
mridul krishnan
sambhav jain
stanford university  stanford  ca       usa

abstract
in this paper  we document the development of a
learning algorithm that rates the popularity of a song on a
scale of   to    using a carefully chosen set of musical
features  along with personal interest  the main motivation
is to be able to help both the artists and label advertisement
companies in the music industry  we considered two
different datasets  mp  and msd  and we tried to mitigate
the effect of unwanted factors as much as possible by
carefully choosing the songs  we trained  tuned  and
compared three different learning algorithms  and chose the
svm as it has the best performance  the results show that
we can correctly classify a given song with       accuracy
into the correct class  and in the event of misprediction 
there is a     chance that the error is only one class away 
   introduction
although music is subjective in its own terms  the quality
and success of a song is far from being random  many
factors come in the picture when quantifying a songs
success popularity  this mainly includes the quality of the
song  genre  popularity of the artist  theme  and other artistic
factors such as the video clip quality and lyrics  this work
examines only the correlation between the popularity of a
song and its musical features  i e  musical quality  
there are two main motivations for choosing to work on this
problem  first  all our group members are passionate about
music  and we thought it would be interesting and fun to
apply the concepts we learned in the course on a music
related project  the second motivation was realizing the
impact and value that the ability of predicting a songs
popularity even before its release can add to the music
industry  it provides artists a tool to modify tailor their song
composition to generate popular songs  assuming this is their
goal   and offer the music advertisement label companies
assistance in investing in a particular artist song that can
generate for them the most success 
to define our project even further  our prediction system will
take as input a set of musical features of a song  and will
classify the song in one of five groups depending on its
expected popularity  we are using the number of views on
youtube as a metric for a songs popularity  and we map
these views in five ranges to generate the labels 
before starting the discussion of our approach to
implement the song rating system  we describe in the
following section how we modeled our labels and how we

gtouma stanford edu
mridulk stanford edu
sambhav stanford edu

chose the songs  as this is particularly important in our
project application  we then report and discuss previous
similar work  we also discuss our feature extraction process 
the learning methods algorithms we considered  and finally
the learning results 
  

data represetation and selection

a  label generation
as mentioned earlier  we modeled our learning problem
as a classification problem over five classes  and since we
are using youtube views  which can take any integer
number up to almost   billion  as the success metric  we
mapped them to the following ranges to generate the labels 
views range  k     
m     

label

     k

 

  k    k
  k    m
  m     m
   m      m

 
 
 
 

table    mapping between youtube views ranges and the labels

b  song selection
as previously mentioned  out of many factors that can
determine the popularity of a song  this project only focuses
on modeling the musical  audio  aspect  thus  properly
choosing the songs to be considered for feature extraction is
very important  and the following sections discuss the
strategies that we followed to mitigate the effect of the other
factors as much as possible 
c  time and the general music taste
over time  music content and composition has changed a
lot  and the hits that were very popular in the   s and   s
for example  are very different than the modern
contemporary hit songs  therefore  it is important  at least
for the initial study  to focus on one musical era 
otherwise  the data might have very small correlation with
the results  for this reason  we narrowed our choice of songs
to after year of      
d  youtube popularity
since we are learning our algorithm based on the number
of views on youtube  another important factor to take into
account is the date youtube started becoming popular  for
example  a song could have been very popular right before
youtube was released  and still considered as modern song  

fibut it did not get enough views on youtube because it has
already been out on the radio and people already know the
song  the statistics  trends  below show that narrowing
down our search to songs released after            
present  is a good choice 

figure    monthly videos published on youtube                

e 

genre diversity
music comprises a very large number of genres  these
genres have different structures and composition processes 
which results in  relatively  different song features 
therefore  we also focused on gathering features of songs
from genres that are close  in particular pop and alternative
rock  the incentive was that this choice might increase the
correlation between the input and output data 
f 

artist style diversity
another key difference is the artists styles  in particular
the composition and musical content of the song  to mitigate
the effect of this diversity  we chose a certain number of
artists  based on the assumptions above   and we performed
feature extraction on a full album instead of individual songs 
the idea being that comparing individual songs across a
wide variety of artists will give little correlation  in addition 
an album has  almost  always relatively popular and
unpopular songs for the artist  and this will make it easier to
contract this popularity over the difference of the features of
these songs 
g  artist popularity
it is common that if an artist is already very famous  the
user rating will be biased for any new song  even if its
quality was not as good as the previous songs   although this
factor is important  it is hard to mitigate  one way to try to
reduce its effect is to choose the first album of an artist that
became recently popular 
h  typical trend of youtube views
when choosing a song  it is important to take into
account the time and duration since it has been released  this
is to make sure that the number of views reaches a relative
steady state  or constant growth   according to statistics
published by youtube  this trend is exponential  and reaches
a steady state after around   months from the release date 

figure    youtube views versus time  in days  for popular songs    

  

related work

li su  et al      implement a system that classifies guitar
playing techniques using features extracted from the audio
signal  we looked at this paper hoping to gain some insight
into possible features we can extract from the audio content
of a song  however  this paper implements a very specialized
system and therefore  uses only a limited number of features 
we were looking for a broader way of classifying the input
songs 
in      the author seems to favor metadata of songs such
as user s recommendations over the features extracted from
the actual content of the song for music recommendation
systems  therefore  this paper recommends techniques like
collaborative filtering which try to determine user
preferences from historical usage data  the problem with this
approach is that it would be difficult to recommend new
songs that do not have much usage data 
we also looked at systems that implemented neural networks
for feature extraction  in      a deep belief neural network is
used to extract features which are then passed on to an svm
for genre classification  the drawback of such a system is
that we would need a large number of training examples for
such a system to function properly 
in another paper  van den oord  et  al      implemented a
content based music recommendation system using deep
convolutional neural networks  this paper improves upon
collaborative filtering based approaches to music
recommendation  which relies on historical usage data to
determine user preferences  by trying to predict the usage
data inside one of the layers  this helps overcome the
problems faced by collaborative filtering with new songs for
which there is no usage data available  this is a really cool
idea  however  the users had access to a very large database
of songs  the spotify song database  and hardware required
to implement training of the neural network  therefore  we
decided to take a different approach 
  

dataset and features

in order to extract relevant features  we first needed to
decide on both  the type of audio data to process and the
features to extract  for the former  we considered three types 
mp   midi  and million song dataset  msd       we
investigated three different types because each had its own
advantage and disadvantage as will be discussed next  for the
features  we considered both static features as well as time
series  however  given the amount of time we spent on data
collection and filtering  it was more convenient to work with
static features  as working with time series require additional
time  we also used a software called jaudio     for
mp  midi music feature extraction  while the msd data had
the features already extracted 
a  mp  and jaudio
after a thorough search for audio features extraction
software  we chose jaudio for its ability to extract a large set
of audio features and its compatibility with both mp  and
midi songs  jaudio is part of a digital signal processing
project  it was developed to extract several audio properties
of songs  e g  beat points and statistical summaries  tailored
to machine learning algorithms that aim to predict the hit
degree of songs  as for the features  jaudio provides static

fifeatures such as the fft of the song  strongest beat 
harmonic spectral centroid  and others  it exports the
extracted features into excel sheets  type double and integer  
also  before passing this data to our learning algorithms  we
normalized it  divided by the maximum value of the
corresponding range  especially for magnitude dependent
learning algorithms 
a main advantage of mp  songs over midi and msd is that
it contains all the information about the song  instruments 
pitch  vocals  and others  however  during mp  data
collection  we faced several difficulties  first  even though
we wrote a script to automate the download  we needed to
download many other songs individually from the internet 
another problem was that jaudio was able to process only a
portion of the mp  songs  around       and we had to
manually input the songs one by one for feature extraction 
the previous two issues left us with around     songs with
extracted features  out of almost        given that jaudio
provides up to     features  we wished to have more songs to
avoid over fitting in case we needed to use a large number of
features for higher accuracy  another main issue was noise  it
was difficult to determine how much noise an mp  song
contained  glitches  etc   even after passing the songs
through filtering programs  it was still hard to determine how
much the noise can affect the results 
b 
msd
another dataset we considered is the million song dataset
 msd   msd is a set of audio features and metadata for one
million songs provided by the echo nest  it offers a great
advantage over mp  and midi songs in terms of the size of
the dataset    million  and the features that are already
extracted  in total  it offers    features that we can choose
from  the only main disadvantage is that it does not provide
flexibility in extracting new features for the songs  and does
not give prior knowledge of the noise  among the features
msd provides  we name the key  mode  major minor   mode
confidence  genre  year  and others  most of the features can
be considered as static features 
the msd dataset is very large       gb   luckily the
developers provides a subset of        songs that we could
download within reasonable time  interfacing msd dataset
with our algorithms required developing python  perl  and
matlab scripts  we also used them to filter out the songs
released before      and other criteria  discussed earlier in
the song selection section   after filtering  we ended up with
     songs 
c 
midi
even though midi songs have no noise  they do not
contain the vocal track  which could be important for a
songs success  we were also not able to obtain a large
dataset online  and thus we decided to work with the two
previous options 
d 
label extraction
to get the number of youtube views  we developed a
script that takes a list of songs  fetches the corresponding
youtube webpage and extracts the number of views for the
first song in the youtube list  which has usually the highest

number of views  the script then normalizes the numbers in
the corresponding ranges and labels the data        
  

data exploration

after extracting the features  and before running our
learning algorithms  we worked on visualizing our data by
performing principle component analysis  pca   and
calculating the mutual information for the features 
pca helped us observe how the data is clustered  whether it is
linearly separable  and based on the result determine the type
of kernel we need to use in our learning algorithm  to know
the size of the basis to project our data on  we plotted the
variance captured by the different principal components and
found that most of the information  variance  is in the first   
  components for msd and mp  features  shown below is
mp  case   therefore  having a  d figure should give us a
good representation of the total variance  the pca plots
which we show below for different classes did not show a
very clear clustering of the data  suggesting that we need to
use a kernel different than the linear one  confirms with the
results we discuss in the next sections  

figure    percentage variance captured by the pc vectors  mp  

figure    data for different classes projected on   dim using pca
 mp  

in addition to pca  we calculated the mutual information
for the different features  this helped us rank them for the
cross validation experiments  discussed in the results
sections   the plots below show the mutual information
score  after normalization  versus the feature index for
jaudio  mp   and msd datasets 

figure    mutual information for msd and jaudio features

fi  

methods

in our project  we used three different learning algorithms
to train our classifiers  gaussian discriminant analysis
 gda   modified gda  and support vector machines 
a  gaussian discriminant analysis
given that most of our features are real valued and
extracted from the audio signal of the song  we made a
fairly reasonable assumption that the feature vector has a
multivariate normal distribution  gda is known to be
asymptotically efficient if the feature vector is gaussian
and this was our main source of motivation to proceed
with gda 
gaussian discriminant analysis models the distribution
of the data points  the        given information about their
corresponding class labels  the         as being
multivariate gaussian  for our project  we implemented a
five class classifier  that is             and used two
variations of gda  in the first variation  we assumed the
covariance matrix   to be the same for all classes 
therefore  the conditional of    given    is given by 
 

 



 

 

   

 
 

 



 
 

exp  

 

 

 

  

    





 

    

where  is the dimension of the feature vector  so each
           is the mean of each class and  is the
covariance matrix  using bayes rule  the conditional
distribution of      given      is then found to be 
 

 

 



                
                
   

 

given a new songs feature vector   a prediction is
made by finding 
                          
the parameters of this model are then the class prior
probabilities                          and   the
optimal estimate of these parameters that maximizes the
log likelihood of the data can now be obtained as follows 
   

b 

 

 

       
     

 
   



 

 

                               
to use the svm for our five class classification
problem  a one vs one implementation is used      in this
implementation  a new binary classifier  which in this case is
an svm  is learned for each pair of classes  this means there
are               svm classifiers which are learned  during
prediction  each classifier  or binary learner  makes a
prediction and the class which gets the largest number of
predictions  or votes  is output as the final predicted class 
  

experiments and results

in this section  we discuss some experiments we ran in
order to make some informed decisions about the choice of
hyper parameter values for our learning algorithms such as
the optimum number of features  the type of kernel function
to use and so on  using these tuned parameter values we then
discuss the results obtained with the three learning
algorithms 
a 

experiiment    k fold cross validation
all parameters of the gda learning algorithm  both with
the same and different class co variances  are learned during
training  however  there are some things that cannot be
explicitly learned such as the number of features to use 
therefore  we used filter feature selection with k fold cross
validation  k     to help us choose the optimum number of
features  in order to do so  we varied the number of features
from one to the maximum number of features available for
each data set      for mp   and    for msd   for a
particular number of features chosen  say n   we found the
features with the n best mutual information scores  we
then found the optimal number of features as the one that
gives us the best average accuracy using k fold crossvalidation  we ran this procedure with the million song
dataset and the mp  song dataset separately 

       



 
     

   

 

  

hyper plane is found by solving the following optimization
problem 
 
        

    



 

       
 

    

 



modified gaussian discriminant analysis

in our second variation of gda  we used different
covariance matrices for each class  therefore  all
parameters would be updated in the same way as before
except   which would now be updated separately for each
class as follows 
   

 
   



 

    
  

 



 

   

    

 

       

c  support vector machines
the support vector machine learning algorithm is
inherently a binary classifier that tries to find a hyperplane
that separates data points belonging to two classes  this

figure    k fold cross validation for msd features  k     starting
with the highest mutual information scores

figure   shows a plot of the average accuracy versus the
number of features chosen for the msd dataset obtained
using the gda classifier  as can be seen in this plot  beyond
a point the accuracy falls sharply as the number of features
increases  this may be due to redundant features being added
which would increase the risk of over fitting  the optimal
number of features is found to be   for the gda classifier 
for the mp  dataset  however  the k fold cross validation
accuracy seemed to be increasing as the number of features
was increased  however  using more than    features creates

fia singular covariance matrix  which results in erratic results
and a very low accuracy when a larger test set is used 
therefore  we chose the optimum number of features for the
mp  dataset to be    for the gda classifier  the trend would
be similar for the modified gda classifier with different
class co variances and so would the corresponding optimum
number of features 
b 

experiiment    hold out cross validation

for the svm classifier  we used all the features available
in each dataset  when we ran the svm with a linear kernel 
we were getting a lower accuracy than the gda and gda
modified classifiers  rather than reduce the number of
features  we decided to try using a gaussian kernel  our
motivation for doing so was that we had obtained a higher
accuracy with gda which assumes that the distribution of
the feature vector is gaussian  furthermore  during initial
runs of the svm using linear and gaussian kernels  the run
time was significantly lower with the gaussian kernel as
compared with the linear kernel  this suggested that the
optimization problem for svms was easier to solve using a
gaussian kernel and this was our main source of motivation
for choosing the gaussian kernel  this also confirms with
the pca results we obtained before  we also decided to
specify a cost matrix   for misclassification where
        
       
and               

 

       
   

in order to test the performance of these different
approaches  we used holdout cross validation where we
trained on     of the data set  randomly chosen points  and
tested on the remaining     of the data  we ran the above
procedure and obtained the classification accuracy over the
test data for three cases 
a  svm classifier with a linear kernel 
b  svm classifier with a gaussian kernel 
c  svm classifier with a gaussian kernel and the cost
matrix c specified 
the classification accuracies obtained for each of these
classifiers on the msd dataset is shown in figure    from the
figure  we can see that the best accuracy was obtained using
the svm with a gaussian kernel and the cost matrix c 

the same data points for each data set  the results we
obtained are shown in table    for both the msd and the
mp  data sets  the svm obtains the highest classification
accuracy  for the msd data set the performance of gda and
the modified gda classifiers are similar with gda doing
slightly better  however  for the mp  dataset  the modified
gda classifier does significantly worse  the reason for this
may be the following  the sample size for this data set is
fairly small  therefore  the training set may have been
imbalanced meaning the co variance matrices for the
minority classes are not accurate  hence  if these classes
appeared in the test set  they will most likely be
misclassified 
apart from classification accuracy  another method we
used to compare the performance of the different classifiers
was to see how much far the erroneous predictions were from
the actual predictions  we obtained this by breaking down
the number of misclassified test data points into percentages
of points that were only misclassified by one class  by two
classes and so on 
the results obtained can be seen in table    from
table    we can see that for the msd data set  all the
classifiers misclassify by one class majority of the time           as our system only gives a rating for a song  a
misclassification by one class is not a big issue  for the mp 
data set  we see that the gda with different class covariances misclassifies by one class majority of the time
        however  the svm  although more accurate 
misclassifies by two classes most of the time        
classifier
gda
modified gda
svm

msd

mp 

       

         

      
      

         
       

table    classification accuracy
diff
between
true
 
pred 
class

msd dataset

mp 

gda
   

mod 
gda
   

svm
   

gda
   

mod 

  class

     

     

     

     

     

     

  class
  class

     
     

    
     

     
    

     
     

     
     

     
     

  class

    

    

    

    

    

    

gda
   

svm
   

table    misclassification error

  

figure    accuracy with different svm hyper parameters

c 

results
using the tuned values of these parameters  we ran a
simulation to compute the classification accuracy of each
classifier using the msd and mp  datasets  we used
classification accuracy to be the main metric to judge the
performance of each classifier  each classifier was trained on
    of the data set  randomly chosen points  and tested on
the remaining     of the data  in order to make a fair
comparison  all the classifiers were trained and later tested on

conclusion

in this work  we implement a five class song popularity
classifier based on well defined musical features  svm
algorithm showed to give a better performance compared to
gda  in its two versions  mainly because it has a lower bias
in general than gda  our future work will involve obtaining
more mp  data to learn from  and investigating other features
including time series  which could give even higher
accuracies 
references
   

study  the top     global brands winning on youtube publish    to
    videos a month         august     retrieved december          

fi   

   

   

from
http   marketingland com study top     global brands winningon youtube publish anywhere from    to     videos a month      
billion view videos are happening faster on youtube   n d    retrieved
december
   
     
from
http   youtubetrends blogspot com         billion view videos are happening html
l  su  l  f  yu  and y  h  yang  sparse cepstral and phase codes for
guitar playing technique classi cation  ismir            slaney  m  
 web scale multimedia analysis  does content matter    in
multimedia  ieee   vol     no    pp        feb      
slaney  m    web scale multimedia analysis  does content matter   
in multimedia  ieee   vol     no    pp        feb      

   
   

   
   
   

 n d   
retrieved
december
   
     
from
http   ismir     ismir net proceedings ismir        pdf
van den oord  aaron and dieleman  sander and schrauwen  benjamin 
 deep content based music recommendation   advances in neural
information processing systems                       curran
associates  inc 
welcome 
 n d   
retrieved
december
   
     
from
http   labrosa ee columbia edu millionsong 
jaudio 
 n d   
retrieved
december
   
     
from
http   jaudio sourceforge net
      multiclass and multilabel algorithms   n d    retrieved december
          from http   scikit learn org stable modules multiclass html

fi