recommendation system using yelp data
cs     machine learning
jia le xu  yingran xu

 

introduction

yelp dataset challenge provides a large number of user  business and review data which can
be used for a variety of machine learning applications  our project is aiming to create a friend
and business recommendation system using yelp data  we plan to find hidden correlations
among users  and then recommend new friends to users with similar interests  the second
motivation is to identify what these interests are  we want to know what business the user
favors more  so that we implemented the business recommendation system  which predicts
the users rating on a certain business using users past experience  ratings on similar business 
and other peoples rating on this business  the application of this project can extend the use
of yelp to a social networking level  which allows users to find new friends and experience
certain business together 

 

related work

in this project  we use k means to group users with similar interests  centroid initialization
in k means algorithm can affect the final clustering performance  there are several ways
proposed for centroid initialization  arai and barakbah     used a hierarchical method to
run k means a few times  and applying hierarchical clustering algorithm to find the best
centroids in the set  this method generates good results for high dimensional dataset 
but it takes longer to run  another method called k means   proposed by arthur and
vassilvitskii     chooses initial centroids uniformly randomly  and choose the subsequent
centroid with weighted probability proportional to the squared distance from its closest
existing centroid  this method improves speed and accuracy of k means algorithm  and
we use this initialization scheme in our project  on the other hand  matrix factorization is
commonly used for recommendation system and finding latent relations between users and
items  it is easy to implement and does not require too much pre processing of data    

 

data preprocessing

we choose to only analyze the data on one type of business  restaurant  in our project 
but the application may extend to larger scopes  yelp has grouped restaurants into many
different categories  in order to have more data to show similarity among users  we choose
to use the categories  not individual restaurants  to group the users in the first part of the
project  some users only have a small number of reviews        in the dataset  which is not
enough for determining a users preference of certain type of restaurants  so we filter out the
users with number of reviews less than     and left with      data  later  we also try to
 

fiuse the user data with number of reviews greater than              and     to compare the
results  then we split the data into     training set and     test set to use for hold out
cross validation later 

 
   

algorithms   result discussion
k means

the baseline for the first part of the project is to use one cluster with centroid of the total
averaged rating for all users of all businesses in the training dataset  in this baseline  we
used all users with review count greater than     and the averaged rating is found to be     
k means algorithm basically takes each users input feature vectors  star rating and times
of visit   and groups the users into clusters based on the euclidean distance of each users
feature vectors to the clusters centroids 
     

methodology

to implement k means algorithm  first we need to determine the number of clusters to use 
we run the algorithm with different values of k  and then plot their distortion measurements  the graph below shows the plot for      training data  we choose value k to be the
knee of the graph  which is    in this case 

figure    finding number of clusters in k means
for k means initialization  we first initialize all centroids randomly  and then we use kmeans   initialization  which is described earlier 

 

fito evaluate the algorithm  we use rmse on star rating as our error measurements  after clustering the users  we calculated the expected rating for each category in every group
of users using training data  then for evaluation  we assign each test data  a new user  to
the cluster with minimum euclidean distance  and calculate the rmse of its true rating on
each category with the expected rating calculated in each cluster 
p
clustertestdatai   argmink   jcategories  wtestj  testj  ckj       k
q
testdatai jcategories  e ratingclusteri  ratingtestdatai   
rm se  
numberof ratings
for each group of training data  reviews             etc   we train the weight vector by
giving different weight values for each feature  w    weight for star rating  w    weight for
times of visit  and calculate the rmse to find the weights that gives the minimum error in
the test dataset 
     

result discussion

the results are shown in the following table 
table    results comparison using k means
data group
baseline      reviews   reviews  
  
  
training data     
    
    
clusters
 
  
  
random initialization
rm setrain
     
     
     
rm setest
     
     
     
k means   initialization
rm setrain
     
     
     
rm setest
     
     
     

reviews
   
   
 

  reviews
   
   
 

     
     

     
     

     
     

     
     

comparing to baseline algorithm  k means makes some improvements when we focus on
the users with large number of reviews  comparing two centroid initialization schemes 
rm setest using k means   is slightly smaller than using random initialization  but
rm setrain using k means   is generally smaller than using random initialization  especially when the training dataset is larger and more random 
however  considering the highly skewed nature of the dataset  around     of reviews have
rating of   or     a rmse about     is not very good  so we decide to explore if users in
the same area tend to have more similar interests  we used all users with review count     
 since if we use larger review count groups  the data will be too few   and run k means for
each state 

 

 

fitable    k means results for each state
state
nv
pa
training data     
   
rm setrain
     
     
rm setest
     
     

az
    
     
     

il
  
     
     

nc
   
     
     

wi
   
     
     

from the table above  we find that the result considering each state separately is not improved  this is mainly caused by lack of data  il only has    training data  which is likely
to produce a high variance result 
the high variance result is also shown in the first case where we did not split data into
states  this may because the features we used are too simple  also  due to the unsupervised
nature of this problem  it is hard to accurately measure how good the result is  here  we are
only considering the star rating as our measurement  however  the users reviews may also
have an impact on the clustering  for example  some users give high ratings because of the
food  while others may care more about the ambience and service 

   

matrix factorization

we explore another collaborative filtering algorithm called matrix factorization  the basic
idea of it is to decompose a matrix contain user business ratings into two matrices  these
two matrices are related via latent features  one relates userss preference to features  the
other one relates business to features 
     

methodology
r  p q  rub  

k
x

puk qkb

k  

where rub denotes how the n th user would rate the m th item in the model  r  r n m    
p  r n k    q  r km     n     of users  m     of business  k    of features  we then use
cost function 
 
eub     rub  rub       ptu pu   qbt qb   
 
with additional regularization term to prevent overfitting 
we then use gradient descent to find optimal  p    q     arg min p q  rmse 
puk    puk       eub qkb   puk   
next we use improved regularized matrix factorization  add bias for user and businesses  
rub   cu   db  

k
x
k  

 

puk qkb

fiwhich trained as cu    cu      rub     cu   db  globalmean  

     

result discussion

we run tests on two states  az and nv  since they contain more users and businees with
higher number of reviews  for a given user business matrix  we randomly set     of the
rating to    which means not rated  and use it as our testing set  the rest     becomes the
training set  we then experiment with different number of features and plot the rmse of
testing set  nv        is the dataset contains user with review count larger than     and

figure    rmse with different number of features
businesses with review count larger than     therefore  nv       is the largest dataset
 about        reviews   we can observe an increase of performance compared against the
baseline  moreover  for larger dataset  the optimal k value  number of features  also increases
as expected 

 

conclusion   future work

k means algorithm using user data with larger number of reviews shows a decent grouping
result  however  the feature selection and evaluation methods can be improved  if we
are taking this project further in the future  we would like to add more features  for
example  we can find the major characteristics of each business  and the key words in user
reviews  and then relate them to the users rating  we can utilize the features discovered by
matrix factorization  and use it to improve k means or facilitate developing some supervised
learning  furthermore  we can also explore other collaborative filtering algorithms or neural
networks to find correlations among the features 

 

fi 

references

    k  arai  a  r  barakbah  hierarchical k means  an algorithm for centroids initialization
for k means  reports of the faculty of science and engineering saga university  vol     
no          pp        
    arthur  d  and vassilvitskii  s          k means    the advantages of careful seeding   proceedings of the eighteenth annual acm siam symposium on discrete algorithms 
society for industrial and applied mathematics philadelphia  pa  usa 
    arkadiusz paterek  improving regularized singular value decomposition for collaborative filtering  kddcup    august          

 

fi