ivan suarez robles  joseph wu  

section    introduction
mixed martial arts  mma  is the fastest growing competitive sport in the world  because the
fighters engage in distinct martial art disciplines  boxing  wrestling  jiu jitsu  etc   on their feet 
grappling  and on the ground  it would be interesting to implement learning algorithms on these fights
to find any potential patterns as very few have tried  as input  we are using   key statistics collected
over a fighters career  the fighters profile   as output were predicting the outcome of a fight
between the two fighters  as well as clustering the fighters stylistically 
section    related work
there are not many attempts at analyzing data relevant to mma  though one attempt at it
comes from the article  betting on ufc fights   a statistical data analysis  which uses a random
forest classifier to extract several results from the data  unfortunately  decision tree learning tends to
overfit on training data  so in our case it may not be a good idea to use this method 
regardless  even if we uncover a model that can predict accurately the outcome of a match 
the model itself will not be complete since we are not incorporating the fact that previous matches for
a fighter a may influence the outcome of his her next match  as suggested in the book  predictive
modeling for sport and gaming  as mentioned in the book  a fighters psychology will have
influence over his actions  something that we do not consider in our learning algorithms  though it
would have been too difficult to do so 
for our learning algorithms  we mainly focus on logistic regression and svms  in which both
algorithms tend to do well as mentioned in the paper  comparison between svm and logistic
regression  we found  in accordance to the paper  that both logistic regression and svms do similar
in performance  when choosing a good kernel for svms   the paper mentions that svms will
commonly achieve a better accuracy with less data as opposed to logistic regression  but it did not
matter much in our case since we have     training samples        data points  to work with 
choosing the best features is very important to svm training  the study combining svms
with various feature selection strategies discusses using different feature selections and mapping
and characterizing their effectiveness using an f score  which measures how well these features
distinguish the data points from each other   in our project  we tried different feature mapping from
the fighters attributes  which has made a difference in the results of our algorithm  if we had more
resources  we could objectively score these features based on a criteria like the f score 
in this study relationships between mindfulness  flow dispositions and mental skills
adoption  a cluster analytic approach  the researchers used k means clustering to group athletes into
buckets according to features such as emotional control  flexibility  engagement  etc   these clusters
are then compared in terms of the average performance of the athletes  this study is quite similar to
our approach to classify fighters stylistically through clustering 
section    dataset
our data was collected from fightmetric  a small company dedicated to providing data on
mixed martial arts  mma  fighters and events  we collected     training samples and    testing
samples from the data that fightmetric provided on the ufc matches over the past few years 
for each training sample   testing sample we collected  which is represents a match during the
ufc   we do the following preprocessing  each training sample contains eight total features  in which
each consist of a mapping of the following eight statistics of fighter   and fighter    significant
strikes landed per minute  significant striking accuracy  significant strikes absorbed per minute 
significant strike defence  the   of opponents strikes that did not land   average takedowns landed
per    minutes  takedown accuracy  takedown defense  the   of opponents td attempts that did
not land   and average submissions attempted per    minutes 
here  we also do something subtle  for each ufc match  we create two data points  one which
consists of mapping statistics of fighter   and fighter    in that order  with the outcome of the match

fiivan suarez robles  joseph wu  

for fighter    and a second point which flips fighter   with fighter    this was done to prevent any
possible bias in the data if we happen to list fighter a and b as fighter   and    respectively  or if we
happen to switch them instead  of course  this creates the assumption that the outcome of fighter   in
a given match is independent from the outcome of fighter   in the same match  which is definitely not
the case  but we regardless make this assumption for simplicity of our work 
section    methods
we used three different learning algorithms for predicting the outcome of each ufc match 
they are the following  naive bayes classifier  logistic regression  support vector machines
 svms   we also implemented k means clustering to help us categorize different styles of fighting
and observe any trends between matches of different clusters 
for the naive bayes classifier  we sought to model the function p x y  where x represents the
ufc match sample given and y represents whether fighter   won the match  y      or lost  y       in
the classifier  all our p x y s are estimated from the training data and then tested on the sampling data 
for logistic regression  we seek to determine the function  h x   

 

      

 here represents weights that we estimate by maximizing the following equation  the log likelihood
of h x  
  
  
  
  
l     
                             
once determining an appropriate  that maximizes the above equation  we plug in each testing sample
into our h x   with one edit  we add an extra attribute for each sample  x  whose value is    this is also
done with all training samples  
for svm  we seek to find a hyperplane that separates all sample points into two regions and
which maximizes the smallest distance between a data point and the hyperplane margin  formally 
we wish to minimize the following equation 
        w      c
   
such that y     w  x      b      i        m
here  the      w    term is the distance from the data point to the separating hyperplane  of course 
most data sets in reality are not linearly separable  which explains the c
    term  this term
incorporates a penalty for when we misclassify a data point  finally  the constraint ensures that our
margin is greater than one  as opposed to less than one or even negative since we are trying to
correctly classify data and not misclassify it  
the k means clustering algorithm is an iterative unsupervised learning algorithm where k
cluster centroids are randomly initialized  at each iteration  training examples are assigned to the
closest centroid and each centroid is updated to be the mean of all the training examples assigned to it 
this algorithm is guaranteed to yield convergence in practice 
section    experiments   discussion   results
we first formatted the data extracted from fightmetric in the following way  for each statistic
x listed for each fighter    and    of a match  we take the statistics x  and x   and map them to a
feature x  this is done for the following eight statistics from each fighter  significant strikes
landed per minute  significant striking accuracy  significant strikes absorbed per minute 
significant strike defense  the   of opponents strikes that did not land   average takedowns landed
per    minutes  takedown accuracy  takedown defense  the   of opponents td attempts that did
not land   and average submissions attempted per    minutes  in total  we will have eight features
to work with  as for the mapping itself  we used three different mappings and compared the results of
each  which are the following mapping functions 
                                        and                                

fiivan suarez robles  joseph wu  

accuracy
  

nave bayes

      

      

      

logistic regression

      

      

      

linear kernel svm
k u v    u  v    

     

      

      

normalized linear kernel svm

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

sigmoid kernel svm
k u v    tanh u  v     

      

     

      

norm  sigmoid kernel svm

      

     

      

      

      

      

      

      

      

k u v   

 


with

accuracy
  

with

accuracy with      
        

classifier

uv   

polynomial kernel svm   nd 
k u v     u  v     

 

norm  polynomial kernel svm   nd 
 

k u v      u  v     

 



polynomial kernel svm   rd 
k u v     u  v     

 

norm  polynomial kernel svm   rd 
 

k u v      u  v     

 



 

k u v    tanh  u  v     


gaussian kernel svm
  

k u v       u  v 

norm  gaussian kernel svm
k u v    

 


   u  v    

as we can see  in general  algorithms that use   as the feature mapping function do better 
which makes sense since   does not negate the resulting value if its arguments are flipped  while in
our data  if we switch fighter   with fighter    the resulting classification is reversed   as for    the
potential problem with it is that the value it returns is not normalized  so if we double the value of the
arguments  the value of  is also doubled    takes care of that for us fortunately  and also switching
the arguments reverses the value returned  which is negation in our case  
for the learning algorithms used  logistic regression does best  whereas naive bayes does
poorly and svm does decently in general  the reason that naive bayes does poorly could be that not
a lot of data was given to the classifier                training samples   and given the high
dimensionality of our data for the naive bayes classifier  the sparse data will not allow naive bayes
to learn well  hence its poor performance  as for svms  the accuracy depends partly on the kernel
being applied  where linear and gaussian seem to perform well for the most part as opposed to
polynomial and sigmoid kernels   logistic regression does well since instead of a linear dependency 
it assumes a logistic dependency  which is a dependency encountered more often with big data as
opposed to a linear dependency 

fiivan suarez robles  joseph wu  

clusters

slpm

str  acc

sapm

str  def

td avg

td acc

td def

sub avg

well rounded

    

    

    

    

    

    

    

    

the striker

    

    

    

    

    

    

    

    

the grappler

    

    

    

    

    

    

    

    

style

well rounded    
 striker     
 grappler     

grapplers tend to have an advantage over well rounded fighters      victories 
well rounded fighters tend to have an advantage over strikers      victories 
grapplers and strikers seem more evenly matched      for gapplers 
once we implemented the k means algorithm  the decision was to choose what value of k we
should use  which was based on our intuition and knowledge of mixed martial arts  we tried k        
  and chose the value  k      that made the most sense in clustering fighters by their styles  observe
the   clusters above  the well rounded fighter  the striker  and the grappler  the striker is
characterized by high significant strikes landed per minute  slpm   low takedown attempts  td
avg  and low submission attempts  sub avg   if the numbers could tell the story  this type of fighters
likes to stay on their feet and exchange punches and kicks  the grappler is characterized by a
different set of numbers  low slpm  high td avg  and high sub avg  this type of fighters likes to
bring the fight to the ground and avoid exchanging blows on their feet  the well rounded fighter has
medium slpm  td avg  and sub avg  and seems to be well versed in standing and on the ground 
assigning each fighter to a cluster allows us to observe any interesting tendencies that occur
when a fighter of a certain style is matched up with a fighter of another cluster  the results are
reported under the pie chart  

fiivan suarez robles  joseph wu  

fight

 return on     

market
probabilities

prediction

prediction
probabilities

aldo vs  mcgregor

       

          

aldo

            

weidman vs  rockhold

       

          

weidman

          

souza vs  romero

       

          

romero

          

maia vs  nelson

       

          

maia

          

holloway vs  stephens

       

          

holloway

          

faber vs  saenz

       

          

saenz

          

torres vs  lybarger

       

          

torres

          

alves vs  covington

       

          

alves

            

santos vs  lee

       

          

lee

          

proctor vs  mustafaev

       

          

proctor

          

makdessi vs  medeiros

       

          

makdessi

          

mcgee vs  alexandre jr 

       

          

mcgee

          

for the predictions above  we used our best performing algorithmlogistic regression with a
feature mapping function of                     the reported probabilities represent our values of
h x   these are compared with the market probabilities  which are computed from the betting odds
the public has generated  using the inverse relationship between betting return and favorability  
market probability fighter      betting return on fighter      betting return on fighter     betting
return on fighter    
we can see that only in   of the    fights  highlighted in yellow  do our predictions of the
winner deviate from the market  this shows that for the most part  our algorithm is consistent with the
intuition of the fans and betters of the sport 
section    future work
some ideas for future work are including more features  making predictions on other aspects
of fight outcomes  and running analysis on market predictions  for example  besides the   attributes
we used for this project  we can build a more comprehensive profile for each fighter by incorporating
height  reach  and past record or recent performance  all of which are very relevant to how a fighter is
expected to perform at the next fight  we can also make prediction not just on win or loss but on the
method of winning  knockout  submission  or judges decision  and the round in which the fighter
would finish the fight  lastly  we can extend on the market probabilities we calculated from betting
odds to compare the accuracy of market probabilities with the probabilities generated from learning
models 

fiivan suarez robles  joseph wu  

works cited
chih chung chang and chih jen lin  libsvm   a library for support vector machines  acm
transactions on intelligent systems and technology                      
chen  yi wei  and chih jen lin   combining svms with various feature selection strategies  
feature extraction studies in fuzziness and soft computing                 web 
kee  ying hwa  and c k  john wang   relationships between mindfulness  flow dispositions and
mental skills adoption  a cluster analytic approach   psychology of sport and exercise    
                 web 
salazar  d a  et al        comparison between svm and logistic regression  which one is better
to discriminate  revista colombiana de estadstica                      
schumaker  robert p   osama k  solieman  and hsinchun chen  sports data mining  new york 
springer        print 
singh  vik   betting on ufc fights   a statistical data analysis   viks blog  n p      sept       
web     dec       

fi