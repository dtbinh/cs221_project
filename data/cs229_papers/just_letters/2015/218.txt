  

a personalized company recommender system for job seekers
yixin cai  ruixi lin  yue kang

abstract
our team intends to develop a recommendation system for job seekers based on the information of
current employees in big companies  several models are implemented to achieve over     success
rate in classifying employees  and we use these models to help job seekers identify their best fitting
company 

   introduction
job seekers want to find the most satisfactory jobs through improving their resumes and working
experience  however  they lack effective guidance for improvement  they may also be curious about the
variant hiring criteria for different companies  and whether they possess certain qualities hiring managers
are looking for  by exploring and analyzing employees  features of big companies  such as apple 
facebook  and google  our team proposes an effective recommendation system to match job seekers to
their most suited companies 
our recommendation is composed of evaluating the features of current employees and classifying
them based on their companies  our target companies include apple  facebook and google  the
employees data are mainly retrieved from linkedin website  the procedure works as follows     collect
employee data and extract features     train different multinomial classification models  eliminate poorly
uncorrelated features  and keep features with high correlation     choose the optimal classification model 
   for a job seeker  predict the best fit company based on features of that person 

   related works
although there are few papers on company recommendation system  we could still find many research
results on similar topics like personalized music  movie  products  webpages recommender systems  and
group recommendations for social networks  douglas eck  thierry bertin mahieux and paul lamere    
developed music auto tagging system using meta learning algorithm  claudio biancalana    proposed a
method to recommend movie applying neural networks  yukun cao and yunfeng li    designed a fuzzybased system for consumer electronics to retrieve optimal products  lihong li  wei chu  john langford
and robert e  schapire    developed a personalized news article recommendation system by exploiting
contextual information about the users and articles  rafael sotelo  yolanda blanco fernndez  martn
lpez nores  alberto gil solla and jos j  pazos arias    proposed a tv program recommendation
approach  which created personalized tv schedules for groups of users based on tv anytime
descriptions of tv contents and semantic reasoning techniques  our team is inspired by the idea of
recommendation using classification  and we will implement a feature based multinomial classification
system to give job seekers best recommendation 

   dataset and features
    data collection
as mentioned before  we collect employee data from linkedin website  we have gathered     pieces of
information and divided the samples into a training set of     samples and a test set of     samples  in
particular  for the training set  we have     samples from google      from apple and     from
facebook  for the test set  we have    samples from google     from apple  and    from facebook  the
sample split is random  and later we used cross validation to verify the result 
    features
we first consider an employees industrial experience like years in industry  years in the current
company and past internship experiences  these features are reasonable indicators of a persons past

  

   

fi  
working experience  secondly  we explore feature related to the academic attributes of employees like the
highest degree and academic publication  personal skills are also taken into account  there are features
like the number of skills listed linkedin homepage and the number of the endorsement of the most
endorsed skill  finally  we consider some personalized attributes like gender and the employees
linguistic skills 
in summary  the features we are experimenting on right now include whether an employee has more
than   or   or    year s  working experience  whether he she has more than   or   year s  of working in
the current company  whether he she has a doctoral masters degree  whether he she has publications or
patents and the number of publications and patents  whether he she is multilingual  whether the number of
most endorsed skills is greater than twenty  whether he she has internship experiences in each of the three
companies  and finally the gender of an employee 

   methods
    labeling
there are several ways to give labels to the training set  for naive bayes and decision tree  the labeling
is not important  so we directly label the companies as         k    given k is the number of companies 
for svms  we decompose the multiclass classification problem into binary classifications  we generally
have   decomposition methods including one to rest  one to one  and an algorithm called errorcorrecting output codes  for each of the three methods  we need to build k  k  k       and n  code word
length n  classifiers respectively 
for neural network  we use one hot labeling  where google is          facebook is         and apple is
        
    models
      decision tree
one big problem with using decision tree model is that it will definitely have overfitting on the training
set  however  we can still get some good insight on training data  which includes whether the training set
is linearly separable  and how useful a feature is in classification 
      naive bayes  with smoothing 
we start from the naive bayes classifier we have implemented in problem set    and add one more
dimension to the labels  we also included smoothing to achieve a better result 
      svm  linear kernel and gaussian kernel 
we assume that the input data is linearly separable and build binary linear svm classifiers  for the
multi class problem  we adopt all of the three decomposition methods 
one to rest decomposition  we build three binary classifiers  for each classifier  the label is   for
interested company  like facebook      otherwise 
one to one decomposition  we build three binary classifiers including google vs  facebook  google vs 
apple  and apple vs  facebook  label one of the companies as    rest    
error correcting output codes  ecoc   we choose a code length of   and build   binary classifiers  for
details of the ecoc algorithm  please refer to online documents 
we also use svm classifier with gaussian kernel for comparison 
      neural network
we created the neural network with   hidden layer and   hidden layers  the input layer has dimension
of       the size of each hidden layer is      the function on hidden layer is hyperbolic function  tanh  
the output layer has dimension      finally we use a softmax function to produce the final one hot label 
the loss function is the negation of log likelihood plus a regularization factor  we used l  regularization
with lambda equal to        

  

   

fi  

   experiments and results
    f  scores using different methods
for naive bayes  we build our own model using matlab  we utilized the python scikit learn
packages to test the result of svm and decision tree  the neural network is built using java  the results
of these algorithms are shown in the table   
model
decision tree
naive bayes
support
neural
neural
 with
vector
network   
network   
smoothing 
machine
hidden layer 
hidden layers 
f  score
      
      
      
      
      
table    f  score of different models
as expected  decision tree works worst  since it has overfitting problem on the training set 
for naive bayes  the result without smoothing is worse than svm and neural network  however  if we
eliminate some features  we can get a result of         which is slightly worse than svm 
for svm  the linear kernel svm with ecoc or   v rest decomposition works best and achieves an f 
score of         which slightly outperforms the other decomposition scheme    v    with a f  score of
         the three decomposition methods do not make a big difference to results  so we built another
linear kernel classifier without decomposition methods and found a result of         which is same as
the best result we have obtained  when we build the gaussian kernel classifier  we again did not use any
decomposition method  it gives a result of         which is worse than the linear kernel classification
results 
for neural network  since there could be some local maximum  we have decided to train the model
multiple times with random weight initialization and choose the one with best result  minimal loss   by
tuning parameters  we have found that the best learning rate is        the best number of iterations is   
for one hidden layer     for two hidden layers  the number of hidden layer and the number of items in
hidden layers do not affect the result 
in addition  we have discussed about the findings on facebook in milestone report  where none of the
classifier can label facebook employees correctly  the further investigation of this phenomenon is
included in the next section 
    confusion matrix
test set
company
google
facebook
apple

precision
      
      
      

recall
      
      
      

f  score
      
      
      

train set
company
precision
recall
f  score
google
      
      
      
facebook
      
      
      
apple
      
      
      
table    confusion matrix from neural network on train set and test set
the confusion matrix in the table   illustrated some interesting phenomenon on google and facebook 
similar patterns are observed not only in neural network  but in other models as well  we can see google
has low precision and high recall  while facebook has high precision and low recall  this means we tend
to correctly classify google employees  but we also include employees from other companies  for
facebook  we are pretty confident with employees labeled with facebook  but we still classify true
facebook employees to other company  there could be several reasons for this behavior  maybe some of
facebook employees share a strong pattern  it is also possible that google does have a diverse employee

  

   

fi  
body  so it is hard to tell who is real google employee  in the future we may further investigate this
behavior by collecting more data 
    feature analysis
      feature effectiveness analysis

figure    feature analysis across different methods
we tested feature effectiveness by excluding one feature and see the result change in different models 
the results are shown in figure xx  we can see that each model has its own ineffective features  and it is
hard to identify any feature that is not effective for all models  on the other hand  if we exclude the
feature of facebook internship  we can see a significant f  score drop in all models  it is obvious that
facebook internship is the most effective feature 
      feature weight examination
we have examined the weight of each feature on each company in naive bayes model  and we have
some interesting findings 
apple has more employees with long years of industrial experience  there are more long time
employees in apple than the other two companies  also apple favors people with many skills 
google has the most employees who just joined the company  there are also more google employees
with master s degree and bilingual multilingual abilities 
facebook has most employees who have been in the company for   to   years 
finally  internship experience plays a significant role in classifier  the companies all have a significant
percentage of employees who have former internship experience in current company 

  

   

fi  
      fold cross validation
at the final stage    fold cross validation is applied to help evaluate different models  we split all the
    data samples into   disjoint subsets randomly  repeatedly trained on   of the subsets and then tested
on the left one subset 
      svm
for the svm with linear kernel and gaussian kernel  following result is obtained  it is easier to see that
the f  score of svm using cross validation is similar to the result in section     
test set
 
 
 
 
average
test f  score  linear 
test f  score  gaussian 

      neural network
test set
test f  score
train f  score

      
      
      
      
      
      
      
      
table    f  score of svm with cross validation

      
      

 

 

 

 

average

      

      

      

      

      

      
      
      
      
table    f  score of neural network with cross validation

      

since the average f  score on training set is pretty close to the average f  score on test set  we are
confident that our implementation of neural network will not overfit the train set  and the result is quite
close to the to the generalized accuracy 

   conclusions and future work
our team is pretty happy with our result  using either svm or neural network  we are able to achieve
f  scores around     on test set  since training error is close to test error  our models do not overfit train
set and is a good estimate of the generalized error 
also  our team has found some interesting features that different companies looked for  before this
project  we have heard some rumors  such as masters degree is important to get in google  and apple
favors experienced employees  we are glad to have proved these claims after the project 
in addition  our model recommended google to all of our team  which does support our finding that
google includes everyone  the possible future works include expanding the number of companies and
include more features to receive a more diverse recommendation system 

  

   

fi  

references
    douglas eck  thierry bertin mahieux  paul lamere  and stephen green  automatic generation of
social tags for music recommendation  neural information processing systems conference  nips     
vancouver  british
   claudio biancalana  fabio gasparetti  alessandro micarelli  alfonso miola  and giuseppe sansonetti 
context aware movie recommendation based on signal processing and machine learning  proceedings of
the  nd challenge on context aware movie recommendation  p       october              chicago 
illinois
   yukun cao  and yunfeng li  an intelligent fuzzy based recommendation system for consumer
electronic products  expert systems with applications  an international journal  v    n    p         
july      
    lihong li  wei chu  john langford  and robert e  schapire  a contextual bandit approach to
personalized news article recommendation  in proceedings of the nineteenth international conference on
world wide web      
    rafael sotelo  yolanda blanco fernndez  martn lpez nores  alberto gil solla  and jos j  pazosarias  tv program recommendation for groups based on muldimensional tv anytime classifications 
ieee trans  consum  electron   vol      no     pp           feb      

  

   

fi