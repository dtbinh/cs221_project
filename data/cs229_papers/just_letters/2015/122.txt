condition monitoring using accelerometer
readings
cheryl danner  kelly gov  simon xu
stanford university
abstractin the field of condition monitoring  machine learning techniques are actively being developed to detect and or
predict faults in equipment  in this paper  the authors prototype
a process to monitor the condition of rotating machinery using
accelerometer readings  time domain and frequency domain
features are used to categorize data samples  with performance
compared for three supervised learning algorithms  logistic
regression  naive bayes  and svm  two unsupervised learning
algorithms  k means and mixture of gaussians  are investigated
for use in filtering data initially and identifying machine malfunctions  logistic regression gives the lowest error rate in tests
run on the available dataset  classifying all test samples correctly
using time or frequency features  a combination of k means and
mixture of gaussians algorithms shows potential for filtering data
and identifying machine malfunctions 

i  i ntroduction
in the industrial and manufacturing world  a vibration
analysts job is to diagnose problems with rotating equipment 
thus  analysts must familiarize themselves with typical spectra
of various machinery in order to identify machine malfunction
and distinguish bad channels erroneous readings 
for our project  we plan to use machine learning techniques
to develop a few aspects of a condition monitoring algorithm 
characterizing typical states for different types of equipment
and identifying erroneous readings  performance on these tasks
will be compared using time domain features and frequency
domain features 

around the frequencies that are indicative of faults      this is
good for certain fault patterns  such as the raised harmonics
present in mechanical looseness  but not so good for other
common problems  such as rolling bearing wear  which are
present in subharmonic frequencies  while there are simpler
techniques  a trained machine learning algorithm can be the
most effective at classifying machinery problems from spectral
patterns 
iii  dataset and f eatures
to train and test our models  we have obtained several
datasets from different rotating machines  labeled m   m  
m   and sn    which refer to a feed pump  a condensate
pump  the motor driving the condensate pump  and a shaker
motor  respectively  the data obtained is raw time history data
consisting of approximately      time points per sample  this
data has been post processed into acceleration and velocity
in each of the x  y  and z directions  we have further
applied a fast fourier transform  fft  to convert the data
into the frequency spectrum  figures   shows unprocessed
accelerometer measurements  and figure   shows fft output
for the sn    machine 
fig     example of waveform data from sn   machine

ii  r elated work
in the new and developing field of condition monitoring
and predictive maintenance  many different approaches have
been explored by companies and researchers  some groups
use support vector machines for classification      others use
bayesian models  and still others use artificial neural networks
 anns       using a combination of techniques can lead to a
more accurate solution  especially as machines can be highly
variable  not only are the machines different  but they can
have different operating conditions  although there is a lot
of interest in using anns to do predictive maintenance  it
takes a long time to train  and the black box nature of the
neuron node matrix limits traceability  since vibration science
is highly empirical  having a way to identify the reasoning
behind an algorithms decision is very valuable  in this nascent
stage  using some other techniques would be helpful for
troubleshooting  but as condition monitoring becomes more
advanced  anns may become a good choice  outside of
machine learning  other alarm techniques set bandpass filters

two classes of features were used  time domain features and
frequency domain features  in the time domain  rms  peak 
kurtosis  and crest factor were calculated from experimental
accelerometer time history data for both acceleration and
velocity in each of the x  y  and z directions for a total of
   time domain features  these time domain features were

fifig     example of frequency spectrum of data from sn   machine

table i
data filtering using threshold for z velocity rms

total samples
  retained
  filtered out
  filtered out

m 
    
    
   
   

m 
    
   
    
   

m 
    
   
   
   

sn  
    
    
   
   

although it would be possible to have an expert select
upper and lower thresholds to implement rms filtering for
each machine  alternative approaches may be able to lower
the amount of manual work 

selected for being relatively straightforward to calculate and
their utility in other condition monitoring studies         
in the frequency domain  the power spectra for acceleration
and velocity in each of the x  y  and z directions were
calculated with a resolution of   hz resulting in       
features  to reduce the number of frequency domain features 
correlation was done using octaves built in function corr 
features which exhibited low correlation with machine type
were discarded in our model  this proved to be problematic
in the implementation of naive bayes  as the features that
remained were those with strong peaks in the m  data  due
to the implementation of multinomial naive bayes  this biased
the algorithm toward predicting m   and it was unable to
function properly  this issue may be avoidable by normalizing
the features so that the large magnitude difference in frequency
features between different machines is no longer a factor 
after correlation analysis and experimentation  we restricted
the frequency domain features to the z velocity set      
features   as this provided sufficient information to create
accurate prediction models 

a  methods
   k means  one approach uses k means to cluster the data
and select the cluster that is closest to expected measurement
values  here  x  y  and z velocity rms were used because
clusters using these features mapped most closely to the results
from the manual rms filtering method  the expected values
are defined by selecting the peak bin from a histogram of the
full data set while ignoring the extreme highest and lowest
bins  for example  figure   shows the histogram of y velocity
rms values for the sn   machine  where the expected y
velocity value was determined to be     mm s  for each
machine  the k means algorithm was run     times  and the
cluster with a centroid closest to the expected values was
declared to be correct measurements 
   mixture of gaussians  the same procedure was implemented using mixture of gaussians as the clustering algorithm
instead of k means  this used the em algorithm to converge to
a solution  since the converged solution depends on an initial
guess  this is best identified by using the best k means result
to create a starting point 
fig     histogram of y velocity rms values for sn   machine

iv  data filtering
after starting work with the original dataset  m  and m 
machines only   we discovered anomalies in the data  these
anomalies are unsurprising  as the company is currently still
in the development phase of using low cost sensors which
can diminish data fidelity  although it cannot be conclusively
determined whether data from a particular measurement was
erroneous or not  we used a heuristic to filter the data  if
the z velocity rms lands within a range of values  the
measurement is considered to be correct  values near zero and
extremely high values are considered erroneous  when data
points classified as incorrect using this rms filtering method
were discarded  performance of algorithms to discriminate
across machine types  discussed in section v  improved
significantly  for the m  and m  machines  a large percentage
of samples were discarded  but the m  and sn   machines
had most of their data retained  as shown in table i 

b  results
since it is not known which data samples are correct versus
erroneous  an error rate against the correct labeling cannot

fibe calculated  instead  classification results from the k means
and mixture of gaussians methods were compared against the
labeling produced by the rms filtering method  the resulting
error rates in table ii can be interpreted as measuring the
algorithms ability to match results produced by a human  the
k means clustering was better able to achieve this objective 
with error rates of less than    for m   m   and sn  
machines  the automatic filtering was not able to closely
match the rms filtering for the m  machine  which had a
much larger spread of values compared to the other machines 
the large discrepancy with the m  data is mirrored by a
large distance from the expected value  so there is at least
an indicator of poor performance 

fig     k means clustering for the sn   showing x and y velocity values
with a green point representing expected values overlaid

table ii
d isagreement between data filtering algorithms versus
manual rms filtering

k means
mixture of gaussians

m 
   
   

m 
    
    

m 
    
    

sn  
    
     

figure   shows sample z rms velocity values over time
for k means with the manually selected upper and lower
bounds used for filtering overlaid  figure   displays the same
clusters plotted using the x and y rms velocity values 
the two other features used for clustering  the green dot
shows the expected values for correct measurements based on
measurement histograms 
fig     k means clustering for the sn   machine with manually selected
rms thresholds overlaid as black lines

v  c lassification
ideally  a database containing labeled examples of machine performance under different faulty conditions would
be available to train learning algorithms  however  such an
extensive data set is not currently available for the set of
machines being examined  one of the four machines  sn   
was labeled as malfunctioning for    data points  because

there was insufficient data to classify various fault states  we
classified data samples as coming from one of four machines
as a proof of concept  additionally  the mixture of gaussians
method was applied to the machine for which data points from
a malfunctioning state were available 
a  methods
three different learning algorithms were applied to both
time domain and frequency domain feature sets  cross validation used to compare performance of the different algorithms
with     of the filtered data used for training and     of the
data held out for testing  unfortunately  there were only a few
measurement points that had the malfunction label  so the size
of this training set is less than the number of features 
   logistic regression  one method used to classify data
from the four different machines was multinomial logistic
regression  implemented using matlabs mnrfit and mnrval
functions  for the time domain feature set  all features were
used  but the frequency domain set  although restricted only
z velocity  needed to be reduced to allow the algorithm to
run in a reasonable amount of time  the reduced number
of features has the added benefit of reducing the risk of
overfitting  logistic regression was run on the frequency data
using    features     features  etc   and the resulting test error
rates were compared 
   naive bayes  the multinomial naive bayes algorithm
was used on the frequency spectrum data in order to classify
data by machine type  the frequency of occurrence of each
token was represented by the power at each frequency  value
of the feature   from the time domain side  we used a feature
set of    calculated time domain values for each measurement
sample  by calculating the posterior with bayes theorem 
we can classify machine state by selecting the state with the
highest likelihood  this method makes a critical assumption
that the data are independent and identically distributed  which
is not an accurate assumption in this case 

fitable iii
t est error rates for three learning algorithms applied to

fig     multinomial classification results for logistic regression on time data

time domain and frequency domain feature sets

learning algorithm
logistic regression
naive bayes
svm

time domain
    
   
     

frequency domain
     
     
     

     frequency domain features used for logistic regression

   svm  we classified our data into the four machine
categories using the svm algorithm through the libsvm
library  we assessed test error rates using a linear kernel
with default parameters  followed by higher degree polynomial
kernels and modifications to the cost value and libsvms
polynomial kernel coefficient gamma 
b  results
   logistic regression  when    frequency domain features were used  the error rate for logistic regression was    
but dropped to       using    features and    for    to    
features  this result is shown in figure    using time domain
features  logistic regression was again able to correctly classify
the test set with no errors 
using the set of same    frequency domain features on
pre filtered data  the error rate was      using time domain
features on pre filtered data gave an error rate of      
   naive bayes  classifying the test data into four machine
categories through the naive bayes algorithm with     
frequency domain features resulted in an error rate of       
this result is shown in figure    using the    time domain
features  the error rate was much higher  at     
   svm  when using the svm algorithm with the frequency domain features on the full dataset  good  bad  and
malfunctioning   the error rate was initially        through
optimization of the kernel function and parameters  this was
reduced to      
when using only good and malfunctioning data  throwing
out the bad data   the svm with a linear kernel and default
parameters was able to achieve an error rate of just       
this result is shown in figure   
   mixture of gaussians  the mixture of gaussians method
was able to identify clusters of nominal and malfunctioning
data for the sn   machine using only two time domain
features  figure   shows the resulting gaussians 
vi  c onclusion and future work
machine learning can be successfully applied to classification based on accelerometer data using either frequency
domain or time domain features by applying a three step
process     sort good data from bad data     categorize data
into one of several expected states     identify data that
represents malfunction for that state  good data must be sorted
from bad data  as sensor measurements are sometimes noisy
and prone to error  a model for good vs bad data can be

fig     multinomial classification results using naive bayes on frequency
data

generated using unsupervised learning methods such as kmeans initially  and then that model may be applied to the test
data to determine whether the data may be further processed
for classification 
for machine type classification  as a stand in for machine
state based on limited available data as proof of concept  
logistic regression with a subset of available features is extremely accurate on both time and frequency domain data 
svm also provides high accuracy on both feature sets  naive
bayes works well on the frequency domain feature set  but
performs poorly on time domain data  for our purposes  we
recommend using logistic regression 
once the machine type  state  is known  unsupervised
learning methods such as mixture of gaussians may be applied
to find data that represents a malfunction 
a drawback of this approach is that a new test sample
that is matched against these pre defined gaussians may be

fifig     multinomial classification results using svm on frequency data

acknowledgment
the authors would like to thank petasense  for providing
the data that was used to develop this prototype process 
r eferences
    a  widodo and b  s  yang  support vector machine in machine condition monitoring and fault diagnosis  mechanical systems and signal
processing  vol      no     pp                 
    a  k  nandi  c  liu  and m  l  d  wong  intelligent vibration signal
processing for condition monitoring  pp      
    g  a  hassaan  frequency spectrum filtering for machinery fault
diagnostics  vol     no     pp               
    a  k  jardine  d  lin  and d  banjevic  a review on
machinery diagnostics and prognostics implementing conditionbased maintenance  mechanical systems and signal processing 
vol      no     pp                   online   available 
http   linkinghub elsevier com retrieve pii s                
    h  e  kim  a  c  tan  j  mathew  and b  k  choi  bearing
fault prognosis based on health state probability estimation  expert
systems with applications  vol      no     pp                   online  
available  http   linkinghub elsevier com retrieve pii s                

fig     sn   data points plotted for two time domain features with pdf
contours overlaid and surrounding nominal and malfunctioning data points

classified as good instead of malfunctioning because the
characteristics of this new type of malfunction may be far
from those of the malfunction in the dataset from which the
gaussians were computed  an approach to minimize this type
of error would be to create a single gaussian over only the
good data  a threshold could be set  for example  two or three
standard deviations from the mean  such that if a new sample
is below that threshold  it warrants further analyst attention as
a potential malfunction 
because machines can fail in a finite number of ways  it is
theoretically possible to collect a dataset that includes samples
in all malfunction states  using this full dataset  supervised
learning may be employed to create a definitive model against
which to classify future samples  this is a recommended next
step to a party with access to such a dataset 

fi