predicting song popularity
james pham

edric kyauk

edwin park

jqpham stanford edu
department of computer science
stanford university

ekyauk stanford edu
department of computer science
stanford university

edpark stanford edu
department of computer science
stanford university

abstractpredicting song popularity is particularly important
in keeping businesses competitive within a growing music industry  but what exactly makes a song popular  starting with
the million song dataset  a collection of audio features and
metadata for approximately one million songs  we evaluated
different classification and regression algorithms on their ability
to predict popularity and determined the types of features that
hold the most predictive power 

i  i ntroduction
music has been an integral part of our culture all throughout human history  in      alone  the u s  music industry
generated     billion  of this     billion  the majority of the
revenue is generated by popular  mainstream songs  having a
fundamental understanding of what makes a song popular has
major implications to businesses that thrive on popular music 
namely radio stations  record labels  and digital and physical
music marketplaces 
the ability to make accurate predictions of song popularity also has implications for customized music suggestions 
predicting popular songs can be applied to the problem of
predicting preferred songs for a given population 
making predictions of song popularity based on machine
learning  often referred to as hit song science  is a problem
that has gained a lot of traction within the past    years  many
private companies in the music industry are working on this
problem  but details about the success of these companies are
held private for competitive reasons 
our project focuses on predicting whether or not a song is
popular based on a number of characteristics of the song and
its artist  the input for our algorithm is a list of song characteristics consisting of both acoustic features and metadata  we
then use a number of machine learning algorithms  svms 
neural networks  logistic regression  gaussian discriminant
analysis  and linear regression  to output whether or not the
song is popular  or in the case of linear regression the score
of the song popularity  
ii  r elated w ork
the problem of predicting popularity is one that has been
heavily researched  salganik  dodds  and watts conducted an
experimental study on popularity that focused heavily on the
social influence of popularity  they found that the quality of a
song only partially influences whether or not a song becomes
popular  and that social influence plays an extremely large role
     therefore  our project aims to use both acoustic features

and metadata features to create a more accurate prediction
model 
the work by koenignstein  shavitt  and zilberman  which
predicts billboard success based on peer to peer networks 
potentially captures this social influence on song popularity 
this group was extremely thorough with their work and
used multiple regression and classification algorithms for their
predictions     
bertin mahieux et al  found that machine learning techniques can be used to apply labels to songs based on acoustic
features  they created a model for predicting social tags from
acoustic features on a large music database by using adaboost
and filterboost      while this group was extremely thorough
with considering the possible models to use and sanitizing their
features  using svms instead of adaboost with filterboost
may have been a better option 
however  pachet and roy investigated the problem of
making predictions of song popularity and made the blunt
claim that the popularity of a song cannot be learnt by using
state of the art machine learning      in order to test the effectiveness of current machine learning algorithms  they test the
improvement of their classification models to a generic random
classifier  similarly to our work  pachet and roy consider both
acoustic features and metadata  however  the study deals with
an extremely large number of features  over      but does
not mention any type of feature selection algorithm  as a
result it is extremely likely that their model was subjected to
overfitting  pacet and roy also considered features commonly
used for music analysis which potentially could have affected
the success of their results 
however  ni et al have responded to the above definitive
claim with more optimistic results on music popularity prediction  using a shifting perceptron algorithm to classify the
top   hits from the top       hits  a slightly different problem
from the aforementioned study       however  this study also
uses more novel audio features which is a likely factor in their
improved results 
iii  dataset and f eatures
a  data
we used music data from the million song dataset     
the million song dataset is an exhaustive collection of
audio features and metadata for one million songs dating to
      the audio features include attributes about the music
track itself  such as duration  key  year  the metadata uses

fimore abstract features  such as danceability  energy  or song
hotttnesss  generated from the echo nest  a music intelligence
platform  our project uses a subset of this data  we extracted
       tracks from the database and of those        tracks 
we removed all tracks that were missing any of features we
were considering  this left us with       tracks  we divided
these tracks so that     of the tracks was used for training
and     was used for testing  below is a subset of the fields
for a song in the datset 
feature
key
loudness
mode
mode confidence
release

type
int
float
int
float
string

description
key the song is in
overall loudness in db
major or minor
confidence measure
album name

b  feature extraction
   baseline features  the million song dataset contains a
plethora of feature types  ranging from number type features
such as those that measure the general loudness of a song 
string type features such as names of artists and albums  and
array type features such as those that contain pitches across
the length of the song  all array type acoustic features contain
measures for segments across the song  we included the mean
and variance throughout all of the segments as features 
   additional features  by looking at plots of different
features vs  song popularity  we saw that there were some nonlinear relationships  by squaring the values  we were able to
capture polynomial relationships between some of our features
and the popularity  additionally  to avoid constraining our
model under an additive assumption  we also incorporated
some interaction terms  e g  tempo  major minor  to capture
multiplicative effects 
   bag of words  our dataset includes many string features 
including song name  artist id  and terms that the artist is
frequently associated with  genre   in order to capture these in
our model  we used a bag of words approach and added the
top     frequently occurring words as term frequency features
in our model 
c  popularity

result  using all features suffered from overfitting  in order
narrow down the number of features and find the most relevant
features  we conducted several feature selection algorithms 
   forward stepwise selection  forward selection greedily
chooses the best combination of features by starting with an
empty subset of features  then incrementally adding a feature
to the model that was selected through evaluation of the feature
subset through cross validation  this step is repeated until
the generalization error is minimized and the best subset of
features is reported 
   backward stepwise selection  backward stepwise selection works similarly to forward stepwise selection  however 
instead of starting with an empty subset of features  it begins
by evaluating the use of all features and incrementally removes
features until the model is optimized 
   l  regularization  l  regularization is a shrinkage
method that regularizes the coefficient estimates by shrinking
the coefficients towards zero  regularization often improves
the fit because reducing coefficient estimates can significantly
reduce their variance  thus decreasing the effect of overfitting 
min


iv  m ethods
a  feature selection
in total  our final dataset consists of     features  many
of which were not relevant to predicting popularity  as a

 y  i   t x i       

i  

n
x

 j  

j  

by increasing the tuning parameter   the shrinkage penalty
term effectively serves to force some coefficient estimates
to become exactly equal to zero  l  regularization has an
advantage over l  regularization in that the models obtained
by l  regularization are easily interpretable  setting some
coefficient estimates to zero is essentially performing feature
selection  tuning  has a bias variance trade off  increasing 
decreases the flexibility of the fit but also increases bias 
b  classification
   logistic regression  we used logistic regression with l 
regularization  logistic regression selects the parameter  that
maximizes the likelihood function 
l    

m
y
i  

the echo nest provides social field for a song called song
hotttnesss which we will use as our metric of popularity  while
the exact calculation of this field is not released  the metric is
generally based upon total activity they see for the songs on
the thousands of websites that echo nest uses  songs with a
hotttnesss value above a threshold were classified as popular 
in our case  we defined songs as popular if they were in the
top     of song hotttnesss  we set this threshold to be       
since this was the   th percentile for our dataset 

m
x

 i 

 i 

p y  x      

m
y

 i 

 h  x i    y   h  x i    y

 i 

i  

where
h  x    g t x   

 
    et x

   linear discriminant analysis  lda   we used lda 
which is a specific method of gaussian discriminant analysis 
to build our classifier  lda assumes that samples have come
from a multivariate gaussian distribution with a specific mean
vector and a covariance matrix that applies to all classes  lda
is similar to logistic regression in that they both produce linear
boundaries and thus similar results  but lda tends to perform
better when the gaussian assumptions are met 
  

 
t  
p x       
exp

 x

 

 x

 
 
   n        

fi   quadratic discriminant analysis  qda   similar to
lda  qda is another specific method of gaussian discriminant analysis that assumes that samples come from a
multivariate gaussian distribution with a specific mean vector 
however  unlike lda  it assumes that each class has its
own covariance matrix  by estimating multiple covariance
matrices  qda allows for more flexible fit by allowing nonlinear boundaries 
  

 
t  
exp

 x 

 x 
p x    k    
k
 
   n    k     
   support vector machines  svm   we also leveraged
support vector machines to classify our data  to create an
optimal margin classifier  a decision boundary or separating
hyperplane can be calculated that maximizes the distance
of the nearest points of any class to the decision boundary 
for svms to perform efficiently in high dimensional spaces 
svms leverage the kernel trick  which allows for computation
without having to explicitly represent the high dimensional
feature vectors 
m
m
x
  x  i   j 
y y i j hx i    x j  i
max w     
 i  

 
i j  
i  

fig     forward stepwise feature selection

fig     backward stepwise feature selection

s t     i  c  i           m
m
x

i y  i     

i  

we used a gaussian radial basis function  rbf  kernel to
create a non linear classifier by transforming the feature space 
   x  z    
k x  z    exp
   
   multilayer perceptron  we also used a multilayer perceptron classification algorithm  an example of a neural network model  the mlp consists of a directed graph  where
possibly different dimensional layers of nodes are all fully
connected  the first layer of nodes embody the original set
of features  and the final layer of nodes represents higher
level features influenced by multiple original features  the
weights of these nodes are learned through backpropagation 
to minimize the error of the output  we use stochastic gradient
descent to find the change of each nodes weight and the
activation function y vi     tanh vi   to map the weighted
inputs to the output of each neuron 
 x  
e n   
e  n 
  j j
e n 
wji  n    
yi  n 
vj  n 
c  regression
seeing our classification results  we noticed that classification approaches lose valuable information about the value
of the song popularity itself due to the binary conversion 
as a result  we also use regression to predict the values of
popularity  for regression  we fitted models using a standard

fig     most important variables

multiple linear regression  and applied feature selection methods to achieve the best coefficient estimates for regression 
for feature selection  we evaluated each model of size       m
features using cross validated mean squared errors 
v  e xperimental r esults
a  feature selection
for both forward stepwise selection and backward stepwise
selection methods  we determined the optimal number of
features in our fitted model by seeing which set of features
gives the smallest cross validation error  from a model with
    features  forward stepwise selection chose a model of
   features  see fig      whereas backward stepwise selection
chose a model of    features  see fig      in both feature selection methods  significant features included artist familiarity 
loudness  year  and tag words such as alternative  guitar 
and jazz  see fig     

fifig     roc curve for svm with gaussian kernel

model
svm  linear kernel 
svm  rbf kernel 
logistic regression  lr 
lda
qda
multilayer perceptron  mlp 

auc
    
    
    
    
    
    

fig     auc for classification models

model
svm  linear 
svm  rbf 
logistic reg
lda
qda
mlp

p
     
     
     
     
     
     

r
     
     
     
     
     
     

f 
     
     
     
     
     
     

train
     
     
     
     
     
     

test
     
     
     
     
     
     

fig     classification results   train  test  accuracy

b  classification
   metrics  since we set our threshold such that     of
the songs in our dataset are classified as not popular and
    are classified as popular      accuracy can be achieved
by predicting all  s  therefore  we concluded that accuracy
alone would not be a good measure of how well our model
can classify  in order to capture this  we also considered the
precision  recall  f   and auc scores of our models 
precision  recall  and f  score are used to capture how well
our model does in the task of classification  precision measures
the portion of examples that were classified as popular that are
truly popular while recall measures the portion of examples
that are truly popular that our model classified as popular  f 
score acts as the weighted average between these two values 
the area under the receiver operator characteristic curve
is a metric used to evaluate the performance of a binary
classifier by taking the area under a curve created by plotting
tpr vs  fpr at different probability thresholds  the auc
represents the probability that the classifier ranks a random
positive example higher than a random negative one 
   tuning parameters  with respect to the kernels used
by our svm models  we optimized two parameters  c and
  c determines the trade offs between misclassification and

simplicity of the decision surface   determines the weight of
a single training example  we used    fold cv to tune the c
and  parameters  for the linear kernel  c and  were chosen
to be   and n  respectively  and for the rbf kernel  c and 
were chosen to be    and       respectively 
additionally  we used    fold cv to tune two parameters for
the mlp  we chose tanh x  to be the activation function for
the hidden layers of nodes  and we chose stochastic gradient
descent to be the algorithm for node weight optimization 
   results  see fig        and   
   discussion  the algorithm with the highest f  score
was the svm using a gaussian kernel  considering the fact
that the svm with a linear kernel had a lower f  score than
the gaussian kernel  our data is likely non linear  as a result 
svms using a gaussian kernel would naturally perform better
than the other models that assume linearity  additionally 
higher f  scores were achieved using the rbf kernel over the
linear kernel suggesting nonlinear relationships between the
audio metadata features and popularity 
however  there were no significant differences in the performance among all our our tested models  f  scores all ranged
between     and     and the accuracies all ranged between
     and       this could be due to the fact that all of our
classification algorithms assume the data is linearly separable  and the data was mostly likely not linearly separable 
the differences in the performance of these models can be
attributed to the tradeoffs made in the algorithms  for example 
svms are primarily influenced by the data points closest to
the margin  while logistic regression and other models are
influenced by all data points  svms also perform better in
problems with a high number of dimensions 
we chose our hotttnesss threshold to consider the top    
of songs to be popular  songs with a hotttnesss larger than
        we initially chose a threshold that considered the
top     of songs to be popular and were receiving fairly
low metrics across the board  including precision  recall 
f  score  and accuracy  we hypothesize that this happened
because popular songs  which we predict to have defining
characteristics  in reality are only a small subset of all songs 
therefore  the top percentile of popular songs that had these
defining characteristics were confounded by the more songs
we labeled as popular  as a result we changed our threshold
to classify the top    as popular  this increased the accuracy 
but it was the result of our algorithms predicting that all songs
were not popular  a fact that was reflected in recalls of   
a likely cause of this result is a lack of popular training
examples  by using the top     of songs as popular  we are
able to have songs with defining characteristics in addition to
enough popular examples to properly train our models 
c  regression
   metrics  in the regression setting  we use mean squared
error  mse  to evaluate how well our model predicts popularity  the average error is obtained by taking the square
root of the mse  which approximates the standard error of

fifig     cross validation for optimal  for lasso

model
baseline
full model  n       
selected model  n      
lasso             

mse
       
       
       
       

avg error
      
      
      
      

fig     regression results

our predictions  therefore  the smaller the mse  the higher
confidence we have about our predictions 
   tuning parameters  the  parameter for l  regularization was tuned using    fold cross validation 
in addition  the number of features to use for determining
forward and backward stepwise feature selection was obtained
using    fold cross validation 
   results  see fig    
   discussion  according to the results in fig     seeing
that the test error increases from the baseline model    
features  to the full model      features   we can conclude
that adding a lot of additional bag of words features leads
to overfitting to noise in our training set  however  by significantly reducing the number of features to    using forward
feature selection  we were able to significantly decrease the
variance of our fit and consequently reduce overfitting 
overall  the smallest test error among our models is
achieved by using lasso regression     fold cross validation
is used to choose the optimal value of   which turns out to
be          over a grid of log  values   see fig      lasso
regression gave an output of    different features with nonzero coefficient estimates  the features chosen by the lasso
are very similar to the ones produced by forward and backward
feature selection 
our feature vector is generally very sparse due to the large
number of bow binary features  so stepwise selections greedy
approach may not work as well as lassos shrinkage method 
vi  c onclusion
through several different feature selection algorithms  we
were able to identify the most influential features in our
dataset by taking the intersection among the feature selection
algorithms  namely artist familiarity  loudness  year  and a
number of genre tags  all of the features can be seen in fig    
we found that the acoustic features arent nearly as predicative

fig     features names scaled by the log of coefficients for linear regression

as the metadata features  a likely reason for this is that there
is a lot of variation in acoustic features within a single song
that make it difficult to extract metrics that represent an entire
song  metadata such as genre tags or year of release are much
better at accurately reflecting a trait of a song 
currently  the features we used divided the range of pitch
and timbre into buckets  however  because the original data
consists of time series data points with respect to these
values  we could add features that represent the transition
between certain pitch values  an n gram type model using
sequences of pitches loudness as features would allow us to
investigate if particular pitch intervals have any influence on
song popularity 
in addition to using the song hotttnesss metric  we can also
create our own metric of popularity  which we can define as
the number of downloads on itunes or the number of plays
on spotify  this would allow us to more accurately capture
what we define to be popular and allow us to generalize our
findings to commonly understood metrics  furthermore  we
can potentially extend the application of this project to a song
recommendation system  training a model on examples with
the most number of plays labeled as popular could lead to
personal playlist or song recommendations 
r eferences
    bertin mahieux  thierry  et al  autotagger  a model for predicting social
tags from acoustic features on large music databases  journal of new
music research                      
    hastie  trevor  and hui zou  regularization and variable selection via
the elastic net  j r  statist  soc  b       
    james  gareth  daniela witten  trevor hastie  and robert tibshirani  an
introduction to statistical learning  springer texts       
    koenigstein  noam  yuval shavitt  and noa zilberman  predicting billboard success using data mining in p p networks  multimedia       
ism      th ieee international symposium on  ieee       
    ni  yizhao  et al  hit song science once again a science   th international workshop on machine learning and music  spain       
    pachet  franois  and pierre roy  hit song science is not yet a science 
ismir       
    salganik  matthew j   peter sheridan dodds  and duncan j  watts 
experimental study of inequality and unpredictability in an artificial
cultural market  science                          
    thierry bertin mahieux  daniel p w  ellis  brian whitman  and paul
lamere  the million song dataset  in proceedings of the   th international society for music information retrieval conference  ismir       
     

fi