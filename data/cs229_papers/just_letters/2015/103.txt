parameter estimation with mock algorithm
bowen deng  bdeng  
november         

 

introduction

wine quality has been considered a difficult task that only few human expert could evaluate 
however  it is infeasible to give all wine produced a quality label by one of those experts 
in this project  we focus on the task of predicting wine quality from physicochemical properties via data mining  we propose a new algorithm for this task  called monte carlo kernel
 mock   and compared its performance with ordinary linear square  ols  

   

related work

    proposed a neural network approach for predicting human wine taste preferences      proposed a regression tree model for the same problem  both models obtained pretty good accuracy 
      by neural net  and        by regression tree 
regression tree seems a better fit not only because the accuracy is higher  but also because
neural network is prone to overfitting given only thousands of examples  on the contrarary 
regression tree is not that sensitive to noise  and it can avoid overfitting by cross validation and
pruning  however  both models are painful to train  and computationally expensive 

   

data overview

the data we use is wine quality data set from      the dataset has      examples  with
   features for each example 
the output feature is quality  which is an integer score between   and     the input features
feature
fixed acidity  g tartaric acid  dm   
volatile acidity  g acetic acid  dm   
citric acid  g dm   
residual sugar  g dm   
free sulfur dioxide  mg dm   
total sulfur dioxide  mg dm   
density  g cm   
ph
sulphates   potassium sulphate  dm   
alcohol  vol   

min
   
   
   
   
 
 
     
   
   
   

max
    
   
   
    
   
   
     
   
   
    

mean
   
   
   
   
  
   
     
   
   
    

table    the physicochemical data statistics for input features
are fixed acidity  volatile acidity  citric acid  residual sugar  free sulfur dioxide  total sulfur dioxide  density  ph  sulphates  and alcohol  all values are numeric  no missing values is present 
 

finotice the range of the score is large  we view this task as regression rather than classification 
the correlation matrix for the dataset is shown in figure   

figure    heatmap for correlation matrix of wine quality data

 

methods

we first present the general mock algorithm  then focus on the wine quality prediction
problem 
take   a subset of   and a kernel function k   rm  rm  r 
algorithm   monte carlo
for j           b do
sample  j   unif    
for i           m do
zi  f j   x i   
end for

 
y 

 
w j   k          
ym

kernel algorithm


z 
    
  
zm

end p
for
b
j   w j  j 
   p
b
j  

w j 

theorem    assume    m    m   n   for each x i    y  i  sampled from n   t x i          and
we use a symmetric kernel function k  y  z    k  yz
   satisfying
z
k x    

 

fithen as m  m   
  
the proof will be presented in supplementary material 
remark  these properties hold for common kernel functions including gaussian kernel and
uniform kernel 
for linear model  which we will be using for the regression on wine quality  the algorithm
will have the following degenerations 
f j   x i       j t x i 
k  y  z    exp  ky  zk      gaussian kernel 
we split the data into     of training examples       examples  and     of training examples
     examples   and we use root of mean square error  rmse  as the evaluation criteria 

 

results

set m           m  we implement the mock algorithm in r 
the  we obtained by mock algorithm is 
intercept
    
total sulfur dioxide
     

fixed acidity
     
density
    

volatile acidity
    
ph
    

citric acid
     
suphates
    

residual sugar
    
alcohol
     

free sulfur dioxide
     

table     obtained by mock algorithm with    m         m       

   

comparison

we compare the rmse and runtime of mock with those of ols 
to prove the accuracy is not by pure chance  we apply permutation test     shuffle the order

figure    comparison of rmse  left  and runtime  right  for textbfmock and ols
of values for training data  train the parameter  and predict with the perturbed parameter  the
result is also shown on the figure 
 

fithe runnng time of mock versus number of iterations is also shown  the running time of
ols is fixed as we are using the built in stats  lm function 
for the task of predicting wine quality  the loss of mock is less than that of ols when
iteration number is more than       on the other hand  mock has an almost linear runtime 
which exceeds the time for ols when number of iteration is more than      
there is a clear tradeoff between the accuracy  rmse  and the runtime  however       is a
sweet spot where accuracy is almost converged and its     lower than that of ols  and the
runtime is     smaller than that of ols 
by looking at the error for perturbed dataset  the rmse obtained by both mock and ols
are significantly lower than that of perturbed dataset  hence  we can safely draw the conclusion
that both algorithms are capturing the signal rather than noise 
we dont have the detailed accuracy result of neural net and regression tree  therefore  we
cannot compare the results with that of theirs  however  the focus of this project is to evaluate
the mock algorithm rather than proposing models that beat the existing work  we believe
mock also work if we modify the model to neural network model  though with more parameter
tuning 

 
   

conclusion
discussion

the mock algorithm is easy to implement  it converges quickly  and the accuracy is relatively
high 
the drawback of mock compared with ols  is that it requires more parameter tuning  in
the wine quality example  we tuned   the bandwidth   m  the bound of parameters  for several
times to obtain good training error  another issue is that mock doesnt provide a p value
indicating the significance of each variable as ols does 

   

future work

in this project  we only focus on parameter estimation with linear model  and due to this
limitation  we only compared the mock estimator with ols estimator 
another extension is to study heuristics to setup  and m   so users dont have to tune the
parameter for a long time  one possible way is to use cross validation  this approach isnt used
in this project due to the limited size of the training examples 
as mentioned in methods section  this algorithm is valid for a very general class of problems 
including classification  confidence interval estimation  etc  as a future work  we can apply
the mock algorithm on other interesting datasets  and compare the performance with other
approach  including naive bayes  logistic regression  svm  even neural network 
on the theoretical side  we only proved the consistency for linear model  and have not provide
probability bound which gives the minimum m required to obtain  accuracy  apart from
giving an exact bounds for m  we can also exploit the mathematical proof for the consistency
for classification models 

 

supplementary material

proof for theorem   

 

fiproof  by law of large numbers 
pm

i   k z i   y i  

m
similarly 
pm
i   k z i   y i   i 
m

 e k z  y  

 ek z  y 
 

ek z  y    x   ek z  y  x   x 

 

ek z  y    x   ek x   x     x   x 



ek z  y    x   e  x   x k x   x     x   x k    x   x  

 

ek z  y    x   e  x   x k x   x  
z
 
 s  x k s  x    
ek z  y    x
s x x m m  n
z
 s  x k s  x    
ek z  y   x  

 
 

sx m m
 
 n

the last equality holds because
z
z
 s  t k s  t      
srm

the integral diminishes as

z

r

 s k s       

sk s      

srm

z

srm

sk s        
s

k     and by cauchys rule 
pm
i   k z i   y i   i  m
p
  
m
i   k z i   y i   m
ek z  y 

ek z  y 
  

references
    a  asuncion  d  newman  uci machine learning repository  university of california 
irvine       http   archive ics uci edu ml datasets wine quality
    p  cortez  a  cerdeira  f  almeida  t  matos and j  reis  modeling wine preferences by data
mining from physicochemical properties  decision support systems  elsevier                
     
    fisher  r a  the design of experiments  new york  hafner       
    michal horak  prediction of wine quality from physicochemical properties  data mining 
czech technical university in prague          

 

fi