detecting sarcasm in text  an obvious solution to a trivial problem

chun che peng
mohammad lakis
jan wei pan

chunche   stanford   edu
mjlakis   stanford   edu
jwpan   stanford   edu

abstract
sarcasm detection in writing is challenging in
part due to the lack of intonation and facial
expressions  nonetheless  the human comprehension system can often spot a sarcastic sentiment  and reason about what makes it so  recent advances in natural language sentence generation research have seen increasing interests
in measuring negativity and positivity from the
sentiment of words or phrases  however  accuracy and robustness of results are often affected by untruthful sentiments that are of sarcasm nature and this is often left untreated  sarcasm detection is a very important process to
filter out noisy data  in this case  sarcastic sentences  from training data inputs  which can be
used for natural language sentence generation 
in this paper  we attempt to design a machine
learning algorithm for sarcasm detection in text
by leveraging the work done by mathieu cliche
of www thesarcasmdetector com and improving
upon it  by analyzing the strengths and weaknesses of the baseline model  we strive to develop
one that will achieve better results 

   introduction
     motivation
analysis on social media has attracted much interest in the
research areas of nlp over the past decade  ptacek et al  
       in fact  on june          the bbc reported that
the u s  secret service was looking for a software system that could detect sarcasm in social media data  bbc 
       misinterpreting irony and sarcasm represents a big
challenge  however  although sarcasm detection in text is a
daunting task  it is an important chapter in the advancement
of artificial intelligence 
this paper investigates the possibility of classifying sarwriteup for stanford cs     machine learning final project 
copyright      by the author s  

casm in text reliability and identifies typical textual features from twitter that are important for sarcasm in the process  as there is only a weak boundary in meaning between
irony  sarcasm and satire  reyes et al          the usage of
the term sarcasm in this paper refers to the general concept 
     statement of problem
sarcasm sentences can be used almost in all topics  they
can take variable grammatical structures  also  to understand sarcasm  one has to know the context of the sentence 
for instance  the sentence i love being rich is not sarcastic by itself  however  if you know that the speaker is poor 
you will decide that this is a sarcastic sentence  therefore 
to detect sarcasm  you have to have prior knowledge about
the subject or sarcasm  which might not always be available  for our approach  we will not attempt to start from
scratch  rather  we will leverage the work done by mathieu cliche of www thesarcasmdetector com and build upon
it  as a baseline for our project we will replicate some results from cliches work  our goal is to develop a machine
learning algorithm that will achieve better results 
in his work  cliche gathered tweets from twitter labeled
with  sarcasm and made the hypothesis that sarcastic
tweets often have big contrast of sentiments  i e  start very
positively but end very negatively   he also adds other features such as n grams and topics  he then trains an svm
and compares it with other classification algorithms such
as nave bayes  his results show that using an svm on
the engineered features yields better results from previous
work  cliche        
in the following section  we will conduct error analysis to
pinpoint areas for improvement 

   related works
sarcasm is a challenging problem in the field of sentiment
analysis for a wide range of languages  for example  lunando and purwarianti presented their sarcasm detection
classifiers  including a naive bayes classifier and a support vector machine  for analyzing indonesian social media  using features of negativity and number of interjec 

fidetecting sarcasm in text  an obvious solution to a trivial problem

tion words  their aim of using negativity feature was to
catch the global sentiment value  and the interjection feature was to represent the lexical phenomena of the text message  their intents were however challenged  because it
was shown that negativity features were not useful as many
sarcasm texts that they analyzed had no global topic  and
thus making the text topic is not widely known  also  there
was quite a lot of text with personal message that could
only be analyzed if the reader has prior knowledge about
the context or writer  lunando   purwarianti        
gathering data to be categorized as sarcastic and nonsarcastic is a challenge in of itself  fortunately  twitter
has proved itself to be a valuable tool for whole variety
of natural language processing investigations  the idea of
using  sarcasm as a way of gathering positive data points
from twitter is not new as evident by the research done by
 liebrecht et al          the authors made use of balanced
winnow and achieved an accuracy of     

   dataset and features
     baseline model description
the baseline model uses a support vector machine  svm 
as implemented by the linearsvc function from scikitlearn  a popular open source machine learning library in
python  aside from a value of     for the penalty parameter c  all other configuration options are left as default 
features are extracted from the raw twitter data to create
training examples that are fed into the svm to create a hypothesis model  although much of the machine learning
implemented is already provided by a third party tool  effort is still necessary for feature engineering 

scores are collected for the overall tweet as well as each individual part  furthermore  the contrast between the parts
are inserted into the features 
parts of speech  the parts of speech in each tweet are
counted and inserted into the features 
capitalizations  a binary flag indicating whether the tweet
contains at least   tokens that start with a capitalization is
inserted into the features 
topics  the python library gensim which implements topic
modeling using latent dirichlet allocation  lda  is used to
learn the topics  the collection of topics for each tweet is
then inserted into the features 

   methods and analysis
     analysis of baseline model
initial analysis of the baseline model quickly reveals that
the testing error far exceeds the training error  in fact  the
training error is virtually non existent  a value of     is
initially used for the penalty parameter c in the svm  since
the parameter is a measure of how much one wants to avoid
misclassifying each training example  smaller values of c
       and        are then used 

the tweets were collected over a span of several months
in       the sanitation processed included removing all
the hashtags  non ascii characters  and http links  in addition  each tweet is tokenized  stemmed  and uncapitalized through the use of the python nltk library  for each
tweet  features that are hypothesized to be crucial to sarcasm detection are extracted  the features fall broadly into
  categories  n grams  sentiments  parts of speeches  capitalizations  and topics 
     baseline features
n grams  individual tokens  i e  unigrams  and bigrams
are placed into a binary feature dictionary  bigrams are extracted using the same library and are defined as pairs of
words that typically go together  examples include artificial intelligence  peanut butter  etc 
sentiments  a tweet is broken up into two and three parts 
sentiment scores are calculated using two libraries  sentiwordnet and textblob   positive and negative sentiment

figure    training and testing error percentages for various values
of the penalty parameter c 

despite trying different values of c  it appears that the testing error can be improved only slightly  the testing error
remains at around      nonetheless  the best results are
obtained for c        the large gap between training and
testing error suggests that the model is suffering from high
variance 

fidetecting sarcasm in text  an obvious solution to a trivial problem

     targeted areas for improvement
the high testing error of the model at hand implies that we
are fitting noise  this problem could be caused by the fact
that we have a high dimensional feature space  another
possibility is that there are features that are not relevant for
detecting sarcasm  in both cases  we think it is important
to reduce the dimension of feature space and use relevant
features  for instance  the benefit of adding some features
such as bigrams  sentiments and topics is not clear  bigrams might have the same effect as unigrams  also  we
should test whether adding sentiments improves our classification by a significant factor  while it is true that some
sarcastic sentences have words with negative sentiments
and others with positive sentiments  many other sentences
do not have this property  thus  adding this feature might
not be useful  also  non sarcastic sentences can still have
both positive and negative sentiments  we also think that
finding the sentiments in each training example takes a lot
of time  for each training example  we have to look for
the sentiment of each word in a dictionary  which takes a
lot of time  we also want to investigate the topics that are
added  topic modeling using lda might be returning similar words as the unigrams of the training example  and we
might end up getting redundant information  however  we
think that categorizing the training examples into a set of
topics can be useful in a different way than it is used  instead of adding topics as a separate feature  we might split
our classifier to n classifiers  where n is the number of topics in the training set  in other words  we build a classifier
for each topic  consider for instance the following topics 
soccer and unemployment  words used in sentences about
soccer are different from those used in sentences about unemployment  therefore  the unigrams that are used to detect spam in soccer topic will be very different from the unigrams used to detect sarcasm in unemployment  so what
we get is a set of classifiers with much lower feature space 
to analyze the classification problem that we have  we start
by training a simple naive bayes classifier  based on the
error analysis from this classifier  we tried other classifiers
such as one class svm and a binary svm with different
features and a non linear kernel  gaussian kernel  
     model improvement methods
       naive bayes
we first created a multinomial naive bayes classifier to
train and test the datasets that were previously collected by
clich  during the pre processing  we performed an automated tagging of        datasets as sarcastic and        
datasets as non sarcastic  based on the labels from clichs
datasets  then  we randomly selected     of the data for
training  and     of the data for testing purposes  after
that  we constructed a term frequency inverse document

frequency  tf idf  vector  and then fed it into a multinomial naive bayes classifier using the tfidfvectorizer and
naive bayes modules from nltk toolkit  scikit learn 
       the results are discussed in section   
       o ne c lass svm
we noticed that the sarcastic data has a lot of ambiguous
sentences  without the knowledge of the subject of a sentence  we expect it to be non sarcastic  on the other hand 
the non sarcastic data sample is clean and clear  also  we
have around         non sarcastic example compared to
       sarcastic example  this motivated us to rely more
on non sarcastic data  so we decided to use one class svm
as described in  scholkoph et al         and  manevitz  
yousef         our one class svm will be trained only on
non sarcastic data  hence  we can think of sarcasm detection as novelty detection  scholkoph et al         scikitlearn         this means we are trying to detect sarcasm
by measuring how similar it is to the training set  for one
class svm  we want to solve the following optimization
problem 
n

  x
 
i  
min kk   
    
n i  
subject to  


i           n

    

i           n

  xi    i  

with the decision function being 


f x   sgn   xi   

   

in our implementation  we used a gaussian kernel with different values of  
therefore  the decision function becomes 


f x   sgn  k xi   x   
   
where  according to  scikit learn          represents an
upper bound on the fraction of training errors  and a lower
bound of fraction of support vectors  we implemented one
class svm with a feature vector formed of unigrams and
bigrams  we discuss the results in section   
       g aussian k ernel
its possible that the dataset is not linearly separable and
so using a gaussian kernel instead of a linear kernel in the
svm might be a better approach  we use the svc function
 rbf kernel  from the same python library scikit learn  in
addition to the penalty parameter c  theres the paramter
gamma which defines how far the influence of a single
training example reaches  through repeated trials of varying both pamaters  we find that the values for c and gamma

fidetecting sarcasm in text  an obvious solution to a trivial problem

that lead to the best results are     and   respectively  we
also investigate the choices of the features by conducting
leave one out of each feature type to see the effect  the
results are discussed in section   

   results and discussion
     naive bayes
our nave bayes classifier was built and the classification
performance was also compared  all using the scikit learn
package for python  we use the following confusion matrix
to visualize the classification accuracy based on the training
data 

positive
 actual 
negative
 actual 
overall

positive
 predicted 

negative
 predicted 

accuracy

     

  

      

     

    

      





total

accuracy
negative

positive

   
    
   

   
    
   

   
   
   

   
   
   

   
    
   

      

table above shows  of the       patterns that are sarcastic        were correctly predicted sarcastic while   
were incorrectly predicted as non sarcastic  accuracy of
         similarly  of the       patterns that are nonsarcastic         was reported to be correctly predicted
non sarcastic  the overall accuracy of the classifier for
predicting both classes given this dataset was evaluated
achieving        
to avoid the effect of large class imbalance  i e  model
prediction becomes biased to the majority class for all predictions and still achieve high classification accuracy  the
following additional measures were applied based on the
training data 

non sarcastic
sarcastic
overall

data  so we used a small value of         and hence set an
upper bound of     training error   our settings produced
a testing accuracy of     on non sarcastic data  however  only     of the sarcastic data was classifier correctly 
overall  this would translate to     classification accuracy 
which is not satisfying  we tried to make a tighter bound by
setting  to       this resulted in better detection of nonsarcastic sentences        but with much less detection of
sarcastic sentences  only        while these results overall
average to      we are still unable to detect sarcasm  the
results are summarized in the table below 

precision

recall

f  score

   
   
   

    
   
   

   
   
   

the precision rate in the table above shows that there is
a larger number of false positives       in non sarcastic
sentences than the sarcastic sentences        nave bayes
also classifies more false negatives in sarcastic sentences
than the non sarcastic ones  as suggested by the reported recall values  using the reported precision and recall values 
the classifier demonstrates higher f  score in non sarcastic
sentences than the sarcastic ones 
     one class svm
we built a one class svm using scikit learn package for
python  we want to set a tight bound on the non sarcastic

the main observation is the following  if we detect nonsarcasm with very high accuracy  we will not be able to
detect any sarcastic example  i e  our classifier will always
decide that the test example is non sarcasm   if we relax
the bound on non sarcasm  the error on positive  sarcastic  examples will slightly decrease  but will significantly
increase on negative  non sarcastic  examples 
as we have formulated our classification as a novelty detection problem  it seems that there is very high similarity between sarcasm and non sarcasm based on our feature
space of unigrams and bigrams  we think that our labeled
data can be visualized as in figure   below  which is a representation of a linearly inseparable data  this tells us  that
using only unigrams and bigrams is not useful for detecting
sarcasm  to be able to do so  we have to engineer new features that distinguish between sarcasm and non sarcasm 
i e  make them separable 

     gaussian kernel
the leave one out approached yielded very similar results
regardless of the feature type that was left out  this suggests that no feature is more important than the other  in
addition  we re ran the model without sentiment analysis
scores using a gaussian kernel on the full dataset and obtained a testing accuracy of       and but a training accuracy of over      while it shows signs of the same high
variance error as the baseline model  the gaussian kernel
approach shows potential for being better than the baseline  however  it does appear that the baseline approach
achieved better results for smaller sizes of the dataset 

fidetecting sarcasm in text  an obvious solution to a trivial problem

references
bbc  us secret service seeks twitter sarcasm detector        url http   www bbc com news 
technology          
cliche  m  the sarcasm detector        url http   
www thesarcasmdetector com about  
liebrecht  c   kunneman  f   and van den bosch  a  the
perfect solution for detecting sarcasm in tweets  not 
in proceedings of the  th workshop on computational
approaches to subjectivity  sentiment and social media
analysis  pp             

figure    a simple visualization of our data

lunando  e  and purwarianti  a  indonesian social media
sentiment analysis with sarcasm detection  in      international conference on advanced computer science
and information systems  icacsis        
manevitz  l  m  and yousef  m  one class svms for document classification  journal of machine learning research  pp               

   conclusion and future work
as mentioned in section      sarcasm can be found in wide
variety of topics  therefore  if we want to build a classifier that detects sarcasm in all topics  we need to sample
much larger data  also  as we saw in section      the use of
unigrams and bigrams alone is not sufficient  finding new
features relevant to sarcasm is a critical step for improving
sarcasm detection  more investigation on the binary svm
is warranted 
the poorer results obtained using naive bayes were not
completely unexpected  we expect to see that some sort
of contextual clues  feature types such as sentiment contrast  order of words  etc   to play a big role in the sarcastic
nature of a sentence  as implemented  the naive bayes approach does not take any of that into account  we did find
agreement between naive bayes and one class svm  both
of them misclassify most of the sarcastic data 
we also see that the accuracy greatly depend on a mixture
of feature types  unigrams and bigrams alone are insufficient in designing an accurate classifier  when combined
with other types such as topic modeling  the accuracy is
greatly increased 
the importance of feature engineering  relative to simply
obtaining more data points  cant be over emphasied  we
believe it is where most of the effort should be placed in
order for sarcasm detection to be successful  in the end  we
found more questions than answers but that in of itself is a
small step in the right direction 

ptacek  t   habernal  i   and hong  j  sarcasm detection on
czech and english twitter  in the   th international conference on computational linguistics  coling       
     
reyes  a   rosso  p   and veale  t  a multidimensional
approach for detecting irony in twitter  language resources and evaluation                     
scholkoph  b   platt  j  c   shawe taylor  j   smola  a  j  
and williamson  r  c  estimating the support of a highdimensional distribution  technical report  microsoft
research       
scikit learn 
support fector machines       
http   scikit learn org stable 
modules svm html 

url

fi