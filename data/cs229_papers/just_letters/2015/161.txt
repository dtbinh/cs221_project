service capacity estimation through telemetry analysis
daniel de freitas adiwardana  joe wang
capacity planning traditionally has been an imprecise process in which owners of large scale internet services
anecdotally make a guess as to the number of servers to procure and then increase that estimate by a factor
of     although overprovisioning services may satisfy user demand  it certainly is not the most cost ecient
method by which to scale out  in this paper  we present a novel method  using machine learning  for estimating
actual service capacity  as a crucial component to a larger service capacity model  this work should help produce
a more exact  and therefore cost eective  solution to the problem of capacity planning 
not impossible to replicate the entire set of service interdependencies just for testingin fact  many stress tests
actually run on production services to validate actual behavior an end user might see  that being said  engineers
cannot allow these benchmarks to impact production performance  limiting their eectiveness  finally  service code
and topologies change fairly regularly  which makes writing specific tests rather time consuming and frankly inefficient  these are myriad other issues all show traditional
performance testing to be cost prohibitive 
rather than taking the traditional approach  we propose to utilize service qos  quality of service  telemetry to
 workload projection  the ability to predict drivers
build a machine learning model for predicting a services
of load on the system such as user initiated requests
estimated capacity 
 or more generally user behavior   device or software
initiated requests  such as downloading system up  inputs and target
dates   and so forth  and
to state our problem more formally  we wish to construct
some hypothesis that takes a set of api features  some
 capacity estimation  the ability to estimate the
api identifier  the data size  etc  with an rps and outmaximum load a given service can handle  given its
puts a latency value  as input  these api characteristics
current and past performance characteristics 
can be derived solely from telemetry dataservice logs
in this paper  we present a unique method of addressing events created when handling requests  while the rps can
be calculated as the count of all the requests processed
the second point 
during any given second 
related work
before diving into the data  however  there are some
before continuing further  it should be said that there cur  observations we can make to help choose the best route to
rently does exist various strategies for estimating a ser  take when developing our learning algorithm 
vices capacity  in particular  the most common method   the latency logged by a particular api may be
ology for doing so is for engineers to write specific perskewed upward if the server handling that api was
formance benchmarks to stress their own services         
under high load  due to requests to that api  or
in doing so  the test would output a set of numbers corother available apis  
relating load  rps or requests per second  with response
time  latency  and processor utilization  these numbers
   at a very high levels  all apis share common behavwould be able to fairly accurately predict the maximum
ior  in the way requests are queued and handled  
workload it could handle 
despite executing vastly dierent instructions 
unfortunately  this methodology does not apply very
well to the large scale  loosely coupled services backing the
   the api identifier narrows down the set of possible
internet properties found today      first and foremost  it
behaviors an api may exhibit  but does not uniquely
is very dicult to stress these services in isolation  as they
identify a single behavior 
often have several layers of upstream or downstream dependencies      finding an upper bound on a particular at a first glance  it seems like we are working with a regresservice may not generate enough load to find the upper sion problem in which some of the inputs are continuous
bound on downstream services  and conversely  a given variables  while some are discrete categorical variables 
upper bound on a given service may not be an actual
upper bound  but rather the reflection of a bottleneck in
a downstream service  second  it is often very dicult if

motivation
in the world of large scale services today  one of the critical investments a company must make is the purchase of
hardware in the datacenter  ideally  a services capacity 
or ability to handle user requests  should match its workload  or actual volume of user requests  a larger capacity than workload means wasted dollars powering unused
servers  while a larger workload than capacity means slow
response times and a poor experience for customers  from
this observation  we hence derive two important aspects of
a capacity model for any given service 

 

fidatasets
in working on this project  we were collected two distinct
datasets of sample production telemetry from an internet scale property currently serving millions of users  the
first dataset was collected early on and was used primarily
to determine a baseline for the learning algorithms  while
the second dataset was collected on a day with higher user
trac to provide a wider range of api behavior  the two
datasets collected contain the following fields 

where x is a vector composed of the numerical features
and encoded categorical features   is the weight vector
assigned to the features  and b is the bias 
neural network
neural networks are a class of models which can learn
complex non linear functions  each neuron of the network
takes a number of inputs xi and outputs h  x  where x is
a feature vector with components xi  
x 

 qosid  this is the unique identifier for a particular
api being called on the service 

output

 latencyms  this is the latency of this particular invocation of the api in milliseconds 

x 

 requestsizebytes  this is the size of the payload for
this particular request in bytes 

h  x 

x 

 protocolstatuscode  this is a string identifier of the
result  success failure type  of the request 

inputs

the figure above provides an illustration for three inputs 
 rps  this is the number of requests per second a parwhere h  x  is a non linear function of the linear combiticular server was handling for this api during this
nation of the inputs xi   that is
invocation of the api 
 
 

in the first dataset  up to     sample requests were colh  x    g
wi xi
lected per hour per api for    hours to be used as the
i
training set  an additional hour of data was collected to
where wi are the neuron model parameters  a k a  weights 
be used as the test set  the second dataset contained   
and g is some non linear function called the activation
hours of training data and   hours of test data  dataset
function  a common choice for g is the sigmoid function
sizes were    mb and    mb with training example counts
 
        and         respectively 
g z   
 
    ez
a note on data quality 
a neural network is a collection of such neurons  the neuan issue that we noticed early on was the general qual  rons can be interconnected in various ways  one choice is
ity of the available databecause the collected telemetry the feed forward architecture  in which neurons are orgaevents were the direct result of instrumentation by engi  nized into layers and the outputs of the neurons of one
neers  there were instances where fields had invalid values  layer feed into the input of neurons of the next layer  the
or where certain fields seemed rather sparse  for instance  illustration below shows an example network with a single
most of the requestsizebytes did not have a value  and hidden layer containing   neurons 
only some of the protocolstatuscode did  we realize that
this will likely have an impact on how good of results
input
output
hidden
we may be able to obtain  but acknowledge that this is
layer
layer
layer
just the state of the world in solving a challenging industry problem  we hope that as the data quality improves
x 
in the future  our learning models will become richer and
more accurate 
x 

methods
linear regression
because our problem space required the computation of a
model that could accurately predict a real valued latency
given the input set of features  we naturally attempted to
use a linear regression model for training our baseline  as
inputs  we had both numerical features  requestsizebytes 
rps  as well as categorical features  qosid  protocolstatuscode  for which the unique set of values were encoded
as integers  a model output from the regression can be
represented by a simple equation

x 

x 

x 

y   t x   b
 

h  x 

fithe model parameters of a neural network are computed
by optimizing the following cost function
m  
   
    

 i 
 i  
j w  b   
h  x    y 
m i    

model  use a predefined loss function to measure its error 
and correct for this error in the next model to be trained 
so in a sense  each model of the obtained ensemble will
have been trained in a way that complements the previous
models deficiencies by focusing on its errors 

where x i  and y  i  are the features and label of the ith
training example  respectively  currently  the most commonly used algorithm for finding the parameters that minimize the given cost function is called backpropagation 
the backpropagation algorithm randomly initializes the
parameters and iterates over the following steps until convergence   i  compute all the outputs of every neuron down
to the output layer using the current parameter values   ii 
work backwards from the output layer towards the input
layer to compute the gradient of the cost function j with
respect to the parameters of each layer  this gradient can
then be used to find new parameters values that minimize
j for each layer in each iteration  for example  one could
use gradient descent to update the layer parameters 

filter feature selection
feature selection is one way of finding what features xi of
our dataset could be the most relevant to predict the
target variable  filter feature selection accomplishes this
by first scoring each feature xi according to some scoring
function s i   which measures how informative each feature xi is about the label y  the algorithm then outputs
the k highest scoring features  in our work  we chose s i 
to be the mutual information between xi and y  which can
be defined as 
m i xi   y    kl p xi   y   p xi  p y  
where kl is the kullback leibler divergencea way of
measuring the dierence between the probability distributions p xi   y  and p xi  p y   we picked mutual information as the scoring function because it is capable of quantifying general relationships between variables  unlike say 
persons correlation  which is mostly used to quantify linear relationships 

boosted decision tree regression
decision tree regression is an algorithm that produces a regression search tree model  in this model  each node in the
tree is a question about a given test point whose answer
takes the search to exactly one of its child nodes  eventually  if no data is missing in the test point  the search will
reach a leaf  each leaf in turn is associated with a possible
predicted value for the test point  the tree is built starting with the complete training set from the root and then
by picking a feature variable and question split value in
a way that it splits the training set to greedily minimize
the sum of the squared errors of all leaves so far  the
algorithm then proceeds recursively on the formed subtrees  formally it finds a partition of the training set that
greedily minimizes
 
j 
 y  i   y   
leaves

discussion
baseline linear regression
upon obtaining the first dataset  we set out to train our
first model using batched linear regression  which constitutes our baseline  we also ran a diagnostic to determine
our bias variance  and whether our training set size was
sucient  the figure below shows the learning curve of our
first run  where the error measure is the mean absolute error  mae   we use mae rather than root mean squared
error  rmse  because we care more that our predictions
are mostly correct  rather than the magnitude of error for
any particular prediction  i e  we dont want large outliers
to skew the error  

i

where each y  i  is a training example associated to a particular leaf and y is the mean of all such training examples 
the following figure is an example of a fictitious binary
regression decision tree for deciding the price of baseball
card given its age  conditions and whether it features a
famous player 

mae
   
   
   

training
   

test

   

age
    y 
yes

   
no

cond 
good 
yes

   

 

famous 
no

     

yes

   k

  

  

  

  

   

  training set

original dataset baseline 

no

    

unfortunate but not unexpected  we deemed the mae
of
      
to be too high  armed with this information  we
boosting is a method to increase the accuracy of any learndecided
to
 i  collect more data with better features and
ing algorithm by building an ensemble of weak models
 ii 
produce
a more complex model 
that together form one strong model  the present work
utilizes the gradient boosting method  the basic idea of
the gradient boosting algorithm is to  at each step  train a
 

fibetter data
we knew going in that data quality was an issue  and so
at this point  we decided to try to collect a more representative set for training  our hypothesis revolved around
the idea that by increasing rps  a services latency should
increase  however  our dataset had very few instances of
high trac volume  therefore  we decided to collect data
from a day for which we suppose would produce a higher
load  black friday   in this collection  we also decided to
double the amount of training examples 
we also tried to add features and cleanup noise by
including more metadata about each data point that we
thought may be helpful  e g  the service name  the average latency per api  and filtering out data points from
non production servers  e g  testing and integration  
by doing these things  we were able to obtain the learning curves  for both datasets  below 

we obtained a training mae of        and a test mae of
       
since our training error was still high we attempted
increasing the number of neurons tenfold to increase the
learning capacity of the model  this actually increased the
training mae to         perhaps because the minimization had not yet converged  we attempted to diagnose
the convergence of the model by modifying the number of
iterations  which showed that it wasnt converging 
  iterations
  
  
   
   
   

we didnt invest much further into this approach given
the long training time requirements of the neural network 
these results indicated that we might actually not be underfitting an existing pattern  but that perhaps the pattern is mixed with a lot of noise with respect to our current
feature set and or data quality 
in light of this realization  we then applied a feature selection algorithm to select a subset of the   most relevant
features out the   we had  this could reduce potentially
noisy data  the feature selection algorithm we used was
filter based selection utilizing mutual information as the
scoring function  the following table shows the resulting
feature relevance scores 

mae

   

training

   

test
   

   
 

  

  

  

  

   

mae
      
      
      
      
      

  training set

original dataset  cleaned 
mae

qosid
requestsizebytes
protocolstatuscode
rps

   
   
   

training

   

test

the feature selection scores point to the removal of the
rps feature  however  given our domain knowledge  we
believe that this feature is actually relevant  but the data
we currently have is mostly for very low rps values  so
in preparation for potentially higher rps values in future
data we chose to preserve it  the second least relevant feature is protocolstatuscode  after removing this feature
our linear regression model scored        test mae 
also  because qosid seemed to be an important feature
by which to slice the data  it was possible that the patterns inside each stratum defined by a unique qosid would
be less noisy  so we tried an algorithm that could leverage
this fact  the decision tree regression algorithm could be
expected to be able to start by splitting the data according to the various qosid values  concretely  given that the
qosid s appear to be very informative of the label values 
then the qosid values to branch on the lower nodes of the
tree may also minimize the total squared error of the resulting set of leaves  which is the goal of the algorithm  on
the other hand  decision trees are notorious for overfitting
the training set  so we used a boosted decision tree solution which is meant to generalize better  but preserve the
decision trees capability of learning non linear functions 

   
   
   
 

  

  

  

  

   

    
     
     
     

  training set

black friday dataset  cleaned 
we see that we were able to drop the test error significantly  to         just by obtaining a better dataset 
however  we still werent quite happy with these results 
given our results  we hypothesized that the model is most
likely underfitting the training data  and so we needed
models capable of better representing the intricacies of the
underlying target function 
more complex models
we first tried a neural network because of its potential
for learning complex non linear models  since we didnt
have many features  we picked a neural network architecture comprised of a single hidden layer with a number of
neurons in the same order of magnitude as our number of
features as a heuristic to avoid overfitting our training set 
so in our first experiment we tried   hidden layer with   
neurons        learning rate and     epochs  from this
 

fias a starting point  we picked the following learning
parameters  maximum number leaves per tree equal to    
learning rate     and total number of trees in the boosting
ensemble to be      it scored a        test mae  so it
already performs slightly better than our baseline  this
algorithm trained a model fast enough that it allowed us
to perform an automatic random sweep over the learning
parameter space and measure its training error  the best
scoring model contained just   leaves  allowed a minimum
of   instances per leaf  used a learning rate of      and
    trees in the ensemble  it marginally performed better
than the initial parameter settings producing a        test
mae 

have likedeach set had errors that were just as poor as
our original attempts 
conclusion and future work
in tackling this particular problem of capacity estimation 
we arrived at   findings 
   the dataset we used may not have been representative of actual api behavior  the rps values were
skewed too low  many of the features were sparse due
to poor instrumentation  
   a rich model that encompasses all the data needed to
perform service capacity estimation requires a mixture of learning algorithms to produce desirable results 

error analysis
at this point  we werent sure whether additional runs of
the algorithms above would net us a better result  so we
decided to dig a bit deeper and understand how our model
performed with respect to each individual api  by aggregating by qosid and averaging the training and test error 
we discovered that we could logically group apis with similar error  in particular  the following categories had the
largest error 

the next steps  therefore  are to collect better data and
try additional methods to tease out the behaviors of each
api  in terms of data collection  we could apply a better
sampling algorithm to obtain telemetry that better reflect
the distribution of incoming requests to the service  for
instance  we could first analyze the distribution of latencies
on each api  and collect samples based on that distribution 
as for additional training  we have several ideas in
mind 

 security  encryption  decryption 
 database writes

 clustering  we could try the idea of clustering apis
and using the clusters as features  like we described
in the composed models section above 

 file downloads
 server timeout errors
 poorly instrumented telemetry

 classification  we could also try turning the problem into a classification one by partitioning the output latencies into some number of buckets  despite
the final model not being as precise  it could still
produce useful data for capacity estimation 

while the following categories had the lowest error 
 database lookups
 frontdoor request handlers

there remains much more work to be done on this project 
but if we find a successful solution  it has the potential to
this made it very apparent that our original assumption save millions in server costs 
about most apis behaving in a similar manner to be false 
the apis that were bound to some factor  like cpu or
disk  stood out in particular  these were requests that were references
simply more computationally expensive  we noticed that 
in performing this qualitative analysis  it appeared that     p  brebner  service oriented performance modeling the
mule enterprise service bus  esb  loan broker applicathere may be multiple clusters of apis that shared behavtion  in software engineering and advanced applicaior  which our current single algorithm models wouldnt
tions        seaa       th euromicro conference on 
be able to fit very well 
pages         aug      
composed models
the logical next steps here would have been to perform     j  meier  carlos farre  prashant bansode  scott barber  and dennis rea  performance testing guidance
clustering of the data by qosid to obtain features that
for web applications  patterns   practices  microsoft
could then be used as part of the regression  however  we
press  redmond  wa  usa       
didnt have enough time to run the needed experiments 
as a first shot  we used domain knowledge to partition the     ian molyneaux  the art of application performance
dataset by the average latency of each qosid into three
testing  help for programmers and quality assurcategories  apis with low       ms   medium      ms
ance  oreilly media  inc    st edition       
and        ms   and high        ms  latency  we then
trained each set individually in hopes of a better overall     newman sam  building microservices  oreilly media 
     
error  unfortunately  this did not turn out as we would
 service health endpoints

 

fi