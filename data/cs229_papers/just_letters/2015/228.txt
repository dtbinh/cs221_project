cs           group    
learning with difference of gaussian features in the  d segmentation of
glioblastoma brain tumors
zhao chen  zchen   at stanford edu   tianmin liu  tianminl at stanford edu  
darvin yi  darvinyi at stanford edu   project mentor  irene kaplow

introduction

glioblastoma  gbm  is an especially aggressive brain tumor that accounts for over    
of brain tissue tumor cases      gbms have a high mortality rate with a one year survival of     and a three
year survival rate of          much is still being done
to understand gbm and its two subtypes  high grade
glioma  hgg  and low grade glioma  lgg   but there is
still a gold mine of untapped data  chief amongst these
is imaging data in the form of magnetic resonance  mr 
scans  most methods of analyzing and extracting quantitative information from these imaging data requires some
form of segmentation of the gbm  and better yet  classification of the tumor into four sub categories  necrosis 
edema  non enhancing tumor  and enhancing tumor  to
date  the gold standard of segmentation is still human
radiologist segmentations  however  with the pure size
of imaging data being accrued  manual segmentation of
all images is no longer a sustainable system  we propose a statistical learning pipeline that takes difference of
gaussian features into a hierarchal neural net to segment
and classify tumors into their sub categories  we thus
take as input a  d mr image and output one of five
labels  normal or one of   tumor subtypes  for each voxel
 the  d analog of pixel   our combined median hgg
and lgg results in a dice accuracy score of      for the

whole tumor detection       for the tumor core detection 
and      for the active tumor detection  we will see that
this is quite competitive with the leading programs at the
moment 

data

we used the pre processed training data provided by the miccai brain tumor image segmentation
 brats  challenge      for each patient  four main mr
modalities were given      t   pre contrast      t   postcontrast      t   weighted  and     flair  the training
data comes already pre processed  which involves skull
stripping     and co registration  co registration is crucial  as it aligns images for all four modalities such that
the voxel found in the image coordinates  x  y  z  in all
four modalities will point to the same coordinates in real
space 
figure  a shows an example of a single cross section of
the four modalities  juxtaposed with the expert segmentation of the tumor which we will use as ground truth 
note that it is co registration which allows for reliable
overlay of the four modalities with the expert segmentation  note also that the flair image is somewhat cut
off due to the nature of the mr scan  however  big data
algorithms are generally robust against small artifacts
like this 

 b   d rendering of tumor
 a  modalities
 ul  t  pre  ur  t  post  dl  t w  dr 
flair 

figure    tumor visualization

 

fithroughout this project  all of the analysis and space  thus  for our data volume v and our dog filter
methodology built around the data interprets the data f  g   g   where var g         and var g           
as a   dimensional object  each slice gives information
xxx
v  n  m  l f  x  n  y  m  z  l 
on mr intensity in  x y   but the slices themselves rep   v  f   x  y  z  
n m
l
resent the mr information in z  thus  the data can be
imagined as a   dimensional cube as seen in figure    and
 fft   fft v  fft f     x  y  z 
we can extend classic  d imaging techniques to an addi fft   fft v  fft g   g      x  y  z 
   
tional dimension to work on our data 
 

 

 

 

 

where we know fft gi     e   i  m  n  l     as mentioned 
we can further simplify the calculation by taking each linear dimension separately 
as a final point  we note similarities between the dog
filter and the edge sensitive laplacian of gaussian  log 
filter      as visualized in figure    thus  our dog is not
only a blob detector  but also a makeshift edge detector 
we will get a high peak at a pixel if it is at the center
of a blob  however  we will be getting a very low absofigure    data visualization
lute value if were at an edge  because our segmentation
feature extraction the difference of gaus  program is very interested in finding accurate edges  this
sian  dog  convolution filter has been used as a blob de  edge detection aspect of the dog filters is very useful 
tector for some time in  d  and it features prominently
we thus associate with each voxel  x  y  z  the followin the scale invariant feature transform  sift  algo  ing set of features 
rithm      we can see sifts feature detection applied
 one voxel intensity v  x  y  z  
to the iconic sunflower image and one of our brain mr
slices in figure    on the sunflower image  we can see that
 one voxel intensity gradient v  x  y  z  
the features  based on dog filters  find almost all circu eight dog convolutions   v  dog  x  y  z  
lar objects in the image  similarly  on the brain mr slice 
the most predominant sift feature is the tumor  which
 eight dog convolutions in gradient space   v 
is quite blob like 
dog  x  y  z  
this gives    features per modality  and thus we have   
features overall  in addition  because dog convolutions
act as edge  i e  inflection point  detectors  we can argue that they provide information on a functions second
derivative  thus  the above set of features gives us information on all derivatives from  th to  rd order 

algorithm

we begin with an overview of our algorithm  first  we divide our patients into a training and
test set  for our program  we feed in all four modalities  t  pre contrast  t  post contrast  t  weighted  and
flair  of our pre processed data into feature extraction  once we extract our features  we will have a feature
vector associated with each voxel in our brain  we treat
each voxels feature vectors completely independently 
thus  in the hierarchal neural net training phase of our
program  we will not take into account voxel position or
neighborhood other than what is already encoded in the
feature extraction 

figure    sift as evidence of blob detection
our project is in  d  and so we propose building a
bank of   dimensional dog filters  figure     all of different scales  by convolving our  d data with these  d
filters  we will be able to build a blob profile feature vector
for each pixel of our data  in addition to the robustness of
dog filters as blob detectors  we can also notice two more
important features      dog filters are rotationally symmetric and     dog filters are efficient for  d convolution 
the rotational symmetry reduces system bias by not placing special importance on a set of discretized directions 
this makes dog filters more robust than directional filters  such as the  d gabor filters which were used in
first iterations of our work  the dog filter convolution is
easy to calculate by separating the gaussian into each linear dimension and performing all calculations in fourier

hierarchal neural nets
once we have extracted
our features  our learning environment will be a hierarchal neural net  we first train a standard feed forward
neural net    hidden layers     neurons per layer  for
each of the four tumor subtypes  neural nets are standard in machine learning  and make predictions based on
 

filearned
features  neurons  which are linear combinations
p
wi zi of the inputs zi to that neuron  the algorithm
iteratively finds the weights wi   and these neurons are
then activated  fired  when they observe inputs parallel
to their learned feature directions  nnets are relatively
low bias and can model complex nonlinear relationships
 the neuron firing potential  which is usually a sigmoid 
is highly nonlinear  between input features and output 
this is appropriate here as we do not expect our tumor
classifications to be simple linear combinations of our
dog convolutions  after all four neural nets are trained 
we then classify in a cascading fashion as shown in algorithm   on the next page 
essentially  our classification priority in descending order goes  enhancing  necrosis  non enhancing  and edema 
if our neural nets returns positive classifications for multiple tumor subtypes  we classify to the positive subtype
with the highest priority  this hierarchal design is based
off of the hierarchical majority vote used to combine several different algorithmic results     
this seemingly arbitrary methodology makes perfect
sense in the context of our classification problem  tumor
segmentations are judged generally in terms of three accuracies  whole tumor accuracy  tumor core accuracy  and
enhancing tumor accuracy  thus  because they have their
own accuracy scores  we must prioritize classification of
the core over the non core  edema   and then also the
enhancing core over the other core  the enhancing core
generally covers a smaller area of the brain  which lends
even more reason to be more sensitive to its detection 
results are reported as the standard dice score calculated via    fold cross validation  see  beginning of
next section   we do not use cross validation to select
parameters  deciding to keep our neural net parameters
set to default values  this is both because the additional
computation time would be prohibitive  and also because
our dice scores  which are also calculated from the cross
validation  would become biased upwards 

figure    use of dog as log proxy

figure    dog kernels

results and discussion for the rest of
the paper  we report accuracies as dice coefficients  also
known as the srensen dice index   we can describe this
index as     
dice score  

   pred  ref 
 
 pred     ref 

   

where pred is the voxels that return a positive prediction and ref is the set of voxels which are positive in
the ground truth  in our case  the expert segmentation  
we can see that in our case  this is also equal to the harmonic mean of the precision  as denoted by  predref 
 pred   
and the recall  as denoted by

 predref 
  
 ref 

figure    main methodology of learning pipeline

 

fialgorithm   the hierarchical majority vote  the neural net output  between
  and    per voxel for each of the four tumor structures  edema  non enhancing core 
necrotic core  enhancin core  is indicated by pedm   pnen   pnec   penh   respectively 
label  nrm
if pedm      then  label
if pnen      then  label
if pnec      then  label
if penh      then  label
end

 edm 
 nen 
 nec 
 enh 

we first tried our pipeline  figure    with different algorithms  lda gda  decision tree  naive bayes   and
we see that neural nets perform the best  we further note
that we only trained on a subset of the data for the results
in figure    and because neural nets are low bias they also
have the most potential to improve with more data  in
contrast  the other higher biased methods have already
most likely asymptoted to their final performance  thus 
neural nets is the clear choice for training algorithm 
we can see the cv accuracies of segmentation on all
    patients in figure    our median dice performance on
whole tumor detection is above      to wit  the interradiologist repeatability is only      so our accuracy has
saturated with respect to the ground truth  one particularly successful segmentation can be seen in    a full  d
visualization of our tumor segmentation can be found at
https   youtu be kwde  rvdpq  the main draw back
of our program are outliers  more than half of our segmentations are wildly successful  but some segmentations
return sub     scores  which you would not typically see
with a radiologist 
the confusion matrix is 

healthy
       

       
c 
       

       
      

edm
      
      
      
      
      

nec
      
      
      
      
      

neh
      
      
      
      
      

 initialize normal tissue 
 edema
 non enhancing core
 necrotic core
 enhancing core

figure    comparison of algorithms


enh
      

      
    
      

      
      

the matrix was normalized to rowsums  so the diagonal
represents percent true positives for each class   thus 
cij is the percentage of pixels in class i that were classified as class j  the most confused classes are edm   neh 
neh   nec  and nec   healthy  the first two are natural results of our hierarchy  neh overwrites edm  neh
overwrites nec   but the last one is more interesting  and
can be explained by the fact that nec generally shows up
as darker on mr scans  but so does healthy tissue 
our cv mean scores for whole  core  and active tumor
detection are           respectively  this is very competitive with previous methods  some notable ones in     
include ones by zhao and subbanna which incorporated
markov random fields  mrf   achieving dice accuracies

figure    histogram of dice score accuracies
 

fibe biological evidence backing our higher bias model  it
has been known for a long time that neurons in the optical system form receptive fields resembling two concentric
circles  with positively firing neurons surrounded by feedback neurons or vice versa           see figure    for reference  however  these receptive fields look very much like
dog profiles  thus  although we are highly biased compared with a deep learning framework  our features may
be more successful models of how the human eye perceives
information at a low level  the subsequent feed forward
neural net can then learn higher level features from each
pixels lower level biological features  in such a way  we
may be more successfully mimicing human biology in this
context than higher level models like deep learning can
claim  by no means are we suggesting that our methodology outperforms deep learning in all contexts  but we
figure    data visualization  from left to right  t  may in some ways be on the right side of the bias variance
tradeoff  possibly due to the biological underpinnings of
post contrast  our prediction  expert segmentation
our feature space 
of          and           respectively      festa from
     used random forests to achieve a dice of              
in       groups used deep learning and convolution neural
nets  cnns  to achieve accuracies of           davy  and
          urban        it may come as rather surprising
that our methods are competitive with highly complex
learning methods such as cnns  it is worth asking why
this is the case 
we begin with a discussion of the bias variance tradeoff  one important assumption in our data is that voxels
are independent  only coupled by information ingrained
in their feature vectors  while this is a high bias decision  it allows us to use n       billion training samples
rather than only n       patient samples  contrast this
to deep learning algorithms like cnns  which learn the
important features from the data by choosing convolution
kernels on the inputs that capture the maximal amount
of variance of the outputs      however  cnns use each
patient as a single training sample  which allows access to
the entire atlas of a  d mr scan at once and hence the
ability for the computer to automatically find complex
features which relate wholly different parts of the brain 
we  on the other hand  a priori select dog convolution filters as our way to relate voxels to their neighborhoods  we are not learning the optimal neighborhood
information to train on  but instead choose a contrived
set of information based on prior knowledge  this injects
much bias into our model  but allows us to increase our
number of training samples by a factor of more than   
million  not only are neural nets intrinsically low bias  the
hope is that the improved variance caused by the enlarged
sample space will more than compensate for our high bias
assumptions  from the success of our algorithm  it is very
plausible that our hopes were not in vain 
however  it is worth mentioning that there may also

figure     biological receptive fields
figure taken from tim jacob     

conclusions we have thus shown that a hierarchical neural net model performs remarkably well on the
glioblastoma segmentation problem  our segmentation
results are competitive with those using much more complex methods  and we argue our success is due to our
smart choice of features along with a greatly enlarged
sample space and flexible training method  neural nets  
our algorithm is powerful despite its relatively high bias 
and we hope that it may serve the medical community in
their work 
the natural next step of this project is a thorough
analysis of our models asymptotics  we have claimed
that our large data set has significantly reduced model
variance  but it is unknown whether we can further reduce variance with more data  given that our segmentation algorithm is already on par with our reference expert
segmentations  we suspect but would like to confirm that
our model has already reached its large data asymptotic
performance 

 many of these other algorithms were trained on only a subset of    patients in line with brats challenge rules  however  our
algorithm returns dice scores of          on the same subset  not appreciably different from our results on the full     patients 

 

fitional conference on computer vision    pp           

references
   

   

   

   

bauer  s   et  al          a skull stripping filter for
itk  insight journal 

martin  john h          neuroanatomy  text and
atlas   ed 

   

bleeker  f  e   et  al          recent advances in the
molecular understanding of glioblastoma  journal of
neuro oncology                

menze  b  h          the multimodal brain tumor
image segmentation benchmark  brats   ieee
transactions on medical imaging      

    

ng  e y k   et  al          human eye imaging and
modeling 

    

olga russakovsky   jia deng   hao su  jonathan
krause  sanjeev satheesh  sean ma  zhiheng huang 
andrej karpathy  aditya khosla  michael bernstein 
alexander c  berg and li fei fei       equal contribution  imagenet large scale visual recognition
challenge  ijcv       

    

srensen  t          a method of establishing groups
of equal amplitude in plant sociology based on similarity of species and its application to analyses of the
vegetation on danish commons  kongelige danske
videnskabernes selskab             

brats challenge manuscripts         miccai
      harvard medical school  boston  massachusetts 

   

hinton  geoffrey          neural networks for machine learning  coursera

   

jacob  tim          vision cardiff university

   

lawrence  steve          face recognition  a convolutional neural network approach  ieee transactions on neural networks       

   

lowe  d  g          object recognition from local
scale invariant features  proceedings of the interna 

 

fi