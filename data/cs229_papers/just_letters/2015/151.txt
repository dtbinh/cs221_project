identifying injury inducing factors in baseball pitchers
jae jang

raejoon jung

abstract
this paper aims to identify which metrics in baseball
are meaningful in predicting whether a pitcher will get
injured before a particular season  to do so  we define a cost function and build a framework that takes
into account the asymmetric reward and cost associated
with correctly  or incorrectly  predicting injuries  we
then vary the sets of features on various machine learning techniques  i e   svm and linear regression  to test
each model within our framework and compute a utility
score for each model  finally we use this utility score
in conjunction with other standard feature filtering techniques such as pca and mutual information analysis to
determine which features provide the most useful information regarding whether a player will get injured in the
context of a season 

 

introduction

the integration of technology in professional sports and
recent advances in wearable technology has led to an exponential increase in the amount of data available for
sports analytics  this is especially true for baseball 
where many of its performance metrics are readily quantifiable and are recorded consistently across different
games and teams  with the abundance of data  it becomes increasingly challenging to pinpoint which data is
meaningful and to determine how beset to use the data 
in this paper  we address a problem that plagues not only
individual players  but major league baseball teams year
in and year out  pitcher injuries  having a healthy pitcher
for a starting season crucially impacts the outcome of
a season  and teams and managers consequently invest
millions of dollars into acquiring and identifying pitchers
who can stay healthy for a full season  with this context
in mind  we focus specifically on identifying the features
that are useful for predicting injuries before a season  for
this task  choosing features based on correlation or mu 

prafull sharma

tual information analysis alone has a few shortcomings
as these techniques do not take into account the relationship of the predictor variables to the response variables 
in our approach  we first define a cost function that reflects the cost and reward for predicting injuries and build
a framework that provides a meaningful measure of how
well a model performs in predicting an injury based on
this cost function  finally  we support the results by verifying that it is consistent with other feature filtering techniques and provide an intuition for each of the selected
features 

 

related work

the prediction of injury in baseball has been a topic of
interest for a long time due to the financial implications
of being able to do so successfully  much of the past
research and papers make the conclusion that the best
indicator of future injury is whether a player has suffered injury or undergone any type of arm surgery in the
past      as examples of such past work  we point to two
articles that employ well known machine learning techniques  forward search and random forests  carleton
    uses a forward stepwise model to rank the usefulness
of features as indicators of future injuries and concludes
that the one feature that is consistently meaningful in predicting an injury is past injury occurrence  in      the
study uses random forests as a means of injury prediction and reaches a conclusion similar to that of the first
paper  that past injury is the best indicator of future injury 
we argue  however  that past injury is a signal that general managers and team owners are already taking into
account  baseball teams are reluctant to trade for players
with past injuries  and the stock of a pitcher plummets
after an incidence of injury or surgery      we attempt
to answer a more challenging problem in our paper  the
problem of predicting injuries for players without past
injuries 

fidataset and features

  

analysis of dimension of the data via pca

   

  

we combined data from two databases to create our
dataset  from      we obtained player statistics on all
mlb pitchers for the past five seasons  with each year
containing    features for each player  we then used injury data from     to label each sample in the first dataset 
the injury data provides the date and name of every major league player to undergo tommy john surgery during their career since       and in the labeling process 
we matched each sample by name  team  and year to
avoid duplicate name collisions  we were able to preserve all our samples using this method as there were
no instances of a team ever having two pitchers with the
same name in our dataset  we elected to use the data in
two ways  in one approach  we treated data from different years as different input features and in another  we
used average and cumulative statistic for each player as
input 
when treating data from different years as different input features  we elected to use a mapping from player
name to career statistics  because every player contains data from different seasons  not always contiguous   we packaged the set of statistics for different years
into another mapping from season year x  to statistics for year x  the following steps were also taken to
merge the datasets and filter certain features  with a brief
rationale provided for each 

   

  

singular value

  

cumulative variance

 

   

  
 

   

 
 

   

 
 
 

 

  

  
  
principal components

  

  

   

figure    dimensionality of the data
removed as many players  especially foreign players  has these fields missing in this data and very
few of the players seemed to share same instances
of these two features 
after all the features were removed  our dataset consists of      samples  players  and     positives samples  we make particular note of the asymmetry in the
data with positive samples comprising only about    to
    of the data depending on the year  a fact that will
become much more relevant in the context of our testing
framework 
finally  we use two scaling methods on the data
throughout our process  normalization and standardization  we either normalize the columns of each feature to
a        scale or standardize each feature set to have zero
mean and unit variance  additionally  we performed a
principal component analysis on the standardized data
to get an initial picture of the variance and covariance
between the features  figure    
one important thing to note is that despite having over
   features  less than half      principal components account for     of the variance in the dataset  this is
largely due to the fact that many of our features were
calculated from one another  there was a high correlation
between the features  as a concrete example  we point
to whip  which is calculated as  walks   hits    innnigs
pitched  all three of which are also features in our dataset 

   remove players who moved teams during a season
via trades transfers
these players show up multiple times in a year and
because some features are sums  while others are
averages over numbers of games  and others yet are
averages over innings or balls pitched  we decided
   such instances from our dataset  none of our
positive samples fell under this case 
   remove seasons after a player got injured
our goal is to make predictions before a player gets
injured  and we thus elected to remove data for seasons an injured player played after coming back
from his most recent surgery since the player would
then be classified as having a past injury occurrence 
also  because some players had surgery multiple
times  we also explored how the result differed if
we removed seasons after a players first surgery  or
did not remove any seasons at all  our initial rationale behind electing to remove only seasons after
the final surgery was that the means of positive and
negative samples were most different in this case
and we provide a more formal justification in the
context of data noise in the results section 

 

methods

as a baseline approach  we ran k fold using the entire
dataset using gda  linear regression  and svm  the
results were consistent in all the attempts  with gda underperforming in nearly every case  regardless of the
model  we achieved a deceptively high prediction accuracy of        with each test  we describe the result

   features removed
features like high school  college of players were
 

fias deceptive because upon examination  we found that
our models were always predicting a negative label for
all input instances  and the test accuracy corresponded
exactly to the proportion of negative samples in the test
data           this problem is magnified in the k folds
approach as some of the training chunks sometimes receive very few or even zero positive samples  leading to
a model that predicts negative for any given input 
as an initial attempt at curing this result  we mapped
the features to higher dimensions and use svm with various kernel function to see if it resulted in clearer separation  even when using a polynomial of the second order  however  we achieved a training accuaracy of nearly
      but the test error fell below      this confirmed
that increasing the number of features  especially given
the high correlation between our predictor variables  was
not the correct path to explore and that we needed a different approach to address the asymmetry of of the data 
we intergrated two ideas into our model  down sampling
the majority and defining a cost function to offset the
level of asymmetry 

prediction via svm with different down sampling ratio
   

   

   

c n
 
   yi      yi     
n i  
u c    c   y    c c    c   y 

error    

utility

  
  

   

   

  
   

   
   
   
   
negative dataset size   positive dataset size

full

 

figure    prediction via svm with different downsampling ratio

majority down sampling
another idea we implemented as part of the training process was to down sample the majority to a factor of the
positives samples  in addition to the full training set  we
used   different negative positive sample ratio to train
each algorithm  a simple implementation of varying the
ratio  however  led to very arbitrary result depending on
the run  upon investigation  we found that the reason
for this was that because of the small ratio of positives
samples  in some instances of random down sampling 
the training set contained little to no positive samples 
and the hypotheses in these cases led to predictions with
an overwhelming number of false negatives  in one approach  we kept the number of positive samples fixed for
each k fold instance  but this introduced the problem of
our training set and testing set being too similar  to remedy this issue  the final approach we adopted was to    
separate our positive samples from the negative samples 
    select the      training  and      testing  chunks
from each respective set      combine and shuffle the two
randomly selected chunks to ensure that every training
set was guaranteed some positive samples 

 

   

results and discussion

of the many variables with which we experimented 
we elected to specifically display the test results for
the two more interesting methods we implemented into
our framework  majority down sampling and positive negative cost ratio  the test results from different
ratios  using svm with a gaussian kernel  are displayed
in figure   as shown in the figure   above  the overall test
error  especially the false positive error  is highest when
using a down sample ratio of     ratio  but the high test
error is also accompanied by a high utility  in fact the

   

where yi   h xi   w  b   c  and c are costs of false negative and false positive errors  respectively 
estimated cost of drafting an injured player
estimated cost of not drafting a healthy player
c 
number of negative samples

 
c
number of positive samples

  

  

   

by using test error as our only measure of accuracy  we
were failing to capture one very important characteristic
about predicting injuries  the cost of labeling an injured
player as healthy was much higher than the cost of labeling a healthy player as injured  to provide a little
more intuition on this notion  it makes sense from the
economic perspective that the cost of drafting acquiring
an injured player is much higher than the  opportunity 
cost of not drafting a healthy player  thus  the total test
error alone  wasnt the most appropriate measure of how
accurate our predictions in the context of baseball  and
we defined our own cost function in order to capture this
difference in the cost of misclassification  we adopt a
method discussed in bach et al s work on handling asymmetry of data with svm for our cost function      we
formally define the cost function for svm as follows 
c  n
   yi      yi     
n i  

  

  

cost function

c c    c   y   

false pos  error
false neg  error

   

 

fiprediction with aymmetric error cost
 negative sample down sampling ratio     
 

prediction via svm with different amount of stats per player

   

false pos  error
false neg  error
svm
blind pic
  
blind pic  w prior

  

  
  
  

   
error    

  

  

error    

utility

  
   

false pos  error
false neg  error

   

  
  
  
  

  

   

  

   
 

 
  
  
false negative cost   false postive cost

  

 

 

figure    prediction with asymmetric error cost

cumulative

 
 
 
 
number of years each player have data

 

figure    prediction with different amount of stats per
player

utility decreases continually as we increase the downsample ratio  decrease the asymmetry of data in the training set   intuitively  this is consistent with exactly what
we were trying to integrate into our model  the cost of
failing to identify an injury is much higher than the cost
of mis labeling a healthy player as injured  and this is
illustrated in the figure  the highest utility is achieved
at a level when the instances of false negatives are low
even at the cost of having relatively high number of false
positives  figure   plots the results over our second variable of interest  the penalty ratio  cost of false negative
  cost of false positive  used in the svm cost function
with the down sample ratio fixed at      we compare our
model against two different baseline models  one using a
blind random pick        chance  and one using a random pick with knowledge of the prior  to elaborate  the
prior baseline model uses its prior knowledge to make
predictions  for example  if the prior is the     of the
players are healthy then it predicts that the player will
be healthy with a probability of      figure   plots the
corresponding utilities of these two baseline models for
every penalty ratio  when the penalty ratio is less than   
svm performs slightly worse than the other two models
but achieves a higher utility for all other ratios 
bach et al s paper recommends a penalty ratio corresponding to  num majority samples   num minority samples  to offset the asymmetry of the data  but the reason we test our model using different penalty ratios was
that the true ratio of the cost of false negative to the cost
of false positives in baseball is unknown and we ideally
wanted our model to as robust as possible and outperform the baseline models for different penalty ratios  we
extend the test cases all the way to a penalty ratio of   
based on the intuition that the cost of investing millions
in a soon to be injured player is much higher than maintaining the incumbent player at the current position  presumably much higher than the empirical ratio of    based

purely on the ratio of pos neg samples  
we also highlight one additional variable of interest
introduced in the data section  as mentioned briefly as
part of data processing  we viewed the number of years
prior to an injury as an important factor in training our
model  especially given the fact that our dataset was obtained with years as different cross sections from the
database  we thus varied the number of years prior to
an injury to use with several models as we made changes
to the cost function and down sample ratio  figure   illustrates the   errors using different number of years 
the lowest false positive error is achieved using data
from the most recent two years before a particular season while the count of false negatives is relatively constant for all down sampling ratios  one reasonable interpretation might be that too few years leads to a lack
of data to accurately predict the results while using too
many years  where statistics from each year mean additional feature variables  results mostly in additional noise
while not adding much more meaningful information 

 

conclusion future work

using the framework that we developed  we applied a
forward search process on all our features and were able
to rank the features in the order selected by the process 
we list the    highest ranked features in figure    along
with the mutual information for each variable of interest  when testing using only these    features versus the
entire set of    features  we achieve a utility of       
versus         we commit the remainder of the discussion to provide an interpretation for each of the selected
features 
the above features can be classified into three major categories  pitch velocity  workload per season  and
workload per outing  the first category is best described
 

fi 

top    related features with injury
strike
outs
batters
faced
innings
pitched
games
played

    http   www baseball reference com 
    disabled list data  http   www baseballheatmaps 
com disabled list data 

hits

    young arms and curveballs  the real story behind
it all        http   www drivelinebaseball com  

earned run
allowed
whip
r allowed

    predicting injury status        http   
makenolittleplans net predicting injury status  

bb
era
    

references bibliography

    

    

    

    
score

    

    

    

    injuries impact newly expanded
top draft prosepects list       
http   m mlb com news article           
injuries impact landscape of top     draft prospects list 

    

figure    top    related features with tommy john
surgery

    bach   f  r   h eckerman   d   and h orvitz  
e  considering cost asymmetry in learning classifiers  the journal of machine learning research
                   

as representing the velocity of the pitch  strike outs 
whip  r allowed  and era are all measures that are associated with a pitcher with throwing velocity  a pitcher
with a strong fastball in his repertoire is more likely
to have a higher strikeout  lower whip  runs allowed 
hits  and era but also more prone to injuries than pitchers who rely on finesse and change ups       the second
category is the workload per season  or pitching volume 
of the pitcher as measured in innings the pitcher has to
handle per season  batters faced and innings pitched are
traditional measures of the workload volume a pitcher in
a season and pitchers with high values in these two features become susceptible to injuries from overuse     
the third category represents the length of time a pitcher
is out on the field in one outing  this quantity is best
measured by hits  bb  walks  as pitchers with a high
number in these two categories usually stay on the plate
longer per inning than the average pitcher 

    c arleton   r  a  baseball therapy  what really predicts pitcher injuries        http   www 
baseballprospectus com article php articleid 
      
    parks   e  d   and r ay  t  r  prevention of
overuse injuries in young baseball pitchers  sports
health  a multidisciplinary approach             
       
    z immerman   j       starting pitcher dl projections        http   www fangraphs com fantasy 
     starting pitcher dl projections 
     z immerman   j  velocitys realtionship with pitcher arm injuries 
      http   www hardballtimes com 
velocitys relationship with pitcher arm injuries  

as possible areas of further research  we would like
to explore integrating detailed data about pitcher physiology and mechanics  examples of such features include
their throwing motion  the height of ball release  average
velocity of pitches     
another area of future research involves not relying on
the asymmetry of data to define the relative penalty costs
but use a ratio that is reflective of the cost and reward associated with drafting or not drafting a player in the real
world  this might be done by comparing the financial
cost of drafting a soon to be injured player to the opportunity cost of foregoing drafting a healthy player  using
salary information and modern baseball metrics such as
war  wins above replacement  may provide a measure
of such an opportunity cost 
 

fi