calorie estimation from fast food images
kaixi ruan

lin shao

kaixi stanford edu

lins  stanford edu

december         

abstract

the outline of this report is as follows  in section   we
describe the dataset we use and the pre processing steps
taken before any actual machine learning implementation 
in section    we describe the different features we looked
at for svm  including the deep learning tools we used 
in section   we present some test results  section   concludes with some discussion and guidelines for the next
step 

the project consists of two steps  identifying food from
an image  and convert the food identification into a
calorie estimation  we perform food image classification
using svm and deep learning algorithms  different
features such as lbp  hog  and cnn  are explored and
compared  for the calorie estimation step  we create a
calorie map for the image classification labels 

 
 

introduction

related work

tatsuya et al     tried to estimate calorie by comparing input image with ground truth data based on image
features such as color histograms  color correlograms and
surf features   mei et al     used color histogram and
bag of sift features to build a discriminative machine
learning model to classify food images  however shape
and texture features are rarely used in previous work  we
adopt hog and lbp descriptors to capture these features 

calorie tracker applications are popular for on diet
population  with such applications  people can enter
their meals and estimate the daily consumption of calories  somehow  the meal entry task can be inconvenient 
sometimes it may not be possible to judge the size of the
dish  while eating out for example   thus a good idea
to help making these applications more user friendly is to
ask users to take a photo of their meal  and from that photo
to give a calorie estimation 

 

dataset

hence  this project aims to achieve this task  predict
the calorie content of a meal from an image showing one
or more food objects  technically speaking  the project
involves several tasks  identifying the food contained in
an image  estimating the quantity of food contained  and
converting the food classification into an calorie estimation  for the scope of this project  we ignore the scale
and quantity of food in an image and treat it as an image figure    ten categories we labeled for pfid data set
classification problem and we then convert the predicted  from top left to bottom right   burrito  salad  donuts 
labels to calorie estimations using online food database 
breakfast sandwich  pie  burger  toast sandwich  chicken 
pizza and bread
we use publicly available fast food image dataset for
pittsburgh fast food image dataset is a data set conthis project  we manually label our dataset  and test different classification algorithms  mainly svm and cnn  taining       images of fast food      stereo pairs     
different features used in image processing are used and     degree videos  we choose      fast food images
taken in laboratory or restaurants and divide them into ten
compared 
 

ficategories  the ten categories are burrito  salad  donuts  histogram of gradients are computed in every cell  the
breakfast sandwich  pie  burger  toast sandwich  chicken  histograms are then normalized over larger spatial regions
pizza and bread 
called blocks  hog is computed from images scaled to
resolution of           the picture below shows hog
feature of a given picture in our data set 

 

pre processing   features

calorie map we collected some data from the following web pages http   nutrition mcdonalds 
com getnutrition nutritionfacts pdf
http   www calorieking com foods 
calories in fast food chains restaurants 
c y lkptix html bid    
and
http 
  fastfoodnutrition org pizza hut 
which contain food calorie tables  then we get a clean
category to calorie dictionary so that once we get the
classification result we can convert it easily into calorie 
category
burrito
salad
donuts
breakfast sandwich
pie
burger
toast sandwich
chicken
pizza
bread

kcal
   
   
   
   
   
   
   
   
   
   

figure    hog feature

lbp features lbp is also a local feature descriptor
used to capture texture information of an image  after
changing the image from rgb to gray format  the image
is divided into small cells  the value of every pixel is
compared to its   neighbor pixels  if value in center is
higher than neighbors value    is set  otherwise  set it
   it generate   digits after comparing all   neighbor pixels  a histogram counting the occurrence of   digit series
in each cell is then created  concatenating histogram in
all cells will finally generate the feature vector  a picture
below shows the pipeline of computing lbp 

table    category to calorie table
image cropping note that the images from pfid are
taken in the laboratory with a huge white background  it is
generally considered good to crop out the features in question for a better cnn result     thus  we use the function
crop from python image library to process these images 
data augmentation we rotate images every time by   
degree from    degree to     degree  we gain       images totally  we split the data set into training set       
images   validate set       images  and test set       images  

 

hog features hog  histogram of gradients  is a local feature descriptor applied in image processing  the
image is divided into small regions called cell and intensify gradients are calculated over the pixels in the cells 

svm svm is a classical machine learning algorithm  it
gives classification boundaries by optimizing the margin
and some regularization terms  we use one vs one method
when svm is applied to multiclass classification problem 

figure    lbp feature

 

methods

fi 

a linear kernel is used when svm classifies two classes
at each iteration 

   
cnn we run cnn on caffe     in this stage  we adopt
bvlc reference caffenet from http   caffe 
berkeleyvision org model zoo html  it is
mainly based on the model that alex trained on imagenet large scale vision recognition challenge in     
 ilsvrc        krizhevsky et al  describe it in imagenet classification with deep convolutional neural networks in nips          table   shows the architecture of
cnn model we use 

results and discussion
svm on local features

we run svm on local features hog and lbp  the confusion matrices are shown below  generally speaking  lbp
is a little better than hog features  it indicates that texture information is better than shape information in our
classification problem  the lbp in classifying bread and
pie outperforms the hog feature 

layers
fc  relu  drop 
fc  relu  drop 
conv  relu  pool 
conv  relu 
conv  relu 
conv  relu  pool  norm 
conv  relu  pool  norm 
table    architecture of cnn model
fine tuning fine tuning uses a pretrained cnn model
and starts to train on new data set after changing some
higher lowers if necessary  the idea is based on observations that lower layers capture more generic image features while higher layers deal with more specific image
features associated with users data set  because the data
set we have is small  it is better to fine tune cnn model 
we fixed the first five layers and update parameters in the
last two fully connected layers  therefore in the fine tuning process  back propagation only exits in the layer two
layers 
back propagation is an optimization algorithm used in
cnn models  the back propagation is based on the chain
rule of taking derivatives f  g x     f  g x  g x  
back propagation algorithm could be divided into two
stages  in first stage  a forward propagation from input
data layer to output layer  then a loss function is calculated based on the output and its true value  the derivative of the loss function is taken with respect to different layers parameters  the direction of taking derivatives
is from higher layers to lower layers based on the chain
rule  in the second stage  the weight is updated by sub  figure    confusion matrix for hog  top  and
lbp down 
tracting the gradient multiplied by a learning rate 
 

fi   

svm on cnn features

specific with given dataset 
the accuracy percentage table below shows the accuan accuracy curve is generated when we fine tune cnn racy percentage using different methods 
models  the horizontal axis shows iterations  the vertical
axis represent accuracy percentage on validate set 
svm   hog
      
svm   lbp
      
svm   fc  pre trained model        
svm   fc  pre trained model        
svm   fc  fine tuned model 
      
svm   fc  fine tuned model 
      
cnn fine tuned model 
      
table    accuracy percentage table
figure    accuracy curve

 
we choose the model after      iterations to avoid over
fitting problem 
we then extract the features from the fc  and fc  layers  each feature is a      dimension vector  a linear
classifier svm is used to train these features  we also extract the features from fc  and fc  layers of the pre trained
cnn model  the features are then trained using the same
linear classifier  the confusion matrices are shown below 

future work

we want to enlarge the dataset  currently dataset is
small and contains only    categories  we want to put
more food types in the dataset  ideally it is also better to
add more images to the pre existing categories  it might
be interesting to combine different features to achieve
better accuracy  also to use a nonlinear kernel in svm
 throughout the project we have been using linear kernels   worried about over fitting issues with our current
data set  we choose not to do so 
the optimization becomes more and more important in
improving cnn performance  we also want to partially
focus on optimization method  i e  we want to use different optimization methods and compare their performance
in order to improve the optimization method if possible 

references
    ken chatfield  karen simonyan  andrea vedaldi  and andrew zisserman  return of the devil in the details  delving
deep into convolutional nets  corr  abs                 
    mei chen  k  dhingra  wen wu  lei yang  r  sukthankar 
and jie yang  pfid  pittsburgh fast food image dataset 
in image processing  icip          th ieee international
conference on  pages         nov      

figure    confusion matrices using cnn features  fc 
no fine tuning top left   fc  no fine tuning top right   fc 
fine tuning  down left   fc  fine tuning  down right  

    yangqing jia  evan shelhamer  jeff donahue  sergey
karayev  jonathan long  ross girshick  sergio guadarrama  and trevor darrell  caffe  convolutional architecture
for fast feature embedding  arxiv preprint arxiv           
     

we find out that the test results from fc  features are
the same for pre trained model and fine tuned model  the
test error from fc  in pre trained model is bigger than finetuned model  it indicates that fine tuning process mainly     alex krizhevsky  ilya sutskever  and geoffrey e  hinton 
changes the fc  layer and improves its output  it could
imagenet classification with deep convolutional neural networks  in f  pereira  c j c  burges  l  bottou  and k q 
be explained by the observations that higher layer is more
 

fiweinberger  editors  advances in neural information processing systems     pages           curran associates 
inc        
    tatsuya miyazaki  gamhewage c  de silva  and kiyoharu
aizawa  image based calorie content estimation for dietary
assessment  in ism  pages         ieee computer society       

 

fi