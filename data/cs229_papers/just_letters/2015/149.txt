prediction of yelp ratings based on reviewer comments
segmented by business type


kent lee 
  stanford



and james ross 

university  department of structural biology  biophysics program
  stanford

university  department of computer science

i  introduction
yelp    is a popular website that allows users to
submit numerical ratings  integers      inclusive   
being positive sentiment  and text reviews  reviewers
comments  to express their experiences interacting
with various businesses  this information helps others
determine which businesses best fit their needs  the
prevalence and utility of rating and review services
provide the opportunity and motivation to study the
prediction of ratings based on reviews  while these
services are prevalent  many internet forums are dedicated to publishing user reviews of products such
as laptops    and vehicles    without quantitative
ranking  often  forums hosting qualitative reviews
such as  laptop stopped working but helpdesk was
useless   and  customer service was horrible  would
benefit from an algorithm predicting rating from reviews to summarize user sentiment quantitatively 
furthermore  prediction algorithms allow rating and
review websites gather additional rating information
by predicting from external enthusiast forums where
reviews are more descriptive 
our goal was to apply machine learning techniques
to yelps published dataset to accurately predict ratings from reviews  an input of a string of words
into our multinomial naive bayes algorithm would
output a predicted rating between   and   describing the customers sentiment regarding a business 
while this has previously been attempted        most
approaches do not focus on training data segmentation  we believed that segmenting training data
by business sector  e g  restaurants  allows more
accurate predictions because feature sets become
less  diluted  or noisy and words gain meaningful
value when given a focused context  for example  an
auto mechanic business customer may be  extremely
satisfied with the new cold air intake system   while
a restaurant customer may say that  the food took a
while and came out cold   taken together  if feature
 these authors contributed equally to this work

size was fixed  the word  system  would offer as
little predictive value in ranking restaurants as  food 
would for the auto business  furthermore   cold  is
sentimentally negative in the restaurant review  yet
positive in the auto business review  training data
segmentation aims to reduce such uninformative occurrences 
ii  related work
interesting approaches involve looking up the quantified sentiment of each word from sentiwordnet and
summing the positive negative neutral in a document
and fitting to regression rather than a completely
probabilistic approach          while i think this is
the best method  the disadvantages are being limited to characterized words  groups using non word
features such as part of speech is an approach we
have not considered      a useful troubleshooting
approach is displaying the highest impact features
in a prediction     the potential to use latent factors
through matrix factorization seemed to have potential  but others who tried it received lower mse than
us    
iii  dataset and features
a  dataset
data was downloaded from yelps dataset
challenge    in json format containing     million
reviews and    thousand businesses  the dataset
was trimmed by a custom c  script to yield a dataset
containing entries with only metrics of interest 
review text on the business and reviewer rating of
the business  this formed the dataset allreviews  to
create a dataset containing only reviews from one
business segment  we identified the top represented
business segment in allreviews and created a dataset
containing only entries from this segment  the top
represented segment was restaurant         entries 
so all reviews on restaurants made up segreviews 
thus  allreviews and its subset segreviews are the
two datasets that were used  each dataset contained

fi      entries as training set        as validation set 
and       as test set  set sizes were smaller than
available data due to hardware constraints during
optimization  data was converted from the json
format to the form of
   reviews ratings txt 
 
 
 
 

 
 
 
   
   reviews reviews txt 

 

 

 

 

this vegas thai place can be tricky to find
it is off the strip hidden away in a
strip mall    
yum yum thai iced coffee fried tofu starter
and    
the commercial center mall is not the most
obvious choice for las vegas best thai
   
   
b  preliminary dataset processing
allreviews and segreviews were processed as follows  for each review entry  all characters were removed except for whitespaces and english alphabet
characters  all characters were converted to lowercase  each occurrence of a whitespace character
was replaced with one space character  all consecutive space characters were replaced with one space
character  this preempts potential string parsing and
string comparing problems  improves compatibility
with potential dictionaries and third party algorithms
 e g  stop word corpus  stemming algorithms   and
most importantly  normalizes and combines similar
features  e g  dont vs dont  thai vs thai  delicious vs
delicious   
c  dataset processing during optimization
stop words based on natural language toolkits
 nltk     stop word corpus were removed to reduce
common neutral sentiment features that provide little
predictive value  stemming was introduced by accessing nltks implementation of porters stemming
algorithm  which allows for further normalization and
combination of similar features 
d  feature selection
after preliminary processing  the baseline feature
size was        for allreviews and        for segreviews  manual removal of features was attempted by
looking through the feature list  ngrams were used to
increase the feature set to include groups of words

that may collectively have sentimental value while
sentimentally neutral individually  selectkbest using
a chi squared distribution was used to select features
that were found to have a dependence on specific
labels  selectkbest and ngrams were implemented
through scikitlearn    
iv  methods
a  multinomial naive bayes
like many learning algorithms  multinomial naive
bayes first attempts to derive parameters that maximize the joint likelihood of the training data  given
by

l y          y p    j y          j y p    

m
y

p x i    y  i   

i  

   
where y q   p  y   q   j y q   p  xj     y   q   q is
a number in the range of classes  j is a number in the
range of features  m is the number of training examples  p is the number of classes  and  x i    y  i    are the
ith training example  making the  naive  assumption
that given any y   all xi are mutually independent  the
solution to the maximization is

n

o

 i 
 i 
  
i     xj      y

 
pm
j y q  
 i    q
i     y

 
pm
 i 
 q
i     y

pm

y q  

m

   
   

once the parameters from equations   and   are
fit from the training data  prediction of a given test
example is simply calculating argmaxq p  y   q x   
p  x   y q p  y q 
  where q is the class with the highest
p  x 
posterior probability of all classes and x is the feature
vector 
b  support vector classifier
svc attempts to define a line  or hyperplane in
higher dimensions  that separates classes in a plot
of the training set that maximizes the distance  also
known as the margin  between the line and the closest
training example of each class  this line is called
the decision boundary  if line is given by f  x   
 wt x   b   it can be shown that the decision boundary
parameters can be set by
m

x
 
 
min w b  w    c
i
 
i  

   

with the constraint that

y  i   wt x i    b      i   i           m

   

i     i           m

   

 i 

 i 

where  x   y   are the ith training example  w and b
are parameters of the line  c and  are penalty terms

fithat penalize the objective function for each training
example on the wrong side of the decision boundary 
and m is the number of training examples  after the
optimization problem is solved  the decision boundary
is known and classification can be made by determining which side the training example lies with respect
to the decision boundary  it turns out that the decision boundary depends only on the training examples
closest to the decision boundary  known as support
vectors   which makes training svcs computationally
efficient  furthermore  it turns out that the solution
can be written as a linear combination of hx i    xi 
which is the form of a kernel  allowing efficient computation for large feature sizes  thus  features are often transformed into other feature spaces to achieve
better data separation  here  we used a linear kernel 
for classification with more than   classes  simply
classify one class versus the rest of the classes  for
each class  we applied scikitlearns implementation
of both algorithms  immediately before running any
algorithm  the reviews were first tokenized with the
exception of experiments with selectkbest  where the
features are tokenized  then run through selectkbest 
then run through the machine learning algorithm 
v  discussion
a  metrics
the main metric used was accuracy  given by the
number of validation or test examples correctly labeled divided by the total examples to be predicted 
a higher accuracy suggested that the predictor was
often able to correctly classify the reviews  while
cross validation was not done on validation and test
data     fold cross validation was used in generating learning curves  in the final comparison  mean
squared error  mse  was used to determine the average difference between the predicted label and the
pn 
 yi pred  yi actual     
actual label  n 
 
b  baselining
to construct an initial accuracy comparison between predictors trained on unsegmented and segmented datasets  baseline prediction accuracies of
allreviews and segreviews were each determined by
training a multinomial naive bayes  mnb  algorithm
on       training examples and testing on       test
examples  with a vocabulary of the       highest
frequency words  mnb was used because it was one
of the simplest and quickest to train classification
algorithms available  while we started with mnb  we
later attempted svc after optimizing our features 
the number of training examples and feature size
initially used were picked arbitrarily to ensure room
for optimization in either direction  this prevented

wasting time optimizing the model in the beginning
when many decisions were still in flux 
table i presents the data that will be discussed in
the rest of the discussion section  attention drawn to
specific rows will be of the form  r   
the baseline showed that segreviews  r   had
higher accuracies than allreviews  r   for the test
set       and      respectively   which supported our
hypothesis that segmented training examples yield
better predictors than unsegmented  however  lack
of difference in training errors  both       led us to
suspect that test set accuracy differences may have
been noise 
c  stop words and stemming
once a baseline was formed  it was more efficient
to focus on improving only segreviews accuracy instead of applying each subsequent change to both
segreviews and allreviews  once performance on
segreviews was satisfactory  we returned to apply the
same optimizations to allreviews and compare accuracies again  thus from here onwards  optimization
was against segreviews only  stop words and stemming is known to help with feature normalization and
reducing the possible total vocabulary by removing
words that are either neutral or common in all classes
 e g   the    and    was   and by replacing words
stemming from the same root with the root itself
 e g  replacing  purchase    purchased    purchasing 
with  purchas   collapses   features into     after removing stop words  r    training accuracy increased
marginally to      while validation accuracy remained
constant at      as compared to validation baseline
 r    stemming  r   decreased training accuracy to
     and validation accuracy decreased to       a
plausible explanation for no significant improvement
after stemming and removing stop words was that our
feature set was still too large for such optimizations to
make a difference  the top features may still contain
words that have little sentimental value  it is also
possible that the features used may contain few stop
words and words affected by stemming 
d  learning curve analysis
we wanted a rational approach to improve our
model rather than attempting random optimization
pathways so we generated a learning curve with
scikitlearn to test for overfitting or underfitting  plots
have points representing averages of    fold cross
validation  with shaded regions being standard deviation  as seen in figure    training accuracy was
significantly higher than cross validation accuracy 
indicative of high variance and overfitting  the high
number of features allowed the algorithm more degrees of freedom to fit the training data better 

firow
 
 
 
 
 
 
 
 
 
  
  
  
  
  

procedure
baseline
baseline
baseline
a   baseline   stop words
b   a   stemming
c   b   featuresize    
d   c   trainingexamples     
e   d   manual stop words
f   e   skb       featuresize       
g   f   bigram   trigrams  optimal 
g  optimal 
g  optimal 
g  optimal 
g  optimal 

dataset
allreviews
segreview
segreview
segreview
segreview
segreview
segreview
segreview
segreview
segreview
segreview
allreviews
segreviews
allreviews

type
test data
test data
validation
validation
validation
validation
validation
validation
validation
validation
test data
test data
test data
test data

validate test accuracy
     
     
     
     
     
     
     
     
     
     
     
     
     
     

train accuracy
     
     
     
     
     
     
     
     
     
     
     
     
     
     

mse
     
    
     
     
     
     
    
     
     
     
     
     
     
     

algorithm
mnb
mnb
mnb
mnb
mnb
mnb
mnb
mnb
mnb
mnb
mnb
mnb
svc
svc

table i
the effect of optimization procedure on prediction accuracy and mean squared error based on dataset and algorithm used 

fig    
learning curve after stop word removal and stemming
with    features shows high bias  score is prediction accuracy
fig     learning curve after stop word removal and stemming with
      features shows high variance  score is prediction accuracy 

fig    
learning curve after stop word removal and stemming
with     features is optimal  score is prediction accuracy

yielding significantly higher training accuracy  to reduce overfitting  we attempt to reduce the number
of features  figure   shows the learning curve with
    features while figure   shows underfitting when
feature size decreased to     where training accuracy decreased dramatically from a maximum of     
to a maximum of       indicating high bias  after
empirical optimization  stop word removal and stemming with     features was optimal  r    yielding
lower training and higher validation accuracy      
for both training and validation accuracy   figure  
shows no more overfitting or underfitting  the increase in validation accuracy was encouraging and
the decrease in training accuracy was associated with
the correction from overfitting  with       training
examples and     features  this agrees with the idea
that the number of features should be significantly
smaller than the number of training examples  the
convergence between training and cross validation
accuracy implies that the predictor generalizes well to
unseen data  figure   shows slight upwards slope in

ficross validation accuracy  suggesting that increasing
training examples may increase validation accuracy
further  increasing training set size from       to
      revealed clear convergence  plot not shown 
of training and cross validation accuracy  but decreased validation accuracy to       r    suggesting
that cross validation learning curve has plateaued
and no more optimization of features size or training
examples is necessary 
e  feature optimization
starting with manual feature optimization    
sentiment neutral words  e g  food  burger  dish  thai 
chicken  bellagio  were identified from the features
to add to the stop words list  with the next highest
frequency words replacing those removed  the goal
of this is similar to that of removing stop words
and the process  r   increased test accuracy to
      speaking to the value of customized stop word
lists  however  it is nontrivial to manually remove
all words we considered sentiment neutral given the
large vocabulary  furthermore  it is likely that using
the highest frequency features may shadow some
highly predictive mid frequency features  this led us
to selectkbest using the chi squared  which evaluates the likelihood that a given feature is independent
of a label and selects features that are not independent of a label  chi squared describes how likely
the appearance of a specific feature for a specific
label is due to random chance based on the training
features and labels  from       features  selectkbest
selected     features whose appearance for a label
are unlikely to be due to random chance  and thus are
dependent on the label   this significantly improved
validation accuracies to      after some optimization  r    bigram and trigram features were used
to further increase the features selectkbest could
choose from  increasing validation accuracy to     
 r     ngram helps because some features have little
correlation with labels independently  but more correlation when grouped together  giving selectkbest
more dependent features  select features identified
by selectkbest are   pretti damn    goooood    lick
plate    flavorless    oh well    perfect    realli tast  
 tasteless    would highli   and  appoint  
f  confusion matrix analysis
figure   shows a confusion matrix for the optimal
state  r     the matrix has percentages that add to
    across rows  adjacent misclassifications make
up a majority of errors  which is understandable
since the difference between   and a   is slight and
subjective  we are pleased to see the majority of
classifications in each row are correct  red in the

fig     confusion matrix for fully optimized segreviews with mnb
in percentages for each row  total sample size is      calculated
by scikitlearn

diagonal   troubling areas are actual      predicted
    and actual     and predicted     and   
g  return to baseline
satisfied with the improvements  we compare test
data accuracies between allreviews and segreviews
after applying our optimizations to both and against
baseline  baseline  before optimization   segreviews
 r   was      more accurate than allreviews  r  
      against       respectively   but after optimization  segreviews  r    was      more accurate than
allreviews  r          against       respectively  
additionally  optimization  r    increased segreviews
 r   accuracy by      compared to baseline  with
svc  after applying the mnb optimization  segreviews  r    was      more accurate than allreviews
 r          against       respectively  
vi  conclusion
we have shown that training data segmentation
has a significant effect on prediction accuracy  especially if incremental upon other dataset optimizations 
training only on yelps restaurant data shows that
an accuracy improvement of      over unsegmented
training data when given the same optimization procedure with mnb  the highest performing algorithm
was mnb with nltk stop word removal  proters
stemming  manual stop word removal        training
examples  bigram and trigrams  and select     best
from       features  this was better than svm likely
because the whole optimization process was done
with mnb  at optimal  our mnb mse was        so
on average  our prediction was off less than one a
yelp rating         
for future work  implementing forward search 
backward search  and mutual information calculations to select better features may yield better selections than selectkbest  introducing weights to
tokenization through tf idf  with tf factor being
raw counts  binary  or log normalized    log feature
frequency   may help adjust for frequently appearing  low impact words  finally  applying segmented
training sets to other business segments would help
confirm our finding 

fireferences
    yelp 
 n d   
retrieved
december
  
     
from
http   www yelp com 
    yelp dataset challenge   n d    retrieved december         
from http   www yelp com dataset challenge
    notebookreview   n d    retrieved december          from
http   forum notebookreview com 
    values
 
prices
paid 
 n d   
retrieved
december
  
     
from
http   forums edmunds com discussions tagged x valuesprices paid
    li  c   zhang  j   n d    prediction of yelp review star rating using sentiment analysis  retrieved december         
from http   cs    stanford edu proj     chen li  jin zhang 
prediction of yelp review star rating using sentiment analysis pdf
    xu  y   wu  x     wang  q   n d    sentiment analysis of
yelpas ratings based on text reviews  retrieved december          from http   cs    stanford edu proj     yun xu 
xinhui wu  qinxia wang  sentiment analysis of yelps ratings
based on text reviews pdf
    bird  s   klein  e   and loper  e  natural language processing
with python  oreilly media      
    pedregosa et al  scikit learn  machine learning in python 
jmlr     pp                  
    mooney  r  j   bennett  p  n   roy  l          book recommending using text categorization with extracted information  in
proc  recommender systems papers from      workshop 
technical report ws       
     gupta  n   di fabbrizio  g   haffner  p         june   capturing the stars  predicting ratings for service and product
reviews  in proceedings of the naacl hlt      workshop on
semantic search  pp          association for computational
linguistics 

     qu  l   ifrim  g   weikum  g         august   the bag ofopinions method for review rating prediction from sparse text
patterns  in proceedings of the   rd international conference
on computational linguistics  pp            association for
computational linguistics 
     siersdorfer  s   chelaru  s   nejdl  w   san pedro  j        
april   how useful are your comments   analyzing and predicting youtube comments and comment ratings  in proceedings of the   th international conference on world wide web
 pp            acm 
     feng  y   zhengli  s  yelp user rating prediction 
http   cs    stanford edu proj     yifei   feng
    zhengli   sun    yelp   user   rating   
prediction pdf

fi