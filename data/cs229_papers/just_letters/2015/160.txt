forecasting rossmann store leading   month sales
cs     fall     
sen lin  eric yu  xiuzhen guo

abstract

related work

we investigated the comparative performance of frequency domain regression  fdr  and support vector
regression  svr  for time series prediction of rossman
store sales  due to the extent of the data variables provided  svr clearly outperformed fdr  within svr  our
results reviewed that a polynomial kernel with regularization is most effective 

one standard approach in dealing with time series data was
the use of frequency domain regression  with band spectrum
selection  harvey         this model assumes that the disturbances from the mean are periodic and can effectively capture features like seasonal sales fluctuations in weather related
equipment sales  wilson  reale and laywood        

introduction

other papers have also investigated the use of support vector machines for time series forecasting  muller and vapnik 
        specific examples include electricity load prediction 
as conducted by researchers from national taiwan university
 hu  bao and xiong       

sales forecasting is critical for inventory management in the
retail industries  ideally  store managers can use accurate predictions to meet demand while minimizing inventory footprint
and therefore operational costs  further  discrete factors such
as holidays  opening of competitors and promotions all have a
significant level of demand at any given day  we seek to analyze the impact of these factors with the aid of time series
analysis and machine learning techniques 

lastly  groups have explored the use of neural networks for
the same purpose  connor  martin and atlas         we did
not investigate this owing to the lack of resources  but this is a
promising area for further research 

we used data from the kaggle competition rossmann store
sales   forecast sales using store  promotion  and competitor
data  rossmann gmbh is a major pharmaceutical chain with
over       stores across europe  including stores in poland 
hungary  czech republic  albania  and turkey  rossmann is
very similar to the pharmacy company walgreens in the u s 
the data contains a rich set of features  including both boolean
and continuous variables 

we were provided with data on      stores located across
germany  the data included sales records for each store over
the course of     days  giving us a total of about   million
data points  a second set of data included additional information on the model of the store  assortment of goods sold and
presence of competitors in the area  we believe that this is
sufficient data for our purposes  a summary of the raw data is
shown in table   below 

we investigated both the frequency domain regression and
the svr method  we found that time series methods underperformed more powerful machine learning techniques  upon
further scrutiny  we realized that this is because sales variations were mostly driven by these discrete events  while the
time series trends of seasonal or inter year trends were minimal  we believe that this finding is generalized to many forecasting problems  where more granular day to day predictions
are required on a short span of     years 

cross validation  we divided     of the training examples
into the training set  and used the remaining     as the test
set  we chose the first     of training examples in chronological order  since we wanted to test our models on their ability
to extrapolate on dates outside of their given range 

c       association for the advancement of artificial
copyright 
intelligence  www aaai org   all rights reserved 

data set

data preprocessing  there we some general steps to take  including numerizing all data  calculating the day of the week 
month of the year and so on  we also had to clean up the data
for routine store closures  further data processing was done
differently for frequency domain regression and svr 
   we observed that some of the shops were closed for ex 

fitable    raw data fields
field

value range

store id
date
sales
customers
open
school holidays
state holidays
store type
product assortment
competitor distance
date since competitor open
promo 
existence of promo 
date since promo  began
months with promo 

       
  jan          july     
           
       
   
   
       
a b c d
a b c
            meters
  jan          july     
   
   
  jan          july     
jan  dec

y x      

x
 kx
 kx
 ak cos
  bk cos
     x 
n
n
k

tended periods of time and that these data points with  
sales affected our predictive algorithms  since we only want
to assess the algorithms predictive power on days when the
stores were open  we opted to remove the days when a store
was closed from the data 
   for svr  we first normalized the sales by subtracting the
mean sales for each store from the stores sales numbers 
the mean sales number was retained as a parameter  this
allows us to focus the svr on impact of events on disturbances from the mean  then  we made numeral boolean the
variables of the store type and product assortment  whether
there was a promotion  a specific holiday  a competitor
opening  and how long it has been open for 
   for fdr  we treated the event variables as a blackbox and
simply worked with sales versus time for each store 

methodology
we used three different approaches in order to predict store
sales with respect to time  each method was trained on data
from a single store  and then used to predict the sales for that
particular store  this process was subsequently repeated for
every store 
first we used linear regression to obtain a baseline for the
prediction and to capture any inter year trends which we may
want to use to further normalize the data for svr and fdr 
the parameters for linear regression were found by using
matlab to solve the normal equations
    x t x   x t y
we then ran a discrete fourier domain regression to construct
a regression model for the periodic time series behavior  in
short  this method attempts to model the sales y on a particular
day x over the time period n by choosing the top k frequencies as shown in the following equation 

we also used support vector regression  which we felt was
better suited to predict the effects of events  such as promotions and holidays  on store sales  for the training set
  x      y              x m    y  m      where y  i  is the sales for a
particular point in time x i    we seek to find a hypothesis of
the form hw b  x    wt x   b with a small value of w  our
optimization problem is
l

min

x
 
  w      c
 i   i  
 
i  

s t 

y  i   wt x i   b     i

i           m

i

i           m

w b

t

 i 

w x  by
i   i   

 i 

 

where      is a given fixed value  we solved this problem with the aid of of the support vector regression function
in the scikit learn package  we can then avoid underfitting or
overfitting of the training data via conventional validation on
the variable c to control the slack allowance through the term
l
p
c
 i   i    as well as a choice between linear  polynomial
i  

or gaussian kernels 

error metric
the metrics that we used for our analysis was the root meansquared percentage error  rmspe   which is calculated as
v
u n 

u   x yi  yi  
t
rmspe  
n i  
yi
where n is the number of days yi is the sales of a store on
a single day and yi is the corresponding prediction  this is a
number used operationally in inventory planning and is hence
pertinent to the problem at hand 

experiment results and discussion
we only managed to train test on a limited number of stores
owing to computation resource constraints  our observations
for linear regression  fdr and svr are summarized in
table  
table    test errors for training methods
method
linear regression
frequency domain linear regression
support vector regression

test error
     
     
     

fiperhaps unsurprisingly  the more powerful svr  with a
degree   polynomial kernel and c        significantly outperformed lr  however  it was a surprising that fdr did so
poorly   in many cases even worse than linear regression on
the test data  we analyze this result below 

the use of fdr was motivated by the periodic movement of
sales data over     weeks  which becomes evident when we
plot over a period of     months  shown in figure  a at the
top is periodicity observed and the corresponding fitted trend
over training data  the plot in  b at the bottom shows the
performance of the model with a chosen set of extrapolated
test data 

linear regression
this model is a rudimentary first look into the large scale
trends  we did not expect it to capture the granular movements
of the sales numbers and indeed it didnt  reporting an average
rmspe of        shown in figure   below is the trend observations for a single store over the relevant time period 

figure    linear regression
we observe that there are minimal inter year trends and therefore can safely disregard them in future considerations 

frequency domain regression
the results of fdr are as follows 

figure    frequency domain regression results
the green line and points correspond to the training data and
fdr trendline  the red line and points are the extrapolated
prediction plotted against the test set  in the frequency domain graph  the black line shows the amplitude of each frequency  plotted as cycles per year  the red crosses denote the
frequencies chosen for the regression model 

figure      month plot with fdr line

clearly  the model seemed to be almost shifted by half a phase
from the actual periodicity of the data  although it fitted the
training data extremely well  its extrapolated performance was
unacceptable  we believe that it is due to the following factors 
   the periodicity was not due to unknown weekly or fortnightly factors but due to company driven actions   promo  
later  when plotting promo  against the sales  we realized
that the sales increases when the boolean promo  is true  in
this sense  there is no true periodic factors with consistent
phase and frequency  the company has introduced periodicity on its own schedule 
   the model is numerically unstable  even if there is a natural periodicity  a small error in frequency is equivalent to a
beats phenomenon in harmonic analysis  causing the model
to be eventually  out of phase with the original trendline
after some time  given the low resolution     data points
per cycle  of each period  the inherent imprecision is too
big given our extrapolation time span 
with the knowledge that the periodicity is event driven  we
then approached the problem with svr 

fisupport vector regression
from lr and fdr  we now know that the sales is unexpectedly lacking in event agnostic time series behavior  virtually
all movements in the sales volume are event driven  thus  we
stripped the data of all time based information   save for holidays  which we store as boolean variables   and plugged the
entire dataset into an svr 
here  a stumbling block was the computational complexity of
svr  as a rule of thumb  the big o for svr algorithms are
given  chapelle       
gaussian kernel  t  n  k    o n  k 
linear kernel  t  n  k    o nk    
figure    svm with gaussian kernel error plots
where n is the size of the training set and k is the number of
features  by this estimate  with         training data points 
this was clearly unfeasible  an approximate svm algorithm
t  n  k    o k     exists  claesen et al         but we did not
have time to try this 
we did however analyze a single store of type b and product assortment b  which is the most representative among the
population of stores  the results are summarized in figure   
  and   

the gaussian kernel on the other hand exhibited clear highvariance behavior  it was able to incrementally improve its
performance on the training data as we increase c  indeed 
it has almost perfected fitted the training set at c         unfortunately  the test error did not follow and only reached an
optimal at around c       

as we increase c  we are forcing the svr algorithm to work
with smaller slack variables  thus  as c increases  we expect
the training errors to fall 

figure    svm with linear kernel error plots

figure    svm with linear kernel error plots

the linear kernel is seen to be unable to increase its accuracy  despite our increasing c  our results suggest that after
c      all the svr is able to achieve is a great cost function
without changing the underlying regression line  the prediction error thus plateaued in a high bias situation 

clearly  polynomial kernels outperformed both gaussian and
linear kernels  it seems to be the optimal model  with c  
      in the bias variance trade off  here we note an anomaly
in the polynomial kernel  where the training error briefly rose
at c         this is cause for further investigation beyond this
report 
we are also concerned that the gaussian kernel underperformed polynomial kernels and would like to look deeper into
this phenomenon 

ficonclusion
our highest performing method was the support vector machine  which displayed the lowest amount of testing error  and
the worst performing method was linear regression  for the
support vector machine we achieved the best results with the
polynomial kernel  which achieved the best balance between
overfitting and underfitting  as expected  linear regression did
not perform very well due to the non linearity of the data 
unfortunately  the frequency domain linear regression model
failed to work as well as we had hoped  due to the fact that the
factors driving the sales were not really periodic in nature  but
rather due to company driven promotions 
there are numerous areas for future work  we may include
additional features in relation to some of the boolean variables in order to improve our models  for example  a more
careful treatment of the promotional data would have possibly
improved the prediction power of our algorithms  since the
presence of promo  seems to be more closely related to the
first derivative of sales 
we could have also implemented the o k     approximation
scheme for the gaussian kernel  so that our model can scale
to the full         data set 
additionally  it would be good to investigate the anomaly observed  a more thorough investigation of the tradeoffs between using a polynomial kernel and a gaussian kernel would
possibly have allowed us to optimize the accuracy of our
model 
in the future  we also hope to explore the usage of neural networks in time series prediction  since they are also a widely
used method for time series prediction  given the amount of
data we have  this can be very promising  it will also be interesting to compare their performance with the other methods at
hand 

acknowledgments
we would like to thank our mentor bryan mccann for his
helpful input on this project 

references
chapelle  olivier  training a support vector machine in the
primal  neural computation                        
chen  bo juen  ming wei chang  and chih jen lin  load
forecasting using support vector machines  a study on eunite competition       power systems  ieee transactions
on                        
claesen  marc  et al  fast prediction with svm models containing rbf kernels  arxiv preprint arxiv                  

connor  jerome t   r  douglas martin  and les e  atlas  recurrent neural networks and robust time series prediction 
neural networks  ieee transactions on                     
harvey  andrew c  linear regression in the frequency domain  international economic review                 
kaggle        https   www kaggle com 
hu  zhongyi  yukun bao  and tao xiong  electricity load
forecasting using support vector regression with memetic algorithms  the scientific world journal             
muller  klaus robert  et al  using support vector machines
for time series prediction  advances in kernel methodssupport vector learning  mit press  cambridge  ma                
smola  alex j   and bernhard schlkopf  a tutorial on support
vector regression  statistics and computing                     
wilson  granville tunnicliffe  marco reale  and john haywood  models for dependent time series  vol       crc press 
     

fi