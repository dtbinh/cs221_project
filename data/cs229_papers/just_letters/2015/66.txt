preprint typeset using latex style emulateapj v          

automated image artifact identification in dark energy survey ccd exposures
joseph w  derose and warren r  morningstar
kavli institute for particle astrophysics and cosmology   physics department  stanford university  stanford  ca        usa

abstract
in this work  we present an implementation of a machine learning algorithm to identify and classify
image artifacts in observations taken by the dark energy survey  des   specifically  we downsample
background subtracted ccd exposures and treat the downsampled pixel values as features in both a
support vector machine  svm  and a convolutional neural network  cnn  to classify full exposures 
in general the cnn outperforms the svm  in the two class problem and the    class problem  our svm
implementation does not perform better than random guessing on our test set for binary classification 
and predicts no artifact for nearly everything in the    class problem  cnns give a best test accuracy
of     on the binary classification problem and     on the    class problem  we discuss sources of
systematic error in our models and plans to account for these in future work 
   introduction

in modern cosmology  much attention has been turned
toward using large photometric sky surveys to provide
constraints on structure formation and the composition
of our universe  an important component of modern sky
surveys is the management and processing of the large
volumes of data produced by the survey instruments 
current sky surveys  such as the dark energy survey
whose data is used in this work  generate on the order
of several gigabytes of images and metadata per night 
future sky surveys will produce tb of data in the same
time frame  because of the vast quantities of data produced  the much of the data reduction and analysis is
automated 
while this provides significant advantages in performance  an obvious disadvantage is that it is prone to
overlooking subtle features in the data which may cause
systematic errors in measurements of important quantities  in particular  since the goal of many photometric surveys is to provide precise measurements of the
brightness of astronomical objects  any spurious brightness variations within a detector have the potential to be
interpreted as a real signal  and thus may interfere with
the accuracy of measurements 
brightness variations in a detector can be caused in
many different ways  and thus have a variety of appearances  a few notable examples that have been observed
by ongoing sky surveys include airplanes and satellites
passing across the field of view  cosmic rays striking the
detector  stray scattered light and improper subtraction
of background noise  some of these are detected and
masked away by the survey data reduction pipelines  but
a large number are missed  these missed aberrations are
usually referred to as image artifacts  reliable identification of artifacts is an essential component of preparing
data for analysis 
currently  the identification of artifacts is carried out
by members of survey collaborations  a process that uses
a significant number of human hours and that could be
better spent devoted to more scientifically interesting
problems  therefore an automated means of identifying
and classifying image artifacts is desirable 
in this paper  we discuss our implementations of both
support vector machines and convolutional neural net 

works trained to identify image artifacts found in observations performed by des  in section   we review attempts in the literature to perform similar tasks  we describe our data set and choice of features in section    in
section    we discuss the theoretical underpinnings and
implementations of our models  in section    we present
the results of our svm and cnn on both a binary and
   class problem  in section    we discuss these results 
including ways in which our methods could be improved 
   related work
automated image classification in astronomy is only
just becoming a problem worth solving  in the past 
many collaborations focused on taking a small number
of very long exposures over a small area of the night
sky  in these cases  great care was taken to gather data
only in the best observational conditions  and these data
were not numerous enough to require automated checking  a few surveys such as the sloan digital sky survey
 sdss   lupton et al         the   micron all sky survey   mass   skrutskie et al        and the palomarquest  pq  survey  donalek et al        have implemented automated means of dealing with image artifacts 
the first step in artifact identification in all of these surveys are background subtraction and object identification pipelines  additionally  the surveys all attempt to
classify the objects which are extracted in these first steps
as being real astronomical objects or artifacts  as opposed
to our approach of classifying artifacts on the ccd pixels themselves so that corrections can be applied before
object catalogs are created  sdss and  mass both accomplish their classifications by making cuts in measured
parameters of the objects such as color and morphology 
something akin to a manually trained linear regression
algorithm  sdss does not provide quantification of their
performance on artifact detection  while  mass comments that they achieve their requirement of having less
than       artifact contamination in their source catalogs  which is much less stringent than future requirements will be  pq employed a multi layer perceptron
for its classification  also using object parameters such
as shape and size as input variables  they report a    
classification accuracy  but we again emphasize that this
is classification done after objects have already been ex 

fi 
tracted  not on the actual ccd pixels 
while image classification is just making its way into
astronomy  it has been the subject of much work in the
field of machine learning for a number of years  two
approaches that have gained notoriety are the use of
support vector machines and especially convolutional
neural networks  in chapelle et al          the authors
process images into color histograms and use these histogram values as inputs to a support vector machine
trying a number of kernels  their work reports an error rate of       on the corel training set of rgb images  while this is an interesting result  it relies on color
images in order to construct features  an option that is
not available to us  convolutional neural networks have
been used for a number of years in image classification
problems  an early attempt in this direction was lecun et al         reporting a classification error rate of
     on a test set of written digits  another very interesting machine learning result in recent years was the
imagenet  krizhevsky et al        implementation of a
cnn  achieving       accuracy on a      class image
classification problem  both of these papers used much
larger training sets than we had available  with many
more examples per class  but they are good examples of
the successes of cnns on image classification problems 
additionally  most image classification in the field of machine learning is done on relatively high signal to noise
images  it has been reported that when adding small
perturbations to images classified with high confidence
by cnns it is possible to fool them entirely  goodfellow
et al         this may be relevant to our problem  since
the varying noise properties of individual exposures can
be interpreted as adding such perturbations to artifacts
that may otherwise be classified correctly 
   data
the dark energy survey  des  is a sky survey being
conducted across many institutions  des is being carried
out using the  m blanco telescope located at the cerro
tololo inter american observatory in chile  the survey
saw first light in       and is currently in its  rd year
of data taking  the des camera  decam  is made up
of    charge coupled devices  ccds  each composed of
           pixels  each pixel measures the flux on the
sky as a number of electrons freed from the valence band
of the ccd silicon per second  the number of exposures
that des takes per night varies widely depending on the
time of year and observing conditions  but a typical night
yields approximately     new exposures 
given that the survey has been active for several years
taking data at the rates given above  the total volume
of data is on the order of    tb  this makes training a
model prohibitively expensive without reducing the size
of the data  even if only using a subset of the total data 
as a means of making our methods computationally feasible  we decided to downsample the image data  we did
this by replacing squares of pixels of a characteristic side
length with the mean of all the pixels within the square 
this type of coarse graining will not hide any artifacts
as long as the side lengths of the squares are significantly
smaller than the sizes of the smallest artifacts  we found
that binning the data into  x  pixel bins  reducing our
data volume by a factor of      sufficiently reduced the
size of our training set  while keeping the pixels signifi 

cantly smaller than the observed sizes of artifacts 
each ccd exposure also has associated with it an estimation of the background light not grouped into any
of the identified objects  as well as a mask identifying
the regions of the ccd containing bright stars  cosmic
rays and other spurious sources identified by the current
des image reduction pipeline  before downsampling the
exposures we subtract the estimated background and apply the mask  as a final pre processing step we apply the
transformation
arcsinh i  m
      
   
m m
where i is the flux of the pixel  m   max i  and
m   min i   this transformation emphasizes low level
noise in the image  where many of the artifacts have their
strongest signature 
currently des identifies unmasked image artifacts
manually via a web based application  melchior et al 
       users inspect single ccd exposures  and upon
finding an artifact label a single pixel of the exposure
with the artifact type  thus  there is no information
about the extent of the artifact  making classification on
a pixel by pixel basis unfeasible  artifacts are grouped
into    classes  including some obvious defects such as
cosmic ray  airplane  and satellite  and some more subtle and obscure such as haze  dark halo  and wavy sky 
we add an additional label  no artifact as a null result
for our classifier 
we used the des web utility to provide us with our
training examples  specifically  our training data consists
of all of the exposures obtained in the first year of des 
which have at least one ccd that was manually classified
as having an artifact  the total size of this data set
is       ccd exposures  obtained from approximately
     observations  the number of artifacts classified in
the data is approximately       spread across roughly
   of the ccd exposures  figure   contains examples
of    of the    artifact classes 
we labeled our training data based on which artifact
class it contained  many of our exposures contain multiple classes of artifacts  for these  we randomly set the
artifact label to one of the artifacts present  when we
are attempting a binary classification this is not an issue  but when we attempt to classify into the full    class
space this may be a source of error 
finally  we created an augmented training set consisting of      ccd exposures  half of which contained artifacts  we did this as a means of reducing the run times
of our algorithms  as well as emphasizing artifacts in our
training sets  this will likely bias our estimations of the
probabilities of artifacts high  as this training set contains a much higher proportion of ccds with artifacts
than the actual des dataset  but a bias in this direction
is desirable  it is the opposite bias  one against classifying ccds as containing artifacts  that is detrimental
since this means that spurious objects make it into catalogs being used for science 
   methods

     support vector machine
our first attempt at an image artifact classifier was a
support vector machine  this was not the ideal choice

fi 

figure    example artifacts 

for such a high dimensional feature space  as we show
in   but svms require little fine tuning in order to optimize their performance and are thus ideal for setting
performance baselines 
svms classify objects by assuming the hypothesis
takes the form
t

hw b  x    g w x   b 

   

where w and b are the weights and biases of the classifier
and x is a feature vector  the svm is trained by minimizing the geometric margin of the training set given
by
m

x
 
 
min w b kwk   c
i
 
i  

   

s t  yi  wt xi   b        i   i              m
i     i              m

   
   

w t i
b
where    yi   kwk
x   kbk
  is the geometric margin 
i are parameters allowing the training set to deviate
from linear separability and c is a regularization parameter controlling the sizes of the i s  in practice this
minimization is performed by maximizing the dual objective  which allows us to replace inner products with
arbitrary kernels  implicitly using a higher dimensional
feature space  in our implementation  we tried using
both a linear kernel as well as a gaussian kernel  finding no significant differences between the two in terms of
generalization error 

     convolutional neural network
convolutional neural networks  cnns  are a class of
learning algorithms tailored toward recognition of abstract image features  cnns accomplish this feat by
creating a number of convolutional filters which data
is passed through before reaching one or more densely
connected layers which operate more like conventional
machine learning methods  because of the convolutional
layers  these networks are better suited for use with images than svms  because they are able to overcome problems like translations or rotations of image features and
can construct their own set of robust features out of raw
pixel data  cnns are relatively difficult to tune due to
the large number of components that can be optimized 
but when used correctly can lead to high image classification accuracies 
we have implemented a cnn using the python
wrapped library tensorflow  abadi et al         we
have constructed our cnn with the following architecture 
 a primary convolutional layer  followed by a max
pooling step to reduce the dimensionality of the
output features and a relu activation layer 
 a secondary convolutional layer with a similar max
pooling step  followed by a dropout layer to reduce
overfitting and a relu activation layer 
 the image is flattened  and then passed to a primary fully connected layer followed by an additional dropout layer and a relu activation layer 
 a secondary fully connected layer followed by a
dropout layer and a relu activation layer 
 a final fully connected layer which produces the
probabilities of each class via a softmax activation 
in the convolutional layers  we convolve our images with
a series of filters and add a bias constant to each convolved image  the result of the convolution is given as
x
yi   j    k   
wijkk  xi i   j j    k   bi  j 
   
i j k

where wijkk    bi   j   are the learned convolution weights
and biases respectively  we then apply a rectified linear
unit  relu  activation function
relu  x    max     x 

   

to determine the output of each layer  in the densely
connected layers  we perform a matrix multiplication using the outputs of the previous nodes as well as weights
matrices and constant bias terms  we also use relus
for activation after these layers  the dropout layers exist to randomly deactivate the connections between neurons in order to prevent overfitting  since if neurons are
randomly deactivated they cannot learn complex interdependencies  finally  a softmax activation on the last
densely connected layer produces the probabilities of
each class 

exp w  j t x   b j 
    
hjw b  x    p  y   j x    pn
 j t x   b j 
j   exp w
using the probabilities of each class  we compute the
cross entropy  defined as
s 

m x
n
x
i   j  

ptrue ij log ppred ij

   

fi 
where the sums are over the training examples and different classifications respectively  the cross entropy is a
measure of how similar two probability distributions are 
in this case the true probability of each class  and the
predicted probability  our objective with the cnn is to
minimize s with respect to the parameters of all the different layers  in practice  we perform this minimization
using an adam optimized  kingma   ba       batch
gradient descent  adam optimization is a variant of gradient descent where the parameter updates are given as
follows
p
t   t      mt    vt    
    
and mt and vt are estimates of the first and second moments of the gradient of the optimization objective with
respect to the parameters   this update adaptively adjusts the effective learning rate  such that the learning
rate is higher or lower based on the ratio of the first and
second moments of the gradient  in practice  this implements a sort of annealing  where updates become smaller
when approaching minima  we varied the batch sizes
that we used in various training runs eventually using a
batch size of   images for our best run 

figure    training and cross validation error plotted against
number of training examples with a coarse graining factor of   

   results

we have decided to examine our models using two different classification schemes  the    class problem in
which we try to classify images based on their labels as
given by the exposure checker  and the binary problem
in which images are flagged as either artifact or no
artifact  this allows us to explore multiple metrics for
the success of our method  including its effectiveness at
classifying certain artifacts  for these exercises we constructed a test set by holding out     of the training
examples from the training set constructed as detailed
in section   
to diagnose the effectiveness of the svm we computed
training and test error as a function of number of training examples  we find that the test error of the svm
consistently remains at     for both the binary and   
class problem independent of the number of training examples  while the training error is always   as can be
seen in figure    this behavior is indicative of overfitting manifested as low training error  this is to be
expected as the high dimensionality of the feature space
allows the training set to be linearly separable  but this
linear boundary is not representative of the true decision
boundary due to the small number of training examples
with respect to the number of features and classes  we
tried using larger coarse graining factors in order to reduce the dimensionality of the feature space  but this
does not result in any improvement in the test error 
the    class problem always has     error because because our classifier is labeling all test examples as label
    the number corresponding to no artifact 
our training and test errors for the cnn as a function
of number of training epochs for both the two and   
class problems are shown in figure    it is apparent that 
although the cnn significantly outperforms the svm
 achieving a maximum test accuracy of       it is still
overfitting the data  we discuss means of resolving this
issue in section   

figure    training and test error as a function of the number of
training epochs  dashed lines indicate training error  while solid
lines indicate test error

figure    false positive rate vs  false negative rate for the
binary classification problem  the colors indicate the threshold
probability necessary to be classified as an artifact 

when identifying artifacts  our main objective is to
minimize the rate of false negatives  because we do not
want artifacts to make it into object catalogs being used
for science  this means that it is useful to re adjust our
decision boundary to only accept data if the model is very
confident that there are no artifacts  however  there is

fi 
a trade off  because adjusting the decision boundary increases the rate of false positives  in order to maximize
the utility of our classifier in terms of number of exposures that do not need to be manually examined  this
rate should also be minimized  we have thus plotted an
roc like curve in which we attempt to determine the
best probability threshold to use as our decision boundary  it is plotted in figure   

figure    confusion matrix for our best cnn classifier for the
   class problem  the   th label is no artifact 

figure    confusion matrix for our best cnn classifier for the
binary problem breaking down the true labels into their actual
classes  the   th truth label and the top predicted label are no
artifact 

   discussion and future directions

we have trained both a cnn and an svm on a sample of data from the dark energy survey  finding that
the cnn significantly outperforms the svm  achieving a
test accuracy of up to      while the svm is consistent
with random guessing  since the major problem with the
cnn appears to be overfitting  the most straightforward
way to improve our classifier will be to collect additional
training data  this will become available with the release of the data taken during additional des observing
seasons  overfitting can also be reduced in the cnn by
increasing the dropout probability in the dropout layers 
or by applying additional coarsegraining to the data  we
must be careful with the latter however  since excessive

coarsegraining will diminish our sensitivity to artifacts
such as cosmic rays  which only take up a few of the
original image pixels 
it is also possible that our cnn is mis classifying artifacts because their features are too subtle or noisy to be
observed  figure   shows the most noticeable examples
of all of the different artifact classes  while several are
obvious  there are others that could be missed altogether
even by a human observer  because of this  it is possible
that many of the false negatives found occur because the
features of that particular class of artifact are too subtle
to be noticed by the cnn  to examine this possibility 
we have plotted the test error for all the classes present
in our test set in figure    we have found that treerings  haze  and a b jump artifacts were never classified
as being artifacts in our test set  which agrees with our
hypothesis since all three of these have very subtle signatures in the data  the subtlety of the features of some
artifacts may also mean that some of the true training labels are incorrect  a possibility that we have not
attempted to account for 
another source of classification error in our data is our
requirement that each artifact has only   training label 
in the second from the top panel on the right column of
figure    we see that both a satellite  and bright streaks
are present in a single exposure  this suggests that we
should adjust our model either to allow for multiple classifications of a single image  or adjust our training set so
that only one class of artifacts is present in each image
section  the difficulty in doing this is that each artifact label is only assigned to a single pixel  meaning that
we are currently limited to requiring that each artifact
also fully fall on a single ccd  we can overcome this in
principle by applying a region growing algorithm which
could be used to classify each pixel in our training set
with its appropriate artifact label  this is beyond the
scope of this project however  so we merely note its potential as an improvement  we must also re iterate that
this problem only exists when considering the    class
problem 
from this work  we draw the following conclusions 
 our cnn outperforms an svm  although it is still
prone to overfitting 
 we could improve our model by adding additional
training data  or by using smaller postage stamp
images with more extensive labeling 
 our classifier is less successful at identifying artifacts whose features are subtle 
we plan to continue this work with the hope that it will
eventually be integrated into the des image processing
pipeline 
references
abadi  m   agarwal  a   barham  p   et al        tensorflow 
large scale machine learning on heterogeneous systems 
software available from tensorflow org
chapelle  o   haffner  p     vapnik  v  n        neural
networks  ieee transactions on          
donalek  c   mahabal  a   djorgovski  s   et al        arxiv
preprint arxiv          
goodfellow  i  j   shlens  j     szegedy  c        arxiv preprint
arxiv          
kingma  d     ba  j        arxiv preprint arxiv          
krizhevsky  a   sutskever  i     hinton  g  e        in advances
in neural information processing systems          
lecun  y   jackel  l   bottou  l   et al        in international
conference on artificial neural networks  vol          

fi 
lupton  r  h   ivezic  z   gunn  j  e   et al        sdss image
processing ii  the photo pipelines  tech  rep   technical report

melchior  p   sheldon  e   drlica wagner  a   et al        arxiv
preprint arxiv           
skrutskie  m   cutri  r   stiening  r   et al        the
astronomical journal           

fi