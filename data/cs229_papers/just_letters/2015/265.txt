 

usings cnns to estimate depth from stereo
imagery
tyler s  jordan  skanda shridhar  jayant thatte

abstractthis paper explores the benefit of using convolutional neural networks in generating a disparity space image
for rendering disparity maps from stereo imagery  an eightlayer fully connected network is constructed with      neurons
and trained on one million positive and negative image patch
samples  the disparity space image is aggregated using contextaware cross based method  the disparity map is generated by a
winner takes all strategy 
great improvements can be visually observed in comparison
to the naive subtractive plane sweep method especially in regions
with little to no texture  quantitatively as well  we find cnns
outperform the naive subtractive plane sweep on a selected set
of stereo pairs 

i  i ntroduction and r elated w ork
depth based stereoscopic image rendering and  d reconstruction has been an important area of research in multimedia 
broadcasting and in computer vision  the area has received a
lot of attention from the broadcast research community for
its applications in  d television   dtv  and free viewpoint
television  ftv                     at the core of all of these
applications is the ability to produce precise and accurate
depth maps for the scene under consideration  this helps in
synthesizing novel views  which is crucial to supporting varied
applications 
humans have an innate ability to perceive depth from
stereo imagery  however  conventional stereo correspondence
algorithms are generally incapable of producing reliable dense
disparity maps  most algorithms attempt to do this by first
computing a matching cost and then using various image
processing techniques to estimate depth from the cost   for
instance a common approach is to use squared intensity
differences and absolute intensity differences     
in our project  following     we have used a convolutional
neural network to predict the matching cost  this is followed
by an image processing pipeline that uses an assortment of
techniques to estimate disparity  the input to our system is a
stereo image pair and the output is a predicted disparity map 
ii  a lgorithm
we chiefly followed zbontar and lecuns pipeline    
shown in figure    the algorithm performs the following
four steps  first a cost function is computed which gives
a correlation value between the shifted image pairs at each
disparity  this cost function aides in determining the disparities
of objects  the cost function is intelligently blurred and energy
constraints are place on it  the the disparity map is generated
by using the disparity which minimizes the cost function in
each region  the disparity map is then refined by combining
the information from the disparities gathered from both views 

fig    

pipeline for generating the disparity map

a  matching cost computation
stereo correspondence algorithms generally begin by sweeping one of the images of the pair  right over left in our
approach  and computing a pixel wise cost at each disparity
value  the resulting stack of costs  figure    is called a
disparity space image  dsi      at each disparity level in the
dsi  the regions with the minimum cost are most likely to be
at that disparity in the scene 

fig     a cost function is computed between the the input images at every
disparity value  the disparity value that minimizes a cost in a given region is
used for that region 

common matching costs include square intensity differences
 sd  and absolute intensity differences  ad      such as 
x
cad  p  d   
 i l  q   i r  qd  
   
q   patch

in our approach we have trained a convolutional neural
network to output a cost given a left and a right image 
   data set and features  while training  the input to the
network is a pair of  x  patches  one drawn from each image
of a stereo pair  after training  the network outputs a score
indicated how well the pair of patches is correlated  the kitti
stereo data set  for which the ground truth disparity values are

fi 

known  was used to construct positive and negative training
samples  altogether  one million samples were used to train the
cnn  half of which were positive samples  and the remaining
half were negative
   methods  we used the convolutional neural network architecture specified in      consisting of   layers with rectified
linear units inserted in between each layer 
the final layer of the network produces two outputs  these
are passed through a softmax function to separate them and
this is outputted as a cost  while training  the following cross
entropy loss function is minimized using stochastic gradient
descent with a batch size of     
n

e 

  x
 pn log pn         pn  log    pn   
n i  

   

while training the network is configured as a fully connected
network as this is more computationally efficient  however it is
tedious to evaluate an entire image as an array of  x  patches 
therefore  after training  the fully connected network is reshaped into a convolutional network 
for instance  layer l  is reshaped so that for each node 
the     inputs are rearranged in the form of a  x x   filter
which can be used to perform a  d convolution with the   
 x  outputs from layer l   a similar modification is applied
to layer l   turning it into a convolutional layer with  x x   
filters 
once the network has been made convolutional  it accepts a
pair of complete images as input  and we can use it to prepare
the disparity space image for the subsequent image pipeline 
the output resembles the structure shown in figure   
b  cost aggregation
to ensure that the costs outputted for a given region are
smooth within that region cost aggregation is performed  to
ensure regions and not just outlier pixels are minimized we
want to blur the image  however  we would like to make sure
that blurring does not occur across discontinuities  such as
edges  in the scene  for example  it would be a bad outcome
if the disparity values at the edge of a car were averaged with
the wall behind it 
for this reason  we aggregate costs using a context aware
technique called cross based cost aggregation      the crossbased technique essentially creates size restricted regions of
similar color which heuristically correspond to objects assumed to be at the same depth  for each pixel p  in the left
and right images  a support region is constructed by creating
vertical and horizontal arms of a cross that are limited by a
length constraint
  p  pl        
   
and a color difference constraint 

fig    

architecture of our cnn    

the support region for each pixel consists of the union
of horizontal arms along the vertical arm  figure     the
combined support region is the intersection of the support
regions in each image given disparity d 
ud  p     q q  u l  p   qd  u r  pd  

   

   

fig     cross based cost aggregation creates support regions around each
pixel which consists of the union of all the horizontal arms of the pixels in
the vertical arm  arms for a particular pixel are outlined in white 

where zbontar and lecun only created support regions from
grayscale images  we implemented zhangs original method
    which compares the intensity of all three color channels 

disparity space is aggregated four times over this region for
each pixel  this aggregation can be done relatively computationally efficient using integral images  first  each horizontal

max   ic  p   ic  pl       

c r g b 

fi 

arm is summed using a horizontal integral image  then a
vertical integral image is created from the result and used to
sum along the vertical arm of each pixel  each integral image
cost one addition per pixel and each sum costs one addition
per pixel  this saves a lot of computational power when we
only use   additions per pixel rather than n   where n is the
number of pixels in the support region 
after cost aggregation  an energy constraint is placed on the
cost function as specified in zbontar and lecuns paper     
c  disparity computation
in our procedure we calculate the pixel wise disparity using
a winner takes all approach  for each pixel  the disparity
level at which the cost is minimum is recorded as the disparity
for that pixel 

fig     regions in the disparity map which have no match are filled in by
searching in    directions for correct disparities  then assigning the median to
the pixel value

d  disparity refinement
using the previous steps we produce disparity maps referenced to both the left and the right images  next  we can refine
these maps using the following heuristic suggested by zbontar
and lecun     
for each pixel in the left disparity map we check to see if a
corresponding pixel in the right image shares that disparity to
within        if it does  we classify it as a match  if it doesnt 
we scan the horizontal axis for a pixel that is a match  if we
find one  that pixel is most likely an occlusion  figure     if
we do not find one it is most likely a mismatch 

fig     the top two images are the left and right disparity maps respectively 
when they are compared to one another mismatched regions are filled 
fig     the right and left cameras capture the scene from different angle
 left  so some pixels in the disparity map generated from each view might be
occluded in the other right   when an occlusion region is detected in the left
disparity map  pixels from the left are used to fill in the hole 

to resolve occlusions we replace the occluded pixel by the
disparity value of the nearest match to the left  to resolve
mismatches  we search in sixteen directions until we find a
matching pixel in each direction and use the median of these
to replace the mismatched value  figure     the refinement
can be seen in figure   
iii 

r esults

a  qualitative analysis
using convolutional neural networks to create a cost
disparity space resulted much cleaner results than the naive
plane sweep with a    subtractive method specified in eq 
     figures       and   show a comparison of the two methods 
the cnn approach does a much better job at estimating
disparity of smooth surfaces 

from the results images we can see that our predictions
suffer at the edges  which is to be expected because we do
not have overlapping data there  additionally  as we slide the
images with respect to each other to generate the cost function 
we lose information from the edges as our disparity increases 
techniques exist for edge refinement  and given more time we
would have explored these 
another discrepancy occurs not because of the algorithm 
but because of optical reflections which trick the cost function
to pick disparities which are further away because the image
in the reflection is optically further than the reflective object 
besides these small problems  the algorithm is shown to
perform quite well 
to test the subjective quality of our disparity maps  we
generated red cyan anaglyphs to judge the quality of the
resulting  d image   we tried two methods  generating only
a novel right view from the left image and disparity map  and
generating novel left and right views from the the left image
and disparity map 
the novel right view is generated by applying the appro 

fi 

fig      top  the left image in the stereo pair  middle  disparity map created
with the convolutional neural network   bottom  disparity map created with
   subtractive method  the cnn performs better especially on smooth
surfaces such as the road  edges are not so well defined because of lack
of overlapping area between the input images

priate amount of negative disparity to each pixel in the left
image according to the depth map  figure      similarly  the
left novel view is generated by applying the half the positive
disparity to each pixel in the input left image  the holes
remaining in the novel view from occlusions are filled in with
pixels to the right in the right image and to the left in the left
image  figure     
the anaglyphs give us a very intuitive way to judge the
disparity map quality  we found that they produced fairly
realistic  d scenes  the novel views  however  contain small
distortions in certain areas due to the minor imperfections in
the disparity map  though the method which generates only a
right image requires more occlusion holes to be interpolated 
it produces more appealing results  this is probably due to the
minor distortion our disparity map applies to the novel images 
when one image is perfect  our brain tends to interpolated it
to the other eye  but when both images have distortions the
resulting scene does not look as good 
another way to assess the quality of the results is to compare
them with depth maps produced using a naive subtractive
approach  as can be seen from figures     and     using the
matching cost produced by the cnn yielded depth maps that
are smoother  and without the jarring holes in the maps that
result from the naive approach  also  regions with smooth
texture that are traditionally considered difficult to produce
depth values for are modeled surprisingly well 

fig      top  the left image in the stereo pair  middle  disparity map created
with the convolutional neural network   bottom  disparity map created with
   subtractive method 

b  quantitative analysis
we scored the disparity maps generated by both the cnn
and by subtractive plane sweep against the ground truth data
according to the kitti data set specification  to score  we
compute the ratio of of close disparities  within    to total valid
disparity pixels in the ground truth disparity map  the right
and left edges of the disparity maps are discounted because
our algorithm does not handle edges currently for reasons
discussed earlier  additionally  disparity values in the ground
truth are counted as invalid if they are greater than    because
that is the extent of our plane sweep 
for each of   test images we compute a score in this fashion
and then average the scores 
the scores are in table i below 
table i 
subtractive plane sweep
    

iv 

r esults
convolutional neural network
    

c onclusion

in our project we attempted to use a convolutional neural network to output a matching cost that could then be
aggregated and refined to compute pixel wise disparities  to
make training computationally efficient it was necessary to use
a fully connected network  to make testing computationally
efficient  it was necessary to transform the fully connected
network into a convolutional network 

fi 

fig       d anaglyphs generated from the original left image and synthesized
right view top   synthesized left and right views  middle   and original stereo
imagery  bottom 
fig       top  the left image in the stereo pair  middle  disparity map created
with the convolutional neural network   bottom  disparity map created with
   subtractive method  reflections through off the disparity measure 

elled rather well by this approach  anaglyphs were generated
from the depth maps to subjectively evaluate the results 
the next step step for us is to implement edge refinement
and rigorously compare our performance against ground truth
for our data set  owing to computing constraints we have not
yet been able to run exhaustive evaluations  but we are in
the process of obtaining these resources  and plan to produce
quantitative evaluations against the data set results in the
coming days 
acknowledgment
this work was also presented by tyler s  jordan and skanda
shridhar for ee      digital image processing  
r eferences
   

fig      a novel right view  top  is synthesized from the disparity map and a
left image  the original right image is shown for comparison  bottom   notice
how much of the scene looks very natural such as the roads and buildings 
but smaller features such as signposts are distorted 

once matching costs were computed  we made use of a
context aware aggregation scheme called cross based cost
aggregation  we then estimated disparities using a winner
takes all minimization approach  we also made use of occlusion interpolation to refine the computed pixel wise disparities 
we found that the cnn based approach leads to disparity
maps that are smoother than those obtained with a naive
approach  regions with low texture which are traditionally
considered difficult to produce disparity values for are mod 

   

   

   
   
   

christoph fehn  depth image based rendering  dibr   compression  and
transmission for a new approach on  d tv  in electronic imaging      
pages        international society for optics and photonics       
julien flack  philip v harman  and simon fox  low bandwidth
stereoscopic image encoding and transmission  in electronic imaging
      pages         international society for optics and photonics 
     
daniel scharstein and richard szeliski  a taxonomy and evaluation of
dense two frame stereo correspondence algorithms  international journal
of computer vision                    
graham thomas and oliver grau   d image sequence acquisition for tv
  film production  in null  page      ieee       
jure zbontar and yann lecun  computing the stereo matching cost with
a convolutional neural network  arxiv preprint arxiv                 
ke zhang  jiangbo lu  and gauthier lafruit  cross based local stereo
matching using orthogonal integral images  circuits and systems for
video technology  ieee transactions on                       

fi