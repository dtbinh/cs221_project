cs      fall     

 

clustering a customer base using twitter data
vanessa friedemann

abstractthis paper presents a method for clustering customers of a company using social media data from twitter 
retail and market analysis using social media has become a
promising field for large enterprise companies  applications
include customizing advertising campaigns  localizing unexplored
market segments  and projecting sales trends  the technique
outlined in this paper scrapes publicly accessible twitter data and
constructs features  these features are clustered using a similarity
measure to produce groupings of users  this method performs
well using the sample data set provided and exhibits potential to
further improve given access to more data 
keywordsunsupervised learning  k means  pca  clustering 
social media  customers  market segmentation  retail 

i  i ntroduction
applications of clustering in retail
there are numerous applications within the retail industry
for clustering large populations  clustering a companys customers allows marketing teams to tailor advertising messages
for specific groups of like minded people with similar interests  clustering a competitors customers  or the market as
a whole  helps a company to identify untapped niches into
which it can expand  further  customer clustering can feed
into recommendation systems to suggest items that similar
users purchased  according to forbes magazine      of
business leaders believe analytics will revolutionize business
operations     
a burgeoning area of research in the market analysis field
involves using publicly accessible social media data  the analytics website researchaccess states that social media can
be a value add to traditional recruitment strategies     
about this paper
our approach uses publicly available twitter data to perform
customer clustering for a chosen company  nike  we first
harvest the data from twitter using the open source tweepy
package in python      for efficient storage and querying  we
store this data into a local sqlite database 
we start with features selected from the data but then prune
and transform into a lower dimensional feature space using
principal component analysis  pca   these features are passed
into the k means unsupervised learning algorithm to segment
the samples into clusters  we then determine the appropriate
number of clusters by performing a quantitative analysis of the
resulting intra class variances and inter class distances 
section ii of this paper discusses related work involving
social media data and improvements on the standard k means
algorithm  section iii details the data and features used in
this paper  section iv elaborates on the k means clustering
technique and parameter selection  in this section we also
develop a quantitative metric to benchmark the quality of
clustering  section v presents the results of our algorithm 

why twitter data 
large scale private sector data  such as sales history and
loyalty account information  is prohibitively difficult to obtain
for persons unaffiliated with the company to which the data
pertains  for any company in need of information regarding
customers other than its own  there is a need for an alternative 
a key assumption we make is that a user who follows a
brand on twitter is a customer of that brand  although twitter
accounts lack some basic information such as gender  they
allow us to see other brands and public figures in which
a customer has indicated interest  this information helps to
create a more holistic view of the customer  we therefore
consider twitter data to be a reasonable proxy for customer
data when the latter is unavailable 
ii  r elated w ork
significance of social media data
past work has found that data scraped from social media is a
meaningful reflection of the human behind the account  using
twitter data  bergsma  drezde  et al  were able to successfully predict hidden features such as gender and ethnicity by
clustering on observed attributes such as first name  last name 
and friends list      a study from the ibm haifa research lab
demonstrated that using the same tags  bookmarking the same
web pages   and  connecting with the same people were all
features that led to like minded clusters      a pennsylvania
state university research project partitioned users based on
their levels of connectedness and engagement on social media 
and showed that there was significant difference amongst
the clusters regarding willingness to interact with a company
online      these studies set a precedent for the features we
selected  which are discussed in section iii 
improving on k means
k means is an efficient and flexible unsupervised learning
algorithm  it can be adapted in a number of clever ways to
suit various data sets including numerical  binary  and string
features  lingras and west use rough k means  which estimates
an upper and lower bound for each centroid rather than a single
mean  to account for a bad or incomplete data set      ding
and he present a strong argument for preprocessing with pca
     their analysis found a quality increase of more than    
when reducing from      dimensions to   prior to running kmeans  the authors attribute this to the principal components
being the features most indicative of cluster membership  z 
huang points out that k means is poorly suited to categorical
data  and proposes the use of k modes instead      a drawback
of this solution is that it forces centroids to take on the majority
feature value without indicating whether the data points in that
cluster are in strong agreement  further  pham et al  cautions

fics      fall     

 

the twitter user  the lexicographic proximity between the
language acronyms for en and es is not indicative of actual
similarity  to satisfy the similarity requirement  we convert
language to a tuple of float values by mapping the language
acronym to the latitude and longitude coordinates of the largest
city in the country with the most people who speak this
language  for example  the language acronym th is mapped
to the geographic coordinates of bangkok  thailand         
n           e  
the k means algorithm is isotropic with respect to all
features  as a consequence  a feature with a larger range than
another will indirectly receive more weight in the algorithm 
one approach to alleviate this distortion is to map all features
to be within the same range       we choose to map the
statuses posted  number of followers  number of accounts
following  latitude  and longitude features to be within the
range of the features output by pca  described below  
fig    

percentage of followers for a set of chosen influencers 

against using k means as a black box and arbitrarily selecting
the number of clusters      
iii 

data s et and f eatures

user data
twitters api rate limit constrains data gathering to a
maximum limit of     data points per hour       as such 
we only consider a subset of        users from nikes total
    million followers  for each user  the data set includes a
number of basic features including statuses posted  number
of followers  number of accounts following  and language  in
addition  we record whether each user is following one or more
of a select list of popular twitter accounts  we refer to these
accounts as influencers  this set was hand selected from a list
of the     most followed twitter accounts and consists of 
 taylor swift  espn  bill gates  pope francis  cnn  barack
obama  kim kardashian  cristiano ronaldo  jimmy fallon 
oprah winfrey  lil wayne  nasa        figure   shows
the percentage of users following each influencer for nikes
followers as well as the general twitter population  note that
the distribution for nikes followers is different than that for all
twitter users  for example  nikes followers are more likely to
follow espn than barack obama  while the opposite is true for
the general twitter population  such differences are indicative
of inherently distinct preferences for a chosen customer base 
this further reaffirms the application of this analysis in targeted
advertising 
feature similarity
the basic k means algorithm requires features to have a
numerical representation so that the chosen cluster centers
coordinates are well defined  specifically  it is important to
preserve the meaning of the euclidean distance between two
samples as relating to similarity  in our case  all of the
selected features are numerical except for the language of

dimensionality reduction
the original feature set includes two traits called verified and
utc offset  the verified feature holds a boolean value to indicate
if the user is famous or not  the utc offset field represents the
users timezone as an offset in seconds from gmt  both of
these features are shown to have low variance across the data
set  the large majority of users have verified set to   and do not
provide a utc offset value  possibly due to privacy concerns  
accordingly  these fields should be discarded from the final
feature set 
we represent users following relationships towards influencers as a binary matrix with a   in the  i  j  position if user
i follows influencer j  as previously mentioned  k means does
not work well on binary data  therefore  as a pre processing
step  we perform pca on the influencers matrix  we choose to
reduce from    dimensions to    this corresponds to the lowest
dimensionality that explains at least     of the variance 
which is a common rule of thumb  figure   illustrates how
this minimum dimensionality is chosen 
iv  m ethods
k means
the k means algorithm partitions the data by assigning each
sample to a cluster for a predetermined number of clusters
k  on initialization  k cluster centroids are randomly chosen 
at each iteration  the algorithm assigns each sample to the
cluster of the nearest centroid  it then recomputes the centroid
to be the mean of the samples currently assigned to its
cluster  the nearest centroid for a sample is defined to be
the one with smallest euclidean distance from that sample 
k means converges when the centroid values stabilize  the
cluster centers c and labels are determined by minimizing
arg min
c

k x
x

 

kx  ci k

   

i   xci

we employ k means to perform the clustering because it
produces acceptable experimental results and is considered to

fics      fall     

 

cluster size that results in a silhouette coefficient of more than
a chosen threshold        

fig    

explained variance as a function of dimensionality 

be relatively computationally efficient  our application requires
clustering for a potentially massive social media data set  this
suggests choosing k means over slower alternatives such as
hierarchical clustering      
the specific implementation of k means we use in this paper
is provided by pythons scikit learn package      
silhouette coefficient
the remaining issue is to determine the number of clusters
k  we begin by selecting the optimal number of clusters by
maximizing the silhouette coefficient shown below  this metric
is indicative of how well each object lies within its chosen
cluster      

a i 

    b i    a i    b i 
 
  a i    b i         
s i   

 b i       a i    b i 
a i 

the term a i  is the average dissimilarity of sample i to
all other samples within the same cluster  it represents how
well sample i fits in its cluster  and the term b i  is the
smallest average dissimilarity of sample i to any other cluster 
of which it is not a member  this represents the next best
fit for sample i  intuitively  the goal is to select clusters
such that we maximize every samples fit to its own cluster
while minimizing the fit to the next best cluster  to achieve
the maximum of s i       we require a i     b i  for all
samples 
one shortcoming of the silhouette coefficient is that it
provides no preference for using less clusters  a maximum
silhouette coefficient can trivially be obtained by selecting m
clusters and assigning one to each sample  we attempt to overcome this deficiency by iteratively computing the silhouette
coefficient for increasingly more clusters  we select the first

clustering performance
given the optimal value for k chosen above  it is necessary
to measure the clustering performance on our data set  one
feasible option is to simply use the output of the silhouette
coefficient function corresponding to this value of k  however 
one of our primary goals is to illustrate our clustering results
in r    which is more conducive to visualization  to attain
this  we compute a metric of clustering quality related to the
intra cluster variation and inversely proportional to the intercluster distance  this metric allows us to easily map to a lower
dimensional space while still maintaining the same metric
value  intuitively  this will transform our clustering instance
to a lower dimensional representation with the same ratio of
intra cluster variation to inter cluster distance  we define the
clustering performance as
 pm

  x j  ci    x j  ci    
pk
j  p
m
 j 
i  
j  

q x  k   
pk

i  

 pk
j  

  x

ci  

  i  j   ci cj    

pk
j  



 

   

  i  j 

where it is desirable to achieve a low score for the clustering
performance q  the mean  rather than min or max  is chosen
as the aggregate statistic for both intra cluster variations and
inter cluster distances to be more robust to outliers 
v  r esults
selecting the number of clusters
in selecting the optimal number of clusters  we ignore the
meaningless solution of k      further  we upper bound the
number of clusters at k      since that seems reasonable given
our particular application  as described above  we iteratively
run k means for the remaining candidate values of k and
compute the corresponding silhouette coefficient  figure  
illustrates the silhouette coefficient for each value of k  the
optimal value of k was experimentally determined to be k     
measuring clustering performance
given the number of clusters k selected above  we next
compute the clustering performance q for our data set  figure
  shows the relative clustering performance scores for randomized data  our data set  and perfectly clustered data  low
values of q correspond to better clustering performance  this
result indicates that our clustering performance is in between
that of ideal data and that of randomized data 
visualizing clusters
as described above  one key ambition is to visualize some
representation of our clustering output in r    figure   indicates one such visualization  the depicted clusters have the
same ratio of average intra cluster variation to average intercluster distance as our clustering output  this suggests that our
data set can be cleanly clustered in our dimensionality space 

fics      fall     

fig    

silhouette coefficient as a function of number of clusters 

 

fig     representative clusters in r  that share the same ratio of intra cluster
variations to inter cluster distances as our clustering output 

cluster    these users are based in spanish or portuguese
speaking countries  they are not following the majority of
the influencers  however  there is one noteworthy exception 
nearly all follow soccer star cristiano ronaldo 
cluster    these users are based in asia  they appear
slightly more active on twitter than users in the other
clusters  a number of accounts in this cluster have usernames
that are a long series of letters and numbers  for example
  b rsk qao  kkm and  bikaoqta  k ndb  this
warrants further investigation and may correspond to bot
twitter accounts  if we suspect that a significant number of
these users are indeed bots  we can try running k means with
k     on just this cluster to separate the legitimate users from
the rest 
fig     cluster performance q for randomized data  our data set  and perfectly
clustered data 

manual labeling
we attempt to determine the mode user of each cluster by
examining a randomly selected subset of samples from each
of the k     clusters 
cluster    these users speak english and follow many
of the chosen influencers  this group represents americans
that are actively engaged in pop culture 
cluster    these users live in europe  primarily in wealthier
western countries such as france and germany  they follow
fewer of the influencers than cluster    however  the
influencers these users do follow are international figures such
as the pope or barack obama 

cluster    these users speak english  and follow few
to none of the influencers we selected  however  further
examination of their profiles shows that they are following
other companies and public figures  these include louis
vuitton  which indicates an interest in luxury and brand
name goods   kendall jenner  whose fan base is younger
than all the influencers on the current list   and sports brands
such as puma and adidas  which implies an interest in
all athletic wear and not nikes products in particular  
this suggests that our influencers list did not fully capture
all interests common among nikes followers  expanding
the influencers list will likely lead to better clustering accuracy 
an experiment was performed to validate the meaningfulness of these selected clusters  a human subject was presented
with the chosen clusters and their descriptions  then the
subject was given a sample input feature and asked to assign
it to the most fitting cluster  this process was performed
repeatedly and the number of classifications that contradicted
our clustering was tracked  our empirical results show that the

fics      fall     

 

human and our algorithm were in agreement approximately
    of the time 

   
   

vi 

c onclusion

summary
this paper has shown a method for extracting and processing
publicly available social media data for the purposes of customer clustering  section iii showed how to use dimensionality
reduction techniques to sanitize the extracted features  section
iv developed metrics for selecting the optimal number of
clusters k and evaluating the overall clustering performance q 
lastly  in section v we illustrated a representative clustering
output for nikes twitter followers in r   

   
    
    
    
    
    

    

discussion
figure   indicates that the quality of clustering achievable
using our techniques is midway in between that of ideal and
randomized data  further  the result shown in figure   shows
that the clusters created are remarkably pronounced and welldefined  the manual labeling experiment demonstrates that
the selected clusters have recognizable meaning to a human
observer  overall the outcome of these experiments further
reinforces the credibility of using social media data for market
analysis 
future work
future research on this topic should focus on applying these
algorithms to a more reliable data set  one assumption we
make in this paper is that twitter users are accurately reporting their preferences through their following actions  this
could be skewed because following preferences are publiclyvisible  more factual data sources might include credit card
transactions  newsletter subscriptions  and amazon shopping
cart history  researchers with access to these types of proprietary information would likely discover clusters with a better
clustering performance than presented here 
r eferences
   

   

   
   

   
   

l  colombus  roundup of analytics  big data business intelligence
forecasts and market estimates       
http   www forbes com sites louiscolumbus            roundup ofanalytics big data business intelligence forecasts and market estimates     
g  timpany    ways market researchers can use social media analytics  researchaccess      
http   researchaccess com         social media analytics 
j  roesslein  tweepy 
http   tweepy readthedocs org en v        retrieved      
s  bergsma  m  dredze  et al  broadly improving user classification via
communication based name and location clustering on twitter       
http   www clsp jhu edu  sbergsma twitterclusters 
i  guy  m  jacovi  et al  same places  same things  same people  ibm
haifa research lab        http   dl acm org citation cfm id        
b  jansen  k  sobel  et al  classifying ecommerce information sharing
behaviour by youths on social networking sites  journal of information
science       

    

p  lingras  c  west  interval set clustering of web users with rough
k means  journal of intelligent information systems       
c  ding  x  he  k means clustering via principal component analysis 
acm  page          
z  huang  extensions to the k means algorithm for clustering large
data sets with categorical values       
d  pham  s  dimov  et al  selection of k in k means clustering       
twitter  api rate limits  retrieved      
https   dev twitter com rest public rate limiting
twittercounter  retrieved      
http   twittercounter com 
a  jain  data clustering  a review  acm computing surveys  volume
   issue    pages               
m  kaur  u  kaur  comparison between k mean and hierarchical
algorithm using query redirection  international journal of advanced
research in computer science and software engineering       
scikit learn org  retrieved      
http   scikit learn org stable 
p  rousseeuw  silhouettes  a graphical aid to the interpretation and
validation of cluster analysis  computational and applied mathematics 
               

fi