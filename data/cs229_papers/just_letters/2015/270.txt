learning of visualization of object recognition features and image
reconstruction
qiao tan

yuanlin wen

chenyue meng

qtan stanford edu

yuanlinw stanford edu

chenyue stanford edu

abstract we introduce algorithms to visualize feature
spaces used inin object recognition systems by inverting a visual
feature back to a natural gray scale image  by investigating
algorithms including binary  and multi class svm  pairwise
dictionary and cnn  we succeed in boosting the correlation
measures up to       when comparing the inverted and original
images and speed up the inversion process to a few seconds on
a desktop computer 

in the following sections of this report  we will first
disclose details of features and dataset we have used and then
describe learning algorithms we have proposed to solve the
inversion problem  after that  we will present the training
and validation results  followed by a section of discussion
with insights 
ii  dataset and f eatures

i  introduction
feature visualization techniques have been inspiring many
applications in the field of computer vision  computer vision
researchers have been relying on these visualizations to
understand object recognition systems as well as to reveal
information encoded by features       to find security failures
in machine learning systems      to fix problems in convolutional neural networks       etc 
it makes feature visualization a even more promising tool
to complement failures in the computer vision systems when
parikh and zitnick      introduced a new paradigm for
human debugging of object detectors through visualizations 
by inverting visual features back to natural images and
thus providing more perceptually intuitive representation of
features  we can gain better understanding of the failures and
behaviors of object detection systems and future boost their
performance 
a great amount of efforts have been put in developing
effective feature inversion algorithms  weinzaepfel et al     
were the first to reconstruct an image given its keypoint sift
descriptors  their approach obtains compelling reconstruction performance by using a nearest neighbor based approach
on a massive database  this method analytically solves for
the inverse image problem yet requires an extensive dataset 
in later work  zeiler and fergus      presented a method to
visualize activations from a convolutional neural network and
girshick et al     proposed to visualize convolutional nueral
networks by finding images that activate a specific feature 
although these methods achieve to reconstruct and visualize
images from their respective features  they are either tailored
to a specific feature or computationally expensive 
in this project  we aim at leveraging advantages in algorithms presented in previous work and developing our
own feature visualization algorithms  namely  we will use
multi class svm  pairwise dictionary and cnn to invert the
input feature descriptors of particular image and produce a
reconstructed image as the output 

a  dataset
our training and test images are drawn from microsoft
object class recognition image databases     which consist
of     pixel wise labelled images  each of size        
from six object classes 
b  feature selection
one common way of performing object recognition is to
extract hog features from the original image and train a
linear svm classifier on a set of hog features  compared
with other feature descriptors which could have been used for
object recognition  like sift or surf which compute the
gradient histograms only for patches around specific interest
points  hog counts occurrences of gradient orientation in all
localized portions of an image and thus capture the gradient
information over the full image  consequently  to reconstruct
the whole original image  we are more interested in first
trying building our feature space on hog descriptors rather
than other local descriptors 
iii  methods
a  binary class support vector machine
in the first method  we try to invert hog features into
black white images and use multiple binary class svm classifiers to recover pixel values  either   or    
first  we divide the original image into multiple nonoverlapping      cells  for each cell i  we extract its hog
feature by computing its histogram over    bins  which is
interpreted by a    value vector  h i    to represent the cell
block  in other words  for each pixel in an      cell region 
its corresponding feature vector is  h i    then to predict all
the    values  either   or    in a cell  we need to build   
svms  one for each spot in the cell region 
we regard this method as one baseline method which other
methods can compare to 

fib  multi class support vector machine
support vector machines  svm  were originally designed
for binary classification problem  yet many experts are engaged in effectively extending it for multi class classification 
several methods have been proposed where typically we
construct a multi class classifier by combining several binary
classifiers  the most popular methods are one against all
method  which builds one svm per class  training it to
distinguish samples in a single class from the samples in
the remaining classes  and one against one method  which
builds one svm for each pair of classes  as discusses in
citehsu    comparison  the second method is more efficient
in computing the inversions than the first one  so we will
use the one against one strategy in the multi class svm
training method 
the one aginst one method was first used in       this
classifiers where each one is
method constructs k k  
 
trained on data from two classes  for training data from
the ith and the jth classes  we solve the following binary
classification problem 

imagine we can represent an image x i   rp and its
feature  i   rq with a image basis u  rpk and
a feature basis v  rqk   we can then estimate u and
v such that images and features can be encoded in their
respective bases but with shared coefficient   rk as
x i    u  and    v   once u and v have their paired
representation  we can then invert features by estimating
an that reconstructs the feature well  by using the same
 obtained from optimizing feature representation in the
previous step  we are able to produce reconstructed image
y  i  from the feature by computing y  i    u  
to build up the pairwise dictionary  which consists of
a one to one mapping from a hog descriptor basis to a
image basis  images patches x i  and their corresponding
hog features  i  are extracted from pascal voc     
    and we learn the dictionary by solving the optimization
problem as follows using spams            see fig     for
visualization of some learned basis pairs in the dictionary  
argmin
u v 

argmin
 ij  bij   ij

  ij t ij
       c
 
ij t

x

tij

t

ij

     xt     b 
  ij  t  xt     bij 

   tij   ifyt   i 
    tij   ifyt   j 

tij    
we use the following voting strategy suggested in      to
perform the multi class classification  if sign   ij  t  x   
bij   says x is in the ith class  then the vote for the ith class is
added by one  otherwise  the jth is increased by one  then
we predict x is in the class with the largest vote  the voting
approach described above is also called the max wins
strategy  in case that two classes have identical votes  we
simply select the one with the smaller index 
practically we solve the dual of equation above where
number of variables is the same as the number of data in two
classes  hence if in average each class has l k data points 
we have to solve k k     quadratic programming problems
where each of them has about  l k variables 
c  pairwise dictionary
the previous methods aim to reconstruct the images from
given descriptors directly at pixel level  which means we
approximate every pixel value using a batch of values from
the histogram of a cell in the hog features  regardless
of how descriptors and image patterns are tightly related
together  in other words  correlations between adjacent pixels
are disregarded due to the pixel level reconstruction  which
should be highly preserved in the ideal case  in this section 
we describe an algorithm which learns an over complete
pairwise dictionary from patches extracted from images and
corresponding hog descriptors and uses that dictionary
to encode descriptors and reconstructs the original images
accordingly 

s t 

x

i
 
  u    

  x i   u i           i   v i          i    

   and   v        

to encode hog descriptors using the feature bases in the
pairwise dictionary  we use the matching pursuit algorithm
proposed by   empirically  we found success producing fairly
good visualization results by encoding features using only a
few number of bases  see results section for full details  
d  convolutional neural network
convolutional nerual networks  cnns  have been proved
to be a powerful method over various computer vision tasks
like image classification           object recognition     and
detection          typically we train supervised cnns to
output high level abstract representations taking raw images
as inputs  inspired by      we reverse the standard cnn to
realize deconvolutional neural network  decnn  where each
layer consists of unpooling  convolution and relu  details
will be demonstrated later in sec  iii d    then we use
decnn to reconstruct original images from their features 
which are high level abstractions of images 
specifically  our decnn takes features generated from a
gray scale image as inputs  and outputs the same gray scale
image  we train decnn using standard backpropagation to
minimize the euclidean distance between the original and
reconstructed images  and we use theano  a python library
to build our neural network        
   hog feature  based on the analysis in sec  ii and a
few attempts like svm and pairwise dictionary which have
been illustrated above in sec  iii  we may have proven that
hog feature is a very good descriptor to represent the highlevel abstraction of an image  because of the plausibility of
image reconstruction using hog feature  we assume decnn
may work fine as well 
however  we failed to use decnn to reconstruct images
from hog features  because it is difficult to simulate the
process of computing hog feature using cnn  not to

fimention reversing it  according to the illustration in sec  ii 
we may assume the calculation of hog feature requires two
major steps  gradient computation and orientation based histogram computation  gradient magnitude is computed with
one dimensional filter kernels like           and          t
or      sobel masks  which can be realized perfectly with
cnn 
the major problem is about orientation based histogram 
when counting the occurrences of different gradient orientations in each cell  it is inevitable to lose specific position
information of each gradient orientation  however  position
information of gradient is extremely important for unpooling
operation in decnn       especially in our case where the
region for computing hog feature is as large as     which
leads to massive position data loss 
we tried using a three layer decnn to recover image
from its hog features but only outputs an image full of
noise  which further strengthens our previous assumption that
hog feature may not be a proper representation for image
reconstruction 
   cnn feature  to overcome the weakness of hog
feature whose local position information is lost  we extract
features of images directly using cnn  which will be much
easier and more plausible for decnn to invert  and those
cnn features can also be used for object recognition     
and classification      
generally we build an auto encoder which is composed
of two layers of convolution operations and two layers of
deconvolution operations  shown in fig    

fig    

architecture of the auto encoder  cnn   decnn 

the convolution part  which basically plays a role as
feature extraction  takes image as input and outputs its cnn
feature  then the deconvolution part aims to reconstruct the
original image  whose input is the extracted cnn feature and
output is the reconstructed image  more details of our autoencoder network  such as unpooling operations and kernel
sizes will be illustrated in sec  iv 
iv  r esults
in this section  we show our results of all algorithms we
proposed in iii and using both quantitative and qualitative
measures to evaluate the performance 
a  binary class svm
training hog features using binary svm algorithm  we
get the reconstructed image in fig   
in reconstructed image of fig    we can only roughly see
the contour of the hat and the face with the mean normalized
cross correlation being         this result provides us a
baseline in evaluating later inversion algorithms 

fig    
we show results for image reconstruction using binary svm
algorithm  left column  original image of lena  right column  hog feature
inversion 

b  multi class svm
after trying to reconstruct images in the training set  we
found that the mean normalized correlation is unacceptably
high  however  when we test the model  test error is unacceptably high where the classifiers tend to randomly pick a
pixel value to output 
this result can also be shown from correlation value
between original and predicted vectors  which are        
               corresponding to the three images in the
training set 
at first we set our parameters as  cellsize  
   blocksize      numbero fd irections       and
overlap      from results above  we deduce that the bad
performance of testing sets is due to overfitting  so we adjust
numbero fd irectons       which means we use    features
to estimate one pixel point  from experiments and other
experiences  we think the reason this method fails should
be more than overfitting 
we know that hog features counts occurrences of gradient orientation in localized portions of an image  specifically 
a group of features describe gradient or edge information
of one block   in our model  we set one block to be a
cell of     pixels   in order to estimate values of pixels
by hog features  we down scale our image by   so that
one group of hog features can be used to estimate value
of the corresponding pixel  it seems to be reasonable but
when we dig deeper into the principle of estimation  we find
that we are using gradient or edge features to estimate rgb
value of one pixel  which is equal to use velocity to estimate
distance without knowing an origin  in other words  this
method makes no sense even theoretically  not to mention
in reality 
after figuring out the problems of visualizing hog features by multi class svm algorithm  we decide to use a
different method  pairwise dictionary  to fix it 
c  pairwise dictionary
we have trained our pairwise dictionary over the training
set pascal voc          using spam      and obtained
     pairwise bases  which are used to decompose hog
features in the validation set  we show our inversion results
in fig   
qualitatively  by learning a dictionary over the correlation
between hog features and natural images  pairwise dictionary method tends to produce good visualizations of hog

fifeatures with higher correlation values in the validation set 
compared with the baseline method  the binary svm classifiers  notice that during the inversion  pairwise dictionary
method recovers high frequencies  which are invisible in
the original images  without introducing significant noise 
as hog is invariant to illustration changes and amplifies
gradient  inverting hog features provides us with extra
surrounding information about the original images and helps
us obtain a better understanding about the difference between
hog and human visions in an object recognition system 
we have also discovered that the learnt dictionary is
generalized enough to produce fairly good visualization with
only few bases  if we only use top n bases with largest
coefficients in the matching pursuit algorithm to reconstruct
the original images  we end up with producing visualizations
with good quality by using few bases  see fig      this
observation is significant in reducing computational costs in
a sense that we are able to perform fast inversions in a few
seconds over hog features on a desktop computer without
losing high level content of the inverse  

fig     inverting hog feature using different number of bases in the
dictionary  as we increase number of bases used  edges are captured better
in the results 

d  cnn
the convolution layer in fig    is standard  which consists
of three operations  convolution  maxpooling and relu  as
for the deconvolution layer  we change the order of those
three operations to realize the inversion of convolution  the
operations are unpooling  convolution and relu      the
diagram of unpooling operation is shown in fig     where
we replace each entry of a feature map by a      block with
the entry value in the top left corner and zeros elsewhere 
table i
c onvolution and de c onvolution filter and pooling size

conv  kernel
max un pool size

layer  
  
  

layer  
  
  

layer  
  
  

layer  
  
  

the details about the sizes of convolution filters and
pooling can be found in tab  i  for the first and second
layers  we operate maxpooling  and for the third and forth
layers  unpooling is operated 
another critical parameter of our network is the number
of channels at different layers  to research on the influence
of this parameter  we vary the numbers of the channels in
the   middle stages  shown as       in fig     and see how
it influences cnn features  shown in fig    
when channel number set is        we see that the cnn
features extracted from   convolution layers are basically
down sampled images  and   out of   basically store no

fig     we show results for inversions in all six categories using pairwise
dictionary algorithm  left column  original images  middle column  hog
features  right column  hog feature inversions 

fig    

illustration of      unpooling operation used in the network

information of our original image  if we reduce the channel
numbers to        we can see the results are quite similar 
hence we assume that the previous layer  layer    passes
in too much information which is not needed for decnn to
realize image reconstruction 
however  if we reduce all the channel numbers by half to
       then the extracted features become edge information
rather than down sampled image  and this situation will
remain the same even if we increase the middle channel
numbers to    hence the number of channels in our network
has a significant impact on the feature extraction 
the learning rate also affects the training speed and
performance of our netowork  so we had a few attempts
and the results are illustrated in fig    
after building our network  we trained the auto encoder
with different sets of the numbers of channels        and
       and reconstruct images shown as follows in fig    
the reconstructed image from       is recovered using the

fifig     cnn feature visualization  of different number of channels   from
top to bottom                                        
error vs iteration number      

error vs iteration number      

   

    
       
       
      

   

   

   

   

      
      
      

   

average euclidean distance

average euclidean distance

   

    
   
    
   

fig     we show results for inversion in all six categories using cnn
and decnn  left column  original images  middle column  channels       
right images  channels       

    
   

   

     
  

fig    
rates

    

 

  
iteration

 

  

     
  

 

  
iteration

convergence rate versus iteration numbers over different learning

table ii
m ean normalized cross correlation
category

down sampled feature while the image from       is built
using edge feature  these results verify our former analysis
of the cnn features 
v  c onclusion
in this project  we have implemented different algorithms 
namely binary  and multi class svm  pairwise dictionary
and cnn  to visualize object recognition features and provide more intuitive understandings of what happens in an
object recognition system  it turns out that both of pairwise
dictionary and cnn methods produce promising results in
terms of visualization quality  while cnn is able to invert
features with less errors  pairwise dictionary method tends to
perform fast inversions without losing high level contents of
the original image  for future work  it would be interesting
to investigate methods to recover a color image from hog
features by possibly overlaying multiple layers of inversions
over different color channels 
acknowledgment
we sincerely acknowledge our classmates shutong  zhang
and yixin  wang for their helps on setting up the cnn

house
face
car
tree
cow
plane

pairwise
dict
     
     
     
     
     
     

cnn
     
     
     
     
     
     
     
     
     
     
     
     
     
     

framework and thank teaching staffs of cs    for bring us
such a rewarding course 
r eferences
    microsoft object class recognition image databases kernel description       
    f  bastien  p  lamblin  r  pascanu  j  bergstra  i  j  goodfellow 
a  bergeron  n  bouchard  and y  bengio  theano  new features
and speed improvements  deep learning and unsupervised feature
learning nips      workshop       
    j  bergstra  o  breuleux  f  bastien  p  lamblin  r  pascanu  g  desjardins  j  turian  d  warde farley  and y  bengio  theano  a
cpu and gpu math expression compiler  in proceedings of the
python for scientific computing conference  scipy   june       oral
presentation 
    b  biggio  b  nelson  and p  laskov  poisoning attacks against support
vector machines  in international conference on machine learning 
     

fi    j  donahue  y  jia  o  vinyals  j  hoffman  n  zhang  e  tzeng  and
t  darrell  decaf  a deep convolutional activation feature for generic
visual recognition  arxiv preprint arxiv                 
    a  dosovitskiy  j  t  springenberg  and t  brox  learning to
generate chairs with convolutional neural networks  arxiv preprint
arxiv                 
    m  everingham  l  van gool  c  k  i  williams  j  winn 
and a  zisserman 
the pascal visual object classes
challenge       voc      results 
http   www pascalnetwork org challenges voc voc     workshop index html 
    r  girshick  j  donahue  t  darrell  and j  malik  rich feature
hierarchies for accurate object detection and semantic segmentation 
in arxiv                
    r  girshick  j  donahue  t  darrell  and j  malik  rich feature
hierarchies for accurate object detection and semantic segmentation 
in computer vision and pattern recognition  cvpr        ieee
conference on  pages         ieee       
     c  w  hsu and c  j  lin  a comparison of methods for multiclass
support vector machines  neural networks  ieee transactions on 
                   
     a  krizhevsky  i  sutskever  and g  e  hinton  imagenet classification
with deep convolutional neural networks  in advances in neural
information processing systems  pages                
     j  mairal  f  bach  j  ponce  and g  sapiro  online dictionary learning
for sparse coding  in international conference on machine learning 
pages         ieee       
     d  parikh and c  l  zitnick  the role of features  algorithms and data
in visual recognition  in computer vision and pattern recognition 
      pages             ieee 
     a  s  razavian  h  azizpour  j  sullivan  and s  carlsson  cnn features
off the shelf  an astounding baseline for recognition  in computer
vision and pattern recognition workshops  cvprw        ieee
conference on  pages         ieee       
     p  sermanet  d  eigen  x  zhang  m  mathieu  r  fergus  and
y  lecun  overfeat  integrated recognition  localization and detection
using convolutional networks  arxiv preprint arxiv                 
     c  vondrick  a  khosla  t  malisiewicz  and a  torralba  hoggles 

    
    
    
    
    

visualizing object detection features  in international conference on
computer vision  pages           ieee 
p  weinzaepfel  h  jegou  and p  perez  reconstructing an image from
its local descriptors  in computer vision and pattern recognition 
      pages           ieee 
d  m  zeiler and r  fergus  visualizing and understanding convolutional networks  in computer vision and pattern recognition       
m  zeiler and r  fergus  visualizing and understanding convolutional
networks  in arxiv                 
m  d  zeiler and r  fergus  visualizing and understanding convolutional networks  in computer visioneccv       pages        
springer       
l  zhang  h  dibeklioglu  and l  van der maaten  speeding up
tracking by ignoring features  in computer vision and pattern
recognition  cvpr        ieee conference on       june      
pages             ieee       

fi