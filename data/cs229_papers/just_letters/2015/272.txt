identifying the higgs boson
guy amdur    anton apostolatos    leonard bronner 
 gamdur  antonaf  lbronner  stanford edu

  introduction
this paper discusses the identification of the higgs boson
subatomic particle from jet pull energy colorflow images
of the particles decay  as modeled by the atlas experiment at the large hadron collider in cern     
the higgs field is an hypothesized energy field thought
to permeate the entire universe  without it  the standard
model of particle physics would break down  as atomic
particles would not have the required mass to attract each
other  leading them to simply float around in the universe
at the speed of light       its proof would completely
alter our understanding of mass as a physical property 
making the discovery of the higgs field the fundamental
unanswered question in particle physics in the last halfcentury      
the standard model suggests that if the higgs field
were to exist  then its quantum excitation  a particle referred to as the higgs boson  would also have to exist
     
the large hadron collider  lhc   tasked with finding this particle  consisting of multiple super powered
electromagnets  collides charged particles traveling at
near lightspeed  these collisions deform space upon impact  breaking the charged particles into subatomic constituents  it has been hypothesized that with a proton collision at high enough energy  the higgs boson would decay in observable ways 
the atlas detector at the lhc records    million
proton collisions a second  making human curation of
these events unfeasible       an accurate classification
system that would label the most promising observations
as higgs boson particle decays is  therefore  required 
in collaboration with slac and the atlas experiment at cern we were given access to energy images
for both higgs boson and gluon decay  referred to as signal and background respectively  seen in figures   and
  
the purpose of this project was to build a binary classifier which  given the colorflow energy image of the decay of an unknown particle  would accurately distinguish
whether or not that particle was a higgs boson 
while we tested a wide array of supervised learning models  we focused primarily on ensemble methods  in particular we developed and fine tuned an adaptive boosting classifier  adaboost  with a random forest
classifier as its base estimator          we also utilized a
number of image feature extraction mechanisms includ 

 a  signal image

 b  background image

figure           pixel colorflow energy images

 a  signal image

 b  background image

figure             pixel colorflow energy images
ing the laplacian operator for edge detection and features from accelerated segment test  fast  for corner
detection          

  related work
current approaches to this problem involve the use of jet
pull features  which is a class of features used to characterize the superstructure of a particle decay event      jet
pull information provides insight as to whether an event
was initiated by a quark or a gluon  or if it came from a
single objects decay  as would be the case for a higgs
boson particle decay  by describing the angle between energy decay patterns           the current state of the art
model leverages this feature set  while using fisher discriminant analysis  fda  for classification 
the approach extracts discriminating information between different classes of jets  similar to techniques used
in computer vision       the algorithm uses a representation of jets as images  applies preprocessing techniques to
construct a consistent set of jet images  and applies a linear discriminant  which has been trained on a collection
of example jets     
fda identifies the plane in the high dimensional
feature space which maximizes the separation between
the jet classes and simultaneously minimizes the scatter
within each jet class  since fda uses knowledge of the
within class variations  it is not significantly influenced
by variations present in both classes     
this method achieved an auroc of       for the
higgs boson classification          we will be comparing

  stanford

computer science department
statistics department
  special thanks to ariel schwartzman at slac  benjamin nachman
and michael kagan at cern for their guidance  advice and access to
data 
  stanford

 

fiour results with the results achieved by this model 

  dataset and features
we were given access to energy images for both higgs boson and gluon decay  the two dimensions of these images
corresponded to the spherical coordinates called  and  
where  is the azimuthal angle in the x y plane perpendicular to the beam direction and  is the angle in x z  these
were preprocessed to center the jet  with resonance being
kept constant in every sampled data point  as is evident
in figure   there is a stark difference between signal and
background colorflow images  so automatic classification
seems feasible 
we had two datasets of images of different sizes 
       images composed of     floats         images  and        images of        floats           images   while these larger images provide higher resolution  the nature of the electromagnetic mechanism of jet
pull energy observation leads these to less accurately detect charged particles  thus  there is an inherent balance
between higher granularity and lower quality of information 
our baseline consisted of vectorizing these images in
r    and r       vector space  respectively  and feeding
those to our classifier  while for more advanced features
we experimented with different image processing tools 
for low level image processing  one dimensional edge
detection and multidimensional corner detection have
been proven to be very successful image processing techniques       thus  the first featureset we developed used
a laplacian of the image  we were expecting to see an
increase in accuracy as the laplacian provides us with
the edges of the color flow images  filtering any irrelevant
noise      corners  on the other hand  can be found at
the regions which have maximum variation when moved
in all regions around it  we settled on the features from
accelerated segment test  fast   a modern corner detection method     
we also tested image histograms as features  the motivation behind this is that higgs boson decay energy distributions  while probabilistic  fall under a specific intensity
range  which is what image histograms discretely quantify  we also utilized the image histograms as a way to
gain intuition about the tonal distribution of our images 
these methods are explained with greater detail in the
following sections 

figure    visualization of fast algorithm    

figure    fast keypoints of a signal event

where the second derivative of a pixel array is equal to
zero are indicators of areas where there is an edge  in order to minimize noise  we applied gausssian smoothing
before computing the laplacian of the image     
      fast
the fast algorithm for corner detection works by analyzing pixels and their surroundings  given a pixel p with
intensity ip and a defined threshold value t  the pixel p is
considered a corner if in the circle of    pixels pn around
it are darker or lighter than it  as is displayed in figure
   more specifically  a pixel p is considered a corner if
 pn  ipn  ip   t  or  pn  ipn  ip  t  are found to
be true 
the fast detector outputs multiple keypoints for each
colorflow energy image  with information that includes
the coordinates and angle of each keypoint  the diameter
of the keypoint neighborhood  the response by which the
most strong keypoints were selected  and the octave from
which the keypoints were extracted       we used these
keypoints as the features of our dataset of images  figure   displays these keypoints for a sample higgs boson
particle decay event 
      image histograms
an image histogram is a graphical representation of the
distribution of tones in any given digital image  in our
case  it is an array with pixel values  ranging from   to
     in x axis and corresponding number of pixels in the
image on y axis  the typical histogram for our data con  methods
tained a bin with a very high number of pixels of inten    image feature extraction
sities    as it is the background intensity for the images 
      laplacian operator
the number of non zero bins was usually around     with
the laplacian operator is a robust method used primarily very low intensities as well 
for edge detection  the laplacian operator is given by     classification algorithms
the relation
we used a variety of classification algorithms dicussed in
 f
 f
lecture  however  most of our work was with ensemble
l f    
   
x 
y
algorithms 
where each partial is taken with respect to each axis       adaptive boosting
      in images  edges are typically areas with high varia  adaptive boosting  adaboost  is a meta algorithm that
tion of intensity between neighboring pixels  thus  areas combines multiple weak classifiers into a more accurate
 

filaplace
fast
histogram
classifier  adaboost runs these weak classifiers multiple
auroc
     
     
     
times  adapting each time so that subsequent classifiers
are used to favor misclassified labels made by previous
classifiers      algorithm   presents the algorithm with table    auroc scores for image processing using admore detail and rigor  for our particular case  this weak aboost classifier
classifier l was a random forest classifier and the number of iterations t was    

    training and testing methods

since we had large datasets at our disposal we used holdout cross validation  namely  we split our dataset into
two sets  a training set which composed of     of the
data  and a testing set which comprised of the remaining
    of the data  we would train each model on the training set and would then evaluate the hypothesis returned
from that model on the test set  classifiers will be evaluated by their receiver operating characteristics  or roc
curves  we will also be quantifying the performance of
all binary classifiers tested by calculating the area under
the roc curve  or auroc  we use this method because
the auroc represents the probability that a signal example will be classified correctly  which is exactly what we
wish to optimize towards 

algorithm   adaboost algorithm         
  

initialize the distribution as
d   i      m  i              m

  
  
  

for t     to t do
get weak hypothesis ht   h         from training weak learner l using distribution dt
compute the error rate
t  

n


dt   i   ht  xi     yi  

i  

  

compute the weight t as
 
 
 
   t
t   ln
 
t

  experiments and results
    image processing

while testing with both datasets  the results presented are
those run on the finer granularity data in r         this
 
is because the colorflow images in the lower granulardt  i   
dt   i  exp t   yi   ht  xi   
zt
ity dataset had too low of a resolution for many of these
methods to provide any meaningful outputs 
where
we ran an adaboost classifier for each of the imn
age processing feature extraction methods detailed pre
zt  
dt   i  exp t   yi   ht  xi   
viously  results for these are presented in table    as is
i  
evident  all image descriptors tested fall short of current
state of the art methods  we hypothesize that the reason
   end for
why these image descriptors performed so poorly was that
   construct and return the final classifier
the images that we are working with are not typical phot
tographic images  very few pixels of these images have

h x    sign 
t ht  x  
non zero value  thus  descriptors such as the laplace
t  
operator provide very limited information about the image since there are many sparse energy jets captured in
the colorflow images themselves  the image histogram 
while outperforming the other two extraction methods 
      random forest
was not a particularly meaningful feature since  unlike a
the random forest algorithm is a general ensemble typical image with a very rich corresponding histogram 
learning classification method  relying on decision tree our images were so sparse that the histograms themselves
models       the random forest classifier works by con  were heavily skewed to   
structing multiple classification trees  where leaves repre      vectorized image classification
sent either    or   labels and branches represent conjunctions of features  the classifier builds b trees during       classifier selection
training  when an unseen sample requires classification  our first task was to find the classification method best
the input vector is passed through every single tree con  suited for the vectorized images as image features  for
structed  where every specific tree tb outputs a prediction this we utilized the smaller granularity images since 
     the classifier returns the label which most trees es  given that the number of features for each sample is a
timated  given that an explicit algorithmic description of number of orders of magnitudes smaller than the higher
the method requires multiple pages of pseudo code  we resolution images  classifiers ran much faster  allowing us
decided against presenting it in this paper  we invite in  to perform more tests 
figure   presents the roc curves for our tests using
terested readers who wish to get a thorough description of
multiple classifiers  namely  linear discriminant analthe classification method to refer to     
  

update the distribution  for i              m as

 

fifigure    roc curves for various classification methods figure    roc curves for adaboost classifier with
for        samples of lower resolution images
random forest estimators for lower resolution images
        samples  and higher resolution images        
ysis  lda   quadratic discriminant analysis  qda   samples  and fda classifier with pull data
k nearest neighbors  k neighbors   gaussian naive
bayes  random forest  extra trees  logistic regression
and adaboost with random forest classifiers as its base
estimators      evidently  ensemble learning methods
such as extra trees and adaboost and classification tree
methods such as random forest outperformed other predictive models  with an auroc of        the adaboost
classifier not only surpassed all other classifiers tested 
but was also a far better model that current state of the art
classifiers running fda on jet pull data 
given the exceptional results achieved with vectorized
images in comparison to those attained through various
image descriptors and image processing techniques  we
decided to keep exploring vectorized images as our featureset 
figure    auroc scores for top features
      granularity analysis
the next step in our experimentation was to compare
image granularity and its effect on classification performance  figure   displays the roc curves for an adaboost classifier with random forest estimators  presenting the curve for fda using jet pull data for comparison
purposes  its interesting that the lower resolution images
outperformed the finer granularity images  this indicates
that the higher resolution did not offset the loss of information that came as a result of larger images  given its
poorer performance and much greater training computation time  we proceeded to keep exploring methods using
only the coarse dataset 
      feature selection
the adaboost classifier  we found  was completely overfitting to the training data  to the extent that it was perfectly classifying all training examples  thus  we set out
to select only the most important features  allowing us to
enhance our classifiers generalization  the importance
of a figure can be calculated given the depth of the feature in a classification tree  features found at the top of a
decision tree have a much higher contribution to the final
result than features at the bottom  and thus have a larger
effect on the final prediction decision      we would take
the average depth of each feature in each decision tree in
every random forest base estimator and use that calculated estimate as the relative importance of that feature

     figure   demonstrates the relationship between feature size and the predictive quality of our classification
methods  our intuition that the most important features
are in the center of the image are confirmed in figure   
      training size analysis
an evaluation of the dataset size would give us valuable information as to whether more training data was
required  interestingly  adaboost was able to get a very
high auroc score even with a small training size  already for training sizes of around      we achieved an
auroc of       and after      examples the marginal
gain of adding more samples was zero  thus  there is no
need for more training samples  our intuition here is that
since our images are generated from the same event and

 a  ten features

 b  forty features

figure    most important features
 

fi  conclusion
we set out to construct a binary classifier for the identification of higgs boson decay events from colorflow jet
images as modeled by the atlas experiment  we were
able to construct a classifier which was able to achieve an
auroc of        this is substantially better than state
of the art systems utilizing jet pull information  the work
detailed in this paper provides a glimpse of the incredible
potential that decision tree and ensemble methods have
for this classification problem  it is interesting that our
experiments related to computer vision were not able to
achieve higher results  but that it was simply vectorizing
the colorflow images as is that generated the best auroc  as described above  there are a few reasons for our
results  on the one hand it is because our training and
testing images were very similar  which made classification inherently easier  second  there is clear distinction
between the higgs and non higgs energy decay rate and
these differences can be characterized by few features  to
see this  simply observe figures   and figures   to see
that she shape of the higgs boson energry and the shape
of the most important features are very similar  nonetheless  it is important to stress that this is paper may represent a breakthrough in the higgs boson identification
process as we were able to vastly increase the probability
of correctly identifying the presence of such a particle  at
the same time  there is still a lot of work that lies ahead 

figure    varying number of features for split at nodes

  future work
figure     varying classification tree maximum depths

first  the most important next step is to test our findings
on new data that comes from different events  while the
fda baseline and our results use the same data  it is still
unclear whether our findings are useful when it comes to
distinguishing higgs boson decay from in different contexts 
furthermore  it may be interesting see what happens
when more data or different data from the same events
are added  the coloflow images we used are all preprocessed  and while this is not a computationally heavy process  it would be interesting to see whether our algorithms
are able to detect rotations and translation  in addition 
adding more features apart from simply the energy pattern may be interesting and we can imagine that this may
lead to even higher accuracy in identification 
finally  there are more sophisticated algorithms that we
would wish to test  the first thing that comes to mind is
a convolutional neural network  these have been seen
to lead to improved image recognition algorithms      
however  there are a number of issues here that arise due
to the high pixelation in the images 
we very much look forward to running these experiments in the upcoming months and hope to publish our
results as soon as possible 

there are only few important features  training and testing
examples are very similar  thus few training examples is
enough to learn 

      base estimator hyperparameter optimization
while random forest classifiers have multiple parameters associated to them that can be adjusted to maximize performance  the adjustable parameter which random forest classifiers is most sensitive to is the number of
variables selected at each node used to calculate the split
     increasing it amplifies the correlation between any
two trees in the forest  but also increases the strength of
every individual tree      thus  there is an optimal value
that balances both effects  figure   shows us that the optimal value for this parameter is      we ran these tests
on a third  development set  to make sure that our final
numbers still reflected a generalized error 
we also tested various maximum depth constraints for
the decision trees in the random forest classifiers  when
no maximum is provided  then the nodes are expanded
until all leaves are pure      as is evident in figure    
while after a depth of   the parameter began to have only
a small effect on classification power  larger depths increase power of classification  the most optimal maximum depth found was    

references
    g  aad  e  abat  j  abdallah  a  abdelalim 
a  abdesselam  o  abdinov  b  abi  m  abolins 
h  abramowicz  e  acerbi  et al  the atlas exper 

fiiment at the cern large hadron collider  journal of
instrumentation        s            

     r  e  schapire  explaining adaboost  in empirical
inference  pages       springer       

    s  bernard  l  heutte  and s  adam  influence of hy       b  scholkopft and k  r  mullert  fisher discriminant analysis with kernels  neural networks for sigperparameters on random forest accuracy  in mulnal processing ix            
tiple classifier systems  pages         springer 
     
     j  shelton  tasi lectures on jet substructure  arxiv
preprint arxiv                 
    g  bradski  dr  dobbs journal of software tools 
    l  breiman and a  cutler 
random forests       s  m  smith and j  m  brady  susana new approach
to low level image processing  international journal
classification description  department of statistics 
of computer vision                   
berkeley       
    l  buitinck  g  louppe  m  blondel  f  pedregosa       m  sstrassler  the known particles   if the higgs
field were zero  october      
a  mueller  o  grisel  v  niculae  p  prettenhofer  a  gramfort  j  grobler  et al  api de       l  j  van vliet  i  t  young  and g  l  beckers  a
sign for machine learning software  experiences
nonlinear laplace operator as edge detector in noisy
from the scikit learn project 
arxiv preprint
images  computer vision  graphics  and image
arxiv                 
processing                     
    j  cogan  m  kagan  e  strauss  and a  schwarzt       d  g  viswanathan  features from accelerated segman  jet images  computer vision inspired techment test  fast        
niques for jet tagging  journal of high energy
physics                    
    m  denil  d  matheson  and n  de freitas  consistency of online random forests  arxiv preprint
arxiv                 
    y  freund  r  e  schapire  et al  experiments with a
new boosting algorithm  in icml  volume     pages
             
    j  gallicchio and m  d  schwartz  seeing in
color  jet superstructure  physical review letters 
                    
     t  k  ho  the random subspace method for
constructing decision forests  pattern analysis
and machine intelligence  ieee transactions on 
                   
     a  hook  m  jankowiak  and j  g  wacker  jet dipolarity  top tagging with color flow  journal of high
energy physics                    
     a  krizhevsky  i  sutskever  and g  e  hinton  imagenet classification with deep convolutional neural
networks  in advances in neural information processing systems  pages                
     j  lucio et al  proceedings of the ii mexican school
of particles and fields  technical report  teaneck 
nj  world scientific pub  co        
     l  mackey and a  schwartzman  physics event reconstruction at the large hadron collider  stanford
data science workshop       
     j  matas and j  sochman  adaboost  center for
machine perception  czech technical university 
prague       
 

fi