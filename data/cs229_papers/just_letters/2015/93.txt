predicting movie revenue from pre release data
benjamin flora  thomas lampo  and lili yang
december         

 

introduction

the film industry is predicted to generate      billion dollars in box office revenue for       with continued
growth to nearly    billion dollars by         film production exhibits a great deal of financial risk in an
age where blockbuster movies can have budgets in excess of of hundreds of millions of dollars  this risk
could be reduced to an extent with the use of quantitative modeling  since movie scripts and projects
are pitched and budgets are set and spent well before any revenue is ever made  we plan to construct a
predictive model using features that are generally known before the movie release date 

 

prior work

several cs     groups previously generated predictive models for movie revenue using tens to hundreds
of features  prior models include linear and logistic regression  support vector machines  naive bayes 
and k means clustering  see apte  forsell    sidhwa       ericson   grodman       gross  merwe   
eimon       yoo  kanter    cummings       xue   chen       im   nguyen        classification
models using revenue bins generally perform in the range of     assignment error or above when
bins are log spaced  while pure linear regression models  even when weighted  generally perform more
poorly  in the scientific literature  similar studies have been performed to find features that correlate
with revenue  older studies identified features such as actor and director pay     while newer studies
discovered that activity on social media such as twitter and wikipedia correlate well with revenue   

 

data acquisition

imdb is the largest store of movie data on the web but they do not document their api so we decided
to use omdb com which has movie data from imdb and box office revenue from rottentomatoes com 
the omdb api requires a movie title in the search so we obtained a list of movies from imdb  which
publishes flat files that include all movie titles  http   www imdb com interfaces  
using this list and the omdb api  we were able to curate data to develop our training  development 
and test sets  looking at movies released between      and      we were able to pull      movies that
also had box office revenue numbers  see fig    for revenue histogram   once we pulled the relevant data
to create the features discussed below we split the data randomly into   sets   strain   sdev   and stest  
where sdev and stest each contain approximately     of the data and strain the remainder  specifically 
strain contains      movies  sdev contains     movies  and stest contains     movies 

 

features

since our goal is to build a model that can predict the profitability of a movie during development  we
are only interested in data and features that would be available or could be projected before release 
specifically  our models are built around the following sets of features 
genre  mpaa ratings  movie length  it stands to reason that different types of movies have
different degrees of commercial success  after all  who doesnt like a nice romantic comedy  we model the
movie
genre
as
a
set
of
binary
features 
one
for
each
genre 
  http   www pwc com gx en global entertainment media outlook assets      filmed entertainment key insights  global box office pdf
  simonoff   sparrow  chance                 
  mestyan  yasseri    kertesz  plos one    e            

 

fi 
   

  of movies

  of movies

a particular movie can be classified into one or more genres
    
as well as length  in minutes  and its mpaa  motion picture
    
    
    
association of america  rating  we look at rating both as
    
a multinomial feature that scales from   for g to   for
    
    
nc    and as a set of binomial features  one for each of
   
   
g  pg  pg     and r   we omit the binary feature
 
 
   
   
   
   
revenue  millions of   
   
for nc    because there are not enough movies rated as
such to make the distinction viable  
   
release date  important information can also be de   
rived from the release date of the movie  we split the release
 
date of a movie into the year and the month  intuitively 
 
 
 
 
 
 
 
 
log revenue      
the year feature could allow our model to account for long
term trends such as inflation or trends in movie going rates  figure    label data  movie revenue  exhibits
conversely  incorporating months as a set of binary features a narrow distribution that is better spread and
could give us insight into seasonality  for instance  wed ex  scaled logarithmically  main plot is a histogram
the log  base     of revenue  while the inset
pect better performance from movies released around christ  on
histogram uses just revenue 
mas or in the first month of summer 
actors  directors  and writers  films with big name
actors  directors  and or writers will often heavily publicize this fact  so it seems intuitive that the star
quality of the participants could provide an indication of the success of the movie  however  star quality
is itself a nebulous quality that can be difficult to model  so in our baseline model we use as a rough
proxy the average number of movies made by the actors  directors  and writers  it seems reasonable that
the more famous an actor is  the more movies he or she will have made 
locality  where a movie is made can also be important to the success of movie  it is a well known
trend that the most profitable movies tend to be us movies out of hollywood  we attempt to use two
different features to model the locality of a movie  the first is whether or not the movie was made in
the us  and the second is the number of languages that it has been translated into 
natural language processing features  each movie comes with a brief  textual description of
the plot of the movie  similar to what a prospective theatergoer might see  we use natural language
processing  nlp  to extract two types of features from this text  structural and tonal  this first type of
features include the length of the summary  the number of sentences  the average length of a sentence 
and the average tf idf score of the words in the summary  for the second type of features  we ran the plot
summaries through the online sentiment analysis tool at http   text processing com demo sentiment  
for each movie  we distilled a positive score and a negative score  describing respectively how strongly
positive and negative the tone of the summary was 

methods and model analysis results
linear regression

we first seek to predict the movie revenue using a continuous variable strategy  we use linear regression
for its simplicity of implementation and guaranteed convergence  several of the previous class projects
examining movie revenue performed linear regression on their feature set and generally concluded that
linear regression poorly fit the data  in light of this  we chose to also perform a linear regression on the
logarithm  base     of the revenues  in addition to being incredibly simple to implement in matlab  this
method distributes the data more uniformly and reduces the effect of larger revenue values from biasing
the fit parameters  figure    
we use two metrics to compare our results  the pearson correlation coefficient and the success rate
 define as a prediction being one order of magnitude of the actual revenue   the log linear regression
generally performs better than the linear regression  and we find that normalizing our non binary features
by their maximum value results in a minor improvement in the metrics for the test and development
sets  table     normalization prevents features with very large values from biasing the prediction 
the training set metrics exhibit the same values with or without normalization  as would be expected 
removing one effective feature at a time  we find that removal of the mpaa ratings from the feature set
resulted in the largest decrease in our performance metrics  with reduction in the pearson correlation
of      and the success rate of      for the development data  table     we show a scatter plot
and a cumulative probability distribution for the best performing model  the log linear regression with
normalized features  and find that the outliers are generally movies significantly under performed their
 

ficorrelation  train 
correlation  dev 
correlation  test 
success rate  train 
success rate  dev 
success rate  test 

log lr
 norm ft  
    
    
    
     
     
     

lr
 norm ft  
    
    
    
     
     
     

log lr
    
    
    
     
     
     

log lr  norm ft  
no mpaa 
    
    
    
     
     
     

lr
    
    
    
     
     
     

table    pearsons correlation coefficient and success rate for the training  development  and test sets  lr is linear
regression  log lr indicates a linear regression fit to the logarithm of movie revenue  norm ft  indicates that the nonbinary features are normalized by their maximum value  and no mpaa indicates removal of the mpaa rating binary
features 

logeactuallrevenue es cc

 

b

testldata
logllinearlregression
successlboundaries

cumulativelprobability

a   
 
 
 
 
 

 

   

   

trainldata
devldata
testldata
successlboundary

   

   

 
 
 

 

 

 

logepredictedlrevenue es cc

 
 

  

 

 

 

absolutelloglerror

 

 

figure     a  actual test set revenue vs  revenue predicted from the log linear regression model for the test set with nonbinary features normalized to their maximum value  data points are red xs  the black line shows the log linear regression
prediction  and the black dashed line designates our success rate metric  one order of magnitude from the prediction line  
 b  cumulative probability distribution as a function of the absolute log error for all three data sets  the black dashed
line designates our success rate metric 

predicted revenue value  figure     this is likely partially due to the smaller amount of data for smaller
revenue movies available relative to movies that made     million 

   
     

classification methods
data classification

the data was partitioned into buckets by rounding down the log  base     of the revenue  for the
training set this gave us buckets from   to    or      to      million   this strategy gave a more
uniform distribution than labeling the revenue buckets linearly  figure    
     

naive bayes

although we know some features are related we wanted to use a classification algorithm for multinomial
classification  as stated in class naive bayes is simple but effective for many problems sets  we implemented naive bayes with pysparks mllib   implementation of multinomial naive bayes with laplace
smoothing  it should be noted that removing laplace smoothing had a negligible a effect on model
performance in this case   the priors are calculated as discussed in class 
we used the development set to investigate the effects of removing one class of features at a time  e g  
the genre binary features  in order to identify the most important features  through that analysis we
found that the nlp features and writer features hurt the model most  using leave one feature out after
removing the nlp and writer features showed that there were no significant gains in either classification
or      classification  thus removing any additional features would potentially overfit the development
set  through this same analysis we identified the actor feature as the most important to this model 
we then examined how well the model classified correctly and how often it was within   bucket of being
correct  the naive bayes model correctly predicted the movie revenue test set buckets       of the
time  and was within   bucket       of the time  table    
  https   spark apache org docs       api python pyspark mllib html

 

fibucket
unbalanced
balanced
number of data points

 
     
     
  

 
     
     
   

 
      
      
   

 
      
      
   

 
      
      
   

 
      
      
    

 
      
      
   

table    overall accuracy on the development set for the unbalanced svm model  where every point is given the same
weight  vs the balanced svm model  where the weight of every training point is inversely proportional to the number of
point in the bucket  

figure    confusion matrix for svm  featuring classification on the development set      total movies   green is classified
correctly  orange is classified within   and red is misclassified 

     

multinomial svm

we implemented a multinomial svm model using the python scikit  library  we used scikit for two
reasons  first mllib did not have a multinomial svm it only had binary and secondly we wanted to
get a feel for multiple python libraries  using backward search on the set of features  we found that
we produced the best results        accuracy on the development set  with a linear kernel and a set
of features that included all features except the release month as a linear value  we also experimented
with training models using a gaussian kernel and a quadratic kernel  but those performed worse in the
general  producing scores on the development set of only       and       even for the best sets of
features  see table   for a summary of of svm results 
if we dig a little more deeply into the results of the svm classifier  we see that not all buckets are
classified equally well  for instance  our model was able to predict the movies in bucket   with      
accuracy  whereas in buckets   and    we see as low as    accuracy on the development set  this is
not so surprising when we examine our underlying training data set       training data points fall into
bucket    the largest in our data set  in contrast  buckets   and   are our two smallest  with only    and
    data points respectively  it is very likely that we simply did not have enough data in those buckets
to make accurate predictions  another part of the problem is that with an unbalanced data set  the
classifier tends to favor the class with the largest membership  as an experiment  we retrained our best
svm model   this time with each data point in the training set weighed inversely proportional to the
size of its bucket  the overall performance of this model        which is significantly worse than our
original model  however  performance is much more consistent across the different buckets  including
buckets with smaller membership  see table    
     

multinomial logistic regression

an alternative simple way to examine data is through multinomial logistic regression  we implemented
this using pyspark mllib  using the development set and the leave one out removal of features we
determined that subtracting features did not affect the model performance  the only parameter that
changed the model was the regularization parameter  fitting for the development set this parameter
was set to         the results of multinomial logistic regression are similar to our other classification
methods as can be seen in table   

 

conclusions and future work

counter to initial expectations  the performance of the more complex svm model was not better than
that of simpler models such as naive bayes and logistic regression  table     on the contrary  svm
with linear kernels did a little worse on the test set         in comparison to naive bayes         and
  http   scikit learn org stable modules svm html

 

fitable    the performance of different classification models  naive bayes  svm  multinomial logistic regression  are compared for the test and development sets

logistic regression          svm with higher order kernels did worse still  however  this result becomes
less surprising when we consider the size of data set  splitting this data into seven buckets leaves the
majority of those buckets with fewer than     data points  simpler classification methods that rely on
more assumptions about the data  such as naive bayes  tend to shine when the data set is very small 
it is possible that we could achieve significant improvements in the svm model if the movie data set
were larger  in our current analysis  we found that all three models classified a movie to the same bucket
    of the time  and within one bucket of one another     of the time  again we attribute this small
variance in model performance  which we expected to be larger  to the data set size 
the sparsity of data in certain buckets is a weakness in all of our models  this is evident by the
fact that our accuracy on a per bucket level range from    in the smallest buckets to nearly     in our
largest bucket  table   for svm   this discrepancy holds across all of the classification models 
the movie that was misclassified the highest by all   of our algorithms and under performed with
the largest log linear regression error was meeting evil  imdb says this film by magnolia pictures
made      at the box office and stars samuel jackson and luke owen  since our actor feature score
is simply the number of movies they star in  it is understandable that our models predict this movie
to have a high box office revenue  in general  under performing movies had very high director or actor
feature numbers  and were essentially box office flops  it also worth noting that magnolia pictures is
not a major film studio and generally produces smaller budget movies that produce less revenue 
the movie that was misclassified the lowest by all   of our classification models and over performed
with the largest log linear regression error was space station  d  this was an unrated    minute
imax documentary film about life on the international space station with narration by tom cruise 
our training set had few other imax films and documentaries usually generate little revenue  also  this
movie was unrated  so it didnt have an mpaa rating feature score  which was the strongest contributing
feature for linear regression  removing mpaa rating features from the linear regression models greatly
decreases this movies outlier status   the short run time also contributed by lowering the prediction
score in a manner not consistent with the assumed linear trend for regular films that are generally    
to   hours long  this movie was also classified much lower than its actual performance despite having
tom cruise counted for the actor feature  interestingly  the director toni meyers has only directed three
films  but all her projects make tens of millions of dollars despite being documentaries 
some of our outliers could likely be better accounted for by strategically adding features for trends
currently unaccounted for  we generally want to avoid unnecessarily adding more features when weve
already determined the data set is relatively small for our modeling methods   most of our misclassified and highest error movies under performed their prediction  and generally were labeled on rotten
tomatoes as limited release  adding a limited release feature would likely help better classify and
predict revenue for these movies  which generally made less than a million dollars  we could also add
another binary feature for whether or not the studio backing the film is a major studio  which could
better account for films made by smaller studios like magnolia pictures  another strategy may be to try
different actor and director features  such as net worth or number of online search results  
in our project we showed that movie revenue forecasting is amenable to predictive modeling by
supervised learning methods  by obtaining data for all movies with available online data from      to
      we generated the largest modern data set we could to perform both continuous fitting and multiplelabel classification methods  in general  we obtained a similar level of predictive power for all our models
using our performance metrics  likely due this data set still being relatively too small  we consider our
models to be a very coarse estimate of revenue prediction  but we are ultimately skeptical that even a
very sophisticated feature development and selection would result in significant improvements  there are
many factors that influence movie revenue that are difficult to quantitatively measure and even harder to
predict  instead  these sorts of models would probably work best complementing a humans analysis and
intuition  preventing unconscious  or conscious  biases leading to a poor investment of studio resources 

 

fi