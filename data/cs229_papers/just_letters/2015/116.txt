sales prediction with time series modeling
gautam shine  sanjib basak
i  introduction
predicting sales related time series quantities like number of transactions  page views  and revenues is
important for retail companies  our work focuses on the revenue data for a us based online retail
company  digital river  inc   that is responsible for the ecommerce platform of its clients  as online sales
are increasing at a massive rate  accurate prediction of sales allows the company to properly prepare for
handling the shocks to product stock  website traffic  and customer support 
during the   biggest days  thanksgiving  black friday and cyber monday  the company earns about
    of the revenue of the whole year  so it is considered a leading indicator of overall sales  predicting
revenue on special days such as this is especially challenging  as those are usually large spikes  i e 
anomalies  compared to normal days  for example  gross sales on black friday are usually more than   
times of the median sales of the year  our data was limited to only     years of black friday  cyber
monday  and holiday season sales data so building a robust model is difficult because these special
incidents have only a few data points 

ii  data and prior work
time series forecasting grew out of econometrics and involves parameter fitting using data to predict
future values of some quantity  the input data consists of pairs  rt  t  of some quantity r at time t  unlike
the i i d  observations prevalent in most of machine learning  time series data points are emphatically not
independent  and in fact we rely on their autocorrelation structure to forecast the future 
traditional forecasting tools are based on autoregression  ar  and moving averages  ma   which are
described below  in addition to these  we will use feed forward artificial neural networks with time series
inputs to see how they perform  in principle  neural nets have greater freedom to handle nonlinearities 
but they are also non convex black boxes while ar and ma have the advantage of being interpretable
and parsimonious because they are specific
to time series  neural nets were popular for
time series forecasting in the     s  but
interest died down due to mixed results
relative to ar and ma models         they
have been used specifically for sales
forecasting with some success        
the data we will use for forecasting has
been taken for one large client of digital
river from april      until the present  for
this data set itself  prior predictions by the
company have been carried out by moving
averages  which have low accuracy  nave
seasonal methods have also been used 
which gives decent accuracy but no
dynamism since its merely repeating the
prior years observations  we will attempt to
use learning and prediction to forecast this
series  with particular attention to the distinctive
spikes in sales on holidays 

fig    time series sales data used in this work 

fiiii  methods and features
autoregressive integrated moving average  arima 
the baseline time series modeling methods are     
   autoregression  ar   the output at time t is a linear combination of past outputs
 

          

       
   

   moving average  ma   the output at time t is a linear combination of past shocks  noise terms 
 

          

       
   

ar and ma can be combined  they can also be applied to the differenced series  i e  an approximation to
the derivative  of the desired order and integrated to retrieve the original series  putting these three
features together yields the more general autoregressive integrated moving average  arima  model 
 

          

 

         
   

       
   

the order  p d q  of the arima model specifies the number of autoregression lags  order of differencing 
number of moving average lags  respectively  our model chose these parameters based on the akaike
information criterion  aic   which trades off the likelihood of the model against the number of parameters 
it is therefore a regularized maximum likelihood estimate and theoretically minimizes   step mse 
because we have multiple seasonality components and discrete spikes in the data to deal with  we have
used arima with additional regressors  one set of regressors are the first   to    largest fourier
components for weekly and yearly seasonality  the other set are indicator vectors that are   throughout
the year except for  s on certain special days like thanksgiving  black friday  and christmas  the latter
is necessary  rather than simply using the input         because some of these days change dates every
year  i e  always on a friday  and because of leap years 
seasonal and trend decomposition using loess  stl 
stl decomposition is a useful tool for accounting for seasonal effects  in sales data  it is common to have
repeating patterns every    hours  or every   days  or every     days due to work sleep cycles and
holidays  it is beneficial to remove these consistent fluctuations so that the model parameters have
greater freedom to fit any underlying trends  i e  broad changes  and then add the periodic pattern back in
as a post processing step  both our arima and neural net models made use of stl decomposition 
feed forward neural networks  ffnn 
a feed forward neural network weights its inputs and feeds them into hidden layers that apply some
th
function to these internal inputs  the input yj into the j hidden layer is 
 

       

    
   

after which yj is transformed using a sigmoidal function for categorical or probability outputs or a linear
function for regression outputs  which is applicable to our case  the parameters bj and wij are learned
from the data and used to make future predictions  fig    shows a visualization of one of the actual neural
networks used in this work  with the line thicknesses encoding the trained weight parameter values 

fiin order to predict time series  an autoregression component can be included into neural nets by feeding
in lagged values of the series  without the hidden layer  a neural net with inputs rt rt    rt p is equivalent
to an ar p   i e  autoregression of order p  the inclusion of the hidden layer induces nonlinearity that
could potentially allow the neural net to surpass arima  as with the arima model  we used holiday
indicator vectors as regressors in addition to the lagged time series 

x 
x 
x 
x 
x 
x 
x 
x 
x  
x  
x  
x  
x  
x  
x  
x  
x  
x  
x  
x  
x  
x  
x  

i 
i 
i 
i 
i 
i 
i 
i 
i 
i  
i  
i  
i  
i  
i  
i  
i  
i  
i  
i  
i  
i  
i  

b 

b 

h 
h 
h 
h 
h 
h 
h 
h 
h 
h  
h  

o  x 

fig    feed forward neural network
with    inputs and    hidden layers 

iv  results
neural net        n a
  

predicted 
actual 

  




neural network 
   hidden nodes 

  

sales  million usd 

  
  

 

  

 

 
 

sales  million usd 

arima 
order         

  

predicted 
actual 

  




  

  

arima       

 

   

   
time  days 

   

 

   

   

   

time  days 

fig    sales forecasts using arima  left  and neural nets  right  

our     day sales forecast is shown above for an arima        model and a neural net with   
autoregression lagged inputs    indicator vectors for special days  and    hidden nodes  the arima
model had a higher mean square error  mse  of    to the neural nets     but their failures are similar 

fi  
  
 

 

since the neural net can qualitatively
capture the holiday spike  it would be
interesting to combine linear regression
with holiday indicator variables into the
arima equation to capture the same
effect  fig    shows such a model  where
the optimal order has now changed to
        per the aic criterion and the mse
decreased further to    

  

sales  million usd 

  

  

both severely underpredict holiday sales  particularly the black friday to cyber monday spike  while the
neural net successfully captures its discrete nature  the arima model smoothly goes up then down  as
expected from its equations 
arima       
the notable spike at around day    
highlights the difficulty of this prediction
 predicted 
task  this particular jump in sales was
arima 
 actual 
induced by a hyped up new product
order         
launch and thus could not have been
predicted using any of our input features 
  regression 
a hypothetical feature vector to handle this
would need to be trained on previous
product launches and needs to somehow
encode the event into a representative
number 

 

   

fig    sales forecast using arima with regression 

  

  

  

  

  

   

mse v  hidden nodes

mean square error

the number of hidden nodes was chosen
by test error minimization  but the caveat is
that the actual mse was close in
magnitude to similar models and all of
them are ensemble local optima solutions
so its possible the true global minimum is
not at our chosen value of    

   

time  days 

parameter fitting in neural nets
the neural net optimization problem is
non convex when there are one or more
hidden layers  so the solution lands in a
local optimum almost every time and
differs for different initial parameters  we
used     runs of the neural net initialized
randomly using different seed values and
averaged the predictions 

   

 

  

  

  

  

the order of autoregression was similarly
number of hidden nodes
chosen by minimizing test mse  but we
fig    test mse against hidden node count 
found that beyond   terms made little additional
difference  the same caveat applies  although
the anticipated effect is small since mse values did not differ much 

  

fithe learning curve for our time series data is
shown in fig     the curves are nonmonotonic since different set sizes entail
different forecast intervals and some parts of
the series are more difficult to capture 
nevertheless  we can observe that neural nets
have much higher generalization error for low
training set sizes but become roughly
comparable as the set size increases 




arima 
neural net 

discussion and future work
pure black box time series prediction can only
do well under limited circumstances  such as
highly seasonal data with no long term
changes  the greatest improvement to our
models could come from the use of domain
knowledge to construct highly relevant
regressors that can account for discrete
fig    test mse against training set size 
events  e g  a product release  or long term
changes  e g  company or economy is on the
upswing   we demonstrated this with the use of indicator vectors for special days like thanksgiving but
much more could be done given greater domain knowledge and data 
the issue of whether neural nets can outperform conventional time series models remains open  we
showed that they are comparable  but much greater effort needs to be put into the neural net to achieve
even that  in principle  neural nets would have an advantage if interacting regressors were useful for
prediction because the hidden layers can capture that cross term  another improvement that could be
made to the neural net is to input differenced time series as in arima and integrate after prediction in
order to capture the non stationarity that is typical in sales data  another path to explore is the
decomposition demonstrated in     demonstrated some success in using arima to model the linear
component of the data and neural nets to model the residual nonlinear component

v  references
    z  tang  c  almeida  p a  fishwick  time series forecasting using neural networks vs box jenkins
methodology  simulation  vol            pp          
    r  sharda  r  b  patil  neural networks as forecasting experts  an empirical test  in  proceedings of
the international joint conference on neural networks  washington  d c   vol           pp         
    j  t  luxhj  j  o  riis  b  stensballe  a hybrid econometric neural network modeling approach for
sales forecasting  international journal of production economics  vol                 pp        
    f m  thiesing  o  vornberger  sales forecasting using neural networks  international conference on
neural networks  vol            pp             
    r  j  hyndman  g  athanasopoulos  forecasting  principles and practice  otexts       
    g  zhang  time series forecasting using a hybrid arima and neural network model  neurocomputing 
vol                   

fi