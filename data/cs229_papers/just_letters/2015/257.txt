machine learning techniques for thyroid cancer
diagnosis
cs    final report  fall     

chenjie yang

jingtao xu

tiffany liu

department electrical engineering
stanford university
stanford  ca
yangcj stanford edu

department electrical engineering
stanford university
stanford  ca
jiangtaox stanford edu

department electrical engineering
stanford university
stanford  ca
tiffliu stanford edu

abstract drawing inspiration from alexanders paper  on
classification of thyroid cancer  we are interested in
replicating and possibly improving the predictive results of a
learning model for detecting thyroid cancer from gene
expression data from thyroid nodules  this data set is the same
data used in the paper by alexander   we will develop our
own gene expression classifier by applying different feature
selection methods and supervised learning algorithms to
predict whether thyroid nodules are malignant or benign using
gene expression data  with a l  regularized linear support
vector machine  we achieved a maximum predictive accuracy
of        
keywordsmachine learning techniques  principal component
analysis  logistic regression  support vector machine

i  introduction
tumors found in thyroid cancer are commonly presented
as thyroid nodules  but not all thyroid nodules are cancerous 
about       percent of thyroid nodules can be malignant 
diagnosis of thyroid cancer is typically conducted by fine
needle aspiration  however         of aspirations yield
indeterminate cytologic findings and lead to diagnostic thyroid
surgery  most of the people referred for diagnostic thyroid
surgery prove to have a benign form of the disease after
histopathological review   histopathological review classifies
if a nodule is benign or malignant by examining whole tissues
for abnormalities  whereas cytological review examines tissue
fragments or cells for abnormalities  this kind of surgery 
which is not necessary for those patients  exposes them to risk
of serious surgical complications and causes patients to have
levothyroxine replacement therapy for life   thus 
improvement of diagnostic evaluation for patients with
indeterminate cytologic findings is critically needed 
a  related work
gene expression data is now readily available for many
diseases and has been used extensively to develop classifiers
to help physicians diagnose and treat the disease  alexanders
paper showed the potential for diagnosing thyroid cancer using

gene expression data  the investigators extracted genes that
are highly related to thyroid cancer and built a geneexpression classifier using linear kernel support vector
machine   lsvm   the model has a high sensitivity when
classifying malignant samples  but benign samples are not
classified with high accuracy  we attempt to increase the
predictive accuracy both for malignant and benign samples by
applying feature selection methods  i e  principal component
analysis  pca  and forward search  to machine learning
algorithms  i e  logistic regression  svm  svr and boosting  
the paper is organized as the following  section ii describes
our data set  section iii describes our process in developing a
gene classifier  section iv reviews our results and comments
on future work 
ii  data set
data was collected by study conducted by alexander  the
study collected genetic data from fine needle thyroid nodule
aspirates from thyroid nodules   cm across the united states
over a    month period  more detailed information is stated in
alexanders paper  they collected      samples  of which
    were indeterminate cytologically  of the          were
viable for resection  so the patients underwent thyroid surgery
to determine if their thyroid nodules were malignant or
benign      resection samples were classified by
histopathological review  of the          was considered to
be a valid data set  in addition  the paper also evaluated a
randomly selected subset of    cytologically benign and   
cytologically malignant surgical samples from an independent
group of patients  for our gene expression classifier  we used
the    and    randomly selected independent subsets as our
training data  so we had a training data size of     
while we were training models  we found that there were  
mislabeled samples in our training data  these   samples were
cytologically labeled as malignant  but histopathologically
labeled as the opposite  we choose to remove the data rather
than correct them because we wanted our model to be
cytologically accurate  therefore  we ultimately used a
training set with    samples 

fithen we used     samples classified as cytologically
indeterminate as our testing data  the true diagnosis of the
cytologically indeterminate samples was determined
histopathologically  we split the data in this fashion because
we hypothesize that by training the model with data from
cytologically confirmed results  a more accurate model for
classifying the cytologically indeterminate aspirates can be
built  future work can be done to address samples that have
conflicting cytological and histopathological results  data has
been preprocessed by robust multiarray average  rma 
method  so our data set is just an estimate of the expression
measure for each gene using all the replicated probes for that
gene  the data has     features overall 

curve with respects to varying feature set size to understand
the effect of each feature selection method  we used a linear
support vector machine in the following section to test our
data set 
b  learning curve
   principal component analysis
we varied the size of dimensions compressed by principal
component analysis  pca  to see how the training error and
test error changes  demonstrated in figure   below 

iii  learning algorithm setup
to create our gene expression classifier  we first applied
nave learning models to gain intuition about what is the best
way to handle our data 
a  na
ve baseline models
we first applied pca to conduct our initial phase of preprocessing  pca finds orthonormal basis for data and sorts
dimensions in order of importance  thus getting more
compact description of features and discarding lower
significant  redundant dimensions of features  after applying
pca on the training set  we selected the most important   
components  which accounts for around     of the variance 
out of the original     dimensions of feature  we created
some nave baseline models  the nave baseline models
helped us understand the structure of our data to build a
strategy for classifying  the simplest models we used are
logistic regression and support vector machine  linear kernel  
in developing our intuition  we tried some slightly more
complicated models  support vector regression  adaboost  and
neural networks  for methods which have model parameters 
we used    fold cross validation to choose parameters  we
implemented the machine learning algorithms using
matlab  for svm  we used libsvm   the initial results
are displayed in table   
algorithm

cv
test
accuracy
accuracy
logistic regression
 
      
support vector machine
      
      
support vector regression
      
      
adaboost
      
      
neural networks
      
      
table   cross validation accuracy and test accuracy
results for different learning models
as shown in the table  only support vector regression
improved the testing accuracy to         our test accuracy
seemed to be limited to around      also  note that theres a
large gap between cross validation error and test error  which
indicates over fitting  so for the next step we experimented
with feature selection methods  we examined the learning

figure   test error vs  training error for pca
as training error quickly drops to    testing error increases
slightly as the feature set grows  a sign of over fitting  it is
possible that the preliminary feature selection process is
choosing extraneous features that lead to over fitting  as we
known  pca can efficiently discard redundant dimensions of
features  but it cannot find extraneous features because pca
does not use the knowledge of data labels  next  we
experimented with forward search 
   forward search
instead of using the conventional greedy algorithm of
forward search  we used another version  restricted forward
selection  rfs  algorithm   the rfs algorithm is similar to
the greedy algorithm except that at each step to insert an
additional feature into the subset  conventional greedy
algorithm considers all the remaining features  while rfs only
considers part of them  the set of features it considers
decreases in each step   rfs is shown to be much more
efficient and gets performance very close to the conventional
greedy algorithm  
in each step of forward search  we use leave one out crossvalidation  loocv  error to evaluate feature set and choose
the best feature to be added in  figure   shows the learning
curve using forward search  again we used a linear support
vector machine 
from the figure  we know that the error of training and
testing drops quickly for the first   steps  but after that the

fitraining error drops to    the test error increases slightly as the
feature set grows  this demonstrates that the forward search
method does not reduce over fitting either 

figure   test error vs  training error for forward
search

figure   test error vs  training error for pca with and
without l  regularization

of the two different feature selection techniques we tested 
we found that forward search and pca helped us discard some
extraneous features  however  the test error is still around
     and there was a big gap between testing error and
training error  intuitively  both training error and testing error
should be big but the gap between them should be small when
we have low model complexity  i e  small number of features  
as the model complexity grows  both training error and
testing error should drop rapidly  when the number of features
increases above a certain threshold  the testing error starts
rising because additional features generate no useful
information at all and can cause overfitting  in our learning
curves  the constant big gap between training error and testing
error suggested that overfitting still exists in our model 

d  reweighting
after taking a closer look at the testing results  we found
that while the testing errors of benign sample were relatively
small  our model misclassified a significant percentage of
malignant samples  we would like the testing error of
malignant samples to be as small as possible since the ability
to differentiate malignant samples from others is the main goal
of the classifier  therefore we tried to adjust the decision
boundary of our model by adding a penalty to any
misclassification of malignant samples during training  the
penalty is kept below a threshold because overall test accuracy
would drop significantly if we imposed a large penalty  table
  contains the testing results of our model after a penalty is
added 

c  regularization
it is possible that the high model complexity leads to the
over fitting  to further reduce the complexity of our models 
we applied regularization to our model because it is known to
help prevent overfitting  in our case  we chose to use l 
regularization  we used pca to select features and the feature
set size is     then we applied linear svm and logistic
regression both with l  regularization and without
regularization to our data set  the result is shown in the
following table  the test accuracy slightly increases  but not
by much  the learning curve with and without regularization
 using svm  is shown in figure   
algorithm

test accuracy
test accuracy
without
with l 
regularization regularization
logistic regression
      
      
svm
      
      
table   test accuracy result of l  regularized models

algorithm
total test
malignant
benign
 benign penalty  accuracy
samples
samples
malignant
testing error
testing
penalty 
error
l  logistic
      
      
     s 
regression      
l  logistic
      
      
      
regression      
l  logistic
      
      
      
regression       
l  regularized
      
      
     
linear svm      
l  regularized
      
      
      
linear svm      
l  regularized
      
     
      
linear svm
      
table   test accuracy of l  regularized models with
penalty

fiiv  results
a  summary of reults
we tried several methods to reduce over fitting  but they
didnt work very well  feature selection methods such as pca
and forward search contribute little to the improvement of
over fitting  regularization did help a little bit in reducing
over fitting but it was still far from ideal  we think this may be
because of the small sample size used for training data 
b  future work
for future work  we could try other methods to develop a
learning model for gene classification such as bayesian
networks  bayesian networks have a unique advantage by
incorporating prior distributions into the classification process 
therefore giving us a method to statistically capture the gene
to gene interaction that is not accounted for in our current
models 
v  acknowledgment
we would like to acknowledge olivier geveart for
providing us with the paper and data set to explore this topic 
we would like to thank and acknowledge irene kaplow for
help and guidance throughout this project 

vi  references
alexander  e  k  et al  preoperative diagnosis of benign
thyroid nodules with indeterminate cytology  n  engl  j 
med                     
     thyroid neoplasm   wikipedia  wikimedia foundation 
   apr        web     nov       
    chang  chih chung  and chih jen lin   libsvm   tist
acm transactions on intelligent systems and technology
acm trans  intell  syst  technol                    web 
    deng  kan  omega  on line memory based general
purpose system classifier  pittsburgh  pa   carnegie
mellon u  the robotics institute        print 
   

fi