 

training a minesweeper solver
luis gardea  griffin koontz  ryan silva
cs      autumn     

abstractminesweeper  a puzzle game introduced in the     s 
requires spatial awareness and an ability to work with incomplete
information  utilizing different machine learning and artificial
intelligence approaches  we implemented solvers that make use of
linear and logistic regression  reinforcement learning  as well as
constraint satisfaction problems  we were able to have various levels
of success with different board sizes using different models  finding
that the csp model functions best  with the other models being
limited by the difficulty of enumerating every board configuration
for a given board size 

i  i ntroduction
to start a game of minesweeper  the player is presented with
a rectangular grid of tiles  behind which are hidden a certain
number of randomly distributed mines  the standard board is
  x   with    mines   the player uncovers a tile by clicking it 
if the clicked square is not a mine  it reveals an integer  its value  
which is the number of adjacent uncovered tiles  including those
that only share a corner  that contain a mine  using this limited
information  the players goal is to uncover all of the tiles that
do not have mines  but the player loses the game at any point
if an uncovered square contains a mine  using the techniques
discussed in this class  we aimed to implement programs that
can play minesweeper 
given a particular board state  such a solver must be able to
decide which tile to uncover next  knowing only the information
given by currently uncovered squares  sometimes this information is sufficient to determine with      certainty that a mine
will be in a given location  in other cases  one can only know
the probability distribution of a mines location  thus  a solver
must be able to find guaranteed safe tiles that cannot possibly
contain mines  and when no such tiles exist  it must select the
tile with the lowest probability of containing a mine  notably 
an early algorithm for this problem has already been written 
by enumerating all possible mine configurations that satisfy the
uncovered tiles values  one can determine the probability that
a mine is in any particular tile  however  the time complexity
of this approach quickly makes the algorithm infeasible  determining whether a given mine configuration satisfies the board
constraints was proven to be np complete in           because
the previously mentioned algorithm involves enumerating all
possible solutions to this np complete problem  it belongs to
a more difficult class of problems called  p complete      thus
much of the difficulty in designing a minesweeper solver lies
in approximating the probability that a mine will be underneath
any specific tile  the problem is further complicated by the fact
that the tile with the lowest probability of containing a mine is
not always the optimal move 
ii  l iterature r eview
several approaches have been made to solve games using
machine learning  mnih et  al  implemented a deep reinforcement
learning technique used to learn strategy for playing atari
games      a modified q learning algorithm was enhanced by
function approximation with a convolutional neural network 
which was able to effectively generalize learning of the state
space  as for specific methods applied to solving the game of

minesweeper  several attempts were made in the   s  where
adamatzky constructed a cellular automaton that populated an
n  n board in  n   with each cell having    neighbors and   
states      various other models have been made  ranging from
use of genetic algorithms  graphical models and other learning
strategies      there have been previous implementations to the
csp approach  which is the current state of the art method
        nakov and wei     derive bounds on the complexity
of playing minesweeper optimally  the authors formulate the
minesweeper game as a pomdp and use enumeration to convert
the game to an mdp  while also reducing the state space  they
then use value iteration methods to solve the mdp for a  x 
board  but the method is not scalable 
iii  m ethods  a pproaches
a note is to be made for the general approach with which the
first move is made  although initially  any random square will
have the same probability of being a clear  given mine density
d 
p xij   clear       d
however  in order to win the game  it is helpful to obtain a
zero  as this will clear out a particular square and also all of the
squares adjacent to it  we then have the following probabilities
for different squares of being clear
p xij     ij   corner        d  
p xij     ij   edge        d  
p xij     ij   inside        d  
because of this  if we select a corner square  we know that we
will clear out a larger area of the board  gaining more information
on the board and increasing the probability of winning 
another note to be made is the fact that testing is being done
with the standard real rules  this means that the player cannot
lose on the first move  thus if the first move is actually a mine 
the game is implicitly restarted and not counted as a game so
that the move that the player selected is not a mine 
a  supervised learning
data for our supervised learning approaches is generated in
the following manner  each square can be represented as a
feature with an integer determined by the squares state in the
current board  if a square is uncovered  the corresponding feature
is represented by the number of mines to which the square
is adjacent  if the square is covered  it is represented by a
covered value  and if the square is out of bounds  it is
represented with an out of bounds value  we generate data
by simulating games of minesweeper  and play each game until
it is won by always choosing a correct move  at each state  the
perimeter consists of all squares that are covered  but are adjacent
to uncovered squares  moves are chosen randomly from squares
within the perimeter with some fixed probability  and otherwise
from all uncovered squares  this method models normal game
play where most moves are selected from the perimeter of the
current board  in our work  the machine learning algorithms do
not flag squares indicating a mine is present  they only predict

fi 

whether a square is suitable to be a next move  we play a
version of minesweeper that automatically uncovers neighbors
of squares that are not adjacent to any mines  the general greedy
algorithm for playing minesweeper with a predictor is presented
in algorithm    two approaches using supervised learning to
solve minesweeper are presented 
algorithm   playingminesweeper
   while not game over do
  
use trained model to predict all squares in the perimeter
  
if no reasonable moves in the perimeter then
  
choose random move outside perimeter
  
else
  
probe square with lowest chance of being a mine
  
end if
   end while
   local classification  this method uses the local board
configuration to classify an uncovered square in a minesweeper
game  the classifier uses a feature extractor to obtain input from
the local board space  this feature extractor was chosen because
nearby squares contain the most relevant information about the
uncovered square that is currently being classified  note that
feature vectors in this dataset can potentially be correctly labeled
in both classes  since the same board state can have multiple mine
configurations  this means that the dataset is not separable  and
to solve this non separability  we label squares positively only
when there is certainty that the square does not contain a mine
 i e there are no mines in a given square for all possible mine
configurations  
gathering data in this way tends to skew the data towards the
negative class  the class predicting a mine is present   sixty six
percent of our data is labeled negatively  this has an adverse
effect because predictors trained on this data will favor making
a prediction that a mine is present  and tend to misclassify safe
squares  to counteract this  during training we give the positive
class higher weight so that the classifier makes more accurate
predictions about safe moves 
we train a logistic regression as well as an svm classifier for
predicting uncovered squares      the new optimization problem
for the svm with weights i is
m

min  w   
w

x
   
w w c
i  i
 
i  

subject to
yi  w   xi     b      i  
i    

i              m
i              m

then  our dual becomes
w     

m
x

i 

i  

m
  x
i j yi yj k xi   xj  
  i j  

subject to
m
x

yi i    

i  

   i  ci

i              m

and kkt conditions become
i  yi  w   xi     b       i       
 ci  i  i     

i              m
i              m

   global probability regression  this method uses all
squares as features  and regression is done on the output of a
full minesweeper solver  which calculates exact probabilities for
every square in exponential time  both the training data as well
as labels are high dimensional vectors in this regression problem 
and the label is a real valued vector  the dimensionality of the
dataset cannot be reduced without losing accuracy because of
symmetries in the game and the fact that every square contains
essential information for predicting probabilities 
for this problem  we use a multiple kernel ridge regression
     with cross validation for setting the meta parameters for this
problem  kernelizing the regular form of multiple kernel ridge
can be done as follows 
the closed form of the parameters of the multiple ridge
regression problem is given by
     x   x   in    x    y
where y is a matrix of training labels  using the identity
 b   r  b   p    b   p     p b    bp b     r  
we can reformulate  as
   x    xx     im    y 
to make a prediction with kernelization  we can use
  x   y    xx     im    xx
  y    k   im    k
where
kij   hxi   xj i
and k is a vector of inner products between the data and new x 
k    k x    x           k xm   x   
b  simplified q learning
one approach involved modeling minesweeper as an mdp
and using a modified version of q learning to discover the best
actions for each given board configuration  after learning the
q values  the algorithm would then use the values obtained to
play minesweeper  the standard q learning algorithm takes the
following form 
qopt  s  a        qopt  s  a     r    vopt  s    
this structure allows the algorithm to learn not just about the
direct reward of a particular action  but whether a particular
action is more likely to lead to reward in the long term  while
this is crucial for many games like chess  we are not as concerned
with the endgame result in minesweeper  instead we are more
interested in the immediate reward  whether a particular move
will uncover a mine on a specific board configuration  in order to
approximate this reward  we remove the  vopt  s    term  leaving
qopt  s  a        qopt  s  a     r 
by letting the reward for choosing a non mine be some positive
number  say     and that of choosing a mine be some negative
number       we are able to estimate which tile is least likely to
have a mine in a given board configuration by finding the tile with
the highest q value  with this in mind  the initial implementation
is shown below  while this approach had moderate success  it
was very slow at exploring the state space  this led us to wonder
if we could gather information on possible actions more quickly 
we devised a further modification that at each state would update
information about all correct moves  but would only choose one

fi 

algorithm   initial q learning
   begin by probing a corner square
   while not game over do
  
s  current state of the board
  
uncover square at random location  a  b 
  
if square is mine then
  
r   
  
else
  
r 
  
end if
   
qopt  s  a        qopt  s  a     r 
    end while
algorithm   improved q learning
   begin by probing a corner square
   while not game over do
  
s  current state of the board
  
array  all tiles on frontier not mines
  
for tile in array do
  
p  s  a   p  s  a     
  
end for
  
probe random square in array
   end while
to proceed  the algorithm is shown in the following column 
this training algorithm makes a few changes  one change is
that the algorithm only considers correct moves  in addition 
we have introduced the notation p  s  a  because we no longer
store the q value for a given  state  action  pair  in fact p  s  a 
more closely resembles the probability that a given tile does not
contain a mine  removing the  terms is only acceptable because
we do not compare p values between different states  we only
compare different actions within the same state  suppose our
learning algorithm has visited a state s n times  tiles with a
p value close to n have very rarely contained mines  and tiles
with a p value closer to zero have frequently contained mines 
thus  tiles with higher p values in a given board state are less
likely to contain mines than tiles with lower p values in the same
state  this assumes that s is large  however  in order to acquire
a proper probability distribution  after storing p values for these
 state  action  pairs  we must use them to play minesweeper and
determine our win rate  for each move  the playing algorithm
plays the tile from the frontier with the highest p value  however 
the only exception is if all tiles from the frontier have a p value
of zero  and if the training algorithm had seen this state at least
once  the implication being that there may not be any correct
moves on the frontier  in this case  the playing algorithm selects
a random tile that is not on the frontier and continues 
c  constraint satisfaction problem  csp 
when posing the problem of solving a minesweeper game as a
csp      all board positions are thought of as boolean variables 
having a value of either   or   to represent the presence of a
mine  when a tile is probed  either a mine is found  in which
case the game is lost  or its value is shown  knowing the value
of a tile allows for a constraint to be set on the variables that
surround it  this is done by stating that the sum of these variables
must equal the value of the tile  thus  our constraint is
x
xij  
xkl
k l

where xij is now a known constant and where k   i      i  i 
    l   j      j  j     and are within the bounds of the rows

and columns of the board  when new values are discovered  the
constraint is simplified by subtracting from both sides  variables
can be simplified further when they share variables in common 
given the constraints x    x    x    x      and x    x      
it can be deduced that x    x      and the larger constraint
can be discarded  constraints can be easily solved if they are
trivial  ie  xij      or if the constant is equal to the number of
variables or    in which case all variables are mines or all are
clear  respectively  this is an implementation of the equation
strategy     
constraints are then grouped by common variables and the
backtracking algorithms finds all possible assignments  if a
square is found to be   or   in all solutions  it can be probed or
marked a mine  there are cases in which not enough information
can be found and solutions cant be used  these cases force the
algorithm to make guesses  where a guess is made in a way to
attempt to minimize the probability of there being a mine 
the backtracking algorithm used for the csp attempts to find
all of the possible solutions to satisfy the constraints  variables
are assigned values  with variables being assigned first if they are
more constrained  each variable is tested with a   first  then a   
each assignment is checked for consistency  if one assignment is
inconsistent  the other is tested  if assignment doesnt work  then
backtracking occurs  when all variables are assigned  a solution
is found and the algorithm backtracks to find the next solution 
iv 

r esults and a nalysis

we use three metrics to understand how well our approaches
perform in playing minesweeper  the testing accuracy  which
is how well the classifier predicts individual board states  the
average percentage of the board uncovered  and the average
number of game wins  we plot these three different metrics
because win rate alone can be misleading  predictors with a
low win rate may still achieve reasonable training and testing
accuracy  this is because the machine learning and q learning
algorithms must make many consecutive correct predictions in
order to win  one can imagine a scenario where such an algorithm
is able to clear a large percentage of the board before making an
incorrect move  in this situation  the average percentage of the
board uncovered might be a more revealing statistic than win
rate alone 
first  we observe the relative performance of the four approaches  the classification  linear regression  and q learning
algorithms all exhibit moderate success on  x  boards  the qlearning approach achieves roughly a     win rate  the greatest
of the three  however  the performance of these three algorithms
drops immediately as board size increases  notably  each has
a winning rate of      on a  x  game board  and     on
a  x  board  the csp  however  enjoys significantly greater
success  with a win rate of approximately     on an  x  board 
furthermore  its win rate decreases very little as the board size
increases  seeing a win rate of slightly less than     on a   x  
board 
second  we would like to highlight the decrease in win rate as
mine density increases  this effect applies to all the algorithms 
a game with more densely placed mines is simply harder to win
because a game with more mines has far more possible layouts 
consider an nxn board with p mines  where p  n    on this
board  the number of distinct board configurations is equal to
n   
p  np   excluding rotations and symmetric configurations  this
 

 
value drops to  p  nn  p  
  one can see that the number of possible
mine configurations is maximal when p   n      not surprisingly 
this number increases as p approaches n    a greater number
of possible mine configurations causes a more challenging game

fi 

the most significant observation about the classifier
model is that it is highly prone to be biased when the
feature extractor operates on a relatively small amount of
the board  we vary the number of local features used in
training to illustrate how the number of features affects bias
in the classifier as well as the win rate of the algorithm 

regression  iterations vs  success rates   x  board    mines 
 
   
   
   
   

rate

while the q learning model shows promise  it suffers from
a hugely large state space  to approximate its magnitude  on
a minesweeper board  we see that each tile can hold one of
ten values  unknown  i e  covered      i e  empty   or      thus
we see that   mn is an upper bound on the number of board
configurations  while this number is significantly greater than
the true number of configurations  due largely to inconsistent
configurations   the number still illustrates that the state space
explodes as board size increases  the issue of increasing magnitude of state space is compounded by the fact that in order
to be accurate  the q learning algorithm must visit each state
many times  to see why  we recognize that the algorithm aims
to compile a probability distribution of whether each tile on the
frontier is or isnt a mine  given the same board state  what is
visible to the player   however  a tile may be a mine under one
mine configuration  but be safe under another  in other words 
different mine distributions can produce the same board state 
therefore the algorithm must visit each board state under a
random sampling of mine configurations in order to accurately
approximate the probability of whether each tile is safe  this is
why the algorithm struggles so mightily with increasing board
sizes  it must play significantly many more training games to
achieve the same exploration rate of each state  as an example 
when moving from a  x  to a  x  board  the state space can
  
 
be said to increase by a factor of   
            according to this
naive calculation  the algorithm must train for one billion times
longer in order to achieve the same exploration level of each
state  again  the true value is smaller  although it still grows at
an alarming rate  the enormously large  and rapidly increasing 
state space of minesweeper explains the performance of the qlearning algorithm  it requires far more training iterations than
classification and linear regression because it needs to thoroughly
explore the entire state spaceit cannot generalize to unseen
states  and its win rate drops quickly as board size increases
because the state space simply explodes  and it cannot thoroughly
explore larger boards in any reasonable amount of time 

win rate 

   
   
   
   

train accuracy
test accuracy
win rate

   
 

   

   

   

     

number of iterations

supervised learning methods each have benefits and drawbacks  the classifier model has potential to scale to larger
size boards  since the feature vector is not dependent on the
board size  and the prediction is made solely on the local board
state  yet this approach currently underperforms compared to
our other two machine learning approaches  on the other hand 
because we use an exponential time minesweeper solver to train
the regression model  we cannot train our algorithm on large
boards  therefore  we optimize learning on smaller boards where
learning the probabilities for every square is feasible 
number of training iterations on a  x  board with three mines vs  win rate
   
classification
   
regression
qlearning
   
   

win rate

simply because there is less certainty  it results in a larger state
space  and there are fewer guaranteed safe moves 

   
   
   
   

number of features vs  win rate and training accuracy
 

 

logreg  test accuracy
logreg  win rate
svm  test accuracy
svm  win rate

   
   

   

rate

   

   
   
training iterations

   

board size vs  win rate

   

   

   

   

   

classification
regression
qlearning

   

   
   

win rate

   
   
 

 

  
number of features

  

the regression model suffers from high variance and choosing
the correct parameters for regularization is essential for good
learning  we illustrate how test accuracy  the accuracy on
individual states  as well as win rate increase with the size of
training the training set  correlating less variance with higher

   
   
   
   
 

 x     mines 

 x     mines 
board size

 x     mines 

   

fi 

number of mines on  x  board vs  win rate

csp  board size vs  win rate at constant mine density

   

 
classification
regression
qlearning

   

   
   

   

   

   

   

win rate

win rate

   

   
   

   

   

win rate
avg    of board cleared

   
 

 

 
number of mines

 

 

the
csp approach was the most successful at correctly solving larger
boards  this is due to the fact that it does not have to enumerate
every possible state in order to obtain good results  the way that
the problem is posed allows the csp to make as few guesses as
possible and most of the moves that it makes are done with full
certainty of correctness  the guesses that the csp solver does
have to make come from the situation where it is forced to make
a crap shoot guess  this is unavoidable and no optimizations
could help the solver  the other type of guesses comes when
there is not enough information on the board to be able to solve
systems of constraints 

csp  number of mines on   x   board vs  win rate
 
   
   
   

win rate

   
   

   

 

   

   
   
   
   
   
win rate
avg    of board cleared

   
 
  

  

  

  

  

  

  

  

  

  

  

  

  

our results show that increasing mine density quickly drops
the rate of success for the csp solver  similar to the other solvers 
because there are more mines on the board  the likelihood of
incorrectly guessing for mines greatly increases and there are
also fewer non mine squares to get information from  however 
while the mine density greatly affects the csp  the board size
does not seem to affect it as much  the solver was tested using
the same mine density     mines for an  x  board  on larger
board sizes and  while the win rate did drop  it was by less than
    

while the csp is more accurate than the other solvers for
playing games on large boards  it is much slower  the other
methods use most of the time in doing pre computations and
learning  but once that is done and saved  they can play many
more thousands of games than the csp  even when the csp
required no pre computation  this is mostly due to the slow
backtracking algorithm  which could be optimized to be faster 

 

 x 

  x  

  x  

  x  

  x  

  x  

  x  

v  f urther r esearch  w ork
moving forward  there are several additional approaches to
explore related to our current research  the first is in improving
the success rate of our csp approach  while the csp excels
at determining which tiles are guaranteed to be safe and which
tiles are guaranteed to be mines  it does not have an effective
mechanism for making guesses in cases without complete certainty  since our other approaches attempt to approximate mine
probability  we believe that integrating them with the csp will
lead to a greater success rate  for instance  we propose training
our q learning algorithm on a smaller board  say   x  or  x  
and applying it to certain regions of a larger board  similarly  we
also would like to utilize the classification algorithms probability
estimates to better inform the csps guesses  since this approach
is inherently scalable  the resulting insight into which squares
are least likely to be mines will help the csp make more
educated decisions  as stated in the above section  another area
where the csp could be improved is in performance  the csp
backtracking algorithm is slow and could be optimized to be
faster 
in addition to improving the csps guess accuracy  we also
believe that the approach of deep q learning holds promise  a
key feature of minesweeper is that the same method for solving
one board state can directly be applied to another board state 
which makes function approximation in q learning especially
ideal  specifically  given the strong local dependencies of making
decisions while playing the game  we think using a convolutional
neural network  cnn   similar to      is a promising area of
exploration because learning local strategies can be generalized
to the entire board  greatly helping to learn the expansive state
space for larger boards 
r eferences
   
   
   
   

   
   
   

   

kaye  r          minesweeper is np complete  the mathematical intelligencer           
adamatzky  a          how cellular automation plays minesweeper 
applied mathematics and computation              
maznikova  m  a  minesweeper solver 
mnih  v   kavukcuoglu  k   silver  d   graves  a   antonoglou  i   wierstra 
d     riedmiller  m          playing atari with deep reinforcement
learning  corr 
nakov  p     wei  z          minesweeper   minesweeper 
welling  m  kernel ridge regression university of california  class notes 
yang  x   song  q   wang  y          a weighted support vector machine
for data classification  international journal of pattern recognition and
artificial intelligence                  
studholme  c          minesweeper as a constraint satisfaction problem 
unpublished project report 

fi