cs   finalproject
asoundhoundforthesoundsofhounds
weaklysupervisedmodelingofanimalsounds
robertcolcord ethangeller matthewhorton

abstract 
we  propose a hybrid approach to generating  acoustic models for recognizingspecific species of animals
based on their vocalizations  using unsupervised analysis and recognition of similar sounds  in a larger
recording 

in many applications of machine learning to audio analysis andprocessing  suchas voicerecognition  the
primary challenge is finding and annotating training data  this makes unsupervised clustering of similar
sounds attractive as a means for creating acoustic models  the cornell lab of ornithologyhostsa large
quantity of field recordingsofalargevariety of species ofanimals  however  manyoftheserecordingsare
exceptionally long  and the animal in questionsometimes will notbe audible for several minutesat atime
within these larger recordings  searching andediting theselong recordings to extract goodaudiodatacan
be an extremely timeconsuming process  however  analyzing audio on the basis of  similar repetitive
soundscouldformafoundationforapotentialsolutiontothisproblem thatiswhatthisprojectexplored 

introduction 
theobjectiveofthisalgorithmistolookforthe
longestsimilarsounds
acrossalargerecording inprevious
workbyarenjansenetal  thesehavebeendescribedaspseudoterms todothese wefirstneedtofind
thefollowing 
   asuitablecriteriaforthesimilarityoftwoequallengthaudiosignals 
   arobustmethodofdetecting
consecutive
similaritiesovertime 
   amethodtoisolatetheseconsecutivesimilaritiesanditerate and
   asatisfactorycriteriaforconvergence 

havingsolvedthesefourproblems wecanreliablysaythatthealgorithmfoundthemostcommon
pseudoterminagivenrecording bysearchingfor
mostconsecutivesimilarities
ratherthan
instancesof
highestsimilarity
 wecanavoidmatchingshortcommonambientsounds suchascoughsandtreesbeing
hit  andassumethatlongerincidentalsounds forestnoise water windnoise resembleagaussiannoise
distribution 

givenafieldrecordingwithasignificantamountofvocalizationsbyananimal weaimtoimplementthis
methodtofindapseudotermthatcouldbeconsideredtobethemostgenericacousticmodelforthe
vocalizationofthatanimal 

relatedwork 
arenjansen duringhistimeasaseniorresearcheratjohnhopkins originallyproposedthemethodwe
usedforfindingouracousticmodelsasawaytocombthroughunannotatedrecordingsofhumanspeech 
unsupervisedmethodsofclusteringrecordingsofspeechareattractivebecauseofhowexpensivetraining
dataisforvoicerecognitionsoftwareacompetentenglishlanguagevoicerecognitionsolutiononthescale
ofapples
siri
orgoogles
googlenow
willtypicallyrequirearound      hoursoftranscribedspeech 
consideringthatittakesonaverageapproximately  hoursforahumantotranscribeonehourofspeech it
canbeincrediblyexpensiveandtimeconsumingtobuildreliableacousticmodelsforthehumanvoice this
iswhyarenjansenproposedtheapproachtoweaklysupervisedacousticmodeltrainingthatweusedfor
thisproject 


fidataset 
weusedtenfieldrecordingsofanimalsoundsasourtrainingdataset thespeciesrepresentedinthe
recordingsincludechimpanzee northernelephantseal whitenosedcoati reddeer brownhowlermonkey 
andredsquirrel eachofthesefieldrecordingslastsanywherefromtwentysecondstothirtyminutes and
therepresentedanimalvocalizesduringeachfieldrecordingseveraltimes inall thiscomprisedfiftyfive
minutesandfifteensecondsofaudiodata thefieldrecordingswereacquiredwithpermissionfromthe
macaulaylibraryatthecornelllabofornithology 

 allprocessingandfeatureextractionofthedatawas
doneinmatlab 

features 
thekeyfeatureoftheaudiodatausedinthegenerationofmodelsisthemelfrequencycepstrum mfc of
thesound themfcisatoolusedinaudioanalysisthatrepresentsshorttermpowerspectrumofasound 
melfrequencycepstrumcoefficients mfccs aretheindividualamplitudevaluesofanmfc theprocess
offindingthemfccsatacertainpointintimetisintuitive first weextractsignal x t   t   w   wherein w is
thewindowsize wethentakethatsegmentandgetits
smoothedcepstralvalues
 

x cep   fft h  i fft log fft x     

here wegetthecomplexfrequencysamplesofoursignal thentakethelogoftheresultingspectrum in
doingthis weeliminatethephasecomponentofthefrequencysamples sowhenwerunaninversefourier
transformontheresultingsignal allofthefrequenciesbeginat n      thisallowsustosmoothour
cepstrumbytruncatingthesignal totruncatethesignal wemultiplyitbyawindow h  whichwedefineas

h n        n   m      n   m    n   m  

where m      n   canbedescribedasasmoothingfactorforourcepstrumthesmallerthevalueof m  the
lessnoisyourcepstrumwillbe next wemeasuretheenergyofourcepstrumatspecificpointsonthemel
scale themelscaleisalogarithmicmappingoffrequencyusingthefollowingformula 

f hertz
f mel         log           
 

wechosethemelscalebecausebyutilizinglogarithmicallyspacedfrequenciesasourfeatureset weget
muchmoreresolutionathigherfrequenciesthanlowerfrequencies thismeansthatouralgorithmwillbe
abletofocusmuchmoreonthequalitiesofasoundthatdeterminethe
timbre
ofananimalsvocalization 
ratherthanthefundamentalpitchofthesound whichcanvaryonapervocalizationbasis  anexampleofa
melfrequencycepstragram whichcanbedescribedasthewindowedmfccsatfixedincrementsintime
acrossthesignal similarlytoa
spectrogram
  canbeseenin
figure 
 

inordertofurthercleanourdata weremovedthedccomponentoftheoriginalfieldrecordings usinga
highpassfilterwithafrequencycutoffascloseaspossibleto hz typicallydescribedasa
dcblocking
filter 

ahyperparameterwhichwehadtorigorouslytestwasthefrequencybandthatweweregeneratingmfccs
for whenanalyzingvoice onecantypicallyusearelativelynarrowrangeoffrequenciessincethehuman
voicedoesnotproduceanysignificantspectralcontentabove    hz however forgeneralizedanimal
vocalizations wehadtouseamuchbroaderrange sincewewantouralgorithmtoperformaccuratelywith
bothlowpitchedandhighpitchedanimalsounds 

fi
similaritycriteria 
whencreatingoursimilaritycriteria wewantedtomakesurewewerelookingforspectralpeaks andavoid
falsenegativesfromvariationsinoverallgaininthesignal i e ifadogislouderat     thanheisat      
wedonotwanttotreatthatasdissimilarity  therefore wewanttonormalizeourmfccsonaperframe
basis besidesthis thesimilaritycriteriaweusedisthesameoneproposedbyjansen 

 x  x    

kij                x i x j       
i

j


where xi isourmfccsetatframe i   xj isourmfccsetatframe j  and kij isthesimilarityofourfileat
timeframes i and j  thus  k constitutesa
similaritymatrix
oftherecordingwithitself becauseofthis  k is
symmetric and diag k       examplesimilaritymatricescanbeseenin
figures 
 

aproblemwiththisapproachisthatsilencewillresultinveryhighsimilarities thesolutionweendedup
implementingwasasimplenoisegateifthereisnomfccaboveacertainthresholdatacertainpoint we
setitssimilarityto  thishastheaddedbenefitofgreatlyreducingthecyclesouralgorithmtakes 

amethodforfindingconsecutivesimilarities
afterwecomputeoursimilaritymatrix weneedtofindconsecutiveinstancesofhighsimilarityinrespectto
time inthecontextofoursimilaritymatrix thesewillbelinesegmentsthatrunparalleltothediagonal at
    
houghtransform
tolookforthehighest
    again webuildonasolutionthatjansenproposes usinga
densityofsimilarityalonganylinerunningparalleltothediagonal theresultingvalueswillalwaysincrease
relativetohowclosethelineyouarelookingatistothediagonalofthematrix however wecanfindlocal
maximaintheresultingvaluestolookforhighestdensityofsimilarityataspecifictimedelta fromthere we
goelementwisethroughthatdiagonaltolookforourlongestlinesegment ahoughtransformisseenin
figure  

removinguniquesoundsanditerating
atthispoint wetakeanyinstancesoflinesegmentsandsavethecorrespondingaudiofromtheoriginalfile 
afterweconcatenatethoselinesegmentstogether westartoverwhilelinearlydecreasingthehopsizeof
ourmfccepstragram thisresultsinmoretimeframes thusgivingusincreasedresolutioninour
cepstragram aseconditerationsimilaritymatrixisshownin
figure   

checkingforconvergence
westopiteratingwhenwecannolongerfindlocalmaximaaboveacertainthresholdinourhough
transform inthecasethatwefindnopeaksaboveourstartingthreshold wedecreaseourthresholdfor
localmaxima 

results 
weran  differentaudiofilesthroughouralgorithm ofthose  audiofiles thealgorithmdidnotconverge
fortheentiretyofonefile file  andanotherfilewasaduplicate file    sowesuccessfullyanalyzed 
fieldrecordings inordertodeterminetheefficacyofourmethods wedecidedthatasuccessfuloutput
wouldbeanoutputwhichcontainedasoundmadebytheanimalthattheoriginalrecordingwasmeantto
capture measuredbyhumanperception thisseemedtobethemostdirectapproach consideringthe
applicationsofthesemethodsincludecuttingdownhoursoffieldrecordingsintoasubsetofshort
recordingswithonlytheimportantaudio 


fihowever formemoryconcerns webroketheseaudiofilesinto  secondchunksasweprocessedthem 
uponanalysisofthedata thispresentedaproblem forcertainanimals vocalizationscanlastalmostas
longasanaudiochunkandcanevenspanchunks thisdoesnotlenditselftotheanalysisbasedon
similarityandrepetitionthatweproposeinthispaper also oftentimes achunkwouldonlycontainother
noise humanspeech environmentalnoises bumpsontherecorder thesoundsofwalking etc   andthe
outputwouldbeasubsetofthatnoise 

forthisreason weconsideredtwomeasurementsofefficacy the
cynicalinterpretation
andthe
realistic
interpretation
 thecynicalinterpretationmeasuressuccessasthepresenceofananimalsoundinan
output therealisticinterpretationmeasuressuccessasthepresenceofananimalsoundinanoutput
onlyif
therewasananimalsoundpresentintheinput iftherewasnoanimalsoundpresentintheinput that
chunkisthrownoutoftheanalysis 

thismodificationdoesnotsolvealloftheproblemswiththedata forexample ouralgorithmisstillunable
tohandlelong repeatedvocalizationsthatmightbebetterhandledbylargerchunks however itdoessolve
manyotherissues 

figure 
showsthecynicalinterpretationversustherealisticinterpretationintermsofpercentages
successfuloutputsperchunkinanaudiofile overall thecynicalinterpretationgivesouralgorithma
successrateof       andtherealisticapproachgivesouralgorithmasuccessrateof    

conclusions 
webelievethemethoddescribedhereforweaklysupervisedmodelingofanimalsoundsshowsmuch
promiseasasolutiontotheproblemofannotatinglengthyorotherwiseunwieldyaudiodata basedon
preliminaryresults itappearsthatthemodelishighlysuccessfulatidentifyingthelongestsimilarsoundsin
alengthyrecordinginordertofindageneralizedacousticmodelforthevocalizationoftheanimalspeciesin
therecording morerigoroustestingneedstobedoneonthemodelsoutputstodetermineitspitfallsand
limitationsandtofurtherrefinethealgorithm itisourbeliefthatdoingsoisaworthyendeavor asthismodel
presentsauniquesolutiontoacommonlimitationinaudioanalysisresearch 

references 

a jansen s thomas andh hermansky weaktopdownconstraintsforunsupervisedacousticmodel
training in
proceedingsoficassp 
     

a norouzian r rose s h ghalehjegh anda jansen zeroresourcegraphbasedconfidence
estimationforopenvocabularyspokentermdetection in
proceedingsoficassp 
     










appendixafigures


fi
figure  matlaboutputshowingoriginaltimedomainwaveformandmfcofsound




figure  similaritymatrixofasoundsegmentwithitselfafterone left andtwo right iterations






fi

figure  houghtransformofsimilaritymatrix



figure  successpercentagescynicalinterpretationvsrealisticinterpretation 


fi