local ancestry inference in admixed populations
naveen arivazhagan

hye ji kim

edwin yuan

department of computer science
stanford university
stanford  ca        usa
email  naveen   stanford edu

department of electrical engineering
stanford university
stanford  ca        usa
email  hyejikim stanford edu

department of applied physics
stanford university
stanford  ca        usa
email  edyuan stanford edu

i  i ntroduction
contemporary human sub populations exhibit great differences in the frequency of various alleles  or the set of variations of a particular gene  advances in genome sequencing
have rapidly improved speed  cost  and accuracy  allowing
unprecedented opportunity to map the functionality and location of such genetic variation  of particular interest is the
mapping of disease associated loci in the genome  in admixed
populations  or populations that are the result of a mixing of
two or more ancestral populations over a small number of
generations  one technique that has been used extensively is
mapping by admixture linkage disequilbrium  mald   the
rationale behind mald is that disease affected individuals in
the admixed populations should share higher levels of ancestry
near disease carrying loci with the ancestral population from
which the disease loci arose  the accuracy of mald thus
depends crucially on the accuracy with which one can infer
the ancestry around any loci in an admixed genome  this
particular task has been termed local ancestry inference
 lai  
much of the early work in local ancestry inference took
form around the assumptions of hidden markov models  while
this method is computationally efficient  the markov assumptions fail to model the correlation in inheritance between base
pairs  or linkage disequilibrium  ld   later models developed
at stanford  such as saber     and hapaa      explicitly
model linkage disequilibrium within the hmm framework 
by extending the dependence of the posterior probabilities
to previous states even further behind in the chain  in doing
so they are also computationally expensive  a later approach
lamp      utilized probability maximization within a sliding
window  assuming that only one recombination event took
place within each window  this is based on the fact that 
biologically  ancestral haplotypes are inherited in blocks of
alleles  and thus between any two blocks there is a single
recombination event  lamp is considered amongst the gold
standard for lai in recently admixed populations  such as the
chinese and japanese 
in       the      genomes projects phase i released a
data set of      individuals from    populations that was
unprecedented in its detail  genomic completeness  and scope 
soon after  maples  gravel  kenn  and bustamante released a
discriminative model  uses p y x  as opposed to p x y   called

rfmix     which uses conditional random fields  crf  based
on random forests within windowed sections of the chromosome  rfmix was shown to be both faster and more accurate
than the existing lamp method  the modern challenges for
local ancestry inference are  efficiency in light of increasingly
large and dense genomic data sets  discrimination between
recently divergent ancestries  and overall algorithm accuracy 
understanding ancestry inference as the previous section
illustrates  there is great variety in nature of the algorithms
implemented for global ancestry inference  with different
levels of performance depending on the admixing scenario
in question  fundamentally  there are two approaches to this
problem of ancestry inference  the first takes an entirely nonbiological approach  treating this task as one analogous to
identifying which ancestry a particular sequence of nucleotide
letters is most statistically related to  the second approach is
highly motivated by the biology of the genome  attempting
to incorporate mechanisms for recombination  mutation  etc 
most models in the field have been of the second type 
to explain in detail how these algorithms work in general 
we take rfmix as an example  in the most basic framework 
rfmix segments an input strand of dna  a sequence of snps 
from an admixed individual into contiguous windows of single
nucleotide polymorphisms  snps  and then assigns each of
these windows of snps to one of several reference ancestries 
this is shown in figure    the statistics for determining the
snps ancestry come from a training set of reference panels 
which are entire sequences of snps that have been globally
assigned to one of the ancestries in consideration 

fig     illustration of ancestry inference problem     two admixed
chromosomes are shown with the true ancestries above and with the decoded
ancestries below  the admixed individuals are mixtures of   ancestral populations 

rfmix has a second functionality  the previous approach is
fast and works well when one has an abundance of reference
panels  this is  however  not typically the case because despite

filarge organized efforts of hapmap and the      genomes
project  publicly available population size data sets remain
sparse  the admixed samples  on which rfmix is tested 
itself contains ancestry information of snps  albeit in a
jumbled form  rfmix thus is able to iteratively infer and
then incorporate ancestry information from the admixed  test 
samples using em 
finally  rfmix models phase errors that are produced
as part of the local ancestry inference and then attempts
to autocorrect these errors  in an example simulation the
paper provides  it was shown that  by this procedure  rfmix
significantly improves long range phasing error  by comparing
the fraction of snp pairs correctly phased relative to each
other  the new phasing generated by rfmix achieved     on
this metric  compared to     achieved by the original beagle
phased data  beagle is a standard phasing algorithm that uses
haplotype clustering methods 
ii  data and f eatures
we were able to utilize some pre processed data that the
authors of the rfmix paper provided  the data set consists
of       snps from both chromosome ones of     individuals  the snps were assumed to be bi allelic  the test set
consists of    admixed  latino individuals  whose genomes
were created using a wright fischer simulation to sample   
generations after admixture  the simulated latino genomes
were generated from existing data sets and have     native
american  nat       european  hapmap ceu   and   
african  yoruba in ibadan  ancestry  other simulated samples
were used to construct genomes of the reference panels  of
which there were     native american  nat       african
 yri   and     european  ceu   the snps used were created
to be perfectly phased  and so untangling phasing error was
not a part of the following analysis 
a  principal component analysis
despite the high dimensionality of the data set  with each
training example containing       snps  the   separate
ancestries  native american  african  and european could
very easily be distinguished by a     component principal
component analysis  shown in figure    the yellow admixed
ancestries indeed lie between the   ancestral populations in the
principal component space  the yellow admixed individuals
show much larger variation within the group compared to any
of the ancestral populations  pca also shows graphically  as
expected  that the admixed group as a whole is closer to native
american and european ancestries than to african  this is
expected given that the admixed individuals are on average
only    african 

fig     pca the full training set of    native american  nat  red     
african  yri  blue   and     european  ceu  green  individuals projected
onto the first   principal axes  the    admixed individuals are shown in
yellow 

second step we classify the windows that we have identified
into one of the   source populations 
in our paper we use a simple heuristic for identifying the
windows  we divide the chromosome into windows of fixed
centi morgans  by the definition of a centi mogran  there is
thus a variable number of snps per window  but they are
grouped according to the average number of chromosomal
crossovers expected within the group 
having identifies the windows  for the second step  we use
a variety of classifiers to correctly classify the window of an
admixed genome into the correct population ancestry based
on its similarity with the corresponding windows from the
reference panel 
the full training set consists of    native american  nat  
   african  yri   and     european  ceu  individuals  a
more moderate and realistic training set consists of    native
american  nat      african  yri   and    european  ceu 
individuals  finally  the extreme case in which one has a
scarcity of well sequenced reference panels is represented by  
training examples of each ancestry    native american  nat  
  african  yri   and   european  ceu  individuals  in reality 
the possibility of having such large cohorts of  accurately
sequenced data is unlikely given modern sequencing technologies  there is also increasingly a push to move beyond
the heavy reliance on reference panels in order to perform
ancestry inference 
a  manhattan method

iii  m ethods
we use a pipeline approach consisting of two steps  in this
first step we identify windows   sections of the genome that
are believed to be highly correlated to each other and therefore
tend to be inherited together  since they are inherited together 
they will have the same population ancestry  therefore  in our

the first classification method we implemented was a simple criteria of determining how closely related two sequences
of nucleotides are  we devised a notion of similarity between
windows in the reference samples and those in the admixed
samples by counting the number of replacements needed to
get from one window to another  for example if in some

fireference window one has          and in an admixed
window           the number of replacements needed is just
one  the fewer replacements needed to convert between the
sequences the more similar they are  this is the gist of the socalled manhattan metric  we identify the windows amongst the
reference panels to which the admixed window has the highest
similarity  we then use a voting scheme where the ancestry of
the admixed window is assigned to the reference population
in which it has largest number of the highest similarity values 
a result of the algorithm labeled ancestry when the window
size   cm is shown in figure   below for the entire length of
one chromosome of one admixed individual 

of the haploblocks  rfmix achieves       accuracy but can
iteratively incorporate the admixed predictions into em to
boost performance 
varying window size because inheritance of genes takes
place through haploblocks  each of a single ancestry  choosing
the correct window size is essential for achieving optimal
performance  the result of varying window size on overall
accuracy is shown in figure   when using the full training
set 

fig     manhattan method window size after training on the full reference
panels  the overall accuracy of the manhattan algorithm is shown as a function
of window size

fig     manhattan method labeling plots showing the ancestry labels of
each of the       snps under consideration for windows of   cm of a
single admixed chromosome  the red bars show the true ancestry while the
blue over layed lines show the ancestry predicted by our manhattan algorithm
a  compares the ancestry labels when the algorithm is trained on a set of   
individuals of each ancestry b  shows the same when trained on a set of  
individuals of each ancestry  note that there are no snps inherited from yri
simply because the admixed genome under review doesnt have any 

in figure  a  we see that  when trained on moderately large
data sets of    individuals of each ancestry  the manhattan
method is extremely accurate at predicting ancestry  the
haploblocks are large and the manhattan method finds the
correct label but only up to small shifts  it similarly misses
changes in the ancestry that occur over just a few snps 
the overall accuracy here of the manhattan method is around
      compared to       achieved by rfmix 
on the other hand  the algorithm performs much more
poorly when training on a smaller data set of only   individuals  although the overall accuracy of labeling is still
relatively high at         its clear from figure  b that the
manhattan method does very little to infer the overall shape

the results suggest very high performance  compared to
rfmix  peaking at around       accuracy for a window size
of     cm  for the same window size rfmix uses      cm 
the accuracy is only        as window size is increased  the
accuracy peaks and then falls rapidly  it is important here
to keep in mind that the benchmark accuracy  that achieved
by random guessing  is already        given that we have  
ancestral populations 
b  support vector machine
as a point of comparison we also applied a support vector
machine  svm  classifier to our data  again we take the
approach of fixed window size and use the svm on training
data to classify vectors with length equal to the number of
snps that exist within each window  the results below are
trained on the full set of reference panels  we find that the
performance of the svm depends significantly on parameters
like the type of kernel employed  the window size  and the
value of an internal parameter c which is explained below 
figure   compares the overall accuracy of the svm using a
linear kernel versus that of one using the radial basis kernel
for different window sizes 
it is evident from the figure that the linear kernel outperforms the radial basis kernel  with the default parameters  at
all plausible window sizes  to investigate this further we note
that the svm with the radial basis kernel depends on two
parameters  namely c and gamma  we vary the parameters 

fifig     svm accuracy vs  window size a plot of the overall accuracy
achieved as a function of the fixed window size  centi morgans  used  for the
radial basis kernel and the linear kernel  in both svms are trained on the
full set of reference panels 

fig     svm accuracy vs  parameter c for an svm using the radial
basis kernel  we plot the overall accuracy as a function of the internal svm
parameter c  whose function is also explained below  the training set is the
full set of reference panels 

fixing the window size at     cm  for the radial basis kernel 
 
k x  y    exp xy    gamma thus determines how much
weight to put on a single training data for a given euclidean
distance between that single training data and the test data 
the larger  is  the more weight placed on training data that
are closer in distance to the test data 
we found that as we decreased gamma  the accuracy increases  for         the accuracy is      and for         
the accuracy is         we conjecture that this takes place
because when gamma is smaller  more of the training data
is taken into account  another factor of consideration is
that the euclidean metric may not be the best indicator of
how far a given test point is from a training data point 
the discrete manhattan distance may characterize the notion
of distance between two sequences more functionally and
increase classifier performance 
another large determinant of the svms performance is the
value of the internal parameter c  the parameter c controls
the tradeoff between classification correctness on the training
data and the largeness of the largest minimal margin  a large
value of c indicates a willingness to increase the classifiers
accuracy rating by giving weight to outlier training examples
that are quite far from the mean of the data  in a general sense 
a large c value tolerates overfitting behavior  as expected  as
we increase c  the accuracy of the svm increases as shown
in figure    here we are using the radial basis kernel while
training on the full reference panels 
finally  we evaluated the performance of our svms using
only small numbers of training data  we first tested with   
training examples from each ancestry  and in that case  we get
about     overall accuracy for the svm with the linear kernel
and the svm with the radial basis kernel  this is quite a small
reduction from the svm performance on the full set of training

data  and indicates that in the regime of large reference panels
we are gaining very little performance by adding more panels 
on the other hand  when we evaluate the performance using
the extreme scenario of   training reference panels from each
group  we achieve     accuracy using the svm with radial
basis and     accuracy using the svm with linear kernel 
again  the linear kernel yields superior performance to the
radial basis kernel 
c  random forest
we use an ensemble of trees to make prediction on the
windows  the random forest generates multiple decision trees
and take the average vote to predict the label of test data  as
the number of decision trees increase  the accuracy increases 
but as a drawback  the run time also increases  we also observe
that increasing the number of trees does not tend to cause overfitting easily 
we then tested the random forest method using only
three
 training examples  we set the number of estimators
as window length nc and vary nc from   to       for
nc      we get     accuracy  and for nc         we get
    accuracy 
in figure    we plot the accuracies of manhattan method 
svm method  and the random forests method as a function
of the window size  we use all the training data   we see that
for all methods  the accuracies peak at around window size
 cm  for a smaller number of window size  including  cm  
manhattan method and random forest method perform better
than svm 
d  hidden markov model
we use hidden markov model  state i is the ancestry
 african  european  etc  at the i th position of a haplotype 

ficlassifier
svm
random forest

train size  
train size   
full train
    
    
    
    
    
    
table i
t he performance of svm  and random forests when evaluated
on the true windows

train size  
train size   
full train
    
    
    
    
    
    
table ii
t he performance of svm  and random forests when evaluated
classifier
svm
random forest

on the the heuristic based windows

fig     accuracy of manhattan method  svm method  and the random forests
method vs  window size

and the observed variable is snp at the i th position of a
haplotype 
the hmm requires three probability matrices  one is the
probability of each hidden state  and the second is the emission
probability  and the third is the transition probability from one
state to another state 
for the first probability  we assume every ancestries are
equally likely  secondly  to estimate the probability of emission probability of i th state  we use the empirical probability
in the reference haplotypes  note that this emission probability
is not stationary i e   it depends on i  lastly  we assume with
probability      there is a transition from one ancestry to
another ancestry at time i  and for the remaining probability 
there is a transition to a new ancestry with equal probabilities 
using this approach we get only get a        accuracy 
this is because the hmm does not pay any attention to the
index of the snp and is therefore not able to capture the
distribution of the specific columns in the data  we also notice
that the predictions are skewed n favor of population   because
of its high start probability and the low transition probabilities 
iv  e rror a nalysis
we describe two independent sources of error in not just
our classifiers  but also other more complex local ancestry
inference algorithms 
   windowing of the snps  in perfect windowing  all
snps within a window originate from not just the same
ancestry but also the same ancestral individual within
a population  if snps from two different ancestries
fall within the same window  then we will inevitably
misclassify one of the two segments within that window 
alternatively  even if a window contained two segments
from the same ancestry  but from different people  any
similarity measure may fail  because said similarity
measures only compare a given test window against the

corresponding training window of a single individual 
the classification will not be ideal  and may lead to
errors 
   assuming now  that windowing is correct  an independent source of error is classification error within a
given window  this error exists because in a real world
scenario  the reference panels used to train the classifier
are not directly ancestors of the admixed individuals 
we sought to investigate whether the majority of error in our
simulated data came from the first or the second source  to this
end  we used the true windows of an admixed individual while
training the classifier  instead of the fixed centimorgan window
sizes we had been using  we then again tested with different
classifiers and training sizes  comparing tables i and ii  we
find that we can achieve near perfect performance if we are
given the correct admixed windows  this is the case even when
the number of reference panels is very few    per ancestry 
thus we find that it is in fact the windowing algorithm that is
the main bottleneck in our approach and further work should
be devoted to this step of the process  various of the more
recently published algorithms such as winpop take steps to
deliberately optimize the search for the best window length at
each locus along the chromosome 
v  c oncluding remarks
our conclusion from running various different learning
algorithms  is that a large majority of them work very well
 above     accuracy  given an abundance of reference panel
training data  this is true for even relatively simple algorithms
such as the one based on the manhattan metric  when the number of reference panels is few however  em is valuable method
for iteratively improving performance  furthermore our error
analysis suggests that a large proportion of the error comes
from poor choices of windowing  by windowing more ideally 
many algorithms can achieve near perfect performance even
when reference panels are scarce  thus developing methods
for judiciously choosing window size are an important effort
in local ancestry inference 
r eferences
    h  tang  m  coram  p  wang  x  zhu  and n  risch 
reconstructing genetic ancestry blocks in admixed individuals  american journal of human genetics       

fi    a  sundquist  e  fratkin  c  b  do  and s  batzoglou 
effect of genetic divergence in identifying ancestral
origin using hapaa  genome research  vol     
no     pp                    online   available 
http   www ncbi nlm nih gov pmc articles pmc        
    s  sankararaman  s  sridhar  g  kimmel  and e  halperin 
estimating local ancestry in admixed populations  american journal of human genetics       
    b  k  maples  s  gravel  e  e  kenny  and c  d 
bustamante  rfmix  a discriminative modeling approach
for rapid and robust local ancestry inference  the
american journal of human genetics  vol     
no     pp                       online   available 
http   dx doi org         j ajhg            

fi