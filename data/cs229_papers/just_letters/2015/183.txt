 

generating motion capture data for arbitrary rigs
marianna neubauer  shannon kao

i  i ntroduction
as motion capture techniques become more advanced and
accessible  motion capture data has become an increasingly
popular source of efficient  realistic animation  the process of
motion capture involves placing markers on an actors body
and recording movement data for each marker  this data can
then be mapped onto a digital human skeleton  called a rig 
which consists of joints  e g  hips  elbows  wrists   motion
capture is a practical alternative to the more traditional method
of hand animating each joint in a rig  however  the data
obtained by motion capture is highly specific to the rig used
to record it  making it difficult to transfer recorded animation
from one rig setup to another 
there is a plethora of motion capture data available on line 
however  d artists who already have an existing rig that is
well suited for a unique character cannot use that animation 
this project aims to break the dependence of motion capture
on a specific rig by generalizing animation for arbitrary rigs
using machine learning algorithms 
a  system overview
in this paper we introduce a system that generates motion
capture based animation for an arbitrary input rig  we split
our training datarigs and associated motion capture animation
from various databasesinto individual joints  assigning each
joint a time varying series of translations and rotations  our
system then applies a k means clustering algorithm to classify
the joints  finally  it uses linear regression with gradient
descent on the calculated clusters to output an appropriate
animation sequence for each joint in the input test rig 
ii  r elated w ork
motion synthesis is the problem of generating animated motions that meet a set of requirements  recently  there has been
a surge of algorithms addressing the creation of new animation
sequences from existing motion segments  in general  motion
synthesis methods can be classified as physically based     
    or example based  like our algorithm 
in the realm of example based motion synthesis  the concept
of motion graphs  introduced by kovar      lee      and
thuraisingham     in       has gained significant traction 
motion graphs apply the technique of texture synthesis to
the problem of motion synthesis  in general  though  these
algorithms require a library of motion clips specific to one
skeleton  these clips are cut and interpolated to create unique 
original motions          
image based motion synthesis uses video clips as input
data  there are a variety of techniques used to infer  d
structure from video                and extract motion data from
these structures     to output a three dimensional animation 

however  when applied to rigged characters  these methods
largely require the user to have foreknowledge of skeletal
positioning and hierarchy 
motion synthesis methods up until this point have focused
largely on generating original motion for an existing character
rig  they assume knowledge of the rig structure  as well as
an existing set of animations specific to that rig  we approach
this problem from the other direction  assuming a large dataset
of one class of motion  can we generate similar data for an
arbitrary rig 
to analyze such a dataset  we turn to machine learning
techniques  there is a variety of research in the area of
motion classification and analysis       ranging from analysis
on level of motion clips as a whole             down to a
neurological interpretation of joints as primitives       while
these algorithms are largely used to split and classify a range of
different motions  we found the common method of clustering
over animation groups     applicable to our problem 
the system we propose makes no assumptions about rig
structure or layout  by treating joints as individual data points 
we are able to apply these methods agnostic of underlying
skeletal hierarchy  further  this system makes no requirements
on input animation  drastically different rig structures can
be used to provide useful motion data  despite variation in
scale  positioning  and animation phase  we utilize clustering
and linear regression to learn a predefined motion from a
large database of example animation  then generate believable 
realistic motion data for the input rig 
iii  data s et and f eatures
we used biovision hierarchy  bvh  files for our training
data  each bvh file contains a rig and a single motion defined
as a time series of the root translation and joint rotations  our
data set consists of    files from carnegie mellons motion
capture database       for the scope of the project  we trained
only on walk cycles  a common motion that has a well defined
structure  however  our techniques could easily be generalized
to commonly encountered motions like running  sitting  or
throwing 
bvh file format  a bvh file has two sections  the first
section defines a rig in a tree like hierarchy of joint structures 
with a root that represents the pelvis of a human skeleton  each
bvh file has a unique skeleton  where the number of joints 
parenting structure  motion channels  and joint offset from
parent may vary  the second section defines the animation 
each joint in the skeleton has a time series of transformations 
translation for the root joint and rotations for the other joints 
a  data preprocessing
   loading the bvh files  we utilized a bvh loader      to
load and preprocess the training data  a bvh file contains the

fi 

absolute translation and rotation of the root joint and relative
rotations of all other joints  this script computed the absolute
translations from that information and the relative offsets of
the joints from their parent  we use these absolute translations
in our error metric and curve visualization 
   normalise animation frames  the input data has animations recorded at anywhere from    to     frames per second 
we normalise all data to    fps by omitting extraneous frames
of animation from higher rate samples  a minimum frame rate
of    fps was chosen to reflect general industry standard for
real time animation 
   joint absolute positions  our system is designed to
works on varying rigs  so the number of joints and their
placement will vary between different samples  to handle this 
we explode each rig into individual joints  and train our data
across all joints  a joint in the bvh file is defined with a
transformation relative to its parent in the hierarchy  so we
perform a recursive depth first traversal of the bvh to obtain
the absolute positioning of each joint 
   scale and center rigs  the input skeletons have a wide
range of positions and sizes  to address this  we scale all rigs
to be the same height  using the y axis as a metric in order to
avoid size errors due to hand or arm positioning along the xand z axes  we also center each rig at           to normalize
for offsets in geometry placement 
b  features
   input features  the input features for each joint includes
the absolute position in xyz coordinates  the offset of the joints
from its parent  the depth of the joint in the hierarchy tree 
and the number of children of the joint  this feature space
encapsulates both position and hierarchy information for the
joints 
   target features  our goal is to generate an animation
sequence defining the movement of a particular joint over a
time sequence  this movement can be recorded as a series of
rotations or translations  each associated with a particular time
t  each spatial and rotational coordinate is called a channel 
both rotations and translations have   channels  x  y  and z
 for a total of   channels for an animation curve  figure    
rotation  a    t matrix  where t is the total number of
animation frames in our training data  at each frame  there
is an xyz vector defining the euler rotation about each axis 
relative to the parent joint 
translation  a    t matrix  the xyz coordinates define the
absolute translation of that joint in word space  this translation
is computed from the relative rotations and the offset of the
joint from its parent 
iv  m ethods
in order to assign animation sequences to an arbitrary
skeleton rig  we break down the skeleton into its individual
joints and assign an animation sequence to each joint  our
training algorithm has two steps  cluster the joints  then run a
linear regression within each cluster  using the output of the
linear regression on each cluster  we hope to produce animation
curves like the ones seen in figure   from the position and
joint hierarchy information of a test skeleton rig 

a  k means clustering
we cluster the joints according to the input features described in section iii  we set k to be the maximum number
of joints a single skeleton has in the training data set  if
a skeleton has more joints than the number of clusters  we
do not want neighboring joints to collapse into the same
cluster because they may have dramatically different animation
curves  consider a collarbone joint  many skeletons may not
this particular joint  but it should not be assigned the animation
curve of the neighboring shoulder joint  using our feature set
and a fixed k  there are many optimal solutions to k means
clustering if the centroids are randomly initiated  this presents
a problem because we require that the joints in the training
set are consistently clustered so linear regression runs on
animation curves with similar structures  our current solution
to this problem is to set the initial centroids to the joints of
the skeleton with the most joints 
b  linear regression
we perform a linear regression within each joint cluster
to compute time varying coefficients for each channel of the
animation curve  using the aforementioned input features  we
perform gradient descent      on each channel and time point
individually  this results in c n  t matrices of coefficients
    where c is the number of channels  n is the number of
features  and t is the number of frames 
gradient descent attempts to calculate   rnt for
each animation channel  tx   ty   tx   rx   ry   and rz   we
iteratively assign the elements of  according to the cost
function j   and learning rate  

j  
   

j is an input feature and t is the time point in the animation curve  the cost function  j   is the least squares cost
function 
jt    jt 

m

j    

 x
 i 
 t x i   yt   
  i  
 i 

i is the current joint in the cluster and yt
curve at time t for joint i 

   
is the animation

c  computing animation for a test rig
given a test rig with no associated animation  we compute
the rotations and translations of each joint at each time point
by premultiplying the input features of each joint by the
corresponding  
d  result visualization
using the xyz translation coefficients found in linear regression  we can compute the absolute translations of the joints
over time and visualize it in  d animation software such as
autodesk maya  as in figure   

fi 

fig     the animation curves of one skeleton from the cmu dataset  each curve represents the translation or rotation of a single joint over time  this skeleton
has    joints and    frames of animation 

e  error computation of animation curves
in order to compute the error between animation curves 
which are time varying series  we compute the distance
between two cx  t vectors  figure     where c is the
number of channels       each channel of an animation curve
has periodicity  so it is appropriate to perform dtw on the
animation curve  dtw is a dynamic programming algorithm

fig    

conceptual drawing of the distances calculated in dtw     

that computes  in order  the difference between each pair of
time points in two curves  adds it to the minimum distance
of its three neighboring pairs  and caches the result  the final
distance observed after all pairs of time points are compared
is the reported distance of the curve 

v  r esults
a  clustering
for our clustering algorithm  we found that using absolute
position  offset from parent  depth in the joint hierarchy  and
number of children produced the best results  figure   shows
the joint clusters found using these features  other feature
sets we tried include absolute position alone  animation curve
alone  and the set of position  hierarchy  and animation data 
see section v c   for the performance details of these different
methods 
b  linear regression
by iteratively tuning parameters in the linear regression  we
found         and      iterations to produce the best results 
if alpha was smaller or the number of iterations were smaller 
gradient descent did not converge  if they were larger  the
cost function j diverged  since our dataset was small  iterative
tuning was reasonable  figure   shows the animation curves
derived from the s computed from linear regression 
c  performance
distance metric  in order to analyze performance  we
needed a distance metric to calculate the similarity between

fi 

two motion curves  our initial attempt was simply the sum of
the euclidean distance between corresponding frames along
the curve  we found  however  that a frame by frame comparison of this time series data was extremely susceptible to
slight variation in animation phase and period  as our data
was highly periodic  we modified our distance metric to use
dynamic time warping  dtw  as described in section iv e 
   linear regression  we compare linear regression using
the average error  that is  the distance between the animation
output of our theta function and the ground truth animation
curve  this distance is calculated using dynamic time warping 
data type
average error
clusters  without curve 
      
cluster  with curve data         
all points
       
we ran a simple linear regression on every joint in the
data set and found it fairly ineffective  linear regression on
the clustered points  calculated using all features including
the animation curve  was significantly better  while clusters
 without the animation curve feature  result in by far the most
accurate linear regression models 
   clustering  the performance of the clustering was
measured using the ratio of cluster diameter to cluster spread 
where cluster diameter was the average distance between each
pair of points in a cluster  and cluster spread was the average
distance between each pair of cluster centroids 

fig     k means clustering of joints from the cmu data set  k       features
include position and joint hierarchy

fig    
comparison of true skeleton pose during an animation and the
corresponding pose computed from our learning algorithm  visualized in
maya  a  frame    of an animation from a bvh file in the cmu dataset 
b  frame    of a the learned animation computed for the same skeleton    
of the joints  highlighted in white  move along the z direction in the shape of
a human  the   feet joints    on each foot  alternate back and forth  but with
a smaller stride than in the ground truth  there appears to be one long arm
swinging back and forth 

data type
range spread
all features
      
absolute position
      
all features   animation curve       
animation curve
      
our initial method used only the absolute position of
the joints to compute clusters  we found  however  that with
the full set of input features described in section iii b  our
clusters were much more precise  additionally  we attempted
clustering by animation curve alone  but found that these
clusters were not accurate or useful 
   cross validation  to analyze our system as a whole we
implemented   fold cross validation  we split the data      
for training testing sets respectively  using the difference
between output animation curve  calculated using linear
regression  and the known animation sequence as the distance
metric  we again found that using the feature set described
but excluding animation curves was the most effective for our
algorithm 
feature set
all features
all features   animation curve
animation curve
vi 

average error
       
       
       

f uture w ork

there is much that can be done to improve and test our
learning algorithms  we first hope to train our system on a
more diverse data set  the skeletons we found currently share

fi 

fig     animation curves computed from linear regression on a test skeleton taken from the cmu data set  this test skeleton is the same skeleton whose true
animation curves are figure  

similar joint and parenting structure  but we would like our
system to be robust to widely varying rig structures 
both k means clustering and linear regression do not converge reliably  k means clustering must be initialized with the
same set of joints in order to converge on the same clusters 
since the animation data is periodic  we could add features
from the frequency domain to cluster over  this may improve
convergence of the clustering with random initialization  linear regression requires hand tuning parameters in order to get
the most reasonable result 
we should use cross correlation to determine the time
lag between the animation curves and then offset the curves
appropriately before running linear regression  we will likely
get much stronger signals in our result if we include that step
in the preprocessing 

choice  there are several interesting refinements to this system 
from more precise clustering to cross correlation  that we hope
to address in future iterations of this project 
acknowledgment
the authors would like to thank sam corbett davies  nikhil
parthasarthy  the cs     staff  and professor andrew ng 
r eferences
   

   

   

vii  c onclusion
in this paper we proposed an example based motion synthesis technique for arbitrary rigs  we utilize k means clustering
to categorize the joints  then perform linear regression within
each cluster to generate an appropriate animation curve for
an input joint  by breaking hierarchical rigs into individual
joints  this algorithm is able to generate animation data for any
rig configuration  our approach allows users without access
to expensive motion capture hardware to utilize free on line
motion capture data in order to animate an input rig of their

   

   

c  k  liu and z  popovic  synthesis of complex dynamic character
motion from simple animations  in proceedings of the   th annual
conference on computer graphics and interactive techniques  ser 
siggraph     new york  ny  usa  acm        pp         
p  hamalainen  s  eriksson  e  tanskanen  v  kyrki  and j  lehtinen 
online motion synthesis using sequential monte carlo  acm trans 
graph   vol      no     pp             jul       
l  kovar  m  gleicher  and f  pighin  motion graphs  in proceedings
of the   th annual conference on computer graphics and interactive
techniques  ser  siggraph     new york  ny  usa  acm       
pp         
j  lee  j  chai  p  s  a  reitsma  j  k  hodgins  and n  s  pollard 
interactive control of avatars animated with human motion data  in
proceedings of the   th annual conference on computer graphics and
interactive techniques  ser  siggraph     new york  ny  usa 
acm        pp         
b  thuraisingham  b  prabhakaran  l  khan  and k  w  hamlen 
a database inference controller for  d motion capture databases 
international journal of information security and privacy  ijisp  
      forthcoming 

fi 

   
   

   

   

    

    

    

    

    
    

    

    

    

o  arikan and d  a  forsyth  interactive motion generation from
examples  acm trans  graph   vol      no     pp          jul       
o  arikan  d  a  forsyth  and j  f  obrien  motion synthesis from
annotations  in acm siggraph      papers  ser  siggraph    
new york  ny  usa  acm        pp         
p  f  felzenszwalb and d  p  huttenlocher  pictorial structures for
object recognition  int  j  comput  vision  vol      no     pp       
jan       
m  pawan kumar  p  h  torr  and a  zisserman  learning layered
motion segmentations of video  int  j  comput  vision  vol      no    
pp          mar       
m  c  burl  m  weber  and p  perona  a probabilistic approach to
object recognition using local photometry and global geometry  in
proceedings of the  th european conference on computer visionvolume ii   volume ii  ser  eccv     london  uk  uk  springerverlag        pp         
a  fod  m  j  mataricacute  and o  c  jenkins  automated derivation
of primitives for movement classification  autonomous robots  vol     
no     pp             
j  barbic  a  safonova  j  y  pan  c  faloutsos  j  k  hodgins  and
n  s  pollard  segmenting motion capture data into distinct behaviors 
in proceedings of graphics interface       ser  gi     school of
computer science  university of waterloo  waterloo  ontario  canada 
canadian human computer communications society        pp     
    
t  kwon and s  y  shin  motion modeling for on line locomotion
synthesis  in proceedings of the      acm siggraph eurographics
symposium on computer animation  ser  sca     new york  ny 
usa  acm        pp       
cmu graphics lab motion capture database   online   available 
http   http   mocap cs cmu edu 
a 
wetzler 
linear
blend
skinning 
 online  
available 
http   www mathworks com matlabcentral fileexchange      linear blend skinning content loadbvh m
j 
rebello 
linear
regression
with
multiple
variables
without
regularization 
 online  
available 
http   www mathworks com matlabcentral fileexchange      linear regression with multiple variables without regularization 
q  wang  dynamic time warping  dtw    online   available 
http   www mathworks com matlabcentral fileexchange      dynamic time warpingdtwk  h  lee  m  g  choi  and j  lee  motion patches  building blocks for
virtual environments annotated with motion data  acm trans  graph  
vol      no     pp          jul       

fi