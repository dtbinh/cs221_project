 d model classification using convolutional neural network
junyoung gwak
stanford
jgwak cs stanford edu

abstract

our work  we let the network learn the features by training
a  d convolutional neural network 
there exists many works which utilizes convolutional
neural network to classify  d images        our work
shares similar motivation and network structure  however 
our input is in  d and we convolute over  d space to directly extract  d features 
wu et al     approached this problem using a generative model based on a probability distribution using convolutional deep belief net  our approach is a discriminative
model learning a direct mapping from voxel to classification 
for analysis of the network  we plotted the activation and
the gradient of channel with respect to data     our work
verified that the same technique can be applied to visualize
 d convolutaionl networks 

our goal is to classify  d models directly using convolutional neural network  most of existing approaches rely
on a set of human engineered features  we use  d convolutional neural network to let the network learn the features
over  d space to minimize classification error  we trained
and tested over shapenet dataset with data augmentation
by applying random transformations  we made various visual analysis to find out what the network has learned  we
extended our work to extract additional information such as
pose of the  d model 

   introduction
consider a  d model in figure    just with a quick
glimpse of it  we can accurately classify that this is a sofa 
this ability to infer the class of a  d model is important
for various problems interacting with the real world such as
autonomous driving  likewise  the class of the  d model
provides cues to pose  grasping  affordance  and other properties  for similar reasons  object classification of a  d image has traditionally been one of the most tackled problems
in computer vision  however  there has been a little effort
to classify a  d model as a whole  this is partially due
to lack of training data and difficulty of building intuitive
hand engineered features on  d space 
in this paper  we prepared training data using
shapenet    dataset   a richly annotated  large scale dataset
of  d shapes   along with data augmentation by applying
random transformations to the model on the fly  moreover 
we trained a  d convolutional neural network to let the network learn the best features over  d space to classify  d
models  then  we made a thorough analysis of the network
to investigate what the network has learned  additionally 
we extended this work by extracting additional semantic information of the model such as pose 

   method overview
     input data
one of the challenges of training a neural network is in
preparing a large amount of input data  our initial concern has been lifted with advent of shapenet      richlyannotated  large scale dataset of  d shapes  among   million models in it  we used a part of the shapenetcore    
common daily categories with more than        d models 
since we train the network over many iterations  we need
a lot more data than shapenetcore  therefore  we virtually
augment the dataset by applying random transformation as
followed 


vtransformed

cos r 
 sin r 
 
  
 


sin r    tx
cos r    ty 
v
 
  tz 
 
  s

where v is a matrix of vertices in homogeneous space 
r is degree of yaw rotation  tx  ty  tz is degree of x  y  z
translation  and s is scale of the transformed model  we
randomly chose the parameters above to augment the data 
our rotation ranges from  to   translation from   to     

     related work
some of the previous works involve classification of  d
objects over intuitive hand engineered features           in
 

fi a   d model

 b  voxels

 c  data augmented voxels

figure    sample input data pipeline  we first augment the input data by applying random transformation to the  d model 
then  we voxelize the augmented model to fix the input shape of the neural network 
layer
input
conv 
pool 
conv 
pool 
conv 
pool 
conv 
pool 
fc 
fc 
softmax 

filter shape
                
         
                 
         
                  
         
                   
         
      
      

output shape
                   
                    
                    
                    
                 
                  
                  
                  
                  
          
          
        

table    detailed network configuration  please note that
relu and dropout layers always follows after convolutional and fully connected layers 

and scale from     to      a sample input data with data
augmentation can be found in figure   
finally  neural network requires the input data to be
in fixed shape  therefore  mesh representation of the  d
model should be converted to a fixed sized data without loss
of  d information of the model  therefore  we convert the
 d model to a single channel binary voxel 

      d convolutional neural network configuration
from an input  d model  we wish to learn the correct
class  we train the network in following two steps  first  we
pre process the data by applying random transformation to
the mesh and then voxelize it  then  we train the network by
updating weight based on the gradient of the classification
cost with respect to each parameter 
our network is composed with the following layers 

    d convolutional layer   d convolutional layer convolutes the data by computing local weighted sum using learned weight  it takes input of size  batch size 
channel size  x size  y size  z size  and convolutes with
filter of size  filter size  input channel size  filter x
size  filter y size  filter z size   the convolutional layer
learns the  d feature to be used for classification 
   rectified linear unit relu   relu layer applies a
simple activation function  f  x    max    x  where
x is the input to a neuron  this rectifier introduces
non linearity with very efficient computation and simple gradient propagation 
   pooling  pooling layer reduces the size of the data by
choosing the largest value of the pool  this layer allows us to reduce the size of the input and to learn abstract features efficiently 
   fully connected layer fc   fully connected layer
takes all neurons in the previous layer and connects
it to every single neuron it has  this layer allows highlevel reasoning of low level local features learned from
preceding layers 
   dropout layer  dropout layer prevents overfitting by
dropping out some unit activations in a given layer by
setting them to zero 
   softmax  softmax regression is a generalization of logistic regression to the case where we want to handle
multiple classes  this final layer allows us to compute
the regularized likelihood of each class based on a linear classifier 
all of the layers above are put together to build a  d
classification network  please check table   for details of
the network configuration 

fifigure    training loss vs number of iterations 
figure    confusion matrix of the classification results 

     training the network
given the training data and the network configuration
above  we train the network to classify voxels  we update
weights of each convolutional and fully connected layer using batch gradient descent with momentum  following is
the formulation of the update where n is the size of the
batch   is the learning rate   is the momentum rate   w
is the momentum  and w is the weight 
 w    

n
x

 qi  w       w

i  

w    w     w
while training  we tracked the change of training loss
over number of training iterations  then  we adaptively
lowered the learning rate whenever the loss stopped decreasing  for example  in figure    we lowered the training
rate by      at       iterations to decrease the training loss
further down 

   result
we achieved test accuracy of         please check figure   for confusion matrix of the classification result  as a
baseline of this work  we can compare the classification accuracy with that of wu et al      who tried classification on a
smaller set of shapenet  wu et al  achieved total accuracy
of       on    classes while ours achieved test accuracy
of        on    classes  we achieved better result since
our network learns discriminative model of class probability given voxels while wu et al  learns generative model of
the voxels and prior of the data to produce class likelihood 
from the confusion matrix  we observed two properties
of the network  first  it prefers to output the classes with

more models  this is due to a bias in the number of training
data in each class that the softmax has learned  second  it
prefers to output the classes with simple shape  the classes
that misleads others tend to have simple shape  for example  the network tends to output cabinet or speaker which
usually has a simple blob over classes with complex shape
such as airplane or car 
we made further analysis of the network with various
approaches to visualize what the network has learned 

     analysis    activation output
we plotted the output of relu layers as voxel to visualize the activation 
please check figure   for some visualization of convolutional channel activations  we can observe that initial convolutional layers perform basic filtering operations  extracting simple shapes such as horizontal or vertical shapes 

     analysis    gradient of activation
next  we plotted the gradient of channel activation with
respect to the input data  this will visualize which part of
the input contributed to the activation of a specific channel 
please check figure   for some sample gradient of channel with respect to input data  first row  channel    of convolutional layer    seems to have learned leg  similarly 
channel     of convolutional layer   seems to have learned
wheel of a vehicle  we can observe that deeper convolutional layers tend to learn high level concepts of the  d objects 

     analysis    inputs activating a channel
finally  we took average of    models that has highest
activation on each channel  this will again visualize the

fiinput

input

conv  channel  

conv  channel  

conv  channel  

conv  ch 

conv  ch 

conv  ch   

conv  ch  

conv  ch   

conv  ch  

conv  ch   

conv  ch  

conv  ch   

conv  channel  

figure    average of top    input that activates the channel

figure    channel activations

such as car  desk  and guitar 
through all of the analysis above  we found that the network learns simple filtering operations at the beginning of
the convolutional layers and some high level concept of the
 d models at the end of the convolutional layers 

   model pose estimation
conv 
ch   
leg

conv 
ch    
wheel
figure    gradient of channel with respect to input data

as an extension of this work  we explored the possibility of the network extracting further information about the
model  specifically  we explored the possibility of our network estimating the pose of the  d model along with the
class 
in our data augmentation step in section      we showed
that a random yaw rotation has been applied to all of the
training and testing data  we discretized the degree of rotation into   bins from  to   such discretized bins along
with class is used as a new label of the data 
we achieved this goal by adding another fully connected
layer and softmax layer at the end of the network  the second softmax layer classifies model pose into   bins as defined above  then  we defined the training cost as following 
total cost   classification cost     pose cost

high level shape of what the channel has learned 
as shown in figure    channel   learned interesting highlevel shapes  some learned dominant shape such as circle 
rod  and rectangle plate  others learned class specific shape

where         the network structure and all other training
sequences stay the same 
for this experiment  we achieved pose accuracy of
        as shown in figure    most of the confusion came

fi   

   

   

   

figure    confusion matrix of model pose estimation 
   


from pose nearby or     apart  this is a promising result
suggesting the possibility of the network to extract various
semantic data of the model in addition to its class 

   conclusion
we proposed a method to classify  d models as a whole
using  d convolutional neural network  we used shapenet
dataset along with data augmentation to prepare enough
data to train the network over long iterations  we built and
trained a network to achieve a reasonable test accuracy on
our dataset  we made a thorough analysis on the network
to investigate what the network learned  we found that the
beginning convolutional layers tend to do simple filtering
operations while higher convolutional layers tend to make
high level understanding of the  d model  moreover  we
explored the possibility of the network to extract useful semantic data on top of model class from the input  d model 

acknowledgement
this project is part of a research at computational
vision and geometry lab  stanford  the author received advice about design and code from christopher
choy chrischoy ai   a ph d  student in the lab  this
project is also a joint project with cs     i allocated advanced analysis of the network and pose estimation of the
 d model for cs    

references
    i  atmosukarto and l  g  shapiro  a learning approach to
 d object representation for classification  in structural  syntactic  and statistical pattern recognition  pages        
springer         
    a  x  chang  t  funkhouser  l  guibas  p  hanrahan 
q  huang  z  li  s  savarese  m  savva  s  song  h  su 
j  xiao  l  yi  and f  yu  shapenet  an information rich

   

 d model repository  technical report arxiv           
 cs gr   stanford university  princeton university  toyota technological institute at chicago         
m  a  kassimi  o  el beqqali  s  mohamed  and f  morocco 
 d model classification and retrieval based on semantic and
ontology         
a  krizhevsky  i  sutskever  and g  e  hinton  imagenet classification with deep convolutional neural networks  in advances in neural information processing systems  pages     
             
c  szegedy  w  liu  y  jia  p  sermanet  s  reed  d  anguelov 
d  erhan  v  vanhoucke  and a  rabinovich  going deeper
with convolutions  arxiv preprint arxiv                   
a  teichman  j  levinson  and s  thrun  towards  d object
recognition via classification of arbitrary object tracks  in
robotics and automation  icra        ieee international
conference on  pages           ieee         
z  wu  s  song  a  khosla  f  yu  l  zhang  x  tang  and
j  xiao   d shapenets  a deep representation for volumetric
shapes  in proceedings of the ieee conference on computer
vision and pattern recognition  pages                     
j  yosinski  j  clune  a  nguyen  t  fuchs  and h  lipson  understanding neural networks through deep visualization  arxiv
preprint arxiv                    

fi