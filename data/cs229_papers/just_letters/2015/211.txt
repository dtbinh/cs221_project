predicting time of peak foreign exchange rates
charles mulemi  lucio dery
   abstract
this paper explores various machine learning models of predicting the day foreign exchange rates peak in a given
window  we obtained non trivial results which we can likely improve upon by obtaining more data  domain knowledge
and trying out more complicated algorithms that account for more randomness in our data 
   introduction
as international students  we often have to make international transactions involving more than one monetary
currency due to fluctuations in foreign exchange rates  it is hard to foresee the value we get for the money we send
to and from home  our motivation was to derive a model that would predict the time of the week the exchange rate
would peak so that we could make those transactions  consequently we decided to build a machine learning model
that would mine from a list of previously observed econometric features and predict when the foreign exchange rate
would peak on a given week  our inputs were the historical exchange rate time series between two currencies  as well
other econometric indicators  we then use a support vector machine  svm  to make predictions and output the
day in the following week when the exchange rate would be at its maximum value  this paper explains the various
approaches we took to build our model and the results we obtained 
   related work
in our research we came across interesting attempts at solving similar problems in finance  osuna  freund and
federico  worked on training support vector machines on foreign exchange time series data  wei  nakamori  and
wang  similarly used support vector machines to predict weekly movements in stock markets their paper points
out that the complexity of the finance markets necessitated the use of more than one model moreover  the paper
establishes preference of svr over other training models since it minimizes structural risk as opposed to empirical
error risk  another interesting approach at predicting currency uses a neuro fuzzy model  the model is a hybrid
between neural networks and fuzzy logic  this is meant to better account with the inherent non linearities in the
variables used in such models 
   data
we where able to obtain    years       days  of kenyan shilling vs us
dollar exchange rate from the world bank forex data bank  we also acquired
statistics on the following macro economic indicators  purchasing power parity 
inflation rates  interest rates  external debt and balance of goods and services
for the unites states and kenya the same period  our choice of these features
was based on joseph finnertys paper on foreign exchange forecasting    the
exchange rate data was daily whilst the economic indicators were annual  we
decided to overcome the differences in the granularity of the data sets by replicating each annual entry of an economic indicator     times  we split the data
into two sets      was used as the training set whilst the remaining     we
used as our cross validation set  figure   shows the variation of the exchange
rate with time  the data varies wildly on both local and global scales  making
predicting peak time in a given window a non trivial problem 

figure    time series 

   methods
in order to solve our forecasting problem  we applied various machine learning algorithms and techniques to the
problem  before we begun using the procedures we are about to discuss  we had to decide on the best way to represent
our data before feeding it into our algorithms  we structured our problem as a supervised learning problem  however 
since the time series data does not come explicitly with the desired labels we had to decide on the how to represent
our data 

 

fi    sliding window representation
for this representation we split the exchange rate data into feature vectors of    day  dimensions using a sliding
window through the data that advanced by one day after each iteration  our target variable for each feature vector
was the exchange rate for the day after the end of the window  under this representation  our goal was  given a
feature vector of the exchange rates for the current week  to predict the exchange rates for the next week and output
the day on which the maximum predicted exchange rate falls  we achieved this using linear regression and locally
weighted linear regression models 

linear regression
linear regression makes a transformation from rn r using the coefficients  which can be learned by minimizing
a cost function j   
let x i  be our feature vector of exchange rates for the ith training example and y  i  be the target variable  exchange
rate of the next day    for our problem x i   r  and y  i   r
our prediction of the exchange rate for the next day is 
h   t x i 
and our cost function is the square error
j    

 
 

p

 h  x i     y i   

we obtained  from the normal equations
    x t x   x t y

locally weighted linear regression
this approach is similar to linear regression described above  differing only in terms of the cost function  for this
we have the hypothesis 
h     x i 
and the cost function
j    

 
 

p

wi  h  x i     y i   

where the weights w i  are
w i    exp

kxx i  k 
 

 i 
m

our parameters  and  are tuning parameters   captures the similarity between the feature vector we are
trying to predict for and the training example x i     on the other hand capture the closeness  in terms of date time 
between the feature vector under consideration and the training example  we again use the normal equation to solve
for 
    x t w x   x t w y
w is the diagonal matrix of wi s 

    weekly representation
we decided on a second format for our data more suited as input to multi class classification algorithms  in this
representation  the feature vectors we derived from the exchange rate series were the rates over a week  thus our
     data points reduced to              feature vectors  our target variable for week  i   y  i  was set to the day
of the peak exchange rate for week  i       we represented days in the week as numbers such that y  i          with
monday corresponding to   and so on  we fed the above representation to the following multi class classification
algorithms 

 

fimulti class support vector regression
support vector regression was developed by vapnik    with this we try to find the optimal hyper plane that
separates the data points into the required classes  given our data of m training examples  x i    y  i     i          m
and y  i          we describe a one versus all multi class l  regularized svm below  for our svm we seek 
pm
p 
minwl  i    l   wlt wl   c i   i
subject to
wyti xi  wlt xi  eli  i i            m
where
 
eli

 

   if yi   l
   otherwise

the parameter c is our regularization parameter which we use to tweak our separating hyper plane
our decision function is
ouputclass   max l           wlt x
where x is our feature vector to be classified 
for svm regression  we relied on liblinear  matlab package and fitcecoc function in the matlab statistics and
machine learning toolbox 

softmax regression
softmax is a generalized linear model  glm  for multi class classification problems  it is a multi dimensional
analogue of logistic regression  since our decision classes  days  are mutually exclusive  we chose this instead of using
k binary classifications  given the same data set we saw above for svm  softmax seeks  which maximizes
pm p 
 
 i 
j      m
  j  log p y  i    j  x i    
i  
j     y
where   r x  and        so as to avoid the need for a parameter to account for over fitting  the decision function 
once  has been determined is
maxj log p y  i    j  x i      
   results and discussion

best rmse

linear
regression
     

locally
weighted lr
     

softmax
    

svm
 linear 
     

svm
 gaussian 
     

svm poly 
     

table     model prediction performance rmse
we did not perform any dimensionality reduction on our feature set  since our feature vectors live in a relatively
low dimensional space  we would not have made much gain from this both in terms of run time improvements and
inferences about the data  our performance metrics were rmse  root mean square error   accuracy and average
error 

    regressions
our first approach to the problem of peak exchange rate time prediction was to use the sliding window representation and perform linear regression  in order to predict for a feature  we used linear regression to generate  
points corresponding to the next weeks predicted exchange rates and found the day on which the peak fell  as
can be seen from table    we obtained a rmse of       for predictions on our testing set  though not a desirable
 

fiperformance  the fact that this is less than        days  in week           assured us that the  from linear regression
was not tending towards a random process  a plot of the confusion matrix revealed a maximum per class accuracy
of roughly      this occurred for classes   and    a look at the data revealed that these were the most dominant
classes in our training data set and as such  a lot more of our predictions were for these classes 
after performing linear regression  locally weighted linear regression was used to try to capture more of the
structure of the time series data since the lr confusion matrix figure   suggests under fitting of the data 
as already described  the tuning parameters  and  were used
to capture structure   accounts for how similar the current example is to the feature set to be predicted and  temporal closeness of
the example set and feature set respectively  as can be seen from
table   using this approach gave us a    reduction in the rmse
we had for logistic regression  the effect of the introduction of
these parameters can better be understood from figure    it can be
noticed from figure   that generally  for a fixed    as  increases 
the percentage accuracy of locally weighted lr increases  this
agrees with our intuition that points closer in time to our current
feature example should give a better sense of the trend of the data
around that example and thus lead to better predictions of peak
day  increasing  also increased performance  this seemed initially counter intuitive since this meant that giving more weight to
training examples more similar to the current feature set reduced
performance  to rationalize this  we realized that though two features vectors might be similar  the overall trend of the data around
them increasing  decreasing or stable   which is what informs the
figure    linear r  confusion matrix
peak day  are not correlated  thus  giving greater weight  lowering
   to these examples reduces performance
though we had an improved accuracy  our average error of prediction went up from       to       this indicates
that though locally weighted linear regression captured more of the trend in the data  the predicted points were
generally translated vertically by a larger amount as relative to the actual values 

best average error

linear regression
     
table     average error of regressions

locally weighted lr
    

    multi class classification
using the weekly representation of the data already discussed 
we first proceeded to perform multi class support vector regression  we tweaked our algorithm by vary the multiclassification technique  trying out different kernels and using l  regularization to try
to optimize the separating hyper plane 
the techniques we explored were one vrs all  all pairs and binary
complete approaches   
in trying out different kernels  we tried to change the dimensionality of the space that our feature vectors live in  we tried gaussian 
linear and polynomial kernels the table below shows the results
for each type of kernel under each classification technique 
kernel
linear
linear
linear
gaussian
gaussian
gaussian
polynomial
polynomial

technique
all pairs
one vrs all
binary complete
one vrs all
all pairs
binary complete
one vrs all
all pairs
 

figure    tau vs gamma vs percent accuracy
best rmse
     
     
     
     
     
     
     
     

fitable     best performance svm under l  regularization
the fact that the best performing kernel was the linear kernel
informs us that the data does not have much hidden high dimensional structure  the all pairs technique consistently
outperformed other techniques given the same kernel  we believe that the reason for this follows similarly from why
linear regression performed well on classes      and    since these are the classes with the highest frequency  any
binary classifier of either class against the other classes will tend to give a larger number of positive as against
negative predictions  figure   the confusion matrix for the linear kernel  all pairs svm evidences this hypothesis 
majority of the test samples were classified into day      and    we reasoned that using ordinary down sampling
technique to correct the imbalance could eliminate examples key to capturing the time series trend  we therefore
settled with these results  after determining that a linear  all pairs classifier worked best  we proceed to tune this
by varying the regularization parameter c  figure   shows our results for this experiment  we found that tweaking
the decision boundary  to make it less sensitive to outliers  by increasing the box constraint enhanced performance
up till c     and then performance plateaus 
using support vector regression with the techniques and tuned parameters described  we obtained a      increase
in percentage accuracy over locally weighted linear regression 
our final experiment was with softmax regression using the weekly representation  with this approach  we could not
get any improvement upon our previous svr approach  we obtained a rmse of       which  though an improvement
on linear regression is outperformed by locally weighted linear regression 

 a  all pairs  l  regularized linear svm confusion matrix

 b  box constraint  c vs percentage accuracy

    feature selection
generally  we found that including the macro economic indicators mentioned in the data section tended to increase
the rmse  this poor performance can be attributed to our approach to fix the mismatch in the granularity of the
time series and the economic indicators  replicating the annual values to obtain weekly and daily data introduced
correlations that did previously exist in the data and which masked the time series trends 
proceeding notwithstanding this limitation and using forward search feature selection  we found that the macro
economic indicators that produced the best results were inflation rate and balance of goods and services  we had
an rmse of of       when we run forward search using our best performing svr 
   conclusion
the nature of our problem was inherently difficult  consistent with what we had observed from related work at
finance prediction  our best performing mode was the svm 
more approaches that we intend to explore is to use an ensemble of classifiers that work in tandem as opposed
to separate prediction models  more effort can also be directed into feature selection in order to find econometric
variables that have the highest correlation with exchange rate data and also have daily granularity  overall  we
conclude that though rmse of       is not an exciting result  it is promising since it means we are not modeling
randomness 
 

fi   references
   finnerty  joseph e  foreign exchange forecasting and leading economic indicators  n p   n p   n d  bebr 
web     nov       
    v  n  vapnik  the nature of statistical learning theory  new york  ny  usa  springer verlag new york 
inc        
    journal of machine learning research                     and submitted       published       liblinear  a library for large linear classification   n d    n  pag  web     dec       
    http   www mathworks com help stats fitcecoc html
    osuna  edgar  robert freund  and federico girosi  an improved training algorithm for support vector
machines  neural networks for signal processing        vii  proceedings of the      ieee workshop  ieee 
     
    huang  wei  yoshiteru nakamori  and shou yang wang  forecasting stock market movement direction with
support vector machine  computers   operations research                         
   lin  chin shien  et al  a new approach to modeling early warning systems for currency crises  can a
machine learning fuzzy expert system predict the currency crises effectively   journal of international money
and finance                        

 

fi