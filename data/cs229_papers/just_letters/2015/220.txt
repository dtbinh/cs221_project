classification of book genres by cover and title
holly chiang  yifan ge  and connie wu 

abstract this paper discusses the classification of
books purely based on cover image and title  without
prior knowledge or context of author and origin  several
methods were implemented to assess the ability to distinguish books based on only these two characteristics  first
we used a color based distribution approach  then we
implemented transfer learning with convolutional neural
networks on the cover image along with natural language
processing on the title text  we found that image and text
modalities yielded similar accuracy which indicate that
we have reached a certain threshold in distinguishing
between the genres that we have defined  this was
confirmed by the accuracy being quite close to the human
oracle accuracy 

i  introduction
there is a saying that you shouldnt judge a book by
its cover  but for most readers the cover forms their first
impression of a book  it has been shown that the cover
design has a significant impact on the sales of a book 
with book sales often shooting up after a change in
design  our goal is to create a model that can determine
how representative a cover is of its genre  as a method
to later evaluate if the more a book cover resembles
others in its genre  the higher the book sales 
we fed our algorithm the cover image and the covers
title  which often are what book consumers look at
first whether it is in store or online  without any other
information such as prior customer purchases or similar
book associations  we want to guess the genre purely
based on these two characteristics  surprisingly it is
very difficult for even a human to distinguish between
books of different categories  especially if the title is
vague or if the book cover does not allow for much
inference 
the motivation for solving this problem is for designing covers of new books that want to come onto
market with a relatively unknown author  this study
would show what types of features concerning covers
and titles are most important for determining a books
genre  and subsequently how a consumer perceives
such a book 
we classify books into five genres  business  fantasy  history  science fiction  and romance such as in

fig     we classify book covers into five genres  business  fantasy  history  science fiction  and romance

figure   by using a multi class svm  these categories
are large enough to allow us to easily extract large
training and test sets and have covers distinct enough
that our methods should have some success 
ii  r elated w ork
there were no previous attempts that we could find
aimed at tackling our particular problem of classifying
novels by genres  however one work that was tangentially similar was classifying paintings by artistic genre      zujovic et al  tackled the problem by
extracting features from gray scale and color images 
texture and edge features were extracted from gray
scale images using steerable filter decomposition and
the canny edge detector  color image features were
extracted using an   bin histogram for each of the hsv
values  they then tried multiple different classifiers
including naive bayes  k nearest neighbors with   and
   nearest neighbors  svm  a neural network with  
hidden layers  and a j   decision tree  the strong point
of this approach is they were able to try a wide variety
of classifiers  with accuracy ranging from      to      
the weakness of the approach lies in the fact that the
features extracted using steerable filter decomposition
included edge information  constraining their results 
similar to this approach  we tried binning the hsv
histogram and finding the image complexity in terms
of number of edges 
to extract features from book covers  we also looked
into previous studies on measuring image complexity 
we think it would be a good indicator of genres  image

ficomplexity is best represented by compression level 
however  compression level is costly to compute  on
the other hand  spatial information displays a strong
correlation with compression level      yu discussed
how the mean  rms  and standard deviation of spatial
information relate to the image complexity 
in conjunction  recent studies have shown that
generic image descriptors extracted from convolutional
neural networks are powerful when used in combination with svm or softmax classifiers in visual recognition tasks      earlier layers have general features
such as color blobs and edge detectors whereas later
layer features are more specific to the dataset such as
distinguishing unique characteristics of objects in the
same category     this is why we chose to use a neural
network trained on imagenet  since it covers a variety
of images from a large database 
finally  we looked into correlating a novels title to
its genre  originally we wanted to find the conditional
probability a book belonged to each genre given a
particular word  but quickly realized that titles tended to
be unique  with many words appearing only once across
the entire data set  to address this  we instead used
word vec     pretrained using the skip gram model
on the google news dataset  word vec was able to
return metrics even for most of the unique words in
the dataset  its main drawback was that the metrics
it returned were not specifically trained to tell how
indicative a word was of a genre 
iii  dataset and f eatures
to obtain the data set  we looked into several options 
the google books api  google image search  and
the openlibrary api  each of these options had its
advantages and drawbacks  the google books website
has higher quality images than the others  however  it
requires google account login information and its api
is more geared towards accessing the users own book
collection  when we attempted to collect book cover
images from google image search  we found the results
returned were quite inconsistent  especially the quality
and size  this had the potential to cause issues later
on  finally  we decided to use openlibrarys api  its
api is well documented and maintained  compatibility
with restful api makes openlibrarys data very
accessible with python urllib function calls  it also
provides an interface to obtain a list of books by genre 
however  since openlibrary book cover images are
user uploaded  the quality of the images are very inconsistent  also  all the images are relatively small with

         pixels  since the features we extract dont
depend on the details  small images mostly wont hurt
our performance but will improve our processing speed 
for images with blank or no useful information  we
developed some pre processing algorithms to improve
the quality of our dataset  which will be discussed in
detail in that subsection 
our dataset obtained from openlibrary org consists
of a total of      images from the five genres  business  fantasy  history  science fiction  and romance 
the assumption we made here was that these genres
have small overlaps and are relatively easy to differentiate from their covers  among these       book cover
images  we have       training images and     test
images for each genre 
a  pre processing
among the images we obtained from openlibrary 
there were some images with single color blocks or
were extremely low resolution with minimal text  since
our project is focused on using cover images to extract information about the genre  pure text covers do
not provide the requisite information  to improve the
dataset quality  we decided to research and implement
some pre processing algorithms to filter the original
dataset 
the image processing steps we used are listed in
order below 
   convert the image to gray scale
   use median filter to blue the image
   adaptive threshold to isolate features of an image
   compute the ratio between the number of thresholded pixels over the total pixel count
finally  we discarded images with thresholded pixel
counts less than     of the total image pixels  after tuning the parameter in the filter and adaptive
thresholding algorithm  we were able to successfully
distinguish low quality images from the dataset  an
example of processing three book covers are shown
in fig    and fig     in the example  we picked three
images where we want to discard  a and keep  b and
 c  notice that differentiating  b from  a is harder  we
accomplished this by aggressively using large median
filter blocks and picking the best threshold value 
b  imagenet
we have extracted features from a fully connected
fc   second to last  layer of a convolutional neural network model  pre trained on imagenet from krizhevsky
et al  as shown in figure        the neural network

fi a 

 b 

 c 

fig     original book cover images  a  is low quality
cover need to discard  b  and c  are good images need
to keep 

 a 

 b 

fig     a fully connected layer of the imagenet cnn

 c 

fig     processed book cover images  the threshold
pixel ratio for a   b  and c  are                and
        respectively

was trained on     million high resolution images in
the lsvrc      imagenet training set  each vector
has length of      features 
taking each image in the test set  we fed it as input
to the cnn and using the extracted fc  layer  we associated each of these vectors with the respective genre
label  after  we normalized the features by dividing
by the norm of the vector  then we stored the feature
vectors and their labels in a dictionary to be combined
with the extracted nlp features 
c  stanford nlp
we extracted features from book covers using two
different nlp classifiers as shown in figure    the
first classifier we used was the stanford nlp classifier 
which is a probabilistic softmax classifier  the features
it used were character n grams of size   to    the
prefixes and suffixes  and the string length bucketed
into         or    characters 
the second classifier used was word vec  which
produces word vectors from a text corpus using skipgram  we fed it the google news dataset and used the
extracted vector to find the distance of each word in
the title to a word representing each genre  we used

fig     nlp feature extraction

softmax to find the probability of the title belonging to
any genre category 
from each of the two classifiers  we made feature
vectors consisting of the probabilities of the title belonging to each of the five categories  and one hot
encoding for the overall predicted category 
d  image processing
intuitively  different genres are more likely to have
different color schemes  for example  science fiction
may have brighter colors  such as yellow and red 
whereas history tends to have a bland colors such as
beige and brown  thus  the first set of image features
we constructed were based on the color distribution
in hsv space  we converted images to hsv space
and binned the pixels into    color schemes  these
color schemes are defined by shattering of the image
spectrum shown in fig   a  then we used a   
threshold value to convert the histogram to a    bit onehot feature vector  the average histogram is visually
represented in fig     as can be seen  each histogram
has a different color pattern  the average histogram
of history genre is starkly different whereas the other
histograms are subtly distinct 
besides using the color histogram  we also looked
into the image complexity  image complexity can be

fiv  results

 a 

 b 

 c 

 d 

 e 

 f 

fig     hsv histogram  a  hsv color spectrum map 
b  business  c  fantasy  d  history  e  science fiction
and f  romance

best represented by the compression level of an image 
however  getting the compression level can be costly 
thats why we also looked into spatial information 
which has decent correlation with complexity    and
is much more efficient to calculate  hence  we added
spatial information vectors to the feature set 
iv  m ethods
a  multi class svm
after combining the features  we used a multi class
support vector machine to classify our training set 
it is similar to the binary classification  where we fit
classifiers to each class and look for the largest distance
from a hyper plane  however  now we use a one versusrest approach to determine which of the five categories
an image most belongs to  where the category that
outputs the highest distance will determine the category
of the image      the dual optimization problem for the
classifier is stated below     
 
min    yi y j k xi   x j     e  
a  
subject to y      

since we used supervised learning  we were able
to quantify the performance of our algorithm  it was
interesting to observe that the results were similar for
transfer learning on the cover image versus nlp on the
title text hovering around      this is quite close to
the average human trial accuracy we found which was
around     done on over    human subjects 
we originally tried three different approaches  image
processing  transfer learning  and nlp  however  we
found that when we tried to train with both the image
processing features and the transfer learning features
the overall accuracy went down  this was because all
the image processing features we came up with were
already incorporated in the neural net  and so adding in
the image processing features ended up decreasing the
power of the pre trained convolutional neural network 
therefore our best model combined the cnn and nlp
features since they had the most divergent features and
therefore best represent the span of features per image 
the results of the cnn and nlp combinations are
below 
table i  transfer learning
genres
business
fantasy
history
science fiction
romance
total

tp
   
   
   
  
   
   

fn
  
  
  
   
  
   

fp
  
   
  
  
  
   

precision
   
   
   
   
   
     

recall
   
   
   
   
   
     

table ii  natural language processing
genres
business
fantasy
history
science fiction
romance
total

tp
   
  
   
  
   
   

fn
  
   
  
   
  
   

fp
  
   
  
   
  
   

precision
   
   
   
   
   
     

recall
   
   
   
   
   
     

     c  i           n
k xi   x j     exp  xi  x j     
since science fiction and fantasy books are not necessarily separable  soft margins are incorporated  similarly  we used the radial basis function kernel since it
allows for higher dimensions in the data space allowing
for more flexibility in separating the data 

table iii  transfer learning and nlp
genres
business
fantasy
history
science fiction
romance
total

tp
   
   
   
  
   
   

fn
  
  
  
   
  
   

fp
  
  
  
  
  
   

precision
   
   
   
   
   
     

recall
   
   
   
   
   
     

fir eferences

fig     total accuracy of various methods

over all the genres  science fiction and fantasy consistently had the worst accuracy  as shown in the tables
i iii above  this can be explained by the similarity of
the covers and titles of books in the two genres  so that
many science fiction books are classified as fantasy and
vice versa  there is some difficulty in that many books
can be classified into more than one genre  and also
were genres that we did not address in our classifier 
along with svm  we also tried to use softmax to
train the model  after the training  the prediction from
softmax had       accuracy with transfer learning
features  this is lower than       result we got from
svm  thus  we decided to use svm in the final model 
vi  conclusions
the convolutional neural network features performed
the best out of the methods that were attempted due to
the fact that the original imagenet model was trained
on many more images than any of our other methods 
we were constrained from doing the same for the nlp
and image processing techniques from of resources
since training on such a set would take multiple gpus
over several weeks to train  therefore given access
to those resources we would like to train over the
entire image database with our specific task to see if
performance can be improved 
the openlibrary api json output also has related
keywords for each book in the database  given more
time  it would be interesting to investigate whether the
nlp portion of the project can be used on these words
to provide more context for book predictions 
ultimately we would like to see if the ability to
identify of the book is directly correlated with its sales 
that way this can help publishers and authors recognize
which book cover type most attracts new readers 

    zujovic  jana  et al  classifying paintings by artistic genre 
an analysis of features   classifiers  multimedia signal
processing        mmsp    ieee international workshop
on  ieee       
    yu  honghai  and stefan winkler  image complexity and
spatial information  quality of multimedia experience
 qomex        fifth international workshop on  ieee 
     
    razavian  ali s   et al  cnn features off the shelf  an
astounding baseline for recognition  computer vision and
pattern recognition workshops  cvprw        ieee conference on  ieee       
    yosinski  jason  et al  how transferable are features in deep
neural networks   advances in neural information processing systems       
    goldberg  yoav  and omer levy  word vec explained  deriving mikolov et al s negative sampling word embedding
method  arxiv preprint arxiv                  
    krizhevsky  alex  ilya sutskever  and geoffrey e  hinton 
imagenet classification with deep convolutional neural networks  advances in neural information processing systems 
     
    fan  rong en  et al  liblinear  a library for large linear
classification  the journal of machine learning research  
                  
    pedregosa  fabian  et al  scikit learn  machine learning in
python  the journal of machine learning research   
                  
    jia  yangqing  et al  caffe  convolutional architecture for fast
feature embedding  proceedings of the acm international
conference on multimedia  acm       

fi