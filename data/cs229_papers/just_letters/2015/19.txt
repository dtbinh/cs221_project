facial keypoint detection
ashkan esmaeili
aesmaili stanford edu

khashayar khosravi
khosravi stanford edu

abstract facial keypoint detection is one of the most
challenging and important topics  which is taken into
account in realm of machine learning and computer
vision  the importance originates in its applications  the
most three important of which are     face recognition 
which is of high importance in identification as an example 
   medical purposes and biomedical applications  medical
surgeries and psychiatric tests like analyzing facial
expressions could be carried out on patients using facial
detection     tracking faces in images and videos  these
days many applications have a built in feature of facial
analysis  in this report  first  we briefly introduce the topic
in section i  then we proceed with the explanation of the
methods and algorithms we used in section ii including our
proposed method pclwlr  then in section iii  we
mathematically formulate the pclwlr  and finally  we
report the achieved rmse values for different methods in
addition to providing plots illustrating keypoints detected
on images  we conclude in section v and summarize the
results 
keywords keypoint  target variables  edge detection 
pca  pclwlr  lwlr
i 

introduction

face recognition is one of the most famous vision challenges 
many authors have worked on this topic  while deep
convolutional networks known to be the state of art so far     
here we focus on machine learning algorithms with less
complexity that can also guarantee reasonable performance 
the dataset we are going to use is provided for kaggle
competition      the training data consists of      images of
size      pixels  each row in data matrix contains the
coordinates  x y positions  for    keypoints on the face  and in
addition  the image pixels  gray scale values  are stored in a
row ordered fashion in the same row of data  we could consider
each pixels value as a feature used for prediction  these pixel
values are integers in the interval          the    keypoints are
left eye center  right eye center 

seyedshabaddin mirjalili
ssmirjal stanford edu

left eye inner corner left eye outer corner right eye inner 
corner right eye outer corner left eyebrow inner end left e
yebrow outer end right eyebrow inner end right eyebrow o
uter end nose tip mouth left corner mouth right corner 
mouth center top lip 
and
mouth center bottom lip
respectively  in     authors utilized the mean patch algorithm 
as introduced in      to make accurate predictions about
left eye center and right eye center  in this report  however
we focus on prediction of the location of all    keypoints on
new images of peoples faces based on what we have learned
from the image dataset provided 
it is worth noting that some target variables are missing  only
about      images among      training images have no
missing target variables and this makes the matrix completion
a necessary step of prediction 
while there are many papers in literature working on matrix
completion           and      it turns out that mean imputation
on missing target variables leads to the least rmse  the first
and foremost challenge in image keypoints prediction is that 
there is plethora of features  pixels  which makes predictions
prone to overfitting  therefore  feature selection and dimension
reduction are necessary  moreover  there is complexity dealing
with this data due to large amount of variation in zooming 
translation  and rotation of photos  there are photos which are
far from standard caption making the prediction difficult like
the following images 

fig     sample image

fig     sample image

we notice that in figure   the eyes  lips  and mouth information
are missing  in figure    lips are hidden and the location of eyes
and nose are translated significantly from the standard mean
values and further the photo is taken in a rotated fashion 

fitherefore  we should look for a method which captures these
rotations and translations  we have observed many images in
kaggle dataset  most of them suffer from such problems  some
are quite blurred and ambiguous for which prediction may be
meaningless  yet  we did not purify the dataset from such
troublesome images and worked with the dataset including all
training photos 
ii 

algorithms

we have implemented several ideas for locating keypoints
with better precision  first  some methods are complex in terms
of runtime  at the beginning the nave idea is to consider each
pixel in the      as a feature and run the linear regression on
the entire pixels  which is complex and prone to overfitting
leading to a high rmse on test set  by adding a regularization
term and applying ridge regression  we can overcome the
overfitting issue  yet  we cannot implement more complex
methods according to the large dimension of features  we had
two ideas to reduce the dimension of features used to predict 
first idea is applying edge detection on the images  edges are
assumed to contain the most important information in images 
as a feature selection step and we confined predictions to the
boxes around keypoints to get rid of additional time consuming
calculations  in figures      and    one can find attempts we
have made for the edge detection and ridge regression on the
box around the keypoint for prediction  for edge detection
purpose  we have applied canny filter in matlab      this
performed better in comparison to the previous method 
however  there are still some flaws in this approach  the
sensitivity of the edge detection algorithm affects the quality of
prediction noticeably  in addition  it doesnt capture the
rotation  translation  and other characteristics of images 

fig     the original image

contain the most important characteristics in training set
images  to proceed  we project all images onto the new
subspace and then we can apply regression methods to obtain
better performance  we used the idea of locally weighted
linear regression  lwlr  to take similarities between images
into the account of prediction purpose  this helps us to
capture the important information in neighbor images  this idea
is exactly similar to the logic of k nearest neighbors  knn  and
lwlr  we will call the proposed method pclwlr in this
paper from now on  which stands for principal component
locally weighted linear regression  in the next section  we
provide the formulation and mathematical analysis of our
algorithm  the rmse values for each introduced methods will
be reported in the summary section 
iii 

pclwlr

in this section we explain how pclwlr works  let 
denote the matrix  which includes all training images as vectors
in its rows 
first  we extract the most important information of  via
singular value decomposition 
   

   

figure   shows the plot of eigenvalues of   as it illustrates  the
most important information of  is contained within the top    
initial singular vectors  as a sanity check  we also tried our
method for the first     singular values and the performance
was not changed remarkably  working with fewer singular
vectors is also more desirable in the sense of the computational
effort that we make for prediction  hence  we work with the
first     singular vectors from now on 

fig     edges of the image found
using the canny filter

fig     logarithm of singular values

similar to principal component regression  pcr       after
loading principal components  we project the data on the
singular vectors to find scores  as follows 
fig     the box of size    plotted around the left eye center which will be
used for the prediction  red dot shows the ground truth 

secondly  we have come up with the idea of applying pca to
retrieve the first few singular vectors that are assumed to

fi     
     
 

       for              
    
 
 

     
    

   

scores are predictors that we later on use for prediction in the
new space  after mapping images to the new space  we define
the euclidean distance between the test score vector and
training score vectors as follows 
 

  
  
   
 
   for             

   

then  we can apply the idea of locally weighted linear
regression after defining weights based on these distances  we
define the weight matrix  as a diagonal matrix as following 
   exp  


  
    

for            

   

here we normalized the distances by the maximum distance
value  there is a parameter called  in this definition which is
the bandwidth considered for neighbors in assigning the
weights  we have tuned for  via hold out cross validation as
in the following figure 

fig     rmse values obtained by hold out cross validation   is taken to be
     

the optimal value  is found to be     
note that  in order to find the best pair of     one needs to
alternatively optimize the value of     however after running
these iterations we found the values of                 close
to optimal 
finally  in order to make prediction of a target variable  we
use the following formula 
  
       


iv 

analysis

   

and simulations

to evaluate our performance  we use the   fold crossvalidation method on our training data  we divide the training
images into five subsets of equal size at random  then  each
time we train our method on   subsets and use the fifth subset
as the validation set  the provided metric for performance
evaluation is rmse  which is given as 


 
 
    
         


   

  

fig     rmse values obtained by hold out cross validation  here  is assumed
to be     

this gives the optimal value of          finally  we find the
parameter for prediction  using the following normal equation
             

   

note that we included a regularization term in order to maintain
a reasonable trade off between bias and variance  tuning for
the parameter  can be done via cross validation as the
following figure shows 

where  is the total number of non missing target variables of
the validation set  note that  since some of targets are missing
we do not consider them in the above formula  finally  we
report the mean of rmse values as our prediction error 
the following figure shows the rmse values we achieved for
each target variable under pclwlr 

fitable i 

  rmse values
methods

rmse

simple linear regression

    

ridge regression

    

edge detection   box
finding   lwlr

    

pclwlr

    

for better visual understanding  in the following images the
keypoints predicted using pclwlr are shown 

fig     rmse values for different keypoints

as mentioned earlier  for better precision the error values are
found using   fold cross validation  we also used
bootstrapping to evaluate the confidence intervals for our
estimated error values and have found out that the final rmse
of other methods fall outside the confidence interval of
pclwlr 
the following table shows the average rmse of different
methods when applied to all    target variables 
rmse of the proposed pclwlr method on the left eye center
is equal to         and on the right eye center is equal to        
which
gives
us
the
mean
rmse
of
 
 
on
the
first
two
keypoints 
                             
this shows a great improvement on the value reported in     
where the authors were able to obtain the error equals to       
on the validation set 

fig     predicted and true keypoints on a sample image  red and blue points
are ground truth and our predictions respectively 

fig     predicted and true keypoints on a sample image  red and blue points
are ground truth and our prediction respectively 

fithat can be implemented is support vector regression  svr  
deep learning methods can also be applied to extract higher
level features for the prediction purposes 
acknowledgem ents
the data set we use here was graciously provided by dr 
yoshua bengio of the university of montreal 
references

fig     predicted and true keypoints on a sample image  red and blue points
are ground truth and our prediction respectively 

   

sun  yi  xiaogang wang  and xiaoou tang   deep convolutiona l
network cascade for facial point detection   computer vision and
pattern recognition  cvpr        ieee conference on  ieee 
     

   
   

https   www kaggle com c facial keypoints detection
wang  yue  and yang song   facial keypoints detection   project
report  cs     stanford university      

   

jain  ramesh  rangachar kasturi  and brian g  schunck  machine
vision  vol     new york  mcgraw hill      
cai  jian feng  emmanuel j  cands  and zuowei shen   a
singular value thresholding algorithm for matrix completion   siam
journal on optimization                       
keshavan  raghunandan h   andrea montanari  and sewoong oh 
 matrix completion from a few entries   information theory  ieee
transactions on                       
cands  emmanuel j   and benjamin recht   exact matrix
completion
via
convex
optimization   foundations
of
computational mathematics                     
canny  john   a computational approach to edge detection  
pattern analysis and machine intelligence  ieee transactions on
                  
zou  hui  trevor hastie  and robert tibshirani   sparse principal
component analysis   journal of computational and graphical
statistics                      

   

v 

summary

in summary  we proposed the pclwlr method for the facial
keypoint detection  in this method  after reducing the dimension
via pca  a regularized version of locally weighted linear
regression was applied to train the model  hold out cross
validation was then used for tuning the parameters of the model 
finally  we reported the error of the proposed method using  fold cross validation and compared its performance with other
methods  for future work  one idea is coming up with a better
idea for finding near neighbors of images  so that the local
regression methods achieve higher accuracy  the other method

   

   

   

   

fi