 

an attempt at adaptive sampling for photorealistic image generation 
learning sampling schemes for monte carlo rendering
winnie l in  stanford university  email  winnielin stanford edu
timothy w u  stanford university  email  thsuanwu stanford edu

abstractwe take a machine learning based approach to
adaptive sampling for monte carlo rendering  by using geometric and lighting data obtained through prior renders of scenes 
using nonlinear kernels  we trained support vector machines
of high accuracy  but complications arose in the labelling of our
data  resulting in slightly impractical results for the sampler itself 

i  i ntroduction and r elated w ork
as a result of the constant drive towards improving
aesthetic appeal  most companies involved in computer
generated imagery  cgi  in the industry either use or are
shifting towards photorealistic ray tracing methods to generate
their images  in essence  ray tracing is the implementation
of a virtual camera  and the simulation of photons that the
cameras light sensors receive from a mathematically described
virtual scene 
we represent the image plane as a virtual plane that is normal
to the direction of the camera  we trace the reverse path of
photons from the camera into the virtual scene  record the
intensity and color of the photon  then calculate the value of
each pixel as the total sum of photons passing through it  a
diagram is as follows 

et al s comprehensive overview     on recent advances
in optimization via light field analysis for monte carlo
rendering  as well as moon et al s approach to using local
regression on filter based features for sampling     
while the aforementioned papers all described great results 
we were wondering if machine learning approaches combined
with only straightforward lighting and geometric data could
produce good results  without having to resort to bandwidth
dependent filtering and lightfield analysis  considering that
the pbrt     method for adaptive sampling is a simple model
which sets two different sampling rates depending on whether
the rays of a pixel hit only one shape in the scene  we thought
it would be interesting to combine the two approaches into a
simple but effective learned sampler 
ii  overview of a daptive s ampling
adaptive sampling is a technique where the number of ray
samples per image pixel is heterogenuous  ideally  the number
of sampled rays of a pixel would depend on the pixels rate
of convergence to the ground truth pixel  the ground truth
pixel defined as the result of sampling an infinite number of
rays in other words  we would only sample a high number
of rays on pixels we predict are far from the ground truth 
removing unneccessary or less impactful calculations from
image generation 
the challenge is thus to predict when a pixel is close to
the ground truth pixel  without having prior idea of what the
ground truth pixel is 
iii  m ethods

the most general ray tracing scheme is monte carlo ray
tracing  where pixels in the image plane are approximated
as the average color of a collection of randomly sampled
light beams  as known as rays  passing through the pixel 
this scheme deftly handles a rich variety of object materials 
complex lighting and particle effects  but the downside is
it tends to be computationally expensive  due to the high
number of rays needed per pixel to achieve a relatively
noiseless render  this then contributes to and influences the
interest in optimization 
in recent years  there has been an increased amount of machine
learning related research in such optimization techniques 
mostly in terms of smart filtering and postprocessing via
lightfield analysis      we were particularly inspired by
the kalantari paper      where neural networks where
applied to postprocess and filter noisy renders  zwicker

a  objective
given an input of a collection of ray samples for a pixel 
by using a support vector machine corresponding to this
collection size 
our objective is to predict whether we should increase the
size of the collection or not 
we use a model that has an individual support vector machine
for each collection size  the justification of this will be given
after the description of our features   the proposed model will
now be described in more detail 
b  overview of support vector machines
support vector machines are used to separate labelled
points in high dimensional spaces  in our case  the labels
correspond to the distance of a pixel to its corresponding
ground truth pixel  and the points position in space will be

fi 

determined by our features  as determined in the next section  
given a kernel k   rn  r  a weighting c  r that balances
optimizing a clear separation  hyperplane with large margin 
versus a separation for as many data points as possible  and
a set of datapoints x i   rn with labels y  i           we
find find the coefficients ci corresponding to
m
  x
ci cj y  i  y  j  k x i    x j   
 
i j  
i  
x
subject to    ci  c  
ci y  i      

maximizeci

m
x

ci 

as shown in professor ngs lecture notes  this is the dual
problem of finding the optimal separating hyperplane of the
labelled training data  therefore  given any testing data x  we
can predict its corresponding label y  or which side of the
hyperplane x is on  by solving and checking the value of
x
f  x   
ci k x i    x 
ci    

against the intercept as determined by the support vectors x i 
where ci      

we were not able to train models on data sets without it 
due to the high dependency of the previous features on
the actual color value of the ray collection 
 the variance in light source illuminance  if our ray
collection has a high variance in power illuminance  we
think that it corresponds to complex lighting  this term is
fast to compute using a recursive relationship between the
two sets of samples within our old ray collection  given
the variance a   b and mean a   b of two separate sets
of samples  with the fact that the two sets are of the same
size  we derived
ab       a   b   and
 
ab
       a     b     a  b      
other features we considered include the average number
of bounces of a ray before it reaches the pixel  and the
surface area of the convex hull of the normal direction of the
ray object intersection  however  given the restrictions within
the existing pbrt pipeline and the complexity of computation 
we limited ourselves to the ones described above  here are
some visualizations of the features corresponding to shape 
difference in y channel  combined mean of xyz channels 
and variance of illuminance  left to right 

c  pipeline
the method with which we incorporate our trained support
vector machines into the rendering pipeline is as follows  for
each pixel 
   we start by sampling a fixed minimum samples  and
record relevant data 
   using f  x  of the first layer of support vector machines 
predict whether we need to continue sampling or not 
   if we need to continue sampling  we add an extra
collection of ray samples  doubling the size of the
sample collection   run it through the next layer of
support vector machines  and continue until termination
as determined by the hypothesis or the cap we set on
the maximum number of samples 
d  features
intuitively  we predict that we need more samples if the
pixel corresponds to a part of the scene with complex geometry
and or complex lighting  with that in mind  we set our features
to be 
 the number of intersection shapes  this term captures
the complexity of the geometry  if the collection of rays
of a pixel hits multiple shapes  we know that it might
correspond to the edge of an objects silhouette or an
edge on the objects surface 
 the difference in x y z color channels between the
old ray collection and the newly sampled rays  if the
two collections of rays corresponding to the same pixel
are distinctly different in color  we think this is a good
indication of complex lighting or complex color textures 
this data is easy for us to obtain and compare  as the
way our model is designed gives us a set of old samples
and a set of new ones of equal size 
 the mean of x y z color channels of the overall ray
collection  this feature was added when we found that

e  motivation of multiple layers
coming back to our model design  it can be noted that our
normalized feature values themselves are highly dependent
on the number of samples we have  for example  a higher
number of samples would naturally give us a higher variance
in illuminance and a lower color difference between the
two subsets of the ray collection  to illustrate  these are
visualizations of the color difference for the layer of  
samples and     samples  respectively 

using the layer count itself as a feature would further increase
the complexity of our svms and increase the number of
support vectors  which we will see later on is rather a
major problem already   with this in mind  we arrived at the
decision to use multiple layers of svms 
f  data collection and labelling
in our data collection stage  we repeatedly render scenes
sampled with a uniform number of rays  varying the overall
sample number from   rays to      and collect feature data
corresponding to each sample rate during this process  afterwards  we record the color distance between each pixel of

fi 

sample rate less than     and its corresponding pixel of    
rays  then label the feature data according to some threshold
of the color distance 
originally  we set our threshold to be the just noticeable
difference  jnd  for the human eye as determined in lab color
space      however  we were actually unable to train all our
svms with this labelling  nor with any other threshold that
was uniform throughout all svm layers  libsvm threw out
nan values   we hypothesize that the labelling was simply too
unbalanced  if the svms of lower samples were trainable  then
ones with the higher samples  which would have color distance
closer to the     samples  would yield labellings that were
too skewed towards having distances smaller than the global
threshold  and vice versa  in the end  we settled on varying
the threshold for each layer to be the mean color difference
for all of the pixels  this gave us perfectly balanced labelling
 it partitions the data exactly in half  and great training results 
yet it is not what wed hope for for the sampler itself 
g  software implementation
we wrote our sampler within the c  based pbrt     framework  for the prediction stage  we linked libsvm     into
the pbrt sampler  for the training stage  we wrote our data
collector also as an extension of pbrt  parsed and labelled
data with python scripts  and trained our models with python
scripts and libsvm  we also wrote a simple visualizer with
libpng     to visualize the features and results 
iv  r esults   t he good   the bad and the ugly
specifically in that order 

layer
layer
layer
layer
layer

original data         samples 

sampled data        samples 

   fold cross validation

      
        
       
        
        

        
        
        
        
        

       
      
        
        
        

 
 
 
 
 

the following chart corresponds to testing data from
the bunny scene as shown in the features section  and another
teapot scene and a kangaroo scene all rendered at    x   
pixels  this were trained on the svms of the filtered dataset 

layer
layer
layer
layer
layer

bunny
       
        
        
        
        

 
 
 
 
 

teapot
        
        
        
        
        

kangaroo
        
        
        
        
        

bright kgr
        
        
        
        
        

while we predicted that the teapot would have a higher
accuracy rate due to its similarity with the teapot scene in the
training data  it was rather perplexing how high the accuracy
of the killeroo scene was  originally we thought that it was
due to the fact that most of the scene was unlit and uniformly
black  but even increasing the lighting did not reduce the
accuracy 
b  support vectors

a  model accuracy
while with a lot of labelling schemes and kernels our data
was not trainable at all   in particular  linear kernels and a
globally uniform labelling scheme never worked   our models
are extremely accurate with the right parameters  in particular 
the radial basis kernel
k x i    x    e

on training data  and another on a subset of our testing scenes 

  x i  x   
 
   

with balanced data labelling gave rise to predictions
consistently above ninety percent  we collected data on    
thousand pixels obtained from these three images  which
were chosen respectively for their color variance  shadow
variance  and object complexity 

the number of support vectors was surprisingly high  with
the models trained on the original data and the sampled data
as shown below 
layer
layer
layer
layer
layer

 
 
 
 
 

original data         

sampled data        

     
     
     
     
     

    
    
    
    
    

however  as shown previously  performing cross validation
on our results continued to yield high accuracy in the    s 
which to some extent decreases the probability that we
might be overfitting  a ta mentioned that a high number
of support vectors was often the case when training data
includes rgb xyz color values directly as features  since
the variance within the color space is so high 
c  renderer accuracy and efficiency

we then trained our svms once on the entire set of
training data  once on one tenth of the pixels randomly
sampled from the data collection  and tested them both on
the training data and data obtained from rendering various
other scenes  here is an accuracy chart of our model tested

despite the promising accuracy of the model itself with
collected data  as of now it does not work as well in practice 
in particular  rendering the bunny scene under the adaptive
sampler  which should sample between   and     pixels 
took between      to      seconds under multiple renders 
using the standard pbrt sampler  rendering     samples
took between      to      seconds  but rendering with  
samples takes     to     seconds with no noticeable difference 

fi 

a huge speedup may potentially occur  during the presentation
session  someone also suggested that working consistently in
lab color space instead of rgb xyz might give us better quality
svms with lower number of support vectors  which we still
need to look into  
vi  c onclusion
below is a visualization of the number of samples per
pixel  brightest color corresponds to     samples  darkest to
    and it shows us that for some reason  in this scene  the
relatively simply flat ground plane requires up to     samples 

v  f uture w ork
there are still many improvements that could potentially
make this sampling scheme work  we have listed a few of
these below 
   a better labelling scheme or pipeline structure  we
think the normalized labelling scheme really affected the final
results  yet we havent found a better way to label our data 
   more complicated scenes  due to restrictions on the
computing power of my laptop  we did not figure out the
farmshare task submission framework in time  and my computer repeatedly froze on some of the more complex scenes
we attempted   all the scenes weve used have been relatively
simple  and are most likely not representative of scenes that
would actually benefit from such a sampling scheme 
   experimentation with neural networks  while all attempts at using linear classification failed rather spectacularly 
it would be interesting to try to apply neural networks to
our problem  given the success of nonlinear functions in our
current svms and the complexity of our data 
   experimentation with more features  as we mentioned
before  we only included   features  bundled into   main
categories  due to time constraints and the complexity of data
retrieval  however  rewriting more parts of pbrt would give us
access to a wider array of data that we could probably use to
our advantage 
for example  we originally only considered features that were
constrained within the pixel due to the limitations of the
sampler superclass of pbrt  but as previous research in related
areas have shown  features dependent on image filtering across
pixels     have yielded good results 
   optimization  the fact that the radial basis kernel
 which involves many exponential calculations  was the only
one that produced satisfactory results made the prediction
stage rather expensive  and thus resulted in a adaptive sampler
that was not significantly faster than sampling at the highest
rate  however  upon the suggestion of a friend and further
examination of the libsvm source code  we realized that if we
implemented a lookup table for the exponential values instead 

in summary  our intended model was complicated by the
inability to use the same labelling scheme throughout all
layers  and the label normalizing approach we took in the end
to bypass this was neither as accurate nor as fast as we had
hoped 
however  simply from a svm quality standpoint  the models
we obtained had high accuracy all above    percent  even with
scenes that were highly dissimilar from the training scenes 
some main points we discovered through adjusting the training
parameters were 
 the radial basis kernel yielded optimal results  while
linear kernels did not work at all 
 a filtering of our training data reduced the number of
support vectors while still retaining a high accuracy for
the test data 
the accuracy in our trained models and the large potentials
in optimization lead us to continue to believe that adaptive
sampling is an area that may benefit from maching learning
techniques 
vii  c ode
code for this project is currently available at https   github 
com winnie        project if interested 
acknowledgments
wed like to thank albert haque for his advice and feedback
on the project  professor ng for the great course  and all the
tas for making a course of this size possible  wed also
like to acknowledge the rendering course taught by professor
hanrahan in the spring of       which was extremely helpful
in setting up the framework of this project  and radiant entertainment  whose flexibility in intern work schedule allowed
winnie to sightsee at siggraph and gain her first exposure
to machine learning in computer graphics 
despite all the unexpected twists and turns and complications
and less than stellar results  working on such an unpredictable
project all in all was rather exciting  additionally  we were
exposed to many potential problems that might arise in future
machine learning adventures  and are grateful for this particular learning experience 
r eferences
    m  zwicker  w  jarosz  j  lehtinen  b  moon  r  ramamoorthi  f  rousselle  p  sen  c  soler  and s  e  yoon  recent advances in adaptive sampling and reconstruction for monte carlo rendering  computer graphics
forum  proceedings of eurographics   vol      no     pp          may
     
    n  k  kalantari  s  bako  and p  sen  a machine learning approach
for filtering monte carlo noise  acm transactions on graphics  tog 
 proceedings of siggraph        vol      no          

fi 

    b  moon  n  carr  and s  e  yoon  adaptive rendering based on weighted
local regression  acm trans  graph   vol      no     pp              
sep         online   available  http   doi acm org                
    m  pharr and g  humphreys  physically based rendering  from theory
to implementation  elsevier       
    e  n  d  g  sharma  w  wu  the ciede     color difference formula 
implementation notes  supplementary test data  and mathematical observations  color research and application  vol      no          
    c  c  chang and c  j  lin  libsvm  a library for support vector
machines  acm transactions on intelligent systems and technology 
vol     pp                   software available at http   www csie ntu 
edu tw cjlin libsvm 
    g  v  simon pierre cadieux  eric s  raymond  libpng version       
     

fi