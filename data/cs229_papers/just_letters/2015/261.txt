learning chemical trends in heterogeneous catalysis
xinyan liu  leo shaw  charlie tsai
department of chemical engineering  stanford university
fxinyanl leoshaw ctsai  g stanford edu

abstract

face of each material are needed  although specific data for
material surfaces are lacking  properties for bulk materials
are widely available through several large databases  in this
project  we train a model that bridges the gap between surface phenomena and bulk properties  which do not contain
information about the surface and are poor at directly describing the chemical reactivity of materials  bulk properties can be combined with a priori information about the
surface  such as the crystallographic planes  and training
data from existing computations and experiments  a model
can then be developed to directly predict surface properties
from widely available bulk data without the need for computationally expensive quantum chemical calculations  in
terms of surface properties  we will be focusing on thermochemical data  which most directly describes how efficient a
material will be for a given chemical process  as the possible predictors are numerous  variable selection will be used
to determine their relative importance 

despite tremendous advances in the understanding of
catalysis in the past few decades  the discovery of improved materials for energy transformation processes has
been guided by physical intuition and trial and error approaches  even though computational simulations have
provided a more rational approach  even the most systematic studies involving the most well described systems require a large number of costly and repetitive calculations 
we attempt to mitigate this problem by proposing a learning model for directly obtaining energetic parameters relevant to catalysis using widely accessible bulk chemical
data  among the methods surveyed  our tree based models
achieved a cross validation error of about      ev  which
approaches the error obtained from simulations  about    
ev  

   introduction and background

   related work

one of the major bottlenecks in developing improved
and sustainable energy technologies is the lack of cheap and
efficient materials  for applications ranging from batteries
to fuel cells to inexpensively produced fertilizers  the materials needed to run these chemical reactions are either prohibitively costly or missing entirely  new materials are typically discovered in the laboratory through trial and error 
an inefficient and slow process  with significant advances
in computing power  the rational design of new materials
has the potential to be a more efficient approach  where detailed simulations are performed to help predict new materials  despite this  however  the successful design of a
new and improved material is still a rare occurrence  partly
due to the vast amount of calculations needed to adequately
sample the space of candidate materials  thousands of possibilities exist for even the most well understood systems 
for example  in heterogeneous catalysis a further complication arises from the fact that chemical reactions occur at specific interfaces  i e  surface terminations of the
crystal   for which detailed chemical data usually does not
exist  vast quantities of calculations specific to each sur 

mean field microkinetic modeling has long been a powerful and efficient means of analyzing catalytic reactions   
inputs related to the energetics on the catalyst surface are
needed in order to solve the rate equations and determine
important metrics like the turnover frequency of the desired product  in order for predictions to be made about
the reaction rates  the solutions to the rate equations need to
be expressed as a function of the energetic inputs  since
a vast number of possible mechanisms may be involved 
the relation among the different energetic inputs needs to
be known in order to reduce the parameter space and make
the problem tractable    the adsorption strengths of different reaction species has been found to scale linearly with
one another on a wide range of heterogeneous as well as
homogeneous catalysts     as long as the linear relations
are known  the rate can be determined as a function of the
binding energies for a few species  simple bond counting
principles have been used to determine the slopes of these
linear scaling lines  but calculations are still needed to fit
the intercept  an improved catalyst can then be identified by finding the required binding energies for maximiz 

fiing the rates  although this descriptor based analysis has
led to the discovery of many improved catalysts  they have
so far been restricted to the simplest types of systems and
for the most well studied reactions  furthermore  detailed
calculations related to each catalytic site need to be made
for a single prediction  even the simplest transition metal
nanoparticles have a multiplicity of sites and surface terminations  recent efforts have focused on understanding
the role of surface coordination number   in determining adsorption strength but costly calculations are still required to
make the predictions  most efforts are concerned with detailed simulations of known active sites  and there is so far
no model for predicting the relevant energetics using only
a priori information about the surface and the material  if
reaction energetics at the interface can be directly predicted 
then the inputs needed for estimating reaction rates can be
obtained at negligible computational cost 

   data set and features
a significant simplification in describing catalytic activity arises from the fact that all reaction steps are related to
the stabilities of the reactant species on the catalytic surface  these are usually determined as adsorption energies
 the energy required to stabilize the adsorbate molecule
on the catalyst  or how strongly the catalyst binds the adsorbate  we retrieved data for the reaction energies from
the catapp database   from the suncat research group at
stanford university and the bulk properties of the catalysts
were taken from the materials project database    to simplify the initial evaluation of models  weve restricted the
catalysts to transition metals and their binary alloys  for
the chemical reactions  we considered elementary reactions
of the form ab   a c b  there were approximately     
data points for these reaction energetics on transition metals
and their binary alloys  these results can be directly used in
kinetic models describing catalytic reactions such as higher
alcohols conversion and co  reduction 

index

predictor

type

units

 
 
 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

miller index h
miller index k
miller index l
stoichiometry for metal  
stoichiometry for metal  
energy of formation
density
unit cell length a
unit cell length b
unit cell length c
unit cell angle 
unit cell length 
unit cell length 
metal   s electrons
metal   p electrons
metal   d electrons
metal   f electrons
metal   s electrons
metal   p electrons
metal   d electrons
metal   f electrons
max adsorbate bonds  ab 
adsorbate bonds  ab 
intramolecular bonds  ab 
  c atoms  ab 
  h atoms  ab 
  o atoms  ab 
  n atoms  ab 
max adsorbate bonds  a 
adsorbate bonds  a 
intramolecular bonds  a 
  c atoms  a 
  h atoms  a 
  o atoms  a 
  n atoms  a 
max adsorbate bonds  b 
adsorbate bonds  b 
intramolecular bonds  b 
  c atoms  b 
  h atoms  b 
  o atoms  b 
  n atoms  b 

discrete
discrete
discrete
discrete
discrete
continuous
continuous
continuous
continuous
continuous
continuous
continuous
continuous
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete
discrete






ev
g cm 
a
a
a
degrees
degrees
degrees






























table    summary of physical parameters describing the crystal
structure  surface termination  and molecular identity of the reactants 

     response
     predictors

the response variables are either the reaction energy
erxn   which is the energy difference between the final and
initial state of each chemical reaction step  or the activation energy ea   which is the reaction barrier associated
with each reaction step  these parameters can be directly
plugged into kinetic rate equations to determine the activity
of a given catalytic site  for all reactions  the magnitude of
the response is typically between   ev and   ev  state ofthe art density functional theory calculations are typically
accurate within     ev of the experimental values  so our
model should have at most a generalized error of that order
of magnitude  otherwise  it could not be a viable alternative
to the calculations 

our choice of    predictors was based on both the availability of bulk material data and properties suspected of being physically and chemically important during a catalytic
reaction  the identity of the surface  i e  the specific crystallographic plane  involved with the reaction is encoded
with the discrete integers of the corresponding miller indices        for binary alloys  the stoichiometry       and
number of electrons         uniquely identify the two individual elements and the overall composition  for pure
metals  the metals values were duplicated for metal   to
maintain the same number of features  the crystalline structure of a catalyst is represented by the   lattice constants
 

fi      and angles         that uniquely describe the crystallographic unit cell of the material  to identify the molecule
involved in the reaction  we have used the maximum number of bonds in the atom closest to the surface  based on
bond order analyses from previous work      the number of
bonds directly made to the surface  as well as those made
within the molecule                        this must be
done for the initial state  ab  and the final states  a and b  
furthermore  adsorbates could bind to the surface through
the same type of atom  but have different chain lengths or
other constituents further from the surface  we encoded
these possibilities by explicitly including the number of
each type of element present                       

for each split  we find
x
argmin
 yk
i j

for our regression problem  we chose     linear regression methods      tree based methods  and     kernel based
methods  this range of flexibilty allowed us to negotiate
the bias variance trade off inherent in constructing a useful
model 
regularization and feature selection are important in removing features with little predictive value  for example 
lasso regression and ridge regression are modifications
of simple linear regression whereby the cost function is supplemented with a penalty on the coefficients themselves 
specifically  the model coefficient vector  is

argmin


n
x
id 

 yi

 

p
x

kwxk  r   i j  

 yk

yor    

kwxk  r   i j  

where yorm is the prediction for region rm   i e  the mean
of the training observations in that region  this process is
done iteratively  except each round after the first produces
a split not in the whole predictor space  but only in one of
the regions  the most important features can be determined
from this process 
several methods have been developed to improve upon
this basic algorithm  for example  boosting involves slowly
creating a model by sequentially adding trees in order
to avoid overfitting  bagging involves creating bootstrap
training sets sets of random samples  with replacement 
from the original set of training points and then growing decision trees  which are averaged together  random
forest methods were developed as a way to improve the
performance of bagged decision trees by specifically decorrelating the individual boot strapped trees by shrinking
the set of p predictors considered at each split typically
p
p predictors are used 
lastly  we used support vector regression  svr    to
model our data  an extension of support vector classification  the method with soft margins solves for w and b 

   methods

 

x

yor     c

n
x

 
 
min kwk c c
i c i
 

  

i d 

j xij a c kkk

with the following conditions on the tuning parameter c  
tolerance   and slack variables i and i  

j d 

where k d   for ridge  k d   for lasso  and the tuning
parameter  is chosen by cross validation  the left term is
the residual sum of squares  rss   and the term on the right
the shrinkage penalty causes the coefficients to tend
toward zero for large values of   with less important features having smaller coefficients than more important ones 
subset selection can also be used to determine which
predictors are most relevant  rather than evaluate models
for all     possible subsets of the predictors  we chose backward stepwise selection  the initial set of model predictors
m  is the entire set p   and new sets mi for each subsequent
iteration removes one predictor by evaluating the models
resulting from the removal of that predictor  the optimal
model gives us the set of the most important predictors 
tree based methods allow for regularization as well  decision trees partition the p dimensional predictor space into
n distinct  non overlapping boxes  whereby splits in a predictor domain are evaluated by calculating the rss among
the set of all splits for all predictors  in other words  for
predictor xi and cutpoint j   a split creates the half planes

yi

hw  xi i

hw  xi i c b

b   c i
yi   c i

i   i   

   results
     learning curves
to evaluate each models performance  the training error
and cross validation error were determined as a function of
the training set size  these results are summarized in fig 
   starting with linear regression  the least flexible model 
both the training error and cross validation errors converge
before the full training set is used  at around     samples  
indicating that increasing the training set size will not further improve the model accuracy  the cv error stabilizes
at about     ev and is much too large  suggesting that either more flexibility in the model are needed  in the random
forest model  the training error is in an acceptable range
for larger training sets  while the cross validation error is at

r  d fxjxi   j g  r  d fxjxi  j g
 

fi b 

 a 

 d 

 c 

figure    learning curves for the linear regression  lm   random forest  rf   and support vector regression  svr  with a linear and
gaussian kernel  the training error and the cross validated generalization error is shown as a function of the training set size 
 b 

 a 

figure     a  size of the coefficients from a linear fit using the l  norm penalty   b  ranking of the importance of the various predictors in
the random forest model  the numbering of the features corresponds to table   

cv error for the gaussian kernel is about     ev and  like
the rf model  could be improved with additional samples
to decrease the generalization error further 

   

cross validation score  mae 

   
   

     feature selection and model performance

   

we applied several approaches for performing feature selection on parametric and non parametric models  a norm
penalty for the linear model  i e  the lasso and ridge regression  and comparing the rss decrease of each variable
in the tree based method  random forest   both the lasso
and ridge regression yield comparably small yet non zero
coefficients for many of variables  the training and cross
validation errors were typically worse than standard linear regression  suggesting that these regularization methods
may not be appropriate for feature selection 
since random forest already shows reasonable performance on the training data  fig      it is used as a means
of determining the importance of each feature  the results
shown in fig    suggest that      adsorbate bonds of a to
the surface       the intramolecular bonds in a           the
d   electrons for each metal of the catalyst       adsorbate
bonds of the initial material ab  and        the miller indi 

   
   
   
   
 

 

                 
number of features selected

  

  

figure    backward subset selection for the features used in the
random forest model 

about      ev when all data points are used  for svr  a linear and a gaussian kernel were chosen  the training errors
are about     and     ev respectively  with the linear kernel
performing similarly overall to the linear regresssion  the
 

fitable    summary of model performances
cross validation mae  ev 

methods

w o feature selection

with feature selection

linear regression  regularization 

linear regression
lasso
ridge

    
    
    

    
    
    

tree based methods

random forest
bagging
boosting

    
    
    


    
    

kernel based methods

kernel ridge regression

linear kernel
polynomial kernel
gaussian kernel

    
    
    



    

support vector regression

linear kernel
polynomial kernel
gaussian kernel

    
    
    



    

cies h and k are the seven most important features  there is
a clear drop in importance for the remaining variables  this
result agrees with known physical concepts in catalysis  the
magnitude of the adsorption energy is determined mostly
by the bonds of the reactant molecule  the d  electrons are
the most important in correlating binding strength with the
identity of the metal catalyst  and the reaction energies are
a strong function of the stabilization of reactants via surface
bonding  the larger errors bars unfortunately indiciate that
the uncertainties associated with each of the feature importance metrics can change the relative importance of these
predictors  many of the features may be redundant or nonnegligibly correlated  for example  the large variance for
the importance of the lattice parameters and angles       
of the catalyst is likely due to the similar influence they each
have on the models  however  a few predictors  such as the
metal s electrons          and the energy of formation of
the metal     are reliably unimportant  backwards recursive
feature selection with cross validation was also performed
to corroborate our results  we simulated the feature ranking with recursive feature elimination and cross validated
selection of the best number of features  in fig     the crossvalidation error curve decreases monotonically until about
  predictors are selected  at which point the error plateaus 
the predictors are in good agreement with the feature importance plot from before  in summary  only a few of the
features have a large influence on the response  and they
also have relevant physical significance 

methods were still able to achieve the lowest cv error  with
the random forest and bagging having a mae less than    
ev 

   conclusions and future work
as a first step  our work demonstrates that it is possible
to make predictions on surface phenomena using a priori
information about the surface in addition to bulk chemical
data  the regularization analyses confirm the importance
of certain parameters  i e  the d  electrons  the bond order
of the adsorbates  etc   established in previous physical
models  we have so far restricted our data set to binary
transition metal alloys and elementary reactions of the form
ab   a c b  even by considering just c  n  h  and o
containing species  the results account for the vast majority of catalytic reactions of industrial importance  however 
more features would be needed to generalize our models to
other catalytic reactions or materials other than transition
metals  currently  only the most flexible models are able to
reach the target accuracy of      ev  and only for the training set  additional data can be obtained  but they will also
be increasingly dissimilar from the current data set  as we
have focused on the most consistent systems in this study 
beyond increasing the number of features  performing regularization  and increasing the number of training examples 
course grain calculations may be needed as an additional
inputs  calculations can be obtained at a negligible computational cost if the accuracy is sufficiently low  however 
this would provided additional structure for the underlying
data 

the performance of all models are summarized in table
   feature selection for the tree and kernel based models
used the features selected by the random forest  only features whose importance is greater than or equal to the mean
feature importance were kept  in almost all cases  the cv
error with feature selection performed mostly slightly worse
than for the models with all predictors  again  all forms of
linear regression performed poorly  while the gaussian kernel performed better for the other methods  the tree based
 

fireferences
    honkala  k   hellman  a   remediakis  i  n   logadottir  a  
carlsson  a   dahl  s   christensen  c  h   nrskov  j  k  science                   
    medford  a  j   lausche  a  c   abild pedersen  f   temel  b  
schjdt  n  c   nrskov  j  k   studt  f  top  catal       
    abild pedersen  f   greeley  j   studt  f   rossmeisl  j  
munter  t  r   moses  p  g   skulason  e   bligaard  t  
nrskov  j  k  phys  rev  lett                   
    fernandez  e  m   moses  p  g   toftelund  a   hansen  h  a  
martnez  j  i   abild pedersen  f   kleis  j   hinnemann  b  
rossmeisl  j   bligaard  t  angew  chem                 
     
    bligaard  t   nrskov  j  k   dahl  s   matthiesen  j   christensen  c  h   sehested  j  j  catal                    
    calle vallejo  f   loffreda  d   koper  m  t  m   sautet  p 
nat  chem                  
    hummelshj  j  s   abild pedersen  f   studt  f   bligaard  t  
nrskov  j  k  angew  chem                    
    jain  a   ong  s  p   hautier  g   chen  w   richards  w  d  
dacek  s   cholia  s   gunter  d   skinner  d   ceder  g   persson  k  a  apl mater                  
    smola  a  j   scholkopf  b  statistics and computing      
           

 

fi