

cs   project rossmanntimeseries
allenhuangjesiskatandy
stanforduniversitystanforduniversity
allenh stanford edujtandy stanford edu
  introduction
datasetsthatvarywithtimearebecomingincreasinglyimportantandprevalentinbusinessandindustry therefore we
feltthatitwouldbeinterestingtolearnmoreaboutthedifferencesandnuancesofinterpretingandpredictingtimeseries
data tothatend wedecidedtousethedatasetprovidedinakagglescompetitiontitledrossmannstoresales  to
buildandverifymodelsthatcouldbeusedtoforecastsalesofstoresovermultiplemonthsgivenhistoricalsales 

  relatedwork
asthecreatoroftherforecastpackagerobj hyndmanwritesinhisonlinetextbook therearemanydifferenttypesof
techniqueswhendealingwithtimeseriesdata therearedecompositionbasedmethodsthatincludemovingaverage
techniquesandotherrobusttechniquessuchasstl seasonalandtrenddecompositionusingloess     someofthe
techniquesexploredincludeclusteringandrandomforests      thereareevenmoreadvancedtechniquessuchas
exponentialsmoothing arimamodels andevenautoregressiveneuralnetworksmodels    classificationand
regressiontrees cart havebeencomparedtomanyofthesetechniquesforpredictingtimeseries andwhileitmaynot
beconsideredthebestwhenitcomestotimeseries    itisworthnotingthatallthesecomplexmodelsarefixatedon
forecastingbasedsolelyonasingletimeseries thatis thesetechniqueswerenotmadetohandlethecasewhereyou
havemanyothercovariatesandmultiplepossiblycorrelatedtimeseriesdata 

  datasetandfeatures
table  summaryofthegivenfeaturesweusedduringthecourseoftheproject 
column feature

train csv

test csv

store csv

comments

store

x

x

x

factor        storeid

dayofweek

x

x



    monday  sunday 

date

x

x



year month day

sales

x







promo

x

x



binary  foractivepromo

stateholiday

x

x



binary  

schoolholiday

x

x



factor   a b c

storetype





x

factor a b c d

assortment





x

factor a b c


  methods
weseparatedthegiventrainingdataintothreedatasets training                    validation         
           andtest                    

wealsousedalogtransformonthesalesoutcomevariablebecausesalesrevenueisinherentlyapositiveoutcomeandthe
logarithmictransformmitigatestheeffectofthelargerangeofsalesacrossdifferentstores 
 


https   www kaggle com c rossmannstoresales

 

fi

themetricsweultimatelydecidedtousewastherootmeansquarepercenterrorandthemeanabsolutepercenterror 
thesemetricswerecomputedinaggregateacrossallthedailysalesfiguresforallthestoresandfortheentiremonthof
thevalidationset asshownbelow 




 rmsp e   

 
ds

s d



i   j  

 


s d
      yijaij    
m ap e   ds
a
i   j     ij  

yijaij  
   

aij

 

   


where yij isthepredictedsalesforagivenstoreandagivenday  aij istheactualsales sisthetotalnumberofstores and
disthetotalnumberofdaysinthedataset 

ourintermediateandfinalmodeluserecursivelypartitionedtrees rpartrpackage  themodelisasfollows    
m

f  x      cmi x  rm 

   

m  



 

where c m isaconstantineachregion minimizingthesumofsquares  yi  f  xi    wewouldobtaintheaverageof yi 


asthebest cm     depictedintheequationbelow 

cm   ave yi xi  rm 
   

inwords theideaisthatgivennfeatures wepartitionthendimensionalspaceintosubregions givenanewdatapoint 
wefindthesubregioninwhichitresidesandguesstheaverageoutcomeofallthetrainingdatapointsinthesubregion 
recursivepartitioningisagreedyalgorithmthatfindstheoptimalsplitsthatdefinetheseregions 

thecomplexityparameter cp isthethresholdabovewhichasplitinthetreehastoimprovetherelativeerrorforasplit
tobeaccepted thatis asmallercpvalueyieldstreesthathavemorebranches 

  experiments

   baselinemodels
seasonalnaivemethod
first therewastheseasonalnaivemethodofsimplypredictingthemediansalesbasedthestore dayofweek andpromo
covariates notethatwealsotriedpredictingthemean thoughthemedianseemedtogivebetterandmoreconsistent
results thisisshowninfigure below 

baggeddecisiontreemodel
webeganwithanunbaggedrparttreemodelwiththefollowingrformula sales store dayofweek promo 
stateholiday schoolholiday storetype assortment 


weperformedsensitivityanalysisofthecomplexityparameterandtheresultsareshownintable  theresultsindicated
thattheoptimalcpvaluewas       asdecreasingthecpvaluestartedtoyieldonlymarginalimprovementsbut
increasedthecomputationaltimesignificantly 

table  rmspevaluewithvaryingcp 
cp

    

     

      

       

        

         

rmspe

     

     

     

     

     

     

 

fi

wethenextendedtherparttoabaggedregimewherebywebootstrappedthetrainingdatasetbtimes fitbdecisiontrees 
andaveragedtheresultsofthosebdecisiontrees thisgivesusamorerobustresultbecausesitreducesthevariance
componentofourgeneralizationerrorsincewereaveragingoverbootstrappeddatasets wedonotexpectthatthis
processwillreducethebiascomponentofourgeneralizationerroraswearenotaddingfeatures 

   understandingtheeffectsoftimeseries
inordertoseeoneeffectthattimeserieshadinourpredictivepower wetrainedthemodelsaboveonasubsetofour
trainingdata theideawasthatdatathatwastoolongagomightbelessrelevantatpredictingthesalesoftoday 

asseenfromfigure  allthemodelsuniformlygotbetteras
youincreasedtheamountofhistoricaldataitwasallowedto
trainonupuntilaround  months whenyouaddmore the
predictivemodelstartstogetworse asaresults allofour
modelsonlyrelyon  monthsworthofhistoricaldata the
dataafterthatseemstobenoise 


figure  performanceofvariousmodelstrainedonvariouslengthsof
historicaldata 


   findingtimeseriescovariates
inordertofindwhatsortoftimeseriesfeatureswouldbethemostrelevanttopredictingthesalesoftoday wedidaseries
ofautocorrelationanalysesonthesalesofindividualstores 


figure  a autocorrelationofsalesincludingclosedstores b autocorrelationofsalesexcludingclosedstores 


ourfirstpasswithautocorrelation figure a showedasignificantcorrelationbetweenthesalesoftodayandthesales  
      and  daysprior however itwassurprisingtousthatthesalesofpreviousdaydidnotcorrelatemuchatall and
uponfurtherthoughtwerealizedthatthiswasduetotheinclusionofsalesofclosedstores sinceamajorityofthestores
wereclosedonsundays thezerosalesonthosedaysdraggeddownthecorrelationssignificantandaccentuatedthedayof
weekeffect afterremovingthosedayswhenthesaleswerezero theautocorrelationshowedasignificantcorrelationwith
previousdayssales confirmingourintuition 
fromthisanalysis wedecidedtoaddthefollowingtimeseriescovariatestoeachrowofourdataset inourmodel tm i 
representsthesalesidaysbeforethecurrentsaledate wherei                          ma representsthe
movingaveragesalesoverthelastweek andma  representstheaveragesalesoverthelast weeks 
 

fi
   significanceoftimeseriescovariatesandinteractionterms
fromourautocorrelationgraphs weknewthatthetimeseriescovariatesthatweaddedwereimportant however inorder
toidentifytherelativeimportancebetweenthosefeaturesandtheirinteractions wedecidedtouseanordinaryleast
squares ols approach 

theadvantagesoftheolsapproachwerethata wecoulddirectlyinspectthesignificanceofthetimeseriescoefficients
andb itscomputationalefficiency i e wecouldtrain     linearmodelswhereasourbaggeddecisiontreestook
approximatelyanhoureachtotrain  thedisadvantagewasthatwecouldnotusestoreasafactorintheanalysis  with
    stores thelmmethodinrcreates     i e       dummyvariables whichdrasticallyexplodedthenumberof
columnsofthedesignmatrixitwastryingtomanipulate invert  

thus wetrainedaseparateolsmodelfor
eachindividualstore
withallthecolumnsofthetimeseriesfeaturesdescribed
aboveaswellaswitheverysingleinteractionterm rformula sales tm  tm  tm  tm  tm  tm  tm  tm  
 tm   tm   ma  ma   
   
 wesubsequentlylookedatthesignificanceofthecoefficients 

table  
abridged
outputofthesummaryoftheresultantlinearmodelfitwithtimeseriesdataforstore    
covariate

coefficient

standarderror

pvalue

importance

intercept

     

    e  

    e  

   

tm 

    e  

    e  

        

  

tm 

    e  

    e  

        

  

tm 

    e  

    e  

       

 

tm   ma 

    e  

    e  

    e  

   

ma  ma  

    e  

    e  

    e  

   

 note morestarsmeansthecoefficientismorelikelytobesignificant    indicates     falsepositiverateforthat
coefficient  

forus wewanteda    falsepositiverate butinordertoaccountformultiplehypothesisbias weusedthebonferroni
correctioninordertoensurethatthecoefficientswechoseactuallyhada    falsepositiverate thus ourpvalue
thresholdwas     mwheremisthenumberofcovariatesthatwehad afteranalyzingthesignificancecoefficients
fromsomerandomlyselectedstores wedecidedtoincludethefollowingcoefficients 

tm  tm  tm  tm  ma  tm  tm  tm  tm  tm  tm  tm  ma   tm  tm  tm  tm  tm  ma   
tm  tm  tm  tm  tm  ma   tm  ma  tm  ma   tm   ma   ma  ma  

   finalmodel baggedtreeswithtimecovariates
armedwithourtimecovariates wetrainedourfinalbaggedtreemodelwiththefollowingrformula   

sales store dayofweek promo stateholiday schoolholiday storetype assortment tm  tm  tm  
tm  ma  tm  tm  tm  tm  tm  tm  tm  ma   tm  tm  tm  tm  tm  ma   tm  tm  tm  tm  
tm  ma   tm  ma  tm  ma   tm   ma   ma  ma  


 


weusedacpparameterof       and  bootstrappeddatasets  ittookapproximatelyanhourtotrain  

 

fi
  results
wecomparedthermspeandmapevaluesofourbaselinemodelsandourfinal bestmodel forourvalidationset we
foundthattheerrorvaluesofthenaiveseasonalbaselinemodelandourbaggedtreewithouttimecovariatesmodel
producedverysimilarerrorvalueshowever ourbaggedtreewithtimecovariatesmodelgavearmspeandmape
valuesthatare  ourbaselinemodels this  errorwillactuallytranslatetoalargenumberofsales thusitisahuge
improvementoverourbaselinemodels whenweranourmodelsonourtestset weactuallysawthatourbaselinemodels
gotworsebutourfinalmodelstayedroughlythesameintermsofperformance thissuggeststhatourfinalmodelwith
thepropertimecovariatesisactuallyreasonablyrobustagainstoverfitting 

table  rmspeandmapevaluesofourmodelsforvalidationset val andtestset test  
model

rmspe val 

mape val 

rmspe test 

mape test 

baseline median 

     

     

      

     

baggedtreeswithouttimecovariates

     

     

      

     

baggedtreeswithtimecovariates

     

     

     

     









figure  a autocorrelationofpercenterrorusingourbaggedtreewithouttimecovariatemodel b autocorrelationofpercenterror
usingourbaggedtreewithtimecovariatemodel 


autocorrelationoftheresidualsofboththebaselineandbaggedtreeswithouttimecovariatesmodelyieldedgraphsthat
weresimilartofigure a thelinearpatternintheresidualssuggeststhattherewasstillsometemporalstructureofthe
modelsthatwasnotcapturedbythemodel figure bsuggeststhatourfinalmodeltakesadvantageofthetemporal
structure accountingfortheimprovementinprediction 

  conclusion futurework
ourbaggeddecisiontreemodelwiththemostimportanttimecovariatesyieldedthebestandmostconsistentresultson
boththevalidationandtestsetwith     and     rmsperespectively autocorrelationanalysisoftheresiduals
showedthatourbestmodeldidabetterjobofcapturingthetemporalstructureofthedata ifwehadmoretimeand
computationalpower wewouldexploregradientboostedtreesaswellasgradientboostedregressionsincewesawduring
thecs   postersessionon         thatthosetechniquesseemedtoworkwellforotherprojectteamstacklingthe
samedataset atanevenhigherlevel wewouldalsoliketoexplorewaysinwhichtoincorporatesomeoftheadvanced
timeseriesforecastingtechniques e g autoregressiveneuralnetsorarimamodels intoatypeofensemblestructure 
thatis howcanwemakesomeofthemoreadvancedtimeseriesmethodsworktogetheronadatasetlikethiswithmany
relatedparalleltimeseries 



 

fi
references

   hyndman robj andgeorgeathanasopoulos forecasting principlesandpractice      web 
http   otexts org fpp 
 accessedondec       

   wang xiaozhe katesmith androbhyndman  characteristicbasedclusteringfortimeseriesdata  
datamining
andknowledgediscovery
                  

   oliveira mariana andlustorgo  ensemblesfortimeseriesforecasting  
proceedingsofthesixthasian
conferenceonmachinelearning
     

   bontempi gianluca souhaibbentaieb andyannalleborgne  machinelearningstrategiesfortimeseries
forecasting  
businessintelligence
 springerberlinheidelberg           

   ahmed nesreenk  amirf atiya neamatelgayar andhishamelshishiny  anempiricalcomparisonofmachine
learningmodelsfortimeseriesforecasting  
econometricreviews
                   

   hastie trevor roberttibshirani andjeromefriedman  treebasedmethods  
theelementsofstatisticallearning 
datamining inference andprediction
  nded springer          print 

   therneau terry bethatkinson andbrianripley recursivepartitioningandregressiontrees rpackageversion
          
  http   cran rproject org package rpart

   peters andreaandtorstenhothorn ipred improvedpredictors rpackageversion           
http   cran rproject org package ipred





 

fi