methods for predicting type   diabetes

cs    final project
december     

duyun chen    yaxuan yang     and junrui zhang  

abstract
diabetes mellitus type    t dm  is the most common form of diabetes  who          more than    million people in the
united states are affected by t dm and another    million are in a state of prediabetes  a condition that exhibits high
risk to progress into diabetes  nih          many t dm cases can be prevented or avoided by improved awareness
and lifestyle adjustments  nih          our project aims to improve t dm diagnosis methodologies using supervised
machine learning algorithms trained on data from electronic medical records  emr   specifically  svm  adaptive
boosting with decision trees  random forests  and logistic regression were used to build models for predicting
t dm 
keywords
diabetes  machine learning  logistic regression  svm  random forest  decision tree  adaboost

introduction
more than    million people in the united states are affected
by type   diabetes mellitus  t dm   and many cases can be
prevented or avoided by improved awareness and lifestyle
adjustments  the goal of this project is to build a model for
predicting t dm  kaggle offers a vast feature set ranging
from medical history to lifestyle data provided by practice
fusion  one of the fastest growing electronic health record
communities 
after scrutinizing the raw data set  three main challenges
were identified 
   feature selection   the data exhibits high diversity 
ranging from physical attributes and demographics to
personal data such as smoking history and medication
profile  therefore  feature selection and engineering
were very important  we chose to first select features
based on domain knowledge  all team members hold
degrees in biological fields  and literature review 
in a second pass  the features were further pruned
using both bottom up and top down sequential feature
selection methods 
   data imbalance and invalidity   because only    
of the patients in the dataset are designated dmt 
positive  the data set is imbalanced and will affect
the final training model  to address this problem 
both undersampling and oversampling techniques
were used to rebalance the data set  f  score is
used to evaluate the model performance  moreover 
approximately half of the records exhibit incorrect
information such as negative blood pressure and
impossibly low height weight  because the unuseable
data made up a significant fraction of the data set  the
focus was primarily on the raw data set  but logistical
regression was used to analyze the cleaned data set
for comparison 
   nonlinear classification   principle component analysis  pca  of the preliminary selected features with
  components revealed no clear decision boundary
between the classes  suggesting linear classifiers will

not be an optimal choice  therefore  instead of arbitrarily selecting classification methods  several specific classification models that generally work well
with such issues were chosen  support vector machine
 with various kernels   random forest  and adaptive
boosting  adaboost  with decision tree as the weak
learner 

data and methods
dataset  preliminary feature extraction and
feature engineering
this project used a publicly available emr dataset released
by practice fusion in      for a kaggle competition  kaggle
         it consists of electronic health records for      
patients  among whom       have been diagnosed with
dmt  
first  a relational database was constructed by extracting
data from   tables in the kaggle dataset     raw features
were selected as preliminary inputs for model training 
including bmi  gender  age  systolicbp  systolic blood
pressure   diastolicbp  diastolic blood pressure   ndccode
 national drug directory medication code   smoking
status  icd code  international statistical classification of
diseases and related health problems  diagnosis code  
hl   health level    identifier and isabnormalvalue
 abnormal lab result   these features were chosen based on
domain knowledge obtained through literature review  to
note  bmi is a derived variable from two of the original
features  height and weight 
different approaches have been taken to engineer
categorical features  for ndccode  binary features were used

  department

of computer science  stanford university
of statistics  stanford university
  department of computer science  stanford university
email  duchen stanford edu
yangyax stanford edu
junrui stanford edu
  department

fi 

to indicate if a patient has taken a specific medication 
to reduce the dimensionality  only the top    most used
medications were considered  for icd code     binary
features were chosen to indicate if a patient has been
diagnosed with a certain disease belonging to these   
classes  these related diseases were chosen based on
literature  for hl identifier  blood tests   all labs listed in
the data set were screened by researching the relevance to
dmt      lab tests were selected because of supporting
correlations between abnormal concentrations of these
compounds in the blood stream and dmt    eschwege 
richard  thibult        
through this preliminary filter using domain knowledge
and literature support     features out of over     were
selected for model construction and further analysis 

feature normalization and cleanup
in the provided training dataset  several features have
missing values  these cases were handled by setting them
to   
by examining the distributions of all features  a few
abnormalities have been identified  figure     for example 
despite the patients all being adults  approximately half of
them are shorter than    inches in height  also  over    
of the patients weigh less than    pounds  in addition 
negative blood pressures were observed in some cases 
since eliminating these records dramatically reduced the
data set  approximately       only logistically regression
was trained on the cleaned data set for a simple comparison 

dataset partition and rebalancing
    of the original dataset was used as validation set for
feature selection  and     was taken as a test set for
generalization error evaluation  the remaining     was used
as the training set 
two different techniques were chosen to rebalance
the class labels  undersampling and oversampling 
undersampling was performed by random majority
undersampling with replacement  and the ratio of two
classes was balanced to     by pruning the data  for
oversampling  synthetic minority oversampling technique
 smote  was used to balance the ratio of the two
classes to        the unbalanceddataset package
 https   github com glemaitre unbalanceddataset 
was
used to perform the balancing  the undersampling technique
reduced the patients without diabetes from      to      
while the oversampling method increased the diabetic
samples from      to      

models
a logistic regression classifier was trained using the glm
package in r  additional data quality check was performed
to remove extreme outliers and or abnormal values  see   
lasso regularization was performed to auto select features 
the scikit package was used to do the svm  random
forest and adaboost analyses  http   scikit learn org     for
svm  all kernels supported by this package were used in the
analysis  linear  polynomial  degree     sigmoid  and rbf
 gaussian  radial basis function   also  the regularization
parameter was varied between      and       for random
cs     machine learning  stanford university

cs          

figure    distributions of three numerical features in the raw
data set  height  weight and age  note that approximately half of
the patients exhibit abnormal height records       inches
despite being all adults      yr old   also  there are roughly
     patients who weigh under    lbs  these are considered
incorrect observations and will be excluded in logistic
regression analysis  they were not excluded from other models
due to how much the data would be reduced 

forest     trees were used  for adaboost  decision tree
was chosen as the weak learner  and the samme discrete
boosting algorithm was used  as default settings  the
maximal number of estimators at termination is      and
maximal decision tree height was set to    for later
parameter adjustment with adaboost  the maximal tree
height was varied from   to     and the number of estimators
was tested from    to     with a learning rate of    

principle component analysis
pca was performed using scikit package  http   scikitlearn org stable     and two major components were selected
for visualization 

results and discussion
model selection and data balancing
to get a preliminary understanding of the targeted problem 
we performed pca visualization using the top   major
components  figure not shown   and no possible decision
boundary was observed  therefore  we decided to only use
discriminative non linear classifiers such as svm  random
forest  adaboost  in addition  logistic regression was used
to check the effect of data cleanup 
the dataset was balanced using both undersampling and
oversampling  we found undersampling worked better than
the raw skewed data  for example  using adaboost  skewed
data has a f  score of        while undersampled data has a
f  score of         oversampling generally worked better
than undersampling  so oversampled dataset was used by
default for training and validation 

learning curve analysis
as most of the features were selected using domain
knowledge  some features could be redundant  which can
lead to overfitting  thus  a learning curve analysis using
different sized training dataset  balanced by oversampling 

fichen  yang  and zhang

 

 a  rf bottom up undersampling
figure    learning curves of the adaboost learner on training
sets of different sizes  the curves are evaluated by f  score 
blue  training data  red  test data 

with an adaboost learner was implemented and the results
are shown in figure    the learning curve concluded the
size of the training dataset did not significantly affect the
generalized f  scores  suggesting that high variance is not
an issue  therefore  retaining redundant features is not a
problem  similar results were also observed for the learning
curve analyses on logistic regression and svm models 
together  this result suggests a bias issue rather than a
variance issue 
however  since precision and recall was used instead of
other evaluation methods to plot the learning curves  the
results here may not completely rule out the existence of
redundant features  therefore  feature selection was done
despite the above results 

 b  rf bottom up oversampling

feature selection
both bottom up and top down sequential feature selection
algorithms were tested on svm  random forest and
adaboost learners  we were also interested in how
much the undersampling and oversampling techniques
improved the learners performances  so they were evaluated
simultaneously  the results of the random forest and
adaboost models are shown as precision recall curves  pr
curves  in figure   and table    we found different learners
had different weights on features 
judging from the p value of the coefficients  the most
significant features of the logistic regression are height 
bmi  weight  diastolic systolic blood pressures  age 
gender  abnormal triglyceride level  and previous diagnosis
of metabolic immune circulatory diseases 
the top   features that made the most significant
contributions to the svm model are  in order of
significance   gender  weight  height  age  systolic blood
pressure  these are not surprising  as the literature supports
them as factors for t dm  they were computed using topdown feature selection and choosing the highest decreases in
f  after removing certain features 
the top   features for the random forest model are 
circulatory diseases  metabolic diseases  blood chloride
level  albuterol treatment and septrads treatment  it is
not surprising that circulatory and metabolic diseases are
the most important indicators as diabetic patients have an
cs     machine learning  stanford university

 c  ada bottom up oversampling
figure    precision recall curves of feature selections  the
inlet graph is the zoom in of the pictures  the red dot represents
the selected feature set  rf  random forest  ada  adaboost 
top down  top down sequential feature selection 

extremely high chance to also suffer from life threatening
circulatory diseases      of people     years old   aha
         while diabetes itself is a metabolic disease 
albuterol can induce high blood sugar levels  proair        
while there is no reported correlation between diabetes and
septrads treatment  mihic mautner feness grant         or
chloride levels 
the top   features for the adaboost model are 
circulatory diseases  metabolic diseases  blood potassium
level  genitourinary urinary diseases and ill defined disease
conditions  potassium plays a very important role in diabetes
 chatterjee yeh edelman brancati          it is also wellknown that diabetes will stress the urinary system  and can
lead to many ill defined symptoms 

fi 

cs          

 a  precision recall curve with respect to various cutoff
probabilities

 b  f  scores with respect to different cutoff probabilities
figure    precision  recall and f  score of the logistic
regression classifier with respect to different cutoff probabilities 
 a  precision recall value evaluated at a range of different
cutoff probabilities   b  relationship between f  score and
cutoff probability

consistent with the varied feature weights across different
models  the feature selection was neither very effective nor
readily repeatable  figure     which also agrees with the
result observed in the learning curve  the learners did not
exhibit a high variance issue  one possible reason is that
the training process is selected by two values  the canonical
cost function in the model and the f  score for feature
selection  which intrinsically prevents overfitting  the low
bias is probably because the random forest and adaboost
methods are generally high variance techniques and svm
can also exhibit high variance depending on choice of kernel 
another observation is that both random forest and
adaboost exhibit nondeterminism  meaning the f  scores
can vary across trials  due to this random nature and the mild
improvement of f  scores during feature selection  there are
substantial variations during the selection process and some
features may be erroneously pruned just based on noise 
one final observations was that the learners prefer recall
to precision  which is desired as this project is the first trial
to identify possible diabetic patients  so high recall is better
than high precision to ensure low false negative rate 
cs     machine learning  stanford university

 a  over sampled data

 b  raw data
figure    precision recall curve of parameter search with
adaboost with decision tree on oversampled  a  and raw
dataset  b   red  selected point 

discussion and parameter selection
to obtain the best model  we also performed parameter
selection on logistic regression  figure     adaboost
 figure    and svm  table    
for logistic regression  we fine tuned the decision
boundary by altering the cutoff probability  lowering
the cutoff probability increases recall and decreases the
precision  which is preferred  the best recall score is about
     with a cutoff probability of       if consider f  score 
the optimal is reached with a cutoff probability of     
 figure    
for the adaboost model using decision tree  there were
three parameters to train  max height   the maximal height
of the decision tree  n estimator   the maximum number
of estimators at which boosting is terminated  and learningrate   the rate that each classifiers contribution shrinks 
since there is a trade off between n estimator and learningrate  we only optimized on max height and n estimator 
the selection result is shown in figure  a  it should be noted
that boosting with svm could also have been tried  as this
method has been shown to address imbalanced datasets fairly
well  wang and japkowicz         
we found that the selection process fit the training and
validation sets much better than the test set       vs    
f  scores   and as the max height increases  the f  scores
for training set and validation improved steadily while
decreasing test set  especially recall   suggesting overfitting 

fichen  yang  and zhang

 
table    svm results

method

kernel

regularization coefficient

precision

recall

f  score

svm
svm
svm
svm
svm
svm
svm
svm
svm
svm
svm
svm

rbf
rbf
rbf
 rd degree polynomial
 rd degree polynomial
 rd degree polynomial
linear
linear
linear
sigmoid
sigmoid
sigmoid

   
   
    
   
   
    
   
   
    
   
   
    

      
      
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      

      
      
      
      
      
      
      
      
      
      
      
      

table    random forest and adaboost feature selection results

method

precision

recall

f  score

rf bottom up under sampling
rf top down under sampling
rf bottom up over sampling
rf top down over sampling
ada bottom up over sampling
ada top down over sampling

      
      
      
      
      
      

      
      
      
      
      
      

      
      
      
      
      
      

this was suspected to be caused by the inconsistency
between training set and test set as the training and validation
sets were oversampled  while the test set is skewed  thus  the
skewed raw data was also used as training and validation sets
to perform the same selection  figure  b  
the search on raw dataset  as expected  resulted in
worse results  suggesting that balancing the data significantly
improved the model  and we also noticed the same
overfitting problem with high max height  however  unlike
the situation of the oversampled data  the search on raw
data actually selected high precision  not recall  which is not
desired  the possible reason is that the model favors labeling
every patient as non diabetic to reduce the training cost since
the fraction of diabetic patients is low  due to the observed
complexity of parameter selection  possible future directions
can include more sophisticated data balancing techniques  as
this was a significant factor in the results 
we also found that the parameters with max height
of   and n estimator of    gave the best result on
test data  reaching a precision of        and a recall
of         since these parameters favor a relatively lowvariance learner  we felt that the selected features probably
cannot accurately predict t dm  and leaving relatively low
correlation between features and t dm occurrence  this is
consistent with the fact that the data are full of invalid values
and needs to be cleaned 
among all the learners  logistic regression worked best 
likely because the cleaned data set with abnormal records
pruned was used  for the logistic regression model  most
coefficients are quite small  even though they are significant 
lasso regularization was chosen to introduce sparsity
in coefficients  this served as an auto feature selection
procedure  the best regularization parameter  the best
cs     machine learning  stanford university

lambda  was determined by cross validation  the final model
eliminated two features compared to the original logistic
regression model  the lasso regularization has improved f 
score by    compared to the original model 

conclusion and future work
in this project  four learning techniques were explored to
predict t dm  we made the following observations after
significant analysis 
   balancing the data set can improve the prediction  and
oversampling generally works better than undersampling 
   the data set is highly diverse and contained significant
amounts of invalid entries  preprocessing is the key as
logistic regression with the cleaned data set report the
best performance 
   the adaboost model with decision tree works best
with the un cleaned data set  but minimal height
decision tree gave the best results  suggesting the very
loose correlation between features and labels  again 
this proves data cleanup is essential 
in the future  we will focus on two aspects  a specifically
designed cleanup method  and better feature selection
through domain knowledge and other quantitative methods 
we have shown that even adding a preliminary data cleanup
step would significantly improve the generalized prediction
accuracy  and there was low correlation between features and
the true classification 

fi 

acknowledgements
we would like to thank kaggle for the project idea and also the
dataset  website 
https   www kaggle com c pf     diabetes  most importantly  we
want to thank the cs    staff for the guidance and excellent
instruction in machine learning to enable us to perform the analysis
necessary for this project 

references
causes of diabetes        http   www niddk nih gov healthinformation health topics diabetes causesnational
diabetes documents causes of diabetes     pdf 
institute of health
diabetes fact sheet        http   www who int nmh publications 
fact sheet diabetes en pdf  world health organization
mokdad a and ford e        prevalence of obesity  diabetes  and
obesity related health risk factors  the journal of american
medical association  vol      no   
practice
fusion
diabetes
classification
      
https   www kaggle com c pf     diabetes  kaggle
wang b and japkowicz n        boosting support vector
machines for imbalanced data sets
eschwege e  richard jl  thibult n  et al       coronary heart
disease mortality in relation with diabetes  blood glucose and
plasma insulin levels  the paris prospective study  ten years
later  horm metab res suppl  vol   
statistical fact sheet        https   www heart org idc groups heartpublic  wcm  sop  smd documents downloadable 
ucm        pdf  american heart association
drugs that can affect blood glucose levels       
http   www diabetesincontrol com drugs that can affectblood glucose levels  diabetes in control
m  mihic  l  s  mautner  j  z  feness  and k  grant        effect
of trimethoprim sulfamethoxazole on blood insulin and glucose
concentrations of diabetics  can med assoc j   vol    
r  chatterjee  h c  yeh  d  edelman  and f  brancati       
potassium and risk of type   diabetes  expert rev endocrinol
metab   vol  

cs     machine learning  stanford university

cs          

fi