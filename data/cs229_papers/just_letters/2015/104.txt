multiclass emotion analysis of social media posts

alec glassford and berk coker
stanford university
gla stanford edu  bcoker stanford edu

abstract
we performed    class emotion classification on tweet length social media posts 
our models were able to predict emotions with far greater accuracy than random
chance  among the models we built  the linear svm performed the best with
       accuracy  despite these results  however  distinguishing between similar
emotions remains a challenge  the high variance in human text is hard to mitigate
with model optimizations  and potential improvements with more data introduce
scalability problems 

 

introduction

social media provides a corpus of text that is rich with emotion  for our project  we were curious
to see how successfully we could implement multi class sentiment analysis on human text  specifically  we wanted to classify social media posts into    fine grained buckets  as seen below  building
a classifier that would output the mood that best describes the authors mindset in writing the text 
lonely  depressed  sad  disappointed  worried  upset  stressed  angry 
annoyed  excited  hopeful  optimistic  satisfied  thankful  thoughtful
for this task  we built and optimized the following models  multinomial naive bayes  softmax regression  linear svm   svm with rbf kernel and convolutional neural network  our selection
of models was guided by the literature review 
the ability to detect fine grained emotion in social media posts has many potential applications  for
instance  it could be used to build and maintain an emotional profile for a user to track psychological health and general well being  or even detect suicide risk  in fact  for our cs    project  we
explored using the same data to build such emotional profiles with hidden markov models  with the
classifications from this project helping define the emission probabilities 
moreover  our fine grained emotional analysis could be applied to other types of short form text  like
amazon or yelp reviews  which could provide specific feedback and insights to merchants  finally 
from a purely psychological standpoint  it is interesting to see if there is underlying structure to text
that distinguishes similar emotions like lonely and depressed 

 

related work

our review of prior work on supervised semantic analysis resulted in two important deductions 
first  we concluded that the complexity of models and methods for this task saw a dramatic change
over the past two decades  we observed that while the earlier works used linear models like linear
regression and svms  the recent ones use non linear vector space models like neural networks  in
contrast  the earlier works seem to have incorporated more sophisticated preprocessing techniques
and intricate systems  unlike the recent ones  which favor generalizable features like word vectors 
and all in one model systems for scalable and flexible applications  these improved models also
 

fiallowed for research on more challenging tasks  which brings us to the second deduction  the definition of the task has also partially changed over the past years  there was a shift in interest from
the binary categorization of opinionated text to the multiclass one  which  for instance  brought
stanfords new sentiment treebank into existence  the cutting edge research is tending toward classification with finer grained scales  as is the case  we see our project as a natural continuation of
these prior works 
in their paper  hatzivassiloglou and mckeown    focus on the task of predicting semantic orientation of adjectives  they approach the problem by focusing on conjunctions  they first train a
log linear regression model to predict if conjoined adjectives have the same polarity  and then using
a clustering algorithm  they categorize all the adjective instances into two separate clusters  the polarity is determined by the frequencies in each cluster  the higher frequency being the right polarity 
for adjectives that occur modest number of times in the corpus  they report     accuracy 
dave  lawrence and pennock     on the other hand  focus on the task of extracting opinions  they
use numerous pre processing techniques like thresholding and laplacian smoothing on counts  a
unigram naive bayes model  and an svm is used to make predictions  they also post process the
results by reweighting the predictions  they report that svms do not necessarily outperform nb
and other models  some issues they raise are ambivalence of human text and sparsity of features 
another paper on sentiment analysis is by pang and lee     who focus on the task of multiclass
sentiment analysis  unlike earlier research  this paper considers finer grained scales  they try to predict the numerical ratings in imdb movie reviews  for classification  they train one vs all svms 
which they report as performing slightly better than nb and maxent models     they also report 
however  that koppel and schler        found that applying linear regression to classify documents   provided greater accuracy than ova svms and other algorithms    
socher    takes on a more complicated formulation of sentiment analysis in his paper  he trains a
recursive neural tensor network that is based on the compositionality of phrases  with each word
having a polarity from   to   that contributes to the overall score  trained on stanfords new treebank 
the rntn model outperforms all previous methods  bringing the accuracy on movie reviews from
    up to       on binary classification 
lastly  yoon kim     in his paper uses pre trained word vectors on convolutional neural networks to do sentence level sentiment classification  he shows that a simple cnn with little hyperparameter tuning achieves better results on multiple benchmarks 

 

dataset and features

we acquired labeled data from experience project  a social networking website where users can 
among other things  share posts with a mood tag that describes how they are feeling at the time 
text  feeling better then yesterday but am lost
mood  lonely
text  job interview today    d
mood  excited

kanjoya  the company that runs experience project  provided us with        examples per emotion 
for each of the    aforementioned emotions  we removed duplicate statuses and statuses with less
than    characters to reduce noise  we were left with around between        and        examples
per emotion  which we split between a training set        a hold out cross validation set        and
a final test set       
then  we preprocessed this data in various ways throughout our experiments  but generally we
treated the status as bags of words  representing each one as a vector of term frequencies  whose
length was the vocabulary of our training set  we made sure to include punctuation as tokens  since
it is often significant to the meaning of social media posts  on the other hand  we did not distinguish
upper and lowercase text  to better capture document similarities  could be done otherwise with
more data   using the tweettokenizer from the nltk module took care of certain normalizations
that helped our models 
 

fiin some cases  we used term frequency inverse document frequency  tf idf  to transform these vectors  that is  we multiplied the term frequency weights by smoothed inverse document frequency 
    log nmt where m is the total of documents we trained on and nt is the number of documents
which term t appeared in  this had the effect of reducing the weight of common stop words  the
scikit learn implementation of tf idf that we used also normalized the lengths of our feature vectors
to    idf was learned from the training set but applied to all vectors when tested 

 
   

methods
multinomial naive bayes

this model makes the relaxed assumption that features  that is the weighted term frequencies  are
conditionally independent given the mood tags  then for an example with features x        xn   its
label y can be estimated with
n
y
arg max p  y 
p  xi  y 
y

i  

where in our case  the priors p y  are the same for each mood since our data set is evenly split
token i occurs in statuses labeled y  
these  are
among emotions  and p xi  y  is estimated by i y     times
total   tokens in statuses labeled y n
gathered from our training set  the frequencies being weighted by tf idf when we used it   and the
   and  n are laplace smoothing 
   

softmax regression

this model predicts the conditional probability of each label y given x  using the following formulation  p y   i x      i  

tx

ei
pk
j  

e

t x
j

  as each i is a probability  the sum of all i s equals to

   the model is trained by maximizing the following log likelihood  which is equivalent to finding
 that gives the maximum number of correct predictions 
l    

m
x
i  

   

log

k 
y
l  

t

e l
pk

j  

x i 
t

e j x

  y i   l 
 i 

support vector machines

and svm finds a separating hyperplane with maximal margin  and so is trained by solving the
following optimization problem  or its dual problem  
x
 
min   w      c
i s t  y  i   wt x i    b      i   i   
 w b  
i  
where w and b are weight and intercept vectors that are later used for prediction  we trained svms
in a one vs  rest scheme  that is  we trained a classifier for each mood  where x i  are our feature
vectors  and y  i  is   or   depending on whether that status is labeled with the desired mood  at
prediction time  all    classifiers are run  and then mood with the greatest margin is predicted 
   

 svm and rbf kernel

the  svm formulation is a re parametrization of the c svm 
 
  x
min   w     
i  
s t   w   x i        i   i   
 w b  
l i  
as described by schlkopf et al   the parameter  has a natural interpretation    it is an upper bound
on the fraction of margin errors and a lower bound of the fraction of support vectors relative to the
 
scholkopf  bernhard  et al  estimating the support of a high dimensional distribution  neural computation                         apa

 

fitotal number of training examples  thus on a large data set  higher  values make the nusvc model
on sk learn scalable  as opposed to svc  
in our implementation of  svm  we use the rbf kernel  radial basis function  rbf  is defined
as k x  x      exp  x  x        and is a generalization of the gaussian kernel  thus  we formulate
the dual problem as 
 x
  x
min
i j k xi   xj   s t     i   
i    
  
l i
ij
   

convolutional neural network

our implementation follows the model architecture formulated by yoon kim     in our model  each
sentence is represented as a matrix  formed by the concatenation of word vectors xi  rk  row
vectors   as shown above in the figure  to find the hidden layers  we apply the convolution operation
on the matrices  which takes windows of h words  filters them with weight wh  rhk   and then
applies a non linear transformation  such as relu or tanh  thus 
ci   f  w  xi i h    b 
a feature map c is then defined as c    c         ci        cnh      over the feature map  we apply a maxovertime pooling operation  and take the maximum value c   max c  as the feature corresponding
to the window size h  using the features generated with different window sizes  we apply a final
softmax layer to make the prediction  for the back propagation  we retrain our word vectors  and
apply dropout to prevent over fitting 

 
   

experiments  results  discussion
experiments

the order in which we trained the models follow the outline of section    thus the first model we
trained and optimized for our task was multinomial naive bayes  surprisingly  the model gave very
good results  even as a baseline  whereas a random classifier would have performed with     
accuracy on    classes  our naive bayes model was performing at        accuracy  these results
were obtained with tf idf reweighting of the vocab length document vectors  removing english stop
words decreased the accuracy by     this might be indicative of how even though semantically
trivial  some stop words have emotional implications 
after multinomial naive bayes  we trained and optimized softmax regression models  while optimizing our softmax regression model  we conducted several checks on our pre processing techniques  one of the conclusions we drew at this point was that stemming was actually decreasing the
accuracy of the models  after cross checking this with naive bayes  we decided to not stem our
words  another realization we came to was that while training logistic regression on bigrams with
count vectors was over fitting  by normalizing the vectors  tf idf was performing very well  we saw
a slight improvement when we added trigrams to our tf idf vectorizer 
the next model we trained was a linear svm  we trained this model with both tf idf vectors and
count vectors  heres the learning curve of the svm 

figure    learning curve
 
r  collobert  j  weston  l  bottou  m  karlen  k  kavukcuglu  p  kuksa        natural language processing  almost  from scratch  journal of machine learning research            

 

fito reduce the number of features to prevent over fitting  we tried applying pca on our document
vectors  this was not only not helpful  but also time costly  following that  we tried training a kernel
svm with rbf  however the size of our data made it impossible for a regular computer to train the
model in reasonable time  thus we trained a  svm instead with the kernel trick  sacrificing on
errofinally we trained a cnn model  hoping that word vectors pre trained on twitter posts  would
help better classify the documents  since they capture semantic information  the cnn model did
not outperform the svms  but it could be promising with more data  increasing the number of
examples as we trained proved this  
some other models we tried that are not included explicitly in this writeup are supervised ldas    
randomforest and adaboost 
   

results

in reporting our results  we used the accuracy metric  as we had equal number from each emotion 
making precision and recall scores less relative  another metric we thought of was giving partial
credit when the models were picking up on similar emotions  even though this approach made
sense  it did not give meaningful variations  so we dropped this evaluation metric  below we report
the accuracies obtained from each model 
model

accuracy

multinomial naive bayes
softmax regression  one vs  rest 
svm  linear kernel  squared hinge loss  c      
nusvm  rbf kernel  nu      
cnn  rbf kernel  w dim      

   

      
      
      
      
      

discussion

 a  naive bayes

 b  softmax regression

 c  svm

figure    normalized confusion matrices
one of the results we got was that svms were worse in separating positive from negative emotions 
as evident by the confusion matrix above  this was backed up with numbers we got after splitting
our mood set into two  naive bayes also seems to under perform for the emotion upset compared
to other models  a common issue is separating similar emotions like annoying and angry  as
this is the case for all classifiers  the data might be noisy  after hand tagging some posts  we were
able to confirm this  in fact after tagging     posts  we were able to get     accuracy  which means
that our models are performing close to human judgment 

 

conclusion and future work

one of the issues that we did not consider was the imbalance of emotion in space  because of our
data  we had to split emotions evenly  also with more data  we know that we can get better results
using cnns 
 

http   nlp stanford edu projects glove 

 

fi 

references and acknowledgments

acknowledgments
we thank kanjoya inc  for providing us with the sample of moods data and for being encouraging
about our research 
references
    dave  kushal  steve lawrence  and david m  pennock  mining the peanut gallery  opinion extraction and
semantic classification of product reviews  proceedings of the   th international conference on world wide
web  acm       
    hatzivassiloglou  vasileios  and kathleen r  mckeown  predicting the semantic orientation of adjectives 
proceedings of the   th annual meeting of the association for computational linguistics and eighth conference of the european chapter of the association for computational linguistics  association for computational
linguistics       
    kim  yoon  convolutional neural networks for sentence classification  arxiv preprint arxiv          
       
    mcauliffe  jon d   and david m  blei  supervised topic models  advances in neural information processing systems       
    pang  bo  lillian lee  and shivakumar vaithyanathan  thumbs up   sentiment classification using machine learning techniques  proceedings of the acl    conference on empirical methods in natural language
processing volume     association for computational linguistics       
    pang  bo  and lillian lee  seeing stars  exploiting class relationships for sentiment categorization with respect to rating scales  proceedings of the   rd annual meeting on association for computational linguistics 
association for computational linguistics       
    socher  richard  et al  recursive deep models for semantic compositionality over a sentiment treebank 
proceedings of the conference on empirical methods in natural language processing  emnlp   vol       
     

 

fi