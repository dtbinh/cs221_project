pedestrian detection with rcnn
matthew chen

department of computer science
stanford university
mcc   stanford edu

abstract

frame we generate class independent proposal
boxes  in our case with a method called selecin this paper we evaluate the effectiveness of us  tive search  then we train a deep neural neting a region based convolutional neural net  work classifier to classify the proposals as either
work approach to the problem of pedestrian de  pedestrian or background 
tection  our dataset is composed of manually
annotated video sequences from the eth vision lab  using selective search as our proposal   related work
method  we evaluate the performance of several
this paper many follows an approach known
neural network architectures as well as a baseline
as regions convolutional neural networks inlogistic regression unit  we find that the best retroduced in      this method tackles the probsult was split between using the alexnet archilem classifying and localizing objects in an imtecture with weights pre trained on imagenet as
age by running detection on a series of prowell as a variant of this network trained from
posal boxes  these proposal boxes are generally
scratch 
precomputed offline using low level class independent segmentation methods such as selective
search       though recent work has incorporated
  introduction
this process into the neural network pipeline      
pedestrian tracking has numerous applications given the proposals  a deep convolutional neural
from autonomous vehicles to surveillance  tra  network is trained to generate features which are
ditionally many detection systems were based off fed into class specific svm classifiers  this apof hand tuned features before being fed into a proach as proved successful in localizing a large
learning algorithm  here we take advantage of class of items for the pascal voc challenge 
recent work in convolutional neural networks
for the architecture of our cnn we test a
to pose the problem as a classification and local  baseline logistic method and compare it to reization task 
sults from implementations of well known cnns 
in particular we will explore the use of region these cnns include cifarnet which was develbased convolutional neural networks  the pro  oped in     for the cifar    dataset and alexnet
cess starts with separating the video into frames which won the      imagenet challenge       adwhich will be processed individually  for each ditonally we look at the effect of using pretrained
 

fiing set and two sequences        frames  in the
test set as shown in table    the annotations
are not complete in that they do not strictly label all pedestrians in a given image  it is usually
the case that only pedestrians which take up a
certain subjective threshold of the screen are labelled  this leads to what could be some false
negatives in the training set 
statistic
num images
avg pedestrians
avg proposals
pos proposals
neg proposals

test
   
 
    
   
    

train
    
 
    
   
    

figure    original image on top left  positive
selective search bounding boxes on top right 
warped background and pedestrian image on table    data statistics split up by training and
test sets
bottom left and right respectively
only a subset of the data was used  for the
two sequences in the test set  the annotations
were sparse in that they were recorded only on
every fourth frame  thus we included only the
frames which annotations existed  additionally 
for training  we set the number of proposals used
proportional to the number of positive proposals 
specifically we set the ratio at     positive pedestrian images to negative background images 

weights for alexnet and fine tuning the last layer 
the eth pedestrian tracking dataset was established through through a sequence of papers
             these papers use additional information collected including stereo vision and odometry data as additional sources of information
for their models  we are only using monocular
camera data for each of the collected video sequences 

 
 

methods

dataset and features
the complete pipeline from video frame to
bounding box output is shown in figure    we
start with a given video sequence and split it up
by frames  then we run a algorithm to generate
proposal bounding boxes  in this case we use selective search       which we cache for use across
the process  we pass these bounding boxes along
with the original image to the detector which
is our convolutional neural network  the cnn

the dataset is composed of several sequences of
videos produced by a camera on a moving platform  each frame has hand labelled annotations
denoting bounding boxes of pedestrians  overall
there are seven sequences of videos with a combined       frames  the data was split into a
training and test set where we have the frames
from five sequences        frames  in the train 

fiimg

   

proposal
bbs

iou

raw
image

proposal method
edgebox
ss

   
   

bbs
   
test

train

dataset

pedestrian
detector

scores

nonmaximal
supression

figure    comparison of selective search and
edgebox proposal algorithms

given the proposals and ground truth bounding boxes we could then generate a training set
where the proposals were labeled based on their
overlap with the ground truth images  we used a
produces softmax scores for each bounding box
threshold of     so that images which had at least
which are used in the final non maximal suppresthis overlap with a given ground truth bounding
sion step 
box were considered positive examples and the
rest negative 
figure    pedestrian detection pipeline

   

proposal boxes

we tested two different proposal box method
which were popular in the literature      the
edge box method      actually performed better
in terms of the average intersection over union
 iou  across all images in the set as shown in
figure    however we opted to use selective
search as it proposed fewer boxes and hence increased the runtime of our algorithm  we started
by precomputing proposal boxes for all frames in
the dataset  then we created an image processor
to preprocess and warp these proposals  which
varied in size and aspect ratio  into a fixed size to
input into our neural network  the preprocessing involved mean subtraction and whitening for
each frame  using these sub sampled images we
trained a convolutional neural network on top of
this data to classify a proposal as either background or pedestrian 

   

detector

we start by baselining our results relative to a
logistic regression network that we train on our
images  additonally we experiment with various
neural network architectures and measure their
performance on our task  we start with using
the cifarnet architecture which takes image at a
  x  x  scale     
for the alexnet pretrained architecture we
maintained the exact architecture specified by
the initial paper with the exception of the last
layer which was replaced by a softmax function
with two outputs initialized with random weights
     the softmax function generates what can be
interpreted as the probability for each class and
is defined as follows 
 

fi   

   

architecture
alexnet
alexnet pretrained
cifarnet
logitnet

   

miss rate

precision

   

architecture
alexnet
alexnet pretrained
cifarnet
logitnet

   

   
   
    

    

    

    

    

 

recall

  

  

  

   

false positives

figure    precision recall curves for various figure    miss rate to false positives by method
methods on test set
proportional sub sample of    images across the
entire dataset  we tested each net on the complete test set  figure   shows a comparison of
the precision and recall curves of each net when
adjusting threshold for classifying the image as
pedestrian as opposed to background  the precision and recall is calculated on the test set using
the same pedestrian overlap threshold to denote
positive examples for proposal boxes 
for alexnet with pre trained weights  all the
weights besides the fully connected layers and
the last convolutional layer were frozen at initialization for fine tuning  all other networks
were trained from scratch with weights initialized from a truncated normal distribution with
standard deviation proportional to input size 
we find that alexnet with pretrained weights
from imagenet performs the best in moderate
prediction score thresholds while a slightly larger
variant of alexnet  trained from scratch  performs better at higher acceptance thresholds 
the cifarnet performance is not that far behind 
which is interesting as it as order of magnitude

tx

ei
p y   i   x      p
k

j   e

jt x

next implement a simplified variant of the
alexnet architecture in which we remove group
convolution and local response normalization
layers  we modify the middle convolutional layers maintain full spacial depth form the previous
layers   doing so simplifies the implementation
as grouping was used primarily due to memory
constraints from training on two separate gpus
in the original implementation  these networks
were built using the tensorflow library     and
trained running on multiple cpus in parallel
 the exact number of cpus and specifications
varied as this was run across multiple servers  

 

results

after training our net for      iterations  in
which each iteration was composed a random
 

fitional training time to reach convergence as the
number of iterations we used was relatively small
compared to the amount of time it took to train
on imagenet and other large vision benchmarks 
additional hyperparameter tuning of parameters
such as regularization on fully connected layers
would also likely improve the results 
the use of region based convolutional neural networks for the task of pedestrian detection
does show promise  our example output image
shows the technique produces reasonable bounding boxes  however additional work needs to be
figure    example final output of our algorithm
done to improve the overall performance of the
system 
fewer parameters and takes input images of size
  x  x  compared to    x   x  for alexnet 
  future work
for the non maximal supression step we aimed
for a minimal threshold for our bounding boxes the main constraint of the work presented in
and used       we then did a final evaluation of this paper was lack of gpu support for runour algorithm by looking at the miss rate to false ning these models due to resource contraints 
positive curve shown in figure    we can see most cnn training is currently implemented usthat our best performance still has a    percent ing one or multiple gpus which should have a
miss rate  an example of the final output for a order of magnitude speed up  training on a
given frame is shown in figure   
gpu would allow for more iterations through
the dataset to increase the change of convergence
as well as runtime comparisons to current rcnn
  discussion
results in other domains  additionally the added
computational power would enable us to use a
we find that alexnet with pre trained weights larger pedestrian dataset such as      training
from imagenet and fine tuning of the last layers on a large dataset such as this one would allow
performs the best on a majority of the thresh  the nets to generalize better  this is especially
old levels  overall our approach still has a miss true for the larger network architectures which
rate that is too high for many real world appli  require larger training sets corresponding to the
cations  this rate can be due to several factors  larger number of parameters to tune 
first is the proposal box method  as we have
shown the best bounding boxes only had a mean
iou ratio of around     which would serve as
an upper bound on the accuracy of our overall system  next it is likely the case that our
neural networks could have benefited from addi 

fireferences
   

   

   

   

   

   

   

martn abadi et al  tensorflow  largescale machine learning on heterogeneous
systems        in  software available from
tensorflow  org    

   

jan hosang  rodrigo benenson  and
bernt schiele  how good are detection proposals  really  in  arxiv preprint
arxiv                  

   

alex krizhevsky and geoffrey hinton 
learning multiple layers of features from
tiny images       

piotr dollar et al  pedestrian detection 
an evaluation of the state of the art 
     alex krizhevsky  ilya sutskever  and gein  pattern analysis and machine intellioffrey e hinton  imagenet classification
gence  ieee transactions on             
with deep convolutional neural networks 
pp         
in  advances in neural information proa  ess et al  a mobile vision system for
cessing systems        pp           
robust multi person tracking  in  ieee
     shaoqing ren et al  faster r cnn  toconference on computer vision and patwards real time object detection with
tern recognition  cvpr     ieee press 
region proposal networks  in  advances
     
in neural information processing systems
andreas ess  bastian leibe  and luc van
 nips        
gool  depth and appearance for mo     koen ea van de sande et al  segmentabile scene analysis  in  computer vision 
tion as selective search for object recogni      iccv       ieee   th internation  in  computer vision  iccv       
tional conference on  ieee        pp   
ieee international conference on  ieee 
  
      pp           
andreas ess et al  moving obstacle de     stefan van der walt  s chris colbert  and
tection in highly dynamic scenes  in 
gael varoquaux  the numpy array  a
robotics and automation        icra   
structure for efficient numerical computaieee international conference on  ieee 
tion  in  computing in science   engi      pp       
neering              pp       
ross girshick  fast r cnn  in  inter     c lawrence zitnick and piotr dollar 
national conference on computer vision
edge boxes  locating object proposals
 iccv        
from edges  in  computer visioneccv
ross girshick et al  rich feature hierar      springer        pp         
chies for accurate object detection and semantic segmentation  in  computer vision and pattern recognition  cvpr  
     ieee conference on  ieee       
pp         

 

fi