modeling mooc dropouts
degao peng  degao stanford edu   gaurav aggarwal  gaggarwa stanford edu 

abstract
in this project  we model mooc dropouts using user
activity data  we have several rounds of feature
engineering and generate features like activity counts 
percentage of visited course objects  and session counts
to model this problem  we apply logistic regression 
support vector machine  gradient boosting decision
trees  adaboost  and random forest to this classification
problem  our best model is gbdt  achieving auc of
        about    off the kdd winner 

   introduction
massive open online course  mooc  revolutionizes education
by providing easy access to course materials through internet 
mooc can achieve a very large scale compared to traditional
schools thanks to the availability of the materials  however 
mooc also faces an embarrassing issue  because there is almost
no cost to register to a course  the dropout rate is very high  the
completion rate on coursera is only            studying
mooc dropouts can help reducing dropout rate and boost the
values of mooc  better understanding dropout behaviors can
also help improving mooc content websites to retain more
students 
in this project  we are modeling mooc dropouts using the     
kdd cup data      the task is to predict an enrollment  an
enrollment is a  user  course  tuple which means user registers a
course  will drop out or not  based on given data  the term
dropout is refer to all who failed to complete a course  input
is data sets with majority of the data being user activity log data 
and some course structure data  but no user profile data  it is
challenging to extract useful features from log data to training 
meanwhile  this problem is also very similar to other problems
many websites like linkedin and facebook are facing with
massive event log data  techniques in modeling mooc
dropouts can also be beneficial to solve these problems 

   related work
in in this section we will briefly discuss related works on
mooc dropouts prediction  we will go over major approaches
explored in mooc dropouts literature 
a large number of prior research has focused on contextual
information like discussion posts  yang et al             tried to
assess posting behaviour in discussion forum and analyze
student participation by model a concept of social positioning 
aggregated weekly actions  posts   replies  in discussion forum
were considered as a measure of social positioning  this
approach is very restrictive in application because of its reliance


on a small stream of input  discussion forum is just one of the
input among problem set  video and many other events 
similarly  some research  ramesh et al             depends on
discussion forum events including viewing a post 
upvote downvotes  cognitive engagement  and sentiment 
as per huang et al             not all students engage in peer topeer discussion forum which reduces our coverage for social
positioning 
meanwhile  some prior research do try to model behavioural
aspect of students  kloft  et al           tries to identify most
active time for a user and how that relates with drop outs  for
instance features like hours of activity facilitates identification of
night users and day users  similarly  sinha  et al            use a
sequence of events  features such as clickstream n gram looks
promising  both these work are very restricted in modelling
algorithm 
kloft  et al           explores only svm classification  another
set of prior works explore student interaction with lecture
videos  kim  juho  et al            analyzes click events from
student activities for a given mooc video  namely skipping 
zooming   playing  panning  pausing  and quitting 
after all  not all features mentioned above are available in our
dataset  we take a more generic approach by working with
student events and course structure data sets  we explore
multiple learning methods by leveraging features from        
and creating some of our own 

   data description
our data sets are sourced from kdd cup           all the data
sets are event and relationship based with no contextual
information  there is no text based information available 
overall dataset is divided into four types    course and module information  this data set provides
hierarchical information about modules and courses  a
course can have multiple modules and a module also have
multiple modules within itself  data set schema is as
follows a  module   course id module id category children start 
b  course   course id  start time  end time 
module level start time is only available for modules of
category chapter  course or sequential  majority of
modules are of problem  sequential  vertical and
video type 
  

event log  this data set provides events log for user
actions  event schema is  event time  source  event type 
module id  enrollment id    event types are evenly
distributed except wiki      and access       
a 
some events have event time before associated
module start time  that is  student interacted with
 

fimodeling mooc dropouts

  

  

module even before module was posted  this seems
like an anomaly in the data with about     of
enrollment ids in our train set 
b  page close events are corrupted as all page close
events are associated with same module which do not
exist in course information data set 
c  we find that many events       are associated with
d  modules which are not present in module information
dataset 
enrollment  this data set is a mapping of enrollment id 
student id and course id  each student can opt for
multiple courses 
completion  this is the label set with enrollment id and
    label     drop out   class distribution is skewed
towards dropout labels       against non dropouts      
labels 

   

we acknowledge that people prefer to study at a particular hour
of day or a day of the week  for instance  a full time working
professional may visit mooc only during the weekend or late at
night  we hypothesised that may be a particular time of students
are more susceptible to drop out  we created    features  one for
an hour each and   features  one for a day of the week 
   

   

round    basic count based features

since there are no directly available basic user profile data  e g 
user age  gender  occupation and etc  and course profile data
 e g  course category  prerequisites  difficulty  and etc   the log
data would be the most powerful source of knowledge  our first
batch of features are some basic counts of activities for each
enrollment  enrollment is one  user  course  entry   these
features are frequently used in many literatures of mooc
dropout study  e g           it is in this exploration that we find
kdd cup data set is somehow corrupted  with visited items in
the event log absent in course material catalog  due to the defect
of the source data  some event type has zero counts  in round   
we generate    nonzero features 
   

round    number of visits discounted by number of
items

our second bet on features is the ratio of unique items visited
discounted by the total items given in the course  in the category 
the original idea was to get the coverage of the items visited by
a user  since this gives a hint of how the user make use of the
course material and what is the proportion of material visited by
the user  we validated our findings by exploring feature matrix
and label vector using weka     figure   is an example of our
observation which showcase that students who have lower
coverage on video and problems are likely to dropout  we
observed appreciable f  score improvements over round   
table   lists all features used in round   in addition to round   
we added one new features for percentage of course modules
covered by a students from each course  in round    we generate
  additional features 
   

round    number of activity at day x

we also observe that all courses are open for exactly    days 
therefore  we use    new features  one for number of
activities    at day x  the first day of the class is day    and
added them as features  we generate    additional features in
this round 

round    study session counts of week x

we observe that students study in sessions which contain
multiple events in quick succession  we consider two events to
be in same session if they are separated by less than    min gap 
we created   features  one for total count of study session in a
given week  please note that no course extends beyond   weeks
   weeks      days  
   

   featurization

round    activity at date of week hour

failed features

here we also list some failed trials on our feature explorations 
for example 
   total enrollments per course   idea was that large class
size will have a negative effect on student experience and
hence will affect dropout rate  this feature was not fruitful
and had a negative impact on f  score and auc score 
probable reasons could have been the fact that we have only
   courses and number of students per course is in similar
range 
   maximum parallel enrollments   idea was to create a
signal to identify students who sign up for a course just out
of curiosity  these kind of students are likely to sign up for
too many courses  we added this feature but we did not
observed any appreciable positive impact  probable
explanation for this effect can be attributed to the fact that
we have only    courses data and that the data was spread
over   year           which gives very few number of
concurrent courses for students 
   average lag in viewing videos   idea was to identify
student lagging in course and hence are likely to drop out 
but we do not have data about when a video was posted 
   average lag in problems   idea was to identify student
lagging in course and hence are likely to drop out  but we
do not have data about when a problem set was posted 
   average lag in chapter   similar to    and    but we had
data for some of the chapter posting dates  this feature was
learned by logistic regression algorithm and a non zero
coefficient was assigned  but there was no appreciable
metric impact
  
amount of time spent in watching videos   we need to
identify whether a student completed a video or not  sadly
we do not have data to infer if a student completely watched
a video or not 
  
n gram events  we thought that there are some behaviour
pattern    in event log  an ideal pattern could be student
visiting video for learning  problem and then
discussion for asking any doubts  we created features
using a sequence of events for   gram and   grams  we
tried    number of events  x    source  combination which
creates        grams and        grams feature  this
 

fimodeling mooc dropouts
approach really bloated out feature count and drastically
slowed down our training step for all the models  we
believe event log data from kdd is not continuous and
probably a sampled set of data which removed sequential
pattern and affected this n gram feature

   methods
in this section we will briefly discuss learning algorithms used 
they are commonly used  thus we do not introduce the details
here 
   

logistic regression

logistic regression was the first training algorithm we tried  we
tuned lambda  l  regularization parameter  from     e       e      e       e            e      e    the best lambda for the
final feature sets is    e    logistic regression is based on
logistic function with parameter for input
as follows  

   

svm

we observe that our data set might have non linear relationships
which compelled us to try svm  we first used linear svm and
then extended to gaussian kernel  svm is large margin
classifier which try to separate positive and negative samples
with a separating hyperplane w  we need to solve following
optimization problem to find the concerned separating
hyperplane minimize  in w   b 

subject to  for any i           n 

we tuned svm hyperparameters using sckit learn grid search to
arrive at following results  linear svm c       
 gaussian svm c         gamma        
   

ensemble

ensemble method is a type of learning algorithm which rely on a
set of models for the prediction and final output is determined on
the vote of all the individual models  generally  the ensemble
model utilize bagging or boosting  the idea behind bagging is to
train multiple models and each model is trained by uniformly
sampling training data to a smaller set and output is determined
as a weighted combination of individual models  decision trees
are popular choice for individual models  on the other hand 
boosting          is an alternative to bagging  boosting rely on
training multiple weak learners and combine them to obtain a
strong learner      
     
adaboost
adaboost     is type of boosting ensemble learning algorithm 
where output is defined in terms of multiple weak learners as
follows  

where each is a weak learner taking an input x and returning a
real valued output  the sign determine predicted class  while
absolute value determined the confidence in the result  labels
are generally positive if the sample is in positive class  otherwise
negative 
we tuned adaboost using scikit learn grid search and found
n estimators     with all other default hyperparameter to be the
best choice for validation set 
individual weak learners      produces a response given by
  for each sample in the training data  we select a weak
learner at each iteration t and assign a coefficient   which
results in minimized
i e  training error at stage t 

where

is the classifier trained as part of previous

stage  e f  is also an error function and
the final weak learner 

is

we weight each sample in the the training data set  according to
the the current error e f  t    x i   on the concerned
sample this enable next set of learners to favour currently
misclassified samples 
     
gradient boosted decision trees
gradient boosted decision trees  gbdt          is an ensemble
tree learner  at each iteration  gbdt tries to generate a tree to
minimizes the error  direct minimization is usually very
difficult  therefore gbdt uses a gradient descent approach to
train the new trees to approximate the gradient of the total loss
function 
to use gbdt  one should specify the loss function to be used 
the number of trees  number of features  the learning rate  and
the maximal depth of the trees  in this study  we find that using
deviance loss with learning rate           trees of maximal
depth   and maximal features     x total number of features
optimal to our dataset 
     
random forest
random forest      is bagging based ensemble approach which
leverage random subspaces  we tuned random forest
hyperparameters with grid search to arrive at n estimators     
max depth   and max features     using sckit learn 
the idea behind random forest is that we train multiple models
as decision trees by randomly sampling training data as well as
randomly selecting features  we combine results of individual
models by taking a majority vote  overall  individual trees in the
forest is trained with three step procedure  we start with
randomly sampling  with replacement  to create a new data set
from entire data set  then  we move forward by randomly
selecting features  and then we start to build tree with this
subset of data and features 

   metrics
      accuracy
 

fimodeling mooc dropouts
the accuracy is the simplest metrics in a classification problem
which defines as the percentage of instances correctly classified
in the validation set  however  since the labels are skew with
    positives and     negatives  accuracy is not a good metric
since a dummy model predicting all positive will achieve
accuracy of     

    

roc auc

    

      confusion matrix  precision and recall
the confusion matrix is a detailed numbers of instances of a
class classified to a certain class  in this two class classification
problem  the confusion matrix is a  x  matrix with   entries 
true positive  false negative  false positive  and true negative 
shown in table   

    
gradient boosting
random forest
adaboost
logistic regression
linear svm  raw 
linear svm  normalized 

    

 

table   confusion matrix

positive
negative

with the confusion matrix  other metrics can also be defined 
for example 
precision tp  tp fp 
recall true positive rate tp  tp fn 
false positive rate fp  fp tn 
      f  scores
f  score is the harmonic mean of precision and recall 
f    precision recall  precision recall 
      roc auc
area under receiver operating characteristic curve  roc auc 
is the main metric we use to do parameter tuning and model
selection  for classifiers with probability output  a moving
threshold can change the confusion matrix and so precision and
recall  the roc curve is defined as the curve of true positive
rate v s  false positive rate varying the threshold  figure  
shows some example of roc curves in this study  the area
under the roc curve  i e  roc auc  is a number between  
and    also there is a similar concept of pr auc  i e  area under
precision recall curve  auc is a comprehensive metric that
accounts information of probability so we choose roc auc as
our main metric for hyper parameter tuning and model
selections  note that auc is the metric used in kdd cup to
judge the winner 

 
feature engineering round

 

 

figure   roc auc at different feature engineering round

actual
positive
negative
true positive
false positive
false negative
true negative

 

   

true positive rate

predicted

 

   

   
gradient boosting
random forest
adaboost
logistic regression
linear svm

   

 

 

   

   
   
false positive rate

   

 

figure   roc curve for different models

   results
wit with the features generated as stated in featurization
section  we do training using logistic regression  svm 
adaboost  gbdt and random forest  all feature processing
code is in python  link to repo  we use svmlight for svm
training t  joachims  making large scale svm learning
practical  advances in kernel methods   support vector
learning  b  schlkopf and c  burges and a  smola  ed    mitpress          and scikit learn    python to do other training
tasks  in order to do cross validation  we split the data according
to               partitioning to train  validation and test
sets  we do holdout validation for parameters tuning using roc
auc citation   data are standardized to have zero mean and
unit variance before training 

 

fimodeling mooc dropouts
figure   shows the validation auc for different round of
feature engineering  using all default parameters  at round   
we have in total    features  models are not tuned in this figure
and we just want to confirm that these feature engineering
actually have positive impact on the metric  we also observe
that standardization is very important for svm  we include
nonlinear svm and ensemble methods because we think there
may be nonlinear effects in the dataset  figure   shows that
nonlinear effects are significant in some rounds  the rest of the
paper will show aucs of all features we generated 

valiation roc auc

    

     

    
gradient boosting
random forest
adaboost
logistic regression
linear svm

     

    

 

   

   
   
fraction of data points used in training

   

 

figure   learning curve of different models

logistic
regression
linear
svm
svm with
gaussian
kernel
gdbt
adaboost
random
forest

test metrics
auc
f 
score

accura
cy

precision

recall

      

     

     

     

     

      

      

     

     

     

     

      

      

     

     

     

     

      
      
      

      
      
      

     
     
     

     
     
     

     
     
     

     
     
     

valida
tion
auc
      

for ensemble models  we also plot the validation auc v s 
number of trees in figure    these models will add a tree per
iteration  we notice that random forest models are generally
monotonically improved with more trees  while gbdt and
adaboost have a desired number of trees to reach the best auc 
more trees require more computation time  in this case  for run
time perspective  gbdt and adaboost is favorable compared to
random forest 

in this section we will briefly discuss related works on mooc
dropou in this study  we apply various machine learning
methods to model mooc dropouts  we achieve a test auc
of        from gbdt  which is    off from the kdd winner 
note that they are using a different test data sets for the judge 
we explore a couple ensemble tree models not covered in the
class  and they all performed better than logistic regression and
svms after tuning  gbdt is a very powerful learner  and
achieves very good results even at round   compare to logistic
regression 

    

validation roc auc

model

   conclusion

    

    

    
random forest  gini 
random forest  entropy 
adaboost
gradient boosting  exponential 
gradient boosting  deviance 

    

    

table   validation and test metrics on all models

 

   

   
   
number of trees

   

   

figure   convergence of ensemble tree models
in order to get best performance  we do hyper parameter tuning
for each models  the hyper parameters we tuned are listed in
models section  we do exhaustive grid search and select the
best hyper parameters according to auc on validation
data  for validation and test sets  gbdt gave the best
performance with test auc         adaboost and random
forest are the second tier  with slightly better metrics than
logistic regression and svms  the roc curves for these models
are shown in figure   
to gauge the goodness of the fitting  we also draw the learning
curve in figure    as the curve of validation auc v s 
fraction of training data used in the training 

references
  

  
  
  
  
  
  

massive open online course         december    
in wikipedia 
the
free
encyclopedia 
https   en wikipedia org w index php title massive open o
nline course oldid          
kdd cup       the website may be down already 
https   kddcup     com 
kdd cup      data set description  https   goo gl xyzzq 
kloft  marius  et al   predicting mooc dropout over weeks
using machine learning methods   emnlp                 
bussaba amnueypornsakul  bussaba  suma bhat  and
phakpoom chinprutthiwong   predicting attrition along the
way  the uiuc model   emnlp                 
weka  http   www cs waikato ac nz ml weka 
agarwal  deepak  et al   personalizing linkedin
feed   proceedings of the   th acm sigkdd international
conference on knowledge discovery and data mining 
acm       
 

fimodeling mooc dropouts
  
  
   

   

   
   
   

   
   
   

   
   
   

scikit learn package  http   scikit learn org stable index html
implementation code  https   bitbucket org lics    moocdropout prediction 
sinha  tanmay  patrick jermann  nan li  and pierre
dillenbourg   your click decides your fate  inferring
information processing and attrition behavior from mooc
video clickstream interactions   in      empirical methods
in natural language processing workshop on modeling
large scale social interaction in massively open online
courses  no  epfl talk              
yang  diyi  et al   turn on  tune in  drop out  anticipating
student
dropouts
in
massive
open
online
courses   proceedings of the      nips data driven
education workshop  vol           
huang  jonathan  et al   superposter behavior in mooc
forums  proceedings of the first acm conference on
learning  scale conference  acm       
ramesh  arti  et al   learning latent engagement patterns of
students in online courses   twenty eighth aaai
conference on artificial intelligence       
kim  juho  et al   understanding in video dropouts and
interaction peaks inonline lecture videos   proceedings of
the first acm conference on learning  scale conference 
acm       
mla
friedman 
jerome
h 
 greedy
function
approximation  a gradient boosting machine   annals of
statistics                   
friedman 
jerome
h 
 stochastic
gradient
boosting   computational statistics   data analysis     
                
freund  yoav  and robert e  schapire   a decisiontheoretic generalization of on line learning and an
application to boosting   journal of computer and system
sciences                      
breiman  leo   random forests   machine learning     
             
schapire  robert e   et al   boosting the margin  a new
explanation for the effectiveness of voting methods   annals
of statistics                   
friedman 
jerome 
trevor
hastie 
and
robert
tibshirani  the elements of statistical learning  vol    
springer  berlin  springer series in statistics      

 

fi