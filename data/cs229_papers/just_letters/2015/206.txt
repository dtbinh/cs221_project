cs    final project   medical record understanding
justin fu
justinfu stanford edu

 

daniel thirman
dthirman stanford edu

introduction and background

after completing an examination or treatment
with a patient  doctors record detailed notes known
as medical records  these records typically include a summary of past medical history  medications  a brief hospital course  discharge diagnoses 
etc 
the icd coding system is a relatively comprehensive system with support for most symptoms 
operations  and diseases  the icd   system has
over        codes  and the icd    system has
over           icd codes are important because
they are a computer readable summary that is invaluable for collecting statistics  and hospitals use
these codes to predict risk factors  mortality rates 
etc 
the problem of automatic icd coding gained
significant interest in the biomedical informatics
research community following the release of the
     computational medicine center international challenge  classifying clinical free text
using natural language processing  in particular  two styles of approaches were popular  rulebased algorithms  such as       and machine learning algorithms  rule based methods were found to
be surprisingly effective     
previous work on using text based machine
learning algorithms have typically relied on using
bag of words features and expert crafted rules     
however  such methods have been shown to scale
poorly with the large label space      and no results to date have achieved a practically usable accuracy on this problem  recent work has applied
intuitions about the structure of the problem  such
as using hierarchical svms     to leverage the fact
that the many labels are specific instantiations of
others 
the goal of our project is to understand the errors made by previous work on this problem  discover additional structure in the data  and leverage

figure    the distribution of codes on the mimic
iii dataset  the x axis is the number of codes  and
the y axis is the percentage of coverage over the
dataset 
that to build a better model and improve accuracy 

 

dataset

we used the mimic iii dataset for our project 
which contains roughly        emergency room
discharge records from a single hospital  these
notes were hand labeled with icd   codes by  
experts  two hospitals and a company  and then
aggregated together  a single note typically has
      codes 
there are several well known challenges with
existing medical record datasets  some of which
we do not attempt to tackle in this project 
   label distribution  the distribution of labels is incredibly lopsided  since only a small
minority of symptoms and diseases are common  in our dataset  a total of      labels were present  but the first     labels accounted for approximately     of all codes 
and approximately      codes had only   example  this distributino is shown in figure   
   label noise  icd codes are known to be very
noisy      for example  in the cited report 

fi    of alzheimers cases were present in the
notes but not coded  and    of cases were
coded without evidence in the note  similar
numbers hold for other diseases 

 
   

baseline model
model

for our baseline model  we used a multi label 
multi class logistic regression model with l  regularization to enforce sparsity of features  we
implemented our model using theano and used
scipy for optimization 
   

features

we tried several variations of bag of words features  and in the end  we settled on using the specialist lexicon as a dictionary containing relevant words and phrases  phrases proved to be
important  for example  the feature urinary tract
infection is a great feature for the urinary tract infection  but the individual words are very generic
and low precision 
in total  there were         phrases we extracted from the lexicon  and after filtering by frequency in our dataset  we ended up with approximately        features 
   

results

while our entire dataset had      total labels  we
focused on a small   label subset in order to do indepth error analysis  for this subset  we achieved
an macro averaged f  score of      we scaled
up to    labels  this score dropped to      we
report our results in table    and the top   features
for each code in table    unfortunately  we did
not yet find other paper in the literature that uses
the mimic iii dataset  but f  scores in previous
work have typically ranged from the     range on
   codes  with hand engineered features   down to
about     on     codes     
   

results

surprisingly  the features learned were very reasonable  except for pulmonary hypertension 
which had the lowest training support out of all
  labels 
features learned were typically drug names
 such as albuterol  singulair for asthma  
naming variations  such as hcap  for hospital
acquired pneumonia   or generally related proce 

dures  such as intubation extubation for respiratory failure  
   

error analysis

we observed several phenomena during our error
analysis  and we categorized several commonly
occurring ones  typically  different codes present
different types of errors  which means that this
list is likely incomplete since we only analyzed  
codes in depth 
      overfitting to noise
this was one of the most common errors made by
our model  for false negatives our model typically
picked up a single strong signal that was correct 
but it was drowned out by several hundred smaller
features which summed up to cancel out the correct signal  each note has on the order of        
features firing   a typical false positive looks like
 in this case  we are trying to predict pneumonia  
top features weight bottom features weight
pneumonia
     
esld
      
pna
     
neither
      
levofloxacin
     
blastic
      
lll
     
mg oxide
      
lower lobe
     
high normal
      
a false positive typically has many somewhat related  such as intubation extubation
for acute respiratory failure  or completely unrelated words with small positive scores that sum up
to a certain threshold  although we added l  regularization to enforce sparsity  it only zeroed out
some of the weights and many were still left with
small ones 
      label structure
icd   codes form a hierarchy  but if a patient has
some specific disease such as diabetes with renal
complications  the doctor does not apply every
code on the path from the root to the code of interest  instead  there are specific coding guidelines 
such as only the most specific code should be used 
or that certain codes are mutually exclusive  if our
model predicted diabetes and kidney failure  we
would be wrong  in our   code analysis  we only
used the most general forms of diseases  and thus 
we had false positives whenever a more specific
form of a disease was present 
      requires deeper inference computation
a large class of these errors arose from test results
in which the only evidence for a blood related diagnoses is a low hematocrit    of red blood cells

fiicd code
urinary tract infection
thrombocytopenia
pneumonia
acute resp  failure
anemia
cardiac arrest
asthma
rheumatoid arthritis
pulmonary hypertension
macro averaged total

precision
    
    
    
    
    
    
    
    
    
    

recall
    
    
    
    
    
    
    
    
    
    

f  score
    
    
    
    
    
    
    
    
    
    

support
    
   
   
    
   
   
   
   
  
    

table    test set f  scores for baseline model 
icd code
urinary tract infection
thrombocytopenia
pneumonia
acute resp  failure
anemia
cardiac arrest
asthma
rheumatoid arthritis
pulmonary hypertension

first
uti
thrombocytopenia
pneumonia
respiratory failure
anemia
arrest
asthma
rheumatoid
moderate

second
urinary tract infection
hit
hcap
intubation
normocytic
pea
albuterol
rheumatoid arthritis
contrast

third
urinary tract
antibody
hospital acquired pneumonia
extubation
dilution
cpr
singulair
arthritis
although

table    top indicators for baseline model 
by volume  for anemia  or low platelet count  for
thrombocytopenia   for example 
test result
diagnosis
plt smr low plt count    
thrombo 
hematocrit is       platelets     
anemia
hematocrit of     platelet count      thrombo 
our model can only pick up on single words 
and cannot execute logic such as comparing test
results against a threshold 
some more difficult errors are ones involving
judgement of the severity of an illness  our model
commonly predicted false positives for acute respiratory failure when the true label was acute
respiratory distress  since outside of explicitly
mentioning distress and failure  the two codes
present similar features  the only difference we
observed was that the failure cases were more
severe than the distress cases  and indeed  the
two codes are mutually exclusive by the icd  
coding guidelines 
     

context

a nonzero amount of our false positives came
from features firing from the medical history

section  which for some diseases should not be
coded  however  for others  such as chronic diseases  such as rheumatoid arthritis  which is an autoimmune disease which attacks the joints   being
present in the medical history is enough to justify
a code 
      multi word understanding
in many cases  the only good feature that fires is
one related to a disease  but not necessarily enough
to make a decision on its own  for example  the
following is a sentence from a note coded with
thrombocytopenia  or low platelet count 
she also had acute platelet drop
while on balloon pump and heparin 
platelet is a feature that is obviously relevant
to thrombocytopenia  but it is common to mention
it with blood tests and other blood related complications  so it is a very low precision feature 
however  the phrase acute platelet drop is very
indicative of thrombocytopenia  especially when
it is mentioned with heparin  which is an anticoagulant that commonly causes platelet levels to
drop  resulting in heparin induced thrombocytope 

fifigure    a diagram of our model
nia  abbreviated as hit  which is one of the top
features   part of the issue here is that we dont
have a good mechanism for automatically extracting good phrase features from the text 

 

full model

   

model

we wished to revise our model in order to fix some
of the errors we observed   in particular  we focused on enforcing sparsity to reduce overfitting 
high level context understanding  and multi word
understanding  a pictoral representation of our
model is located in figure   
our model is roughly split into   parts 
   we divide each document into multiple segments  we used a heuristic rule and divided
be section  such as medical history  hospital course   and score each segment with a
coarse model  we simply used a linear function with weights initialized from our baseline model  this segment selection process
helps reduce the number of features that fire 
and allows the model to assign low scores to
sections such as medical history 
   we embed the best segment  either using an
rnn  with the word embedding layer initialized with word vec  or as a bag of words 
   we score the embedding using logistic regression  linear layer   softmax   to alleviate non differentiability problems  we multiply the segment score into the logits before
passing it into the softmax 
due to time limitations  we have currently only
implemented this model to work for binary classification on one code 

additionally  there are a few architectural problems which we are in the process of figuring out
how to solve  one is that this model trains extremely slowly due to the non differentiability of
using a max for segment selection  and we are currently multiplying in the score to the logits as a
workaround instead of resorting to monte carlo
methods such as reinforce  the second is that
noisy features still end up affecting the segment
selection  which further slow down training since
only weights from the best segment get adjusted
due to the aforementioned differentiability problems 
   

results

again  due to how slowly the model trains  we
have run very few experiments for this model  so
far  we have done experiments on anemia with a
balanced dataset consisting of equal numbers of
positive and negative labels  and have achieved
a test f  score of     with the bag of words
embedding  and     with the rnn embedding 
these results are only slightly worse than our
baseline  but the problem is much easier due to the
balanced dataset 

 

conclusions

we presented a baseline linear model  which to the
best of our knowledge  has achieved comparable
results to several other pure classification based
methods that have previously used 
we have not seen good results from our full
model yet  but we are in the process of running
more training iterations and possibly rethinking
our architecture to make it easier to train 

 

future work

there are several potential problems of interest
that we have not addressed in this project  one is
exploiting the structure of the codes labels  since
we know that some labels are mutually exclusive 
some are a conjunction of two other labels  and
some are subclasses of other labels  the subclass
observation has been explored in previous work 
but not the others 
another potential problem to tackle is addressing the codes which have little training support be
exploiting outside knowledge  each code has a
short description  and using knowledge bases or
the internet can provide the additional information

finecessary for a model to justify a label  however  since these are rare codes  its not clear if
there is a strong practical need to get these correct 
and much of previous work  especially ones with
hand engineered features  have only focused on
subsets of codes  as we have done in this project 
finally  an important problem to tackle is the issue of noisy labels in the dataset  we wish to apply
ideas such as semi supervised learning and bootstrapping to improve our models ability to handle
label noise 

references
    ira goldstein  anna arzumtsyan  and ozlem
uzuner  three approaches to automatic assignment of icd   cm codes to radiology reports  in amia annual symposium       
    adler perotte  rimma pivovarov  karthik
natarajan  nicole weiskopf  frank wood  and
nomie elhadad  diagnosis code assignment 
models and evaluation metrics  in journal
of the american medical informatics association  jamia        
    stefano g  rizzo  danilo montesi  andrea
fabbri  and giulio marchesini  icd code retrieval  novel approach for assisted disease
classification  in data integration in the life
sciences  dils        
    suchi saria  gayle mcelvain  anand k  rajani  anna a  penn  and daphne l  koller 
combining structured and free text data for
automatic coding of patient outcomes  in
amia annual symposium       
    illes solt  domonkos tikk  viktor gal  and
zsolt t  kardkovacs  semantic classification
of diseases in discharge summaries using a
context aware rule based classifier  in journal
of the american medical informatics association  jamia        
    wei qi wei  pedro l  teixeira  huan mo 
robert m  cronin  jeremy l  warner  and
joshua c  denny  combining billing codes 
clinical notes  and medications from electronic health records provides superior phenotyping performance  in journal of the
american medical informatics association
 jamia        

fi