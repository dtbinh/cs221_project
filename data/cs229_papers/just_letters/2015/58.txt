improving search for explorecourses

eddie wang
stanford university
stanford  ca      
eddiew stanford edu

sam redmond
stanford university
stanford  ca      
sredmond stanford edu

 

introduction

currently  using stanfords default course catalog  explorecourses  is a frustrating experience for
users  the current search implementation on explorecourses generates course results by substring
matching a users query against course codes  titles  instructor names  and descriptions  and then
sorts the results in alphabetical order by course code  while not terrible  this strategy often leads to
situations where the most relevant courses are not on the first page of results  which is the source of
many headaches come class registration time  most significantly  the most relevant results are often
not even on the first page  students have to search several different variations of a single concept in
order to find the best courses  additionally  since explorecourses works by exact substring match 
it can be sensitive to slight differences in search terms 
we chose to pursue this problem because improving search for explorecourses will benefit not just
ourselves as students but also the whole of the stanford community  the classes we take are integral
to our intellectual vitality  so it is very important that students have the right tools in hand to find
courses 
the input to our algorithm is a string representing a users query  e g  machine learning   using a
composite model that we have built  we then generate an ordered list of courses with high relevance
to the given search string  e g   cs              

 

related work

the usage of vectors to represent the meaning of words for the purpose of analysis has been studied
extensively          the current state of the art model  word vec  is described in      recently  an
extension to word vec to obtain vectors for sentences and paragraphs was proposed in      this is
done by treating each paragraph  or label  as a context word used as an additional input feature  this
project uses the distributed memory model of paragragh vectors  pv dm  described in that paper 
with a neural network language model  nnlm  as described in     
no prior literature exists on improving search specifically for explorecourses  but usage of word
vectors in search engines is described in     and is widespread today  additionally  neural networks
have been applied to topic spotting      a very similar problem to searching for relevant courses 
that being said  modern search engines still favor substring matching over semantic matching  and
the technique used in      where a neural network classifier is trained for each of    topics  would
be infeasible for our dataset of    thousand courses 
additionally  we initialize training with pretrained word vectors obtained from      the pretrained
vectors were trained on roughly     billion words from google news  using a skip gram model with
negative sampling as described in     
 

fi 

dataset and features

our data comes from the           explorecourses course listings      and contains information
about the    thousand courses stanford offers this year  for each course  we scrape its code  title 
and description  giving us a dataset of    thousand unique tokens and     million total tokens 
cs   a  programming methodology 
introduction to     and testing  uses the java programming language     
our pv dm model must be trained on a list of labeled sentences  where the label for each sentence
corresponds to the course with which it is associated  to obtain the labeled sentence list for a
particular course  we apply the following processing steps 
   tokenize sentences with the punkt sentence tokenizer from the nltk natural language
processing library      this tokenizer is an unsupervised machine learning algorithm pretrained on a general english corpus  and it can differentiate between true sentence breaks
and periods used in abbreviations  we treat the course title as a sentence 
   tokenize words with penn treebank tokenization 
   identify and condense likely bigrams 
we condense likely bigrams  such as
machine learning  into a single token machine learning  because the bigram
often has a different meaning than the average of the component words  this is done according to the collocation likelihood ratio metric described in      
   tag each sentence with the course code 
after processing the example course  we obtain the following labeled sentence list 
   programming  methodology   cs   a  
  introduction  to       and  testing      cs   a  
  uses  the  java  programming language      cs   a  
    
each of these labeled sentences is one training example  and our training set consists of    thousand
such labeled sentences 

 

methods

we use a composite model  averaging the results of two models  a course vector model and a naive
bayes word vector model 
   
     

training
word and course vectors

both models use word and course vectors to obtain query results  so we train a pv dm model
according to      our pv dm model uses a nnlm with   hidden layer of     nodes  and we use
huffman tree hierarchal softmax to efficiently represent our sentences as in      this model produces
    dimensional vectors  to match the dimensionality of the pretrained vectors 
we begin training by initializing the word vectors to pretrained values  or to random values if unknown  pretrained words learn at     of the normal rate to reflect the difference in how much they
have to learn  we train with stochastic gradient descent for     epochs  tracking the total absolute
difference in vector weights  if the absolute difference does not decrease over   epochs  we decrease
the learning rate by     to improve convergence 
     

word course probabilities

for our naive bayes word vector model  we compute a mapping of words to their most related
courses  we make the naive independence assumption  each word in a courses information is
 

fiindependent of the others   allowing us to use bayes theorem to compute the probability that a
particular query word w came from a particular course c 
p  c   w   

p  w   c p  c 
p  w 

we compute this probability for every word course pair and construct a mapping as follows 
java   cs   a         engr  a         cs          
 ms e            cs   a           
   

predicting

figure    flow chart illustrating the prediction process 
upon receiving a query string  we convert the string into a query vector by averaging the word
vectors  using the pv dm model to predict a label vector gives highly variable results   we feed
this vector into the two models  described below  obtaining two lists of course suggestions with the
confidence for each suggestion  we compute the final list of suggested courses by averaging the
confidences for each suggestion  this process is outlined in figure   
     

course vector model

given a query vector v and a requested number of results n  we find the n most similar labels  corse
codes  by cosine similarity  we choose cosine similarity over euclidean distance because cosine
similarity accounts more for differences in vector direction  a labels cosine similarity to the query
vector represents the models confidence in that label  we pair each course with its cosine similarity
and return the n  course  similarity  tuples 
     

naive bayes word vector model

this model also takes a query vector v and a requested number of results n  it begins by finding
the    most similar words  synonyms  to the query vector by cosine similarity  we treat the cosine
similarity of a synonym si to the query vector v as the probability p  si   that the user would be
satisfied with searching for that synonym  this allows us to compute the probability that the user
queried for a particular course c given the query vector v as 
y
p  c   v           p  si  p  c   si   
i

we take the n most likely courses by this metric  with each courses score given by
score  

 
   p  c   v 

representing the models confidence in the course  we return the list of n  course  score  tuples 
 

fi 

results

in both qualitative and quantitative tests  our model outperforms explorecourses  in no cases does
our model perform worse 
we seek to increase the relevance of course search results  so we measure success subjectively
by analyzing sample queries and conducting user tests  it is often the case that students query
explorecourses without a particular course in mind  they are using explorecourses to find courses
that might interest them  given this behavior  it doesnt make sense to evaluate our model objectively
with a test set 
qualitative evaluation
by inspection  our model outperforms explorecourses for a plethora of sample queries  we present
three searches that demonstrate some of the different types of queries that students make  table    
these queries demonstrate how our model outperforms explorecourses in a variety of ways 
table    sample queries illustrating the difference in top three results generated by explorecourses
 middle  and our composite model  right 
query

explorecourses results

composite model results

computer
programming

bio physics of
multi cellular systems
physics based simulation
computational genomics

violin lessons

none

linear algebra

advanced feedback control design
numerical methods in engineering
mechanical vibrations

introduction to
computing principles
programming service project
introduction to computers
introductory violin class
violin
advanced violin
calculus
modern algebra
linear algebra and
differential calculus

the first query  computer programming should return introductory computer science classes 
however  explorecourses returns several bioengineering classes that happen to contain both computer and programming in their course information  in contrast  our model finds relevant courses
  cs     cs     and cs     other relevant results  cs   a  cs   b  and cs   x also appear
on the first page of results 
the second query illustrates a problem with explorecourses in that both search terms must appear
in a courses information in order for it to be found  no courses exist that contain both violin and
lessons  so explorecourses generates zero results  in this case  our model is able to find stanfords
three violin classes because it also looks for synonyms of lessons 
the third query demonstrates searching for a specific topic  it seems fair to assume that a student
searching for linear algebra expects to find classes about linear algebra  not classes which merely
use it  however  explorecourses doesnt differentiate between these two concepts  and in this case
it returns the alphabetically first classes for which knowledge of linear algebra appears as a prerequisite  our model again outperforms explorecourses by finding math classes which teach linear
algebra or are highly relevant to classes that do 
quantitative evaluation
we asked    students to assess the performance of our models against explorecourses across three
query categories  each student generated    queries in a given category before giving an overall
relevance score from    not relevant at all  to    extremely relevant  to a specific model in a specific
category  in increasing order of generality  the three categories were  i  searching for a specific
 

ficourse in a particular subject area   ii  finding any courses on a specific topic or within a specific
department  and  iii  finding any course on a general topic  results are shown in table   

table    average scores  out of    given by n    students assessing performance of different models
across a variety of search categories
category

explorecourses

course vector

nb word vector

composite

specific course
specific topic
general topic

   
   
   

   
   
   

   
   
   

   
   
   

total

   

   

   

   

unsurprisingly  explorecourses performs poorly across the board  the explorecourses results get
worse as the queries become more abstract  because of its reliance on exact substring matches  interestingly  the course vector model actually performs better on generic queries  because its course
vectors capture abstract  high context meaning  the naive bayes word vector model does extremely
well on specific searches  especially because it builds synonymous queries to ensure that any courses
close to the query string are produced  as expected  nb word vector model is weaker for generic
searches  because there are fewer specific search phrases to work with 
our composite model yields not only the highest relevance results overall  but also the most stable
results across the three categories  by combining the strengths of the course vector model and the
nb word vector model  the composite model is able to accurate find good courses whether students
search for something as specific as a single course or something as vague as a general topic 

caveats
as always  we need to be cognizant of overfitting to our training set  however  for this project our
training set  the entire stanford course catalog  represents the entire universe of discourse  therefore  overfitting isnt a serious problem  because we will never need to generate courses that arent
in our training set  while its possible that new courses could be added  or old course information changed  this happens at most four times per year  and the model can easily be retrained that
frequently 

 

conclusion

in conclusion  we have built a model that generates a list of highly relevant courses given a search
query by combining two existing models trained on the entire corpus of existing stanford courses 
one component model uses cosign similarity on a query vector to find similar courses  and works
very well on general queries  the other component uses a combination of word vec and naive bayes
to find synonymous queries and associated courses and works very well on specific queries  these
results are then aggregated  weighted by their relative confidences  to yield final results  overall  the
suggested courses have much higher relevance in a number of search categories  and seems to be a
qualitative and quantitative improvement over the existing explorecourse implementation 
in the future  we hope to integrate our search tool with explorecourses in production so we can
obtain vital statistics about usage patterns which we can then use to improve the model  ideally 
we would a b test different parameter choices at scale in order to gain a much more accurate idea
of what the best  most relevant courses are for common queries  additionally  if we replaced our
nnlm with an recurrent nnlm  we may see slightly better performance 
 

fireferences
   tomas mikolov  kai chen  greg corrado  and jeffrey dean  efficient estimation of word representations in
vector space  iclr workshop       
   tomas mikolov  ilya sutskever  kai chen  greg s corrado  and jeffrey dean  distributed representations
of words and phrases and their compositionality  advances in neural information processing systems  p               
   y  bengio  r  ducharme  p  vincent  a neural probabilistic language model  journal of machine learning
research                    
   quoc v le and tomas mikolov  distributed representations of sentences and documents       
   http   www puttypeg net papers vector chapter pdf
   wiener  erik  jan o  pedersen  and andreas s  weigend  a neural network approach to topic spotting 
proceedings of sdair      th annual symposium on document analysis and information retrieval  vol      
     
   https   code google com p word vec 
   http   explorecourses stanford edu 
   kiss  tibor and strunk  jan         unsupervised multilingual sentence boundary detection  computational linguistics            
    manning  christopher d   and hinrich schtze  foundations of statistical natural language processing  mit
press       
    gensim  topic modelling for humans  radim rehurek       

 

fi