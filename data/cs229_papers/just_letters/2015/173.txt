sound texture classification
using statistics from an auditory model
gabriele carotti sha

evan penn

daniel villamizar

electrical engineering
stanford university
email  gcarotti stanford edu

mangement science   engineering
stanford university
email  epenn stanford edu

electrical engineering
stanford university
email  danvilla stanford edu

abstractthis project aims at applying machine learning techniques for the classification of acoustic textures and environments 
results are shown for different supervised learning methods 
indicating that some of the proposed features are particularly
useful for textural recognition 

i  i ntroduction
sound textures may be defined as a category of sounds
produced by the superposition of many similar acoustic events 
falling rain  boiling water  chirping crickets  a moving train
are some examples whose perceptual qualities can be captured
to great extent by a small set of statistical measures  as
shown by mcdermott and simoncelli      as described in
their paper  extensive work has been done to     analyze the
features of sounds that are potentially used by the auditory
system for textural recognition and     develop synthesis
techniques to generate realistic sounding textures based on
these features  the notion of a texture is similar to that used
in image processing  where new images are generated by first
identifying characteristic distributions at each sample point of
an exemplar and then extending those distributions to generate
repeating patterns 
as a natural extension of this work  we propose the application of standard machine learning techniques to verify whether
this same feature set can be used for classification 
some audio texture examples are shown in figures      
and    as can be seen  certain characteristics of the spectrum
can be discerned to differentiate one class of sounds from
another  however  it is in some cases difficult to know what
class a particular texture belongs to  note that for a human
listener recognition is not a difficult task for the particular
waveforms we chose  apart from steady state behavior  context
and temporal pattern are extremely important psychoacoustic
cues as well  the question is how small a feature space can
we utilize for the purposes of classification 
ii  dataset and f eatures
a  perceptual model
we replicated the model of the auditory system developed
in      the input waveform  generally between   to   
minutes long  is windowed into   second time frames with
    overlap  each frame serves as a training sample for
measurement  each window is then convolved with a bank of

fig     birds chirping

fig     thunderstorm

fig     crickets

equivalent rectangular bandwidth  erb  cosine filters whose
center frequencies correspond to the masking sensitivity of
human hearing across the spectrum  qualitatively  acoustic
stimuli with the same intensity are more easily discriminated
at lower bands than at higher bands  the erb bandwidths
capture this phenomenon by providing finer resolution at the
low end and increasing non linearly up to nyquist 

fithe envelope for each subband is then extracted by taking
its hilbert transform  a compression is applied in order to
simulate the nonlinear sensitivity of the auditory system to
intensity levels  finally  a second filter bank is applied to each
subband  further subdividing it into    modulation bands  see
figure     all filters are implemented as raised cosines so as
not to introduce any power gain 

iii  m ethods
we ported the public distribution of the sound synthesis
toolkit     to python  implementing the previously described
model  we then applied four different supervised learning
methods  random forest  decision tree  regularized linear regression  and support vector classification using the scikitlearn distribution     
these features are numerous  leading to a need to avoid
overfitting  we did this by keeping track of performance on
meaningful feature subsets  we propose that there are two
possible ways to use the recorded data when building the
train test set  one way is to take training and test samples

fig     perceptual model implemented by mcdermott and
simoncelli  indicated as m are the moments computed for each
subband and modulation band  c and c  indicate correlations
between subbands  whereas c  are the correlations between
modulation bands of a given subband 
fig     train test error for svm with regularization of    
b  measured features
each input waveform is normalized  by signal rms  so that
the respective measures are on the same scale  the computed
measures are  first through fourth moments and autocorrelation
of each input subband  fourth through fourth moments of each
subband envelope  power of each modulation band for each
subband  this is a smaller set than that used by mcdermott
and simoncelli  since they also included correlations between
pre modulated subbands and between modulated subbands 
this was essential for synthesis  but not necessarily for classification 
c  dataset
train and test data was collected by taking live recordings of
various acoustic environments  cafes  train and metro stations 
and by accessing royalty free content online  we maintained
input sampling rates at the limit of human hearing       khz 
with bit rate of either    or    bps  train and test samples
were taken from different recordings as an attempt to avoid
overfitting 

fig     train test error for random forest classifier using   
estimators

fifrom the same recording randomly  this would account for
the scenario where we are trying to make predictions using
the same equipment in a similar environment  another way is
to make the train test data mutually exclusive with respect to
the recordings such that no recording has windows in both the
train and test split  this allows us to measure generalization
performance over different instantiations of textures  rather
than simply different time points in the recording of a single
texture  nonetheless  our models tended to fit the training data
perfectly  and show only mediocre performance on test data 
further experiments showed that regularization strength did
not make a large difference in either test or train performance 
clearly  more work is necessary 
we then performed feature selective and ablative analysis
to determine the impact of the feature categories as shown in
the tables below  the first set of features only includes correlations between subbands  the second set includes subband
moments  mean  variance  skew  and kurtosis  the third set
includes envelope features  while the last set shows all features
combined 
we also attempted to implement a blended model that took
into account all of the other models  for this  a validation
set was exstracted from the test set  the validation set was
not trained on  instead  for each model the predicted class
probabilities were kept for each validation row  this new
matrix  with each row corresponding to a validation data point
and k columns for each model where k is the number of
classes  we then fit a logistic regression on the blended dataset 
this did not yield an improvement  it may be because

fig     logistic regression confusion matrix

iv  r esults
fig     random forest confusion matrix

a  model results
initial results using train test data from the same recordings
showed a tendency to overfit as we discussed earlier  see
fig    and     our error plots show this trend  we show the
confusion matrices  using all features  for logistic regression
 one vs all  and random forest with    trees  the tables  last
page  provide a breakdown of performance by model and
feature subset on training and testing data  measured in simple
accuracy  we see that logistic regression typically performs
best  perhaps because its decision function is less complex
and so resists overfitting  this data has    classes  so we are
well above random guessing level 
v  c onclusion
a  possible applications
given that each feature has an explicit physical meaning 
the supervised classifiers thus generated can be implemented
using specialized signal processing hardware  this offers the
benefit of low power consumption while maintaining high
classification performance  these devices can be used to
enable systems to become aware of the textural information
of their environment  this could be useful  for example  in
locations where visibility  or any non acoustic sensing  is
impaired  this technique could also be useful in voice texture

recognition where the goal is to identify who is speaking rather
than what they are saying 
b  future work
our initial idea was to test whether this feature space
could serve not only the purposes of classification of simple
sounds  but also that of more complex signals  environments or speech   the first hurdle is that these features  as
mentioned previously  are characteristic of the steady state
signal  transient information is essential to speech and to
timbre information in general  a violin note  for example 
is perceptually characterized by its onset as much as by
its sustained acoustic behavior   the model would therefore
have to incorporate some of the standard acoustic features
 cepstral components  gaussian mixtures  etc   used for more
sophisticated applications  however  another direction to take
would be to concentrate on the steady state behavior of an
input source and study the limits of this representation  for
example  though speech involves phonetic variation  the timbre
quality of a persons voice  as in the sustained note performed
by a professional singer  may very well be described by sets of
time averaged measures  incorporating this information with

fitime varying structure could aid in realistic and personalized
vocal synthesis or recognition 
acknowledgment
the authors would like to thank prof  andrew ng and the
entire staff of cs    at stanford university for teaching an
inspiring course  we would also like to thank hyung suk kim
from the dept  of electrical engineering  stanford university 
for pointing us to mcdermotts research 
r eferences
    j  h  mcdermott  e  p  simoncelli  sound texture perception via statistics
of the auditory periphery  evidence from sound synthesis  neuron       
    http   mcdermottlab mit edu bib php publications php
    http   scikit learn org stable 

fitable i  training error vs  feature subset for training data
model
random forest   trees
random forest    trees
random forest    trees
decision tree  max depth  
decision tree  max depth  
decision tree  no max depth
logistic regression      regularization
logistic regression      regularization
logistic regression      regularization
svm  rbf kernel     regularization
svm  rbf kernel      regularization
gradientboostingclassifier
ensemble
avg

subband correlations

pre modulation moments

modulated

all features

    
    
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    
    
    
    

table ii  training error vs  feature subset for test data

random forest   trees
random forest    trees
random forest    trees
decision tree  max depth  
decision tree  max depth  
decision tree  no max depth
logistic regression      regularization
logistic regression      regularization
logistic regression      regularization
svm  rbf kernel     regularization
svm  rbf kernel      regularization
gradientboostingclassifier
ensemble
avg

subband correlations

pre modulation moments

modulated

all features

    
    
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    
    
    
    
    
    

fi