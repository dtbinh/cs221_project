kpi driven predictive ml models approach
towards municipal budgeting optimization
bo shen

pradipta a  b  hendri

kun shao

 boshen  dip  kunshao  stanford edu
 cs    machine learning project final report 
abstract this project aims to use machine learning
techniques to predict cities key performance indicators
 kpi  based on municipal governmental budget components towards segments including education  public safety 
and health  the project started with building prediction
model for the city of palo alto and then generalized the
model for a cluster of cities that contains the city of palo
alto  the result shows that autoregressive linear models
can predict crime index and health index reasonably well 
by building satisfactory kpi prediction models  this project
sets a path towards municipal budgeting optimization 
i  introduction
key performance indicators  kpis  of a city are a set of metrics used to evaluate factors that are crucial to the success of a
city  government annual budgets name and prioritize regional
kpi  through agency sub budgets and programs  agency missions are turned into programs addressing single or multiple citizen concerns about economic development  education  energy 
environment  health  housing  shared infrastructure  public
safety and other factors 
budgets reveal spending by a single program in isolation 
given the complexities of urban life  a single kpi  for instance 
health  can be the function of multiple other elements  such as
environmental and food pollutants  housing quality  transportation use  and education   likewise  strategies of improving any
given kpi can be ways of budget allocation across multiple agencies 
the project aims to use machine learning to predict kpi using
municipal budget data and set a path to optimize a part of or
entire budget towards certain kpis 
ii  methodologies
as an overview  we began with accumulating budgeting and
kpi data for different cities in the us  we started with building
prediction model for the city of palo altos crime index  we
then applied unsupervised clustering on demographics data of
these cities to identify similarity groups and attempted to generalize the prediction model  the cluster to which palo alto belongs was chosen as the group to which we generalized our analysis 

a  kpis
cities and other independent parties evaluate the performance using metrics such as the following 
   crime rate  as a measure of safety
   proportion of residents self reporting better than fair or
poor health  as a measure of health of city residents
   ratio of average household income to cost of living index  coli   as a measure of affordability
   ethnicity diversity index  which is a normalized measure
of ethnicity composition deviation index relative to statewide ethnicity composition
it is the interest of municipal government to develop the necessary infrastructure and environment to bring the maximum
benefit for the inhabitants  and kpi driven approach is a succinct method to summarize the performance of a city when it
comes to numerical calculations within a data driven decision
support system 
b  budget components
municipalities produce comprehensive annual financial report  cafr  that they publish on online and printed media  the
cafr segments city financial budgeting as follows 
category of cafr components
revenues

expenses

sales and use tax revenues
property tax revenues
other tax revenues
charges for services
licenses and fees
intergovernmental grants
investment earnings
miscellaneous revenues
total revenues

general government expenses
human resources expenses
public safety expenses
public service expenses
public works expenses
environmental expenses
other program expenses
capital outlay
principal debt service
interest debt service
total operating expenses

category of cafr components  continued 
sources   uses

change in fund balances

ratios

neglected

neglected

neglected

fithese components serve as categories of focus areas in which
the city invest for maintenance and future development  bloomberg l p  collected these financial data from numbers of cities in
the united states  and we can access data through bloomberg
professional service provided in special bloomberg terminal 
c  data set
for financial data  we obtained cafr data from     cities in
california for years between      and      
for kpi data  we obtained crime rates  cost of living index 
health index  and median income from all cities in the united
states annually  from      up to      
for demographics data  we obtained      census population
data of all census registered cities in the united states 
to aggregate the data  we chose geoid primary index provided by united states census bureau to establish relationships
in the rows of data obtained from different data sources 
d  regression analysis
first  we attempted to predict the crime index of the city of
palo alto using its financial data  we explored five regression
models 
   bayesian linear regression 
   neural network regression 
   boosted decision tree 
   linear regression  and
   decision forest regression 
among    financial features  we first cleaned the missing data
by removing features with missing data  it left us with    features with complete dataset 
for each of the five regression models  we first trained the
model using the all    features with complete dataset  then  we
trained the models using just one feature  the public safety expense  which intuitively  we think is most correlated to crime index  lastly  we used filter based selection methods to identify
the features that are most predictive  and trained the models using the top two features  the five feature scoring method we
tried are 
   pearson correlation  pearsons   
   mutual information  mi  
   spearman correlation  spearmans    and
   chi squared       test 
we apply this method to more cities as determined by the
clustering result  and obtain a more generic model trained with
data belonging to multiple cities instead of a single one 
e  unsupervised clustering
it is a possibility that there are multiple underlying models
between financial budgeting and kpis for cities depending on
some hidden factors  in reality  cities dissimilar in scale and living standard require different policies of governance to make
successful progress  to generalize the prediction model  we attempt to establish similarity clusters of cities in the dataset
based on scale and living standard  with the following factors
considered 
   population census in     
      year population growth from      to     
   total revenue per capita in     
   total expense per capita in     

   c ers cost of living index  coli  in     
each cluster will have its own regressive model  ultimately allowing higher degree of freedom to the big picture  to reduce
generalization error  we explore multiple clustering algorithms  which are 
   k means clustering 
   k medoids clustering 
   agglomerative clustering  and
   gaussian mixture model 
we determine the cluster count using    norm silhouette
value as a measure of purity from dissimilarity  higher is better  
silhouette     

                
      
max                    

where 
     centroid of cluster containing 
       centroid nearest to  satisfying           

in addition  separately for each algorithm and cluster count
we remove outlier points from data that induces the algorithm
to create clusters containing low number of points  with this reduced data set  we run each clustering algorithm with     replicates per cluster count  choosing the result that maximizes
mean silhouette value  we then choose the model that maximizes the mean silhouette value over different cluster counts  the
pseudo algorithm for each clustering algorithm is as follows 
def n replicate      
for k     to sqrt size data   
def data k   data
def c low    dummy point 
while size c low      
run clustering on data k
if any cluster has less than min size points 
c low   join all clusters with size   min size
remove all points in c low data from data k
end while
for r     to n replicate 
def index kr   result of clustering on data k

def sil kr   silhouette value of index r

if mean sil kr    mean sil k  
index k   index kr  sil k   sil kr
end if
end for
end for
def index   index k that maximizes sil k over k

iii  results
a  baseline model
first  we attempted to predict the crime index of the city of
palo alto using its financial data 
the results of feature scoring in descending order is shown
on figure    to evaluate the models     fold cross validation
was used  the estimated generalization errors of each model in
terms of root mean squared error  rmse  are presented in figure    each row represents errors of models using different sets
of features  for example  the row  public safety expenses  shows
the errors from just using one feature  public safety expenses 
the row  pearson correlation  shows the errors models using the

fitop two features selected by pearson correlation method 
among all the models we trained  the linear regression model
using the public safety expenses alone was able to predict the
crime index with the lowest error of       

shown in figure    additionally  another criterion is applied for
a model with given parameter to be acceptable  all cluster
within the model must have at least one point with silhouette
value higher than the model wide mean silhouette value  points
satisfying this criterion is marked with black circle in figure   

top   features using   
top   features using
spearmans 
top   features using mi
top   features using
pearsons 
public safety expenses only

all features

linear

bayesian linear

 
  
  
  
nn decision forest

      
boosted dt

figure  cross validation rmse of baseline model 

figure  clustering algorithms performance comparison 
figure  feature scoring 
b  unsupervised clustering
unsupervised clustering was applied against separately obtained scale and living standard data for     cities in california
as described in part e of methodologies  unfortunately  some
values are found to be missing after merging the factors  due to
the nature of unsupervised clustering  it makes little sense to
apply imputation or surrogate techniques  so we simply remove
points having one or more missing factors and were left with
    points  clustering performance based on silhouette value is

from figure   we can observe that gaussian mixture model
quickly degenerates with increasing cluster count  whereas the
other   considered algorithms performs similarly  we note that
silhouette value by definition will be high for cluster count of  
so long as the algorithm is allowed to converge  due to    norm
being used for both clustering and silhouette  as           
always in this setting  keeping silhouette       for all points 
with this consideration  as well as desire to lower the size of
cluster to which palo alto belong  we pick the agglomerative
clustering model pruned to   clusters because it maximizes the
silhouette value  figure   illustrates how this model clusters the

fipoints  using principal components  we found     cities similar
to palo alto based on the factors considered 

in figure   we see that the cross validated   receive little to
no improvement past the first order of autoregression  so in the
interest of simplicity and avoiding overfitting  we opt for the
first order model 
                                           
where 
     crime index of the year
        crime index of preceding year  autoregressive 
     public safety expense of the year  in million us 

figure  agglomerative clustering on pca  k   
based on our baseline model findings in figure    we determine that the project should be scoped to linear models  to improve the performance of models  we augment stepwise linear
model construction with autoregressive terms  the significance
of autoregressive terms is supported by assumption that preexisting quality of life in the city affects the extent to which
budgeting decision for the year could influence the outcome of
the development which is incremental in nature 
c  public safety kpi
we applied linear model augmented with autoregressive
terms to the public safety kpi  which is the crime index of cities
inside cluster containing palo alto  the chronological extent of
our dataset allows for autoregression up to   th order  and we
used    fold cross validated   as goodness of fit statistic of
models  the result is shown in figure    along with p values of
the coefficients involved in the linear model  to evaluate the significance of augmented autoregressive terms  we consider only
the maximum of p values associated with these terms 
shown also in figure   is the akaike information criteria
 aic  of models  corrected to account for finite sample sizes  although aic typically provides sensible measure to compare models having varying number of coefficients  in this application we
observe that the aic decreases due to the likelihood component
diminishing in value  this may be caused by the number of training samples accounted for in aic calculation decreases as we expend the temporal limit of our dataset into providing values
used for autoregressive terms  therefore  we simply use the
cross validated   to choose the model 

figure  performance of autoregressive linear models
for public safety kpi 
d  health kpi
we noted from figure   that using all cafr components increased the validation error of model  for health kpi model  we
apply stepwise construction of linear model in addition to the
autoregressive terms similar to public safety kpi model  stepwise selection will prevent overfitting due to including all cafr
components 
during model construction  we encountered a lot of missing
data for cafr components for a given year  to maximize training dataset utilization  since the model is linear  we impute missing data with zeros  our temporal dataset enables us to construct up to  th order autoregression 
we found  as can be seen in figure    that the autoregressive
models perform poorly for models lower than  th order  the
ar    model  however  does not include any of cafr components  therefore  we will pick the ar    model 
 

                                  
  

where 
     health index of the year
       health index of  years ago  autoregressive 
     human resources expense of the year  in million us 
   coefficient of p th autoregressive term

fif  diversity kpi
diversity kpi data  as with that of affordability kpi  was limited to a single year  the resulting model is again weak without
any autoregressive terms 
 intercept 
public safety expenses
interest debt services
      

          

estimate
      
      
      

p value
            
      
      

   fold cv           

for this results we also maintain that our proposed methodologies may perform well given more temporal data 

figure  performance of autoregressive linear models
for health kpi 
e  affordability kpi
affordability kpi data was limited to a single year  which puts
autoregression out of reach  the resulting model is weak 
 intercept 
public safety expenses
      

          

estimate
        
      

p value
            
      

   fold cv           

however  we also see weak performance in non autoregressive linear models for public safety and health kpi  the failure
to obtain a meaningful model for this kpi does not present evidence that would invalidate our proposed methodologies for the
project  a meaningful model may be obtained with more temporal data 

iv  c onclusion
this project showed promising outcome for public safety kpi
 crime rate  and health kpi  proportion of residents self reporting better than fair or poor health  as shown by the goodness of
fit of the autoregressive linear models for these kpi  the optimization of municipal budget is achievable using the outcome of
this project  for public safety and health kpi for a cluster of    
cities 
further works deriving from this project should consider obtaining more training data  it is observed from the goodness of
fit of models for public safety kpi and health kpi that linear
models without autoregressive terms can be dramatically improved by adding autoregressive index values  we observed
that affordability kpi and population diversity kpi models have
poor performance using only the latest publicly available kpi
values  obtaining affordability kpi would require us to purchase
the cost of living index report for us     to enable the level of
analysis equivalent to that of public safety and health  which
was cost prohibitive  nevertheless  based on the evidence available to us and given the importance of affordability to the quality of life  we recommend further works to acquire temporally
extensive data points for affordability kpi 
further works should also consider expanding geographical
extent of the analysis  due to bloomberg terminal usage limits
imposed on us  our analysis could only consider financial budgeting data from the state of california 
lastly  further works should consider augmenting other nonlinear regressive models with autoregressive terms for the final
models  due to time and resource limitation  we only considered
autoregressive linear models 
v  a cknowledgements
we would like to thank consulting professor bruce cahan and
visiting scholar tomasz golinski for providing us with city financial data 
vi  references
bloomberg l p         city credit report  retrieved nov     
     from bloomberg database 
city data com   city data com   stats about all us cities        
 online   available  http   www city data com    accessed  oct      

fi