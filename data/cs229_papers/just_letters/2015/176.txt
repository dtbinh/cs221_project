classification of photographic images based on
perceived aesthetic quality

jeff hwang
department of electrical engineering  stanford university

jhwang     stanford   edu

sean shi
department of electrical engineering  stanford university

sshi     stanford   edu

abstract
in this paper  we explore automated aesthetic evaluation of photographs using machine learning and image processing techniques  we theorize that the spatial distribution of certain visual elements within an
image correlates with its aesthetic quality 
to this end  we present a novel approach
wherein we model each photograph as a set
of image tiles  extract visual features from
each tile  and train a classifier on the resulting features along with the images aesthetics ratings  our model achieves a   fold cross validation classification success
rate of         corroborating the efficacy
of our methodology and therefore showing
promise for future development 

   introduction
aesthetics in photography are highly subjective  the
average individual may judge the quality of a photograph simply by gut feeling  in contrast  a photographer might evaluate a photograph he or she captures
vis a vis technical criteria such as composition  contrast  and sharpness  towards fulfilling these criteria  photographers follow many rules of thumb  the
actual and relative visual impact of doing so for the
general public  however  remains unclear 
in our project  we show that the existence  arrangement  and combination of certain visual characteristics does indeed make an image more aestheticallypleasing in general  to understand why this may be
true  consider the two images shown in figure    although both are of flowers  the left photograph has
a significantly higher aesthetic rating than the right
photograph  one might reason that this is so simply because the right photograph is blurry  this con 

figure    a photograph with a high aesthetic rating  left 
and a photograph with a low aesthetic rating  right  

jecture  however  is imprecise because the left photograph is  on average  blurry as well  in fact  the majority of the image is even blurrier than the right photograph  here  it seems that the juxtaposition of sharp
salient regions with blurry regions and their locations
in the frame positively influence the perceived aesthetic quality of the photograph 
accordingly  we begin by identifying generic visual
features that we believe may affect the aesthetic quality of a photograph  such as blur and hue  we then
build a learning pipeline that extracts these features
from images on a per image tile basis and uses them
along with the images aesthetics ratings to train a
classifier  in this manner  we endow the classifier with
the ability to infer spatial relationships amongst features that correlate with an images aesthetics 
the potential impact of building a system to solve
this problem is broad  for example  by implementing such a system  websites with community sourced
images can programmatically filter out bad images
to maintain the desired quality of content  cameras can provide real time visual feedback to help
users improve their photographic skills  moreover 
from a cognitive standpoint  solving this problem
may lend interesting insight towards how humans
perceive beauty 

fi   related work
there have been several efforts to tackle this problem from different angles within the past decade 
pogacnik et al     believed that the features depended
heavily on identification of the subject of the photograph  datta et al     evaluated the performance
of different machine learning models  support vector
machines  decision trees  on the problem  ke et al    
focused on extracting perceptual factors important to
professional photographers  such as color  noise  blur 
and spatial distribution of edges 
also  in contrast to our approach  it is interesting
to note that these studies have focused on extracting global features that attempt to capture prior beliefs on the spatiality of visual elements within highquality images  for example  datta et al attempted to
model rule of thirds composition by computing the
average hue  saturation  and luminance of the inner
thirds rectangle of the image  and pogacnik et al defined features that assessed adherence to a multitude
of compositional rules as well as the positioning of
the subject relative to the images frame 

   dataset
our learning pipeline downloads images and their
average aesthetic ratings from two separate datasets 
the first is an image database hosted by photo net  a
photo sharing website for photographers  the index
file we use to locate images was generated by datta
et al  members of photo net can upload and critique
each others photographs and rate each photograph
with a number between   and    with   being the best
possible rating  due to the wide range and subjectivity of ratings  we choose to only use photographs with
ratings above   or below      which yields a dataset
containing      images split evenly between positive
labels and negative labels 
the second comprises images scraped from dpchallenge  another photo sharing website that allows
members to rate community uploaded images on a
scale of   to     the index file we used to locate images was generated by murray et al      following
guidelines from prior work  we choose to use photographs with ratings above     or below      resulting in a dataset containing      images split evenly
between positive and negative labels 

   feature extraction
prior to extracting features  we partition each image
into equally sized tiles  figure     by extracting fea 

figure    tiling scheme applied to image by learning
pipeline 

tures on a per tile basis  the learning algorithm can
identify regions of interest and infer relationships between feature tile pairs that indicate aesthetic quality  for example  in the case of the image depicted
in figure    we surmise that the learning algorithm
would be able to discern the well composed framing
of the pier from the features extracted from its containing tiles with respect to those extracted from the
surrounding tiles 
below  we describe the features we extract from each
image tile 
subject detection  strong edges distinguish the images subject from its background  to quantify the
degree of subject background separation  we apply a
sobel filter to each image tile  binarize the result via
otsus method  and compute the proportion of pixels
in the tile that are edge pixels 
p
fsd  

 x y tile

  i x  y    thresholded edge 

   x  y   x  y   tile  

color  a photographs color composition can dramatically influence how a person perceives a photograph  we capture the color diversity within an image
tile using a color histogram that subdivides the three
dimensional rgb color space into    equally sized
bins  since each pixel can take on one of     discrete
values in each color channel  this results in each bin
being a cube with    possible values in each dimension  we normalize each bins count by the total pixel
count so that it is invariant to image dimensions 
we also measure the average saturation and luminance of each tiles pixels  finally  for the entire image  we compute the proportion of pixels that correspond to a particular hue  red  yellow  green  blue 
and purple  
detail  higher levels of detail are generally desirable
for photographs  particularly for its subject  to approximate the amount of detail  we compare the number of edge pixels of a gaussian filtered version of the

fiimage tile to the number of edge pixels in the original
image tile  i e 
p
fd  

 x y tile

p

  if iltered  x  y    edge 

 x y tile

  i x  y    edge 

for an image tile that is exceptionally detailed  many
of the higher frequency edges in the region would be
removed by the gaussian filter  consequently  we
would expect fd to be closer to    conversely  for a
tile that lacks detail  since few edges exist in the region  applying the gaussian filter would impart little
change to the number of edges  in this case  we would
expect fd to be closer to   
contrast  contrast is the difference in color or brightness amongst regions in an image  generally  the
higher the contrast  the more distinguishable objects
are from one another  we approximate the contrast
within each image tile by calculating the standard deviation of the grayscale intensities 
blur  depending on the image region  blurriness may
or may not be desirable  poor technique or camera
shake tends to yield images that are blurry across the
entire frame  which is generally undesirable  on the
other hand  low depth of field images with blurred
out of focus highlights  bokeh  that complement
sharp subjects are often regarded as being pleasing 
to efficiently estimate the amount of blur within an
image  we calculate the variance of the laplacian of
the image  low variance corresponds to blurrier images  and high variance to sharper images 
noise  the desirability of visual noise is contextual 
for most modern images and for images that convey positive emotions  noise is generally undesirable 
for images that convey negative semantics  however 
noise may be desirable to accentuate their visual impact  we measure noise by calculating the images entropy 

figure    block diagram of learning pipeline 

for each of the features we identified  there exists a
feature extractor function that accepts an image as
an input  calculates the feature value  and inserts the
feature value mapping into a sparse feature vector allocated for the image  we rely on image processing
algorithms implemented in the scikit image and
opencv libraries for many of these functions        
after the pipeline generates feature vectors for all
images in the training set  it uses them to train a
classifier  for the learning algorithm  we experimented with scikit learns implementations of
support vector machines  svm   random forests  rf  
and gradient tree boosting  gbrt       we focus our
attention on these algorithms because they can account for non linear relationships amongst features 
svm  the svm learning algorithm with    regularization involves solving the primal optimization
problem
min

 w b

subject to

y  i   wt x i    b      i   i           m

  the dual of which is
max


saliency  the saliency of the subject within a photograph can have a significant impact on the perceived
aesthetic quality of the photograph  we post process
each image to separate the salient region from the
background using a center vs surround approach described in achanta et al      we then sum the number
of salient pixels per image tile and normalize by the
tile size 

m
x
 
  w      c
i
 
i  

subject to

m
x
i  

i 

m
  x  i   j 
y y i j hx i    x j  i
  i j  

   i  c  i           m
m
x

i y  i     

i  

   methods

accordingly  provided that we find the values of 
that maximize the dual optimization problem  the hypothesis can be formulated as

pm
 i   i 
  if
i   i y hx   xi   b   
h x   
 
otherwise

figure   depicts a high level block diagram of the
learning pipeline we built  the pipeline comprises
three main components  an image scraper  a bank of
feature extractors  and a learning algorithm 

note that since the dual optimization problem and
hypothesis can be expressed as inner products between input feature vectors  we can replace each inner product with a kernel applied to the two input

fivectors  which allows us to train our classifier and
perform classification in a higher dimensional feature
space  this characteristic of svms makes them wellsuited for our problem since we speculate that nonlinear relationships amongst features influence image
aesthetic quality  for our system  we choose to
 use the
gaussian kernel k x  y    exp   x  y       which
corresponds to an infinite dimensional feature mapping 
random forest  random forests comprise collections
of decision trees  each decision tree is grown by
selecting a random subset of input variables to use
for splitting at a particular node  prediction then involves taking the average of the predictions of all the
constituent trees 
m
  x
ti  x 
m i  

 

h x    sign

because of the way each decision tree is constructed 
the variance of the average prediction is less than that
of any individual prediction  it is this characteristic that makes random forests more resistant to overfitting than decision trees  and  thus  generally have
much higher performance 
gradient tree boosting  boosting is a powerful learning method that sequentially applies weak classification algorithms to reweighted versions of the training
data  with the reweighting done in such a way that 
between every pair of classifiers in the sequence  the
examples that were misclassified by the previous classifier are weighted higher for the next classifier  in
this manner  each subsequent classifier in the ensemble is forced to concentrate on correctly classifying the
examples that were previously misclassified 
in gradient tree boosting  or gradient boosted regression trees  gbrt   the weak classifiers are decision
trees  after fitting the trees  the predictions from all
the decision trees are weighted and combined to form
the final prediction 
h x    sign

m
x

 
i ti  x 

figure    classifier    fold cross validation accuracy versus
tiling dimension  svm with c     and         dpchallenge dataset  

each feature from the set and run cross validation on
the resulting set to verify that the feature contributes
positively to the classifiers performance 
in experimenting with different tiling dimensions  we
found that dividing each image into five by five tiles
gave the best performance  figure     a tiling dimension of   corresponds to extracting each feature
across the entire frame of the image  as anticipated 
this yields significantly worse performance  larger
tiling dimensions should theoretically work better
provided that we have enough data to support the associated increase in the number of features  unfortunately  given the limited sizes of our datasets  the addition of more features causes our classifier to overfit
and thus degrades its accuracy for dimensions larger
than   
for svm  we tuned our parameters using grid search 
which ultimately led us to use c     and         for
random forest  we used     decision trees  we determined this value by empirically finding the asymptotic limit to the generalization error with respect
to the number of decision trees used  for gradient
tree boosting  we used     decision trees and a subsampling coefficient of      using a sub sampling coefficient smaller than   allows us to trade off variance for bias  which thereby mitigates overfitting and
hence improves generalization performance 

i  

in literature  tree boosting has been identified as being one of the best learning algorithms available     

   experimental results and analysis
for each learning algorithm  we measure the performance of our classifier using    fold cross validation on the photo net dataset and the dpchallenge
dataset  we run backward feature selection to eliminate ineffective features to improve classification performance  for the final set of features  we remove

table   shows our    fold cross validation accuracy
for each learning algorithm  for both datasets  we got
the highest performance with gbrt  with accuracies
of        and         the difference in performance
may have resulted from the dpchallenge datasets
having higher resolution images than the photo net
dataset  which makes certain visual features more
distinct in the former than the latter  nonetheless 
the similarity in results suggests that our methodology generalizes well to different datasets 
figure   shows the confusion matrix for    fold cross 

fiphoto net
dpchallenge

svm
      
      

rf
      
      

gbrt
      
      

table       fold cross validation accuracy

predicted label
 
 
 
actual
label

 

tp
fn
             
fp
tn
             

figure    confusion matrix for    fold cross validation with
gbrt on dpchallenge dataset 

validation using gbrt on the dpchallenge dataset 
the true positive and false negative rates are approximately symmetric with the true negative and false
positive rates  respectively  which signifies that our
classifier is not biased towards predicting a certain
class  this also holds true for the photo net dataset 
to analyze the shortcomings of our approach  we examine images that our classifier misclassified 
figure   shows an example of a negative image from
the photo net dataset that the classifier mispredicted
as being positive  note that the image is compositionally sound  the subject is clearly distinguishable from the background  fills most of the frame  is
well balanced in the frame  and has components that
lie along the rule of thirds axes  the hot pink background  however  is jarring  and the subject matter is
mundane and lacks significance  unfortunately  because it discretizes color features so coarsely  the classifier is likely not able to effectively differentiate between the artificial pink shade of the images background and the warm red shade of a sunset  for instance  moreover  it has no way of gleaning meaning
from images  we therefore believe that it is primarily
due to these shortcomings that our classifier misclassified this particular image 

figure    negative image classified as positive by the
model 

figure    positive images classified as negative by the
model 

figure   shows two photographs from the dpchallenge dataset that our classifier misclassified as being negative  while the left photograph follows good
composition techniques  the subject has few high frequency edges  so the classifier would likely need to
rely more on saliency detection to pinpoint the subject  unfortunately  the current method of detecting
the salient region is not consistently reliable  so despite this photographs having a distinct salient region  the classifier may deemphasize the contributions of this feature  we believe that improving our
salient region detection accuracy across all images
may enable the classifier to utilize the saliency feature
more effectively  and thus correctly classify this photograph  in the right image in figure    the key visual
element is the strong leading lines that draw attention to the hiker  the subject of the image  leading
lines  however  are global features that are not wellcaptured by our tiling methodology  and  thus  are
likely not considered by the classifier 
in sum  although our system performs respectably 
examining the images it mispredicts reveals many potential areas of improvement 

   future work and conclusions
we have demonstrated that modeling an image as a
set of tiles  extracting certain visual features from each
tile  and training a learning algorithm to infer relationships between tiles yields a high performing photographic aesthetics classification system that adapts
well to different image datasets  thus  our work lays
a sound foundation for future development  in particular  we believe we can further improve the accuracy of our system by deriving global visual features
and parsing semantics from photographs  our model
should also apply to regression for use cases where
numerical ratings are desired  finally  augmenting
the system with the ability to choose a classifier depending on the identified mode of a photograph  e g 
portrait or landscape  may lead to more accurate classification of aesthetic quality 

fireferences
    pogacnik  d   ravnik  r   bovcon  n     solina 
f          evaluating photo aesthetics using machine learning 
    datta  r   joshi  d   li  j     wang  j  z         
studying aesthetics in photographic images using a computational approach  in computer
visioneccv       pp            springer berlin
heidelberg 
    ke  y   tang  x     jing  f         june   the design of high level features for photo quality assessment  in computer vision and pattern recognition       ieee computer society conference on
 vol     pp            ieee 
    murray  n   marchesotti  l     perronnin  f 
       june   ava  a large scale database for aesthetic visual analysis  in computer vision and pattern recognition  cvpr        ieee conference on
 pp              ieee 
    achanta  r   hemami  s   estrada  f    
susstrunk  s         june   frequency tuned
salient region detection  in computer vision and
pattern recognition        cvpr       ieee conference
on  pp              ieee 
    van der walt  s   schonberger  j  l   nuneziglesias  j   boulogne  f   warner  j  d   yager  n  
      yu  t  the scikit image contributors       
scikit image  image processing in python  peer
j       
    bradski  g          the opencv library  doctor
dobbs journal                  
    pedregosa  f   varoquaux  g   gramfort  a  
michel  v   thirion  b   grisel  o         vanderplas  j          scikit learn  machine learning in
python  the journal of machine learning research 
              
    friedman  j   hastie  t     tibshirani  r         
the elements of statistical learning  vol 
   
springer  berlin  springer series in statistics 

fi