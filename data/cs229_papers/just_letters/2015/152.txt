bitcoin utxo lifespan prediction
robert konrad   stephen pinto
december         

 

background   motivation

the bitcoin crypto currency        is the most widely used and highly valued digital currency in
existence  every day sees thousands of transactions added to the blockchain  the blockchain is a
global  agreed upon ledger of every transaction that has ever occured and is continually extended
as a single linked list  each transaction in the blockchain  say alice paying bob    btc  has one or
more transaction outputs  txo  which serve as sums of spendable btc  these unspent sums are
called unspent transaction outputs  utxo   they remain utxos until the owner  bob in our
example  redeems them to pay someone else  at which time they are referred to as spent txos  
this project seeks to predict how long a txo will remain unspent  more formally  given
some information about the beginning transaction which created the utxo and some information
about the bitcoin market on the day of its creation  this project predicts which of ten broad time
scales the utxo lifespan will fall into  this predictor could inform broader applications such as
anomaly fraud detection  trade volume and volatility prediction  and the modelling of individual
spending habit  the bitcoin industry is worth billions of dollars and growing rapidly  possible
insights into the previosly mentioned topics would be of use to any number of financial institutions
involved in the future of cryptocurrencies 

 

dataset   features

one of the  many  blockchain explorers  blockchain info  has a public api exposing data about
individual transactions as well as general bitcoin market statistics  a python script queried
blockchain info at a polite rate to gather       training samples and then exported the data to a
matlab readable format  a matlab script then curated the data into a matrix with the features

figure    illustrated explanation of a utxo  an arbitrary amount of time may pass before bob spends
his utxo 

 

fifigure    the features used as inputs to the classifier  

figure    the histogram of collected utxo lifespans with two regions magnified 

listed in figure    the feature set consists of information pertaining to the individual beginning
transactions  and information about the bitcoin market statistics on the day of creation 
we dummy coded the weekday with the reference day being sunday  this created   new
binary features  where each feature dictates whether the transaction occurred on a particular day 
sunday  the reference day  is represented by these   features being    the unix time of beginning
transaction corresponded to the number of hours that occurred since the epoch time  thursday   
january        the   th feature  transaction volume on creation date  corresponds to to the total
number of unique bitcoin transactions that occurred on the day of creation  the final three features
are the three  nd order polynomial parameters that fit the last weeks usd to btc conversion
rate 

 

methods

as shown in figure    the tail of the utxo lifespan distribution is extremely long  as such 
regression might lead to prediction errors that are large enough to remove their useful meaning 
 

fimaximum likelihood distribution for each cluster
  

  

  

  

 

  

  

   

  

  

     

    

  

 
 

   

 

  

    

 

  

    

 
   

   

     
 

 

    
 

 
 

    

 

    
 

 
   

   

     
    
 

 

 
              

            
    
    
    

 

   
 
  

               
 
  

 
 

    

    

 

    

     

figure    the maximum likelihood distribution fits for each of the six    penalty clusters 

classification into a finite set of lifespan bins  defined by ranges of time  clarifies this issue and
provides more intuitive results  the trick  however  is to define useful  data dependent time ranges 
hardcoding these based on eyeballing the distribution seemed meaningless so we chose to instead
split the full domain into ten equal probability ranges 
two methods of doing this are either     entirely empirically or     based on a fitted distribution 
the former case is simply a matter of sorting the lifespan dataset and splitting it into ten equally
sized groups  the latter requires more processing  understanding that the data should show signs
of a laplace or exponential distribution based the standard application of those distributions  the
first step was to cluster the lifespan set using k median     penalty function  clustering  from
there  we fitted either a normal  laplace  or exponential  whichever was most likely  distribution
to each cluster using maximum likelihood estimation and then formed a global distribution as a
weighted sum 
upper bound of subdomain
  of dataset in subdomain

 m
  

   m
  

   m
  

   m
  

 h
  

 h
  

 d
  

 d
  

  wk
  


  

table    table of subdomain boundaries and the distribution of datapoints within subdomains for empirically calculated subdomains 

upper bound of subdomain
  of dataset in subdomain

 h
  

 h
 

    h
 

    h
 

     h
 

     h
 

 d
 

    d
 

  wk
  


  

table    table of subdomain boundaries and the distribution of datapoints within subdomains for subdomains from a fitted distribution 

tables   and   describe the ten subdomains with raw data and the fitted distribution respectively  table   reveals that the fitted distribution does not sufficiently capture the heavy weighting
 

fifigure    classifier performance vs  and c  one region of the broader heatmap is magnified for higher
granularity 

towards   since     of the data is falling into what we hoped was a     probability domain 
keeping in mind that the goal of this subdomain split is to find a meaningful set of lables  the
choice between the two options is up to which domains seem more meaningful to a future user  we
created two classifiers  one for each label set 
we used two different classification algorithms  svm with a  gaussian  radial basis kernel and
softmax regression  the svm optimization problem is as follows           
m

x
 
min   w      c
i
 w b  
i  

 i 

t  i 

s t y  w x

  b      i  

i           m

i    

i           m


 
  this kernel function implicitly moves the
with the kernel function k x  z    exp  kxzk
   
feature set to a high dimensional space where the optimal margin between classes is larger and
better fit by a linear equation than in the original  low dimentional space 
softmax regression is a glm that can be run on a multinomial dataset  in class we saw that if we
dummy coded our labels  with one being a reference label   then we could express the multinomial

distribution as a member of the exponential family  the softmax function  i   pke i j   where
j  

e

 is the natural parameter and k is the number of labels  is found to describe the conditional
distribution of y given x  
tx

ei

p y   i x      pk

j   e

ei

j

 p
k

jt x
j   e

with this conditional probablity we are able to estimate the probablity of a certain feature set
falling into each category  i 

 

results

svm with a radial kernel performed significantly better than any other tested alternative so this
section highlights only those results on the empirically decided equal probability labels  the parameters  and c changed the predication accuracy as they varied so figure   highlights the process
 

fifigure    the accuracy of the svm classifier using empirical labels with the sequential addition of features
and the training test error vs dataset size 

of first training and   fold validating on a rough range of the two  then zooming in for finer changes
to find an ideal pair of values at             and c             
figure   shows the training and test error with respect to training set size with the peak 
and c pair as well as the effect of each feature on prediction accuracy as the features are added
in one by one  since space is scarce  suffice to say we have corresponding plots of figures   and  
for the fitted distribution defined equal probability labels  the baseline accuracy  i e  predicting
label   every time  is     while the peak accuracy with all features present is about      using
other classifiers  softmax regression  linear svm kernel   rd degree polynomial svm kernel  and
sigmoid svm kernel  we had prediction accuracies                and    respectively 

 

conclusion   future work

it would be interesting to study the stationarity  or lack there of  of the utxo lifespan distribution  i e  are typical spending habits varying over bitcoin history   such information might help
with finding a better fitting underlying distribution that would be more robust than relying on
equal probability binning of raw data  similarly  attempting to model the underlying distribution
as a mixture of laplace distributions might make more sense than fitting a set of adjacent clusters
with individual distributions  we started down that path and would like to acknowledge junjie
qins help but we were unable to bring it to a useful state  it would also be worth see how many
equal probability bins we can meaningfully classify into  the more the better   finally  two interesting follow up projects would be to use this prediction tool to create expected volatility plots of
the bitcoin market or pairing this predictor with de anonymizing tools to form individual spending
models for clustered entities on the blockchain 

 

fireferences
    s  nakamoto  bitcoin  a peer to peer electronic cash system       
    e  f  a  m  s  g  arvind narayanan  joseph bonneau  bitcoin and cryptocurrency technologies 
     
    a  ng  cs     lecture notes       
    c  wei hsu  c  chung chang  and c  jen lin  a practical guide to support vector classification 
     
    s  boyd and l  vandenberghe  convex optimization  cambridge university press       

 

fi