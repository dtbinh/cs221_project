machine comprehension using robust rule based features and
multiple sentence enhancing
wei chen
cwind 

danyang wang
danyangw 

abstract

a typical question is shown as follows 

in this project  we designed multiple featurelizers to extract information and answer multiple choice reading comprehension questions  given a triple of passage
question and answer  the featurelizer will
generate a set of features which are designed using robust nlp tools  we then
feed generated features into a neural network classifier which gives a probability
score for each answer  the features we
used are improved sliding window  key
word distance  syntax feature  word embeddings  multiple sentences and coreference resolution 

 

introduction

machine comprehension  mc  is a raising research field which attracts interest from both
industry and academia  there are a number of
datasets available for this task  each designed to
reflect different challenges in mc  the facebook
babi dataset  weston et al         contains short
examples which requires to derive answers by
combining two sentences  the mc    dataset
 richardson et al         contains longer passages
and various types of multiple choice questions 
wiki qa  smith et al         introduces a context
where agents are required to read full length
wikipedia articles before answering related questions 
we use mc    as the guildeline to evaluate
our mc system  the dataset provides     instances of stories  each instance contains one
passage  four multiple choice questions and each
question contains four choices  instances are
designed such that answers to each question can
be entailed only using information in the passage 


 stanford edu

xiaoshi wang
xiaoshiw 

passage     john asked tim if he could play
on the slide  tim said no  john was very
upset and started crying  a girl named susan
saw him crying  susan told the teacher ms 
tammy     
question 
who saw john crying and
told ms  tammy 
a  tim
b  susan
c  john
d  ms  tammy
such tasks are easy for human readers but are hard
for machines  even though answers are designed
to be retrievable from the passage  it does not
imply that the agent could be knowledge free  in
fact  locating the answer in the passage requires a
large knowledge base  for example  in the sample
above an agent has to understand a girl named
susan implies the girl is susan  in general 
machine comprehension challenge involves the
application of many fields  especially in nlp and
machine learning 

 

previous works

state of art methods usually approach machine
comprehension in two major directions  neural
network based and feature based  both directions
incorporates with the observations that the knowledge required to retrieve answers must be learned
or hard coded 
for neural network based methods   hermann et al         suggests word similarities can
be used to train lstm which embed sentences

fiinto a vector space which preserves sentence
similarities  similarly   kapashi and shah       
uses word embedding  mikolov et al        
vectors as input to lstm to approach wiki qa
task 
on the other hand  feature designed systems
represent candidate answers by hand crafted features to train linear classifiers  regression  wang
et al          svm  narasimhan and barzilay 
       ect     richardson et al         proposed
a simple bag of word and word distance feature
as baseline   smith et al         uses enhanced
bag of word feature to capture cross sentence
matches   wang et al         uses various nlp
tools to process the original data and uses matches
in semantics  dependencies and work tokens as
features  in  sachan et al          the system
introduce hypothesis as latent variables in the
model 
neural network based systems automatically
generate features from a weak feature  whereas
feature based systems provide strong features
specifically designed and tuned for the dataset 
therefore  neural network based systems have
more potential to generalize  however  feature
based systems reveals more nlp natures of the
problem and have better performance in practice 

 

approach

   

overview

our system framework is similar to the one
proposed in  wang et al          for each
multiple choice question  it consists of a passage p   a question q and a set of answers
a    a    a    a    a     there is exactly one
answer a  a labeled correct  our goal is
to select the answer a without knowing the
labelings 

   from preprocessed data  generate feature
vectors f  p  q  ai   for each candidate answer  we also label each candidate answer
with a binary label indicating whether it is the
correct one 
   train a classifier using feature vectors and binary labels 
similarly  in testing stage we also preprocess the
data and generate feature vectors  however  given
candidates to a particular question  p  q  ai   
instead of generating binary labels  the classifier
outputs a distribution describing the likelihood
that ai is correct  we select the answer with
maximum likelihood 
   

the baseline system proposed in  richardson et
al         uses a simple bag of words score to
evaluate each candidate answer  concretely  we
first concatenate the question and an answer to
form a string s  within a sliding window in p of
size k  we count the number of word matches to
s and score the answer by the maximum sliding
window count  to prevent counts boosted by
trivial words  we weighted the count of each word
w by its inverse frequency across the passage 
the original baseline uses k   word size s  
which is the total number of words in s 
 narasimhan and barzilay        suggests that
a simple modification could significantly boost
the performance  instead of using the score of
size k sliding window  we used the sum of sliding
window scores from size   to size     we also
notice that weighted sum of sliding windows
of various size has even better performance in
experiments  we use fixed weights set to be the
inverse of the sliding window sizes 
   

given a multiple question  p  q  a   our system
generates features for each answer candidates
ai   the features are represented in feature vector
f  p  q  ai    those features can be used to train
a classifier which selects the answer  in training
stage  our pipeline includes three steps 
   read in each question  p  q  a  and preprocess the text file using stanford corenlp
 manning et al         tools 

enhanced sliding window features

distance features

another feature used in the baseline system is distance of key words between question and candidate answer  the intuition is that the part of the
passage representing the question is usually not far
away from the one for the true answer  for a question q and answer ai   we calculate the distance
between the question and answer by 
di  

min

qsq  asa i

d q  a  

fibe the word such that arc ua   ra     nsubj
and replace the entire a by ua   in q  replace c
by the updated a 

with
sq    q  p w   u 
and
sa i    ai  p w    u  q  
u provides a dictionary of stop words which
intend to filter out non keywords 
   

   c   where  arc c  rq     advmod  and
p os rq     v b  if there is a word uq such
that arc uq   rq     dobj  in q  insert a after
uq   otherwise insert a after rq   also delete
first two words in q 

syntax features

the sliding window score captures similarities
by word matches  however  it does not capture
matches in word dependencies  investigating
grammar structures of questions and answers
 wang et al         provides insights to latent
variables which aligns question answer pair  in
syntax features  we represent similarities between
statements using dependency tree parsing  chen
and manning        
we generate statements mainly following rules
proposed by  wang et al          for example 
q  what did he do on tuesday 
a  he went to school 
generated  he went to school on tuesday 
we slightly modified the rules to obtain more accurate results  in general  we denote arc u  v 
be the grammar relationship between word u and
word v and p os u  be the part of speech penn
tree tag for word u  for question q  let c be the
wh word and rq be the root word  similarly  for
answer a  let ra be the root word  rules are described as follows  each with an example in the
box 
   c   what  p os rq     v b and rq  
do  and arc c  rq     dobj  let uq be the
word such that arc uq   rq     nsubj  if
ra is a verb  let ua be the word such that
arc ua   ra     nsubj  removed ua from a 
in q  remove the first two words as well as rq  
insert the updated a after uq  
   c   what  p os rq     v b and rq    do 
and arc c  rq     dobj  if ra is a verb  let ua
be the word such that arc ua   ra     nsubj 
remove ua and ra from a  in q  insert the
updated a after rq  
   c   what  p os rq     n n   and
arc c  rq     nsubj  if ra is a verb  let ua

   c   where  arc c  rq     advmod  and
rq   is  let uq be the word such that
arc uq   rq     nsubj  in q  delete the first
two words  put rq after uq   and finally insert
a after q 
   c   who  arc c  rq     nsubj  and
p os rq     n n   if ra is a verb  let ua be
the word such that arc ua   ra     nsubj and
replace the entire a by ua   in q  replace c by
the updated a 
it is also intuitively sounding to construct rules
for other types of questions  for example  for
why questions we can generate the statement
by connecting the answer and question using
because of  however  in practice  the passage
usually does not explicitly state such relationships  it is more likely that the actual statements
in the passage lies in several different logically
connected sentences 
therefore  we cannot
retrieve dependency matching out of those type of
answers  it turns out that adding more such rules
rarely improve the result 
after generating the answer statement  we
parse the statement and compare its dependency
tree to each sentence s in the passage  the
score sy p  q  ai   s  to each sentence is given
by the number of exact dependency matches  in
other words  let es  us   vs   be an edge for s and
ea  ua   va   be one for a  we increment sy by   if
us   ua   vs   va and arc us   vs     arc ua   va   
we select the sentence with maximum score as
the syntax feature 
sy p  q  ai     max p  q  ai   s  
sp

   

word embeddings

in previous features  we compare word matches
with direct string match   mikolov et al        
suggests that it is possible to embed words into a
vector space in which similarities between words

fiis measured by inner products  furthermore 
 wang et al          hermann et al         and
 kapashi and shah        suggests that in linear
combination of word vectors is representative
for phrases and sentences  in addition  as the
embedding provided by  mikolov et al         is
trained over a dataset containing over    billion
training words  this embedding implicitly covers
abundant amount of knowledge which we might
not able to retrieve if training merely on the
mc    dataset 
the word embedding we feature measures
similarities between concatenated q a pairs
 q   ai   and a sentence  s  in the passage 
concretely  we measure the cosine of the angle
between the vector of the concatenated statement and that of the sentence  let v w  be the
embedding of a given word w 
x
vqai  
v w  
wq ai

and
vs  

x

v w  

ws

we use the word embedding feature 
we p  q  ai     max
s

   

t v
vqai
s

kvqai kkvs k

 

multiple sentences

our previous features  sw  sy  and we  each
represent the triple  p  q  ai   using a score of
a particular portion of the passage  a sliding
window or a sentence   although the score is
obtained by comparing to those obtained from
other portions of the passage  the feature itself
only reflects a local statistics of the passage  but
failed to retrieve information across the whole
passage 
for a feature f  p  q  ai   selected from individual sentence scores f  p  q  ai   s   we
previously have 
f  p  q  ai     max f  p  q  ai   s  
sp

we enhance the score selection process so that features previously taken on single sentences are improved to incorporate the overall score of the passage  for a sentence s  we compute the weighted
sum of all sentences in the passage  taking nearby

sentences with higher weights  specifically  we
generate new score g for each sentence by 
g p  q  ai   s 


x
d s  s    
 
exp 
f  p  q  ai   s  
 
 
s p

then we select the maximum of the enhanced feature 
f    p  q  ai     max g p  q  ai   s  
sp

   

coreference resolution

our previously used exact string match and word
vector similarities would fail on coreferences 
in other words  if two different phrases  e g 
mr obama and the president  actually refer
to the same entity  our feature generator should
regard them as matched phrases 
stanford corenlp  manning et al        
provides a robust tool for coreference resolution 
given a passage  corenlp pipelines generates a
set of entities and for each entities a set of tokens
refering to this entity  it also selects the most
representative name string for each entity  for
each token in the passage  if it refer to certain
entity  we replace the token by the name of the
entity 

 

classifier

since the data contains      s and      s  we
balance the data by replicating each correct candidate three times  we select the best model by selecting the hyperparameters which optimize the kfold cross validation result on the union of training
and developing set  in practice we choose k      
our final system uses a shallow neural network as
the classifier  the neural network contains one
hidden layer with    nodes  the learning rate is
    and the momentum is      

 

performance

our system achieved results comparable to the
baseline system  although the full implementation did not yield the desired accuracy  further
investigation does reveal many interesting nlp
natures of the problem 
table   shows accuracies using a single feature  word embedding we turns out to have

fitype
how
when
which
why
count
what
where
who
other
all

the best single feature improvement  it implies
that word embedding is a representative feature
having the potential to support more generalized
models as suggested by  hermann et al        
and  kapashi and shah        
feature
baseline sw d 
enhanced sw d
sw d coref
sw d syntax
sw d wordembed

accuracy
     
     
     
     
     

single
multi
all

dev
     
     
     

test
     
     
     

train
     
     
     

train 
     
     
     

table    performance of full implementation  we
train the dataset using train and record the accuracy over dev  test and train  the last column is obtained using test as training data but
train as test data 
to further investigate the performance  we record
accuracy on different types of questions  notice
that the accuracy is high on why  when and
how questions  we are able to outperform
 smith et al         on how type questions by
      
as shown in table    the most challenging type
of questions we found in the dataset are those
required to summarize a particular aspect of the
passage 

total
  
 
  
  
  
   
  
  
  
   

accuracy
     
     
     
     
     
     
     
     
     
     

table    accuracy on different types of questions  the statistics are taken over test set 

table    performance of single features  the first
line uses baseline features sw d  each other row
is obtained by adding one feature improvement
over the baseline sw d features 
table   shows the final performance with full
implementation  we are able to achieve accuracy comparable to baseline system reported in
 richardson et al         on test set and dev set 
since our train accuracy is significantly higher
than others  we add one more set of experiments
to ensure that the classifier is not overfitted  we
swap the train set and test set  it turns out that we
still get high accuracy on train set  which implies
that questions in the test set is harder than those in
the train set 

correct
  
 
 
  
 
   
  
  
  
   

q  how many rooms did i say i checked 
in those questions  neither the answer statements
nor their paraphrases are explicitly embedded in
the passage  it requires us to generate specified
matches  i say i checeked  as we did for other
features  and then reduce those matches  how
many  to the answer  the major challenge requires us to parse the question into two parts and
solve two sub questions cooperatively 

 

future considerations

we could extend features which require match
counting to incorporate with word embedding
space to better reflect wordwise similarities  for
syntax feature  our analysis show that dependency
graph match should be weighted to reflect relationship between a question and an answer candidate 
for multiple sentence enhancing  we can view our
approach as applying a convolution filter over the
score of each sentence  which reveals the potential
of applying signal processing or cnn techniques 

 

conclusion

in this project we developed a mc system using sliding windows  syntax  and word embedding
as features  we improved those features through
coreference resolution and multiple sentence enhancing  our full system performance reveal interesting nlp natures of the mc task  which implies
possible furture research direction 

fireferences
j weston 
a bordes 
s chopra 
a m rush 
b merrienboer  and t mikolov towards ai complete question answering  a set of prerequisite toy
tasks arxiv           
n a smith  m heilman  and r hwa question generation as a competitive undergraduate course project
in proceedings of the nsf workshop on the question generation shared task and evaluation challenge  arlington  va      
c d manning  m surdeanu  j bauer  j finkel 
s j bethard  and d mcclosky
the stanford
corenlp natural language processing toolkit
acl      
m richardson  c j c burgers  and e renshaw
mctest  a challenge dataset for the open domain
machine comprehension of text  emnlp       
h wang  m bansal  k gimpel  and d mcallester machine comprehension with syntax  frames  and semantics  acl      
k narasimhan and r barzilay machine comprehension with discourse relations mcdr      
m sachan  a dubey  e p xing  and m richardson
learning answer entailing structures for machine
comprehension ijcnlp      
e smith  n greco  m bosnjak  and a vlachos a
strong lexical matching method for the machine
comprehension test emnlp      
t mikolov  i sutskever  k chen  g s corrado  and
j dean distributed representations of words and
phrases and their compositionality in advances
in neural information processing systems     pages
           curran associates  inc 
k m hermann  t kocisky  e grefenstette  lasse espeholt  w kay  m suleyman  and p blunsom
teaching machines to read and comprehend
arxiv           v       
d chen and c manning a fast and accurate dependency parser using neural networks emnlp      
d kapashi and p shah answering reading comprehension using memory networks cs   d report 
stanford university      
m wang  n smith  and t mitamura what is the jeopardy model  a quasi synchronous grammar for
qa emnlp      

fi