spacecraft navigation in cluttered 
dynamic environments using  d lidar
andrew bylard  and shreyasha paudel 
abstract many new classes of deep space and on orbit
missions require efficient navigation of environments having
untracked dynamic obstacles  space probes will need to autonomously identify and classify these objects for purposes of
localization  collision avoidance  and identification of targets
having high value  scientific or otherwise   in addition  lidar
is becoming a key sensing tool for close proximity space
operations  we implement a lidar simulation for cluttered space
environments and explore  i  a k d tree based algorithm for
clustering and identifying obstacles in  d lidar point clouds and
 ii  naive bayes and svm algorithms for classifying lidar point
clusters into obstacle types  the svm classifier was found to
perform better with an overall accuracy of         depending
on the obstacle type  compared to naive bayes which had an
accuracy of        

i  introduction
future operations in space may require autonomous spacecraft to navigate uncertain environments with dynamic obstacles in order to complete their goals  examples include
probes collecting samples of scientific interest in saturns iceand rock filled rings  and manipulator spacecraft navigating
and performing tasks in a large scale on orbit construction
project  in the absence of external sources of tracking data 
the spacecraft would need to rely on its own sensors to
estimate the size  position  and movement of nearby obstacles
for obstacle avoidance  the spacecraft would also need to
classify these obstacles for localization and identification of
scientific opportunities 
traditional sensors such as optical  ultrasonic  and radarbased systems have met with mixed success  but  d lidar is
emerging as a low power  cost effective solution for onboard
sensing of a spacecrafts surrounding environment  thus  this
paper targets the identification and classification aspect of
a cluttered space environment sensing using  d lidar  we
explore using machine learning techniques to  i  cluster
simulated lidar point cloud data in order to identify obstacles
and  ii  classify them into a fundamental set of known
obstacle shapes 
ii  related work
 d lidar based perception is becoming increasingly popular and various approaches have been proposed to effectively
segment and classify the resulting point clouds  for example 
in      a regression based method is used to classify static
 this work was partially supported by nasa space technology research fellowship grant nnx  ap  h 
  a  bylard is with department of aeronautics and astronautics  stanford
university  stanford  ca bylard at stanford dot edu
  s  paudel is with department of aeronautics and astronautics  stanford
university  stanford  ca spaudel  at stanford dot edu

fig     close observation and sample retrieval from saturns rings will
require accurate environment sensing for localization  object identification 
and obstacle avoidance 

point clouds into basic geometric shapes  which are then
classified into common household objects  a more common
use of lidar is in autonomous driving                in
     a log based estimator is used to classify objects seen
by a car based lidar system into relevant object classes 
similarly  in      the authors use the planar structure of
the problem to segment objects in a      d occupancy grid
and run classification for previously defined object classes 
the classification problem is addressed for rgb generated
point clouds in      which uses svms to classify common
household objects based on edge feature data  however these
algorithms are either trained to classify commonly available
objects for which large training sets are easily available     
    or use the inherent planar structure of the problem to
simplify it               
iii  datasets and features
a  lidar data generation
the first task of our project was to acquire a large amount
of relevant training and test data  however  not much lidar
data is freely available from spacecraft proximity operations 
particularly for the cluttered scenarios we had in mind  in
addition  lidar systems are currently very expensive  and
since we did not have access to an existing lidar setup or
a testbed that can model a dynamic  cluttered spacecraft
environment  collecting data experimentally was out of the
question 
instead  we developed a simulation which could model a
variety of obstacles and generate artificial  d lidar datasets 

fipercentage observed

rect 

ell 

cyl 

con 
feature combination index
fig     sample lidar scans of rectangular  ellipsoidal  cylindrical  and
conical obstacles  each blue point represents a captured lidar data point 

our simulation was written in matlab  and we made
use of a spacecraft motion planning package to generate
and keep track of sets of obstacle parameters for different
obstacle types  though the package supports many types of
obstacles  including complex shapes such as spacecraft and
solar panels  we focused on four fundamental  d obstacle
shapes  rectangular  ellipsoidal  cylindrical  and conical  as
our test cases of interest 
the simulations lidar scanning was modeled after the
velodyne hdl   e  which has a     horizontal field of
view and a    vertical field of view  the hdl   e scanner
has    lasers  each capturing a single point in a given vertical
scan  and by its default settings  the hdl   e will capture
    vertical scans per horizontal sweep  these parameters
were replicated in our simulation 
to generate training data  we randomly generated and
scanned one obstacle at a time  example scans are shown in
figure    parameters for these obstacles included the shape 
proportions  size  rotation  and distance angle from the lidar
scanner  for our lidar test simulation  we modeled entire
cluttered space environments by generating environments
with dozens of randomly placed obstacles  to be within the
field of view of the lidar scanner  the obstacles were clustered
close to a  d plane with the lidar source at the center 

fig     comparison of the frequency of the most prominent fpfh feature
combinations  particular combinations of     and  values  for each
obstacle type  each color represents a single training example 

fig    

geometric representation of pfh descriptors

   theoretical primer  the computation of pfh relies
on  d coordinates and estimated surface normals      let pi
and pj be two neighboring points  and ni and nj be their
estimates surface normals respectively  then  to compute
the relative difference  we define a coordinate frame uvw
centered on pi as shown 
u  

ni

v

 

 pj  pi    u

w

 

uv

   

using this frame  the difference between ni and nj can be
expressed as a set of angular features by 

b  feature extraction



lidar point clouds for each obstacle observation were distilled into features using point feature histograms  pfhs  
a tool widely used in computer vision problems to encode
a point or a pixels k neighborhood geometrical properties 
pfhs determine these properties by generalizing the mean
curvature around the point using a multi dimensional histogram of values 
for this project  we implemented a simplified version
of pfh called fast point feature histogram  fpfh   the
following subsections briefly give a theoretical primer on
pfh and then describe implemented algorithm for normal
estimation and feature histogram 




  v  nj
u   pj  pi  
 
  pj  pi   


w  nj
 
  tan
u  nj

   

the uvw frame  the normals  and the angles are shown
geometrically in fig    
fpfh descriptors simplify the computational complexity
of pfh from o n    to o nk  by only computing the    
and  corresponding to k nearest neighbors of a query point
pi instead of every point in the cloud      these angles are
calculated and stored as a simplified point feature histogram

fifig     a  d k d tree  the first split  red  cuts the root cell  white  into
two subcells  each of which is then split  green  into two subcells  finally 
each of those four is split  blue  into two subcells 

 spfh   finally  the fpfh is calculated as shown 
f p f h pi     sp f h pi    

 
k

k
x
j  

 
sp f h pk  
wk

   

where  wik is the distance between pi and neighbor pk  
   normal estimation  the normals were estimated using
unconstrained least squares as described in      the closedform solution for normal vector ni corresponding to point pi
is
ni   mi  bi
   
pk
p
k
where  mi   j   pj ptj and bi   j   pj   the pj s in the
sum correspond to the k nearest neighbors of point pi   for
this project  we chose k     
   fpfh implementation  each feature was discretized
into nf levels  leading to a n   n f possible feature
combination for each point  in our implementation  we chose
nf      and n         in addition no features were
extracted from point clouds which had fewer than   points 
iv  obstacle identification
to identify individual obstacles within a lidar scan of a
cluttered space  it was necessary to find clusters within the
full point cloud  to this end  we implemented a clustering
algorithm using k d trees 
a  k d trees
a k d tree is a generalization of binary search tree to a
higher dimensional space  every non leaf node of the tree
divides the hyperplane into two halfspaces in one of the kdimensions  for example  d k d tree is shown in fig   
hence  a balanced k d tree can be constructed by cycling
through the axes used to select the splitting planes  and
splitting the points by finding the median with respect to
the axes selected 

algorithm   pseudocode for clustering
form k d tree from point cloud
while count  number of points do
randomly select pi from point cloud
if pi has not been clustered then
add pi to queue q
while q is not empty do
pj   dequeue q 
add pj to current cluster
find all the neighbors of pj within range d that
have not been processed  and add to q
end while
start a new cluster
end if
end while
that were within a given range  algorithm   presents the
steps used in the clustering 
for this implementation  we assumed that the space environment being explored is free of unwanted clutter so that
all of the lidar readings correspond to objects of interest  in
addition  the algorithm relies on a range d as the minimum
distance between clusters  based on euclidean distance  in
practice  minimum spacing tends to hold true in space
environments  both during on orbit formation maneuvers and
within saturns rings  where most of the rocks are separated
by meters 
v  obstacle classification
two algorithms were explored for classifying lidar point
clusters into obstacle types  in both cases  clusters with too
few points to extract features were marked as unclassified 
   naive bayes classifier  for this classifier  we assumed
that each feature combination extracted from a given point
cluster was an i i d  random variable  this leads to the
following log likelihood function 
 
n
y
  q    log
p xi   k y   q nk p y   q 
   
k  

where q represents a particular obstacle type  n is the
number of possible feature combinations  and nk is the
number of occurrences of the kth feature combination in x
 where x is the list of feature combinations extracted from a
point cloud  taken from a test obstacle of type y   let k y q
and y q be estimates of p xi   k y   q  and p y   q  
respectively  then   q  is approximately proportional to
n
x

nk log k y q     log y q  

where we assume a uniform prior  y q        and
m

k y q  
b  clustering implementation
using an inbuilt matlab function  we created a k d tree
representation of the full lidar point cloud  then the point
cloud was divided into clusters by grouping all the points

   

k  

  xx
 j 
  xi   k 
m j   i

   

where m is the number of training examples  after training 
each test case was classified as the obstacle type resulting in
the highest log likelihood 

fiactual
 a  original obstacle set

rec
ell
cyl
con

rec
   
   
   
   

predicted
ell
cyl
   
   
       
       
   
   

con
   
   
   
   

 b  clustered lidar cloud

actual

table i
naive bayes c onfusion m atrix

rec
ell
cyl
con

rec
   
   
   
   

predicted
ell
cyl
  
   
   
  
       
  
   

con
  
  
   
   

table ii
svm c onfusion m atrix

fig     full process of identifying and classifying the obstacles  lidar
source is located at the center red circle   c  classification output labeled
by color  red   rect  blue   ell  magenta   cyl  green   con   the blue
circle represents the maximum distance within which training examples
were generated 

   svm classifier  the svm classifier was implemented
using the matlab wrapper for the libsvm package  this
allowed us to easily vary kernel functions  regularization
parameters and training size  after   fold cross validation 
a gaussian kernel with      was selected  the results
from training and testing are described in more detail in the
following section 
vi  experiments and results
the classification algorithms were trained using     
examples for each of the obstacle types  plots of the resulting
fpfh data for each type are shown in fig     for testing 
cluttered environments were randomly generated  using one
obstacle type per set to permit straightforward accuracy
measurements while maintaining the key dynamic of obstacle
occlusion during lidar scanning  to check for overfitting 
we tested the classifier using increasing numbers of training
examples  as shown in fig     the accuracy leveled off
quickly  ruling out overfitting and showing that more training
examples were not needed 
the resulting confusion matrices for each algorithm are
shown in tables i and ii  svm clearly outperformed naive
bayes for each obstacle type  this may be due to naive
bayes assumption of independence between feature combinations  which is not in fact correct  however  even svm
overall it did not perform as well as might be desired  that
being said  as shown in fig   c  classification performed very
well on obstacles within the maximum distance from the lidar
source in which training examples were generated 

class  

 c  classified obstacle set

con
cyl
ell

class  
rec
ell
cyl
   
   
   
   
   
   

table iii
svm t wo  c lass c lassification

to gain further insight into the relatively low accuracy results of svm  we restricted and trained the classifier on only
two obstacles at a time  and ran the tests again  the results
in table iii show that svm mostly performs quite well  and
that distinguishing cylinders and cones was the most difficult
classification task  this can be explained by the myopic knearest simplification in the fpfh algorithm  which fails to
capture feature information on obstacle surfaces across long
distances  thus  both the curved and flat surfaces of a cone
can easily be mistaken for those of a cylinder  and vice versa 
vii  conclusions and future work
the results of our clustering algorithm for identifying
obstacles in lidar point clouds are very promising  in a
project developed alongside this for aa      decisionmaking under uncertainty  we showed that safe navigation
is possible in a highly cluttered and dynamic environment
using only   lasers to detect obstacle surfaces  thus  we
are confident that the obstacle positions identified by the
clustering algorithm will be more than sufficient for safe
navigation 
for classification  we showed that svm outperforms naive
bayes  future work may be to extract more complex features 
e g  using view point features  such features could also be
used to estimate the size  position  and velocity of obstacles 

fipercent correct
number of training examples per obstacle type
fig    

convergence of the svm classifier with increased training

additional future work to enable safe and efficient navigation in cluttered dynamic environments may be to  i  track
obstacles using kalman filter techniques  and  ii  improve
on the related proof of concept from the aa     project 
extending the work to pomdps for planning under uncertainty 
r eferences
    r  b  rusu  z  c  marton  n  blodow  m  dolha  and
m  beetz  towards  d point cloud based object maps for
household environments  robotics and autonomous systems 
vol      no      pp                 online   available 
http   dx doi org         j robot            
    a  teichman  j  levinson  and s  thrun  towards  d object recognition via classification of arbitrary object tracks  proceedings   ieee
international conference on robotics and automation  pp           
     
    b  douillard  j  underwood  n  kuntz  v  vlaskine  a  quadros 
p  morton  and a  frenkel  on the segmentation of  d lidar point
clouds  proceedings   ieee international conference on robotics and
automation  pp                 
    m  himmelsbach and t  luettel  real time object classification
in  d point clouds using point feature histograms 
iros 
     
pp 
        
     
 online  
available 
http   ieeexplore ieee org xpls abs all jsp arnumber        
    h  s  koppula  a  anand  t  joachims  and a  saxena 
semantic labeling of  d point clouds for indoor scenes 
neural information processing systems  pp             online  
available  http   pr cs cornell edu sceneunderstanding nips      pdf
    r  b  rusu  n  blodow  and m  beetz  fast point feature histograms
 fpfh  for  d registration       ieee international conference on
robotics and automation  pp                 
    h  badino  d  huber  y  park  and t  kanade  fast and accurate
computation of  nsurface normals from range images  no  may 
     

fi