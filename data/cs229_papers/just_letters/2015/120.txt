stanford university
cs      machine learning techniques
project report

emotion classification on face images

authors 
mikael jorda
nina miolane

instructor
andrew ng

december         

fi 

introduction

humans can recognize intuitively emotions on peoples faces  but computers or robots  while the microsoft
project oxford announces on november   th      the release of its machine learning tools identifying facial
expressions  we also tackle the problem of emotion recognition on face images  in our case  emotion recognition
is treated as a supervised classification problem  we use a subset of the ck   expanded cohn kanade 
database      with     face images of    x    pixels across     subjects  as a pre processing  the images are
cropped around the faces and intensity normalized  each image has a label from a set of   emotions    anger 
  contempt    disgust    fear    happy    sadness and   surprise  our goal is to train a classifier that 
given a new image  automatically annotates it with the corresponding emotion 
as we have a small data set  we implement methods traditionally used on such small datasets  see section
    as well as a deep learning method but adapted to small datasets  section     we compare and discuss the
results obtained in section   and   

figure    examples of face images  from left to right  disgust  label     happy  label    and sadness  label    

 

featurization of the images with traditional methods

we build an image representation  i e  an appropriate featurization of the image with respect to the emotion
classification problem  in the literature  authors have developed efficient featurizations that perform very well
for face recognition or object recognition on small databases         we have focused on the bag of words  bow 
and fisher vector  fv  representations  which we have adapted here to the emotion classification problem 

   

sift and dense sift local descriptors of images

both bow and fv featurizations rely on a beforehand computation of local descriptors of images  we choose
to consider the very popular sift  scale invariant feature transform  descriptors or dense sift descriptors 
their computations rely on the gaussian scale space of the image  and the corresponding difference of gaussians
 dog  that detects images keypoints like edges  the sift is defined as a     dimensional vector describing
the image intensity by computing local gradient patches at these keypoints  in contrast  dense sift compute
a     dimensional descriptor at each point of a regular grid predefined on the image 
very interesting properties of these descriptors with respect to our problem are their invariance to affine
transformations  and robustness to changes in illumination  noise  and small changes in view point  thus they
may capture facial expression even if the subjects head appears with some angle  we used the functions vl sift
and vl dsift  of the vlfeat library     to implement sift and dense sifts  one controls the average number
of detected sift by varying the peak and edge thresholds  which respectively eliminate too small peaks of the
dog scale space  and peaks whose curvature is too small  one controls the number of detected dense sift by
refining the grid step on the image 
as shown on fig       sift descriptors seem relevant to our approach  they detect emotion related keypoints  like forehead folding for disgust and sadness  but not for happiness 

   

principal component analysis on the local descriptors

studies have shown that gradient patches surrounding sift keypoints are highly structured  and therefore
easier to represent using principal component analysis  pca       the first components of the pca subspace
are claimed to be sufficient to encode the variations in the gradient patch caused by the identity of the keypoint 
in contrast  the later components shall represent details in the gradient that are not necessarily useful 

 

fifigure    examples of sift descriptors of our images 
thus we perform a principal component analysis on the sift or dense sift descriptors with the idea of
getting more distinctive and more compact descriptors  following recommendations in the literature      we
select the first principal components to project our descriptors 

   

pooling of local descriptors  bag of words and fisher vector

on figure      some descriptors are attached to keypoints that are irrelevant for emotions classification  such
as those attached to hairs for example  such keypoints are also often subject specific and as such  rare among
all local descriptors  to remove these unsuitable descriptors  we perform another step in our featurization
procedure  in the literature  this step is known as the coding and pooling step  we consider two strategies 
bag of words and fisher vector 
     

bag of words representation

the bag of words  bow  featurization works as follows  first  in the coding step  one learns a visual dictionnary
of the local descriptors projections  this is done by training a k means algorithms on the total set of sift  or
dense sift  descriptors projections  whose k centers define the k visual words 
second  in the pooling step  each descriptor projection of a given image is hardly assigned to a cluster 
the final bow representation is an histogram counting the occurrences of each visual word in the image  the
image is represented by a single vector of length k  we normalize it successively through power normalization
         and l  normalization  techniques that have been shown to improve the featurization      the size of
the vocabulary k is selected by cross validation as we shall see in the results section 
     

fisher vector representation

the fisher vector featurization is very close to bag of words  being even considered as its generalization      it
works as follows  first  in a coding step  one learns a generative model of the descriptors projections  this model
is taken to be a gaussian mixture model  gmm   as such models may approximate any continuous distribution
with arbitrary precision  it accounts for example for the probability of descriptors around the eyes  the mouth 
or the folding of the forehead  the maximum likelihood estimates of the gmm parameters are learned on a
training set of descriptor projections using the expectation maximization algorithm  em   implemented in the
function vl gmm of vlfeat 
second  in a pooling step  the fv representation characterizes the image by the deviation of its sift
descriptor projections from the sift generative model  see     for the interpretation of the fisher vector in the
context of information geometry  
in practice  we use the function vl fisher of the vlfeat library to compute the fv of a new image  the image
is represented by a single vector of length      m  where we recall    is the number of principal components
selected for the descriptors projections and m is the number of gaussians  we also normalize this vector
successively through power normalization          and l  normalization      the number m is selected by
cross validation as we shall see in the results section 

 

fi 

featurization of the images through a deep learning method

lately  deep convolutional neural networks  cnn  have been shown to be extremely powerful for image recognition  in particular for faces recognition      but these networks usually require a huge amount of training data
 several millions  in order to be trained properly and to be efficient  as our database contains only     images 
we do not train such a network ourselves 
rather  we use the deep face net from      which has been pre trained on    m face images  however  as
the goal of     was face recognition and not emotion recognition  we choose to cut the last layers of the cnn
which are the most specialized  then we process our images with this cut neural network  the hidden units at
the chosen layer form a vector which we normalize and use as our feature vector  the number l of layers that
we cut is selected through cross validation 

 

classification via support vector machine

we use support vector machine with the one vs the rest strategy for multi class classification  more precisely 
we train   classifiers to separate one emotion from the rest  solving the primal problem for l  loss with l regularization  in practice  we use liblinear library for the implementation      the results below show the    fold
cross validation accuracy on our whole dataset  the regularization parameter c is automatically determined to
give the highest accuracy 

   

first results

for each of the featurization methods  we vary a parameter to achieve the highest cross validated accuracy  for
fisher vectors  we vary the number of gaussians in the gmm  m   for bag of words  the number of clusters
 k   and for the cnn method  the number of removed layers  l   the results are summarized in table   
table       fold accuracy percentage on the whole dataset     
bag of words
fisher vector
cnn
k               m     
        l          
k               m     
        l          
m               l          
l          
l          

images 
 
 
 
 
 

the bag of words featurization performs quite well with a cross validated average accuracy of        but
the best featurization is the fisher vector  with a cross validated average accuracy of         this seems
natural as the fisher vector is a generalization of bag of words  containing more information on the images 
the cnn approach performs less well  this means that the results on the hidden units of our pre trained
cnn may not be a good featurization for our emotion classification problem  the cnn pre trained for face
recognition may not be adapted for emotion classification if the goal is to reach an outstanding accuracy  note
that training our own cnn for emotion recognition would require at least    or     times more images that we
have  thus we discard this option 

   

introducing the spatial pyramid kernel

the spatial pyramids approach consists in placing a sequence of increasingly coarser grids  a pyramid  on the
images  and computing the feature vectors on each of the zones      as such  it incorporates spatial information 
the location of the descriptor projections in each of the zones  which was lost in the featurization process 
we decide to consider only one grid and split the image in   zones  which are defined as shown in figure
     taking advantage of the images cropping  these zones are chosen to be pertinent for emotion classification 
one zone contains the mouth  another the nose  two others the eyes etc  thus  the featurization with spatial
pyramid compares mouth descriptor projections with mouth descriptor projections  nose descriptor projections
with noise descriptor projections etc  the new feature vector  fv or bow  is defined as the concatenation of
the   feature vectors per zone  this amounts to run svm with a mercer kernel called the spatial pyramid
kernel     
adding the spatial pyramid kernel completes our pipeline  featurization and classification   which is
summarized on figure   

 

fifigure    the   zones considered for the spatial pyramid kernel 

pre processing
raw images

compute
local descriptors

cropped images with
normalized intensities

sets of local descriptors
coding and pooling method
using spatial pyramids

multi class
svm
classifier

learning

power and l 
normalizations

normalized vector
representations

vector representations
 fisher vector or bag of words 

figure    pipeline of our learning algorithm 

   

results with the spatial pyramid kernel

using spatial pyramid kernel  the average accuracy is significantly increased both for bag of words and fisher
vectors  figure     shows the results for these two methods for different parameters  cross validating on the
hyper parameters m and k  we now obtain        for bag of words  k        and        for fisher vectors
 m        we select the corresponding classifiers 
   fold cross validation accuracy on whole training set
in function of number of gaussians in the gmm
 fisher vector featurization 

  

  fold cross validation accuracy    

  fold cross validation accuracy    

   fold cross validation accuracy on whole training set
in function of number of clusters
 bag of words featurization 
    
  
    
  
    
  
    
  
   

   

   

   

   

   

   

number of clusters

  
  
  
  
  
  
  
  
  
  
  
 
  

 

  

 

  

 

  

number of gaussians

figure    accuracy of svm with the two featurization methods 
ultimately  we compute a better estimate of the generalization error on the selected classifiers  we divide
our dataset in two parts  train and test sets  we train the two best classifiers  m      for fv and k       for
bow  and adjust the regularization parameter c with a   fold cross validation on the training set  first half  
then  we test the two classifiers on the test set  second half   we get the following results for the estimates of
the generalization error  to be exhaustive  we also include the result for cnn  
        for bow 
        for fv 
 

fi        for the cnn  without spatial pyramid kernel  l     
our method manages to classify   emotions with a reasonable accuracy for such a small dataset of     images 

 

analysis and conclusions

a main source of errors come from the fact that we may recognize faces instead of emotions  we remark that if
we train our classifier on some images and try to predict the emotion of a new face of a subject absent from the
training set  the success rate is high  but if we try to predict the emotion of someone who was in the training
set  we tend to fail  with more images from more people  we would densify the space of face geometry while
keeping the space of emotion at the same size  therefore the separation of the emotions would be more visible
than the separation of face geometries and this source of errors would be reduced  with millions of images  we
would always have someone resembling our subject in the training database for each emotion so this problem
would disappear 
more images would also allow us to to train a full neural network and to use deep learning techniques for
emotion classification  with the success of these techniques on images  it would certainly be interesting and
efficient 
we also notice the great improvement in accuracy due to the introduction of the spatial pyramid kernel  this
was expected since this method allows to compare mouths with mouths  noses with noses and so on  therefore 
we expect our algorithm to be able to detect more easily the facial expression  local information  compared to
the face geometry  global information 
then  and in regards of concrete applications  we would like to be able to recognize emotions from images
taken from different point of view and in different environments  this would mean  again  to have more training
images  but now taken in a lot of different orientations  of course  our sift based representation would be
naturally suited for this with its robustness to light conditions and affine transformations of the image 
ultimately  a substantial adding to our algorithm would be the possibility to rank all   emotions  using
svm ranking methods for example  indeed  facial expressions are much more complex than the label of a single
emotion  capturing more complex facial behavior  with for example a percentage of each emotion presence 
would make our algorithm much finer and closer to human intelligence 

references
    rong en fan  kai wei chang  cho jui hsieh  xiang rui wang and chih jen lin  liblinear  a library
for large linear classification  journal of machine learning research          
    ke  y  and sukthankar  r   pca sift  a more distinctive representation for local image descriptors 
proceedings of the conference on computer vision and pattern recognition        
    lazebnik  s   schmid c  and ponce j   beyond bags of features  spatial pyramid matching for recognizing
natural scene categories  proceedings of the international conference on computer vision and pattern
recognition        
    lucey p   cohn j f   kanade t   saragih j   ambadar z  and matthews i   the extended cohn kanade
dataset  ck    a complete dataset for action unit and emotion specified expression  proceedings of the
computer vision and pattern recognition workshops        
    vedaldi a   fulkerson b   vlfeat  an open and portable library of computer vision algorithms  proceedings of the international conference on multimedia        
    perronnin f   sanchez j  and mensink t   improving the fisher kernel for large scale image classification 
european conference of computer vision                
    sanchez j   perronnin f   mensink t   and verbeek j   image classification with the fisher vector  theory
and practice  international journal of computer vision                 
    ionescu b   benois pineau j   piatrik t   quenot g   bag of words image representation  key ideas and
further insight  advances in computer vision and pattern recognition        
    parkhi o  m   vedaldi a  and zisserman a   deep face recognition  proceedings of the british machine
vision conference        

 

fi