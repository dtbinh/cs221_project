 

blind audio source separation pipeline and
algorithm evaluation
wisam reid  kai chieh huang   doron roberts kedes
abstractthis report outlines the various methods and experiments employed by its authors in their search for algorithmic
solutions for blind audio source separation  in the context of music  advancing bss would lead to improvements in music
information retrieval  computer music composition  spatial audio  and audio engineering  an understanding and evaluation
on the advantage and disadvantage of different bss algorithms will be beneficial for further usage of these bss algorithm in
different context  this report discusses three blind audio source separation algorithms  gmm  nmf  and ica  and evaluates
their performance based on human perception of audio signals 
index terms audio signal processing  blind source separation  bark coefficient analysis  non negative matrix factorization 
gaussian mixture model  critical band smoothing

f

 

p roject background

blind source separation  bss  is the separation of a set
of source signals from a set of mixed signals  without
the aid of information  or with very little information 
about the source signals or the mixing process  one way
of categorizing these algorithms is dividing them into
the approach in time domain and frequency domain  an
example of time domain approach is the independent
component analysis which works with input data that
contains both positive and negative values  on the other
hand  algorithms such as non negative matrix factorization works in the frequency domain where the input data
is the magnitude of the spectrogram which can only be
positive  although bss is an active research area where
new techniques are continuously being developed  there
is little literature studying the characteristics and the
differences between different bss algorithms and having an objective way of measuring the performance of
the bss algorithm in the context of human perception 
thus  it would be interesting to study the differences of
bss algorithms and compare them by evaluating their
separation results  in this report  we studied three major
bss algorithms  gaussian mixture model  gmm   nonnegative matrix factorization  nmf   and independent
component analysis  ica  and examine their performance along with a perceptually relevant criteria for
measuring the error  thus enabling regression on the
parameters of our model 

 

p ipeline

with the goal of comparing the performance of each
algorithm used in this paper in a convenient fashion  we
designed a pipeline structure as shown in fig    performance of bss supervised and unsupervised algorithms
for both under determined and determined systems  was
compared using this process  using this structure  weve

fig     pipeline for performing algorithm evaluation
implemented a system that automatically generates mixings and feeds the mixings into different algorithms to
evaluate and compare their performance 

 

nmf

source separation can be viewed as a matrix factorization problem  where the source mixture is modeled
as a matrix containing its spectrogram representation 
spectrograms are commonly used to visualize the time
varyingspectral density of audio  and other time domain
signals     audio signals can therefore be fully represented by a matrix with rows  columns  and element
values corresponding to the horizontal axis t  representing time   the vertical axis f  representing frequency  
and the intensity or color of each point in the image
 indicating the amplitude of a particular frequency at
a particular time  of a spectrogram respectively  the
spectrogram of a signal x t  can be estimated by computing the squared magnitude of the short time fourier

fi 

transform  stft  of the signal x t   and likewise  x t  can
be recovered from the spectrogram through the inverse
short time fourier transform  istft  after processing the
signal in spectral domain     
   

modeling source separation as an nmf

adopting this view  it follows that source separation
could be achieved by factorizing spectrogram data
as a mixture of prototypical spectra  while there are
many commonly practiced matrix factorization techniques such as singular value decomposition  svd  
eigenvalue decomposition  qr decomposition  qr  
lower upper decomposition  lu   nmf is a matrix
factorization that assumes everything is non negative 
giving this technique an advantage when processing
magnitude spectrograms  as an added advantage nonnegativity avoids destructive interference  guaranteeing
that estimated sources must cumulatively add during
resynthesis  in general nmf decomposes a matrix as a
product of two or more matrices as follows    
f t
   v   r 
original non negative data
f k
   w   r 
matrix of basis vectors  dictionary
elements
kt
   h   r 
matrix of activations  weights  or gains
in the form 

 


v
w
h


typically k   f   t and k is chosen such that
f k   kt  f t   hence reducing dimensionality     
in the context of source separation spectrogram data is
modeled as v   the columns of v are approximated as
a weighted sum  or mixture  of basis vectors w representing prototypical spectra and h representing time
onsets or envelopes  nmf is underlaid by a well defined
statistical model of superimposed gaussian components
and is equivalent to maximum likelihood estimation of
variance parameters  nmf can accommodate regularization constraints on the factors through bayesian priors 
in particular  inverse gamma and gamma markov chain
priors  estimation can be carried out using a generalized
expectation maximization  this can also be solved as a
minimization of d where d is a measure of divergence 
in the literature  factorization is usually framed as an
optimization problem min d v  w h      commonly
w h  

solved using euclidean or the
leibler  kl  divergence  defined
x
dkl  x y    x log
y
x
vf t
min
vf t log
w h  
 w h f t

generalized kullbackas
x y

giving

vf t    w h f t

f t

the former is convex in w and h separately  but
is not convex in both simultaneously  nmf does not
always give an intuitive decomposition  however
explicitly controlling the sparseness and smoothness
of the representation leads to representations that are

fig     a closer look at non negative matrix factorization
parts based and match the intuitive features of the data
     a deeper intuition is needed for how regularization
techniques relate to the performance of these algorithms
on audio data 
euclidean and kl divergence are both derived from a
greater class of  divergence algorithms  while it should
be noted that the derivative of d  x y  with regard to
y is continuous in   kl divergence and the euclidean
distance are defined as        and        respectively  this is noteworthy since factorizations obtained
with
    will rely more heavily on the largest
data values and less precision is to be expected in the
estimation of the low power components  this makes
kl nmf especially suitable for the decomposition of
audio spectra  which typically exhibit exponential power
decrease along frequency f and also usually comprise
low power transient components such as note attacks
together with higher power components such as tonal
parts of sustained notes      majorization minimization
 mm  can be performed using block coordinate descent 
where h is optimize for a fixed w   then w is optimize
for a fixed h  this is then repeated until convergence 
since solving a closed form solution is intractable  this is
solved
using jensens inequality  introducing the weights
p
k ijk     which gives d v  w h 
x
x
x
vf t

  vf t
 
 wf k hkt   
f tk log
f t

f tk

k

k

 
wf k hkt

choosing f tk to be p w  h   as suggested in     mm
fk
k
kt
updates can be derived  where majorization is achieved
by calculating f tk and minimization is achieved by
minimize
w h  
x
x
vf t
f t

k

f tk logwf k hkt

 

x

wf k hkt

k

as mentioned earlier  the mm estimation is equivalent
to a generalized em estimation with the added bene 

fi 

fit of accommodating regularization constraints on the
factors through markov chain priors  this is intuitive
since the em algorithm is a special case of mm  where
the minorizing function is the expected conditional log
likelihood  this approach stems from the fact that only
vf t is observed  but the full model involves unobserved
variables k  em is used to fit parameters that maximize
the likelihood of the data  maximizing over p k t  and
p f  k  gives em updates where the e step involves
calculating
p  k t p  f  k 
p  k f  t    p
k p  k t p  f  k  

and an m step maximizing
x
x
vf t
p  k f  t logp  k t p  f  k 
f t

k

unfortunately the number of parameters that need to
be estimated is f k   kt   in such a high dimensional
setting it is useful to impose additional structure  this
can be done using priors and regularization  priors can
encode structural assumptions  like sparsity  commonly
the posterior distribution is calculated using the posterior mode  map   another way is to impose structure
is through regularization  by adding another term to the
objective function
minimized v   w h     h 
w h  

where  encodes the desired structure  and controls the
strength      as discussed earlier  sparsity and smoothness are good choices for  h   these structures are
useful when encoding the transient features of common
audio sources  in addition  an interesting area of future
work could be the inclusion of gmm derived structure
through clustering  the beginnings of this research are
discussed further in this report 
   

fig     decomposing spectrograms

 

gmm

n sources are separated from a mixed signal by fitting
a gaussian mixture model  gmm  with n components
on the signals magnitude spectrogram  each bin in the
original spectrogram is assigned to one of n gmm
components  spectrograms containing the bins assigned
to each gmm component are inverted to produce estimations of the source signals  the spectrogram of the
mixed signal was generated using a short time fourier
transform  stft   the stft was computed with a     
sample kaiser window with a beta value of     a hop
size of    samples  and zero padding by a factor of
   these parameters were chosen to minimize spectral
leakage while providing extremely high resolution in
both the time and frequency domain  the top most
graph in fig   shows the spectrogram of a mixed signal 
where the magnitude is in decibel scale  all data points
with a magnitude less than    db were discarded  the
threshold value of    db was chosen experimentally as
the value that most effectively disambiguated between
silence and acoustic events 

seperating sources

in the current research nmf is used to estimate w and
h which are in turn used to derive masking filters ms as
seen in the signal flow in fig    here audio source
mixtures are first represented as spectrograms by a stft
algorithm  then factorized into w and h in order to
derive masking filters used to extract estimated sources
x where x   ms v and is the hadamard product
 an element wise multiplication of the matrices   these
estimates are then synthesized into time domain signals
via a istft algorithm  the original phase components
 v are added back into the estimates  and passed down
to the next stage of the pipeline for evaluation  unsupervised  partially supervised  and fully supervised
algorithms were evaluated  using this method nmfs
separation and source estimation performance where
compared to ica and gmm algorithms against the
performance criteria outline later in this report 

fig     gmm source separation process

fi 

   

clustering

after thresholding data based on magnitude  the magnitude feature was discarded from the data used to fit
the gmm  fitting a gmm on data without magnitude
consistently outperformed the gmm fit on data with
magnitude included  this is not surprising since the time
and frequency of a bin are much more indicative of
source signal membership than magnitude  the gmm
was fit to the data with an equal number of components
as source signals to be estimated  each component was
fit with a full covariance  non diagonal  matrix independently of the other components  a full covariance
matrix reflects the highly unpredictable nature of the
covariance of time and frequency in audio sources  the
independence of each components covariance matrix
reflects tendency for some audio events to be highly
concentrated in time or frequency  while other audio
events are more dispersed in time and frequency  initial
values for the components were selected using the kmeans algorithm 
   

source estimation

after fitting the gmm to the data  each bin in the
positive frequency portion of the original mixed signal
spectrogram underwent hard assignment to the component that maximized the posterior probability  the
middle graph in fig   shows the result of this assignment
after fitting a gmm using both frequency and time
information  a new spectrogram was generated for each
component consisting only of the bins in the original
spectrogram that were assigned to the component  finally  in the bottom of fig   shows the spectrograms of
two estimated sources   the first having predominately
low  narrow frequency content  and the second having
predominately high  disperse frequency content  each of
these spectrograms was inverted using an inverse shorttime fourier transform to obtain estimates of the original
source signals  the evaluation result of this algorithm is
discussed in the end of this paper 

 

the interference of other sources and the error term of
artifact introduced by the algorithm  and then calculate
the relative energy of these component in time domain 
this evaluation technique hence has the advantage of
providing information on how well a particular bss
algorithm suppresses the interference of other sources or
the artifact introduced while performing the separation 
however  the relationship between human perception on
the quality of separated results to these metrics is not
well established  accordingly  we proposed an improved
performance evaluation approach which relates human
perception on audio signals to the metrics based on
modifying the method proposed in     
   

critical band smoothing

since human hearing is only sensitive to spectral features
wider in frequency than a critical bandwidth  we can
model how human perceive audio signal by blurring
spectral features smaller than a critical bandwidth in
the spectrum using critical band smoothing procedure
      in this paper  the equivalent rectangular bandwidth
 erb  scale      is used for determining the critical
band  the erb and frequency in khz are related by
the equations be       log        f        and f  
be
                    with this relationship in hand  we can
smooth the spectral features of a certain audio signal by
replacing the magnitude of each frequency bin with its
average magnitude across one critical bandwidth using
the calculation below 
f  b        

p        

x

  f  b   

  

 h     

 

   

where we are using a       in this paper  the effect of
critical band smoothing can be understood through the
graph in fig   

p erformance e valuation

in order to fully understand and compare the performance of each algorithm used in this paper  it is
important to have an objective way of measuring the
estimated source result against its true source  several
methods commonly used to evaluate audio quality such
as peaq     are particular tailored to measure audio
codec performance and are in consequence not ideal
for evaluating audio source separation algorithms  one
set of metrics used to measure the performance in the
literature of bss that particular suited for studying the
characteristics of different bss algorithms are source
to distortion ratio  sdr   source to interference ratio
 sir   and sources to artifact ratio  sar       these ratio
are derived based on decomposing the estimated source
into true source part plus error term corresponding to

fig     critical band smoothed spectrum example

   

proposed performance criteria

in this article  a new performance criteria is designed
to study the performance among different bss algorithms in the context of human spectral perception 
for the evaluation of the bss algorithms in this paper 

fi 

the estimated source is decomposed into three parts as
discussed previously in      but instead of measuring the
energy ratio in time domain  we examine the energy
ratio in critical band smoothed frequency domain to
include the objectiveness of human hearing perception 
for instance  the critical band smoothed spectrum of the
estimated source is decomposed as sestimate   strue  
sinterf ere   sartif act where  sestimate is the critical band
smoothed spectrum of the estimated source  strue is the
projection of the critical band smoothed spectrum of
the estimated source onto the critical band smoothed
spectrum of the targeted true source  sinterf er is the
summation of all the projections of the critical band
smoothed spectrum of the estimated source onto all
other true sources  excluding the targeted true source  
and finally sartif act is calculated as sestimate    strue  
sinterf er   which stands for additional error or artifact
introduced by the bss algorithm  the three metrics sdr 
sir  and sar in this paper is defined as follows 
sdr     log    

kstrue k

 
  

   

  

   

ksinterf ere   sartif act  k
 

sir     log    

kstrue k

ksinterf ere k

 

sar     log    

kstrue   sinterf ere k
ksartif act k

 

 

   

where strue   sinterf ere   and sartif act are the critical
band smoothed spectrums as stated previously  it is
critical to note that sar stands for sources to artifact
 
ratio and in the numerator  kstrue   sinterf er k is the
total energy of all the sources present in the estimated
source  this arrangement makes sar independent of
sir and make a robust and accurate evaluation on the
artifact caused by the bss algorithm  an evaluation
test on an estimated source generated by a true source
adding more and more white noise using the new established performance measurement as a demonstration is
presented in fig   

fig     performance evaluation demonstration

 

fig     fast ica  ica  gmm  supervised nmf  unsupervised nmf  and partially supervised nmf

r esult   c onclusion

through the algorithm evaluation pipeline  we have successfully generated the sdr  sir  and sar comparison

among gmm  nmf  and ica by testing on the same
mixing generated using two sources  a bass and a drum
audio clip  as mentioned in the performance evaluation
section  sdr measures the general accuracy of how well
the estimated source is compared to its targeted true
source  sir on the other hand  measures how well the
algorithm prevent other sources from interfering the
estimated source while separating  finally  sar evaluate
how well the algorithm is at avoiding artifact  as is clear
in fig    fitting gmms with spectrograms of mixed audio
signals yielded the highest sir measured  but yielded
the lowest sdr except for unsupervised non negative
matrix factorization  these results are likely due to the
sharp division in the frequency domain between source
signal estimations created by hard assignment of spectral
data points to gmm components  the results of gmm in
fig   show a typical cutoff in the frequency domain  the
abrupt cutoff in frequency prevents source signals in different frequency bands from interfering with the source
being estimated  this suppression leads to gmms high
sir value  however  a negative consequence of the sharp
frequency cutoff is that signal content on the wrong
side of the cutoff is excluded from the source estimation
entirely  this suppression leads to a low sdr value  on
the contrary  fast ica  ica and nmf have similar sdr 
sar performance which are the highest among all the
algorithm weve evaluated  there is however  a major
difference among ica and nmf  where ica performs
well in a determined system when there is sufficient
mixing examples  while nmf performs well in an underdetermined system but requires a supervised learning
process on the true sources examples  furthermore  we
also evaluate the performance on the unsupervised and
partially supervised version of nmf  as we can see
from the result in fig    the performance of nmf drops
according to the degree it is unsupervised 

fi 

r eferences
   

boualem boashash  time frequency analysis  elsevier science       
    e  jacobsen and r  lyons  the sliding dft  signal
processing magazine  ieee              mar      
    p  smaragdis and j c  brown  non negative matrix
factorization for polyphonic music transcription  in
ieee workshop on applications of signal processing
to audio and acoustics  waspaa   pages        
october      
    cedric fevotte  nancy bertin  and jean louis durrieu  nonnegative matrix factorization with the
itakura saito divergence  with application to music
analysis  neural comput                 march      
    patrik o  hoyer  non negative matrix factorization
with sparseness constraints  corr  cs lg         
     
    cedric fevotte and jerome idier  algorithms for
nonnegative matrix factorization with the betadivergence  corr  abs                 
    judith c  brown paris smaragdis  non negative
matrix factorization for polyphonic music transcription  ieee workshop on applications of signal processing to audio and acoustics  pages         october
           
    treurniet w  bitto r  schmidmer c  sporer t 
beerends j  colomes c  keyhl m  stoll g  brandenburg k  feiten b  thiede  t  peaqthe itu standard for
objective measurement of perceived audio quality 
journal of the audio engineering society              
january february      
    e  vincent  r  gribonval  and c  fevotte  performance measurement in blind audio source separation  audio  speech  and language processing  ieee
transactions on                  july      
     jonathan s  abel and david p  berners  signal processing techniques for digital audio effects  pages
        spring      
     b  c  j  moore and b  r  glasberg  a revision of
zwickers loudness model  acta acustica        
     spring      

fi