cs    cs    project report   december       stanford university

 

intelligent rapid voice recognition using neural
tensor network  svm and reinforcement learning
davis wertheimer  aashna garg  james cranston
 daviswer  aashnagarg  jamesc   stanford edu

abstractwe propose two machine learning improvements on
the existing architecture of voice  and speaker  recognition software  where conventional systems extract two kinds of frequency
data from voice recordings and use the concatenation as input 
we propose two methods to allow the input vectors to interact
multiplicatively  the first is a neural tensor network layer under
a softmax classifier  and the second is a constrained variant of the
neural tensor network with reduced dimensionality  we compare
these methods with the current approach  using svms on the
concatenation of extracted data vectors  second  we trained a
shallow neural network on a q learning framework in order
to intelligently and dynamically minimize the amount of audio
required to make an accurate classification decision  while the
neural network architectures failed to improve on the existing
svm model  the q learner did learn to dynamically minimize
audio sampling while improving on the accuracy of the svm
system 
keywordsfunction approximation  markov decision process 
mdp  mel frequency cepstral coefficients  neural network  neural
tensor network  mfcc  policy optimization  q learning  security 
signal processing  support vector machine  svm  voice authentication  voice recognition 

i  i ntroduction
conventional voice  and speaker  recognition systems extract two kinds of frequency data from voice recordings 
mfccs  and the delta  rate of change  of each mfcc value 
machine learning systems  typically svms  are then trained
on the concatenation of those two vectors  while these systems do learn to distinguish between speakers based on the
signs and magnitudes of the mfcc and delta values  they
do not capture the intuition that each delta corresponds to
a particular mfcc value  we can use this information by
explicitly defining multiplicative relationships between the
corresponding elements  taking their product in addition to
scaling them by the appropriate learned weight parameter  this
allows us to capture information on to what degree the mfccs
and their deltas are adopting similar values  we hypothesize
that by introducing explicit multiplicative interaction to our
machine learning architecture  via neural tensor network  we
can improve accuracy for the speaker recognition task 
andrew ng  associate professor with the department of computer science 
stanford email  see http   www andrewng org  
percy liang  assistant professor with the department of computer science stanford email  see http   cs stanford edu  pliang  
justin fu is our cs    project mentor with the department of computer
science  stanford e mail  justinfu stanford edu 
junjie qin is our cs    project mentor with the department of computer
science  stanford e mail   see http   web stanford edu  jqin   

there are two lines of reasoning to support this claim 
the first is that by introducing multiplicative interaction  we
are incorporating new  useful information on the relationship
between mfccs and their deltas  the second is that we avoid
overfitting to the training data by constraining our system to
learning only linear and multiplicative relationships between
the two vectors  svms using the gaussian kernel could
possibly overdetermine the problem by implicitly learning
higher degree monomial relationships which are likely to be
uninformative  we predict that this leads to unnecessarily
convoluted decision boundaries 
in order to evaluate our hypothesis  we train two softmax
neural tensor networks consisting of a softmax layer over
a neural tensor network layer  and compare performance to
an array of one vs one binary svms performing multiclass
classification  we test performance on sets of   to   speakers
in order to measure how the three systems handle incremental
growth in the number of classes 
the second component of our study is a reinforcement
learning system which attempts to minimize the amount of
time and computation involved in the speaker recognition
task  without sacrificing the accuracy of the highest performing
classification system from part    the part   classifiers act
as high accuracy  high cost systems which the higher level
decider should utilize as little as possible  this forms a markov
decision process with a continuous state space  where states
consist of a confidence rating for each class  plus the number
of audio samples already taken  and actions consist of either
sampling again  or making the prediction of whichever class
has the highest current confidence rating  the reinforcement
learner for this mdp uses the q learning algorithm and a
shallow neural network to approximate the expected reward for
each state action pair  the trained system dynamically decides
whether to predict or continue sampling based on its current
confidence judgments and the amount of time elapsed since
start 
finally  we used the classifier and reinforcement learner to
build a system which can recognize peoples voices in real time 
as they speak 
ii 

r elated w ork

during the recent years  there have been many studies on
voice recognition using several features and techniques some
of the previous research studies in the field of voice recognition
include using svms along with linear discriminant analysis
with mfccs which increases the accuracy and prediction rate

fics    cs    project report   december       stanford university

 

  

  

framing  each audio sample  about       seconds long 
is split into    ms time windows  with a    ms jump
rate  any discrete point within the original audio sample
is then contained in exactly two clips 
fast fourier transform  fft   fft is performed on
each clip  and the real component is rescaled to mel
frequencies  which corrects for the fact that pitch is
logarithmic   using the following equation 
m  f          ln     f      

  
fig    

mfcc block diagram    

over svms alone      yu  li and fang     propose contextdependent deep tensor neural network to reduce error rate and
compares with deep neural network hidden markov models 
a new pattern classification method called the nearest feature
line  nfl  is proposed in li      where the nfl explores
the information provided by multiple prototypes per class 
audio features like mfcc  zcr  brightness and bandwidth 
spectrum flux were extracted  lu  zhang    li             
and the performance using svm  k nearest neighbor  knn  
and gaussian mixture model  gmm  were compared  audio
classification techniques for speech recognition for unsupervised multi speaker change detection are proposed in huang
and hansen      two new extended time features  variance of
the spectrum flux  vsf  and variance of the zero crossing
rate  vzcr  are used to pre classify the audio and supply
weights to the output probabilities of the gmm networks 
the classification is then implemented using weighted gmm
networks  a speech recognition system using artificial neural
network technique called reservoir computing  rc  was
given by abdulrahman      here they aim to improve the
performance of the conventional rc approach by developing
two approaches esnsvms  echo state networks with support
vector machines  and esnekms  echo state networks with
extreme kernel machines  
iii 

dataset and f eatures

our data set consists of audio clips collected from   students on campus    female    male  we record each person
reading aloud the first paragraph of lewis carrols alice in
wonderland  followed by a       second passage randomly
selected from another section of the same book  this way  we
have for each speaker one sample where the word content is
the same  and another where it is different  pre processing the
data consists of slicing each audio sample into a collection of
overlapping    ms clips  each an individual data point for that
speaker class  we then filtered out empty clips  max volume
    of max volume for the entire recording   and calculated
the mel frequency cepstral coefficient  mfcc  values for
each of the remaining clips  finally  we calculate the mfcc
deltas  or the trajectories of the mfcc coefficients over time 
together  these form the inputs to the classification systems 
each returning a single prediction per clip  calculating mfccs
involves seven steps  figure     each described briefly below 

  
  

  

computing mel filterbanks  the amplitudes of the
scaled mel frequencies are passed through each of
   triangular filters  staggered over the mel frequency
range in the same overlapping manner as the sliding
windows on the original audio clip  ensuring that
each amplitude is weighted equally  since adding any
two consecutively filtered bands produces the original
strength audio clip in the overlapping area  
every amplitude value is then summed within each
filtered band  yielding    energy density estimates over
the range of produced frequencies 
discrete cosine transform  a discrete cosine transform  dct  yields the final mfccs  representing the
energy distribution as a sum of generating frequencies
in the time domain 
the second input vector is a delta vector on the mfcc
values  we use the standard formula 
pn
n ct n  ctn  
dt   n   pn
  n   n 

which represents the rate of change of the generating
forces behind the vocal intensity distribution  the more
distant windows are weighted twice as heavily because
the closer windows each overlap with the one under
examination  sharing     of their generating audio
signal 
   finally  we log scaled both mfcc and delta vectors 
since they ranged from decimal scales to the hundreds
of thousands  final input vectors range from about         
we then held out one fifth of the dataset to use as testing
data  all of our subsequent systems  except the real time
classifier  were trained using the remaining     
iv  m ethods
our four machine learning systems are described in detail
below 
a  neural tensor network
a neural tensor network  ntn  allows two input vectors
to interact in a non linear fashion  by representing the weight
matrix as a   dimensional tensor  activation values use the
formula 

 

e 
   k 
 
g e    r  e      u 
f
e
w
e
 
v
 
b
 
r
r
r
 
r
e 

fics    cs    project report   december       stanford university

 

fig     low dimensional examples of the input supervectors used by our systems and their equivalence to traditional neural network   neural tensor network
formulations  the first is the ntn supervector  the second is snn  and the third is svm  the left hand side of each figure represents the traditional setup while
the right hand side gives the equivalent supervector 

fig     pca plots for ntn  snn  and svm input supervectors  respectively    classes are shown here  progressively more structure is imposed as the size of
the supervector increases 

where e  and e  are same dimensional input vectors  wr is a
square matrix slice of tensor w  vr is a vector slice of weight
matrix v  br is a bias term  and f is the activation function 
because tensors are difficult to represent in python  we chose
to re represent the input vectors as a single  mathematically
equivalent input supervector  which could then be fed into a
standard neural network  to generate the new input vector  we
append a bias term of   to each input vector  then calculate
their outer product  this creates a square matrix containing
every value of the first vector multiplied against every value
of the second  plus every value in the first vector  every value in
the second vector  and a bias term  due to the bias terms in both
vectors   using a standard weight matrix on these values is
equivalent to taking the tensor product  and adding the standard
weight product and a bias term  see figure   for a lowdimensional example  we replaced the  x   dimensional input
of the tensor network with the                 dimensional
input of a standard network  we use    hidden layer nodes 
plus a bias  since there are    delta mfcc pairs in each
input and extracting additional relationships is likely to be
uninformative  we used mean squared error as the objective
function and hyperbolic tangent as the activation function 
b  constrained tensor network   softmax neural network
due to the large dimensionality of the ntn we decided
to reduce the size of the supervector  since multiplicative
interactions are only of interest between each mfcc and its
corresponding delta  the rest can be discarded  we used a
supervector equal to the mfcc and delta vectors concatenated with their elementwise product  plus a bias  this is
mathematically equivalent to a tensor layer with the tensor
holding only zeros except on the diagonal  the final row 
and the final column  and the inputs have bias terms   fig
  gives a low dimensional example  while both systems are
technically tensor and softmax networks  we refer to the
higher dimensional system with the full tensor as the ntn
and the lower dimensional system as the softmax neural

network  snn   the input vector for the snn consists of
                    features  as opposed to the ntns     
the hidden layer is identical to that of the ntn  for the same
reasons  activation function remained hyperbolic tangent  and
we used mean squared error as the objective 
c  support vector machine  svm 
in addition to using the ntn and snn to make class predictions  we compare the algorithms performances to svms 
the svm we used derived from the optimization algorithm
used in class 
m
m
x
  x  i   j 
y y i j hx i    x j  i
max w     
i 

 
i  
i j  
s t 

i     i              m
m
x
i y  i     
i  

because an svm can take only a single input vector  we
concatenate the mfcc vector with the delta vector  visualizations of the supervectors in the data set for all three models
are given in figure    since svms can only perform binary
classification  we use a series of svms which each predict
whether or not the sample belongs to a single given class versus
another  and take the result with the highest overall certainty 
d  q learning and function approximation
our higher level audio sampler and decision maker explores
a continuous state space  necessitating a function approximator
to evaluate the expected reward for each state action pair  our
state space consists of confidence ratings for each class  plus
the number of samples taken so far for the particular query
being processed  because expected reward cannot be expressed
in terms of a linear combination of these values  they all
increase with time monotonically and roughly proportionately  

fics    cs    project report   december       stanford university

we use a simple   layer neural network approximator with
hyperbolic tangent activation function and objective function
following the form 
 
x 
min
qopt  s  a  w    r    vopt  s    
w

 

table i 

c omparison of ntn snn and svm based on    class
experiments

 s a r s   

  class statistics

ntn

snn

svm

train accuracy
test accuracy
f  score
improvement

    
    
    
   

    
    
    
    

    
    
    
    

and update rule for each  s  a  r  s    as follows 
h
i
w  w   qopt  s  a  w    r    vopt  s      s  a 
our state feature vector consists of the sorted  cumulative
prediction strength for each class  plus the number of samples
taken since the beginning of the authentication process  plus
an action term  plus a bias term  committing to a prediction
set the action term to    while resampling set the action term
to     thus our network consisted of a size n   input layer  n
hidden nodes  and a single output  where n is the number of
classes  we use a size n hidden layer for the same reason we
use    on the predictor  extracting more than one activation
value per class is likely to be uninformative 
v  experiments and results
we collected two audio clips from each speaker  one in
which they read the same passage  and the other with different
passages  training the classifiers on either data set produced
no discernible net difference for any of the systems  so for all
subsequent analyses we trained the classification systems on
the combination of both sets 
a  classifiers
we trained our three classification systems on progressively
larger subsets of our data set  first with   speakers  then
   then    up to    in order to evaluate how each handles
stress in the form of additional classes  both neural networks
trained for     passes over the training set  long enough to
reach convergence on all training sets  step size was inversely
proportional to the number of classes  and number of updates
per pass over the training set  and annealed at a rate inversely
proportional to the number of passes already performed  while
we experimented with l  normalization and momentum  neither improved performance or learning rate for either model 
we trained our binary svm array to convergence on the same
progressively increasing data sets  with normalization constant
  and final stopping epsilon equal to      
our metrics for the classifier experiments are training accuracy  test accuracy  f  score on the testing data  and percent
improvement over random guessing  because chance performance decreases monotonically with the number of classes 
it could be the case that performance relative to the expected
level of error is increasing even when the total accuracy drops 
the formula for percent improvement over chance is given by
    a
  n   where a is test accuracy and n is the number of
classes  this indicates the proportion of error from random
guessing that vanishes when the algorithm is employed  a
comparison of the results for   class classification is given in
table    and figure   shows the progression of these metrics

fig    

performance comparisons between ntn snn svm

over increasing numbers of classes  a comparison for all three
systems is given for test accuracy and percent improvement
from chance in figure   
unfortunately  neither neural network outperforms svm  as
expected from the large dimensionality  ntn overfits  evidence
by the gap between training and test accuracy  but the lowerdimensional snn variant fixes this problem  we suspect that
svm outperforms neural networks because the supervectors
create highly non convex objective functions  sgd is not
equipped to handle this  and we see from the confusion
matrices in fig   that ntn and to a lesser extent snn become
trapped at local maxima  for   class classification  the ntn
simply assigns all inputs to the two speakers with the most
training samples  svm does not overfit by making use of
extraneous information  so we used svm as the underlying
prediction system for the minimal sampling q learner 
b  reinforcement learner
the q learning neural network  like the classifiers  was
trained on successively larger sets of speakers  for      passes 

fig    

confusion matrices for   class ntn  snn  and svm  respectively

fics    cs    project report   december       stanford university

 

fig     test accuracy  training accuracy  f  score and percent improvement for ntn  snn and svm  respectively  note that y axis scaling is not preserved
between figures 

where a pass consists of one epsilon greedy walk over each
speakers training audio  step size was inversely proportional
to the number of classes  and annealing rate inversely proportional to the number of passes already performed  epsilon
annealed at a rate inversely proportional to the square root
of passes performed  in order to maintain randomness in late
stages  l  normalization was employed with decay constant
annealing to zero at a rate proportional to step size  producing
more stable training behavior  rewards were fixed at      for
correct incorrect predictions  and a small  controllable penalty
for resampling  gamma was fixed at        while gamma
could act as the resampling penalty parameter with the reward
fixed at zero  we found that constant gamma and varying
penalty produced faster convergence 
the q learner converged consistently to a single narrow
range of samples per decision for all numbers of classes 
showing that it dynamically responds to confidence levels as it
samples  however  because the q learner depends on random
initialization of weights and random walks over randomly
shuffled training data  setting a single value for the negative
resampling reward produced a fairly wide range of models with
different mean samples per decision  we trained six q learners
on each training set  with penalty parameters equal to       n
where n ranges from   to    the resulting samples per decision
rates fluctuated too widely to extract meaningful relationships
between results and parameters  other than that larger penalties
lead to faster  less accurate systems  while smaller creates
the opposite  however  we did log the minimum number of
average samples per decision in models achieving greater than
    test accuracy  and these results are given in figure   
this minimum learned sample rate steadily increases with the
number of classes  showing that the q learner  despite its wide
range of outputs  gracefully handles decreasing accuracy rates
in the underlying classifier 
c  real time classification
finally  we used the trained q learner and svm classifier to
build a system that samples audio  performs mfcc  resamples
dynamically as required  and makes speaker classification
predictions in real time  we tested it on ourselves  using  class algorithms  the system was able to make highly accurate
predictions with only a short lag time  less than   second  
though we were unable to record the exact lag times and
accuracies since the system was making predictions in real
time  far too quickly to log or record the results  regardless 

fig     average number of samples per decision  among the fastest models
still achieving above     accuracy for each number of distinct speakers 

this shows that a trained classifier under a subsequently trained
sampler is a viable model for real time speaker diarization 
even for large numbers of speakers  since the minimum number
of samples required for the q learner to achieve     accuracy
increased only slightly with the number of classes 
vi  c onclusion a nd f uture w ork
unfortunately  we were wrong in our prediction that explicitly defined supervectors would minimize overfitting relative
to the implicitly defined supervector of a gaussian kernel
svm  the supervectors create highly non convex objectives
under mean squared error  with the result that sgd leads to
highly local optima  svm remains the best system for speaker
classification of single clips  however  our q learning system
shows that an intelligent data sampler can effectively balance
accuracy with speed  achieving greater than     test accuracy
for up to   speakers with less than    seconds worth of audio
input per decision  results indicate that the q learning system
is highly robust and can be expected to maintain this level
of performance for higher numbers of speakers  we were
then able to construct an intelligent  real time  highly accurate
speaker diarization engine  further research in this area would
include the incorporation of non mfcc data into the classifier
input vectors  and additional experimentation with q learning
training parameters in order to gain finer control and produce
more stable behavior 
r eferences
   

aamir khan   muhammad farhan  asar ali  speech recognition  increasing efficiency of svms      

fics    cs    project report   december       stanford university

   

dong yu  li deng  frank seide  the deep tensor neural network with
applications to large vocabulary speech recognition      
    li  s  z  content based audio classification and retrieval using the
nearest feature line method  ieee transactions on speech and audio
processing     
    lu  l   zhang  h  j   li  s  z content based audio classification and
segmentation by using support vector machines  multimedia systems 
    
    huang  r   hansen  j  h  l  advances in unsupervised audio classification and segmentation for the broadcast news and ngsw corpora  ieee
transactions on audio  speech and language processing     
    abdulrahman alalshekmubarak towards a robust arabic speech recognition system based on reservoir computing     
    http   recognize speech com feature extraction mfcc

 

fi