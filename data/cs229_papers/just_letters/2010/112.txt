twitter spammer profile detection
grace gee  hakson teh
gracehg stanford edu  hakson cs stanford edu
december        
   introduction
twitter is a free microblogging service that allows users to post messages  called tweets  up to
    characters in length  its value is in its ease of sharing and accessing user generated content 
including opinions  news  and trending topics  thus  twitter provides an opportunity to generate
large traffic and revenue  especially since it has hundreds of millions of users 

however  these opportunities make twitter a prime target of spammers  it is easy for humans to
distinguish spammers from actual users  but the existence of spammers wastes user time and
attention  puts users at risk in accessing malicious and dangerous content  and devalues twitters
services and the overall online social network  in a      study of twitter demographics by pear
analytics  spam profiles made up about    of all twitter profiles      up to date  twitter does
not have an effective way of addressing its spammer problem  which has long been an issue  it
currently allows two options for users to deal with spammers themselves 
   users can report spammers to the  spam profile  but many of the profiles reported are
normal users  and it usually takes a few days before the actual spammer profiles are
identified and deleted 
   users can submit an online help ticket  which again  can take up to a few days before it
is addressed 

in this paper  we will discuss how we approached the problem of detecting spammer profiles on
twitter  how we collected training data  and how we implemented a supervised learning
algorithm aimed at classifying spammer profiles and normal user profiles 

   problem statement
the goal of this project was to implement a supervised learning algorithm that would be able to
label a twitter profile as a spammer or normal user  after being trained on an initial training set
of spammer profiles and normal user profiles  the first step was identifying an initial set of
 

fifeatures that could be used by the learning algorithm to distinguish between spammer profiles
and normal user profiles  then we needed to collect a large enough set of profiles to accurately
train the algorithm  this step was time consuming since our research had concluded that there are
no publicly available sets of labeled  as spammer or normal user  twitter profile data  we
planned on collecting and manually labeling our own set of data using the twitter api  as
discussed in section    training data collection  we implemented a nave bayes algorithm
first  as it is simple and a good initial test of how well a learning algorithm could do in
identifying spammer profiles  finally  after some error and data analysis  we used a more
sophisticated algorithm  the support vector machine  svm   to further improve our model 

   feature selection
when choosing features to distinguish between spammer profiles and normal user profiles  we
first took into account the different types of spammer profiles 


duplicate tweeters  tweet the same post multiple times



promoters  link to other businesses  surveys  etc 



phishers  pose as a normal user to acquire private user data



fake users  pose as a normal user  with non spam tweets   but tweeting spam content
periodically

from these types of spammers  we identified the following key features to be good distinguishers
between spammer and normal user profiles 
 followers to following ratio  spammers are expected to follow a large number of
people  but have few followers themselves  this number is expected to be low       for
spammers 
 number of tweets to account lifetime ratio  spammers are expected to have short
account lifetimes  but a large amount of tweets  this number is expected to be high for
spammers 
 average time between posts  spammers are expected to have more posts than normal
users on average  over a period of the same time  this number is expected to be low for
spammers 
 posting time variation  spammers are expected to post at predictable  scheduled times 
this number is expected to be low for spammers 
 

fi max idle hours  spammers are not expected to be idle for long periods of time  this
number is expected to be low for spammers 
 link fraction  spammers are expected to post links in a majority of their tweets  this
number is expected to be high for spammers 

   training data collection
we used two different techniques to collect spammer profiles and normal user profiles for our
training set  to collect  likely  normal user profiles  we polled twitter s public timeline through
the twitter api and gathered user profiles one by one  the user data was represented in
javascript object notation  json  and a second api call was made to additionally include up to
    tweets from each user  this data was subsequently written out of disk in compressed gzip
format and a human readable html file of the user profile was pulled directly from twitter s
servers 

for the  likely  spammer profiles  we polled for mentions of   spam  and extracted any
username of the form   username  within mentions of   spam   we then pulled the profile of
all such usernames exactly as we did before with the  likely  normal user profiles  essentially 
we captured profiles that were reported to   spam  for spamming  assuming that most of the
reported profiles had a high probability of being a spammer 

we then took this raw dataset and manually labeled each profile as being a  spammer  or  nonspammer  based on the html user profile  foreign language profiles were discarded as there
was no way for us to ascertain whether or not they were spam 

post labeling  the json format of the data files were then read and compiled into two separate
matrices in comma separated value  csv  format corresponding to spammers and normal
users  features were extracted from the data and inserted in the csv files  with the usernames
representing the rows of each matrix and each feature representing a column of each matrix 

these two csv files composed the training set of feature input data for our learning algorithms 

 

fiwe used     of our collected data to train our algorithms and saved     of the data to test
them  all code for the profile extractor and feature matrix compiler was written in python 

   learning algorithm implementation
we first tried to implement a nave bayes learning algorithm in matlab to classify the
collected twitter profiles  using a total of     normal user profiles and     spammer profiles
yielded an error rate of about      this error was higher than our goal of achieving an error rate
of less than     
we then implemented a linear classifier svm using national taiwan universitys machine
learning groups liblinear      using the default dual l  regularized l  loss support
vector classification solver  cost value  c  of    and no bias  we obtained an error rate of    
using the svm 

the unusually high error of the initial run of the svm compared to nave bayes suggested that
there was an issue with the implementation of the svm  after some investigation  we identified
the problems to be a lack of data scaling and inaccurate calibration of svm parameters  c and
gamma   we also decided to try some non linear kernels for better classification using chihchung chang and chih jen lins libsvm library     
in our final svm implementation  we normalized the entire feature dataset  used libsvms
default radial basis function  rbf  kernel  and performed   fold cross validation on the
training set to determine the optimal svm parameters c and gamma  c         gamma  
           cv rate            

   results
our final results from the improved svm classification are as follows 
       precision  percentage of profiles classified as spammers that were true spammers
       recall  percentage of true spammers classified as spammers
       accuracy        error   percentage of all correctly classified profiles

 

fi   conclusion
the high precision and recall suggests that using this particular svm for detecting spammer
profiles could be usable in practice  most of the work  however  lies in feature engineering  we
were not able to pursue highly technical features  e g  cohesiveness of social graph  and those
that would require a lot of time to develop  e g  semantic analysis of tweets   it is very likely that
precision and recall can be improved to at least     if the full power of twitters database is
leveraged to create features that can strongly distinguish between spammers and normal users 
and to use as a more cohesive training set 

this learning algorithm would be very useful if deployed internally to flag profiles as likely
spam before being forwarded to a human for further review  however  we would caution against
aggressive deployment of this system  where for example  the result from the algorithm is used
to automatically disable profiles for review  such an aggressive deployment should only be
considered if precision can be raised above      due to the risk of accidentally disabling a
normal users profile 

references
   

twitter study  available  http   www pearanalytics com blog wpcontent uploads         twitter study august      pdf  accessed  october          

   

r  e  fan  k  w  chang  c  j  hsieh  x  r  wang  and c  j  lin 
liblinear  a library for large linear classification  journal of
machine learning research                     software available at
http   www csie ntu edu tw  cjlin liblinear

   

chih chung chang and chih jen lin  libsvm   a library for support vector
machines        software available at http   www csie ntu edu tw  cjlin libsvm

 

fi