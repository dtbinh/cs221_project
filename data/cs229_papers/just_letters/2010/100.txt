classifying parts of songs
nick colonnese
december        

 

problem statement

audio visualizers are programs that take in music and produce images that
correspond to the music in some pleasing way  in most songs there are
several different parts  the verse  chorus  a solo  and so on  ideally  a music
visualizer would change its output to match the different parts of the song 
while it is quite easy for humans to detect the difference between different
parts of songs the task is not straightforward for computers  this project
aims to use machine learning techniques to find if different parts of a song
can be classified  the goal would be that before a song is played it could
be processed by the algorithm and the transitions times from one part of a
song to the next could be detected with the visualizer changing its display
accordingly  a similar problem is approached using a different method in     

 

data collection

to get the music data into a form that is workable songs are converted from
mp  into wav format and then loaded into matlab  the songs are converted
from mp s to wav format with free online software such as mp  converter
simple  the songs are converted to mono  so only one channel is considered 
once the data is in wav format it can be loaded into matlab at a specific
sample rate  this is done using the built in function wavread  the data
representing a song takes the form of a long vector 

 

fi 

approach

to classify different parts of a song the following approach was taken 
   sample from the song every couple of seconds the region around the
sample time 
   extract features from the samples containing information about which
part of the song the sample was taken 
   create points in which an element of a point is a feature 
   run k means clustering on the points to find clusters for various
values of k  these clusters represent different parts of the song 
   choose the value of k corresponding to the minimum of an objective
function which attempts to discover the true value of k which should
correspond to the number of parts in the song 
   given a sample from a song and an estimate for the number of different
parts of a song classify the sample by determining which cluster it is
closest to 

   

feature selection

for ease of implementation as well as visualization only two features were
used  first  five second regions were sampled throughout the length of the
song  this is displayed in figure   

figure    sampling throughout the length of song
 

fithen  for each sample the spectral content was estimated and then smoothed 
this was done with the pseduospectrum function in matlab  the first feature was the frequency at which there was the highest spectral content  the
second feature was the standard deviation of the spectrum a fixed amount
around the maximum  a similar method for gathering features is in      the
feature selection method is displayed in figure   

figure    feature extraction

   

choosing the number of clusters

to use k means clustering to classify different parts of a song the number of
clusters k is required  different options were explored to deal with this  one
quick and dirty method was to try to find k by finding a balance between the
number of clusters and the average variance of the clusters  this was done
by setting k equal to the arg min of the following function 
pk

arg min 
k

i

var clusteri  
  c  k 
k

where var represents the variance and c is a set constant  this method
did not work usually because it is extremely dependent on the constant c  a
better solution was seen in     in which many clusters are tried and their fit is
judged with bayesian information scoring  but is complex  for this research
k was set by hand  more is said on this choice in the conclusion 

 

fi 

results

the algorithm was tested on several songs  the classification error was in
the range of       percent for real songs  figure   contains scatter plots of
the features found by the algorithm for two songs  the colors correspond to
different parts of the song  the x axis of the points corresponds to the the
frequency with the highest spectral content  while the the y axis corresponds
to the standard deviation 
the plot on the left is of a test song that consists of only three distinct parts 
but these parts are interchanged and repeated many times  the plot of the
right is of a real song called  s and  s by queens of the stone age 

figure    test song  left  and  s and  s  right  scatter plot of features
the scatter plot of the features for the test song  left  are separated fairly
well into clusters  circles representing the centroids locations are shown with
circles  however  for the real song  right  the data does note separate as well 
the scatter plot on the right for  s and  s was typical of other real songs
put through the algorithm  some parts of the song could be classified well  but
other parts were usually too similar to be differentiated using this method 

 

fi 

conclusion and future work

this algorithm works to a certain degree  but could be improved greatly if instead it was recast using em instead of k means clustering  it would be more
appropriate because em would allow for probabilities of a certain sample 
not hard classifications like k means  it would also allow for non circular
boundaries  and perhaps most importantly would obviate the need to find
the k in k means 
in terms of the audio visualizer application this algorithm sometimes still
works well  the algorithm classifies different sounding samples of songs well 
which may be more appropriate for knowing when to change an audio visualizer than classic parts of song classification  also  time was not a feature 
and if time was included the algorithm could probably do much better in this
respect 
the algorithm was developed in matlab  for a real time application the
algorithm would need to be ported to c or similar language 

references
    andrew moore dan pelleg  x means  extending k means with efficient
estimation of the number of clusters  in proceedings of the seventeenth
international conference on machine learning  pages         san francisco        morgan kaufmann 
    kiran murthy eleanor crane  sarah houts  musical hit detection  cs
    final project       
    greg sell song hui chon  gauthum mysore  musical instrument detection  center for computer research in music and acoustics       

 

fi