classification of road images for lane detection
mingyu kim

insun jang

eunmo yang

minkyu   stanford edu

insunj stanford edu

eyang   stanford edu

   introduction
in the research on autonomous car  it is important to
extract as much information about the road as possible
from various sensors on the car  especially  it is extremely
helpful to know the relative position of traffic lanes and
the car  so that the car can be driven properly on a
legitimate lane and not on the opposite lanes or bike lanes 
stanford autonomous car group has collected laser map
data and preprocessed them to produce road images in the
birds eye view  they have manually labeled lanes on the
raw image files and we developed a system to recognize
the position of lane lines using support vector machine to
make the labeling faster  because laser beams are not
affected by changes in sunlight and shade  we can
circumvent such problems of noise from light sources 
the overall task can be divided into two phases  pixelwise classification and post processing  first  we learned
support vector machine that classifies each pixel into
whether or not it is on a lane line  after that  postprocessing steps are done to filter outliers and to come up
with a cleaner output format 

image file and no other high level information is provided 
we have manually labeled the pixels into lanes and nonlanes by drawing three pixel thick lines on top of the lanes

figure   sample road image
using image editing tools  we have been conservative in
labeling lanes  if it was ambiguous to the human eye
whether the given portion of the image is a lane or not 
such parts were not labeled as lanes  bike lanes were
included as well as lanes  an example of labeling is shown
in figure    intuitively  the black pixels represent the lanes
and the white pixels represent the non lanes 

the following sections will describe what feature
representation we have used for classification and
experimental results of the classification  and will explain
what post processing steps we used 

   datasets
a sample of the preprocessed road images is shown in
figure   as briefly mentioned in the introduction  the
images are preprocessed from laser map data which was
collected from the panoramic laser on top of the research
car of the stanford autonomous car group 
images are processed to be in the size of     by     pixel
and each pixel represents the intensity of laser beam
reflected off of the corresponding surface  because lane
lines tend to give stronger reflections to laser beams than
the road surface does  we could identify lane lines from
the laser image by the intensity value 
since only the intensity value of a pixel is given in the raw

figure   sample road lane labeling

next section describes how we extracted examples for
classification from the laser images and the labeling 

   feature representation
we followed the following steps to create examples from
the laser map images 

acknowledgement
this work has been possible with advice from quoc le  mike sokolsky  jesse levinson and jiquan ngiam  and data from stanford
autonomous car group 

fi   canny edge detection
   max neighbor processing
   rotation alignment and averaging intensity value

    canny edge detection
because an edge is a great indicator of a lane line  we
performed canny edge detection on the original laser map
images  the sample result is shown on figure    shankar
sastrys matlab implementation of canny edge detection    
was used 

   crop    by    

   rotate

   take the middle    by   

figure   overview of feature formation

    rotation alignment and averaging intensity
value
we decided to use    by    pixels surrounding each pixel
to form an example  we started with a larger area  i e    
by    pixel surrounding each pixel  so that rotation
doesnt affect the middle    by    pixels of the box  the
following explains the steps to form an example for one
pixel 
   crop out the surrounding    by    pixel box from
both the original intensity map and the maxneighbor processed canny edge image  call them
and respectively 
   compute the rotation angle of the box by
averaging the gradient values from canny edge
detection of the middle   by   points 
   rotate and by the rotation angle computed at
the step   so that the edge is aligned vertically 
call the rotated images
and
respectively 
   crop out the middle    by    box from
and
  by using sliding window of size   by   over
without overlaps and averaging each window 
get the average intensity matrix
of size
   by    
   concatenate
and
to generate a feature
representation of      dimension 
cropping the middle    by    pixel is done because we
are only interested in the middle part where the edge lies 
also  averaging the intensity values is done because
intensity values do not have as much of information as the
edge points and averaging them will make it more robust
to noise 
the following section will describe the classification
results using the feature representation described above 

figure   output of canny edge detection

    max neighbor processing
after canny edge detection  there were lots of edges on
non road portion of the image  which could be interpreted
as lanes  to solve noise issues within the image  the image
was processed such that each pixel value was reassigned
to be maximum intensity value of its neighbors  in other
words  we treated a pixel as an edge point if itself or any
of its   immediate neighbors was determined to be an edge
point by canny edge detection  non road areas were then
shown to be a clump of edge points and lanes were shown
as a clearer line  which made it easier to separate out edges
in non road areas from true edges 

   classification experiments and results
    balancing positive and negative examples
because our dataset is highly biased with only    of the
examples being positive  we had to adjust the weight of
svm on each of the labels  following the general
approach  we set the weight of negative examples to   and
the weight of positive examples to the ratio of the number
of negative examples to that of positive examples 
however  this approach over penalized misclassifying
positive example to produce a great number of false
positives  because our ultimate goal is to find where the
lane lines are  not to perfectly classify all the positive
examples  high precision is preferred over high recall 
thus  we decided to penalize less on false positives by
multiplying a scalar to the previous weight  decreasing the

fiweight on positive examples definitely helped increasing
precision and the result is shown on figure   
by plotting the results  we have concluded that the weight
factor     has a good balance of precision and recall so
that it removes a good number of false positives without
missing too many positive examples  the plots of the
results are shown on figure   
   
   
   
   
   
   
   
   
   
 

    choosing classification method
the classification library we worked with  liblinear
     offered various options to classifying  so we have tried
both svm  with no kernels  and linear regression  the
plots of the results are shown on figure    generally  svm
had better precision and linear regression showed better
recall  as stated above  we put our preference in high
precision over high recall  so svm was chosen over linear
regression  in sum  we ran the classification with linear
svm with l  regularization  and used weight factor    
for all the ensuing results 
 
   
   
   

 

   

   
   
weight factor s
precision
recall

   

 

figure   precision and recall with various values of
weight factor

precision svm
recall svm
precision lr
recall lr

   
 
    

     

     
box size

     

     

figure   precision and recall by svm and logistic
regression

    choosing box size
originally we experimented with a box size of    by    
the choice was arbitrary and quite small for fast
prototyping  we strived for an optimal box size  and we
tried to maintain the elongated rectangle box structure  we
have tried five sizes  each one approximately double the
previous one     by       by        by        by     and
   by     the results are shown on figure    box sizes
smaller than    by   would have done poorly and box
sizes larger than    by    was computationally impractical
since each feature matrix would have been larger than
 gb  although box size    by    had better precision  it
started showing decrease in recall  and we thought overfitting had occurred  so for the following results  we have
used a box size of    by    

figure   plots of classification results and ground truth
of test image

fi   
   
   
precision
recall

   
 
    

     

     
box size

     

     
figure    sample output from pixel wise classification

figure   precision and recall with different box sizes

   post processing
pixel wise classification result contains fair number of
false positives  and we developed the following postprocessing steps to filter out false positives and to output
cleaner lane lines 

   
   
   
precision
   

recall

 
 

 
 
 
number of training images

 

figure   precision and recall with different number of
training images

    choosing training size
for the experiment whose data is plotted in figure    we
have tested on   images and tested on    because we only
identified pixels as feature points if and only if it had an
edge point in its immediate neighborhood  each image had
nearly         feature points  and we thought   was a
large enough number  after prototyping  we tried testing
out different training set sizes  the results are displayed in
figure    with five training images  we start to see
decrease in both precision and recall  so we assumed that
over fitting started to take effect  therefore we chose the
training set of   images as our optimum 

to summarize  we used linear svm with l 
normalization as the classification method  chose       as
the box size and trained   images  the sample output is
shown in figure     pixel value is the probability to be on
the lane line if positively classified  and   otherwise 

  
  
  
  

direction estimation
non maximum suppression
clustering
cluster discretization

    direction estimation
we first estimated the direction of the lane lines for each
of the positively classified pixels by linear regression  for
each pixel  we used    by   surrounding box to run linear
regression without intercept terms     by    box is small
enough to assume lane lines are straight in the box  we
replaced the pixel value with the sum of probabilities of all
positively classified pixels within   pixels from the
learned line  pixels with the sum of probabilities value
less than     of the maximum sum of probabilities value 
because such pixels are likely to be false positives 

    non maximum suppression
as can be seen from figure    detected lane lines are more
than one pixels wide and non maximum suppression is
performed to attain cleaner outputs with each lane line at
most   pixel wide  this is the same step as the one in the
canny edge detection algorithm with normal vector to the
estimated slope from     as the direction of gradient and
the sum of probabilities value as the norm of gradient 
this step suppressed all the pixels except for the one pixel
wide lane lines 

    clustering
for better applicability  we clustered the lane line points
from      we clustered two points into the same cluster if
they are less than    pixel apart and the angle between the
two corresponding slopes are smaller than    degrees 
this step allowed us to differentiate separate lane lines

fiand to drop out more false positives by ignoring clusters
with less than    pixels 


    cluster discretization
for better applicability  it is important to output lanes by
clear lines rather than clumped lines of pixels  for each
cluster of pixels  we selected starting and ending pixel and
in between pixels that are separated by certain distance 
then  we output each cluster  which corresponds to one
lane line  as a sequence of several points so that the clear
lane line can be reconstructed by just connecting the
points in order 

   final results
after post processing steps  each lane is represented as a
sequence of points and it can be reconstructed by
connecting the points in order  the sample lane line
detection results are shown below 



knowledge to improve the performance of postprocessing steps 
better roadmap image  there is room for
improvement in the pre processing steps of laser
roadmap image  higher quality input images
from better calibration and pre processing steps
will definitely help improving the performance 
lane classification  the lane we identified
doesnt tell much about their functions  for
example  we treat output lines all equally  such as
boundaries between roads and non roads  centre
lines  dotted lines  or cross roads  it will be more
useful if we differentiate preprocessing procedure
of the raw image by lane functionalities and run
our lane detection algorithm on each to detect
each lanes  for example  for boundaries we will
focus on preprocessing to discriminate from nonroad white  region to road black  region in the
image  after detecting boundaries of roads  we
can detect centre lines by focusing on the road
region only  we can detect crossroads or stop
lines by focusing on intersections 

   references
     canny edge detector algorithm matlab codes   uc
berkeley robotics and intelligent machines lab home
page  web     nov       
 http   robotics eecs berkeley edu  sastry ee   cacode html
  
    canny  j   a computational approach to edge detection 
ieee trans  pattern analysis and machine intelligence 
                 
    r  e  fan  k  w  chang  c  j  hsieh  x  r  wang  and c  j 
lin  liblinear  a library for large linear classification
journal of machine learning research                    

figure    sample results

   discussion
as can be seen from figure     we successfully found
some of the lane lines but there is room for further
improvement 


better post processing steps  we see that output
lanes are sometimes disconnected or there are
undetected portion of lines  in this work  we
havent utilized the fact that lane lines are
approximately parallel to each other and lane
lines usually form a long straight line  we can
possibly taking into account of such higher level

fi