janitor bot   detecting light switches
jiaqi guo  haizi yu
december         
   introduction
the demand for janitorial robots has gone up with the rising affluence and increasingly busy lifestyles of
people      both in offices and personal homes  all too often people forget to switch off lights  close
doors  throw away garbage and so on  this is where a janitorial robot would come in handy  this kind of
robot must have the necessary characteristics of being able to autonomously navigate through its
surroundings  and also detect and recognize objects of interest for its assigned tasks  in this project  we
focus on the latter problem for the specific case of turning off lights  the robot needs to know where the
light switch is in order to turn the lights off  so the visual system must be able to precisely detect the  d
location of the light switch on the wall 
in computer vision  there have been numerous object detection methods        that involve extracting
haar features and forming integral images from the original images  before passing them to a classifier
that is trained using various machine learning algorithms  these have achieved high accuracy and low
false positive rates for the detection of faces  as well as other objects  but necessary modifications are
required for detecting objects related to janitorial tasks due to the difference in characteristics that we
could make use of to improve the efficiency of detection        we aim to design an algorithm that
detects a light switch as efficiently as possible 
switches come in all kinds of sizes  and the range of lighting conditions  the fluctuation in angles that the
image of the switch was taken from  and the decoration on walls as well as switches make the learning
problem difficult  but a common characteristic is the rectangular switch plate shape  which we will
exploit in tandem with a classifier  as described in this paper  for the purposes of this project  we are
assuming that the robot is able to look at the wall from a one yard distance  at a height range of roughly
half a meter above and below the normal height of a light switch 
   data collection and preparation
the training examples for machine learning were obtained by taking photographs of interior walls in
various buildings around campus  at a distance of roughly a yard away from the wall and a height range
of roughly   meter around the normal height of a light switch  since the robot will also be viewing the
wall at this distance and height  they were taken directly facing to the wall or at a slight angle from the
perpendicular  these full photographs were resized to    x    pixels  which is the resolution of the
image that the robot would see 
light switch plates usually have a height width ratio of        so we chose our positive training examples
to be    x    pixel images cropped from the resized full photographs  with individual switches roughly
occupying    x   pixels and parts of double or triple switches occupying    x   or    x    pixels  see
figure  a   negative training examples were    x    pixel images of objects  parts of objects  or wall
surfaces located at roughly the same height as a light switch  see figure  b   these are considerably
abundant compared to the positive examples  an image that contains part of a switch is considered a
negative example 
 a 

 b 

figure    a    b   instances of positive and negative training examples respectively  note that in  a   half of a double
switch  third example  is taken as a training example 

fithe images were passed through a selective gaussian filter to remove some noise  and used to train the
classifier as grayscale images  we chose to use grayscale images to reduce the number of raw features
that we are starting with  as color information might cause unnecessary overfitting 
after training the classifier and testing on a full image of a wall  not used for creating the original
training set   some of the false positives detected were placed in the training set to retrain the classifier
to increase its accuracy  still  due to the lack of a sufficiently large image database for training the
classifier as of yet  we designed our detection algorithm to reduce the chances of the svm detecting
false positives by making use of the common characteristics of light switches 
   method
    testing training algorithms
we first trained both an artificial neural networks  ann  classifier and a support vector machine  svm 
classifier using       raw pixel values as features  we then trained these two classifiers by performing
pca on the pixel values of the cropped images  looping through the number of principal components
retained to find the optimum number to keep that would give us the lowest error rates  the error rates
 see table    suggested that we should use pca with    components kept as features  and svm as a
classifier for the detection of the switch in the full image 
training error
test error

raw  ann
  
   

raw  svm
  
   

pca  ann
  
  

pca  svm
  
  

table   error rates for each classifier  raw   raw pixel features used  pca   pca with    components kept as
features  ann   ann classifier used  svm   svm classifier used 

these errors are given for the original training set that we started out with  without adding the false
positives that were added later from our experiments 
    sliding window
to detect the  d location of a switch  we implemented a    x    pixel sliding window that moves over
the whole image in a zig zag pattern and determines if the area that it bounds contains a switch using
the detection algorithm described in the next section  to improve the efficiency of the search  the
movement of the sliding window is sped up if certain conditions are met  as described later  the sliding
window was also used to capture false positive images for retraining the classifier 
    detection algorithm
raw features
edge
detection
   wall
elimination

   asymmetry
detection

pca

   non frame
detection

   svm
classifier

positive

negative
figure   flowchart for detection algorithm  stages     consitute preprocess detection  which throw out obvious
negative image patches based on whether they have the common characteristics a switch has  image patches
surviving these stages are then sent to the classifier to be identified as a switch or not 

in preprocess detection  stages       we extract edge features from using the canny edge extraction
algorithm  to generate a boolean valued image  called edge image   and perform various computations
to sift out obvious negative examples such as walls and areas with absolutely no switch like

ficharacteristics  before we pass it into an svm classifier  stage     this reduces the possibility of the
classifier identifying false positives 
although we are using edge features in all of the first three stages  the features extracted are different
in each  as we tuned the sensitivities for edge detection for each stage differently to filter out the right
amount of noise and getting the edge features that are useful for each different stage  the sensitivities
were chosen as fixed values based on similar computations with examples from the training set  and
optimized as best as possible toward the goal of each stage 
      stage    wall elimination
the majority of non switch areas appearing in a natural scene are simple wall or wall like areas with
negligibly few features of high frequency  such an area would have a very small variation in luminance 
thus its edge image should have a very small number of ones  we set a threshold for the sum of ones in
a    x    pixel image  below which we classify the image as a non switch  or an area with too few
features to be a switch 
      stage    obvious asymmetry detection
light switches are usually situated in the center of a rectangular switch plate  so an individual light
switch centered properly forms an image of high symmetry  upon running some tests  we found that a
switch that is part of double or triple switches is still more symmetric than a large quantity of image
patches that the sliding window will encounter  which contain incomplete parts of a certain object
 including parts of the switches   image patches like these that are clearly non symmetric are what we
aim to remove from the full image using this asymmetry detector proposed here  we can compute the
total number of ones in the upper and lower halves  and left and right halves of the edge image  and
represent the symmetry of the image by the variance of these four numbers  we then eliminated the
images with a variance above a threshold chosen to keep image patches of individual light switches or
parts of multiple switches 
      stage    obvious non frame detection
we also note that a complete light switch would have a perfect or near perfect rectangular frame in the
edge image  which non switch areas would not have  parts of multiple switches also have more of a
frame than most non switch areas  we represent the probability that the image patch has a frame by
the sum of the number of ones in a margin around the sides of the edge image  and then eliminate the
areas which have a probability lower than a threshold chosen to retain switches based on values
computed from our training set  we chose the size of the margin such that the inner edge of the margin
always lies within the switch plate of an individual switch  images of objects that have frames or partial
frames in such area should exhibit large probabilities  this detector could eliminate a switch with a
frame that is smaller than the inner edge of the border  but rescaling the image and repeating the
search procedure over the larger image can easily solve this problem 
      stage    supervised learning via an svm classifier
in our experiments  we trained the svm with a linear kernel beforehand and load the support vectors to
make a prediction on whether the image patch contained in the sliding window that had survived the
previous three stages is indeed a switch  the svm was trained using parameters that were automatically
optimized for the training set in the training process  such that the k fold cross validation estimate of
the test set error is minimized 
    sliding window shifting strategy
in order to speed up the detection procedure  since it would be unfeasible to have a robot stand in front
of a wall taking five minutes to make a decision on where the switch is  we slightly modified the normal
sliding window movement that just shifts horizontally or vertically by a fixed distance each time  if the
image captured by the sliding window is determined to be a wall in stage    or to be a switch in stage   
the sliding window will shift to its right by half of the sliding window width  i e     pixels in our
experiments 

fi   results and discussion
we tested our algorithm on various images obtained from the interior of buildings  our proposed  stage detector eliminates most of the non switch areas on the full image so that the image patches that
are passed to the classifier  stage    have a higher probability of being switches  see figure    
 a 

 b 

 c 

 d 

figure   the white rectangles shown in this figure are bounding boxes for the positive image patches that are
allowed through a stage of the detection algorithm   a  positive image patches allowed through the wall
elimination stage  b  image patches allowed through the symmetry detector stage  c  image patches allowed
through the frame detection stage  d  image patches detected as switches by the final classifier

the number of image patches that survive each detection stage depends on the objects in the image 
but for a wall like the one shown above  the image patches remaining after each stage are            
   and     or                and      of the original number of image patches respectively  the
percentage improvement is the most obvious in the frame detection stage  establishing the importance
of the rectangular frame characteristic for identifying a switch  the latter two characteristics could also
be used as features to train the classifier  which would eliminate the problem of having to manually set
the sensitivities and thresholds for each detection stage  an alternative solution would be to use k fold
cross validation errors to tune the sensitivities 
full detection runs on other images managed to identify most of the switches  both individual switches 
and switches that are part of a double or triple switch  on a test set of    full images containing at least
one individual switch  our precision rate was      and recall rate was        the switches that were not
detected were part of a multiple switch  and were not as clean because of extensive reflections  or
had only two edges in the sliding window and additional noise from objects attached to the switch plate
 see figure     further pre filtering of the training and test images to remove more noise and reflections
than a gaussian filter can  and to adjust for lighting would probably improve our results 

fi a 

 b 

 d 

 c 

 e 

 f 

figure   some results of detection on full images  the white boxes show image patches that were detected as
switches   d  the switch in the middle was not detected because of the complicated barcode on top   f  the switch
on the left was not detected as it could not pass the asymmetry detection stage due to extensive reflections 

   conclusion and future work
through our experiments  we conclude that feature extraction is crucial for increasing precision for light
switch detection  our detection algorithm detects most switches accurately  but by including other
features such as haar features  the symmetry of the image patch  and the probability that the image
patch contains a frame  our results could improve further  not all training examples have the same
importance in training too  so we could consider using weighted training examples to improve the
accuracy of the svm classifier 
in addition  to take into account the possibility of non linear separation between switches and nonswitches  we could use a non linear kernel for svm classifier  while svm is a powerful learning
algorithm by itself  we could improve the performance of the detector by combining different learning
algorithms using boosting 
   acknowledgements
we would like to thank ellen klingbeil for her patient guidance throughout the course of the project  and
professor andrew ng and the tas for teaching us machine learning concepts 
   references
    y mae et al  proposal of a wheelchair user support system using humanoid robots to create an ssr
society        
    p viola and m  jones  rapid object detection using a boosted cascade of simple features 
conference on computer vision and pattern recognition       
    r  lienhart and j  maydt  an extended set of haar like features for rapid object detection  ieee icip
      
    e  klingbeil  a  saxena  a  ng  learning to open new doors  rss workshop on robot manipulation
      
    e  klingbeil  b  carpenter  o  russakovsky  a  ng  autonomous operation of novel elevators for
robot navigation  icra       

fi