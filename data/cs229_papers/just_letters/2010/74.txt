emotion recognition with deep belief
networks
tom mclaughlin  mai le  naran bayanbat
introduction
for our cs    project  we studied the problem of
reliable computerized emotion recognition in images of
human faces  first  we performed a preliminary
exploration using svm classifiers  and then developed an
approach based on deep belief nets  deep belief nets  or
dbns  are probabilistic generative models composed of
multiple layers of stochastic latent variables  where each
building block layer is a restricted boltzmann machine
 rbm   dbns have a greedy layer wise unsupervised
learning algorithm as well as a discriminative fine tuning
procedure for optimizing performance on classification
tasks      
we trained our classifier on three databases  the
cohn kanade extended database  ck        the japanese
female facial expression database  jaffe       and the
yale face database  yale       we tested several
different database configurations  image pre processing
settings  and dbn parameters  and obtained test errors as
low as     on a limited subset of the emotion labels 
finally  we created a real time system which takes
images of a single subject using a computer webcam and
classifies the emotion shown by the subject 

facial emotion into a set of action units  aus   which
describe the specific muscle groups involved in forming
the emotion  we chose not to use facs because accurate
labeling currently requires trained human experts      and
we are interesting in creating an automated system 
part     features
part       norm of differences between neutral face
and full emotion
each of the ck  images has been hand labeled with
   standard active appearance models  aam  face
landmarks that describe the x and y position of these
landmarks on the image  figure    

figure    aam facial landmarks
we initially trained the svm on the norm of the
vector differences in landmark positions between the
neutral and peak expressions  with this approach  the
training error was approximately     for hold out cross
validation  see figure    

part    exploration of svm based approaches
to set a baseline for comparison  we applied an
svm classifier to the emotion images in the ck 
database  using the liblinear library and its matlab
interface      this database contains     image sequences
across     human subjects  beginning with a neutral
expression and showing the progression to one of seven
peak emotions  when given both a neutral and an
expressive face to compare  the svm obtained accuracy
as high as      this section summarizes the
implementation of the svm classifier  for additional
details on this stage of the project  please see our
milestone document 
part     choice of labels  emotion numbers vs  facs
features 
the ck  database offers two sets of emotion
features  emotion numbers and facs features  emotion
numbers are integer values representing the main emotion
shown in the peak emotion image  the emotions are
coded as follows    anger    contempt    disgust 
  fear    happiness    sadness  and   surprise 
the other labeling option is called facs  or the
facial action coding system  facs decomposes every

figure    accuracy of
svm
with
normdisplacement features 

figure    accuracy of
svm with separate x  y
displacement features 

part       separate x and y differences between
neutral face and full emotion
because the initial approach did not differentiate
between displacements of landmarks in different
directions  we also provided the differences in the x and
y components of each landmark separately  this doubled
the size of our feature vector  and resulting in a significant
 about      improvement in accuracy  figure    
part       feature selection
finally  we visualized which features were the most
important for classifying each emotion  the results can be
seen in figure    the figure shows the x and y

fidisplacements for each emotion compared to the average
values over all emotions  with average features colored in
green and both extremes colored red and blue 
respectively  one interesting result is that the y features
are in general more importantthere are fewer side toside motions of facial features during the formation of
expressions  also  surprise showed by far the most
extreme displacements for many features  this exercise
helped us understand which aspects of our images contain
the most information about emotion  and so was valuable
for designing our approach to the dbn 

part     face detection and image preprocessing
we used opencvs haar feature detection
algorithms to create an image preprocessing program to
prepare the images in our databases  there are   key steps
in the processing chain     identify and crop a face in the
image     identify the eyes  and use their location to
letterbox the left and right sides of the face  and   
perform histogram equalization  the letterboxing serves
to hide areas of the image that dont correlate with
emotion  such as the ears and hair  equalization serves to
sparsify the image matrix and emphasize the features of
interest  as well as ensure that all our input data has the
same contrast 

figure    visualization of relative feature importance 
part       limitations of aam landmarks
figure    image pre processing steps
while the svm trained on aam facial landmark
provided promising results  it has a fatal flaw  there is not
yet an accurate  automated method for identifying the
landmarks on a human face  because we want to make a
fully automated emotion classifier  we had to abandon
aam landmarks  fortunately  dbns can be trained on
raw images  and actually performed better with these
inputs than if they were given the aam features  
part    deep belief nets
dbns are probabilistic generative models composed
of hidden stochastic variables and are similar in structure
to neural nets  however  unlike other neural nets  dbns
perform learning one layer at a time  computing
generative weight matrices that define connections
between the nodes of every two adjacent layers  once the
weighted matrices are calculated  the hidden variables at
each layer can be inferred from the visible input by
reversing the matrices 
our dbn implementation is based upon a
modification of geoff hintons code for classifying the
mnist handwritten digit database      the two problems
are actually very similar  since both involve training a
dbn on a raw image and sorting the training examples
into      classes  we hoped that  as in the digit
recognition case  the dbn algorithms ability to identify
complex patterns in the input would yield high accuracy
in our classification task 
this section describes the steps we took in setting up
and configuring our dbn based system  and concludes
with test results 

as it turned out  equalizing the data was extremely
important  but the letterboxing technique actually
degraded performance  see results  
an important image preprocessing question is the
size to which the input images should be scaled  the
hinton paper on digit recognition used    by    pixel
inputs  however  human faces are much more complex
than handwritten digits  so higher resolution is required to
avoid losing important details  excessively high
resolution  on the other hand  would greatly increase the
running time of the algorithm and could actually degrade
accuracy  due to the decreased proportion of relevant
data in the image  with this in mind  we chose to scale
our input images to     by     pixels 
part      parameter selection
the two most important parameters of a dbn are a 
the number of layers and b  the number of hidden
variables in each layer  the default settings in the hinton
code are to use   layers  containing           and     
latent variables  with the final hidden layer variables
corresponding directly to our classes 
in general  the more layers present in the dbn  the
better performance will be  networks with insufficient
depth can require more computational elements than
architectures whose depth is well matched to the task 
because deeper networks with fewer hidden variables can
provide a simpler  more descriptive model      the
problem with deep nets is that they are often harder to
optimize  and the best performance is often determined
empirically 

fiwhile it is agreed that adding more layers to the
network will enhance performance  beyond a certain
threshold the payoff of adding more layers is no longer
worth the additional time and computing resources needed
to run the dbn  in addition to the standard   layers in the
hinton code  we also tested the dbn with   and   layers 
since human faces are much more complex than
handwritten digit images  we decided not to try decreasing
the number of layers 
there are many rules of thumb for determining the
optimal number of hidden variables per layer  in general 
the number of hidden variables required depends in a
complex way on the size of the input and output layers 
the number of training examples  the amount of noise in
the data  and other factors  increasing the number of
hidden units too much would make the network prone to
over fitting  while not enough hidden units could mean
under fitting and the network maybe unable to capture
necessary higher order features  we chose to try several
settings and determine the best performance empirically 

that equalization creates dramatic improvements in
performance  up to     less training error   see figure  
for a comparison of learning curves obtained by training
on all three databases together  with equalization both on
and off 

part      results

figure    effect of equalization on test error 

part       determining convergence over fitting

table    effect of histogram equalization and
letterboxing on test accuracy
databases
nonequalized
equalized 
included
equalized
letterboxed
ck 
    
    
    
ck   yale
    
    
    
ck   yale      
    
    
jaffe

increasing back propagation duration may result in
over fitting  when allowed to run for a sufficiently long
time  the training error decreases steadily while the test
error remains constant or increases  figure     for this
reason  it is important to be careful how about when we
terminate the back propagation phase  we initially ran our
tests for a constant     epochs  but later found that the
time at which over fitting begins is dependent on the
specific settings of the test run  in all the results reported
in this paper  we allowed each test run to proceed until
over fitting was observed  the number of testing epochs
this required was recorded  and repeated runs with the
same settings were run for the same number of epochs  in
many cases this took as many as     epochs 

on the other hand  our letterboxing technique of
isolating only the main part of the face actually degraded
performance somewhat  its possible that this is because
the parts of the face which it excluded  such as the outline
of the cheek and cheekbone  were more important than
we had thought for classification  although further study is
necessary to be sure 
part       limited emotion and training sets

figure    dbn over fitting 
part
     
testing
histogram
letterboxing  limited emotion sets

equalization 

we began with a series of tests to determine the best
way to pre process our input images  the results show

we observed both in our svm explorations and in
our early tests of dbns that certain emotions in our
databases  especially contempt and disgust  were a  very
difficult for the algorithm to tell apart  difficult for
humans as well  in some cases  and b  presented
themselves differently in different subjects  we
hypothesized that excluding one or more of these
emotions would improve our test accuracy  we trained
and tested on two different subsets of the emotion labels 
the full   emotion set  and a limited   emotion set
containing only the emotions happy  sad  surprised  and
angry 

fitable    effect of test error when training on a
limited emotion set
  emotions
  emotions
ck 
    
    
ck   yale
    
    
ck   yale 
    
    
jaffe
as expected  using the limited emotion set produced
improved results   see figure   for sample learning
curves  

converged much faster to a good solution  however  the  
and   layer configurations took a much longer time to
train  so they do have their drawbacks  for this reason  we
did not test numbers of layers greater than   
finally  we explored what happens when you vary
the number of latent variables in the model  while it is
difficult to determine what the optimal configuration is
for a given total number of hidden units  it seems clear
that increasing the number of latent variables beyond a
certain amount decreases performance significantly  this
is reasonable  because an excess of hidden variables
makes the model more prone to over fitting  figure   
shows the effect of varying the number of hidden
variables on a   layer dbn 

figure    learning curves when training on limited
emotion set 
part       varying dbn depth and number of hidden
variables
we also experimented with varying the number of
hidden layers and latent variables  figure   shows a
comparison of the learning curves for a   layer    layer 
and   layer dbns 

figure    learning curves with varied dbn depth 
adding more depth generally improved the
performance  with the   layer dbn outperforming all
other configurations  in particular  the deeper dbn

figure     learning curves with varied number of
hidden variables    layer dbn 
as might be expected  this over fitting phenomenon
was even more pronounced in a    or   layer dbn with a
large number of hidden variables  figure     

figure     effect of varying number of hidden
variables on a   layer dbn 
part   application  our real time classifier

fito conclude our project  we created a real time
demo system which enables the user to look into a
webcam  push a button  and have their picture taken and
their emotion classified  see figure      this system used
the classifier trained on the   emotion dataset  using all
three databases  when used in proper lighting conditions 
it was surprisingly accurate   even in our poorly lit area
of the cs    poster session  several volunteers had their
emotions classified correctly every time  
this system is a proof of concept  and
improvements of it could lead to applications such as
those discussed in our initial project proposal  emotionaware software  point and shoot cameras with happiness
detection  or helping train autistic individuals in
recognizing and producing emotional cues 

images  we had only     training examples  or   
examples per emotion  when using all three databases 
references
    hinton  g  e   osindero  s     teh  y  w          a
fast learning algorithm for deep belief nets  neural
computation                
    lucey  p   cohn  j f   kanade  t   saragih  j  
ambadar  z   matthews  i      the extended cohnkanade dataset  ck    a complete dataset for action unit
and emotion specified expression   computer vision and
pattern recognition workshops  cvprw        ieee
computer society conference on   vol   no   pp        
      june       doi          cvprw              
    michael j  lyons  shigeru akamatsu  miyuki
kamachi  jiro gyoba  coding facial expressions with
gabor wavelet  proceedings  third ieee international
conference on automatic face and gesturrecognition 
april             nara japan  ieee computer society 
pp          

figure     real time demo system 
part    conclusion and future directions
in conclusion  histogram equalization during the
image preprocessing step produced a clear improvement
in test accuracy  the letterboxing technique we
attempted  however  did not produce improved results 
suggesting that it may be best to give the dbn as much
data as possible and not try to guess which parts of the
image are most important 
as expected  our accuracy was best  around     
when testing on the limited set of   emotion classes 
where the more ambiguous emotions were eliminated 
 we would note that a classifier working with only these
  emotion classes covers the most common emotions  and
would still be useful for many practical applications  
increasing the number of dbn layers caused the
algorithm to perform better  in particular  it converged to
good training error much faster than dbns with smaller
layers  using more hidden variables  on the other hand 
resulted in generally worse performance due to overfitting  the effect was especially prominent when there
were both many layers and many hidden variables 
the learning curves from our data show that
combining our different databases results in the best
performance  we suspect that further performance gains
could probably be realized by increasing the size of our
training database  indeed  the mnist handwritten digit
database contains        images and        test images 
or       images  on average  for each of the    digit
classes  due to the difficulty of obtaining good emotion

    georghiades  a   belhumeur  p   kriegman  d   from
few to many  illumination cone models for face
recognition under variable lighting and pose  ieee
trans  pattern anal  mach  intelligence               
      
    r  e  fan  k  w  chang  c  j  hsieh  x  r  wang  and
c  j  lin  liblinear  a library for large linear
classification  journal of machine learning research
        
          
software
available
at
http   www csie ntu edu tw  cjlin liblinear
    s  lee  r  xiang  s  cetintas  y  fang  deep belief
nets  cs   m paper presentation  fall       department
of computer science  purdue university 
    y  lecun  l  bottou  y  bengio  and p  haffner 
 gradient based learning applied to document
recognition   proceedings of the ieee                   
november      
    michael j  lyons  shigeru akamatsu  miyuki
kamachi  jiro gyoba  coding facial expressions with
gabor wavelet  proceedings  third ieee international
conference on automatic face and gesture recognition 
april             nara japan  ieee computer society 
pp          

fi