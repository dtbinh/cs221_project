classification of handwritten digits by the set of partial linear and
quadratic models
youngsik kim
cs    final project
stanford university
youngsik stanford edu

abstract

an arc is a part of an ellipse  we can divide the feature extraction as two parts  finding a linear model for the best line
segment and a quadratic model for the best arcs or ellipses 
basically we used the locally weighted linear regression by
solving a normal equation 

there have been many algorithms to categorize a set of images  they are successful in some sense  but they usually
are vulnerable to small variations  such as rotation  translation  skewness  etc  handwritten digits also have many
variations  but we can promptly recognize what the digit
is without much effort  when we think about the moment
writing a digit  we can easily find that we are actually drawing several lines  arcs  or ellipses  in this project  we focused on the constituents of a digit  which are line segments
and ellipses  and their relative positions  this project has
two major steps  the first step is to find a set the best line
segment and ellipse models that can represent a digit using
locally weighted linear regression model  the second step
is to generate features from the set of models  and to categorize digits using existing classification methods  the result
is noticeable for several digits  but not as good as the best
performing algorithm  yet 

     linear model
any line can be written as 
ax    bx    c    

   

it is hard for a digit to have a line segment whose extension
passes the origin  which is the upper left part of an image 
lets assume that c cannot be    in order to form a normal
equation  we can rewrite the equation as below 
ax    bx    t x   y

   

where     a b t   x    x  x   t   and y        t
to minimize mse  we know the answer is 

   introduction

    x t x   x t y

when we write a digit  we dont think about pixels but the
entire topology  more specifically  we just draw lines and
ellipses or arcs  which are parts of ellipses  the main goal
of this project is to show that it is possible to categorize a
digit with the set of simple  st order or  nd order models 
we will use the locally weighted linear regression method
to find the best locally fitted linear or quadratic model  and
group the similar models together to represent them with a
small number of features  the last step will be using naive
bayesian method for the pairs of the features to emphasize
the association between features  in this project  we are going to use mnist database of handwritten digits      expected goal of this project is to get the decent error rate and
a good classifier that can tolerate lots of variations 

   

     quadratic model
general form of a quadratic curve is 
ax       bx  x    cx       dx     f x    g    

   

we can also assume that g is not zero  since there will be no
ellipse that passes the origin  then we can obtain the same
expression as equation   after defining x    x  x   t   and
    a  b c  d  f  t  
though we can get the parameter vector  from the normal
equation  it cannot be always an ellipse  in order to be a
matrix  these three conditions     have to be satisfied 
fi
fi
fi a b c fi
fi
fi
   
   fifi b c f fifi     
fi d f g fi
fi
fi
fi a b fi
fi
fi  
j  fi
   
b c fi

   feature extraction
based on the usual experience  we can assume that the constituents of a digit are line segments  arcs  and ellipses  since

 

fi
  
   
a c
when we obtain the parameter vector   we can also test
whether it is a closed ellipse or not  also  when it is open 
the direction of missing arc is also important  unless we
know it  there is no way to distinguish   from   
     weight matrix

 

 

  

  

  

  

  

  

  

  
 

now the remaining question is how we can find a set of
points which gives us the best linear or quadratic model  if
we use all the points in modeling  we may find a good model
for simple digits such as   and    but for the other complex
digits  there cannot be a model that includes all the points 
on the other hand  if we use too few points  the model may
not represent a real constituent of the digit  thus  we have
to use the locally weighted linear regression method with a
weight matrix w  

  

  

  

  

 

 

  

  

  

  

  

  

  

    x t w x   x t w y

   

  

  

  

  

 

  

  

  

  

  
 

it is clear that the model we get depends on the weight
matrix  therefore  we need to apply various weight matrices to find the best model  in order to minimze the inteference from unnecessary points  we can define a weight
matrix w as 
 
    if  x   p        x   p       r 
wx   x   
   
    otherwise

 

  

  

  

  

figure    finding best models  left column shows the remaining points  while right column represents the reconstructed digit  red crosses are for the best model found by
the iteration 
     feature representation

where  p    p    is a center  and r is a radius of a circle  we
may use the famous weight function that is similar to gaussian distribution  but the number of points that have significant effect on the model grows very fast as  increases 
this weight function is better for controlling the number of
effective points than gaussian like weight functions 
obviously  there are two variables that affects w   the
center and radius of a circle  again  to minimize the interference  the top bottom left right most points are chosen to
be the candidate for center of a circle  for example  when
we choose a random point from a digit    the points close to
both a circle and a line are not good candidiates to guess a
model  then we sweep the radius r from   to the width of a
digit image 

though we have a lot of parameter vectors   we can group
them together with several features  lines can be grouped
depending on whether they are more horizontal or vertical 
we are also able to group ellipses by their center and the
direction of the empty arc  most of the time  zeros or ones
can be represented by a single model as in figure   
however  the other numbers need at least two models 
and the relationship between models as well as the existence
of the models becomes very important  as in figure    the
existence of certain models cannot tell two models at all 
therefore  we can define a feature as a pair of two models
and their relative positions 
if there is a pair of two ellipses  their relative radii are
encoded as a feature  if an ellipse and a line segment are
a pair of models  the contact point or the closest point is
found  and the relative positions are encoded based on the
pont of contact  when we have two line segments  we can
handle them as the same manner by finding the closest point
or the contact point 
table below shows the entire set of features  total    
features are used  in this project  but one of the important
thing is that a digit can be represented by a sparse vector
since   or   models are enough to cover all the points in a

     set of best models
once we have found the best model among all centers and
radii  we can keep doing this process after removing the
points which are close to the found models  because we
are reducing the number of remaining points  this repetition finishes either by too few number of remaining points
or by absolutely bad fitting score of the best model  figure
  shows the steps of finding best models  and the reconstructed digt based on the models 

 

fi 

 

  

  

  

  

  

  

  

  
 

  

  

  

  

 

  

  

  

  

figure    simple digits such as   and   can be represented
a single model 

 

 

  

  

  

  

  

  

  
  

  

  

  

 st answer

 nd answer

 
 
 
 
 
 
 
 
 
 

     
    
     
     
    
     
     
     
     
     

    
    
     
     
    
     
     
    
     
     

avg 

     

     

table    error rate of categorization 

and ellipses representing a digit are independent from each
other if the digit is given  though we used pairs of models as features rather than the linear or quadratic models  we
still have doubt in independence of features 

  
 

digit

   evaluation
 

  

  

  

  

     dataset and test method
mnist handwritten digit dataset      which is a subset of
nist handwritten dataset  is used  it has its own training
examples and test examples  however  in this project  we
used only      images per digit in the training set  we computed error rates by taking average of    different trials     
training and     test examples were randomlly chosen for
every iteration  features are extracted in the same manner
for both training and test examples 

figure    existence of an ellipse and a line segment is the
same for   and    relative position has to be considered 
digit  average l  norm of the feature vectors is      in the
dataset we used 
   classification

     result
we used naive bayesian method with laplace smoothing 
the main reason of using naive bayesian is because we
have binary feature vectors and only positive examples for
each digit  to apply the other methods  we need many
meaningful negative examples  too  for example  to categorize digit zero  there have to be a meaningful set of examples
which are not zeros  they can be training set of other digits 
or randomly generated feature vectors  the former might
have an issue of over fitting  and the latter might generate
meaningless data that can harm the performance of classification  laplacian smooothing is also useful since the feature vectors are very sparse  and there can be features that
has never been found by training set  actually there were
    features that have never been found in the training set 
the only concern is the assumption of this method which
assumes the conditional independence between the features
given the class  of course  it is hard to say that the lines

average error rate is about      this error rate is relatively
bad when we compare it with the published result in      if a
digit is simple as   or    the error rate becomes lower  also 
we can explain the low error rate of digit   and the high error
rates of digit   and   as the difficulty of estimating quadratic
models and get a good feature from them  the good thing
about this result is that almost     of classification results
were correct with  nd guess  it shows that this algorithm at
least is heading a good direction  if we can eliminate the
interference of the incorrect first choice later  it still have a
chance to perform better 
   conclusion
in this project  weve tested a new algorithm to categorize
handwritten digits which is based on the intuition for the

 

ficonstituents of digits  it has some drawbacks  such as exhaustive search for the best models  and mediocre performance  however  if we can find the best models using parallel processing  and devise good features from them  it is
doable  on the other hand  this algorithm has two advantages over other algorithms  first  the concept of constituents
of handwritten digits also can be applied many kinds of
handwritings  such as various set of alphabets in many languages  since we usually dont think about more complex
models when we write something  second  the feature vector is relatively tolerant to the variations 
the relatively high error rates might have come from the
inappropriate method of generating features  or from the errors when finding the best models  for example  when a
stroke in a digit is too thick  it is hard to remove all the relevant points because there is a risk of deleting other points
which are important to find the next best model from the remaining points  we can try some techniques in vision area
to perfectly extract lines and ellipses  but it will be a future
work  also  using other techniques but naive bayesian for
classification would be a good direction for a future work 
   references
    http   yann lecun com exdb mnist 
    http   mathworld wolfram com ellipse html

 

fi