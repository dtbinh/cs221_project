comparison of supervised   unsupervised learning in s
estimation between stocks and the s p   
j  wei  y  hassid  j  edery  a  becker  stanford university


i  introduction

t

he goal of our project is to analyze the relationships
between stocks within the s p     and use various
machine learning techniques that weve studied in class
to do so  ideally  the analysis will lead us to the discovery of
effective ways to calculate the s between stocks and the
s p     which would ultimately allow us to obtain a proper
hedge ratio for trading the stock vs  the s p    
to premise  for most of our analyses  we will use the log
returns of the data  as in financial modeling of data typically
people do not look at the absolute values of the data but
instead at the percent returned for the asset  i e  st   st     and
taking the logarithm allows us to introduce some linearity to
the problem 
at the end of our project  we modeled the relationship
between the stocks with the s p    using a stochastic
differential equation  and by focusing on the idiosyncratic
component of this model we were able to detect a signal to
trade off of  we end our project with an analysis of our
various trading strategies and their respective profit and
losses  pnl  
our data comes courtesy of eva hedge fund in san
francisco  ca  and consists of intra day data  specifically 
   minute time intervals  of the s p    and its
components 
a  motivation  about the 
the  is the coefficient between the market component and
the constituent component  namely it can be expressed as the
linear relationship between 

the time series  by doing so  one could determine when the
stock is trading too cheap or rich to the market  and then take
advantage of this inefficiency by initiating a trade  this
difference between the stock and the market can be used as a
signal in high frequency trading  and is the main
motivation behind the stochastic differential equation
proposed by avellaneda et al   and which is explained in
more detail in the following section 
b  back testing methodology  modeling
we used a quantitative approach to stock pricing based on
relative performance within industry sectors or pca factors 
which has been presented in      the stock prices are noted
where is time  and where the indices are
noted
  in the case of supervised learning 
represents the price of the
factor used to span the market 
the stock returns are modeled according to the following
stochastic differential equation 

it is composed of 



a systematic component

  driven by

the returns of the indices
an idiosyncratic component
  it is assumed
to be the increment of a stationary stochastic
process which models price fluctuations
corresponding to over reactions or other
idiosyncratic fluctuations in the stock price which
are not reflected the industry sector 

logret  smarket       logret  scomponent 
the  in turn has several natural interpretations as well as
uses  though all of the interpretations and uses are
intimately related  the natural interpretation is that the  can
be used as a hedge ratio between the constituent component
 i e  the stock or the sector of stocks  and the market
component  i e  the s p    index   this ratio tells us the
amount a trader would have to buy sell the market stock to
remain risk neutral 
another use for the  is for forecasting and prediction  by
modeling the linear relationship between the log returns  one
could then use the estimated  to forecast future values of

the
component is modeled as an ornsteinuhlembeck process  i e  follows this model 

where
is an indicator of the mean reversion speed  this
process is stationary and auto regressive  in particular  the
increment
has unconditional mean zero 
c  back testing methodology  trading strategy
we focus only on the process
and define the
dimensionless variable 

fiwhere
and
  these values are
computed with a sliding window before the time of
estimation  
the s score measures the distance to equilibrium in units
standard deviations of
  the cointegrated residual which
is computed from
  in other words  it describes how
far away a given stock is from the theoretical equilibrium
value associated with our model 
our basic trading signal based on mean reversion is

ii  supervised learning
a  the different norms
the main difficulties with our dataset concern its
distribution  over the two year period we have  we cover a
period of big growth and the financial crisis  the first
problem is that our dataset may not be stable  i e  the betas in
those different periods may differ  due to fundamental
market conditions  with the analogy of house prices  we can
imagine that the house prices have fundamentally changed
between those periods  meaning that it may not be possible
to learn a model from one period and apply it to the other 
the other difficulty is that the distribution is not gaussian 
there are a lot of jumps and big variations  and a tdistribution seems to be a better fit 

where the hedge values are determined empirically  in
practice  we used
and
 
such a trading strategy is illustrated by the figure below 

modeling the dataset distribution
actual frequency

fitted gaussian

fitted student

     
    
   
  
 
  

  

   

 

 

in order to deal with those problems  we have selected
different objective function to minimize 
the usual one involves the l  norm  but it does not seem
robust to the non gaussian case  and does not adapt to the
fundamental changes in the dataset 
the l  norm has the property of being much more robust to
outliers  for example  in a simple  d setting  using the l norm  we know the maximum likelihood estimator of a
series of number is the mean  however using the l  norm 
this estimate is the median  which is more robust to outliers 
where the axis represents the time  the black line is
and
the red line is the pnl  notice that the pnl fluctuates only
on specific times  corresponding to points where
crosses
one of the hedges define above 
notice also that the pnl may drop because we used two
additional cut offs
which
represent stop loss hedges  at which we close our position 
despite the fact that the cointegrated residual does not
returns to the mean  this accounts for jumps in the stock
value which arent taken into account in our mean reverting
model  but which breach our risk limits  by closing our
position  it results in a money loss and explains the drops of
the pnl  but is necessary in practice because of risk limits 

in order to deal with the instability and the fundamental
changes  we can divide our dataset into two different
clusters  one for the highly volatile days  and one for the
other days  we can use a k means or a mixture of gaussians
to separate the different days  we have observed that during
the crisis  we had much more volatile days than before  and
in practice one could either turn off their trading strategies
during high volatility days  or one could design a separate
trading strategy that handles highly volatile days well and
switch between the two  in our setting  we tested one
strategy which uses the same  for both periods of time
 high volatility and low volatility  and a separate strategy
which only predicts during low volatility days  to calculate
volatility  we were careful to only use half a days worth of

fidata  as in practice the objective is to guess whether or not
a day will have low volatility and high volatility as early
into the day as possible  hence  this naturally introduces a
possible misclassification error rate which we calculated to
be        once we had computed all half day volatilities 
running k means gave us 

gaussians for the weights and the l  norm for example 
below is a summary of the different supervised methods we
used as well as their respective objective functions 
norm

objective

mi n yij   jt fi 

 

l  norm
l  norm
mixture



i j

mi n yij   jt fi


i j

mi n


i j

 

 i 

y

ij

  jt fi 

 

b  choosing the norms and parameters
we need to choose different parameters such as the ratio of
test size to training size  the numbers of factors we use or
the overall time interval we can use  lets plot the test
error training error or the influence of each factor to choose 

test error
test error

    
   
    
   
    
from which we can see a very clear volatility clustering
effect when illuminating all high volatility days 

 

  
  
training size test size

  

fig     test error with respect to the ratio training size   test set size using
the usual l  norm 

the improvement in the test error is small after a ratio of
    which we will use for the backtesting  furthermore  the
cross validation error is fairly stable over time with the total
set size  meaning that we can expect the same performance
for different time interval 
finally  we have assessed the importance of each factor by
the increase in error when it is excluded  the financial sector
is the most important  as the financials played an important
role during the crisis  and the telecom sector is the least
important 
c  back testing results
in order to backtest our models  we have used the trading
strategy described in part b 
using the mean squared error  mse  as a measurement for
strength of prediction  we compare the two strategies and
find that the mse for the first strategy  same  for all days 
was      times higher than the mse for the second strategy
 only forecasting on low volatility days  
however  despite these positive results  for the purposes
of pnl and back testing we chose to implement the nave
strategy of using the same  for all days  finally  we note
that we could also combine the methods  using mixture of

the results are very different depending on the period we
choose  and our strategy is not able to yield good returns in a
consistent manner  during the crisis  and precisely at the
time of lehmans failure  we have a huge loss  on average
we get a yearly return of     a year  which is not that bad
for such a period  and a sharpe ratio of     over ten days 
which is the standard  the mixture of gaussians method
gives the best returns and sharpe ratio 

fib  results
our graphs show the eigenvalues of the pca components
for the l  and l  norms  as expected  the part of the
variance explained by the first components is higher with the
l  norm than with the l  norm 

fig     pnl comparison of l   l   and mixture of gaussians supervised
learning methods  mixture of gaussians  red  performed best 

we defined the training and test error of our model 
iii  unsupervised learning
a  motivation
though supervised learning provides a sufficient
framework to find the s and trade  we would like our
strategy to rely on indices chosen to be the most relevant
ones to explain the considered log return stock  rather than
pre defined 
to address this problem  we used the principal component
analysis  which enables us to identify the driving forces of
the market and predict the evolution of the stock in terms of
very few indices which explain most of the market s
variance  the advantage of the principal component
analysis as an unsupervised learning technique is that we
make no assumption on the predictor variables  the
algorithm finds itself the linear factors that best explained
the response 

error  l  
error  l  

 
nm

 y

 
nm

y

i

j

  tj fi



 

i  j

i

j

  tj fi

i  j

the graphs below represent the difference of a particular
stock and its estimated value against the number of factors
used in the estimation  averaged over all the s p    stocks 
as expected  the error decreases when the number of factors
increases 

the commonly used l  pca maximizes 

arg max w t x
w

 

when the maximization problem is expressed in terms of the
l  norm  the result is unfortunately very sensitive in
presence of outliers and could result in a skewed estimation
of the betas  thus  we modified the maximization problem in
terms of the l  norm  which provides a robust principal
component analysis 

arg max w t x
w

 

though the traditional l  pca was performed through rs
standard package  we used the pcapp package in r to
perform the computation of the l  pca  it provides the
robust principal components using the grid search
algorithm  presented in     

c  back testing of strategy
in order to test if we should use the l  norm rather than the
l  norm  we performed a back testing strategy on the stocks
using the two different s estimations  we train the pca on
    of the data to estimate the s and the factors  we then
execute our statistical arbitrage strategy on the test set with
estimated s and factors 

fiiv  conclusion
for our project  we investigated the relative performance of
several supervised learning methods  l  regression  l regression  and mixture of gaussians   as well as several
unsupervised learning methods  l  pca and l  pca  
because of the fat tailed nature of many financial time
series  there is a higher tendency for outliers and intuition
tells us that by using a more robust statistic  namely the l norm  we could have more success in our modeling  using
pnl and sharpe ratio as a metric for determining the
effectiveness of a given   we determined that for both
supervised and unsupervised learning methods  the l  norm
indeed performed better and in fact had similar returns for
both cases  more specifically  in the case of supervised
learning methods  we saw that the mixture of gaussians for
the weights with the l  norm objective function had a
yearly return of about      while the l  pca for the
unsupervised learning method had a yearly return of about
      
for future improvements  we would like to re implement our
back testing algorithm so that it tries to test for mid day
volatility and take this into account before deciding to trade 
we believe that by eliminating highly volatile days  such as
the period surrounding the lehman incident  we can
improve our overall returns and also improve upon the
consistency of our returns 

references
   
   

the graph on the top represents the profit and losses  pnl 
of the trading strategy presented in the introduction  starting
at       the graph on the bottom presents the distribution of
sharpe ratios obtained over the different s p    stocks   
factors were used in the pca  
we obtained that the l  norm has a better pnl and sharpe
ratio distribution in many cases  in our example  the pnl is
      for l  norm compared to       for l  norm after    
iterations and the mean of the sharpe ratios are of      for
the l  norm and      for l  norm  this result is very
encouraging and proves that our intuition that the outliers
affect negatively the estimation of the s was true 

avellaneda  m  and lee  j  h          statistical arbitrage in the
u s  equities market     july 
croux c  filzmoser p  oliveira m         algorithms for projectionpursuit robust principal component analysis  chemometrics and
intelligent laboratory systems

fi