forecasting avalanches in the pacific northwest
wes dyer
wesdyer gmail com

  

introduction

from            avalanches killed    people in the washington state  cen     over one million dollars is spent annually
to manage avalanche hazards that threaten highways in the
state  in addition to the loss of life and the public cost 
ski resorts also invest a great deal to mitigate the risks of
avalanches within their boundaries  accurate forecasts assist both professionals and recreationalists by reducing costs
and increasing safety 
despite the benefits of avalanche forecasts  it is often difficult to accurately forecast avalanches for specific locations
and times  this is because there are simply not enough
forecasters to provide information for the vast number of
possible avalanche sites  using machine learning  avalanche
forecasts can be given for a much larger region at significantly greater detail than a handful of human forecasters
can hope to provide 
this paper investigates applying machine learning to avalanche forecasting in the maritime climate of the pacific northwest  it begins with a discussion of the dataset and the
measures used to gauge success  next  the paper discusses
feature and model parameter selection  it then compares the
forecasting performance of three statistical methods  support vector machines  logistic regression  and nearest neighbors  finally  it discusses future research possibilites and
concludes with recommendations 

  

data

suprisingly  avalanche data is rather hard to come by  despite more than twenty years of research into machine assisted avalanche forecasting  there are no public datasets 
furthermore  even if there were avalanche datasets  avalanche
occurrence is greatly influenced by climate  ms    and the
pacific northwest has a decidely maritime climate which differs dramatically from that of the rockies or the alps 

   

preparation

fortunately  several entities within the state maintain pertinent datasets  first  the northwest weather and avalanche
center  nwac  collects weather and snowpack data from
a number of sensor sites scattered throughout the cascade
mountains with a bias towards locating sensors near ski
resorts and highways  although other organizations operate these sensor sites  they report the readings to nwac 
second  the washington state department of transportation  wsdot  collects and records data used to help winter maintenance and avalanche hazard management crews 
this data includes weather and snowpack data  which incidentally is reported to nwac  but more importantly it
includes avalanche observations 

the avalanche observations are for the snoqualmie pass area
in washington state  the data extends from           winter season to the           winter season  each season begins october  st and extends into april of the next year 
three nearby weather and snowpack observation datasets
are selected to build avalanche forecasting models  hourly
weather observations from the      foot level  hourly weather
and snow pack observations from      foot level  and daily
observations that include both sensor data and human readings 
the three weather and snowpack observation datasets are
combined with the avalanche observations to produce a daily
conditions summary  the dataset contains a number of
weather related features  high temperature  average temperature  low temperature  new snow  new snow water equivalent  how much water is contained in the new snow   rain 
precipitation  total new water   barometric pressure  relative humidity  fog  sky conditions  average solar input  wind
speed  and wind direction  it also contains some snowpack
based features  snowpack height  snow crust  snow wetness 
ram drop penetration  how far a probe drops into the snow
from a fixed height   hand penetration  and surface hoar 
the dataset is combined with itself to produce summary
daily conditions which include the current days observations  yesterdays observations  and the observations from
two days ago  table     note that the inclusion of previous
days conditions also allows us to add features indicating observed avalanche activity on the previous two days because
they are in the relative past 

   

problems

there are few interesting charactertistics of the dataset 
first  the dataset contains a number of missing values which
represent times when some sensor was either broken  inoperable  or not yet installed  these missing values are left
in the dataset to be removed after feature selection since it
isnt yet clear which features are needed  similarly  there
are some wildly inaccurate values like negative wind speeds
which are resolved by simply interpolating the data if it is
straightforward or changing them to missing values 
second  the avalanche observations are somewhat limited 
these observations only cover a fixed number of important
avalanche paths that threaten interstate     furthermore 
about half of the avalanches are artificially triggered by some
label
avalanche

today

conditions
yesterday two days previous

table    combined feature vector

fipredicted positive
predicted negative

actual positive
true positive  tp 
false negative  fn 

actual negative
false positive  fp 
true negative  tn 

table    confusion matrix
pod  probability of detection 
sr  success rate 
hr  hit rate 
tpr  true positive rate 
fpr  false positive rate 

probability
probability
probability
probability
probability

that
that
that
that
that

the event is forecasted when it occurred  p od   t p  t p   f p  
the event occurs when it is forecasted  sr   t p  t p   f n  
forecast is correct  hr    t p   t n    t p   t n   f p   f n  
the event is forecasted when it occurred  t p r   t p  t p   f n  
the event is forecasted when it did not occur  f p r   f p  f p   t n  

table    forecast accuracy measures
means like explosives  however  note that any artificially
triggered avalanche is still an avalanche  it simply means
that the avalanche might not be triggered by a less severe
stimulus such as a skier crossing the slope  our goal is to
reduce the risk of exposure to avalanches and any artificially
triggered avalanche means that avalanche conditions exist 
but perhaps will not actually be triggered  in this light 
naturally triggered avalanches are actually worse since they
could possibly have been triggered previously with less powerful stimuli 

avalanche  but the model is still the same  the f score does
not capture this  instead  we can use another measure called
the receiver operator characteristic  roc  curve which has
been used for years in medicine and biology  hm    and
has recently been shown to excel at comparing classification
models in machine learning  bra     this curve represents
the tradeoff between correctly forecasting avalanches and
raising false alarms  it plots the tpr against the fpr  to
compute a single number  we take the area under the curve
using the trapezoid rule 

third  wsdot and nwac both state that the avalanche
observations might not be complete  this means that there
may be other avalanches that are not listed because either
conditions such as thick fog make it hard to observe them or
it is too dangerous to make the observations  this is another
reason to favor predicting avalanches 

to choose good enough features and parameters for a model 
a search is performed which maximizes the f score  the fscore is chosen as an expedient to reduce the time needed
to perform the search  it would be much better to use the
roc area under the curve and we aim to use that statistic
in the future  note that the roc area under the curve is
still used  but only to compare models and not for searching
purposes 

fourth  earlier seasons seem to have spottier sensor data
and avalanche observations  because of this  only the      
     through the           seasons are kept 

  
the final dataset contains      training examples with   
features  of the      days  only    are avalanche days 

  

measuring success

after constructing the dataset  initial experiments are conducted using all of the features and removing training examples with any missing values  the resulting training set
contains     training examples with    avalanche days  immediately a model is created with     accuracy  unfortunately  this coincides exactly with the percent of nonavalanche days  the model simply predicts no avalanche
for every day and gets it right most of the time  clearly  accuracy alone is not a good measure of success in avalanche
forecasting 
like many other fields  avalanche forecasting instead uses
the confusion matrix  table    and the associated forecasting measures pod  hr  and sr  table     in the interest
of obtaining a single number to represent the quality of a
model  the f score is computed as the harmonic mean of
the pod and sr  equation    

f  

   p od  sr
p od   sr

   

however  the f score is sometimes also unsatisfactory  note
that if we build a statistical model to forecast the probability of avalanches  we can vary the f score by increasing or
decreasing the threshold probability for which to forecast an

feature selection

if you open any book on avalanches  you will find a detailed
list of features that spell certain doom on the snowy slopes 
it is therefore somewhat surprising that the feature list can
be improved  to pick the set of features to use  we select an
initial set of features commonly known to be good indicators
of avalanche activity  these features include  day of season 
new snow            snowpack height  rain water             wind direction              wind speed              sky
conditions  ram drop              high temperature        
     and avalanche activity           note that        and   
represent the current day  yesterday  and two days previous
respectively  if no number is included then it means only
the current day is used 
next  a backward feature search algorithm eliminates unnecessary features followed by a forward feature search algorithm to add unincluded features to the list  note that
during the search  the same folds must be used throughout
in order to have stable statistics to compare  otherwise instead of comparing features  the search algorithm may end
up comparing the quality of partitions  during feature selection      or more folds are used in order to have reliable
measures of the quality  furthermore  since missing values
still persist in the data  only the training examples without
missing values for the tested feature set are used and since
the same set must be used throughout for a stable comparison then only the intersection of the training examples that
correspond to each subset of the possible feature selections
is used during the search 
after the feature search  the final set of features are  new

fifigure    nearest neighbors learning curve

figure    logistic regression learning curve

snow          snowpack height  rain water  wind direction    
     wind speed          sky conditions  ram drop  high temperature              average temperature  low temperature
      precipitation       and avalanche activity           note
that nine features are removed and three features added 
now that the final feature set had been selected  all training
examples with missing values are removed from the original
dataset of      days  this leaves     days with    avalanche
days 

been shown that nearest neighbors requires more training
data and may suffer from overfitting problems  mbac    
the model was included as a baseline to compare with other
models 

  

parameter selection

another problem is selecting the right parameters for various statistical models  remember that initially the models
simply forecast every day as a no avalanche day  for many
models  one way to improve the behavior of the system is
to penalize misclassification differently for different classes 
it seems intuitive to penalize misclassifying avalanche days
more than misclassifying non avalanche days  this is done
by changing the weights of various classes  furthermore 
many models also have other important parameters which
means that many parameters must be selected 
at first  grid search was attempted to select the optimal
parameters  but this took much to long and requires human
attention to be tractable  next  a coordinate ascent method
was tried  but this was eventually replaced with a much more
efficient simulated annealing method that quickly finds good
parameter values even when many parameters are optimized
at once 

  

statistical models

three statistical machine learning models are compared using the prepared dataset  selected features  and parameter
selection methods  nearest neighbors  nn   logistic regression  lr   and support vector machines  svm  

   

nearest neighbors

the nearest neighbors algorithm has long been used in avalanche forecasting  bus    despite repeated attempts to replace it with other more sophisticated models such as artificial neural networks  the reason that nearest neighbors is so
popular is that it is simple  easy to understand  and it gives
human forecasters the ability to interpret results  because
of these reasons  professional forecasters often employ nearest neighbors to assist in forecasting  nevertheless  it has

the nearest neighbors algorithm takes a training set and
converts each training example into a unit vector  then
when testing  nearest neighbors takes the given vector and
converts it to a unit vector and computes the distance between it and all of the training vectors  the k closest vectors
are used to provide a prediction where the probability of an
avalanche is equal to the percentage of the k closest vectors
which were avalanche days  testing shows the that nearest
neighbors algorithm performs well when k      note that
the resolution of the estimated probability is a function of
k  therefore  to provide higher resolution estimates for later
comparisions  k is chosen to be     the learning curve  the
f score plotted against the training set size  shows an interesting characteristic of the algorithm that the training error
is the same as the test error only shifted higher due to the
inclusion of the test vector in the training set  figure    

   

logistic regression

the next algorithm is logistic regression  previous studies
have on occasion used logistic regression to forecast avalanches although this method does not enjoy the widespread
use that nearest neighbors has achieved 
liblinear is used to train and test logistic regression
models  fch       as previously mentioned  while training classifiers for avalanche forecasting  equal weights should
not be given to misclassification of avalanche days and nonavalanche days  there are two reasons for this  first  avalanche days are much less common and mistakes that misclassify avalanches are also less common  second  while repeatedly forecasting avalanches on a non avalanche days is an
annoyance to recreationalists and causes maintenance crews
to spend more money then they otherwise would need to 
it is not injurious to life or limb  it is difficult to say that
there would not be an avalanche give a more powerful stimulus and as long as not too many false positives occur there is
some tolerance for misclassification  on the other hand  not
forecasting avalanches on avalanche days is a fatal mistake 
to compensate for these facts  the best logistic regression

fifigure    svm learning curve

figure    roc curve

models weights misclassifying avalanches approximately eight times worse than misclassifying non avalanche days  the
resulting learning curve shows that the algorithm converges
nicely  figure     but there is some room for improvement
due to high variance possibly by further eliminating features
or increasing the dataset size 

   

support vector machines

the last model is support vector machines  despite their
relatively recent development  support vector machines have
been used to forecast avalanches with success  ppk    although it remains to be seen if the model can overcome the
advantages and broad acceptance of the nearest neighbors
algorithm 
libsvm is used to train and test the support vector machines  cl     similar to logistic regression  the class weights
need to be adjusted to produce good results with the optimal weights penalizing avalanche day misclassification about
four times the amount as non avalanche day misclassification  a gaussian kernel is used with            finally 
in order to produce probabilitic measures of the likelihood
of avalanches  the sigmoid function is used both in training
and in test  pla    
the resulting model behaves very similar too  although slightly better than  the logistic regression model  figure     like
logistic regression  it appears that there is high variance that
can probably be addressed with more data or less features 

   

comparison

interestingly  when the three models are plotted on a roc
curve against each other it is clear that they all perform
fairly well  figure     each of the methods makes good to
excellent forecasts  support vector machines perform the
best  especially when the tolerance for misclassifying nonnearest neighbors
logistic regression
support vector machines
random
perfect

     
     
     
  
 

table    roc area under the curve

figure              avalanche forecast

avalanche days is lower  the area under the roc curve is
similarly instructive  table     it shows that support vector
machines perform best  then logistic regression  and finally
nearest neighbors 
i suspect that with further effort in eliminating the higher
variance and improving parameter selection especially for
maximizing the area under the roc curve instead of maximizing the f score  these numbers could be improved although they are already quite impressive 

  

discussion

the investigations into the possibility of using machine learning models to forecast avalanches in the pacific northwest
show that they are quite promising  for example  the support vector machine model can be applied to the          
season  figure    and the           season  figure     for
each season  all other seasons are used as training data and
the season in question is tested  the forecasted probability
of an avalanche is plotted for each day in the season  furthermore  actual avalanche days are indicated with dots on
the top and non avalanche days are indicated with dots on
the bottom 

ficonfirm intuition about important avalanche features  typical avalanche conditions  and patterns of occurrence  using machine learning to assist in avalanche forecasting is a
promising endeavor to pursue on a broader scale 

   

acknowledgements

john stimberis and the washington state department of
transportation are thanked for providing avalanche occurrence  weather  and snowpack data  mark moore  garth
ferber  and the northwest weather and avalanche center
are also thanked for providing detailed weather and snowpack data  without their help  this work could not have
been done 

   

references

 bra   

figure              avalanche forecast
the graphs show that the estimated probability closely follows the occurrence of actual avalanche days  furthermore 
days near avalanche days also have a high probability of
avalanches  this is good because avalanche probability follows a curve that increases sharply as weather events occur
such as snow storms or abnormal heat and then drop as the
stimulus is removed and the snow stabilizes over time 

  

future work

there is quite a bit of work still needed to achieve the goal
of providing detailed location and time specific forecasts for
the northwest 
first  spatial data needs to be incorporated into the model 
the data that wsdot and nwac provide contains coordinates for the sensors and the coordinates for avalanche
occurrences  from the avalanche occurrence coordinates 
important spatial features such as latitude  longitude  elevation  slope angle  and slope aspect can be computed  this
information can be used together to provide location specific
forecasts 
second  the current work only uses daily observations  however  the data actually contains observations on an hourly
basis  this can be used to provide hourly based forecasts
and allow people like recreationalists to choose time dependent safe routes through otherwise questionable terrain 
third  it would be interesting to take the human forecasters
predictions for the last decade and use them as a model
and compare them against the other models  it would be
fascinating to see the roc curve of human forecasters 

  

conclusions

the results are very encouraging  initially  the modest amount of avalanche occurrence data and its subjectivity seemed
to perhaps thwart efforts to apply machine learning to avalanche forecasting in the area  for example  the current data
only includes avalanche occurrences near i    over approximately twenty predefined avalanche paths that threaten i  s passage over snoqualmie pass in washington state  perhaps  additional avalanche data can be found for the area or
maybe avalanche sensors could be installed that give more
reliable and safe accounts of avalanche activity  despite the
modest amount of data  the models perform very well and

a  p  bradley  the use of the area under the
roc curve in the evaluation of machine learning
algorithms  pattern recognition              
     
 bus   
o  buser  avalanche forecast with the method
of nearest neighbours  an interactive approach 
cold regions science and technology 
               
 cen   
colorado avalanche information center 
avalanche accident statistics 
http   avalanche state co us acc 
accidents stats php  december      
 cl   
chih chung chang and chih jen lin 
libsvm  a library for support vector
machines        software available at
http   www csie ntu edu tw  cjlin libsvm 
 fch      rong en fan  kai wei chang  cho jui hsieh 
xiang rui wang  and chih jen lin 
liblinear  a library for large linear
classification  journal of machine learning
research                   
 hm   
j  a  hanley and b  j  mcneil  the meaning
and use of the area under a receiver operating
characteristic  roc  curve  radiology           
     
 mbac    c  mccollister  k  w  birkeland  r  aspinall 
and r  comey  exploring multi scale spatial
patterns in historical avalanche data  cold
regions science and technology            
     
 ms   
d  mcclung and p  shaerer  the avalanche
handbook  the mountaineers books  third
edition       
 pla   
j  c  platt  probabilistic outputs for support
vector machines and comparisons to regularized
likelihood methods  pages       mit press 
     
 ppk    a  pozdnoukhov  r  purves  and m  kanevski 
applying machine learning methods to
avalanche forecasting  annals of glaciology 
                

fi