using the deformable part model with autoencoded feature descriptors
for object detection
hyunghoon cho and david wu
december         

 

introduction

given its performance in recent years  pascal visual object classes voc challenge      the deformable part model  dpm 
is widely regarded to be one of the state of the art object detection and localization algorithms  the dpm as described by
felzenszwalb  et al      uses histogram of oriented gradients  hog  descriptors     as the underlying feature representation
for an object  in this paper  we consider using features learned by a single layered  sparse autoencoder as a substitute for
hog descriptors in the dpm  the rationale for this is that these learned feature descriptors may capture additional details
present in the image that are not present in a human engineered set of features such as hog  using this more descriptive set
of features may in turn yield a better object detector  additionally  it is noteworthy that while deep learning algorithms such
as the sparse autoencoder alone generally do not perform as well compared to other vision algorithms  it may be possible to
integrate learned features into an existing image classication system such as the dpm  to further evaluate the performance
of such an integration  we consider the eect of factors such as block normalization and colored features on the performance
of the autoencoder backed dpm  finally  we also examine the performance of the autoencoder backed dpm across several
dierent object classes from the pascal voc challenge 

 

methodology

our training images are sampled from the pascal      training image sets and our test images are sampled from the
pascal      test image sets     

for this paper  we consider two dierent training set sizes  small     positives      

negatives  and medium          

   

autoencoder training

we train a sparse  single layered  autoencoder with a sigmoid activation function

  to obtain a set of features  we iterate

over each positive training image in the training set and crop the image to the ground truth bounding box for the image 
we convert the image to grayscale and whiten it 

from this set of whitened  positive examples  we sample          x 

image patches to train an autoencoder with          or     hidden nodes  we center and standardize each patch

x  r  

xx
according to
x prior to training the autoencoder  we also consider colored image patches in which each  x  image patch
   
now corresponds to a vector x  r
    components per color channel  and train an autoencoder with     hidden nodes 
in the dpm  felzenszwalb  et al      consider the mirror image for each training example to eectively double the size of
the training set 

with hog descriptors  it is sucient to mirror the orientation of each gradient to determine the hog

representation of the mirror image  to allow for similar functionality with the autoencoder  we compute the mirror image of
each feature learned by the original autoencoder to obtain a mirrored autoencoder with the same number of hidden units 
we concatenate the original and mirrored autoencoders to obtain a set of           or     features  finally  felzenszwalb 
et al      also incorporate one additional occlusion feature that denotes whether the full object is visible in the image or not 
likewise  we introduce one additional occlusion feature 

   

model training and visualization

we replace the hog feature descriptors in the dpm  at the low level  the dpm divides the image into a rigid grid of  x 
pixel non overlapping cells and computes a histogram for each cell  in addition  the model captures ner details  part lters 
in the object by using smaller  x  pixel patches  we adapt this approach to work with the autoencoder features 

 

autoencoder training toolkit provided by adam coates

 

fi     

histograms of autoencoder features

to determine the features that comprise a particular image patch  we determine the distribution of features in a particular

 
  ex is the sigmoid activation function for the hidden layer  and w
are the corresponding weight and intercept terms for the inputs to the autoencoder  the resultant activation vector

image patch
and

b

x

by computing

g w x   b 

where

g x   

expresses the degree to which each hidden node is activated by the given image patch 
in addition to using the sigmoid activation function  we consider another method of computing a distribution of features
for each image patch  in particular  we substitute a nonlinear activation function
and linear with slope

a

above the threshold  we cap the activation at a value

h x 

that is

 

below some threshold

c   

c   

 
 
x   c 
h x   
min  a x  c     c    x  c 
we determine our histogram of features by computing

h w x   b  

in particular  we choose

c   c   

and

a

so that the range of

values in the histogram of features is similar to that computed by hog 
to train the dpm  we compute histograms of features for  x  image patches which are used by the part lters  we cannot
train a completely separate autoencoder on  x  patches since the features learned from  x  image patches do not necessarily
coincide with features learned from  x  image patches 

we consider two dierent approaches 

in the rst approach  we

construct a  x  autoencoder from the  x  autoencoder where for each feature in the  x  autoencoder  we remove every other
row and column to produce a scaled down  x  feature  we use this autoencoder to construct the histogram of features for
 x  image patches  in the second approach  we use only the  x  autoencoder  to construct the histogram for  x  image
patches  we scale the  x  image patch up to obtain an  x  image patch  which we then run through the autoencoder to
obtain the histogram 
we consider a simple method of incorporating color into the histograms using the existing autoencoder  when training
the model  instead of working with grayscale images  we consider each color channel separately  now  for each feature  we
simply take the maximum activation for each feature over the three color channels and use that as the activation 
for the nal test  we consider the result of combining hog descriptors with autoencoder features  in this scheme  we
rst compute a histogram of autoencoder features using an autoencoder with     hidden nodes  we then compute the hog
descriptors and adjoin these two vectors to obtain a     element vector      autoencoder       mirror      hog  that
serves as the feature descriptor for the image patch 

     

normalization

in dalal and triggs  hog implementation      they consider block normalization where the gradients for a patch are averaged
over neighboring blocks 

felzenszwalb  et al 

normalization procedure     

has experimentally demonstrated noticeable improvements using a block

we consider a similar normalization method as     

square of the norm  of the feature histogram for each image patch
and multiply the elements by the normalization constant

cx y
where



 

 
 

x
i j     

cx y

 i  j  

first we calculate the energy

ei j  the
 x  y 

then we take the histogram at each patch

where

 
p
ex y   ex i y   ex y j   ex i y j   

 

is a small constant so we do not divide by zero  this normalization has the eect of mitigating situations where

there is a high local variation in the energy of a block 

     

model visualization

to visualize the model  we take the image patch that maximally activates each hidden node in the autoencoder  these image
patches are given by the rows in the weight matrix for the input layer  for each patch in the model  we alpha blend the
feature image patches using

i  

a i
th
feature  where
e as the opacity of the i

ai

is the activation value and

e

is the energy of

the feature histogram 

     

tuning the latent svm

finally  we consider the eect of changing the regularization parameter used to train the latent svm  lsvm  in the dpm 
the value used by felzenszwalb  et al 
autoencoder features 

    works well in the case of hog descriptors  but may not be well tuned for

hence  we consider both higher and lower values of the regularization parameter

objective function  we evaluate by testing on both a subset of the training set as well as the test set 

 

c

in the lsvm

fi   

model evaluation

to evaluate an object model  we test on a sample of test images from the pascal voc          test set that are similar to the

area predictedtrue 
area predictedtrue       
where predicted denotes the bounding box predicted by the model and true denotes the true bounding box for the image 
training images  we use the same scoring criterion as pascal  a detection is correct if and only if

if one object is detected multiple times  only one is taken to be a true positive and all the other ones are taken to be
false positives  using this information  we can compute a precision recall curve for the detector  as well as compute a value
describing the average precision for the detector  this is the metric used by pascal 

 

results and discussion

figure   

top left 

sample training image of bicycle 

bottom left  middle 

the same picture represented using hog

descriptors  grayscale autoencoder features  and colored autoencoder features  right  grayscale  top  and colored  bottom 
autoencoder features learned from  x  grayscale and colored image patches of bicycles 

figure    from left to right  model of bicycle using hog descriptors  autoencoder with     hidden nodes  colored autoencoder
with     hidden nodes  and both hog and autoencoder with     hidden nodes  hog features in yellow   top row shows
root lter and bottom row shows ner part lters  to the right  we show the precision recall curve for the four models 

table   shows the eect of various parameters on average precision of the model  with the exception of the specied
parameter we are evaluating  each model described in the table is for a bicycle model trained without block normalization
and using only the  x  autoencoder with     hidden nodes on a medium training set  noting that the autoencoder with the
nonlinear

h x 

activation function slightly outperformed models trained with the sigmoid

g x 

activation function  for the

majority of tests  we only train and evaluate models using that particular activation function  first  we see that while there
is no sizable benet from using a larger training set in the case of hog  there is an improvement in the autoencoder models
by using a larger training set  therefore  one possible way of achieving better performance with the autoencoder may be

 

fiactivation function
hog descriptors

sigmoid

g x 

small training set

      

 

medium training set

      

      

nonlinear

h x 

           hidden nodes 
            hidden nodes 
           hidden nodes 
            hidden nodes 

block normalization

 

      

      

without patch standardization

 

 

      

scaled down  x  autoencoder

 

 

      

features over max color channel

 

 

      

higher threshold for

 

 

      

highest threshold

 

 

      

h x   c      
for h x   c      

table    average precision for dierent training set sizes and methods of computing histogram of autoencoder features

to further increase the size of the training set  interestingly  increasing the number of features did not appear to have as
substantial an impact as increasing the training set size 
next  we consider four variations  described above  on the way we compute our feature histogram  adding block normalization  removing patch standardization when training the dpm  using a scaled down  x  autoencoder for computing  x 
part features  and evaluating on each color channel separately  contrary to expectations  the block normalization scheme
does not increase the eectiveness of the model  and in the case where we use the
signicantly worse performance 

h x 

activation function  results in

similarly  removing patch standardization also decreases the performance of the model 

however  removing this additional preprocessing step signicantly increases the speed of the training by almost a factor of
two  hence  in cases where run time performance may be more important than the accuracy of the model  this may be a
viable trade o  finally  we consider the approach of using a separate  x  autoencoder  eectively a scaled down version
of the  x  autoencoder   this leads to a signicant drop in detector precision compared to the model trained using only the
 x  autoencoder  where  x  image patches are scaled up to  x  and represented using features from the  x  autoencoder  
this may have been due to the fact that simply removing every other pixel from each feature in the  x  autoencoder is not
a reasonable way of constructing a  x  autoencoder and may have ended up distorting the features  finally  we consider a
way of incorporating color similar to what was done by felzenszwalb  et al       we use the maximum hidden node activation
value over the three color channels as the activation for a particular image patch  this appears to have a fairly insignicant 
even detrimental  eect on the performance of the model  a potentially better method of incorporating color may be to use
a separate autoencoder that incorporates colored image patches  we discuss this result later 
the nal set of tests we consider is to change the threshold used in computing the

h x 

activations  higher thresholds

would imply fewer hidden node activations for each image patch  possibly resulting in less noise in the histogram of features 
but at the same time  reduce the number of features that are expressed in the histogram  the data indicate that performance
generally deteriorated for higher values of the threshold  admitting fewer node activations  
bicycle

car

bottle

horse

sofa

airplane

hog descriptors

      

      

      

      

      

      

autoencoder features

      

      

      

      

      

      

table    average precision values for dierent object classes
table   shows the average precision values for dierent object models from the voc challenge      for each object class 
we train the autoencoder backed dpm with a medium training set and using

h x 

as the activation function  we test both

the autoencoder backed model and a hog backed model on a sample test set taken from the voc challenge  though the
autoencoder backed dpm did not achieve superior performance  these results indicate that our system has the potential to
work across many dierent object categories 
table   above shows the average precision values for models trained with a variable number of features 
for an autoencoder with

n

nodes  the number of features is

 n    

 original autoencoder features

 

note that

mirrored features

 

occlusion feature   in the case where we integrate the autoencoder features with the hog descriptors  the occlusion feature
is already incorporated in the hog features 
using activation function

h x  

each of the above models are trained on the bicycle medium training set

it is interesting to note that additional features  hidden nodes  did not necessarily correlate

to better performance  there was a slight gain going from    hidden nodes to     hidden nodes  but not much thereafter 
interestingly  incorporating color also did not yield an observable benet  it is possible that we need a larger training set
in order to further improve performance 

finally  it is noteworthy that incorporating both hog descriptors as well as

autoencoder features lead to an observable improvement in the detector s performance 

 

in particular  its performance is

fiaverage precision
   features     hog 

      

    features     hidden nodes 

      

    features      hidden nodes 

      

    features      hidden nodes 

      

    features      hidden nodes     hog 

      

    features      hidden nodes with color 

      

table    average precision values using dierent number of features  bicycle  medium training set 

slightly higher than the hog model trained on the same training set  this indicates that there might be features that are
captured by hog  but are not completely captured by the autoencoder 
regularization parameter

average precision  training 

       hog 

      

average precision  test 
      

     

      

      

     

      

      

     

      

      

     

      

      

    

      

      

table    average precision values from dierent regularization parameters  bicycle  medium training set 
in table    we consider using dierent values of the regularization parameter

c

used to train the latent svm desribed

in     to try and make the average precision on the training set converge to the average precision achieved on the test set 
in general  while increasing the value of

c

increases performance on the training set  performance on the test set appear

relatively unaected  the value felzenszwalb  et  al     used to train the hog backed dpm         appears to work well in
practice for the autoencoder models  overall  changing the regularization parameter did not appear to be very signicant as
far as performance on the test set is concerned 

 

conclusion and future work

overall  the results indicate that the autencoder backed dpm is a viable object detector 

while using only autoencoder

features do not outperform the model trained using hog features  the average precision values tend to be comparable 
furthermore  integrating autoencoder features with hog descriptors produces a detector whose results are actually slightly
better than those obtained by hog alone  results also indicate that variations such as using more hidden nodes  adding
block normalization  and varying the threshold for

h x  do not lead to noticeable gains in detector performance 

rather  the

single more important factor appears to be training set size  current results show that we may be able to achieve substantial
improvements if we further increase the size of the training set and that is one avenue of future consideration 

another

interesting possibility for further research would be to use multiple  stacked autoencoders to learn more complex low level
feature representations for a given object 

finally  we are currently looking into optimizing the run time performance of

the training algorithm in order to support substantially larger training sets  which should in turn  lead to better overall
performance 

 

acknowledgments

we would like to thank professor andrew ng and adam coates for the help and advice they provided for this project 

 

references

  m  everingham and l  van gool  the pascal visual objects classes challenge      
http   pascallin ecs soton ac uk challenges voc voc     index html 
  p  felzenszwalb  d  mcallester  d  ramanan  a discriminatively trained  multiscale  deformable part model  proceedings
of the ieee cvpr      
  n  dalal and b triggs  histograms of oriented gradients for human detection  in

 

cvpr  pages i                

fi