a framework for assessing the feasibility of learning
algorithms in power constrained asics
alexander neckar
with david gal  eric glass  and matt murray  from ee   a 

  introduction
whether due to injury or neurodegenerative disease  millions of paraplegics suffer from an inability to actuate
their limbs despite functional thought processes  neuroscientists have developed methods     of monitoring and
interpreting neural activity  by surgically implanting an electrode array in the motor cortex of the brain 
scientists can tap into the real time neural activity of an individual  these neural observations can be interpreted
as an intended actuation which can then be realized on behalf of the individual  a paraplegic  once lacking the
agency to perform simple physical tasks  can now do so by thought alone  a revolutionary improvement in quality
of life  current neural decoding implementations render the patient tethered to a cart of computers with visible
wires emerging from his or her head  collection of neural activity occurs beneath the skullcap while processing
is done remotely  there is much room for improvement on this setup  patients are embarrassed by the physical
appearance of the apparatus and can only utilize it in the controlled environment of a university laboratory 
the natural solution to this problem is to embed the processing that currently takes place remotely into the same
physical space as the data collection   an embedded processor implanted in the brain  to date  however  no such
system has been designed  it is not immediately obvious that such a system could exist  the environment of the
human brain presents design challenges and specifications not typically present in traditional computing systems 
primarily  any implanted system may not raise the temperature of brain tissue by more than   c  this implies a
low power design  in addition  the complete system area is constrained to a small physical space  ideally less
than the size of the existing   mm x  mm electrode grid 
as a group  we explore the requisite hardware resources necessary to implement the dynamic portion of the
current neural decoding algorithms within the confines of a human brain  we develop a framework with which
to test the feasibility of such a design and conclude that such a device is indeed possible within the design
constraints  individually  i then go on to extend our evaluation framework to apply to any learning algorithm
written in c or matlab  i use this framework to assess the feasibility of implementing the static regression portion
of the decoding algorithm on chip  finally  i demonstrate the flexibility of the framework by assessing the
performance of a different learning algorithm to the neural decoding problem 

  neural decoding algorithm  kalman filter
to implement neural decoding  a kalman filter is used  this is necessary due to the large amounts of noise
inherent in the collection of neural observations  the system is modeled with linear dynamics  there is a linear
relationship between kinematic state of the cursor  x y z position and velocity  and neural observations  noise
and uncertainty is gaussian  this can be summarized as follows 

where x is the kinematic state of the cursor  y is neural observations  and w and v are gaussian noise sources 
the training sets are collected as follows  a monkey with the electrode grid planted in its motor cortex is fitted
with a special glove  this glove controls a cursor on a  d screen  the monkey is given targets on the screen  it
moves the cursor to these targets in exchange for a reward  each reach test takes on the order of one second 
every    ms  the cursor s kinematic state is measured and recorded along with the number of neural spikes

fiobserved on each individual electrode over the course of the timestep  each element of the training set thus
consists of the following 
  a    element neural observation vector containing the binned spike count for the last    ms on a single
electrode  there are    electrodes in the grid 
  a   element vector that describes the cursor s x and y position  velocity  and acceleration as well as the
intercept term

the algorithm that is implemented is a kalman filter with some special modifications      the algorithm
essentially has two phases  the initial regression phase or static phase  where observations are regressed on
cursor state and future cursor state is regressed on present cursor state  and the kalman update phase  where 
given a new neural observation  the likely cursor state is predicted and the present uncertainty in position is
updated and the time update is performed  the basic kalman updates to cursor state and uncertainty and the time
updates  respectively  are as follows 

  framework for analysis of asic implementations of learning algorithms
specification

profiling

fu models

temperature

fig     asic analysis framework

for the purposes of the original project  we focused on the implementation of the more time critical and
necessarily on chip dynamic phase of the algorithm  we envision that initial implementations of this device will
not include hardware to perform static calculations  the static regression phase is very computationally
heavyweight compared to the dynamic kalman update  and since the current framework for training setcollection requires patient proximity to computers anyway  it seems reasonable to have those computers perform
the regression  where computing resources are much cheaper  and pass only the static variables needed by the
kalman update to the device 
after studying the execution profile of the kalman update step and making a full assessment of its computational
demands  we envisioned a very simple asic device upon which to implement the algorithm  composed of a
single execution unit that carries out the necessary floating point math and a single memory bank in which to
hold the data  control circuitry is assumed to introduce an overhead which does not dominate the total power
consumption 
we then used tools to generate operational power and area models for each of these components  each
component is abstracted as having three parameters  static leakage power  per access energy  and area  by
inputting the profile obtained for the update  from these models we were able to derive a power and area model
for our asic 
using this area and this total chip power  we used a thermal simulator to study the effect of the device
implementing the algorithm on brain temperature  determining the feasibility of the design  in our original study 
we found that the kalman update is easily implemented within the constraints  with the device causing only a
     c increase in brain temperature  further  we derived the maximum power consumption budget of such a

fidevice to be roughly    mw 
i extended our framework to allow for any matlab or c program to be easily instrumented to obtain the necessary
figures and partially integrated some layers of the existing framework  essentially making the framework much
more portable and useful to a first time user  i describe the overall framework  starting with the original
components used in our initial study 

    memory system simulation  cacti
in order to generate a power and area model for our memory system  we used the cacti simulator      while
originally only for modeling caches  cacti is now well suited to model a variety of memory architectures  for
our purposes  cacti s most important output are the per access energy  leakage power  and area of the memory 
given the frequency of memory access obtained from the profiled code  this allows us to calculate a power
consumption for our memory  additionally  cacti contains several transistor models and allows the user to vary
parameters such as feature size  enabling a thorough exploration of the design space  given the most attractive
choices of low power dram  low standby power sram  and low operation power sram  low standby power
sram proves to be the best performing in our application 

    floating point unit simulation  mcpat
just as we used cacti to simulate the memory system  we used mcpat     to model the fpu  mcpat is a
powerful tool with many features which we did not explore  it allows the user to specify a complete multicore
chip in great detail and returns power and area figures for many different subsystems  in our case  we only use it
to obtain leakage power  per operation energy  and area for the fpu  mcpat would also help to pin down the
number of fpus that would be required by the design  like cacti  mcpat allows the user to vary feature size
and memory technology  analogous to what we found for our memory system  lstp transistors prove
themselves be optimal for the fpu 
mcpat also provides a rough basis for determining the number of fpus needed by a given execution profile and
time bound  while the timing model for the fpu is not detailed  the one modeled is a    stage pipelined design
capable of operating at at least   ghz  given a time bound and a factor of algorithm parallelism  the number of
fpus required can be estimated 

    hotspot thermal model
to simulate the thermal behavior of our system  we turned to hotspot         hotspot allows the user to generate
a detailed thermal model of an integrated circuit  given a floorplan divided into functional blocks and power
consumption values for those blocks  normally  hotspot is used to obtain a very fine model of on die
temperatures  however  the specification of our device places no demands on the temperature of the die itself 
only on the surrounding tissue  while hotspot holds ambient temperature as a fixed constant  through clever
modification of the tool  we are able to model the temperature of the tissue adjacent to the device 

    extensions to the framework
in order to assess the feasibility of an asic implementation of a general learning algorithm  i modif ied our
original non portable profiling techniques to allow for profiling on a variety of platforms and to function as a
simple wrapper to existing code written in c or matlab  to this end  i selected the papi     suite as the primary
profiler  papi provides an easy to use api to access hardware counters during program execution  i make use of
the floating point operation and memory reference counters  papi works on most current cpu architectures can
be integrated with c or matlab programs 

fiadditionally  i integrated several layers of the tool  after applying the customized papi wrapper to the algorithm
to be assessed and specifying an time constraint on the algorithm  a script is run that automatically passes the
results of the profiling to the necessary functional models  which generate a power and are model  if the device is
meant for implantation in the brain  the power and area model can be passed to the thermal model as well  in
order to determine the memory footprint  necessary for the power and area model  the user must first profile the
code in either valgrind or using the matlab memory profiler and pass this parameter when the script is called 

  application of the framework
as it is possible to envision future calibration scenarios that do not require the recipient of the device to interface
with outside computers  and given the greatly improved power of the framework  i then focus on the aspects of
the existing algorithm that we did not examine in great depth  in particular  i examine whether the cost of
performing the regression phase can be minimized to an acceptable level such that it may be performed on chip 
i then offer further demonstration of the framework s power in assessing the possibility of alternatives to the
kalman filter itself 
using the framework to evaluate the current implementation of the static phase  and focusing on very expensive
regression of observations on cursor state  i find that for the complete training set of       points  lms
regression by solution of the normal equations demands about      million fpu operations and    million
memory references  for comparison  each update of the kalman filter only contains        fp operations and
       memory references  for the per access energies and leakages of the fpu and memory units that i derived 
this implies that the regression is indeed possible on chip provided that the computation is spread out over more
than      seconds  this  however  represents a power consumption    times in excess of what is required to do
kalman updates  if this factor is reduced to     about    seconds are required to do computation 

    attempted optimization with stochastic gradient descent
initially  i attempt to achieve a lower power consumption via use of stochastic gradient descent to perform the
regression  sgd seemed an appealing choice due to the small cost of a single update to the hypothesis  indeed 
the number of fpu ops required is only about          if sgd could converge within    iterations  it could
possibly outperform the solution of the normal equations  this  however  proved to be unrealistic  the training
data proved to not be so weakly linear that convergence cannot occur in an efficient manner 

    batch gradient descent 
given the failure of stochastic gradient descent  i analyze batch gradient descent as well  however  i find that a
full sweep of the training set costs     million fpu operations  unlike for sgd  bgd converges on this training
set but only with very careful manipulation of the learning rate and a huge number of iterations  consequently 
bgd s energy demands are in great excess of those of the normal equations 

    alternatives to the kalman filter
as an experiment testing the framework  i attempt assess the power demands of a direct regression of cursor state
on neural observation  opposite to what the static phase of the kalman filter demands   given weak linearity of
the training set  i choose to evaluate an algorithm which captures additional patterns in the data  locally weighted
linear regression  i find that even for a greatly reduced training set  a single state prediction for lwlr takes more
than a billion operations  and corresponds to a huge power consumption  provided that one prediction must be
made every    ms 

fipower consumption for lwlr
   
   

power  w 

   
   
   
   
   
 
    

 k

  k

  k

  k

training set size

figure    power consumption for lwlr across various training set subsets     nm technology

  future work
while the integrated framework is already a useful tool  some additional work could be done to make its use even
simpler  primarily  the hand profiling to assess the memory footprint of the algorithm could be integrated  with
regards to the neural decoding problem examined here  additional regression techniques could be applied and
evaluated with the framework 

  conclusion
in increasing the power  ease of use  and portability of our original framework  i have created a useful tool for
those seeking to implement a learning algorithm on an asic with a power constrained application  given the
increasing deployment of embedded systems  and the large class of biomedical  battery operated  and other lowpower applications that can be imagined  this could be an extremely useful tool for those doing initial feasibility
studies for such a device  using the original form of this framework we have already shown that a brainimplanted neural decoding device is possible  and i have demonstrated how the expanded framework may be
applied to assess additional learning algorithms 

  acknowledgements
i would like to thank vikash gilja for his support and energy in allowing us to pursue this project  additional
thanks to christos kozyrakis for suggesting and advising the original project 

references
    v  gilja  towards clinically viable neural prosthetic systems  phd thesis  stanford unviersity       
    w  huang  s  ghosh  k  sankaranarayanan  k  skadron  and m  r  stan  hotspot  thermal modeling for cmos vlsi systems  in ieee transactions on
component packaging and manufacturing technology       
    l  sheng  mcpat  an integrated power  area  and timing modeling framework for multicore and manycore architectures  in micro            pages
             
    k  skadron  k  sankaranarayanan  s  velusamy  d  tarjan  m  stan  and w  huang  temperature aware microarchitecture  modeling and
implementation  in acm transactions on architecture and code optimization  pages        march      
    s  wilton  cacti  an enhanced cache access and cycle time model  in ieee journal of solid state circuits               pages              
    moore  s   terpstra  d   london  k   mucci  p   teller  p   salayandia  l   bayona  a   nieto  m      papi deployment  evaluation  and extensions   user
group conference        proceedings   vol   no   pp                 june     

fi