geometric understanding of indoor scenes
moontae lee
dept  of computer science
stanford university
moontae cs stanford edu

abstract
finding and recognizing objects are basic functions in
computer vision which can play fundamental roles in
various applications  as indoor scenes have high degree of
rigid structures  we study the problem of understanding
indoor scenes in terms of geometric clues inherent in each
image  since traditional  d detectors are highly sensitive
to changing of viewpoints and partial occlusion  we argue
how  d approaches can be utilized to improve the
performance of object localization and detection  starting
from an assumption that all objects are standing on the
floor  we first recover  d structures to assign a reasonable
three dimensional coordinates over the  d images  and
then slide  d windows having different scales over each
spatial area to localize their positions  we next evaluate
their visible faces by using histogram of oriented
gradients and self similarity descriptor features  and then
learn the classifier to detect sofa  table  and bed  finally 
we report the performance of our classifier and discuss
how these efforts can contribute to the problem of holistic
scene understanding  for the future works  we will hire
richer information considering spatial context and
interactions between objects 

   introduction
imagine you are walking to your room in the house at
night without using any light sources  all you can see are
only small part of wall edges and partial outlines of objects 
under this condition  you probably start to think that   
walls are running parallel to each other and orthogonal to
the floor     objects are standing on the floor and likely to
be aligned along walls     the door should be on the wall
because of your prior knowledge about the structure of
house  as a result  you can easily find your room though
you could see almost nothing  the interesting part is that
you are able to apply same processes to find objects even in
unfamiliar place  this is the power of geometric inference
that humans are easily able to do immediately 
while this inference is a natural process for humans  it is
not easy for machine to achieve the same information

because what machine had is only one single projection
image of a real scene  nevertheless  three assumptions     
   are still reasonable for machine setting because they are
physically valid in most indoor contexts  thus if we can
somehow figure out the original  d structures of each
projection image  we are able to infer geometric
information which could be largely utilized in finding and
recognizing objects 

     overview
in this paper  we first show that it is available to recover
 d structures from projection images to a certain degree by
finding the vanishing points information  and then we will
explicitly construct the plausible  d coordinates for the
given image in order to draw the  d box fitting to room
geometry  since pretty large objects are likely to be aligned
along wall directions and other objects along the large ones 
once we constructed the plausible  d coordinates  it means
that we can draw reasonable boxes for target objects in
many cases 
after  d reconstruction  we will formally generate a
number of  d windows to slide over the image space  thus
the collection of different  d sliding windows forms
hypothesis space in our setting  to evaluate the target
inside the current  d windows  we will score each visible
face by evaluating hog  histogram of oriented gradients 
and ssd  self similarity descriptor  feature  after scoring
each face independently  we will combine them as an
unified metric  as hog and ssd can be efficiently
computed on a rectangular region  we here rectify all the
visible faces 
however  it is still challenging to find how to improve
detection results by hiring spatial contexts similar to what
humans normally do through their general knowledge
about the indoor structures  to tackle this problem  we will
focus on two spatial interactions  interaction with other
objects  e g  relative distance and relative size  and
interaction with the room layout  e g  distance from the
bottom centroid to each wall   this is because  for example 
a table is more likely to be located in the middle of several
sofas or beside beds rather than just being alone aligned
along a wall  therefore we expect that learning a classifier

fitype   floor   center

type   floor   center
  right

type   floor   center
  left

type   floor   center
  left   right

type   floor   center
  right   ceil

type   floor   center
  left   ceil

type   floor   center
  right   left   ceil

type   two rights
 invalid 

figure    seven valid room layouts
with hiring these spatial features will cause similar effect
with finding some degree of general knowledge like    
which can be applicable in various other indoor scenes  in
other words  our approach is attractive because we can
reuse revealed knowledge as a prior for finding plausible
hypothesis  it will substantially reduce the size of
hypothesis space and contribute to improvement of
detection result in the same time 

     related work
in our work  finding the plausible  d geometries inside
 d image is the first task  to accomplish this goal  we are
recovering intrinsic and extrinsic camera parameters by
using the information of vanishing points  in the early
    s harlick     studied perspective transformation to
analyze  d location from  d image  in       as an
extension of      wang     tried to extract those parameters
in terms of vanishing lines formed by a rectangular
parallelpiped inside the image  in the early     s 
wilczkowiak     revisited similar approaches with     by
using more systematic ways  however  their calibration
methods given in     and     are both based on one
particularly shaped object inside the image whereas we
estimates vanishing points by collecting all of remarkable
straight lines given in the scene  this is the same approach
with the recent developments of wang     and hedau     
thus mainstream of our work is closely connected to two
works of hedau     and wang      starting from    s room
layout detection result  see the above figure     we will
accept similar assumptions to     in which they modeled
real world structures as the set of boxes  they assumed

that    all objects stand on the floor     each face of objects
are parallel to the walls  due to the first assumption  they
could decide the shape of box from fixing one of corners on
the floor as a reference point  the second assumption
means the orientation of objects are always aligned along
the wall direction  owing to this assumption  they can
uniformly rectify each face only through the information of
vanishing points  but  realistically  there are many cases
where the second assumption is violated whereas the first
assumption is largely valid  therefore  in this paper  we
adopt only the first assumption and loose the second
assumption by considering rotations on the floor   it means
we are no longer able to rectify visible faces only through
vanishing points information 
in addition to accepting previous assumptions  we put a
constraint that every wall should be appeared at most once 
for instance  type   in the above figure   is invalid because
of two right walls  recently  lee     introduced the concept
of indoor world model which is the combination of
manhattan world and single floor single ceiling  here
we employ much tighter constraints so as to neatly figure
out the spatial interaction with the room layout 
however  in contrast to      we are trying to detect more
than one object by hiring ssd features as well as hogs 
this is because  under the single target setting  it is difficult
to distinguish correct detection from correct localization 
detecting single large object such as bed is suitable only for
the previous assumption    which is not always true 
furthermore  the bigger target objects are  the harder we
can figure out the effectiveness of spatial interactions
because the most part of image is filled only by a single
object  therefore we will detect three frequently appeared

fiindoor objects  sofa  table  or desk   and bed in order that
they can reveal the power of general knowledge 

    d reconstruction
as an initial step  we find vanishing points which
implied the information of three orthogonal directions in
the world coordinate  this can be done by collecting
relatively long lines inside the image  and then find the
three dominant intersections  which can be placed outside
of the image plane  since finding vanishing points is not the
main purpose of our paper  we will not cover the exact
details  which can be easily found in     

     layout detection
our paper is starting from wang    s room layout
detection results given in the previous figure    it was done
by considering room clutters as latent variables and
learning discriminatively through structured svm  to
avoid terminology confusion  we call the room
configuration of wall and border as the room layout
instead of the box layout  this is because a box
represented a room in the paper     whereas we defined it
as cuboid like  d windows to be fitted for target objects 
to neatly sliding  d windows  the room layout should be
one of the seven predefined types given in the figure     e g 
if there are two right walls like type    then some  d box
near the upper right corner will invade wall areas 
furthermore  distances to each wall will play so
fundamental roles as spatial features in future that we
should know the exact positions of borders between walls 
thus we here detected the exact number of global
borderlines through both hough transform and
shi tomasi corner detection  and merge local borderlines
into global ones  after getting the proper number of global
borderlines  we re compute every corner by an average
intersection of three borders  finally we recognize
characteristics of borderlines  e g  the border between left
and center wall  by checking orthogonal direction around
the them in the room layout image  the following figure
shows the detected   borderlines 

     camera calibration
now we start to recover the camera parameters for the
full  d reconstruction  let the p be a  d homogeneous
pixel coordinates and p be the corresponding  d
homogeneous world coordinates  then projection between
two coordinates can be formalized by the following
equation 
p   k r    t p
 where  r   t   camera extrinsic matrix mapping world
coordinate to camera coordinate  k  camera intrinsic
matrix mapping camera coordinate to pixel coordinate 
since it is possible to arbitrarily fix the origin of world
coordinate  we can achieve the natural world coordinate by
setting t as a zero vector of no translation   i e  world
coordinate is centered at the optical center  which is a
camera center   if we assumes the zero skew and unit aspect
ratio  the projection equation will be given as below 


p   krp          
 
 

 

 


 
          
z
 

 where f  focal length  the distance between image center
and camera center   u   v    image center  the intersection
of principal axis and image plane  r i  i th column vector of
rotation matrix 
from the fact that vanishing points are the projection
result corresponding to the limit point of three orthogonal
directions in world coordinate  we can get the following
relations 
                                   
                                  
                                  
 where ei  i th euclidean basis in world coordinate  vi  i th
vanishing points in pixel coordinate  since  can be
arbitrarily fixed  we set its value as   for convenience 
by an orthogonality of basis directions  we can get the
following results 
                               
                               
                               

figure       detected borderlines for type   layout

 where r t and r   are cancelled each other because every
rotation matrix is orthogonal  since we knew the
information of three vanishing points  v   v   v    it is
available to uniquely determine three intrinsic parameters
 f  u   v   as closed form equations through the above three
equations 
after recovering the camera intrinsic matrix k  we are

fialso able to recover the rotation matrix r by the relations
we already revealed 
                      
                     
                     
if we merge the above three equations into a single
matrix form  we can easily get the rotation matrix r as a
closed form equation given in the following 

transformation from  d pixel coordinate to  d world
coordinate  and then normalize its height as    this is
because y coordinate of any points on the floor should be   
 see the figure    in after  these results will be utilized in
precisely formulating  d sliding windows with different
sizes at different position in the image space 
in case that there are two infinite vanishing points  one
horizontal and one vertical   it is impossible to recover the
focal length f analytically because it is infinite  to resolve
this problem  i manually set the focal length as      and
adjust the image center as the third vanishing point 

              k  v  k  v  k  v      

   features
 where v    v  v  v     the column wise collection of three
vanishing points vectors 
up to this point  we recovered all intrinsic and extrinsic
parameters by the closed form equations except the
translation vector  which was arbitrarily fixed at the camera
center  note that xy plane for camera coordinate has the
same orientation with uv image plane  and world
coordinate is centered at the camera center in our natural
coordinate of zero translation  see the following figure   
u
op

 u   v   f 
x
z

x

z

oc ow

v
y

y

figure     three coordinates systems

to evaluate each window hypothesis  we need a method
to score visible faces inside the given window  in order to
score each face uniformly  we rectify all visible faces  this
process substantially distinguishes our  d approaches from
the traditional  d detectors by the fact we can still evaluate
other faces even if the front face is occluded by other
object 
since we  in contrast to    s approach  did not assume
all objects are precisely aligned along wall directions  we
rectify visible faces by using  d information that we
recovered from the previous section  not only through
vanishing point directions  we then evaluate    
dimensional hog features and     dimensional ssd
features from each rectified face 

     image rectification
though parallel lines were not parallel anymore in the
image plane  they are still parallel in world coordinate 
since all camera parameters that we recovered allowed us
to fully reconstruct each image as  d scene  we are able to
find four ideal target points to which original skewed four
vertices of each face will be mapped  after then  we are
able to compute the homography matrix between pairs of
four points  it will provide the rectifying transform matrix 

 where uv  pixel coordinate  xyz  camera coordinate 
xyz  world coordinate   op  oc  ow   origin of three
coordinates respectively   u   v   f   the image center at
camera coordinate 
having these calibrated parameters  we can put
everything into the unified perspectives  in other words  if
we assume the camera height measured from floor is    the
unit length  world coordinates corresponding to points on
the floor in the image plane can be evaluated by the
following equation 
   
       
   
 where v   the vertical vanishing point  which could be out
of image planet  note that this equation means the inverse

figure     three visible faces for rectification
see the above figure    even if an object is covering the
front face of a bed  we can still evaluate the left and upper
faces by rectifying them  figure   in the next page is now
showing three rectified images and feature extractions 

fifigure     image rectifications and feature extractions   st row   hog   rd row   ssd 

     feature extractions
after rectifying visible faces  we resize each rectified
fragment to the   x   pixels square patch   if the size of
fragment is smaller than the patch  it will be extrapolated to
the given size by inter area interpolation  then we will first
compute the hog feature by dividing each patch into  x 
cells  where each cell has    orientation bins  thus the total
dimension of hog features is  x x          note that
hog features can be efficiently computed on a rectangular
region  this is also the reason why we are rectifying all
visible faces 
hog features are proven as good in the part based
model     because it is invariant to the change of lighting
and small deformations  and also showed fairly remarkable
performance on the previous paper      however  we also
introduce ssd features  which are strong local features 
this is because many indoor objects are of repeated
patterns on their faces  since we are focusing on both
localization and detections of three different objects 
introducing ssd features is reasonable for better detection 
to compute the ssd feature  we will follow the same path
suggested in the paper      here we computed ssd   times
as intervals of    pixels by sliding    pixels small patches
horizontally and vertically  each sliding will evaluate   
orientations with different four different radii  as a result 
we acquire   x x        dimensional ssd features 

the above figure   illustrates all features that we
extracted from each face  as we can observe in the first row 
hog grasp how strong each gradient direction is at the
given point in the image  whereas ssd catches the strong
orientation having similar shapes   white area means
strong similarity toward that direction 

   learning and analysis
in previous discussion  we divided our  d sliding box
into the set of visible faces  thus we trained the classifier
per each face and combine them to conclude the final
decision  we used   vs all svm with linear kernel using
the following number of positive and negative images 
face

  of positive   of negative
samples
samples
 
  
    
bed
 
  
    
 
  
    
 
   
    
table
 
   
    
 
   
    
 
   
    
sofa
 
   
    
 
  
    
figure     the number of positive   negative samples

finote that we used   vs all svm  which means all other
images are included as negative samples when we are
training a classifier for one object  the following table is
the training result 
face sv
precision
recall
 
   
      
      
 
   
      
      
 
   
      
      
 
   
      
      
table
 
   
      
      
 
   
      
      
 
   
      
      
sofa
 
   
      
      
 
   
      
      
figure     the training result  per face 
bed

   visual result
though we could not go further for lack of positive
samples  here we illustrate the good detection result  based
on some visual confirmation  we firmly believe if we
introduce more positive images  then the performance of
classifier beats traditional  d detectors 

as shown in the above table  the classifier achieves the
abnormal level of both precision and recall  it means there
are neither false positives nor false negatives  this is
mainly because we dont have enough number of positive
samples  based upon a visual confirmation  the current
classifier denies almost all hypotheses if they are not tightly
fit like manually constructed ground truth bounding boxes 
see the following testing result 
face sv
precision
recall
 
   
      
      
 
   
      
      
 
   
      
      
 
   
      
      
table
 
   
      
      
 
   
      
      
 
   
      
      
sofa
 
   
      
      
 
   
      
      
figure     the testing result  per face 
bed

though the entire precision and recall are slightly
decreased compared to the previous training result  they are
still too very high  this is because it is very rare to
encounter the right bounding box in current hypothesis
space  which is the collection of randomly generated
bounding box  in other words  the above testing result is
almost same with only denying classifier 
however it does not mean that the  d sliding structure is
meaningless  if a random hypothesis is luckily good
enough such like what humans drew  the classifier quite
surprisingly well localize the bounding box and detect the
object correctly  but  the problem is that most hypotheses
are negative sample even though we generated them very
carefully by fixing one point on the bottom 
 note that  since the result is too high  we did not try the
other kernel such as polynomial or rbf 

 note that all the above detection results were achieved
by generating more than      hypothesis per each image 

   conclusion and future works
using geometric information for object detections are
very promising in terms of its tight precision and ability to
evaluate not only the front face but also other visible faces 
in near future  we should first try more positive samples  at
the same time  figuring out how to make good hypothesis is
the most urgent issue to utilize this setting  after then we
can introduce spatial features that we originally designed 

fireferences
    v  hedau  d  hoeim  and d  forsyth  thinking inside the
box  eccv     
    h  wang  s  gould  d  koller  discriminative learning with
latent variables for cluttered indoor scene understanding
 eccv     
    v hedau  d  hoeim  and d  forsyth  recovering the spatial
layout of cluttered rooms  iccv     
    d  lee  m  hebert  t  kanade  geometric reasoning for
single image structure recovery
    r  haralick  using perspective transformation in scene
analysis  computer graphics and image processing      
    l  wang  w  tsai  computing camera parameters using
vanishing line information
from a rectangular
parallelepiped   machine vision and applications      
    m  wilczkowiak  e  boyer  p  sturn  camera calibration and
 d reconstruction from single images using parallelpipeds
    p  f  felzenszwalb  r  b  girshick  d  mcallester  d 
ramanan  object detection with discriminatively trained
part based models   pami          
    e  shechtman  m  irani  matching local self similarities
across images and video  cvpr      

acknowledgement
i started this project as the part of cs   a under the
supervision of professor daphne koller  however 
unfortunately  i have been struggled most parts of my
project by myself because this is the first trial of geometric
reconstruction  since i now established all the basic setting 
it will become worth topic to research  thanks for this
quarter and valuable advice 

fi