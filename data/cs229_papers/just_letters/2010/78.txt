cs     project  a machine learning framework for biochemical reaction matching

tomer altman      eric burkhart    irene m  kaplow    and ryan thompson 
 
stanford university    sri international
biochemical reaction databases capture the sum of human knowledge of biochemical reactions and chemical compounds  as the amount of data available on metabolic reactions and chemical substrates increases  the necessity of
central repositories increases as well  unfortunately  there is no established algorithm for being able to calculate the
degree of similarity between reactions in different databases  a set of features have been defined and were calculated for all pairs of reactions between the kegg and metacyc reaction databases  features include reaction name
match  tanimoto coefficient of the reactions in stoichiometric vector form  enzyme identifier matching  and enzyme
commission classification differences  logistic regression  non linear svm  nave bayes  and decision tree learning
methods were implemented  and feature selection  cross validation  k means clustering and other debugging methods
were applied to determine how to improve the algorithms and data  we conclude that decision trees and logistic
regression provide the most accurate methods  and the tanimoto coefficient is a key feature for the performance of
both learning methods 

   introduction

   features

biochemical reaction databases capture the sum
of human knowledge of biochemical reactions and
chemical compounds as found across a multitude of
organisms  and not one particular organism  as the
amount of data available on metabolic reactions and
chemical compounds increases  the necessity of central repositories increases as well  several encyclopedic repositories of metabolic network data have been
established over the years  including rhea    kegg   
and metacyc   
the problem is that  unlike with chemical compounds and polymer sequences  there is no established algorithm for computing the degree of similarity between reactions in different databases  without a means of comparing the contents of different
reaction datasets  there is no easy way to combine or
interlink these new bioinformatic data sources  we
have defined a set of features for comparing two reactions from different databases and have evaluated
them in the context of logistic regression  svm  nave
bayes  and decision tree classifiers 
in prior work    a set of features were defined and
calculated for all pairs of reactions between the kegg
and metacyc reaction databases  features include
reaction name synonym matching  cosine similarity
of the reactions in stoichiometric vector form  enzyme identifier matching  and enzyme commission
number match 

     feature details
here we briefly describe the set of features 

       reaction name matching
reactions either have a primary name and synonyms 
or names and synonyms can be derived by the associated enzymes that are known to catalyze the reaction  both an exact case insensitive string match
and the natural language processing capabilities of
pathway tools  for understanding enzymatic nomenclature have been utilized to find matching reaction
names 

       stoichiometry vector features
a chemical reaction can be represented as a vector by
having columns represent compounds  and by having
rows represent reactions  using the stoichiometric coefficient for the numerical values  if a compound is
not present in a reaction  it has a value of zero  one
measure of similarity of two stoichiometry vectors is
taken as the absolute value of the cosine similarity 
 
 
r
r
cos       r  kegg    r m eta     
kegg
m eta
biochemical reaction networks exhibit a smallworld network property    in other words  a small
fraction of the chemicals participate in a large number of reactions  this means that trivial participants
in reactions  such as nad  atp  water  and protons are weighted equally with more rare or signif 

fiicant reactants  in analogy to information retrieval
from documents  a inverse frequency scaling coefficient was applied to the values of the stoichiometry
vectors when calculating the cosine similarity 
in addition to the cosine similarity  we implemented features for the tanimoto coefficient  no
inverse frequency scaling applied   the number of
compounds in common between the two reactions 
the number of compounds in the metacyc reaction
that had links to kegg compounds  but not ones in
the given kegg reaction  the number of compounds
in the metacyc reaction that had no known link
to a kegg compound  the number of compounds in
the kegg reaction that had links to metacyc compounds  but not ones in the given metacyc reaction 
and the number of compounds in the kegg reaction
that had no known link to a metacyc compound 

       uniprot identifier match
uniprot  is the preeminent protein database  reactions either link directly to the uniprot entry representing the enzyme that catalyzes the reaction  or
the reaction is linked to a protein object that in turn
links to uniprot  two reactions that can be mapped
to the same identifier in uniprot are then catalyzed
by the same enzyme  and therefore are essentially the
same reaction 

       uniref   protein cluster match
uniprot provides the uniref    dataset  which includes proteins from uniprot clustered at     sequence identity or higher  proteins with this degree
of sequence similarity are typically functionally related  two reactions with enzymes within the same
uniref   cluster are thus likely to share the same
enzymatic function 

       biochemical pathway match
       enzyme commission hierarchy
the enzyme commission of the international union
of biochemistry and molecular biology  curates an
ontology of enzymatic activities  classes or instances in this ontology are assigned unique ec
numbers  this forms the back bone of many reaction databases  unfortunately  there are often duplicates of any given ec number  misannotations to
the close  but incorrect  ec number  or partial ec
numbers  we have used the ontology to compare reactions on the degree of similarity of their ec numbers  when present  the similarity was represented
both as a categorical feature  with values from zero
to four  representing how many levels of the hierarchy are shared   and as individual binary features
for each category  only one of the two forms  binary versus categorical  was included for any given
learning algorithm 
reactions that represent a reaction exactly as
the enzyme commission depicts them are termed
official ec reactions  variants of the official ec
reaction will have the same ec number  but will have
slight differences in the reaction equation  ec number matches for all four levels between official ec
reactions were provided as a separate feature 

a network of biochemical reactions form a biochemical pathway  kegg pathways tend to be ten times
as large as metacyc pathways  and thus a one to one
mapping between the two databases pathways is not
possible  related biochemical pathways between the
two datasets were determined  and pairs of reactions
were evaluated to determine if they are present in
related pathways 

       data completeness features
one of the characteristics of bioinformatic databases
is that the attributes of entries are inconsistently
populated with data  for example  even though a reaction may have a pathway attribute  some entries
might have zero  one  or more pathways populating
that attribute  when comparing two reactions to determine if they are a match  it is possible that both 
one  the other  or neither of the two reactions have
pathway information specified  if we report which
reaction pairs are within the same pathway  without
representing the situation where there was no match
possible due to one or both of the reactions missing
pathway links  then we are introducing a form of bias
into our training dataset 
we used four categories to represent missing

fidata  both     kegg only     metacyc only    
neither     we have created such status features
for sequence data  covering exact uniprot identifier
matches and uniref   features   stoichiometry vector features  and same pathway features  we did
not create a status feature for the name match feature  as the full set of attributes that the natural
language processing program utilizes is unknown 

     development of a gold standard
training set
in continuing work at sri international  ph d  biologist curators have reviewed matches made by a conservative ad hoc rule over the feature set  and have
identified true and false predictions  these manual assessments formed the gold standard training
dataset 
kegg version    and metacyc version      were
used in this project  metacyc version      contains
     small molecule reactions  and kegg version   
contains      small molecule reactions  data from
metacyc was extracted using the pathway tools
software  and data from kegg was extracted using
the biowarehouse kegg loader    
this leads to a potential dataset of over    million pairs of reactions  extracting features and analyzing a training dataset of millions of examples
proved to be too inefficient for generating results for
this project  additionally  the majority of the full
dataset contains millions of examples where there are
no non zero features  thus  we included a sampling
of the full space of reaction pairs  based on data content and curated match information  the final training dataset contained      examples and twenty one
features 

   utilized learning algorithms
     nave bayes with laplace
smoothing
we implemented nave bayes with laplace smoothing to classify metacyc and kegg reaction matches 
since the subset of ec number features are not
mutually independent  we used only the official
ec number level four feature  similarly  the subset of stoichiometry vector related features are also
not mutually independent  so we used only the num 

ber of compounds in the kegg reaction that did not
have a match in the metacyc reaction but did have a
matching compound in the metacyc database  since
      reaction pairs have a value of four or or less for
this feature  we binned the integer number of compounds by setting any value greater than four to four 

     logistic regression
we implemented logistic regression using the
newton raphson method and applied it to the training data 

     svm with radial basis function
we have used libsvm   to train a non linear svm
using a radial basis function kernel with an optimized
 
 value of      e uv   

     decision trees with gini coefficient
we used a decision tree program   to create a decision tree based on our features 

     k means clustering
a debugging technique based on unsupervised learning was utilized to locate sets of training examples
that had poor separation between positive and negative labels  the training dataset was stripped of
its labels  and several rounds of k means clustering
of the examples were performed for values of k ranging from   to      manual inspection of the resulting
clusters revealed five predominant clusters with more
than      examples  clusters with approximately
    positively labeled members were examined to
search for potential missing features that could be
added to better separate the clusters 

   results
we ran our learning algorithms with       hold out
cross validation to assess performance  the results
for the utilized learning algorithms are summarized
in table   
we ran nave bayes with     hold out crossvalidation for ten randomly partitioned sets  in order to determine the most significant features  we
ran nave bayes several times with different features
removed 

fitable   

learning method performance

method

mean training set error

mean test set error

most important feature

 nd most important feature

nave bayes
decision tree
logistic regression
svm

     
     
     
     

     
     
     
     

  mismatched compounds in kegg
tanimoto coefficient
tanimoto coefficient
tanimoto coefficient

ec match   official
ec match   official
ec match level  
ec match   official

the most useful feature for each of the ten decision trees tested was the tanimoto coefficient  the
top node of the decision tree always split on a threshold of the tanimoto coefficient   cosine similarity
and official ec number match level four features
were secondary in importance  always splitting nodes
at the second level of the decision tree 

fig    

learning curve for logistic regression 

the decision tree additionally shows evidence of
a variance problem  with the test error being twice
the size of the train error 

   conclusion
fig     receiver operator characteristic curve for decision
tree classifier 

points on an roc curve were plotted for each
leaf corresponding to a true match based on a decision tree trained on the entire dataset  figure    
many of the points being located in the upper left
corner  along with an auc value of       suggests
that our classifier performs well 
the logistic regression cross validation training
error mean was       with a standard deviation of
      and the test error mean was       with a
standard deviation of        the optimal  found
the had the following components with the largest
magnitudes        tanimoto score         ec match
         ec match          name match 
all of the classifiers had indications of high bias
in our learning problem  the logistic regression classifier was used to construct a learning curve  figure     which illustrates the bias 

     performance of learning
algorithms
nave bayes did not perform as well as the other
classifiers  this is possibly due to a violation of
the mutual independence assumption  another possible reason for the inferior performance could be
due to a suboptimal categorization of the integer and
real valued features  such as the tanimoto coefficient
and cosine similarity  alternative categorization approaches could be explored to attempt to improve
performance 
the decision tree classifier has the best performance  table    in terms of train error  in contrast
to other classifiers  its performance on the training
set was consistently better than its performance on
the test set  its performance may be explained in
part because the majority of our features are binary
or categorical 
the logistic regression classifier has the best performance in terms of test error  it also lacks the variance problem observed with the decision tree  indicating that it might be a more reliable classifier 

fithe superior significance of the tanimoto coefficient might indicate that the inverse frequency scaling applied to the cosine similarity was detrimental 
and may be analyzed in future work  the k means
clustering analysis also indicated problems with cosine similarity not differentiating properly between
positive and negative examples 
the machine learning framework approach
to the problem of matching biochemical reactions demonstrates an improvement over
the ad hoc rule previously implemented 
it
can be summarized as 
official ec match
  or  cosine similarity        and uniprot
link  or  cosine similarity        and name
match  
applied to the training set  the ad hoc rule has
an error rate of        every learning method attempted succeeded in surpassed the performance of
the ad hoc rule  with the best approaches reducing
the error rate by more than half 

     high bias problem
the small difference between training and test error
for logistic regression in figure   indicates the chosen
hypothesis has not over fit the data  the magnitude
of the errors indicate that the available features are
not sufficient and that we can benefit from finding
additional useful features 
a fundamental question is whether we have a
systematic bias in our training dataset due to the nature of evaluating pairs of entities  for two databases
with n reactions each  there are potentially order
o n     reaction pairs  with only o n   pairs being
true matches  this means that training on the full
set of pairs  or a random sampling of the pairs might
have one or more orders of magnitude in difference
between the number of positively and negatively labeled examples 
in our sampling of the o n     reaction pair
space  we specifically filtered out reaction pairs that
had no non zero feature values  this introduces another layer of bias 
as we discovered useful features  we found ways
to break up the feature into a number of more refined
features  this has incrementally improved the performance of our learning algorithms on our dataset 
future work will involve evaluation of classification
results to identify additional hidden features and re 

finement of well performing features 
we would like to acknowledge the work of dr 
ron caspi and ms  anamika kothari  who reviewed
predicted matches and curated our gold standard
training dataset with true matches and mismatches 
and helpful discussions on the work with dr  douglas brutlag  dr  peter d  karp  joseph m  dale 
and dr  luciana ferrer 

references
   rhea database  http   www ebi ac uk rhea 
   kanehisa  m   goto  s   furumichi  m   tanabe  m  
and hirakawa  m   kegg for representation and
analysis of molecular networks involving diseases and
drugs  nucleic acids res      d    d           
   caspi r  altman t  dale jm  dreher k  fulcher
ca  gilham f  kaipa p  karthikeyan as  kothari
a  krummenacker m  latendresse m  mueller la 
paley s  popescu l  pujar a  shearer ag  zhang
p  karp pd  the metacyc database of metabolic
pathways and enzymes and the biocyc collection
of pathway genome databases  nucleic acids res 
         database issue  d      
   altman t  biochem     final paper  large scale
alignment of encyclopedic metabolic networks 
      http   tinyurl com   cells
   karp pd  paley sm  krummenacker m  latendresse
m  dale jm  lee tj  kaipa p  gilham f  spaulding a  popescu l  altman t  paulsen i  keseler im 
caspi r  pathway tools version       integrated
software for pathway genome informatics and systems biology  brief bioinform       jan            
   barabasi al  oltvai zn  network biology  understanding the cells functional organization  nature
reviews genetics                  
   the enzyme commission   iubmb  enzyme
nomenclature  supplement    eur  j  biochem 
                   
   the uniprot consortium  the universal protein
resource  uniprot  in       nucleic acids res 
   d    d           
   suzek b e   huang h   mcgarvey p   mazumder
r   wu c h  uniref  comprehensive and nonredundant uniprot reference clusters  bioinformatics                    
    lee tj  pouliot y  wagner v  gupta p  stringercalvert dw  tenenbaum jd  karp pd  biowarehouse 
a bioinformatics database warehouse
toolkit  bmc bioinformatics       mar          
    chih chung chang and chih jen lin  libsvm
  a library for support vector machines       
http   www csie ntu edu tw  cjlin libsvm
    padoan  andrea  decision trees and predictive
models with cross validation and roc analysis
plot  http   tinyurl com   padwn       

fi