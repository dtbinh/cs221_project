semi supervised learning of named entity substructure
alden timme
aotimme stanford edu
cs    final project
advisor  richard socher
richard socher org

abstract
the goal of this project was two fold     
to provide an algorithm to correctly find
and label named entities in text  and     to
uncover substructure in the named entities
 such as a first name  last name distinction
among person entities   the underlying
algorithm used is a class hidden markov
model  chmm   a hidden markov model
with hidden states that emit observed
words as well as observed classes  this
algorithm is further bolstered by incorporating features into the model  substituting
the multinomial probability distributions
for transitions and emissions in the model
with the outputs of logistic regressions using the features 

 

introduction

named entity recognition  ner  is a task in natural language processing  nlp  which aims to identify entity types of interest in a collection of text 
for example  one might want to find entities corresponding to a person  per   location  loc   or organization  org   given a set of entity types  the
task of ner is to find and correctly label entities
of these types within text  and correctly label other
words as other  supervised training of a model to
perform ner gives the model a set of labeled training data and aims to learn enough to correctly label
entities on the test set  ner can be seen as a very
useful task because such entities are often some of

the most important words for determining the content of a document  as such  one of the obvious
goals of this project was to maximize the precision
and recall of ne assignments  precision is the accuracy of predicted entities  e g  the probability that an
entity labeled per is actually a person   and recall
is the ability to recognize an entity  e g  the probability that a person entity is actually labeled per  
the other goal of this project  and a different objective than other nlp algorithms that are used for
ner solely  is to see if the model could uncover
a latent substructure to the named entities encountered  that is  we wanted to see if the model would
be able to  for example  discriminate between the
first name and last name of a person while labeling
the entire entity as a person  and maybe even be able
to discriminate a third subset which corresponds to
an abbreviation of the first name  for instance  take
the person john ratcliffe  which could appear in its
full form as john ratcliffe or in other forms such as
john  ratcliffe  or j  ratcliffe  an idea of the project
was to see if the model could identify all occurrences
as per but also identify the differences in the words
that make up the same entity   i e  that j  and ratcliffe are two different parts of the same entity 
evaluation of the system is done on two different
data sets  they are the conll      english ne
data set   and the muc   english ne data set     labeling and evaluation of the ner task requires that
the system correctly determines the entities types as
well as their start and end boundaries 
 
 

www cnts ua ac be conll     ner 
www nlpir nist gov related projects muc proceedings muc   toc html

fi 

the model

the basic model used for the project is a class hidden markov model as proposed in krogh         to
supplement the ability of the chmm as a ne classifier  we then incorporate features in the model using
the same system as berg kirkpatrick  et al        
   

 named entities  are then deterministically given by
the state assignments 
   

feature enhanced chmm

class hidden markov model

figure    the graphical structure of a class hidden
markov model for ner  in which classes and words
are observed 
this is a hidden markov model where there are
two observed states for each hidden state  in particular  these observed states are the words of the text
and the classes of entity to which they belong  in reality  a chmm can be thought of as a regular hmm
which emits a pair of values  however  thinking of
it as a model with two separate emission types helps
for inference  in which only the words are observed 
one can either allow a probability distribution over
classes for each state or assign a class deterministically to each state  in this project we make the
simplifying assumption that each state is assigned
to only one class  we also assign the same number
of states to each entity type  including other 
learning and inference with a chmm is done
in much the same way as with a normal hmm  in
the learning period we wish to determine the transition and emission probabilities given the observed
classes and words  this is done via a modified version of the forward backward equations using the
training data  with the one class per state assumption  this amounts to finding looking at only valid
paths through the model  where valid paths are those
where the state labels agree with the observed class
labels 
inference on the test data is then done simply by
performing the standard viterbi algorithm to find the
hidden states given the observed words  the classes

figure    feature enhanced class hidden markov
model for ner  where transitions and word emissions are feature based  with features f and featureweights   superscript  t  denotes transition features and weights  and superscript  e  denotes emission features and weights 
the feature enhanced class hidden markov
model makes use of word features to enhance the
performance of the chmm  the idea for feature
incorporation comes from berg kirkpatrick et al 
        in which each component multinomial of the
model become the outputs of local multi class logistic regressions  that is  the transition probability between two states y and y   and the emission probability of word x from state y are given by  respectively 
exp

p y    y   t    f  t     
p

y   

p

x 



 t   t 
 
i i fi  y  y  

exp

exp

p x y   e    f  e     

p

p

p

exp

 t   t 
  
i i fi  y  y  
 e   e 

i i fi  y  x 

p





 e   e 



 
i i fi  y  x  

where superscripts  e  and  t  correspond to emission and transition features and weights 
given a normal prior on the feature weights  we
get the regularized log likelihood of the observed
data as
l     log p  x   x  c   c   f          
where x and c are the word and class sequences 
in order to find the optimal feature weights   we
optimize the regularized log likelihood by direct
gradient ascent using any hessian free optimizer  in
this case  lbfs   in order to climb l  we need a
formula for its gradient  however  it turns out that

fifeature
onedigitnum
twodigitnum
  fourdigitnum
 
x
x
ay y   f  y  y      yeardecade
ey y  f  y  y     
    e   
containsdigitanddash
z   
y y  
 
 
containsdigitandoneslash
x
x
by x  f  y  x   
 
ey x f  y  x  
containsdigitandcomma
y x
x 
containsdigitandperiod
  
allcaps
capperiod
where
capotherperiod
capperiods
 
 t   t 
ay y    p y  y     f  
initialcap
by x   p x y   e    f  e   
its gradient is equal to the gradient of the regularized
expected log likelihood 

as computed above  and ey x   ey y  are the expected
counts of the number of emissions of word x from
state y and the expected number of transitions from
y to y     these expected counts are calculated
through the modified viterbi algorithm where only
valid paths are considered  at e   e     
     e         l  
so we can use this gradient for the direct gradient ascent optimizations  recalculating e   at every step 

 

results and evaluation

we ran the model on two well known ner data
sets  the conll      english data set and the
muc   english data set  the conll data set has
four different named entities  location  loc   miscellaneous  misc   organization  org   and person  per   as well as the other  o  class  the
muc   data set has seven different entities  date
 date   location  loc   money  money   organization  org   percent  percent   person  person   location  loc   and time  time   along with
the other  o  class  results for each entity type  and
all entity types  are measured in terms of precision 
recall  and f   
precision 
recall 
f   

tp
tp   fp
tp
r 
t p   f n 
p r
f     
p  r
p  

example
 
  
    
    s
     
   
      
     
ibm
j 
st 
n y 
ratcliffe

explanation
number
year
year
decade
date
date
money
money percent
organization
name abbr 
location abbr 
loc or org
capitalized

table    features used for the feature enhanced
model on the muc   data set 

where t p is the number of true positives  correct
classifications   f p is the number of false positives
 incorrectly classified the entity as its type   and f n
is the number of false negatives  incorrectly classified entity as not its type  
for each data set  the model was first run without features  where the only features are the basic
features  a basic feature is the baseline in which the
only feature for a word is the word itself  this corresponds to what is the original class hidden markov
model without any features  for all models  the only
features used for transitions are the basic features 
since there do not seem to be any notable features of
states that would help with classification 
runs were then done with features  for the
conll data set  i used two different feature sets 
one feature set only includes two features      all
letters in a word are capitalized  and     the initial letter is capitalized  the second feature set was
the word shape  where there are only three word
shapes      all letters are capitalized  xx       only
the first letter is capitalized  xx   and     all letters
are lower case  xx   the muc   data set featureenhanced runs incorporated many more features  table     culled from zhou         figure   shows the
f  scores for the basic and feature enhanced runs on
the conll data set and muc   data set with different values of the regularization parameter  and
different values for the number of states per class

fispc
 
 
 
 
 
 
 
 
 

type
basic
capitalization
word shape
basic
capitalization
word shape
basic
capitalization
word shape

loc
      
      
      
      
      
      
      
      
      

misc
      
      
      
      
      
      
      
      
      

org
      
      
      
      
      
      
      
      
      

per
      
      
      
      
      
      
      
      
      

overall
      
      
      
      
      
      
      
      
      

table    f  scores for best regularization parameter           on conll data set with different feature
sets  spc is the number of states per ne class  
spc
 
 
 
 
 
 

type
basic
features
basic
features
basic
features

date
      
      
      
      
      
      

loc
      
      
      
      
      
      

money
      
      
      
      
      
      

org
      
      
      
      
      
      

percent
      
      
      
      
      
      

person
      
      
      
      
      
      

time
      
      
      
      
      
      

overall
      
      
      
      
      
      

table    f  scores for best regularization parameter           on muc   data set with and without features
 spc is the number of states per ne class  
 spc   tables   and   contain the results in terms
of f  scores for the conll and muc   data sets
respectively 

 

figure    f  scores on the conll data set  top  and
muc   data set  bottom  with different feature sets
and different numbers of states per ne class 

conclusion

as can be seen fairly obviously from figure   and
figure    incorporating features helps quite a bit 
with both data sets  the f  scores are considerably
lower when the model considers only the basic features  unfortunately  however  there does not seem
to be anything added by the class hmm for the
conll data set  having one state per class almost
always does best  suggesting that a feature enhanced
regular hmm would do better than a class hmm
with a number of states per class  the muc   data
set does benefit from including a number of states
per class  however  the observation on the conll
data set also suggests that the chmm does not exploit a substructure to the named entities  and 
in fact  from analysis of the inference on both the
conll and muc   data sets  i cannot find any evidence of the model finding a substructure within the

finamed entities it classifies 
the model also does not do a very good job on the
ner task itself  falling well short of state of the art
numbers  which have f  scores around      for the
conll data set and      for the muc   data set 
perhaps including more features would help  but i
do not think that better features would account for a
        jump in f   

references
anders krogh        hidden markov models for labeled sequences  proceedings of the   th iapr international conference on pattern recognition  los
alamitos ieee computer society press  california 
guodong zhou and jian su        named entity
recognition using and hmm based chunk tagger 
proceedings of the   th annual meeting of the association for computational linguistics  pages         
philadelphia  pa  july      
taylor berg kirkpatrick  bouchard cote alexandre 
denero john  klein dan        painless unsupervised learning with features  the      conference
of the north american chapter of the acl  pages         los angeles  california  june      

fi