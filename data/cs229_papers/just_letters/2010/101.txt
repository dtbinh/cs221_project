 

parallelizing machine learning algorithms
juan batiz benet

quinn slack

matt sparks

ali yahya

 jbenet   sqs   msparks   alive    cs   stanford   edu
abstractimplementing machine learning algorithms involves of performing computationally intensive operations
on large data sets  as these data sets grow in size and algorithms grow in complexity  it becomes necessary to spread
the work among multiple computers and multiple cores 
qjam is a framework for the rapid prototyping of parallel
machine learning algorithms on clusters 

i  introduction
many machine learning algorithms are easy to parallelize
in theory  however  the fixed cost of creating a distributed
system that organizes and manages the work is an obstacle
to parallelizing existing algorithms and prototyping new
ones  we present qjam  a python library that transparently parallelizes machine learning algorithms that adhere
to a constrained mapreduce model of computation 
ii  previous work
significant research has been done in the area of distributed data processing  perhaps the most notable
and relevant contribution is the mapreduce programming
model      which applies the map and reduce functions
from functional programming to large datasets spread
over a cluster of machines  since their introduction  the
mapreduce concepts have been implemented in several
projects for highly parallel computing  such as apache
hadoop     
chu et al      show how ten popular machine learning algorithms can be written in a summation form in
which parallelization is straightforward  the authors implemented these algorithms on a mapreduce like framework and ran them on multicore machines  they yielded a
near linear speedup as the number of cores was increased 
whereas chu et al  experimented on single multicore
machines  our project extends their ideas to a cluster of
networked computers  rather than use a framework like
hadoop      which is intended for large batch processing
jobs  we have designed and implemented a lightweight
framework for low latency tasks that requires minimal
server configuration 

a  code style
r is stylistically very similar to matlab  matrix and
list operations are first class operations  and it provides
built in equivalents to most of matlabs probability and
statistics functions  also  the r interpreter makes plotting
and visualizing data structures just as easy as in matlab 
while pythons syntax is less suited for matrix operations  the numpy package for python     includes matlib 
an interface that attempts to emulate matlabs syntax 
it is designed specifically for matlab programmers and
to ease the porting of matlab code  certain syntactic
elements are still overly verbose  e g   m transpose   vs
m  and may hinder the readability of an algorithm 
strictly from a syntactic and stylistic perspective  r
wins on its simplicity and similarity to matlab  however  pythons slight disadvantage here is far outweighed
by its relative performance  as described below 
b  performance
python is not a mathematical language  but it is easily extensible and provides many high quality mathematics packages  numpy in particular   though interpreted 
python can easily call down to c and avoid dynamiclanguage overhead in computationally intensive operations  for instance  numpys matrix multiplication is implemented in c  yielding very good performance without
sacrificing ease of use or readability in the python code 
we benchmarked the performance of r against pythons
 using the numpy package  
in order to avoid
implementation  or algorithm specific bias  we decided to
benchmark the common linear algebra functions  such as
matrix multiplication  that are ubiquitous in learning algorithms 

iii  choosing a language

table i shows the running times of python and r on
various operations using different matrix or vector sizes 
as well as the time ratio of p ython r  every test ran
       operations  in terms of performance  python is the
clear winner  it outperforms r in every case  most of the
cases by an order of magnitude  in the worst case  python
takes     of the time that r takes 

our two criteria for language choice were ease of development and good support for linear algebra operations 
c   is known to provide excellent performance  but it
is not conducive to rapid prototyping  matlabs licensing costs make it infeasible for use on large clusters  we
evaluated python and r as possible options 
the following sections compare python and r and explain why we chose python 

although nave python implementations of serial machine learning algorithms tend to be slower than their
matlab equivalents  recent benchmarks of the parallel sparse autoencoder show that pythons performance
penalty is not as significant in parallel execution as it is
amortized over the number of workers  also  since we are
targeting rapid prototyping  not peak production performance  a small performance hit is acceptable 

fi 

size
  
  
   
   
   

matrix multiplication
python
r
python   r
      
      
      
      
      
      
      
      
      
      
      
      
               
      

element wise matrix multiplication
size python
r
python   r
   
             
      
   
             
      
   
             
      
   
             
      
   
             
      

machines  one remoteworker has a single target
machine that can be reached via ssh  there can be
many remoteworkers with the same target  say  in
the case where there are many cores on a machine  
but only one target per remoteworker  at creation 
the remoteworker bootstraps the remote machine by
copying the requisite files to run the worker program 
via ssh  after the bootstrapping process completes 
the remoteworker starts a worker process on the remote machine and attaches to it  the remoteworker
is the proxy between the master and the worker 
master  the master is a python class that divides
up work and assigns the work units among its pool
of remoteworker instances  these remoteworker
instances relay the work to the worker programs
running on the remote machines and wait for the
results 

size
  
  
   
   
   

matrix transpose
python
r
python   r
             
      
             
      
             
      
             
      
             
      

figure   shows the communication channels between
components on multiple machines 

size
    
    
    
    
     

vector inner product
python
r
python   r
             
      
             
      
             
      
             
      
             
      

master

qjam library

library
master

table i
benchmarks of python and r for linear algebra operations 

worker  

remoteworker
remoteworker
slave
slave
slave

worker  

iv  architecture

worker  

remoteworker

worker  

this section describes the architecture of the qjam
framework  subsection a defines the major components
of the system and how they communicate with each other 
subsection b explains the programming interface  subsection c describes the protocol that qjam uses to communicate  finally  subsection d describes details of qjams
python implementation 

remoteworker

remoteworker pool
corn  

corn  
localhost

fig     master controlling four remoteworkers with workers in two
machines 

a  components

b  qjam library api

qjam is a single master distributed system made up of
instances of the following components 

this section describes the interface exposed by qjam
and provides a simple example of its use  the workflow of
a typical distributed computation on qjam is divided into
two phases  in the initialization phase  the client creates
an instance of the master class by passing its constructor
a list of remote workers  in the execution phase  the client
specifies a python module containing a function  mapfunc 
to be executed on each worker along with a dataset and
a list of parameters for the computation  the framework
then breaks the dataset into smaller pieces and distributes
the work to the worker processes  the following two sub 

worker  the worker is a program that is copied to
all of the remote machines during the bootstrapping
process  it is responsible for waiting for instructions
from the master  and upon receiving work  processing
that work and returning the result 
remoteworker  the remoteworker is a special
python class that communicates with the remote

fishort names  parallelizing machine learning algorithms

sections elaborate on the details 
b   initialization
at a fundamental level  the qjam library is built on top
of the remoteworker class  an instance of remoteworker
defines a single connection to a worker node  a collection of remoteworker objects is passed to the constructor
of master to define the pool of workers available to the
master 
the following code demonstrates the initialization of the
worker pool and master 
workers    remoteworker corn   stanford edu  
remoteworker corn   stanford edu  
remoteworker corn   stanford edu  
master   master workers 

b   execution
once the list of remoteworkers and the master have
been initialized  the client must first wrap any static data
into a dataset object  and then it can issue a call to
master run      to distribute the computation  results
of the work are obtained through the return value of this
call 
b   a creating a dataset object  in order for master to
know how to partition the task data between the registered
remoteworkers  it needs to have some notion of how the
data is structured  in order to fulfill that requirement  the
client can either resort to one of the convenience dataset
classes provided by qjam  or define a custom data class
that inherits from basedataset 
the dataset classes provided by qjam include support for python tuples or lists of any kind  or numpy
matrices 
in the case the client wishes to represent the data as a matrix  he can choose between
numpymatrixdataset  which simply represents the matrix in memory  or numpymatrixfiledataset  which represents the matrix as a file on disk in the case that it is too
large to fit in memory 
in the case that the client wishes to define a custom data
set class that inherits from qjams basedataset class  he
must implement at least the following two member functions 
   chunks   returns the number of chunks into which
the internal data can be divided 
   slice index  returns the slice of data at the given
index where index is an integer in     chunks       
b   b defining a code module  the code that is to be executed at each remote worker must be written by the client
in a self contained python module  the module must contain a function called mapfunc that will be called by the
framework  the function mapfunc must take two arguments  the first argument are the parameters    passed
by the client in the call to master run   can be of any
type and is passed  without modification  to every remote
worker  the second argument of mapfunc is a subset of
the dataset created by the client as described in section
b   a  note that qjam guarantees that different workers
will receive different  non overlapping subset of the data 

 

the client also has the option of defining a reduce function as part of the same module  if the client opts out of
this option  then the return value of mapfunc must be of a
type that defines the sum operator or a list of types that
define the sum operator  more complex return values are
possible if the client defines a custom reduce function 
a simple mapfunc might be defined as follows 
def multiply sum theta  dataset  
return sum  theta   x i for x i in dataset  
mapfunc   multiply sum

b   c calling master run 
once the code module and
the dataset object have been defined  the client can make
a call to the function master run to distribute the computation  the master run function takes the client defined
code module  the parameters  and a dataset object as arguments  the return value of master run is the result of
the computation 
the following simple example shows a call to
master run 
from examples import multiply sum
params     
dataset   listdataset range         
result   master run multiply sum  params  dataset 

c  protocol
communication between the qjam master and each of
the workers occurs via a connection that is persistent
throughout the existence of the master object  this section describes the details of the communication protocol
that is used by our implementation to assign tasks to remote workers  efficiently distribute data  and coalesce results 
the protocol implementation relies on five different
types of messages  figure   shows the use of those messages in a typical communication workflow 
c   task message
the task message type is sent by the master to each
worker to initiate a task  it contains an encoded  representation of the clients code module  a hash of the chunks
that compose the workers assigned dataset  and an encoded representation of the client specified parameters 
c   state message
upon receiving a task message  the worker must respond with a state message  this message contains a
status field that can take one of two values  running
or blocked  in the case that the status field is set to
blocked  the worker must include a separate field whose
value is a list of hash values where each hash value identifies a chunk of the dataset that the worker is missing 
  objects are encoded using a base   representation of the serialized python object 

fi 

master

worker

task

state    blocked 

refs

state    running 

d   automatic bootstrapping
an important design goal for qjam is to make the execution of a distributed computation as easy as possible 
to that end  our implementation strives to minimize the
amount of setup necessary on each worker machine  qjam
has the ability to transparently bootstrap each remote
worker with all of the code it needs to communicate with
the master  after initiating an ssh connection to a worker 
the master sends a source code of the worker protocol implementation and remotely executes it on the worker node 
this allows any computer with python and an ssh server
to serve as a remote workerno manual setup required 
v  evaluation

result

we benchmarked the framework running various algorithms with multiple workers 
a  l bfgs sparse autoencoder

fig     communication between master and a single remoteworker
during the execution of a typical qjam distributed computation

c   refs message
if the master receives a state message whose status is
set to blocked  then it responds with a refs message 
this type of message includes a list of encoded objects that
correspond to the data chunks that the worker identified
as missing 
c   result message
finally  the result message is sent to the from the
worker to the master whenever it completes its task  this
message contains an encoded representation of the computations result 
c   error message
in the case that the worker encounters an unexpected
state  it can send an error reply to any message sent by
the master  this message contains a description of the
error 

we benchmarked qjam using a sparse autoencoder with
l bfgs      a sparse autoencoder is an unsupervised
learning algorithm that automatically learns features from
unlabeled data  it is implemented as a neural network
with one hidden layer  parameters  that adjusts its weight
values at each iteration over the training set  l bfgs is
a limited memory  quasi newton optimization method for
unconstrained optimization 
we benchmarked the running time of the sparse autoencoder using a parallelized cost function  with l bfgs optimizing it   we tested a regular single core implementation
against          and    workers over four multicore machines  we tested with three datasets  of                and
        patches each   table ii summarizes per iteration
results  while table iii is the sum of all iterations plus the
masters setup overhead 
workers
 
 
 
 
  

 k
           x 
           x 
           x 
           x 
           x 

  k
           x 
           x 
           x 
           x 
           x 

   k
            x 
           x 
           x 
           x 
           x 

table ii
iteration mean time  seconds 

d  feature highlights
d   remote data caching
one important feature of qjam is caching of data by each
remote worker  the master initially sends each worker a
list of the hash values of each data chunk that the worker
will need for a given task  if a worker cannot find the data
object that corresponds to one or more hash values  it requests them from the master and caches them  in later
iterations  the master can take advantage of data locality by assigning workers data chunks that they have seen
before 

workers
 
 
 
 
  

  
  
   
   
   

 k
    x 
    x 
    x 
    x 
    x 

  k
        x 
        x 
        x 
        x 
        x 

   k
         x 
         x 
         x 
        x 
        x 

table iii
total running time  seconds 

for the large job     k   qjam performs better than the
single core every time  as seen in figure   a   the running

fishort names  parallelizing machine learning algorithms

total running time speedup
 k
 
  k
   k
 
singe core

speedup  times faster 

 

 

 
 
 
 
 

 

 

 
 
workers

  

per iteration vs total speedup
per iteration
 
total time

speedup  times faster 

 
 

 
 
 
 
 
 

 

performance and reliability under high stress  moreover 
having more data about qjams performance would more
clearly reveal whatever bottlenecks remain 
with regard to features  another important step is to
achieve feature parity with other  more general parallel
frameworks  e g  mapreduce   handling worker failures 
anticipating stragglers  and using a smarter job scheduling
algorithm will likely yield performance improvements  particularly when running on larger or heterogeneous clusters
than those we tested on 
we currently use ssh and json to transfer data and
messages  using a more efficient protocol and data encoding will improve performance and reliability  we noticed that ssh occasionally dropped connections and implemented a workaround to automatically reconnect upon
failure  this  however  remains the biggest source of instability on qjam 
finally  aside from implementation related improvements  we will also improve usability  as a start  we can
offer a wider range of convenience dataset subclasses
beyond those that encapsulate matrices and lists  e g   imagedataset  audiodataset  
vii  conclusion

 

 

 
 
workers

  

fig     a  total running time speedup  b  per iteration and total
speedups     k patches   per iteration times reflect only client code 
whereas total times incorporate the masters coordination overhead 

times show a significant speedup when using qjam with
multiple workers  in particular  the    worker trial saw
a speedup of over   times the single cores running time 
comparing the speedups observed per iteration against the
total running time of this trial  figure   b   reveals that
the master overhead is very small  yielding no significant
slowdown 
the non intensive job    k  saw a small increase in performance  but not significantly  for the smallest  trivial
job   k   the overhead of coordinating many workers with
very little to compute drove the performance below that
of the single cores implementation  just as expected 
a particular number of workers seems to be suited for
a particular job size  for the   k patches trials  the best
run was that with   workers  the others performed worse 
though still most performed better than the single core 
for the largest job  though the    worker runtime was the
lowest  the savings from   workers to    were proportionally small  requiring twice the number of workers for  x
more  this further confirms that in order to minimize the
overhead of distributing the job  the number of workers
should be picked according to the job size  further research
should explore various job sizes with different worker pools 
vi  future work
the next logical step in the development of qjam is running more benchmarks with significantly larger datasets
and more iterations  it is important to observe qjams

we have presented a framework that greatly simplifies
the rapid prototyping of distributed machine learning algorithms  qjam provides an abstraction of the complexities
associated with building an entire distributed system just
to run a task on multiple computers in parallel  as a result 
it is now possible rapidly prototype and execute distributed
computations without having to explicitly manage communication overhead and the distribution of code and data to
remote workers 
moreover  qjam offers satisfactory performance  on a
computation that takes a mean of    seconds to complete
on a single machine  we observed  x speed up on   workers
and  x speedup on    workers 
viii  acknowledgements
we would like to recognize the assistance of those in
our cs     class research group  prof  andrew ng  adam
coates  bobby prochnow  milinda lakkam  sisi sarkizova 
raghav pasari  and abhik lahiri 
references
    jeffrey dean and sanjay ghemawat  mapreduce  simplified data
processing on large clusters  in proceedings of the  th conference
on symposium on operating systems design   implementation
  volume    berkeley  ca  usa        pp        usenix association 
    apache hadoop  http       hadoop   apache   org  dec      
    c t  chu  s k  kim  y a  lin  y y  yu  g  bradski  a y  ng 
and k  olukotun  map reduce for machine learning on multicore  in advances in neural information processing systems
    proceedings of the      conference  the mit press       
p      
    scientific computing tools for python  numpy  http      
numpy   scipy   org   dec      
    dong c  liu and jorge nocedal  on the limited memory bfgs
method for large scale optimization  mathematical programming  vol      pp                        bf         

fi