twitter relevance filtering via joint bayes classifiers
from user clustering
alexander l  churchill

emmanouel g  liodakis

simon h  ye

achur stanford edu

liodakis stanford edu

sye stanford edu

dec          

 

introduction

the task of classifying feed item data  such
as email or rss items  has been a subject
of proposed learning algorithms since the
mid     s  unlike spam classifiers  relevance classification cannot use a universal
training set  but rather must be trained
by each individual user  however most relevance classifiers use an approach similar
to spam classifiers  most research in relevance classification has employed a classifier over an individualized training set 
usually one of a nave bayesian classifier 
support vector machines  or neural network 
case based  or knowledge based approaches
         however  in practice  few of these
algorithms have been implemented  and
those that have enjoy only limited success 
in large part  this is due to common user
expectations with regard to classification
accuracy  users tolerate few errors and
expect immediate results     
the past few years have seen a radical
shift in the way users consume data  in
particular  services like twitter have dramatically increased social feed consumption  this poses the opportunity to build
implicit social graphs to improve the quality of relevance classification over smaller

training sets  in this paper  we examine the use of hierarchical clustering on
twitter users to build these implicit social
graphs and to then use the multinomial
bayesian classification approach over the
augmented training sets to do tweet relevance classification  in this way  we leverage the power of social feeds to improve
the quality and training speed of individualized relevance classifiers 

 

dataset description

the dataset consisted of approximately      
tweets curated from    of the most influential users on twitter based on number of
followers  this consisted mostly of celebrities  comedians  heads of state  and prominent news sources  the distribution was
roughly even so approximately    tweets
were gathered per tweeter  the user ratings were performed by    users  with each
person rating approximately     tweets randomly sampled from half of the users in
the dataset  totaling approximately       
tweets  all ratings were performed in a
binary manner for which the user either
liked or disliked the tweet 

twitter relevance filtering via joint bayes classifiers from user clustering 

 

fi 
   

algorithm description
data preprocessing

the textual content for each tweet was tokenized through a multistage process  all
urls were first parsed from the tweet and
normalized to the base domain name of
the linked to site  bit ly links were also
followed through and the resulting url was
also stripped to the base domain name 
to process the textual content  all punctuation was stripped from both sides of
words while all casing was converted to
lowercase  tokenizing was performed using whitespace as a delimiter  each token
was then stemmed using the porter stemming algorithm to conflate differently suffixed versions of the words into stemmed
tokens  finally for each tweet  a metatoken was added to indicate the author
of the tweet  all of the tweets were then
processed for the most significant bigrams
according to chi squared significance  of
which the most significant     bigrams were
also added to the token dictionary  tweets
were also processed similarly for training
and testing phases of the classifier 

   

hierarchical clustering

hierarchical clustering progressively clusters data points by taking the two closest training examples and placing them
as sibling nodes in a tree  these cluster
centroids are then reweighted to represent
consituent training examples before making the next clustering assignment  twitter users are represented as sparse vectors
in n dimensional space  where n is the total number of tweets  each element of the
vector takes on a three values           
where    corresponds to disliking a tweet 
  for no answer  and   for liking a tweet 

users are clustered using the jacard distance 

   

multinomial bayesian classification using clustering
results

multinomial bayesian classifiers are a set
of discriminative algorithms that predict
the probability of classifying a tweet as either    or   based on its features by using
bayes rule and calculating the predicate
probability of each feature qualified on the
rating of its tweet and the predicate that
the feature exists in the tweet  which can
be easily calculated with one pass through
the data 

   

mathematical description
of algorithm

given a training set 

 x  n    y  n           x  n    y  n   
where each x  i  is a vector of tweets and
each y  i  is a vector of their corresponding
ratings r          we let w    w         wp  
be the set of all words in the training set 

twitter relevance filtering via joint bayes classifiers from user clustering 

 

fip p
p p
 i 
 i 
for each  x  i    y  i     define j   nk   j   x  i   y  i      and define j   nk   j   x  i   y  i       
the multinomial bayesian classifier applied to a single  x  i    y  i    yeilds 
 i 

 i 

 i 
p  yk

    wj 

 i 
xk  

j

 

 i 

 i 

and

j   j

 i 
p  yk

    wj 

 i 
xk  

 

j
 i 

 i 

j   j

so we derive that
 i 

p  wj  yk     p  y  i      
 
q
 i 
    p  y  i         wj x  i  p  wj  yk     p  y  i      
q

 i 

p  y 

 i 

wj xk

 i 

    x      q

 i 

 i 

wj xk

p  wj  yk

k

additionally  given our data set  we can calculate our sample expected value to estimate
our expectation
 i 

 j 

e   p  y   y     

 x
 j 
 i 
 j 
 i 
p  yk     yk    p  yk     yk  
k k

which we can estimate using f     j z  i    z  j     where j is the jacard distance  i e   we
estimate
p
 
  y  i   y  j   
k
 i 
 j 
k
k
 
e   p  y   y      aij    f p
 
k  y  i      and y  j      
k

k

where f                  monotonically  however  sample expected value is highly subject to outliers  to mitigate this issue and to estimate the values for f   we hierarchically
cluster the users using the jacard distance and let f     for i and j in the same cluster
and let f     elsewhere  note that aii     
therefore  we estimate
p  yn i      p

  x
aij p  yn j      xn j    
a
j ij j

in practice  we use log liklihood     and laplace smoothing to classify by selecting the
larger of 
x
 i 
 i 
 i 
log p  yk     xk     log p  yk       
log wj  y  i       and
 i 

wj xk
 i 

 i 

 i 

log p  yk     xk     log p  yk       

x

log wj  y  i      

 i 
wj xk

p

where wk  y  i      

p

 j 

aij k   
p  j 
j aij
h h  p
j

p

and wk  y  i      

p

 j 

aij k   
 
p  j 
j aij
h h  p
j

twitter relevance filtering via joint bayes classifiers from user clustering 

 

fi 

experimental proceedure

testing was performed using k folds cross validation running our algorithm on the dataset
for k               to predict the tweets for an invidual user  holding fixed and training
on the values of the other users for clustering purposes   we ran our algorithm using
cluster sizes of              and     for a control set  we also ran the same experimental
proceedure using the stock bayesian classifier in the nltk toolkit 

 

results

in comparison with the nltk nave
bayes  our algorithm outperformed the
toolkit in positive precision         to
         in positive recall         to
         and negative precision        
to          while the toolkit implementation very slightly outperformed our algorithm in negative recall         to
         in overall accuracy  our algorithm substantially outperformed the
toolkit nave bayes         to        
our performace by fold was largely
consistant with a slight bump on   fold cross validation  by approximately       to       
results were also most positive with   clusters  achieving an accuracy of         compared
with        for   cluster         for   clusters         for    clusters  and        for   
clusters 

twitter relevance filtering via joint bayes classifiers from user clustering 

 

fi 

conclusion

the overall accuracy of the collated classifier was around        based on the average results of all    users  the simple
nave bayes classifier from the nltk natural language processing package achieved
around      the advantage of our classifier over the toolkit implementation lies on
the collated nature of the classifier which
strengthens the classifications by bringing
in extra information for each users base
bayesian classifier  in particular  our algorithm significantly outperformed the nltk
toolkit classifier on positive recall  which is
arguably the most significant metric with
regards to user experience 
examining overall trends  our classifier
performed very well on precision and recall metrics for disliked tweets  but significantly worse on the same metrics for liked
tweets  there are a number of reasons
for this disparity between classifying likes
and dislikes  ratings were more heavily
weighted towards dislikes as an overall trend
by raters  with simply the pure number
of dislikes heavily outweighing the number of likes  therefore  there were much
fewer examples of liked tweets to train the
bayesian classifier to begin with  furthermore  users were much more likely to dislike entire blocks of tweets simply based on

author whereas the qualities exhibited for
a liked tweet are much more nuanced  with
only a small fraction of tweets even from
the users favorite tweeters being worthy
of being liked  this makes it difficult to
predict whether a user will like a tweet  resulting in poor performance in predicting
liked tweets  nevertheless  the overall accuracy of our classifier is fairly high  our
test error was actually smaller for   folds
cross validation  indicating that the modeling each word  with relevant preprocessing  as a feature likely overfits the data 
future research will focus on improving
the choice and quality of features  which
should additionally improve the overall accuracy  the consistancy across folds did
indicate success in earlier prediction of tweets 
which as introduced with the problem  is
an important factor in a successful algorithm  given the difficulty in classifying
tweets because of their short nature and
lack of very much informational content 
the classifier did a good job at determining whether a user would like or dislike a
tweet 

references
    mock  kenrick  dynamic email organization via relevance categories 
intel architecture labs  may         
    mock  k   vemuri  v  information filtering via hybrid techniques 
journal of information processing
and management  permagon press 
v    n   pp               
    sahami  m   dumais  s   heckerman 
d   horvitz  e  a bayesian approach
to filtering junk e mail  aaai  
workshop on learning for text categorization  madison  wi  july      

twitter relevance filtering via joint bayes classifiers from user clustering 

 

fi