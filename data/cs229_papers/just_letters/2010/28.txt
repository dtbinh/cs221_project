optimizing leakage power using machine learning
shuhan bao
sbao nvidia com
december         

 

abstract

minimal vt and equivalently minimal delay  we can use
this knowledge to define an optimal achievable timing
slack of the design  sopt   where each sopt  i  is the timing
slack through cell i  under the condition that all cells in
the design are of the minimal vt  and thus fastest  type 
additionally  we can define a leakage term l i  vt    is the
leakage of cell i  given that we have assigned its threshold voltage class to vt  i   the optimization problem is
then to choose an array vt of threshold voltages over i
which satisfies

as transistor technology nodes continue to scale into
deep sub micron processes  leakage power is becoming
an increasingly large portion of the total power  this
has been true for many years now  ever since deep submicron processes became available  in addition  more
recently  computing is becoming increasingly mobile 
where minimal power is of paramount importance  as
a result  companies are becoming increasingly aware of
the need to optimize leakage power to the greatest extent possible  one of the most popular approach to leakage reduction has been to use gates with higher threshold voltages  which reduces the leakage of the gate exponentially  at the cost of increasing the delay through
the gate  by swapping gates in paths with significant
positive timing slack to their high vt equivalents  it is
possible to greatly reduce the leakage of a design  in this
paper  i will discuss an algorithm for solving this optimization problem  by using machine learning to provide
a model for the design and standard cell library  we can
model the salient variable  rather than an indicator of
that variable  and dramatically increase the set of potential swaps we consider  at the cost of adding some
error to the timing model 

 

min

n
x

l i  vt  i  

i  

s t  s i  vt     sopt  i   s i  vt     
in other words  we wish to minimize the leakage power
of the design  while maintaining the performance of the
design  alternatively  this constraint can be expressed
as requiring that all paths either meet timing s i  vt    
   or consist entirely of the leakiest  but fastest cells 
current algorithms to do this will heuristically
swap some subset of vt based on analysis of the potential power savings and the difference in the cell delay as calculated by the library model  in general  this
method requires multiple iterations as crucially  the library only gives a model for the cell delay  but not the
quantity s i  vt    the path slack  in current deep submicron technologies  it is not guaranteed that cell delay
changes are perfectly indicative of path delay changes 
as changes to the slew propagation will cause downstream cells to speed up or slow down  figure     as
a result  if optimization proceeds solely on the basis of
cell delay  it will be suboptimal for situations in which
the path delay differs significantly from the cell delay 
additionally  after each iteration  the full timer must be

introduction

of the methods for reducing the leakage power of a chip 
using libraries with multiple vt classes is amongst the
most popular  this method assumes a standard cell library consisting of two or more vt equivalents for at
least most if not all cell types in the library  for every
cell type  there would exist a variant of that cell with
 

fiupdated with the new cell types to determine the new     training
s i  vt   
in order to gather the training data  an existing eda
tool was used to load a relatively small block of a nextgeneration gpu chip  then for each cell in the design 
the vt was swept across all possible values for which an
equivalent cell existed in the library  and the subsequent
change in path slack was recorded  along with relevant
input features  for the most part  in the library that
was tested    vt settings were available for each standard
cell type  based on
since the goal of the model is to output a continuous
valued function  a linear regression minimizing square
error on the slack delta was tried  the model parameters are determined by solving the closed formed equation for the parameters  as gradient descent was found
to converge very slowly  despite the potential complexfigure    path delay vs cell delay  x y line displayed
ities of analyzing a full path as opposed to a single cell 
the linear regression was in fact able to achieve a reasonthe purpose of this work is to use machine learning ably good training error  this will be discussed further
to generate a model for the path slack for each potential in the results section 
swap  which can then be evaluated on new inputs very
features for the linear regression were selected priquickly  in order to allow for optimization algorithms marily on the basis of first order contributors to transisto work on the path delay change rather than the cell tor and wire delays  additionally  the amount of downdelay change  if the error of such a model is minimized  stream logic was included in order to represent the effect
it would be possible to very quickly compute the effect of slew propagation along the path 
of changing vt  i  on s i  vt   for all cells in the design 
and use these values to find an optimal vt configuration 

   

 

leakage optimization algorithm

once the models for each swap are generated  it is possible to load any design that is bound to the library
which was trained on  and apply the leakage optimization algorithm  two algorithms were tried for the leakage optimization  both are suboptimal in that both
lack complete information that would typically be held
in a timer graph  in favor of time constraints  building such a complete view of the design connectivity
was decided against  additionally  both methods use
a heuristic method to obtain some connectivity information  which simply assumes that cells with the same
slack value are likely to be on the same path  this generally holds if the number of possible slack values is large
compared to the number of paths in the design  for the
cases where it does not hold  the merged paths will
diverge after any change along either of the paths  in

methods

in this section  i will describe the methodology for implementing this algorithm  in order to implement the
algorithm  as described  it would be necessary to create
a model for the slack difference
s   s i  vt    s i  vt   
observed when swapping cell i  in practice  it makes
more sense to create a model for changing the threshold
voltage of a standard cell library cell  then applying that
model for all cells in the design which are mapped to
that library cell 
 

fiin both algorithms  we execute the algorithms across
the entire design  after each pass  it is necessary to reevaluate the timing to verify both that the estimated
slack agrees with the actual calculated slack  it is necessary to recompute the timing due to two sources of error  first  there is the potential test error of the learned
slack prediction model  second  there is potential error
associated with having an incomplete connectivity picture when doing the optimization  the algorithm may
believe two cells to be on independent paths and individually act on both cells  when in fact they are on the
r i  vt   i         c  log       s i  vt  vt     
same path  and should have been treated together  after re evaluating the timing  the algorithm will either
c log       l i  vt  vt     
stop if it has converged  or dump the state data and
where the model learned previously is used to estimate iterate again 
s i vt i    c         is a parameter to control the relative weighting of the leakage versus the slack minimization as the deltas can be orders of magnitude apart  for   results
simplicity  the reward function above is only valid for
swaps to lower threshold  the converse higher thresh  we can view the results in three sections  first  an analold swap would simply be    r i  vt   i    this reward ysis of the training error  second  an analysis of the test
function is chosen on the basis that the best swaps are error  and finally  a report of the actual results of runthose with the best ratio of small timing degradation in ning the algorithm on real designs 
exchange for large leakage reduction  in this method  c
needs to be varied from favoring leakage reduction towards the beginning  to favoring timing fixing towards     training error
the end  as the final design is expected to achieve sopt
the primary contributors to training error seemed to
or close to sopt  
in method    we evaluate each path as described be complex cells and flops  initially this effect was even
above  first  swap all cells to their lowest vt equivalent  more pronounced  until separate models were built for
this gives a value for sopt   in subsequent iterations  for each pathway through the cell  for example  a mux
each path  we have a set of cells p  and some slack value has   pathways from s to z  i  to z  and i  to z   in
s i  i  p     c is constant over all cells along the path  particular  before building path specific models of the
given this simple path  we can solve the     knapsack delays  the error for flops was enormous  as the effect of
packing using dynamic programming  first compute a swapping is dramatically different for the delay of the q
set of weights for each swap as defined by the amount pin  which acts as a driver  and the setup time of the d
the slack would degrade if the swap was executed  we pin  which is only serving to capture the signal   one
do this using the model learned previously  second  the explanation of the remaining error in complex cells and
value of the swap is simply the beneficial change in flops can be given in terms of conditional arcs  which
leakage  the total capacity of the sack is just c  solving cause the delay to differ depending on the state of other
this problem will yield the optimal leakage configuration inputs to the cell  since modeling this would require a
for any single path  a similar problem can be solved for much more complex model of the design  it was decided
paths with negative slack  to find the set of changes to to accept this error  from the table below  the overall
vt that minimize leakage degradation  but set s i  i  training error is seen to be approximately    ps across
all models built 
p     sopt  i  i  p   or greater than   

general  this assumption is neither always true  nor is
it complete  but in practice is a very simple to implement method that improves the performance of both
algorithms dramatically over having no connectivity information whatsoever 
in algorithm    first  the s i  vt    and x i  is dumped
for all cells in the design  where x i  is the input feature vector for cell i  for each potential single element
change in vt  i   vt   i   a reward function is then calculated 

 

fitype
buffer inverter
complex
sequential
total

count
  
   
  
   

error  ps 
      
      
      
      

table    training error for a typical library
based on the observed characteristics of the training
error  it was decided that more complex model would
not help the accuracy of the model  figure   shows the
data for a worst case training error cell type  in this
case for a complex xor gate  in the figure  capaci 

figure    test error histogram
of the algorithm may swap typically on the order of ten
thousands cells at once  without guarantees on their
independence  we can see that test error is generally
much greater than training error  and that the error is
spread over a much wider range  observations of greater
error can be attributed to two factors  first  one of the
input features selected for determining the slack differential is the input slew to the cell  for a single swap 
this value will be invariant  but in practice when many
cells along a path may be swapped at once  the input
slew of the downstream cells will change  rendering the
model estimate less accurate  the second factor stems
from the fact that as described above  the algorithm
did not build a complete graph of the cell connectivity  as a result  it may be unaware that is swapping
cells along the same path  and independently calculate
the expected slack for each path  in this case  the final observed slack will depend on both changes  while
the expected values for both only depend on the single
change in vt  

figure    worst case training error example
tance is chosen to be plotted against the slack delta 
but the same type of graph can be seen for all of the
input features  primarily  work was done to find an input feature that showed reasonable correlation with this
output data  but there is no conclusion on this issue yet 

   

test error

figure   summarizes the test error of the algorithm
when executed on a standard   nm design  the data
is gathered by actually running algorithm   on a design  and at each iteration comparing the algorithms
expected value of the new slack against the actual observed slack value  of note is that while training occurred one change per iteration  the actual execution

   

leakage recovery results

the table below summarizes the actual result of running
the algorithm on some select designs  unfortunately 
due to the enormous size of most interesting designs at
nvidia  it was not possible to gather more data points
 

fidesign
design
design
design
design

 names changed 
 
 
 
 

cell count
      
      
      
     

initial leakage  mw 
   
     
     
  

algorithm  
   
    
    
    

algorithm  
   
    
    
    

current flow
   
    
     
n a

figure    leakage results after various optimization methods

 

within the time frame of the project  we can see from
these results that actually method   tends to outperform method    despite the fact that method   is only
a heuristic approximation to the packing problem that
method   solves  this can be understood if we account
for the error in the models  because algorithm   tries to
optimize the leakage to fit exactly within the slack budget  its possible that it may add fairly suboptimal swaps
 i e  bad leakage to timing degradation ratio  to fill in
what it perceives to be a small shortfall in the slack budget  if the error is sufficiently large  however  this swap
may turn out to block a much more useful swap  unless
the timing is violating  algorithm   cannot undo previous swaps that it did even based on new information 
as this would cause it to take much longer to converge 
algorithm   on the other hand is always selecting the
best swaps from an infinite budget perspective  and so
in the presence of greater errors  it will perform better 
the biggest problem observed while running these trials
was that as the algorithm proceeded  even though the
achieved leakage number was very good compared to
the expectation set by the existing leakage optimization
flow  the algorithm had a lot of difficulty reconverging
on the timing  as noted in the discussion on test error  large errors can be attributable to the algorithm
working on seemingly independent  but actually identical data pathways  it often required many iterations
and some guidance  reducing the number of swaps at
each iteration for example  to make the algorithm converge in the presence of these errors  in many cases
where the design was too large  the runtime needed to
converge on both a good leakage number and good timing was prohibitive 

conclusions and future work

overall  this was a fairly basic trial to see if a machine
learning based algorithm could enable a better leakage
optimization algorithm  for certain  there are cases
where the algorithm is doing a good job  especially on
simple buffer chains  the algorithm performs very well to
find an optimum setting for vt   however  there are still
two large sources of error in the method that need to
be worked out  primarily  the training error associated
with complex cells  and the lack of a complete timer
graph  as the algorithm can provide very good leakage numbers when given enough iterations to converge 
resolving these two issues with both improve the convergence time and improve the overall achievable leakage 
future work will focus on selecting a more complete set
of input features  and generating better models of the
design as a whole  rather acting on individual cells in
fairly independent fashion 

 

fi