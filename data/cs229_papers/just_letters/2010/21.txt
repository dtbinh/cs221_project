vocal based musical genre
classification
bryan huh

arun miduthuri
abstract

musical genres are labels assigned to pieces of music  features of a genre
generally include lyrical structure  rhythmic structure  instrumentation  and
harmonic content  in recent years  efforts have been made to classify genres of
music using machine learning techniques on the above mentioned aspects of a
song  our project attempts to find what audio features are more important when
classifying vocal tracks into different genres  two vocal datasets are examined 
one containing indian vocal genres with no accompaniment  and another with
accompaniment filtered out with the help of a recent vocal separation technique 
introduction
as the digital database for music grows  so
does the demand for its organization 
currently  much of music classification is
still done by individual users who store the
artist name  song title  genre  and album in
the metadata of the music file  however 
the vast quantity of music files on the web
is making the manual classification of music
libraries more and more infeasible  the
automatic classification of music has thus
become an important problem  and is one of
the goals of music information retrieval
 mir  
automatic
musical
genre
classification is particularly sought after  but
it is also a great challenge  the boundaries
of a genre are generally not well defined 
and even humans will often disagree on the
genre of a song  indeed  human
performance on genre classification has
shown that automatic genre classification is
fundamentally limited by the subjectivity of
genre     

the vast majority of research on musical
genre classification has targeted featureextraction  previous studies using  timbral
features  such as mel frequency cepstral
coefficients  mfccs  and rhythmic
features such as beat features  chroma
features  and other pitch related features
have shown that by far the most useful
feature in genre classification is the
mfccs  surprisingly  those features which
humans seem to rely on in genre
classification such as rhythm  harmony  and
vocal content have not yet made an impact
in automatic genre classification  in
particular  the role of vocals separately in
genre classification has never been formally
addressed before  since vocals play a large
role for humans in genre classification  it is
an important question how much they are
being utilized in
automatic
genre
classification  perhaps features which have
had little contribution in the past  when
extracted from vocals  can make a greater
impact in musical genre classification  in this

fipaper  we determine the relative importance
design
of various features in the genre
classification of a standard genre dataset datasets
three datasets  two vocal datasets  were
used in     and a primarily vocal dataset 
used for genre classification  the first is a
standard genre dataset used in      which
related work
we will call the original general genre
dataset  we selected those genres which
musical genre classification has been had vocal content  country  disco  hiphop 
explored in detail in the seminal work by rock  blues  reggae  pop  metal  the
tzanetakis et al          related problems second dataset was generated from this
include singer identification      finding genre dataset with the aim of making the
similar
music
using
unsupervised vocal component of the songs more
methods     and locating singing voice prominent  a peak clustering algorithm
segments within musical pieces     related  marsyas  was used to isolate the vocals of
to our task of vocal genre classification is the genre dataset  we call this the vocalthe broader idea of separating vocals from separated dataset  finally  we used a
accompaniment in monoaural recordings  dataset of traditional indian music since
this has been done in several different indian music has a large databank of purely
ways  for example  independent component vocal songs  this was divided into eight
analysis      mixed gaussian models      and genres  female
bollywood  female
peak clustering      in our work we make carnatic  female hindustani  female
use of three primary features  mel  mantra  male carnatic  male hindustani 
frequency cepstral coefficients  chroma male qawwali  and male rajasthani  male
features  and linear spectral pair features and female vocals were separated for better
 lsps   mfccs and lsps are widely used training 
for speech discrimination  but have proven
useful in music classifiers  for example  see features
     there are additional spectral centroid  the genre classification was done using
rolloff  and flux features added on the basis combinations of the mfcc features 
of features used in      in addition  linear spectral features  spectral centroid  spectral
spectral pair coefficients have been added rolloff  spectral flux  time domain zero
as they are widely used in speech coding  crossings       chroma features and lsps 
chroma features are commonly used to we adopt the name timbral features    
capture pitch content and harmony  since for the collection of mfccs and spectral
lsps are primarily used for speech features combined  it is standard to include
modeling  it would not be surprising if lsps timbral features as a baseline  we then
contribute most to genre classification when classified using timbral features combined
they are extracted from pure vocals 
with either chroma features or lsps 
feature extraction was done using
marsyas  an open source software used
for audio analysis      for each audio file  a

fisingle feature vector was computed 
training and classification
previous results     have shown that a
gaussian svm classifier is a successful
classifier in genre classification  thus for
each of our data sets a gaussian svm
classifier was used  and our results were
obtained using    fold cross validation 
results and discussion
the figures on the next page  figure   
figure    summarize the results for the three
datasets and the various combinations of
features  for the original genre dataset 
adding chroma features significantly
improves the classification accuracy 
however  linear spectral pair features made
no contribution  for the indian music
dataset  timbral and timbral chroma
features alone gave poor classification
accuracy  but here linear spectral pair
features make a significant contribution  the
same is true for the vocal separated set 
the significant contribution of the linear
spectral pair features in the genre
classification of the indian music dataset is
not surprising considering that the indian
music consisted entirely of vocals  and lsps
figure   a   confusion matrix  w lsp features

have traditionally been used for speech
coding  examination of the confusion
matrices  figure    in classification runs
where the linear spectral pairs were
included and left out shows that without
them  a number of the male vocal genres
were misclassified as belonging to male
qawwali  interestingly  one of the female
genres  female carnatic  which had
melodies in the same pitch range as some
male voices  was also misclassified as male
qawwali in every test example  the genres
are intrinsically somewhat similar to one
another in terms of harmonic quality  and
are generally mainly different in tone of
voice  evidently linear spectral pairs capture
this tone difference  however  their failure
to improve the classification accuracy for
the original genre dataset suggests that their
contribution can only be made when vocals
are at least moderately isolated  this can be
seen in the case of separated vocals  where
lsps cause a dramatic improvement in
classification accuracy  in contrast  the
chroma features  which capture pitch and
harmony  are assisted by background
instrumentation as they only make
contributions in the original genre dataset
and marginally in the vocal separated
dataset  in which there continued to be some
residual
background
accompaniment 
figure   b   confusion matrix  w o lsp features

fifigure  

figure  
classification results and feature comparison
general genre classification  dataset   
features
timbral
timbral   chroma
timbral   lsp

accuracy
     
     
     
indian vocal music  dataset   

features
timbral
timbral   chroma
timbral   lsp

accuracy
     
     
     
separated vocals  dataset   

features
timbral
timbral   chroma
timbral   chroma   lsp

accuracy
     
     
     

ficonclusion and future work
we found that linear spectral pair features
are most useful in genre classification when
they can be extracted from vocals without
the
interference
of
background
instrumentation  the opposite seems to be
true with chroma features  this is consistent
with intuition  and it suggests that first
isolating the components of the music file 
and then extracting features from the
isolated components  in particular the vocals 
may be an important preceding procedure for
improved musical genre classification 
the most immediate avenue for future work
would include improving upon general genre
classification by including linear spectral
pairs from the separated vocals  it would
also be interesting to see how the relative
importance of features changes with gradual
attenuation
of
the
background
accompaniment  in particular we would like
to see if any other features commonly used
in genre classification behave differently
when the vocals are more prominent  for
example  lpccs are also a common voice
feature like lsps   we could also test other
methods for separating vocals  such as by
means of ica or mixed gaussian models 
finally  we would like to expand our vocal
dataset to include western genres 
references
    s  lippens  j  p  martens  m  leman  b  baets  h  meyer 
and g  tzanetakis  a comparison of human and automatic
musical genre classification  in proceedings of the ieee
international conference on audio  speech and signal
processing       
    g  tzanetakis  p  cook  musical genre classification of
audio signals  ieee transactions on speech and audio
processing  vol     no    july      

    t  li  g  tzanetakis  factors in automatic musical genre
classification of audio signals       ieee workshop on
applications of signal processing to audio and acoustics 
    y e  kim  brian whitman  singer identification in popular
music recordings using voice coding features  proceedings of
the  rd international conference on music information
retrieval       
    x  shao  c  xu  m s  kankanhalli  unsupervised
classification of music genre using hidden markov model 
     ieee international conference on media and expo
 icme  
    a berenzweig  d  ellis  locating singing voice segments
within musical signals  ieee workshop on the application of
signal processing to audio and acoustics       
    s  sofianos  a  ariyaeeinia  r  polfreman   towards
effective singing voice extraction from stereophonic
recordings  ieee int conf on acoustics  speech and signal
processing      
    tsai et al   blind clustering of popular music recordings
based on singer voice characteristics   th international
conference on music information retrieval       
    lagrange et al  normalized cuts for predominant melodic
source separation  ieee transactions on audio  speech  and
language processing       
    marsyas toolkit for audio classification tasks 
available http   marsyas sourceforge net

fi