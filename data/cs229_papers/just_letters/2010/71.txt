human accuracy anaylsis on the amazon mechanical turk
jason chen  justin hsu  stefan wager

platforms such as the amazon mechanical turk  amt  make it easy and cheap to gather human
input for machine learning problems  the flipside  however  is that some human contributors can be confused
or inaccurate  the challenge then becomes to extract trustworthy information from the answers of more or
less accurate contributors 
image net is an effort to organize images collected online into hierarchal synonym sets  synsets   such
as dog or jigsaw puzzle  image net then employs amt turkers to label whether the images it has gathered
are actually typical representatives of the synset they were grouped under 
since the turker labels are not      accurate  image net currently determines whether an image is
correctly labeled by majority vote  in this project  we consider machine learning algorithms that could
enable us to identify the more accurate turkers  and to recognize more typical representatives of synsets
using the available amt votes  first  we present an unsupervised em algorithm that assigns accuracies to
individual turkers and assumes that their votes are bernoulli distributed  second  we present a supervised
algorithm that identifies a few dozen key images  which we correctly label  and then uses this information
to identify trustworthy turkers  the supervised approach produced some very promising results  especially
in synsets with ambiguous definitions  such as bishop  the chess piece   the unsupervised results were a bit
more mixed 
in both our approaches  we make the following assumptions  first  we assume that each of our voters has
a consistent accuracy level  second  we assume that the majority is more often correct than not  we then
attempt to identify turkers who vote with the majority most often  infer that they are our best labelers  and
follow these trusted labellers in ambiguous cases 
unsupervised learning approaches
first approaches  naive em and skill scoring  before settling on our final design  we attempted a
naive em approach  briefly  we assume each turker has a weight ci corresponding to their accuracy  we
set the weights to be the log odds of the fraction of the turkers votes that are correct  then we adjusted
the labels of the pictures based on the weighted majority vote  though this seemed promising at first 
we encountered one of the main difficulties of this project  too many negative images  since most of the
images the turkers are presented with are negative examples  a turker who votes no to all images will score
very well  thus  these people will have disproportionately high weights  skewing our labels  and leading to
mediocre performance 
to remedy this  we considered using a skill scoring approach  in which we roughly estimate the fraction
of positive images  with this number  we can calculate baseline performances of turkers  if they simply
always vote yes or always vote no  by taking this baseline performance into account  we can decrease the
bias  the main problem with this approach is that it isnt clear how to normalize the performances  a
turkers maximum performance depends not only on how many images she votes on  but also on the votes
she casts  as it is easier to get a no vote correct than a yes vote  after trying several normalizing schemes 
we found that the results were much more promising than the first approach  with poor performance only
in identifying false positives 
final approach  specificity and sensitivity em  we went back to our first approach  and looked for
a model in which voters were expected to score correctly at a high rate when voting no  and to correct for
date  november      
 

fi 

jason chen  justin hsu  stefan wager

this bias  our idea was to have different weights for when turkers voted yes  and for when turkers voted no 
this led to the following model  derivation closely follows      
let y        be the ground truth of a given image  and y j        is voter j labeled the image as  for voter
j  we associate parameters j   pr y j     y        j   pr y j     y       known as the sensitivity and the
specificity  respectively  we also have one more hidden parameter  p   pr y       or the fraction of typical
u
images amongst all images  now  if d is the observed votes  yi j is the vote given to picture i by turker
uj   the jth turker to vote on this picture  and  are the parameters j    j   p  we have maximum likelihood
function 
n
n n
o
y
y
pr yi            yiri  yi         p   pr yi            yiri  yi             p 
pr d    
pr yi            yiri     
i  

i  

independence of votes gives 
ai    pr yi            yiri  yi         

ri
y

pr yij  yi      j    

j  

bi    pr yi            yiri  yi         

ri
y

ri
y

j

j

 j  yi     j   yi

j  

pr yij  yi       j    

j  

ri
y

j

j

  j   yi      j  yi

j  

qn

thus we want to maximize pr d     i   ai p   bi     p   denoting the ground truth as y    y            yn   
pn
we get that the log likelihood is i   yi ln pi ai       yi   ln    pi  bi
e step  we calculate the expected value of this log likelihood  this will be our lower bound for the true
log likelihood   taking the expectation with respect to pr y d      qi  y   we have
   

e ln pr d  y     

n
x

i ln pi ai       i   ln    pi  bi

i  

where i   pr yi     yi            yiri      by bayes  we update
i  pr yi            yiri  yi         pr yi     

 i   

ai p
ai p   bi     p 

m step  we wish to maximize the lower bound calculated in the e step with respect to the parameters
j    j   by setting the  and  gradients of     to   and update p  we get 
pn
pn
n
k
k
  x
k
i   i yi
i       i      yi  
k    p
i

  
p
  
pn
n
n i  
i   i
i       i  
pn
by reestimating p   n  i   i every iteration  we can run this until convergence  initializing i to be
pri j
the majority vote i   pr yi     yi            yiri     n  j  
yi to calculate our final labels  since i is the
probability that image i is typical  we can set a threshold  and mark images that have i    as typical 
results  the results from our unserpervised approach were somewhat mixed  for some synsets  we managed
to perform better than majority vote  on others  though  we generated a large number of false positives 
below are results for the following three synsets  as well as their definitions according to image net 
 caterpillar  cat  a large tracked vehicle that is propelled by two endless metal belts  frequently used
for moving earth in construction and farm work 
 bishop   chess  a piece that can be moved diagonally over unoccupied squares of the same color 
 horseshoe  u shaped plate nailed to underside of horses hoof 
for each synset  we record the number of positives the algorithm recognized  the fraction of images that
were unambiguously typical  and the false positive rate  we did not count ambiguous images in either of
these categories 

fihuman accuracy anaylsis on the amazon mechanical turk

 

figure    sensitivity  left  and specificity  right  of users in the caterpillar  cat synset
results
images recognized definitely typical false positives
cat cat  unsupervised
   
   
   
cat cat  majority vote
   
   
   
bishop  unsupervised
   
   
    
bishop  majority vote
   
   
  
horseshoe  unsupervised
    
   
   
horseshoe  majority vote
    
   
   
our algorithm worked fairly well for caterpillar  cat  however  it performed poorly for bishop  we
suspect this is because a very small fraction of the images presented to the amt are in fact typical  under
     this means that voting on no images is very easy  while getting a high score on yes images is hard 
thus  most turkers have very high specificities but low sensitivities 
such numbers tend to push split votes toward a yes decision  since our high specificity and low sensitivity
reflect an assumption by the model that false positives are quite unlikely  whereas false negatives are common 
if we try to fix this problem by computing only a single credibility for each turker  as we did in our first
model   we run into another related problem  all the easy no votes give most turkers an artificially high
credibility 
a challenge for unsupervised learning approaches to the image net dataset is that the interesting images
are swamped by a large mass of easy no images from which it is difficult to learn anything new  in the next
section  we present an alternative approach that only learns turker accuracies from contentious  or difficult
images 
supervised learning approach
we suspect our work unsupervised learning algorithms ran into difficulties for the following reasons 
 learning contributor accuracies from all images is not very effective  because interesting  difficult
images are swamped by easy images on which everyone votes correctly 
 learning contributor accuracies from the most difficult images in an unsupervised way can be dangerous  since even a large majority can be wrong on difficult images 
one way to overcome these problems is to automatically find the most difficult and contentious images 
and then have an accredited expert provide the ground truth on these images  though this seems to defeat
the purpose of using amt input  we think that this approach is valuable if a researcher really needs accurate
labels on a set of tens of thousands of images and has time to manually label a few dozen images per synset
to train the supervised learning algorithm  after these labels are set  the full collection of amt votes can
then be used effectively 

fi 

jason chen  justin hsu  stefan wager

our idea is an example of a collaborative filtering approach  in that we estimate of how each turker
might have voted on our small labeled training set by comparing them to turkers that actually voted on our
training set  we then compute weights for each turker using a bernoulli maximum likelihood estimate  and
infer labels for our images using a weighted majority vote 
specifically  we first pick    images with a negative majority vote and    images with a positive majority
vote  while maximizing the quantity   yes votes   no votes  for each image  these are our contentious
images form our key images  which we label manually  for each key image kl we provide a definite label
l kl          
to compute weights for all turkers  we first need to to obtain predictions aikl for how each turker i would
have voted on key image kl   clearly  if i voted on kl   then aikl   aikl   however  if i did not vote on
kl   we need to somehow guess how i would have voted on kl   to do this  we first compute the similarity
coefficient uij for all turkers i and j 
p

kimages aik ajk
uij   p
kimages  aik ajk  

assuming that turkers  lj   voted on key image kl   we use these parameters to give a guess for the vote of
p
i
   lj   on kl   aikl   j uilj alj kl   we are now ready to compute weights for each turker  assuming that
the votes by turker i are bernoulli distributed such that they are accurate with probability ci   we get the
following experssion to maximize 
y

max l kl  aikl    

ci

     ci  max l kl  aikl    

i kl
p

with a little math  see milestone   we get that ci  

p

kl

kl

ci
  
log   c
i

l kl  aikl

 l kl  aikl    

taking the log of the likelihood

we do not let additive weights drop below
function  we can also find additive weights wi  
zero  instead  we ignore turkers with negative weights  having computed additive weights for each turker as
described  we proceed to a weighted majority vote with which we infer labels for the remaining images 

results  the results using our supervised algorithm were quite promising  especially for very confusing
synsets  such as caterpillar  cat  our algorithm did a good job at weeding out turkers working under a wrong
definition  below are some detailed results  the yes and no on the second row indicate the decisions by our
algorithm 
caterpillar cat
total number of images
sample size
number of definite positive
number of ambiguous
number of definite negative

majority vote no
no
yes
     
   
   
   
 
  
 
  
  
 

majority vote yes
no
yes
   
   
   
   
 
  
  
  
  
 

many images  such as vehicles with wheels manufactured by cat  or vehicles with tracks but not directly
useable for farming  were ambiguous as to whether they should be considered to represent caterpillar  cat
or not  we labeled these ambiguous  the sample size row indicates how many images we looked at in each
category to evaluate our algorithm  evidently  in all the cases where our algorithm disagreed with the
majority vote  it had less than   chance in    of making a non ambiguous mistake 
from the point of view of image net  which is trying to accumulate a large and accurate database of
images  the two most important metrics are the number of positive images recognized  and the false positive
rate  we provide such statistics below for the   synsets we worked with 

fihuman accuracy anaylsis on the amazon mechanical turk

 

results
images recognized definitely typical false positives
cat cat  supervised
   
   
  
cat cat  majority vote
   
   
   
bishop  supervised
   
   
  
bishop  majority vote
   
   
  
horseshoe  supervised
    
   
   
horseshoe  majority vote
    
   
   
our algorithm performed quite well on both caterpillar  cat and bishop  we notice that both of these
synsets have somewhat confusing definitions  some might mistakenly believe that the first applies to larvae
of butterflies  and the second to catholic clergy  our hypothesis is that our algorithm managed to eliminate
confused voters  and thus clean up the vote dataset 
our algorithm does not  however  perform nearly as well on horseshoe  the difficulty in picking good
images of horseshoes is not so much due to confusing definitions  but rather in learning what to do with
limit cases such as horseshoe shaped necklaces  these results suggest that our algorithm is good at picking
out confused turkers  but not so good at picking out turkers without a keen attention to detail 
as support for the hypothesis that our algorithm works essentially by eliminating confused labellers 
consider the following numbers  with caterpillar  cat  we gave    out of    turkers a weight of    and with
bishop     out of    voters got no weight  on the other hand  with horseshoe  we only gave   out of    
turkers a weight of    this suggests that we did poorly on the latter synset because we couldnt identify the
turkers who were consistently wrong on a majority of the key images 
discussion and further works
our results show that machine learning techinques can successfully be applied to improve the value of
votes gathered on amt  our supervised approach  in particular  makes it easy for a researcher who is willing
to spend about a minute labelling images from a synset to eliminate data from turkers who do not share her
understanding definitions of the synsets 
our unsupervised approach presents some interesting challenges  the central difficulty is that  for many
synsets  the number of bad images swamps the number of interesting images  if we give turkers a simple
bernoulli accuracy  the high number of trivially bad images makes this accuracy artificially high  conversely 
if we try to give each turker a separate sensitivity and specificity  we end up giving each turker an extremely
high specificity  this results in unwanted false positives  since having very high specificities makes it unlikely
that any image having received many yes votes could be a negative 
the success of the supervised approach suggests that it is most useful to infer turker accuracies from
their performance on the most difficult images  an interesting problem for further study would be to work
on unsupervised learning algorithms that focus more closely on contentious images  one way this could be
implemented is by ignoring all images with unanimous votes while learning accuracies  another approach
could be to introduce a parameter for the difficulty of each imagethe probability of a turker making a
mistake could then depend both on her accuracy and on the difficulty of the image  see  for example      for
an idea similar to the latter 
our results show that there is much promise and much room for improvement in automatic amt vote
analysis  since amt is one of the most promising ways of collecting machine learning data on a large scale 
it is critical that we find good ways of analyzing amt data as efficiently as possible  we look forward to
seeing what approaches will surface in the literature over the next years 
references
    v  rayker  et al  learning from crowds  journal of machine learning research                     
    j  whitehill  et al  whose vote should count more  optimal integration of labels from labelers of unknown expertise 
advances in neural information processing systems  forthcoming        

fi