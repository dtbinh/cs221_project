cs    

final project report

tianxi li   yu wu

twitter hash tag prediction algorithm
twitter is one popular web application nowadays  twitter allows users to use
hash tags to classify their tweets  in this research project  we propose an algorithm
to predict tags  by utilizing machine learning and network relatedness methods 

   problem definition
hash tag prediction is different from normal texts classification  here we dont
know how many clusters we need to find  in addition  the tag set changes so
frequently that it is almost impossible to effectively carry out classification or
clustering  since a new tag would force us to establish a new class and a new
classification rule  our intuition is  if we can measure the correlation between various
tweets as the mathematical metric we can treat the collected tweets as points in a high
dimensional space  and construct a network by the latent space model 

   method
    theory
an intuitive way to solve this problem is to use euclidean distance between
points as the measurement of their similarity  we developed our theory based on this
distance  since in a euclidean space  the distance is equivalent to the norm of a vector 
we will focus our discussion on norms 
let u    u   u p be the standard bases  with unit norm  of a p dimensional

euclidean space  then for any vector v with coordinates  x 

x   x p  

x p    we

p

have v   xi ui   then the euclidean norm of vector v is given by
i  

p

p

i  

i  

v  v  v   xi u i   xi ui 
 

p

 x x u u

i   j  

i

j

i

j

   

where  represents the inner product operation defined in the euclidean space 
clearly  if we assume ui  u j      that is  ui and u j are orthogonal  whenever i  j   the
euclidean norm equals to v   xi    in our problem  the bases are the words in the
 

dictionary  the preliminary assumption for euclidean distance is that the bases are
orthogonal to each other  that is  the words in dictionary are uncorrelated  which is
against common sense  therefore  we need to perform some transformation to capture
this correlation 
in formula      as ui and u j are unit vectors  their inner product is actually the

fics    

final project report

tianxi li   yu wu

cosine of the angle between them  thus we can rewrite     in a matrix form as
v   x 
 

 cos     cos   p   x  

 
 xp   

      xmx t
 cos 
 cos  pp   x p 
p 


where cos ii      i    p and x   x 

x   x p  

   

xp   

now we try to find the angle between each pair of terms in the dictionary and then
calculate the matrix m   notice that m is clearly a symmetric and non negative
definite matrix  if we decompose m in the way

m  cc t

    

 
  t where x  xc   so the norm can be seen as
then     becomes v  xcc t x t  xx

the euclidean norm of the transformed coordinates  here we take     as the eigen
value decomposition of m   so x could be the coordinates of vector v in a new
coordinate system where axes are orthogonal to each other  please note that we can
use any other decomposition in the form of     to get the same norm in computation 
even when c is not a square matrix  with this property  the computation becomes
applicable 
    estimate the cosine matrix
first  we construct the preliminary weighted matrix  say    by using the wordnet
to initialize the semantic correlation among words from the dictionary  if two words

ti   t j are similar to each other  and they both appear in one tweet  we add positive
weights for both words  this process can be expressed as
p

xi  xi   ij x j
j i

where ij          equals to one when ti   t j are similar words and zero otherwise 
here we take the same positive number  for all ij          and if ij      so is  ji  
then we can construct the symmetric matrix  as
      p 


     


 p     

x  x 

   

in the second step  we get m tweets  say x    x m   and transform them by     to
get x    x m   then by these data  we use cosine similarity in variable analysis to

fics    

final project report

tianxi li   yu wu

construct matrix m   set the text matrix as the m  p matrix

 x    x  p 


    x  t  x tm  t        
 x

 m   xmp 
we would estimate the cosine between the ith and jth terms as
m

cos ij 

x ti x  j



x i x  j

 x

x

m

m

k  

ki kj

 x  x
 
ki

k  

k  

   
 
kj

the distance estimate obtained from formula     is equivalent to what proposed by
l  jing  l  zhou  k  ng and j  huang         but with a better mathematical
explanation  note that since our data is represented as frequency  all the elements of
the matrix  would be non negative  so the cosine estimated in this way can only be
non negative  therefore  all angles between words are cute or right angles  in this way 
all words tend to be similar to each other in some degree  this may well incorporate
the similarity elements  but might also be vulnerable to noise  in the following  we
give a modified estimate which also includes the possibility of obtuse angle and takes
dissimilarity into consideration  which is also the sample correlation in statistics 
m

cos ij 

   x

ki

k  

m

   x
k  

ki

 xi    xkj  x j  

 xi  

   

m

 

   x

kj

k  

 x j  

 

since the distance from     was named as ontology based distance  obd  in the
original paper  here we call the distance in     centralized ontology based distance
 cobd   we will discuss the pros and cons of the two methods in section    in the
following sub section  we will make another adjustment to the method 
    normalization
note that the various scales of vectors may still cause us some problem  consider
a special case where x               

x                 x               obviously 

x   and x   here should have high similarity value between them  but in this case  the
distance between x   and x   is much smaller 
to make our method more reasonable  before we compute the distance between
transformed points  we need to rescale their distances to the original point as    and
then we measure the euclidean distance between normalized points 

fics    

final project report

tianxi li   yu wu

    prediction of tags
finally  we try to predict tags based on the distance  an intuitive way is to simply
select the tag of the closest tweet  in this case  it may be unwise to simply pick the
closest tweets tag  since that relies on the acurracy of distance too heavily  to
increase the accuracy  we collect a few closest tweets  and make the prediction based
on tag ratios  specifically  we will collect n initial closest tweets at first  then from
this point  we will keep adding tweets while check a certain tag has become dominate 
if there is a tag with a ratio higher than      we will choose this tag as our primary
predicted tag  since in some cases tags have very similar meanings  such as
 government vs   election   sometimes we will also pick a secondary tag to predict 

   results and discussion
to compare the performances of various distances discussed above  we use a test
dataset consist of     tweets that are not included in the sample set we used to
estimate matrix m   there are   different tags  we first process the obd on a dataset
with     tweets that are not in our test set  choose the best performance         and
use it for both obd and cobd  the table below shows the test result for euclidean
distance  eucd   obd and cobd 
test error rate
type ii error
eucd
      
    
cobd
     
    
obd
      
    
table   the test error rate and type ii error for three distances  type ii error is the rate
we assign a wrong tag to a particular tweet 
both obd and cobd outperform eucd  and obd is the best one  if we see the
data for different tags  not provided here for concise   we would find cobd is the
most stable one  while eucd is far more unstable  but the disadvantage of cobd lies
in computation  we need to estimate the cosine matrix m to construct the distance 
which involves computation for matrices with tens of thousands rows and columns  it
wont be a big problem for obd since the matrices are sparse  but in cobd  the
matrix becomes non sparse  so we need many decompositions and transformations of
matrices to make the computation applicable  given their close performances  obd is
more practical in application  while the cobd is a better model theoretically 
the left picture in figure   shows the cobd from other tweets to a random
selected tweet  different colors represent tweets with different tags  it can be seen that
most of the tweets are very close to the        distance boundary  and the majority of
points falling in the circle are from the correct tag group  this indicates that tweets
with different topics are projected onto orthogonal axes  the right plot illustrates the
distance distribution  the lighter the color is  the shorter the corresponding distance is 
since the tweets are sorted by tags  we see that the distance within each group appears

fics    

final project report

tianxi li   yu wu

to be shorter  as shown by the light rectangles along the diagonal 

figure    the distance to one point and the distribution of sample distance matrix

figure    prediction visualization

in figure   different colors represent what tag cluster the tweets belong to  a link
will be added between a pair of nodes when they are near enough  in addition  the
deeper color the line is  the higher the similarity value is  as we can see  the lines
appear to be very dense among each tag cluster  and sparse between tweets with
different tags  it indicates that tweets with the same tag cluster are near on average 
due to the vagueness of many tweets  the correct rate of more than     is
actually very high  apart from the accuracy  our method has other advantages 
    the whole system is easy to store  we only need to store the c matrix in      
    it is easy to update when dictionary changes  only needs to compute an extra
column and add it back to original matrix 
    it wont lose power when the topics trend changes with time  and it can work with
personal elements and settings  which makes it more flexible  since we can set the
algorithm to only consider the distance of the objective tweet to certain subset of
other tweets  so elements like location  time  etc can be incorporated  
    in addition  the distance provides us the possibility to transform the twitter system
and even other text systems into social networks by latent space approach  so we
can use traditional social network methods to discuss the properties of such
systems 

fi