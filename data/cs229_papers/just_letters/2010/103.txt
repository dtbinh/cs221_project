recognizing hand gestures with a  d camera
michael marx  michael fenton  gage hills
distinct hand gestures were identified and classified from  d camera data using multiple machine learning approaches  two divergent development paths were attempted successfully 
the first used simple image segmentation and normalization  followed by feature selection for
a support vector machine working off of pixel based features  the second approach focused on
generating more sophisticated features and used an ensemble of bagged decision trees for
classification  both approaches were successful in obtaining a median classification rate higher than     for each hand state in the data set 

   introduction
 d cameras have the potential to allow new
types of user interaction with computers and
other devices  most  d camera tracking
currently used for user input  such as with the
microsoft kinect system  recognize position of
the body at a distance  to our knowledge  no
current systems operate in a modality in
which sufficient resolution and accuracy are
obtained on hands to recognize specific finger
gestures from  d data 
for this project  we used a prototype  d
camera system intended for mobile devices to
capture data in a modality in which the hand
is captured with high resolution and high
fidelity  the objective of the project was then
to generate a method of classifying the hand
state on a frame by frame basis  coupled with
temporal tracking  this would allow for a
robust user interface similar to the multitouch track pad system of using single finger 
multiple fingers  and other hand positions to
generate unique control inputs 

   data collection
a small  d camera was used to collect many
frames of a user moving their hand with four
different hand configurations  one finger
point  two finger point  closed fist  and open
hand  for each of these gestures  we captured
    frames as the user moved their hand
throughout the field of view while maintaining the gesture  for the context of this
document  the data set for a single users right
hand was used   this data set was meant to
in order to explore the ability to classify across
left and right hands and across different users 
 

exercise single hand gesture classification
with arbitrary position and orientation 
an individual frame of data is a    x    pixel
field of brightness and phase values  brightness corresponds to the amount of light being
reflected from the target  and phase corresponds to the distance from the camera to the
target  sample frames of magnitude and
phase data are shown below in figure   

   image processing
several steps were taken in preparing the
data for both classification approaches  the
goal of data preparation was to reduce each
frame to a consistent representation of the
hand without a background  the first step
was to segment the full hand and arm in each
frame  this was accomplished by removing
sufficiently dim pixels  filling any resulting
holes in the foreground image  i e  imclose  
then finally labeling the largest contiguous
blob as the hand  as it was the largest 
brightest object in all of our datasets   simple
inspection was sufficient to show the effectiveness of this mechanism to separate the
hand from the background 
in the base data set  the hand occasionally
moved outside of the field of view  in order to
only classify frames in which the hand was
fully visible  we looked for intersections of the
hand arm outline with the frame border and
ignored frames which had more than two
points of overlap 

other data sets were collected using different
users and alternating hands  however these
results have been omitted for brevity 

fifigure    magnitude and phase of   hand positions

additionally  we identified which row
contained the wrist  using a simple function
of foreground thickness variation across
rows  and removed frames that did not have
a wrist as defined by this constraint  after
these removal stages      frames of full hand
data were preserved with pixel wise determined positions of both the hand and wrist 

   svm based classification
the first of the two major approaches to
classification taken in this project was to
apply support vector machines to learning
how to classify a particular hand state  this
was initially attempted using the raw magnitude and phase data  as well as a few
manipulations and features extracted from
the data  however  it was found that the large
variability in hand location and orientation
defeated the svms attempts at classification 
focus was instead given to separating the
hand from the rest of the image  and to
generate a normalized and reduced set of
features for the svm to regress against 
with the hand locations determined for every
frame  the data was normalized for svm
application  it was desired that distance from
the camera  and related scaling of hand size 
would not throw off the classification  to
enable this  each frame was resampled down
to a consistent field     x    pixels  that
spanned from the wrist to the farthest
fingertip and from the far left to the far right
side of the hand  further  we separated the

hand from the background by renormalizing
the distances based on the minimum object
distance 
using the normalized distance per pixel as the
input to svm  the classifiers were able to
achieve an overall accuracy of more than
      using         train test crossvalidation   but took an exceptionally long
time to compute  in order to reduce computation time  feature selection was employed 
to determine performance against a small
number of features  four sets of        
train test cross validation were prepared  all
features were tested for each of the four
classifiers  with a fitness function defined as
 fitness     probability of detect    probability of false alarm  for each   these will be
expressed as pd and pfa henceforth   at each
stage  each unused feature was fed to an svm
along with the previously determined best
features  and the new feature that achieved
the best fitness value was then added to the
list of best features  the available features
were the previously described normalized
phases along with many other features that
ended up being discarded by the feature
selection process  performance of the svm
for each of the   cases against different
numbers of features is shown in figure   
maximum performance  among the number
of features computed  was achieved with a
minimum of    features for one finger    
features for two finger    features for closed
hand  and   features for open hand 

fifigure    fitness function vs  number of selected features
fitness for best n features

    

fitness   p

   
    

one finger
two finger
closed hand
open hand

   
    
  

  
  
  
number of features

fitness using n training samples

d

  p

fa

 
   
   
   

one finger
two finger
closed hand
open hand

   
 

  

  

  

              
number of training samples

   

   

   

for the ensemble method our approach was
to build up as many features as possible that
provided some intuitive information about
the hands position  these features need to
be only slightly more descriptive than     in
being able to distinguish between any two
gestures to be helpful  additionally  the more
distinguishing the feature is  the more useful
the feature is to the classification process 

   

d

 p

fa

    

 

figure    fitness growth vs  size of training set

   ensemble based classification

 

 

space and time  the nearby frames will be
more similar than disparate frames 

fitness   p

in order to determine an upper limit on the
effectiveness of the selected features  leave
one out cross validation was employed using
only the selected features for each classifier 
one
finger
classification
achieved
             pd pfa  two finger classification achieved               closed hand
and open hand were classified with       
and        detection rate respectively  and
both had zero false alarms  across the full
data set  every frame was either classified
correctly  not classified  or classified as two
possible hands  in no case  during loocv 
was a frame classified incorrectly 

  

  

  

finally  the amount of training necessary was
investigated  different portions of the data
was selected for training the svm and used to
test against the remaining data  the resulting
curves are shown in figure    as can be seen
from the curves  the open hand case is very
easy to classify  achieving     fitness after
only    samples  and reaching     fitness
after    samples  the closed hand classifier
also converges quickly  reaching     fitness
in only    samples  and reaching     accuracy in    samples  the one and two finger
cases take much longer to converge  both
taking     samples to reach     fitness and
growing slowly from there  it is believed that
this result reflects the svm requiring training
frames that are similar to the test frames in
order to classify accurately  as the training
set size grows  it becomes increasingly likely
that neighboring frames to the test data will
have been included in the training data 
because the hand moves continuously in

the advantage of tree based classification is
that it does not require a single feature to
clearly discriminate one gesture from another  with sufficient features  it is able to
optimize the decision tree to maximize the
classification rate  even in the presence of
fairly weak features  better features will
likely also lead to a more compact decision
tree 
for example  a highly descriptive
feature is the perimeter of the hand  in either
pixel distance  number of edge pixels  or in xy
space  which separates the open hand
gesture well from the other three gestures 
consequently  the first decision in the tree is
based on the perimeter of the hand  a perimeter above a certain threshold automatically
classifies into the open hand gesture  the
effect of the perimeter is seen in the comparison below 

fifigure    edge map of open and close hand

another useful feature is the distribution of
depth values of each of the four gestures  the
variance is a strong indicator of which label
the gesture belongs to  pictured below 
figure    depth histogram   variance plot  two finger
point  one finger point  closed fist  open hand 

fingers with closer depth than
hand 
number of pixels
closer than zthresh
closer than the
max distance on
the hand

distinguish one finger   two finger
point  as fingers should be greater
than roughly   mm from the
center of the hand

horizontal gradient
in z

distinguish one finger   two finger
point  as there are more local
depth changes than on flat open
hand

in order to evaluate the expected performance of each of our features  we used a
metric to measure the normalized distance
between two distributions  for each feature 
that features value is calculated for each
frame  e g  the depth variance for the hand  in
the case above  and lumped into one of four
distributions based on its label  the figure of
merit for that feature measures the maximum
distance between all six combinations of the
four distributions  the maximum is representative of the feature strength because a
bag tree does well if it can separate any two
of the features  we used the following metric
to determine the expected performance of
feature f  for gestures i and j 
 
 

other key features that we used are described
in the table below  as well as qualitative
description of their expected behavior with
respect to each gesture 
feature

expected behavior

perimeter variance
in radius from
center of mass

distinguish open hand from other
three gestures  extra edge pixels
along fingers instead of just
around hand 

center of mass

closed fist to have center of mass
closest to center of woi  open
hand to have center of mass
farthest away

variance range in
z

open hand to have little variance
in z  hand is along a single plane in
cartesian space   two finger point
to have highest variance  two



 
 

sorting the features by this metric yields the
table in figure   
we chose the features as they have an
intuitive correlation to the gestures  however  we found that we were also able to use
features that have a less intuitive relationship
with the gestures when observed independently  take  for example  the absolute
depth measurement of the hand  there is not
a reason why this feature alone should be
able to classify the gesture  since any gesture
could be performed at any depth  the
absolute depth measurement can  however 
identify proper thresholds for classification
with other features such as the perimeter or
area of the hand  a closed fist may have the

fisame perimeter as a far away open hand  thus
the absolute depth helps to separate cases
such as these in conjunction with other
classifiers 
figure    feature descriptions   distribution

   conclusions
we were successful in creating two classifiers
which were able to accurately recognize hand
configurations using  d camera data  both
approaches relied heavily upon properly
segmenting the image  which is a non trivial
task for traditional rgb cameras  but was
relatively simple for the case of our  d
camera  we were able to attain over    
successful classification rate for both the
svm based and ensemble method based
classifiers on our dataset 
the per pixel svm based approach would be
an ideal implementation for high performance applications which required minimal
classification times and did not require
updates to the support vectors frequently
 due to the extraordinarily slow process of
identifying support vectors in our datasets  

for these reasons  we found the best results
when we fed as many features as possible to
the classification tree builder  and let it
optimize based on what it found most useful 
as opposed to only feeding it features we
thought would be useful 
using these features  we used the ensemble
method of bagged decision trees to classify
each of the frames of data  randomly subsampling the dataset into         training test
subgroups  the resulting classification rate
for     trees per subgroup was over     in
all cases  with a median classification rate of
       across the four gestures 
this
surprisingly good success rate prompted us
to expand the dataset to include five users
and both hands for those users  the median
classification rate was     across the four
gestures over all of the expanded dataset 
which shows both reasonable success and
promise for future improvements 

the ensemble method based classifier had
significantly higher per frame runtime
requirements  due to the computation
involved in calculating the feature values  
but a much lower regeneration time  which
would make it ideal for situations where
conditions or users were frequently changing 
using either of our hand classification systems  it would be straightforward to
implement gesture recognition for a user
interface  by giving an immediate classification of hand state in every frame  a second
level program could monitor the hand state
and position continuously to recognize a set
of control inputs  enabling a more robust
level of interaction for the user 

fi