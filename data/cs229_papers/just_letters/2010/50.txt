autonomous generation of bounding boxes for image sets of the same object
shui hu  jean feng  marc rasi
december         

 

introduction

one of the challenges of computer vision research is to achieve accurate autonomous object recognition  this project focuses
on the specific problem of finding bounding boxes of a given object in a set of pictures  each of which is guaranteed to contain
this object  we run our experiments on the image database imagenet  developed by stanfords vision lab  in imagenet 
each  synset  is a group of about      images of a certain object where the bounding boxes are labeled manually via amazon
mechanical turk  since this method is not scalable  we propose an algorithm that generates bounding shapes and can partially
eliminate the need for human labor  in this paper  we compare this new algorithm detectrec  which relies on high level image
cues such as object shape  to our initial algorithm that relies on low level cues like hog 

 

an initial algorithm using low level cues

the initial algorithm we implemented relied on finding potential bounding boxes based on its objectness score and then learning
hog features to identify boxes that contained an object of the desired class  the objectness measure  as described in the paper
what is an object  by alexe  desealers  ferrari      tries to quantify how likely an image window contains an object of any
class based on multi scale saliency  color contrast  edge density  and closed boundary characteristics 
our initial algorithm is as follows 
   use objectness measure to automatically collect bounding boxes for simple training images  single object against monochrome
background  and generate hog features for each box
   fit a gaussian distribution for the training data
   repeat step   on test images  getting    candidate bounding boxes per image
   use the gaussian distribution to calculate the probability of each of the bounding boxes being correct bounds for the class
as we will show in our results and discussions  this algorithm did not perform very well  which suggests that the gaussian
distribution did not fit the hog data well  either because there was not enough data or because it is the wrong model to use
in general  so we developed a new algorithm that follows the same general framework of finding general objects and then using
high level features to identify objects belonging to the specific class 

 

detectrec algorithm

detectrec takes a high level approach to the object localization problem  in essence  the algorithm only takes into account the
object shape once given the object segmentations  an outline for the algorithm is as follows 
   learn generic shape models of an object class by running k means on the object segmentations from the class 
   for each image 
a  use hierarchical object detection  explained below  to find potential object 
b  select the object that is most similar to one of the generic shapes  and draw a tight bounding box around it 
 

fiautonomous generation of bounding boxes for image sets of the same object

   

shui hu  jean feng  marc rasi

learning shape models

given an object segmentation s  the algorithm first approximates s with a    gon p   which is further simplified to the vector
 n  c  r  where
 n is the number of segments that are convex  concave  or straight relative to the object  a segment is a set of consecutive
angles of p that have the same convexity  greater than  close to  or less than   relative to p  
 c is a vector denoting which segments belonging to which class of convexity
 r is vector denoting the regularized version of each angle  specifically  the regularized angle is the average of the angles
belonging to that continuous section of the same convexity concavity  if the segment is straight  the regularized version is
 
the intuition behind using an angle of vectors is that our shape model can then be made invariant to rescaling  reflections  and
rotations  the vector  n  c  r  is useful since it captures the characteristics at different levels of generality  where n is the
highest level and r is the lowest 

 

shape similarity

from this shape model  there are two ways we can measure shape similarity between two different shapes  n  i    c  i    r i    and
 n  j    c  j    r j     first is simply the difference in number of segments  which we denote n d i j   
n d i j     n  i   n  j   
the second measure of shape similarity combines the difference between convexity and angles in the two shape vectors  in
order to make this metric invariant to rotations and reflections  we take the minimum distance over all possible rotations and
reflections of one of the shape vectors  we denote this measure by sc  i j  and define it as


  
  
x
 x
  
 j 
  
 j  
sc   min
  ck   ck  
 rk  rk  

  
  
 c

 r

 

k  

  

 j 

ck  ck

where  c      r     ranges over all cyclic permutations and reversals of  c  i    r i   
we put these two measures together by multiplying them  smaller n d i j  sc i j  denotes greater similarity  if two comparisons
yield the same n d i j   sc  i j   for example  many comparisons may have n d       the one with smaller sc  i j  is more
similar  n d i j   sc  i j  takes into account both the difference in the matching segments of and the overall difference between
two shapes  the value n d accounts for the overall similarity between the two shapes while sc measures the degree of difference
in matching parts of the two shapes  the similarity score is also capable of identifying the similarities between a complete object
and a partially occluded one 

 

learning generic shapes

given the set of training vectors containing the angles of    gon approximations  we cluster the vectors using k means and return
the centroids as shapes to use in finding bounding boxes  we use n d  sc as the distance metric for k means 
to find the number of k means clusters  we use the binary search algorithm  if there are m training examples  we start with
m clusters  for each pair of centroids  if the inter cluster n d  sc is below a certain threshold  we decrease the number of
clusters  if the intra cluster n d  sc between two vectors in one cluster is greater than a certain threshold  we increase the
number of clusters 
the centroids correspond to generic shapes for the object class reflecting the intra class variation due to angle of perception and
variation within the object class itself 

 

fiautonomous generation of bounding boxes for image sets of the same object

shui hu  jean feng  marc rasi

figure    demonstration of the object segmentation algorithm at different grid resolutions

 

general object segmentation

given an image  im   this step produces a list  d  of candidate object segmentations 
first  use k means to cluster the colors of im to just two colors  producing a binary image  bim   this step reduces noise
because the background tends to blend into one color  then run the following hierarchical object detector on the binary image 
   initialize an empty list  d  of objects 
   divide the black and white image bim into an  x  grid 
   set the color of each grid cell to the most common color in the image in the grid cell 
   refine the shapes of objects in d by absorbing adjacent cells with the same color 
   add each contiguous set of cells of the same color to the list d of objects 
   repeat this process for finer grids    x      x      x       x     
at the end  d gives us a list of potential objects in im   these objects tend to be the more prominent objects in the image
because they tend to have large regions of coherent color which corresponds to contiguous sets of cells of the same color 

 
   

results
analysis for first algorithm

we ran the first algorithm on pictures from   different synsets  mangos  shoes  laptops  backpacks  and cameras   for each
synset  our algorithm outputted a trained gaussian model for hog features of bounding boxes containing objects  from the
objectness step of the algorithm  we get    candidate bounding boxes and then we classify bounding boxes as positive if they
had an overlap of at least      with a true  manually labeled  bounding box and as negative if they had no overlap of      with
a true bounding box  for both algorithms  overlap between two shapes a and b as
area a  b 
area a  b 
we then classified all the bounding boxes using our gaussian model and plotted roc curves  figure   shows the roc curves
for the   different synsets 
we also tried a few other things to get a better understanding of how our algorithm was working  we first tried training on
manually labeled data  as opposed to the automatic labeling we normally do in step   of our algorithm   which is illustrated by
the green line in the mango roc plot in figure   
to test our assumption that training on simple images produces better results than training on complicated images  we trained
our gaussian model with image sets of both types  figure   also shows the roc curves from these tests 
we also tried training on positive examples from one synset and then testing on testing images from a different synset  to test if
our algorithm was learning what one specific type of object looked like or if it was learning what objects look like in general 
figure   shows the roc curves from these tests 
finally  we also plotted    roc curves for testing on cameras after training on    through     training examples  to see how
our algorithm performance changed with number of training examples 
 

fiautonomous generation of bounding boxes for image sets of the same object

shui hu  jean feng  marc rasi

figure    roc curves on   different synsets  also  training on complicated images 

figure    left  center  training on one synset and testing on a different synset  right  roc curves for varying number of
training examples

   

discussion for first algorithm

we can see from our plain roc curves on the individual synsets that our algorithm does do better than chance  which is good 
so our algorithm is slightly helpful in picking out the positives and the negatives from the candidate boxes  but since there are
so few positives in the candidate boxes to begin with  we found that about    of the candidate boxes were positives   we are
still left with far more false positives than true positives  so we would like to know why the algorithm does not perform so well
and what would be required to improve it 
figure   show that performance does not increase very much as the number of training examples increases  the lowest green
roc curve is the roc curve for    training examples  so our algorithm does improve a bit with number of training examples
in the range of    to    training examples  but additional training examples do not significantly improve performance  this
suggests three reasons why our algorithm is not performing so well 
   the automatically labeled positive training examples might be bad because objectness does not find objects very well  even
in simple pictures 
   the positive examples might all be so similar that our algorithm does not learn very much when it sees new examples 
   our model might not fit the data very well 
reason     is not the reason  as shown by the green line in figure    the green line shows how well our algorithm performs if
we manually label positive examples  and it is not significantly different from the red line which corresponds to automatically
labeled positive examples  so a combination of reasons     and     are probably making our algorithm perform poorly  reason
    is reasonable that there is not much variation in the simple images of objects that we are using for our training examples 
reason     is also likely since a single gaussian distribution probably does not model all the different possible ways an object
can appear  therefore  our algorithm performs more poorly on laptops and backpacks  which are deformable objects and look
different from different angles  than on shoes  mangos  and cameras  which all look reasonably similar across all the images in
the test sets  either because amazon turk users collect similar images or the object just looks the same from different angles  
although reason     suggests that training a model only on simple images does not generate a robust model  our data does
support the idea that  if we want to automatically generate bounding boxes without human intervention  we should start by
training on the simple images  specifically  if we run our automatic algorithm on complicated images instead of on simple images 
we get the roc curves shown in figure   
 

fiautonomous generation of bounding boxes for image sets of the same object

shui hu  jean feng  marc rasi

figure    cluster centroids for the shapes used in the detectrec algorithm on the shoe synset  different shoe shapes are distinctly
visible 
the last thing we tried was to train on examples of one set and test on examples from a different synset  to see if our algorithm
was learning the appearance of specific objects versus general objects  the roc curves from this are shown in    by training on
one synset and testing on a different one  this algorithm performed slightly worse than when we trained and tested on the same
synsets  yet  it was still better than chance  this suggests that this first algorithm is using image cues from the specific objects
and characteristics of general objects  it is true that by training on shoes and testing on laptops  actually performed better than
when we trained on laptops and tested on laptops  this just suggests that the algorithm wasnt able to learn anything specific
to laptops  which supports reason      our model cant model all important features for complicated objects like laptops 

 

detectrec results and analysis

we tested detectrec on the shoe image synset  with an initial training set of    images and a test set of     images  detectrec
achieved     accuracy overall  since classification is done in two steps  first finding objects and then classifying the object  we
further broke down these results 
   given the image test set  the object of the desired class  shoe  was segmented in     of images 
   given a correct general object segmentation  the object classifier then correctly identified the desired object in        of
the images 
objects detected by the object detector tended to be rather large and differed significantly in color from their surroundings 
over half of the images where the object detector failed to detect the correct object were cases where the correct object was
adjacent to or occluded by another similarly colored object  so the object segmentation algorithm was unable to separate them 
therefore  detectrec does suffer to some extent by forcing every image to be black and white 
we also tested the difference from adding more images  using    training images  detectrec found three representative shapes
and achieved     accuracy overall for    test images  by breaking down these results again  we found that the general object
segmentation algorithm achieved     accuracy while the object classifier accuracy rose to         once again  this is given that
the object was segmented correctly in the first place   this shows that even with a limited amount of data  the object classifier
will achieve a decent enough accuracy to at least warrant a collaboration between humans and computers to find bounding boxes
for images for large databases such as imagenet 

 

conclusion

the absolute accuracy of our approach does not compare very well to the state of the art algorithms  desealers  alexe  and ferrari
achieve     accuracy by a similar metric to ours on a much more difficult test set in       our paper show the advantages and
disadvantages to different approaches for object localization and can aid in generating bounding boxes for large image databases
such as imagenet 

references
    alexe  bogdan  desealers  thomas  ferrari  vittorio  what is an object  computer vision laboratory  eth zurich  ieee
computer vision and pattern recognition  cvpr   san francisco  june      
    alexe  bogdan  desealers  thomas  ferrari  vittorio  localizing objects while learning their appearance  computer vision
laboratory  eth zurich  european conference on computer vision  eccv   crete  greece  september      

 

fi