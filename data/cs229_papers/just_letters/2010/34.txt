 

classifying structural mri scans of patients with
major depressive disorder
joe marrama  christie paz  guillaume davo  estelle comment

abstractthe goal of this paper is to determine if machine
learning algorithms can be applied to distinguish differences
between structural mri brain scans of patients with major
depressive disorder and those of healthy patients  a large range
of standard machine learning techniques were tested in this study 
while a majority of these suffer from the small size of the
dataset we used and thus are prone to overfitting  it appears
that deep belief nets can be trained for this classifying task
with a reasonable accuracy 

i  p roblem s tatement
major depressive disorder  mdd  is a serious mental
ailment that affects        of women and       of men 
symptoms include headaches  irritability  a feeling of worthlessness  and thoughts of suicide  although     of people
diagnosed with mdd at some point in their life recover
completely  family members may be     to   times more likely
to develop this condition 
currently  the diagnosis of mdd relies upon self reported
experiences of a patient  these diagnoses are often biased 
mdd patients may deny that their feelings are abnormal  for
this reason  it is critical that unbiased tests be developed to
diagnose this disorder 
recent research using machine learning on medical images 
such as fmri and mri scans  has proved to be successful for
many diagnosis algorithms  such as drug addiction      ecker
et  al      recently used support vector machines  svm  on
mri scans to diagnose autism with accuracies over     
in this paper  we will discuss several algorithms we used
to classify structural mr images of patients with mdd and
controls  in the future  these algorithms may be used to
develop a clinical diagnosis for mdd and may even provide
insight on the causes of this disorder 

most of our experiments were done on a balanced set of
   examples  the training and test sets were then randomly
selected  with a ratio of about            
iii  c lassifiers
a  support vector machine with l  regularization
in an svm  l  regularization encourages sparsity in the w
coefficients  in our problem where we have too many features 
we can use it as a method of feature selection  the l  norm
regularization is equivalent to  
min
w

l
x
 
 
  w     
max       yi wt xi  
c
i  

the smaller c is  the more the coefficients of w are reduced 
the optimal value of c was found to be around      for
which the mean test error was        with a standard deviation
of       
the non zero coefficients of w correspond to points in the
 d scan  that we can plot against the map of the brain  see
figure     these are the features selected by the svm 

ii  m aterials
all participants were scanned at stanford university using
high resolution   tesla or   t scanners  we acquired    brain
scans     female mdd     male mdd     female controls 
   male controls  from subjects of various ages          the
scans were then normalized so that each of the    x   x   
voxels in the image mapped to approximately the same point
in  d space within the brain 
given the large number of features and small number of
examples  our primary problem was  to reduce our feature
space to avoid overfitting while minimizing the training and
test errors  one solution was to reduce the resolution of our
dataset by averaging  in this paper  we will refer to reduced
resolution data sets as lo  for resolution reduced by    lo  for
resolution reduced by    etc 

figure   
c    

coefficents of features selected by l  svm  on lo  data  with

b  naive bayes
we initially tried nave bayes as a benchmark algorithm 
we discretized the data with equally spaced bins  and tested
   times on different resolutions of data  taking out the
background features  nb performed well compared to other
methods  we know that in cases where there are few examples 

fi 

table i
naive bayes test error   mean     std   on original data

lo 
lo 
lo 
lo 
full resolution

   bins
              
              
              
              
               

   bins
              
              
              
              
              

   bins
              
              
              
              
             

it can outperform svm  it seemed to perform best on the full
set of features  see table i  
we also tried nb on gradient maps of the data  taking only
the binned direction into account    and    bins of direction   
this also performed well on the full size data  but much worse
       on the lower resolutions  see table ii  
table ii
naive bayes test error   mean     std   on gradient data

lo 
lo 
full resolution

  bins
              
              
              

   bins
              
              
              

c  logistic regression
we implemented a logistic regression algorithm with various learning rates on the lo  data set  our algorithm iterated
through each training sample  of    subjects      of our total
data  and each feature until the value of theta converged to
a learning threshold of        we then classified the test set
using the converged value of theta  figure   summarizes our
results  unfortunately  this algorithm did not have significant
test error  however  the training error was   for all iterations 

figure    average test error of logistic regression on lo  data over   
iterations  training over     data

if the null hypothesis can be rejected  using afnis open
source toolbox  we created a t test mask from our two sets of
data  mdds versus controls  this mask contained coefficients
for each voxel that were proportional to the likelihood that
the difference between voxel values in these two sets were
significant   voxel values that appeared to be significantly
different in the two sets had higher coefficients   our raw data
was then multiplied by this mask and put into an svm  using
leave one out cross validation and reducing resolution of the
new data set by a factor of    our average test error was      
using l  normalization also did not prove to be effective  our
test error was      
e  handpicked anatomical feature mask
given previous psychological research on mdd  we reduced our feature space to include only those voxels that were
in areas of the brain that were already thought to be related to
mdd  this reduced our feature space to only      features
per sample  we then fed this in to our support vector machine
using leave one out cross validation to determine the error 
unfortunately  this method failed to classify mri images
with reliable accuracy  see fig      the test error of leaveone out cross validation was        figure   also shows that
the mdd test errors tended to be smaller than the test errors
of control  but not significant enough to suggest that the svm
favored one classification over the other 
since mdd affects twice as many women as it does men 
we compared the test errors between females and males to see
if there were any significant differences  in fig     you can see
the test errors of support vector machines that were trained on
just female data or just male data  its interesting to note that
the test errors are not that different even though female are
more likely to have mdd than males 

figure    est errors from hand picked anatomical feature mask from leaveone out cross validation of lo  data of a sample set composed of all data 
a sample set composed only of females and a sample set composed only of
males

d  students t test
t test students t distribution is a continuous probability
distribution that resembles a normal distribution where the
sample size is small  t testing uses students t distributions
to determine if two sets of data are significantly different  i e 

f  principal component analysis
principal component analysis is used to massively reduce
the features space dimension  to test the efficiency of pca
on our problem  we used a balanced set of    examples  the

fi 

training and test sets were then randomly selected  with a
ratio of about             since our data represents images 
the mean  training  image was subtracted from the examples
but no variance scaling was done  after projecting both the
training and test examples on the principle components  we
ran a soft margin svm with linear and gaussian radial basis
function kernels  classification results were quite unsatisfactory  see figure    

features performance was cross validated in the training set
to determine the best  this method didnt yield good results
either  and seemed to select features rather uniformly across
the brain  see figure     it also had a very long running time 
on lo   the average test error was         with a standard
error of        

figure   
figure    mean  blue   standard deviation  red  on average for    trials 
versus number k of eigenvectors used for svm  the first k eigenvectors are
used 

features selected by forward search  on lo 

i  forward block feature search

we also derived an other algorithm form forward search
for feature selection  instead of selecting each feature corresponding to a voxel individually during the search  we divided
the full resolution scans of the brain into   x  x   cubes
and selected a subset of brain cubes for our features with
forward search  ten fold cross validation was used at each step
to choose which cube to include in the feature set  we hoped
this method could help us select specific brain areas related to
mdd 
we also derived another algorithm from forward search for
feature selection  instead of selecting each feature corresponding to a voxel individually during the search  we divided the
full resolution scans of the brain into   x  x   cubes and
selected a subset of brain cubes for our features with forward
search  ten fold cross validation was used at each step to
g  feature selection by mutual information
choose which cube to include in the feature set  we hoped
a classic method for feature selection is to chose those who this method could help us select specific brain areas related to
have the best mutual information with the labels 

 mdd  however since the sparsity of the points giving the best
x
p xi   x  y   y 
results for the svm is high  the cross validation error profile
i xi   y    
p xi   x  y   y  log
p xi   x p y   y 
is usually a step function and the test error is close to     
x y
 see figure    
the probabilities were estimated by maximum likelihood
 by counting the occurrences and normalizing  and laplacesmoothed  mutual information failed because we had so few j  histogram of oriented gradients
examples and so many features  in all the available features  it
most feature selection techniques and algorithms we used
was always possible to find a feature that correlated perfectly do not really take into account the very nature of the data 
with the labels  by chance  this was usually a noise feature which is basically  d images  on the contrary hog descripthat had escaped denoising  out of the brain 
tors are features descriptors used in image processing for
object detection  so we tried to transform our dataset into
h  forward feature search
hog features and then run an svm classifier  we derived a
since mutual information failed  we tried forward feature simplified version of the algorithm described in      first the
search to select the best features  using l  svm  each three components of the gradient  dx  dy  dz  are computed
the values are averaged for    trials  random permutations
of our original data set   the mean error is around     so
it seems that there is no information left at all relative to our
classification task after pca  however it can be noted that
the error is minimal when a median number of eigenvectors is
used  about      as expected  using more eigenvectors gives
indeed more information on the initial features  but energy
is concentrated on the first eigenvectors so using the last
eigenvectors worsen performance  to understand why pca
performs so poorly  we studied the features projections on two
of the main components  unsurprisingly  the data does not look
separable at all  hence the difficulty for svm to classify on
the test set 

fi 

figure    distance measures  original and shrunk the periodic variations
correspond to sections through the brain 
figure    typical cross validation error profile on the full resolution data set

for each image in the dataset  then these components are used
to bin the gradient direction  we tried to divide the space into
  and    solid angles  after binning  the image is divided
into  x x  cells and a histogram of oriented gradients is built
for each cell  each voxel votes for its bin and its vote is
weighted with the norm of its gradient  finally  histograms are
juxtaposed to form the new features vector  unfortunately  the
svm classification on these new features yields unsuccessful
results  for     trials on the full resolution images  mean test
error was        with a standard deviation of        for
   bins  lower resolution data sets were also tested without
success 
k  nearest shrunken centroids
nsc is a regularized version of gaussian discriminant
analysis  with an assumption of independence between features  this assumption is reasonable since with our small
number of examples  we could not have estimated the full
covariance matrix anyway  to the standard gaussian analysis 
we add a soft thresholding of the normalized distance between
each features mean and class centroid      even though the
shrinking seems to be active  as seen in figure the results are
close to     test error 
nsc is a regularized version of gaussian discriminant
analysis  with an assumption of independence between features  this assumption is reasonable since with our small
number of examples  we could not have estimated the full
covariance matrix anyway 
to do the standard gaussian analysis  we add a soft thresholding of the normalized distance between each features mean
and class centroid     
even though the shrinking seems to be active  as seen in
figure    the results are close to     test error 
l  deep belief networks
to help reduce the high dimensionality of the data  we
experimented with running the input through deep belief nets
and variants thereof in hopes of effectively preserving the
information in the data while condensing it  using a process

similar to gradient ascent  we went through all of our preprocessing methods  post processing classification techniques 
and our variants on deep belief nets in order to find the best
combination  surprisingly  in the end  it was a single restricted
boltzmann machine with a svm on top  trained on the noncompressed dataset  that performed the best  a discussion of
our methods and results follow 
   preprocessing methods   by just flattening the     by    by    mri scan matrices  the dbn variants we tried
didnt get the best performance  each example had        
points  of which the majority were    going through the
complete data matrix  with each row as an example  and
removing each column that contained all zeros  we reduced
the dimension of each example to         this resulting
nozerocolumn dataset performed much better with all our
models  because the columns that contained all  s contain no
helpful information  and likely correspond to points outside of
the brain on the mri scans 
as described before  we also tried crudely merging the
points adjacent to each other in the mri scan  using both
these compressed datasets and these datasets further processed
with all zero columns removed didnt help performance in any
of our dbn models 
   post processing classification methods   without exception  the highest performing classification algorithm on the
processed data from every dbn model was a l  regularized
svm with a c value of      naive bayes typically performed
the worst  and standard svms did slightly better  l  regulated
svms typically did much better than both naive bayes and
normal svms  but the l  svm with a c value of     always
did better than the rest  as the same on the normal dataset
without dbn processing 
   deep belief net models and results   for all of our deep
belief net models  we used a standard rbm with a sparsity
target for the activations of the hidden units         the sparsity
target was     the learning rate for the sparsity was      and
the learning rate for all other weight bias updates was      we
let the overall training loop run for     epochs  although the
error usually converged well before     iterations 
the first model we tried was a standard rbm with varying
numbers of hidden units  the standard rbm by far got the

fi 

best performance on the full nozerocolumn dataset  unfortunately  due to the high dimension of the data  we could only
use up to     hidden units on the corn clusters  the graphs
below show the performance of these models  surprisingly  the
rbm performed much worse on all the condensed datasets 
with and without the zero columns removed  trained on each
and every condensed dataset  the rbm got around     test
error  see figure    
figure    top row     by    voxel patches of the brain moving backwards 
bottom row  the resulting weights for these patches after being trained on
the training set

figure   
units

rbm test set performance as a function of the number of hidden

our next model was a standard   layer dbn  on the full
nozerocolumn dataset  this process greatly worsened our
performance from a single rbm  because the first hidden
layer is so much smaller then the dimension of the data  we
suspect that the second and third layer cant extract any useful
features from the first layer  rather they just get in the way 
we trained   layer dbns on the compressed datasets  the
smallest of our datasets had      features  which allowed us
to have comparable numbers of hidden units   but all dbns
trained on the compressed data still got an average of    
test error 
we then tried training a rbm on only a small patch of the
data  running all patches of that size through the rbm  and
combining the resulting data in hopes of effectively reducing
the feature size  for our first attempt at this  we used the
nozerocolumn full dataset and sampled patches from the
smoothed out data  unfortuantely  for all patchsizes and factors
we reduced the datas dimension by  our test error didnt
deviate much from      we also tried training a separate
rbm on each patch  with the same results  however  the
patches we sampled from in the nozerocolumn dataset
correspond to generally uniformly distributed points in all
areas of the brain  not localized patches  thus  we next tried
sampling from cubes in the brain instead of random patches
and repeating the same methods  see figure      this also didnt
produce good results  for all brain cube sizes we tried  test
error still didnt deviate far from     
   dbn error analysis   from both the performance of our
models and the different datasets  a clear pattern emerges  all
models that arent trained on the full  non compressed dataset
end up performing poorly  every run we did with a compressed
dataset had test error close to      as well as every model
that trained an rbm or dbn  or multiple rbms  on a subset
of each example  looking at larger patches from the mri
data of both normal and depressed brains  it becomes apparent

that the data is very regular  and that there is no immediately
discernible pattern usually found in one type of brain and
not the other  taking this into account  it makes sense that
almost all of the techniques we tried to get around the high
number of features failed on our mri scans  this is because
the indicative features of a depressed brain most likely lie in
subtle points and relations between the points  which is easily
lost in compression and convolution  training an rbm on
the full dataset must capture some of this information  which
allows classification using svms to perform much better than
without the rbm 
iv  c onclusions
although many of the algorithms we implemented failed
to be significantly accurate  deep belief networks proved to
be the most promising  with more data from more subjects 
our other algorithms would perform better with less variance 
although this problem was apparent when we first began this
project  we had hoped to overcome this problem 
there are still many other algorithms that we can try 
including lar  least angle regression  to find the best
weight for l  svm  and recursive feature elimination  we
can also explore more combinations of the various methods
we tried 
r eferences
    ecker  christine  et  al  investigating the predictive
value of whole brain structural mr scans in autism  a pattern
classification approach  neuroimage                  
    zhang  lei  et  al   machine learning for clinical diagnosis from functional magnetic resonance imaging   computer
vision and pattern recognition       
    n  dalal  b  triggs  histograms of oriented gradients
for human detection  in  computer vision and pattern recognition  san diego  ca  june            
    trevor hastie  robert tibshirani  jerome friedman 
the elements of statistical learning  data mining  inference 
and prediction  second edition  feb        springer 
    g  e  hinton  s  osindero  and y  w  teh  a fast
learning algorithm for deep belief nets  neural computation 
                     
    chaitanya ekanadham sparse deep belief net
models for visual area v   stanford university 
url 
http   ai stanford edu  ang papers nips  sparsedeepbeliefnetworkv  ps

fi