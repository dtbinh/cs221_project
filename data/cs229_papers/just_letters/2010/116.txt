adult website classifier
saikat sen
cs    machine learning course project  dec     

abstract
the goal of this project was to detect adult websites and pages that are not safe for kids  we use five
different techniques  we create an adult vocabulary and use a composite classifier formed of multiple nave
bayes classifiers to classify pages based on url  title  keywords and content  we use hue  saturation and
histogram of gradients to train random forests  different boosting classifiers and mlp on boxed images for
local image classification  the intent is to then use a viola jones or haar approach to classify images
globally  we show an edge detection technique that works better than cannys for some images  we show
an extension to markov chains that can help detect edges  the intent is to use classifiers such as svms with
gaussian kernels to use edge information in detecting body parts  lastly  we propose adultrank  a ranking
metric that serves as an indicator of the adultness of a page  all the techniques together can be used
effectively to detect adult web sites and pages  the only overlap this work has with previous related work is
in image recognition using the features we have used and edge detection techniques 

introduction

strategy

website classification is an old problem  internet explorer
labels websites as phishing and malware  google leaves
out malware sites from its search results  the goal of this
project was to build a classifier that can classify websites
and web pages as adult  i e  sites and web pages that are
unsafe for kids 

we employ three main techniques  image analysis  text
analysis and ranking  for text analysis  we inspect page
title  keywords  url and content  for image analysis  we use
different image recognition techniques  the opencv
package was used for image recognition and ml classifiers 
for ranking  we propose adultrank  a ranking metric
similar to pagerank 

applications of this classification are many  parents dont
want their kids exposed to adult content  some adults find
porn images offensive  some governments ban porn sites
and have an ongoing requirement to detect them  many
porn sites have a malware payload and install rootkits 
adware  spyware and other viruses  so guarding against
them is an additional safety measure 
in general  sites and pages could be classified as adult sites
based on many factors such as adult images  sexual
content  violent content  racist sentiments  extreme
radical views etc  the scope of this project is limited to the
first two categories  we try to classify pages based on
metadata and try to find good classifiers for adult images 
video classification was out of scope for this project but
can be done by analyzing individual frames  we also
extend markovs model  propose a ranking metric
adultrank and propose a new convolution filter for edge
detection 

 

url text classification

   

url features

the following metadata of web pages were used for adult
classification 





meta tag  rating  there are some standards
that sites can use to indicate adult content but
none that we saw use the rating meta tag  if
the rating tag is found to be adult or restricted 
the page is classified as adult  the code was not
included in the final toolset since this analysis
can be done independently without using
machine learning techniques 
title  if the page title contains an adult word  the
page is classified as adult 
url  if the page title contains an adult word  the
page is classified as adult  the chosen
implementation is nave  it looks if the words
from an adult dictionary exist in the url as

fi



   

substrings  a proper implementation would
parse the url into words with an optimum match 
take the site content into consideration and then
do a dictionary lookup  as an example  we
consider tit to be an adult word but this false
positives sites with title in the url  as an
example of requiring site content to be
considered  google can be parsed as the
mathematical number google  and go ogle 
the site content would help determine which of
the two parsings is more appropriate 
keywords  adult sites and pages tend to contain
adult words in their list of keywords for better
search engine rankings  we search for the
keywords in an adult vocabulary 
content  page content is an important
determinant  sites such as theonion com are
adult sites with expletive but non sexual
content  certain blog pages and similar usercontributed content pages  comments on news
articles  discussion forums etc   with expletives
cannot be filtered out by any method but
content filtering 

adult dictionary  standards preprocessing techniques such
as stemming and skipping stop words were not used but
ideally should be 

adult vocabulary

caution  many porn sites will install malware  rootkits 
adware  spyware  viruses  on your system via drive by
attacks 

in the absence of a good online adult dictionary  we
constructed one using a custom application and using the
princeton wordnet lexical database  the custom
application allows the user to choose a source set of
words  outputs the synonyms in each iteration  and allows
the user to classify the synonyms as adult  gray and clean
before proceeding with the next iteration with the adult
synonyms  it is essential to classify the synonyms in each
iteration  otherwise the word bag escalate to size in
thousands due to words with multiple meanings such as
tool  we iterated until a new iteration didnt output any
new words  gray and clean words are not iterated upon 
the final list includes two files  adult txt and gray txt 
adult txt contains confirmed adult words that we would
like to filter  gray txt contains words that we would like to
filter but can be used in adult and non adult contexts  the
goal is for the classifier to learn the appropriate weights on
all words during training 
our vocabulary contains     blacklisted adult words and
   gray words 
limitations of the current classification method include
not being able to parse different forms  plural  tenses 
conjunctional forms  of the parent word  this can be
easily solved by preprocessing words before looking up the

   

url data

a custom app was written that could start with a starting
set of urls and find all the outbound http and https links
one level deep  the app allows filtering out urls in each
iteration and automatically filters out urls with schemes
such as mailto and about  schemeless urls such foo html
that are clearly internal links were filtered out in each
iteration 
using this method  we collected     additional porn urls
with a starting set of    porn urls and      good urls with
a starting set of    good urls  both sets were manually
checked to make sure the set contains correct data  most
could be easily discerned from the urls themselves 
a custom app was written to output data files for the good
and adult sites in csv format    data files were generated 
adult and good for title  keyword  url matching and
content 

   

url text classifier

the text classifier classifies sites and pages based on the
features mentioned in the preceding url features
section 
the text classifier is a hierarchical composite classifier
with a nave bayes classifier each for title  url  keywords
and content  we experimented with the individual
classifiers  constructing the composite classifier can be
easily done  if any of the classifiers outputs   indicating
adult  the final decision is taken as adult 

   

url text classifier results

the nave bayes classifier works well in almost all cases
with high accuracy  high tp rate and a consistently low fp
rate  including more blacklisted words into the vocabulary
and reducing the number of gray words improved the
metrics  and a bigger training set and vocabulary can
further improve the performance of these classifiers  in
the image below  content is shown to have quite a few
false positives  this was with     blacklisted adult words
and    gray words 

finot used for training  we did not employ background
subtraction or other image pre processing techniques 

   

 

image classification

the goal of the image classification is to find adult images 
we tried both global classification and local classification
with boxed images  in this form  the strategy is to train
different classifiers to male and female organs from
different angles  we did the project with just one class of
adult images due to shortage of time but the intent is to
extend the approach and train other classifiers similarly 

we mostly tried object recognition using the following
features  but also tried edge detection  time prevented us
from training classifiers with edge detection techniques 
two new edge detection techniques were attempted as
described below 
image features used include 


in a complete classification model  we imagine training
different classifiers for different classes of adult images
and compositing them  the final classification would use a
weighted sum over the learned individual classifiers as is
done in boosting models 


h x    sign   t   ht x  
where the summation is done over t     to t    classifiers
and the t parameters are learned using the boosting
algorithm 

   

image data

craigslist personals and other sections were used as the
data source  a custom app was written to look for images
in the personals section  enumerate the html img tags 
crawl those urls and download images from the urls to a
local folder  a second custom labeler app was written that
allowed easy enumeration through the downloaded
images and labeling with outputs organized by labels 
office picture manager was subsequently used to box the
images for optimal training 
images were grouped into two positive classes of     
images each  where one class corresponds to the frontal
and the second class corresponds to profile view  positive
 adult  images were collected from the personals sections
of three different cities       negative  clean  images were
collected from the baby and pets section of two different
cities  because of craigslist user moderation  these two
sections did not contain any positive images 
note that all boxed images were quality images  images
that were poor resolution  incomplete  hazy  mixed with
other body parts or clothes  grayscale and cartoonish were

image features

color histograms  hsv histograms of images
were obtained and hue and saturation
histograms were extracted  we tried with       
and    bins for hue and    bins for saturation 
we experimented with hue separately as a
feature and with  hue  saturation            x
    bins  as an example     hue bins x   
saturation bins produced     features per
image  hue is a good indicator of skin 
histogram of gradients  the gradient at each
pixel of an image was calculated as arctan dy dx 
and mapped to one of    buckets in the      
range  finally the percentage of pixels in each of
the    buckets was output as an image feature 
this produced    features per image 

the intent is to be able to run the viola jones haar
classifier that uses a cascaded boosted rejection model to
detect body parts in images using the trained local
classifiers  we trained the opencv haar classifier
successfully using the image database but the    bit
opencv haar classifier consistently failed to malloc at
runtime  we will continue working on this 

   

image classifiers

we tested the following classifiers for classifying images 




random forests  with     trees  max depth of
    min sample count of     regression accuracy
of    no surrogates  no priors     max categories 
forest accuracy of      
boosting classifiers with max depth of       
weak classifiers  weight trim rate of     
 samples with summary weight      do not
participate in the next iteration of training   no
surrogates  no priors 
o adaboost  real  gentle and discrete
o logitboost

fisplitting criteria used  gini for real  miscclass for discrete and least squares error for logitboost and gentle adaboost 

   

image classification results

we experimented with different features and the two classes of images to see which classifiers fared better  to check the
relative importance of features and to determine the optimal values of the different parameters  we tested one run with mlp
as well  that took     hours to run  for the boosting classifiers half the set was presented as training set and half as test set 
for random forests      of the data was used as training data  in all cases  both training and test sets had a mixture of positive
and negative data  we considered k fold cross validation but didnt use it 

     

results for hue histograms

as the roc curves show the fp rate in all cases is extremely low         with tp rates      for hue for local  we did not get
good results with our set for global detection  accuracy is high in all cases  this validates that hue is a good indicator of skin and
can be used reliably for skin detection in local analysis  all boosting classifiers fared well 

accuracy

  

accuracy  

true positive rate    

roc curve
  
  
  

   
  
  
  
 

  

  
 hue bins

 
 

   

 

false positive rate    

   
random forests
logitboost

random forests

logitboost

discrete adaboost

discrete adaboost

real adaboost

real adaboost

gentle adaboost

gentle adaboost

figure    roc curves and accuracy graph for feature  hue  detection  local  image class    

  

  

fiaccuracy

  
accuracy  

true positive rate    

roc curve
  
  
  
 
 

   

   

   

   

  
    
  
    
  
    
  

 

 

  

  

false positive rate    

  

  

 hue bins

random forests

logitboost

random forests

logitboost

discrete adaboost

real adaboost

discrete adaboost

real adaboost

gentle adaboost

gentle adaboost

figure    roc curves and accuracy graph for feature  hue  detection  global  image class    

     

results for hue saturation histograms

as the roc curves show the fp rate in all cases is extremely low         with tp rates with peak      for hue saturation 
results are worse for global analysis  best models  gentle and discrete adaboost 

    

accuracy

  

  
accuracy  

true positive rate    

roc curve
  
  
  
 

  
  
  
  

 

   

 

   

 

 

 

false positive rate    

 

 

 h s bins

random forests

logitboost

random forests

logitboost

discrete adaboost

real adaboost

discrete adaboost

real adaboost

gentle adaboost

gentle adaboost

figure    roc curves and accuracy graph for feature  hue saturation  detection  local  image class    

 

fiaccuracy

   
  
 
 

   

 

   

accuracy  

true positive rate    

roc curve
   
  
  
 

 

false positive rate    

 

 

 

 h s bins

random forests

random forests

logitboost

logitboost

discrete adaboost

discrete adaboost

real adaboost

real adaboost

gentle adaboost

gentle adaboost

figure    roc curves and accuracy graph for feature  hue saturation  detection  global  image class    

     

results for histogram of gradients

we calculated the histogram of gradients of images  for both full and local classification  with    histogram bins  we got the
best results  tp rate      fp rate       with discrete and gentle adaboost  the other boosting models and random forests did
not fare well  this is kind of expected  full classification is a far harder problem than local classification and we wonder how the
histogram of gradients would fare as a feature in global image classification with large data sets 
results are far better for local classification with discrete and gentle adaboost returning      tp rates       fp rates and
     accuracy as the chart below shows 

figure    results for feature  histogram of gradients  detection  local  image class    

   

new filter  debrushing

during experimentation we realized that edge detection
would benefit from removing the internal pixels of a solid
object  we applied a method we call debrushing to
achieve this  below we show the results of applying this
method to some non sexual images  the results are
define a threshold t to be in the range         

promising and seem to be more effective in edge
detection for some images as we show below 
the pseudo code for this method is as follows 

fifor each pixel p do
begin
h    hue value of this pixel
for each pixel q that is in the  north  east  ne  se  of this pixel  h    hue value of q
if    h   h     t  for each combination of  p q   color p as red else color p as white 
end

this algorithm does not work well with rgb channels as might be expected  in essence  the above algorithm removes all pixels
that have very similar hue values to its neighboring pixels  as an example  following is the result of applying this filter to the
image of a dog against a grassy background  with a configurable hue threshold of    two neighboring pixels are considered to be
the same hue if their hue values differ by   or less   this filter removes all the grass instead of detecting the edges in them 

below is what cannys edge detector outputs for the same image  it shows the edges in the grass as well  the debrush filter
performs better in this case 

below are mona lisas pictures convolved using this filter 

fifigure    from left to right  mona lisa  original   using cannys edge detector  using my debrush operator with a hue
threshold of    using my debrush operator with a hue threshold of    
we did not get time to use the convolved images using suitable classifiers for edge detection and using edges as image features
but we will continue working on this 

 

extension of markov model

we propose an extension of the markov model to detect
edges in images  markov models have not been used in
image recognition  this might be relatively slow to run but
nevertheless is an interesting technique 
observation    the starting point of a random markov
walk does not matter  irrespective of the starting point 
one finally arrives at the optimal value functions and
optimal policy 
observation    at any time  it is possible to deploy
multiple agents simultaneously walking the set of states
and bookkeeping rewards and transitions with one agent
doing periodic policy and value function updates  one
would still finally converge and would converge at the
optimal value functions and optimal policy 
we do not prove the second observation but it is easy to
see why this would hold true 

these two observations imply that markov chains can be
executed on parallel threads in a large state space  this is
important  because we apply the markov model in edge
recognition in images with a large state space  the
cardinality of the state set is the number of pixels in the
image  before applying to this problem  the distributed
walk was implemented on the inverted pendulum problem
and worked well  we make one important observation  in
a multi agent markov walk where there is one thread that
does updates to the value functions periodically  the
update thread works slow because it performs a lot more
computations relative to the other say     worker
threads  the update thread needs to be prioritized with
higher priority and the others as low priority for this model
to work well  we added synchronization so the workers
would wait for the update thread to complete before
proceeding with the next iteration  without this  the
update thread will starve and not get enough time slices to
complete one update iteration 

fisimplification  

equivalently  we want to transition from p to a pixel q with
high value v but also such that p and q have similar hues 

consider the case where the result of a transition from a
state s upon action a is well defined instead of a
probability distribution  i e  t s a    s is well known
instead of being a probability distribution 

for further illustration  consider the following case  b and
r are   hue values that are completely different             
     are six pixels laid out with hue labels thus 

in this case  bellmans equation for the optimal value
function 

v  s    r s    s maxaa psa s  v  s 
simplifies to 

v  s    r s    sn s  maxaa v  s 
where n s  is the set of neighbors of s  the set of states
one can transition to from s  i e  
n s     s   s  t s  a   where the transition function t s  a 
gives the state reached from s on taking action a 
this simplification comes handy in case of large state
 

spaces by reducing the o n   term psa s  to an o n  term
 n being the cardinality of the set of states   thus reducing
computation and memory requirements  in our case  we
used a state space proportional to the size of an image in
pixels  the runtime memory requirement of our
application was in the order of gigabytes before this
simplification 

     are neighbors  so are                     and          and
  clearly both have high values  you are trying to decide
the best transition from    you have a choice to transition
from   to   or   to    clearly  to draw an edge the optimal
transition is from   to   because they have the same hue 
there are   actions for each pixel  transition to the pixel in
the direction n  e  ne and se  in a variant of this example 
consider the case where   has a lower value v than    the
best transition is still   to    for drawing the edge 
this example illustrates the role of the similarity function 
we define the similarity function for this example as 

extension

 s  s              where

we build upon simplification   in this extension  consider
a case where different transitions are possible from a state
s but the transition you want to make does not depend
only on the value of the new state but also on a function 
that is indicative of the similarity between s and s and the
reward the transition entails 

s  s are two neighboring states  pixels and

consider the example we use this model in  we want to
detect edges in an image  given any pixel that is on an
edge  to draw the edge you would want to transition to
the next pixel that has a hue value close to this pixels hue
value  however  there could be multiple candidates among
the   pixels in the n  e  ne and se directions to this pixel 
and a jump to the pixel closest in hue may eventually lead
you to a dead end  as in  going greedy short term may not
be the best choice long term   the best candidate pixel q
for a given pixel p is the one that is close in hue to p but
also neighbors pixels that are close in hue to itself 

     hue s   hue s    is the difference in hues of the two
states

the above function is defined such that  takes the value
  for two pixels with the same hue and   for two pixels
with hue values differing by     and is a real value in       
bellmans equation in this model is 

v  s    r s    sn s  maxaa v  s     s  s 
where  s  s  is a real in      

fi

and the value iteration algorithm becomes 

  
  

for each state s  initialize v s      
for every state  update



v s     r s    sn s  maxaa v  s   
 s  s 



we do not include a formal proof but the above algorithm
can be easily proven to converge since we replace the
probability function by a similarity function with range
       our test runs indicate that it converges  although it
can take time for a big image 
putting it all together
the extension and observations above allow us to treat
edge detection as a markov chain problem and detect
edges in images fast with multiple threads  the update
thread must be high priority and the others lower priority 
it helps to synchronize between the threads so while the
update thread runs  the others wait 
in the end  one needs to use the debrushing method when
the run is complete to zero out the internal pixels of a solid
object  the benefit of using this is we get more continuous
edges than debrushing alone 

 
using edge information in
image classification
we did not have time to use edge information in doing
classifications  svms with gaussian kernels have been
used in the past with reported success even with fuzzy
images for object recognition and we would like to try this
technique  histograms obtained by using the laplace 
canny  scharr filters to images can be used  so can the
debrushing filter we propose and the markov walk 

 

adultrank

we propose adultrank  a rank for web pages to indicate a
measure of adultness of the page  the concept is
somewhat similar to googles pagerank  prior to
establishing the concept  we observe 



porn sites have strong inter linkage and almost
form a closed set 
many porn sites link to facebook and twitter 
both clean sites 

some clean sites with unmoderated usercontributed content such as some wiki and blog
pages link to porn sites 
most other clean pages and sites do not have
outbound links to adult sites 
craigslist has a personals section which requires
age verification and is an adult section but the
rest of craigslist is kid friendly  some of the
craigslist discussions have expletives 

with this in mind  we propose adultrank  the range of
adultrank could be anything  but we assume here it to be
       
let  be the intrinsic adultrank of a page p  this is a
score computed by classifiers we use to classify the page 
we do not propose a detailed way to calculate this score
in this paper but assume it is calculated using a reasonable
heuristic 
let also i be the adultranks of the web pages p links to 
let  be the effective adultrank of p   is calculated as
follows  with w being a real in the       range  a good
estimate is      

if    maxi   i  
then    
else    w          w    max   i  

we do not include a formal proof of convergence for this
algorithm but it can be shown to converge  this also takes
into account the preceding bullet points in this section 
clean sites with user content are not unduly marked as
adult but they do accumulate rank  the rating of an adult
page is not diluted by having outbound links to clean
pages  craigslist personal section and adult discussions are
marked as adult but not other sections  adultrank flows
between interlinked adult sites and adult sites do not pass
on their ranks to outbound links  considering a threshold
 say   or     a browser could decide to block a site as adult
if its adultrank exceeds the threshold 
we have not yet experimented with the urls database to
check how adultrank fares in practice 

 

limitations

local image classification is more accurate than global
classification but there are limitations of this method 
certain pictures can be easily classified as adult by a

fihuman judge even if they do not show explicit body parts 
this method will also not be effective in judging fuzzy 
incomplete  cartoonish and unclear images 
markov walks are expensive and  unless this method is
further optimized  may not fare well on client machines if
real time image classification is the need 

 

conclusions

we got strong results with metadata analysis  which
proves that a nave bayes classifier would fare extremely
well for classifying sites and pages based on url  title 
keywords and content 
our experiments on image analysis with even a limited
data set shows that global analysis purely based on skin is
unreliable but a similar data set with boxed images
grouped into classes works reliably with     detection
rates based on hue alone and    hue bins  saturation
seems to be somewhat of a randomizing feature  as whilst
we noted monotonically better recognition rates with
increasing hue bins  we noticed worse performance when
saturation was added to the feature set and did not notice
any particular pattern with increasing number of bins as
one might expect  gradient of histograms is a strong
feature  we got tp rates exceeding      just like for face
detection  the local analysis method can be used in
conjunction with a viola jones classifier to do body part
detection in a bigger picture  the downside of this
approach is if the analysis needs to be done on a client
with low computing resources  this method would be
expensive 
the boosting classifiers  logitboost and variations of
adaboost  outperformed random forests by significant
margins in general  gentle adaboost worked very well in
most situations  we used the mlp perceptron as well but
that takes several hours for a run while the others take a
minute or less to train and test  we hit peak tp rates of
    with discrete adaboost in the hue based local case
and     with gentle adaboost in the hue saturationbased local case 
for global detection  the boosting classifiers hit peak    
tp rates but it is hard to tell if this is reliable  at best  we
conclude that boosting classifiers can be used as weak
classifiers for global analysis 
in all local and global analyses  we noticed low fp rates
and high accuracy  part of which is due to the negative
data set size being significantly larger than the positive set 

adultrank has a lot of promise and we will experiment
with this  we also want to use some of the edge detection
methods  such as svms with gaussian kernels  used in the
past using outputs from the laplacian  scharr filter 
cannys filter  the debrushing method and the debrushing
method applied after our markov walk 
an effective all round approach would be to use
adultrank followed by the nave bayes classifiers followed
by image classifiers 

references
    canny  j f   a computational approach to edge
detection  ieee trans  on pattern analysis and
machine intelligence  vol           pp          
    fleck  m  m   forsyth  d  a   and bregler  c         
finding naked people  european conference on
computer vision 
    bradski  g          programmer s toolchest the
opencv library  software at
http   opencv willowgarage com 
    rowley  h a  jing  y  baluja  s  large scale image based
adult content filtering 
http   static googleusercontent com external content un
trusted dlcp www google com en us research pubs arch
ive    pdf
    brin  s   page  l   the anatomy of a large scale
hypertextual web search engine 
http   infolab stanford edu  backrub google html
     page     page  l   brin  s   motwani  r   winograd  t 
the pagerank citation ranking  bringing order to the
web 
http   google stanford edu  backrub pageranksub ps
    jiang  z   yao  m   yi  w   filtering objectionable image
based on image content 
http   portal acm org citation cfm id         
    fei fei  l   fergus  r   torralba  a   recognizing and
learning object categories 
http   people csail mit edu torralba shortcourserloc ind
ex html

appendix a
code and some of the data will be made available on
http   www saikatsen info or http   www saikatsen com 

appendix b
the following custom applications were built during this
work on windows  some c   applications require win  

fiand need to be compiled in    bit mode  haar classifier
requires    bit build of open source opencv 

partitioning index between train and test data in a
matrix  without the shuffling  all test data would be
negatives 

custom c  apps   require  net     


custom c   apps 
crawler  given a set of sites  crawls them and outputs
outbound links  used to collect list of good and bad
sites  this tool lists subdomains as well in the
outbound list 



cladultfetcher  gets images from craigslist 
positives from personals  negatives from pets and
babies  all images for a post are downloaded  city
and section  pets  babies etc   are configurable 



imagelabeler  tool used to label and classify boxed
images  boxed using office picture manager   images
were classified into five classes only two of which
were finally used since they had the most samples 



adultguard  crawls sites and extracts title  keywords 
url  content  reads a blacklist and graylist file and
writes out   for word present and   for word absent
in csv format to an output file that can be fed into the
bayes classifier for training and testing 



createhaarindexfile  creates an index file for
consumption by opencv haarclassifier  the haar
classifier was trained successfully to this index file 



imagefeatureextractor 
imagefeatureextractorconsole  calculates histogram
of gradients  bins them into    bins and calculates  
in each bin  a second function can apply the debrush
filter to a specified image 



createadultdictionary  loads the princeton wordnet
dictionary  iterates through words user provides  lets
user bucket them into blacklist and graylist and
continues iterating  in the end  lets you save the
dictionary to files adult txt and gray txt  requires preinstall of wordnet 



datastructures  custom library with trie
implementation  used by other apps 



filerandomizer  given a file  shuffles the lines in the
file  this is needed so that positive and negative data
in a file is randomly shuffled into an output file that
can be partitioned into train and test data by
classifiers  opencv allows you to specify a



sampleapp  imagefeatureextractorhsv  calculates
hue and hue saturation color histograms  applies
canny  laplace filters 



sampleapp  classifier  the master program that runs
random forest classifier  boosting classifiers  nave
bayes and mlp on train and test data  and reports
test and train recognition  rate and tp  fp  tn  fn
data 

machine learning code  image recognition code 


opencv  http   opencv willowgarage com 

fi