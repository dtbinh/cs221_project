domain adaptation for relation extraction
daniel posch  sheldon chang  matthew watson
 dcposch  sheldonc  mdwatson  stanford edu
mentored by mihai surdeanu and david mcclosky
          
abstract
we describe our experiments with domain adaptation strategies in order to boost the performance
of the javanlp relation extraction system built by stanfords natural language processing group  we
implemented a domain adaptation preprocessing step known as easyadapt as well as a confidenceweighted linear classifier with domain adaptation and compared them to several baseline strategies    
easyadapt outperformed all baselines 

 

 

introduction

   

prior work
relation extraction

several different approaches have been tried for algorithmically extracting relations from textual data 
such algorithms might discover  for example  that
ronald reagan succeeded jimmy carter in office  or
that wheels are part of a car  they generally fall into
supervised approaches  which take a corpus of text
labeled with known entities and relations  and unsupervised approaches  which discover new relations
directly from unlabeled text  the stanford kbp
algorithm    focuses on an in between approach described in     mintz et al   relation extraction via
distant supervision  the algorithm parses input text
into a collection of sentences  an example for a relation is simply a pair of entities  and each sentence
containing that pair is assumed to express that relation  if one of the examples for person child
is  darth vader  luke skywalker   then the sentence in episode vi  luke skywalker is shocked to
learn that darth vader is his father would match 
each tuple of  entity   entity   sentence  is
then turned into a large vector of featuresfor example  the words that occur between the two entities
and the relative positions of the entities in a syntactic
parse tree  each feature is encoded as a string 
finally  the algorithm creates a set of training examples  xi   yi   where xi are feature vectors and yi are
the corresponding relation labels  known in knowledge base population as slots  it trains a classifier

relation extraction means identifying instances of
relations  such as created by or part of   in our
case from a body of text and a set of initial examples  it is part of the larger field of knowledge base
population  our goal was to make an existing relation extractor perform well on text from multiple
domains  such as wikipedia and newsgroup articles 
the system begins with positive examples of each relation suppliedin other words  the knowledge base
does not start out empty 
the main focus of our project is applying domain adaptation strategies to the kbp system in
the hope of improved performance  traditionally  domain adaption has been about making learning models perform well on domains other than the training 
or source domain  in our case  both our training
and testing data is heterogenous  ie  from multiple
domains   we apply domain adaptation with the intuition that different sources of training data will provide different feature weights  so it is a mistake to
treat them all equally 
to our knowledge  and as far as our mentors in
the nlp group are aware  we are the first to explore
domain adaptation on a complex information extraction system 
 

fion this data  during testing  the system is queried
with an entity and asked to populate the predefined
relations using other named entities that appear in
sentences with the query entity  these sentences 
like the training examples  are drawn from newsgroup
text  web snippets  and wikipedia  a candidate feature vector is then constructed for the original entity
and the extracted named entity  and this feature vector is then classified as one of the relations or a no
relation category 

knowledge base      of the entire data available  
with half of the data used as training and the other
half as testing  the train and test sets each contained roughly    mb of text  sentences were extracted with a known slot type in the same manner
as in training  we then scored the classifiers ability
to predict the correct slot type for a given sentence
by measuring precision  p   recall  r   and f score
 f    p r
 pr   

   
   

easyadapt

domain adaptation

the first and simplest strategy we implemented is
described in     daume        in that approach  we
simply expand the feature space by adding one copy
of each feature per domain  in addition to the generic 
domain independent original  for example  if a sentence comes from a web snippet and has feature x 
then we will augment its feature vector to also contain
web x  it will not contain news x or wiki x  if the
original feature space was n dimensional and we are
adapting our algorithm to d domains  then the new
  methods
feature space is n d      dimensional  each feature
now has a general version as well as d domain specific
for this project  we sought to improve the perforones  when we train a classifier  we are determining
mance of the existing kbp model by implementthe relative importance of each feature for predicting
ing the easyadapt feature augmentation strategy
instances of each relation  as well as the importance
 daume        and the confidence weighted multiof each feature in each specific domain 
domain linear classifier described in     dredze and
crammer  
we evaluated these systems against several base      dredze and crammer
lines 
we implemented a more involved domain adaptation
domain adaptation in nlp is the challenge of enabling algorithms to perform well on text written in
the same language but in different formats or styles 
and to be able to train algorithms on similarly disparate input 
we have experimented with several domain adaptation strategies 

strategy based on a generalization of the perceptron
algorithm  confidence weighted online linear classifiers work by assigning a variance to each feature
weight      whenever a new example xi arrives  the
classifier updates its weights as little as possible to acwebonly  newsonly  wikionly
comodate it  following the authors convention  the
using each domain individually as a source do  weights after step i are i and the variances i   repmain  e g  training on just web snippets  then resented as a diagonal covariance matrix  the update
testing on all three domains 
rules are 
i     i   yi i xi
linint training three separate classifiers on each
 
t
domain  then linearly interpolating the result 
i     i    xi xi
ing classification probabilities
as dredze notes  the uncertainties associated with
as daume noted  these baselines are surprisingly each weight are strictly decreasing as training prodifficult to beat  his easyadapt strategy managed gresses 
for our setting  we needed the classifier to handle
to surpass all of these baselines  and several others 
on a large variety of datasets  making it one of the multiple labels  the classifier described in the paper 
however  is binary  we used another technique  by
few models for domain adaption to have done so 
we evaluated the baselines and the domain  crammer  to do multiclass classification      unlike
adapted systems on a smaller version of the kbp its binary counterpart  the multiclass cw classifier
all using the union of all three domains as the
source domain for the classifier  this is the behavior of the original kbp system implemented
by surdeanu et al 

 

fihas an update rule that cannot be expressed as convex optimization  nor is it solvable in closed form  as
a result  we had to choose among the several heuristic
update functions the paper described  we chose the
simplest function to start withthe single constraint
update  this takes a form very similar to the update
rule of the binary classifier  in our case  it simplifies
to

xi   while r is the highest scoring label accoring to
the weights after step i  much like a perceptron  no
change is made to the parameters when the system
guesses correctly  ie when yi   r 
we implemented and tested this classifier by itself
and using daumes feature augmentation as a preprocessing step 
finally  we implemented domain adaptation by
leveraging the measures of confidence the classifier is
able to assign to each feature weight  we trained
a confidence weighted classifier separately for each
source domain  then linearly combined the resulting
weight vectors according to each weights confidence 
as described by     dredze and crammer   that paper described four different ways to combine weights 
we picked one that was both simple  and  in their
tests  effective  it simply takes the weighted average of the classifier   weighting each element by a
constant minus the corresponding sigmaso that elements with low sigma  high certainty  are weighted
heavily 

i   yi   i   i i yi xi
i   r   i  i i r xi


t
i      l   
i l      i   l   yi  l   r xi xi

 

   where ai is given by
     mi    

p

      mi       mi  vi  
 vi

mi   i yi  xi  i r  xi and  is a learning aggressivness parameter  here  yi is the correct label for

 

results

we had a few surprises come out of our results  easyadapt was the only domain adaptation strategy
that produced an improvement in f score over the original algorithm  all  which simply lumps text from
multiple domains together as one input corpus   interestingly  text from web snippets turned out to be
almost as good as the entire input corpus  we had initially suspected that this would be the case for the
more consistent wiki sentences 
linint  which interpolates between web  wiki  and news  achieved its highest score by only using
web  as shown below 

 

fifinally  we evaluated the original  unmodified javanlp relation extractor on the same labels  slots 
shown in     mintz et al  

using easyadapt  we achieved improvement over almost all relation slots  considering that javanlp is
fairly mature software  we are pleased with this result 

 

future work

heuristic for the online multiclass confidenceweighted classifier described in  dredze et al  
the paper notes that the cost function each update tries to minimize is not convex  nor does
it have a closed form solution  as such  updates
are necessarily heuristic 

we may explore additional domain adaptation strategies as the nlp group prepares for the      text
analysis conference  we are hoping to enter submit
our results to a workshop at this conference  stanfords relation extraction system may also compete
in the conferences knowledge base population competition  with mihais guidance  we are considering
several future directions for the project 

 

discussion and conclusion

as our results indicate  for most relations the
easyadapt classifier outperformed the baselines  we
suspect that the reason why we saw these improvements is because augmenting the feature space allows
the system to account for the fact that domains that
see a lot of a certain type of relation will perform
 testing the remaining three classifier weight better on that relation  contrast this with linint 
combination methods described in  dredze  where even if a certain relation was predicted with
high confidence in one domain  it was often negated
crammer  
by the fact that the other domains had not seen the
 implementing a more sophisticated update relation and predicted a nr label 

 switching our classifier from mention level to
relation level  in other words  collapse all instances of a given relation  e g    bill gates 
org founder  microsoft  into a single vector 
based on     riedel et al   ecml       

 

fithe dredze and crammer model is theoretically
immune to this problem  since it takes confidence into
account  however  it did not perform quite as well as
easyadapt  this may be because the drezdes multiclass confidence weighted linear classifier has an imprecise  heuristic  update step  we may experiment
with different update steps and different weighting
algorithms in future work 
linint tended to push every predicted label towards the nr  no relation  label  it would only predict a positive label when there was a fair amount of
confidence across all domains  which did not happen
often  this lead to high accuracy as it was making
obvious choices  but poor overall results 
in our examination of the feature weights
across all models  it was clear that some fea 

tures were highly predictive for certain categories 
for example  the feature span word chairman
had a very high weight for the labeling
organization top membersslashemployees 
other features that consistently demonstrated high
feature weights include the trigger words used by
surdeanu et al in their sentence retrieval  however 
other features had very little predictive power  and
from initial observations  the parse tree features did
not carry a lot of weight  experimenting with feature
categories and seeing which ones the classifier deems
important is one area we can investigate in the future  as using fewer but more relevant features would
improve training speed  preliminary experiments in
feature tweaking were able to further boost our f 
score by roughly     

references
    task
description
for
knowledge
base
population
http   nlp cs qc cuny edu kbp      kbp     taskdefinition pdf

at

tac

    

    mihai surdeanu  et al  a simple distant supervision approach for the tac kbp slot filling task
proceedings of the tac kbp workshop       
    mike mintz  steven bills  rion snow  and dan jurafsky        distant supervision for relation extraction
without labeled data http   www stanford edu  jurafsky mintz pdf

    hal daume iii        frustratingly easy domain adaptation http   www umiacs umd edu  hal docs daume  easyadap
    mark
dredze
et
al 
     
confidence weighted
http   www cs jhu edu  mdredze publications icml variance pdf

linear

classification

    mark dredze and koby crammer        online methods for multi domain learning and adaptation
http   www cs jhu edu  mdredze publications multi domain emnlp   pdf
    koby
crammer
et
al 
     
multi class
http   www aclweb org anthology d d   d        pdf

confidence

weighted

algorithms

    sebastian riedel et al  ecml       modeling relations and their mentions without labeled text 
http   www springerlink com content           qm rw  fulltext pdf

 

fi