potentials  psps   wehr and zador 
       if spikes had not been blocked
pharmacologically  the larger psps would
likely have triggered spikes  with  at most 
two to three large psps per second  the
activity of these neurons is temporally
sparse 
neurons sometimes showed striking
kevin nam truong  moorxu and daniel hawthorne
trial to trial reliability  consistent with the
neural prediction challenge  primary auditory cortex
high trial to trial reliability of spike count
reported previously  deweese et al         
i 
introduction
this is particularly evident in the central
panel of figure   e  in which the responses
to repeated
presentations of the same
the typical model of cortical processing assumes that it an inherently noisy  possibly degenerate 
process 
are nearly
however  recent findings have shown that individual cells in the primary auditory cortex of a rat couldstimulus
be described
as identical  reliability
was stimulus
dependent  the same neuron
a binary process  rather than a highly variable poisson process  as illustrated in figure    picturing neuron
e and fs
less reliable for a different stimulus
response in different trials to the same stimulus  a  neurons are highly selective and consistent in theirwas
responses 
 fig    e  right panel  
to quantify the amount of stimuluslocked activity  we compared a single response trace with the average over the remaining trials  a sample comparison  fig 
 a  same data as in fig    d  e  left panel 
shows that the deviations of a single trial
from the average primarily involved the
fine structure of the voltage fluctuations 
to quantify this observation  we computed the coherence function between the
single and average traces  the coherence
measures the frequency resolved correlaneural responses of neuron e and f to stimulus kf 
tion of two time series  see materials and
methods 
andtoranges from zero  absence
given the hypothesis that neural responses form consistent representations of the stimulus we
endeavor
of stimulus locked activity  to one  when
form a deterministic mapping between the neural responses to auditory stimuli 
all traces feature the same stimulus locked
a number of coding schemes such as rate coding  temporal coding  population coding  and sparse
coding
excursion in membrane potential   the
have been proposed to explain how continuous neural responses represent information  recently in anaverage
extreme
version functions correspondcoherence
of temporal coding patrick suppes et al   found that they were able to distill the neural representation of
wordsexamples in figure    d
ingspoken
to the three
through averaging the spike data across large swaths of auditory cortex  and then representing this signal
with
the
and
e 
are
shown
in figure  b  these funcfigure    responsive and unresponsive cells  we used in vivo whole cell methods to record subthreshold responses of single
superposition of a few
sininwaves 
wea  endeavored
to compare
this method
to a population
scheme
the
tionswhere
demonstrate
the typical range of
neurons
auditory cortex
action potentials were
blocked pharmacologically 
a  b  responses
of two cells tocoding
conventional
origin of the neural signal
leveraged
as a potentials
feature 
pure tone is
stimuli 
evoked membrane
are shown for an array of frequencies and intensities  the loudest tones are on the stimulus independent background activity dawley
observedrat
in the experiments  all cells
top row  
both cellssingle
exhibitedcell
robustrecordings
responses to pure
with typical
v shapedcortex
tuning  and
had similarofcharacteristic
we used the
attached
of tones 
primary
auditory
neurons
the sprague
  kf  
frequencies
of     khz   a  andresearch
  khz   b   c  d  in
spectrogram
of a   sec segment
of the call of a knudsens
frog  stimulus
feature reliable
activity for lower frequenmade available through
the  cfs 
collaborative
computational
neuroscience
 crcns 
organizations
auditory
e  f  responses of these two cells to this sound were strikingly different  in e  this stimulus evoked robust and reliable responses  cies      hz   however  when presented
cortex data set the first
step was to process the data  pictured raw for one penetration below 
whereas in f  after a transient onset response  the cell was completely unresponsive  the cell in f was similarly unresponsive to all with the right stimulus  the coherence insix natural stimuli tested  data not shown   g  this stimulus contained power at the cfs of both cells  arrows show cfs  colors creased dramatically  the light gray curve
match traces in a  b  e  and f    in fact  stimulus power was greater at the cf of the unresponsive cell  h  most cells in our sample had
 bm  shows the coherence corresponding
cfs of    khz  arrows show cfs of the two cells in a  b  e  and f  i  responsiveness to natural stimuli varied across cells  here 
to the central panel in figure    d and e 
responsiveness is quantified by the sd of the membrane potential evoked by natural stimuli  note that nonstimulus evoked
response reliability also differed from
activity also contributes to this measure   arrows show the different responsiveness of the two cells in e and f 
cell to cell  figure  c displays the average
magnitude of the stimulus independent
properties  such as mean intensity  fluctuate over time   these
activity  to compute this quantity  the variance of the response
properties distinguish natural sounds from conventional artifiabout its mean was averaged over time  see materials and methcial stimuli  which are either deterministic stimuli  such as movods   in all cases  the average magnitude of the noise     mv  is
ing ripple stimuli  or stationary random stimuli  such as random
small compared with the magnitude of the psps        mv  
chord stimuli   the spectrograms of three example sections of
emphasizing the overall reliability of the responses 
natural sounds used in this study are shown in figure   d 
spectrotemporal receptive fields
response reliability
in the next step  we characterized the linear component of the
responsive neurons typically showed a combination of both
stimulusresponse relationship  this task is considerably simplispontaneous and stimulus locked voltage fluctuations in refied when the stimulus is represented by a spectrogram  cohen 
sponse to natural stimuli  figs    e    e   both spontaneous and
      klein et al          see materials and methods  as in figure
stimulus locked responses are presumably attributable to the
   c and d  and figure   d  the spectrogram provides a rough

to do this  we identified the location of each trigger in the neural response in order to divide the neural
response into two portions  the spontaneous response  background neural signal  and the evoked response from the
auditory trigger  we filtered out the neural signals that did not pertain to the trigger response  and isolated the portions
of the signal that might have been induced by our trigger 
from our preprocessing we could determine whether the characteristic frequency for each penetration was
unique  as we would expect given previous findings  we found that the characteristic frequencies were distinct as
pictured below in the side by side tuning curves  t       p         

fituning property of penetration  
ii 

tuning property of penetration  

support vector machines for neural prediction

in hopes of an accurate prediction  we initially ran a svm using the evoked period neural traces as our
training data  we aggregated the trigger frequencies into two classes    low frequencies and high frequencies    and we
then did a linear two class svm using the liblinear package in matlab  this yielded an initial accuracy of       
we then pursued a number of avenues to improve the accuracy of our svm algorithm  we took the discrete
fourier transform of the neural trace to convert the data into the frequency domain  testing suppes method in which
he encapsulated the trace into a small subset of the highest amplitude frequencies  we took the five most prominent
frequencies of the fourier transformed neural trace  we then ran the two class linear svm using this as our training
set  in order to correct for artifacts induced by the fast fourier transform  we applied a hamming window function to
the result  training on the five highest spikes gave the same accuracy of       as training on the raw data 
to contrast with suppes averaging method we separated out the data by penetration  neuron  to allow the
learning algorithms to do population like coding  grouping responses by specific neuron improved our our accuracy to
      in the binary two class case  we also tried using a gaussian kernel for the svm instead of the linear kernel  this
was done using the libsvm package for matlab  and we achieved a slightly better accuracy of       

summary of our binomial svm implementations 
note that grouping by neurons induces the most
significant rise in accuracy
up to now  we see that our algorithm can distinguish between low frequencies and high frequencies with
fairly good accuracy  we wanted to expand our problem by separating the original    different pure tones into four
frequency ranges  using four classes and   classes and   penetrations we first attained an accuracy of        not much
larger than what would be expected by chance  with a larger data set we attained an accuracy of       using   classes
and   penetrations  indicating that our hypothesis may have not yet converged  and that we are at least partly
bottlenecked by the number of training samples 
in addition to using the raw neuronal response data or the most prominent frequencies  we also tried to
predict trigger frequency using other features  for example  we computed the running average of the response trace and
used this running average as our training examples  heuristically  this running average captures the trend of the
neuronal response trace  and indeed  we attained an accuracy of       using   classes and   penetrations

fiusing only three penetrations we achieved an accuracy of only       compared to the      we achieved with
five  including more penetrations increases the accuracy as indicated in the graph below  even with the increased
sample size  by a factor of      that was available when reducing the number of penetrations  our algorithms accuracy
was better using all five penetrations  this indicating that having multiple different neurons was more important than
having more many training examples  even controlling for the difference in information contained in each training
point in the two conditions 

accuracy versus number of penetrations  which varies
inversely with number of training samples

iii 

confusion matrix using four class labels and five
penetrations

experimental svm

even through all of our processing of the data  liblinears svm was unable to properly predict the tonal
frequency from the neural signals  across the    multiclass labeling of the tonal frequencies  liblinear was able to
predict on average    of the test data using hold out cross validation  our test error is therefore      and at the same
time  our training error is surprisingly at     this suggests that we were overfitting our data 
it is our goal to be able to better classify this multiclass labeling of tone frequencies  and we believe that there
exist a better algorithm to process the data and extract features from it would significantly increase the accuracy and
reduce our problem of overfitting  our main motivation in further processing the data comes from the fact that each
neuron has a different tuning curve  instead of clumping all five neuron data into one matrix  it would be more natural
to mimic the neurons and train on each separate neuron individually  and only after do we have five separate trained
models do we aggregate them into a single model 
as a result  we attempt to add a new layer of svm training to our data  in our outer most layer  we have
our original data matrix  that contains the top   spikes in each of the   penetrations in each row  split into five separate
matrices  one for each penetration area  we then train five svm models  one for each penetration  after training the
model  we extract the confidence vector of each penetration  which has size n  where n is the number of total labels we
have  each entry corresponds to a specific label  indicated by the label vector that we extracted   and contains a real
number  the index to highest entry in the confidence vector is read into the same index in the model label vector  and it
is this entry in the label vector that indicates what label the svm predicts 
normally  the svm would only output the label with the highest confidence value  however  we believe that
valuable information is lost this way  we instead normalized the magnitude of each entry in the confidence vector to
range from   to    and raised every term to the fifth power  as a result from trial and error  to greatly reduce the weight
of less confidence labels while keeping the high confidence ones at approximately the same value  we then normalized
the labels vector such that the lowest frequency is replaced with the entry    the second lowest with entry    and so on 
we now treat the confidence vector as a vector of weights with each weight corresponding to the same entry in the
labels vector  we then do a weighted average of the normalized labels vector  which gives us a single number that
indicates the best weighted guess influences not just by the most confident label  but also the second  third  and other
less confident labels  we believe this number tells us more about each neurons prediction of the tone than just finding
the most confident label 
we repeat this for every m training samples  and eventually receive five m by   vectors  one for each
penetration  with each entry corresponding to the best weighted guess of that particular training sample  we merge
these five vectors into a single aggregate matrix  this aggregate matrix has five entries per row  each corresponding to

fia specific penetration areas best weighted guess  this matrix makes more intuitive sense to predict that the original
data matrix because we are treating each neuron as a specific feature instead of treating each neurons top   spike as a
specific feature  in the latter case  we would have a matrix    entries    neurons    spikes each   but this is actually five
groups of five unordered features  libsvm cannot distinguish between ordered features and these unordered features
within each penetration area  and thus we believe is a flaw in predicting the tonal frequencies 

as a result  our accuracy significantly improved from    to a peak of      we believe this result to be
considered impressive  as we are trying to classify    different labels from a sample of    training sets  where    of
them are training samples and    are tests  that means on average we have three training samples per label  and this
layered svm was able to predict the correct label one fourth to one third of the time  our testing error increased from
   to an average of      which indicates that we are no longer overfitting our data 
although the numbers are still low in an absolute scale  we believe that it is due to the bottleneck of the
number of our training samples  we attempted to further overfit and underfit the data with other various features 
including the gaussian kernel  and all returned with either the same or less predictive power  this idea is further
supported by the fact that if we reduce the number of distinct labels  as in demarcating them into intervals  e g  high
frequencies and low frequencies   our accuracy significantly improves  without this layered svm  our accuracy of a   
multiclass label is     with a multiclass of   labels  our accuracy averages      and with a binomial label  our
accuracy rises to above     
iv 

neural networks

ficonfusion matrix for neural network
a standard three level  feed forward  back prop neural network was also used to classify the neural signals 
a number of different feature schemes were used  each representing a different way of coding the neural data   the
best network used a variant of a standard running average measure of the membrane potential  taking into account the
origin of the signal  which neuron the signal was from   this neural nework had an average training error of     the
confusion matrix for this network is shown below  the comparable training and testing errors indicates that the
algorithm is able to generalize well  which was not the case with alternative coding schemes 
v 

conclusion

consistent with previous findings we determined that different penetrations in a  had unique characteristic
frequencies  and their tuning curves were determined  first in a test of suppes theory we averaged across neural
signals and represented the responses as the primary frequencies of the spectral decomposition and used these
frequencies to predict the stimuli that generated the neural responses  this method was unsuccessful at predicting the
stimuli  utilizing the unique characteristic frequencies of each penetration is a population code yielded significantly
better results  and characterizing the neural traces with a modified running average was more useful than the five best
frequencies of the spectral decomposition  all neural signal coding schemes were used to characterize the neural
response in order to predict the stimuli that elicited them with both support vector machines and neural networks  as
more data and penetrations were added the results of both algorithms increased indicating that with more penetrations
and data a better estimate of the initial stimulus is possible 

references
 

deweese  m   wehr  m   zador  a   binary spiking in auditory cortex   journal of neuroscience research        
suppes and han brain wave representation of words by superposition of a few sine waves  proceedings of the
national academy of sciences of the united states of america        vol          pp      
 
m  zador  a   linearity of cortical receptive fields measured with natural sounds   journal of neuroscience research 
      
 
r  e  fan  k  w  chang  c  j  hsieh  x  r  wang  and c  j  lin  liblinear  a library for large linear
classification journal of machine learning research                    
 

fi