Journal Artificial Intelligence Research 53 (2015) 41-90

Submitted 03/14; published 05/15

Learning Relational Event Models Video
Krishna S. R. Dubba
Anthony G. Cohn
David C. Hogg

krishna.dubba@gmail.com
a.g.cohn@leeds.ac.uk
d.c.hogg@leeds.ac.uk

School Computing, University Leeds,
Leeds, UK. LS2 9JT

Mehul Bhatt
Frank Dylla

bhatt@informatik.uni-bremen.de
dylla@informatik.uni-bremen.de

Cognitive Systems, SFB/TR 8 Spatial Cognition
University Bremen, Bremen 28334, Germany

Abstract
Event models obtained automatically video used applications ranging
abnormal event detection content based video retrieval. multiple agents
involved events, characterizing events naturally suggests encoding interactions
relations. Learning event models kind relational spatio-temporal data using
relational learning techniques Inductive Logic Programming (ILP) hold promise,
successfully applied large datasets result video data.
paper, present novel framework remind (Relational Event Model INDuction)
supervised relational learning event models large video datasets using ILP.
Efficiency achieved learning interpretations setting using typing
system exploits type hierarchy objects domain. use types
helps prevent generalization. Furthermore, present type-refining operator
prove optimal. learned models used recognizing events
previously unseen videos. present extension framework integrating
abduction step improves learning performance noise input
data. experimental results several hours video data two challenging real
world domains (an airport domain physical action verbs domain) suggest
techniques suitable real world scenarios.

1. Introduction
advent digital technology wide availability cameras video recorders,
quantity video data increased enormously recent years, e.g., YouTube users
upload 100 hours video site every minute (YouTube, 2015). data
semantically rich lack algorithms process utilize data effectively.
number applications demand video processing, especially event modelling
recognition, content based video search, robotics, automatic description
activities, video surveillance etc. main objective work provide supervised
relational learning framework learn high level human understandable event models
use recognize events video. Supervised learning machine learning task
inferring model labelled training data.
c
2015
AI Access Foundation. rights reserved.

fiDubba, Cohn, Hogg, Bhatt & Dylla

Video considered sequence images area video analysis poses several
challenges. interesting aspect video compared images objects
(or parts objects) video perceived move space time. changes
state space dimension interesting call events satisfy certain
properties sufficiently frequent sufficiently well defined boundaries
etc. event change state single object, moving parts
body (for example people waving hands) interaction multiple
objects. interactions, context, mean movement objects relative
surroundings well relative other. example, interaction
two objects might objects moving towards one rest
moving away it. events recognized, assume objects involved
detected tracked source video. requirement general
since approaches (Laptev, 2005) require detection objects prior event
detection.
events involving multiple objects, interactions objects become distinguishing factor recognizing event instance. Capturing interactions crux
event modelling recognition hypothesis event distinguished
interactions objects involved. events might one
interaction pattern identifies event. One way capture interactions
abstract interactions relations objects. order represent interactions objects abstract form, use relations objects depend
spatial configuration motion pattern objects period time. call
spatio-temporal relations paper focus purely use qualitative
spatial relations since abstract away metric details particular object trajectories thus facilitate recognition interactions instances event
class (Cohn et al., 2006). unique way represent interactions using qualitative
spatio-temporal relations, best set relations use depends domain, kind
data available (speed, orientation, size moving objects, etc.) objectives
task.
Though event class distinguishing interaction patterns, two particular
challenges event learning examples expressed qualitative spatio-temporal relations. Firstly, automatic object detection tracking video perfect
introduce errors relations. Secondly, event may performed different
ways.
1.1 Overview Framework
follow relational learning approach cognitive vision task learning event
models videos using recognition (Cohn et al., 2006; Dubba, Cohn, &
Hogg, 2010). video data (sequence images pixel data) converted relational
facts involving qualitative spatio-temporal relations using tracking data objects
involved scenes. use several qualitative spatial calculi represent video
data relational form. Event instances annotated temporally spatially though
objects involved event delineated separately annotations used
obtaining positive negative examples events. learning procedure well
42

fiLearning Relational Event Models Video

extension procedure using abduction (explained later sections) applied
relational data obtain event models. event models form
Prolog rules used queries relational data unseen video.
answer substitutions extract spatial temporal extensions recognized event
instances.
main contributions1 paper are:
novel supervised relational learning framework remind learning event models
video recognizing event instances using models.
optimal Type Refinement operator upward refinement hypotheses exploits type hierarchy domain finding better event models.
extended framework integrate induction abduction interleaved fashion
embedded spatial theory improving learning event models.
evaluation framework two real world video data sets (aircraft turn-arounds
events include aircraft arrival, luggage loading human interactions
events common action verbs exchange, follow, dig etc).
Though concentrate relational data obtained tracking objects video,
principles techniques work equally apply spatio-temporal relational data
acquired non-visual sources (e.g. laser mapping, GPS tracks, textual descriptions etc).

2. Related Work
Much work event analysis (Ivanov & Bobick, 2000; Medioni, Cohen, Bremond,
Hongeng, & Nevatia, 2001; Vu, Bremond, & Thonnat, 2003; Albanese, Moscato, Picariello,
Subrahmanian, & Udrea, 2007; Ryoo & Aggarwal, 2009, 2011; Morariu & Davis, 2011),
involve learning models used. Instead high level event models hand-coded
using different representations (Nevatia, Hobbs, & Bolles, 2004; Hakeem, Sheikh, & Shah,
2004).
Techniques based similarity based metric space low level pixel based
features local space-time features (Laptev, 2005) frequently used modelling
recognizing events. generally suitable single agent events human
activities based motion. kind activities generally include particular motion
signature event recognized running, jumping, waving hands
etc. event recognition systems, hand-coded high level event models used top
learned low level human activity models (Ivanov & Bobick, 2000; Ryoo & Aggarwal,
2009, 2011).
One best performances date event recognition using low level pixel-based
features obtained Stack convolutional Independent Subspace Analysis (ScISA) (Le,
Zou, Yeung, & Ng, 2011) algorithm. ScISA based pixel level flow based features
used model events using hierarchical representation using deep learning
techniques (Bengio, 2009). authors present extension Independent Subspace
1. paper extended version work Dubba et al. (2010, 2012).

43

fiDubba, Cohn, Hogg, Bhatt & Dylla

Analysis learn invariant spatio-temporal features unsupervised fashion instead
using predefined features.
events considered sequence primitive states events, state-space models
useful representing event models. easy hand-code structure
state space models, though parameters better learned encoded hand.
provide robust statistical event model hand-coded models event recognition
done using inference models. Bayesian Networks popular event
modelling lack temporal aspect though state space models Hidden
Markov Models (HMM) (Rabiner, 1989) Dynamic Bayesian Networks (DBN) (Ghahramani, 1998) extensively used event modelling recognition. simple HMM
effective modelling complex events. Several extensions HMM used suit
context type event models. Hoogs Perera (2008) proposed DBN jointly
solving event recognition broken tracks linking problems. event model set
discrete states expresses actors event interact time. assume
states strictly ordered may limit learning events involve complex
temporal relations during, overlaps etc.
main problem state space models difficult encode high-level
temporal relations during, overlaps etc. states sub-events event
assumed sequential order case many domains.
states propositional nature hence semantically less complex relational
representation.
Veeraraghavan et al. (2007) learn Stochastic Context Free Grammar based models
traffic videos using predefined regions image. event model spatio-temporal
pattern primitive actions expressed string, = a1 , a2 , . . . , . event learning
algorithm aims find grammar generate corresponding pattern event.
primitive actions sequentially arranged, hence Allens temporal relations
used connect primitive actions. Gupta et al. (2009) claim fixed structure
DBNs poses serious limitations modelling events many variations
way event happen. Instead use AND-OR graphs modelling event models.
order nodes imposes causal relationship among nodes. this,
Allen relationships during, overlaps etc. cannot modelled limits
application since modelling relations important many domains.
Though low-level features state space models popular simple motion patterns,
possible build high-level event recognition systems several layers reasoning.
systems use simple pattern recognition techniques detect primitive events
use temporal structure reason complex events. main motivation using
high level temporal structure low level features (like bag-of-features) discard
information regarding relations different entities data
thus makes hard recognize events involving complex interactions multiple
objects.
Moyle Muggleton demonstrated using simple blocks world domain specific
axioms learned temporal observations using ILP framework (Moyle & Muggleton, 1997). work Needham et al. (2005), Progol system (Muggleton, 1995)
used learn protocols table top games real sensory data video camera microphone. key aspect work method spatio-temporal attention
44

fiLearning Relational Event Models Video

applied sensor data audio video devices. identifies subsets sensor
data relating discrete concepts. Symbolic description continuous data obtained
clustering within continuous feature spaces processed sensor data. Progol
ILP system subsequently used learn symbolic models temporal protocols present
presence noise over-representation symbolic input data. framework
based time points used successor temporal relation.
Konik Laird (2006) proposed learning observation framework learn agent
program mimics human experts behaviour domains games. learned
concepts used generate behaviour rather classification. applied ILP techniques artificially created examples expert behaviour traces goal annotations.
relational data used simple predicate valid situation (an abstract time
point) hence concepts sophisticated temporal relations Allens interval
algebra (Allen, 1983) use intervals cannot learned. limits real world applicability framework different events occurring parallel hence
requires using Allens interval algebra model them. framework uses positive
examples negative examples generated randomly controlled fashion.
Fern, Givan Siskind (2002) introduced system, leonard, learns event definitions videos following standard specific-to-general learning approach
positive data. seven simple event types learned system namely
pick up, put down, stack, unstack, move, assemble disassemble. relational data
obtained tracking objects indoor scenarios. negative examples supplied
event models found computing least-general covering formula (LGCF)
positive example computing least-general generalisation (LGG)
resulting formulae. computing LGCF example, resulting LGCF
interval information. Hence model support equal
temporal relations states.
important aspect note review work area
done either artificial simulated data (Moyle & Muggleton, 1997; Konik &
Laird, 2006) simple real world data (Fern et al., 2002; Needham et al., 2005)
involves objects, events short duration objects scene
involved events. case, tracked data videos large
time complex noisy contains objects.
Several attempts made literature integrating induction abduction
learning better theories. pointed Tammaddoni-Nezhad et al. (2006) abduction induction integrated general two conditions hold: background
knowledge incomplete hypothesis language disjoint observation language. setting latter condition holds called non Observation Predicate
Learning (non-OPL) setting (i.e. OPL setting, examples hypotheses define
predicate). assume existence theory connects hypothesis
language observation language start with. Since theory learned,
considered background theory. general strategy case abduce (Kakas & Riguzzi, 2000) missing observations using background theory use
abduced data inducing new theories. Muggleton Bryant (2000) proposed Theory Completion using Inverse Entailment (TCIE) non-OPL setting. TCIE abduces
adds facts called Start Set connect target predicate observable pred45

fiDubba, Cohn, Hogg, Bhatt & Dylla

icates observation data generalizes data. case, missing facts
noise observed data set target predicates set
observables whereas TCIE, target predicate observable
set target predicates set observables disjoint.
Moyle (2003) introduces ILP system (alecto) combines abduction induction learn theories robot navigation. One limitation system
restricted positive observations learning. integration interleaved nature abduction first used generate explanations example induction
applied set explanations. means abduction phase take
consideration concepts learned induction phase dealing noise data
left future work.

3. Relational Representation Scenes Video
represent interactions objects relational data, use spatial temporal relations.
Since input work video, spatial relations defined either
image plane ground plane (if homography used map image plane
ground plane). spatial relations necessary encode state particular pair
objects in. states two objects change time progresses, hence
need temporal relations connect states. section, explain objects
interactions converted relational data.
Notation: use first-order typed language (L) following alphabet: {, , ,
, , , ,R}. Let R = {r1 , r2 , . . . , rm } denote set qualitative spatial relationships
arbitrary qualitative spatial calculus. sorts (and corresponding variables)
given (upper case letter denotes set lower case letter denotes set element):
time points



time intervals



spatial objects



events

E

temporal relations



object types



special event-predicate tran(ri , ok , ol , tm ) E denotes transition spatial
relation ri objects ok ol time point tm . Note work,
take values set 13 Allens base relations (Allen, 1983) i.e. = {before, after,
meets, met by, overlaps, overlapped by, during, contains, equals, finishes, finished by, starts,
started by}. say two intervals disjoint Allen relation
set {before, after, meets, met by}.
3.1 Spatial Relations
order get high level description interactions objects videos, need relations encode interactions objects without loss essential information (Cohn
et al., 2006). several possibilities kind relations choose.
Since interactions objects video take place spatial dimensions, natural
46

fiLearning Relational Event Models Video



?







?





?











Figure 1: Qualitative Trajectory Calculus (QT CL1 ) (Van de Weghe et al., 2006):
blob possible QT CL1 spatial relation. blob, asterix (left object) circle (right
object) represent objects motion star black dot represent objects rest
direction arrow shows direction motion object. example,
top-left ellipse interpreted two objects moving towards bottom-left
ellipse interpreted right object moving away left object left
object moving towards right object (i.e left object chasing right object).
Though nine relations possible QT CL1 shown figure, practice
reduce six exploiting symmetry relations. one object changes
motion state (note object cannot change direction without going
rest state), QTC relation changes along thick line connecting two relations.
objects change motion state instantaneously, relation changes along dotted line.

use qualitative spatial calculi model interactions. interactions
temporal dimension occur period time, extend spatial relations
arguments modelling temporal dimension. say interactions objects
mean interactions bounding boxes2 (aligned axes) objects
get tracking objects using computer vision algorithms (Yilmaz, Javed, & Shah,
2006). different kinds spatial calculi target different aspects object
interactions topology, orientation, direction, trajectories etc. calculi use
domain dependent choice (Chen, Cohn, Liu, Wang, Ouyang, & Yu, 2015). primarily use three spatial relations encode object interactions topological level:
dc (Discrete) intersection pixels bounding boxes two objects empty,
(Inside) intersection pixels pixels bounding box
one objects touch every case. set simple topological relations
abstracted version3 RCC-8 (Randell, Cui, & Cohn, 1992) spatial calculus, reduced
practical purposes without loss essential information event analysis. use
QT CL1 (Van de Weghe et al., 2006) (Fig.1) domain specific relations primitives
represent interactions objects videos.
2. principle, shape abstractions could used well, e.g. convex hulls, silhouettes, bounding ovals
etc.
3. two relations version RCC called RCC-5 equal contains (inverse in).
relation equal rarely occurs experiments use contains convert
reversing arguments.

47

fiDubba, Cohn, Hogg, Bhatt & Dylla

o1

o1

o1
o2

o2

1

3

2

dc

o2

touch



dc(o1 , o2 , 1 )
touch(o1 , o2 , 2 )
in(o2 , o1 , 3 )
meets(1 , 2 )
meets(2 , 3 )
before(1 , 3 )

Figure 2: Converting interactions objects relational data.
3.2 Temporal Interval Relations
define temporal relations time intervals based Allens interval algebra.
use start end frames interval represent intervals. advantage
approach is, precalculate temporal relations store beforehand
database inference. Instead, Prolog rules calculate temporal relations given start
end time points two intervals used. order incorporate temporal information
describing scenario, extend spatial relations temporal interval extra
argument.
3.2.1 Temporally Extending Spatial Relation
state spatial relation r objects o1 o2 holds throughout interval
represented r(o1 , o2 , ) r R , o1 , o2 . Grounding expression
objects intervals database provide us spatio-temporal facts.
temporal relation two spatio-temporal facts Allen relation
intervals spatio-temporal facts.
3.3 Representing Event Class
event class represented set Horn clauses head predicate
event name consideration body non empty conjunction atoms
consisting spatial temporal predicates.
structure clause event model event class follows:
() : 1 , . . . , , . . . , n
either form r(o1 , o2 , ) r R, o1 , o2 ,
form (1 , 2 ) 1 , 2 .
1
48

fiLearning Relational Event Models Video

4. Deictic Supervision
supervised learning, need positive preferably negative examples event
instances. One major problem supervised learning collecting labelled training
data. general ambiguity defining spatial particular temporal
extent event (i.e. events precisely start finish), difficult annotate
videos event labels. possible approach annotate objects involved
event give events temporal extent. annotating objects tedious prone
human error events may uncertainty objects involved.
avoid using Deictic Supervision (Dubba et al., 2010). Instead annotating
exact objects involved training event instances, give bounding spatial
temporal extent event instance may contain objects. spatial extent
region indicating event happening video. temporal extent
interval includes actual temporal extent event, may deliberately
longer order avoid accidentally truncating state changes relevant event.
makes preparation training data easier learning process robust less
biased labelling learning algorithm able induce reasonable
models even data.
Delineating spatio-temporal volumes videos learn feature-based representations actions hand gestures without precedent computer vision
literature (Laptev & Perez, 2007), use extends multiple simultaneous actors relational descriptions resilience perturbations placement cuboids
provided events fully enclosed.
4.1 Deictic Interval Region
work, deictic spatial region rectangle image plane indicating
event happened deictic interval time interval indicating event
happened. deictic spatial region obtained hand-delimiting event image
plane rectangle4 , hence represented using coordinate point (top-left corner
vertex), height width rectangle (x, y, h, w). deictic temporal interval provided
specifying start end time points interval. Together define space-time
cuboid delimits spatial temporal extension event.
deictic cuboid defines set spatial facts temporal relations them;
event instance subset facts corresponds positive example
learning interpretations setting. Obtaining positive negative examples learning
using event annotations form deictic spatial regions deictic temporal intervals
explained following sections. Note deictic interval region regarded
interval object respectively spatial relations
computed accordingly. positive negative examples computed, spatial
relations involving deictic regions one objects discarded database
use.
4. tracking data ground plane back-project rectangle automatically
minimum enclosing rectangle ground plane using homography (Hartley & Zisserman, 2004).

49

fiDubba, Cohn, Hogg, Bhatt & Dylla

4.2 Herbrand Interpretation Event
Let si deictic spatial region deictic temporal interval instance
event class video v. Let v set spatio-temporal facts present v, Ov
set objects v v set time intervals v. set facts Ei v
Herbrand Interpretation event v iff facts contained
entailed v , whose temporal intervals disjoint deictic interval whose
objects relation touch within deictic region.

Ei = {r(o1 , o2 , ) : v r(o1 , o2 , )
v (i , )
/ {before,after,meets,metby}
1 [v r1 (si , o1 , 1 ) r1 {touch,in}
v 1 (i , 1 ) 1
/ {before,after,meets,metby}]
2 [v r2 (si , o2 , 2 ) r2 {touch,in}
v 2 (i , 2 ) 2
/ {before,after,meets,metby}]
o1 , o2 , si Ov r R 1 , 2 v
}

example interpretation event instance AFT Bulk LoadUnload Airport
domain illustrated Fig.3. interpretation includes spatial facts involving
objects relation touch deictic region lie within
two vertical dashed lines (the deictic interval). set Herbrand Interpretations
corresponding set deictic regions intervals event form positive
examples learning phase. rest relational facts video form
negative example event model fires instance database, considered
false positive. Herbrand Interpretation extracted set spatiotemporal facts video, interpretation independent facts
spatio-temporal database5 video hence facts assumed false
interpretations point view.
Note definition spatio-temporal facts spatio-temporally overlap
deictic region interval event instance relevant event. Considering
facts outside indicated event occurrence increases size training data
makes example instances different event classes less distinct.
One limitation using cuboid shaped deictic region delineating event instance
possible differentiate among multiple co-occurring instances
event type involving different objects region. One way overcome limitation
use one cuboid enclose event instance allowing elimination unwanted
facts.
5. spatio-temporal database subset Herbrand Base video obtained using
predicates (spatio-temporal relations) constants (objects time intervals) video.

50

fiLearning Relational Event Models Video

Figure 3: example interpretation event AFT Bulk LoadUnload Airport
domain. vertical black lines start end deictic interval. row
represents interactions two objects present deictic region
deictic interval video. colours lines represent spatial relations
pairs objects point time. figure show effect deictic
spatial region, would correspond elimination certain rows (where
objects spatial relation touch whilst deictic spatial region
deictic temporal interval.
4.3 Herbrand Interpretation Non-event Interval (Negative Example)
framework, negative examples explicitly labelled. negative example
given event video set spatio-temporal facts database
video present positive examples event video. Note
negative example general contain data might positive examples
event classes video. Another alternative use labelled positive examples
events negative examples event learning. convenient
classification purposes recognition tasks miss background data
might useful minimize detections background regions.
Let v union spatio-temporal facts Herbrand Interpretations
event video v. set facts NIv v Herbrand Interpretation negative
example event video v iff contains facts v v , i.e.,
NIv = v v .

5. Typed ILP
event learning recognition system, low level image processing computer
vision techniques may introduce noise system. One kind noise, particular
video quality bad videos CCTVs, wrong type may
assigned tracker object history. object detector typically trained
51

fiDubba, Cohn, Hogg, Bhatt & Dylla

Person
Aircraft
GPU
Transporter

Object

Light Vehicle
Push Back
Service Vehicle
Mobile Stairs
Vehicle
Loader
Conveyor Belt
Passenger Boarding Bridge
Heavy Vehicle
Container
Catering
Tanker
Bulk Loader

Figure 4: Tree-structured object type hierarchy Airport domain.
many example images objects detected. Even though many example images
given training, possible capture possible ways object appear
lighting, viewing direction, size, shape, etc. (Lowe, 2004). may result
correctly localized objects wrong categories objects, especially
look visually similar low contrast images.
input data huge noisy, several problems ILP system
face. One hypothesis evaluation take lot time size
data. noise tend make hypothesis specific system learns
rules cover inconsistent examples. Using typed ILP system speed
evaluation typed arguments hypothesis (Walther, 1985; Cohn, 1989)
reduce number false positives avoiding certain cases types
arguments match. event model objects specialized type
fail recognize event instances object appears different type.
contrast, event model type system uses generic type
objects object, thing etc., approach many false positives
cannot differentiate events structure involving different types
objects. One possible approach find appropriate type generalization instead
using one two extremes: generic type specialized type.
ILP systems, type hierarchy objects integrated learning
process. example, Progol, types objects used mode declarations
since assumes flat type hierarchy domain, search procedure cannot
take type hierarchy consideration. example, tracking system sometimes
confuses two types objects (1 , 2 ) objects type 1 misclassified
52

fiLearning Relational Event Models Video

s2
s1

s4
s3
s5

Figure 5: Tree-structured example object type hierarchy. s1 general type
s2 , s4 , s5 specific types.
type 2 , Progol generates two rules, one 1 another 2 . Even
dealing vision system introduces noise high level learning
reasoning system, cases event might involve objects particular sub-group
objects. case, instead using generic type object particular
types type object itself, efficient use intermediate generic type
represents sub-group. variable without type restrictions satisfied
type object instantiating Horn clause. However, appropriate generalization
enforced learning system variable type 1 t2 type hierarchy,
satisfied6 objects type 1 2 , thereby reducing false positives.
5.1 Representing Typed Hierarchy
wish use existing Prolog engine hypothesis evaluation way
encoding type using terms must found. several ways depending
whether structure object type hierarchy tree lattice. use
type representation proposed Bundy, Byrd Mellish (1985) deal tree
structured type hierarchies; develop refinement operator incorporating
representation hypothesis search procedure. advantage using representation
ordinary unification used determine whether two types compatible.
write < j , subtype j 6= j . Every object type n
hypothesis represented term 1 (2 (. . . n (o) . . .)) 1 , . . . , n
maximal sequence types n < . . . < 2 < 1 . denote representation
function . Note need constraint, i.e. tree structured type hierarchy,
order guarantee uniqueness sequence 1 , . . . , n .
example, let s1 , s2 , s3 , s4 , s5 types s4 < s3 < s1 , s5 < s3 < s1
s2 < s1 shown Fig.5. object type s4 represented follows:
(o) = s1 (s3 (s4 (o)))

object oi compatible object oj hypothesis (oi ) unifiable
(oj ). example: s1 (s3 (o1 )) unify s1 (s2 (o2 )) unify
s1 (s3 (s4 (o3 ))) s1 (s3 (s5 (o4 ))), hence compatible.
5.1.1 Example Representing Type Hierarchy
object type hierarchy occurs one two domains used evaluation
section work shown Fig.4. hierarchy Fig.4 hand defined based
6. variable type 1 2 unify term type 1 2 .

53

fiDubba, Cohn, Hogg, Bhatt & Dylla

observed errors object classification tracking data Airport domain.
airport domain, ground power unit (GPU), transporter push back vehicle
small vehicles look similar videos CCTV cameras airport
low resolution contrast without much colour sharp edges. makes challenging
train object detector use detecting objects videos. objects
Verbs domain present particular challenges automatic classification point
view events involve objects particular subset objects, example,
throw event involves balls different types small ball, basket ball, etc. Hence using
type hierarchy based utility expected help find event models better
performance detecting events unseen videos.
vehicle V type GPU represented obj(veh(light veh(gpu(V ))))7
V type light veh represented obj(veh(light veh(V ))). Note
obj(veh(light veh(V ))) unifies vehicles type GPU vehicles type Transporter. using obj(veh(light veh(V ))) model cover examples either
involve GPU Transporter hence handle noise object detector
confuses vehicles outputting GPU place Transporter vice versa.
5.2 Type Refinement Operator
refinement operator used traverse hypothesis lattice. two
types refinement operators: upward downward (Nienhuys-Cheng & De Wolf, 1997).
write Hg Hs Hg generic8 hypothesis Hs . assume
top element hypothesis lattice generic hypothesis bottom
hypothesis specific hypothesis, upward refinement operator
defined follows (the downward refinement operator defined similar fashion):
Let L set possible hypotheses. (upward) refinement operator defined
hypothesis H, produces generalizations H, (H) = {Hg | Hg
H, Hg L}.
define (upward) Type Refinement operator operator generalizes
object types H. Apart object types, structure H members (H)
identical.
define type generalizing operator follows:
generalize type(1 (2 (. . . n1 (n (o)) . . .))) = 1 (2 (. . . n1 (o) . . .))
Type Refinement operator, , applies generalize type operator selected
object type present hypothesis, resulting generic hypothesis moving
exactly one level type hierarchy.
Though specific current representation type hierarchy using functors requires
tree structured hierarchy, tree structured hierarchy beneficial computational viewpoint limiting type generalizations, i.e., multiple ancestors.
tree-like type hierarchy natural many domains though domains might
7. Note short forms used Object, Vehicle Light Vehicle.
8. several possible generality orders, important subsumption logical implication (Nienhuys-Cheng & De Wolf, 1997).

54

fiLearning Relational Event Models Video

well defined tree-like object type hierarchy. cases, lattice structured type
hierarchy suitable though increase size search space since
number possible refinements increased, particular tree structure type generalization deterministic whilst case lattice structure.
5.2.1 Optimality Type Refinement Operator
Refinement operators ideal optimal (Nienhuys-Cheng & De Wolf, 1997)9 .
optimal refinement operator generates hypothesis hypothesis lattice
unique way produce hypothesis. kind refinement operator
desirable complete search algorithms duplicate generation hypotheses increase
cost search procedure. optimality Type Refinement operator proved
Appendix A.

6. Learning Interpretations Setting Learning Event Models
result deictic supervision gives us examples sets spatio-temporal facts.
Though examples (sets facts) come different videos,
independent other, i.e., mapping example class independent
examples. kind learning setting example independent
example set facts, learning interpretations setting
apt choice (Blockeel, De Raedt, Jacobs, & Demoen, 1999). setting specified
formally thus:
Given:
set classes C (each class label c nullary predicate).
set classified examples E (each element E form (Ei , c) Ei set
facts c class label)
background theory B,
Find : hypothesis H (a set Horn clauses), (Ei , c) E:
H Ei B c,
c0 C {c} : H Ei B 2 c0
current event learning problem, setting applied event class
case set classes two elements, event class background class. Background class represents negative examples class label c
nullary predicate.
9. ideal refinement operator proper complete whereas optimal refinement operator weaklycomplete non-redundant. See Appendix formal definitions.

55

fiDubba, Cohn, Hogg, Bhatt & Dylla

6.1 Traversing Search Space
search process hypothesis starts initial hypothesis nullary
predicate head empty body. hypothesis lattice traversed using Progol
Type Refinement operators interleaved fashion. Progol refinement operator
specialization operator adds atoms bottom clause hypothesis.
specialization operator moves top (empty clause) bottom hypothesis
space lattice bounded bottom clause bottom. Adding atoms
bottom clause makes hypothesis specialized body
hypothesis conjunction atoms atom considered constraint.
Adding atoms body increases constraints satisfy become true.
Progol refinement operator use based bottom clause
called most-specific clause non-redundant though weakly-complete
respect general subsumption order (Tamaddoni-Nezhad & Muggleton, 2009).
most-specific clause Progol refinement operator uses computed training examples, mode declarations background knowledge (Muggleton, 1995). Mode
declarations user defined syntactic biases form predicates specify
predicates background knowledge expected target hypothesis
nature variables (input, output, constant). selection atoms
added hypothesis bottom clause done controlled manner. atoms
considered starting left moving right atom added
(Tamaddoni-Nezhad & Muggleton, 2009). constraints selection
atoms makes refinement process non-redundant, i.e., hypothesis generated twice.
additional refinement operator refines unifying two variables arbitrarily
selected hypothesis substituting variable constant. use
operator unifying two variables needs checking hypothesis consistency
respect underlying spatial theory fixed constants (apart frame
numbers) domain constants example independent constants
examples. example, consider three relations Section 4.1 spatial
theory Allens relations temporal relations: cannot unify two arguments
predicate (spatial temporal) violates semantics relations.
Type Refinement operator generalizes hypothesis generalizing type
object hypothesis (Fig.6). two possible approaches apply Type
Refinement operator: type first approach select type set types
hypothesis generalize type variables belong selected type
variable first approach select variable hypothesis generalize type
occurrences variable hypothesis. type first approach generalizes
selected type throughout hypothesis may involve several variables
variable first approach generalizes type one variable. work, use
type first approach fewer number refined hypotheses smaller search
space variable first approach larger number choices hence larger
search space. One reason use type first approach computer vision
algorithm might confuse type whole group objects belong particular
type rather single object video inaccurate object detector.
56

fiLearning Relational Event Models Video

Figure 6: Type refinement operator (generalization).
6.2 Searching Event Model
most-specific clause computed, sub-lattice bounded mostspecific clause searched using best-first search hypothesis maximum
score calculated based combination (1) number positive examples covered, (2)
number answer substitutions negative examples, (3) length hypothesis
(4) number distinct variables hypothesis subject given constraints
(discussed next subsection).
score(H) = p (% n + l + v)

= weight positive examples
p = number positive examples covered
% = weight answer substitutions negative examples
n = number answer substitutions negative examples
l = length hypothesis
v = number distinct variables hypothesis
answer substitution example e substitution grounds hypothesis,
h b1 , . . . , bn , query b1 , . . . , bn succeeds database e. Note
learning interpretations setting positive example separate database
hypothesis used Prolog query database, might result multiple
answer substitutions. example considered covered hypothesis one
answer substitutions. testing hypothesis test database, answer
substitution considered one recognized event instance. recognized event interval
falls outside event ground truth test video, considered false positive.
event recognition domain, hypothesis used recognizing events unseen videos
57

fiDubba, Cohn, Hogg, Bhatt & Dylla

instead classifying videos, hypothesis fewer false positives desirable. Hence
hypotheses penalized using number answer substitutions10 negative examples.
number positive negative examples disproportionate numbers, giving
weight positive examples negative examples using % result
hypothesis better performance test data.
Since starting hypothesis empty completely generic, cover
negative examples. hypothesis specialized Progols refinement operator,
number false positives decreases. score hypothesis longer increases,
Type Refinement operator used generalize types thereby increasing generality
hypothesis possible increase positive examples covered (as well false
positives). process interleaved application operators continued
hypothesis score longer increases.
satisfactory hypothesis found, argument representing temporal information
form list time intervals formed using time intervals body
event model introduced head order explicitly represent event
occurs useful using hypothesis event monitoring allows interval
event occurs explicitly flagged viewing video.
learning algorithm uses set covering method (Quinlan, 1990) learn event
model set clauses interpreted disjunction. covering method starts
empty model learns clause using provided positive negative examples
adds clause model. repeats procedure positive examples
covered earlier clause. process repeated positive
examples covered.
6.3 Constraining Search Space
size search space depends size bottom clause (Muggleton, 1995).
Thus, event learning domain, depends number spatial relations
used number objects event instances used positive examples. size
bottom clause increases number Allens temporal relations interval
atoms spatial predicates temporally connected every interval
atoms spatial predicates. creates many atoms temporal predicates
bottom clause.
order decrease size search space, algorithm makes use domaindependent domain-independent constraints structure hypothesis.
constraints algorithm uses restrictions hypothesis length number
variables hypothesis etc. domain-independent structural constraints
depend predicates used domain knowledge. following two
domain-dependent constraints reduce search space time thereby making
learning process efficient.
Upper bounds number atoms body rule.
10. Counting number answer substitutions instead number examples covered heuristic used
FOIL system (Quinlan & Cameron-Jones, 1993).

58

fiLearning Relational Event Models Video

interval atom spatial (temporal) predicate appear atom
temporal (spatial) predicate. hypothesis atoms satisfy
criteria semantically meaningful since might satisfied facts
related event question.
However constraints listed domain dependent constraints rather application specific constraints, i.e., constraints involve spatial temporal
predicates applicable most, event learning scenarios. Note
constraints hard (i.e. inviolate). hypothesis violates constraint,
discarded without scoring refining. example, domain-independent constraints
first domain-dependent constraint mentioned hard. contrast, hypothesis violates constraint hard, example, second domain-dependent
constraint listed above, scored discarded generating refined hypotheses it. discarding hypotheses without refining might obstruct
traversal lattice. example, current work, algorithm starts search
process empty hypothesis initial hypotheses obtained refining empty
hypothesis violate second domain-dependent constraint listed (since contain exactly one predicate therefore cannot contain spatial temporal
predicate).
6.4 Event Recognition
learned event models used event recognition unseen videos. purpose,
test video converted relational data used database event models
used Prolog queries. querying done whole database intervals
extracted answer substitutions queries give temporal extent
recognized instances events. order record event takes place, change
arity event predicate (the rule head) monadic argument
list interval variables occurring body. Note would possible
introduce second argument record objects involved event (i.e. list
variables type object - equivalently occur first two arguments
spatial predicate body).
issue arises exactly event occurs given consists multiple
overlapping temporal intervals instantiated predicates given answer substitution. Given list intervals occurring instantiated body hypothesis,
various possibilities present themselves. One could take maximal interval exactly
spans intervals . one could take interval exactly spans interval
first transition (i.e. pair meeting intervals involving pair objects)
last transition. Clearly possibilities too. Ultimately probably
domain dependent decision. experiments, take list intervals
temporal extension event obtained taking minimum maximum
time points .
Note may several rules event class, rule capturing variation
event happen. rules weights specifying important
reliable rule recognizing events. recognizing events, rules event
class used may result multiple answer substitutions.
59

fiDubba, Cohn, Hogg, Bhatt & Dylla

7. Interleaved Induction Abduction (IIA)
previous section showed ILP applied learn rule-based relational
event/activity models, given observation dataset, positive negative examples
events whose models learnt. However, data visual sensors tend
noisy high variability sample space. leads over-fitted models (i.e.,
rules), model cover examples corrupt
sensor noise. model rules result many false positives used
event-recognition test data.
section, show well-fitted, semantically meaningful event models
learned noisy data interleaving induction abduction. acquires significance
cases training data scarce noisy. apply Typed ILP system presented
previous section learn event-based models using models domain
theory, explain examples/observations covered induced theory using
abduction. uncovered examples either noisy, examples event
reality happened different way. Using explanation rectify errors
noisy examples corrupted tracking errors thus reduce requirement additional
rules. framework, examples noisy (i.e. incorrect) thereby requiring
observation data revision manner consistent initially learned theory,
general common-sense knowledge space, spatial change, dynamics
domain. Note many ILP approaches discard examples considering noisy
using heuristic stopping criteria. acceptable cases scarcity
training data, learning every example potentially important.
7.1 Domain-Independent Spatial Theory
order pursue goal, Axiomatic Characterisation Spatial Theory necessary. Many spatial calculi exist, corresponding different aspect space. Here,
suffices focus one spatial domain, e.g., topology, corresponding mereotopological axiomatization way binary relationships RCC-8 fragment Rrcc8 .
axiomatic viewpoint, spatial calculus defined R general properties (P1P5),
assumed known apriori. realize domain-independent spatial theory
used reasoning (e.g., spatio-temporal abduction) across dynamic domains,
necessary formalize domain-independent spatial theory (space ) preserves
high-level axiomatic semantics generic properties. reasons space
sketch properties P1P5 neglect formal axiomatization.
(P1P2) Basic Calculus Properties (cp ) describe jointly exhaustive & pairwise disjoint (JEPD) property, i.e., two entities O, one one spatial
relationship R holds given situation. jointly exhaustive property n = |R|
base relations axiomatized n ordinary state constraints and, similarly, pairwise disjoint property axiomatized [n(n 1)/2)] constraints. miscellaneous
properties symmetry asymmetry expressed manner.
(P3) primitive relationships R continuity structure, referred Conceptual Neighbourhood (cn ) (CND) (Freksa, 1991), determines direct, continuous changes quality space (e.g., deformation and/or translational motion).
(P4) axiomatic viewpoint, spatial calculus defined R (primarily) based
60

fiLearning Relational Event Models Video

derivation set Composition Theorems (ct ) JEPD set R.
general, calculus consisting n JEPD relationships, [n n] compositions
precomputed. composition theorems equivalent ordinary state constraint, every n-clique spatial situation description satisfy.
(P5) Additionally, Axioms Interaction (ai ) necessary one spatial calculus modelled non-integrated manner (i.e., independent composition
theorems). axioms explicitly characterize relative entailments interdependent aspects space, e.g., topology size.
Now, let space def [cp cn ct ai ] denote domain-independent spatial theory
based axiomatizations encompassing (P1P5).
7.2 Physically Plausible Scenarios
Corresponding spatial situation (e.g., within hypothetical situation space),
exists situation description characterizes spatial state system. necessary spatial component state complete specification, possibly
disjunctive information. k spatial calculi modelled, initial situation description involving domain objects requires complete n-clique specification [m(m 1)/2]
spatial relationships calculus. Therefore, need define scene description
C-Consistent, i.e., compositionally consistent, n-clique state spatial situation
description corresponding situation satisfies composition constraints every
spatial domain (e.g., topology, orientation, size) modelled. one calculus
modelled inter-dependent constraints (P5) must hold well.
viewpoint model elimination narrative descriptions (abductive)
explanation process, C-Consistency scenario descriptions key (contributing) factor
determining commonsensical notion physically realizability (abduced) scenario completions. Bhatt Loke (2008) show standard completion semantics
causal minimization presence frame assumptions ramification constraints preserves notion C-Consistency space within logic programming framework,
well arbitrary basic action theories.
7.3 Inductive-Abductive Framework
interleave inductive abductive commonsense reasoning space, events
change within logic programming framework. Induction used means learn event
models generalizing sensory data, whereas abductive reasoning used noisy
data correction scenario narrative completion, thereby improving learning.
7.3.1 Explanation Abduction
Diametrically opposite projection planning task post-dictum explanation (Poole, Goebel, & Aleliunas, 1987), given set time-stamped observations
snap-shots, objective explain events and/or actions may caused
observed state-of-affairs. Explanation problems demand inclusion narrative
description, essentially distinguished course actual events may
incomplete information (Miller & Shanahan, 1994). Narrative descriptions typi61

fiDubba, Cohn, Hogg, Bhatt & Dylla

cally available sensory observations real execution system process. Given
narratives, objective often assimilate/explain respect underlying
process model.
abductive explanation problem stated follows (Kakas, Kowalski, & Toni,
1992):
Given: Theory observations G, find explanation 4 that:




4G





4 consistent

i.e., observation follows logically non trivially theory extended given
explanation. Abductive explanations usually restricted ground literals predicates undefined theory, namely abducibles. Abductive explanations
derived trying prove observation initial theory alone: whenever literal encountered clause resolve with, literal added
explanation.
abduction procedure results many valid explanations. order reduce
number explanations, several restrictions listed used (Kakas et al., 1992):
Explanations basic means one explanation explain another
explanation. enforced allowing abducibles head rule.
Explanations minimal means one explanation subsume another explanation.
Explanations satisfy integrity constraints restriction, obtain explanations valid domain consideration. work,
explanations satisfy spatial constraints underlying spatial theory.
7.3.2 Scenario Narrative Completion
easy intuitively infer general structure narrative completion abductive
explanation. Consider illustration Fig.7 hypothetical situation space characterizes complete evolution system. Fig.7 situation-based history given
solid arrows represents one path, corresponding actual time-line discretized
intervals h0 , 1 , . . . , i, within overall branching-tree structured situation space.
Given incomplete narrative descriptions, e.g., corresponding ordered intervals
terms high-level spatial (e.g., topological, orientation) occurrence information,
objective explanation derive one paths branching situation space,
could best-fit available narrative information. Formally:


1 touch(a, c, 1 )












dc(a,
c,

)

in(b,
a,

)

dc(b,
c,

)


2
4
4
4








[



]
|=

,



space
1
2


( , j ).[ meets(1 , ) bef ore(i , 4 ) dc(b, a, )






touch(a, c, ) dc(b, c, )]











[
meets(
,

)

meets(
,

)

touch(b,
a,

)



j
j
4
j






touch(a, c, j ) dc(b, c, j )]
62

(7.1)

fiLearning Relational Event Models Video




c

b


c


c

b



c


b
c

ab

c

b
c


b

c

Figure 7: Branching/Hypothetical Situation Space. possibilities shown.
clearly paths initial scenario target scenario.
possible states.

(7.1), 1 denotes initial situation 2 denotes final situation represented
terms spatial relations (RCC-5) among objects present scene. abductive
derivation , explains scene changed situation 1 situation 2 ,
primarily involves non-monotonic reasoning form minimizing change, addition
making default assumptions inertia, appropriate treatment ramification
constraints (Bhatt & Loke, 2008).
7.4 IIA Algorithm
ILP systems use covering algorithm learn models examples. search
ranges hypothesis lattice hypothesis evaluated based number
positive negative examples covers. selected suitable hypothesis based
scoring function, hypothesis (rule) added model, covered examples
removed process repeated positive examples covered. Examples
corrupted noise resulting missing incorrect facts. cases,
rules learned necessary order cover examples. number
rules concept increases, may result many false positives rules
used classification/recognition test examples. order avoid learning corrupt
examples, framework identifies examples corrupted explaining
abduction using already induced model background theory (Dubba et al., 2012).
63

fiDubba, Cohn, Hogg, Bhatt & Dylla

main assumption make noise examples consistent.
noise consistent (i.e., present examples similar fashion)
becomes part pattern defines concept might learned learning
algorithm.
pseudo algorithm given Algorithm 1. induction algorithm induces
initial hypothesis based score function explained previous sections. positive
+
examples covered (ERule
) hypothesis removed list positive examples
yet covered. induced theory along background knowledge used explain
uncovered examples treating example narrative. Abduction gives several
possible explanations different cost (based nature number facts
explanation). explanations rejected cost specified
threshold. Furthermore, given formulation spatial theory space , C-Consistency
+
abduced explanations ensured. examples (E4
) explanation whose cost
less specified threshold removed positive examples list yet
covered, considered covered already induced model.
process induction abduction repeated positive examples covered.
Apart constraints enforced spatial theory filter abduced explanations,
several heuristics used give score explanation low cost consistent
explanation selected system. One several possible heuristics prefer
explanations number transitions spatial relations minimal (Hazarika &
Cohn, 2002). heuristic direct consequence McCarthys Common Sense Law
Inertia (McCarthy, 1986) states change abnormal persistence
preferred absence data. spatio-temporal domain, explanation abduced
absence data set spatio-temporal facts three ways add
explanation: (i) Extend current relation two objects (can done
directions timeline situation permits) (ii) change current relation
two objects neighbouring relation CND (iii) introduce new object (hypothetical)
scene spatial relations objects scene well. cost
explanation based type spatio-temporal fact chosen calculated
explained below.
7.4.1 Cost Abduced Explanation
Let 4 explanation abduction procedure 4 set grounded spatiotemporal facts form r(oi , oj , k ) denoted fijrk , Ep+ current positive example
(an interpretation, i.e., set facts) let r set spatial relations R
spatial calculus. Let set objects Ep+ . Let cfijrk cost abducing fijrk .
X
total cost 4 denoted C4
cfijrk .
fijrk 4

cost

,
,
cfl =

n,

abducing fijrk calculated follows:
exists fijrm Ep+ k disjoint
exists fijsm Ep+ k disjoint r =
6
n number hypothetical objects (objects O) fijrk

< < .
64

fiLearning Relational Event Models Video

first case cost function occurs system abduces fact extends
relation two objects temporal dimension. count spatial
transition hence low cost. contrast, second case occurs
system abduces fact extends existence two objects temporal dimension
different relation (the new spatial relation must neighbour existing relation
CND) one already exists them. counts spatial
transition cost first case. third case occurs necessary
hypothetical object satisfy hypothesis Ep+ . case used
object involved event completely missed object tracker first two cases
used scenarios object detected temporal slice life time.
Note first case clearly preferred abduction procedure find
low cost explanation third case expensive applies object
completely missed object tracker. Though possible avoid transitions
reduce score, sometimes mandatory consider transitions. example, consider
scenario two objects dc relation final state relation.
case, algorithm abduce facts two transitions (one
dc relation changes touch another touch changes relation). Note
necessary abduce temporal relational facts Prolog definitions temporal
relations background theory used compute needed.
achieved including temporal predicates list abducibles.
abduction procedure uses existing constants database one issue
though number relations objects small, number possible
intervals large constrained. order constrain possible explanations,
introduce intervals predefined duration database abduction uses
intervals abducing explanations. Note abduction defined
adds missing spatio-temporal information cannot used retract corrupted
data resulting noise.

Algorithm 1 Interleaved Induction Abduction algorithm (IIA)
procedure IIA(E + , E , B) . training sets background knowledge (includes spatial
theory)
H
4
E + 6=
Rule
Induce(B, E + , E )
H H {Rule}
+
E + E + ERule
4 Abduce(B, H, E + )
+
E + E + E4
end
return H
. Learned theory
end procedure

65

fiDubba, Cohn, Hogg, Bhatt & Dylla

Figure 8: Airport domain: videos recorded using 6 static cameras looking
scene different angles.

8. Experimental Results
section, present evaluation remind, well extension presented
Section 7. experiments, used two real world video datasets different
many aspects. videos datasets shot outdoor settings
different weather light conditions (rainy, cloudy, sunny, night). variations
videos present various challenges vision system subsequently learning
system training phase event recognition phase.
two datasets used work evaluation airport logistics verb
videos. datasets domains differ many aspects number objects
video, length video, duration events, background structures, number
cameras used capture events plane (image plane ground plane)
tracking data made available. view differences datasets
positive aspect - framework shown work two different kinds scenarios.
remind11 implemented Python speed, modules implemented
Cython; SWI-Prolog used underlying Prolog engine storing querying
relational facts background knowledge.
8.1 Airport Logistics
experiments airport logistics domain, 15 turn-arounds12 used
turn-around shot using 6 cameras different angles (Fig.8) video
average one hour long (15 frames per sec).
following informal descriptions International Air Transport Association (IATA) events aim learn models for:
11. Available request first author made public near future.
12. turn-around duration plane entering leaving apron area.

66

fiLearning Relational Event Models Video

Aircraft Arrival

Aircraft comes apron

Aircraft Departure

Aircraft moves away position apron

GPU Positioning

Ground power unit comes positions zone

Left Refuelling

Fuel truck arrives left side aircraft refuelling

PB Positioning

Push-back vehicle positioning front aircraft

PBB Positioning

Passenger Boarding Bridge attaches aircraft

PBB Removing

Passenger Boarding Bridge detaches aircraft

FWD CN LoadUnload

Container Loading/Unloading front end aircraft

AFT CN LoadUnload

Container Loading/Unloading rear end aircraft

AFT Bulk LoadUnload

Baggage Loading/Unloading rear end aircraft

FWD Bulk LoadUnload

Catering Loading/Unloading front end aircraft

Within event, high variability noise tracking
objects extraneous event entering event scene. Note events might
present may occur multiple times turn-arounds. scenes involve
interactions vehicles people zones apron. zones specified
ground plane according IATA specifications position zones
depends type aircraft. zones used parking steering vehicles
different operations carried turn-around. Note zones static
throughout video change size position, unlike bounding boxes
vehicles obtained tracking. Hence zones included type hierarchy used
domain (Fig.4) since suffer visual noise. main reason use
zones RCC-5 spatial relations bounding boxes vehicles people
ground plane rarely touch, hence interactions encoded dc zones
used. important use zones interactions happen
zones. According IATA specifications, vehicle transition zones
position vehicle particular zones important determine events.
use object tracks provided partner Co-Friend project (Ferryman,
Borg, Thirde, Fusier, Valentin, Bremond, Thonnat, Aguilera, & Kampel, 2005); certain
details events detectable tracking system direction
baggage rail loader vehicle whether trolleys empty arrive
scene. Load/Unload events obtained IATA events differ details (if
trolleys loaded arrive scene baggage moving towards
aircraft, event loading trolleys empty arrive
scene baggage moving away aircraft, event unloading). Apart
details, semantically similar hence regarded events (for
example, FWD CN Load FWD CN Unload regarded events named
FWD CN LoadUnload, strategy followed Load/Unload events).
8.1.1 Tracking Obtaining Relational Data
apron scene area large covered single static camera. events
apron occur sides aircraft difficult cover
67

fiDubba, Cohn, Hogg, Bhatt & Dylla

single camera size aircraft possible many occluded
objects scene. order solve problems, six cameras used shoot
scene different angles entire area covered number occluded
objects minimized. Working ground plane data results learned models
independent camera view airport models readily applied
different airports different camera configurations.
tracking data obtained videos six cameras turn-around
fused together get 3D data ground plane (Ferryman et al., 2005). tracking
data noisy low quality, bad light weather conditions low contrast
CCTV videos. noise presence phantom objects, missing objects,
wrong types vehicles, inaccurate bounding boxes, broken trajectories, object identity,
inconsistencies etc. typical problems computer vision tracking system.
turn-around separately processed get relational data consists set
spatial relations among vehicles zones apron. Prolog rules decide
temporal relationships among intervals considered background information ILP
system. data video 250 500 spatial relational facts (excluding
temporal relational facts) depending number objects interactions
objects.
Note event requires least one change state (here, spatio-temporal
relations pairs objects) objects. relation two objects
dc change life span objects, signifies objects
interacting relational fact discarded spatio-temporal facts
contain relevant information defining event models. tracking data consists
bounding boxes people scenes, discarded people germane
semantics events increase size relational data.
8.1.2 Annotation Events
supervised learning need positive preferably negative example instances
events. airport domain, temporal extent events provided individuals expertise IATA protocols apron activities, specifying
start end frame numbers event instance video. spatial extent
obtained using tool polygon drawn one image planes
corresponding ground plane region obtained using homography (it easier
human annotator watch actual video provide spatial annotation rather
view 3D visualization ground plane, fusion imperfectly
tracked data always show relevant objects). region gives spatial
extent event instance.
8.2 Physical Action Verbs Dataset
Action Verbs dataset13 corpus video vignettes (Fig.9) portray motion verbs
approach, exchange, jump, collide, etc. enacted natural environments parks,
13. dataset (Minds Eye Year 1 recognition task videos) provided DARPA publicly available
http://www.visint.org/datasets

68

fiLearning Relational Event Models Video

(a) Approach event tracked objects

(b) Snatch event tracked objects

Figure 9: Example event instances Approach Snatch Action Verbs dataset
urban places, etc. vignettes short duration compared videos
airport domain, tens seconds. full list verbs given Table 3.
Though vignette shot portray single verb action, verbs inevitably
present well, sometimes overlapping time. primarily unavoidable, example,
vignette portrays verb carry, automatically include walk person carrying
object hand. aspect taken consideration annotating
vignettes. able obtain tracked data external source (Morariu, Harwood,
& Davis, 2013) including object type information (Fig.10).
new challenge using dataset different ways verb enacted.
48 verbs dataset total 1615 vignettes used training
2348 vignettes used testing.
8.2.1 Tracking Obtaining Relational Data
tracking data available us often suffers errors, e.g., bouncing ball often
tracked held fast moving objects running person missed.
used Qualitative Trajectory Calculus relations (QT CL1 ) (Van de Weghe et al., 2006)
primitive spatio-temporal relations. choose RCC dataset
seemed unlikely purely topological representation would sufficient. contrast,
QT CL1 relations capture typical movements verbs dataset moving away,
approaching, follow etc. example, chase event one object following another
object relation dc, using RCC, two objects standing still
distance between.
difficult model motion patterns objects run, walk, raise, bend etc. using
relational data without referring parts person. verbs dataset contains
events involve motion patterns recognize these, pixel based models
appropriate. primitive events recognized videos using method
proposed Jiang, Lin Davis (2010), action represented sequence
joint HOG-flow descriptors (Dalal & Triggs, 2005) extracted independently
frame. Instead applying approach entire frame video proposed
Jiang et al. (2010), input restricted sliding temporal windows along spatio69

fiDubba, Cohn, Hogg, Bhatt & Dylla

Person
Object

Vehicle


Figure 10: Tree-structured object type hierarchy Action Verbs domain.
temporal volume defined persons bounding box. primitive events14 addition
QT CL1 relations provide relational data verbs domain.
8.2.2 Annotation Events
ground truth events verbs dataset vignettes different nature
ground truth airport domain. development test set annotated
10 people using Amazon Mechanical Turk (AMT). vignette presented
annotator 48 questions presented form: verb X present vignette?
verbs annotated 50% annotators considered events present
vignette. development set, annotations extended providing
event instance temporal extent.
8.3 Experimental Results Evaluation Typed ILP Framework
Sample rules15 learned Aircraft Arrival AFT Bulk LoadUnload events given
below. example, Aircraft Arrival rule interpreted as: aircraft arrives
aircraft bounding box relation right AFT Bulk TS Zone
moves forward thereby changing relation touch. happens aircraft
arrives moving position. rule correctly identifies bounding
box belong object type aircraft. goals rule ordered
spatial predicates come (to left of) temporal predicates since
temporal facts16 compared spatial facts ordering speeds query execution.
aircraft arrival([intv(T1,T2), intv(T3,T4)]) :in(obj(aircraft(V)), right AFT Bulk TS Zone, intv(T1,T2)),
touch(right AFT Bulk TS Zone, obj(aircraft(V)), intv(T3,T4)),
meets(intv(T1,T2), intv(T3,T4)).
aft bulk loadunload([intv(T1,T2), intv(T3,T4)]) :touch(left TK Zone, obj(veh(heavy veh(V1))), intv(T1,T2)),
touch(obj(veh(V2)), left TK Zone, intv(T3,T4)),
meets(intv(T3,T4), intv(T1,T2)).
followed standard leave-one-out methodology testing performance
airport domain. turn-arounds except one used training remaining one
used test case. process iterated turn-around used test case
14. data provided Vlad Morariu University Maryland.
15. temporal interval represented intv(T1 , T2 ) programming convenience T1 T2
starting ending frame numbers interval.
16. already noted, temporal facts explicitly stored computed via background knowledge
rules.

70

fiLearning Relational Event Models Video

Event

#Examples

Without Type Generalization

Type Generalization

FWD CN LoadUnload

7

0.86

0.06

0.11

0.86

0.08

0.15

GPU Positioning

16

0.4

0.03

0.05

0.27

0.02

0.04

Aircraft Arrival

15

0.43

0.01

0.02

0.36

0.01

0.02

AFT Bulk LoadUnload

29

0.72

0.20

0.31

0.72

0.20

0.31

PBB Removing

15

0.43

0.06

0.10

0.36

0.12

0.18

Left Refuelling

8

0.25

0.03

0.05

0.12

0.10

0.11

PB Positioning

14

0.28

0.04

0.07

0.14

0.06

0.08

Aircraft Departure

12

0.41

0.11

0.17

0.33

0.19

0.24

AFT CN LoadUnload

15

0.80

0.05

0.09

0.67

0.07

0.13

PBB Positioning

15

0.73

0.16

0.26

0.67

0.34

0.45

FWD Bulk LoadUnload

3

1.00

0.24

0.39

1.00

1.00

1.00

Weighted Average

0.15

0.20

Table 1: Performance comparison models obtained without using types using
RCC-5 primitives airport domain. first, second third columns
category recall, precision f1 respectively. best f1 value case presented
bold. clear table using types improves overall performance.
without type generalization mean, type information tracker ignored (all objects
type) type generalization performed learning.

exactly once. results experiments summarised Table 1. third
fourth columns show recall precision without using types 15 turn-arounds
(i.e., type information tracker ignored, hence objects type
type generalization performed learning). fifth sixth columns show
recall precision using type hierarchy. tables clear using type
information increase accuracy event recognition. combined execution
time experiments using type generalization reduced roughly 30%
compared execution time experiments without type generalization.
detailed recognition results (temporal localization) events turn-around
shown Fig. 11 (best seen colour). plot shows turn-around one subplot showing ground truth event instances another subplot showing recognized instances
Typed ILP system turn-around. event colour coded comparing
ground truth recognized instance intervals. Note recognized event instance
considered true positive overlaps least 20% corresponding event ground
truth interval (Oh et al., 2011). cases temporal extent recognized event in71

fiDubba, Cohn, Hogg, Bhatt & Dylla

Figure 11: Recognition events turn-around 1 airport domain (best viewed
colour).

stances long spatial relations important event extend beyond
deictic interval event.
8.3.1 Evaluating Learned Event Models Hand-Coded Event Models
learned models evaluated comparing hand-coded models.
hand-coded models provided domain experts using set domain-dependent
spatial relations (Ferryman et al., 2005). order directly compare performance without
change underlying representation, rather using RCC-5, recomputed
relational data remind using domain-dependent primitives. comparisons
given Table 2. clear table learned models better performance
event categories compared performance hand-coded models.
hand-coded models single primitives rather set primitives connected
temporal relations. kind models one single predicate far
false positives compared models set spatial relations connected
72

fiLearning Relational Event Models Video

Event

#Examples

Learned (RCC-5)

Learned (d-d)

Hand-coded (d-d)

FWD CN LoadUnload

7

0.86

0.08

0.15

0.14

0.50

0.22

0.71

0.04

0.07

GPU Positioning

16

0.27

0.02

0.04

0.44

0.03

0.05

0.00

1.00

0.00

Aircraft Arrival

15

0.36

0.01

0.02

0.07

0.01

0.01

0.07

0.05

0.06

AFT Bulk LoadUnload

29

0.72

0.20

0.31

0.59

0.27

0.37

0.03

0.05

0.04

PBB Removing

15

0.36

0.12

0.18

0.26

0.14

0.18

0.00

1.00

0.00

Left Refuelling

8

0.12

0.10

0.11

0.38

0.23

0.28

0.00

1.00

0.00

PB Positioning

14

0.14

0.06

0.08

0.07

0.08

0.07

0.21

0.09

0.12

Aircraft Departure

12

0.33

0.19

0.24

0.00

1.00

0.00

0.00

1.00

0.00

AFT CN LoadUnload

15

0.67

0.07

0.13

0.33

0.05

0.08

0.47

0.07

0.12

PBB Positioning

15

0.67

0.34

0.45

0.26

0.20

0.22

0.40

0.07

0.12

FWD Bulk LoadUnload

3

1.00

1.00

1.00

0.00

1.00

0.00

1.00

0.02

0.04

Weighted Average

0.20

0.16

0.05

Table 2: Table comparing learned (RCC-5), learned (domain-dependent) hand-coded
models performance (domain-dependent). first, second third columns
category recall, precision f1 respectively. best f1 value case presented
bold.
temporal relations. hand-coded models use specific vehicle type event
models affects performance reducing true positives noise
object type detection, whereas learned models use appropriate generalized object
type cover instances.
8.3.2 Evaluating Learned Event Models Different Spatial Relations
performed evaluation investigate effects different spatial relations.
comparison used RCC-5 domain specific relations airport domain.
use QTC relations domain examples learn
many spatial relations QTC spatial calculus, patterns
events emerge. results given Table 2. table clear
models learned using RCC-5 better recognition performance (mean f1: 0.25)
compared models learned using domain-dependent relations (mean f1: 0.13). One
reason might RCC-5 better representation granularity compared
domain-dependent primitives. RCC-5 JEPD (jointly exhaustive pair-wise
disjoint) property domain-dependent primitives airport domain
(it lacks pair-wise disjoint property).
8.3.3 Evaluating Verbs Dataset
framework uses type generalization applied verbs dataset
48 verbs. Table 3 shows precision, recall f1 scores classification task.
video test set, event models used queries event model
73

fiDubba, Cohn, Hogg, Bhatt & Dylla

succeeds, particular verb considered present video (and variable
bindings give time occurrence objects involved). compared
ground truth obtain precision recall values.
provide sample rules learned events Approach Snatch cover
instances shown Fig.9. QT CL1 relations moto (short form moving towards
stationary object), static depart (short form moving away stationary object)
corresponds relations blobs row 2 column 1, row 2 column 2, row 2
column 3 respectively Fig.1. note unlike models learned Airport
Dataset, list temporal intervals argument head rules here.
want recognize events videos Action Verbs
dataset videos short find temporal extent event.
approach() :moto(obj(vehicle(J)), obj(person(K)), intv(V 32,V 33)),
static(obj(vehicle(J)), obj(person(K)), intv(V 34,V 35)),
meets(intv(V 32,V 33), int(V 34,V 35)).
snatch() :static(obj(person(J)), obj(person(K)), intv(V 24,V 25)),
moto(obj(other(L)), obj(person(J)), intv(V 40,V 41)),
depart(obj(other(L)), obj(person(K)), intv(V 18,V 51)),
overlaps(intv(V 40,V 41), int(V 18,V 51)),
during(intv(V 40,V 41), intv(V 24,V 25)),
during(intv(V 18,V 51), intv(V 24,V 25)).
proposed framework, compared existing systems results
presented Tables 4-7. One systems compared with, RedVine
system, supervised learning version framework proposed Sridhar, Cohn
Hogg (2010). based graphical representation relational facts, event
represented histogram graphemes (small graphs represent spatio-temporal
interactions objects involved event) mapped vector space facilitate
classification. Stack convolutional Independent Subspace Analysis (ScISA) (Le et al.,
2011)17 based pixel level flow based features used model events
using neural network. spatio-temporal features used algorithm learned
unsupervised fashion instead using predefined features SIFT (Lowe, 2004),
HoG (Dalal & Triggs, 2005), etc.
evaluation dataset provided DARPA total 2348 vignettes.
found vignettes (1294) training set appeared evaluation set.
call dataset 2348 vignettes Verb Evaluation Dataset-1 (VED1)
remaining vignettes discarding 1294 vignettes appeared training dataset
VED2. Evaluation VED1 gives interesting insights overfitting underfitting
different learning frameworks compared. chose two different average
mechanisms (macro micro)18 get overall f1 Matthews correlation coefficient
(MCC) scores verbs vignettes. True Negatives play role f1
17. Results using system provided Tuyen Huynh SRI.
18. Macro-average calculated first calculating precision recall category taking
average values, micro-average calculated constructing global contingency table
calculating precision recall using sums.

74

fiLearning Relational Event Models Video

Verb

precision recall

approach
arrive
attach
bounce
bury
carry
catch
chase
close
collide
dig
drop
enter
exchange
exit
fall

0.36
0.28
0.08
0.11
0.05
0.14
0.05
0.04
0.07
0.14
0.02
0.08
0.17
0.06
0.15
0.10

0.78
0.73
0.49
0.71
0.57
0.53
0.58
0.44
0.29
0.83
0.36
0.47
0.74
0.56
0.71
0.62

f1

Verb

0.49
0.40
0.14
0.19
0.10
0.22
0.10
0.07
0.11
0.24
0.04
0.14
0.28
0.11
0.25
0.17

flee
fly
follow
get
give
go
hand
haul

hit
hold
jump
kick
leave
lift
move

precision recall
0.07
0.06
0.09
0.15
0.11
0.52
0.10
0.09
0.46
0.14
0.47
0.06
0.07
0.29
1.00
0.76

0.82
0.42
0.62
0.50
0.66
0.79
0.66
0.46
0.60
0.64
0.69
0.25
0.38
0.76
0.00
0.74

f1
0.14
0.11
0.16
0.23
0.18
0.63
0.17
0.15
0.52
0.23
0.56
0.09
0.11
0.42
0.00
0.75

Verb
open
pass
pickup
push
putdown
raise
receive
replace
run
snatch
stop
take
throw
touch
turn
walk

precision recall
0.10
0.22
1.00
0.16
1.00
0.33
0.15
0.07
0.10
0.11
0.39
0.24
0.06
0.64
0.47
0.32

0.77
0.39
0.00
0.82
0.00
0.63
0.70
0.77
0.82
0.51
0.78
0.62
0.39
0.53
0.53
0.80

f1
0.17
0.28
0.00
0.27
0.00
0.44
0.25
0.13
0.18
0.19
0.52
0.35
0.10
0.58
0.50
0.45

Table 3: Classification results per verb physical action verbs domain.

scores considerable effect MCC scores MCC differentiate
positive negative classes. MCC give scores even class labels
interchanged f1 scores change. Note much work literature activity
recognition use f1 scores.
Tables 4-7, clear ScISA better MCC scores cases
remind better f1 score VED2, though lower MCC scores
MCC scores two algorithms. note drop performance ScISA
VED2 set compared VED1, whereas remind RedVine almost
performance indicating ScISA overfitting data remind RedVine
underfitting data. reason high f1 low MCC score remind
True Negatives.
ScISA performs quite well (w.r.t. MCC score) modelling capability
framework since underutilizes temporal domain. outperform
state-of-the-art evaluation measures, proposed scheme still general, i.e.,
(i) gives good interpretations activities video scenes; (ii) take temporal
domain account unlike ScISA therefore provides better modelling capabilities;
(iii) gives high recall precision improved post-processing
(iv) provides (elegant) logical rules easily interpreted human observer.
One major drawback ScISA lack spatio-temporal localization recognized
event. suitable event classification tasks (verbs dataset)
event recognition tasks (airport domain). Although report localization
(owing short videos data set), deriving localization (or position) information
remind trivial event recognized since intervals objects involved
explicitly identified rule body.
75

fiDubba, Cohn, Hogg, Bhatt & Dylla

Method
remind
RedVine
ScISA

avg-prec
0.24
0.32
0.91

avg-rec
0.56
0.24
0.54

f1
0.34
0.28
0.68

MCC
0.05
0.16
0.67

Table 4: Performance verbs domain: VED1, macro-average per verb.

Method
remind
RedVine
ScISA

total prec
0.21
0.37
0.92

total rec
0.59
0.24
0.60

f1
0.31
0.30
0.72

MCC
0.0
0.19
0.70

Table 5: Performance verbs domain: VED1, micro-average (total detection classification)

Method
remind
RedVine
ScISA

avg-prec
0.25
0.35
0.49

avg-rec
0.59
0.25
0.20

f1
0.35
0.29
0.29

MCC
0.04
0.17
0.21

Table 6: Performance verbs domain: VED2, macro-average per verb

Method
remind
RedVine
ScISA

total prec
0.21
0.40
0.59

total rec
0.63
0.26
0.29

f1
0.32
0.31
0.39

MCC
0.08
0.20
0.33

Table 7: Performance verbs domain: VED2, micro-average (total detection classification)

8.4 Experimental Results Evaluation IIA
IIA framework evaluated airport verb datasets. use
Hyprolog, logic programming framework capable abductive inference (Christiansen &
Dahl, 2005).
8.4.1 Embedding Spatial Theory Airport Domain
airport domain, encoded RCC-5 spatial theory space framework contains conceptual neighbourhood graph, JEPD relationships
composition theorems spatial relations used follows:
76

fiLearning Relational Event Models Video

% Sample
dc(X, Y,
dc(X, Y,
dc(X, Y,
dc(X, Y,
dc(X, Y,

JEPD
T) ,
T1),
T1),
T1),
T1),

constraints
touch(X, Y,
touch(X, Y,
touch(X, Y,
touch(X, Y,
touch(X, Y,

(P1 - P2) RCC-5
T)
T2), during(T1, T2)
T2), during(T2, T1)
T2), overlaps(T1, T2)
T2), overlaps(T2, T1)

<=>
<=>
<=>
<=>
<=>

fail.
fail.
fail.
fail.
fail.

% Conceptual Neighbourhood constraints (P3) RCC-5
dc(X, Y, T1), in(X, Y, T2), meets(T1, T2) <=> fail.
in(X, Y, T1), dc(X, Y, T2), meets(T1, T2) <=> fail.
% Sample Composition Theorem (P4) RCC-5
in(X, Y, T1), dc(Y, Z, T2), touch(X, Z, T3), during(T2, T1),
during(T3, T2) <=> fail.

JEPD CND property constraints forbid abduction facts contradict spatial theory thus avoiding physically impossible scenarios helps
abduction complete reasonable time.
explain approach, consider following fragments actually occurring datasets
(Ex:1 - Ex:4) event Aircraft Arrival :

Ex:1

dc(arr zone,obj(aircraft(obj45)),intv(6661,7137))
touch(arr zone,obj(aircraft(obj45)),intv(7138,29114))
touch(arr zone,obj(veh(light veh(gpu(obj54)))),intv(7154,8161))
dc(arr zone,obj(veh(heavy veh(loader(obj2)))),intv(749,30380))

Ex:2

dc(arr zone,obj(aircraft(obj68)),intv(2342,2663))
touch(arr zone,obj(aircraft(obj68)),intv(2664,29524))

Ex:3

dc(arr zone,obj(veh(light veh(trolley(obj0)))),intv(285,21494))
touch(arr zone,obj(aircraft(obj41)),intv(4458,32404))
touch(arr zone,obj(veh(light veh(trolley(obj2)))),intv(1712,32405))

Ex:4

dc(arr zone,obj(aircraft(obj33)),intv(2435,6987))
touch(arr zone,obj(veh(heavy veh(loader(obj27)))),intv(2197,2310))
dc(arr zone,obj(veh(heavy veh(loader(obj27)))),intv(2311,2645))

obtain following model Aircraft Arrival event learned ILP approach
first two examples given examples arr zone denoting specific zone
apron Ti denotes time point. fact two time points indicating start
end interval spatio-temporal fact holds.

aircraft arrival([intv(T1,T2), intv(T3,T4)]) :dc(arr zone, obj(aircraft(V)), intv(T1,T2)),
touch(arr zone, obj(aircraft(V)), intv(T3,T4)),
meets(intv(T1,T2), intv(T3,T4)).
77

fiDubba, Cohn, Hogg, Bhatt & Dylla

obj

obj

Z1
Z2

Z1
Z2
Z3

Z3

arr_zone

Z4

Z5

arr_zone

Z4

Z5

time

aircraft_arrival(T1,T2)
dis(arr_zone,obj(aircraft(V)),T1,T)
con(arr_zone,obj(aircraft(V)),T+1,T2)
(a) Spatial primitive based event modelling

966

966

Z1
Z2
Z3
Z4

Z1
Z2
Z3

arr_zone
Z5

Z4

arr_zone
Z5

time

aircraft_arrival(5338,16868)
rel?(arr_zone,obj?,5338,16630)
con(arr_zone,obj(aircraft(obj996)),16631,16868)
(b) Narrative completion (of data video) previously learned model

Figure 12: IIA Scenario Narrative Completion; E.g., aircraft arrival
rule states aircraft arrival takes place interval
aircraft disconnected arr zone directly followed interval, i.e., meets,
aircraft connected arr zone. model cover examples
apart Ex:1 Ex:2. Ex:3 missing dc relation related aircraft whereas
Ex:4 missing touch relation (Fig. 12b). represent typical data corruption
higher level tracking error lower level video processing different stages
video.
8.4.2 Narrative Completion Airport Domain
Multiple explanations interesting give several possible scenarios consistent narrative. example, consider Ex:4 touch fact related aircraft
arrival event missing narrative. happens vision algorithm fails
detect aircraft coming towards parking zone big object changes
light conditions scene. abduction system comes two explanations (as
shown following sample interactive run system), one filling missed fact
consistent narrative background knowledge constraints. Another
explanation using hypothetical object ( G41673) present database.
78

fiLearning Relational Event Models Video

explanation expensive first explanation, system chose first
explanation.
%A small narrative three observations (The touch fact
%is missing, happens, vision algorithm fails
%to detect aicraft close: Approximate
%interval specified aircraft-arrival query
%dc(arr_zone,obj(aircraft(obj33)),intv(2435,6987))
%touch(arr_zone,obj(veh(heavy_veh(loader(obj7)))),intv(2197,2310))
%dc(arr_zone,obj(veh(heavy_veh(loader(obj7)))),intv(2311,2645))
?- aircraft_arrival(intv(2000,12000)).
touch(arr_zone,obj(aircraft(obj33)),intv(6988,7988))
true ;
dc(arr_zone,obj(aircraft(_G41673)),intv(2435,6987))
touch(arr_zone,obj(aircraft(_G41673)),intv(6988,7988))
true ; false.
narrative completion, possible cover examples given above, one
single Aircraft Arrival model learned. avoids learning spurious rules cover
corrupted examples thus giving us compact semantically meaningful models.
evaluate approach, compare rules learned using induction rules
learned using IIA algorithm. first column Table 8 shows events
considered experiments, second column shows number instances
particular event 15 turnarounds. third column shows number rules learned
using ILP fourth column shows results using IIA algorithm
fifth column shows number examples covered induced rules
explained using abduction hence rules learned them. interleaving
induction abduction, able avoid learning spurious rules shown
results. classes, number rules reduced 50% overall
performance increased. observed rules previously
learned examples covered abduction semantically correspond
events.
8.4.3 Evaluating IIA Verbs Dataset
verbs domain, encoded spatial theory QT CL1 spatial calculi. Though
used domain-dependent primitive events domain besides QT CL1 ,
encode spatial theory relations well defined. example,
domain-dependent primitives domain neither jointly exhaustive pair-wise
disjoint. avoided abducing explanations relations including
relations list abducibles. 10-fold cross-validation used evaluation verbs
dataset. Since video short duration around 200 frames, used classification
instead recognition. Table 9 clear using abduction reduces number
rules event model thereby giving compact model. verbs dataset results,
considerable change performance classification task rather
recognition task. main performance increase IIA inference comes
79

fiDubba, Cohn, Hogg, Bhatt & Dylla

Airport Events

#pos

FWD CN LoadUnload
5
GPU Positioning
15
Aircraft Arrival
15
Aircraft Departure
15
AFT Bulk LoadUnload
12
Left Refuelling
6
PB Positioning
15
AFT CN LoadUnload
7
PBB Positioning
15
PBB Removing
15
FWD Bulk LoadUnload
3
Num rules Induction 2

2
5
5
5
5
2
4
3
4
5
2
Num



2

RoI

PoI

RIA

PIA

1
2
0.8
0.3
0.8
3
4
1
0.2
1
2
5
0.38
0.26
0.33
2
7
0.8
0.15
0.71
2
4
0.63
0.43
0.63
1
2
0.66
0.5
0.66
3
2
0.33
0.34
0.33
1
3
0.57
0.4
0.57
3
2
1
0.57
1
2
5
0.54
0.23
0.54
1
1
1
1
1
rules IIA avg num examples covered

0.4
0.4
0.32
0.26
0.65
0.55
0.42
0.51
0.62
0.31
1
abd

Table 8: Airport domain IIA results averaged iterations leave-one-out testing.
RoI, PoI - recall precision induction: RIA, PIA - recall precision using
IIA.
Verb Events

#pos

2



RoI

Approach
584
12
5
45
0.73
Arrive
8
2
1
2
0.50
Attach
48
6
3
12
1.00
Bounce
22
2
2
0
0.95
Catch
201
7
4
31
0.59
Chase
108
11
7
19
0.59
Collide
101
6
4
14
0.98
Dig
140
10
7
21
0.96
Drop
44
2
2
0
1.00
Exchange
18
6
3
4
0.40
Fall
134
8
5
18
0.92
Give
552
27
20
54
0.94
Jump
150
6
4
14
0.98
Kick
48
4
3
6
1.00
Leave
116
10
4
34
0.67
Lift
78
8
5
17
0.67
Pass
76
8
4
13
0.87
Pickup
40
6
4
8
0.81
Run
76
7
5
7
0.57
Throw
26
3
2
5
0.67
Num rules Induction 2 Num rules IIA avg

PoI

RIA

0.12
0.74
0.05
0.50
0.14
1.00
0.06
0.95
0.11
0.56
0.08
0.57
0.16
0.98
0.38
0.96
0.16
1.00
0.03
0.40
0.35
0.90
0.56
0.94
0.13
0.98
0.15
1.00
0.20
0.67
0.24
0.67
0.10
0.87
0.13
0.81
0.12
0.57
0.11
0.67
num examples covered

PIA
0.12
0.05
0.17
0.08
0.11
0.08
0.18
0.39
0.16
0.03
0.35
0.60
0.13
0.15
0.22
0.24
0.12
0.16
0.12
0.11
abd

Table 9: Verbs dataset IIA results averaged iterations 10-fold cross-validation
testing. RoI, PoI - recall precision induction: RIA, PIA - recall precision
using IIA.

reduction false positives fewer rules recognition high
possibility multiple rules firing test data thereby giving many false positives.
classification, case, vignette classified member
particular event class rule, classification rules event class
affect overall outcome vignette.

80

fiLearning Relational Event Models Video

9. Limitations Future Work
models used remind local, i.e., without context wider activity model
could used filter recognized instances thereby increasing performance.
example, turn-arounds airport domain, Aircraft Departure event
sometimes recognized even Aircraft Arrival recognized resulting false positives
Aircraft Departure. Another limitation learned models lack representation
duration events. Many recognized event instances rejected system
temporal extent recognized instances long fails criteria 20% overlap
ground truth. reduced learning global model (Greenall, Cohn, &
Hogg, 2011) constrains ordering events Aircraft Departure detections
happen Aircraft Arrival. activity models represent expected
duration events, temporal separation events number occurrences.
framework sensitive initial example selected start learning procedure.
induction system used based algorithm uses bottom clause (Muggleton,
1995) constructed selected example guide refinement hypothesis
searching lattice. Hence possible might select corrupted example initially
might affect whole induction process. typical problem machine learning
several ways avoid this. One promising approach followed
work repeat learning different examples chosen randomly starting point
selecting iteration gives minimum number rules.
Another limitation framework dependency tracking objects
uses interactions objects model events. Challenging scenarios object tracking
pose limitations current framework. current framework probabilistic, i.e.,
neither input data learned models probabilistic. One direction future work
extend framework using statistical relational learning use soft evidence
learn robust probabilistic relational models. Since current framework
handle hierarchies events, framework could extended handle hierarchical
composition events. One possible approach learn models events
particular layer using events lower layers primitives.

10. Conclusion
paper, proposed supervised relational learning framework, extension using abduction, learn event models complex videos. event models
used recognize event instances unseen videos. presented Type Refinement
operator exploits object type hierarchy domain search better hypotheses proved optimal refinement operator. presented empirical
evaluation proposed framework two real world video data sets results
encouraging, showing framework effectively used real world systems
event recognition various domains. showed proposed framework
better generalization capabilities performance compared state-of-the-art
systems event modelling. Finally, note although focused learning
video data here, fact approach would suitable learning
data sources provide tracks interacting moving objects (e.g. GPS streams).
81

fiDubba, Cohn, Hogg, Bhatt & Dylla

Acknowledgements
thank colleagues CO-FRIEND, RACE, STRANDS VIGIL projects consortia
valuable inputs research, respective funding EU Framework
7 (FP7-ICT-214975, FP7-ICT-27752, FP7-ICT-600623) DARPA (W911NF-10-C-0083).
financial support Deutsche Forschungsgemeinschaft Transregional Collaborative Research Center SFB/TR 8 Spatial Cognition project R3-[Q-Shape] gratefully
acknowledged.

Appendix A. Proof Optimality Type Refinement Operator
Let type hierarchy tree set nodes TV , set leaf nodes TL , i.e.
specific types (TL TV ) r root tree (most generic type). type
parent node generic types children nodes write
= .
Let g function, g : TV TV , maps child node immediate parent.
function g considered generalizing operator generalizes type nearest
generic type. g applied long 6= r
Let Si ordered (from most-specific general) set possible generalizations including .
Si = {i , g(i ), g(g(i )), . . . , r }
set types {1 , 2 , . . . , n }, define corresponding sets S1 , S2 , . . . , Sn .
Let {h1 , h2 , . . . , hm } set types19 clause C {h1 , h2 , . . . , hm } TV .
{h1 , h2 , . . . , hm }, define Sh1 , Sh2 , . . . , Shm . make set {h1 , h2 , . . . , hm }
generic applying g (one times) arbitrarily selected subset types
one type time.
Cartesian product Sh1 Sh2 . . . Shm set tuples tuple
possible generalization {h1 , h2 , . . . , hm }.
Let l function mapping non-leaf type node integer specifies many
times g applied original leaf node obtain non-leaf node20 , l : TV N .
Using l, generate new set Nhi Shi replacing l(i ).
generate new Cartesian product Nh1 Nh2 . . . Nhm .
Example .1. Let (1 , 2 , 3 ) set types clause C let type hierarchy
given Fig.13. define S1 , S2 , S3 N1 , N2 , N3 follows
tree representation Cartesian products S1 S2 S3 N1 N2 N3 given
Fig.14 Fig.15 respectively.
19. consider list types clause C types may repeated
arguments type, results appendix still valid.
20. Note general, non-leaf node obtained leaf nodes descendants
unique leaf node obtained store original leaf node generalized using g
get non-leaf type node.

82

fiLearning Relational Event Models Video

r

1 g(2 ), g(3 )

2 3

Figure 13: example type hierarchy.

S1 = {1 , g(1 )}
S2 = {2 , g(2 ), g(g(2 ))}
S3 = {3 , g(3 ), g(g(3 ))}
N1 = {0, 1}
N2 = {0, 1, 2}
N3 = {0, 1, 2}

1
2

g(2 )

g(1 )
2

g(g(2 ))

g(2 )

g(g(2 ))

3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 ))

Figure 14: Representing Cartesian product S1 S2 S3 tree. root empty
next layer corresponds S1 on. Note g(1 ) = g(g(2 )) = g(g(3 )) = r .
path tree leaf possible generalization (1 , 2 , 3 ) leftmost path
null generalization, i.e. (1 , 2 , 3 ).
Definition .2. (Type Substitution, ) type substitution set
{h1 /1 , h2 /2 , . . . , hn /n } hi type subset variables
clause C immediate generic type hi (parent node hi tree ).
say substituted hi clause. set {h1 , h2 , . . . , hn } called domain
, denoted dom( ) set (1 , 2 , . . . , n ) called range , denoted rng( ).
type substitution used generalize type subset variables clause.
Definition .3. (Most Generic Type Substitution, r ) generic type substitution
type substitution whose range set {r } r root type hierarchy tree .
generic type substitution used check two clauses structurally equivalent
(Def:4) substituting types variable r . Note every clause C unique
generic type substitution, Cr , whose domain set types C range
set {r }.
83

fiDubba, Cohn, Hogg, Bhatt & Dylla



0

0

1

1

2

0

1

2

0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2

Figure 15: Representing Cartesian product N1 N2 N3 tree. root empty
next layer corresponds N1 on. path leaf represents possible
generalization (1 , 2 , 3 ). generalization obtained following path
root leaf generalizing type layer number times indicated
node value. example, highlighted sequence (1,2,1) corresponds generalization
(g(1 ), g(g(2 )), g(3 )). obtained generalizing 1 generalizing 2
twice generalizing 3 once. top bottom order (left right case tuples)
followed, unique way achieve generalization (g(1 ), g(g(2 )), g(3 ))
(1 , 2 , 3 ).
Definition .4. (Structurally Equivalent, ) Two clauses, C C 0 structurally equiv0
alent, denoted C C 0 , CCr C 0 Cr .
clause C structurally equivalent clauses obtained replacing subset
types variables C generalizations.
Definition .5. (Generic Order w.r.t. types, ) clause C said general
w.r.t. type another clause C 0 , denoted C C 0 , iff C C 0 set types C
correspondingly generic set types C 0 .
Definition .6. (Type-Refinement Operator) Let clausal language, type hierarchy
C clause . CT subset defined C clause C 0 CT
structurally equivalent C, i.e., C C 0 . Let subsumption order defined above.
Type-Refinement operator hCT , function (C) {D|D C}.
One-step type refinement C defined applied once, i.e. 1 =
(C). n-step type refinement defined similarly, i.e. n = {D | E, E
n1
(C) (E)}. set type refinements C given

(C) = 1 (C) 2 (C) . . ..
locally finite every C , (C) finite computable.
proper every C , (C) {D|D C}.
complete every C, C, E (C)
E (i.e. E equivalent order).
84

fiLearning Relational Event Models Video

weakly complete hCT , (C) = CT .
non-redundant every C, D, E , E (C) E (D) implies
C (D) (C)
ideal locally finite, proper complete.
optimal locally finite, non-redundant weakly complete.
type refinement operator selects type hi set {h1 , h2 , . . . , hm } C applies type generalizing operator type resulting set {h1 , h2 , . . . , g(hi ), . . . , hm }
used substitution C obtain generic clause C 0 respect type, i.e.,
C 0 C . type refinement operator follows left right order generalizing types
avoid generating redundant clauses, i.e., type position generalized
next step refinement h0 type position j, j < selected generalizing.
Theorem .7. locally finite
Proof. Let type hierarchy tree TV set nodes TC =
{h1 , h2 , . . . , hm } set types clause C TC TV . Let g type
generalizing operator type refinement operator. operates C selecting
type set {h1 , h2 , . . . , hm } generalizing applying g. |TC |
possibilities select possible type selected one possible
generalization, type one parent tree . type
generalized finite number times (i.e., becomes r ). Hence number possible
refinements, i.e., | (C)| finite making locally finite.
Theorem .8. weakly complete
Proof. given clause C set types {h1 , h2 , . . . , hm } defined above.
1 , 1 , . . .} obtained one-step type refinement
Let X1 set substitutions {,1
,2
1 C 0 1 (C). Let X = X X . . . X set
Ci0 = C,i
1
2
2


1 , 1 , . . . , 1 }
substitutions obtained two-step type refinement {i1
i2
im
1 ).
rng(,i
1 , 1 , . . . , 1 ), . . . , ( 1 , 1 , . . . , 1 ), . . .}, i.e. 1
Let 1 set tuples {(11
12
1m
i1 i2
im
set tuples tuple represents possible type refinement {h1 , h2 , . . . , hm }
one-step type refinement let = 1 2 . . ..
easy observe tuple P tuple Cartesian product
Sh1 Sh2 . . . Shm . fact exact one one matching members
members Sh1 Sh2 . . . Shm . easy obtain member tuple, say P
P = (1 , 2 , . . . , ) Cartesian product generalizing {h1 , h2 , . . . , hm }. type hi
generalized equal moving next type immediate right
hi . way possible type generalizations {h1 , h2 , . . . , hm } reachable
{h1 , h2 , . . . , hm }, i.e., possible type generalized clauses reachable C, hence
weakly complete.
Theorem .9. non-redundant
85

fiDubba, Cohn, Hogg, Bhatt & Dylla

Proof. Let Nh1 Nh2 . . . Nhm defined previously set types {h1 , h2 , . . . , hm }
clause C. Cartesian product represented tree root
empty next level elements Nh1 on. path leaf represents
possible generalization {h1 , h2 , . . . , hm }. generalization obtained following
path root leaf generalizing type layer number times
indicated node value. top bottom order (left right case tuples)
followed, unique way obtain generalization path generates. Hence
non-redundant.
Example .10. example Fig.15, sequence (1,2,1) bold corresponds generalization (g(1 ), g(g(2 )), g(3 )). obtained generalizing 1 generalizing
2 twice generalizing 3 once. top bottom order followed,
unique way achieve generalization (g(1 ), g(g(2 )), g(3 )) (1 , 2 , 3 ).
Theorem .11. optimal
Proof. Since type refinement operator locally finite, weakly complete non-redundant,
optimal.

References
Albanese, M., Moscato, V., Picariello, A., Subrahmanian, V., & Udrea, O. (2007). Detecting
stochastically scheduled activities video. Proceedings International Joint
Conference Aritificial Intelligence (IJCAI), pp. 18021807.
Allen, J. F. (1983). Maintaining knowledge temporal intervals. Communications
ACM, 26, 832843.
Bengio, Y. (2009). Learning deep architectures AI. Foundations Trends Machine
Learning, 2 (1), 1127.
Bhatt, M., & Loke, S. (2008). Modelling dynamic spatial systems situation calculus.
Spatial Cognition & Computation, 8 (1-2), 86130.
Blockeel, H., De Raedt, L., Jacobs, N., & Demoen, B. (1999). Scaling Inductive Logic
Programming learning interpretations. Data Mining Knowledge Discovery, 3 (1), 5993.
Bundy, A., Byrd, L., & Mellish, C. (1985). Special-purpose, domain-independent, inference mechanisms. Progress Artificial Intelligence, pp. 93111. London: Ellis
Horwood.
Chen, J., Cohn, A. G., Liu, D., Wang, S., Ouyang, J., & Yu, Q. (2015). survey
qualitative spatial representations. Knowledge Engineering Review, 30, 106136.
Christiansen, H., & Dahl, V. (2005). HYPROLOG: new logic programming language
assumptions abduction. Logic Programming, 159173.
Cohn, A. G. (1989). Taxonomic reasoning many-sorted logics. Artificial Intelligence
Review, 3 (2), 89128.
86

fiLearning Relational Event Models Video

Cohn, A. G., Hogg, D. C., Bennett, B., Devin, V., Galata, A., Magee, D. R., Needham, C.,
& Santos, P. (2006). Cognitive vision: integrating symbolic qualitative representations
computer vision.. Vol. 3948 LNCS, chap. 14, pp. 221246. Springer.
Dalal, N., & Triggs, B. (2005). Histograms oriented gradients human detection.
IEEE Conference Computer Vision Pattern Recognition (CVPR), Vol. 1, pp.
886893.
Dubba, K. S., Bhatt, M., Dylla, F., Hogg, D. C., & Cohn, A. G. (2012). Interleaved
inductive-abductive reasoning learning complex event models. Inductive Logic
Programming, pp. 113129. Springer.
Dubba, K. S., Cohn, A. G., & Hogg, D. C. (2010). Event model learning complex
videos using ILP. Proceedings European Conference Artificial Intelligence
(ECAI), Vol. 215, pp. 9398.
Fern, A., Givan, R., & Siskind, J. (2002). Specific-to-general learning temporal events
application learning event definitions video. Journal Artificial Intelligence Research, 17, 379449.
Ferryman, J., Borg, M., Thirde, D., Fusier, F., Valentin, V., Bremond, F., Thonnat, M.,
Aguilera, J., & Kampel, M. (2005). Automated scene understanding airport aprons.
LNCS-3809, Springer Verlag, 3809, 593.
Freksa, C. (1991). Conceptual neighborhood role temporal spatial reasoning.
Singh, M., & Trave-Massuyes, L. (Eds.), Decision Support Systems Qualitative
Reasoning, pp. 181187. North-Holland, Amsterdam.
Ghahramani, Z. (1998). Learning Dynamic Bayesian networks. Adaptive Processing
Sequences Data Structures, 168197.
Greenall, J., Cohn, A. G., & Hogg, D. C. (2011). Temporal structure models event
recognition. British Machine Vision Conference (BMVC).
Gupta, A., Srinivasan, P., Shi, J., & Davis, L. (2009). Understanding videos, constructing
plots learning visually grounded storyline model annotated videos. IEEE
Conference Computer Vision Pattern Recognition (CVPR), pp. 20042011.
Hakeem, A., Sheikh, Y., & Shah, M. (2004). CASEE : hierarchical event representation
analysis videos. Proceeding National Conference Artificial
Intelligence (AAAI), pp. 263268.
Hartley, R., & Zisserman, A. (2004). Multiple View Geometry Computer Vision (Second
edition). Cambridge University Press.
Hazarika, S. M., & Cohn, A. G. (2002). Abducing qualitative spatio-temporal histories
partial observations. International Conference Principles Knowledge
Representation Reasoning, pp. 1425.
Hoogs, A., & Perera, A. G. A. (2008). Video activity recognition real world.
Proceedings National Conference Artificial Intelligence (AAAI), pp. 1551
1554.
87

fiDubba, Cohn, Hogg, Bhatt & Dylla

Ivanov, Y., & Bobick, A. (2000). Recognition visual activities interactions stochastic parsing. IEEE Transactions Pattern Analysis Machine Intelligence (PAMI),
22 (8).
Jiang, Z., Lin, Z., & Davis, L. S. (2010). tree-based approach integrated action localization, recognition segmentation. Third Workshop Human Motion (in
conjuntion ECCV).
Kakas, A., Kowalski, R., & Toni, F. (1992). Abductive logic programming. Journal Logic
Computation, 2 (6), 719.
Kakas, A., & Riguzzi, F. (2000). Abductive concept learning. New Generation Computing,
18 (3), 243294.
Konik, T., & Laird, J. (2006). Learning goal hierarchies structured observations
expert annotations. Machine Learning, 64 (1), 263287.
Laptev, I. (2005). space-time interest points. International Journal Computer Vision,
64 (2), 107123.
Laptev, I., & Perez, P. (2007). Retrieving actions movies. IEEE International Conference Computer Vision (ICCV), pp. 18.
Le, Q., Zou, W., Yeung, S., & Ng, A. (2011). Learning hierarchical invariant spatio-temporal
features action recognition independent subspace analysis. IEEE Conference Computer Vision Pattern Recognition (CVPR), pp. 33613368. IEEE.
Lowe, D. (2004). Distinctive image features scale-invariant keypoints. International
Journal Computer Vision, 60 (2), 91110.
McCarthy, J. (1986). Applications circumscription formalizing common-sense knowledge. Artificial Intelligence, 28 (1), 89116.
Medioni, G., Cohen, I., Bremond, F., Hongeng, S., & Nevatia, R. (2001). Event detection
analysis video streams. IEEE Transactions Pattern Analysis Machine
Intelligence (PAMI), 23 (8), 873889.
Miller, R., & Shanahan, M. (1994). Narratives Situation Calculus. Journal Logic
Computation, 4 (5), 513530.
Morariu, V. I., & Davis, L. S. (2011). Multi-agent event recognition structured scenarios..
IEEE Conference Computer Vision Pattern Recognition (CVPR), pp. 3289
3296.
Morariu, V. I., Harwood, D., & Davis, L. S. (2013). Tracking peoples hands feet
using mixed network and/or search.. IEEE Transactions Pattern Analysis
Machine Intelligence (PAMI).
Moyle, S. (2003). Using theory completion learn robot navigation control program.
Proceedings International Conference ILP, 182197.
Moyle, S., & Muggleton, S. (1997). Learning programs Event Calculus. LNAI-1297,
Springer-Verlag, 205212.
Muggleton, S. (1995). Inverse entailment Progol. New Generation Computing, 13 (3&4),
245286.
88

fiLearning Relational Event Models Video

Muggleton, S., & Bryant, C. H. (2000). Theory completion using inverse entailment. Proceedings International Conference ILP, pp. 130146, UK. Springer-Verlag.
Needham, C., Santos, P., Magee, D., Devin, V., Hogg, D., & Cohn, A. (2005). Protocols
perceptual observations. Artificial Intelligence, 167 (1-2), 103136.
Nevatia, R., Hobbs, J., & Bolles, B. (2004). ontology video event representation.
Computer Vision Pattern Recognition Workshop (CVPRW-04), pp. 119119.
IEEE.
Nienhuys-Cheng, S., & De Wolf, R. (1997). Foundations Inductive Logic Programming,
Vol. 1228. Springer Verlag.
Oh, S., Hoogs, A., Perera, et al. (2011). large-scale benchmark dataset event recognition surveillance video. IEEE Conference Computer Vision Pattern
Recognition (CVPR), pp. 31533160.
Poole, D., Goebel, R., & Aleliunas, R. (1987). Theorist: logical reasoning system
defaults diagnosis. Knowledge Frontier, pp. 331352.
Quinlan, J., & Cameron-Jones, R. (1993). FOIL: midterm report. Proceedings
European Conference Machine Learning (ECML), pp. 120.
Quinlan, J. (1990). Learning logical definitions relations. Machine Learning, 5 (3),
239266.
Rabiner, L. (1989). tutorial Hidden Markov models selected applications speech
recognition. Proceedings IEEE, 77 (2), 257286.
Randell, D. A., Cui, Z., & Cohn, A. (1992). spatial logic based regions connection. Proceedings International Conference Knowledge Representation
Reasoning, pp. 165176. Morgan Kaufmann.
Ryoo, M. S., & Aggarwal, J. K. (2009). Semantic representation recognition continued
recursive human activities. International Journal Computer Vision, 82 (1), 1
24.
Ryoo, M., & Aggarwal, J. (2011). Stochastic representation recognition high-level
group activities. International Journal Computer Vision, 93 (2), 183200.
Sridhar, M., Cohn, A. G., & Hogg, D. C. (2010). Unsupervised learning event classes
video. Proceedings National Conference Artificial Intelligence (AAAI),
pp. 16311638.
Tamaddoni-Nezhad, A., Chaleil, R., Kakas, A., & Muggleton, S. (2006). Application
abductive ILP learning metabolic network inhibition temporal data. Machine
Learning, 64 (1), 209230.
Tamaddoni-Nezhad, A., & Muggleton, S. (2009). lattice structure refinement
operators hypothesis space bounded bottom clause. Machine learning,
76 (1), 3772.
Van de Weghe, N., Cohn, A., De Tre, G., & De Maeyer, P. (2006). qualitative trajectory calculus basis representing moving objects geographical information
systems. Control Cybernetics, 35 (1), 97.
89

fiDubba, Cohn, Hogg, Bhatt & Dylla

Veeraraghavan, H., Papanikolopoulos, N., & Schrater, P. (2007). Learning dynamic event
descriptions image sequences. IEEE Conference Computer Vision Pattern
Recognition (CVPR), pp. 16.
Vu, V.-T., Bremond, F., & Thonnat, M. (2003). Automatic video interpretation: novel
algorithm temporal scenario recognition. Proceedings International Joint
Conference Artifical Intelligence (IJCAI), Vol. 3, pp. 12951300.
Walther, C. (1985). mechanical solution Schuberts Steamroller many-sorted resolution. Artificial Intelligence, 26 (2), 217224.
Yilmaz, A., Javed, O., & Shah, M. (2006). Object tracking: survey. ACM Computing
Surveys (CSUR), 38 (4), 13.
YouTube (2015) http://www.youtube.com/yt/press/statistics.html. Accessed January 25, 2015.

90


