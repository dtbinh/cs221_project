journal artificial intelligence

submitted published

towards adjustable autonomy real world
scerri isi edu
pynadath isi edu
tambe usc edu

paul scerri
david v pynadath
milind tambe
information sciences institute computer science department
university southern california
admiralty way marina del rey ca usa

abstract

adjustable autonomy refers entities dynamically varying autonomy transferring decision making control entities typically agents transferring control
human users key situations determining whether transfers control
occur arguably fundamental adjustable autonomy previous work investigated approaches addressing often
focused individual agent human interactions unfortunately domains requiring collaboration teams agents humans reveal two key shortcomings previous
approaches first approaches use rigid one shot transfers control
unacceptable coordination failures multiagent settings second ignore costs e g
terms time delays effects actions agent team due transfers ofcontrol
remedy article presents novel adjustable autonomy notion transfer control strategy transfer control strategy
consists conditional sequence two types actions actions transfer decisionmaking control e g agent user vice versa ii actions change
agent pre specified coordination constraints team members aimed minimizing
miscoordination costs goal high quality individual decisions made
minimal disruption coordination team present mathematical model
transfer control strategies model guides informs operationalization
strategies markov decision processes select optimal strategy given
uncertain environment costs individuals teams
carefully evaluated including via use real world deployed multi agent system
assists group daily activities


introduction

exciting emerging application areas ranging intelligent homes lesser et al
routine organizational coordination pynadath et al electronic commerce collins
et al long term space missions dorais et al utilize decision making
skills agents humans applications brought forth increasing
interest agents adjustable autonomy aa e entities dynamically adjusting
level autonomy situation mulsiner pell many exciting
applications deployed unless reliable aa reasoning central component
aa entity need make decisions autonomously rather choose reduce
autonomy transfer decision making control users agents
c ai access foundation morgan kaufmann publishers rights reserved

fiscerri pynadath tambe
expected net benefit dorais et al barber goel martin
hexmoor kortenkamp
central aa determine whether transfers decision making
control occur key challenge balance two potentially con icting goals
one hand ensure highest quality decisions made agent transfer control human user another agent whenever user superior decision making
expertise hand interrupting user high costs user may
unable make communicate decision thus transfers control minimized previous work examined several different techniques attempt balance
two con icting goals thus address transfer control example
one technique suggests decision making control transferred expected
utility higher expected utility making autonomous decision
horvitz jacobs hovel second technique uses uncertainty sole rationale
deciding control forcing agent relinquish control user
whenever uncertainty high gunderson martin yet techniques transfer
control user erroneous autonomous decision could cause significant harm dorais
et al agent lacks capability make decision ferguson allen
miller
unfortunately previous approaches transfer control reasoning indeed
previous work aa focused domains involving single agent single
user isolated interactions entities applied interacting teams
agents humans interaction agent human impacts interaction entities techniques lead dramatic failures particular
presence entities team members introduces third goal maintaining coordination addition two goals already mentioned previous
techniques fail address failures occur two reasons firstly previous techniques
ignore team related factors costs team due incorrect decisions due
delays decisions transfers control secondly importantly
techniques use one shot transfers control rigidly committing one two choices
transfer control wait input choice h ii act autonomously choice however
given interacting teams agents humans choice lead costly failures
entity control fails make report decision way maintains coordination
instance human user might unable provide required input due temporary communication failure may cause agent fail part joint action
joint action may dependent user input hand forcing
less capable entity make decision simply avoid miscoordination lead poor
decisions significant consequences indeed seen section applied
rigid transfer control decision making domain involving teams agents users
failed dramatically
yet many emerging applications involve multiple agents multiple humans acting
cooperatively towards joint goals address shortcomings previous aa work
domains article introduces notion transfer control strategy transfer ofcontrol strategy consists pre defined conditional sequence two types actions
aa general involves transferring control one entity another
typically focus interactions involving autonomous agents human users



fitowards adjustable autonomy real world
actions transfer decision making control e g agent user vice versa
ii actions change agent pre specified coordination constraints team members
rearranging activities needed e g reordering tasks buy time make decision
agent executes strategy performing actions order transferring control
specified entity changing coordination required point time
entity currently control exercises control makes decision thus previous
choices h two many different possibly complex transfer ofcontrol strategies instance adah strategy implies agent initially attempts
make autonomous decision agent makes decision autonomously strategy
execution ends however chance unable make decision
timely manner perhaps computational resources busy higher
priority tasks avoid miscoordination agent executes action changes
coordination constraints activity example action could inform
agents coordinated action delayed thus incurring cost inconvenience
others buying time make decision still cannot make decision
eventually take action h transferring decision making control user waiting
response general strategies involve available entities contain many
actions change coordination constraints strategies may useful singleagent single human settings particularly critical general multiagent settings
discussed
transfer control strategies provide exible aa complex systems
many actors enabling multiple transfers control two entities
rather rigidly committing one entity e h strategy attempts provide
highest quality decision avoiding coordination failures particular multiagent
setting often uncertainty whether entity make decision
e g user may fail respond agent may able make decision
expected communication channel may fail strategy addresses uncertainty
multiple transfers control cover contingencies instance
adh strategy agent ultimately transfers control human attempt ensure
response provided case agent unable act furthermore explicit
coordination change actions e actions reduce miscoordination effects cost
better decisions made finally since utility transferring control changing
coordination dependent actions taken afterwards agent must plan strategy
advance sequence actions maximizes team benefits example
reacting current situation repeatedly taking giving control strategy
adhadh may costly ahead making bigger coordination
change shorter adh strategy developed decision theoretic model
strategies allows expected utility strategy calculated hence
strategies compared
thus key aa select right strategy e one provides
benefit high quality decisions without risking significant costs interrupting user
miscoordination team furthermore agent must select right strategy despite
significant uncertainty markov decision processes mdps puterman natural
choice implementing reasoning explicitly represent costs benefits
uncertainty well lookahead examine potential consequences sequences


fiscerri pynadath tambe
actions section general reward function presented mdp
agent carefully balancing risks incorrect autonomous decisions potential miscoordination
costs due changing coordination team members detailed experiments
performed mdp key follows relative importance
central factors cost miscoordination varied resulting mdp policies
varied desirable way e agent made decisions autonomously cost
transferring control entities increased experiments reveal phenomenon
reported literature agent may act autonomously coordination
change costs low high middle range agent tends act
less autonomously
conducted context real world multi agent system
called electric elves e elves chalupsky gil knoblock lerman oh pynadath russ
tambe pynadath et al used six months
university southern california information sciences institute e elves assists
group researchers project assistant daily activities providing exciting
opportunity test aa ideas real environment individual user proxy agents called
friday robinson crusoe servant friday act team assist rescheduling
meetings ordering meals finding presenters day day activities course
several months mdp aa reasoning used around clock e elves
making many thousands autonomy decisions despite unpredictability user
behavior agent limited sensing abilities mdp consistently made sensible
aa decisions moreover many times agent performed several transfers control
cope contingencies user responding one lesson learned actually
deploying system sometimes users wished uence aa reasoning e g
ensure control transferred particular circumstances allow users
uence aa reasoning safety constraints introduced allow users prevent
agents taking particular actions ensuring take particular actions
safety constraints provide guarantees behavior aa reasoning making
basic generally applicable particular making applicable
domains mistakes serious consequences
rest article organized follows section gives detailed description
aa presents electric elves motivating example application section
presents formal model transfer control strategies aa readers interested
mathematical details may wish skip section operationalization
strategies via mdps described section section detailed
experiments presented section looks related work including earlier aa work
analyzed within strategies framework section gives summary article
finally section outlines areas work could extended make applicable
applications


adjustable autonomy

general aa previously formally defined literature particularly multiagent context following formal definition given
clearly define task aa reasoning team may consist entirely


fitowards adjustable autonomy real world
agents include humans joint activity entity team works
cooperatively joint activity agent role team depending
specific task roles need performed successfully order
joint activity succeed primary goal agent success
pursues performing performing requires one non trivial decisions
made make decision agent draw upon n entities set
e fe en g typically includes agent entity e e g human
user capable making decision entities e necessarily part
team performing different agents users differing abilities make decisions
due available computational resources access relevant information etc coordination
constraints exist roles members team example
roles might need executed simultaneously certain order
combined quality total cost critical facet successful completion joint task
given jointness ensure coordination team members maintained
e violated thus describe aa instance tuple
ha e
aa perspective agent take two types actions decision
first transfer control entity e capable making decision general
restrictions often long decision making control
transferred particular entity typically agent transfer decision making
control general assume agent transfers control
guarantee exact time response exact quality decision made
entity control transferred fact cases know whether
entity able make decision even whether entity know
decision making control e g control transferred via email agent may know
user actually read email
second type action agent take request changes coordination constraints team members coordination change gives agent
possibility changing requirements surrounding decision made e g
required timing cost quality decision may allow better fulfill responsibilities coordination change might involve reordering delaying tasks may
involve changing roles may dramatic change team pursues
completely different way changing coordination cost may better
incur cost violate coordination constraints e incur miscoordination costs
miscoordination team members occur many reasons e g constraint
limits total cost joint task might violated one team member incurs higher
expected cost team members reduce costs article
primarily concerned constraints related timing roles e g ordering constraints requirements simultaneous execution turn usually requires
agent guards delayed decisions although require decision
made soon
thus aa agent given instance ha e
choose transfer control coordination change actions maximizes overall
expected utility team remainder section describe concrete real

fiscerri pynadath tambe
world domain aa section initial failed motivates solution
section

electric elves
initiated response issues arose real application
resulting extensively tested day day running application
electric elves e elves project usc isi deploy agent organization
support daily activities human organization pynadath et al chalupsky
et al believe application fairly typical future generation applications involving teams agents humans operation human organization
requires performance many everyday tasks ensure coherence organizational
activities e g monitoring status activities gathering information keeping everyone informed changes activities teams software agents aid organizations
accomplishing tasks facilitating coherent functioning rapid exible response
crises number underlying ai technologies support e elves e g technologies
devoted agent human interactions agent coordination accessing multiple heterogeneous
information sources dynamic assignment organizational tasks deriving information
organization members chalupsky et al technologies useful
aa fundamental effective integration e elves day day running
real organization hence focus
basic design e elves shown figure agent proxy called
friday robinson crusoes man servant friday acts behalf user
agent team design friday proxies discussed detail tambe pynadath
chauvat das kaminka referred teamcore proxies
currently friday perform several tasks user user delayed meeting
friday reschedule meeting informing fridays turn inform users
presentation slot open friday may respond invitation present
behalf user friday order user meals see figure track
user location posting web page friday communicates users wireless
devices personal digital assistants palm viis wap enabled mobile phones
via user workstations figure b shows palm vii connected global positioning
service gps device tracking users locations enabling wireless communication
friday user friday team behavior teamwork model
called steam tambe steam encodes enforces constraints roles
required success joint activity e g meeting attendees arrive
meeting simultaneously role within team needs filled steam requires
team member assigned responsibility role best suited person
team auctions role allowing consider combination factors assign
best suited user friday bid behalf user indicating whether user
capable willing fill particular role figure b shows tool allows users
view auctions progress intervene desire auction progress jay
modi friday bid jay capable giving presentation unwilling
paul scerri agent highest bid eventually allocated role



fitowards adjustable autonomy real world

friday

friday

friday

friday



b

figure overall e elves architecture showing friday agents interacting users
b palm vii communicating users gps device detecting
location



fiscerri pynadath tambe
aa critical success e elves since despite range sensing devices
friday considerable uncertainty user intentions even location hence
friday appropriate information make correct decisions
hand user required information friday cannot continually ask
user input since interruptions disruptive time consuming four
decisions e elves aa reasoning applied whether user attend
meeting time ii whether close auction role iii whether user willing
perform open team role iv order lunch
focus aa reasoning two decisions whether user attend meeting
time whether close auction role decision whether user
attend meeting time often used dicult decisions friday
faces brie describe decision close auction later insight
provided model strategies led significant reduction amount code
required implement aa reasoning decision decision volunteer user
meeting similar earlier decisions omitted brevity decision order
lunch currently implemented simpler fashion least yet illustrative
full set complexities
central decision friday describe terms formulation
ha e whether user attend meeting currently scheduled meeting time case friday agent joint activity meeting
attendees attend meeting simultaneously friday acts proxy user hence
role ensure user arrives currently scheduled meeting time
coordination constraint friday role roles fridays
occur simultaneously e users must attend currently scheduled time
attendee arrives late time attendees wasted
hand delaying meeting disruptive users schedules decision whether
user attend meeting could made friday user e
e fuser fridayg clearly user often better placed make decision
however friday transfers control user decision must guard miscoordination e attendees wait waiting user response
decisions potentially costly e g incorrectly telling attendees user
attend friday avoid taking autonomously buy time
user make decision gather information friday could change
coordination constraints action friday several different actions disposal including delaying meeting different lengths time well able
cancel meeting entirely user request action e g via dialog box
figure buy time make meeting user decides required
friday conduit fridays hence users informed
friday must select sequence actions transferring control user delaying
cancelling meeting autonomously announcing user attend
maximize utility team
second aa decision look decision close auction open
role assign user role case joint activity group
roles submitting bids auction aa decisions simpler hence
focus



fitowards adjustable autonomy real world



b

figure friday transferring control user decision whether order lunch
b e elves auction monitoring tool
meeting role auctioneer users submit bids
role immediately fact bids may spread several days users might
bid specific decision focus whether close auction
assign role continue waiting incoming bids individual team members
provide bids auctioneer agent human team leader decides presenter
input e fuser auctioneer agentg team expects willing presenter
high quality presentation means presenter need time
prepare thus coordination constraint capable willing user must
allocated role enough time prepare presentation despite individually
responsible actions agent team may reach highly undesirable decision e g assigning
user week week hence advantage getting human team leader
input agent faces uncertainty e g better bids come costs e later
assignment less time presenter prepare needs consider
possibility human team leader special preference
presentation particular meeting transferring control agent allows
human team leader make assignment decision coordination change action
would reschedule meeting however relative cost cancelling
meeting cost rescheduling high rescheduling useful action

decision tree
one logical avenue attack aa e elves apply
used previously reported successful meeting scheduling system particular cap
mitchell caruana freitag mcdermott zabowski cap friday learned
user preferences c decision tree learning quinlan friday recorded values
dozen carefully selected attributes user preferred action identified asking


fiscerri pynadath tambe
user whenever make decision friday used data learn decision
tree encoded autonomous decision making aa friday asked user
wanted decisions taken autonomously future responses friday
used c learn second decision tree encoded rules transferring control
thus second decision tree indicated friday act autonomously would
take action suggested first decision tree initial tests c
promising tambe et al key soon became apparent
friday encountered decision learned transfer control user
would wait indefinitely user make decision even though inaction caused
miscoordination teammates particular team members would arrive
meeting location waiting response user friday would end
completely wasting time response arrived address user
respond within fixed time limit five minutes friday took autonomous action
although performance improved resulting system deployed led
dramatic failures including
example tambe user friday incorrectly cancelled meeting division
director friday generalized training examples
example pynadath another user friday incorrectly cancelled group weekly
meeting time forced choice incorrect autonomous
action
example friday delayed meeting almost times time minutes
correctly applying learned rule ignoring nuisance rest
meeting participants
example tambe friday automatically volunteered presentation
actually unwilling friday generalized examples
timeout occurred took undesirable autonomous action
clearly team context rigidly transferring control one agent user failed furthermore time rigidly transferred control back agent
capable making high quality decision failed particular agent needed
better avoid taking risky decisions explicitly considering costs example
take lower cost actions delay meetings buy user time respond example
furthermore example showed agent needed plan ahead avoid taking
costly sequences actions could replaced single less costly action example
theory c friday might eventually able learn rules would
successfully balance costs deal uncertainty handle special cases
large amount training data would required


strategies adjustable autonomy

avoid rigid one shot transfers control allow team costs considered
introduce notion transfer control strategy defined follows


fitowards adjustable autonomy real world
definition transfer control strategy pre defined conditional sequence two

types actions actions transfer decision making control e g agent
user agents vice versa ii actions change agent pre specified
coordination constraints team members aimed minimizing miscoordination costs

agent executes transfer control strategy performing specified actions
sequence transferring control specified entity changing coordination required
point time entity currently control exercises control
makes decision considering multi step strategies allows agent exploit decisionmaking sources considered risky exploit without possibility retaking control
example control could transferred capable available decision
maker taken back decision made serious miscoordination occurred
complex strategies potentially involving several coordination changes give agent
option try several decision making sources exible getting input
high quality decision makers transfer control strategies specifically allow
agent avoid costly errors enumerated previous section
given aa instance ha e agent transfer decision making
control decision entity ei e denote transfer control
action symbol representing entity e transferring control ei denoted
ei agent transfers decision making control may stipulate limit time
wait response entity capture additional stipulation
denote transfer control actions time limit e g ei represents ei
decision making control maximum time action two possible outcomes
ei responds time makes decision respond decision
remains unmade time addition agent mechanism
change coordination constraints denoted change expected timing
decision action changes coordination constraints team members
action associated value dvalue specifies magnitude e much
alleviated temporal pressure cost dcost specifies price paid
making change concatenate actions specify complete transferof control strategy instance strategy h would specify agent first
relinquishes control asks entity h denoting h uman user user responds
decision within five minutes need go
agent proceeds next transfer control action sequence example
next action specifies agent make decision complete task
transfers control occur case define space possible
strategies following regular expression

e r e r



e r possible combinations entity maximum time
readability frequently omit time specifications transfer ofcontrol actions instead write order agent transfers control among
domains may make sense attempt get input one entity hence
requiring strategies actions might executed parallel however work first
step consider strategies furthermore relevant domains hand



fiscerri pynadath tambe
entities executes ds e g often write ha instead h time
specifications omitted assume transfers happen optimal times e
times lead highest expected utility consider strategies
sequence actions different timings strategy agent je jk
possible strategies select k maximum length strategy je j
number entities thus agent wide range options even practical
considerations lead reasonable upper bound k je j agent must select
strategy maximizes overall expected utility
rest section present mathematical model transfer control strategies aa use model guide search solution moreover model
provides tool predicting performance strategies justifying use
explaining observed phenomena use section presents model aa
strategies detail section reveals key properties complex strategies including dominance relationships among strategies section examines e elves application
light model make specific predictions properties successful
aa reasoning application class predictions shape
operationalization strategies section

mathematical model strategies
transfer control model presented section allows calculation expected
utility eu individual strategies thus allowing strategies compared calculation strategy eu considers four elements likely relative quality different
entities decisions probability getting response entity particular time
cost delaying decision costs benefits changing coordination constraints parameters might modeled similar manner experience
e elves aa work suggests parameters critical ones
across wide range joint activities
first element model expected quality entity decision general
capture quality entity decision time functions eq feqde
r rg quality decision ects probability entity make
appropriate decision costs incurred decision wrong expected quality
decision calculated decision theoretic way multiplying probability
outcome e decision utility decision e cost benefit
decision example higher probability entity make mistake
lower quality even lower mistakes might costly quality decision
entity make vary time information available changes
time think second element model probability entity
make decision control transferred functions p fp e r g
represent continuous probability distributions time
entity e respond
r ei
probability ei respond time p dt
third element model representation cost inappropriate timing
decision general making decision particular point time incurs
best time transfer control found e g differentiating expected utility equation
section solving



fitowards adjustable autonomy real world
cost function time coordination constraints
team members stated earlier focus cases constraint violations due delays
making decisions thus cost due violation constraints caused
making decision point time write wait cost function
w f returns cost making decision particular point time
given coordination constraints miscoordination cost fundamental aspect
model given emphasis multiagent domains called wait cost
miscoordination arises team waits entity make ultimate
decision domains e elves team incurs wait costs situations
example meeting attendees assembled meeting room time
meeting kept waiting without input decision friday potentially
cannot provide high quality decision get input user notice
different roles lead different wait cost functions since delays performance
different roles different effects team assume
point time costs accrue e f f
deadline maximum cost due inappropriate timing decision
incurred finally assume general wait cost function nondecreasing ecting idea bigger violations constraints lead higher wait costs
final element model coordination change action moves agent
away deadline hence reduces wait costs incurred
model effect letting w function dvalue rather
action fixed cost dcost incurred immediately upon execution
example e elves domain suppose time meeting friday delays
meeting minutes action following time period incur
relatively low cost making decision minutes meeting dvalue
rather relatively high cost making decision time meeting
possibly complex action could used
use four elements compute eu arbitrary strategy utility
derived decision made time entity control quality
entity decision minus costs incurred waiting e euedc eqdec
w coordination change action taken effect utility
coordination change value dvalue taken time incurred wait cost
w wait cost incurred w dvalue w dvalue
thus action taken time cost dcost value dvalue
utility decision time euedc eqdec w w dvalue
w dvalue dcost calculate eu entire strategy multiply response
probability mass function value instant eu receiving response
instant integrate products hence eu strategy given
instance ha e
z
h


e

eus

p euedc dt


strategy involves several actions need ensure probability response
function wait cost calculation ect control situation point
strategy example user h control time p ect h


fiscerri pynadath tambe

w

euad eqda
eued

euea







z


z



eueddea

p eqde
p eqde

w dt
w dt


p eqde


z



z



r



w dt

p dt eqda

w



p eqe w dt

p eqe w w dvalue w dvalue dcost dt
r

p eqa w w dvalue w dvalue dcost dt



rt

table general aa eu equations sample transfer control strategies
probability responding e p h end break integral
equation separate terms term representing one segment strategy
e g strategy ua would one term u control another
control
basic technique writing eu calculations write
specific equations arbitrary transfer control strategies equations table
eu equations strategies e ea e dea respectively equations
assume agent make decision instantaneously least delay
significant enough affect overall value decision equations created
writing integral segments strategy described
time agent takes control e time occurs
one write equations complex strategies way notice
equations make assumptions particular functions
given eu strategy calculated aa agent reduces
finding following transfer control strategy maximize eu formally
agent

axiom ha e agent must select
eusha e eush e



fitowards adjustable autonomy real world






w






p

figure graph comparing eu two strategies h da solid line h dashed line
given particular instantiation model constant expected decisionmaking quality exponentially rising wait costs markovian response probabilities p parameter p function higher p meaning longer
expected response time w parameter w function higher w
meaning rapidly accruing wait costs

dominance relationships among strategies
agent could potentially strategy highest eu examining
every strategy computing eu selecting strategy highest value
example consider domains constant expected decision making quality
exponentially rising wait costs markovian response probabilities figure shows
graph eu two strategies h da h given particular model instantiation
notice different response probabilities rates wait cost accrual one strategy
outperforms neither strategy dominant entire parameter space
eu strategy dependent timing transfers control turn
depend relative quality entities decision making appendix provides
detailed analysis
fortunately evaluate compare every candidate
exhaustive search optimal strategy instead use analytical methods
draw general conclusions relative values different candidate strategies
particular present three lemmas domain level conditions
particular strategy types superior others lemmas lead us perhaps
surprising conclusion complex strategies necessarily superior single shot
strategies even multi agent context fact particular strategy dominates
strategies across domains
let us first consider aa subproblem whether agent ever take back
control another entity certain conditions agent
eventually take back control strategy selection process ignore
strategies agent e strategies ending agent
goal strike right balance waiting indefinitely user response


fiscerri pynadath tambe
taking risky autonomous action informally agent reasons eventually
make decision expected cost continued waiting exceeds difference
user decision quality formally agent eventually take back
decision making control iff time
z
p w dt w eqdu eqda



left hand side calculates future expected wait costs right hand side
calculates extra utility gained getting response user
leads following general conclusion strategies end giving control back
agent
lemma isra strategy ending e e sa eusd eusd iff
e e p w dt w eqde eqda
lemma says point time expected cost indefinitely leaving
control hands user exceeds difference quality agent
user decisions strategies ultimately give agent control dominate
thus rate wait cost accrual increases difference
relative quality decision making abilities decreases user probability response
decreases strategies agent eventually takes back control dominate
key consequence lemma opposite direction rate costs accrue
accelerate probability response stays constant e markovian
agent indefinitely leave control user user originally
given control since expected wait cost change time hence even
agent faced situation potentially high total wait costs optimal strategy
may one shot strategy handing control waiting indefinitely
expected future wait costs point time relatively low thus lemma isolates
condition consider appending transfer control action
strategy
perform similar analysis identify conditions
include action strategy agent incentive changing coordination
constraints via action due additional time made available getting highquality response entity however overall value action depends
number factors e g cost taking action timing subsequent
transfers control calculate expected value comparing eu
strategy without useful increased expected value
strategy greater cost dcost
lemma sr included eusd eusd iff
r
p w dt
p w tjd dt dcost
illustrate consequences lemma considering specific model
appendix e p exp w exp eqde c candidate strategies
iff exp exp dvalue
ea e da case euedda euea
dcost figure plots value action vary rate wait cost accumulation
w parameter markovian response probability function p graph shows


fitowards adjustable autonomy real world

value







w



p


figure value action particular model p exp
eqde c



w exp

benefit highest probability response neither low
high probability response low user unlikely respond
even given extra time hence agent incurred dcost benefit
little value probability response high user likely
respond shortly meaning little effect effect
wait costs action taken overall according lemma points
graph goes dcost agent include action points
figure demonstrates value action specific subclass
domains extend conclusion general case well instance
specific model exponential wait costs wait costs grow
slowly fewer situations lemma criterion holds e
useful thus lemma allows us eliminate strategies consideration
evaluation criterion particular domain interest
given lemma evaluation adding single action strategy natural
ask whether second third etc action would increase eu even words
complex strategy better simple one even complex strategy even
better answer necessarily

k n w w p p eq eq optimal strategy
actions
informally lemma says cannot fix single optimal number actions
every possible number actions potential domain e combination
lemma

k

wait cost response probability expected quality functions number
actions justified optimal consider situation cost
function number ds date e cost k th f k example
e elves meeting case cost delaying meeting third time much
higher cost first delay since delay successively annoying
meeting participants hence test usefulness k th strategy


fiscerri pynadath tambe
given specific model appendix



exp exp

f k exp dvalue exp


depending nature f k equation hold number ds
k conditions strategy k ds optimal instance
section maximum length optimal strategy random
configuration entities usually less eight actions
equation illustrates value additional limited changing dcost
lemma shows us factors affect value additional
example even constant dcost value additional depends many
actions agent performs figure shows value depends
rate wait costs accrue rate wait cost accrual accelerates time e g
exponential model action slows acceleration rendering second action
less useful since wait costs accruing slowly notice ds become
valueless deadline wait costs stop accruing
taken together lemmas particular transfer control strategy dominates others across domains moreover different strategies single shot
strategies arbitrarily complex strategies appropriate different situations although
range situations particular transfer control action provides benefit
quite narrow since strategy might low eu set parameters choosing
wrong strategy lead poor hand understand
parameter configuration intended application domain lemmas provide useful
tools focusing search optimal transfer control strategy lemmas
used line substantially reduce space strategies need searched
optimal strategy however general may many strategies finding
optimal strategy may possible feasible

model predictions e elves
section use model predict properties successful aa
e elves approximate functions probability response wait cost
expected decision quality calculate eu strategies determine
types strategies going useful armed knowledge predict
key properties successful implementation
key feature e elves user mobile moves around environment probability responding requests decisions changes drastically e g
likely respond workstation calculate eu different strategies
need know p means need estimate response probabilities
model change user moves around friday communicates via
workstation dialog box user respond average five minutes however
friday communicates via palm pilot average user response time hour users
generally take longer decide whether want present meeting taking
approximately two days average function p average value
minutes user oce average one hour user contacted
via palm pilot average two days decision whether present


fitowards adjustable autonomy real world
meeting necessary estimate relative quality user eqdu
friday decision making eqda assume user decision making eqdu
high respect friday eqda uncertainty user intentions makes
hard friday consistently make correct decisions time user
arrive meetings although sensors e g gps device give indication
user location dealing important meetings cost friday errors
higher thus cases decision making quality user friday
similar e equd eqad cases order magnitude
difference e equd eqad wait cost function w much larger
big meetings small increase rapidly attendees wait longer meeting
room finally cost delays e dcost vary order magnitude
particular cost rescheduling meetings varies greatly e g cost rescheduling
small informal meetings colleagues far less rescheduling full lecture room
pm friday
parameters laid parameters vary decision decision
specific decision use markovian response probabilities e g user
oce average response time five minutes exponentially increasing wait costs
constant decision making quality though changes decision decision calculate
eu interesting strategies calculating eu different strategies values
different parameters shown allows us draw following conclusions table
section presents quantitative illustration predictions

strategy e used since combinations user location
meeting importance eu strategy low

multiple strategies required since different user locations meeting importance different strategies optimal

since quite different strategies required user different locations
aa reasoning need change strategies user changes location

strategy reasonable eu possible parameter instantiations hence
strategy occasionally cause dramatic failures

decisions strategies end agent taking decision since strategies
ending user control generally low eu

predictions provide important guidance successful solution aa
e elves particular make clear must exibly choose
different strategies adjust depending meeting type user location
section described unsuccessful c aa e elves identified
several reasons mistakes occurred particular rigidly transferring control
one entity ignoring potential team costs involved agent decision highlighted
reasons dramatic mistakes friday autonomy reasoning reviewing c
light notion strategies see friday learned one strategy
stuck strategy particular originally friday would wait indefinitely user
response e would follow strategy e learned transfer control shown later


fiscerri pynadath tambe
table strategy low eu fixed length timeout introduced
friday would follow strategy e strategy high eu equd eqad
low eu equd eqad thus model explains phenomenon
observed practice
hand use model understand c failure case
mean never useful aa different strategies required
certain parameters probability response wait cost change significantly
applications parameters change dramatically decision decision
one particular strategy may appropriate applications c might learn
right strategy small amount training data perform acceptably well


operationalizing strategies mdps

formalized aa selection transfer control strategy highest eu need operational mechanism allows agent
perform selection one major conclusion previous section different
strategies dominate different situations applications e elves require mechanism selecting strategies situation sensitive fashion particular
mechanism must exibly change strategies situation changes required mechanism must represent utility function specified expected decision qualities
eq costs violating coordination constraints w coordination change cost
dcost finally mechanism must represent uncertainty entity responses
look ahead possible responses lack thereof may occur future
mdps natural means performing decision theoretic required
best transfer control strategy mdp policies provide mapping agent
state optimal transfer control strategy encoding parameters model
aa strategies mdp mdp effectively becomes detailed implementation
model hence assumes properties use standard puterman
optimal mdp policy hence optimal strategies follow
state
simplify exposition well illustrate generality resulting mdp
section describes mapping aa strategies mdp four subsections
particular section provides direct mapping strategies abstract mdp section
fills state features enable concrete realization reward function
still maintaining domain independent view thus section completely defines general
mdp aa potentially reusable across broad class domains section illustrates
implemented instantiation mdp e elves section addresses practical
issues operationalizing mdps domains e elves

abstract mdp representation aa
mdp representation fundamental state features capture state control

controlling entity entity currently decision making control
ei response response ei made agent requests input


fitowards adjustable autonomy real world
original state action
destination state
ectrl time
ectrl ei response
time
ej
tk
ei
ei
yes
tk
ej
tk
ei
ei

tk
ei
tk
wait
ei
yes
tk
ei
tk
wait
ei

tk
ei
tk

ei

tk dvalue

probability



r tk ei
tkr p dt
tk ei
tk p dt
r tk
ei
tkr p dt
tk ei
tk p dt



table transition probability function aa mdp ectrl controlling entity



time current time typically discretized ranging deadline
e set ft tn g

ei response null time agent terminal state former
case decision value ei response
specify set actions mdp representation e fd waitg
set actions subsumes set entities e since agent transfer decision making
control one entities action coordination change action
changes coordination constraints discussed earlier wait action puts transferring control making autonomous decision without changing coordination
team agent reason wait best action time situation
likely change put agent position improved autonomous decision
transfer control without significant harm example e elves domain times
closer meeting users generally make accurate determinations whether
arrive time hence sometimes useful wait meeting long
time
transition probabilities specified table represent effects actions
distribution effects e ensuing state world state
time tk agent chooses action transfers decision making control entity
ei agent outcome state controlling entity ei
time tk two possible outcomes ei response entity responds
decision transition producing terminal state
derive probability distribution two p wait action similar
branch except controlling entity remains unchanged finally action occurs
instantaneously time controlling entity respond resulting
state effectively moves earlier time e g tk tk dvalue
derive reward function mdp straightforward fashion
strategy model table presents complete specification reward function
transitions take time e transferring control receiving response
table row wait table row agent incurs wait cost interval
transitions agent performs agent incurs cost action table
row terminal states response ei agent derives expected quality
entity decision table row policy maximizes reward agent
expects receive according aa mdp model correspond exactly optimal


fiscerri pynadath tambe
controlling entity time ei response action
ej
tk

ei
ei
tk

wait
ei
tk


ei
tk
yes

reward

w k w k
w k w k
dcost
eqdei tk

table reward function aa mdp
transfer control strategy note reward function described abstract
fashion example specify compute agent expected quality
decision eqad

mdp representation aa within team context
given high level description mdp implementing notion
transfer control strategies aa remainder section provides detailed
look mdp broad class aa domains including e elves agent
acts behalf user filling role within context team activity
reward function compares eu different strategies finding optimal one
current state facilitate calculation need represent parameters used
model introduce following state features capture aspects aa
team context

team orig expect team originally expected fulfilling
team expect team current expectations fulfilling role implies
agent expect agent probabilistic estimation fulfilled
attributes encapsulate aspects joint activity affected
decision

add specific features generic aa state features already
presented overall state within mdp representation decision tuple

hcontrolling entity team orig expect team expect agent expect status
ei response time attributesi
example meeting scenario team orig expect could meet pm teamexpect could meet pm user requested delay agent expect could
meet pm agent believes user make rescheduled meeting
transition probability function aa mdp team context includes
underlying aa transition probabilities table must include probabilities
state features particular addition temporal effect
action described section additional effect coordination
action changes value team expect feature domain dependent


fitowards adjustable autonomy real world
deterministic way actions affect team expectations team orig expect
feature change include simplify definition reward function
transition probabilities agent expect specific features domain specific
provide example transition probabilities section
final part mdp representation reward function team aa mdp
framework uses reward function breaks function table follows

r f team orig expect team expect agent expect
status time
x

eqde time e response



e e nfag

f k team orig expect team expect k
f time
f k team expect agent expect k
f status f



first component reward function captures value getting response
decision making entity agent notice one entity actually
respond one e response non zero corresponds eqed function
used model bottom row table f function ects inherent
value performing role team originally expected hence deterring agent
taking costly coordination changes unless gain indirect value
corresponds dcost mathematical model third row table
f corresponds second row table represents wait cost function
w model component encourages agent keep team members
informed role status e g making decision taking explicit action
rather causing wait without information functions f f represent
quality agent decision represented qad standard mdp
compute expectation agent reward expectation quality
produce desired eqad fourth row table first quality function f
ects value keeping team understanding role performed
accordance agent expects user actually perform role agent
receives reward role performed exactly team expects
uncertainty agent expectation errors possible f represents costs
come errors second quality component f uences overall reward
successful completion joint activity encourages agent take actions
maximize likelihood joint activity succeeds desire joint
task succeed implicit mathematical model must explicitly represented
mdp component f augments first row table account additional
costs transfer control actions particular f broken follows


f

q e e

otherwise




fiscerri pynadath tambe
function q e represents cost transferring control particular entity e g
cost wap phone message user notice detailed domain specific costs
appear directly model
given mdp state space actions transition probabilities reward function
agent use value iteration generate policy p specifies optimal
action state puterman agent executes policy taking
action policy dictates every state finds policy
may include several transfers control coordination change actions particular
series actions depends activities user interpret policy
contingent combination many transfer control strategies strategy follow
chosen depending user status e agent expect

example e elves mdps
example aa mdp generic delay mdp instantiated
meeting friday may act behalf user recall decision whether
let meeting attendees wait user begin meeting joint activity
meeting agent role ensuring user attends
meeting scheduled time coordination constraints attendees
arrive meeting location simultaneously effect action delay
cancel meeting
delay mdp state representation team orig expect originally scheduledmeeting time since attendance originally scheduled meeting time team
originally expects user best possible outcome team expect timerelative meeting may increase meeting delayed status becomes statusof meeting agent expect represented explicitly instead user location used
observable heuristic user likely attend meeting example
user away department shortly meeting begin unlikely
attending time state features total state space contains
states individual meeting large number states arising
fine grained discretization time
general reward function mapped delay mdp reward function following way


g n n


otherwise
n number times meeting rescheduled g function takes
account factors number meeting attendees size meeting delay
time originally scheduled meeting time function effectively forbids
agent ever performing actions
delay mdp functions f f correspond cost making
meeting attendees wait merge single function f expect
consolidation possible similar domains team expectations relate
f



fitowards adjustable autonomy real world
temporal aspect role performance


f

h late late

otherwise



late difference scheduled meeting time time user
arrives meeting room late probabilistically calculated mdp
user current location model user behavior




rff ruser user attends
f rff
meeting takes place user attend

otherwise



value rff inherent value value ruser user
individual value
f given previously equation cost communicating user
depends medium used communicate example higher cost
communicating via wap phone via workstation dialog box
users asked input assumed respond response
correct e user says delay meeting minutes assume
user arrive time scheduled meeting user asked front
workstation dialog one shown figure popped allowing user
select action taken expected quality agent decision calculated
considering agent proposed decision possible outcomes decision
example agent proposes delaying meeting minutes calculation
decision quality includes probability benefits user actually arrive
minutes originally scheduled meeting time probability costs
user arrives originally scheduled meeting time etc



b

figure dialog box delaying meetings b small portion delay mdp
delay mdp represents probabilities change user location e g
oce meeting location occur given time interval figure b shows portion


fiscerri pynadath tambe
state space showing user response user location features transition
labeled delay n corresponds action delay n minutes figure shows
multiple transitions due ask e transfer control user wait actions
relative probability outcome represented thickness arrow
state transitions correspond uncertainty associated user response e g
agent performs ask action user may respond specific information may
respond leaving agent effectively wait one possible policy produced
delay mdp subclass meetings specifies ask state figure b
e agent gives autonomy world reaches state policy specifies
wait however agent reaches state policy chooses delay
agent executes autonomously terms strategies sequence actions
h
earlier described another aa decision e elves namely whether close
auction open team role brie describe key aspects mapping
decision mdp auction must closed time user prepare
meeting sucient time given interested users submit bids
human team leader choose particular user team orig expect highquality presenter selected enough time prepare action hence
team expect team orig expect agent expect whether agent believes
high quality bid believes bid arrive time user allocated
role agent decision quality eqda function number bids
submitted quality bids e g team members submitted
bids one user bid stands agent confidently choose user
presentation thus status primarily quality best bid far difference
quality bid second best bid critical component
reward function equation component gives reward agent
fulfills users expectation willing presenter high quality presentation

user specified constraints
standard mdp provide agent optimal policies subject encoded probabilities reward function thus agent designer access correct
entities e g human users e elves decision qualities probabilities response agent select best possible transfer control strategy
however possible entities accurate information
abilities agent designer exploit knowledge entity could
communicate model quality decision probability response directly
agent designer unfortunately typical entity unlikely able express
knowledge form mdp reward function transition probabilities agent
could potentially learn additional knowledge interactions
entities domain however learning may require arbitrarily large number
interactions take place without benefit entities inside
knowledge
alternative provide language constraints allows entities
directly immediately communicate inside information agent constraint


fitowards adjustable autonomy real world

figure screenshot tool entering constraints constraint displayed forbids
transferring control e forces transfer five minutes meeting
teammates previously given information user attendance
meeting
language provides entities simple way inform agent specific properties
needs entity use constraint forbid agent entering specific states
performing specific actions specific states constraints directly communicated
user via tool shown figure instance figure shown user
forbidding agent autonomous action five minutes meeting define
forbidden action constraints set cfa element constraint
boolean function cfa ft f g similarly define forbidden state constraints
set cfs elements cfs ft f g constraint returns particular domain
element state state action pair appropriate constraint applies
given element example forbidden action constraint cfa forbids action
performed state cfa
provide probabilistic semantics suitable mdp context first provide
notation denote probability agent ever arrive state sf following
jp define semantics
policy p initial state si pr si
f
jp semantics given
forbidden state constraint cfs requiring pr si
f
p ajp
forbidden action constraint cfa bit complex requiring pr si
f
f
e cfa forbids agent entering state sf performing action
cases aggregation constraints may forbid actions state sf case
conjunction allows agent still satisfy forbidden action constraints avoiding sf
e state sf becomes forbidden state sf becomes indirectly forbidden
fashion action potentially leads agent ancestor state
sf likewise becomes forbidden hence effect forbidding constraints propagate
backward state space affecting state action pairs beyond cause
immediate violations


fiscerri pynadath tambe
forbidding constraints powerful enough entity communicate wide
range knowledge decision quality probability response agent
instance e elves users forbidden agents rescheduling meetings
lunch time users provide feature specification states want
forbid meeting time pm specification generates forbidden state
constraint cfs true state meeting time pm constraint
effectively forbids agent performing action would state
meeting time pm similarly users forbidden autonomous actions certain
states providing specification actions want forbid e g action ask
generates forbidden action constraint cfa true state action pair
ask example user might specify constraint states
oce time meeting know
make decisions case users easily create complicated constraints
specifying values multiple features well comparison functions
e g
analogous forbidding constraints introduce required state requiredaction constraints defined sets crs cra respectively interpretation provided
required state constraint symmetric opposite forbidden state
jp thus state agent must eventually reach
constraint pr si
f
p ajp
required state sf similarly required action constraint pr si
f
f
users specify constraints forbidding counterparts e specifying values relevant state features action appropriate addition
requiring constraints propagate backward informally forbidden constraints focus
locally specific states actions required constraints express global properties
states
resulting language allows agent exploit synergistic interactions
initial model transfer control strategies entity specified constraints example
forbidden action constraint prevents agent taking autonomous action
particular state equivalent user specifying agent must transfer control
user state aa terms user instructs agent consider transferof control strategies violate constraint exploit pruning strategy
space user extended standard value iteration consider constraint
satisfaction generating optimal strategies appendix ii provides description
novel finds optimal policies respecting user constraints appendix
includes proof correctness
experimental

section presents experimental aimed validating claims made previous sections particular experiments aim utility complex transfer ofcontrol strategies effectiveness mdps technique operationalization
section details use e elves daily activities section discusses
pros cons living working assistance fridays section shows
characteristics strategies type domain particular different strategies


fitowards adjustable autonomy real world
used practice finally section describes detailed experiments illustrate
characteristics aa mdp

e elves daily use
e elves system heavily used ten users group isi june
december friday agents ran continuously around clock seven
days week exact number agents running varied period execution
usually five ten friday agents individual users capability matcher proxy
interest matcher proxy occasionally temporary friday agents operated
behalf special guests short term visitors
daily counts exchanged messages
messages








jun jul aug sep oct nov dec
date

figure number daily coordination messages exchanged proxies seven month
period
figure plots number daily messages exchanged fridays seven months
june december size daily counts ects large amount
coordination necessary manage activities high variability illustrates
dynamic nature domain note low periods vacations final exams
figure illustrates number meetings monitored user seven
months nearly meetings monitored users fewer meetings
others users meetings delayed includes
regularly scheduled meetings cancelled instance due travel figure b
shows usually delayed meetings autonomously delayed
graph repeated delays single meeting counted graphs
user base system greatly reduced period due personnel relocations
student graduations remains use smaller number users



fiuser delays vs autonomous delays

meetings monitored vs meetings delayed












number meetings

ito

ramanan

tambe

nair

scerri

modi

pynadath

jungh

total delays
human delays



monitored
delayed

kulkarni

number meetings

scerri pynadath tambe









users















users



b

figure monitored vs delayed meetings per user b meetings delayed autonomously
vs hand
agents acting autonomously large number instances equally importantly
humans often intervening indicating critical importance adjustable autonomy
friday agents
seven month period presenter usc isi teamcore group
presentations decided auctions table shows summary auction
column date shows dates presentations column
bids shows total number bids received decision key feature
auction decisions made without users entering bids fact one case
bids received column best bid shows winning bid winner typically
bid e indicating user represents capable willing
presentation high quality bid interestingly winner july made
bid e capable willing team able settle winner
despite bid highest possible illustrating exibility finally columns
winner method auction outcome h column indicates
auction decided human indicates decided autonomously five
seven auctions user automatically selected presenter two manual
assignments due exceptional circumstances group e g first time visitor
illustrating need aa
date
bids best bid winner method
jul


scerri
h
jul


scerri

jul


kulkarni

aug


nair

aug


tambe

sept

visitor
h
oct


tambe

table auctioning presentation slot


fitowards adjustable autonomy real world
evaluating pros cons e elves use
general effectiveness e elves shown several observations
e elves operation group members exchanged email messages announce
meeting delays instead fridays autonomously informed users delays thus reducing
overhead waiting delayed members second overhead sending emails recruit
announce presenter meetings assumed agent run auctions third
web page friday agents post users location commonly used avoid
overhead trying track users manually fourth mobile devices kept users
informed remotely changes schedules enabling remotely delay
meetings volunteer presentations order meals etc users began relying friday
heavily order lunch one local subway restaurant owner even suggested
computers getting order food might think marketing
notice daily use e elves number different users occurred
mdp implementation aa replaced unreliable c implementation
however agents ensured users spent less time daily coordination
miscoordination price paid one issue users felt
less privacy location continually posted web monitored
agent another issue security private information credit card numbers
used ordering lunch users adjusted agents monitor daily activities
users adjusted behavior around agent one example
behavior users preferring minute two early meeting lest
agent decide late delay meeting general since agents never made
catastrophically bad decisions users felt comfortable agent frequently
took advantage services
emphatic evidence success mdp since replacing
c implementation agents never repeated catastrophic mistakes
enumerated section particular friday avoids errors error section
selecting strategy single large action higher eu
strategy many small ds e g dddd friday avoids error large cost
associated erroneous cancel action significantly penalizes eu cancellation
friday instead chooses higher eu strategy first transfers control user
taking action autonomously friday avoids errors errors selecting
strategies situation sensitive manner instance agent decision making
quality low e high risk agent perform coordination change action
allow time user response agent get information
words exibly uses strategies e dea rather e strategy
discussed section indicates reasonably appropriate strategy chosen
situation although current agents occasionally make mistakes errors
typically order transferring control user minutes earlier may
necessary thus agents decisions reasonable though optimal
inherent subjectivity user feedback makes determination optimality dicult



fiscerri pynadath tambe
strategy evaluation
previous section looked application mdp e elves
address strategies particular section specifically examine strategies
e elves fridays indeed follow strategies strategies followed
ones predicted model model led insight
turn led dramatic simplification one part implementation finally
use strategies limited e elves application showing empirically
random configurations entities optimal strategy one
transfer control action cases
figure shows frequency distribution number actions taken per meeting
graph omits wait actions number actions taken meeting corresponds
length part strategy followed strategy may longer
decision made actions taken graph shows mdp
followed complex strategies real world followed different strategies
different times graph bears model predictions different strategies would
required good solution aa e elves domain
table shows eu values computed model strategy selected
mdp recall mdp explicitly users movements locations
model assumes users move hence order accurate
comparison model mdp focus cases
user location change e probability response constant
eu values calculated parameter values set section notice
mdp often perform ds transferring control buy time reduce
uncertainty model abstraction domain actions changes
user location captured except slight discrepancy first case
match mdp behavior model predictions exact provided
ignore actions beginning mdp strategies thus despite model
considerably abstracted domain high correlation mdp
policies model suggested strategies moreover general properties policies
predicted model borne exactly particular recall model
predicted different strategies would required strategy e would used
generally strategies ending would best properties mdp policies
model predicts parameters vary greatly sucient
single optimal strategy follow strategy situation mdp
decision close auction instance e elves pattern
behavior followed every time open role needs filled team consistency
arises wait cost since meetings
pattern incoming bids reasonably consistent variations individuals behavior
cancel look team whole model predicts
parameters change optimal strategy parameters
execute strategy every time however since mdp worked effectively
meeting aa mdp chosen implementing auction aa
realized parameters vary greatly concluded mdp could replaced
simple implementation optimal strategy verify hypothesis replaced


fitowards adjustable autonomy real world

meetings

actions per meeting


















actions





figure frequency distribution number steps taken aa strategy
meeting scenario actions taken meeting meeting
cancelled friday started aa reasoning

location

e
ea e da mdp
small meeting active participant
oce
dde da
dept e ddea
meet loc e
ea
large meeting passive participant
oce
e ddea
dept e
ddea
meet loc e
ea
table eu values simple strategies calculated model last column
shows strategy actually followed mdp



fiscerri pynadath tambe
date bids mdp ea









table auction mdp column shows percentage available auction
time remaining mdp chose close auction ea column
shows percentage available auction time remaining strategy ea
eqde proportional number bids received bids column
would closed auction

general mdp code three simple lines code implementing ea strategy
determined optimal particular parameters log files
recorded actual auctions reported scerri pynadath tambe
experimentally verified mdp ea strategy produced
table shows percentage available auction time remaining e g auction
opened four days role performed closing auction one day
would correspond mdp version ea version code closed
auction number bids used estimate agent expected decision quality
timing auction closing close certainly within hours
precisely mdp strategy implementations mdp
implementation reactive incoming bids strategy implementation
confirm need strategies phenomenon unique particular
settings e elves experiment run randomly generated configurations
entities wait cost configuration increased exponentially rate
accrual varying configuration configuration configurations contained
entities randomly chosen markovian response probabilities randomly
chosen constant decision making quality cost value action
randomly selected configuration agent could respond instantly
lower decision quality entities configuration
optimal transfer control strategy found figure shows percentage optimal
strategies z axis length axis jopt strat j separated according
rate wait costs accrued x axis wait cost param figure shows
rate wait cost accrues low optimal strategies length
one agent handing control entity highest decision making
quality rate wait cost accrual high strategies length two
agent brie giving best decision maker opportunity make decision
taking back control acting wait costs became high intermediate
values wait cost parameter considerably variation length
optimal strategy figure b shows percentage optimal strategies length
wait cost parameter e slice figure hence strategies
often contained several transfers control several coordination changes thus
experiment shows complex transfer control strategies useful e elves


fitowards adjustable autonomy real world
range domains especially wait costs neither negligible
accruing fast
strategy lengths w


opt strats



opt strats





















opt strat















wait
cost
param














opt strat







b

figure percentage optimal strategies certain length broken according fast wait costs accruing b percentage optimal strategies
certain length wait cost parameter
thus shown mdp produces strategies friday follows
strategies practice moreover strategies followed ones predicted model
practical use followed prediction model e mdp
required auctions able substantially reduce complexity one part
system finally showed need strategies specifically phenomenon
e elves domain

mdp experiments
experience mdp aa e elves indicates effective
making reasonable aa decisions however order determine whether mdps
generally useful tool aa reasoning systematic experiments required
section present systematic experiments determine important properties
mdps aa mdp reward function designed optimal strategy
followed state
experiments vary one parameters weights
different factors equation mdp instantiated range values
parameter policy produced value case total policy
defined states policy analyzed determine basic properties
policy particular counted number states policy specifies ask
delay say user attending say user attending statistics
broadly policy changes parameters change e g whether friday gives
autonomy less cost coordination change increased first
aim experiments simply confirm policies change desired expected
way parameters reward function changed instance friday expected
decision quality increased states makes autonomous


fiscerri pynadath tambe
decision secondly practical perspective critical understand sensitive
mdp policies small variations parameters sensitivity would mean
small variations parameter values significantly impact mdp performance
finally experiments reveal interesting phenomena
first experiment looks effect parameter equation represented delay mdp implementation team repair cost function g equation
policies produced delay mdp parameter determines averse friday changing coordination constraints figure shows properties
policy change team repair cost value varied x axis gives value
team repair cost axis gives number times action appears
policy figure shows number times friday ask user input
number times transfer control exhibits interesting phenomenon number
asks maximum intermediate value parameter low values
friday confidently e decision quality high make decisions autonomously
since cost errors low hence less value relinquishing autonomy
high team repair costs friday confidently decide autonomously make
coordination change intermediate region friday uncertain needs
call user decision making often furthermore cost delaying
meeting increases friday delay meeting less figure b tell team
user attending often figure friday gives user less time
arrive meeting choosing instead announce user attending
essentially friday decision quality become close enough user decision quality
asking user worth risk respond cost asking
input except jump value zero non zero value
number times friday says user attending change figure c
delay mdp use e elves team repair cost parameter set two around
value policy changes little hence slight changes parameter lead
large changes policy
second experiment vary parameter equation implemented
delay mdp variable team wait cost function h equation
factor determines heavily friday weigh differences
team expects user fulfill role user actually fulfill role
particular determines cost team members wait meeting room
user figure shows changes policy parameter varied
x axis shows value parameter axis shows number times
action appears policy graph number times agent asks
policy figure exhibits phenomena parameter varied
e increasing decreasing parameter increases graphs
cost teammates time increases friday acts autonomously often figure bd friday asks whenever potential costs asking lower potential costs
errors makes cost time waiting user decision increases balance
tips towards acting notice phenomenon number asks increasing
decreasing occurs way parameter however occurs
slightly different reason case waiting costs low friday decision making
quality high acts autonomously waiting costs high friday cannot


fitowards adjustable autonomy real world

number delays policy













delays

asks

number asks policy







team repair cost weight




















number attending messages policy
attending

attending
















team repair cost weight



b

number attending messages policy







team repair cost weight













c





team repair cost weight



figure properties mdp policy team repair cost varied





fiscerri pynadath tambe
afford risk user respond quickly acts autonomously despite
decision quality low figure b shows number delay actions taken
friday increases states meeting already delayed twice
indicates normally expensive third delay meeting starts
become worthwhile cost teammates wait meeting room high
delay mdp value used decision transfer control e ask
particularly sensitive changes parameter around value slight
changes significant impact
number asks policy

number delays policy


delays

asks



























cost teammates time weight









b

number attending messages policy

attending

number attending messages policy














cost teammates time weight



attending

total
st delay
nd delay
rd delay










cost teammates time weight









c






cost teammates time weight



figure properties mdp policy teammate time cost varied b shows
number times meeting delayed states yet
delayed delayed already delayed
twice already
third experiment value weight joint task varied
figure e elves value joint task includes value user
meeting value meeting without user experiment value


fitowards adjustable autonomy real world
meeting without user varied figure shows policy changes value
meeting without user changes x axis shows value parameter
axis shows number times action appears policy graphs
significantly instability values large changes
simultaneous change utility taking key actions expected
quality friday decision making e g utility saying user attending much
higher meeting low value without user current delay mdp
value set part graph insensitive small changes
parameter
three experiments specific e elves parameters regions
graph small changes parameter lead significant changes policy
however regions graphs policy change dramatically small
changes parameter indicates domains parameters different
e elves policies sensitive small changes parameters













number delays policy


delays

asks

number asks policy











joint activity weight










number attending messages policy

attending

attending











joint activity weight



b

number attending messages policy









joint activity weight









c






joint activity weight







figure properties mdp policy importance successful joint task
varied


fiscerri pynadath tambe
experiments three important properties mdp aa
first changing parameters reward function generally lead changes
policy expected desired second value parameters uenced
policy effect aa reasoning often reasonably small suggesting small
errors model affect users greatly finally interesting phenomena
number asks reaching peak intermediate values parameters revealed
three previous experiments examined behavior mdp changes
parameters reward function changed another experiment central
domain level parameter affecting behavior mdp e probability getting
user response cost getting response corresponding f varied figure
shows number times friday chooses ask axis varies
expected time get user response x axis cost line
graph represents different cost mdp performs expected choosing ask
often cost low likely get prompt response notice
cost low enough friday sometimes choose ask user even
long expected response time conversely expected response time suciently
high friday assume complete autonomy graph shows distinct
change number asks point depending cost outside change
point graphs relatively key reason fairly rapid change number
asks often difference quality friday user decision
making fairly small range mean response time increases expected wait
costs increase eventually becoming high enough friday decide act autonomously
instead asking

asks

number asks policy










cost
cost
cost




mean response time



figure number ask actions policy mean response time minutes varied
x axis uses logarithmic scale
conclude section quantitative illustration impact constraints
strategy selection experiment merged user specified constraints
e elves users resulting set distinct constraints started unconstrained


fitowards adjustable autonomy real world

figure number possible strategies logarithmic b time required strategy
generation
instance delay mdp added constraints one time counting strategies
satisfied applied constraints repeated experiments expanded
instances delay mdp increased initial state space increasing
frequency decisions e adding values time relative meeting feature
expansion three delay mdps artificial uenced
real delay mdp figure displays logarithmic scale line
corresponds original delay mdp states lines b states c
states states correspond expanded instances data point
mean five different orderings constraint addition four mdps constraints
substantially reduce space possible agent behaviors instance original
delay mdp applying constraints eliminated original states
consideration reduced mean number viable actions per acceptable state
end reduction size log strategy space
hand constraints alone provide complete strategy since
plots stay well even constraints since none individual users
able willing provide constraints cannot expect anyone add enough constraints
completely specify entire strategy thus mdp representation associated
policy selection still far redundant
constraints elimination behaviors decreases time required strategy
selection figure b plots total time constraint propagation value iteration
four mdps figure averaged five constraint orderings
data point mean five separate iterations total iterations
per data point values zero constraint case correspond standard value iteration without constraints savings value iteration restricted strategy space
dramatically outweigh cost pre propagating additional constraints addition
savings increase size mdp original delay mdp
reduction policy generation time largest mdp
reduction thus introduction constraints provide dramatic acceleration
agent strategy selection



fiscerri pynadath tambe


related work

discussed related work section section adds discussion
section examine two representative aa systems detailed experimental
presented explain via model illustrates
potential applicability model systems section examine aa
systems areas related work meta reasoning conditional
anytime

analyzing aa work strategy model
goodrich olsen crandall palmer report tele operated teams robots
user high level reasoning robots low level skills required
achieve task within domain examined effect user neglect
robot performance idea user neglect similar idea entities taking time
make decisions case user neglects robot joint task takes longer
perform domain coordination constraint user input must arrive
robot work low level actions needs perform four control systems
tested robot giving different amount autonomy robot
performance measured user neglect varied
although quite distinct e elves system mapping goodrich team robots
aa formulation provides interesting insights system
interesting feature entity robot call decision e user
part team changing autonomy robot effectively changes nature
coordination constraints user robot figure shows performance
axis four control policies amount user neglect increased x axis
experiments showed higher robot autonomy allowed operator neglect
robot without serious impact performance
notion transfer control strategies used qualitatively predict
behavior observed practice even though goodrich et al use
notion strategies lowest autonomy control policy used goodrich et al
pure tele operation one since robot cannot resort decision making
represent control policy strategy u e control indefinitely hands
user second control policy allows user specify waypoints board
intelligence works details getting waypoints since robot highlevel decision making ability strategy simply give control user however
since coordination robot user abstract e coordination
constraints looser wait cost function less severe human giving less
detailed guidance fully tele operated case good according
goodrich et al hence use lower value expected quality user
decision denote uw p distinguish fully tele operated case
next control policy allows robot choose waypoints given user
inputs regions interest robot accept waypoints user ability
robot calculate waypoints modeled since effectively changes
coordination entities removing user need give waypoints model
control policy strategy u du final control policy full autonomy e


fitowards adjustable autonomy real world
performance



udu
u wp

u

neglect


goodrich robot operation eu


eu










b


p





figure goodrich al control strategies plotted neglect experimental thinner lines represent control systems intelligence
autonomy b theoretically derived model strategies presented article p parameter probability response function
robot decision making inferior user hence robot decision quality less
user graphs four strategies plotted probability response
parameter getting smaller right match neglect goodrich et al graph
shown figure notice shape graph theoretically derived model
shown figure b qualitatively shape experimentally derived
graph figure hence theory predicted qualitatively performance
found experimentation
common assumption earlier aa work entity asked
decision make decision promptly hence strategies handling contingency


fiscerri pynadath tambe
lack response required example horvitz work
decision theory aimed developing general theoretical aa reasoning
user workstation prototype system called lookout helping users manage
calendars implemented test ideas horvitz although systems
distinctly different e elves mapping formulation allows us
analyze utility approaches across range domains without implement
domains
critical difference horvitz work work lookout
address possibility receiving timely response thus complex strategies
required typical case lookout agent three options take
action take action engage dialog central factor uencing
decision whether user particular goal action would aid e user
goal action useful goal action
disruptive choosing act act corresponds pursuing strategy choosing
seek user input corresponds strategy u figure shows graph different
options plotted probability user goal corresponds figure
horvitz agent expected decision quality eqda derived equation
horvitz words horvitz model performs detailed calculations
expected decision quality model predicts selection strategies
horvitz e choosing strategy eqda low u otherwise assuming
two strategies available however model predicts something
horvitz consider e rate wait costs accrue becomes
non negligible choice simple figure b shows eu two
strategies changes rate wait costs accruing increased fact optimal
strategy varies wait cost suggests horvitz would immediately
appropriate domain wait costs non negligible e g would need
modified many multi agent settings

approaches aa
several different approaches taken core whether
transfer decision making control example hexmoor examines much time agent
aa reasoning hexmoor similarly dynamic adaptive autonomy
framework group agents allocates votes amongst hence defining amount
uence agent decision thus definition autonomy
agent respect decision barber martin mckay b related
application meeting scheduling cesta collia aloisi taken
providing powerful tools users constrain monitor behavior proxy
agents agents explicitly reason relinquishing control user
least work done multiagent context possibility multiple
transfers control considered
complementing work researchers focused issues architectures
aa instance aa interface architecture bonasso firby gat kortenkamp
consider choosing act autonomous decision hence categorize way autonomous action



fitowards adjustable autonomy real world

horvitzs eu calculations wait cost


eu










probability user goal





horvitzs eu calculations wait cost


eu










b

w

figure eu different agent options solid darkest line shows eu taking
autonomous action dashed medium dark line shows eu autonomously deciding act dotted line shows eu transferring
control user plotted probability user goal
wait cost b plotted wait cost fixed probability user goal
miller slack implemented solve human machine interaction
experienced number nasa projects brann thurman mitchell
experiences showed interaction system required way
deliberative layer detailed control actuators aa controls layers
encapsulated referred fourth layer interaction layer


fiscerri pynadath tambe
schreckenghost similar area aa technology required safety critical
intelligent software controlling nuclear power plants oil refineries musliner
krebsbach work resulted system called aegis abnormal event
guidance information system combines human agent capabilities rapid
reaction emergencies petro chemical refining plant aegis features shared task
representation users intelligent system work goldman
guerlain miller musliner key hypothesis work model needs
multiple levels abstraction user interact level see fit
interesting work fong thorpe baur extended idea tele operated
robotics defining relationship robot user collaborative one
rather traditional master slave configuration particular robot treats
human resource perform perceptual cognitive functions robot
determines cannot adequately perform however yet work looked
possibility user available provide input required would require
robot perform complex transfer control reasoning
previous work aa ignored complex strategies aa work
fields potentially relevant example issues addressed fields mixed initiative decision making collins bilot gini mobasher
b anytime zilberstein multi processor scheduling stankovic ramamritham cheng meta reasoning russell wefald game theory fudenberg tirole contingency plans draper hanks weld peot
smith least superficial similarities aa however
turns core assumptions focus areas different
enough developed related fields directly applicable
aa
mixed initiative decision making human user assumed continually available
collins et al b ferguson allen negating need reasoning
likelihood response furthermore often little time pressure coordination
constraints thus basic transferring control human
agent common mixed initiative decision making aa assumptions
quite different leading distinct solutions likewise related fields make
distinctly different assumptions lead distinctly different solutions instance
contingency draper et al peot smith deals
creating plans deal critical developments environment strategies related
contingency plans deal specific contingency
entity making decision manner maintains coordination however contingency key diculty creating plans contrast aa creating
strategies straightforward key diculty choosing strategies
contribution recognizing need strategies addressing aa instantiating strategies via mdps development general domain independent
reward function leads mdp choosing optimal strategy particular situation
similarly another related area meta reasoning russell wefald
meta reasoning work looks online reasoning computation type meta reasoning
closely related aa chooses sequences computations different ex

fitowards adjustable autonomy real world
pected quality running time subject constraint choosing highest quality
sequence computations possible takes long russell wefald
idea treat computations actions meta reason eu
certain combinations computation base level actions output metareasoning sequence computations executed sequence aa parallels metareasoning consider reasoning transferring control entities reasoning
selecting computations e think entities computations however aa
aim one entity make high quality decision meta reasoning aim
sequence computations high quality moreover meta reasoning
assumption computations guaranteed return timely executed
apply aa finally meta reasoning looks sequence computations use
fixed amount time aa reasons trading extra time better decision
possibly buying time action thus developed meta reasoning
applicable aa
another area conceptual similarity aa field anytime zilberstein anytime quickly finds initial solution
incrementally tries improve solution stopped aa similar
assume agent make immediate decision
property solution available important property anytime
however case general e agent
answer furthermore anytime generally need deal multiple
distributed entities opportunity change coordination e
action
multi processor scheduling looks assigning tasks nodes order meet certain
time constraints stankovic et al entities thought nodes aa
assigning tasks nodes multiprocessor scheduling quality
computation performed nodes usually assumed equal e nodes
homogeneous thus reasoning trades quality time required
aa moreover deadlines externally imposed multi processor scheduling
rather exibly reasoned aa multi processor scheduling
sometimes deal node rejecting task cannot fulfill time constraints
network failures however aa focuses failure get response
central issue load balancing auxiliary issue multi processor scheduling
opposite focus difference focus leads developed
multiprocessor scheduling community well suited aa vice versa


conclusions

adjustable autonomy critical success real world agent systems allows
agent leverage skills resources decision making abilities entities
human agent previous work addressed aa context single agent
single human scenarios solutions scale increasingly complex multiagent systems particular previous work used rigid one shot transfers control
consider team costs importantly consider possibility costly



fiscerri pynadath tambe
miscoordination team members indeed applied rigid transfer control
multi agent context failed dramatically
article makes three key contributions enable application aa
complex multiagent domains first article introduces notion transfer control
strategy transfer control strategy consists conditional sequence two types
actions actions transfer decision making control ii actions change
agent pre specified coordination constraints team members aimed minimizing
miscoordination costs strategies allow agents plan sequences transfer control
actions thus strategy allows agent transfer control entities best able make
decisions buy time decisions made still avoid miscoordination even
entity control transferred fails make decision additionally
introduced idea changing coordination constraints mechanism giving
agent opportunity provide high quality decisions showed changes
cases effective way increasing team expected utility
second contribution article mathematical model aa strategies
allows us calculate expected utility strategies model shows
complex strategies indeed better single shot strategies situations
superior fact analysis showed particular strategy dominates
whole space aa decisions instead different strategies optimal different
situations
third contribution article operationalization notion transferof control strategies via markov decision processes general reward function
leads mdp optimal strategies multiagent context general domainindependent reward function allow potentially applied
multi agent domains implemented applied tested mdp aa reasoning real world application supporting researchers daily activities daily use
showed mdp effective balancing need avoid risky autonomous
decisions potential costly miscoordination furthermore detailed experiments
showed policies produced mdps desirable properties transferring control user less often probability getting timely response low
finally practical experience system revealed users require ability manipulate aa reasoning agents end introduced constraint language
allows user limit range behavior mdp exhibit presented
processing constraints showed desirable property
reducing time takes optimal policies


future work

model aa presented article suciently rich model wide variety
interesting applications however key factors modeled
current formulation required domains one key issue allow agent
factor aa reasoning agents aa reasoning instance
elves domain one agent likely decide delay meeting another agent may
wait decision avoid asking user conversely agent take
back control decision knows another agent going continue waiting user input


fitowards adjustable autonomy real world
might continue wait input interactions substantially increase
complexity reasoning agent needs perform article assumed
agent finding transfer control strategy single isolated decision
general many decisions made agent able
ignore interactions decisions example transferring control many
decisions user reduces probability getting prompt response
reasoning interactions add complexity required reasoning
agent
another focus future work generalizing aa decision making allow
types constraints coordination constraints taken account
would turn require generalization concept action include types
stop gap actions may lead different types strategies agent could pursue
additionally transfer control actions could generalized allow parts decision
transferred e g allow input received user without transferring total
control allow actions could performed collaboratively similarly
actions reversible agent could make decision allow user reverse
hope generalizations would improve applicability adjustable
autonomy complex domains
acknowledgments

supported darpa award f effort
managed air force labs rome site article unifies generalizes significantly extends approaches described previous conference papers scerri et al
scerri pynadath tambe pynadath tambe thank colleagues
especially craig knoblock yolanda gil hans chalupsky tom russ collaborating
electric elves project would thank jair reviewers
useful comments



fiscerri pynadath tambe
appendix example instantiation model

appendix present detailed look one possible instantiation aa model
use instantiation calculate eu commonly used strategies
eu varies parameters rate wait cost accrual time
transfers control performed instantiation agent one entity
call decision e user u hence e fa u g w use following
function



w exp
exp otherwise



exponential wait cost function ects idea big delay much worse
small one polynomial similar function could used exponential
used since makes mathematics cleaner probability response use
p exp markovian response probability ects entity likely
respond next point time previous point users moving around dynamic environment turns reasonable approximation
entities decision making quality constant time particular eqda
eqdu assuming constant decision making quality accurate
dynamic environment since information available entity may change hence uencing
ability make decision however decisions involving static facts preferences
decision making quality relatively constant functions coarse approximation range interesting applications including e elves table shows resulting
instantiated equations simple strategies convenience let figures
b graphically eu ea strategy varies along different axes w
parameter wait cost function higher w means faster accruing wait costs
p parameter response probability function higher p means faster response
notice eu depends transfer time much user
decision quality figure shows value discussed earlier
figure c compares eu e dea e strategies complex
transfer control strategy e transfers control makes atter
eu graph plotted wait cost w response probability p parameters
particular fall wait costs high probability response low
dramatic complex strategy

appendix b constraint propagation correctness

section examined need user specified constraints conjunction
mdp strategies must thus extend standard mdp policy
evaluation support evaluation strategies accounting
standard quantitative reward function qualitative constraints appendix
provides novel developed evaluate strategies accounting


fitowards adjustable autonomy real world


















w





p













b
value












w








beta





p


w

c



p




figure equation e strategy ea plotted e w rate
wait costs accrue e p likelihood response b transfer
time beta user decision quality c comparing strategies e dea
e dotted line e value



fiscerri pynadath tambe


eued exp

exp
euea



exp





















eueddeat



value
exp exp exp
exp exp


dcost exp exp exp exp dvalue exp exp
exp dcost exp exp dvalue exp dvalue
table instantiated aa eu equations simple transfer control strategies
present detailed proof output correct strategy
e strategy highest expected utility subject user specified constraints
standard mdp value iteration value strategy particular
state single number expected utility u addition two types
constraints value tuple hf n u f represents strategy ability satisfy
forbidding constraints therefore boolean indicating whether state forbidden
n represents strategy ability satisfy necessary constraints therefore
set requiring constraints satisfied traditional value iteration
u expected reward instance value state v htrue fcrs g
executing policy state achieve expected value satisfy
required state constraint crs however guaranteed satisfy requiredstate required action constraints addition forbidden nonzero
probability violating forbidden action forbidden state constraint record
forbidding constraints policy violates since violating one equally
bad record requiring constraints policy satisfies since satisfying
constraints preferable satisfying therefore size
value function grows linearly number requiring constraints independent
number forbidding constraints
following form standard value iteration initialize value function
states considering immediate value strategy given state without
lookahead precisely

v





c cfs



c fc crs jc g rs



thus state forbidden forbidden state constraints immediately apply
satisfies required state constraints immediately apply standard value
iteration expected utility value reward function state


fitowards adjustable autonomy real world
value iteration must define updated value function v refinement
previous iteration value function v states become forbidden v
violate constraints directly successors forbidden according v
states satisfy requirements satisfy directly successors satisfy
requirement simplify following expressions define set
successors fs jmssa g following expression provides precise definition
iterative step





max
c
c
f
c c




c cfa v hf n u
fs

fc crsjc g fc cra jc g n
v hf n u

x
rs r mssa u

v hf n u
standard value iteration iterative step specifies maximization possible choices action however two additional components represent value
strategy respect constraints longer obvious comparison
function use evaluating candidate actions therefore perform maximization
following preference ordering x means preferable x
ht n u

f n u
hf n u
f n n uff
hf n u f n u u

v

words satisfying forbidden constraint takes highest priority satisfying
requiring constraints second increasing expected value last define optimal
action p action final v expression maximized
despite set operations equation time complexity iteration
step exceeds standard value iteration linear factor namely number
constraints jcfs j jcfa j jcrsj jcra j eciency derives fact
constraints satisfied violated independently determination whether
single constraint satisfied violated requires time standard value
iteration hence overall linear increase time complexity
expected value lowest priority separate iterative step
equation two phases constraint propagation value iteration
constraint propagation phase compute first two components value function hf n value iteration phase computes third component h u
standard value iteration however ignore state action pairs according
constraint propagation violate forbidding constraint ht n requiring constraint hf n crs cra component wise independence
equation two phase computes identical value function original
single phase version state action pairs satisfy constraints
rest appendix provide proof correctness modified value
iteration policy given policy p constructed according must


fiscerri pynadath tambe
agent following p obey constraints specified user agent
begins state must prove satisfy constraints
v hf cra crs u prove forbidding requiring constraints
separately

theorem agent following policy p value function v generated section state violate forbidding constraint probability zero
v hf n u u n
proof prove theorem induction subspaces states classified

close violating forbidding constraint precisely partition
state space subsets sk defined contain states violate forbidding
constraint minimum k state transitions words contains states
violate forbidding constraint directly contains states violate
forbidding constraints successor state following transition
probability function p e successor state contains states
violate forbidding constraints successors
least one successor state successor state e successor state
etc js j nonempty subsets mutually exclusive sequence
make partition exhaustive special subset contains states
agent never violate forbidding constraint following p first induction
k sk k js j v ht n u required theorem
basis step definition agent violate forbidding constraint
therefore c cfs c c cfa c p
know equation v ht n u
inductive step sk k js j assume induction hypothesis
sk v ht n u definition sk state sk least one
successor state sk according equation v ht n u
disjunction must include f
therefore induction know sk k js j v ht n u
v hf n u prove induction
state v hf n u
basis step v definition
thereff cannot exist c cfs
c equation v f n u
inductive step v assume
inductive
hypothesis

v hf n u know v f n u three disjunctions
equation false first false described basis step second term
similarly false since definition cannot exist c cfa
c p evaluating third term first note words
successor states successor sk finite k
sk since successors know inductive hypothesis
disjunction v successors
fffalse therefore three disjunctive


terms equation false v f n u
therefore induction know v hf n u definition
state partition two prove theorem required


fitowards adjustable autonomy real world
theorem agent following policy p value function v generated described
section state satisfy every requiring constraint
probability one v hf cra crs u u f
proof sketch proof parallels theorem state partition sk
k corresponds maximum number transitions satisfying requiring
constraint however states violate constraint rather

satisfy cycles state space prevent guarantee satisfying requiring
constraint within fixed number transitions although probability satisfaction
limit may current constraint semantics decided
situation fails satisfy constraint behaves accordingly cycles
effect handling forbidding constraints saw theorem
need consider minimum length trajectory
proofs two theorems operate independently policy specified action
satisfy constraints action exists precedence forbidding constraints
requiring ones effect optimal action states however
con icting forbidding requiring constraints state preference ordering
causes agent choose policy satisfies forbidding constraint violates
requiring constraint agent make opposite choice simply change
preference ordering section regardless choice theorems
agent use value function v identify existence violation
notify user violation possible constraint con ict
references

barber k goel martin c dynamic adaptive autonomy multi agent
systems journal experimental theoretical artificial intelligence

barber k martin c mckay r b communication protocol supporting
dynamic autonomy agreements proceedings pricai workshop teams
adjustable autonomy pp melbourne australia
bonasso r firby r gat e kortenkamp miller slack experiences architecture intelligent reactive agents journal experimental
theorectical artificial intelligence
brann thurman mitchell c human interaction lights automation field study proceedings symposium human interaction
complex systems pp dayton usa
cesta collia aloisi tailorable interactive agents scheduling
meetings lecture notes ai proceedings aimsa pp
springer verlag
chalupsky h gil knoblock c lerman k oh j pynadath russ tambe
electric elves applying agent technology support human organizations
international conference innovative applications ai pp


fiscerri pynadath tambe
collins j bilot c gini mobasher b mixed initiative decision support
agent automated contracting proceedings international conference
autonomous agents agents
collins j bilot c gini mobasher b b mixed initiative decision support
agent automated contracting proceedings international conference
autonomous agents agents pp
dorais g bonasso r kortenkamp pell b schreckenghost adjustable
autonomy human centered autonomous systems mars proceedings
first international conference mars society pp
draper hanks weld probabilistic information gathering
contingent execution hammond k ed proc second international conference artificial intelligence systems pp university chicago
illinois aaai press
ferguson g allen j miller b trains towards mixed initiative
assistant proceedings third conference artificial intelligence
systems pp
ferguson g allen j trips intelligent integrated solving assistant proceedings fifteenth national conference artificial intelligence aaai pp madison wi usa
fong thorpe c baur c robot partner vehicle teleoperation collaborative control workshop multi robot systems naval laboratory
washington c
fudenberg tirole j game theory mit press cambridge massachusetts
goldman r guerlain miller c musliner integrated task representation indirect interaction working notes aaai spring symposium
computational mixed initiative interaction
goodrich olsen crandall j palmer experiments adjustable
autonomy hexmoor h castelfranchi c falcone r cox eds proceedings ijcai workshop autonomy delegation control interacting
intelligent agents
gunderson j martin w effects uncertainty variable autonomy maintainance robots agents workshop autonomy control software pp
hexmoor h cognitive model situated autonomy proceedings pricai workshop teams adjustable autonomy pp melbourne australia
hexmoor h kortenkamp introduction autonomy control software journal
experiemental theoretical artificial intelligence
horvitz e principles mixed initiative user interfaces proceedings acm
sigchi conference human factors computing systems chi pp
pittsburgh pa


fitowards adjustable autonomy real world
horvitz e jacobs hovel attention sensitive alerting proceedings
conference uncertainty artificial intelligence uai pp stockholm sweden
lesser v atighetchi benyo b horling b raja vincent r wagner xuan
p zhang umass intelligent home project proceedings
third annual conference autonomous agents pp seattle usa
mitchell caruana r freitag mcdermott j zabowski experience
learning personal assistant communications acm
mulsiner pell b call papers aaai spring symposium adjustable
autonomy www aaai org
musliner krebsbach k adjustable autonomy procedural control
refineries aaai spring symposium agents adjustable autonomy pp
stanford california
peot smith e conditional nonlinear hendler j ed
proc first international conference artificial intelligence systems pp
college park maryland morgan kaufmann
puterman l markov decision processes john wiley sons
pynadath tambe arens chalupsky h gil knoblock c lee h lerman
k oh j kamachandran rosenbloom p russ electric elves
immersing agent organization human organization proceedings
aaai fall symposium socially intelligent agents human loop
pynadath tambe revisiting asimov first law response call
arms intelligent agents viii proceedings international workshop agents
theories architectures languages atal
quinlan j r c programs machine learning morgan kaufmann san
mateo ca
russell j wefald e principles metareasoning brachman r j
levesque h j reiter r eds kr principles knowledge representation
reasoning pp morgan kaufmann san mateo california
scerri p pynadath tambe adjustable autonomy real world multiagent environments proceedings fifth international conference autonomous agents agents pp
scerri p pynadath tambe elf acted autonomously towards
theory adjustable autonomy first international joint conference autonomous agents multi agent systems aamas
schreckenghost human interaction control software supporting adjustable
autonomy musliner pell b eds agents adjustable autonomy
aaai spring symposium series pp
stankovic j ramamritham k cheng evaluation exible task scheduling distributed hard real time system ieee transactions computers


fiscerri pynadath tambe
tambe towards exible teamwork journal artificial intelligence
jair
tambe pynadath v chauvat n das kaminka g adaptive
agent integration architectures heterogeneous team members proceedings
international conference multiagent systems pp
zilberstein anytime intelligent systems ai magazine





