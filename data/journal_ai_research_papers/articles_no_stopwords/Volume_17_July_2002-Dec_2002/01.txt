Journal Artificial Intelligence Research 17 (2002) 35-55

Submitted 12/01; published 8/02

Inferring Strategies Sentence Ordering Multidocument
News Summarization
Regina Barzilay
Noemie Elhadad
Kathleen R. McKeown

regina@cs.columbia.edu
noemie@cs.columbia.edu
kathy@cs.columbia.edu

Columbia University, Computer Science Department
1214 Amsterdam Ave
New York, 10027, NY, USA

Abstract
problem organizing information multidocument summarization
generated summary coherent received relatively little attention. sentence
ordering single document summarization determined ordering sentences input article, case multidocument summarization
summary sentences may drawn different input articles. paper, propose
methodology studying properties ordering information news genre
describe experiments done corpus multiple acceptable orderings developed
task. Based experiments, implemented strategy ordering information
combines constraints chronological order events topical relatedness. Evaluation augmented algorithm shows significant improvement ordering
two baseline strategies.

1. Introduction
Multidocument summarization poses number new challenges single document summarization. Researchers already investigated issues identifying repetitions
contradictions across input documents determining information salient enough
include summary (Barzilay, McKeown, & Elhadad, 1999; Carbonell & Goldstein,
1998; Elhadad & McKeown, 2001; Mani & Bloedorn, 1997; McKeown, Klavans, Hatzivassiloglou, Barzilay, & Eskin, 1999; Radev & McKeown, 1998; White, Korelsky, Cardie, Ng,
Pierce, & Wagstaff, 2001). One issue received little attention organize
selected information output summary coherent. relevant
pieces information selected across input documents, summarizer
decide order present whole text makes sense. single
document summarization, one possible ordering extracted information provided
input document itself. However, Jing (1998) observed that, single document summaries written professional summarizers, extracted sentences always retain
precedence orders summary. Moreover, case multiple input documents,
provide useful solution: information may drawn different documents
therefore, single document provide ordering. Furthermore, order two
pieces information change significantly one document another.
paper, provide corpus based methodology studying ordering. goal
develop good ordering strategy context multidocument summarization
c
2002
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBarzilay, Elhadad & McKeown

targeted news genre. first question addressed importance ordering. conducted experiments show ordering significantly affects readers
comprehension text. experiments show although single ideal
ordering information, ordering unconstrained problem; number good orderings given text limited. second question addressed analysis use
data infer strategy ordering. Existing corpus based methods, supervised
learning, easily applicable problem part lack training data.
Given multiple possible orderings, corpus providing one ordering
set information allow us differentiate sentences must together sentences happen together. led us develop corpus data
sets, contains multiple acceptable orderings single text. corpus
expensive construct therefore, provide enough data pure statistical
approaches. Instead, used hybrid corpus analysis strategy first automatically identifies commonalities across orderings. Manual analysis resulting clusters led
identification constraints ordering. Finally, evaluated plausible ordering strategies
asking humans judge results.
set experiments together suggests ordering algorithm integrates constraints approximation temporal sequence underlying events
relatedness content elements. evaluation plausible strategies measured
usefulness Chronological Ordering algorithm used previous summarization systems
(McKeown et al., 1999; Lin & Hovy, 2001) well alternative, original strategy,
Majority Ordering. evaluation showed two ordering algorithms alone
yield satisfactory results. first, Majority Ordering, critically linked level
similarity information ordering across input texts. input texts different
orderings, however, algorithm produces unpredictable unacceptable results.
second, Chronological Ordering produces good results information event-based,
therefore, temporally sequenced. texts refer events, describe
states properties, algorithm falls short.
automatic analysis revealed topical relatedness important constraint;
groups related sentences tend appear together. algorithm combines Chronological
Ordering constraints topical relatedness. Evaluation shows augmented
algorithm significantly outperforms either simpler methods alone. strategy
characterized bottom-up since final ordering text emerges data
groups together, whether related content chronological sequence. contrasts
top-down strategies RST (Moore & Paris, 1993; Hovy, 1993), schemas (McKeown, 1985) plans (Dale, 1992) impose external, rhetorically motivated ordering
data.
following sections, first show way information ordered summary
critically affect overall quality. give overview summarization
system, MultiGen. next describe two naive ordering algorithms evaluate
them, followed study multiple orderings produced humans. allows us
determine improve Chronological Ordering algorithm using cohesion
additional constraint. last section describes augmented algorithm along
evaluation.
36

fiSentence Ordering Multidocument News Summarization

2. Impact Ordering Overall Quality Summary
Even though problem ordering information multidocument summarization
received relatively little attention, hypothesize good ordering crucial produce
summaries quality. consensus architecture state art summarizers consists
content selection module salient information extracted regeneration
module information reformulated fluent text. Ideally, regeneration
component contains devices perform surface repairs text anaphora
resolution, introducing cohesion markers choosing appropriate lexical paraphrases.
claim paper multidocument summarization architecture needs
explicit ordering component. two pieces information extracted content selection
phase end together not, fact, next one another, surface devices
repair impaired flow information summary. ordering strategy would
help avoid situation.
clear ordering cannot improve output earlier stages summarizer,
among content selection1 ; however, finding acceptable ordering enhance user
comprehension summary and, therefore, overall quality. course, surface devices
still needed smooth output summary, scope paper (but
see (Schiffman, Nenkova, & McKeown, 2002)). section show quality
ordering direct effect user comprehension summary. verify hypothesis,
performed experiment, measuring impact ordering users comprehension
summaries.
selected ten summaries produced Columbia Summarization system (McKeown, Barzilay, Evans, Hatzivassiloglou, Kan, Schiffman, & Teufel, 2001). composed
router two underlying summarizers MultiGen DEMS (Difference Engine
Multidocument Summarization). Depending type input articles summarized, router selects appropriate summarizer. evaluated system
Document Understanding Conference 2001 (DUC) 2 evaluation, summaries produced
several systems graded human judges according different criteria, among
well information contained summary ordered. actually identify
possible impact ordering comprehension, selected summaries humans
judged ordering poor.3 summary, manually reordered sentences
generated summarizer, using input articles reference. so,
change content sentences reordered summaries
ones originally produced summaries. process yields ten additional reordered
summaries thus, overall collection contains twenty summaries.
Two subjects authors participated experiment. summary
read one participant without access input articles. distributed
summaries among judges none read original summary
reordering. asked grade well summary could understood, using
ratings Incomprehensible, Somewhat comprehensible Comprehensible.
1. information added deleted content selection performed.
2. http://www-nlpir.nist.gov/projects/duc/
3. selected summaries produced DEMS system. didnt select summary produced
MultiGen implemented ordering algorithm time. DEMS hand,
specific ordering strategy implemented thus provided us appropriate type data.

37

fiBarzilay, Elhadad & McKeown

results shown Figure 14 . Seven original summaries considered incomprehensible judge, two somewhat comprehensible, one original summary
fully comprehensible. reordered summaries obtained better grades overall five
summaries fully comprehensible, two somewhat comprehensible, three remained incomprehensible. assess statistical significance results, applied
Fisher exact test data set, conflating Incomprehensible Somewhat comprehensible summaries one category obtain 2x2 table. test adapted
case reduced size data set. obtained p-value 0.07 (Siegal
& Castellan, 1988), means reordering not, general, helpful,
7% chance reordering anyway would produce result different quality
original ordering. experiment indicates good ordering improve
overall comprehensibility summary.
Summary set
d13
d19
d24
d31
d32
d39
d45
d50
d54
d56

Original
Incomprehensible
Somewhat comprehensible
Incomprehensible
Somewhat comprehensible
Incomprehensible
Incomprehensible
Incomprehensible
Incomprehensible
Incomprehensible
Comprehensible

Reordered
Incomprehensible
Comprehensible
Comprehensible
Comprehensible
Somewhat comprehensible
Incomprehensible
Incomprehensible
Comprehensible
Somewhat comprehensible
Comprehensible

Figure 1: Impact ordering user comprehension summaries.

case low-scoring summaries, clear poor ordering likely
culprit. instance, readers easily identify grouping two following sentences
unsuitable choice could misleading. Miss Taylors health problems started
fall horse 13 filming movie National Velvet. recovery
Elizabeth Taylor, near death two weeks ago viral pneumonia, complicated yeast
infection, doctors said Friday. cases, information summary
poorly ordered readers cannot make sense text, observed interviews
readers tend blame content selection rather ordering,
even content issue. Thus, issue ordering isolated; affect
overall quality summary.

3. MultiGen Overview
framework MultiGen system (McKeown et al., 1999), multidocument summarizer trained tested news articles. MultiGen part
Columbia Summarization System. operates set news articles describing
4. set names ones used DUC evaluation.

38

fiSentence Ordering Multidocument News Summarization

event, creating summary synthesizes common information across documents.
system runs daily real data within Newsblaster 5 , tool collects news articles
multiple sources, organizes topical clusters provides summary
clusters.
case multidocument summarization articles event, source
articles contain repetitions contradictions. Extracting similar sentences would produce verbose repetitive summary, extracting
similar sentences would produce summary biased towards sources. MultiGen uses
comparison extracted similar sentences select appropriate phrases include
summary reformulates new text.
MultiGen consists analysis generation component. analysis component (Hatzivassiloglou, Klavans, & Eskin, 1999) identifies units text convey similar
information across input documents using statistical techniques shallow text analysis. similar text units identified, cluster themes. Themes sets
sentences different documents contain repeated information necessarily contain sentences documents (see two examples themes Figure 2).
theme, generation component (Barzilay et al., 1999) identifies phrases
intersection theme sentences selects part summary.
intersection sentences ordered produce coherent text. end,
theme single corresponding generated output sentence summary.
following section, describe different strategies ordering output sentences
obtain quality summary.
Theme 1
Mr. Salvi, 24, apparently killed prison cell last November.
state wouldnt execute killing two abortion clinic workers 1994, John
C. Salvi III took life.
John C. Salvi III, convicted killing two people shooting spree two
abortion clinics 1994, killed prison.
Theme 2
attorneys said attempted suicide twice prison.
lawyers said twice tried commit suicide jail, charge authorities
denied.
Figure 2: Two themes corresponding sentences. Theme 2 contains sentences
two articles, Theme 1 contains sentences three input articles.

4. Naive Ordering Algorithms Sufficient
producing summary, multidocument summarization system choose
order present output sentences. section, describe two algorithms
5. http://www.cs.columbia.edu/nlp/newsblaster

39

fiBarzilay, Elhadad & McKeown

ordering sentences suitable multidocument summarization news genre.
first algorithm, Majority Ordering (MO), relies original orders sentences
input documents. second one, Chronological Ordering (CO), uses time-related
features order sentences. strategy originally implemented MultiGen
followed summarization systems (Radev, Jing, & Budzikowska, 2000; Lin & Hovy,
2001). MultiGen framework, ordering sentences equivalent ordering themes,
describe algorithms terms themes. makes sense because, ultimately,
summary composed sequence sentences, one constructed
information one theme. evaluation shows methods alone provide
adequate strategy ordering.
4.1 Majority Ordering
4.1.1 Algorithm
single document summarization, order sentences output summary typically
determined order input text. strategy adapted multidocument
summarization. Consider two themes, h 1 h2 ; sentences h1 precede sentences
h2 input texts, presenting h 1 h2 likely acceptable
order. use majority ordering algorithm order sentences h 1
h2 varies one text another, must augment strategy. One way define
order h1 h2 adopt order occurring majority
texts h1 h2 occur. strategy defines pairwise order themes.
However, pairwise relation necessarily transitive. example, given themes
h1 , h2 h3 following situation: h1 precedes h2 text, h2 precedes
h3 text another text, h 3 precedes h1 yet another text;
conflict orders (T h1 , h2 , h3 ) (T h3 , h1 ). Since transitivity necessary
condition relation called order, relation form order.
We, therefore, expand pairwise relation provide total order.
words, find linear ordering themes maximizes agreement
orderings provided input texts. pair themes, h hj ,
keep two counts, Ci,j Cj,i ; Ci,j number input texts sentences
hi occur sentences hj , Cj,i opposite order. weight
linear order (T hi1 , . . . , hik ) defined sum counts every pair C il ,im ,
il im l, {1 . . . k}. Stating problem terms directed graph
nodes themes, vertex h hj weight Ci,j , looking
path maximal weight traverses node exactly (see Figure 3).
call graph precedence graph.
problem finding path maximal weight addressed Cohen,
Schapire, Singer (1999) task learning orderings. adopt two-stage
approach. first stage, given training corpus ordered instances set
features describing them, binary preference function learned. second stage, new
instances ordered agreement learned preference function maximized.
so, Cohen et al. (1999) represent preference function directed, weighted
graph. precedence graph seen graph preference function
40

fiSentence Ordering Multidocument News Summarization

h11 h12 h13
h23 h22 h24
h34 h31 h32 h33

Th 1
2

2

1

Th 2
2
1

1

Th 3

1
1

1

Th 4
Figure 3: Three input theme orderings corresponding precedence graph. h ji
sentence part theme hi input ordering j.

nodes hi hj Ci,j . orderings input articles provide us
directly preference function and, therefore, need learn it.
Unfortunately problem NP-complete; Cohen et al. (1999) prove reducing
CYCLIC-ORDERING (Galil & Megido, 1977). However, using modified version
topological sort provides us approximate solution. node, assign
weight equal sum weights outgoing edges minus sum weights
incoming edges. first pick node maximum weight, ordering ahead
nodes, delete outgoing edges precedence graph update
properly weights remaining nodes graph. iterate
nodes graph empty. Cohen et al. (1999) show algorithm produces
tight approximation optimal solution. Currently MultiGen uses implementation
algorithm ordering component.
Figures 4 5 show examples produced summaries. One feature strategy
produce several orderings weight. happens
tie two opposite orderings. situation, strategy provide enough
constraints determine one optimal ordering; ordering chosen randomly among
orders maximal weight.
4.1.2 Evaluation
asked three human judges (not including ourselves) classify quality order
information 25 summaries produced using MO algorithm three categories
Poor, Fair Good. use operational definition Poor summary text whose
41

fiBarzilay, Elhadad & McKeown

man accused firebombing two Manhattan subways 1994 convicted Thursday jury
rejected notion drug Prozac led commit crimes.
found guilty two counts attempted murder, 14 counts first-degree assault two counts
criminal possession weapon.
December 1994, Leary ignited firebombs two Manhattan subway trains. second blast injured 50
people 16 seriously, including Leary.
Leary wanted extort money Transit Authority.
defense argued Leary responsible actions toxic psychosis caused
Prozac.

Figure 4: summary produced using Majority Ordering algorithm, graded Good.

Hemingway, 69, died natural causes Miami jail arrested indecent exposure.
book wrote father, Papa: Personal Memoir, published 1976.
picked last Wednesday walking naked Miami.
difficult life.
transvestite later sex-change operation, suffered bouts drinking, depression drifting,
according acquaintances.
easy son great man, Scott Donaldson, told Reuters.
time death, lived Coconut Grove district well-known Bohemian
crowd.
due appear court later day charges indecent exposure resisting arrest.
sometimes went name Gloria wore womens clothes.
cause death hypertension cardiovascular disease.
Taken Miami-Dade Womens Detention Center, found dead cell early Monday,
spokeswoman Janelle Hall said.
booked womens jail sex-change operation, Hall added.

Figure 5: summary produced using Majority Ordering algorithm, graded Poor.

readability would significantly improved reordering sentences. Fair summary
text makes sense, reordering sentences yield better readability. Finally, summary cannot improved sentence reordering
considered Good summary.
judges asked grade summaries taking account order
information presented. help focus aspect texts,
resolved dangling references beforehand. Figure 13 shows grades assigned summaries three summaries graded Poor, 14 graded Fair, eight
graded Good. showing majority grade selected least two
judges. made possible experiments, judges strong agreement;
never gave three different grades summary.
MO algorithm produces small number Good summaries,
summaries graded Fair. instance, summary graded Good shown Figure 4
orders information natural way; text starts sentence summary
event, outcome trial given, reminder facts caused trial
possible explanation facts. Looking Good summaries produced
MO, found performs well input articles follow order
42

fiSentence Ordering Multidocument News Summarization

presenting information. words, algorithm produces good ordering
input articles orderings high agreement.
hand, analyzing Poor summaries, observed input texts
different orderings. trying maximize agreement input texts
orderings, MO produces new ordering occur input text. ordering
is, therefore, guaranteed acceptable. example new produced ordering
given Figure 5. summary would readable several sentences moved
around. example better ordering given Figure 6. summary,
three sentences related fact subject sex-change operation grouped
together, one produced majority ordering algorithm, scattered
throughout summary.

Hemingway, 69, died natural causes Miami jail arrested indecent exposure.
cause death hypertension cardiovascular disease.
picked last Wednesday walking naked Miami.
due appear court later day charges indecent exposure resisting arrest.
Taken Miami-Dade Womens Detention Center, found dead cell early Monday,
spokeswoman Janelle Hall said.
booked womens jail sex-change operation, Hall added.
transvestite later sex-change operation, suffered bouts drinking, depression drifting,
according acquaintances.
sometimes went name Gloria wore womens clothes.
difficult life.
easy son great man, Scott Donaldson, told Reuters.
time death, lived Coconut Grove district well-known Bohemian
crowd.
book wrote father, Papa: Personal Memoir, published 1976.

Figure 6: One possible better ordering summary graded Poor.

algorithm used order sentences accurately certain
input texts follow similar organizations. assumption may hold limited domains
documents fixed organization information. However, case,
input texts processing regularities. Looking daily statistics
Newsblaster collects clusters related articles synthesized one summary,
notice typical cluster size seven. every day several clusters
contain 20 70 articles summarized single summaries 6 .
big number input articles, cannot assume similar
ordering information. MOs performance critically depends agreement
orderings input texts; we, therefore, need ordering strategy fit
input data. on, focus Chronological Ordering algorithm
techniques improve it.

6. giant clusters correspond hot topics day news.

43

fiBarzilay, Elhadad & McKeown

4.2 Chronological Ordering
4.2.1 Algorithm
Multidocument summarization news typically deals articles published different
dates, articles cover events occurring wide range time. Using
chronological order summary describe main events helps user understand
happened. seems natural appropriate strategy. mentioned earlier,
framework, ordering themes; using strategy, we, therefore, need assign
date themes. identify date event occurred requires detailed interpretation
temporal references articles. recent developments disambiguating temporal expressions event ordering (Wiebe, OHara, Ohrstrom-Sandgren, &
McKeever, 1998; Mani & Wilson, 2000; Filatova & Hovy, 2001), correlating events
date occurred hard task. case, approximate theme time
first publication time; is, first time theme reported set
input articles (see Figure 7). acceptable approximation news events; first
publication time event usually corresponds occurrence real life. instance,
terrorist attack story, theme conveying attack date previous
date theme describing trial following attack.
Theme 5
Oct 5, 11:35am

Oct 6, 6:13am
Oct 5, 10:20am

Hours crash, U.S. officials said tragedy
caused S-200 missile fired Ukraine military exercises
Crimean Peninsula.
U.S. officials said immediately crash evidence
passenger jet hit Ukrainian missile.
U.S. officials said crash caused S-200
missile fired mistakenly Ukrainian forces military exercises
Crimean Peninsula.

Figure 7: theme corresponding sentences. time theme shown underlined;
earliest publication time sentences.

Articles released news agencies marked publication time, consisting
date time two fields (hour minutes). Articles news agency
thus guaranteed different publication times. quite likely articles
coming different news agencies. development MultiGen, processed
hundreds articles, never encountered two articles publication time.
Thus, publication time serves unique identifier articles. result, two
themes publication time, means reported first
time article.
Chronological Ordering (CO) algorithm takes input set themes orders
chronologically whenever possible. theme assigned date corresponding
first publication. so, select theme sentence earliest
publication time. call time stamp sentence assign publication time
44

fiSentence Ordering Multidocument News Summarization

time stamp theme. establishes partial order themes. two
themes date (that is, reported first time article)
sort according order presentation article. results total
order input themes. Figures 8 9 show examples summaries produced using
CO.
One four people accused along former Pakistani Prime Minister Nawaz Sharif agreed testify
case involving possible hijacking kidnapping charges, prosecutor said Wednesday.
Raja Quereshi, attorney general, said former Civil Aviation Authority chairman already
given statement police.
Sharifs lawyer dismissed news speaking reporters Sharif made appearance
judicial magistrate hear witnesses give statements him. Sharif said innocent.
allegations stem alleged attempt divert plane bringing army chief General Pervez Musharraf
Karachi Sri Lanka October 12.

Figure 8: summary produced using Chronological Ordering algorithm graded Good.

Thousands people attended ceremony Nairobi commemorating first anniversary
deadly bombings attacks U.S. Embassies Kenya Tanzania.
Saudi dissident Osama bin Laden, accused masterminding attacks, nine others still large.
President Clinton said, intended victims vicious crime stood everything right
country world.
U.S. federal prosecutors charged 17 people bombings.
Albright said mourning continues.
Kenyans observing national day mourning honor 215 people died there.

Figure 9: summary produced using Chronological Ordering algorithm graded Poor.

4.2.2 Evaluation
Following methodology used MO algorithm evaluation, asked three
human judges (not including ourselves) grade 25 summaries generated system
using CO algorithm applied collection input texts. results
shown Figure 13: ten summaries graded Poor, eight graded Fair
seven graded Good.
first suspicion approximation deviates much real chronological order events and, therefore, lowers quality sentence ordering. verify
hypothesis, identified sentences broke original chronological order restored ordering manually. Interestingly, displaced sentences mainly background
information. evaluation modified summaries shows visible improvement.
comparing Good (Figure 8) Poor (Figure 9) summaries, notice two phenomena: first, many badly placed sentences cannot ordered based temporal occurrence. instance, Figure 9, sentence quoting Clinton one event
sequence events described, rather, reaction main events.
tool assigning time stamps would assign sentence date Clinton made
statement. true sentence reporting Albrights reaction. Assigning
45

fiBarzilay, Elhadad & McKeown

date reaction, generally sentence conveying background information,
placing chronological stream main events produce logical
ordering. ordering themes is, therefore, covered CO algorithm. Furthermore, sentences cannot assigned time stamp. instance, sentence,
vast, sparsely inhabited Xinjiang region, largely desert, many Chinese military
nuclear installations civilian mining. describes state rather event and,
therefore, trying describe temporal terms invalid. Thus ordering cannot
improved temporal level.
second phenomenon observed Poor summaries typically contain abrupt
switches topics generally incoherent. instance, Figure 9, quotes
US officials (third fifth sentences) split, sentences mourning (first
sixth sentences) appear far apart summary. Grouping together would
increase readability summary. point, need find additional constraints
improve ordering.

5. Improving Ordering: Experiments Analysis
previous section, showed using naive ordering algorithms produce
satisfactory orderings. section, investigate experiments humans
identify patterns orderings improve algorithm.
5.1 Collecting corpus multiple orderings
Sentences text ordered number ways, text whole still
convey meaning. majority possible orders likely unacceptable break conventions information presentation. One way identify
conventions find commonalities among different acceptable orderings information. Extracting regularities several acceptable orderings help us specify ordering
constraints given input type. naturally occurring existing collection
summaries multiple documents aware 7 . even collection would
sufficient since want analyze collection multiple summaries set
articles. created collection multiple orderings produced different humans. Using collection, studied common behaviors mapped strategies
ordering.
collection multiple orderings, along test corpus available
http://www.cs.columbia.edu/~noemie/ordering/. collected ten sets articles
collection. set consisted two three news articles reporting event.
set, manually selected intersection sentences, simulating MultiGen 8 .
average, set contained 8.8 intersection sentences. sentences cleaned explicit references (for instance, occurrences President resolved President
Clinton) connectives, participants would use clues ordering.
Ten subjects participated experiment, built one ordering per set
7. recent attempt, NIST DUC conference collected sets articles summarize one
summary per set.
8. performed manual simulation ensure ideal data provided subjects experiments.

46

fiSentence Ordering Multidocument News Summarization

intersection sentences. subject asked order intersection sentences set
form readable text. Overall, obtained 100 orderings, ten alternative
orderings per set. Figure 10 shows ten alternative orderings collected one set.
Participant
Participant
Participant
Participant
Participant
Participant
Participant
Participant
Participant
Participant

1
2
3
4
5
6
7
8
9
10












BGIHFCJAE
GBICFAJEH
BIGFJAEHC
CFGIBJAHE
GBIHFJACE
GIBFCEHJA
BGIFCHEJA
BCFGIEHAJ
GIBEHFAJC
BGICFAJEH

Figure 10: Multiple orderings one set collection. A, B, . . . J stand sentences. Underlined automatically identified blocks.

first observed surprisingly large portion orderings different.
ten sets, two sets identical orderings (in one set, two orderings
identical set, two pairs identical orderings). variety
produced orderings interpreted suggesting orderings
actually valid task maybe hard subjects allow
produce reasonable orderings. fact, subjects satisfied orderings
produced. Furthermore, manually went 100 orderings,
appeared valid. words, many acceptable orderings given one set
sentences. confirms intuition need look single ideal total
ordering rather construct acceptable one.
Looking various orderings, one might conclude ordering would
well other. One piece evidence statement that,
shown section 2, orderings yield incomprehensible texts thus avoided.
Furthermore, text n sentences, n! possible orderings, small
fraction actually valid orderings. One way validate claim would
enumerate possible orderings single text evaluate one them.
would doable small texts (a text 5 sentences 120 possible orderings)
texts reasonable size. feasible way validate claim get
multiple orderings text large number subjects. asked subjects
order one text eight sentences. maximum 40,320 possible orderings
sentences. 50 subjects participated, obtained 21 unique orderings, showing
number acceptable orderings grow fast number participants.
conclude small fraction possible orderings information
text contains orderings render readable text.
47

fiBarzilay, Elhadad & McKeown

5.2 Analysis
several alternative orderings produced single summary exhibit commonalities.
noticed that, within multiple orderings set, sentences always appear
together. appear order one ordering another,
share adjacency relation. on, refer blocks. set,
identify blocks automatically clustering sentences across orderings. use distance
metric two sentences, average number sentences separate
orderings. Figure 10, instance, distance sentences G 2.
blocks identified clustering are: sentences B, D, G I; sentences J; sentences
C F; sentences E H.
observed blocks experiment correspond clusters topically
related sentences. blocks form units text dealing subject.
words, valid orderings contain blocks topically related sentences. notion
grouping topically related sentences known cohesion. defined Hasan (1984),
cohesion device sticking together different parts text. Studies show
level cohesion direct impact reading comprehension (Halliday & Hasan,
1976). Therefore, good orderings cohesive; makes summary readable.
Conversely, evaluation CO algorithm showed summaries judged
invalid contain abrupt switches topic. words, orderings cohesive
graded poorly. correlation quality ordering cohesion.
Incorporating cohesion constraint ordering strategy opportunistically grouping
sentences together would beneficial. Cohesion achieved surface devices,
repetition words coreferences. describe next include cohesion CO
algorithm based surface features.

6. Augmented Algorithm
Disfluencies arise output CO algorithm topics distributed
whole text, violating cohesion properties (McCoy & Cheng, 1991). typical scenario
illustrated Figure 11. inputs texts 1 , T2 , T3 (ordered publication time). A1 ,
A2 A3 belong theme, whose intersection sentence A, similarly
B C. themes B topically related, C related. Summary 1 ,
based chronological clues, contains two topical shifts; C back
C B. better summary would S2 , keeps B together.
6.1 Algorithm
goal remove disfluencies summary grouping together topically related
themes. main technical difficulty incorporating cohesion ordering algorithm
identify group topically related themes across multiple documents. words,
given two themes, need determine belong cohesion block.
single document, topical segmentation (Hearst, 1994) could used identify blocks,
technique possibility identifying cohesion sentences across multiple
documents. Segmentation algorithms typically exploit linear structure input text;
case, want group together sentences belonging different texts.
48

fiSentence Ordering Multidocument News Summarization

T1

T2

T3

S1

S2

A1
...
C1

C2
...
A2
B2

A3
B3
...
C3





C

B

B

C

Figure 11: Input texts T1 T2 T3 summarized Chronological Ordering (S1 ) Augmented algorithm (S2 ).

solution consists following steps. preprocessing stage, segment
input text (Kan, Klavans, & McKeown, 1998) based word distribution coreference
analysis, given two sentences within text, determine
topically related. Assume themes B exist, contains sentences (A 1 . . . ),
B contains sentences (B1 . . . Bm ). Recall theme set sentences conveying
similar information drawn different input texts. denote #AB number
pairs sentences (Ai , Bj ) appear text, #AB + number
sentence pairs appear text segment.
first stage, pair themes B, compute ratio #AB + /#AB
measure relatedness two themes. measure takes account positive
negative evidence. sentences B appear together
texts segments, means B highly topically related.
case, ratio close 1. hand, among texts containing sentences
B, pairs segments, B topically
related. Accordingly, ratio close 0. B considered related ratio
higher predetermined threshold. determined experimentally value 0.6.
strategy defines pairwise relations themes. transitive closure
relation builds groups related themes and, result, ensures themes
appear together article related third theme still
linked. creates even higher degree relatedness among themes. use
threshold establish pairwise relations, transitive closure produce elongated
chains could link together unrelated themes. able identify topically
related themes. end first stage, grouped blocks.
second stage, assign time stamp block related themes using
earliest time stamp themes contains. adapt CO algorithm described 4.2.1
work level blocks. blocks themes correspond to, respectively,
themes sentences CO algorithm. analogy, easily show
adapted algorithm produces complete order blocks. yields macro-ordering
summary. still need order themes inside block.
last stage augmented algorithm, block, order themes
contains applying CO algorithm them. Figure 12 shows example summary
produced augmented algorithm.
49

fiBarzilay, Elhadad & McKeown

algorithm ensures cohesively related themes spread text
decreases number abrupt switches topics. Figure 12 shows Augmented
algorithm improves sentence order compared order summary produced
CO algorithm Figure 9; sentences quoting US officials grouped together,
descriptions mourning.
Thousands people attended ceremony Nairobi commemorating first anniversary
deadly bombings attacks U.S. Embassies Kenya Tanzania. Kenyans observing national
day mourning honor 215 people died there.
Saudi dissident Osama bin Laden, accused masterminding attacks, nine others still large.
U.S. federal prosecutors charged 17 people bombings.
President Clinton said, intended victims vicious crime stood everything right
country world. Albright said mourning continues.

Figure 12: summary produced using Augmented algorithm. Related sentences
grouped paragraphs.

6.2 Evaluation
Following methodology used evaluate MO CO algorithms, asked
judges grade 25 summaries produced Augmented algorithm. Results shown
Figure 13.
manual effort needed compare judge system output extensive considering
human judge read three summaries input set well skim
input texts verify misleading information introduced summaries.
collected corpus 25 sets articles evaluation. Overall, 75 summaries
evaluated. size corpus comparable collection used DUC
evaluation (30 sets articles). evaluation shows significant improvement
quality orderings CO algorithm Augmented algorithm. assess
significance improvement, used Fisher exact test, conflating Poor Fair
summaries one category (p-value 0.04). augmented algorithm shows
improvement MO algorithm (p-value 0.07).

Majority Ordering
Chronological Ordering
Augmented Ordering

Poor
3
10
3

Fair
14
8
8

Good
8
7
14

Figure 13: Evaluation Majority Ordering, Chronological Ordering Augmented Ordering.

50

fiSentence Ordering Multidocument News Summarization

7. Related Work
Finding acceptable ordering studied domain independent text
summarization. single document summarization, summary sentences typically arranged order found full document, although Jing (1998)
reports human summarizers sometimes change original order. multidocument
summarization, summary consists fragments text sentences selected
different texts. Thus, complete ordering summary sentences
found original documents.
domain dependent summarization, possible establish possible orderings
priori. valid ordering traditionally derived manual analysis corpus
texts domain, typically operates set semantic concepts. semantic
representation information usually available input ordering component.
instance, specific domain news topic terrorist attacks, summaries
constructed first describing place attack, followed number
casualties, possible perpetrators are, etc.
Another alternative ordering information, still domain dependent framework, use data driven approach, produces flexible output.
priori defined simple ordering strategies combined together looking set features input. Elhadad McKeown (2001) use techniques produce patient
specific summaries technical medical articles. Examples features influence
ordering presence contradiction repetition, relevance patient characteristics,
type results reported. linear combination features assigns weight
semantic predicate included output, allowing ordered.
case, features domain dependent identified corpus analysis
interviews physicians. case domain independent system, would
entire new challenge define compute set features.
Producing good ordering information critical task generation community, extensively investigated issue (McKeown, 1985; Moore & Paris, 1993;
Hovy, 1993; Bouayad-Agha, Power, & Scott, 2000; Mooney, Carberry, & McCoy, 1990). One
approach top-down, using schemas (McKeown, 1985) plans (Dale, 1992) determine
organizational structure text. approach postulates rhetorical structure
used select information underlying knowledge base.
domain limited, encoding developed kinds propositional content
match rhetorical elements schema plan, thereby allowing content selected
ordered. Rhetorical Structure Theory (RST) allows flexibility ordering content establishing relations pairs propositions. Constraints based intention
(e.g., Moore & Paris, 1993), plan-like conventions (e.g., Hovy, 1993), stylistic constraints
(e.g., Bouayad-Agha et al., 2000) used preconditions plan operators containing
RST relations determine relation used ordered respect
relations. Another approach (Mooney et al., 1990) bottom-up used group
together stretches text long, generated document finding propositions
related common focus. Since approach developed generation system,
finds related propositions comparisons proposition arguments semantic level.
51

fiBarzilay, Elhadad & McKeown

case, dealing surface representation, find alternative methods
grouping text fragments.
recent approach Duboue McKeown (2001) implemented
automatically estimate constraints information ordering medical domain,
content planning stage. Using collection semantically tagged transcripts written
domain experts, Duboue McKeown (2001) identify basic adjacency patterns contained
within plan, well ordering. MultiGen generates summaries news
topic. unconstrained domain, would impossible enumerate semantics
possible types sentences could match elements schema, plan
rhetorical relations. instance, Duboue McKeown build content planner based
set 29 semantic categories; case, regularity input
information. Furthermore, would difficult specify generic rhetorical plan
summary news. Instead, content determination MultiGen opportunistic, depending
kinds similarities happen exist set news documents. Similarly,
describe ordering scheme opportunistic bottom-up, depending
cohesion temporal connections happen exist selected text.
ordering component takes place content selection information
pipeline architecture, contrast generation systems, usually ordering
content selection come tandem. separation might come cost
good ordering given extracted information, possible go back
content selection extract new information. summarization, content selection driven
salience criteria. believe ordering strategy work different
content selectors, independently salience criteria. Therefore, choose keep
two components, selection ordering, two separate modules.

8. Conclusion Future Work
paper investigated information ordering constraints multidocument summarization news genre. evaluated two alternative ordering strategies, Chronological
Ordering (CO) Majority Ordering (MO). experiments show MO performs well
input texts follow similar organization information. domains
constraint holds, MO would appropriate highly effective strategy.
news genre cannot make assumption; thus appropriate solution.
Chronological Ordering (CO) algorithm provide acceptable solution many
cases, sufficient summaries contain information event based.
experiments, using corpus collected multiple alternative summaries
multiple documents, show cohesion important constraint contributing ordering.
Moreover, show appropriate ordering information critical allow
easy comprehension summary case possible orderings
information acceptable. developed operational algorithm integrates cohesion
part CO algorithm, implemented part MultiGen summarization
system. evaluation system shows significant improvement summary quality.
paper focused augmenting CO algorithm, believe MO
promising strategy neglected. clear different forms
summarization useful different situations, depending intended purpose
52

fiSentence Ordering Multidocument News Summarization

summary types documents summarized. future work, plan
build approach used DUC 2001 evaluation, developed
summarizer would use different algorithms summary generation depending
type input text. suspect ordering strategies may differ also, depending
type summary. work first investigate whether use augmented
algorithm summary types. algorithm yield good orderings,
investigate corpus analysis summary type specific constraints. suspect
augmented algorithm may apply, instance, biographical summaries, since
information summarized mixture event-based information
chronologically ordered along descriptive information person. unclear
whether apply types summaries summaries different events,
since pieces information may temporally related other. plan
identify types summaries would benefit using MO algorithm
augmented version (the way CO algorithm augmented cohesion
constraint).

9. Acknowledgments
work partially supported DARPA grant N66001-00-1-8919, Louis Morin
scholarship Viros scholarship. thank Eli Barzilay providing help
experiments interface, Michael Elhadad useful discussions comments,
many voluntary participants experiments. initial work problem
presented Human Language Technologies Conference (San Diego, 2001).
thank anonymous reviewers HLT JAIR comments.

References
Barzilay, R., McKeown, K., & Elhadad, M. (1999). Information fusion context
multi-document summarization. Proc. 37th Annual Meeting Assoc.
Computational Linguistics.
Bouayad-Agha, N., Power, R., & Scott, D. (2000). text structure incompatible
rhetorical structure?. Proceedings First International Conference Natural
Language Generation (INLG2000), Mitzpe Ramon, Israel.
Carbonell, J., & Goldstein, J. (1998). use mmr, diversity-based reranking reordering documents producing summaries. Proceedings 21st Annual
International ACM SIGIR Conference Research Development Information
Retrieval.
Cohen, W., Schapire, R., & Singer, Y. (1999). Learning order things. Journal Artificial
Intelligence, 10, 243270.
Dale, R. (1992). Generating Referring Expressions: Constructing Descriptions Domain
Objects Processes. MIT Press, Cambridge, MA.
Duboue, P., & McKeown, K. (2001). Empirically estimating order constraints content
planning generation. Proceedings ACL/EACL 2001.
53

fiBarzilay, Elhadad & McKeown

Elhadad, N., & McKeown, K. (2001). Generating patient specific summaries medical
articles. Proceedings NAACL 2001 Workshop Automatic Summarization.
Filatova, E., & Hovy, E. (2001). Assigning time-stamps event-clauses. Proceedings
AACL/EACL 2001 Workshop Temporal Spatial Information Processing.
Galil, Z., & Megido, N. (1977). Cyclic ordering np-complete. Theoretical Compter Science,
5, 179182.
Halliday, M., & Hasan, R. (1976). Cohesion English. Longman.
Hasan, R. (1984). Reading Comprehension, chap. Coherence Cohesive Harmony.
Hatzivassiloglou, V., Klavans, J., & Eskin, E. (1999). Detecting text similarity short
passages: Exploring linguistic feature combinations via machine learning. Proceedings Joint SIGDAT Conference Empirical Methods Natural Language
Processing Large Corpora.
Hearst, M. (1994). Multi-paragraph segmentation expository text. Proceedings
32th Annual Meeting Association Computational Linguistics.
Hovy, E. (1993). Automated discourse generation using discourse structure relations. Artificial Intelligence, 63. Special Issue NLP.
Jing, H. (1998). Summary generation intelligent cutting pasting input
document. Tech. rep., Columbia University.
Kan, M.-Y., Klavans, J., & McKeown, K. (1998). Linear segmentation segment
relevence. Proceedings 6th International Workshop Large Corpora
(WVLC-6).
Lin, C.-Y., & Hovy, E. (2001). Neats: multidocument summarizer. Proceedings
Document Understanding Workshop (DUC).
Mani, I., & Bloedorn, E. (1997). Multi-document summarization graph search
matching. Proceedings Fifteenth National Conference Artificial Intelligence.
Mani, I., & Wilson, G. (2000). Robust temporal processing news. Proceedings
38th Annual Meeting Association Computational Linguistics.
McCoy, K., & Cheng, J. (1991). Focus attention: Constraining said next.
Paris, C., Swartout, W., & Mann, W. (Eds.), Natural Language Generation
Artificial Intelligence Computational Linguistics. Kluwer Academic Publishers.
McKeown, K. (1985). Text Generation: Using Discourse Strategies Focus Constraints
Generate Natural Language Text. Cambridge University Press, England.
McKeown, K., Barzilay, R., Evans, D., Hatzivassiloglou, V., Kan, M., Schiffman, B., &
Teufel, S. (2001). Columbia multi-document summarization: Approach evaluation.
Proceedings Document Understanding Workshop (DUC).
McKeown, K., Klavans, J., Hatzivassiloglou, V., Barzilay, R., & Eskin, E. (1999). Towards
multidocument summarization reformulatin: Progress prospects. Proceedings Seventeenth National Conference Artificial Intelligence.
54

fiSentence Ordering Multidocument News Summarization

Mooney, D., Carberry, S., & McCoy, K. (1990). generation high-level structure
extended explanations. Proceedings International Conference Computational Linguistics (COLING90), pp. 276281, Helsinki.
Moore, J., & Paris, C. (1993). Planning text advisory dialogues: Capturing intentional
rhetorical information. Journal Computational Linguistics, 19 (4).
Radev, D., Jing, H., & Budzikowska, M. (2000). Centroid-based summarization multiple documents: sentence extraction, utility-based evaluation, user studies.
Proceedings ANLP/NAACL 2000 Workshop Automatic Summarization.
Radev, D., & McKeown, K. (1998). Generating natural language summaries multiple
on-line sources. Computational Linguistics, 24(3), 469500.
Schiffman, B., Nenkova, A., & McKeown, K. (2002). Experiments multidocument summarization. Proceedings HLT Conference.
Siegal, S., & Castellan, N. J. (1988). Non-Parametric statistics behavioural sciences.
McGraw Hill.
White, M., Korelsky, T., Cardie, C., Ng, V., Pierce, D., & Wagstaff, K. (2001). Multidocument summarization via information extraction. Proceedings HLT Conference.
Wiebe, J., OHara, T., Ohrstrom-Sandgren, T., & McKeever, K. (1998). empirical
approach temporal reference resolution. Journal Artificial Intelligence, 9, 247
293.

55


