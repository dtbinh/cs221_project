Journal Artificial Intelligence Research 24 (2005) 851-887

Submitted 08/05; published 12/05

First Probabilistic Track
International Planning Competition
Hakan L. S. Younes

lorens@cs.cmu.edu

Computer Science Department
Carnegie Mellon University
Pittsburgh, PA 15213 USA

Michael L. Littman
David Weissman
John Asmuth

mlittman@cs.rutgers.edu
dweisman@cs.rutgers.edu
jasmuth@cs.rutgers.edu

Department Computer Science
Rutgers University
Piscataway, NJ 08854 USA

Abstract
2004 International Planning Competition, IPC-4, included probabilistic planning
track first time. describe new domain specification language created
track, evaluation methodology, competition domains developed,
results participating teams.

1. Background
Fourth International Planning Competition (IPC-4) held part International Conference Planning Scheduling (ICAPS04) Vancouver, British Columbia
June 2004. request ICAPS04 organizers, Sven Koenig Shlomo Zilberstein,
asked create first probabilistic planning track part IPC-4.
overriding goal first probabilistic planning track bring together two
communities converging similar set research issues aid creating comparable tools evaluation metrics. One community consists Markov decision process
(MDP) researchers interested developing algorithms apply powerfully expressive
representations environments. consists planning researchers incorporating
probabilistic decision theoretic concepts planning algorithms. Cross fertilization begun, intent probabilistic planning track create set
shared benchmarks metrics could crystallize efforts area study.
created new domain description language called PPDDL1.0, described Section 2. PPDDL stands Probabilistic Planning Domain Definition Language, analogy PDDL (McDermott, 2000), introduced IPC-1. PPDDL modeled
PDDL2.1 (Fox & Long, 2003), domain-description language deterministic domains
used IPC-3. Syntactically, language STRIPS/ADL-like flavor, includes
probabilistic constructs. focus energy participants issues dealing uncertainty, chose include constructs durative actions PPDDL1.0.
basing domain-description language PDDL, sought remain spirit
existing planning competition, hope bring communities
c
2005
AI Access Foundation. rights reserved.

fiYounes, Littman, Weissman & Asmuth

together. PPDDL representation relational. Although representations
explicit objects traditional feature MDP-based domain-description languages,
algorithms exploit features begun appear. expected participants
propositionalize domains running planning algorithms and,
part, so.
fully functional parser PPDDL provided participants C++ form
plan validator simple planner. basic tools convert PPDDL decisiondiagram representation provided. many ways, handling rich constructs
PPDDL main hurdle many participants tried provide much
assistance could dimension.
Although PPDDL supports numerical fluents, feature used fullest
extent competition. Numerical quantities used representing reward
values, reward effects required additive.
Since classical track well established point, helpful contrast
probabilistic track differs. defining difference, course, actions
uncertain effects. is, pickup action Blocksworld might behave differently
different occasions, even state. single difference number
significant consequences. First, optimal action choices reaching goal may
function probabilistic outcomes along waya single sequence actions may
sufficient. result, difficult output plan. reason,
decided separate plan synthesis execution two phases, instead evaluated
planners online. Second, unpredictability effects, even optimal plan
reaching goal may get unlucky fail probability. reason,
evaluated planner multiple times problem include separate
optimal planner track. addition, since planners may fail reach goal state
executions, needed way trading goal attainment action
cost. decided score execution goal reward minus action cost chose goal
reward problem. Section 3 describes evaluation methodology detail.
total, designed eight domains competition (Section 4). domains
simply noisy versions classical planning domains, domains designed
specifically thwart greedy replanning approaches ignore uncertainty.
Ten planners seven different groups entered competition. results
competition presented Section 5. deterministic replanner performed best overall,
primarily due disproportionate number noisy classical planning problems
evaluation suite. domains proved challenging participating planners.
latter domains could serve basis future probabilistic planning competitions.

2. Probabilistic PDDL
section describes input language, PPDDL1.0, used probabilistic
track. PPDDL1.0 essentially syntactic extension Levels 1 2 PDDL2.1 (Fox
& Long, 2003). complete syntax PPDDL1.0 given Appendix A. assume
reader familiar PDDL2.1, focus new language features,
include probabilistic effects rewards. detailed account PPDDL1.0 provided
852

fiThe First Probabilistic Track IPC

Name
bomb-in-package package1
bomb-in-package package2
toilet-clogged
bomb-defused

Type
boolean
boolean
boolean
boolean

Init 1
true
false
false
false

Init 2
false
true
false
false

Table 1: State variables initial values Bomb Toilet problem.
Younes Littman (2004). semantics PPDDL1.0 planning problem given
terms discrete-time Markov decision process (Howard, 1960, 1971; Puterman, 1994).
2.1 Probabilistic Effects
define probabilistic decision theoretic planning problems, need add support
probabilistic effects. syntax probabilistic effects
(probabilistic p1 e1 . . . pk ek )
meaning
Pk effect ei occurs probability pi . require constraints pi 0
i=1 pi = 1 fulfilled: probabilistic effect declares exhaustive set probabilityweighted outcomes. do, however, allow probability-effect pair left
effect empty. words,
(probabilistic p1 e1 . . . pl el )


Pl

i=1 pi

< 1 syntactic sugar
(probabilistic p1 e1 . . . pl el q (and))
Pl

q = 1 i=1 pi (and) representing empty effect (that is, state changes).
example, effect (probabilistic 0.9 (clogged)) means probability 0.9
state variable clogged becomes true next state, probability 0.1
state remains unchanged.
Figure 1 shows encoding PPDDL Bomb Toilet example described
Kushmerick, Hanks, Weld (1995). requirements flag :probabilistic-effects
signals probabilistic effects used domain definition. problem,
two packages, one contains bomb. bomb defused dunking
package containing bomb toilet. 0.05 probability toilet becoming
clogged package placed it, thus rendering goal state unreachable.
problem definition Figure 1 shows initial conditions PPDDL
probabilistic. particular example, define two possible initial states equal
probability (0.5) true initial state given execution. Table 1 lists
state variables Bomb Toilet problem values two possible initial
states. Intuitively, think initial conditions PPDDL planning problem
effects action forced scheduled right time 0. Also, note
goal problem involves negation, problem definition declares
:negative-preconditions requirements flag.
853

fiYounes, Littman, Weissman & Asmuth

(define (domain bomb-and-toilet)
(:requirements :conditional-effects :probabilistic-effects)
(:predicates (bomb-in-package ?pkg) (toilet-clogged)
(bomb-defused))
(:action dunk-package
:parameters (?pkg)
:effect (and (when (bomb-in-package ?pkg)
(bomb-defused))
(probabilistic 0.05 (toilet-clogged)))))
(define (problem bomb-and-toilet)
(:domain bomb-and-toilet)
(:requirements :negative-preconditions)
(:objects package1 package2)
(:init (probabilistic 0.5 (bomb-in-package package1)
0.5 (bomb-in-package package2)))
(:goal (and (bomb-defused) (not (toilet-clogged)))))
Figure 1: PPDDL encoding Bomb Toilet example.

PPDDL allows arbitrary nesting conditional probabilistic effects (see example
Figure 2). feature contrast popular encodings, probabilistic STRIPS
operators (PSOs; Kushmerick et al., 1995) factored PSOs (Dearden & Boutilier, 1997),
allow conditional effects nested inside probabilistic effects. arbitrary
nesting add expressiveness language, allow exponentially
compact representations certain effects given set state variables
actions (Rintanen, 2003). PPDDL action can, however, translated set PSOs
polynomial increase size representation. Consequently, follows
results Littman (1997) PPDDL, grounding (that is, full instantiation
action schemata), representationally equivalent dynamic Bayesian networks (Dean
& Kanazawa, 1989), another popular representation MDP planning problems.
Still, worth noting single PPDDL action schema represent large number
actions single predicate represent large number state variables, meaning
PPDDL often represent planning problems succinctly representations. example, number actions represented using objects n
action schemata arity c nc , bounded polynomial size
original representation (m + n). Grounding means prerequisite PPDDL
planning, planners could conceivably take advantage compact representation
working directly action schemata.
2.2 Rewards
Markovian rewards, associated state transitions, encoded using fluents (numeric
state variables). PPDDL reserves fluent reward , accessed (reward) reward,
represent total accumulated reward since start execution. Rewards associated
854

fiThe First Probabilistic Track IPC

(define (domain coffee-delivery)
(:requirements :negative-preconditions
:disjunctive-preconditions
:conditional-effects :mdp)
(:predicates (in-office) (raining) (has-umbrella) (is-wet)
(has-coffee) (user-has-coffee))
(:action deliver-coffee
:effect (and (when (and (in-office) (has-coffee))
(probabilistic
0.8 (and (user-has-coffee)
(not (has-coffee))
(increase (reward) 0.8))
0.2 (and (probabilistic 0.5 (not (has-coffee)))
(when (user-has-coffee)
(increase (reward) 0.8)))))
(when (and (not (in-office)) (has-coffee))
(and (probabilistic 0.8 (not (has-coffee)))
(when (user-has-coffee)
(increase (reward) 0.8))))
(when (and (not (has-coffee)) (user-has-coffee))
(increase (reward) 0.8))
(when (not (is-wet))
(increase (reward) 0.2))))
... )

Figure 2: Part PPDDL encoding Coffee Delivery domain.

state transitions update rules action effects. use reward fluent
restricted action effects form (hadditive-opi hreward fluenti hf-expi),
hadditive-opi either increase decrease, hf-expi numeric expression involving reward . Action preconditions effect conditions allowed refer
reward fluent, means accumulated reward considered
part state space. initial value reward zero. restrictions use
reward fluent allow planner handle domains rewards without
implement full support fluents.
new requirements flag, :rewards, introduced signal support rewards
required. Domains require probabilistic effects rewards declare :mdp
requirements flag, implies :probabilistic-effects :rewards.
Figure 2 shows part PPDDL encoding coffee delivery domain described
Dearden Boutilier (1997). reward 0.8 awarded user coffee
deliver-coffee action executed, reward 0.2 awarded is-wet false
execution deliver-coffee. Note total reward 1.0 awarded
result executing deliver-coffee action execution action leads state
user -has-coffee is-wet hold.
855

fiYounes, Littman, Weissman & Asmuth

2.3 Plan Objectives
Regular PDDL goals used express goal-type performance objectives. goal statement
(:goal ) probabilistic planning problem encodes objective probability
achieving maximized, unless explicit optimization metric specified
planning problem. planning problems instantiated domain declaring
:rewards requirement, default plan objective maximize expected reward.
goal statement specification reward oriented planning problem identifies set
absorbing states. addition transition rewards specified action effects, possible
associate one-time reward entering goal state. done using (:goal-reward
f ) construct, f numeric expression.
general, statement (:metric maximize f ) problem definition means
expected value f maximized. Reward-oriented problems, example problem instance coffee-delivery domain Figure 2, would declare (:metric maximize
(reward)) optimization criterion (this declaration default :rewards
requirement specified). PPDDL defines goal-achieved special optimization
metric, used explicitly specify plan objective maximize (or
minimize) probability goal achievement. value goal-achieved fluent 1
execution ends goal state. expected value goal-achieved therefore equal
probability goal achievement. declaration (:metric maximize (goal-achieved))
takes precedence reward specifications domain problem definition,
default :rewards requirement specified (for example, Bomb
Toilet problem Figure 1).
2.4 PPDDL Semantics
completeness, present formal semantics PPDDL planning problems terms
mapping probabilistic transition system rewards. planning problem defines
set state variables V , possibly containing Boolean numeric state variables,
although consider planning problems without numeric state variables
section. assignment values state variables defines state, state space
planning problem set states representing possible assignments values
variables. addition
V , planning problem defines initial-state distribution
P
p0 : [0, 1] sS p0 (s) = 1 (that is, p0 probability distribution states),
formula G V characterizing set goal states G = {s | |= G }, one-time reward
rG associated entering goal state, set actions instantiated PPDDL
action schemata. goal-directed planning problems, without explicit rewards, use
rG = 1.
2.4.1 Probability Reward Structure
action consists precondition effect ea . Action applicable
state |= G . error apply state
6|= G . Goal states absorbing, action may applied state satisfying
G . requirement must hold order applicable consistent
semantics PDDL2.1 (Fox & Long, 2003) permits modeling forced chains
actions. Effects recursively defined follows (see also, Rintanen, 2003):
856

fiThe First Probabilistic Track IPC

1. > null-effect, represented PPDDL (and).
2. b b effects b V Boolean state variable.
3. r v, v R, effect.
4. c e effect c formula V e effect.
5. e1 en effect e1 , . . . , en effects.
6. p
1 e1 | . . . |pn en effect e1 , . . . , en effects, pi 0 {1, . . . , n},
P
n
i=1 pi = 1.
effect b sets Boolean state variable b true next state, b sets b false
next state. Effects form r v used associate rewards transitions
described below.
action = ha , ea defines transition probability matrix Pa state reward
vector Ra , Pa (i, j) probability transitioning state j applying
state i, Ra (i) expected reward executing action state i.
readily compute entries reward vector action effect formula ea . Let c
characteristic function Boolean formula c, is, c (s) 1 |= c 0
otherwise. expected reward effect e applied state s, denoted R(e; s),
computed using following inductive definition:
.
R(>; s) = 0
.
R(b; s) = 0
.
R(b; s) = 0
.
R(r v; s) = v
.
R(c e; s) = c (s) R(e; s)
n
. X
R(e1 en ; s) =
R(ei ; s)
i=1
n
. X
R(p1 e1 | . . . |pn en ; s) =
pi R(ei ; s).
i=1

factored representation probability matrix Pa obtained generating
dynamic Bayesian network (DBN) representation action effect formula ea .
use Bayesian inference DBN obtain monolithic representation Pa ,
structure factored representation exploited algorithms decision
theoretic planning (see, example, work Boutilier, Dearden, & Goldszmidt, 1995;
Hoey, St-Aubin, Hu, & Boutilier, 1999; Boutilier, Dean, & Hanks, 1999; Guestrin, Koller,
Parr, & Venkataraman, 2003).
Bayesian network directed graph. node graph represents state
variable, directed edge one node another represents causal dependence.
node associated conditional probability table (CPT). CPT state variable
Xs node represents probability distribution possible values X conditioned
values state variables whose nodes parents Xs node. Bayesian network
857

fiYounes, Littman, Weissman & Asmuth

factored representation joint probability distribution variables represented
network.
DBN Bayesian network specific structure aimed capturing temporal
dependence. state variable X, create duplicate state variable X 0 , X
representing situation present time X 0 representing situation one time
step future. directed edge present-time state variable X future-time
state variable 0 encodes temporal dependence. edges two presenttime state variables, future-time present-time state variable (the present
depend future). can, however, edge two future-time state
variables. edges, called synchronic edges, used represent correlated effects.
DBN factored representation joint probability distribution present-time
future-time state variables, transition probability matrix discrete-time
Markov process.
show generate DBN representing transition probability matrix
PPDDL action. avoid representational blowup, introduce multi-valued auxiliary
variable probabilistic effect action effect. auxiliary variables introduced indicate possible outcomes probabilistic effect occurs, allowing
representation correlate effects specific outcome. auxiliary variable
associated probabilistic effect n outcomes take n different values.
PPDDL effect e size |e| consist O(|e|) distinct probabilistic effects. Hence,
number auxiliary variables required encode transition probability matrix
action effect e O(|e|). future-time versions auxiliary
variables necessary. PPDDL problem Boolean state variables, need
order 2m + maxaA |ea | nodes DBNs representing transition probability
matrices actions.
provide compositional approach generating DBN represents transition probability matrix PPDDL action precondition effect ea . assume
effect consistent, is, b b occur outcome
overlapping conditions. DBN empty effect > simply consists 2m nodes,
present-time node X connected future-time counterpart X 0 . CPT X 0
non-zero entries Pr[X 0 = > | X = >] = 1 Pr[X 0 = | X = ] = 1.
holds reward effect r v, change value state variables.
Next, consider simple effects b b. Let Xb state variable associated
PPDDL atom b. effects, eliminate edge Xb Xb0 . CPT
Xb0 entry Pr[Xb0 = >] = 1 effect b Pr[Xb0 = ] = 1 effect b.
conditional effects, c e, take DBN e add edges presenttime state variables mentioned formula c future-time state variables
DBN e.1 Entries CPT state variable X 0 correspond settings
present-time state variables satisfy c remain unchanged. entries set
1 X true 0 otherwise (the value X change effect condition
satisfied).
DBN effect conjunction e1 en constructed DBNs
n effect conjuncts. value Pr[X 0 = > | X] DBN conjunction set
1. transformation increase size DBNs exponentially unless context-specific DBNs
used (Boutilier, Friedman, Goldszmidt, & Koller, 1996).

858

fiThe First Probabilistic Track IPC

R

R

R:
HU:
IW :
UHC:
HC:
IO:

raining
has-umbrella
is-wet
user-has-coffee
has-coffee
in-office

HU

HU

IW

IW

UHC

UHC

Aux1

HC

HC

Aux2

IO

IO

Aux3

Aux 01
1
1
1
1
1
1
1
1
2
2
2
2
2
2
2
2

IO
>
>
>
>




>
>
>
>





HC
>
>


>
>


>
>


>
>



UHC
>

>

>

>

>

>

>

>


UHC 0
>
1
0
1
0
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1

Figure 3: DBN structure (left) deliver-coffee action Coffee Delivery domain, CPT UHC 0 (the future-time version state variable
user -has-coffee) shown right.

maximum Pr[X 0 = > | X] DBNs conjuncts. maximum used
state variable set true (false) conjunctive effect set true
(false) one effect conjuncts (effects assumed consistent, result
taking maximum separate probability tables still probability table).
Finally, construct DBN probabilistic effect p1 e1 | . . . |pn en , introduce
auxiliary variable 0 used indicate one n outcomes occurred.
node 0 parents, entries CPT Pr[Y 0 = i] = pi .
Given DBN ei , add synchronic edge 0 state variables X.
value Pr[X 0 = > | X, 0 = j] set Pr[X 0 = > | X] j = 0 otherwise.
transformation repeated n outcomes, results n DBNs. DBNs
trivially combined single DBN probabilistic effect
mutually exclusive preconditions (the value Y).
example, Figure 3 shows DBN encoding transition probability matrix
deliver-coffee action, whose PPDDL encoding given Figure 2.
three auxiliary variables action effect contains three probabilistic effects.
node labeled UHC 0 (the future-time version state variable user -has-coffee) four
parents, including one auxiliary variable. Consequently, CPT node
24 = 16 rows (shown right Figure 3).
2.4.2 Optimality Criteria
shown construct MDP PPDDL encoding planning problem.
plan objective maximize expected reward MDP. objective
interpreted different ways, example expected discounted reward expected total
859

fiYounes, Littman, Weissman & Asmuth

reward. suitable interpretation depends problem. process-oriented planning problems (for example, Coffee Delivery problem), discounted reward typically
desirable, total reward often interpretation chosen goal-oriented problems
(for example, Bomb Toilet problem). PPDDL include facility
enforcing given interpretation specifying discount factor.
competition, used expected total reward optimality criterion. Without
discounting, care required design planning problems ensure
expected total reward bounded optimal policy. following restrictions
made problems used planning competition:
1. problem goal statement, identifying set absorbing goal states.
2. positive reward associated transitioning goal state.
3. negative reward (cost) associated action.
4. done action available states, could used end accumulation reward.
conditions ensure MDP model planning problem positive bounded
model (Puterman, 1994). positive reward transitioning goal state.
Since goal states absorbing (that is, outgoing transitions), maximum
value state bounded goal reward. Furthermore, done action ensures
action available state guarantees non-negative future reward.

3. Evaluation Methodology
classical planning, plan series operators. successful plan one that,
applied initial state, achieves goal. probabilistic planning, many
proposals plan representations (straight-line plans, plan trees, policy graphs, triangle
tables, example), none considered widely accepted standard. addition, even
simple plans challenging evaluate exactly non-deterministic environment,
possible outcomes need checked results combined (Littman, Goldsmith, &
Mundhenk, 1998).
reasons, chose evaluate planners simulation. is, plan validator server, individual planning algorithms acted clients. Planners connected
validator, received initial state, returned operator/action. dialog
continued terminating condition reached point validator evaluated
performance planner trajectory initial state terminating condition. entire process repeated several times results averaged multiple
runs.
evaluation scheme blurs distinction planner executor,
means computation longer one-time preprocessing cost, something integrated action selection itself. Planner quality, therefore, needs combination
expected utility running time. simplicity, set time threshold allowed
reward gathered time ran out. time threshold known competitors,
whose planners could take consideration deciding balance computation
860

fiThe First Probabilistic Track IPC

action. Since know whether participants would reuse results one trajectory speed planning next, set overall time limit applied total
repetitions evaluator given domain.
Concretely, evaluations, participants presented twenty previously unseen problems PPDDL format. evaluate problem, participants connected one
evaluation servers (at CMU Rutgers). server provided planner
initial state planner selected returned action. dialogue iterated
goal reached, time ran out, planner sent done action. value
obtained problem goal reward, goal reached, minus sum
action costs (if any). problem, procedure repeated 30 times maximum
15 minutes results averaged.
two types problems evaluation set: reward problems goal
problems. goal problems, success percentage determined participants score
problem (no action costs). reward problems, every action fixed cost. times
completion recorded, explicitly used ranking. Planners completed
less 30 runs 15 minutes given score 0 unfinished runs.
design server, believed time needed computation
planner would far outweigh possible communication delay. However, preliminary
evaluations, participantsespecially halfway across worldexperienced disruptive levels latency evaluating planners connecting remotely server.
formal evaluation, offered participants local accounts CMU nearly
availed option.
3.1 Communication Client Server
communication participants client program server took place
XML. made decision two reasons: first parsing messages
easily managed format trivial parties involvedmany solid XML parsers exist
public domain. second bandwidth great concernas mentioned
previous section, participants ran clients machine hosted
server. true excessively large messages take valuable processing
time, specific case large messages corresponded large state spaces,
took somewhat longer process altogether, XML parsing limiting
factor.
client connected server, would request certain problem run.
server would lead client running problem 30 times, sending state
problem, receiving clients action, creating new state old
state action, sending back again. Figure 4 gives schematic illustration
conversation client server. specific format XML element
described Appendix B.
Prior competition, example client written C++ distributed
participants minimize difficulties dealing nuts bolts protocol,
allowing instead focus design algorithms.
861

fiYounes, Littman, Weissman & Asmuth

client: hsession-requesti
server: hsession-initi
loop 30 rounds
client: hround-requesti
server: hround-initi
loop termination conditions
server: hstatei
client: hacti | hnoopi | hdonei
server: hend-round
server: hend-sessioni

Figure 4: interaction client (planners) server (environment) evaluation system.

3.2 Generator-Based Domains
Several example domains provided participants advance serve testbeds
parser planner development. addition, parameterized problem generators
provided two domain classesBlocksworld Boxworld, described detail
Section 4. availability domains served allow participants learn, either manually automatically, domains create domain-specific solutions.
approaches evaluated independently separate category.

4. Competition Domains
section describes domains used competition. Machine readable versions
domains found online competition Web site:
http://www.cs.rutgers.edu/mlittman/topics/ipc04-pt/
4.1 Blocksworld (Traditional)
traditional Blocksworld domain stray far original Blocksworld domain. domain consists two types objects, blocks tables. domain
exactly one table problem instance number blocks (the number
blocks problem specific). actions domain pick-up-block-from putdown-block-on. problem instance, initial configuration goal configuration
blocks given. goal problem move blocks initial configuration goal configuration. domain comes two flavors: goal version
reward version. Within reward version, cost one unit every time action
pick-up-block-from executed, reward 500 reaching goal configuration.
domains used competition, Blocksworld domain
incorporates probabilistic effects adding slip probability. is,
time block picked put down, block slip fall onto table
862

fiThe First Probabilistic Track IPC

probability 0.25. (Of course, intended action put block onto table,
effect always achieved.) Blocksworld domain extremely simple
domain, yet offers lot insight planning process. Two important features
domain are:
1. basic policy solve domain is:
(a) initial configuration, place blocks onto table block
top another block.
(b) Starting bottom up, place block place final configuration.
Note without noise, n blocks, policy takes 4n steps (2 steps
block Part 1a, 2 steps block Part 1b) hence costs 2n
units. So, basic, inexpensive way solve domain.
2. state space domain increases exponentially number blocks.
Thus, domain aims testing planners could find easy (maybe slightly
expensive) policy state space large find good policy. far
complexity domain concerned, one easier domains plan
hope many planners would quite well domain.
generation program random traditional Blocksworld domains provided
participants competition problems generated program.
availability generator allowed participants test planners many problems
liked advance evaluation.
4.2 Blocksworld (Color)
colored Blocksworld domain variant traditional Blocksworld presented above.
traditional Blocksworld, colored Blocksworld consists two types objects,
tables blocks. Again, domain exactly one table problem instance
number blocks. actions domain still pick-up-block-from
put-down-block-on, domain comes two flavors: goal reward.
major difference traditional Blocksworld domain block colored
Blocksworld domain assigned color, goal configuration specified terms
block colors rather specific blocks. Thus, general, many different valid goal
configurations. Goal conditions expressed existential quantification. example,
PPDDL fragment
(:goal (and (exists (?b1) (is-green ?b1))
(exists (?b2) (and (is-blue ?b2) (on-top-of ?b1 ?b2)))))
states goal green block top blue block.
noise colored Blocksworld domain traditional Blocksworld domain. is, colored Blocksworld domain incorporates probabilistic effects
adding slip probability. time block picked put down, block
slip fall onto table probability 0.25.
863

fiYounes, Littman, Weissman & Asmuth

Notice although goal configuration existentially quantified hence precisely specified, basic policy used solve traditional Blocksworld
used solve colored Blocksworld. solve colored Blocksworld problem,
unstack blocks then, bottom fashion, choose block satisfies
color constraint place appropriate position.
colored Blocksworld domain aims add complexity traditional Blocksworld domain incorporating existential quantification goal configuration.
indeterminacy goal colored Blocksworld domain make planning problem
considerably harder traditional counterpart. Thus, colored Blocksworld problem
may impossible given planner solve reasonable amount time, whereas
planner would problem traditional Blocksworld problem
size.2
generation program random colored Blocksworld domains provided participants competition problems generated program.
4.3 Boxworld
Boxworld domain modeled traditional logistics domain. domain consists
four types objects: cities, boxes, trucks planes. problem, graph
superimposed cities two different types edges, one denoting ability
drive one city another denoting ability fly one city
other. actions domain load-box-on-truck-in-city, unload-boxfrom-truck-in-city, load-box-on-plane-in-city, unload-box-from-plane-in-city, drivetruck fly-plane. goal reward versions domain included
evaluation. Within reward version, cost 1 unit every time either
load-box-on-truck-in-city load-box-on-plane-in-city executed, cost 5 units
every time drive-truck executed cost 25 units every time fly-plane
executed. problem instance, initial configuration determines graph
superimposed cities, identifies locations boxes, trucks planes
determines final destination box arrive. goal configuration
specifies destination every box. goal problem move initial
configuration state box destined location.
Noise enters domain action drive-truck. action executed,
desired effect achieved probability 0.8 (that is, probability 0.8 truck
end expected destination). However, probability 0.2, truck get lost
end wrong destination. city, three cities truck
may get lost trying execute drive-truck action. truck actually gets
lost end cities equal probability (that is, probability
1/3).
Blocksworld domains, generation program random Boxworld domains
provided participants competition problems generated
program.
2. important note existentially quantified goal formula colored Blocksworld,
grounded, excessively long. fact serious bottleneck larger instances domain.
Planners avoid grounding benefit here, competition
plan validator grounded goal formula.

864

fiThe First Probabilistic Track IPC

4.4 Exploding Blocksworld
exploding Blocksworld domain dead-end version traditional Blocksworld
domain described earlier. traditional Blocksworld domain, two types
objects (tables blocks) two actions (pick-up-block-from put-down-blockon). initial configuration goal configuration blocks given goal
domain move blocks initial configuration goal configuration.
key difference domain traditional Blocksworld domain
every block exploding Blocksworld domain initially set detonate. Every time
put-down-block action executed, block put yet
detonated detonate probability 0.3; noise domain.
block detonates executing put-down-block action, object beneath block
(whether table another block) destroyed longer accessible within
domain. block detonates, safe longer detonate.
exploding Blocksworld domain aims testing planners ability think ahead.
formally, actions executed possible reach state goal
cannot reached. Consider, example, executing standard Blocksworld approach
blocks unstacked table goal configuration constructed.
seven blocks unstacked, 92% (1 (1 0.3)7 ) probability
table destroyed, rendering problem unsolvable.
One strategy solving exploding Blocksworld problem never place unsafe
block top something valuable (the table block needed final stack). Instead,
block first disarmed, placing top block needed
final configuration, block exists.
illustrate strategy problem instance used planning competition, shown Figure 5. Four blocks needed goal configuration: 4, 8, 9,
10. start repeatedly picking Block 0 placing Block 9 Block 0
detonates. Next, detonate Block 1 way using Block 10. Block 0
Block 1 safe, place Block 1 table Block 0 top Block 1. completes left-most tower. stage, safe moves Blocks 4 8
clear. pick Block 6 put Block 2. last action leads failure
probability 0.3. successful, right-most tower completed. Block 8 clear
use detonate Block 3. Block 3 safely placed top Block 5. Finally,
center tower completed placing Block 7 top Block 3, result failure
probability 0.3. total, success probability given plan (1 0.3)2 = 0.49,
which, fact, optimal given problem (there action costs).
Along several test domains, exploding Blocksworld specifically designed
replanning strategy performs suboptimally (gets stuck high probability).
replanning strategy would ignore 0.3 probability detonation try replan
something unexpected happens. However, high probability approach
render goal state unreachable.
4.5 Fileworld
Fileworld fairly basic domain. consists k files n folders files
filed into. actions domain get-type (reports folder given file
865

fiYounes, Littman, Weissman & Asmuth

initial state
0
1
3
7

2
4

5

6
8

9

goal

10

0
1

7
3
5

6
2

Figure 5: Exploding Blocksworld problem used planning competition. Note
goal condition require Block 2 table.

belongs in), get-folder-Fi (one {0, . . . , n 1}, retrieves Folder filing
cabinet), file-Fi (one {0, . . . , n 1}, inserts given file Folder i)
return-Fi (one 0, . . . , n 1}, returns Folder filing cabinet).
domain comes reward version. cost 100 executing action
get-folder-Fi cost 1 executing action file-Fi. actions
explicit costs since must used conjunction get-folder-Fi file-Fi.
initial configuration problem specifies many folders (the competition
problem used 30 files 5 folders) goal configuration specifies files
must filed. Note initial configuration specify folder file go
into, files cannot filed folder; constraint noise comes
domain.
file filed, destination folder must determined. destination
folder file obtained executing action get-type file question
parameter. action executed, file passed parameter assigned folder,
folder files destination equal probability (that is, probability 1/n).
file destination folder, filed (and this) folder.
Fileworld domain tests planners ability consider strategies choose
one minimizes cost. particular, straightforward plan achieve goal
carry following series actions file turn:
1. Get type get-type
2. Get destination folder executing get-folder-Fi
3. Place file appropriate folder executing file-Fi action
4. Return folder executing return-Fi action
Although plan works, costly. cost would 101k k number
files, get-folder-Fi (expensive) file-Fi (cheap) executed every file.
less costly (in fact, optimal) plan described. first executes get-type every
file. Then, folder {0, . . . , n 1} least one file destination,
runs get-folder-Fi. Next, files every file belongs folder using file-Fi.
uses return-Fi preparation getting next folder.
866

fiThe First Probabilistic Track IPC

expected reward optimal plan 600 (100n + k), n number
folders k number files (this analysis gives 70 optimal expected reward
competition problem). domain designed reward planners able
reason initial destination uncertainty files recognize second
plan much less costly preferred straightforward brute-force plan.
4.6 Tireworld
Tireworld another domain tests planners ability plan ahead uncertainty.
domain consists one type object, namely locations. domain comes two
flavors, goal version reward version. actions common versions
move-car, load-tire change-tire. reward version, additional
action call-AAA.
Within reward version, cost 1 every time one actions move-car,
load-tire change-tire executed cost 100 every time action callAAA executed. initial configuration problem defines set locations,
superimposed graph locations (roads), subset locations representing
locations spare tires, starting location graph. goal configuration
defines destination location graph. goal problem move
starting location goal location.
noise Tireworld comes action move-car. time action
executed, car drives one city another get flat tire probability
0.15. car flat tire, cannot execute action move-car
tire fixed. car ability store one spare tire, pick
executing action load-tire location spare tire. car
holding spare tire, change-tire action invoked fix flat. However,
car currently spare action disabled. goal version,
flat tire may result dead end car gets flat carries spare tire.
reward version, planner choice executing one actions change-tire (if
car spare) call-AAA (at high cost) repair flat. Thus, reward
version, dead ends goal always reachable. Notice since cost
call-AAA large compared costs change-tire load-tire, fixing flat
always less expensive car spare tire.
Figure 6 illustrates Tireworld problem used competition. next compare
probability reaching goal state two different plans problem illustrate
ideal plan looks domain.
optimal plan would look ahead attempt keep spare tires accessible
possible avoid dead ends. start state, car must make three steps without
flat tire reach first spare cc, occur probability 0.853 0.61. Now,
car needs go four steps without getting two flats make next spare d5.
gets zero flats probability 0.854 0.52 one flat probability 4 0.853 0.15
0.37, four-step segment traversed probability 0.52 + 0.37 = 0.89 one
spare tire. three four-step segments must traversed successfully reach
ck. Finally, spare, last two steps traveled certainty. Thus, total
success probability event sequence 0.61 0.893 0.43. Note estimate
867

fiYounes, Littman, Weissman & Asmuth

spare tire
(all boxed locations)
start

goal
d6

d5

ca
c1

cn

cd

cc

c0

cm

cb
c2

ce

cf

cg

ch

ci
c6

c3

c4

cj

ck

c7 c8

c5

cl
c9
d4

d0
d1

d2

d3

Figure 6: Tireworld domain used competition.
lower bound success probability optimal strategy, factor
probability getting flat tire upon arrival state spare tire. Furthermore,
car location cf ch spare flat, unnecessary traverse
loop pick spare tire location d5 cm. accounting factors get
success probability 0.57.
contrast, greedy replanning algorithm would gather spares, since utility
comes realization something might go wrong. planner, best
plan go directly c0 c9 shortest (9-step) route. success probability
0.859 0.23, 40 percent best success probability computed above.
reward version planning problem, optimal success probability one
call-AAA action always available. However, cost action equals
reward reaching goal, always better end execution done
action repair flat tire call-AAA action. Hence, best strategy
goal version optimal reward version well gives reward
45. greedy strategy outlined would result expected reward 22.
call-AAA action used fix flat tires, expected reward drops 29.
4.7 Towers Hanoise
name suggests, domain noisy version famous Towers Hanoi
problem. domain two types objects, disks pegs. problem
used competition five disks three pegs. actions domain
single-move-big-not-moved, single-move-big-moved, double-move-big-not-moved
double-move-big-moved. action names suggest, one move either one two
868

fiThe First Probabilistic Track IPC

disks time (single-move/double-move) outcome move dependent
whether biggest disk moved yet (big-not-moved/big-moved). objective domain maximize probability reaching goal configuration (no
rewards).
initial configuration defines starting positions disks (as Towers
Hanoi, five disks stacked first peg bottom top, largest smallest
order). goal configuration defines destination positions disks (again,
destination positions Towers Hanoi, namely five disks
stacked order initial configuration last peg). goal
problem move disks starting configuration goal configuration.
actions Towers Hanoise noisy outcomes. particular, executing action
possible drop disk lost forever, thus bringing execution dead
end. success probabilities are:

Action
single-move-big-not-moved
single-move-big-moved
double-move-big-not-moved
double-move-big-moved

Success Probability
0.99
0.95
0.80
0.90

Notice probability succeeding move dependent number disks
moved whether big disk moved yet.
Every sequence actions success probability less one problem,
possible reach goal certainty. maximize probability reaching
goal, careful comparison must made. move big disk first last
peg, necessary move four smaller disks middle peg. subgoal
achieved executing single-move-big-not-moved fifteen times smaller disks,
resulting success probability 0.9915 0.86. accomplished moving
four smaller disks two units two using double-move-big-not-moved three times,
resulting low success probability approximately 0.51.
Next, big disk moved first last peg success probability
0.99 (single-move-big-not-moved). Then, four smaller disks need moved,
time middle peg last peg. big disk moved,
success probabilities change two strategies yield success probabilities 0.46
single-move-big-moved 0.73 double-move-big-moved.
planner chooses optimally step would switch single moves double
moves big disk place resulting total success probability 0.9915
0.99 0.93 0.62. One ignores probabilities always uses single moves lower
success probability 0.9915 0.99 0.9515 0.39. planner ignores probabilities
minimizes number steps always using double moves lower success probability
still 0.83 0.990.93 0.37. Thus, optimum performance, planner must realize
policy consider success probabilities actions influenced
status big disk.
869

fiYounes, Littman, Weissman & Asmuth

4.8 Zeno Travel
last domain Zeno Travel, based domain used IPC-3. Problem instances
domain involve using airplanes move people cities. airplane requires fuel fly. flown two different speedsthe higher speed requiring
fuel. problem instance used one aircraft, two people, three cities seven
fuel levels. actions domain start-boarding, complete-boarding, startdebarking, complete-debarking, start-refueling, complete-refueling, start-flying,
complete-flying, start-zooming, complete-zooming. initial configuration
specifies location plane, initial fuel level plane location
people (as well initializations allow arithmetic type operations
fuel-level objects). goal configuration specifies destination plane destinations people. noise domain comes family complete-X
actions. time complete-X action executed desired effect
probability 1/k positive integer k (note k function action executed, specifically k = 20 complete-boarding k = 30 complete-debarking).
desired effect achieved effect, occurs probability
1 (1/k). structure meant represent actions random duration. durative action X represented two primitive actions start-X complete-X, giving
X duration geometrically distributed.
Ultimately, problem presented real challenge neglected include
action costs. Since actions either standard desired effect none all, planner
simple continue execute action effect achieved, without incurring cost.

5. Competition Results
Based initial announcement competition, put together mailing list
87 researchers expressing interest. development PPDDL, server, evaluation
criteria, practice domains progressed, kept community informed releasing
series FAQs (May 2003, FAQ 0.1; September 2003, FAQ 0.5; November 2003 FAQ 1.01).
early 2004, core group participants became evident competition logistics
finalized. Leading June 2004, participants ran planners previously
unseen test problems. tabulated scores set evaluation categories
presented ICAPS04 Vancouver, Canada.
following subsections describe competitions participants, evaluation tracks,
results.
5.1 Participants
Although twenty teams registered competition initially, seven teams four continents ultimately competed. produced ten different planners, evaluated
various subsets problem domains. groups planners were:
Group C. UMass
Participants: Zhengzhu Feng (University Massachusetts) Eric Hansen (Mississippi State University).
870

fiThe First Probabilistic Track IPC

Description: Symbolic heuristic search.
Group E. Dresden (FluCaP, formerly FCPlanner)
Participants: Eldar Karabaev Olga Skvortsova (both Dresden University
Technology).
Description: First-order heuristic search.
Group G. ANU (NMRDPP)
Participants: Charles Gretton, David Price Sylvie Thiebaux (all Australian
National University).
Descriptions: G1: Planner primarily designed domains non-Markovian rewards, G2: NMRDPP augmented control knowledge.
Group J. Purdue
Participants: SungWook Yoon, Alan Fern Robert Givan (all Purdue University).
Descriptions: J1: Human-written policy Classys policy language (Purdue-Humans), J2: Offline policy iteration reduction classification, automatically acquiring domain-specific policy (Classy), J3: Deterministic replanner using
(FF-rePlan).
Group P. Simon Bolvar (mGPT)
Participants: Blai Bonet (Universidad Simon Bolvar) Hector Geffner (Universitat
Pompeu Fabra).
Description: Labeled RTDP lower bounds extracted problem description.
Group Q. Michigan Tech (Probapop)
Participants: Nilufer Onder, Garrett C. Whelan Li Li (all Michigan Technological University).
Description: POP-style planner (no sensing).
Group R. CERT
Participants: Florent Teichteil-Konigsbuch Patrick Fabiani (both CERT).
Description: Probabilistic reachability heuristic DBNs.
5.2 Evaluation Tracks
clear discussions leading competition different groups
prioritizing efforts differently. wanted ensure diverse set powerful
approaches recognized decided tabulate results several different ways
acknowledge value different approaches. six tracks were:
871

fiYounes, Littman, Weissman & Asmuth

Overall. track used reward-based evaluation criterion domains (goal
achievement counted 500 goal-based domains). Domains: Blocksworld (7 problems), Colored Blocksworld (2), Boxworld (5), Exploding Blocksworld (1), Fileworld
(1), Tireworld (2), Towers Hanoise (1), Zeno Travel (1).
Goal-based. track, ignored action costs counted goal achievement
unit reward (thus emphasizing approaches maximized probability
reaching goal state). domains problems used
Overall track: Blocksworld (7), Colored Blocksworld (2), Boxworld (5), Exploding
Blocksworld (1), Fileworld (1), Tireworld (2), Towers Hanoise (1), Zeno Travel (1).
Overall, Non-Blocks/Box. Blocksworld Boxworld dominated full set
wanted see subtler problems handled. Domains: Exploding
Blocksworld (1), Fileworld (1), Tireworld (2), Towers Hanoise (1), Zeno Travel (1).
Domain-specific. Domain-specific allowed human-tuned rules; Domain-specific,
Tuning (only automatically generated rules specific domain
allowed). evaluated using generated domains: Blocksworld (8), Colored
Blocksworld (6), Boxworld (5).
Conformant. Planners category produce straight-line plans, blind
intermediate states encountered. prepared unobservable versions domains
evaluate planners category. Domains: Blocksworld (7), Colored Blocksworld
(2), Boxworld (5), Exploding Blocksworld (1), Fileworld (1), Tireworld (2), Towers
Hanoise (1), Zeno Travel (1).
5.3 Results
display results evaluation track, plotted cumulative reward achieved
participant set evaluation problems (reward accumulated left right).
reward-based tracks, goal achievement counted 500 problems without
explicitly specified goal reward. plots highlight one planner advantage
another (greater slope) well total difference score (height difference
lines).
Figure 7 displays results Overall category. Two planners, J3 P, produced
significantly positive results others, replanning algorithm J3 clearly
dominating others. J3 crowned Overall winner, P runner up. figure
displays results Conformant category, consisted solely Q,
uncontested winner category.
Similar results visible Goal-based track, displayed Figure 8, J3
comes ahead P achieving runner-up status. Comparing Figures 7 8
reveals margin victory J3 P, R G1 diminished Goalbased category. suggests J3 sensitive rewards themselveschoosing
cheaper paths among multiple paths available goal. set problems used
competition, distinction significant graphs look similar.
However, different set test problems might revealed fundamental tradeoff
872

fi873
Zeno Travel

Tower Hanoise

Tireworld (reward)

Tireworld (goal)

Fileworld

Exploding Blocksworld

Boxworld (10, 10; goal)

Boxworld (5, 10; goal)

Boxworld (15, 10)

Boxworld (10, 10)

Boxworld (5, 10)

Colored Blocksworld (8; goal)

Colored Blocksworld (8)

Blocksworld (8; goal)

Blocksworld (21)

Blocksworld (18)

Blocksworld (15)

5000

Blocksworld (11)

Blocksworld (8)

Blocksworld (5)

cumulative reward

First Probabilistic Track IPC

J3
P
C
G1
R
Q

4000

3000

2000

1000

0

Figure 7: Competition results Overall category. result Conformant category line marked Q. numbers parentheses indicate problem size:
number blocks Blocksworld domains; number cities boxes, respectively, Boxworld domains.

fiYounes, Littman, Weissman & Asmuth

J3
P
C
G1
R
Q

14

cumulative goal probability

12

10

8

6

4

2

Zeno Travel

Tower Hanoise

Tireworld (reward)

Tireworld (goal)

Fileworld

Exploding Blocksworld

Boxworld (10, 10; goal)

Boxworld (5, 10; goal)

Boxworld (15, 10)

Boxworld (10, 10)

Boxworld (5, 10)

Colored Blocksworld (8; goal)

Colored Blocksworld (8)

Blocksworld (8; goal)

Blocksworld (21)

Blocksworld (18)

Blocksworld (15)

Blocksworld (11)

Blocksworld (8)

Blocksworld (5)

0

Figure 8: Competition results Goal-based category.
seeking maximize reward seeking reach goal high probability.
Future competitions could attempt highlight important issue.
interesting note J3s outstanding performance stems primarily
early problems, Blocksworld Boxworld problems amenable
replanning. later problems set handled well J3
planners.
Figure 9 displays results Non-Block/Box category. Indeed, J3 performed
much poorly problems category, Planner C taking top spot.
runner-up spot closely contested planners R G1, G1 pulled ahead
last problem claim honors. Planner P performed nearly well
set.
Figure 10 gives detailed view results Non-Blocks/Box category.
optimal score problem indicated graphs.3 Note Planner Cs
performance Tireworld domain well optimal, result now-fixed bug
competition server allowed disabled actions executed. Planner P displayed
outstanding performance Fileworld goal-based Tireworld problems,
attempt solve Tower Hanoise therefore fell behind G1 R overall. Planner R
used time per round Planner G1 Zeno Travel domain, ultimately
cost R second place could complete 27 30 runs domain.
Note planners received negative score reward-oriented problems.
3. optimal scores necessarily apply Planner Q, conformant planner.

874

fiThe First Probabilistic Track IPC

C
G1
R
P
J3
Q

1000

cumulative reward

800

600

400

200

Zeno Travel

Tower Hanoise

Tireworld (reward)

Tireworld (goal)

Fileworld

Exploding Blocksworld

0

Figure 9: Summary competition results Overall, Non-Blocks/Box category.
counted negative scores individual problems zero overall evaluation
give advantage planners even attempt solve problems. Planner Q
entrant (except, possibly, C) receive positive score reward-based
Tireworld problem. planners negative score problem used expensive
call-AAA action ensure goal always reached.
results domain-specific planners shown Figure 11. highest scoring
planners J1 G2, difference primarily due two largest
Blocksworld problems, J1 solved effectively G2. performance
five domain-specific planners colored Blocksworld problems virtually indistinguishable. mentioned earlier, grounding goal condition validator prevented us
using larger problem instances, might otherwise separated planners
domain.
two planners domain specific category ineligible
tuning subcategory hand-tuned domains. Thus, J3 J2
took top spots subcategory. interesting note J3 spite
general-purpose plannerit not, fact, created domain specific. overtook
J2 due two small Boxworld problems J3 solved J2 missed.
Figure 12 summarizes competition results six evaluation categories.

6. Conclusion
happy outcomes first probabilistic track International Planning
Competition. addition bringing attention important set planning challenges,
875

fiYounes, Littman, Weissman & Asmuth

Exploding Blocksworld

Tireworld (goal)

1

1

**
max prob.

0.8

goal probability

0.6
0.4
0.2
0

0.8
0.6
0.4
0.2

*
C

G1

*
P

J3

*
Q

*
R

0
C

1

100
*

*

*

0
-100

prob.
max prob.
reward
max reward
G1

J3

Q

R

P

Q

prob.
max prob.
reward
max reward

0.8

200

C

P

**

300
goal probability

1
0.8
0.6
0.4
0.2
0

J3

Tireworld (reward)

reward

goal probability

Fileworld

G1

0.6

80
60

0.4

40

0.2

20

0

-200

reward

goal probability

max prob.

0

-300

-20

-400
R

C

G1

Tower Hanoise

J3

P

Q

R

Zeno Travel
max prob.

1

1

0.8

goal probability

goal probability

max prob.

0.6
0.4
0.2
0

0.8
0.6
0.4
0.2

*
C

G1

J3

*
P

*
Q

0
R

C

G1

J3

P

Q

R

Figure 10: Competition results Non-Blocks/Box problems (* indicates planner
attempt solve problem; ** indicates anomalous results due bug
server allowed execution disabled actions). Note two
graphs center reward scales right.

876

fiThe First Probabilistic Track IPC

J1*
G2*
J3
J2
E*

8000
7000

cumulative reward

6000
5000
4000
3000
2000
1000

Boxworld (10, 10; goal)

Boxworld (5, 10; goal)

Boxworld (15, 10)

Boxworld (10, 10)

Boxworld (5, 10)

Colored Blocksworld (11; goal)

Colored Blocksworld (8; goal)

Colored Blocksworld (5; goal)

Colored Blocksworld (11)

Colored Blocksworld (8)

Colored Blocksworld (5)

Blocksworld (8; goal)

Blocksworld (21)

Blocksworld (18)

Blocksworld (15)

Blocksworld (11)

Blocksworld (8)

Blocksworld (5)

0

Figure 11: Competition results Domain-specific categories. Tuning
category results, ignore J1, G2, E lines graph (marked
asterisks).

Category
Overall
Goal-based Domains
Overall, Non-Blocks/Box
Domain-specific, Tuning
Domain-specific
Conformant

1st
J3
J3
C
J3
J1
Q

2nd
P
P
G1
J2
G2

Figure 12: Summary competition results category.

877

fiYounes, Littman, Weissman & Asmuth

appears helped spur community use uniform comparison problems
providing domain language set benchmarks (Yoon, Fern, & Givan, 2005).
spite success, feel changes could made future competitions would increase value community. First, competition logistics
side, server logged outcomes interactions planners domains,
keep exhaustive record actions taken timing information. retrospect,
information would helpful identifying planners addressed
domains whether took suboptimal actions got unlucky. addition,
server provisions security. simple password and/or reservation system would
helped evaluations go much smoothly would prevented inadvertent
access server one group another assigned evaluation slot.
domain side, hope future competitions able focus interesting
domains. found simply adding noisy action failures deterministic domain
enough produce interesting probabilistic problemsfor domains, straightforward replanning effective. non-Blocksworld domains created
mastered planners hope retained form future
evaluations.
progression competitions classical track, hope future competitions
probabilistic track move toward domains grounded real-life data real-world
problems including handling partially observability time. second competition
slated held conjunction IPC 2006 urge interested members
planning community participate help keep competition moving productive
direction benefit field.

Acknowledgments
appreciate support National Science Foundation Royal Swedish
Academy Engineering Sciences, well feedback Sven Koenig, Shlomo Zilberstein, Paul Batchis, Bob Givan, Hector Geffner participants contributed
design competition. JAIR editor David Smith anonymous reviewers provided invaluable insights document tried reflect final manuscript.
material based upon work supported National Science Foundation
Grant No. 0315909 Royal Swedish Academy Engineering Sciences (IVA)
grants Hans Werthen fund. opinions, findings, conclusions recommendations expressed material author(s) necessarily reflect
views National Science Foundation IVA.

878

fiThe First Probabilistic Track IPC

Appendix A. BNF Grammar PPDDL1.0
provide full syntax PPDDL1.0 using extended BNF notation following conventions:
rule form hnon-terminal ::= expansion.
Alternative expansions separated vertical bar (|).
syntactic element surrounded square brackets ([ ]) optional.
Expansions optional syntactic elements superscripted requirements flag
available requirements flag specified domain problem currently
defined. example, [htypes-def i]:typing syntax domain definitions
means htypes-def may occur domain definitions include :typing
flag requirements declaration.
asterisk (*) following syntactic element x means zero occurrences
x ; plus (+ ) following x means least one occurrence x.
Parameterized non-terminals, example htyped list (x )i, represent separate rules
instantiation parameter.
Terminals written using typewriter font.
syntax Lisp-like. particular, case significant (for example, ?x ?X
equivalent), parenthesis essential part syntax semantic
meaning extended BNF notation, number whitespace characters
(space, newline, tab, etc.) may occur tokens.
A.1 Domains
syntax domain definitions PDDL2.1, except durative actions
allowed. Declarations constants, predicates, functions allowed
order respect one another, must come type declarations
precede action declarations.
hdomaini

hrequire-def
hrequire-keyi
htypes-def
hconstants-def
hpredicates-def

::= ( define ( domain hnamei )
[hrequire-def i]
[htypes-def i]:typing
[hconstants-def i]
[hpredicates-def i]
[hfunctions-def i]:fluents
hstructure-def i* )
::= ( :requirements hrequire-keyi* )
::= See Section A.4
::= ( :types htyped list (name)i )
::= ( :constants htyped list (name)i )
::= ( :predicates hatomic formula skeletoni* )
879

fiYounes, Littman, Weissman & Asmuth

hatomic formula skeletoni
hpredicatei
hfunctions-def
hfunction skeletoni
hfunction symbol
hstructure-def
haction-def
htyped list (x )i
htypei
hprimitive typei
hfunction typed list (x )i
hfunction typei

::= ( hpredicatei htyped list (variable)i )
::= hnamei
::= ( :functions hfunction typed list (function skeleton)i )
::= ( hfunction symbol htyped list (variable)i )
::= hnamei
::= haction-def
::= See Section A.2
::= hx i* |:typing hx i+ - htypei htyped list (x )i
::= ( either hprimitive typei+ ) | hprimitive typei
::= hnamei
::= hx i*
|:typing hx i+ - hfunction typei hfunction typed list (x )i
::= number

hnamei string characters starting alphabetic character followed
possibly empty sequence alphanumeric characters, hyphens (-), underscore characters ( ). hvariablei hnamei immediately preceded question mark (?).
example, in-office ball 2 names, ?gripper variable.
A.2 Actions
Action definitions goal descriptions syntax PDDL2.1.
haction-def

::= ( :action haction symbol
[:parameters ( htyped list (variable)i )]
haction-def bodyi )
haction symbol
::= hnamei
haction-def bodyi
::= [:precondition hGDi]
[:effect heffecti]
hGDi
::= hatomic formula (term)i | ( hGDi* )
|:equality ( = htermi htermi )
|:equality ( ( = htermi htermi ) )
|:negative-preconditions ( hatomic formula (term)i )
|:disjunctive-preconditions ( hGDi )
|:disjunctive-preconditions ( hGDi* )
|:disjunctive-preconditions ( imply hGDi hGDi )
|:existential-preconditions ( exists ( htyped list (variable)i )
hGDi )
|:universal-preconditions ( forall ( htyped list (variable)i )
hGDi )
|:fluents hf-compi
hatomic formula (x )i ::= ( hpredicatei hx i* ) | hpredicatei
htermi
::= hnamei | hvariablei
hf-compi
::= ( hbinary-compi hf-expi hf-expi )
hbinary-compi
::= < | <= | = | >= | >
hf-expi
::= hnumber | hf-head (term)i
880

fiThe First Probabilistic Track IPC

hf-head (x )i
hbinary-opi

| ( hbinary-opi hf-expi hf-expi ) | ( - hf-expi )
::= ( hfunction symbol hx i* ) | hfunction symbol
::= + | - | * | /

hnumber sequence numeric characters, possibly single decimal point (.)
position sequence. Negative numbers written (- hnumber i).
syntax effects extended allow probabilistic effects,
arbitrarily interleaved conditional effects universal quantification.
heffecti

::= hp-effecti | ( heffecti* )
|:conditional-effects ( forall ( htyped list (variable)i ) heffecti )
|:conditional-effects ( hGDi heffecti )
|:probabilistic-effects ( probabilistic hprob-effecti+ )
hp-effecti
::= hatomic formula (term)i | ( hatomic formula (term)i )
|:fluents ( hassign-opi hf-head (term)i hf-expi )
|:rewards ( hadditive-opi hreward fluenti hf-expi )
hprob-effecti
::= hprobabilityi heffecti
hassign-opi
::= assign | scale-up | scale-down | hadditive-opi
hadditive-opi ::= increase | decrease
hreward fluenti ::= ( reward ) | reward

hprobabilityi hnumber value interval [0, 1].
A.3 Problems
syntax problem definitions extended allow specification
probability distribution initial states, permit association one-time
reward entering goal state. otherwise identical syntax PDDL2.1
problem definitions.
hproblemi

hobjects-def
hiniti
hinit-el
hp-init-el
hprob-init-el
ha-init-el
hgoal
hgoal-speci
hmetric-speci

::= ( define ( problem hnamei )
( :domain hnamei )
[hrequire-def i]
[hobjects-def i]
[hiniti]
hgoal )
::= ( :objects htyped list (name)i )
::= ( :init hinit-el i* )
::= hp-init-el
|:probabilistic-effects ( probabilistic hprob-init-el i* )
::= hatomic formula (name)i |:fluents ( = hf-head (name)i hnumber )
::= hprobabilityi ha-init-el
::= hp-init-el | ( hp-init-el i* )
::= hgoal-speci [hmetric-speci] | hmetric-speci
::= ( :goal hGDi ) [( :goal-reward hground-f-expi )]:rewards
::= ( :metric hoptimizationi hground-f-expi )
881

fiYounes, Littman, Weissman & Asmuth

hoptimizationi ::= minimize | maximize
hground-f-expi ::= hnumber | hf-head (name)i
| ( hbinary-opi hground-f-expi hground-f-expi )
| ( - hground-f-expi )
| ( total-time ) | total-time
| ( goal-achieved ) | goal-achieved
|:rewards hreward fluenti
A.4 Requirements
table requirements PPDDL1.0. requirements imply others;
abbreviations common sets requirements. domain stipulates requirements,
assumed declare requirement :strips.
Requirement
:strips
:typing
:equality
:negative-preconditions
:disjunctive-preconditions
:existential-preconditions
:universal-preconditions
:quantified-preconditions
:conditional-effects
:probabilistic-effects
:rewards
:fluents
:adl

:mdp

Description
Basic STRIPS-style adds deletes
Allow type names declarations variables
Support = built-in predicate
Allow negated atoms goal descriptions
Allow disjunctive goal descriptions
Allow exists goal descriptions
Allow forall goal descriptions
= :existential-preconditions
+ :universal-preconditions
Allow forall action effects
Allow probabilistic action effects
Allow reward fluent action effects
optimization metric
Allow numeric state variables
= :strips + :typing + :equality
+ :negative-preconditions
+ :disjunctive-preconditions
+ :quantified-preconditions
+ :conditional-effects
= :probabilistic-effects + :rewards

882

fiThe First Probabilistic Track IPC

CLIENT

SERVER

/ session-request \
\
/
/ session-init \
\
/

/ round-request \
\
/
/ round-init \
\
/

/ state \
\
/
/ action
\

spec \/

..
.
/ state \
\
/
/ action
\

spec \/

/ end-round \
\
/










repeat










/ end-session \
\
/

Figure 13: Successful communication session.

Appendix B. Communication Protocol
adopt XML-like syntax client/server communication protocol. use
extended BNF notation Appendix describe syntax protocol messages.
hnamei hnumber terminals defined exactly way PPDDL.
hinteger nonempty string numeric characters. hmessagei arbitrary character
string, possibly empty.
Figure 13 shows expected sequence messages. session starts client
sending hsession-requesti message server. server replies hsession-initi
message, tells client number evaluation rounds run. start
evaluation round, client sends hround-requesti message, server replies
hround-initi message. point evaluation round starts. server sends
hturn-responsei message client, hstatei message hend-round
message. every hstatei message client receives, sends haction speci message
return. client receives hend-round message, ends current evaluation
round. client starts new evaluation round hround-requesti message
server, waits hend-sessioni message server case rounds
already run. server sends herror message client error occurs,
example server receives unexpected message client.
883

fiYounes, Littman, Weissman & Asmuth

B.1 Client Messages
Client messages following form:
hsession-requesti ::= <session-request>
<name> hnamei </name>
<problem> hnamei </problem>
</session-request>
hround-requesti

::= <round-request/>

haction speci
hactioni
htermi

::= <act> hactioni </act> | <done/>
::= <action> <name> hnamei </name> htermi* </action>
::= <term> hnamei </term>

B.2 Server Messages
Server messages following form:
hsession-initi

::= <session-init>
<sessionID> hinteger </sessionID>
<setting>
<rounds> hinteger </rounds>
<allowed-time> hinteger </allowed-time>
<allowed-turns> hinteger </allowed-turns>
</setting>
</session-init>

hround-initi

::= <round-init>
<round> hinteger </round>
<sessionID> hinteger </sessionID>
<time-left> hinteger </time-left>
<rounds-left> hinteger </rounds-left>
</round-init>

hturn-responsei ::= hstatei | hend-round
hend-round
::= <end-round>
hstatei [<goal-reached/>]
<time-spent> hinteger </time-spent>
<turns-used> hinteger </turns-used>
</end-round>
hstatei
::= <state> [<is-goal/>] hatomi* hfluenti* </state>
hatomi
::= <atom> hpredicatei htermi* </atom>
hfluenti
::= <fluent> hfunctioni htermi* hvaluei </fluent>
hpredicatei
::= <predicate> hnamei </predicate>
hfunctioni
::= <function> hnamei </function>
htermi
::= <term> hnamei </term>
884

fiThe First Probabilistic Track IPC

hvaluei

::= <value> hnumber </value>

hend-sessioni

::= <end-session>
<sessionID> hinteger </sessionID>
<problem> hnamei </problem>
<rounds> hinteger </rounds>
<goals>
<failed> hinteger </failed>
<reached>
<successes> hinteger </successes>
[<time-average> hnumber </time-average>]
</reached>
</goals>
[<metric-average> hnumber </metric-average>]
</end-session>

herror

::= <error> hmessagei </error>

885

fiYounes, Littman, Weissman & Asmuth

References
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,
11, 194.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Mellish, C. S. (Ed.), Proceedings Fourteenth International Joint
Conference Artificial Intelligence, pp. 11041111, Montreal, Canada. Morgan Kaufmann Publishers.
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence Bayesian networks. Proceedings Twelfth Annual Conference
Uncertainty Artificial Intelligence (UAI 96), pp. 115123, Portland, OR.
Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.
Computational Intelligence, 5 (3), 142150.
Dearden, R., & Boutilier, C. (1997). Abstraction approximate decision-theoretic planning. Artificial Intelligence, 89 (12), 219283.
Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporal
planning domains. Journal Artificial Intelligence Research, 20, 61124.
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithms
factored MDPs. Journal Artificial Intelligence Research, 19, 399468.
Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning using
decision diagrams. Laskey, K. B., & Prade, H. (Eds.), Proceedings Fifteenth
Conference Uncertainty Artificial Intelligence, pp. 279288, Stockholm, Sweden.
Morgan Kaufmann Publishers.
Howard, R. A. (1960). Dynamic Programming Markov Processes. John Wiley & Sons,
New York, NY.
Howard, R. A. (1971). Dynamic Probabilistic Systems, Vol. I: Markov Models. John Wiley
& Sons, New York, NY.
Kushmerick, N., Hanks, S., & Weld, D. S. (1995). algorithm probabilistic planning.
Artificial Intelligence, 76 (12), 239286.
Littman, M. L. (1997). Probabilistic propositional planning: Representations complexity. Proceedings Fourteenth National Conference Artificial Intelligence,
pp. 748754, Providence, RI. American Association Artificial Intelligence, AAAI
Press.
Littman, M. L., Goldsmith, J., & Mundhenk, M. (1998). computational complexity
probabilistic planning. Journal Artificial Intelligence Research, 9, 136.
McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine, 21 (2),
3555.
Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, New York, NY.
886

fiThe First Probabilistic Track IPC

Rintanen, J. (2003). Expressive equivalence formalisms planning sensing.
Giunchiglia, E., Muscettola, N., & Nau, D. S. (Eds.), Proceedings Thirteenth International Conference Automated Planning Scheduling, pp. 185194, Trento,
Italy. AAAI Press.
Yoon, S., Fern, A., & Givan, R. (2005). Learning measures progress planning domains.
Proceedings Twentieth National Conference Artificial Intelligence, pp.
12171222.
Younes, H. L. S., & Littman, M. L. (2004). PPDDL1.0: extension PDDL expressing
planning domains probabilistic effects. Tech. rep. CMU-CS-04-167, Carnegie
Mellon University, Pittsburgh, PA.

887


