Journal Artificial Intelligence Research 41 (2011) 1-24

Submitted 10/2010; published 05/2011

Properties Bethe Free Energies Message Passing
Gaussian Models
Botond Cseke
Tom Heskes

b.cseke@science.ru.nl
t.heskes@science.ru.nl

Institute Computing Information Sciences
Faculty Science, Radboud University Nijmegen
Heyendaalseweg 135, 6525 AJ, Netherlands

Abstract
address problem computing approximate marginals Gaussian probabilistic
models using mean field fractional Bethe approximations. define Gaussian fractional Bethe free energy terms moment parameters approximate
marginals, derive lower upper bound fractional Bethe free energy
establish necessary condition lower bound bounded below. turns
condition identical pairwise normalizability condition, known
sufficient condition convergence message passing algorithm. show
stable fixed points Gaussian message passing algorithm local minima
Gaussian Bethe free energy. counterexample, disprove conjecture stating
unboundedness free energy implies divergence message passing
algorithm.

1. Introduction
One major tasks probabilistic inference calculating marginal posterior probabilities set variables given observations. case Gaussian models,
computational complexity computing marginals might scale cubically number
variables, models discrete variables often leads intractable computations.
Computations made faster tractable using approximate inference methods
mean field approximation (e.g., Jaakkola, 2000) Bethe-type approximation (e.g.,
Yedidia, Freeman, & Weiss, 2000). methods developed discrete probabilistic
graphical models, applicable Gaussian models well. However,
important differences behavior discrete Gaussian cases. example,
discrete models error function Bethe approximationcalled Bethe free
energyis bounded (Heskes, 2004; Watanabe & Fukumizu, 2009), Gaussian
models might always case (Welling & Teh, 2001).
understanding properties Bethe free energy Gaussian models might
help understand properties energy function conditional Gaussian
models. Conditional Gaussian hybrid graphical models, switching Kalman filters
(Zoeter & Heskes, 2005), combine discrete Gaussian variables. Approximate
inference models carried expectation propagation (e.g., Minka, 2004,
2005) viewed generalization Bethe approximation,
marginal consistency constraints approximate marginals replaced expectation
constraints (Heskes, Opper, Wiegerinck, Winther, & Zoeter, 2005). order understand
c
2011
AI Access Foundation. rights reserved.

fiCseke & Heskes

properties Bethe free energy hybrid models, good understanding two
special cases discrete Gaussian models needed. properties Bethe
free energy discrete models studied extensively last decade well
understood (Yedidia et al., 2000; Heskes, 2003; Wainwright, Jaakkola, & Willsky, 2003;
Watanabe & Fukumizu, 2009), properties Gaussian Bethe free energy
studied much less.
message passing algorithm well established method finding stationary
points Bethe free energy (Yedidia et al., 2000; Heskes, 2003). works locally
updating approximate marginals successfully applied discrete (e.g.,
Murphy, Weiss, & Jordan, 1999; Wainwright et al., 2003) Gaussian models (e.g., Weiss
& Freeman, 2001; Rusmevichientong & Roy, 2001; Malioutov, Johnson, & Willsky, 2006;
Johnson, Bickson, & Dolev, 2009; Nishiyama & Watanabe, 2009; Bickson, 2009). Gaussian
message passing simplest case free-energy based message passing algorithm
models continuous variables, therefore, important understand behavior.
Gaussian message passing many practical applications distributed averaging
(Moallemi & Roy, 2006), peer-to-peer rating, linear detection, SVM regression (Bickson,
2009) generally problems involve solving large sparse linear systems
approximating marginal variances large sparse Gaussian systems typically encountered distributed computing settings. applications reader referred
work Bickson (2009) references therein.
Finding sufficient conditions convergence message passing Gaussian models
successfully addressed many authors. Using computation tree approach,
Weiss Freeman (2001) proved message passing converges whenever precision
matrixinverse covarianceof probability distribution diagonally dominant1 .
help analogy message passing walksum analysis, (Malioutov et al.,
2006) derived stronger condition pairwise normalizability2 . different approach
taken Welling Teh (2001), directly minimized Bethe free energy regard
parameters approximate marginals, conjecturing Gaussian message passing
converges free energy bounded below. experiments showed
message passing direct minimization either converge solution
fail converge. adopt similar approach, is, instead analyzing properties
Gaussian message passing algorithm using approaches Weiss Freeman
Malioutov et al., choose study properties Gaussian Bethe free energy
stationary points. help us draw conclusions existence local
minima, possible stable fixed points message passing converge.
paper structured follows. Section 2 introduce Gaussian Markov random
fields message passing algorithm. Section 3 define Gaussian fractional
Bethe free energies parameterized moment parameters approximate marginals
derive boundedness conditions them. two sections based authors
earlier work (Cseke & Heskes, 2008). Section 4 analyze stability properties
Gaussian message passing algorithm and, using similar line argument Watanabe
P
1. matrix diagonally dominant |Aii | > j6=i |Aij | i.
2. Following work Malioutov et al. (2006), call Gaussian distribution pairwise normalizable

Q
factorized product normalizable pair factors, is, p(x1 , . . . , xn ) = ij ij (xi , xj )
ij normalizable.

2

fiBethe Free Energies Message Passing Gaussian Models

Fukumizu (2009), show stable fixed points indeed local minima Bethe
free energy. conclude paper experiments Sections 5 6 supporting
results implications.

2. Approximating Marginals Gaussian Models
probability density Gaussian random vector x Rn defined terms canonical
parameters h Q


1

p(x) exp h x x Qx ,
(1)
2
Q positive definite matrix. expectation covariance V x
given = Q1 h V = Q1 respectively. many real world applications
matrix Q sparse typically low density, is, number non-zero
elements Q scales number variables n.
probability density defined terms undirected probabilistic
graphical model commonly known Gaussian Markov random field (GMRF). Since
interactions variables p pairwise, associate variables xi
nodes v V = {1, . . . , n} undirected graph G = (V, E), edges e E V V
graph stand non-zero off-diagonal elements Q. use j proxy
(i, j) E. using notation introduced above, density p (1) written
product

p(x)
ij (xi , xj )
(2)
ij

Gaussian functions ij (xi , xj ) (also called potentials) associated edges e = (i, j)
graph. h Q given define potentials
j
j


ij (xi , xj ) = exp {ij
hi xi + ij
hj xj ij
Qii x2i /2 ij
Qjj x2j /2 Qij xi xj } ,

P
P
j


ij ij = 1
ji ij = 1 partitioning h Q corresponding
factors. practice, however, factors ij might given problem hand
j computed summing parameters computing
h Q well ij
ij
partitioning respectively. Without loss generality, use Qii = 1, since
results paper easily re-formulated general Qs rescaling
variables (e.g., Malioutov et al., 2006).
numerical calculation marginals, done solving linear system
= Q1 h performing sparse Cholesky factorization LLT = Q followed solving Takahashi equations (Takahashi, Fagan, & Chin, 1973). alternative option
calculate marginal means approximate marginal variances run Gaussian message passing algorithm probabilistic graphical model associated
representation (2). Gaussian message passing algorithm Gaussian variant
message passing algorithm (Pearl, 1988), dynamical programming algorithm
introduced compute marginal densities discrete probabilistic models pairwise interactions tree-structured graphs G. However, turned running loops
graphs cycles, yields good approximations marginal distributions (Murphy
et al., 1999). Weiss Freeman (2001) showed Gaussian message passing
3

fiCseke & Heskes

Figure 1: illustration incoming outgoing messages adjacent nodes j.

algorithm converging, computes exact mean parameters m, thus
used solving linear systems (e.g., Bickson, 2009). Message passing works updating
passing directed messages along edges graph G, which, case algorithm
converges, used compute (approximate) marginal probability distributions.
Gaussian discrete algorithms functional form exception
summation (discrete case) integration operators (Gaussian case). message
ij (xi ) updated according
Z

new
ij (xi ) = dxj ij (xi , xj )
jk (xj ) ,
(3)
kj\i

= {j : j i} denotes index set variables connected xi G. step
current approximations qij (xi ,j ) p(xi , xj ) computed according
qij (xi , xj ) ij (xi , xj )


li\j

il (xi )



jk (xj ) .

(4)

kj\i

update steps (9) iterated convergence. corresponding qij (xi , xj )s
yield final approximation p(xi , xj )s. common use damping, is,
1 new (x ) (0, 1]. practice, helps
replace new
ij (xi ) ij (xi )
ij
dampen possible periodic paths (3), keeps properties fixed points
unchanged. Figure 1 illustrates incoming outgoing messages nodes associated
variables xi xj . quite significant difference discrete Gaussian
message passing replacement sum operator integral operator.
finite sums always exist, integral (3) become infinite. problem
remedied technically canonical parameterization (see Section 4) keeps
algorithm running, lead non-normalizable approximate marginals qij , thus
(possible) break-down algorithm.
Message passing introduced Pearl (1988) heuristic algorithm (in discrete
models), however, Yedidia et al. (2000) showed viewed algorithm
4

fiBethe Free Energies Message Passing Gaussian Models

finding stationary points so-called Bethe free energy, error function measuring
difference p specific family distributions detailed next
section. shown Heskes (2003) later different way Watanabe
Fukumizu (2009) stable fixed points (loopy) message passing algorithm local
minima corresponding Bethe free energy. paper show holds
Gaussian models well.
interest properties Gaussian Bethe free energy corresponding Gaussian message passing algorithm motivated mainly implications
general models inference algorithms non-Gaussian models expectation propagation, respectively. reason, compare speed method
accuracy approximation mentioned exact linear algebraic methods.
mentioned introduction, approach take similar Welling
Teh (2001), is, study properties Gaussian Bethe free energy, parameterized
terms moment parameters approximate marginals. following
introduce mean field Bethe approximation Gaussian models. Readers familiar
subject continue Section 3.
2.1 Gaussian Bethe Free Energy
popular method approximate marginals approximating p distribution q
form makes marginals easy identify, example, factorizes treelike form. common quantity measure difference two probability
distributions Kullback-Leibler divergence [q || p]. often used characterize
quality approximation formulate computation approximate marginals
optimization problem


Z
q(x)

q (x) = argmin dx q(x) log
.
(5)
p(x)
qF
Here, F set distributions mentioned form. Since symmetric,
Kullback-Leibler divergence distance, [q || p] 0 proper q p,
[q || p] = 0 p = q, convex q p.
family F densities possessing form
Q makes marginals easy identify
family distributions factorize q(x) = k qk (xk ). words, problem (5)
approximate p distribution independent variables. approximation q
thisQtype called mean field approximation (e.g., Jaakkola, 2000). Defining FMF ({qk }) =
[ qk || p] writing right hand side (5) detail, one gets
Z
FMF ({qk }) =

dx



qk (xk ) log p(x) +

k

XZ

dxk qk (xk ) log qk (xk ).

k

Using parameterization qk (xk ) = N (xk |mk , vk ), = (m1 , . . . , mn )T v = (v1 , . . . , vn )T ,
reduces
1
1X
1X
FMF (m, v) = hT + mT Qm +
Qkk vk
log(vk ) + CMF ,
2
2
2
k

5

k

fiCseke & Heskes

Q
CMF irrelevant constant. Although [ k qk || p] might convex
(q1 , . . . , qn ), one easily check FMF convex variables v
minimum obtained = Q1 h vk = 1/Qkk . Since

1
1

1
Q kk = Qkk QTk,\k Q\k,\k
Q\k,k
,
one easily see mean field approximation underestimates variances. mean
field approximation computes solution means exact, variances
computed interactions variables, namely, matrix
Q diagonal, thus giving poor estimates variances.
order improve estimates variances, one choose approximating distributions q able capture dependencies variables p.
verified distribution dependencies form tree graph written
form
p(xi , xj )
p(x) =
p(xk ),
p(xi )p(xj )
ij

k

j run edges (i, j) tree k nodes 1, . . . , n.
Although cases undirected graph generated non-zero elements Q
tree, based tree intuition one construct q one two variable
marginals
qij (xi , xj )
q(x)
qk (xk )
(6)
qi (xi )qj (xj )
ij

k

andR constrain functions qij qk marginally
consistent normalize 1,
R
is, dxj qij (xi , xj ) = qi (xi ) j dxk qk (xk ) = 1 k. approximation
form (6) together constraints qij qk called Bethe approximation.
Let us denote family functions FB . choosing qij (xi , xj ) = qi (xi )qj (xj ) one
easily check FMF FB , thus FB non-empty. Assuming approximate
marginals correct q normalizes 1 substituting (6) (5), get
approximation KullbackLeibler divergence (5) called Bethe free energy.
Due factorization p, write Bethe free energy
XZ
FB ({qij , qk }) =
dxi,j qij (xi,j ) log ij (xi,j )
(7)
ij

+

XZ
ij



XZ
qij (xi,j )
dxi,j qij (xi,j ) log
+
dxk qk (xk ) log qk (xk ).
qi (xi )qj (xj )
k

One define free energy Bethe approximation
Z
XZ
dx q (x) log q (x)
dxi,j q (xi,j ) log q (xi,j )
ij

+

X
k

6

Z
(1 nk )

dxk q (xk ) log q (xk )

fiBethe Free Energies Message Passing Gaussian Models

entropy (e.g., Yedidia et al., 2000) substitute marginals functions qij
qRk normalize one connected marginal consistency constraints
dxj qij (xi , xj ) = qi (xi ).
stationary conditions Lagrangian corresponding fractional Bethe
free energy (7) marginal consistency normalization constraints, one derive
iterative algorithm (3) corresponding Lagrange multipliers
consistency constraints (Yedidia et al., 2000). Similarly, approximate marginals
computed according (4). shown one-to-one correspondence
stationary points Bethe free energy (7) fixed points
message passing algorithm (3). Later, Section 4 link stable fixed points (3)
local minima (7).
2.2 Fractional Free Energies Message Passing Algorithm
mentioned introduction, case Gaussian models message passing algorithm
always converge. reason appears approximate marginals
may get indefinite negative definite covariance matrices. Welling Teh (2001) pointed
due unboundedness Bethe free energy.
Since FMF convex bounded Bethe free energy might unbounded,
seems plausible analyze fractional Bethe free energy
XZ
F ({qij , qk }) =
dxi,j qij (xi,j ) log ij (xi,j )
(8)
ij


XZ
X 1 Z
qij (xi,j )
+
dxi,j qij (xi,j ) log
+
dxk qk (xk ) log qk (xk ).
ij
qi (xi )qj (xj )
ij

k

introduced Wiegerinck Heskes (2003). Here, denotes set positive reals {ij }.
showed fractional Bethe free energy interpolates mean field
Bethe approximation. is, ij = 1 get Bethe free energy,
case ij tend 0, mutual information variables xi xj highly
penalized, therefore, (8) enforces solutions close mean field solution. showed
fractional message passing algorithm derived (8) interpreted Pearls
message passing algorithm difference instead computing local marginals
Pearls algorithmone computes local ij marginals.3 local ij marginals
correspond true local marginals ij = 1 local mean field approximations
ij = 0. resulting algorithm called fractional message passing algorithm
message updates defined
Z


new
(x
)
=
dxj ij (xi , xj )
jk (xj ) ji (xj )1 ,
(9)
ij
kj\i

approximate marginals computed according


qij (xi , xj ) ij (xi , xj )
il (xi ) ij (xi )1
jk (xj ) ji (xj )1 .
li\j

(10)

kj\i



Q
3. define marginals distribution p argmin{qk } p k qk , divergence
k
R

R
R
[p || q] = dxp(x) q(x)1 + dxp(x) + (1 ) dxq(x) /(1 ) (e.g., Minka, 2005).

7

fiCseke & Heskes

Power expectation propagation Minka (2004) approximate inference method
uses local approximations divergences. case Gaussian models power
expectation propagationwith fully factorized approximating distributionleads
message passing algorithm one derived (8) appropriate constraints.
Starting idea creating upper bound log partition function p
q exponential distributions, Wainwright et al. (2003) derived form (8)
ij chosen bound convex {qij , qk }.
Message passing works well practice, however, ways find local
minima fractional free energies direct minimization w.r.t. parameterization approximate marginals qij qk (Welling & Teh, 2001). latter method
slower likely converge. following analyze Bethe free energy
expressed terms moment parameters approximate marginals qij . Later
Section 4 analyze stability conditions fractional message passing algorithm
expressing conditions term moment parameters approximate
marginals, show stable fixed points fractional Gaussian message passing
local minima fractional Bethe free energy.

3. Bounds Gaussian Bethe Free Energy
section analyze parametric form (8). show fractional Gaussian Bethe free energy non-increasing function . letting ij tend infinity, obtain lower bound free energies. turns condition
lower bound bounded pairwise normalizability
condition work Malioutov et al. (2006).
mentioned Section 2, without loss generality, work unit diagonal Q. define R matrix zeros diagonal Q = + R,
identity matrix. |R| matrix formed absolute values
Rs elements. use moment parameterization qij (xi,j ) = N (xi,j |mij , Vij )
, v ; v , v j ], v = v .
qk (xk ) = N (xk |mk , vk ), mij = (miij , mjij )T Vij = [vij
ij
ji ij
ij
ji
= mi v v = v k j k, embed
using mi

ij
ik
ik
R ij
R
marginalization ( dxj qij (xi , xj ) = qi (xi ) j) normalization ( dxj qj (xj ) = 1)
constraints parameterization. slight abuse notation matrix formed
diagonal elements vk off-diagonal elements vij denoted V (we take vij = 0
j), vector means = (m1 , . . . , mn )T vector variances
v = (v1 , . . . , vn )T . Substituting qij qk (8) one gets
1
1
F (m, V ) = hT + mT Qm + tr(QT V )
2
2 !
2
X
v
1
1
1X
ij

log 1

log (vk ) + C,
2
ij
vi vj
2
ij

(11)

k

C irrelevant constant. Note variables V independent, hence
minimizations F (m, V ) regard V carried independently.
8

fiBethe Free Energies Message Passing Gaussian Models

Property 1. F (m, V ) convex bounded (m, {vij }i6=j ) stationary point

= Q1 h
vij



p
1 + (2ij Rij )2 vi vj 1
= sign(Rij )
.
2ij |Rij |

(12)

Proof: Q positive definite definition, therefore, quadratic term convex
bounded. variables V independent minimum regard
achieved = Q1 h. One check second order derivative
F (m, V ) regard vij non-negative first order derivative one
2 v v . Since variables v independent, one conclude
solution vi vj vij
j
ij
F (m, V ) convex vij . independence V , follows F
convex (m, {vij }i6=j ).

2 , thus
Since Vij constrained covariance matrices, vi vj > vij
first logarithmic term (11) negative. consequence,

F1 (m, V ) F2 (m, V )



0 < 1 2 ,

1 2 taken element element. observation leads following
property.
Property 2. ij = , F non-increasing function .
F define constrained function
Using Property 1 substituting vij

1
1X
Fc (m, v) = hT + mT Qm +
vk
2
2
k
q

1X 1
1 + (2ij Rij )2 vi vj 1

2

ij ij
!
p
1 + (2ij Rij )2 vi vj 1
1 X 1

log 2
2
ij
(2ij Rij )2 vi vj
n(i,j)

1X

log(vk ) + C c ,
2

(13)

k

C c irrelevant constant. Property 2, follows choosing ij = ,
function (13) non-increasing function . makes sense take
verify whether get lower bound (13).
Lemma 1. v > 0, 0 1 1 2 1 following inequalities hold.


FMF (m, v) Fc1 (m, v) FB m, {vij
}, v


FB m, {vij
}, v Fc2 (m, v) . . .

1
. . . FMF (m, v)
v |R| v
2
Moreover, tight, is,


lim F m, {vij
()}, v = FMF (m, v)
0

9

fiCseke & Heskes





1

v |R| v.
lim F m, {vij
()}, v = FMF (m, v)
2
Proof: Since Bethe free energy specific case fractional Bethe free energy
()}, v) follow Property 2. Now, show
= 1, inequalities FB (m, {vij
upper lower bounds tight. function (1 + x2 )1/2 1 behaves 12 x2
neighborhood 0, therefore,


v 2 ()
log 1 ijvi vj
2 ()
vij
1

lim
lim vij
() = 0

lim
=
= 0,
0
0

vi vj 0


showing FMF (m, v) tight upper bound.
tends infinity,
p
1 + (2Rij )2 vi vj 1

= |Rij | vi vj
lim

2

1
log
lim


!
p
1 + (2Rij )2 vi vj 1
= 0,
(2Rij )2 vi vj

yielding tight lower bound


1

v |R| v.
lim F m, {vij
()}, v = FMF (m, v)

2



Let max (|R|) largest eigenvalue |R|. Analyzing boundedness lower
bound, arrive following theorem.
Theorem 1. fractional Bethe free energy (11) corresponding connected
Gaussian model, following statements hold
(1) max (|R|) < 1, F bounded > 0,
(2) max (|R|) > 1, F unbounded > 0,
P P 1
(3) max (|R|) = 1, F bounded
ij 2n.
ij

Proof: Since F interaction parameters V term
depending bounded due positive definiteness Q, simply
neglect term analyzing boundedness F . Let us write detail
lower bound fractional Bethe free energies form

1
v |R| v =
2

1
1
1 1
Q hT +
v (I |R|) v 1T log(v) + const.
2
2
2

FMF (m, v)

(14)

Statement (1): condition max (|R|) < 1 implies |R| positive definite. Now,
10

fiBethe Free Energies Message Passing Gaussian Models







log(x) x 1, thus 12 v (I |R|) v 1T log( v) 21 v (I |R|) v 1T v + n.
latter bounded follows (14) bounded
well. According Lemma 1, boundedness (14) implies fractional Bethe free
energies bounded below.
Statement (2): assumed Gaussian network connected undirected. According Perron-Frobenius theory non-negative matrices (e.g., Horn & Johnson,
2005), |R| simple maximal eigenvalue max (|R|) elements eigenvector umax corresponding positive. Let us take fractional Bethe free energy

analyze behavior v = tumax . large values
(1 + (2ij Rij )2 (uimax ujmax )2 t4 )1/2 ' 2ij |Rij |uimax ujmax t2 , therefore, sum second
third term (13) simplifies (1 max (|R|))t2 term dominates
logarithmic ones . result, limit independent choice ij
tends whenever max (|R|) > 1.
Statement (3): max (|R|) = 1, direction quadratic term

dominate v = tumax . Therefore, analyze P
behavior loga1
rithmic terms (13) . large ts behave ( ij ij
2n) log(t).
c
reason, boundedness F thus F depends condition
statement (3).

shown Malioutov et al. (2006) condition max (|R|) < 1 equivalent
condition pairwise normalizability. Therefore, pairwise normalizability
sufficient condition message passing algorithm converge, necessary
condition fractional Gaussian Bethe free energies bounded. Using Lemma 1,
show suitably chosen > 0 always exists constrained
fractional free energy Fc possesses local minimum 0 < < (Property A2
Section Appendix).
Example case models adjacency matrix (non-zero entries R) corresponding Kregular graph4 equal interaction weights Rij = r, maximal eigenvalue |R| max (|R|) = Kr eigenvector corresponding eigenvalue 1.
(We define 1 vector elements equal 1.) model symmetric
verifying stationary point conditions, turns choice r
exists local minimum, lies direction 1. One show
model pairwise normalizable (Kr > 1), critical r
p fractional
Bethe free energy possesses local minimum rc (K, ) = 1/2 (K )
valid r critical
p fractional Bethe free energies possesses local
minimum c (K, r) = 21 K(1 1 1/(Kr)2 ). results illustrated Figure 2.
(Note 2regular graphs, valid models pairwise normalizable possess
unique global minimum.)

Kregular graphs, convexity fractional Bethe free energy terms
{qij , qk } requires K, much stronger condition c (K, r). Thus, choose
sufficiently large Bethe free energy guaranteed unique global
minimum, minimum unbounded.

4. Kregular graph graph nodes connected K nodes.

11

fiCseke & Heskes

$

!"

$

)

!"

+0")12&3,)*.&456
+)D)1"7+834.59
+0!:;
+< VTUWff.fi
+0+

#

%&'(&)*+&&)&,&+-.&/

%&'(&)*+&&)&,&+-.&/

#

!"

834.5



!"

"

!"



!"

)

_0")12&3,)*.&456
_)D)7"8"!9!"":
_0!)1%&'(&6
_0_;

!"

_)0)')14<=&+)><?,56


!"

"

!"

)





!"



!"

"

!"


!

!"

!"



)



!"

!"



!"

"

!"


!

!"



!"

Figure 2: Visualizing critical parameters symmetric K-regular Gaussian model Rij = r.
Plots
left panel correspond constrained fractional Bethe free energies Fc

v = 1 8 node 4regular Gaussian model r=0.27 (Kr > 1) varying
.

Plots right panel correspond constrained Bethe free energies F1c v = 1
8 node 4regular Gaussian model varying r. Here, rvalid supremum
rs model valid, is, Q positive definite.

example disproves conjecture Welling Teh (2001), is, even
Bethe free energy bounded below, possess finite local minimum
message passing minimization algorithms converge.

4. Message Passing Algorithm Gaussian Models
section, turn attention towards properties message passing algorithm Gaussian models. Following similar line argument Watanabe Fukumizu
(2009) show stable fixed points message passing algorithm correspond local
minima Bethe free energy. use moment parameterization introduced
previous sections. way proceed following: (1) make linear expansion
message passing iteration fixed point, (2) express linear expansion terms
moment parameters corresponding fixed point finally (3) connect properties latter properties Hessian Bethe free energy using
matrix determinant lemma.
form equation (9) implies messages ij (xi ) univariate Gaussian
functions, thus express terms two scalar (canonical) parameters ij
ij log ij (xi ) = ij x2i /2 + ij xi + ijj , ij irrelevant constants.
expressed terms ij ij , damped message passing algorithm (9) translates
12

fiBethe Free Energies Message Passing Gaussian Models


j
hj +
ij


new
ij

=

(1 )ij +

P

jk + (1 )ji




kj\i

P
ij hi Rij

j

ij
+
jk + (1 )ji

(15)

kj\i



new
ij

=

1
X


j
2
2 Rij
ij
+
jk + (1 )ji
(1 )ij + ij



kj\i

(16)
, j , h R parameters Section 2.1, R = Q
ij

ij
ij
ij
ij
ij
assumption Qii = 1. approximate marginals qij (10) might normalizable,
message passing iteration (15) (16) stays well defined unless zero
denominator rhs. rarely happens practice. However,
common message passing converges intermediate steps
approximate marginals qij normalizable. often remedied choosing
appropriate damping parameter .
iteration (16) ij independent ij iteration (15) ij
linear ij . interesting see h = 0 neither constrained Bethe
free energy (13) message passing algorithm (16) depend sign Rij .
relevant compute meanswhen h 6= 0and signs correlations
(12). result, marginal variances computed either minimizing Bethe free
energy running message passing algorithm depend |R|, similarly
constrained fractional free energy Fc .

4.1 Stability Gaussian Message Passing Algorithm
following analyze stability message passing iteration fixed points,
is, stationary points Lagrangian corresponding constrained minimization Gaussian Bethe free energy. reiterate use G = (V, E) denote
graph corresponding Q, namely, V = {1, . . . , n} E = {(i, j) : Qij 6= 0}. vector R|E| , corresponding set messages {ij }ij , composed concatenation
ij ij followed ji (ij, ji) blocks follow lexicographic order w.r.t.
ij < j. vector consists variables ij follows similar structure .
j
define r, h, R|E| rij = rji = Rij , hij = hj ij = ij
. define
|E| |E| matrix

1 j = k

1 kl = ji
Mij,kl ()

0 otherwise
encodes weighted edge adjacency corresponding G . number nonzero elements M(), scales roughly nnzeros (Q)2 /n, nnzeros (Q) denotes
number non-zeros Q. Since parallel message update given Equations (15)
(16) rewritten terms two matrix-vector multiplications element element
operations vectors, computational complexity update scales roughly
nnzeros (Q)2 /n.
13

fiCseke & Heskes

notation, local linearization update equations (15) (16)
written
( new , new )
(, ) = (1 )I . . .
(, )






h+M()
1
diag r +M() M() diag r (+M())2 M()

,


+
1

0
diag 2 r 2 (+M())
M()
2

(17)

operations vectors element element. stability fixed point
( , ) depends union spectra

J ( , ) 1 diag r( + M() )1 M()


J ( , ) 1 diag 2 r 2 ( + M() )2 M().
important point stability properties depend R
independent h.
goal connect stability properties message passing algorithm
properties Bethe free energy. Therefore, express stability properties terms
moment parameters approximate marginals. leads normalizable approximate marginals qij (xi , xj ), use (10) identify local covariance
parameters Vij defined Section 3, without enforcing marginal matching
= v . correspondence given
constraints vij
ik
"


vij
vij

vij
j
vij


=

#1

1

=

"

j
vij
vij

vj v2
vij
ij
ij
P
+
il + (1 )ij
ij

vij

vij

#
(18)
Rij

li\j
j
ij

Rij

+

P

jk + (1 )ji



.

kj\i
, v j r
approximate local covariances vij fully determined vij
ij
ij
form (12). leaves us |E| moment parameters computed
, v = v j (v) =
message passing algorithm. Let v R|E| defined vij = vij
ji
ij
ij
v j v 2 ), v
vij /(vij
ij
ij computed according (12). checked
ij
mapping v continuous bijective. implies canonical
moment parameter transformation (18) written y(v) = + M(). Since
M() singular = K graph G K-regularsee Property A1
Section Appendix detailsfor rest cases, continuous,
bijective mapping moment parameters v canonical parameters
lead normalizable approximate marginals.
= v v
fixed point ( , ) moment matching, is, vij

ik
k, j i, therefore express stability properties terms moment parameters

14

fiBethe Free Energies Message Passing Gaussian Models

v = (vi , . . . , vn ). Using p
(18) defining diagonal matrix R|E||E|
diagonal elements Dij,ij = vi , get

, v)
v
(,
v
ij

j
= 1 diag q
M()


vi vj


DJ ( (v ))D 1

(19)


2





J ( (v ))D

2

=

1

diag

vij (, vi , vj )2
vi vj

!
M().

(20)


Let (A) denote
spectrum matrix A. Since DJ 1 = (J )

2 J 2 = (J ), sufficient analyze spectral properties right hand
sides equations (19) (20).
message passing algorithm asymptotically stable (v )
max { (J ( (v ))) , (J ( (v )))} < 1,

(21)

() denotes spectral radius. interesting see although functional
forms free energies message passing algorithms different Gaussian
discrete case, stability conditions similar forms. allow us use
results Watanabe Fukumizu (2009). next section, show
implications condition properties Hessian free energy.
4.2 Stable Fixed Points Local Minima
Hessian H[F ] Bethe free energy (11) depends moment parameters
vi , vj vij . Note now, vij unconstrained parameters. (|E|/2 + 2n)
(|E|/2 + 2n) matrix form


Q


0
H[F ](V ) =

0

diag
h 2

0 2

F
2 vij


h

F
vij vi ij,i

0

2 F
vij vi ij,i

h



2 F
vi vj i,j




,


use V denote collection parameters vi , = 1, . . . , n vij , j.
Since block corresponding partial differentials w.r.t. vij diagonal positive
elements, Hessian positive definite V Schur complement corresponding
15

fiCseke & Heskes

partial differentials w.r.t. vi positive definite V . latter given
X 2 F 2 F 1
2 F
v

Hii [F ](V ) =
vi vi
vij vi
vij
ij


1 1
1 X c4ij
=
1
+
,
4
2 vi2

1

c
ij
ij

1
2
2
F
F 2 F 2 F
v
Hij [F ](V ) =

vi vj
vij vi vij vj 2 vij
1 1 1 c2ij
=
,
2 vi vj 1 c4ij

use notation cij = vij / vi vj .
Now, would connect condition (21) positive definiteness
matrix H v [F ](V ). following show stable fixed points (v ) Gaussian
message passing algorithm, satisfying (21), correspond local minima Gaussian free
energy F v vij (, vi , vj ).
According Watanabe Fukumizu (2009), arbitrary vector w R|E| one



det I|E| 1 diag (w) M() = det + 1 A(w)
(1 wij wji ),
(22)
ij


Aii (w) =

X
ij

wij wji
1 wij wji



Aij (w) =

wij
.
1 wij wji

(23)

proof application matrix determinant lemma reproduction
found Section Appendix. Equation (22) expresses determinant
|E||E| matrix determinant nn matrix.

Let c R|E| cij (V ) = vij / vi vj . substituting w = c(V )2 (23), find


det 1 diag c(V )2 M() = f (V ) det (H[F ](V )) ,
(24)
f (V ) positive function defined
f (V ) = 2n |E| |Q|1


k

vk2


2
2
vi vj vij
ij

2
vi vj + vij

2
vij
1
vi vj

!
.

V corresponding normalizable approximate marginals. Now, adapting theorem
Watanabe Fukumizu (2009)

following theorem.
Theorem 1 diag c(V )2 M() C \ R1 Hessian (Gaussian)
Bethe free energy H[F ] positive definite
V.
1
2
Proof: assumption
diag c(V ) M() C \ R1 implies
det 1 diag(c(V )2 M()) > 0. choosing Vij (t) = tvij [0, 1], find
2
c(V(t))2 = t2 c(V )2 , therefore, det 1 diag(c(V (t) )M()) > 0 [0, 1].
16

fiBethe Free Energies Message Passing Gaussian Models

implies det (H[F ](V (t))) > 0 [0, 1]. Since H[F ](V (0)) = > 0
eigenvalues H[F ](V (t)) change continuously w.r.t. [0, 1], results
H[F ](V (1)) > 0 V , thus satisfying condition theorem.



fixed point ( , ) stable
max{(J ( (v ))), (J ( (v )))} < 1.
1

2
implies diag(c(V ) )M() C \ R1 leads following property.

Property 3. Stable fixed points ( , ) damped Gaussian message passing algorithm (16) local minima Gaussian Bethe free energy Fc (13) v ( ).
shows boundedness F existence local minima case
unbounded F plays significant role convergence Gaussian message passing. illustrate Section 5. fractional message passing algorithm converges
converges set messages corresponds local minimum fractional free energy. implies mean parameters local approximate
marginals exact (see Property 1. Section 3). Note observations Section 3
Property A2 Appendix together Property 3 imply always
range values fractional free energy possesses local minimum
fractional message passing converge.
4.3 Damping Fractional Parameters
local stability condition (21) independent damping parameter . Therefore,
alter local stability properties, makes iteration slower numerically stable, is, dampen possible periodic trajectories message
passing algorithm.
fractional parameter characterizes inference process seen
example previous sections, choosing smaller create local minima.
particular case h = 0, somewhat similar property message passing
updates well. Let R|E| set messages lead normalizable approximate
marginals. set characterized model parameters |R|, . reiterate
v j continuous bijective
elements v local variances vij
ij
|E|

mapping v R+ given y(v) = + M(), unless = K G
K-regular. allows us study q
stability properties terms moment parameters
, v j )/
v(). Let c(v, ) = [vij (, vij
ij

v j ] vector local correlations. using
vij
ij ij

Gershgorins theorem (Horn & Johnson, 2005) c(v, )2 c(v, ), find
eigenvalue 1 diag(c(v, ))M() 1 diag(c(v, ))2 M()


|| max 1 c(v, ) [(nj 1) + |1 |] .
i,j

h = 0, updates , rhs equation depends
1 c(v, )2 (see Equations (17) (20)) lim 1 c(v, )2 = 0, thus, small
0

values help achieve convergence. However, h 6= 0 term 1 c(v, )
dominating effects decreasing towards zero ambiguous.
17

fiCseke & Heskes

5. Experiments
implemented direct minimization fractional message passing analyzed
behavior different values max (|R|). reasons simplicity, set ij
equal. results small scale model summarized Figure 3. Note
good correspondence behavior fractional Bethe free energies
direction eigenvalue corresponding max (|R|) convergence Newton
method. Newton method started different initial points. experienced
max (|R|) > 1 setting initial value v0 = t2 u2max , algorithm
converge high values t. explained top plots Figure 3:
high values t, initial point might convergence region local
minimum. fractional message passing algorithm used two types initialization:
=
(1) max (|R|) < 1 set ij normalizable setting ij
= 1/n ,
|Rij |ujmax /max uimax (Malioutov et al., 2006), (2) max (|R|) 1, used ij

is, symmetric partitioning diagonal elements. set initial messages
approximate marginals normalizable first step iteration.
experienced behavior similar described Welling Teh (2001)
standard message passing, namely, fractional message passing direct minimization either
converge fail converge. experiments combination Theorem 1
show max (|R|) > 1, standard message passing best converges local
minimum Bethe free energy. standard message passing fails converge, one
decrease search stationary pointpreferably local minimumof
corresponding fractional free energy.
seen results right panels Figure 2, model
longer pairwise normalizable, local minimum unbounded global minimum
viewed natural continuation (bounded) global minimum pairwise
normalizable models. explains quality approximation local
minimum models pairwise normalizable still comparable
global minimum models pairwise normalizable.

6. Conclusions


seen, FMF FMF 21 v |R| v provide tight upper lower bounds
Gaussian fractional Bethe free energies. turns pairwise normalizability
sufficient condition message passing algorithm converge,
necessary condition Gaussian fractional Bethe free energies bounded
below.
model pairwise normalizable, lower bound bounded, direct
minimization message passing converging. experiments converged
minimum. suggests pairwise normalizable case, fractional Bethe
free energies possess unique global minimum.
model pairwise normalizable, none fractional Bethe free energies
bounded below. However, always range values
fractional free energy possesses local minimum direct minimization
fractional message passing converge. Thus, decreasing towards zero, one gets
18

fiBethe Free Energies Message Passing Gaussian Models

&

!"

&

(

!"

)*+,(-.*/0
_(D(1"2"!3!""4
5*'6*(7_8!9
:;<*=(>;?,0

%

!"

%

!"

#

#

!"

!"

"

"

!"

!"



!"

(





"

!"

!"

!

#

!"
'

!"

$

!"

!"

Function value convergence

Function value convergence

6
5
4
3
2
1
0

"

!"

!

!"
'

#

$

!"

!"

2

0

10

10


7
6
5
4
3
2
1
0
1

2

10

Error variances convergence

Newton method
Message passing
1

10

0

10

1

10



8

7

1

(

!"

8

Error variances convergence

(

)*+,(-.*/0
_(D(1"2"!3!""4
5*'6*(7_8!9
:;<*=(>;?,0

2

10

0

10

0

10

10


2

Newton method
Message passing
1

10

0

10

1

2

10

0

10


10

2

10

2

10

10


2

Figure 3: top panels show constrained
fractional Bethe free energies Gaussian model

8 variables direction v = tumax , umax eigenvector corresponding max (|R|) max (|R|) = 0.9 (top-left) max (|R|) = 1.1 (top-right).
thick lines functions FMF (dashed), FB (dashed dotted) lower bound


FMF 12 v |R| v (continuous). thin lines constrained -fractional free
energies Fc [102 , 102 ]. Center panels show final function values
convergence Newton method. bottom panels
show || ||2 error approximation single node standard deviations = v. Missing values indicate
non-convergence.
19

fiCseke & Heskes

closer mean field energy finite local minimum appear (Property A2
Appendix). experienced suitable range s,s initial values
fractional Gaussian message passing made converge.
mentioned Section 2.1, ij correspond using local ij divergences applying power expectation propagation fully factorized approximating distribution.
Seeger (2008) reports expectation propagation converge, applying power
expectation propagation < 1 helps achieve convergence. case problem
addressed paper behavior explained observation small
make finite local minima likely occur thus prevents covariance matrices
becoming indefinite even non positive definite. Although common reason
using < 1 EP numerical robustness, implies finding saddle point
-fractional EP free energy. might interesting investigate whether
reason convergence likely case Gaussian fractional message passing.
Wainwright et al. (2003) propose convexify Bethe free energy discrete models
choosing ij sufficiently large fractional Bethe free energy unique
global minimum. strategy appears fail Gaussian models. Convexification makes
possibly useful finite local minima disappear, leaving unbounded global minimum. case general hybrid models, use convexification still
unclear.
example Section 3 disproves conjecture work Welling Teh (2001):
even Bethe free energy bounded below, possess finite local
minimum message passing minimization algorithms converge.
shown stable fixed points Gaussian fractional message passing
algorithms local minima fractional Bethe free energy. Although existence
local minimum guarantee convergence message passing algorithm,
practice experienced existence local minimum implies convergence.
Based results, hypothesize pairwise normalizability hold,
Gaussian Bethe free energy Gaussian message passing algorithm ( = 1)
two types behavior:
(1) Gaussian Bethe free energy possesses unique finite local minimum
optimization methods converge starting from, say, mean field solution
vi = 1/Qii ; Gaussian message passing corresponding unique stable fixed
point, converge suitable starting point sufficient damping,
(2) finite local minimum exists, thus, optimization message
passing algorithm diverge.
using fractional free energy fractional message passing varying ,
one switch behaviors. Computing critical c (|R|) general |R|
remains open question. believe properties free energies K-regular
symmetric models (Section 3), critical values easily computed, give good
insight properties free energies general Gaussian models.
20

fiBethe Free Energies Message Passing Gaussian Models

Acknowledgments
would thank Jason K. Johnson sharing ideas properties
message passing algorithm K-regular models. would thank anonymous
reviewers valuable comments earlier versions manuscript. research
reported paper supported VICI grant 639.023.604 Netherlands
Organization Scientific Research (NWO).

Appendix A. Properties Proofs
Lemma A1. (Watanabe & Fukumizu, 2009) graph G = (V, E), edge adjacency
matrix M() (defined Section 4.1), arbitrary vector w R|E| , one


det I|E| 1 diag (w) M() = det I|V | + 1 A(w)
(1 wij wji ),
ij


Aii (w) =

X
ij

wij wji
1 wij wji

Aij (w) =



wij
.
1 wij wji

Proof: reproduce proof somewhat simplified form. Let us define Uij, = eTj ,
Vij, = eTi ek k th unit vector Rn



Sij,ij Sij,ji
0 1
,
=
Sji,ij Sji,ji
1 0
M() = U V S. Let us define W R|E||E| diagonal matrix
wij,ij = wij . Using matrix determinant lemma reads

det 1 W U V

= det + W 1 W U V



= det 1 W U V (I + W S)1 det (I + W S)


= det 1 V (I + W S)1 W U det (I + W S).
(ij, ji) block (I + W S)1 W


1
1
wij
wij
1
0
1 wji wji wji

0
wji


=

1
1 wji wji



wij
wji wij

wij wji
wji



thus, define V (I + W S)1 W U
X wij wji
wij
Ai,i =
Ai,j =
.
1 wij wji
1 wij wji
ij

completes proof matrix determinant lemma (22) Section 4.2.

21



fiCseke & Heskes

Property A1. matrix M() = U V singular K-regular graphs
= K.
P
Proof: Let x R|E| =PM()x. yij = kj xjk xji . Let us fix j,
yij = 0 means kj xjk = xji i. hold graph
K-regular, = K xij equal xij = 0 pair indices ij.

Property A2. suitably chosen > 0, exists constrained
fractional free energy Fc possesses local minimum 0 < < .

Proof: Let us define vM
F = argminv FM F (v)


UM
F = {v : FM F (v) FM F (vM F ) + 2} .

form FM F implies always choose UM
F proper subset
n

n
positive quadrant R , words, UM F R+ . due properties FM F
(continuous convex, unique finite global minimum attained finite value),





domain UM
F closed, bounded, convex vM F UM F \ UM F , is, vM F

n
c

interior UM F . Since FM F F (v) continuous R+ , set UM F closed
bounded lim Fc (v) = FM F (v) (pointwise convergence) v Rn+ , follows Fc
0


c
converges uniformly UM
F 0. This, together monotonicity F w.r.t. ,
implies exists FM F (vM F ) < Fc (vM F ) < FM F (vM F ) 0 <
. Let us fix . known that, since U
< v UM
F
F closed bounded
) + 2

c
c
F continuous, F attains extrema UM F . Since FM F (v) = FM F (vM
F
)+
c

c

v UM F F (v) > FM F (v) v UM F follows F (v) > FM F (vM
F


c

).
v UM F . chosen FM F (vM F ) < F (vM F ) < FM F (vM
F
latter two conditions imply one extrema local minimum
.
interior UM

F

References
Bickson, D. (2009). Gaussian Belief Propagation: Theory Application. Ph.D. thesis,
Hebrew University Jerusalem.
Cseke, B., & Heskes, T. (2008). Bounds Bethe free energy Gaussian networks.
McAllester, D. A., & Myllymaki, P. (Eds.), UAI 2008, Proceedings 24th
Conference Uncertainty Artificial Intelligence, pp. 97104. AUAI Press.
Heskes, T. (2003). Stable fixed points loopy belief propagation minima Bethe
free energy. Becker, S., Thrun, S., & Obermayer, K. (Eds.), Advances Neural
Information Processing Systems 15, pp. 359366, Cambridge, MA. MIT Press.
Heskes, T., Opper, M., Wiegerinck, W., Winther, O., & Zoeter, O. (2005). Approximate
inference techniques expectation constraints. Journal Statistical Mechanics:
Theory Experiment, 2005, P11015.
Heskes, T. (2004). uniqueness loopy belief propagation fixed points. Neural
Computation, 16, 23792413.
Horn, R. A., & Johnson, C. (2005). Matrix Analysis. Cambridge University Press, Cambridge, UK.
22

fiBethe Free Energies Message Passing Gaussian Models

Jaakkola, T. (2000). Tutorial variational approximation methods. Opper, M., & Saad,
D. (Eds.), Advanced mean field methods: theory practice, pp. 129160, Cambridge,
MA. MIT Press.
Johnson, J. K., Bickson, D., & Dolev, D. (2009). Fixing convergence Gaussian belief
propagation. CoRR, abs/0901.4192.
Malioutov, D., Johnson, J., & Willsky, A. (2006). Walk-sums belief propagation
Gaussian graphical models. Journal Machine Learning Research, 7, 20312064.
Minka, T. P. (2004). Power EP. Tech. rep., Microsoft Research Ltd., Cambridge, UK,
MSR-TR-2004-149.
Minka, T. P. (2005). Divergence measures message passing. Tech. rep. MSR-TR-2005173, Microsoft Research Ltd., Cambridge, UK.
Moallemi, C., & Roy, B. V. (2006). Consensus propagation. Weiss, Y., Scholkopf, B., &
Platt, J. (Eds.), Advances Neural Information Processing Systems 18, pp. 899906.
MIT Press, Cambridge, MA.
Murphy, K., Weiss, Y., & Jordan, M. I. (1999). Loopy belief propagation approximate
inference: empirical study. Proceedings Fifteenth Conference Uncertainty Artificial Intelligence, Vol. 9, pp. 467475, San Francisco, USA. Morgan
Kaufman.
Nishiyama, Y., & Watanabe, S. (2009). Accuracy loopy belief propagation Gaussian
models. Neural Networks, 22 (4), 385 394.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufman Publishers, San Mateo, CA.
Rusmevichientong, P., & Roy, B. V. (2001). analysis belief propagation turbo
decoding graph Gaussian densities. IEEE Transactions Information Theory,
47, 745765.
Seeger, M. W. (2008). Bayesian inference optimal design sparse linear model.
Journal Machine Learning Research, 9, 759813.
Takahashi, K., Fagan, J., & Chin, M.-S. (1973). Formation sparse impedance matrix
application short circuit study. Proceedings 8th PICA Conference.
Wainwright, M., Jaakkola, T., & Willsky, A. (2003). Tree-reweighted belief propagation
algorithms approximate ML estimation via pseudo-moment matching. Bishop,
C., & Frey, B. (Eds.), Proceedings Ninth International Workshop Artificial
Intelligence Statistics. Society Artificial Intelligence Statistics.
Watanabe, Y., & Fukumizu, K. (2009). Graph zeta function Bethe free energy
loopy belief propagation. Bengio, Y., Schuurmans, D., Lafferty, J., Williams, C.
K. I., & Culotta, A. (Eds.), Advances Neural Information Processing Systems 22,
pp. 20172025. MIT Press.
Weiss, Y., & Freeman, W. T. (2001). Correctness belief propagation Gaussian graphical
models arbitrary topology. Neural Computation, 13 (10), 21732200.
23

fiCseke & Heskes

Welling, M., & Teh, Y. W. (2001). Belief optimization binary networks: stable alternative loopy belief propagation. Breese, J. S., & Koller, D. (Eds.), Proceedings
17th Conference Uncertainty Artificial Intelligence, pp. 554561. Morgan
Kaufmann Publishers.
Wiegerinck, W., & Heskes, T. (2003). Fractional belief propagation. Becker, S., Thrun,
S., & Obermayer, K. (Eds.), Advances Neural Information Processing Systems 15,
pp. 438445, Cambridge, MA. MIT Press.
Yedidia, J. S., Freeman, W. T., & Weiss, Y. (2000). Generalized belief propagation.
Advances Neural Information Processing Systems 12, pp. 689695, Cambridge, MA.
MIT Press.
Zoeter, O., & Heskes, T. (2005). Change point problems linear dynamical systems.
Journal Machine Learning Research, 6, 19992026.

24


