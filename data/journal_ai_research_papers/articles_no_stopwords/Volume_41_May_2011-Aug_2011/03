Journal Artificial Intelligence Research 41 (2011) 407-444

Submitted 02/11; published 07/11

Efficient Multi-Start Strategies Local Search Algorithms
Andras Gyorgy

gya@szit.bme.hu

Machine Learning Research Group
Computer Automation Research Institute
Hungarian Academy Sciences
1111 Budapest, Hungary

Levente Kocsis

kocsis@sztaki.hu

Data Mining Web Search Research Group, Informatics Laboratory
Computer Automation Research Institute
Hungarian Academy Sciences
1111 Budapest, Hungary

Abstract
Local search algorithms applied optimization problems often suffer getting
trapped local optimum. common solution deficiency restart
algorithm progress observed. Alternatively, one start multiple instances
local search algorithm, allocate computational resources (in particular, processing
time) instances depending behavior. Hence, multi-start strategy
decide (dynamically) allocate additional resources particular instance
start new instances. paper propose multi-start strategies motivated
works multi-armed bandit problems Lipschitz optimization unknown
constant. strategies continuously estimate potential performance algorithm
instance supposing convergence rate local search algorithm unknown
constant, every phase allocate resources instances could converge
optimum particular range constant. Asymptotic bounds given
performance strategies. particular, prove quadratic increase
number times target function evaluated needed achieve performance
local search algorithm started attraction region optimum. Experiments
provided using SPSA (Simultaneous Perturbation Stochastic Approximation) kmeans local search algorithms, results indicate proposed strategies work
well practice, and, cases studied, need logarithmically evaluations
target function opposed theoretically suggested quadratic increase.

1. Introduction
Local search algorithms applied optimization problems often suffer getting trapped
local optimum. Moreover, local search algorithms guaranteed converge
global optimum conditions (such Simulated Annealing Simultaneous
Perturbation Stochastic Approximation, SPSA, see, e.g., Spall, Hill, & Stark, 2006), usually
converge slow pace conditions satisfied. hand,
algorithms employed aggressive settings, much faster convergence local
optima achievable, guarantee find global optimum. common soluc
2011
AI Access Foundation. rights reserved.

fiGyorgy & Kocsis

tion escape local optimum restart algorithm progress observed
(see e.g., Mart, Moreno-Vega, & Duarte, 2010; Zabinsky, Bulger, & Khompatraporn, 2010,
references therein).
Alternatively, one start multiple instances local search algorithm, allocate
computational resources, particular, processing time, instances depending
behavior. Instances started time, number instances may grow
time depending allocation strategy. (see, e.g., Chapter 10 Battiti, Brunato, &
Mascia, 2008 references therein). type problems computational cost
usually measured total number steps made search algorithm instances:
often reflects situation evaluation target function optimized
expensive, costs related determine algorithms use next negligible
compared former (e.g., clearly case task tune parameters
system whose performance tested via lengthy experiments, see, e.g., BartzBeielstein, 2006; Hutter, Hoos, Leyton-Brown, & Stutzle, 2009). paper address
problem dynamically starting several instances local search algorithms
allocating resources instances based (potential) performance.
knowledge, solutions problem either based heuristics
assumption local optima search algorithms converge
extreme value distribution (see Section 2 below). paper, propose new multi-start
strategies mild conditions target function, attractive theoretical
practical properties: Supposing convergence rate local search algorithms
unknown constant, strategies continuously estimate potential performance
algorithm instance every phase allocate resources instances could
converge optimum particular range constant. selection mechanism
analogous DIRECT algorithm (Jones, Perttunen, & Stuckman, 1993; Finkel &
Kelley, 2004; Horn, 2006) optimizing Lipschitz-functions unknown constant,
preference given rectangles may contain global optimum. optimum
within rectangle estimated optimistic way, estimate depends
size rectangle. strategies use function describing convergence rate
local search algorithms similar way size rectangles used
DIRECT algorithm.
Since proposed multi-start strategies potential performance local search
algorithm continuously estimated currently best value target function
returned algorithm, method restricted work local search algorithms
return best known value target function step. case,
example, certain meta-learning problems, goal find good parameter
setting learning algorithm. search space parameter space learning
algorithm, one step local search methods means running learning algorithm
completely possibly large data set. hand, local search algorithm
sort gradient search optimizing error function training data,
value target function usually available case batch learning
(potentially cheap computations), gradient estimated
samples.
rest paper organized follows. Section 2 summarizes related research.
problem defined formally Section 3. new multi-start local search strategies
408

fiEfficient Multi-Start Strategies Local Search Algorithms

paper described analyzed Section 4: Section 4.1 deal selection
mechanism among fixed number instances local search algorithm, while,
addition, simple schedules starting new instances considered Section 4.2,
natural extensions case finitely many local search algorithm instances.
section concludes discussion results Section 4.3. Simulation results
real synthetic data provided Section 5. Conclusions future work
described Section 6.

2. Related Work
problem allocating resources among several instances search algorithms
comfortably handled generalized version maximum K-armed bandit problem.
original version problem consists several rounds, round one
chooses one K arms, receives reward depending choice, goal
maximizing highest reward received several rounds. model easily used
problem considering local search algorithm instance arm: pulling
arm means taking one additional step corresponding algorithm, is, evaluating
target function point suggested algorithm, reward received
value target function sampled point. generic algorithm standard
maximum K-armed bandit problem, reward assumed independent
identical distribution, provided Adam (2001), so-called reservation price
instance introduced, gives maximum amount resources worth spend
instance: instance achieves reservation price, useless select again.
computation reservation price depends model algorithm
learnt specific constraints.
consider scenario several instances some, possibly randomized local
search algorithms run goal maximizing expected performance. instance run terminates. scenario natural assume
values returned instances (usually local optima target function) independent. Furthermore, since good search algorithms follow (usually heuristic)
procedures yield substantially better results pure random guessing, Cicirello
Smith (2004, 2005) suggested rewards (evaluated target function values)
search instances may viewed maximum many random variables (if instances run sufficiently long time), hence may modeled extreme value
distributions. Several algorithms based assumption, hence developed
maximum K-armed bandit problem returns following generalized extreme value
distributions: Cicirello Smith apply (somewhat heuristic) methods use
extreme-value-distribution assumption decision point meta-learning algorithm,
Streeter Smith (2006a) use model obtain upper confidence bounds
performance estimate type algorithms used try algorithms
best expected result. latter theoretically justified example natural
strategy probe algorithm instances while, estimate future performance
based results trial phase, use promising algorithm
time remaining. Streeter Smith (2006b) proposed distribution free approach
409

fiGyorgy & Kocsis

combines multi-armed bandit exploration strategy heuristic selection among
available arms.
standard maximum K-armed bandit problem rewards round
assumed independent, clearly case situation
algorithm instances run parallel reward evaluating target function
point improvement upon current maximum, since samples chosen local
search algorithm usually depend previous samples. Nevertheless, ideas lessons
learnt maximum K-armed bandit problems used case, well:
example, algorithm Threshold Ascent Streeter Smith (2006b) gives reasonably
good solutions case, principle probing instances using
promising time remaining carries situation easily:
algorithms, first exploration exploitation phase, referred
sequel explore-and-exploit algorithms. class algorithms, simple rules
suggested Beck Freuder (2004) predict future performance algorithm,
Carchrae Beck (2004) employ Bayesian prediction.
Another related problem find fast algorithms among several ones solve
problem. precisely, several algorithm instances available produce
correct answer certain question run sufficiently long time. time needed
algorithm instance find answer assumed random quantity
independent identical distributions instances, goal combine
given algorithms minimize expected running time answer found.
distribution running time known, optimal non-adaptive time-allocation strategy1
perform sequence runs certain cut-off time depends distribution
(Luby, Sinclair, & Zuckerman, 1993). distribution unknown, particular running
time sequence chosen results expected total running time
logarithmic factor larger optimum achievable distribution known. note
strategy among provide schedule increases number
algorithm instances. set-up specialized problem: goal find
-optimal approximation optimum running time number steps
needed given search algorithm achieve approximation. Note
case running time algorithm instance providing -suboptimal solution
defined infinity, results Luby et al. remain valid -optimal solution
found positive probability. problem, Kautz, Horvitz, Ruan,
Gomes, Selman (2002) proposed allocation strategy based updating dynamically
belief run-time distribution. Concerning latter, Hoos Stutzle (1999)
found empirically run-time distributions approximately exponential certain (NPhard) problems, Ribeiro, Rosseti, Vallejos (2009) dealt comparison
different run-time distributions.
Finally, set time allocation strategies available optimization problem solved several times, one use standard multi-armed bandit framework
done Gagliolo Schmidhuber (2006, 2007, 2010).
Running several instances algorithm several algorithms parallel selecting
among algorithms intensively studied, example, area meta1. non-adaptive time-allocation strategy running time algorithm instance fixed advance,
is, measured performance algorithm instances effect schedule.

410

fiEfficient Multi-Start Strategies Local Search Algorithms

learning (Vilalta & Drissi, 2002) automatic algorithm configuration (Hutter et al., 2009).
underlying problem similar cases: automatic algorithm configuration
usually refers tuning search algorithms, meta-learning used subset
problems, tuning machine learning algorithms (the latter often allows specific use
data). main problem allocate time slices particular algorithms
aim maximizing best result returned. allocation may depend intermediate
performance algorithms. automatic algorithm configuration metalearning systems use various heuristics explore space algorithms parameters
(see, e.g., Hutter et al., 2009).
Finally, important note that, although multi-start local search strategies solve
global optimization problems, concentrate maximizing performance given
underlying family local optimization methods. Since choice latter major
effect achievable performance, compare results vast literature
global optimization.

3. Preliminaries
Assume wish maximize real valued function f d-dimensional unit hypercube
[0, 1]d , is, goal find maximizer x [0, 1]d f (x ) = f
f = max f (x)
x[0,1]d

denotes maximum f [0, 1]d . simplicity, assume f continuous
[0, 1]d .2 continuity f implies existence x , and, particular, f bounded.
Therefore, without loss generality, assume f non-negative.
form f known explicitly, search algorithms usually evaluate f several
locations return estimate x f based observations.
obvious trade-off number samples used (i.e., number points
target function f evaluated) quality estimate, performance
search strategy may measured accuracy achieves estimating f
constraint number samples used.
Given local search algorithm A, general strategy finding good approximation
optimum x run several instances initialized different starting points
approximate f maximum f value observed. concentrate local search
algorithms defined formally sequence possibly randomized sampling functions
sn : [0, 1]dn [0, 1]d , n = 1, 2, . . .: evaluates f locations X1 , X2 , . . . Xi+1 =
si (X1 , . . . , Xi ) 1, starting point X1 = s0 chosen uniformly random
[0, 1]d ; n observations returns estimate x maximum f , respectively,

bn = argmax f (Xk )
bn ).
X

f (X
1kn1

ties argmax function may broken arbitrarily, is, samples Xk
bn chosen them. avoid ambiguity
achieve maximum, X
2. results easily extended (arbitrary valued) bounded piecewise continuous functions
finitely many continuous components.

411

fiGyorgy & Kocsis

simplify notation, following, unless stated explicitly otherwise, adopt
convention use argmax denote maximizing sample smallest index,
results remain valid choice break ties.
simplicity, consider starting single local search algorithm different
random points, although results work extended allow varying
parameters (including situation running different local search algorithms,
parameter would choose actually employed search algorithm); well allow
dependence among initializations (that is, starting point parameters
local search instance may depend information previously obtained target
function).
clear starting points sampled uniformly [0, 1]d algorithm
bn ) converges
evaluated starting point strategy consistent, is, f (X
maximum f probability 1 number instances tends infinity (in
worst case perform random search known converge maximum almost
surely). hand, algorithm favorable properties possible
design multi-start strategies still keep random search based consistency,
provide much faster convergence optimum terms number evaluations
f.
bn ) bounded non-decreasing, converges (no matter
Since sequence f (X
random effects occur search). next lemma, proved Appendix A, shows
that, high probability, convergence cannot arbitrarily slow.
bn ) = f .3 P (E) > 0,
Lemma 1 f [0, 1]d , let E denote event limn f (X
bn ) f
then, 0 < < 1 event E E 1 P (E ) < f (X
uniformly almost everywhere E . words, exists non-negative, nonincreasing function g (n) limn g (n) = 0



bt ) = f 1 .
b ) f (X
bn ) g (n) nfi lim f (X
P lim f (X
(1)




certain cases, g (n) = O(en ), shown Nesterov (2004) (gradient-based)
optimization convex functions, Gerencser Vago (2001) noise-free SPSA
convex functions, Kieffer (1982) k-means clustering (or Lloyds algorithm) one
dimension log-concave densities. results pertain simple situation
one local optimum global one, many results
extended general situations, observed exponential rate convergence
experiments functions many local maxima.
convergence property local search algorithms guaranteed Lemma 1
exploited next section derive efficient multi-start search strategies.

4. Multi-Start Search Strategies
Standard multi-start search strategies run instance seems converge
location hope beat currently best approximation f .
3. practice usually assume local search algorithms converge local optima, f may
assumed local optimum.

412

fiEfficient Multi-Start Strategies Local Search Algorithms

alternative way using multiple instances local search algorithms run algorithms
parallel, round decide algorithms take extra step. approach
may based estimating potential performance local search algorithm based
Lemma 1. Note g known, obvious way would run instance
possible performances become separated high probability sense
margin performance actually best second best algorithm
large actually best algorithm guaranteed best, long run,
high probability. could pick best instance run given
computational budget exhausted (this would simple adaptation explore-andexploit idea choosing best algorithm based trial phase Beck & Freuder,
2004; Carchrae & Beck, 2004).
practice, however, g usually known, certain problem classes local
search algorithms may known belong function class, example, g may
known (multiplicative) constant factor (here, example, constant may
depend certain characteristics f , maximum local steepness). Even
latter case, best instance still cannot selected high probability matter
large margin (as g may arbitrarily large). However, using ideas general
methodology Lipschitz optimization unknown constant (Jones et al., 1993),
get around problem estimate, certain optimistic way, potential
performance algorithm instance, round step promising
ones.
main idea resulting strategy summarized follows. Assume
K instances algorithm A, denoted A1 , . . . , AK . Let Xi,n , = 1, . . . , K denote
location f evaluated Ai nth time take step, Xi,1
starting point Ai . estimate location maximum algorithm Ai n
samples (steps)
bi,n = argmax f (Xi,t )
X
1tn

bi,n ).
maximum value function estimated fi,n = f (X
i, let = limn fi,n denote limiting estimate maximum f
provided Ai . Let g defined Lemma 1 largest values,
f = max .
i=1,...,K

Since f best achievable estimate maximum f given actual algorithms
A1 , . . . , AK , g gives high probability convergence rate algorithms provide
best estimate maximum long run (note assumption deals
limiting estimate usually local maximum separately, is, assumption
made algorithms whose limiting estimates less f ). Then, Ai evaluates f
ni,r points end rth round Ai converges best achievable estimate
f , Lemma 1 have, probability least 1 ,
fi,ni,r g (ni,r ),


fi,ni,r + g (ni,r )
413

(2)

fiGyorgy & Kocsis

optimistic estimate f . Ai suboptimal sense limn fi,n < f
estimate still optimistic rate convergence slower g ,
pessimistic rate convergence slower g . latter desirable sense
negatively biased estimate expected performance algorithm
want use (we waste samples suboptimal choices).
practice g usually known exactly, estimate (2) often cannot constructed. hand, g known constant factor construct
family estimates scales: Let g denote normalized version g
g (0) = 1 g (n)/g (n) constant n, construct family estimates
fi,ni,r + cg (ni,r )

(3)

c ranges positive reals. reasonable choose, round,
algorithms take another step provide largest estimate values c
(typically, algorithm gives largest estimate c = c interval
containing c algorithm provides largest estimate c I).
way get around fact know real scaling factor g ,
certainly use algorithms provide largest value (3) c = g (1)/g (1),
and, discussed later, waste many samples algorithms
maximize (3) values c. Using optimistic estimate (3) similar, spirit,
optimistic estimates standard upper confidence bound-type solution
multi-armed bandit problem (Auer, Cesa-Bianchi, & Fischer, 2002) well-known
search algorithm (Hart, Nilsson, & Raphael, 1968).
However, exact (local) convergence rate known, even constant factor,
many local search algorithms, even is, corresponding bounds usually
meaningful asymptotic regime, often practical interest. Therefore,
give freedom design algorithm, going use estimate
form
fi,ni,r + ch(ni,r )
(4)
where, similarly requirements g , h positive, monotone decreasing function
limn h(n) = 0. assume, without loss generality, h(0) = 1.
actual form h based theoretical analysis resulting algorithms
heuristic considerations. Essentially use h functions converge zero
exponentially fast, agreement exponentially fast local convergence rates
examples given Lemma 1. optimal choice h, given, example, g ,
known, left future work.
4.1 Constant Number Instances
idea translated algorithm MetaMax(K) shown Figure 1.
consider case fixed number instances, goal perform
(almost) well best (in hindsight), using minimum number
br
evaluations f . Note slight abuse notation MetaMax(K) algorithm X
fr denote estimates algorithm r rounds (and r steps/samples).
first part step (a) MetaMax sweep positive c select local
search algorithms maximize estimate (4). easy see, Ai maximizes
414

fiEfficient Multi-Start Strategies Local Search Algorithms

MetaMax(K): multi-start strategy K algorithm
instances.
Parameters: K > 0 positive, monotone decreasing function h
limn h(n) = 0.
Initialization: = 1, . . . , K, take step algorithm Ai
once, let ni,0 = 1 fi,0 = f (Xi,1 ).
round r = 1, 2, . . .
(a) = 1, . . . , K select algorithm Ai exists c > 0
fi,ni,r1 + ch(ni,r1 ) > fj,nj,r1 + ch(nj,r1 )

(5)

j = 1, . . . , K (ni,r1 , fi,ni,r1 ) 6= (nj,r1 , fj,nj,r1 ).
several values selected step number
ni,r1 keep one selected uniformly random.
(b) Step selected Ai , update variables. is, set ni,r =
ni,r1 + 1 Ai selected, ni,r = ni,r1 otherwise.
bi,n
selected Ai evaluate f (Xi,ni,r ) compute new estimates X
i,r
fi,ni,r .
(c) Let Ir = argmaxi=1,...,K fi,ni,r denote index algorithm
currently largest estimate f , estimate location
br = X
bIr ,n
maximum X
value fr = fIr ,nIr ,r .
Ir ,r
Figure 1: MetaMax(K) algorithm.
(4) particular c = u closed interval containing u Ai
maximizes (4) c I. Therefore, round, strategy MetaMax(K) selects
local search algorithms Ai corresponding point (h(ni,r1 ), fi,ni,r1 )
corner upper convex hull set
Pr = {(h(nj,r1 ), fj,nj,r1 ) : j = 1, . . . , K} {(0, max fj,nj,r1 )}.
1jK

(6)

selection mechanism illustrated Figure 2.
avoid confusion, note random selection step (a) MetaMax(K) implies
algorithms exactly state, is, (ni,r1 , fi,ni,r1 ) = (nj,r1 , fj,nj,r1 )
i, j, one algorithm selected uniformly random (this pathological situation
may arise, e.g., beginning algorithm local search algorithms give
estimate f range step numbers). Apart case one
least used algorithms provides currently best estimate, happens surely
first round usually happen later (and includes previous pathological case),
guaranteed round use least two algorithms, one largest
415

fiGyorgy & Kocsis

0.7

0.6

f(x)

0.5

0.4

0.3

0.2

0.1

0
0.2

0.3

0.4

0.5

h(n)

0.6

0.7

0.8

0.9

Figure 2: Selecting algorithm instances MetaMax: points represent algorithm
instances, algorithms lie corners upper convex hull
(drawn blue lines) selected.

estimate fi,ni,r1 = fr1 (for small values c), one smallest step number
nj,r1 (for large values c). Thus, usually half total number function
calls f used optimal local search algorithm. observation gives practical lower bound (which valid apart pathological situation mentioned above)
proportion function calls f made optimal local search algorithms; surprisingly,
Theorem 6 shows lower bound achieved algorithm asymptotically.
randomization step (a) precludes using multiple instances
step number introduced speed algorithm certain pathological cases.
example, A1 converges correct estimate, algorithms A2 , . . . , AK
produce estimate round, independently samples, inferior
estimates A1 , use randomization, half calls compute f
made A1 , without randomization would drop 1/K
round would use algorithm. Furthermore, could take step algorithms
lie convex hull, similar pathological examples constructed
beneficial use algorithms corners. hand, almost never
happens practice three algorithms lie line, algorithms typically
never fall non-corner points convex hull.
remainder section analyze performance MetaMax(K)
algorithm. Proposition 2 shows algorithm consistent sense performance asymptotically achieves best algorithm instance number rounds
increases. understand algorithm better, Lemma 3 provides general sufficient condition algorithm instance advanced given round, while, based
result, Lemma 4 provides conditions ensure suboptimal algorithm instances
used round stepped many times (i.e., evaluated f
many points) before. Lemma 5 gives upper bound number algorithm
416

fiEfficient Multi-Start Strategies Local Search Algorithms

instances used round. results lemmas used show Theorems 6
8 Remark 9 optimal algorithm instances used (asymptotically) least
minimum frequency that, turn, yields asymptotic rate convergence
MetaMax(K) algorithm.
following proposition shows MetaMax(K) algorithm consistent
sense:
Proposition 2 MetaMax(K) algorithm consistent sense fr f
r,

n
f lim fi,n .
f lim fr = min
r

i=1,...,K

n

Proof proof follows trivially fact algorithm selected infinitely
often, is, limr ni,r = . see latter, show every K rounds
number steps taken least used algorithm, is, mini=1,...,K ni,r , guaranteed
increase one. is, k 0,
min ni,kK k.

i=1,...,K

(7)

described above, round select exactly one algorithms made
least number steps. Thus, K algorithms, minimum step number
per algorithm increase K rounds, completes proof.
2
MetaMax(K) algorithm efficient suboptimal algorithms step
often. next lemma provides sufficient conditions algorithm used
given round.
Lemma 3 algorithm instance Aj used round r + 1 MetaMax(K)
algorithm, algorithms Ai Ak fi,ni,r > fj,nj,r > fk,nk,r either
ni,r nj,r


h(nj,r )
h(nj,r )


fj,nj,r fi,ni,r 1
(8)
+ fk,nk,r
h(nk,r )
h(nk,r )
Proof round algorithms corners convex hull Pr+1 used,
easy see algorithm Aj used round r algorithms Ai
Ak fi,ni,r > fj,nj,r > fk,nk,r either ni,r nj,r
fi,ni,r fk,nk,r
fi,ni,r fj,nj,r

.
h(nj,r ) h(ni,r )
h(nk,r ) h(ni,r )

(9)

finish proof show (8) implies latter. Indeed, (9) equivalent
h(nk,r )(fi,ni,r fj,nj,r ) h(nj,r )(fi,ni,r fk,nk,r ) + h(ni,r )(fk,nk,r fj,nj,r ).
last term right hand side inequality negative assumptions,
inequality satisfied
h(nk,r )(fi,ni,r fj,nj,r ) h(nj,r )(fi,ni,r fk,nk,r )
417

fiGyorgy & Kocsis

equivalent (8).

2

lemma provides conditions using algorithm instances certain
round depend actual performance instances. next result gives similar
conditions, however, based best estimates (usually local optima) achievable
algorithms. Let = limr fi,ni,r asymptotic estimate algorithm Ai f ,
let f = max1iK denote best estimate achievable using algorithms A1 , . . . , AK .
Let {1, . . . , K} set optimal algorithms converge best estimate
f (for algorithms), let |O| denote cardinality (i.e., number
optimal algorithm instances). Note random variable depends actual
realizations possibly randomized search sequences algorithms. next lemma
shows j 6 O, Aj used round r used often far.
Lemma 4 Let

= f max fj
j6O

denote margin estimates best second best algorithms.
0 < u < random index R(u) > 0 j 6 O, Aj
used MetaMax(K) round r + 1 > R(u)
!!



f
j
min ni,r
1
nj,r h1 h
.
(10)
i=1,...,K
f u
Furthermore, let 0 < < 1, O, let g,i denote convergence rate algorithm
Ai guaranteed Lemma 1, let g (n) = maxiO g,i (n) n. P (R(u)
) 1 (where g 1 generalized inverse g ), suboptimal
Kg1 (u)|f1 , . . . , fK


algorithm Aj , j 6 O, used r > Kg1 (u) probability least 1 |O| given
.
limiting estimates f1 , . . . , fK
Proof Let O. Since limn fi,n = = f assumption (7) implies
(u)
limr ni,r = , almost surely finite random index Ri > 0
(u)

r > Ri f fi,n
u
i,r
f fr u.

(11)

Using Lemma 1 easily derive high probability upper bound R(u) . Since
r > Kg1 (u) = R , (7) implies ni,r g1 (u), Lemma 1 yields



P fi,ni,r u r > R = f 1 .

follows probability least 1 |O| fi,ni,r u,
) |O| . Thus,
implies R(u) chosen P (R(u) > R |f1 , . . . , fK
prove lemma, enough show (10).
Clearly, (11), algorithm pick estimate one best algorithms
R(u) rounds. Let Ak algorithm least number steps taken end
418

fiEfficient Multi-Start Strategies Local Search Algorithms

round r, is, nk,r = mini ni,r . fk,nk,r fj,nj,r Aj used round r + 1.
Moreover, since Aj 6 O, fj,nj,r fj < fr case Aj used round r + 1
nj,r nIr ,r (recall nIr ,r number evaluations f initiated actually
best algorithm Ir ). Therefore, Lemma 3 implies Aj used r > R()
!
fj,nj,r fk,nk,r
h(nj,r ) h(nk,r ) 1
.
fr fk,n
k,r

clearly satisfied
h(nj,r ) h(min ni,r ) 1


fj
f u

!

(12)

0 < u < , since (11)
1

fj
fj,nj,r fk,nk,r
fj,nj,r
1
.
1
fr fk,nk,r
fr
f u

Applying inverse h sides (12) proves (10), and, hence, lemma.

2

result provides individual condition suboptimal algorithm
used round. hand, one optimal algorithms
stepped sufficiently many times, give cumulative upper bound number
suboptimal algorithms used round.
Lemma 5 Assume h decreases asymptotically least exponentially fast, is,
exist 0 < < 1 n > 0 h(n+1)
h(n) < n > n . Assume r large
enough ni,r > n i, let r = 1 maxi:fi,n

6=fr
i,r

fi,ni,r
fr

> 0.

r
ln
ln + 1 algorithms stepped round r + 1, x denotes smallest integer
least large x.

Proof Let i0 , i1 , . . . , im denote indices algorithms chosen round r + 1
fi0 ,r < fi1 ,r < < fim ,r = fr . Lemma 3 implies ni0 ,r < ni1 ,r < < nim ,r
fr fik ,r < (fr fik1 ,r )
k = 1, . . . , 1. Repeated application inequality implies
fr r fr fim1 ,r < (fr fim2 ,r ) < < m1 (fr fi0 ,r ) fr m1
yields

ln r
ln
assumed + 1 algorithms chosen round r + 1, fact finishes
proof.
2
m1<

419

fiGyorgy & Kocsis

Based Lemmas 4 5, next theorem shows local search algorithm
converges fast enough (exponentially problem dependent rate, faster exponential) half function calls evaluate f correspond optimal algorithm
instances.
Theorem 6 Assume performance algorithms Ai , = 1, . . . , K
same, is, |O| < K, suppose
(
)
fj
h(n + 1)
lim sup
.
(13)
< min 1
j6O
h(n)
n
f
asymptotically least half function
respond optimal algorithm. is,
P
ni,r
1
P lim inf PiO

K
r
2
i=1 ni,r

calls evaluate f MetaMax(K) cor!



f1 , . . . , fK
= 1.


Furthermore, 0 < < 1 > 0 constant R(,) > 0
$P
%!
K
n
i=1 i,r
f fr g
(2 + )|O|

(14)

(15)

simultaneously r > R(,) ,
probability least 1 |O| given f1 , . . . , fK
(,)
g defined Lemma 4, threshold R
> 0 depends , , h, g1 ,
1
g defined Lemma 4.

Proof show suboptimal Aj chosen large enough r nj,r > mink nk,r .
Lemma 4, sufficient prove that, large enough r,
!!
fj
1
(16)
min nk,r + 1 h
h(min nk,r ) 1
k
k
f u
0 < u < (recall r larger R(u) , almost surely finite
random index Lemma 4).
minimum (13) taken finite set, follows exists small
enough positive u <
(
)
fj
h(n + 1)
lim sup
,
(17)
min 1
j6O
h(n)
n
f u
clearly implies (16) limr mink nk,r = (7). fact finishes proof
(14), first part theorem.
Next prove (15). Let Nu > 0 threshold (17) holds n Nu .
Furthermore, Lemma 1 union bound, (1) holds local search algorithm
Ai g,i place g simultaneously probability least 1 |O|.
420

fiEfficient Multi-Start Strategies Local Search Algorithms

(7) slight modification Lemma 4 imply (16) holds simultaneously
.
r > K max{g1 (u), Nu } = R probability least 1 |O| given f1 , . . . , fK
Since
round two algorithms used, r > R + c
P
n
i,r
c+R
PiO
> 2c+KR
high probability. Since latter bounded 1/(2+)
K
n
i,r
i=1
PK
P
ni,r
c R (K2)/, iO ni,r i=1
r > R(,) = R +R (K2)/
2+

l P highmprobability. algorithm Ai , used least
K
i=1

ni,r
|O|(2+)

rounds, implying statement theorem via Lemma 1.

2

Remark 7 proof Theorem 6 based Lemma 4. proof based Lemma 5
possible, since setting = minj6O (1 fj /f ) lemma, (13) implies that,
large enough r, r , round approximately length 2 lemma.
may happen although decay rate h exponential, quite fast
enough satisfy (13), optimal scenarios theorem hold.
case turns number algorithms converging local maximum
plays key role determining usage frequency optimal algorithms.
Theorem 8 Assume estimates provided algorithms A1 , . . . , AK converge
N > 1 distinct limit points, k0 = |O| algorithms converge f , k1 , k2 , . . . , kN 1
algorithms converge suboptimal limit points, respectively. Suppose furthermore
h decreases asymptotically least exponentially fast, is, 0 < < 1,
lim supn h(n+1)
h(n) < .
P lim inf
r

P

iO ni,r
PK
i=1 ni,r

!


kmax

f , . . . , fK = 1.

K k0 + kmax 1

kmax = max1iN 1 ki .
Furthermore, using definitions Lemma 4 0 < < 1 > 0
constant threshold R(,)
%!
$
PK
k
n
max
i=1 i,r
f fr cg
(K k0 + kmax + )|O|
simultaneously r > R(,) ,
probability least 1 |O| given f1 , . . . , fK
R(,) depends , .,f1 , . . . , sfK convergence rate algorithms4 .
given, fix random trajectories algorithms.
Proof Suppose f1 , . . . , fK
single suboptimal algorithm statement trivial kmax /(K k0 +kmax ) =
1/2 round least two algorithms used, one
suboptimal one. assume least two suboptimal algorithms.
Assume Aj Ak converge suboptimal local maxima (strictly less f ).
r large enough, optimal algorithm Ai better suboptimal ones,

4. Instead convergence rate algorithms, R(,) may defined dependent g .

421

fiGyorgy & Kocsis

is, Ai converges f fi,ni,r > fj,nj,r , fk,nk,r . Assume, without loss generality,
fj,nj,r fk,nk,r . nj,r nk,r clearly Aj chosen round r + 1. Assume
nj,r > nk,r . Since fj,nj,r fk,nk,r convergent sequences (as r ), large enough
r have, j,k < 1,
1

fj,nj,r fk,nk,r
> j,k tj,k


fi,n fk,n
i,r

(18)

k,r

tj,k = ln j,k / ln positive integer. Note Aj Ak converge
point, is, limr (fj,nj,r fk,nk,r ) = 0, second term left hand side
(18) converges 0, j,k chosen , implying tj,k = 1. Rearranging
inequality one obtains
(1 tj,k )fi,ni,r + tj,k fk,nk,r > fj,nj,r .

(19)

nj nk tj,k , conditions h fact nj,r nk,r tend
infinity r (recall (7)) imply that, large enough r, h(nj,r )/h(nk,r ) < tj,k . Since
fi,ni,r fk,nk,r large enough r, (19) obtain


h(nj,r )
h(nj,r )
tj,k
tj,k

fk,nk,r .
fi,ni,r +
fj,nj,r < (1 )fi,ni,r + fk,nk,r 1
h(nk,r )
h(nk,r )
Thus, Lemma 3, r large enough, Aj cannot used round r + 1 nj,r nk,r tj,k .
Since nj,r nk,r tend infinity, follows that, large enough r,
|nj,r nk,r | tj,k

(20)

two suboptimal algorithms Aj Ak . Note fact implies
set suboptimal algorithms converging point, eventually one
used round (since corresponding thresholds tj,k = 1).
Clearly, (7) implies nj,r nk,r grow linearly r, since differences bounded (20), limr nj,r /nk,r = 1. Therefore, suboptimal algorithm
Aj , limn nj,r /r 1/kmax (this maximal rate using elements
largest group suboptimal algorithms converging local optimum). Finally,
optimal algorithm used round r, large enough r,
P
P
iO ni,r
iO ni,r
P
lim inf PK
= lim inf P
r
r
n
+
i,r
n
i6O ni,r
iO
i,r
i=1
kmax
r
lim
=
,
r
r r + (K k0 )
K k0 + kmax
kmax
used fact a/(a + b) increasing function a, b > 0. Since
,
inequality holds realizations trajectories A1 , . . . , AK , given f1 , . . . , fK
first statement theorem follows.
second statement follows similarly (15) Theorem 6. Since exact value
R(,) particular interest, derivation omitted.
2

422

fiEfficient Multi-Start Strategies Local Search Algorithms

Remark 9 main message theorem somewhat surprising observation
suboptimal algorithms slowed large group suboptimal algorithms
converging local optimum; rate suboptimal algorithms used bounded
size largest group.
4.2 Unbounded Number Instances
clear local search algorithms consistent (i.e., achieve
global optimum f ), then, despite favorable properties, MetaMax(K) strategy
inconsistent, too. However, increase number algorithms infinity
get consistency random search, still keeping reasonably fast convergence
rate MetaMax(K).
Clearly, one needs balance exploration exploitation, is,
control often introduce new algorithm. One solution let MetaMax
algorithm solve problem: MetaMax() algorithm, given Figure 3, extension MetaMax(K) able run infinitely many local search algorithm
instances. major issue new local search algorithms started
time time (this ensures algorithm converge global maximum f
since performs random search): implemented modifying step (a)
MetaMax(K) algorithm new, randomly initialized local search algorithm introduced round (randomly selecting one algorithm uniformly infinitely
many possible algorithms used far). Obviously, skip initialization
step MetaMax(K) start algorithm 0 samples. better control
length round (i.e., exploration), round r allow use different
function h, denoted hr1 may depend value measured round r (this
suppressed notation). before, assume hr (0) = 1, hr (n) monotone decreasing n, limn hr (n) = 0 r. Typically make hr1 dependent
PKr1
total number steps (i.e., function calls evaluate f ) tr1 = i=1
ni,r1 made
algorithms round r, Kr1 number algorithm instances used
round r; note Kr1 = r 1 r, start exactly one new algorithm
round.
desired that, although number local search algorithms grows infinity,
number times best local search algorithm advanced MetaMax()
algorithm approaches infinity reasonably fast. Somewhat relaxing random initialization
condition, may imagine situation local search algorithms initialized
clever, deterministic way, first steps find better
value initial guesses. algorithms optimal (this may viewed result
clever initialization), may provide, example, identical estimates
0.5, 0.5, 1 first three steps. easy see algorithm stepped
exactly twice, thus convergence optimum (which would found third
step) achieved. Although random initialization search algorithms guarantees
consistency MetaMax() (see Proposition 10 below), robust behavior even
pathological cases preferred.
achieved slight modification algorithm: round local search
algorithm overtakes currently best algorithm, is, Ir 6= Ir1 , algorithm AIr
423

fiGyorgy & Kocsis

MetaMax(): multi-start strategy infinitely many
algorithm instances.
Parameters: {hr }, set positive, monotone decreasing functions
limn hr (n) = 0.
round r = 1, 2, . . .
(a) Initialize algorithm Ar setting nr,r1 = 0, fr,0 = 0.
(b) = 1, . . . , r select algorithm Ai exists c > 0
fi,ni,r1 + chr1 (ni,r1 ) > fj,nj,r1 + chr1 (nj,r1 )
j = 1, . . . , r (ni,r1 , fi,ni,r1 ) 6= (nj,r1 , fj,nj,r1 ).
several values selected step number
ni,r1 keep one selected uniformly random.
(c) Step selected Ai , update variables. is, set ni,r =
ni,r1 + 1 Ai selected, ni,r = ni,r1 otherwise.
bi,n
selected Ai evaluate f (Xi,ni,r ) compute new estimates X
i,r
fi,ni,r .

(d) Let Ir = argmaxi=1,...,r fi,ni,r denote index algorithm
currently largest estimate f , estimate location
br = X
bIr ,n
maximum X
value fr = fIr ,nIr ,r .
Ir ,r
Figure 3: MetaMax() algorithm.

stepped several times used times AIr1 .5 resulting algorithm,
called MetaMax, given Figure 4. Note algorithms MetaMax()
MetaMax conceptually differ one place: step (c) extended step (c)
new algorithm. result, technical modification appears step (d), and,
simplify presentation MetaMax algorithm, slight, insignificant modification
introduced step (b), see discussion below.
modification MetaMax really significant practical examples
studied (see Section 5), number steps taken algorithm overtakes
currently best algorithm grows quickly MetaMax() algorithm, since
MetaMax overtake usually introduces short rounds (close minimum length
two many cases) leading algorithm becomes used one. goal
modification step (b) synchronize choice optimal algorithms
steps (b) (c). equally good solution would choose, case tie step
5. way achieve actually best algorithm dominates others terms accuracy
number calls made algorithms compute target function. type
dominance used Hutter et al. (2009) slightly different context.

424

fiEfficient Multi-Start Strategies Local Search Algorithms

MetaMax: multi-start strategy infinitely many
algorithm instances.
Parameters: {hr }, set positive, monotone decreasing functions
limn hr (n) = 0.
round r = 1, 2, . . .
(a) Initialize algorithm Ar setting nr,r1 = 0, fr,0 = 0.
(b) = 1, . . . , r select algorithm Ai exists c > 0
fi,ni,r1 + chr1 (ni,r1 ) > fj,nj,r1 + chr1 (nj,r1 )
j = 1, . . . , r (ni,r1 , fi,ni,r1 ) 6= (nj,r1 , fj,nj,r1 ).
several values selected step number
ni,r1 keep one smallest index.
(c) Step selected Ai , update variables. is, set ni,r =
ni,r1 + 1 Ai selected, ni,r = ni,r1 otherwise.
bi,n
selected Ai evaluate f (Xi,ni,r ) compute new estimates X
i,r

fi,ni,r .

(c) Let Ir = argmaxi=1,...,r fi,ni,r denote index algorithm
currently largest estimate f (in case Ir unique, choose
one smallest number steps ni,r ). Ir 6= Ir1 , step
algorithm AIr (nIr1 ,r nIr ,r + 1) times set nIr ,r = nIr1 ,r + 1.
br = X
bIr ,n
(d) Estimate location maximum X

Ir ,r
value fr = fIr ,nIr ,r .
Figure 4: MetaMax algorithm.

(c), algorithm used current round. note that, result
modifications, currently best algorithm (with index Ir ) taken steps,
extra number steps taken step (c) indeed positive. important consequence
modifications that, round r, number steps taken local search
algorithm AIr , best end round, r 2r (see Theorem 15
below).
rest section devoted theoretical analysis MetaMax()
MetaMax, following lines analysis provided MetaMax(K). First, Proposition 10, shown algorithm consistent, is, solution found
algorithm actually converges f . Lemma 12 (a counterpart Lemma 4) shows
suboptimal algorithms make finitely many steps, Lemma 14 gives upper
bound length round. main theoretical results section apply
425

fiGyorgy & Kocsis

MetaMax algorithm: Theorem 15 gives lower bound number steps taken
actually best algorithm end given round, while, consequence, Theorem 16 shows rate convergence algorithm function total number
steps (i.e., function calls evaluate f ) used algorithm instances: turns
quadratically steps needed generic local search algorithm instance
converges optimum.
Since MetaMax() MetaMax strategies perform random search (the
number algorithms tends infinity length round finite), algorithms
consistent:
Proposition 10 strategies MetaMax() MetaMax consistent.
is,
lim fr = f
r

almost surely.
Proof Clearly, event fr converge f written
n

\
n
[


[
lim fr 6= f =
fr < f 1/n

r

(21)

n=1 R=1 r=R

continuity f implies that, n, X chosen uniformly [0, 1]d
qn P
= P(f (X) > f 1/n) > 0. Thus, round r, P(fr < f 1/n) (1 qn )r ,



r=1 P(fr < f 1/n) finite. Therefore, Borel-Cantelli lemma (see, e.g., Ash &
Doleans-Dade, 2000) implies
!
n
[

\

=0
P
fr < f 1/n
R=1 r=R

n. This, together (21) finishes proof,
P



lim fr 6= f

r








X

n=1

P

n
[
\

R=1 r=R

fr < f 1/n




!

= 0.
2

reminder section assume local search algorithms achieve
almost optimal value eventually converge optimum.
Assumption 11 Let F R denote set local maxima f , let = f
supfF ,f<f f. assume > 0 algorithm Ai fi,n > f
n, limn fi,n = f .
local search algorithms converge local optima (which reasonable assumption
practice), assumption usually satisfied: situation
hold pathological case f infinitely many local maxima set
maxima dense global maximum.
426

fiEfficient Multi-Start Strategies Local Search Algorithms

Assumption 11 prove, similarly Lemma 4, suboptimal algorithm selected limited number times increases h1
r . particular,
hr = h r large enough, suboptimal algorithm chosen finitely many
times.
Lemma 12 Suppose Assumption 11, let q = P(f (X) > f /2) X uniformly
distributed [0, 1]d . Then, MetaMax() MetaMax algorithms,
suboptimal algorithm Aj started round r +1 used round r +1, probability
least 1 (1 q)r ,



1
nj,r hr
.
2f
addition, hr (n) non-decreasing function r n,
lim sup
r

h1
r1

n
j,r



2f

<

almost surely.

(22)

particular, hr constant function, is, hr = h0 r, limr nj,r <
almost surely.
Remark 13 Note second
part lemma coulddrop
monotonicity
1
1


assumption hr replace hr1 2f max0r r1 hr 2f (22).
Proof Consider algorithm Aj used round r + 1. First note probability
least 1 (1 q)r , fr > f /2. Furthermore, newly introduced algorithm, Ar+1
used yet, nr+1,r = 0 fr+1,0 = 0. Thus, Lemma 3, Aj used


h(nj,r )


= fr (1 hr (nj,r )) .
fj,nj,r fr 1
hr (0)
Since equivalent
nj,r

h1
r

fj,nj,r
1
fr

h1
r

fj,nj,r
1
fr

!





h1
r



!

,


2f



fr fj,nj,r

fr (f )
(f /2) (f )
=
,
(23)

>

f /2
2f
fr
fr
first statement proof follows.
b denote first round optimal
prove second part, let R


algorithm Ai fi,ni,Rb > f /2. suboptimal algorithm Aj , first part
b
lemma implies that, r > R,










1
1
b
b
+ 1 = max R, hr1
+1
nj,r max R, max
h
0r r1 r
2f
2f
427

fiGyorgy & Kocsis

equality holds since h1
r (n) non-decreasing r. Thus




b
nj,r
R
1
lim sup max
, 1 +




lim sup



h1

r h1
r
h1
r1 2f
r1 2f
r1 2f




b
1
R
, 1 +



max



h1
h1
0

0

2f

(24)

2f

b finite, (24) finite
used h1
non-decreasing r. Since R
r
probability 1.
2
simple modification Lemma 5 implies /2-optimal sample point
found limited number suboptimal algorithms chosen round.
Lemma 14 Consider algorithms MetaMax() MetaMax. Suppose Assumption 11
holds, assume f fR < /2 R > 0. anyround r > R, hr (n) = rn


0 < r < 1 n 0,

ln 2f
ln(1/r )

algorithms chosen

estimates fj f .

Proof proof follows Lemma 5 taking account suboptimal algorithm
Aj satisfies fj f least one optimal algorithm chosen round
r > R: Similarly (23), r defined Lemma 5 bounded r > /(2f ),

l
2f
ln
ln(1/r )

number suboptimal algorithms used round r bounded ln(1/
.
ln(1/
r)
r)
2
Finally derive convergence rate algorithm MetaMax. First bound
number steps taken currently best algorithm, terms number
rounds total number steps taken local search algorithms.
Theorem 15 Consider MetaMax algorithm. end round r number
steps taken currently best algorithm r 2r. is,
r nIr ,r < 2r.

(25)

Furthermore, number calls nIr ,r evaluate f currently
best algorithm AIr
Pr
bounded function total number times tr = i=1 ni,r target function f
evaluated local search instances

2tr + 7 1
nIr ,r
.
(26)
2
Proof first statement lemma simple, since round actually
best algorithm takes one step overtaking, one two steps
428

fiEfficient Multi-Start Strategies Local Search Algorithms

overtaking. Indeed, round r 2, overtaking, is, Ir = Ir1 ,
nIr ,r = nIr ,r1 + 1. Otherwise, Ir 6= Ir1 , nIr ,r = nIr1 ,r + 1, since
0 nIr1 ,r nIr1 ,r1 1,
1 nIr ,r nIr1 ,r1 2
situations. Since first round clearly algorithm used takes 1 step,
is, nI1 ,1 = 1, (25) follows.
prove second part, notice round r, nIr1 ,r1 + 1 algorithms
stepped step (c) algorithm used taken steps
currently best one. Also, step (c) extra samples used overtaking.
case overtaking, AIr advanced step (c), well AIr1 ,
nIr1 ,r1 + 1 extra steps taken AIr . Therefore,
tr tr1 + 2nIr1 ,r1 + 2.
Thus, since overtaking happens round 1, obtain
tr 1 +

r
X

2(nIs1 ,s1 + 1).

s=2

Then, (25)
tr 1 + 4

r
X
s=2

= 1 + 2(r + 2)(r 1) 1 + 2(nIr ,r + 2)(nIr ,r 1)

yields (26).

2

Note proof used crude estimate length usual round (without
overtaking) relative to, example, Lemma 14. This, however, affects result
constant factor long able bound number rounds number
extra steps taken overtaking happens, since effect overtakings
introduces quadratic dependence proof (26). Experimental results Section 5
show (see Figure 10) number algorithm instances (which turn number r
rounds) usual growth rate (tr / ln tr ), which, taken account, may sharpen
bound often best algorithm chosen.
Assumption 11, random search component MetaMax implies eventually optimal algorithm best. point convergence
rate optimal local search algorithms determine performance search,
number steps taken best local search algorithm bounded Theorem 15.
Theorem 16 Suppose Assumption 11 holds. almost surely finite random
index R rounds r > R, estimate fr MetaMax algorithm
total number steps tr taken local search algorithms end round r
satisfies


2t
+
7

1
r

f fr g
2
probability least 1 , g defined Lemma 1 global maximum f .
429

fiGyorgy & Kocsis

Remark 17 (i) value R bounded high probability using properties
uniform random search actual problem; would yield similar bounds
Theorems 6 8 MetaMax(K) algorithm. (ii) Note exploration-exploitation
trade-off MetaMax algorithm: value R potentially decreased introduce
new algorithms often, nIr ,r reduced time. (iii) Theorems 15 16
imply that, asymptotically, MetaMax algorithm needs quadratically function
evaluations local search algorithm
Psthat ensured converge optimum.
particular, f form f (x) =
i=1 (x)ISi (x) Si form partition
[0, 1]d , ISi denotes indicator function Si , belong nicely behaving
function class local search algorithm started Si converges maximum
Si (e.g., f piecewise concave function exponential convergence rate
SPSA algorithm, used sufficiently small step size), preserve
performance local search algorithm original function class price
asymptotically quadratic increase number function calls evaluate f (i.e.,
total number steps taken local search algorithm instances).
4.3 Discussion Results
sense theoretical results presented previous sections weak.
consistency result MetaMax(K) algorithm follows easily fact
local search algorithm used infinitely many times, consistency MetaMax()
MetaMax follows consistency random search. performance bounds
provided disadvantage asymptotic sense hold
possibly large number rounds (a weakness bounds minimum number
rounds obtained properties uniform random search/sampling particular
problem, neglecting attractive properties algorithms). fact, quite easy
construct scheduling strategies consistent asymptotically arbitrarily
large fraction function evaluations (even almost all) used optimal local search
algorithms: explore-and-exploit algorithms achieve goals number
function evaluations used known ahead use arbitrarily small fraction
evaluations target function f exploration. compare performance
algorithms explore-and-exploit algorithms Section 5. particular, match
performance guarantees MetaMax family, use algorithms spend half
time exploration half exploitation, exploration part
uniform allocation strategy used finite number local search algorithms,
schedule Luby et al. (1993) used infinitely many local search algorithms.
Although theoretical guarantees proved paper MetaMax family hold
explore-and-exploit algorithms, experiments MetaMax family seems
behave superior compared algorithms, expected.
theoretical results give sufficient guidance chose parameter
h hr (the time-varying version h considered MetaMax(K) algorithm
simplicity ease presentation). results require sufficiently fast
exponential decay h, problem dependent cannot determined advance.
sufficiently fast decay rate would ensure, example, MetaMax(K) algorithm
could always use stronger results Theorem 6 would never deal
430

fiEfficient Multi-Start Strategies Local Search Algorithms

case bound Theorem 8 holds. One may easily choose h
function decreases super-exponentially: would make asymptotic bounds work,
however, would slow exploration (in extreme case hr (n) 0, excluded
conditions, exploration would performed, algorithms would use
actually best local search algorithm). practice always found
appropriate chose hr decay exponentially. Furthermore, found even
effective gradually decrease decay rate enhance exploration time elapses (the
rationale behind approach assumption good algorithms
less converged while, may greater potential exploration
improve estimates). Finally, connection g h
investigated.
Keeping limitations theoretical results mind, still believe
theoretical analyses given provide important insight algorithms may guide
potential user practical applications, especially since properties MetaMax
family proved asymptotic regime (e.g., rounds quite short)
usually observed practice, well. Furthermore, think possible
improve analysis bound thresholds results become valid
reasonable values, would require different approach and, therefore, left
future work.

5. Experiments
variants MetaMax algorithm tested synthetic real examples. Since
negligible difference performance MetaMax() MetaMax,6
following present results MetaMax(K) MetaMax. First demonstrate performance algorithm optimizing synthetic function (using SPSA
local search algorithm). Next behavior algorithm tested standard data
sets. show MetaMax applied tuning parameters machine learning
algorithms: classification task solved neural network, parameters
training algorithm (back-propagation) fine-tuned MetaMax combined SPSA.
MetaMax applied boost performance k-means clustering. end
section, compare results experiments theoretical bounds obtained
Section 4.2.
experiments, accordance simplifying assumptions introduced
Section 3, main difference individual runs particular local search
algorithm starting point. Obviously, general diversification techniques exist:
example, parameters local search algorithm could vary instance
instance (including running instances different local search algorithms, parameter would select actually employed search algorithm), initialization (starting
point parametrization) new instance could depend results delivered
6. example, relative difference average error eMetaMax() MetaMax()
eMetaMax MetaMax optimizing parameters multi-layer perceptron learning letter
data set (see Section 5.1 especially Figure 6, right details) 0.033 standard
deviation 0.06 (averaged
1000 experiments), relative difference defined


fieMetaMax() eMetaMax / max(eMetaMax() , eMetaMax ).

431

fiGyorgy & Kocsis

existing instances. Although MetaMax strategies could applied
general scenarios, behavior better studied simpler scenario; hence,
experiments correspond setup.
5.1 Optimizing Parameters SPSA
section compare two versions MetaMax algorithm six multi-start
strategies, including three constant three variable number algorithm
instances. strategies run fixed time steps, is, target function
evaluated times, together local search instances (note several reference
strategies use parameter).
used SPSA (Simultaneous Perturbation Stochastic Approximation; Spall, 1992)
base local search algorithm cases. SPSA local search algorithm sampling
function uses gradient descent stochastic approximation derivative:
actual location Xt = (Xt,1 , . . . , Xt,d ), SPSA estimates lth partial derivative f
f (Xt + Bt ) f (Xt Bt )
,
ft,l (Xt,l ) =
2t Bt,l
Bt,l i.i.d. Bernoulli random variables components vector
Bt , uses sampling function st (Xt ) = Xt + ft (Xt ) choose next point
sampled, is,
Xt+1,l = Xt,l + ft,l (Xt,l )
l = 1, . . . , (t scalar parameters).
implementation algorithm followed guidelines provided
(Spall, 1998), gain sequence = a/(A + + 1) , perturbation size =
/(t + 1) , = 60, = 0.602 = 0.101. values vary
different experiments; chosen heuristically based experience similar
problems (this cause problem here, goal experiments
provide fast solutions global optimization problems hand demonstrate
behavior multi-start algorithms compared). addition two evaluations
required perturbed points, evaluate function current point Xt .
starting point chosen randomly, function evaluated first point.
six reference algorithms MetaMax(K) MetaMax algorithms compared following:
Unif: algorithm selects constant number instances SPSA uniformly.
implementation instance = mod K selected time t, K denotes
number instances.
ThrAsc: Threshold Ascent algorithm Streeter Smith (2006b). algorithm begins selecting fixed number instances once. phase
time step ThrAsc selects best estimates produced far algorithm
instances Ai , = 1, . . . , K previous time steps, Ai counts
many estimates produced Ai . Denoting latter value Si,t , time
algorithm selects instance index = argmaxi U (Si,t /ni,t , ni,t ), ni,t
432

fiEfficient Multi-Start Strategies Local Search Algorithms

number times ith instance selected time t,
U (, n) = +

+

p
2n + 2
n

= ln(2T K/). parameters algorithm, experiments
best value appeared 100, set 0.01. note Threshold
Ascent developed maximum K-armed bandit problem; nevertheless,
provides sufficiently good performance setup test experiments.
Rand: random search algorithm. seen running sequence SPSA
algorithms instance used exactly one step, evaluation
random starting point SPSA algorithm.
Luby: algorithm based work Luby et al. (1993). method runs several
instances SPSA sequentially other, ith instance run ti steps,
ti defined

2k1 ,
= 2k 1
ti =
ti2k1 +1 ,
2k1 < 2k 1
definition produces schedule first 2k 1 algorithm instances
one run 2k1 steps, two 2k2 steps, four 2k3 steps, on.
EE-Unif: algorithm instance explore-and-exploit algorithms. first
/2 steps Unif algorithm used exploration, and, subsequently, exploration
phase, SPSA instance achieved highest value exploration phase
selected.
EE-Luby: algorithm similar EE-Unif, except Luby used exploration.
versions MetaMax algorithm tested. Motivated fact SPSA
known converge global optimum exponentially fast f satisfies restrictive
conditions (Gerencser & Vago, 2001), chose hr (n) decays exponentially fast.
control exploration far suboptimal algorithm instances, allowed hr (n)
time-varying function, is, changes tr , total number function calls
evaluate f (or equally, total number steps taken) algorithms far. Thus,
round r + 1 used


hr (n) = en/

tr

(27)

(note used time-varying version hr case MetaMax(K)
latter easily extended situation, omitted simplify
presentation).
algorithms fixed number local search instances (MetaMax(K), Unif,
EE-Unif, ThrAsc), number instances K set 100 simulations,
choice provided reasonably good performance problems analyzed.
multi-start algorithms tested using two versions synthetic function,
tuning parameters learning algorithm two standard data sets.
433

fiGyorgy & Kocsis

synthetic function slightly modified7 version Griewank function (Griewank,
1981):



2xl X 4 2 x2l
cos
f (x) =
100
l
l=1
l=1
x = (x1 , . . . , xd ) xl constrained interval [1, 1]. show
results 2-dimensional 10-dimensional cases.
parameters SPSA = 0.05 = 0.1 2-dimensional case,
= 0.5 = 0.1 10-dimensional case. performance search algorithms
measured error defined difference maximum value
function (in case 1) best result obtained search algorithm given
number steps. results multi-start strategies two- 10dimensional test functions shown Figure 5. error curve averaged 10,000
runs, strategy run 100,000 steps (or iterations). One may observe
cases two versions MetaMax algorithm converge fastest. ThrAsc
better Unif, Luby seems fairly competitive two. two exploreand-exploit-type algorithms (EE-Unif EE-Luby) similar performance 2dimensional function, clearly better non-exploiting base algorithms,
10-dimensional function behavior somewhat pathological sense low
values performances best among algorithms, increasing ,
error actually increases respective base algorithms achieve smaller errors
values . random search seems option 2-dimensional function.
Similar results obtained dimensions 2 10. pathological behavior
explore-and-exploit algorithms start appear gradually starting 5-dimensional
function, pronounced 8 dimensions onwards. Limited experimental data
obtained higher dimensions 100 (averaged hundred runs) shows
superiority MetaMax preserved high-dimensional problems well.
reason pathological behavior explore-and-exploit strategies (i.e.,
error curves monotone decreasing number iterations) illustrated
follows. Assume two SPSA instances, one converging global optimum
another one converging suboptimal local optimum. Assume first
steps optimal algorithm gives better result, suboptimal algorithm takes
reaches local maximum, algorithms run even further, optimal
algorithm beats suboptimal one. exploration stopped first last
regime, explore-and-exploit algorithm choose first, optimal local search instance,
whose performance may get quite close global optimum exploitation phase
(even stopped first regime). exploration stopped middle regime,
suboptimal search instance selected exploitation, whose performance may
even get close global optimum. scenario, error exploitation
phase (i.e. end) lower small, increases higher values . Decrease
error increasing assured optimal instance converges
exploration phase past suboptimal local optima, results selecting optimal
local search instance exploitation. scenario error decrease fast
7. modification made order significant differences values function
global maximum local maxima.

434

fi10

10

1

1

0.1

0.1

average error

average error

Efficient Multi-Start Strategies Local Search Algorithms

0.01

0.001

0.0001

0.001

0.0001
Rand
Luby
Unif
ThrAsc
EE-Luby
EE-Unif
MetaMax100
MetaMax

1e-05

1e-06

0.01

1

Rand
Luby
Unif
ThrAsc
EE-Luby
EE-Unif
MetaMax100
MetaMax

1e-05

10

100

1000

10000

1e-06

100000

1

10

iteration

100

1000

10000

100000

iteration

Figure 5: average error multi-start strategies 2-dimensional (left)
10-dimensional (right) modified Griewank function. 99% confidence intervals
shown color corresponding curves. Note
intervals small.
1

0.1

0.01

0.01

average error

average error

0.1

0.001

0.0001
Rand
Luby
Unif
ThrAsc
EE-Luby
EE-Unif
MetaMax100
MetaMax

1e-05

1e-06

1

0.001

0.0001

Rand
Luby
Unif
ThrAsc
EE-Luby
EE-Unif
MetaMax100
MetaMax

1e-05

10

100

1000

10000

100000

iteration

1e-06

1

10

100

1000

10000

100000

iteration

Figure 6: average error multi-start strategies tuning parameters Multilayer Perceptron vehicle data set (left) letter data set (right).
99% confidence intervals shown color corresponding
curves.

initially, increase may decrease till converges 0,
quite similar observe Figure 5, right. pathological behavior
becomes transparent many local search algorithms, length
exploitation phase scales number local search instances length
exploration instance kept fixed. Analyzing experimental data shows
complex versions scenario outlined occurred simulations
main cause observed pathological behavior (the non-monotonicity error
curves).
tuning parameters learning algorithm, used two standard data
sets UCI Machine Learning Repository (Asuncion & Newman, 2007): vehicle
435

fiGyorgy & Kocsis

letter, Multilayer Perceptron learning algorithm Weka (Witten & Frank, 2005)
(here back-propagation algorithm used training phase). Two parameters
tuned: learning rate momentum, range [0, 1]. size
hidden layer Multilayer Perceptron set 8, number epochs
100. parameters SPSA algorithm = 0.5 = 0.1,
10-dimensional Griewank function (as previous experiment, parameters
chosen based experience). rate correctly classified items test set
vehicle using Multilayer Perceptron varying values two parameters shown
Figure 7, highest rate 0.910112. Similarly, classification rate letter
shown Figure 8, highest rate 0.7505.
error rates optimized Multilayer Perceptron data sets vehicle
letter shown Figure 6, parameters learning algorithm tuned
multi-start strategies above. error cases difference
best classification rate obtained (0.910112 0.7505, respectively)
best classification rate obtained multi-start strategies given number steps.
results shown averaged 1,000 runs. observe MetaMax algorithm
(with increasing number algorithm instances) converged fastest average, three
strategies fixed number algorithm instances nearly identical results, Luby
(and explore-and-exploit variant) slightly worse these, random search
slowest, although performed nearly badly synthetic functions.
reason random search relatively better performance (relative
used SPSA) could twofold: (i) large parts error surface offer fairly small error,
(ii) error surface less smooth, therefore SPSA less successful using
gradient information. explore-and-exploit variants performed well vehicle data
set initially, performance worsened larger values (compared MetaMax,
algorithms extent). This, coupled observation Figure 5,
right would suggest explore-and-exploit variants competitive small values
, despite asymptotic guarantees.
summary, MetaMax algorithm (with increasing number algorithm instances) provided far best performance tests, usually requiring significantly
fewer steps find optimum algorithms. E.g., letter data set
MetaMax algorithm found global optimum runs 100,000 time steps.
conclude MetaMax converged faster multi-start strategies investigated four test cases, notable advantage difficult surfaces (at least
gradient-based optimization viewpoint) induced classification tasks.
5.2 k-Means Clustering
section consider problem partitioning set d-dimensional real vectors
xj Rd , j = 1, . . . , N clusters, cluster Si represented center (or
reconstruction) point ci Rd , = 1, . . . , N . cost function minimized sum
distances
PN(x,Pci ) data points corresponding centers, is, want
minimize i=1 xSi (x, ci ). two necessary conditions optimality (see, e.g.,
Linde, Buzo, & Gray, 1980; Gersho & Gray, 1992): = 1, . . . , N ,
Si = {x : (x, ci ) (x, cj ) j = 1, . . . , N }
436

(28)

fiEfficient Multi-Start Strategies Local Search Algorithms

Figure 7: Classification rate vehicle data set. rates plotted subtracting
0.911112 thus global optima scattered black spots
corresponding value equal 0.001.

Figure 8: Classification rate letter data set. rates plotted subtracting 0.7515 thus global optima scattered black spots
corresponding value equal 0.001.

(with ties broken arbitrarily)
ci = argmin
cRd

X

xSi

437

(x, c).

(29)

fiGyorgy & Kocsis

P

x

8

usual choice squared Euclidean distance, case ci = xS
|Si | . According necessary conditions, k-means algorithm (or Generalized-Lloyd
algorithm, see, e.g., Linde et al., 1980; Gersho & Gray, 1992) alternates partitioning data set according (28) centers fixed, recomputing
centers (29) partitioning kept fixed. easily seen cost
(or error) cannot increase steps, hence algorithm converges
local minimum cost function. practice, algorithm stops (or
insufficient) decrease cost function. However, k-means algorithm often trapped
local optimum, whose value influenced initial set centers. SPSA,
restarting k-means different initialization may result finding global optimum.
consider two initialization techniques: first, termed k-means, chooses centers
uniformly random data points; second, k-means++ (Arthur & Vassilvitskii,
2007) chooses initial center uniformly random data set, chooses
centers data points probability proportional distance
data point closest center already selected.

k-means algorithm usually terminates relatively small number steps,
thus multi-start strategies bounded number instances would run active local
search algorithms, therefore appear particularly attractive. However,
natural domain consider strategy starts new instance, previous
finished. strategy referred subsequently Serial. mentioned
considerations, test MetaMax, variant algorithms applicable
unbounded number instances.9 experiments SPSA, used hr (27).
Note theoretical results indicate k-means may converge exponential
rate (in particular, Kieffer, 1982 showed rate convergence exponential
random variables log-concave densities 1-dimension provided logarithm
density piecewise affine).
Two multi-start strategies, Serial MetaMax tested data set cloud
UCI Machine Learning Repository (Asuncion & Newman, 2007). data set
employed Arthur Vassilvitskii (2007) well. number clusters set
ten. performance multi-start strategies defined difference
smallest cost function obtained strategy given number steps smallest
cost seen experiments (5626.6357). results averaged 1,000 runs
plotted Figure 9. initialization methods MetaMax strategy converges
faster Serial strategy. note data set, k-means++
clever initialization procedure yields faster convergence standard k-means
uniform initialization, consistent results presented Arthur
Vassilvitskii (2007).

8. extension clustering random variables well-known straightforward, omitted
paper consider clustering finite data sets.
9. Note MetaMax algorithm practical modification local search
algorithm terminated chosen anymore. clearly improves performance
algorithm chosen anymore improvement observed.

438

fiEfficient Multi-Start Strategies Local Search Algorithms

100000

10000
1000
100

average error

average error

10000

1000

100

10
1
0.1
0.01
0.001

10

0.0001
1

Serial kmeans
MetaMax kmeans

1

10

100

1000

10000

100000

iteration

1e-05

Serial kmeans++
MetaMax kmeans++

1

10

100

1000

10000

100000

iteration

Figure 9: average error multi-start strategies k-means (left) kmeans++ (right). 99% confidence intervals shown color
corresponding curves.

5.3 Practical Considerations
experiments MetaMax algorithm presented above, observed
number algorithm instances r (shown Figure 10) grows rate (tr / ln tr ) (recall
tr total number function calls evaluate f , total number steps,
algorithm instances end round r). hand, derivation

theoretical bounds (see Theorem 15 Theorem 16) used bound r ( tr ).
contrast quadratic penalty suggested Theorem 16, plugging (tr / ln tr )
estimate r theorem would find logarithmic factor calls
evaluate f (total number steps) needed achieve performance search
algorithm started attraction region optimum.
Finally, perhaps main practical question concerning MetaMax family multistart algorithms decide use them. rule thumb, say
sufficiently large performance difference average run
local search algorithm best one. Clearly, single local search produces
acceptable result worth effort run several instances local search,
especially complicated schedule. many real problems often case
relatively easy get close optimum, may acceptable
applications, approaching optimum greater precision hard; latter
importance, MetaMax algorithm variants may useful. Last, one may
wonder computational costs algorithms. discussed before,
consider case evaluation target function expensive: clearly
case Griewank function, used demonstrate basic properties
algorithm, holds many optimization problems practice, including
experiments considered paper. problems function evaluation
indeed expensive (and depends available data), overhead introduced
MetaMax algorithms depends number rounds. MetaMax(K)
algorithm find upper convex hull set K points round;
worst case take long O(K 2 ) calculations, practice usually
439

fiGyorgy & Kocsis

number algorithm instances * ln(t)/t

1.8

Griewank 2D
Griewank 10D
vehicle
letter
K-MEANS
K-MEANS++
min
max

1.6
1.4
1.2
1
0.8
0.6
0.4
0.2

1

10

100

1000

10000

100000

iteration

Figure 10: Number algorithm instances (r) MetaMax. average number
instances shown six benchmarks: Griewank function (2- 10dimensional), parameter tuning Multilayer Perceptron (on vehicle
letter data set), clustering k-means k-means++.
maximum minimum number instances runs benchmarks
shown. One notice larger values tr , 0.45tr / ln tr r
1.65tr / ln tr .

much cheaper, upper convex hull determined point corresponds
actually best estimate point corresponds least used algorithm,
requires O(K) computations, even less, special ordering tricks
introduced. Since target function f evaluated least twice round, average
O(K 2 ) computational overhead needed evaluation f worst
case, practically reduced O(K), even less. Similar considerations hold
MetaMax() MetaMax algorithms, resulting average O(r2 ) worst-case
overhead call f (in r rounds), closer O(r) even less practice.
examples considered (apart case Griewank function), amount
overhead negligible relative computational resources needed evaluate
f single point.

6. Conclusions
paper provided multi-start strategies local search algorithms. strategies
continuously estimate potential performance algorithm instance optimistic
way, supposing convergence rate local search algorithms unknown
constant, every phase resources allocated instances could converge
optimum particular range constant. Three versions algorithm
presented, one able follow performance best fixed number
local search algorithm instances, two that, gradually increasing number
local search algorithms, achieve global consistency. theoretical analysis asymptotic
440

fiEfficient Multi-Start Strategies Local Search Algorithms

behavior algorithms given. Specifically, mild conditions
function maximized (e.g., set values local maxima dense
global maximum), best algorithm, MetaMax, preserves performance local
search algorithm original function class quadratic increase
number times target function needs evaluated (asymptotically). Simulations
demonstrate algorithms work quite well practice.
theoretical bound suggests target function evaluated
quadratic factor times achieve performance search algorithm started
attraction region optimum, experiments found logarithmic
penalty. clear whether difference result slightly conservative
(asymptotic) analysis choice experimental settings. Also, finite sample
analysis algorithm interest, experiments indicate MetaMax
algorithm provides good performance even relatively small number steps taken
local search algorithms, sense provides speed-up compared
approaches even number times target function evaluated (i.e., total
number steps taken algorithms together) relatively small. Finally,
future work needed clarify connection convergence rate optimal
algorithms (g ) function hr used exploration.

Acknowledgments
authors would thank anonymous referees numerous insightful
constructive comments. research supported part Mobile Innovation
Center Hungary, National Development Agency Hungary Research
Technological Innovation Fund (KTIA-OTKA CNK 77782), PASCAL2 Network
Excellence (EC grant no. 216886). Parts paper presented ECML 2009
(Kocsis & Gyorgy, 2009).

Appendix A. Proof Lemma 1
bn ). Since Un 0 almost everywhere E, Egoroffs
Fix (0, 1) let Un = f f (X
theorem (see, e.g. Ash & Doleans-Dade, 2000) implies event E E
1 P (E ) < Un 0 uniformly almost everywhere E . second part
lemma follows definition uniform convergence.
2

References
Adam, K. (2001). Learning searching best alternative. Journal Economic
Theory, 101, 252280.
Arthur, D., & Vassilvitskii, S. (2007). k-means++: advantages careful seeding.
Proceedings 18th Annual ACM-SIAM Symposium Discrete Algorithms, pp.
10271035.
Ash, R. B., & Doleans-Dade, C. A. (2000). Probability & Measure Theory. Academic Press.
441

fiGyorgy & Kocsis

Asuncion, A., & Newman, D. J. (2007). UCI machine learning repository.
Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite time analysis multiarmed
bandit problem. Machine Learning, 47 (2-3), 235256.
Bartz-Beielstein, T. (2006). Experimental Research Evolutionary Computation
New Experimentalism. Natural Computing Series. Springer, New York.
Battiti, R., Brunato, M., & Mascia, F. (2008). Reactive Search Intelligent Optimization,
Vol. 45 Operations research/Computer Science Interfaces. Springer Verlag.
Beck, C. J., & Freuder, E. C. (2004). Simple rules low-knowledge algorithm selection.
Regin, J. C., & Rueher, M. (Eds.), CPAIOR, Lecture Notes Computer Science
3011, pp. 5064. Springer.
Carchrae, T., & Beck, J. C. (2004). Low-knowledge algorithm control. Proceedings
Nineteenth National Conference Artificial Intelligence (AAAI), pp. 4954.
Cicirello, V. A., & Smith, S. F. (2004). Heuristic selection stochastic search optimization:
Modeling solution quality extreme value theory. Proceedings 10th
International Conference Principles Practice Constraint Programming, pp.
197211. Springer.
Cicirello, V. A., & Smith, S. F. (2005). max k-armed bandit: new model exploration
applied search heuristic selection. Proceedings Twentieth National
Conference Artificial Intelligence, pp. 13551361.
Finkel, D. E., & Kelley, C. T. (2004). Convergence analysis direct algorithm. Tech.
rep. CRSC-TR04-28, NCSU Mathematics Department.
Gagliolo, M., & Schmidhuber, J. (2006). Learning dynamic algorithm portfolios. Annals
Mathematics Artificial Intelligence, 47 (34), 295328. AI&MATH 2006 Special
Issue.
Gagliolo, M., & Schmidhuber, J. (2007). Learning restart strategies. Veloso, M. M. (Ed.),
IJCAI 2007 Twentieth International Joint Conference Artificial Intelligence,
vol. 1, pp. 792797. AAAI Press.
Gagliolo, M., & Schmidhuber, J. (2010). Algorithm selection bandit problem
unbounded losses. Blum, C., & Battiti, R. (Eds.), Learning Intelligent Optimization, Vol. 6073 Lecture Notes Computer Science, pp. 8296. Springer
Berlin/Heidelberg.
Gerencser, L., & Vago, Z. (2001). mathematics noise-free SPSA. Proceedings
IEEE Conference Decision Control, pp. 44004405.
Gersho, A., & Gray, R. M. (1992). Vector Quantization Signal Compression. Kluwer,
Boston.
Griewank, A. O. (1981). Generalized descent global optimization. Journal Optimization Theory Applications, 34, 1139.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. Systems Science Cybernetics, IEEE Transactions on,
4 (2), 100 107.
442

fiEfficient Multi-Start Strategies Local Search Algorithms

Hoos, H. H., & Stutzle, T. (1999). Towards characterisation behaviour stochastic
local search algorithms SAT. Artificial Intelligence, 112, 213232.
Horn, M. (2006). Optimal algorithms global optimization case unknown lipschitz
constant. Journal Complexity, 22 (1), 5070.
Hutter, F., Hoos, H. H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automatic
algorithm configuration framework. Journal Artificial Intelligence Research, 36 (1),
267306.
Jones, D. R., Perttunen, C. D., & Stuckman, B. E. (1993). Lipschitzian optimization without
lipschitz constant. Journal Optimization Theory Applications, 79 (1), 157
181.
Kautz, H., Horvitz, E., Ruan, Y., Gomes, C., & Selman, B. (2002). Dynamic restart policies. Proceedings Eighteenth National Conference Artificial Intelligence
(AAAI), pp. 674681.
Kieffer, J. C. (1982). Exponential rate convergence Lloyds method I. IEEE Trans.
Inform. Theory, IT-28, 205210.
Kocsis, L., & Gyorgy, A. (2009). Efficient multi-start strategies local search algorithms.
Buntine, W., Grobelnik, M., Mladenic, D., & Shawe-Taylor, J. (Eds.), Machine
Learning Knowledge Discovery Databases, Vol. 5781 Lecture Notes Computer Science, pp. 705720. Springer Berlin/Heidelberg.
Linde, Y., Buzo, A., & Gray, R. M. (1980). algorithm vector quantizer design. IEEE
Transactions Communications, COM-28, 8495.
Luby, M., Sinclair, A., & Zuckerman, D. (1993). Optimal speedup Las Vegas algorithms.
Information Processing Letters, 47, 173180.
Mart, R., Moreno-Vega, J., & Duarte, A. (2010). Advanced multi-start methods. Gendreau, M., & Potvin, J.-Y. (Eds.), Handbook Metaheuristics, 2nd edition (2 edition).
Springer.
Nesterov, Y. (2004). Introductory Lectures Convex Optimization: Basic Course.
Kluwer Academic Publishers.
Ribeiro, C., Rosseti, I., & Vallejos, R. (2009). use run time distributions evaluate
compare stochastic local search algorithms. Stutzle, T., Birattari, M., & Hoos,
H. (Eds.), Engineering Stochastic Local Search Algorithms. Designing, Implementing
Analyzing Effective Heuristic s, Vol. 5752 Lecture Notes Computer Science,
pp. 1630. Springer Berlin/Heidelberg.
Spall, J., Hill, S., & Stark, D. (2006). Theoretical framework comparing several stochastic
optimization approaches. Calafiore, G., & Dabbene, F. (Eds.), Probabilistic
Randomized Methods Design Uncertainty, chap. 3, pp. 99117. SpringerVerlag, London.
Spall, J. C. (1992). Multivariate stochastic approximation using simultaneous perturbation
gradient approximation. IEEE Transactions Automatic Control, 37, 332341.
Spall, J. C. (1998). Implementation simultaneous perturbation algorithm stochastic optimization. IEEE Transactions Aerospace Electronic Systems, 34, 817823.
443

fiGyorgy & Kocsis

Streeter, M. J., & Smith, S. F. (2006a). asymptotically optimal algorithm max
k-armed bandit problem. Proceedings, Twenty-First National Conference
Artificial Intelligence Eighteenth Innovative Applications Artificial Intelligence Conference, pp. 135142.
Streeter, M. J., & Smith, S. F. (2006b). simple distribution-free approach max
k-armed bandit problem. Principles Practice Constraint Programming CP 2006, 12th International Conference, CP 2006, Nantes, France, September 25-29,
2006, Proceedings, pp. 560574.
Vilalta, R., & Drissi, Y. (2002). perspective view survey meta-learning. Artificial
Intelligence Review, 18 (2), 7795.
Witten, I. H., & Frank, E. (2005). Data Mining: Practical Machine Learning Tools
Techniques (2nd edition). Morgan Kaufmann, San Francisco.
Zabinsky, Z. B., Bulger, D., & Khompatraporn, C. (2010). Stopping restarting strategy
stochastic sequential search global optimization. J. Global Optimization,
46 (2), 273286.

444


