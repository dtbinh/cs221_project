journal artificial intelligence

submitted published

properties bethe free energies message passing
gaussian
botond cseke
tom heskes

b cseke science ru nl
heskes science ru nl

institute computing information sciences
faculty science radboud university nijmegen
heyendaalseweg aj netherlands

abstract
address computing approximate marginals gaussian probabilistic
mean field fractional bethe approximations define gaussian fractional bethe free energy terms moment parameters approximate
marginals derive lower upper bound fractional bethe free energy
establish necessary condition lower bound bounded turns
condition identical pairwise normalizability condition known
sufficient condition convergence message passing
stable fixed points gaussian message passing local minima
gaussian bethe free energy counterexample disprove conjecture stating
unboundedness free energy implies divergence message passing


introduction
one major tasks probabilistic inference calculating marginal posterior probabilities set variables given observations case gaussian
computational complexity computing marginals might scale cubically number
variables discrete variables often leads intractable computations
computations made faster tractable approximate inference methods
mean field approximation e g jaakkola bethe type approximation e g
yedidia freeman weiss methods developed discrete probabilistic
graphical applicable gaussian well however
important differences behavior discrete gaussian cases example
discrete error function bethe approximationcalled bethe free
energyis bounded heskes watanabe fukumizu gaussian
might case welling teh
understanding properties bethe free energy gaussian might
help understand properties energy function conditional gaussian
conditional gaussian hybrid graphical switching kalman filters
zoeter heskes combine discrete gaussian variables approximate
inference carried expectation propagation e g minka
viewed generalization bethe approximation
marginal consistency constraints approximate marginals replaced expectation
constraints heskes opper wiegerinck winther zoeter order understand
c

ai access foundation rights reserved

ficseke heskes

properties bethe free energy hybrid good understanding two
special cases discrete gaussian needed properties bethe
free energy discrete studied extensively last decade well
understood yedidia et al heskes wainwright jaakkola willsky
watanabe fukumizu properties gaussian bethe free energy
studied much less
message passing well established method finding stationary
points bethe free energy yedidia et al heskes works locally
updating approximate marginals successfully applied discrete e g
murphy weiss jordan wainwright et al gaussian e g weiss
freeman rusmevichientong roy malioutov johnson willsky
johnson bickson dolev nishiyama watanabe bickson gaussian
message passing simplest case free energy message passing
continuous variables therefore important understand behavior
gaussian message passing many practical applications distributed averaging
moallemi roy peer peer rating linear detection svm regression bickson
generally involve solving large sparse linear systems
approximating marginal variances large sparse gaussian systems typically encountered distributed computing settings applications reader referred
work bickson references therein
finding sufficient conditions convergence message passing gaussian
successfully addressed many authors computation tree
weiss freeman proved message passing converges whenever precision
matrixinverse covarianceof probability distribution diagonally dominant
help analogy message passing walksum analysis malioutov et al
derived stronger condition pairwise normalizability different
taken welling teh directly minimized bethe free energy regard
parameters approximate marginals conjecturing gaussian message passing
converges free energy bounded experiments showed
message passing direct minimization converge solution
fail converge adopt similar instead analyzing properties
gaussian message passing approaches weiss freeman
malioutov et al choose study properties gaussian bethe free energy
stationary points help us draw conclusions existence local
minima possible stable fixed points message passing converge
structured follows section introduce gaussian markov random
fields message passing section define gaussian fractional
bethe free energies parameterized moment parameters approximate marginals
derive boundedness conditions two sections authors
earlier work cseke heskes section analyze stability properties
gaussian message passing similar line argument watanabe
p
matrix diagonally dominant aii j aij
following work malioutov et al call gaussian distribution pairwise normalizable

q
factorized product normalizable pair factors p x xn ij ij xi xj
ij normalizable



fibethe free energies message passing gaussian

fukumizu stable fixed points indeed local minima bethe
free energy conclude experiments sections supporting
implications

approximating marginals gaussian
probability density gaussian random vector x rn defined terms canonical
parameters h q




p x exp h x x qx


q positive definite matrix expectation covariance v x
given q h v q respectively many real world applications
matrix q sparse typically low density number non zero
elements q scales number variables n
probability density defined terms undirected probabilistic
graphical model commonly known gaussian markov random field gmrf since
interactions variables p pairwise associate variables xi
nodes v v n undirected graph g v e edges e e v v
graph stand non zero diagonal elements q use j proxy
j e notation introduced density p written
product

p x
ij xi xj

ij

gaussian functions ij xi xj called potentials associated edges e j
graph h q given define potentials
j
j


ij xi xj exp ij
hi xi ij
hj xj ij
qii x ij
qjj x j qij xi xj

p
p
j


ij ij
ji ij partitioning h q corresponding
factors practice however factors ij might given hand
j computed summing parameters computing
h q well ij
ij
partitioning respectively without loss generality use qii since
easily formulated general qs rescaling
variables e g malioutov et al
numerical calculation marginals done solving linear system
q h performing sparse cholesky factorization llt q followed solving takahashi equations takahashi fagan chin alternative option
calculate marginal means approximate marginal variances run gaussian message passing probabilistic graphical model associated
representation gaussian message passing gaussian variant
message passing pearl dynamical programming
introduced compute marginal densities discrete probabilistic pairwise interactions tree structured graphs g however turned running loops
graphs cycles yields good approximations marginal distributions murphy
et al weiss freeman showed gaussian message passing


ficseke heskes

figure illustration incoming outgoing messages adjacent nodes j

converging computes exact mean parameters thus
used solving linear systems e g bickson message passing works updating
passing directed messages along edges graph g case
converges used compute approximate marginal probability distributions
gaussian discrete functional form exception
summation discrete case integration operators gaussian case message
ij xi updated according
z


ij xi dxj ij xi xj
jk xj

kj

j j denotes index set variables connected xi g step
current approximations qij xi j p xi xj computed according
qij xi xj ij xi xj


li j

il xi



jk xj



kj

update steps iterated convergence corresponding qij xi xj
yield final approximation p xi xj common use damping
x practice helps
replace
ij xi ij xi
ij
dampen possible periodic paths keeps properties fixed points
unchanged figure illustrates incoming outgoing messages nodes associated
variables xi xj quite significant difference discrete gaussian
message passing replacement sum operator integral operator
finite sums exist integral become infinite
remedied technically canonical parameterization see section keeps
running lead non normalizable approximate marginals qij thus
possible break
message passing introduced pearl heuristic discrete
however yedidia et al showed viewed


fibethe free energies message passing gaussian

finding stationary points called bethe free energy error function measuring
difference p specific family distributions detailed next
section shown heskes later different way watanabe
fukumizu stable fixed points loopy message passing local
minima corresponding bethe free energy holds
gaussian well
interest properties gaussian bethe free energy corresponding gaussian message passing motivated mainly implications
general inference non gaussian expectation propagation respectively reason compare speed method
accuracy approximation mentioned exact linear algebraic methods
mentioned introduction take similar welling
teh study properties gaussian bethe free energy parameterized
terms moment parameters approximate marginals following
introduce mean field bethe approximation gaussian readers familiar
subject continue section
gaussian bethe free energy
popular method approximate marginals approximating p distribution q
form makes marginals easy identify example factorizes treelike form common quantity measure difference two probability
distributions kullback leibler divergence q p often used characterize
quality approximation formulate computation approximate marginals
optimization


z
q x

q x argmin dx q x log


p x
qf
f set distributions mentioned form since symmetric
kullback leibler divergence distance q p proper q p
q p p q convex q p
family f densities possessing form
q makes marginals easy identify
family distributions factorize q x k qk xk words
approximate p distribution independent variables approximation q
thisqtype called mean field approximation e g jaakkola defining fmf qk
qk p writing right hand side detail one gets
z
fmf qk

dx



qk xk log p x

k

xz

dxk qk xk log qk xk

k

parameterization qk xk n xk mk vk mn v v vn
reduces

x
x
fmf v ht mt qm
qkk vk
log vk cmf



k



k

ficseke heskes

q
cmf irrelevant constant although k qk p might convex
q qn one easily check fmf convex variables v
minimum obtained q h vk qkk since





q kk qkk qtk k q k k
q k k

one easily see mean field approximation underestimates variances mean
field approximation computes solution means exact variances
computed interactions variables namely matrix
q diagonal thus giving poor estimates variances
order improve estimates variances one choose approximating distributions q able capture dependencies variables p
verified distribution dependencies form tree graph written
form
p xi xj
p x
p xk
p xi p xj
ij

k

j run edges j tree k nodes n
although cases undirected graph generated non zero elements q
tree tree intuition one construct q one two variable
marginals
qij xi xj
q x
qk xk

qi xi qj xj
ij

k

andr constrain functions qij qk marginally
consistent normalize
r
dxj qij xi xj qi xi j dxk qk xk k approximation
form together constraints qij qk called bethe approximation
let us denote family functions fb choosing qij xi xj qi xi qj xj one
easily check fmf fb thus fb non empty assuming approximate
marginals correct q normalizes substituting get
approximation kullbackleibler divergence called bethe free energy
due factorization p write bethe free energy
xz
fb qij qk
dxi j qij xi j log ij xi j

ij



xz
ij



xz
qij xi j
dxi j qij xi j log

dxk qk xk log qk xk
qi xi qj xj
k

one define free energy bethe approximation
z
xz
dx q x log q x
dxi j q xi j log q xi j
ij



x
k



z
nk

dxk q xk log q xk

fibethe free energies message passing gaussian

entropy e g yedidia et al substitute marginals functions qij
qrk normalize one connected marginal consistency constraints
dxj qij xi xj qi xi
stationary conditions lagrangian corresponding fractional bethe
free energy marginal consistency normalization constraints one derive
iterative corresponding lagrange multipliers
consistency constraints yedidia et al similarly approximate marginals
computed according shown one one correspondence
stationary points bethe free energy fixed points
message passing later section link stable fixed points
local minima
fractional free energies message passing
mentioned introduction case gaussian message passing
converge reason appears approximate marginals
may get indefinite negative definite covariance matrices welling teh pointed
due unboundedness bethe free energy
since fmf convex bounded bethe free energy might unbounded
seems plausible analyze fractional bethe free energy
xz
f qij qk
dxi j qij xi j log ij xi j

ij


xz
x z
qij xi j

dxi j qij xi j log

dxk qk xk log qk xk
ij
qi xi qj xj
ij

k

introduced wiegerinck heskes denotes set positive reals ij
showed fractional bethe free energy interpolates mean field
bethe approximation ij get bethe free energy
case ij tend mutual information variables xi xj highly
penalized therefore enforces solutions close mean field solution showed
fractional message passing derived interpreted pearls
message passing difference instead computing local marginals
pearls algorithmone computes local ij marginals local ij marginals
correspond true local marginals ij local mean field approximations
ij resulting called fractional message passing
message updates defined
z



x


dxj ij xi xj
jk xj ji xj

ij
kj

approximate marginals computed according


qij xi xj ij xi xj
il xi ij xi
jk xj ji xj
li j



kj



q
define marginals distribution p argmin qk p k qk divergence
k
r

r
r
p q dxp x q x dxp x dxq x e g minka



ficseke heskes

power expectation propagation minka approximate inference method
uses local approximations divergences case gaussian power
expectation propagationwith fully factorized approximating distributionleads
message passing one derived appropriate constraints
starting idea creating upper bound log partition function p
q exponential distributions wainwright et al derived form
ij chosen bound convex qij qk
message passing works well practice however ways local
minima fractional free energies direct minimization w r parameterization approximate marginals qij qk welling teh latter method
slower likely converge following analyze bethe free energy
expressed terms moment parameters approximate marginals qij later
section analyze stability conditions fractional message passing
expressing conditions term moment parameters approximate
marginals stable fixed points fractional gaussian message passing
local minima fractional bethe free energy

bounds gaussian bethe free energy
section analyze parametric form fractional gaussian bethe free energy non increasing function letting ij tend infinity obtain lower bound free energies turns condition
lower bound bounded pairwise normalizability
condition work malioutov et al
mentioned section without loss generality work unit diagonal q define r matrix zeros diagonal q r
identity matrix r matrix formed absolute values
rs elements use moment parameterization qij xi j n xi j mij vij
v v v j v v
qk xk n xk mk vk mij miij mjij vij vij
ij
ji ij
ij
ji
mi v v v k j k embed
mi

ij
ik
ik
r ij
r
marginalization dxj qij xi xj qi xi j normalization dxj qj xj
constraints parameterization slight abuse notation matrix formed
diagonal elements vk diagonal elements vij denoted v take vij
j vector means mn vector variances
v v vn substituting qij qk one gets


f v ht mt qm tr qt v



x
v


x
ij

log

log vk c

ij
vi vj

ij



k

c irrelevant constant note variables v independent hence
minimizations f v regard v carried independently


fibethe free energies message passing gaussian

property f v convex bounded vij j stationary point

q h
vij



p
ij rij vi vj
sign rij

ij rij



proof q positive definite definition therefore quadratic term convex
bounded variables v independent minimum regard
achieved q h one check second order derivative
f v regard vij non negative first order derivative one
v v since variables v independent one conclude
solution vi vj vij
j
ij
f v convex vij independence v follows f
convex vij j

thus
since vij constrained covariance matrices vi vj vij
first logarithmic term negative consequence

f v f v





taken element element observation leads following
property
property ij f non increasing function
f define constrained function
property substituting vij


x
fc v ht mt qm
vk


k
q

x
ij rij vi vj



ij ij

p
ij rij vi vj
x

log

ij
ij rij vi vj
n j

x

log vk c c




k

c c irrelevant constant property follows choosing ij
function non increasing function makes sense take
verify whether get lower bound
lemma v following inequalities hold


fmf v fc v fb vij
v


fb vij
v fc v


fmf v
v r v

moreover tight


lim f vij
v fmf v




ficseke heskes







v r v
lim f vij
v fmf v

proof since bethe free energy specific case fractional bethe free energy
v follow property
inequalities fb vij
upper lower bounds tight function x behaves x
neighborhood therefore


v
log ijvi vj

vij


lim
lim vij


lim





vi vj


showing fmf v tight upper bound
tends infinity
p
rij vi vj

rij vi vj
lim




log
lim



p
rij vi vj

rij vi vj

yielding tight lower bound




v r v
lim f vij
v fmf v





let max r largest eigenvalue r analyzing boundedness lower
bound arrive following theorem
theorem fractional bethe free energy corresponding connected
gaussian model following statements hold
max r f bounded
max r f unbounded
p p
max r f bounded
ij n
ij

proof since f interaction parameters v term
depending bounded due positive definiteness q simply
neglect term analyzing boundedness f let us write detail
lower bound fractional bethe free energies form


v r v





q ht
v r v log v const




fmf v



statement condition max r implies r positive definite


fibethe free energies message passing gaussian







log x x thus v r v log v v r v v n
latter bounded follows bounded
well according lemma boundedness implies fractional bethe free
energies bounded
statement assumed gaussian network connected undirected according perron frobenius theory non negative matrices e g horn johnson
r simple maximal eigenvalue max r elements eigenvector umax corresponding positive let us take fractional bethe free energy

analyze behavior v tumax large values
ij rij uimax ujmax ij rij uimax ujmax therefore sum second
third term simplifies max r term dominates
logarithmic ones limit independent choice ij
tends whenever max r
statement max r direction quadratic term

dominate v tumax therefore analyze p
behavior loga
rithmic terms large ts behave ij ij
n log
c
reason boundedness f thus f depends condition
statement

shown malioutov et al condition max r equivalent
condition pairwise normalizability therefore pairwise normalizability
sufficient condition message passing converge necessary
condition fractional gaussian bethe free energies bounded lemma
suitably chosen exists constrained
fractional free energy fc possesses local minimum property
section appendix
example case adjacency matrix non zero entries r corresponding kregular graph equal interaction weights rij r maximal eigenvalue r max r kr eigenvector corresponding eigenvalue
define vector elements equal model symmetric
verifying stationary point conditions turns choice r
exists local minimum lies direction one
model pairwise normalizable kr critical r
p fractional
bethe free energy possesses local minimum rc k k
valid r critical
p fractional bethe free energies possesses local
minimum c k r k kr illustrated figure
note regular graphs valid pairwise normalizable possess
unique global minimum

kregular graphs convexity fractional bethe free energy terms
qij qk requires k much stronger condition c k r thus choose
sufficiently large bethe free energy guaranteed unique global
minimum minimum unbounded

kregular graph graph nodes connected k nodes



ficseke heskes














vtuwff






























































































figure visualizing critical parameters symmetric k regular gaussian model rij r
plots
left panel correspond constrained fractional bethe free energies fc

v node regular gaussian model r kr varying


plots right panel correspond constrained bethe free energies f c v
node regular gaussian model varying r rvalid supremum
rs model valid q positive definite

example disproves conjecture welling teh even
bethe free energy bounded possess finite local minimum
message passing minimization converge

message passing gaussian
section turn attention towards properties message passing gaussian following similar line argument watanabe fukumizu
stable fixed points message passing correspond local
minima bethe free energy use moment parameterization introduced
previous sections way proceed following make linear expansion
message passing iteration fixed point express linear expansion terms
moment parameters corresponding fixed point finally connect properties latter properties hessian bethe free energy
matrix determinant lemma
form equation implies messages ij xi univariate gaussian
functions thus express terms two scalar canonical parameters ij
ij log ij xi ij x ij xi ijj ij irrelevant constants
expressed terms ij ij damped message passing translates


fibethe free energies message passing gaussian


j
hj
ij



ij



ij

p

jk ji




kj

p
ij hi rij

j

ij

jk ji



kj




ij




x


j

rij
ij

jk ji
ij ij



kj


j h r parameters section r q
ij

ij
ij
ij
ij
ij
assumption qii approximate marginals qij might normalizable
message passing iteration stays well defined unless zero
denominator rhs rarely happens practice however
common message passing converges intermediate steps
approximate marginals qij normalizable often remedied choosing
appropriate damping parameter
iteration ij independent ij iteration ij
linear ij interesting see h neither constrained bethe
free energy message passing depend sign rij
relevant compute meanswhen h signs correlations
marginal variances computed minimizing bethe free
energy running message passing depend r similarly
constrained fractional free energy fc

stability gaussian message passing
following analyze stability message passing iteration fixed points
stationary points lagrangian corresponding constrained minimization gaussian bethe free energy reiterate use g v e denote
graph corresponding q namely v n e j qij vector r e corresponding set messages ij ij composed concatenation
ij ij followed ji ij ji blocks follow lexicographic order w r
ij j vector consists variables ij follows similar structure
j
define r h r e rij rji rij hij hj ij ij
define
e e matrix

j k

kl ji
mij kl

otherwise
encodes weighted edge adjacency corresponding g number nonzero elements scales roughly nnzeros q n nnzeros q denotes
number non zeros q since parallel message update given equations
rewritten terms two matrix vector multiplications element element
operations vectors computational complexity update scales roughly
nnzeros q n


ficseke heskes

notation local linearization update equations
written









h

diag r diag r








diag r





operations vectors element element stability fixed point
depends union spectra

j diag r


j diag r
important point stability properties depend r
independent h
goal connect stability properties message passing
properties bethe free energy therefore express stability properties terms
moment parameters approximate marginals leads normalizable approximate marginals qij xi xj use identify local covariance
parameters vij defined section without enforcing marginal matching
v correspondence given
constraints vij
ik



vij
vij

vij
j
vij












j
vij
vij

vj v
vij
ij
ij
p

il ij
ij

vij

vij



rij

li j
j
ij

rij



p

jk ji





kj
v j r
approximate local covariances vij fully determined vij
ij
ij
form leaves us e moment parameters computed
v v j v
message passing let v r e defined vij vij
ji
ij
ij
v j v v
vij vij
ij
ij computed according checked
ij
mapping v continuous bijective implies canonical
moment parameter transformation written v since
singular k graph g k regularsee property
section appendix detailsfor rest cases continuous
bijective mapping moment parameters v canonical parameters
lead normalizable approximate marginals
v v
fixed point moment matching vij

ik
k j therefore express stability properties terms moment parameters



fibethe free energies message passing gaussian

v vi vn p
defining diagonal matrix r e e
diagonal elements dij ij vi get

v
v

v
ij

j
diag q



vi vj


dj v










j v







diag

vij vi vj
vi vj







let denote
spectrum matrix since dj j

j j sufficient analyze spectral properties right hand
sides equations
message passing asymptotically stable v
max j v j v



denotes spectral radius interesting see although functional
forms free energies message passing different gaussian
discrete case stability conditions similar forms allow us use
watanabe fukumizu next section
implications condition properties hessian free energy
stable fixed points local minima
hessian h f bethe free energy depends moment parameters
vi vj vij note vij unconstrained parameters e n
e n matrix form


q



h f v



diag
h



f
vij


h

f
vij vi ij



f
vij vi ij

h



f
vi vj j







use v denote collection parameters vi n vij j
since block corresponding partial differentials w r vij diagonal positive
elements hessian positive definite v schur complement corresponding


ficseke heskes

partial differentials w r vi positive definite v latter given
x f f
f
v

hii f v
vi vi
vij vi
vij
ij



x c ij





vi



c
ij
ij




f
f f f
v
hij f v

vi vj
vij vi vij vj vij
c ij


vi vj c ij

use notation cij vij vi vj
would connect condition positive definiteness
matrix h v f v following stable fixed points v gaussian
message passing satisfying correspond local minima gaussian free
energy f v vij vi vj
according watanabe fukumizu arbitrary vector w r e one



det e diag w det w
wij wji

ij


aii w

x
ij

wij wji
wij wji



aij w

wij

wij wji



proof application matrix determinant lemma reproduction
found section appendix equation expresses determinant
e e matrix determinant nn matrix

let c r e cij v vij vi vj substituting w c v


det diag c v f v det h f v

f v positive function defined
f v n e q


k

vk




vi vj vij
ij


vi vj vij


vij

vi vj




v corresponding normalizable approximate marginals adapting theorem
watanabe fukumizu

following theorem
theorem diag c v c r hessian gaussian
bethe free energy h f positive definite
v


proof assumption
diag c v c r implies
det diag c v choosing vij tvij

c v c v therefore det diag c v


fibethe free energies message passing gaussian

implies det h f v since h f v
eigenvalues h f v change continuously w r
h f v v thus satisfying condition theorem



fixed point stable
max j v j v



implies diag c v c r leads following property

property stable fixed points damped gaussian message passing local minima gaussian bethe free energy fc v
shows boundedness f existence local minima case
unbounded f plays significant role convergence gaussian message passing illustrate section fractional message passing converges
converges set messages corresponds local minimum fractional free energy implies mean parameters local approximate
marginals exact see property section note observations section
property appendix together property imply
range values fractional free energy possesses local minimum
fractional message passing converge
damping fractional parameters
local stability condition independent damping parameter therefore
alter local stability properties makes iteration slower numerically stable dampen possible periodic trajectories message
passing
fractional parameter characterizes inference process seen
example previous sections choosing smaller create local minima
particular case h somewhat similar property message passing
updates well let r e set messages lead normalizable approximate
marginals set characterized model parameters r reiterate
v j continuous bijective
elements v local variances vij
ij
e

mapping v r given v unless k g
k regular allows us study q
stability properties terms moment parameters
v j
v let c v vij vij
ij

v j vector local correlations
vij
ij ij

gershgorins theorem horn johnson c v c v
eigenvalue diag c v diag c v


max c v nj
j

h updates rhs equation depends
c v see equations lim c v thus small


values help achieve convergence however h term c v
dominating effects decreasing towards zero ambiguous


ficseke heskes

experiments
implemented direct minimization fractional message passing analyzed
behavior different values max r reasons simplicity set ij
equal small scale model summarized figure note
good correspondence behavior fractional bethe free energies
direction eigenvalue corresponding max r convergence newton
method newton method started different initial points experienced
max r setting initial value v u max
converge high values explained top plots figure
high values initial point might convergence region local
minimum fractional message passing used two types initialization

max r set ij normalizable setting ij
n
rij ujmax max uimax malioutov et al max r used ij

symmetric partitioning diagonal elements set initial messages
approximate marginals normalizable first step iteration
experienced behavior similar described welling teh
standard message passing namely fractional message passing direct minimization
converge fail converge experiments combination theorem
max r standard message passing best converges local
minimum bethe free energy standard message passing fails converge one
decrease search stationary pointpreferably local minimumof
corresponding fractional free energy
seen right panels figure model
longer pairwise normalizable local minimum unbounded global minimum
viewed natural continuation bounded global minimum pairwise
normalizable explains quality approximation local
minimum pairwise normalizable still comparable
global minimum pairwise normalizable

conclusions


seen fmf fmf v r v provide tight upper lower bounds
gaussian fractional bethe free energies turns pairwise normalizability
sufficient condition message passing converge
necessary condition gaussian fractional bethe free energies bounded

model pairwise normalizable lower bound bounded direct
minimization message passing converging experiments converged
minimum suggests pairwise normalizable case fractional bethe
free energies possess unique global minimum
model pairwise normalizable none fractional bethe free energies
bounded however range values
fractional free energy possesses local minimum direct minimization
fractional message passing converge thus decreasing towards zero one gets


fibethe free energies message passing gaussian







































































function value convergence

function value convergence

















































error variances convergence

newton method
message passing


























error variances convergence

























newton method
message passing


































figure top panels constrained
fractional bethe free energies gaussian model

variables direction v tumax umax eigenvector corresponding max r max r top left max r top right
thick lines functions fmf dashed fb dashed dotted lower bound


fmf v r v continuous thin lines constrained fractional free
energies fc center panels final function values
convergence newton method bottom panels
error approximation single node standard deviations v missing values indicate
non convergence


ficseke heskes

closer mean field energy finite local minimum appear property
appendix experienced suitable range initial values
fractional gaussian message passing made converge
mentioned section ij correspond local ij divergences applying power expectation propagation fully factorized approximating distribution
seeger reports expectation propagation converge applying power
expectation propagation helps achieve convergence case
addressed behavior explained observation small
make finite local minima likely occur thus prevents covariance matrices
becoming indefinite even non positive definite although common reason
ep numerical robustness implies finding saddle point
fractional ep free energy might interesting investigate whether
reason convergence likely case gaussian fractional message passing
wainwright et al propose convexify bethe free energy discrete
choosing ij sufficiently large fractional bethe free energy unique
global minimum strategy appears fail gaussian convexification makes
possibly useful finite local minima disappear leaving unbounded global minimum case general hybrid use convexification still
unclear
example section disproves conjecture work welling teh
even bethe free energy bounded possess finite local
minimum message passing minimization converge
shown stable fixed points gaussian fractional message passing
local minima fractional bethe free energy although existence
local minimum guarantee convergence message passing
practice experienced existence local minimum implies convergence
hypothesize pairwise normalizability hold
gaussian bethe free energy gaussian message passing
two types behavior
gaussian bethe free energy possesses unique finite local minimum
optimization methods converge starting say mean field solution
vi qii gaussian message passing corresponding unique stable fixed
point converge suitable starting point sufficient damping
finite local minimum exists thus optimization message
passing diverge
fractional free energy fractional message passing varying
one switch behaviors computing critical c r general r
remains open question believe properties free energies k regular
symmetric section critical values easily computed give good
insight properties free energies general gaussian


fibethe free energies message passing gaussian

acknowledgments
would thank jason k johnson sharing ideas properties
message passing k regular would thank anonymous
reviewers valuable comments earlier versions manuscript
reported supported vici grant netherlands
organization scientific nwo

appendix properties proofs
lemma watanabe fukumizu graph g v e edge adjacency
matrix defined section arbitrary vector w r e one


det e diag w det v w
wij wji
ij


aii w

x
ij

wij wji
wij wji

aij w



wij

wij wji

proof reproduce proof somewhat simplified form let us define uij etj
vij eti ek k th unit vector rn



sij ij sij ji



sji ij sji ji

u v let us define w r e e diagonal matrix
wij ij wij matrix determinant lemma reads

det w u v

det w w u v



det w u v w det w


det v w w u det w
ij ji block w w




wij
wij


wji wji wji


wji





wji wji



wij
wji wij

wij wji
wji



thus define v w w u
x wij wji
wij
ai
ai j

wij wji
wij wji
ij

completes proof matrix determinant lemma section





ficseke heskes

property matrix u v singular k regular graphs
k
p
proof let x r e pm x yij kj xjk xji let us fix j
yij means kj xjk xji hold graph
k regular k xij equal xij pair indices ij

property suitably chosen exists constrained
fractional free energy fc possesses local minimum

proof let us define vm
f argminv fm f v


um
f v fm f v fm f vm f

form fm f implies choose um
f proper subset
n

n
positive quadrant r words um f r due properties fm f
continuous convex unique finite global minimum attained finite value





domain um
f closed bounded convex vm f um f um f vm f

n
c

interior um f since fm f f v continuous r set um f closed
bounded lim fc v fm f v pointwise convergence v rn follows fc



c
converges uniformly um
f together monotonicity f w r
implies exists fm f vm f fc vm f fm f vm f
let us fix known since u
v um
f
f closed bounded


c
c
f continuous f attains extrema um f since fm f v fm f vm
f

c

c

v um f f v fm f v v um f follows f v fm f vm
f


c


v um f chosen fm f vm f f vm f fm f vm
f
latter two conditions imply one extrema local minimum

interior um

f

references
bickson gaussian belief propagation theory application ph thesis
hebrew university jerusalem
cseke b heskes bounds bethe free energy gaussian networks
mcallester myllymaki p eds uai proceedings th
conference uncertainty artificial intelligence pp auai press
heskes stable fixed points loopy belief propagation minima bethe
free energy becker thrun obermayer k eds advances neural
information processing systems pp cambridge mit press
heskes opper wiegerinck w winther zoeter approximate
inference techniques expectation constraints journal statistical mechanics
theory experiment p
heskes uniqueness loopy belief propagation fixed points neural
computation
horn r johnson c matrix analysis cambridge university press cambridge uk


fibethe free energies message passing gaussian

jaakkola tutorial variational approximation methods opper saad
eds advanced mean field methods theory practice pp cambridge
mit press
johnson j k bickson dolev fixing convergence gaussian belief
propagation corr abs
malioutov johnson j willsky walk sums belief propagation
gaussian graphical journal machine learning
minka p power ep tech rep microsoft ltd cambridge uk
msr tr
minka p divergence measures message passing tech rep msr tr microsoft ltd cambridge uk
moallemi c roy b v consensus propagation weiss scholkopf b
platt j eds advances neural information processing systems pp
mit press cambridge
murphy k weiss jordan loopy belief propagation approximate
inference empirical study proceedings fifteenth conference uncertainty artificial intelligence vol pp san francisco usa morgan
kaufman
nishiyama watanabe accuracy loopy belief propagation gaussian
neural networks
pearl j probabilistic reasoning intelligent systems networks plausible inference morgan kaufman publishers san mateo ca
rusmevichientong p roy b v analysis belief propagation turbo
decoding graph gaussian densities ieee transactions information theory

seeger w bayesian inference optimal design sparse linear model
journal machine learning
takahashi k fagan j chin formation sparse impedance matrix
application short circuit study proceedings th pica conference
wainwright jaakkola willsky tree reweighted belief propagation
approximate ml estimation via pseudo moment matching bishop
c frey b eds proceedings ninth international workshop artificial
intelligence statistics society artificial intelligence statistics
watanabe fukumizu k graph zeta function bethe free energy
loopy belief propagation bengio schuurmans lafferty j williams c
k culotta eds advances neural information processing systems
pp mit press
weiss freeman w correctness belief propagation gaussian graphical
arbitrary topology neural computation


ficseke heskes

welling teh w belief optimization binary networks stable alternative loopy belief propagation breese j koller eds proceedings
th conference uncertainty artificial intelligence pp morgan
kaufmann publishers
wiegerinck w heskes fractional belief propagation becker thrun
obermayer k eds advances neural information processing systems
pp cambridge mit press
yedidia j freeman w weiss generalized belief propagation
advances neural information processing systems pp cambridge
mit press
zoeter heskes change point linear dynamical systems
journal machine learning




