journal artificial intelligence

submitted published

query dags practical paradigm implementing
belief network inference
adnan darwiche

darwiche aub edu lb

department mathematics
american university beirut
po box beirut lebanon

gregory provan

provan risc rockwell com

rockwell science center
camino dos rios
thousand oaks ca

abstract

describe paradigm implementing inference belief networks consists two steps compiling belief network arithmetic expression called
query dag q dag answering queries simple evaluation
node q dag represents numeric operation number symbol evidence leaf node q dag represents answer network query
probability event interest appears q dags generated standard exact inference belief networks
generated clustering conditioning time space
complexity q dag generation worse time complexity
inference complexity q dag evaluation
linear size q dag inference amounts standard evaluation
arithmetic expression represents intended value q dags reducing
software hardware resources required utilize belief networks line real world
applications proposed framework facilitates development line inference
different software hardware platforms due simplicity q dag evaluation
interestingly enough q dags found serve purposes simple techniques reducing q dags tend subsume relatively complex optimization techniques
belief network inference network pruning computation caching

introduction
consider designing car self diagnostic system alert driver range
figure shows simplistic belief network could provide ranked set
diagnoses car troubleshooting given input sensors hooked battery
alternator fuel tank oil system
standard building diagnostic system put belief network
along inference code onto car computer see figure encountered
number diculties embody belief network technology industrial applications first asked provide technology multiple platforms
applications technology implemented ada pass certain certification procedures others implemented domain specific hardware
supports primitive programming languages second memory limited keep

c ai access foundation morgan kaufmann publishers rights reserved

fidarwiche provan

fuel sensor
fuel
battery

oil pressure
battery sensor

fault

oil pressure
sensor
alternator
alternator
sensor

figure simple belief network car diagnosis
cost unit certain threshold maintain product profitability dilemma
following belief network trivial implement especially optimization crucial porting multiple platforms languages would
prohibitively expensive time consuming demanding qualified manpower
overcome diculties devised exible implementing
belief network systems following observation almost work
performed standard belief networks independent specific evidence
gathered variables example run battery sensor set
low run later variable set dead almost algorithmic
difference two runs branch differently
key decisions makes difference two runs specific
arguments invoked numeric operations therefore one apply standard inference
network evidence parameter instead specific value
returned arithmetic expression parameters
depend specific evidence parameterized expression call query
dag example shown figure
proposing consists two steps first given belief network set
variables evidence may collected evidence variables set variables need compute probability distributions query variables q dag
compiled line shown figure compilation typically done sophisticated software hardware platform traditional belief network inference
conjunction q dag compilation method part process far away
costly computationally second line system composed generated
q dag evaluator specific given platform used evaluate q dag given
evidence parameterized arithmetic expression evaluated straightforward manner
simple arithmetic operations rather complicated belief network inference
sharing subexpressions makes directed acyclic graph instead tree



fia practical paradigm implementing belief network inference

traditional

compiled

fault
variables
causal
network


n
l

n
e

sensor
values

causal network
inference
software

sensor
variables

q dag
compiler

query
dag

q dag
evaluator


f
f
l

n
e


n
l

n
e

fault
probabilities

figure figure compares traditional exact belief network inference
shown left compiled shown right
context diagnostic reasoning traditional belief network
sensor values used line compute probability distributions
fault variables compiled belief network fault variables
sensor variables compiled line produce q dag evaluated
line sensor values compute required distributions
computational work needed perform line evaluation straightforward
lends easy implementations different software hardware platforms
shares commonality methods symbolically manipulate probability expressions spi li ambrosio shachter ambrosio
del favero differs spi objective manipulations hence
obtained spi explicates notion arithmetic expression state
belief network inference viewed expression factoring operation allows
optimization theory utilized belief network inference
hand define arithmetic expression explicate formalize boundaries
line line inference goal identifying minimal piece software
required line therefore oriented towards purpose include
formal definition q dag evaluator b method generating q dags
standard inference need subscribe inference

fidarwiche provan

query variables

evidence variables

causal network

q dag compiler
line

line
query dag

evidence

q dag evaluator

figure proposed framework implementing belief network inference



b

pr

pr b c

pr b c













pr b





b

c















pr c






















c







c

figure belief network corresponding query dag b c evidence
variable interested probability variable b
factoring view used q dag generation c computational guarantees
size q dags terms computational guarantees inference used
generate although spi framework positioned formulate related
pursued direction
important stress following properties proposed first declaring evidence variable compilation process mean evidence must
collected variable line important evidence values e g
sensors may lost practice means evidence may collected therefore one declare variables evidence one wishes second variable
declared evidence query allows one perform value information


fia practical paradigm implementing belief network inference

computations decide whether worth collecting evidence specific variable
third space complexity q dag terms number evidence variables
worse time complexity underlying inference therefore
simple enumerate possible cases finally time space complexity
generating q dag worse time complexity standard belief network
used generation therefore network solved standard
inference time complexity worse space
complexity construct q dag network
following section explains concept q dag concrete example
provides formal definitions section dedicated generation q dags
computational complexity showing standard belief network inference
used compile q dag long meets general conditions section
discusses reduction q dag generated showing reduction
subsumes key optimizations typically implemented belief network
section contains detailed example application framework diagnostic
reasoning finally section closes concluding remarks

query dags

section starts treatment q dags concrete example consider
particular belief network define set queries interest q dag
used answer queries discuss q dag generated
used allow concrete introduction q dags help us
ground formal definitions follow
belief network consider one figure class queries
interested pr b j c probability variable b takes value
given known unknown value c figure b depicts q dag answering
queries essentially parameterized arithmetic expression values
parameters depend evidence obtained q dag actually answer queries
form pr b c use normalization compute pr b j c
first number observations q dag figure b
q dag two leaf nodes labeled pr b c pr b c
called query nodes values represent answers queries pr b c
pr b c
q dag two root nodes labeled c c called
evidence specific nodes esns since values depend evidence collected
variable c line
according semantics q dags value node v v variable v
observed v unknown otherwise values esns determined
evaluate remaining nodes q dag numeric multiplication addition
numbers get assigned query nodes evaluation answers
queries represented nodes
join trees property



fidarwiche provan







pr b c

pr b c

pr b c



pr b c
































































c








c



b









































c










c

figure evaluating q dag figure respect two pieces evidence
c b c
example suppose evidence c esn c
evaluated esn c evaluated q dag figure b
evaluated given figure thus leading
pr b c



pr b c
conclude pr c compute conditional
probabilities pr b j c pr b j c
pr b j c pr b c pr c
pr b j c pr b c pr c
evidence c however c evaluates c
evaluates q dag figure b evaluated given figure b
thus leading
pr b c

pr b c
use following notation denoting variables values variables
denoted uppercase letters b c variable values denoted
lowercase letters b c sets variables denoted boldface uppercase letters
b c instantiations denoted boldface lowercase letters
b c use e denote set variables evidence therefore


fia practical paradigm implementing belief network inference

use e denote instantiation variables represents evidence finally
family variable set containing variable parents directed acyclic
graph
following formal definition q dag

definition q dag tuple v z
v distinguished set symbols called evidence variables
symbol called unknown value
maps variable v set symbols called variable values different

directed acyclic graph
non root node labeled
root node labeled
number
pair v v v evidence variable v value

z distinguished set nodes called query nodes

evidence variables v correspond network variables expect collect
evidence line example figure c evidence variable one
variables set possible values captured function example
figure evidence variable c values special value used
value variable known example may sensor variable
values low medium high lose sensor value line reasoning
case set sensor value query nodes representing answers
user queries example figure b query variable leads query nodes
pr b c pr b c
important notion evidence

definition given q dag v z evidence defined function e
maps variable v v set values v fg
variable v mapped v v evidence tells us v instantiated
value v v mapped evidence tell us anything value
v
state formally evaluate q dag given evidence first
need notation
numeric node n p denotes node labeled number p
esn n v v denotes node labeled v v
useful cases variable measured value information justifies




fidarwiche provan

operation node n

ni denotes node labeled parents
n ni
operation node n ni denotes node labeled parents
n ni
following definition tells us evaluate q dag evaluating nodes
recursive definition according value assigned node function
values assigned parents first two cases boundary conditions assigning
values root nodes last two cases recursive ones
definition q dag v z evidence e node evaluator defined
function maps node number
n p p
value node labeled number number

e v v e v
n v v ifotherwise
value evidence specific node depends available evidence v
consistent evidence otherwise
n

ni n ni
value node labeled product values parent nodes
n ni n ni
value node labeled sum values parent nodes
one typically interested values nodes q dag since
nodes represent intermediate interest user query nodes
q dag represent answers user queries values nodes one
seeks constructing q dag values queries captured notion
q dag output
definition node evaluator extended q dags follows
v z f n n j n zg
set v z called q dag output
output one seeks q dag element output represents
probabilistic query answer
let us consider evaluations q dag shown figure shown
figure given evidence e c assuming qnode b qnode b
stand q dag nodes labeled pr b c pr b c respectively

n c
n c
qnode b
qnode b


fia practical paradigm implementing belief network inference

meaning pr b c pr b c instead
evidence e c set analogous computations done
possible evidence tells us nothing value variable c
e c case would

n c
n c
qnode b
qnode b
meaning pr b pr b

implementing q dag evaluator

q dag evaluator implemented event driven forward propagation scheme
whenever value q dag node changes one updates value children
possible update values possible another way implement evaluator
backward propagation scheme one starts query node updates
value updating values parent nodes specifics application
typically determine method combination appropriate
important stress level refinement enjoyed q dag propagation scheme implications eciency query updates propagation
q dags done arithmetic operation level contrasted propagation
message operation level used many standard propagation schemes
typically optimized keeping validity ags messages invalid messages
recomputed evidence arrives clearly avoid unnecessary computations never avoid unnecessary computations message typically
coarse purpose example one entry message invalid
whole message considered invalid recomputing message lead many unnecessary computations avoided q dag propagation since validity
ags attributed arithmetic operations building blocks message operations therefore necessary arithmetic operations recomputed q dag
propagation scheme leading detailed level optimization
stress process evaluating updating q dag done outside
probability theory belief network inference makes development ecient online inference software accessible larger group people may lack strong backgrounds
areas

availability evidence

construction q dag requires identification query evidence variables
may give incorrect impression must know front variables observed
could problematic applications one may lose sensor
reading thus changing status variable observed unobserved
fact appears background compiler theory may relevant generating ecient
evaluator background belief network theory



fidarwiche provan







pr b true



true
false

pr b true b





pr



b

pr true b


true

pr b false b



pr false b













b true

b false









figure belief network corresponding q dag variable b declared
query evidence
applications variable may expensive observe leading line
decision whether observe value information computation
situations dealt q dag framework first mentioned
earlier q dags allow us handle missing evidence use notation
denotes unknown value variable therefore q dags handle missing sensor
readings second variable declared query evidence means
incorporate evidence variable available compute
probability distribution variable case evidence available figure depicts
q dag variable declared query variable variable b declared
evidence query variable variables true false values
case two esns variable b two query nodes see figure
q dag used two ways
compute probability distributions variables b evidence
available b situation values n b true n b false
set
pr true
pr false
pr b true


fia practical paradigm implementing belief network inference

pr b false

compute probability variable evidence available b
example suppose observe b false value n b true
set value n b false set
pr true b false
pr false b false

ability declare variable evidence query variable seems
essential applications decision may need made whether collect
evidence variable b making decision requires knowing probability
distribution variable b example suppose following formula
pearl page compute utility observing variable b
x
utility observing b pr b bje u b b
b

u b b utility decision maker finding variable b value b
suppose u b true u b false use q dag
compute probability distribution b use evaluate utility observing b
utility observing b

leads us observe variable b observing b value false
accommodate evidence q dag continue analysis

generating query dags

section shows q dags generated traditional exact
belief network inference particular q dags generated
clustering join tree jensen ls jensen lauritzen olesen shachter
andersen szolovits shenoy shafer polytree cutset
conditioning pearl peot shachter outline properties must
satisfied belief network order adapt generating q dags
propose

clustering

provide sketch clustering section readers interested
details referred shachter et al jensen et al shenoy shafer
according clustering method start
constructing join tree given belief network
join tree tree clusters satisfies following property intersection two clusters
belongs clusters path connecting



fidarwiche provan

assigning matrix variable belief network cluster contains
variable family
join tree secondary structure inference operates need
following notation state
sn clusters cluster corresponds set variables
original belief network
potential function cluster si mapping instantiations
variables si real numbers
pi posterior probability distribution cluster si mapping
instantiations variables si real numbers
mij message sent cluster si cluster sj mapping instantiations variables si sj real numbers
e given evidence instantiation evidence variables e
assume standard multiplication marginalization operations potentials
goal compute potential pr x e maps instantiation x
variable x belief network probability pr x e given notation
state follows
potential functions initialized

pr x x
x



x variable whose matrix assigned cluster si
pr x matrix variable x mapping instantiations family
x conditional probabilities
x likelihood vector variable x x x x consistent given

evidence e otherwise
posterior distributions computed

pi


k

mki

sk clusters adjacent cluster si
messages computed
x
mij
mki
si nsj

k j

sk clusters adjacent cluster si


fia practical paradigm implementing belief network inference

potential pr x e computed
pr x e

x
si nfx g

pi

si cluster x belongs
equations used follows compute probability variable must
compute posterior distribution cluster containing variable compute
posterior distribution cluster collect messages neighboring clusters message
cluster si sj computed collecting messages clusters adjacent si
except sj
statement join tree appropriate situations evidence
changing frequently since involves computing initial potentials time evidence
changes necessary general one provide optimized versions
issue however irrelevant context generating q dags
updating probabilities face evidence changes take place q dag level
includes optimization technique discuss later

generating q dags

generate q dags clustering method go two steps first
modify initialization potential functions join tree quantified
q dag nodes instead numeric probabilities second replace numeric
addition multiplication analogous functions operate q dag
nodes particular
numeric multiplication replaced operation
takes q dag nodes
n ni arguments constructs returns node n label parents
n ni
numeric addition replaced operation takes q dag nodes n ni
arguments constructs returns node n label parents n ni
therefore instead numeric operations q dag node constructors instead
returning number computation return q dag node
state q dag clustering realize evidence
e instead set evidence variables e collect evidence
therefore q dag compute answer query pr x e instead
compute q dag node evaluates pr x e instantiation e variables
e
following equations potentials mappings variable instantiations qdag nodes instead numbers example matrix variable x map
instantiation x family q dag node n p instead mapping number
p q dag operations
extended operate potentials
way extended clustering
set equations


fidarwiche provan

potential functions initialized


n pr x
n e
x

e



x variable whose matrix assigned cluster si
n pr x q dag matrix x mapping instantiations x family

q dag nodes representing conditional probabilities
e evidence variable whose matrix assigned cluster si
n e q dag likelihood vector variable e n e e n e e
means node n e e evaluates e consistent given evidence
otherwise
posterior distributions computed

pi mki
k

sk clusters adjacent cluster si
messages computed

mij
mki
si nsj

k j

sk clusters adjacent cluster si
q dag nodes answering queries form pr x e computed

qnode x
pi
si nfx g

si cluster x belongs
qnode x potential maps instantiation x variable x q dag
node qnode x x evaluates pr x e given instantiation e variables e
hence modifications made clustering changing
initialization potential functions b replacing multiplication addition
q dag constructors multiplication addition nodes

example

proposed q dag used generate q dag
belief network figure
one evidence variable example c interested generating q dag answering queries variable b queries form pr b e
figure shows join tree belief network figure tables contain
potential functions needed probabilistic clustering figure b shows


fia practical paradigm implementing belief network inference



ac




c







ab


c






ac









b



b



ab


c

c



n

n c

n

n c



n

n c

n

n c




b

b





b



n

n



n

n

figure join tree quantified numbers q dag nodes b
join tree tables contain potential functions needed q dag
clustering note tables filled q dags instead numbers
apply q dag compute q dag nodes evaluate
pr b e must compute posterior distribution p cluster since
cluster variable b belongs sum distribution variable
obtain want compute distribution p must first compute message
cluster cluster
message computed summing
potential function cluster
possible values variable c e leads
c

n
n c n
n c
n
n c n
n c
posterior distribution cluster p computed p


leads

p b n
n
n c n
n c
p b n
n
n c n
n c
p b n
n
n c n
n c
p b n
n
n c n
n c
q dag node qnode b answering queries
form pr b e computed
summing posterior p variable qnode
p leading
nfb g
qnode b n
n
n c n
n c
n
n
n c n
n c
qnode b n
n
n c n
n c
n
n
n c n
n c




fidarwiche provan

q dag depicted figure b therefore applying
two q dag nodes one evaluate pr b e evaluate
pr b e instantiation e evidence variables e

computational complexity q dag generation

computational complexity generating q dags determined
computational complexity clustering particular proposed applies operation precisely clustering applies additionoperation similarly applies
operation precisely clustering applies
multiplication operation therefore assume
take constant time
time complexity
application
ends adding node q dag
way node added q dag moreover number parents
added node equal number arguments corresponding arithmetic operation
invoked clustering therefore space complexity q dag
time complexity clustering
particular means space complexity q dags terms number
evidence variables time complexity clustering
terms moreover evidence variable e add evidence specific nodes
q dag number values variable e take important
stress without complexity guarantee may hard distinguish
proposed brute force builds big table containing possible
instantiations evidence variables together corresponding distributions query
variables

generation

polytree special case clustering shown shachter
et al therefore polytree modified suggested
compute q dags means cutset conditioning easily modified
compute q dags instantiation c cutset c compute q dag node
pr x c e polytree take sum resulting nodes
exact inference belief networks adapted generate qdags general must satisfy key condition adaptable computing
q dags suggested condition behavior
never depend specific evidence obtained depend variables
evidence collected whether variable e instantiated value v
value v affect complexity whether variable e
instantiated matter
belief networks aware satisfy property reason
seems notion probabilistic independence
specifically read topology belief network relation
x z stating variables x independent given variables z
pr x j z pr x j z pr j z


fia practical paradigm implementing belief network inference

instantiations x z variables possible however hold
instantiations z specific ones standard aware
take advantage instantiation specific notion independence therefore
cannot attach computational significance specific value variable
instantiated property existing makes easily adaptable
generation q dags

soundness q dag clustering

soundness proposed stated proof given appendix

theorem suppose qnode x q dag potential generated q dag clustering query variable x evidence variables e let e instantiation
variables e let q dag evidence e defined follows

evidence e sets variable e value e
e e e otherwise


qnode x x pr x e

theorem guarantees q dag nodes generated
evaluate corresponding probabilities partial full instantiation
evidence variables

reducing query dags

section focused reducing q dags generated main
motivation behind reduction twofold faster evaluation q dags less space
store interestingly enough observed simple reduction techniques
tend certain cases subsume optimization techniques uential practical implementations belief network inference therefore reducing q dags
important practically
section structured follows first start discussing four simple reduction
operations form rewrite rules examples reductions subsume two key optimization techniques known network pruning computation caching

reductions

goal q dag reduction reduce size q dag maintaining
arithmetic expression represents describing equivalence arithmetic expressions
define notion q dag equivalence
definition two q dags equivalent iff set evidence specific
nodes output possible q dag evidence
two level binary networks bn networks versions spi
take advantage independences



fidarwiche provan

q








p



q
q

q

p





q


q

q


q q





q



q

q

b numeric
reduction

c associative
merging

q

q
q

identity
elimination

q

q

commutative
merging

figure four main methods q dag reduction
figure shows four basic reduction operations experimented
identity elimination eliminates numeric node identity element child
operation node
numeric reduction replaces operation node numeric node parents
numeric nodes
associative merging eliminates operation node operation associativity
commutative merging eliminates operation node operation commutativity
rules applied successively different order applications
possible
proven operations sound darwiche provan
analysis network structure preliminary empirical observed
many factors govern effectives operations degree reduction
operations numeric reduction particular reduce size q dag depends
topology given belief network set evidence query variables
example root nodes evidence variables belief network leaf nodes
query variables numeric reduction lead little q dag reduction
focus numeric reduction showing sometimes subsumes two optimization techniques uential belief network optimizations examples unoptimized employs numeric reduction
yields q dag optimized major implication optimizations done uniformly q dag level freeing underlying belief network
implementational complications
following examples assume applying polytree singlyconnected networks


fia practical paradigm implementing belief network inference





p








b








b






p b






p c b

b



p

p b




c




b

figure simple belief network pruning pruning b light shaded
node query node dark shaded node b evidence node

p b b

p b b







b











b




















b

b





original q dag

b reduced q dag

figure q dag reduction b

network pruning
pruning process deleting irrelevant parts belief network invoking inference consider network figure example b evidence variable
query variable one prune node c network leading network
figure b query form pr j b value respect
network clear working smaller network preferred general
pruning lead dramatic savings since reduce multiply connected network
singly connected one


fidarwiche provan

generate q dag network figure polytree
obtain one figure q dag corresponds following expression
x
x
pr e pr b b pr b j pr c j b
c

b

generate q dag network figure b however obtain one
figure b corresponds following expression
x
pr e pr b b pr b j
b

expected q dag smaller q dag figure contains subset
nodes figure
key observation however optimized q dag figure b
obtained unoptimized one figure q dag reduction particular
nodes enclosed dotted lines collapsed numeric reduction single
node value identity elimination remove resulting node leading
optimized q dag figure b
general observation however prunable nodes contribute identity elements computing answers queries contributions appear q dag nodes
evaluate identity elements instantiations evidence nodes
easily detected collapsed identity elements numeric reduction identity
elimination remove q dag leading effect network
pruning whether q dag reduction replace possible pruning operations open
question outside scope

computation caching

caching computations another uential technique optimizing inference belief networks consider example suppose applying polytree
compute pr c b network figure given evidence say b
compute pr c b passing messages shown figure evidence
changes b however employing caching recompute message b represents causal support b pearl since value
message depend evidence b kind optimization typically
note however q dag reduction reduce computational complexity generating qdag although network pruning may example multiply connected network may become singlyconnected pruning thereby reducing complexity generating q dag q dag
reduction still generate q dag working multiply connected network
seen considering following expression evaluated incrementally polytree
message passes
pr c e

x
b

pr c j b b b



x


pr b j pr

z

c b

z
b



clear subexpression corresponding message b b independent
evidence b



fia practical paradigm implementing belief network inference


b
c



pr







pr b






pr c b

b







figure simple belief network demonstrating relationship q dag reduction computation caching light shaded node c query node
dark shaded node b evidence node




b
b

b
c
c

figure message passing c queried b observed
implemented caching values messages keeping track messages
affected evidence
consider q dag corresponding shown figure
nodes enclosed dotted lines correspond message b nodes
evidence specific nodes ancestor set therefore never change values
due evidence changes fact numeric reduction replace one nodes
ancestors single node shown figure b
general numeric reduction applied q dag one guaranteed following
q dag node represents message depend evidence node
evaluated given evidence changes b numeric reduction guarantee
p pr b pr
precisely correspond expression




j

fidarwiche provan

p c b b

p c b b
















b










b



b

b

















cached value













original q dag

b reduced q dag

figure q dag reduction b
q dag evaluation method since replace node ancestor set
single root node

optimization belief network inference

network pruning computation caching proven uential practical
implementations belief network inference fact experience shown
optimizations typically make difference usable non usable beliefnetwork system
one optimizations however specific implementations although general principles e g taking advantage network
topology another make elegant complicated hard
understand moreover optimizations often hard define succinctly hence
well documented within community
contrast belief network inference optimized generating q dags unoptimized inference optimizing generated q dag reduction techniques shown examples earlier respect pruning
caching optimizations however whether alternate optimization
feasible yet known positive answer clearly provide independent
note q dags lead refined caching mechanism q dag evaluator caches value
q dag node updates cached values need
value parent node changes refined mechanism allows caching values messages
depend evidence well



fia practical paradigm implementing belief network inference

fuel sensor
fuel
battery

oil pressure
battery sensor

fault

oil pressure
sensor
alternator
alternator
sensor

figure simple belief network car diagnosis
optimizing belief network inference practically important least
two reasons first q dag reduction techniques seem much simpler understand
implement since deal graphically represented arithmetic expressions without
invoke probability belief network theory second reduction operations applicable q dags generated belief network therefore optimization
q dag reduction would systematic accessible bigger
class developers

diagnosis example
section contains comprehensive example illustrating application q dag
framework diagnostic reasoning
consider car troubleshooting example depicted figure simple case
want determine probability distribution fault node given evidence four
sensors battery alternator fuel oil sensors sensor provides information
corresponding system fault node defines five possible faults normal cloggedfuel injector dead battery short circuit broken fuel pump
denote fault variable f sensor variables e want build
system compute probability pr f e fault f evidence e
probabilities represent unnormalized probability distribution fault variable
given sensor readings q dag framework realizing diagnostic system involves three
steps q dag generation reduction evaluation first two steps accomplished
line final step performed line discuss one steps
detail

q dag generation
first step generate q dag accomplished applying q dag
clustering fault query variable sensors evidence vari

fidarwiche provan

p f normal e

p f normal


p f pump


fuel
normal

p f pump e

fuel
subtree

pump

battery
normal

battery
pump

alternator
normal

oil
alternator
pump

normal

oil
pump

structure sharing

figure partial q dag car example displaying two five query nodes
broken fuel pump normal shaded regions portions q dag
shared multiple query nodes values nodes relevant
value one query node
ables resulting q dag five query nodes qnode f normal e qnode f
clogged fuel injector e qnode f dead battery e qnode f short circuit e
qnode f broken fuel pump e node evaluates probability corresponding fault instantiation evidence probabilities constitute differential
diagnosis tells us fault probable given certain sensor values
figure shows stylized description q dag restricted two five query
nodes corresponding pr f broken fuel pump e pr f normal e q dag
structure symmetric fault value sensor
given q dag symmetric possible faults clarity exposition
look subset needed evaluate node pr f broken fuel pump e figure
shows stylized version q dag produced node following observations q dag first evidence specific node every instantiation
sensor variables corresponding forms sensor measurements possible second
roots q dag probabilities third one five parents query node
pr f broken fuel pump e prior f broken fuel pump four
contributions four sensors example figure highlights dots
part q dag computing contribution battery sensor

q dag reduction

generating q dag one proceeds reducing graph rewrite rules figure
shows example reduction q dag restricted one query node
simplicity give idea kind reduction applied consider
partial q dag enclosed dots figure figure compares reduced q dag
unreduced one generated given goal generating q dags
evaluated eciently possible b require minimal space store


fia practical paradigm implementing belief network inference

key
f fuel sensor
b battery sensor
alternator sensor
oil sensor

p f pump e





p f pump












full











esn b esn esn esn esn

esn f esn b

esn f
empty



dead

charged

ok

ok

low



normal

figure partial q dag car example





reduced q dag
esn b

esn b

dead

charged



b original q dag






esn b

esn b



charged

dead

p b charged p b charged
f pump b charged f pump








esn b



charged

p b dead
p b charged
p b charged
f pump b dead
f pump b charged f pump








p b dead
f pump


esn b
dead
p b dead
f pump b dead



p b dead
f pump


figure reduced unreduced q dags car diagnosis example
important see even simple example q dag reduction make big difference
size


fidarwiche provan

q dag evaluation

reduced q dag use compute answers diagnostic queries
section presents examples evaluation respect generated q dag
suppose obtain readings dead normal ok full battery oil
alternator fuel sensors respectively let us compute probability distribution
fault variable obtained evidence formalized follows
e battery sensor dead
e oil sensor normal
e alternator sensor ok
e fuel sensor full
evidence specific nodes evaluated according definition example

n battery sensor charged

n battery sensor dead
evaluation evidence specific nodes shown pictorially figure definition
used evaluate remaining nodes values node parents
known value node determined figure b depicts
evaluating nodes interest probability assigned
query node pr fault broken fuel pump e
suppose evidence changed value fuel sensor empty instead
full update probability assigned node pr fault broken fuel pump e brute
force method evaluate whole q dag however forward propagation scheme
used implement node evaluator four nodes need evaluated
figure b enclosed circles instead thirteen total number nodes
stress point refined updating scheme easy implement
framework much harder achieve one attempts embed standard beliefnetwork message passing

concluding remarks

introduced paradigm implementing belief network inference oriented towards real world line applications proposed framework utilizes knowledge
query evidence variables application compile belief network arithmetic expression called query dag q dag node q dag represents numeric
operation number symbol depends available evidence leaf node
q dag represents answer network query probability event
interest inference q dags linear size amounts standard evaluation
arithmetic expressions represent
important point stress work reported proposing
belief network inference proposing paradigm


fia practical paradigm implementing belief network inference

pr f pump e
evaluating esns






pr f pump











esn f
empty















esn b
dead

esn f
full





esn b
charged









esn
ok



esn
ok






esn
low



esn
normal



esn values



pr f pump e
b propagating probabilities





esn f
empty






pr f pump







esn f
full




esn b
dead






esn b
charged





esn
ok





esn
ok






esn
low







esn
normal



esn values

figure evaluating q dag car diagnosis example given evidence sensors
bar indicates instantiation esns shaded numbers
b indicate probability values computed node evaluator
circled operations left hand side b ones need
updated evidence fuel system sensor altered denoted circled
esns



fidarwiche provan

implementing belief network inference orthogonal standard inference
engineered meet demands real world line applications class
applications typically demanding following reasons
typically requires short response time e milliseconds
requires software written specialized languages ada c
assembly pass certification procedures
imposes severe restrictions available software hardware resources order
keep cost unit electromechanical device low possible
address real world constraints proposing one compile belief network
q dag shown figure use q dag evaluator line reasoning
brings required memory needed storing q dag evaluator
brings required software needed implementing q dag evaluator
simple seen earlier
proposed still requires belief network generate q dag
makes eciency less critical factor example
standard optimizations belief network inference pruning
caching become less critical q dag framework since optimizations tend
subsumed simple q dag reduction techniques numeric reduction
work reported extended least two ways first qdag reduction techniques could explored oriented towards reducing evaluation
time q dags others towards minimizing memory needed store second
shown optimization techniques dramatically improve belief network
may become irrelevant size q dags q dag reduction employed
investigation needed prove formal guarantees effectiveness
q dag reduction
close section noting framework proposed applicable
order magnitude omp belief networks multiplication addition get replaced
addition minimization respectively goldszmidt darwiche goldszmidt
omp q dag evaluator however much ecient probabilistic
counterpart since one may evaluate minimization node without evaluate
parents many cases make considerable difference performance q dag
evaluator

acknowledgements
work carried first author rockwell science
center special thanks jack breese bruce ambrosio anonymous reviewers
useful comments earlier drafts
shown clustering conditioning used q dag generation
spi li ambrosio shachter et al used well



fia practical paradigm implementing belief network inference

appendix proof theorem

without loss generality assume proof variables declared evidence
variables prove soundness theorem need q dag potential evaluate corresponding probabilistic potential possible evidence
formally cluster variables x matrices assigned
need


n pr x
n x pr x x

x

x

given evidence e establish guaranteed qnode x x
evaluate probability pr x e application
q dag isomorphic application probabilistic respectively
prove equation extend q dag node evaluator mappings
standard way f mapping instantiations q dag nodes f
defined follows
f x def f x
simply apply q dag node evaluator range mapping f
note f
g equal f g therefore

n pr x
n x
xy

n pr x n x
x


pr x n x definition n pr x
x

note definition n x n x x equals n x x therefore
n x x n x x

e n x x
e x x e x

otherwise
x x
therefore


n pr x
n x pr x x
x

x

references

darwiche goldszmidt relation kappa calculus probabilistic reasoning proceedings tenth conference uncertainty artificial
intelligence uai pp
darwiche provan g query dags practical paradigm implementing
line causal network inference tech rep rockwell science center thousand
oaks ca


fidarwiche provan

goldszmidt qualitative probabilities normative framework commonsense
reasoning tech rep r university california los angeles ph thesis
jensen f v lauritzen olesen k bayesian updating recursive graphical
local computation computational statistics quarterly
li z ambrosio b ecient inference bayes networks combinatorial
optimization international journal approximate reasoning
pearl j probabilistic reasoning intelligent systems networks plausible inference morgan kaufmann publishers inc san mateo california
peot shachter r fusion propagation multiple observations
belief networks artificial intelligence
shachter r andersen szolovits p global conditioning probabilistic
inference belief networks proc tenth conference uncertainty ai pp
seattle wa
shachter r ambrosio b del favero b symbolic probabilistic inference
belief networks proc conf uncertainty ai pp
shenoy p p shafer g propagating belief functions local computations
ieee expert




