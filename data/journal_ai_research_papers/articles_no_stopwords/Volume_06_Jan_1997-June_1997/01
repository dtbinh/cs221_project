Journal Artificial Intelligence Research 6 (1997) 35-85

Submitted 7/96; published 1/97

SCREEN: Learning Flat Syntactic Semantic Spoken
Language Analysis Using Artificial Neural Networks
Stefan Wermter
Volker Weber

wermter@informatik.uni-hamburg.de
weber@informatik.uni-hamburg.de

Department Computer Science
University Hamburg
22527 Hamburg, Germany

Abstract
Previous approaches analyzing spontaneously spoken language often based
encoding syntactic semantic knowledge manually symbolically.
progress using statistical connectionist language models, many current
spoken-language systems still use relatively brittle, hand-coded symbolic grammar
symbolic semantic component.
contrast, describe so-called screening approach learning robust processing
spontaneously spoken language. screening approach analysis uses shallow sequences category representations analyzing utterance various syntactic,
semantic dialog levels. Rather using deeply structured symbolic analysis,
use connectionist analysis. screening approach aims supporting speech
language processing using (1) data-driven learning (2) robustness connectionist
networks. order test approach, developed screen system
based new robust, learned analysis.
paper, focus detailed description screen's architecture,
syntactic semantic analysis, interaction speech recognizer, detailed
evaluation analysis robustness uence noisy incomplete input.
main result paper representations allow robust processing
spontaneous spoken language deeply structured representations. particular,
show fault-tolerance learning capability connectionist networks support
analysis providing robust spoken-language processing within overall
hybrid symbolic/connectionist framework.

1. Introduction
Recently fields speech processing well language processing seen
efforts examine possibility integrating speech language processing (von Hahn
& Pyka, 1992; Jurafsky et al., 1994b; Waibel et al., 1992; Ward, 1994; Menzel, 1994; Geutner
et al., 1996; Wermter et al., 1996). new large speech language corpora
developed rapidly, new techniques examined particularly support
properties speech language processing. Although quite
approaches spoken-language analysis (Mellish, 1989; Young et al., 1989; Hauenstein &
Weber, 1994; Ward, 1994), emphasized learning syntactic semantic
analysis spoken language using hybrid connectionist1 architecture topic
c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiWermter & Weber

paper goal screen2 . However, learning important reduction
knowledge acquisition, automatic system adaptation, increasing system
portability new domains. Different previous approaches, paper
demonstrate hybrid connectionist learning techniques used providing
robust analysis faulty spoken language.
Processing spoken language different processing written language, successful techniques text processing may useful spoken-language processing.
Processing spoken language less constrained, contains errors less strict regularities written language. Errors occur levels spoken-language processing.
instance, acoustic errors, repetitions, false starts repairs prominent spontaneously spoken language. Furthermore, incorrectly analyzed words, unforeseen grammatical semantic constructions occur often spoken language. order deal
important problems \real-world" language analysis, robust processing necessary.
Therefore cannot expect existing techniques context-free tree representations
proven work written language simply transferred spoken
language.
instance, consider speech recognizer produced correct German sentence hypothesis \Ich meine naturlich Marz" (English translation: \I mean course
March"). Standard techniques text processing - chart parsers context-free
grammars - may able produce deeply structured tree representations many correct
sentences shown Figure 1.
sentence
verb phrase

noun group

pronoun

verb group

verb

noun group

adverb

ich (I) meine (mean) natrlich (of_course)

noun

Mrz (March)

Figure 1: Tree representation correctly recognized sentence
However, currently speech recognizers still far perfect produce many word
errors possible rely perfect sentence hypothesis. Therefore, incorrect
1. Sometimes connectionist networks called artificial neural networks. use
term \connectionist networks", term \hybrid connectionist architecture" refer
architecture emphasizes use connectionist networks rule use
symbolic representations higher levels might needed.
2. Symbolic Connectionist Robust EnterprisE Natural language

36

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

variations \Ich meine ich Marz" (\I mean March"), \Ich hatte ich Marz" (\I
March") \Ich Ich meine Marz" (\I mean March") analyzed. However,
context-free grammars single syntactic semantic category error may prevent
complete tree built, standard top-down chart parsers may fail completely. However, suboptimal sentence hypotheses analyzed since sometimes sentence
hypotheses best possible output produced speech recognizer. Furthermore,
lot content extracted even partially incorrect sentence hypotheses.
instance, \I March" plausible agent \I" said something
time \March". Therefore, robust analysis able analyze sentence
hypotheses ideally break input.

1.1 Screening Approach: Flat Representations Support Robustness
examples incorrect variations sentence hypotheses, in-depth structured
syntactic semantic representation advantageous since arbitrary word order spontaneous errors make often impossible determine desired deep highly
structured representation. Furthermore, deep highly structured representation may
many restrictions appropriate spontaneously spoken language. However,
maybe even important, certain tasks necessary perform in-depth
analysis. While, instance, inferences story understanding require in-depth
understanding (Dyer, 1983), tasks information extraction spoken language
need much in-depth analysis. instance, output parser used
translating speech recognizer sentence hypothesis \Eh ich meine eh ich Marz" (\Eh
mean eh March"), may sucient extract agent (\I") uttered (\mean")
time (\March"). contrast deeply structured representation, screening approach
aims reaching robust representation spoken language. screening approach
shallow analysis based category sequences (called representations) various
syntactic semantic levels.
representation structures utterance U words w1 wn according
syntactic semantic properties words contexts, e.g., according sequence
basic abstract syntactic categories. instance, phrase \a meeting London"
described representation \determiner noun preposition noun" basic
syntactic level representation \noun-group noun-group prepositional-group
prepositional-group" abstract syntactic level. Similar representations used
semantic categories, dialog act categories, etc.
Kase
(Rubbish)
noun

noun group
negation

ich
(I)
pronoun
animate
noun group
agent

meine
(mean)
verb
utter
verb group
action

naturlich
(of course)
adverb
nil
special group
miscellaneous

Marz
(March)
noun
time
noun group
time

Figure 2: Utterance representation
37

fiWermter & Weber

Figure 2 gives example representation correct sentence hypothesis
\Kase ich meine naturlich Marz" (\Rubbish mean course March"). first line shows
sentence, second literal translation. third line describes basic syntactic
category word, fourth line shows basic semantic category. last two lines
illustrate syntactic semantic categories phrase level.
Kase
(Rubbish)
noun

noun group
negation

ich
(I)
pronoun
animate
noun group
agent

hatte
(had)
verb

verb group
action

ich
(I)
pronoun
animate
noun group
agent

Marz
(March)
noun
time
noun group
time

Figure 3: Utterance representation
Figure 3 gives example representation incorrect sentence hypothesis
\Kase ich hatte ich Marz" (\Rubbish March"). parser spoken language
able process sentence hypotheses far possible, use
representations support necessary robustness. example, analysis
least provide animate agent noun group (\I") made statement
specific time noun group (\March"). Flat representations potential support
robustness better since minimal sequential structure, even error
occurs whole representation still built. contrast, standard tree-structured
representations many decisions made construct deeply structured
representation, therefore possibilities make incorrect decisions,
particular noisy spontaneously spoken language. chose representations
rather highly structured representations desired robustness
mistakes speech/language systems.

1.2 Flat Representations Learned Hybrid Connectionist Framework

Robust spoken-language analysis using representations could pursued different
approaches. Therefore want motivate use hybrid connectionist approach,
uses connectionist networks far possible rule use symbolic
knowledge. use connectionist networks?
important, due distributed fault tolerance, connectionist networks support
robustness (Rumelhart et al., 1986; Sun, 1994) connectionist networks number properties relevant spoken-language analysis. instance,
connectionist networks well known learning generalization capabilities.
Learning capabilities allow induce regularities directly examples. training
examples representative task, noisy robust processing supported
inductive connectionist learning.
Furthermore, hybrid connectionist architecture property different knowledge sources take advantage learning generalization capabilities connectionist networks. hand, knowledge - task control knowledge -
38

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

rules known represented directly symbolic representations. Since humans apparently symbolic inferencing based real neural networks, abstract models
symbolic representations connectionist networks additional potential
shed light human language processing capabilities. respect, approach
differs candidates robust processing, statistical taggers statistical
n-grams. statistical techniques used robust analysis (Charniak, 1993)
statistical techniques n-grams relate human cognitive language capabilities simple recurrent connectionist networks relationships human
cognitive language capabilities (Elman, 1990).
screen new hybrid connectionist system developed examination
syntactic semantic analysis spoken language. earlier work explored
scanning understanding written texts (Wermter, 1995; Wermter & Lochel, 1994;
Wermter & Peters, 1994). Based experience started completely new project
screen explore learned fault-tolerant analysis spontaneously spoken-language
processing. preliminary successful case studies transcripts developed
screen system using knowledge generated speech recognizer. previous work,
gave brief summary screen specific focus segmentation parsing dialog
act processing (Wermter & Weber, 1996a). paper, focus detailed description
screen's architecture, syntactic semantic analysis, interaction
speech recognizer, detailed evaluation analysis robustness uence
noisy incomplete input.

1.3 Organization Claim Paper
paper structured follows. Section 2 provide detailed description
examples noise spoken language. Noise introduced human speaker
speech recognizer. Noise spoken-language analysis motivates representations whose categories described Section 3. basic abstract categories
syntactic semantic level explained section. Section 4 motivate
explain design screen architecture. brief functional overview, show
overall architecture explain details individual modules connectionist
network level. order demonstrate behavior analysis spoken language
provide various detailed examples Section 5. Using several representative sentences
walk reader detailed step-by-step analysis. behavior system explained, provide overall analysis screen system Section 6.
evaluate system's individual networks, compare performance simple recurrent networks statistical n-gram techniques, show simple recurrent networks
performed better 1-5 grams syntactic semantic prediction. Furthermore
provide overall system evaluation, examine overall performance uence
additional noise, supply results transfer different second domain. Finally
compare approach approaches conclude representations based
connectionist networks provide robust learned spoken-language analysis.
want point paper make argument deeply structured symbolic representations language processing general. Usually, deeply
structured representation built, course due additional knowledge con39

fiWermter & Weber

tains, potential powerful relationships interpretations greater
representation. instance, in-depth analysis required tasks making
detailed planning inferences reading text stories. However, screening approach
motivated based noisy spoken-language analysis. noisy spoken-language analysis,
representations support robustness, connectionist networks effective providing robustness due learned fault-tolerance. main contribution
paper, demonstrate building evaluating computational hybrid
connectionist architecture screen based at, robust, learned processing.

2. Processing Spoken Language

goal learn process spontaneously spoken language syntactic semantic
level fault-tolerant manner. section give motivating examples spoken
language.

2.1 \Noise" Spoken Language

domain paper arrangement meetings business partners,
currently use 184 spoken dialog turns 314 utterances domain. One
turn consists one subsequent utterances speaker. 314
utterances, thousands utterance hypotheses generated processed
based underlying speech recognizer. German utterance examples domain
shown together literal English translation. important note
English translations word-for-word translations.
1. Kase ich meine naturlich Marz
(Rubbish mean course March)
2. Der vierzehnte ist ein Mittwoch richtig
(The fourteenth Wednesday right)
3. hm sechsten April bin ich leider auer Hause
(Eh sixth April unfortunately home)
4. ich dachte noch der nachsten Woche auf jeden Fall noch im April
(So thought still next week case still April)
5. Gut prima vielen Dank dann ist das ja kein Problem
(Good great many thanks yeah problem)
6. Oh das ist schlecht da habe ich um vierzehn Uhr dreiig einen Termin beim Zahnarzt
(Oh bad fourteen o'clock thirty date dentist)
7. Ja genau allerdings habe ich da von neun bis vier Uhr schon einen Arzttermin
(Yes exactly however nine four o'clock already doctorappointment)
see, spoken language contains many performance phenomena, among
exclamations (\rubbish", see Example 1), interjections (\eh", \so", \oh", see Examples 3,
40

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

4 6), new starts (\there ...", see Example 6). Furthermore, syntactic
semantic constraints spoken language less strict written text. instance,
word order spontaneously spoken language often different written language.
Therefore, spoken language \noisier" written language even transcribed
sentences, well-known parsing strategies text processing - rely
wellformedness criteria - directly applicable analyzing spoken language.

2.2 \Noise" Speech Recognizer

want analyze spoken language computational model,
\noise" introduced humans speaking \noise" introduced limitations speech recognizers. Typical speech recognizers produce many separated word
hypotheses different plausibilities time based given speech signal. word
hypotheses connected word hypothesis sequence evaluated
providing basis analysis. Typically, word hypothesis consists four parts: 1)
#PAUSE#
0.00-[0.01-0.33]

hm (eh)

ich (I)

0.02-[0.11-0.33]

5.36e-02

0.12-[0.33-0.33]

wie (how)
2.92e-03

htte (had)
1.06-[1.21-1.21]

0.13-[0.33-0.33]

(on)
2.78e-03

April (April)
3.66e-04

0.81-[1.05-1.22]

ich (I)
1.22-[1.37-1.37]

1.12-[1.22-1.22]

ich (I)

leider (unfortunately)
3.33e-04

0.34-[0.43-0.43]

6.84e-03

sechsten (sixth)

6.53e-05

0.44-[0.80-0.80]

3.54e-03

1.13-[1.22-1.22]

bin (am)
1.53e-03

1.23-[1.30-1.37]

1.38-[1.59-1.59]

3.01e-01

5.07e-08

wenn (if)
3.35e-04

ich (I)
1.18e-02

1.31-[1.38-1.38]

1.81e-02

leider (unfortunately)
1.39-[1.59-1.59]

6.37e-04

auer (out of)
1.60-[1.90-1.90]

Hause (home)

6.74e-05

1.91-[2.37-3.38]

7.18e-01

2.38-[3.38-3.38]

#PAUSE#
3.39-[3.39-3.39]

1.88e-07

#not recognized#
2.74e-07

Figure 4: Simple word graph spoken utterance: \ahm sechsten April bin ich
leider auer Hause" (\eh sixth April unfortunately home").
node represents word hypothesis; arrow represents possible
subsequent word hypotheses. word hypothesis shown word
string, start time, end time interval acoustic plausibility.
41

fiWermter & Weber

start time seconds, 2) end time seconds, 3) word string hypothesis,
4) plausibility hypothesis based confidence speech recognizer. show simple word graph3 . practice, word graphs spontaneous speech
much longer leading comprehensive word hypothesis sequences. However, illustrating
properties speech input focus relatively short simple word graph
(Figure 4).
word hypotheses overlap time constitute directed graph called word
graph. node word graph represents one word hypothesis. Two hypotheses
graph generated word hypotheses connected end time first word
hypothesis directly start time second word hypothesis. instance,
word hypothesis \am" (\on") ending 0.43 hypothesis \sechsten" (\sixth")
starting 0.44 connected word hypothesis sequence.
hm
(eh)
hm
(eh)
0sec

ich
(I)


(on)

sechsten
(sixth)

April
(April)

bin
(am)

leider
(unfort.)

auer
(out of)

Hause
(home)


(on)

sechsten
(sixth)

April
(April)

wenn ich ich leider
(if) (I) (I) (unfort.)

auer
(out of)

Hause
(home)

1sec

ich
(I)

3sec

Figure 5: Two examples word hypothesis sequences word graph
example word graph simple. However, shown Figure 5, possible
word hypothesis sequence desired \A hm sechsten April bin ich leider
auer Hause" (\Eh sixth April unfortunately home"), sequence
\A hm ich sechsten April wenn ich ich leider auer Hause" (\Eh sixth April
unfortunately home"). Consequently, deal incorrectly recognized
words extraordinary order. Therefore syntactic semantic analysis
fault-tolerant order process noisy word hypothesis sequences.

3. Flat Category Representation: Intermediate Connecting
Representation
section describe category representations. First, show
categories syntactic analysis depict categories semantic
analysis.
3. speech input form test word graphs taken so-called Blaubeuren Meeting
Corpus. particular word graphs used provided project partners general test
purposes Verbmobil project. particularly generated testing parsing strategies.
Therefore speech recognizer fine-tuned produce relatively small word graphs relatively
high word accuracy 93%. vocabulary size HMM recognizer 628. average number
hypotheses per word 6.3 10 dialogs.

42

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

3.1 Categories Flat Syntactic Analysis

Flat syntactic analysis assignment syntactic categories sequence words, e.g.,
word hypothesis sequence generated speech recognizer. Flat representations
phrase group level support local structural decisions. Local structural decisions deal
problem phrase group (abstract syntactic category) word belongs to.
case local, directly preceding words phrase group uence
current decision. instance, determiner \the" could part prepositional group
\in mine" part starting noun group \the old mine". is, local structural
decisions depending local context made based analysis.
syntactic analysis developed level basic syntactic categories
abstract syntactic categories. syntactic categories may vary depending language, degree detail intended structural representation. However,
general approach rather independent specifically used categories. fact,
used syntactic categories two different domains: railway counter interactions
business meeting arrangements. basic syntactic categories used noun,
verb, preposition, pronoun, numeral, past participle, pause, adjective, adverb, conjunction,
determiner, interjection other. shown abbreviations Table 1.
Category
noun (N)
verb (V)
preposition (R)
pronoun (U)
numeral (M)
participle (P)
pause (/)

Examples
date, April
meet, choose
at,
I,
fourteenth
taken
pause

Category
adjective (J)
adverb (A)
conjunction (C)
determiner (D)
interjection (I)
(O)

Examples
late
often
and,
the,
eh, oh
particles

Table 1: Basic syntactic categories
abstract syntactic categories used verb group, noun group, adverbial group,
prepositional group, conjunction group, modus group, special group interjection group.
abstract syntactic categories shown Table 2.
Category
verb group (VG)
noun group (NG)
adverbial group (AG)
prepositional group (PG)
conjunction group (CG)
modus group (MG)
special group (SG)
interjection group (IG)

Examples
mean, would propose
date, next possible slot
later, early possible
dining hall
and, either ...
interrogatives, confirmations: when, long, yes
additives politeness: please,
interjections, pauses: eh, oh

Table 2: Abstract syntactic categories
43

fiWermter & Weber

categories express main syntactic properties phrases.
basic abstract syntactic categories widely used different parsers. However,
approach representations crucially rely specific set basic
abstract syntactic categories. goal train, learn generalize syntactic
analysis based abstract syntactic categories basic syntactic categories. Local syntactic decisions made far possible. Local syntactic ambiguities
phrase group level (abstract syntactic categories) dealt global ambiguities prepositional phrase attachment dealt since need
additional knowledge, e.g., semantics module. complete syntax trees
certain preference (which might turn wrong based semantic knowledge),
syntactic representation goes far possible using local syntactic knowledge
disambiguation.

3.2 Categories Flat Semantic Analysis

Since semantic analysis domain-dependent, semantic categories differ different
domains. worked particularly two domains: railway counter interactions (called:
Regensburg train corpus) business meeting arrangements (called: Blaubeuren meeting
corpus). 3/4 overlap semantic categories train corpus
Category
select (SEL)
suggest (SUG)
meet (MEET)
utter (UTTER)
(IS)
(HAVE)
move (MOVE)
aux (AUX)
question (QUEST)
physical (PHYS)
animate (ANIM)
abstract (ABS)
(HERE)
source (SRC)
destination (DEST)
location (LOC)
time (TIME)
negative evaluation (NO)
positive evaluation (YES)
nil (NIL)

Examples
select, choose
propose, suggest
meet, join
say, think
is,
had,
come, go
would, could
question words: where,
physical objects: building, oce
animate objects: I,
abstract objects: date
time location state words, prepositions: at,
time location source words, prepositions:
time location destination words, prepositions:
Hamburg, Pittsburgh
tomorrow, 3 o' clock, April
no, bad
yes, good
words \without" specific semantics, e.g., determiner:

Table 3: Basic semantic categories
meeting corpus (Wermter & Weber, 1996b). Differences occurred mainly verbs,
e.g., NEED-events frequent railway counter interactions SUGGESTevents frequent business meeting interactions. semantic categories
44

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Category
action (ACT)
aux-action (AUX)
agent (AGENT)
object (OBJ)
recipient (RECIP)
instrument (INSTR)
manner (MANNER)
time-at (TM-AT)
time-from (TM-FRM)
time-to (TM-TO)
loc-at (LC-AT)
loc-from (LC-FRM)
loc-to (LC-TO)
confirmation (CONF)
negation (NEG)
question (QUEST)
misc (MISC)

Examples
action full verb events: meet, select
auxiliary action auxiliary events: would
agent action:
object action: date
recipient action:
instrument action: using elevator
achieve action: without changing rooms
time: morning
start time: 6am
end time: 8pm
location: Frankfurt, New York
start location: Boston, Dortmund
end location: Hamburg
confirmation phrase: ok great, yes wonderful
negation phrase: stop,
question phrases: time
miscellaneous words, e.g., politeness: please, eh

Table 4: Abstract semantic categories
railway counter interactions described previous work (Weber & Wermter, 1995).
primarily focus semantic categories meeting corpus. basic
semantic categories word shown Table 3. higher level abstraction,
word belong abstract semantic category. possible abstract semantic categories
shown Table 4. summary, categories provide basis analysis.
word represented syntactically semantically context four categories two
basic two abstract levels.

4. Architecture SCREEN System

section want describe constraints principles important
system design. outlined motivated introduction, screening approach
at, robust, learned analysis spoken language based category sequences (called
representations) various syntactic semantic levels. order test screening
approach, designed implemented hybrid connectionist screen system
processes spontaneously spoken language using learned connectionist representations.
summarize main requirements order motivate specific system design
explained subsequent subsections.

4.1 General Motivation Architecture

consider learning extremely important spoken-language analysis several
reasons. Learning reduces knowledge acquisition increases portability, particularly
spoken-language analysis, underlying rules regularities dicult
formulate often reliable. Furthermore, cases, inductive learning may detect
45

fiWermter & Weber

unknown implicit regularities. want use connectionist learning simple recurrent
networks rather forms learning (e.g., decision trees) primarily
inherent fault-tolerance connectionist networks, knowledge
sequence words categories learned simple recurrent networks.
Fault-tolerance often occurring language errors ected system
design. commonly occurring errors (interjections, pauses, word repairs,
phrase repairs). However, fault-tolerance cannot go far try model class
occurring errors. number potentially occurring errors unpredictable constructions far large. screen, want incorporate explicit fault-tolerance using
specific modules correction well implicit fault-tolerance using connectionist network techniques inherently fault-tolerant due support similarity-based
processing. fact, even word completely unknown, recurrent networks use
empty input may even assign correct category sucient previous context.
Flat representations, motivated Sections 1 3, may support robust spokenlanguage analysis. However, connectionist representations provide full recursive power arbitrary syntactic semantic symbolic knowledge structures. contrast
context-free parsers, representations provide better basis robust processing
automatic knowledge acquisition inductive learning. However, argued use potentially unrestricted recursion well-known context-free grammar
parsers provides computational model recursive power humans
order understand language. order better support robustness, want use
representations spontaneous language analysis.
Incremental processing speech, syntax, semantics dialog processing parallel
allows us start language analysis parallel speech recognizer finished
analysis. incremental processing advantage providing analysis results
early stage. example, syntactic semantic processing occur parallel
slightly behind speech processing. analyzing spoken language based speech
recognizer output, want consider many competing paths word hypothesis sequences
parallel.
respect hybrid representations, examine hybrid connectionist architecture
using connectionist networks useful want use symbolic processing wherever necessary. Symbolic processing useful complex control
large system. hand learning robust analysis, use feedforward
simple recurrent networks many modules try use rather homogeneous, supervised
networks.

4.2 Overview Architecture

screen parallel integrated hybrid architecture (Wermter, 1994) various

main properties:

1. Outside module, difference communication symbolic
connectionist module. previous hybrid architectures emphasized different
symbolic connectionist representations, different representations screen
benefit common module interface. Outside connectionist symbolic
46

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

module communication identically realized symbolic lists contain values
connectionist units.
2. previous hybrid symbolic connectionist architectures usually within
either symbolic connectionist module (Hendler, 1989; Faisal & Kwasny, 1990;
Medsker, 1994), screen global state described collection individual
symbolic connectionist modules. Processing parallel long one module
need input second module.
3. communication among symbolic connectionist modules organized via
messages. hybrid architectures often used either activation
values symbolic structures, used messages consisting lists symbols
associated activation plausibility values provide communication medium
supports connectionist processing well symbolic processing.
give overview various parts screen (see Figure 6).
important output consists syntactic semantic category representations based
input incrementally recognized parallel word hypotheses. speech recognizer
generates many incorrect word hypotheses time, even correctly recognized speech
contain many errors introduced humans. representation used since
fault-tolerant robust than, instance, context-free tree representation since
tree representation requires many decisions representation.
module system, instance disambiguation abstract syntactic categories, contains connectionist network symbolic program. integration symbolic
connectionist representations occurs encapsulation symbolic connectionist
processes module level. Connectionist networks embedded symbolic modules
communicate via messages.
However, essential parts needed purposes learning spokenlanguage analysis why? Starting output individual word hypotheses
speech recognizer, first need component receives incremental stream
individual parallel word hypotheses produces incremental stream word hypothesis sequences (see Figure 6). call part speech sequence construction part.
needed transforming parallel overlapping individual word hypotheses word hypothesis sequences. word hypothesis sequences different quality goal
find work best word hypothesis sequences. Therefore need speech
evaluation part combine speech-related plausibilities syntactic semantic
plausibilities order restrict attention best found word hypothesis sequences.
Furthermore, need part analyzes best found word hypothesis sequences
according syntactic semantic representation. category part receives
stream current word hypothesis sequences. Two word hypothesis sequences
shown Figure 6. part provides interpretation word hypothesis sequence
basic syntactic categories, abstract syntactic categories, basic semantic categories,
abstract semantic categories. is, word hypothesis sequence assigned four
graded preferences four word categories.
Human speech analyzed speech recognizer may contain many errors. question
arises extent want consider errors. analysis several hundred
47

fiWermter & Weber

two word hypotheses sequences:
1.

output analysis
2.

Kse

ich

meine

natrlich

(rubbish)

(I)

(mean)

(of course) (March)

N

NG

U

NG



NEG

ANIM

AGENT UTTER ACT

V

VG



SG

N

NG

NILL

MISC

TIME

TMAT

Kse

ich

htte

ich

(rubbish)

(I)

(had)

(I)

N

NG

U

NG



NEG

ANIM

AGENT

V

Mrz

Mrz
(March)

VG

U

ACT

ANIM [AGENT] TIME

[NG]

N

NG
TMAT

....
syntactic/semantic hypotheses

case frame part

dialog part
learned
flat
syntactic
semantic
analysis

correction part
speech evaluation part

category part
constructed word hypotheses sequences:
Kse ich meine natrlich Mrz
1. Rubbish mean course March

speech sequence construction part

Kse ich htte ich Mrz
March

2. Rubbish

....

word hypotheses
word hypotheses generated speech recognizer:
0.00
0.11
0.45
0.45
0.57
0.57
0.58
0.76
0.95
1.12
1.13
0.76
1.15
1.35
3.00

input speech recognizer
current word hypothesis

0.10
0.44
0.56
0.57
0.75
0.75
0.94
1.14
1.11
2.99
1.34
1.11
2.99
2.99
3.00

#PAUSE#
Kse
ich
ich
meine
meine
htte
etliche
ich
Mrz
da
natrlich
Mrz
aus
#PAUSE#

Figure 6: Overview screen
48

(rubbish)
(I)
(I)
(mean)
(mean)
(had)
(several)
(I)
(March)
(there)
(of course)
(March)
(out)

7.022857e02
2.269389e06
3.697864e03
2.017291e03
1.245984e05
1.016475e04
2.831144e08
3.045548e08
1.749518e04
9.596145e16
1.257770e04
1.017243e07
4.249394e15
2.624843e12
7.497616e01

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

transcripts speech recognizer outputs revealed errors occur
often regularly. interjections, pauses, word repairs, phrase repairs.
Therefore designed correction part receives hypotheses words deals
frequently occurring errors spoken language explicitly.
parts outlined far build center integration speech-related
language-related knowledge fault-tolerant learning architecture, therefore
focus parts paper. However, want process complete dialog turns
contain several individual utterances need know certain utterance
starts constituents belong utterance. task performed case
frame part fills frame incrementally segments speaker's turn utterances.
long-term perspective screen provide analysis tasks spoken
utterance translation information extraction. Besides syntactic semantic analysis
utterance, intended dialog acts convey important additional knowledge. Therefore,
dialog part needed assigning dialog acts utterances, instance utterance
request suggestion. fact, already fully implemented case frame part
dialog part utterances. However, describe details two
parts paper since described elsewhere (Wermter & Lochel, 1996).
Learning screen based concepts supervised learning instance feedforward networks (Rumelhart et al., 1986), simple recurrent networks (Elman, 1990)
general recurrent plausibility networks (Wermter, 1995). general, recurrent plausibility networks allow arbitrary number context hidden layers considering long
distance dependencies. However, many network modules screen attempted
keep individual networks simple homogeneous. Therefore, first version
described used variations feedforward networks (Rumelhart et al., 1986)
simple recurrent networks (Elman, 1990). Due greater potential sequential
context representations, recurrent plausibility networks might provide improvements
optimizations simple recurrent networks. However, primarily interested
overall real-world hybrid connectionist architecture screen rather optimization single networks. following description give detailed examples
individual networks.

4.3 Detailed View

motivated various parts screen, give detailed description
architecture screen respect modules syntactic semantic
analysis word hypothesis sequences. Therefore, focus speech related parts,
categorization part correction part. Figure 7 shows detailed overview
parts. basic data ow shown arrows. Many modules generate hypotheses
used subsequent modules higher level. hypotheses illustrated
rising arrows. modules, output contains local predictive hypotheses (sometimes
called local top-down hypotheses) used modules lower level.
hypotheses illustrated falling arrows. Local predictive hypotheses used
correction part eliminate4 repaired utterance parts speech evaluation part
eliminate syntactically semantically implausible word hypothesis sequences.
4. means repaired utterance parts actually marked deleted.

49

fiWermter & Weber

SEGMENT-PARSER

DIA-ACT

frame

slots
dialog act
type
verb-form

...

case frame part 1

2

8

reject
utter
meinen
(mean)

4

3

dialog part
PHRASE-ERROR

2

2

3

3

BAS-SYN-EQ

BAS-SEM-EQ

2

2

2*13

2*20

correction part

LEX-START-EQ

LEX-WORD-EQ

8

5

WORD-ERROR


pause, interjection,
hesitation, unresolved
phonetic material?

INTERJECTION

1

...

PAUSE-ERROR

PAUSE

Dialog Lexicon

2

ABS-SYN-EQ
2

2

2*8

2*17

3

4

SEM-SPEECH-ERROR

2

PHRASE-START?

3

BAS-SYN-PRE

5
4

separates
SYN-SPEECH-ERROR

ABS-SEM-EQ

5

ABS-SYN-CAT

ABS-SEM-CAT

2

8

17

13

13

20

BAS-SEM-PRE

13

20

13

20

BAS-SYN-DIS

2

2

BAS-SEM-DIS

13

20

13

20

3

3
verb, pronoun
UTTER, NIL

speech evaluation part

Syntactic Lexicon
Semantic Lexicon

category part

1
CON-SEQU-HYPS
Kse ich meine

(rubbish mean)
constructed word hypotheses sequences:
Kse ich
Kse ich meine

(rubbish I)
(rubbish mean)

speech sequence construction part

Figure 7: detailed overview screen. abbreviations functionality
modules described text.
50

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

cases arrows would complex used numbers illustrate
data ow individual modules.
4.3.1 Speech sequence construction part

speech sequence construction part receives stream parallel word hypotheses
generates stream word hypothesis sequences within module con-sequ-hyps
bottom Figure 7. Based current word hypotheses many word hypothesis sequences
may possible. cases reduce number current word hypotheses, e.g.,
know time passed far specific word hypothesis sequence cannot
extended anymore time current word hypothesis. case
eliminate sequence since word hypothesis sequences could reach end
sentence candidates successful speech interpretation.
Furthermore, use speech plausibility values individual word hypothesis
determine speech plausibility word hypothesis sequence. using
best word hypothesis sequences reduce large space possible sequences.
generated stream word hypothesis sequences similar set partial N-best
representations generated pruned incrementally speech analysis rather
end speech analysis process.
4.3.2 Speech evaluation part

speech evaluation part computes plausibilities based syntactic semantic knowledge order evaluate word hypothesis sequences. part contains modules
detection speech-related errors. Currently, performance speech recognizers
spontaneously spoken speaker-independent speech general still far perfect.
Typically, many word hypotheses generated certain signal5 . Therefore, many hypothesized words produced speech recognizer incorrect speech confidence
value word hypothesis alone provide enough evidence finding desired
string signal. Therefore goal speech evaluation part provide preference
filtering unlikely word hypothesis sequences. syn-speech-error sem-speecherror two modules decide current word hypothesis syntactically
(semantically) plausible extension current word hypothesis sequence. syntactic
(semantic) plausibility based basic syntactic (semantic) category disambiguation
prediction.
summary, word hypothesis sequence acoustic confidence based
speech recognizer, syntactic confidence based syn-speech-error, semantic
confidence based sem-speech-error. three values integrated weighted
equally6 determine best word hypothesis sequences. way, two modules
5. HMM-speech recognizer used generating word hypotheses domain word accuracy
93% best match word graph desired transcript utterance.
recognizer particularly optimized task domain order able examine
robustness language level. unoptimized version task domain currently 72%
word accuracy.
6. integration speech, syntax, semantics confidence values provided better results
using one two three knowledge sources.

51

fiWermter & Weber

act evaluator speech recognizer well filter language processing
part.
statistical models speech recognition, bigram trigram models used language models filtering best possible hypotheses. used simple recurrent
networks since networks performed slightly better bigram trigram model
implemented comparison (Sauerland, 1996). Later Section 6.1
show detailed comparison simple recurrent networks n-gram models (for n
= 1,...,5). reason better performance internal representation simple
recurrent network restrict covered context fixed number two
three words potential learn required context needed.
output-layer
13 units
N

J

V



R

C

U







P



/

14*13 connections

context-layer

hidden-layer
14*14
conn.

input-layer

2*14 units

14 copy

13*14 connections

13 units
N

J

V



R

C

U







P



/

disambiguated representation "ich" ("I") BAS-SYN-DIS

Figure 8: Network architecture syntactic prediction speech evaluation part
(bas-syn-pre). abbreviations explained Table 1.
knowledge syntactic semantic plausibility provided prediction
networks (bas-syn-pre bas-sem-pre) speech evaluation part disambiguation networks (bas-syn-dis bas-sem-dis) categorization part. example, show network bas-syn-pre Figure 8. previous basic syntactic
category currently considered word hypothesis sequence input network.
example \ich" (\I") word hypothesis sequence \Kase ich meine" (\Rubbish
mean") found pronoun (U). Therefore, syntactic category representation
\ich" (\I") contains \1" pronoun (U) category. categories receive \0".
input network consists 13 units 13 categories. output
network size. unit vector represents plausibility
predicted basic syntax category last word current word hypothesis sequence.
plausibility unit representing desired basic syntactic category (found
bas-syn-dis) taken syntactic plausibility currently considered word hypothesis
sequence syn-speech-error. example \meine" (\mean") found verb
52

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

(V). Therefore plausibility verb (V) taken syntax plausibility (selection
marked box output-layer bas-syn-pre Figure 8).
summary, syntactic (semantic) plausibility word hypothesis sequence evaluated degree agreement disambiguated syntactic (semantic) category
current word predicted syntactic (semantic) category previous word.
Since decisions current state whole sequence made, preceding
context represented copying hidden layer current word context layer
next word based SRN network structure (Elman, 1990). connections
network n:m connections except connections hidden layer
context layer simply used copy store internal preceding state
context layer later processing next word comes in. general, speech
evaluation part provides ranking current word hypothesis sequences equally
weighted combination acoustic, syntactic, semantic plausibility.
4.3.3 Category part

module bas-syn-dis performs basic syntactic disambiguation (see Figure 9). Input
module sequence potentially ambiguous syntactic word representations, one
word utterance time. module disambiguates syntactic category
representation according syntactic possibilities previous context. output
preference disambiguated syntactic category. syntactic disambiguation task
learned simple recurrent network. Input output network ambiguous
disambiguated syntactic category representations. Figure 9 show example
input representation \meine" (\mean", \my") verb pronoun.
However, sequence \Ich meine" (\I mean"), \meine" verb therefore
network receives disambiguated verb category representation alone.
module bas-sem-dis similar module bas-syn-dis instead receiving
potentially ambiguous syntactic category input producing disambiguated syntactic
category output, module bas-sem-dis receives semantic category representation
lexicon provides disambiguated semantic category representation output.
semantic disambiguation learned simple recurrent network provides mapping ambiguous semantic word representation disambiguated semantic word
representation. modules bas-syn-dis bas-sem-dis provide disambiguation
subsequent tasks association abstract categories test category
equality word error detection possible.
module abs-syn-cat supplies mapping disambiguated basic syntactic
category representations abstract syntactic category representations (see Figure 10).
module provides abstract syntactic categorization realized simple
recurrent network. module important providing abstract interpretation
utterance preparing input detection phrase errors. Figure 10 shows
disambiguated basic syntactic representation \meine" (\mean") verb -
small preference pronoun - mapped verb group category higher
abstract syntactic category representation. Based number basic abstract
syntactic categories 13 input units basic syntactic categories 8 output
units abstract syntactic categories.
53

fiWermter & Weber

output-layer
13 units
N

J

V



R

C

U







P



/

14*13 connections

hidden-layer

context-layer
14*14
conn.

input-layer

2*14 units

14 copy

13*14 connections

13 units
N

J

V



R

C

U





P



/

ambiguous representation
"meine" (verb/pronoun)

syntactic lexicon
meine

Kse
(rubbish)



verb
pronoun

ich meine
(I) (mean)

current word hypotheses sequence

Figure 9: Network architecture basic syntactic disambiguation (bas-syn-dis).
abbreviations explained Table 1.
module abs-sem-cat parallel module abs-syn-cat uses basic semantic
category representations input abstract semantic category representations output.
Similar previous modules, used simple recurrent network learn
mapping represent sequential context. input network basic
semantic category representation word, output abstract category
preference.
described four networks provide basis fault-tolerant analysis
detection errors. Furthermore, module phrase-start distinguishing
abstract categories. task module indicate boundaries subsequent
abstract categories delimiter. use boundaries determine abstract
syntactic abstract semantic category phrase7 . Earlier experiments provided
support take abstract syntactic category first word phrase final
abstract syntactic category phrase, since phrase starts (e.g., prepositions) good
7. Figure 7 show uence phrase start delimiter abstract syntactic semantic
categorization dotted lines.

54

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

output-layer
8 units
NG

VG

PG

CG

AG MG

SG

IG

14*13 connections

hidden-layer

context-layer
14*14
conn.

input-layer

13*14 connections

2*14 units

14 copy

13 units
N
J
V

R
C
U

disambiguated representation "meine" (mean)





P



/

Figure 10: Network architecture abstract syntactic categorization (abs-syn-cat).
abbreviations explained Table 2.
indicators abstract syntactic categories (Wermter & Lochel, 1994). hand,
earlier experiments supported take abstract semantic category last word
phrase final abstract semantic category phrase, since phrase ends (e.g., nouns)
good indicators abstract semantic categories (Wermter & Peters, 1994). Furthermore, phrase start gives us opportunity distinguish two equal subsequent abstract
categories two phrases. instance, phrase \in Hamburg Monday"
know border exists first second prepositional
phrase.
4.3.4 Correction part

correction part contains modules detecting pauses, interjections, well repetitions repairs words phrases (see Figure 7). modules detecting pause
errors pause-error, pause interjection. modules pause interjection receive currently processed word detect potential occurrence pause
interjection, respectively. output modules input module pauseerror. soon pause interjection detected, word marked deleted
therefore virtually eliminated input stream8. elimination interjections
pauses desired - instance speech translation task - order provide inter8. Pauses interjections sometimes provide clues repairs (Nakatani & Hirschberg, 1993) although
currently use clues repair detection. Compared lexical, syntactic, semantic
equality constituents, interjections pauses provide relatively weak indicators repairs since
occur relatively often places sentence. However, since mark interjections
pauses deleted could make use knowledge future necessary.

55

fiWermter & Weber

pretation errors possible. Since three modules basically occurrence
tests realized symbolic representations.
second main cluster modules correction part modules
responsible detection word-related errors. Then, word repairs \Am sechsten
April bin ich ich" (\on sixth April I") \Wir haben ein Termin Treffen" (\We
date meeting") dealt with. certain preferences finding repetitions
repairs word level. Among preferences lexical equality two
subsequent words (symbolic module lex-word-eq), equality two basic syntactic
category representations (connectionist module bas-syn-eq), equality basic
semantic categories two words (connectionist module bas-sem-eq). example
three modules, show test syntactic equality (BAS-SYN-EQ) Figure 11.
output-layer
2 units
equal equal
5*2 connections

hidden-layer
5 units
input-layer

(2*13)*5 connections

N J V R C U P /

N J V R C U P /

2*13
units

disambiguated representation second "ich" (I)

disambiguated repr. first "ich" (I)

output-layer
2 units
equal equal
5*2 connections

hidden-layer
5 units
input-layer

(2*13)*5 connections

N J V R C U P /
disambiguated repr. "Termin" (date)

N J V R C U P /

2*13
units

disambiguated representation "Treffen" (meeting)

Figure 11: Network architecture equality basic syntactic category representation (bas-syn-eq). abbreviations explained Table 1.
56

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Two output units plausible/implausible outcome used since network two output units gave consistently better results compared network
one output unit (with 1 plausible 0 implausible). reason network two output units performed better separation weights plausible
implausible hidden-output layer. order receive single value, two output values integrated according formula: unit1 (1:0 , unit2 ). Then, output
three equality modules value 0 1 1 represents equality 0
represents inequality. Although single preference may sucient, common
uence provides reasonable basis detecting word repairs word repetitions
module word-error. Then, word repairs repetitions eliminated original
utterance. Since modules word-related errors based two representations two
subsequent input words since context play minor role, use feedforward
networks modules. hand, simple test lexical equality
two words lex-word-eq represented effectively using symbolic representation.
third main cluster correction part consists modules detection
correction phrase errors. example phrase error is: \Wir brauchen
den fruheren Termin den spateren Termin" (\We need earlier date later date").
preferences phrase errors lexical start two subsequent phrases
equal, abstract syntactic categories equal abstract semantic categories
equal. three preferences modules lex-start-eq, abs-syn-eq
abs-sem-eq. modules receive two input representations two corresponding
words two phrases, lex-start-eq receives two lexical words, abs-syn-eq two abstract
syntactic category representations, abs-sem-eq two abstract semantic category representations. output three modules value toward 1 equality toward
0 otherwise. values input module phrase-error finally decides
whether phrase replaced another phrase. lexical equality two words
discrete test, implemented lex-start-eq symbolically, preferences
phrase error implemented feedforward networks.

5. Detailed Analysis Examples

section detailed look processing output speech recognizer
producing syntactic semantic interpretation concurrent word hypothesis
sequences (also called sentence hypothesis here).

5.1 Overall Environment

overall processing incremental left right, time multiple sentence
hypotheses processed parallel. Figure 12 shows snapshot screen 0.95s
utterance. time snapshot shows first three sentence hypotheses
German words together (literal) English translations (\Rubbish mean", \Rubbish I", \Rubbish had"). screen environment allows user view inspect
incremental generation word hypothesis sequences (partial sentence hypotheses)
preferred syntactic semantic categories basic abstract level.
sentence hypothesis illustrated horizontally. certain time many sentence hypotheses
active parallel. ranked according descending plausibility
57

fiWermter & Weber

SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

line

Stop

Go

single step

1

3 Sentencehypotheses. Time: 0.95s (System)/0.95s (Display)

N



NG

SUG

NEG CONF

Kse (rubbish)

N



0

NG

SUG

NEG CONF

Kse (rubbish)

N



NG

SUG

NEG CONF

Kse (rubbish)

U

NG

SUG

ANIM AGENT CONF

ich (I)

V

NIL

SUG

UTTER NIL

CONF

meine (mean)

U

NIL

SUG

ANIM

NIL

CONF

NG

SUG

ich (I)

U

ANIM AGENT CONF

ich (I)

V

NIL

SUG



NIL

CONF

htte (had)

0

0.0000 0.0000 0.9799 0.0000 0.0038 0.0004 0.1653 0.0048 0.0001 0.0003 0.0001 0.0017 0.0001
N
J
V

R
C
U



P

/

Figure 12: First snapshot sentence \Kase ich meine naturlich Marz (\Rubbish mean
course March"). abbreviations explained Table 1 4. Below,
second pop-up window illustrates full preferences word \meine"
(\mean") basic syntactic categories.
sentence hypotheses. snapshot Figure 12 currently three sentence
hypotheses preferred current sentence hypothesis consists \Rubbish mean".
sentence hypotheses syntactically semantically plausible starts.
underlying variations introduced speech recognizer produced different word
hypotheses slightly overlapping signal parts sentence. Besides speech plausibility, syntax semantics help choosing better sentence hypotheses. Currently
combine speech recognition plausibility, syntactic plausibility, semantic
plausibility compute plausibility sentence hypotheses multiplication
respective normalized plausibility values 0 1. Since speech recognizer
contain syntactic semantic knowledge, sequence hypothesis rated plausible based
speech knowledge alone may neglect potential syntactic semantic regularity.
58

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

using corresponding syntactic semantic plausibility values sentence hypothesis
integrate acoustic, syntactic, semantic knowledge.
word hypothesis shown preferred basic syntactic hypothesis (upper left
square word hypothesis), preferred abstract syntactic hypothesis (upper middle
square), preferred basic semantic hypothesis (lower left square), preferred abstract
semantic hypothesis (lower middle square), preferred dialog act (upper right square)9,
integrated acoustic, syntactic semantic confidence partial sentence hypothesis point (lower right square). size square illustrates strength
hypothesis, full black square means preferred hypothesis close one.
instance, word hypothesis \ich" (\I") first sentence hypothesis
hypothesis pronoun (U) basic syntactic category, noun group (NG)
abstract syntactic category, animate object (ANIM) basic semantic category,
AGENT abstract semantic category, suggestion (SUG) dialog act. Furthermore, length vertical bar word hypotheses indicate plausibility
new phrase start.
another example, see representation example word \meine" (could
verb \mean" pronoun \my" German) used throughout
network descriptions (see Figure 9). network correct preference \meine"
verb (V). Figure 12 shows preference well zoomed illustration
less favored preferences second pop-up window below. see, ambiguous pronoun preference U received second strongest activation
preferences close 0. shown activation preferences output values
corresponding network basic syntactic categorization. shown activation value
snapshots shows preferred hypothesis hypotheses
shown request10.
Within display scroll descending ascending sentence
hypotheses. Furthermore scroll left right analyzing specific longer word
hypothesis sequences. step mode allows screen system wait
interactive mouse click process next incoming word hypothesis
detailed analysis. step mode adapted different number steps (word
hypotheses) switched completely one decides analyze sentence
hypotheses later end word hypotheses. preferred possible
syntactic semantic hypotheses shown. Therefore many different hypotheses appear
size. However, clicking one squares less confident
hypotheses displayed well.
9. dialog acts use are: accept (ACC), query (QUERY), reject (REJ), request-suggest (RE-S),
request-state (RE-S), state (STATE), suggest (SUG), miscellaneous (MISC). Since paper focuses
syntactic semantic aspects screen elaborate implemented dialog
part here. details dialog act processing described previously (Wermter & Lochel,
1996).
10. snapshots Figure 12 abstract syntactic semantic categories yet computed
therefore represented NIL. next processing step computation performed
seen next Figure 13.

59

fiWermter & Weber

5.2 Analyzing Final Snapshot Short Sentence Hypotheses

Figure 13 illustrate final state 3.01s utterance. Eight possible sentence hypotheses remained see first four Figure 13. Starting
fourth sentence hypothesis \Kase ich hatte ich Marz" (\Rubbish march")
see lower rated sentence hypothesis desired sentence. lower ranked
hypotheses good examples current state-of-the-art speech recognizers alone
able produce reliable sentence hypotheses, since problem analyzing spontaneous
speaker-independent speech complex. Therefore syntactic semantic components spontaneous language take account highly irregular
sequences shown below. However, interesting observe underlying connectionist networks always produce preference syntactic semantic interpretation
abstract basic level. fact, although lower ranked sentence hypotheses
constitute desired sentence assigned syntactic semantic categories
correct individual word hypotheses. course may cases network
could make wrong decision uncertain word hypotheses. However syntactic
semantic processing never break possible sentence hypothesis,
respect different well-known methods symbolic context-free chart parsers.
look top-ranked sentence hypothesis \Kase ich meine naturlich Marz" (\Rubbish mean course March") desired sentence. plausible
SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

Go

line

Stop

single step

1

8 Sentencehypotheses. Time: 3.01s (System)/3.01s (Display)

N

NG DSUG



NEG CONF

KSE

0

NG DSUG

ANIM AGENT CONF

ICH

N

NG DSUG



NEG CONF

KSE

U

NG DSUG

NG DSUG

ANIM AGENT CONF



NEG CONF

KSE

U

NG DSUG

NG DSUG

ANIM AGENT CONF



NEG CONF

U

UTTER ACT

CONF

V

VG DSUG

UTTER ACT

V



NG DSUG

V



HTTE



SG DSUG

NILL

MISC CONF

NATRLICH

CONF



SG DSUG

NILL

MISC CONF

NATRLICH

VG DSUG

ACT

CONF

HTTE

ANIM AGENT CONF

ICH

VG DSUG

MEINE

ICH

N

V

MEINE

ICH

N

KSE

U

U

NG DSUG

ANIM AGENT CONF

ICH

VG DSUG

ACT

CONF

U

N

NG DSUG

TIME TMAT CONF

MRZ

N

NG DSUG

TIME TMAT CONF

MRZ

N

NG DSUG

TIME TMAT CONF

MRZ

NG DSUG

ANIM AGENT CONF

ICH

N

NG DSUG

TIME TMAT CONF

MRZ
0

Figure 13: Final snapshot sentence \Kase ich meine naturlich Marz (\Rubbish mean
course March").
60

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

sentence based speech language plausibility. Furthermore, see assigned categories correct: German word \Kase" (\Rubbish") found noun
part noun group expresses negation. \Ich" (\I") starts new phrase,
pronoun noun group represents animate agent. following
German word \meine" particularly interesting since used verb sense
\mean" pronoun sense \my". Therefore, connectionist network
basic syntactic classification disambiguate two possibilities based
preceding context. network learned take consideration preceding
context able choose correct basic syntactic category verb (V) rather
pronoun (U) word \meine" (\mean"). time new phrase start
found well. following word \naturlich" (\of course") highest preference
adverb special group. Finally, word \Marz" (\March") assigned highest
plausibility noun noun group well time something happens.

5.3 Phrase Starts Phrase Groups Longer Sentence Hypotheses

focus detailed analysis second example: \A hm ja genau allerdings
habe ich da von neun bis vier Uhr schon einen Arzttermin". literally translated
SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

Go

line

Stop

single step

1

10 Sentencehypotheses. Time: 2.18s (System)/2.18s (Display)



YES

MG DACC

CONF CONF

JA

YES

MG DACC

CONF CONF

JA

DREJ

CONF CONF

J

YES

YES

MG DACC

CONF CONF

JA



NILL

MG

DREJ

CONF CONF

YES

MG DACC

CONF CONF



NILL



SG

DREJ

NEG CONF





SG

DREJ

NEG CONF

ALLERDINGS

MG DMISC

MISC CONF

DENNOCH





ALLERDINGS

GENAU



JA

YES

MG

GENAU



0

J

MG DMISC

MISC CONF

DENNOCH





SG DMISC

NEG CONF

ALLERDINGS





SG DMISC

NEG CONF

ALLERDINGS

V

VG

DREJ



ACT

CONF

HABE

VG

DREJ



ACT

CONF

HABE

U

NILL

ACT

CONF



NG

DREJ

MISC CONF

ACT

CONF

ANIM AGENT CONF

U

NILL

ES

DREJ

MISC CONF

NILL

SG

DREJ

MISC CONF

NILL

SG DMISC

MISC CONF

DA

MISC CONF

DREJ

TMAT CONF

R

PG

DREJ

TMAT CONF

R



NIL DMISC

NIL

CONF

VON



NILL

DA

PG

VON



NG DMISC

R

VON



NG DMISC

ICH

HABE

NILL

SG

DA

U

VG DMISC



DA

ES

HABE

V

DREJ

ANIM AGENT CONF

VG DMISC



NG

ICH

V

V

U

SG DMISC

MISC CONF

R



NIL DACC

NIL

CONF

VON

0

Figure 14: First part snapshot sentence \A hm ja genau allerdings habe ich
da von neun bis vier Uhr schon einen Arzttermin" (literal translation: \Yes
exactly however nine four o'clock already doctorappointment"; improved translation: \Eh yes exactly however
doctor appointment nine four o'clock").
61

fiWermter & Weber

SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

line

Stop

Go

single step

1

10 Sentencehypotheses. Time: 4.45s (System)/4.45s (Display)



PG

MISC

TIME TMAT CONF

neun (nine)



PG

MISC

neun (nine)



PG

MISC

TIME TMAT CONF

PG

MISC CONF

R

NIL

R

NIL

ACC

R

NIL

bis (to)



PG

MISC

TIME TMAT CONF

vier (four)

PG

MISC

MISC CONF



PG

PG

MISC

MISC

TIME TMAT CONF

MISC CONF



PG

MISC

MISC

TIME TMAT CONF

MISC CONF



PG

MISC

TIME TMAT CONF

N

PG

MISC

TIME TMAT CONF

N

PG

MISC

TIME TMAT CONF

Uhr (oclock)

MISC

TIME TMAT CONF

zehn (ten)

PG

Uhr (oclock)

zehn (ten)

PG

N

Uhr (oclock)

vier (four)

bis (to)

TIME TMAT CONF

neun (nine)

MISC

bis (to)

neun (nine)



NIL

PG

bis (to)

TIME TMAT CONF

0

R

N

PG

ACC

TIME TMAT CONF

Uhr (oclock)



NIL

SG

MISC

MISC CONF

schon (already)



NIL

SG

MISC

MISC CONF

schon (already)



NIL

SG

MISC

MISC CONF

schon (already)



NIL

SG

ACC

MISC CONF

schon (already)



NIL

NG

RES

MISC CONF

einen (a)



NIL

NG

RES

MISC CONF

NIL

NG

RES

MISC CONF

NIL

NG

ABS

OBJ

CONF

N

NG

RES

ABS

OBJ

CONF

N

NG

RES

ABS

OBJ

CONF

Arzttermin(doc.app

RES

MISC CONF

einen (a)

RES

Arzttermin(doc.app

einen (a)



NG

Arzttermin(doc.app

einen (a)



N

N

NG

RES

ABS

OBJ

CONF

Arzttermin(doc.app

7

Figure 15: Second part snapshot sentence \A hm ja genau allerdings habe ich
da von neun bis vier Uhr schon einen Arzttermin" (\Yes exactly however
nine four o'clock already doctor-appointment").
sentence analyzed is: \Eh yes exactly however nine four o'clock
already doctor-appointment". better non-literal translation would be: \Eh yes
exactly however doctor appointment nine four o'clock".
analysis first sentence hypotheses, interjection \ahm" (\eh") detected
corresponding module correction part eliminated respective
sentence hypotheses.
Figure 14 Figure 15 show best found four sentence hypotheses.
categories sentence hypotheses look similar keep separate
hypotheses since differ time stamps speech confidence values.
two snapshots longer example illustrate uence
phrase starts. sequences \von neun" (\from nine") \bis vier Uhr" (\to four
o'clock") constitute two phrase groups clearly separated black bar
prepositions \von" (\from") \bis" (\to"). words \neun" (\nine"),
\vier" (\four"), \Uhr" (\o'clock") start another phrase group. Since underlying connectionist network learning phrase boundaries simple recurrent network
example demonstrates network learned preceding context. Without
learned preposition \von" (\from") \bis" (\to") noun
62

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

\Uhr" (\o'clock") within prepositional phrase group could
part noun phrase another context \vier Uhr pat gut" (\four o'clock fits
well").

5.4 Dealing Noise Repairs
Finally focus example simple word graph shown beginning
paper page 41: \A hm sechsten April bin ich leider auer Hause". literal
translation \Eh 6th April unfortunately home". Using sentence
give example interjection simple word repair. Dealing hesitations
repairs large area spontaneous language processing main topic
paper (a detailed discussion repairs screen found previous work,
Weber & Wermter, 1996). Nevertheless, sake illustration completeness
show ability screen deal interjections word repairs. first snapshot
Figure 16 shows start example sentence 1.39s. leading interjection
\eh" eliminated already.
Furthermore, see second word hypothesis sequence shows two subsequent
word hypotheses \ich" (\I"). possible since two word hypotheses
SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

Go

line

Stop

single step

1

18 Sentencehypotheses. Time: 1.39s (System)/1.39s (Display)

R

PG

SUG

TMAT CONF

(on)

R

PG

SUG

(on)

R

PG

SUG

TMAT CONF

TIME TMAT CONF



PG

SUG

TIME TMAT CONF



PG

SUG

TIME TMAT CONF

sechsten (6th)

PG

SUG

TMAT CONF

(on)

SUG

sechsten (6th)

(on)

R

PG

sechsten (6th)

TMAT CONF

0





PG

SUG

TIME TMAT CONF

sechsten (6th)

N

PG

SUG

TIME TMAT CONF

April (April)

N

PG

SUG

TIME TMAT CONF

PG

SUG

TIME TMAT CONF

PG



ACT

CONF

V

VG

SUG



ACT

CONF

U

PG

SUG

U

NG

STATE

ANIM AGENT CONF

ich (I)

U

NIL

STATE

ANIM

NIL

CONF

U

NIL

STATE

ANIM

NIL

CONF

ich (I)

U

NIL

SUG

ANIM

NIL

CONF

U

NIL

SUG

ANIM

NIL

CONF

NG

STATE

ich (I)

SUG

ANIM RECIP CONF

ich (I)

TIME TMAT CONF

April (April)

STATE

htte (had)

April (April)

N

VG

bin (am)

April (April)

N

V

ich (I)

V

VG

STATE



ACT

CONF

bin (am)

U

ANIM AGENT CONF

ich (I)

ich (I)

0

Figure 16: First snapshot sentence \A hm sechsten April bin ich leider auer
Hause" (\Eh 6th April unfortunately home").
63

fiWermter & Weber

generated speech recognizer could connected. case
four word hypotheses shown below:
start time
1.22s
1.23s
1.23s
1.31s

end time
1.37s
1.30s
1.37s
1.38s

word hypothesis
ich (I)
ich (I)
ich (I)
ich (I)

speech plausibility
1.527688e-03
1.178415e-02
2.463924e-03
1.813340e-02

using speech knowledge word hypotheses, possible connect
second hypothesis runs 1.23s 1.30s fourth hypothesis runs
1.31s 1.38s. example noise generated speech recognizer, since
desired sentence contains one word \ich" (\I") sentence hypothesis
point contains two. repetition treated eliminated way actual
word repairs language. reasons occurrence repairs different
effect repeated word same. Therefore, case repeated \ich" (\I")
eliminated sentence sequence. Figure 17 show final snapshot
sentence. see word repairs occur top-ranked sentence hypothesis
desired sentence.
SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

line

Stop

Go

single step

1

10 Sentencehypotheses. Time: 3.40s (System)/3.40s (Display)



PG

SUG

TIME TMAT CONF

sechsten (6th)



PG

SUG

TIME TMAT CONF

0

sechsten (6th)



PG

SUG

TIME TMAT CONF

sechsten (6th)



PG

SUG

TIME TMAT CONF

sechsten (6th)

N

PG

SUG

TIME TMAT CONF

April (April)

N

PG

SUG

TIME TMAT CONF

PG

SUG

TIME TMAT CONF

PG



ACT

CONF

U

PG

SUG

U

NG

STATE

ANIM AGENT CONF

ich (I)

SUG

ANIM RECIP CONF

U

V

VG

STATE

NG

SUG

ANIM RECIP CONF



ACT

CONF

VG

STATE

NG

STATE

ANIM AGENT CONF



ACT

CONF

U



SG

REJ

NEG CONF





SG

REJ

NEG CONF

leider (unfort.)

ich (I)

V

bin (am)

U



leider (unfort.)

ich (I)

bin (am)

TIME TMAT CONF

April (April)

STATE

ich (I)

April (April)

N

VG

bin (am)

April (April)

N

V





SG

REJ

NEG CONF

leider (unfort.)

NG

STATE

ANIM AGENT CONF

ich (I)





SG

REJ

NEG CONF

leider (unfort.)

R

PG

REJ

LCAT CONF

auer (out of)

R

PG

REJ

LCAT CONF

auer (out of)

R

PG

REJ

LCAT CONF

auer (out of)

R

PG

REJ

LCAT CONF

auer (out of)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

1

Figure 17: Final snapshot sentence \A hm sechsten April bin ich leider auer
Hause" (\Eh 6th April unfortunately home").
64

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

general, language repairs, screen deal elimination interjections
pauses, repair word repetitions, word corrections (where words may
different, categories same) well simple forms phrase repairs (where
phrase repeated replaced another phrase).

6. Design Analysis SCREEN
section describe design choices screen. particular focus
issues use connectionist networks, reach high accuracy little training,
screen compared systems design principles.

6.1 Use Connectionist Networks SCREEN?
past, n-gram based techniques used successfully tasks syntactic
category prediction part speech tagging. Therefore, possible ask developed simple recurrent networks screen. subsection provide detailed
comparison simple recurrent networks n-gram techniques prediction basic
syntactic categories. chose task detailed comparison since currently
dicult task simple recurrent network screen. purposefully
choose subtask simple recurrent network high accuracy,
prediction task since dicult predict category compared disambiguating among categories, instance. chose dicult prediction relatively
low network performance order (extremely) fair comparison n-gram
techniques.
primarily interested generalization behavior new unknown input.
Therefore Figure 18 shows accuracy syntactic prediction unknown test
set. word several different syntactic categories follow syntactic
categories excluded. instance, determiner \the" adjective noun
follow: \the short ...", \the appointment", determiner \the" preposition
implausible occur probably excluded. Therefore important
know many categories ruled Figure 18 shows relationship
prediction accuracy number excluded categories n-grams simple
recurrent network (as described Figure 8).
expect, techniques, n-grams recurrent networks, prediction
accuracy higher categories excluded performance lower
many categories excluded. However, interestingly, see simple
recurrent networks performed better 1-grams, 2-grams, 3-grams, 4-grams 5-grams.
Furthermore, interesting note higher n-grams necessarily lead better
performance. instance, 4-grams 5-grams perform worse 2-grams since
would probably need much larger training sets.
comparison n-grams (1-5) simple recurrent networks
semantic prediction received result simple recurrent networks performed
better n-grams. performance best n-gram often slightly worse
performance simple recurrent network, indicates n-grams
reasonably useful technique. However, comparisons simple recurrent networks per65

fiWermter & Weber

Testset
100

correct prediction %

80

60

40

SRN
1gram
2gram
3gram
4gram
5gram

20

0
0

2

4

6

8

10

12

number excluded categories

Figure 18: Comparison simple recurrent network n-grams
formed least slightly better best n-grams. Therefore, used simple recurrent
networks primary technique connectionist sequence learning screen.
explain result? N-grams 2-grams still perform reasonably well
task simple recurrent networks closest performance. However,
simple recurrent networks perform slightly better since contain fixed
limited context. many sequences, simple recurrent network may primarily use
directly preceding word representation make prediction. However, exceptions
context required recurrent network memory internal reduced
representation preceding context. Therefore, potential exible
respect context size.
N-grams may perform optimally extremely fast. question arises
much time necessary compute new category using new input current
context network. general networks differ slightly size typically
contain several hundred weights. typical representative simple recurrent network
13 input units, 14 hidden units, 8 output units, 14 context units, 500 weights
takes 10,4 Sparc Ultra compute new category within whole forward sweep.
66

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Since techniques smoothed n-grams basically rely ecient table-look-up
precomputed values, course typical n-gram techniques still faster. However, due
fixed-size context may perform well simple recurrent networks. Furthermore, computing next possible categories 10,4s fast enough current version
screen. sake explanation one could argue screen contains 10
networks modules typical utterance contains 10 words, single utterance hypothesis could performed 10,2 s. However, different text tagging, single
sentences process word graphs. Depending specific utterance, 105 word
hypothesis sequences could generated processed. Furthermore
book-keeping required keeping best word hypotheses, loading appropriate networks appropriate word hypotheses, etc. potentially large number
word hypotheses, additional book-keeping performance, number individual
modules syntax, semantics dialog processing explain total analysis time
whole unoptimized screen system order seconds although single recurrent
network performs order 10,4 s.

6.2 Improvement Hypothesis Space
subsection analyze extent syntactic semantic prediction
knowledge used improve best found sentence hypotheses. illustrate
pruning performance hypothesis space integrating acoustic, syntactic, semantic knowledge. speech recognizer alone provides acoustic confidence
values, screen adds syntactic semantic knowledge. knowledge sources
weighted equally order compute single plausibility value current word hypothesis sequence. plausibility value used speech construction part prune
hypothesis space select currently best word hypothesis sequences. Several
word hypothesis sequences processed incremental parallel. given time
11
n best incremental word hypothesis sequences kept .
syntactic semantic plausibility values based basic syntactic semantic prediction (bas-syn-pre bas-sem-pre) next possible categories
word selection preference determined basic syntactic respectively semantic category (bas-syn-dis bas-sem-dis)12 . performance disambiguation
modules 86%-89% test set. prediction modules performance 72%
81% semantic syntactic test set, respectively want exclude least
8 12 possible categories. performance allows us computation syntactic
semantic plausibility syn-speech-error sem-speech-error. Based
combined acoustic, syntactic, semantic knowledge, first tests 184 turns show
accuracy constructed sentence hypotheses screen could increased
30% using acoustic syntactic plausibilities 50% using acoustic,
syntactic, semantic plausibilities (Wermter & Weber, 1996a).
11. experiments low values (n = 10) provided best overall performance.
12. explained detail Section 4.3.2

67

fiWermter & Weber

6.3 SCREEN's Network Performance Networks Yield High
Accuracy Little Training

evaluating performance screen's categorization part meeting corpus
first show percentages correctly classified words important networks
categorization: bas-syn-dis, bas-sem-dis, abs-syn-cat, abs-sem-cat, phrase-start.
184 turns corpus 314 utterances 2355 words. 1/3 2355
words 184 turns used training, 2/3 testing. Usually data used
training testing. preliminary earlier experiments used 2/3 training
1/3 testing. However, performance unknown test set similar 1/3
training set 2/3 test set. Therefore, used testing training data since
interested generalization performance unknown instances test
set compared training performance known instances.
first sight, might seem relatively little data training. statistical techniques
information retrieval techniques often work large texts individual lexical word
items, need much less material get reasonable performance since work
syntactic semantic representations rather words. would stress
use syntactic semantic category representations 2355 words training
testing rather lexical words themselves. Therefore, category representation
requires much less training data lexical word representation would required.
side effect, training time reduced 1/3 training set, keeping
performance 2/3 test set. is, training used category representations
64 dialog turns, testing generalization category representations remaining
120 dialog turns.
Table 5 shows test results individual networks unknown test set.
networks trained 3000 epochs learning rate 0.001 14 hidden units.
configuration provided best performance network architectures.
general tested network architectures 7 28 hidden units, learning parameters
0.1 0.0001. learning rule used generalized delta rule (Rumelhart et al.,
1986). assigned output category representation word counted correct
category maximum activation desired category.
Module

Accuracy test set
bas-syn-dis
89%
bas-sem-dis
86%
abs-syn-cat
84%
abs-sem-cat
83%
phrase-start
90%
word-error
94%
phrase-error
98%

Table 5: Performance individual networks test set meeting corpus
performance basic syntactic disambiguation 89% unknown test
set. Current syntactic (text-)taggers reach 95% accuracy texts. However,
68

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

big difference text speech parsing due spontaneous noise
spoken language. interjections, pauses, repetitions, repairs, new starts
\ungrammatical" syntactic varieties spoken-language domain reasons
typical accuracy syntactic text taggers reached.
hand see 86% accuracy basic semantic disambiguation
relatively high semantics. evidence noisy \ungrammatical"
variety spoken language hurts syntax less semantics. Due domain dependence
semantic classifications dicult compare explain semantic performance.
However, different study within domain railway interactions could reach
similar performance (for details see Section 6.6). experiments syntactic results
better semantic results, indicating syntactic classification easier
learn generalize. Furthermore, syntactic results close 90% noisy
spoken language consider good comparison 95% regular
text language.
performance abstract categories somewhat lower basic categories since evaluation word introduces unavoidable errors. instance,
\in" network cannot yet know time location follow, make
early decision already. general, networks perform relatively well dicult
real-world corpus, given eliminate sentence reason took
spontaneous sentences spoken.
Furthermore, use transcripts spontaneous language training domain
meeting arrangements. utterances questions answers dates
locations. restricts potential syntactic semantic constructions, certainly
benefit restricted domain. Furthermore, mappings ambiguous
learning (e.g., noun part noun group prepositional group) mappings
relatively unambiguous (e.g., verb part verb group). would expect
performance mixed arbitrary domains random spoken sentences
various topics passers-by city. However, performance somewhat
restricted domains learned promising manner (for transfer different
domain see Section 6.6). evidence simple recurrent networks
provide good performance using small training data restricted domain.

6.4 SCREEN's Overall Output Performance
described individual network performance, focus
performance running system. performance running screen system
different performance individual networks number reasons. First,
individual networks trained separately order support modular architecture.
running screen system, however, connectionist networks receive input
underlying networks. Therefore, actual input connectionist network
running screen system may differ original training test sets. Second,
spoken sentences may contain errors interjections word repairs. part
individual network training, running screen system able detect
correct certain interjections, word corrections phrase corrections. Therefore, system
network performance differ dis uencies. Third, want evaluate
69

fiWermter & Weber

performance abstract semantic categorization abstract syntactic categorization
particularly interested certain sentence parts. abstract syntactic categorization,
e.g., detection prepositional phrase, consider beginning
phrase significant function word, e.g., preposition, important
location syntactic categorization. contrast, abstract semantic categorization,
content word end phrase group, directly next phrase start,
important.
Correct syntactic output representation 74%
Correct semantic output representation 72%

Table 6: Overall syntactic semantic accuracy running screen system
unknown test set meeting corpus
expect based explanation previous paragraph, overall accuracy output complete running system lower performance
individual modules. fact, true Table 6 shows overall syntactic
semantic phrase accuracy running screen system. 74% assigned syntactic
phrase representations unknown test set correct 72% assigned semantic
phrase representations. slight performance drop partially explained
uncertain input underlying networks uenced
networks. hand, cases various decisions different modules (e.g.
three modules lexical, syntactic semantic category equality two words)
combined order clean errors (e.g. wrong decision one single module).
general, given 120 dialog turns test set completely unrestricted, unknown real-world spontaneous language turns, believe overall performance
quite promising.

6.5 SCREEN's Overall Performance Incomplete Lexicon

One important property screen robustness. Therefore, interesting question
screen would behave could receive incomplete input lexicon.
situations realistic since speakers could use new words speech recognizer
seen before. Furthermore, test robustness techniques. standard
context-free parsers usually cannot provide analysis words missing lexicon,
screen would break missing input representations, although course
expect overall classification performance must drop less reliable input provided.
order test situation controlled uence removing items
lexicon, first tested scenario randomly eliminated 5% syntactic
semantic lexicon representations. word unknown, screen used single syntactic
single semantic average default vector instead. average default vector contained
normalized frequency syntactic respectively semantic category across lexicon.
Even without 5% lexicon entries utterances could still analyzed. screen
break missing word representations attempts provide analysis good
70

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Correct syntactic output representation 72%
Correct semantic output representation 67%

Table 7: Overall syntactic semantic accuracy running screen system
meeting corpus unknown test set 5% lexicon entries eliminated
possible. expected, Table 7 shows performance drop overall syntactic
semantic accuracy. However, compared 74% 72% performance complete
lexicon (see Table 6) still find 72% syntactic output representations 67%
semantic output representations correct eliminating 5% lexicon entries.
Correct syntactic output representation 70%
Correct semantic output representation 67%

Table 8: Overall syntactic semantic accuracy running screen system
meeting corpus unknown test set 10% lexicon entries
eliminated
another experiment eliminated 10% syntactic semantic lexicon entries.
case, syntactic accuracy still 70% semantic accuracy 67%.
Eliminating 10% lexicon led syntactic accuracy reduction 4% (74%
versus 70%) semantic accuracy reduction 5% (72% versus 67%). general
see experiments percentage accuracy reduction much less
percentage eliminated lexicon entries demonstrating screen's robustness working
incomplete lexicon.

6.6 Comparison Results New Different Domain

order compare performance techniques, show results
experiments different spoken Regensburg Train Corpus. intention cannot
describe experiments domain level detail done
Blaubeuren Meeting Corpus paper. However, provide summary order
provide point reference comparison experiments meeting corpus.
comparison serves another additional possibility judge results meeting
corpus.
different domain chose 176 dialog turns railway counter. People ask
questions receive answers train connections. typical utterance is: \Yes need
eh sleeping car PAUSE PAUSE Regensburg Hamburg". used exactly
screen communication architecture process spoken utterances domain:
architecture used, 1/3 dialog turns used training, 2/3
71

fiWermter & Weber

testing unseen unknown utterances. syntactic processing, even used exactly
network structure, since expect much syntactic differences
two domains. semantic processing retrained semantic networks. Different
categories used semantic classification, particular actions. actions
meetings (e.g., visit, meet) predominant meeting corpus, actions
selecting connections (e.g., choose, select) important train corpus (Wermter &
Weber, 1996b). give reader impression portability screen,
would estimate 90% original human effort (system architecture, networks) could
used new domain. remaining 10% needed necessary new
semantic tagging training new domain.
Module

Accuracy test set
bas-syn-dis
93%
bas-sem-dis
84%
abs-syn-cat
85%
abs-sem-cat
77%
phrase-start
89%
word-error
94%
phrase-error
98%

Table 9: Performance individual networks test set train corpus
Table 9 shows performance test set train corpus. compare
results meeting corpus (Table 5) results train corpus see
particular abstract syntactic processing almost meeting corpus
(84% Table 5 compared 85% Table 9) abstract semantic processing better
meeting corpus (83% Table 5 compared 77% Table 9). modules dealing
explicit robustness repairs (phrase start, word repair errors, phrase repair errors)
show almost performance (90% vs 89%, 94% vs 94%, 98% vs 98%).
Correct syntactic output representation 76%
Correct semantic output representation 64%

Table 10: Overall syntactic semantic accuracy running screen system
unknown test set different train corpus
comparison summarize overall performance different train
domain. Table 10 shows screen syntactic performance two
domains (compare Table 6). different domain essentially confirm
previous results syntactic processing performance (74% vs. 76%). However, semantic
processing appears harder train domain since performance 64% lower
72% meeting domain. However, semantic processing, semantic tagging
semantic classification often found much harder syntactic processing general,
72

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

difference still within range usual performance differences syntax
semantics. Since semantic categories agents, locations, time expressions
two domains dicult action categorization mainly responsible
difference semantic performance two domains.
general transfer one domain another requires limited amount
hand-modeling. course, syntactic semantic categories specified
lexicon transcripts. syntactically semantically tagged transcript sentences
direct basis generating training sets networks. Generating
trainings sets main manual effort transferring system new domain.
generation training sets performed training networks
proceed automatically. training typical single recurrent network takes
order hours. much less manual work required transferring standard
symbolic parser new domain generating new syntactic semantic grammar.

6.7 Illustrative Comparison Argument Based Symbolic Parser
made point screen's learned representations robust
hand-coded deeply structured representations. would elaborate point
compelling illustrative argument. Consider different variations sentence hypotheses
speech recognizer Figure 19: 1. correct sentence hypothesis: \Am sechsten
April bin ich auer Hause" (\On 6th April home") 2. partially incorrect
1.Input: SECHSTEN APRIL BIN ICH AUER HAUSE
(ON 6th APRIL HOME)
1.Output:

PP

,!
VP

NP

NP

NG

NG

R

PP

V

NP

ADJG
N

U

ADJ
am(on)

sechsten(6th)April(April)

R

NG
N

bin(am)

2.Input: SECHSTEN APRIL ICH ICH AUER HAUS
(ON 6th APRIL HOME)
2.Output:NIL (NO ANALYSIS POSSIBLE)

ich(I)

auer(out_of) Hause(home)

,!

Figure 19: Two sentence hypotheses speech recognizer. first hypothesis
analyzed, second partially incorrect hypothesis cannot analyzed
anymore symbolic parser.
73

fiWermter & Weber

sentence hypothesis: \Am sechsten April ich ich auer Hause" (\On 6th April
home"). Focusing syntactic analysis, used existing chart parser existing
grammar used extensively real-world parsing sentence
level (Wermter, 1995). necessary significant adaptation addition rule
N G ! U pronouns, part original grammar. rule states
pronoun U (e.g., \I") noun group (NG).
run first sentence hypothesis symbolic context-free parser receive desired syntactic analysis shown Figure 19, run second slightly
incorrect sentence hypothesis parser receive analysis (The syntactic category abbreviations Figure 19 used manner throughout
paper (see Table 1-4); furthermore usual, \S" stands sentence, \ADJG" adjective group, \NP" complex nominal phrase, \VP" verb phrase. literal English
translations shown brackets).
reason second sentence hypothesis could parsed context-free
chart parser speech recognizer generated incorrect output. verb
second sentence hypothesis additional pronoun \I". mistakes
occur rather frequently based imperfectness current speech recognition technology.
course one could argue grammar relaxed made exible
deal mistakes. However, rules fault detection integrated
grammar parser complicated grammar parser. Even
important, impossible predict possible mistakes integrate symbolic
context-free grammar. Finally, relaxing grammar dealing mistakes using
explicit specific rules might lead additional mistakes grammar
extremely underspecified.
shown, instance Figure 17, screen problems dealing
speech recognizer variations mistakes. main difference standard
context-free symbolic chart parser analysis screen's analysis screen learned
provide analysis noisy conditions context-free parser handcoded provide structural analysis. emphasized
make argument structural representations per se general.
structure provided better, particularly tasks require structured
world knowledge. However, robustness major concern, lower syntactic
semantic spoken-language analysis, learned analysis provides robustness.

6.8 Comparisons Related Hybrid Systems
Recently, connectionist networks received lot attention computational learning
mechanisms written language processing (Reilly & Sharkey, 1992; Miikkulainen, 1993;
Feldman, 1993; Barnden & Holyoak, 1994; Wermter, 1995). paper however,
focused examination hybrid connectionist techniques spoken language processing. previous approaches speech/language processing processing often
sequential. is, one module speech recognizer syntactic analyzer completed work next module semantic analyzer started work. contrast,
screen works incrementally allows system (1) modules running par74

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

allel, (2) integrate knowledge sources early, (3) compute analysis
similar humans since humans start process sentences may completed.
compare approach related work systems. head-to-head comparison different system dicult based different computer environments
whether systems accessed adapted easily input. Furthermore,
different systems typically used different purposes different language corpora,
grammars, rules, etc. However, made extensive effort fair conceptual
comparison.
parsec (Jain, 1991) hybrid connectionist system embedded larger
speech translation effort janus (Waibel et al., 1992). input parsec sentences,
output case role representations. system consists several connectionist modules
associated symbolic transformation rules providing transformations suggested
connectionist networks. parsec's philosophy use connectionist networks
triggering symbolic transformations, screen uses connectionist networks transformations themselves. screen's philosophy use connectionist networks wherever
possible symbolic rules necessary.
found symbolic processing particularly useful simple known tests (like lexical
equality) complex control tasks whole system (when module communicate module). Much actual transformational work done
trained connectionist networks. contrast design philosophy parsec
connectionist modules provide control knowledge transformation
performed. selected transformation actually performed symbolic procedure. screen uses connectionist modules transformations symbolic control,
parsec uses connectionist modules control symbolic procedures transformations.
Different screen, parsec receives sentence hypotheses either sentence transcripts N-best hypotheses janus system. approach receives incremental
word hypotheses used speech construction part build sentence hypotheses. part used prune hypothesis space determine best sentence
hypotheses. analysis screen semantic syntactic plausibilities
partial sentence hypothesis still uence partial sentence hypotheses
processed.
parsec screen modular architecture tested advantage
connectionist module learn relatively easy subtask. contrast
development parsec experience modularity requires less training time.
Furthermore, modules screen able work independently
parallel. addition syntactic semantic knowledge, parsec make use
prosodic knowledge screen currently use prosodic hints. hand,
screen contains modules learning dialog act assignment modules
currently part parsec. Learning dialog act processing important determining
intended meaning utterance (Wermter & Lochel, 1996).
Recent extensions based parsec provide structure use annotated
linguistic features (Bu et al., 1994). authors state \implemented (based
parsec) connectionist system" approximate shift reduce parser.
connectionist shift-reduce parser substantially differs original parsec architecture.
75

fiWermter & Weber

refer \parsec extension". parsec extension labels complete
sentence first level categories. first level categories input
network order provide second level categories complete sentence
on, highest level sentence symbol added.
Using recursion step parsec extension provide deeper structural
interpretations screen currently does. However, recursion step construction structure price. First, labels NP noun phrase
defined lexical items lexicon. Second, important, complete utterance
labeled n-th level categories processing n+1-th level categories
starts. Therefore several parses (e.g., 7 utterance \his big brother loved himself")
utterance necessary. means recent parsec extension
powerful screen original parsec system Jain respect opportunity provide deeper structural interpretations. However, time
parsec extension looses possibility process utterances incremental manner.
However, incrementality important property spoken-language processing
screen. Besides fact humans process language incremental left-to-right
manner, allows screen prune search space incoming word hypotheses
early.
Comparing parsec screen, parsec aims supporting symbolic rules using symbolic transformations (triggered connectionist networks) integrating linguistic features. Currently, linguistic features recent parsec extension (Bu et al.,
1994) provide structural morphological knowledge screen does. Therefore,
currently appears easier integrate parsec extension larger systems
high level linguistic processing. fact, parsec used context janus
framework. hand, screen aims robust incremental processing
using word hypothesis space, specific repair modules, representations.
particular, screen emphasizes robustness spoken-language processing, since
contains explicit repair mechanisms implicit robustness. Explicit robustness covers
often occurring errors (interjections, pauses, word phrase repairs) explicit modules,
less predictable types errors supported implicit similaritybased robustness connectionist networks themselves. general, representations generated extension parsec provide better support deeper structures
screen, screen provides better support incremental robust processing.
recent extension based parsec called feaspar, overall parsing performance
syntactic semantic feature accuracy 33.8%. Although additional improvements
shown using subsequent search techniques parsing results, consider
subsequent search techniques better parses since would violate incremental
processing (Bu, 1996). Without using subsequent search techniques screen reaches
overall semantic syntactic accuracy 72% 74% shown Table 6. However
pointed out, screen feaspar use different input sentences, features
architectures.
Besides parsec berp trains systems focus hybrid spoken-language processing. berp (Berkeley Restaurant Project) current project employs multiple
different representations speech/language analysis (Wooters, 1993; Jurafsky et al., 1994,
1994b). task berp act knowledge consultant giving advice choos76

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

ing restaurants. different components berp: feature extractor receives
digitized acoustic data extracts features. features used connectionist phonetic probability estimation. output connectionist feedforward network
used Viterbi decoder uses multiple pronunciation lexicon different language models (e.g. bigram, hand-coded grammar rules). output decoder word
strings transformed database queries stochastic chart parser. Finally,
dialog manager controls dialog user ask questions.
berp screen common ability deal errors humans
speech recognizer well relatively analysis. However, reaching robustness berp probabilistic chart parser used compute possible fragments first.
Then, additional fragment combination algorithm used combining fragments
cover greatest number input words. Different sequential process
first computing fragments utterance combining fragments, screen
uses incremental processing desirably provides best possible interpretation.
sense screen's language analysis weaker general. screen's analysis never
break produce best possible interpretation noisy utterances. strategy
may particularly useful incremental translation. hand, berp's language
analysis stronger restricted. berp's analysis may stop fragment level
contradictory fragments. strategy may particularly useful question
answering additional world knowledge necessary available.
trains related spoken-language project building planning assistant
reason time, actions, events (Allen, 1995; Allen et al., 1995).
goal building general framework natural language processing planning
train scheduling, trains needs lot commonsense knowledge. scenario, person
interacts system order find solutions train scheduling cooperative
manner. person assumed know goals scheduling
system supposed details domain. utterance person
parsed syntactic semantic parser. linguistic reasoning completed
modules scoping reference resolution. linguistic reasoning, conversation
acts determined system dialog manager responses generated based
template-driven natural language generator. Performance phenomena spoken language
repairs false starts currently dealt already (Heeman & Allen, 1994b,
1994a). Compared screen, trains project focuses processing spoken
language in-depth planning level. screen uses primarily connectionist
language analysis, trains uses chart parser generalized phrase structure grammar.

7. Discussion
First focus learned processing spoken-language processing.
started screen project, predetermined whether deep analysis
screening analysis would particularly appropriate robust analysis spoken
sentences. deep analysis highly structured representations less appropriate since
unpredictable faulty variations spoken language limit usefulness deep structured knowledge representations much case written language. Deep
interpretations structured representations - instance possible HPSG
77

fiWermter & Weber

grammars text processing - make great deal assumptions predictions
hold faulty spoken language. Furthermore, learned generating
semantic syntactic representation even need use deep interpretation
certain tasks. instance, translating two languages necessary
disambiguate prepositional phrase attachment ambiguities since process
translation disambiguations may get ambiguous target language.
However, use structure level words phrases syntax semantics respectively. learned single semantics level rather four
syntax semantics levels sucient since syntax necessary detecting phrase
boundaries. One could argue one syntactic abstract phrase representation one
abstract semantic phrase representation may enough. However, found basic
syntactic semantic representations word level make task easier subsequent abstract analysis phrase level. Furthermore, basic syntactic semantic
representations necessary tasks well, instance judgment
plausibility sequence syntactic semantic categories. plausibility used
filter finding good word hypothesis sequences. Therefore, argue processing
faulty spoken language - task sentence translation question answering -
need much less structured representations typically used well-known parsers
need structured representations single-level tagger.
previous work made early experiences related connectionist
networks analyzing text phrases. Moving analyzing text phrases analyzing unrestricted spoken utterances, tremendous differences two tasks. found
phrase-oriented analysis used scan (Wermter, 1995) advantageous principle
spoken-language analysis phrase-oriented analysis common learning text
speech processing. However, learned spoken-language analysis needs much
sophisticated architecture. particular, since spoken language contains many unpredictable errors variations, fault tolerance robustness much important.
Connectionist networks inherent implicit robustness based similarity-based
processing gradual numerical representations. addition, found classes
relatively often occurring mistakes, explicit robustness provided
machinery interjections, word phrase repairs. Furthermore, architecture
consider processing potentially large number competing word hypothesis
sequences rather single sentence phrase text processing.
Now, focus learned connectionist hybrid architectures. beginning predetermine whether connectionist methods would
particularly useful control individual modules both. However, development screen system became clear general task
spoken language understanding, individual subtasks syntactic analysis
fault-tolerant \noise" spoken language, due humans speechrecognizers well. Especially unforeseeable variations often occur spontaneously spoken
language cannot predefined well advance symbolic rules general manner.
fault-tolerance task level could supported particularly well inherent
fault-tolerance connectionist networks individual tasks support inductive
learning algorithms. learned robust understanding spoken-language
connectionist networks particularly effective within individual subtasks.
78

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

quite lot work control connectionist networks. However,
many cases approaches concentrated control single networks.
recently work control modular architectures (Sumida, 1991;
Jacobs et al., 1991b; Jain, 1991; Jordan & Jacobs, 1992; Miikkulainen, 1996). instance,
approach Jacobs Jordan (Jacobs et al., 1991b; Jordan & Jacobs, 1992), task
knowledge control knowledge learned both. Task knowledge learned individual
task networks, higher control networks responsible learning single task
network responsible producing output. Originally open question whether
connectionist control would possible processing spoken language. automatic
modular task decomposition (Jacobs et al., 1991a) done simple forms function
approximation, complex problems understanding spoken language real-world
environments still need designer-based modular task decomposition necessary tasks.
learned connectionist control architecture lot modules
subtasks currently seems beyond capabilities current connectionist networks.
shown connectionist control possible limited number connectionist modules (Miikkulainen, 1996; Jain, 1991). instance Miikkulainen shows
connectionist segmenter connectionist stack control parser analyze embedded clauses. However, communication paths still restricted within
three modules. Especially real-world system spoken-language understanding speech, syntax, semantics dialog processing translation extremely
dicult learn coordinate different activities, especially large parallel stream
word hypothesis sequences. believe may possible future, however
currently connectionist control screen restricted detection certain hesitations
phenomena corrections.
Considering screening analysis spoken language hybrid connectionist techniques together, developed followed general guideline (or design philosophy )
using little knowledge necessary getting far possible using connectionist
networks wherever possible symbolic representations necessary. guideline
led us (1) robust representation spoken-language analysis (2)
use hybrid connectionist techniques support task choice possibly
appropriate knowledge structure. Many hybrid systems contain small portion
connectionist representations addition many modules, e.g. berp (Wooters,
1993; Jurafsky et al., 1994, 1994b), janus (Waibel et al., 1992), trains (Allen, 1995; Allen
et al., 1995). contrast, important subtasks screen performed directly
many connectionist networks.
Furthermore, learned syntactic semantic representations could give
surprisingly good training test results trained tested medium corpus
2300 words 184 dialog turns. good results mostly due
learned internal weight representation local context adds sequentiality
category assignments. Without internal weight representation preceding context
syntactic semantic categorization perform equally well, choice
recurrent networks crucial many sequential category assignments. Therefore
networks techniques hold potential especially medium-size domains
restricted amount training material available. statistical techniques often
79

fiWermter & Weber

used large data sets, work well medium data sets, connectionist
techniques used work well medium-size domains.
used techniques ported different domains used different purposes. Even different sets categories would used learning networks
able extract syntactic regularities automatically. Besides domain arranging
business meetings ported screen domain interactions railway
counter comparable syntactic semantic results. two domains differed primarily semantic categories, syntactic categories (and networks) screen
could used directly.
screen potential scaling up. fact, based imperfect output
speech recognizer, several thousand sentence hypotheses already processed.
new words processed, syntactic semantic basic categories simply
entered lexicon. structure individual networks change, new units
added therefore networks retrained.
amount hand-coding restricted primarily symbolic control module
interaction labeling training material individual networks.
changed domain railway counter interactions, could use identical control,
well syntactic networks. semantic networks retrained due
different domain.
far focused supervised learning simple recurrent networks feedforward networks. Supervised learning still requires training set manual labeling
work still done. Although especially medium size corpora labeling examples
easier instance designing complete rule bases would nice automate
knowledge acquisition even further. Currently plan build sophisticated lexicon component provide support automatic lexicon design (Riloff, 1993)
dynamic lexicon entry determination using local context (Miikkulainen, 1993).
Furthermore, screen could expanded speech construction evaluation
part. syntactic semantic hypotheses could used interaction
speech recognizer. Currently syntactic semantic hypotheses speech evaluation
part used exclude unlikely word hypothesis sequences language modules.
However, hypotheses connectionist networks syntax semantics -
particular modules basic syntactic semantic category prediction - could
used directly process recognition future order provide
syntactic semantic feedback speech recognizer early stage. Besides syntax
semantics, cue phrases, stress intonation could provide additional knowledge
speech/language processing (Hirschberg, 1993; Gupta & Touretzky, 1994). issues
additional major efforts future.

8. Conclusions
described underlying principles, implemented architecture, evaluation new screening approach learning analysis spoken language. work
makes number original contributions fields artificial intelligence advances
state art several perspectives: perspective symbolic connectionist design argue hybrid solution, connectionist networks used
80

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

wherever useful symbolic processing used control higher level analysis. Furthermore, shown recurrent networks provided better syntactic
semantic prediction results 1-5 grams. perspective connectionist networks
alone, demonstrated connectionist networks fact used real-world
spoken-language analysis. perspective natural language processing argue
hybrid system design advantageous integrating speech language since lower
speech-related processing supported fault-tolerant learning connectionist networks
higher processing control supported symbolic knowledge structures. general, properties support parallel rather sequential, learned rather coded,
fault-tolerant rather strict processing spoken language.
main result paper learned representations support robust processing spoken language better in-depth structured representations connectionist networks provide fault-tolerance reach robustness. Due noise
spontaneous language (interjections, pauses, repairs, repetitions, false starts, ungrammaticalities, additional false word hypotheses speech recognizer) complex structured possibly recursive representations often cannot computed using standard symbolic
representations context-free parsers. hand, tasks information
extraction spoken language may need in-depth structured representation. believe hybrid connectionist techniques considerable potential
tasks, instance information extraction restricted noisy spoken-language domains. in-depth understanding inferencing story interpretation needs
complex structured representations, shallow understanding instance information
extraction noisy speech language environments benefit at, robust learned
representations.

Acknowledgements
research funded German Federal Ministry Research Technology
(BMBF) Grant #01IV101A0 German Research Association (DFG)
Grant DFG Ha 1026/6-3, Grant DFG 1468/4-1. would thank S. Haack,
M. Lochel, M. Meurer, U. Sauerland, M. Schrattenholzer work screen;
well David Bean, Alexandra Klein, Steven Minton, Johanna Moore, Ellen Riloff five
anonymous referees comments earlier versions paper.

References
Allen, J. F. (1995). TRAINS-95 parsing system: user's manual. Tech. rep. TRAINS
TN 95-1, University Rochester, Computer Science Department.
Allen, J. F., Schubert, L. K., Ferguson, G., Heeman, P., Hwang, C. H., Kato, T., Light,
M., Martin, N. G., Miller, B. W., Poesio, M., & Traum, D. R. (1995). TRAINS
project: case study building conversational planning agent. Journal Experimental Theoretical AI, 7, 7{48.
81

fiWermter & Weber

Barnden, J. A., & Holyoak, K. J. (Eds.). (1994). Advances Connectionist Neural
Computation Theory, Vol. 3., Ablex Publishing Corporation.
Bu, F. D. (1996). FeasPar - Feature Structure Parser Learning Parse Spontaneous
Speech. Ph.D. thesis, University Karlsruhe, Karlsruhe, FRG.
Bu, F. D., Polzin, T. S., & Waibel, A. (1994). Learning complex output representations
connectionist parsing spoken language. Proceedings International Conference Acoustics, Speech Signal Processing, Vol. 1, pp. 365{368, Adelaide,
Australia.
Charniak, E. (1993). Statistical Language Learning. MIT Press, Cambridge, MA.
Dyer, M. G. (1983). In-Depth Understanding: Computer Model Integrated Processing
Narrative Comprehension. MIT Press, Cambridge, MA.
Elman, J. L. (1990). Finding structure time. Cognitive Science, 14 (2), 179{211.
Faisal, K. A., & Kwasny, S. C. (1990). Design hybrid deterministic parser. Proceedings 13 th International Conference Computational Linguistics, pp. 11{16,
Helsinki, Finnland.
Feldman, J. A. (1993). Structured connectionist models language learning. Artificial
Intelligence Review, 7 (5), 301{312.
Geutner, P., Suhm, B., Bu, F.-D., Kemp, T., Mayfield, L., McNair, A. E., Rogina, I.,
Schultz, T., Sloboda, T., Ward, W., Woszczyna, M., & Waibel, A. (1996). Integrating
different learning approaches multilingual spoken language translation system.
Wermter, S., Riloff, E., & Scheler, G. (Eds.), Connectionist, Statistical Symbolic Approaches Learning Natural Language Processing, pp. 117{131, Springer,
Heidelberg.
Gupta, P., & Touretzky, D. S. (1994). Connectionist models linguistic theory: Investigations stress systems language. Cognitive Science, 18 (1), 1{50.
Hauenstein, A., & Weber, H. H. (1994). investigation tightly coupled time synchronous
speech language interfaces using unification grammar. Proceedings 12th
National Conference Artificial Intelligence Workshop Integration Natural
Language Speech Processing, pp. 42{49, Seattle, Washington.
Heeman, P. A., & Allen, J. (1994a). Detecting correcting speech repairs. Proceedings
32nd Annual Meeting Association Computational Linguistics, pp. 295{
302, Las Cruces, NM.
Heeman, P. A., & Allen, J. (1994b). Tagging speech repairs. Proceedings Human
Language Technology Workshop, pp. 187{192, Plainsboro, NJ.
Hendler, J. A. (1989). Marker-passing microfeatures: Towards hybrid symbolic/connectionist model. Cognitive Science, 13 (1), 79{106.
82

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Hirschberg, J. (1993). Pitch accent context: Predicting intonational prominence
text. Artificial Intelligence, 63, 305{340.
Jacobs, R. A., Jordan, M. I., & Barto, A. G. (1991a). Task decomposition competition modular connectionist architecture: vision tasks.
Cognitive Science, 15, 219{250.
Jacobs, R. A., Jordan, M. I., Nowlan, S. J., & Hinton, G. E. (1991b). Adaptive mixtures
local experts. Neural Computation, 3 (1), 79{87.
Jain, A. N. (1991). Parsing complex sentences structured connectionist networks.
Neural Computation, 3 (1), 110{120.
Jordan, M. I., & Jacobs, R. A. (1992). Hierarchies adaptive experts. Moody, J. E.,
Hanson, S. J., & Lippmann, R. R. (Eds.), Advances Neural Information Processing
Systems 4, pp. 985{992, Morgan Kaufmann, San Mateo, CA.
Jurafsky, D., Wooters, C., Tajchman, G., Segal, J., Stolcke, A., Fosler, E., & Morgan,
N. (1994a). Berkeley Restaurant Project. Proceedings International
Conference Speech Language Processing. pp. 2139-2142, Yokohama, Japan.
Jurafsky, D., Wooters, C., Tajchman, G., Segal, J., Stolcke, A., & Morgan, N. (1994b). Integrating experimental models syntax, phonology, accent/dialect speech recognizer. investigation tightly coupled time synchronous speech. Proceedings
12th National Conference Artificial Intelligence Workshop Integration
Natural Language Speech Processing, pp. 107{115, Seattle, Washington.
Medsker, L. R. (1994). Hybrid Neural Network Expert Systems. Kluwer Academic
Publishers, Boston.
Mellish, C. S. (1989). chart-based techniques parsing ill-formed input. Proceedings 27th Annual Meeting Association Computational Linguistics, pp.
102{109, Vancouver, Canada.
Menzel, W. (1994). Parsing spoken language time constraints. Cohn, A. G.
(Ed.), Proceedings 11th European Conference Artificial Intelligence, pp. 561{
564, Amsterdam.
Miikkulainen, R. (1993). Subsymbolic Natural Language Processing. integrated model
scripts, lexicon memory. MIT Press, Cambridge, MA.
Miikkulainen, R. (1996). Subsymbolic case-role analysis sentences embedded clauses.
Cognitive Science, 20, 47{73.
Nakatani, C., & Hirschberg, J. (1993). speech-first model repair detection correction. Proceedings 31st Annual Meeting Association Computational
Linguistics, pp. 46{53 Columbus, Ohio.
Reilly, R. G., & Sharkey, N. E. (Eds.). (1992). Connectionist Approaches Natural Language Processing. Lawrence Erlbaum Associates, Hillsdale, NJ.
83

fiWermter & Weber

Riloff, E. (1993). Automatically constructing dictionary information extraction tasks.
Proceedings 11th National Conference Artificial Intelligence, pp. 811{816,
Washington, DC.
Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning internal representations error propagation. Rumelhart, D. E., McClelland, J. L., & PDP
research group (Eds.), Parallel Distributed Processing, Vol. 1., pp. 318{362. MIT Press,
Cambridge, MA.
Sauerland, U. (1996). Konzeption und Implementierung einer Speech/Language
Schnittstelle. Master's thesis, University Hamburg, Computer Science Department,
Hamburg, FRG.
Sumida, R. A. (1991). Dynamic inferencing parallel distributed semantic networks.
Proceedings 13th Annual Meeting Cognitive Science Society, pp. 913{917,
Boston, Chicago.
Sun, R. (1994). Integrating Rules Connectionism Robust Common Sense Reasoning.
Wiley Sons, New York.
von Hahn, W., & Pyka, C. (1992). System architectures speech understanding
language processing. Heyer, G., & Haugeneder, H. (Eds.), Applied Linguistics.
Wiesbaden.
Waibel, A., Jain, A. N., McNair, A., Tebelskis, J., Osterholtz, L., Saito, H., Schmidbauer,
O., Sloboda, T., & Woszczyna, M. (1992). JANUS: Speech-to-speech translation using
connectionist non-connectionist techniques. Moody, J. E., Hanson, S. J., &
Lippmann, R. R. (Eds.), Advances Neural Information Processing Systems 4, pp.
183{190, Morgan Kaufmann, San Mateo, CA.
Ward, N. (1994). approach tightly-coupled syntactic/semantic processing speech
understanding. Proceedings 12th National Conference Artificial Intelligence Workshop Integration Natural Language Speech Processing, pp.
50{57, Seattle, Washington.
Weber, V., & Wermter, S. (1995). Towards learning semantics spontaneous dialog utterances hybrid framework. Hallam, J. (Ed.), Hybrid Problems, Hybrid Solutions
| Proceedings 10th Biennial Conference AI Cognitive Science, pp.
229{238, Sheeld, UK.
Weber, V., & Wermter, S. (1996). Artificial neural networks repairing language.
Proceedings 8th International Conference Neural Networks Applications, pp. 117{123, Marseille, FRA.
Wermter, S., & Weber, V. (1996a). Interactive spoken-language processing hybrid
connectionist system. IEEE Computer { Theme Issue Interactive Natural Language
Processing, July, 65{74.
84

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Wermter, S. (1994). Hybride symbolische und subsymbolische Verarbeitung Beispiel
der Sprachverarbeitung. Duwe, I., Kurfe, F., Paa, G., & Vogel, S. (Eds.),
Herbstschule Konnektionismus und Neuronale Netze. Gesellschaft fur Mathematik und
Datenverarbeitung (GMD), Sankt Augustin, FRG.
Wermter, S. (1995). Hybrid Connectionist Natural Language Processing. Chapman
Hall, Thompson International, London, UK.
Wermter, S., & Lochel, M. (1994). Connectionist learning syntactic analysis
speech/language systems. Marinaro, M., & Morasso, P. G. (Eds.), Proceedings
International Conference Artificial Neural Networks, Vol. 2, pp. 941{944,
Sorrento, Italy.
Wermter, S., & Lochel, M. (1996). Learning dialog act processing. Proceedings
16th International Conference Computational Linguistics, pp. 740{745, Kopenhagen, Denmark.
Wermter, S., & Peters, U. (1994). Learning incremental case assignment based modular
connectionist knowledge sources. Werbos, P., Szu, H., & Widrow, B. (Eds.), Proceedings World Congress Neural Networks, Vol. 4, pp. 538{543, San Diego,
CA.
Wermter, S., Riloff, E., & Scheler, G. (Eds.). (1996). Connectionist, Statistical Symbolic
Approaches Learning Natural Language Processing. Springer, Berlin.
Wermter, S., & Weber, V. (1996b). Artificial neural networks automatic knowledge acquisition multiple real{world language domains. Proceedings 8th International Conference Neural Networks Applications, pp. 289{296, Marseille,
FRA.
Wooters, C. C. (1993). Lexical modeling speaker independent speech understanding
system. Tech. rep. TR-93-068, International Computer Science Institute, Berkeley.
Young, S. R., Hauptmann, A. G., Ward, W. H., Smith, E., & Werner, P. (1989). High
level knowledge sources usable speech recognition systems. Communications
ACM, 32, 183{194.

85


