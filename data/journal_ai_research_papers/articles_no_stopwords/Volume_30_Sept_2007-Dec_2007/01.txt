Journal Artificial Intelligence Research 30 (2007) 51 - 100

Submitted 03/07; published 09/07

Graph Abstraction Real-time Heuristic Search
Vadim Bulitko
Nathan Sturtevant
Jieshan Lu
Timothy Yau

BULITKO @ UALBERTA . CA
NATHANST @ CS . UALBERTA . CA
JIESHAN @ CS . UALBERTA . CA
THYAU @ UALBERTA . CA

Department Computing Science, University Alberta
Edmonton, Alberta, T6G 2E8, CANADA

Abstract
Real-time heuristic search methods used situated agents applications require
amount planning per move independent problem size. agents plan
actions time local search space avoid getting trapped local minima improving heuristic function time. extend wide class real-time search algorithms
automatically-built state abstraction prove completeness convergence resulting
family algorithms. analyze impact abstraction extensive empirical study
real-time pathfinding. Abstraction found improve efficiency providing better trading offs
planning time, learning speed negatively correlated performance measures.
Keywords: learning real-time heuristic search, state abstraction, goal-directed navigation.

1. Introduction Motivation
paper study problem agent-centered real-time heuristic search (Koenig, 2001).
distinctive property search agent must repeatedly plan execute actions
within constant time interval independent size problem solved.
restriction severely limits range applicable algorithms. instance, static search algorithms
(e.g., A* Hart, Nilsson, & Raphael, 1968), re-planning algorithms (e.g., D* Stenz, 1995),
anytime algorithms (e.g., ARA* Likhachev, Gordon, & Thrun, 2004) anytime re-planning
algorithms (e.g., AD* Likhachev, Ferguson, Gordon, Stentz, & Thrun, 2005) cannot guarantee
constant bound planning time per action. LRTA* provides guarantees planning
actions time updating heuristic function, solution quality poor
lengthy convergence process (Korf, 1990; Ishida, 1992).
motivating example, consider navigation gridworld maps commercial computer
games. games, agent tasked go location map current
location. agent must react quickly users command regardless maps size
complexity. Consequently, game companies impose time-per-action limit pathfinding algorithms. example, Bioware Corp., major game company, limits planning time 1-3 ms
pathfinding units (and many units planning simultaneously).
additional challenge comes form limited sensing virtual reality trainers
Artificial Intelligence controlled characters may access entire map priori, order
avoid unrealistic behavior (Dini, van Lent, Carpenter, & Iyer, 2006). agents build
internal map model based sensing limited amount map around position.
efficient search agent would minimize delay incurred planning actions, explore
learn environment quickly, always discover optimal path goal. Unfortunately,
c
2007
AI Access Foundation. rights reserved.

fiB ULITKO , TURTEVANT, L U , & YAU

measures negatively correlated (or antagonistic) optimizing performance one
measure results worse performance one others. instance, reducing amount
planning done action improves agents response time, leads slower learning
due lower-quality actions taken agent.
propose use graph abstraction improve efficiency search agents make
following four contributions. First, introduce new algorithm, Path Refinement Learning
Real-time Search (PR LRTS)1 , enhances existing real-time heuristic search algorithms
automatically-built graph abstraction. PR LRTS learns heuristic function abstract space
thereby substantially accelerating learning. Actions abstract space refined actions
environment A* algorithm. approach allows agents generate actions constant
time, explore environment quickly, converge near-optimal solutions. paper use
previously published clique abstraction (Sturtevant & Buro, 2005). contributions specific
abstraction three-fold. First, introduce initial clique building repair procedure
detail previously published. Second, prove worst-case bound suboptimality
path induced abstraction. Third, present first application state abstraction
real-time heuristic search.
standard practice heuristic search literature promote new algorithms trading
small amount one performance measure large gain another performance measure.
instance, state abstraction non-real time heuristic search shown trade little solution
quality substantial reduction running time (e.g., Holte, Mkadmi, Zimmer, & MacDonald,
1996; Botea, Muller, & Schaeffer, 2004). Unfortunately, always clear whether tradeoffs made optimally. second contribution, demonstrate PR LRTS outperforms
number algorithms respect two antagonistic measures (e.g., learning speed
amount planning per action).
third contribution, analyze effects abstraction search respect commonly
used performance measures: solution suboptimality, amount planning per action, total travel,
total planning time, memory footprint. Knowing effects deepens understanding realtime heuristic search methods well guides practitioner selecting appropriate
search algorithm configuration application. Fourth, show theoretically PR LRTS
unifies extends several well known existing heuristic search algorithms satisfies realtime operation, completeness, convergence properties. contribution viewed
follow-up previous unification extension efforts (Bulitko & Lee, 2006).
rest paper organized follows. begin formulating problem real-time
heuristic search Section 2. new algorithm, PR LRTS, described Section 4. Empirical
results follow Section 5. Theoretical results presented Section 6. review existing
agent-centered search algorithms well work automatic graph abstraction Section 7.
paper concluded discussion current limitations future research.

2. Real-time Heuristic Search
defining property real-time heuristic search amount planning performed
agent per action constant upper-bound depend problem size. Low bounds
preferred applications, guarantee agents fast response presented new
goal. real-time search agent plans next action considering states local search space
1. early version algorithm published conference paper (Bulitko, Sturtevant, & Kazakevich, 2005).

52

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

1 sc s0
2 sc 6= sg
3
sense environment, update agents model
4
compute partial path p originates current state sc
5
execute p
6
update current state sc
7 end
Figure 1: Real-time heuristic search (a single trial).
surrounding current position. heuristic function (or simply heuristic) estimates cumulative
cost state goal, used agent rank available actions select
promising one. process shown schematically Figure 1. Agents current state sc
set initial state s0 line 1. long goal sg reached (line 2), agent senses
environment around (see Section 3 details) updates model search graph
operating line 3. computes (partial) path current state toward goal
state line 4. real-time property requires lines 3 4 execute constant-bounded time
regardless problem size. accomplished calling real-time heuristic search algorithm
line 4. paper, discuss three candidate algorithms: LRTA* Section 2.1, LRTS
Section 2.2, PR LRTS Section 4. would called line 4. agent
executes path line 5 updates current state line 6.
trial defined agents problem-solving experience traveling start state
goal state. goal state reached, agent teleported start state next
trial begins. convergence process defined first sequence trials agent longer
updates heuristic function model search problem. first trial without updates
final trial learning process said converged.
2.1 Learning Real-time A* (LRTA*)
first review best known real-time heuristic search algorithm, Learning Real-Time A*
(LRTA*) (Korf, 1990). algorithm shown Figure 2. line 1, d-ply breadth-first search
duplicate detection used find frontier states precisely actions away current state
s. standard path-max (Mero, 1984) technique used deal possible inconsistencies
heuristic function computing g + h-values. value state, s, sum
cost shortest path sc s, denoted g(s, s), estimated cost shortest path
sg (i.e., heuristic value h(s, sg )). state minimizes sum identified s0
line 2. heuristic value current state updated line 3. Finally, path one action
toward promising frontier state s0 returned line 4.
path LRTA*(sc , sg , d)
1
2
3
4

generate successor states sc actions away
find state s0 lowest g(sc , s0 ) + h(s0 , sg )
update h(sc , sg ) g(sc , s0 ) + h(s0 , sg ) greater current h
return first action along optimal path sc s0
Figure 2: LRTA* algorithm.

53

fiB ULITKO , TURTEVANT, L U , & YAU

2.2 Learning Real-time Search (LRTS)
LRTS extends LRTA* three ways: puts weight heuristic function, uses maxof-min learning rule, utilizes backtracking. review extensions detail
Section 7.2 walk LRTS operation below. LRTS three control parameters: lookahead
N, optimality weight (0, 1], learning quota [0, ]. operates follows.
current state sc , agent running LRTS conducts full-width d-ply lookahead search (line 1
Figure 3). ply, finds promising state (line 2). Assuming initial heuristic
h admissible, safely increase h(sc ) maximum among f -values promising states
levels (line 3). total learning amount u (updated line 4) exceeds learning quota
, agent backtracks previous state planned (lines 5, 8). Otherwise, returns
path moves current state sc promising state level (line 6).
learning amount u reset 0 agent start state (i.e., beginning trial).
path LRTS(sc , sg , d, , )
1
2
3

generate successor states sc , actions away, = 1 . . .
level i, find state si lowest f (si ) = g(sc , si ) + h(si , sg )
update h(sc , sg ) max f (si ) greater current h

4
5
6
7
8
9

increase amount learning u h
u
return path actions sc sd
else
return path actions backtrack previous state, set u =
end

1id

Figure 3: LRTS algorithm.
LRTS parameters previously studied length (Bulitko & Lee, 2006). summarize trends. Higher lookahead reduces convergence travel, convergence memory, suboptimality. However, increases first-move lag. lower heuristic weight leads less optimal
solutions and, generally speaking, reduces convergence travel convergence memory. First-move
lag influenced . lower learning quota causes backtracking tends reduce
convergence travel convergence memory; affect first-move lag.
2.3 Notation
Definition 2.1 search problem defined tuple (G, c, s0 , sg , h0 ) G = (S, E)
directed weighted graph (henceforth search graph). finite set states (or vertices)
E finite set edges them. edge weights defined cost function
c : E (0, ) c(s1 , s2 ) travel cost edge e = (s1 , s2 ). s0 start
state, sg goal state, h0 : [0, ) initial heuristic function. assume
h0 (sg ) = 0. Out-edges state called moves actions. number out-edges (i.e.,
out-degree state) called branching factor state.
Definition 2.2 solution search problem path start state s0 goal state sg .
path denoted (s0 , s1 , . . . , sg ) si valid state valid edge
pair states (si , si+1 ). travel cost path sum travel costs edges.
54

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Definition 2.3 times, search agent resides single search state sc called current
state. agent change current state executing actions thus incurring travel
cost. Initially, current state coincides start state s0 . agent said succeed
makes current state coincide goal state sg .
assume goal state reachable state agent get start
state. needed completeness real-time heuristic search algorithms. follow
standard practice real-time heuristic search literature assume environment
stationary deterministic. Additionally, support backtracking (Shue & Zamani, 1993; Shue,
Li, & Zamani, 2001) (i.e., reversing agents actions), require every action reverse
action. needed backtracking enabled algorithm.
Definition 2.4 travel cost state s1 state s2 denoted dist(s1 , s2 ) defined cost
shortest path s1 s2 . Throughout paper, assume dist satisfies triangle
inequality: s1 , s2 , s3 [dist(s1 , s3 ) dist(s1 , s2 ) + dist(s2 , s3 )]. Then, state, s, h (s)
defined minimal travel cost goal: h (s) = dist(s, sg ). heuristic function, h,
approximation h . admissible overestimate h : [h(s) h (s)]. value
h state referred heuristic value state s. assume heuristic
function h(sg ) = 0 trivially holds admissible h.
experiments break ties moves fixed fashion (e.g., always prefer
action north, north east, east, etc.) entails agents behavior
identical trials final trial. necessarily mean entire search graph
explored learned heuristic accurate states.
Definition 2.5 Convergence travel cumulative cost edges traversed agent
convergence process. Convergence planning amount planning effort expended
agent convergence process. first-move lag amount planning effort expended
agent first move final trial. Convergence memory measured total
number heuristic values stored convergence process. standard practice realtime heuristic search literature (e.g., Korf, 1990; Shimbo & Ishida, 2003) store heuristic
values hash table. Hash table misses handled procedurally specified initial heuristic h0
(e.g., Manhattan distance grid-based pathfinding). convergence memory number
entries hash table convergence. Finally, suboptimality defined percentage points
final-trial solution cost excess relative shortest-path cost. instance, agent
incurred travel cost 120 shortest-path cost 100, suboptimality 20%.
measure planning effort two ways. First, report number states algorithm
touched (i.e., considered) planning. measure called edges traversed (e.g., Holte
et al., 1996, p. 325). Second, report physical CPU time, measured 2.0GHz PowerPC G5
computer gcc 4.0 Mac OS 10.4.8. measure convergence memory terms
number heuristic values stored. meaningful heuristic value stored takes
fixed amount memory (i.e., double type C++) implementation algorithm.
Definition 2.6 search algorithm exhibits real-time performance heuristic search problem
planning effort per move constant-bounded constant independent problem size
(assuming fixed maximum branching factor).
55

fiB ULITKO , TURTEVANT, L U , & YAU

objectives real-time search agent complete (i.e., arrive goal state
every trial), converge (i.e., finish learning process finite number trials),
minimize five performance measures described above. rest paper discuss
existing new algorithms compare terms objectives.
2.4 Application: Goal-directed Navigation
One motivating applications heuristic search goal-directed navigation, known
pathfinding. special case heuristic search problem formalized previous section
search graph (S, E) defined terrain map. Thus, states/vertices correspond
geographical positions map, edges describe passability blocking, cost function
represents difficulty/time traversing terrain.
Real-time pathfinding motivated primarily time-sensitive robotics (e.g., Koenig & Simmons, 1998; Koenig, 1999; Kitano, Tadokoro, Noda, Matsubara, Takahashi, Shinjou, & Shimada,
1999; Koenig, Tovey, & Smirnov, 2003) computer games. latter include real-time strategy
games (e.g., Blizzard Entertainment, 2002), first-person shooters (e.g., id Software, 1993), roleplaying games (e.g., BioWare Corp., 1998). these, time plays critical role since number
agents perform pathfinding simultaneously gamers would rapid response fluid
gameplay. result, pathfinding become major computational expense: Age Empires
II (Ensemble Studios, 1999) takes 60-70% simulation time (Pottinger, 2000).
paper, follow footsteps Furcy Koenig (2000), Shimbo Ishida (2003),
Koenig (2004), Botea et al. (2004), Hernandez Meseguer (2005a, 2005b), Sigmundarson
Bjornsson (2006), Koenig Likhachev (2006) situate empirical study navigation
two-dimensional grid-based maps. cells square cell connected four cardinally
(i.e., west, north, east, south) four diagonally neighboring cells. cell occupied
agent (i.e., free) wall (i.e., blocked).
free grid cell constitutes vertex/state search space S. agent travel
two free neighboring cells, s1 s2 , edge (s1 , s2
) added set edges E.
paper, set edge costs 1 cardinal moves 2 diagonal moves. cell initially
occupied agent s0 ; target cell sg . example converting grid-based map
search problem defined (G, c, s0 , sg , h0 ) shown Figure 4. Note allow
diagonal moves cut corners and, thus, state s6 connected states s1 , s5 , s7 , sg .
done non-zero size agent able pass zero-width bottleneck
formed two diagonally adjacent blocked cells. case one corner (e.g.,
states
s5 s6 Figure 4), allowing cut would lead actual travel distance
exceeding 2 since non-zero-width agent walk around corner.
Video games often feature repeated pathfinding experiences map two reasons:
(i) units commute source destination (e.g., resource collectors
real-time strategy games) (ii) ally units share results learning (i.e., heuristic
function). Since trial typically improves heuristic values many states, even single trial
single unit use units different start states long share goal
state. often case state abstraction entire region map (e.g., room
role-playing game players home base real-time strategy game) mapped
single abstract state. Thus, single-trial learning experiences multiple units approximated
multi-trial learning experience single unit. latter scenario study paper,
56

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Goal

s7

s8

sg

s6

Start

s1

s4

s5

s0

s2

s3

Figure 4: 34 grid-based map (left) converted 9-state search graph (right). Thinner
cardinaldirection edges cost 1, thicker diagonal edges cost 2.
line Furcy Koenig (2000), Shimbo Ishida (2003), Sigmundarson Bjornsson (2006)
others.

3. Search Graph Discovery
paper, require search agent know problem entirety. Instead, portion
search problem neighborhood current state sc sensed agent time
step. assume agent remember parts problem sensed far.
words, times agent internal representation (model) search space like.
model updated agent discovers search graph (line 3 Figure 1).
Let us illustrate exploration process goal-directed navigation. terrain map initially
unknown agent. moves around environment, grid cells whose coordinates within
fixed visibility radius agents current position sensed. Formally, agent situated cell
(x, y) check status (free/blocked) cell (x0 , 0 ) |x x0 | r |y 0 | r,
r N visibility radius. Thus, two visible cells (x0 , 0 ) (x00 , 00 ) agent tell
edge cost. similar virtual sensors used Thalmann,
Noser, Huang (1997).
One common approach assume regular structure unknown part search
space (Koenig et al., 2003; Koenig, 2004; Bulitko & Lee, 2006; Koenig & Likhachev, 2006).
instance, grid-based pathfinding, agent assume obstacles gridworld
senses otherwise (this sometimes called free space assumption). demonstrate
Figure 5, agent assumes space obstacle-free (a) builds internal
model accordingly (b). Exploration reveals obstacles environment (c) cause agent
update model (d). impose restriction search agent never needs add edges
model exploration weights discovered edges never change. words, agents
initial model optimistic contains superset edges actual search graph. Adding edges
allowing arbitrary edge weight changes may require agent explore environment explicitly. Combining exploration exploitation effectively active research area (for early work,
refer Sutton, 1990) addressed paper.
Map discovery natural robotics sensors limited ranges. software domains,
agent theoretically access entire environment. Several types arguments
made justify restricting agents senses software domains. First, omniscient virtual
57

fiB ULITKO , TURTEVANT, L U , & YAU

Actual search space:

Agent's model:

Explored actual search space:

Updated agent's model:

(a)

(b)

(c)

(d)

Figure 5: (a): initially part search space shown solid lines sensed agent
(shown stick figure). agents model assumes regular structure unknown
part (b). agent moves north-east, senses additional part search space
(c) updates model correspondingly (d).
humans tend behave unrealistically and, thus, less suitable virtual reality trainers (Dini
et al., 2006). Likewise, commercial games, revealing entire map AI player viewed
negatively cheating. Second, computationally expensive sense (Orkin, 2006)
reason entire environment (Thalmann et al., 1997; Aylett & Luck, 2000). Consequently,
localized sensing used large-scale multi-unit systems (Reynolds, 1987).

4. Path Refinement Learning Real-time Search (PR LRTS)
Real-time heuristic search algorithms plan using small part search graph surrounds
agents current state. order avoid getting stuck infinite loops, update heuristic
function time. approach guarantees action planned constant-bounded
amount time. downside slow convergence.
central idea PR LRTS address downside running real-time search
smaller abstract search graph refining produced abstract path ground-level path.
abstract graph image original graph abstraction operator. operator
maps region states original graph single abstract state abstract graph.
applied multiple times, hierarchy abstractions formed. hierarchy forest (a tree
connected component search graph) formalized Section 4.2.
variety terminologies used literature discussing relationship states different levels abstraction. different contexts abstract states
referred clusters (Botea et al., 2004), sectors/regions (Sturtevant, 2007), images (Holte
et al., 1996). abstraction forest, line (Bacchus & Yang, 1994; Bulitko
et al., 2005; Sturtevant & Buro, 2005), sometimes call image abstraction operator parent
pre-image children. terms confused successor states lookahead
search. first describe PR LRTS intuitive level illustrate example Section 4.1. give formal details Section 4.2 describe abstraction operator detail.
4.1 Path Refinement
PR LRTS computes paths several levels abstraction. First, path found
abstract search space (at level `). abstract path defines region lower-level abstract
58

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

path PR LRTS(sc , sg )
1
2
3
4
5
6
7
8
9
10
11
12
13

level(sc ) > `
return
end
p =PR LRTS(parent(sc ), parent(sg ))
p 6=
sg = child(end(p))
end
C = {s | parent(s) p}
switch(algorithm[level(sc )])
A* : return A*(sc , sg , C)
LRTS : return LRTS(sc , sg , C)
pass-through : return p
end switch

Figure 6: PR LRTS algorithm.
space searched refining abstract path. refinement proceeds incrementally
level-0 (i.e., ground) search space reached ground path produced. order
keep amount planning per move constant-bounded regardless ground space size,
need real-time algorithm abstract search graph. paper, use LRTS
fixed top level abstraction (`), A* refinement lower levels.2 abstract levels
left pass-through merely increase amount state aggregation; processing
carried them. design choice motivated experimentation (Section 5).
PR LRTS operates recursively presented Figure 6. line 1 checks states passed
top level abstraction pathfinding occur. so, empty path
returned (line 2). Otherwise, function calls recursively compute path
abstract image sc (denoted parent(sc ) line 4) abstract image sg . returned
path (if non-empty checked line 5) used derive new destination line 6. Specifically,
new destination sg child end abstract path p.3 line 8, compute
corridor C comprised pre-images states path p. corridor C empty
path p computed line 4 empty. Finally, run algorithm assigned current level
abstraction (i.e., level sc sg ) lines 10 11. A* LRTS tasked
find either full (in case A*) partial path (in case LRTS) sc sg limited
set states C. convention, empty corridor (C = ) allows A*/LRTS search entire
graph. Note processing happens pass-through level (line 12).4
2. agent explores environment moving about, actually use Local Repair A* instead A*.
described Section 7.
3. child used, choices may lead better performance. Intuitively, child chosen
child(end(p)) closest representative abstract state end(p) among children(end(p)).
pathfinding, implement child(s) return element children(s) geographically closest average coordinates states children(s). Also, goal state sg happens pre-image end(p)
pick child(end(p)).
4. note functions child parent handle pass-through levels. Specifically, line 6, state sg
computed child first non-pass-through level level path p computed. Likewise, line
8, states forming corridor C first non-pass-through level (level i) level path p (level
j). Thus, parent(s) apply abstraction mapping j times parent(s) p level j.

59

fiB ULITKO , TURTEVANT, L U , & YAU

implementation A* standard (Hart et al., 1968) except run (line 10) subgraph
defined corridor C (line 8). implementation LRTS taken literature (Bulitko
& Lee, 2006) described Section 2.2. A*, run LRTS corridor C.

Figure 7: path refinement process. original graph (level 0) shown bottom.
abstract graph (level 1) shown top.
illustration purposes, consider example Figure 7. example ` = 1, one
level abstraction (shown top) used addition ground level (shown bottom).
sc current state sg destination state. LRTS assigned level 1 A*
assigned level 0. Subfigure (i) shows ground state space one level abstraction
above. agent must plan path sc sg located ground level. First, abstract
parents sc sg , parent(sc ) = s0c parent(sg ) = s0g , located. LRTS = 3
plans three steps abstract space (ii). corridor C ground level comprised children
abstract path built (iii). child representing end abstract path set
new destination sg (iv). Finally, A* run within corridor find path sc new
destination sg (v).
agent executing path computed PR LRTS, new areas search graph may
seen. causes updates abstraction hierarchy agent maintains. PR LRTS clears
recomputes abstract paths upon discovering new areas search graph. Also, ground
path proves invalid (e.g., runs newly discovered obstacle), execution stops PR LRTS
replans current state using updated abstraction hierarchy.
Graph discovery lead arbitrary updates abstract search graphs agent maintains.
implementation, LRTS operating abstract graph resets heuristic function abstract search graph updated way. hand, updates ground-level graph
limited state edge removals (Section 3). Consequently, heuristic learned ground
level remains admissible need reset upon updates.
4.2 Automatic Graph Abstraction
use term abstraction operator (or abstraction, short) mean graph homomorphism
line Holte et al. (1996). Namely, abstraction many-to-one function maps (abstracts)
one states single abstract state. Adjacent vertices mapped adjacent identical
vertices (Property 5 below). Given graph homomorphism function model search
problem, PR LRTS agent builds ` additional abstract search graphs, collectively called abstrac60

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

tion hierarchy, follows. first applies graph homomorphism search graph model
(called ground-level graph). result abstract search graph level 1. process
repeated abstract search graph level ` computed. homomorphic abstraction
used long resulting hierarchy abstract graphs satisfies several key properties. following introduce properties informally illustrate example. Appendix B
formalize them.
Property 1 Every abstract graph search graph sense Definition 2.1 Section 2.
Property 2 Every state unique abstract parent (except states top level abstraction).
Property 3 Every state abstract level, least one child state below.
Property 4 Given heuristic search problem, number children abstract state upperbounded constant independent number states ground-level graph.
corollary property number ground-level states abstract single
state fixed level abstraction constant-bounded constant independent
ground-level graph size.
Property 5 (Graph homomorphism) Every edge search graph level abstraction
either corresponding edge level states connected edge abstract
single abstract state.
Property 6 abstract edge exists two states edge least
child one state child other.
Property 7 two children abstract state connected path whose states
children abstract state.
Property 8 abstraction hierarchy consistent agents model search problem
times. is, properties 1 7 satisfied respect agents model.
paper, use clique-based abstraction mechanism (Sturtevant & Buro, 2005). operates finding fully connected components (cliques) search graph mapping
single abstract state. method building abstractions favored recent analysis Sturtevant
Jansen (2007) earlier analysis Holte et al. (1996, Section 5.2) showed reduction
search effort due abstraction maximized minimizing edge diameter set children
maximizing size. clique, edge diameter (i.e., maximum number edges
two elements) one number states clique maximized.
present clique-based abstraction mechanism developing several stages handtraceable example. illustrate properties introduced satisfied
example. formal introduction clique abstraction technique complete pseudocode
found Appendix A. review ways building abstraction Section 7.3. Note
general clique computation NP-complete, finding cliques two-dimensional grid-based search
graphs done efficiently (Appendix A).
61

fiB ULITKO , TURTEVANT, L U , & YAU

single application abstraction procedure illustrated Figure 8. Cliques size four
first located graph, meaning states s0 , s1 , s2 s4 abstracted s01 .
cliques size three already abstracted first step, cliques size two
abstracted next. includes s5 s3 abstracted s02 , s7 s8
abstracted s03 . sg degree 1, add s03 ; however s6 degree two,
abstracted parent, s04 . Adding degree 1 states neighbors reduces number
resulting abstract states increases edge diameter set children (it becomes 2
set {s7 , s8 , sg }). minor detail abstraction happens effective grid-based
pathfinding. One use pure clique abstraction well.
s7

s8

sg

s'3

s6
s1

s4

s'4

s5
s'1

s0

s2

s'2

s3

Level 0 (original graph)

Level 1 (abstract graph)

Figure 8: Clique abstraction: original search graph Figure 4 shown left abstracted
search graph right.

s7

s8

sg

s'3
s''2

s6
s1

s4

s'4

s5
s'1

s0

s2

s'''
1

s'2

s''1

s3

Level 0 (original graph)

Level 1

Level 2

Level 3

Figure 9: Three iterations clique abstraction procedure.
abstraction process successively applied single abstract state connected component original graph remains (Figure 9, Level 3). illustrate
abstraction properties Figure 9. Property 1 requires four abstraction levels
Figure 9 search graph sense Definition 2.1 Section 2. Property 2 requires
62

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

state levels 0, 1, 2 unique parent level above. Property 3 requires
state levels 1, 2, 3 non-empty set children level below. Property 4 places
upper bound number children abstract state have. example bound
4. Properties 5 6 require that, two abstract states connected path, parents
children connected. Consider, instance, abstract states s02 s03 .
connected level 1 abstract path p = (s02 , s01 , s04 , s03 ) them. Thus, child
s02 connected child s03 level 0. instance, s3 connected s7 . Property 7
requires children node s01 connected internal path within s01 . (s00 , s01 , s02 , s04 ) form
clique, property satisfied.
costs abstract edges (e.g., edge (s01 , s02 ) Figure 8) defined arbitrary way
long resulting search graph satisfies properties Section 2. However, better performance, low-cost abstract path abstraction low-cost ground path. paper
experiment grid-based navigation and, correspondingly, define cost edge (s01 , s02 )
Euclidean distance average coordinates children(s01 ) children(s02 ) (Figure 10).

Figure 10: Coordinates edge costs levels abstraction hierarchy. grid level
(leftmost illustration) vertex
coordinates given column/row labels. Ground
edges cost 1 (cardinal) 2 (diagonal). Abstract states labeled (x, y). Abstract
edges labeled approximate cost.

practice, Property 8 satisfied repairing agents abstraction hierarchy upon updates
agents model. illustrate, imagine agent discovered discrepancies
terrain elevation state s4 s6 (Figure 8) prevent able traverse edge
(s4 , s6 ). update model removing edge. Additionally, degree-one state s6
join clique {s7 , s8 }. point, agents abstraction hierarchy needs repaired.
accomplished replacing abstract states s04 s03 single abstract state s05 . edges (s01 , s04 )
(s04 , s03 ) removed. one level abstraction used repair
propagated higher levels well. repair mechanism presented detail Appendix A.2.
prove Section 6 PR LRTS algorithm operate abstraction mechanism
satisfies properties listed above.
63

fiB ULITKO , TURTEVANT, L U , & YAU

Figure 11: Two six maps used experiments.

5. Empirical Study
Empirical evaluation effects state abstraction learning real-time heuristic search
presented four parts. Section 5.1, introduce concept trading antagonistic
measures demonstrate PR LRTS makes trade-offs efficiently. due use
abstraction and, consequently, investigate effects abstraction independently LRTS
control parameters Section 5.2. study PR LRTS performance scales problem
size (Section 5.3). Finally, examine interplay effects abstraction LRTS
control parameters. domain-specific study present details Appendix F.
experimental setup follows. used 3000 problems randomly generated three
maps modeled environments role-playing game (BioWare Corp., 1998) three maps
modeled battlefields real-time strategy game (Blizzard Entertainment, 2002). six
maps 5672, 5852, 6176, 7629, 9749, 18841 states grids 139 148 193 193.
Two maps Figure 11. four maps shown Appendix C. 3000 problems
uniformly distributed across five buckets bucket represents range optimal solution
costs. first 600 problems optimal path cost [50, 60) range, next 600 problems
fell [60, 70) bucket last 600 problems [90, 100) bucket.
experimented various assignments algorithms (A*, LRTS, none) levels abstraction. experimentation, found keeping LRTS top, A* bottom level
leaving intermediate levels pass-through yielded best results testbed. following, present results 160 PR LRTS configurations, denoted LRTS` (d, , ), `
level abstraction LRTS control parameters d, , operates, A* running
bottom level. ` = 0, run LRTS ground level run A* all. LRTS
parameter space follows: ` {0, 1, 2, 3, 4}, lookahead depth {1, 3, 5, 9}, optimality
weight {0.2, 0.4, 0.8, 1.0}, learning quota {100.0, }. Two visibility radii used:
10 1000. analysis, focus case visibility radius 10, line
previous publications area (Bulitko et al., 2005; Bulitko & Lee, 2006). Experiments
visibility radius 1000 yielded similar results. point reference, ran single nonreal-time algorithm: A*. algorithms implemented within Hierarchical Open Graph
framework (Sturtevant, 2005) C++ run cluster, aggregate 1.7 years Intel
Xeon 3.0GHz CPU.
64

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

5.1 Antagonistic Performance Measure Trade-off
practitioners viewpoint, section viewed parameter selection guide. start
finding sets parameters optimize performance PR LRTS along single measure.
consider optimizing pairs antagonistic performance measures.
research optimizing single performance measures within LRTS published Bulitko
Lee (2006). Table 1 extend results include A* PR LRTS. best algorithms
single performance measure A* LRTA* use abstraction. exception
convergence planning interplay planning per move convergence travel.
Table 1: Optimizing single performance measure.
Measure
convergence travel
first-move lag (states touched)
conv. memory
suboptimality
conv. planning (states touched)

best algorithm
A*
LRTA*
A*
A* LRTA*
LRTS3 (d = 1, = 0.2 0.4, ) LRTS2 (d = 1, = 0.2 0.4, )

power abstraction comes attempt optimize two negatively correlated (or
antagonistic) performance measures simultaneously. Consider, instance, convergence travel
first-move lag. order lower convergence travel, agent needs select better actions.
done increasing amount planning per move which, turn, increases first-move
lag. measures negatively correlated, performance along one measure traded
performance along other. Thus, interested algorithms make trade-offs
efficiently. order make analysis specific, first introduce concept dominance
respect set parameterized algorithms.
Definition 5.1 Algorithm said dominate algorithm B respect performance measures
x set problems P average performance measured x worse
Bs: avgP x(A) worse avgP x(B) avgP y(A) worse avgP y(B).
Algorithm C called dominated set algorithms set contains another algorithm
dominates it.
definition illustrated Figure 12 non-dominated algorithms shown solid circles dominated algorithms shown hollow circles. Intuitively, non-dominated algorithms
make trade-off performance measures x efficiently among algorithms
set. considered practice one wants optimize performance measures. Dominated algorithms safely excluded consideration regardless relative
importance measures x particular application.
Non-dominated algorithms ten pairs antagonistic measures summarized Table 2.
A* weighted version Korfs LRTA* extreme cases performance measures: A*
minimizes convergence travel uses heuristic memory; LRTA* minimizes first-move lag.
non-dominated algorithms PR LRTS abstraction. words, abstraction
path-refinement improve efficiency trading antagonistic performance measures. Figure 13
shows dominance plot convergence planning first-move lag. PR LRTS forms frontier
65

fiperformance
measure 2

performance
measure 2

worse

worse

B ULITKO , TURTEVANT, L U , & YAU

B


better

better

Nondominated
algorithms

better

performance
measure 1

better

worse

performance
measure 1

worse

Figure 12: Left: algorithm dominates algorithm B (left). Right: non-dominated algorithms
shown solid circles, dominated algorithms shown hollow circles.
non-dominated algorithms (the rightmost non-dominated point weighted LRTA*
extremely low first-move lag). Plots combinations Appendix D.

Firstmove Lag (states touched)

Dominated
Nondominated

3

10

LRTS3(1,0.4,)
2

10

LRTS2(1,0.4,)

LRTS1(1,0.4,)

1

10

LRTS(1,0.4,)
4

10

5

10
Convergence Planning (states touched)

6

10

Figure 13: Dominance convergence planning first-move lag.
dominance analysis done respect performance measures averaged
benchmark set problems. Dominance analysis level individual problems found
Appendix E shows similar trends.
5.2 Effects Abstraction Individual Performance Measures
section study effects abstraction individual performance measures. arbitrarily choose three diverse LRTS parameter combinations lookahead d, optimality weight ,
learning quota : (1, 1.0, ), (3, 0.2, 100), (9, 0.4, ). plots Figure 14, qualitative
summary Table 3, analysis trends below.
Convergence planning decreases abstraction level. increase planning per move higher abstraction levels overcompensated decrease convergence
travel. exact shape curves due interplay two measures.
66

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Table 2: Trading antagonistic performance measures.
Measure 1
first-move lag
(states touched)
first-move lag
(states touched)
first-move lag
(states touched)
first-move lag
(time)
first-move lag
(time)
first-move lag
(time)
suboptimality
suboptimality
suboptimality
suboptimality

Measure 2
conv. travel
conv. memory
conv. plan.
(states touched)
conv. travel
conv. memory
conv. plan.
(time)
conv. plan.
(states touched)
conv. plan.
(time)
conv. travel
conv. memory

Non-dominated algorithms (extreme cases italic)
A*, LRTA*( = 0.4),
LRTS1...4 (d {1, 3, 5, 9}, {0.2, 0.4, 0.8}, {100, })
A*, LRTA*( = 0.2),
LRTS1...4 (d {1, 3, 5, 9}, {0.2, 0.4}, {100, })
LRTS1...3 (d = 1, = 0.4, = ),
LRTA*( = 0.4)
A*, LRTA*( = 0.4),
LRTS1...4 (d {1, 3, 5, 9}, {0.2, 0.4}, {100, })
A*, LRTA*( {0.2, 0.4}),
LRTS1...4 (d {1, 3, 5}, {0.2, 0.4}, {100, })
A*, LRTA*( = 0.4),
LRTS1...3 (d {1, 3}, {0.2, 0.4}, {100, })
A*,
LRTS2...3 (d {1, 3, 5}, {0.2, 0.4, 0.8}, {100, })
A*
A*
A*

First-move lag increases abstraction level. due fact corridor
ground level induced abstract path length computed LRTS abstract level
increases abstraction level. two additional factors affecting shape curves.
First, average out-degree abstract states varies abstraction level. Second, boundaries
abstract graphs often seen lookahead = 9 higher abstraction level.
Convergence memory decreases abstraction level learning algorithm (LRTS) operates smaller abstract maps incurs smaller travel cost. practice, amount learning
LRTS tends correlate tightly travel. instance, LRTS2 (3, 0.8, ) correlation
convergence memory convergence travel empirically measured 0.9544
confidence 99%.
Suboptimality increases abstraction. increase due fact abstraction
level progressively simplifies ground graph topology and, abstract path guaranteed
refinable ground path, may lead agent away shortest solution. illustrative
example given Appendix B.1 refinement complete abstract path 221% longer
optimal ground path. Derivation theoretical upper bound suboptimality due
abstraction found Appendix B.2. second mechanism explains suboptimality rises faster
shallower LRTS searches. Specifically, A* ground level refines abstract d-step path
finding ground-level solution current state ground representative end
abstract path. solution guaranteed optimal within corridor necessarily
pass geographically closely intermediate states abstract path. Thus, giving A*
corridor induced longer abstract path liberates plot path possibly far-off
intermediate states abstract path. phenomenon illustrated Appendix B.1
feeding A* abstract path small fragments results suboptimality giving
big picture abstract path entirety. third factor affecting suboptimality curves
67

fi4

6

33 4
x 10

22
B ULITKO
, TURTEVANT, L U , & YAU

3
2

Convergence Travel

22

4

x 10

3
2
1

00
0

11

22

33

0 Abstraction
1
2 Level3
Abstraction
Level
Abstraction Level

44
4

First!Move Lag

6000

First!Move Lag
First!Move Lag

44

4

2000

00 0

0 000 0
0

4000
4000

4000

30

2000
2000
2000

20

00 0
0 0 0 1 1 1 2 2 2 3 33
Abstraction
Level
Abstraction
Level
Abstraction
Level

4 44

10

1000

2

x 10
6
2x 10

1.5
1.5 x 106

2

11

1.5

0.5
0.5

1

00

0.5

1500
1500
0

00

0

1000
1000
1500

1

30
1500
1500
30
0 1500
0
20
1000
1000
20

6000
6000

3030 30

6 6

11
22
33
Abstraction
Level
Abstraction Level

2000
2000
0.50.5
4000 0.5

11
00

00

x 10
x 10
22
6000
6000
6
0
x 10
02
1
2
3
1.51.5
Abstraction Level
40001.5
4000
6000 1 1

Suboptimality (%)
Convergence Memory
Suboptimality
(%)
Convergence
Memory
Convergence
Memory
Suboptimality
(%)

Convergence Travel
Convergence Travel

33

4

00

1

4 4

x 10
x 10
44

11

Convergence
Memory Memory
Convergence
Convergence
MemoryConvergence
Planning Planning
Convergence
ConvergencePlanning

First!Move Lag
First!Move
Convergence Travel
First!Move Lag
Lag
Convergence Planning
ConvergenceTravel
Travel
Convergence
Convergence
Planning
Convergence
Planning

4

x 10 4
4 x 10
4

4 4

1
2
3
Abstraction Level

4

11
22
3 3
Abstraction
Level
Abstraction
Level

4 4

500
500
1000

222 2
333 3
111 1
1Abstraction
2 Level
3
Level
Abstraction
Abstraction
Level
Abstraction
Level
Abstraction Level

1
2
3
Abstraction Level

444 4
4

4

00

500
0

00

0

10
500
10500
500
0
0 0
00 0
00 00

11
22
3 3
Abstraction
Level
Abstraction
Level

d=1,!=1,T="
d=1,!=1,T="
1
2
3
d=3,!=0.2,T=100
Abstraction Level
d=3,!=0.2,T=100
d=9,!=0.4,T="
d=9,!=0.4,T="

4

d=1,!=1,T="
d=3,!=0.2,T=100
1
2
3
1111
222 2Level333 3
Abstraction
Abstraction
Level
Abstraction
Level
Abstraction
Level
Abstraction
Level

4
444 4

d=9,!=0.4,T="

Suboptimality (%)

Suboptimality (%)
Suboptimality (%)

Figure 14: Effects abstraction in0 PR LRTS.
Error bars indicate standard errors
d=1,!=1,T="
d=1,!=1,T="
d=1,!=1,T="
0
1
2
3
4
d=3,!=0.2,T=100
d=3,!=0.2,T=100
d=3,!=0.2,T=100
2020 20
small see data points.Abstraction
Level
d=9,!=0.4,T="
d=9,!=0.4,T="
d=9,!=0.4,T="

1010 10

figure optimality weight . Setting lower values leads higher suboptimality
0
independently
00
0
1 abstraction
2
3
4(Bulitko & Lee, 2006).
00
1 1 Abstraction
22
33
44
Level
Convergence
travel
decreases
abstraction bottom level search constrained within
Abstraction
Level
Abstraction Level
narrow corridor induced abstract path. decrease noticeable shallow lookahead searches (d = 1 = 3). Algorithms using lookahead = 9 low convergence
travel even without abstraction, convergence travel lower bounded double optimal
solution cost (one optimal solution first trial map discovered one
final trial map discovery heuristic learning). Consequently, abstraction diminished
gains deeper lookahead (d = 9), although effect would disappear larger maps.
Table 3: Qualitative effects abstraction: general trends.
measure / parameter
first-move lag
convergence planning
convergence memory
suboptimality
convergence travel

0`






Given higher abstraction reduces convergence travel, one may ask compares
reducing convergence travel non-abstract algorithms simply terminating convergence
process final trial. Figure 15 compare four algorithms single problem: A*,
non-abstract LRTS(3, 0.4, ) two abstract versions: LRTS2 (3, 0.4, ) LRTS4 (3, 0.4, ).
left plot figure demonstrates well-known fact convergence learning heuristic
search algorithms non-monotinic (e.g. Shimbo & Ishida, 2003). right plot shows cost
shortest solution function cumulative travel. prefer algorithms find shorter solutions traveling little possible. plot, abstract algorithms perform better (lower
68

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

A*
LRTS(3,0.4,)
LRTS2(3,0.4,)

Travel trial

180

LRTS4(3,0.4,)

160
140
120
100
80

2

4

6
Trial

8

A*
LRTS(3,0.4,)
LRTS2(3,0.4,)

200
Shortest solution found

200

180

140
120
100
80

10

LRTS4(3,0.4,)

160

200

400

600
800
1000
Cumulative travel

1200

1400

Figure 15: Convergence process level individual trials.
curves) preferred. words, single problem, better run abstract algorithms non-abstract algorithms regardless early convergence process terminated.
observe case problems assignments d, , tried.
certain cases, prematurely terminating convergence process non-abstract algorithm indeed
beneficial. Future research investigate extent one automatically select best
algorithm number trials run for.
5.3 Effects Abstraction: Scaling Problem Size
section investigate effects abstraction problem size increases. measure
size problem cost shortest path start goal position (henceforth
optimal solution cost).
Figures 16 17 show five performance measures plotted bucket averages. data
point, use middle bucket (e.g., 55, 65, . . . ) horizontal coordinate. error bars
indicate standard errors. Overall, results demonstrate abstraction enables PR LRTS
applied larger problems significantly dampening increase convergence travel, convergence planning, convergence memory. advantages come price suboptimality
first-move lag. former clearly increases abstraction lookahead small (Figure 16)
virtually bucket-independent. lookahead = 9 (Figure 17) draws curves together
deeper lookahead diminishes effects abstraction suboptimality (cf. Figure 36).
First-move lag virtually bucket-independent except case = 9 abstraction levels
3 4 (Figure 17). There, first-move lag capped problems lower buckets goal
seen start state higher levels abstraction. Consequently, LRTS computes
abstract path shorter nine moves. leads smaller corridor less work
A* refining path. Consequently, first-move lag reduced. problems become
larger, LRTS room compute full nine-move abstract path first-move lag increases.
abstraction level 3 phenomenon takes place bucket 85 seeing goal state
start state frequent enough make impact. happens abstraction level
4 proximity abstract goal continues cut search short even largest problems.
Finally, observe minute decrease first-move lag larger problems. appears
due fact problems higher buckets tend start state located cluttered
region map (so optimal solution cost necessarily higher). Walls reduce number
states touched agent first move reduce first-move lag.
69

fiB ULITKO , TURTEVANT, L U , & YAU

4

5

x 10

4
Convergence Planning

Convergence Travel

5
4
3
2
1
0

2000

400

3

300

2

1

0

55 65 75 85 95
Optimal Solution Cost

x 10

FirstMove Lag

6

55 65 75 85 95
Optimal Solution Cost

200

100

0

55 65 75 85 95
Optimal Solution Cost

30

1500

Suboptimality (%)

Convergence Memory

L=0

25

1000

500

L=1
L=2

20

L=3

15

L=4

10
5

0

0

55 65 75 85 95
Optimal Solution Cost

55 65 75 85 95
Optimal Solution Cost

Figure 16: Scaling up. curve shows bucketed means LRTSL (1, 1.0, ). Error bars indicate standard errors small see data points.

6. Theoretical Analysis
PR LRTS subsumes several known algorithms abstraction used. Clearly, LRTS (Bulitko & Lee, 2006) special case PR LRTS abstraction used. LRTS subsumes generalizes several real-time search algorithms including LRTA* (Korf, 1990), weighted
LRTA* (Shimbo & Ishida, 2003), -Trap (Bulitko, 2004) SLA*/SLA*T (Shue & Zamani, 1993;
Shue et al., 2001).
Theorem 6.1 (real-time operation) heuristic search problem, LRTS` (d, , ) amount
planning per action constant-bounded. constant depends constant control
parameters N, (0, 1], [0, ] independent problems number states.
first prove auxiliary lemma.
Lemma 6.1 (downward refinement property) abstract path p = (sa , . . . , sb ), two
children ends connected path lying entirely corridor induced p. means
abstract path refined within corridor formed children. Formally:
1 k ` p = (sa , . . . , sb ) [p (S(k), E(k)) =
s0a children(s1 ) s0b children(sm )
p0 = (s0a , . . . , s0b ) [p0 (S(k 1), E(k 1)) & s0 p0 [s0 sp children(s)]]].
70

(6.1)

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

5

4000

2000

6000
5000

6

4

2

0

0

200

6

55 65 75 85 95
Optimal Solution Cost

x 10

FirstMove Lag

6000

8
Convergence Planning

Convergence Travel

8000

4000
3000
2000

55 65 75 85 95
Optimal Solution Cost

1000

55 65 75 85 95
Optimal Solution Cost

L=1

150

100

50

0

55 65 75 85 95
Optimal Solution Cost

Suboptimality (%)

Convergence Memory

L=0

5

L=2
L=3

4

L=4

3

2

55 65 75 85 95
Optimal Solution Cost

Figure 17: Scaling up. curve shows bucketed means LRTSL (9, 0.4, ). Error bars indicate standard errors small see data points.
Proof. proof induction number edges abstract path. base case 0.
means two children single abstract state connected path lies entirely
set children abstract state. holds due Property 7.
Suppose statement holds abstract paths length j. show
holds abstract paths length j+1. Consider arbitrary abstract path p (S(k), E(k)), k >
0 j + 1 edges. represent p (s1 , . . . , sj+1 , sj+2 ). Consider arbitrary children
s01 children(s1 ) s0j+2 children(sj+2 ). need show path p0 (S(k
1), E(k 1)) lies entirely union children states p (let us denote
Cp ). Let s0j+1 arbitrary child state sj+1 . Since s1 sj+1 j edges apart,
inductive supposition, path s01 s0j+1 lies entirely Cp . left
show s0j+1 s0j+2 connected within Cp . s0j+1 s0j+2 parent,
Property 7 guarantees connected. different parents, Property 6 provides
guarantee. Either way, induction step completed.
prove Theorem 6.1.
Proof. abstract level `, LRTS(d, , ) considers bd abstract states
algorithm design (cf. Section 2.2), b maximum degree state. assumed earlier
paper, maximum degree state depend number states. resulting
abstract path longer abstract edges induces corridor ground level. corridor
consists ground-level states abstract abstract states path. size corridor
71

fiB ULITKO , TURTEVANT, L U , & YAU

upper-bounded number edges path (at d) multiplied maximum number
ground-level children abstract state level `. latter upper-bounded constant
independent number ground-level states due Property 4. A* running corridor
constant-bounded size takes constant-bounded time. Finally, abstraction repair O(`) `
independent graph size (Appendix A.2).
Completeness defined ability reach goal state every trial. prove completeness LRTS` (d, , ) based following reasoning. Recall LRTS` (d, , ) uses
LRTS algorithm build abstract path level `. uses corridor-restricted A*
ground level refine abstract path sequence ground-level edges. Due Property 7
Section 4.2, A* always able find path ground-level states sc sg
lie within corridor C time execution gets line 9 Figure 6. Due exploration
process, agents model search graph may different graph actually
reality. Consequently, path found A* may contain ground-level edge agent believes
exist reality not. following lemma demonstrates execution failure
possible finite number times given search graph:
Lemma 6.2 finite number path execution failures trial.
Proof. contradiction: suppose infinite number failures. failure due
discovery least one new blocked edge vertex ground-level graph.
infinitely many blocked edges vertices finite graph.
direct corollary lemma trial, moment time
graph discoveries made trial. Therefore, executing A*s path indeed allow
agent follow abstract path actual map.
Lemma 6.3 LRTS complete abstract graph.
Proof. First, show abstract graph satisfies properties LRTS shown
complete (Theorem 7.5, Bulitko & Lee, 2006). is, abstract graph finite, action
reversible, self-loops, actions positive cost, goal state reachable
every state. graph stationary deterministically traversible (p.122, Bulitko
& Lee, 2006). Due abstraction mechanism requirements Section 4.2, properties listed
satisfied clique abstraction mechanism long ground-level graph satisfies
properties well (which require Section 2). Thus, LRTS running abstract graph
ground graph complete.
PR LRTS, however, LRTS abstract graph execute actions. Instead,
current (abstract) state computed abstract parent agents current ground-level state.
Therefore, critical question whether agent able find ground-level path current
state ground-level state corresponding end abstract path computed line 6
Figure 6. failure would mean corridor computed line 8 Figure 6
used refine path contain ground-level path sc sg . Due downward
refinement property (Lemma 6.1), due graph discovery.
According Lemma 6.2, finite number failures, A* algorithm operating
ground level guaranteed find path reach end abstract path computed LRTS.
Thus, LRTS effective ability execute abstract actions. Putting results
72

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

together, conclude valid d, , parameters, LRTS abstract graph finds
goal every trial.
two lemmas lead directly following statement.
Theorem 6.2 LRTS` (d, , ) complete.
Proof. follows directly Lemma 6.2 Lemma 6.3.
Theorem 6.3 LRTS` (d, , ) fixed tie-breaking converges final solution finite
number trials. subsequent trials, update search graph model heuristic
follows path.
Proof. Follows Lemma 6.2 Theorem 7.6 (Bulitko & Lee, 2006) way
Lemma 6.3 Theorem 6.2 proved above.
Theoretical results suboptimality found Appendix B.2

7. Related Research
Existing heuristic search methods situated methods divided two categories: full
search real-time search. Full-search algorithms form entire solution given current
knowledge search graph. contrast, real-time search plans small segment (frequently
first action) solution executes right away. Due local nature planning,
real-time search algorithms need update heuristic function avoid getting stuck local
minima heuristic function.
7.1 Full Search
common full-search algorithm version A* (Hart et al., 1968) called Local Repair A* (Stout,
1996). it, full search conducted agents current state goal state free space
assumption. agent executes computed path either destination reached
path becomes invalid (e.g., previously unknown wall blocks way). latter case, agent
replans current position goal. Local Repair A* suffers two problems. First,
searches shortest solution and, general search problem, may end expanding number
states exponential solution cost due inaccuracies heuristic function (Pearl, 1984).
Second, re-planning episodes re-use results previous search.
first problem addressed suboptimal versions A* frequently implemented
via weighting heuristic function (Pohl, 1970, 1973). weighted A* (WA*) usually finds
longer solution less time. suboptimal solution found, improved upon
conducting additional searches. done re-using open list successive
searches (Hansen, Zilberstein, & Danilchenko, 1997; Likhachev et al., 2004; Hansen & Zhou, 2007)
re-running A* tunnel induced suboptimal solution (Furcy, 2006). later case,
beam search backtracking used place weighted A* (Furcy & Koenig, 2005).
second problem addressed incremental search methods D* (Stenz, 1995), D*
Lite (Koenig & Likhachev, 2002a) LPA* (Koenig & Likhachev, 2002b). algorithms reuse
information previous search, thus speeding subsequent replanning episodes.
73

fiB ULITKO , TURTEVANT, L U , & YAU

algorithms, full path computed first move executed
agent. Consequently, planning time per move constant-bounded increases
problem size. Thus, agent-centered full search real-time.
7.2 Learning Real-time Search
Since seminal work LRTA* (Korf, 1990), research field learning real-time heuristic
search flourished resulting twenty algorithms numerous variations.
described following four attributes:
local search space set states whose heuristic values accessed planning
stage. two common choices full-width limited-depth lookahead (Korf, 1990; Shimbo &
Ishida, 2003; Shue & Zamani, 1993; Shue et al., 2001; Furcy & Koenig, 2000; Hernandez &
Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner, Davison, Bulitko, Anderson,
& Lu, 2007) A*-shaped lookahead (Koenig, 2004; Koenig & Likhachev, 2006). Additional
choices decision-theoretic based shaping (Russell & Wefald, 1991) dynamic lookahead
depth-selection (Bulitko, 2004; Lustrek & Bulitko, 2006).
local learning space set states whose heuristic values updated. Common
choices are: current state (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shue
et al., 2001; Furcy & Koenig, 2000; Bulitko, 2004), states within local search space (Koenig,
2004; Koenig & Likhachev, 2006) previously visited states neighbors (Hernandez &
Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner et al., 2007).
learning rule used update heuristic values states learning space.
common choices dynamic programming mini-min (Korf, 1990; Shue & Zamani, 1993; Shue
et al., 2001; Hernandez & Meseguer, 2005a, 2005b; Sigmundarson & Bjornsson, 2006; Rayner
et al., 2007), weighted versions (Shimbo & Ishida, 2003), max mins (Bulitko, 2004), modified Dijkstras algorithm (Koenig, 2004), updates respect shortest path
current state best-looking state frontier local search space (Koenig & Likhachev,
2006). Additionally, several algorithms learn one heuristic function (Russell & Wefald,
1991; Furcy & Koenig, 2000; Shimbo & Ishida, 2003).
Control strategy decides move following planning learning phases. Commonly
used strategies include: first move optimal path promising frontier state (Korf,
1990; Furcy & Koenig, 2000; Hernandez & Meseguer, 2005a, 2005b), entire path (Bulitko,
2004), backtracking moves (Shue & Zamani, 1993; Shue et al., 2001; Bulitko, 2004; Sigmundarson & Bjornsson, 2006).
Given multitude proposed algorithms, unification efforts undertaken. particular, Bulitko Lee (2006) suggested framework, called Learning Real Time Search (LRTS),
combine extend LRTA* (Korf, 1990), weighted LRTA* (Shimbo & Ishida, 2003), SLA* (Shue
& Zamani, 1993), SLA*T (Shue et al., 2001), large extent, -Trap (Bulitko, 2004).
dimensions described above, LRTS operates follows. uses full-width fixed-depth local search
space transposition tables prune duplicate states. LRTS uses max mins learning rule
update heuristic value current state (its local learning space). control strategy moves
agent promising frontier state cumulative volume heuristic function updates
trial user-specified quota backtracks previous state otherwise (Section 2.2).
Within LRTS, unification several algorithms accomplished implementing
several methods local search space selection, learning rule, control strategy.
74

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

methods engaged run-time via user-specified parameters. resulting parameter space contained original algorithms plus numerous new combinations, enabling tuning
performance according specific problem objective function particular application.
demonstration, Bulitko et al. (2005) tuned LRTS ten maps computer game Baldurs
Gate (BioWare Corp., 1998) achieved convergence speed two orders magnitude
faster LRTA*, finding paths within 3% optimal. time, LRTS
five times faster first move incremental A*. Despite improvements, LRTS
real-time search algorithms converge slowly A* and, visually, may behave unintelligently
repeatedly revisiting dead-ends corners.
7.3 State Abstraction
idea abstraction previously applied full search methods. particular, HPA*
PRA* (Botea et al., 2004; Sturtevant & Buro, 2005) use abstraction speed A* search: instead
running A* lowest-level graph, instead run A* smaller abstract graph. PRA*
computes abstract path refines similar manner PR LRTS. However, PRA*
dynamically chooses abstract level use, computes path intermediate level
(i.e., pass-through levels). PRA* widens corridors decrease suboptimality
cost lower speed.
HPA* abstracts map using large regions, selects connection points (gates) neighboring regions. gates region, optimal paths gates pre-computed off-line
using A* stored table. means refining abstract path (i.e., sequence
region gates) done simply concatenating stored optimal paths. Smoothing applied
post-processing step decrease suboptimality resulting path.
algorithms based ideas presented Holte et al. (1996), used
abstraction mechanism similar manner use clique abstraction. method,
STAR abstraction, described radius abstraction. is, state selected,
aggregated together states fixed radius original state. Holte et al. (1996)s
work initially gain wide acclaim, because, time, little interest problems
small enough fit memory. Motivating applications, pathfinding computer
games, resulted resurgence interest techniques.
class algorithms first plan abstract path, refined traversable path.
Another approach build abstraction directly used planning realworld. includes methods framed quad-trees (Yahja, Stentz, Singh, & Brummit, 1998),
efficiently represent sparse maps. Quad-trees multi-resolution representation,
areas map represented high-resolution, others represented lower resolution.
abstraction differs abstractions clique abstraction applied
once; applications would produce lower resolution maps, although clique abstraction
could applied graph implied framed quad-tree representation.
One common use abstraction provide better heuristics. Holte, Perez, Zimmer,
MacDonald (1995) used result abstract search provide accurate heuristic lowlevel search performed path refinement. Similarly, pattern databases abstractions
built solved off-line. abstract solution costs stored used search
heuristic function (Culberson & Schaeffer, 1996; Felner, Zahavi, Schaeffer, & Holte, 2005).
75

fiB ULITKO , TURTEVANT, L U , & YAU

PR LRTS presented paper first real-time heuristic search algorithm use
automatically-built state abstraction. Path-refinement algorithms listed conduct full-search
therefore cannot guarantee constant-bounded planning time agents moves.

8. Limitations Future Work
results presented paper open several directions future research. First, PR LRTS
able operate wide class homomorphic graph abstraction techniques. Thus, would
interest investigate extent effects graph abstraction real-time search
presented paper specific clique abstraction mechanism pathfinding domain.
Recent work shown clique abstraction parameters well-tuned minimize
work done traditional path planning (Sturtevant & Jansen, 2007). experiments pathfinding
suggested clique abstraction well-suited map abstraction represents key
properties underlying space well. particular, branching factor stays roughly constant
higher levels abstraction. empty map, instance, number nodes level
abstraction reduced factor four clique abstraction, branching factor
every state stay same. (Corner states 3 neighbors, edge states 5
neighbors, middle states 8 neighbors.) may case domains.
instance, sliding tile puzzle maximum branching factor abstract states quickly increases
abstraction level. result, corridor derived abstract path PR LRTS becomes
excessively wide effectively constrain A* search ground level. conjecture
algorithms use homomorphic abstractions effective domain abstraction
preserves average, minimum, maximum branching factor original problem
level abstraction. Clique abstraction, likely work well three-dimensional pathfinding,
problem-specific mechanisms would needed permutation-type puzzles. area
open research provide abstraction.
Second, PR LRTS uses abstract solution restrict search original ground-level
graph. interesting combine complementary approach using cost
optimal solution abstract problem heuristic estimate original search graph
context real-time search. particular, looking effective ways propagating heuristic
values higher lower levels abstraction hierarchy.
Third, state aggregation one way generalizing learning. Future research consider
combining function approximation heuristic function, commonly practiced
large-scale applications reinforcement learning.
Fourth, presently investigating applications PR LRTS dynamic environments.
particular, studying extent savings memory gained learning higher
abstraction level afford application PR LRTS moving target search. existing algorithm (Ishida & Korf, 1991) requires learning number heuristic values quadratic size
map. prohibitive case commercial game maps.
Finally, presently extending graph abstraction method presented paper
stochastic environments formulated Markov Decision Processes.
76

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

9. Conclusions
Situated agents real-time environments expected act quickly efficiently learning
initially unknown environment. Response time learning speed antagonistic performance
measures planning leads better actions and, consequently, faster convergence longer
response time. Full search algorithms, local repair A*, converge quickly
constant-bounded planning time per move. Real-time heuristic search algorithms constantbounded planning times per move, learn slowly.
paper, attempted combine best approaches suggest hybrid algorithm, PR LRTS, learns heuristic function smaller abstract space uses corridorrestricted A* generate partial ground-level path. large-scale empirical study, PR LRTS
found dominate virtually tested algorithms use abstraction respect
several performance measure pairs. combination learning planning brings real-time performance much larger search spaces, substantially benefiting applications pathfinding
robotics video games.

Acknowledgments
Funding provided National Science Engineering Research Council Canada,
Alberta Ingenuity Centre Machine Learning, Informatics Circle Research Excellence,
University Alberta. appreciate input David Thue, Rich Korf, Rob Holte, Csaba
Szepesvari, David Furcy, Adi Botea. Special thanks go Jonathan Schaeffer anonymous reviewers whose detailed comments greatly improved paper. research enabled use WestGrid computing resources, funded part Canada Foundation Innovation, Alberta Innovation Science, BC Advanced Education, participating
research institutions. particular, would acknowledge help Roman Baranowski,
Masao Fujinaga, Doug Phillips.

Appendix A. Clique Abstraction
describe clique abstraction mechanism several stages. First, present
algorithm building initial abstraction hierarchy using free space assumption.
describe repair procedure updates abstract graphs agent explores environment.
Finally, consider suboptimality solution caused abstraction examples derive worstcase upper bound.
A.1 Building Initial Abstraction Hierarchy
pseudo-code building initial clique abstraction Figure 18. abstract procedure
(lines 5 14) takes set states level maps single abstract state level
+ 1. involves creating new abstract state storing parent child links. If, line 20,
new abstract edge added one already exists, add extra edge increase
count associated edge. counts used facilitate abstraction repair described
next section.
general, clique-finding NP-complete problem (Garey & Johnson, 1990). However,
eight-connected two-dimensional grid-based search graphs largest possible clique size 4.
77

fiB ULITKO , TURTEVANT, L U , & YAU

graph CliqueAbstraction(graph g)
1
initialize graph g 0
2
= 4...2
3
unabstracted state g
4
part i-clique c
5
g 0 g 0 {abstract(c)}
6
end
7
end
8
end
9
10 unabstracted state g
11
degree(s) = 1
12
set parent(s) parent(neighbor(s))
13
else
14
g 0 g 0 {abstract(n)}
15
end
16 end
17
18 edge e = (v1 , v2 )
19
parent(v1 ) 6= parent(v2 )
20
g 0 g 0 {(parent(v1 ), parent(v2 ))}
21
end
22 end
23 return g 0
Figure 18: Building initial clique abstraction.
degree
state constant-bounded (as required Section 2) time per

clique constant (i.e., 83 state accesses check eight neighbors find 3 form 4-clique
together current state). Thus, total running time single clique abstraction
O(|S|), |S| number states original search graph. abstraction procedure
reduces graph size least constant factor greater one, total cost abstracting
graph O(|S|) cost additional abstraction step reduced exponentially.
A.2 Repairing Abstraction Hierarchy
agent explores environment, may find edges states blocked. cases,
remove corresponding states edges model need propagate changes
abstract graphs abstraction hierarchy. demonstrate repair code Figure 19
example shows repair procedure amortized constant-time cost.
Figure 20 remove edges Level 0 graph bottom left figure. right
side figure shows full abstract graph edges removed. level
show portion abstract graph assume states edges graph.
shown schematically Level 0 gray.
Level 0 four states marked form abstract state level 1.
true states marked A. joined edge level 1, abstracted
78

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

RemoveEdge(edge e, level l, graph g)
1
decrease edge count e
2
child edge count e 6= 0 return end
3
e = (v1 , v2 )
4
remove e g[l]
5
parent(v1 ) = parent(v2 )
6
AddToRepairQ(parent(v1 ))
7
else
8
RemoveEdge((parent(v1 ), parent(v2 )), l + 1, g)
9
end
RemoveState(state s, level l, graph g)
10 edge e incident
11
RemoveEdge(e, l, g)
12 end
13 remove g[l]
14 AddToRepairQ(parent(s))
HandleRepairQ()
15 RepairQ empty
16
remove state lowest level l g
17
abstraction properties hold
18
AddToRepairQ(parent(s))
19
split state s1 . . . sn abstraction properties holds si
20
= 1 . . . n either:
21
1. Merge si existing abstract state
22
2. Extract si new abstract state
23
end
24
end
25 end
Figure 19: Repairing abstraction hierarchy.
four edges level 0. remove edges level 0 graph using RemoveEdge()
procedure Figure 19, first three removals simply decrement count associated
abstract edge (line 1-2). fourth removal, however, result removing
edge (line 4). removal recursively propagated (line 8)
abstraction hierarchy, change abstract graph level 2, edge count
decremented.
22 edges must removed perform full split top bottom
states level 0 Figure 20. Removing first edge E E level 2 requires
removal 10 underlying edges level 0 correspond 4 edges level 1 (all edges
A, B, B).
State repair first occurs remove edge E E. case E E
parent, G added repair queue (line 5 6). repair queue processed
set removal operations. edge E E removed, children G level 3
longer form clique. Thus, G must split two states H H. Initially states
79

fiB ULITKO , TURTEVANT, L U , & YAU

removal / repair
Level 3

removal / repair
H'

Level 3

split

split

G

E'

H
F'

E'

Level 2

Level 1

Level 2

split

E

F

B'

C'

D'



B

C



E

Level 1

split

E

F

F

A'

B'

C'

D'



B

C



split

E

(10 level 0 edges)

A'

F

A'

Level 0

Level 0

split



split

(4 level 1 edges)

A'

F'

B

C



split



B

C



Figure 20: example repairing clique abstraction.

edge them, edge removed last edges level
0 removed. repair code work many abstraction mechanisms. Specifically,
check abstract states children still form clique (line 17) changed check
corresponding property non-clique abstraction.
example, amortized cost abstraction repair constant. Imagine agent traversing graph level 0 left right discovering wall splitting top bottom rows
states (as shown split label figure). step graph sensed
agent edges removed level 0 graph. Removing three edges (A, A), (A, B),
(B, A) level 1 requires removing six edges level 0. Similarly, removing three edges
(E, E), (E, F), (F, E) requires removing 12 edges level 0. general, agent traveling
level 0 must move twice far (or remove twice many states) repair required
additional level abstraction. Thus, number abstraction levels repaired traversing n
ground edges, is:
n
n
n
n
n
1 + 2 + 3 + 4 + + log2 (n) = O(n).
2
4
8
16
n

Consequently, example, amortized repair cost per edge traveled O(1). general,
worst-case complexity repair O(`) and, PR LRTS, ` constant independent graph size.
repairs propagated abstraction hierarchy (line 18 Figure 19).
80

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Appendix B. Abstraction Properties
Abstraction properties informally introduced illustrated example Section 4.2.
appendix makes presentation mathematically precise. section, variables i, k, run
natural numbers including 0.
Property 1. agent using abstraction maintains hierarchy ` abstract search graphs addition model environment. abstract graphs search graph sense
Section 2. following denote abstract search graph level i, 1 `
(G(i), c(i), s0 (i), sg (i), h0 (i)). before, G(i) = (S(i), E(i)).
Property 2. state search graph level n < ` unique parent state s0 level
n + 1 abstract search graph. formally:


S(k), k < ` !s0 S(k + 1) parent(s) = s0 .

(B.1)

Property 3. state search graph level m, 0 < `, least one child
state s0 level 1. notation children(s) represents set children state s. Thus,
s0 children(s):


S(k), k > 0 s0 S(k 1) s0 children(s) .

(B.2)

Property 4. Given heuristic search problem S, instance problem, number
children abstract state upper-bounded constant independent number states:
S, search problem ((S, E), c, s0 , sg , h0 ) i, 0 < ` S(i)
[| children(s)| < m] .

(B.3)

Property 5. (Graph homomorphism) Every edge (s1 , s2 ) E(k), k < n either corresponding abstract edge level k + 1 s1 s2 abstract state:
s1 , s2 S(k), k < `
[(s1 , s2 ) E(k) = (parent(s1 ), parent(s2 )) E(k + 1) parent(s1 ) = parent(s2 ))] .(B.4)

Property 6. edge exists abstract states s1 s2 edge
child s1 child s2 :
s1 , s2 S(k), k > 0


0
0
(s1 , s2 ) E(k) = s1 children(s1 ) s2 children(s2 ) (s01 , s02 ) E(k 1) .
last property, need following definition.
81

(B.5)

fiB ULITKO , TURTEVANT, L U , & YAU

Definition B.1 path p space (S(k), E(k)), 0 k ` defined ordered sequence
states S(k) whose two sequential states constitute valid edge E(k). Formally, p
path (S(k), E(k)) if:
s1 , . . . , sm S(k) [p = (s1 , . . . , sm ) & i, 1 [(si , si+1 ) E(k)]] .

(B.6)

use notation p (S(k), E(k)) indicate vertices edges path p
sets S(k), E(k) respectively. notation p indicates state path p.
Property 7 two children abstract state connected path whose states
children abstract state:
S(k), 0 < k ` s01 , s02 children(s) p = (s01 , . . . , s02 ) (S(k 1), E(k 1)). (B.7)
B.1 Abstraction-induced Suboptimality: Examples
Abstraction cause suboptimality. Figure 21 left, refining abstract path. Solid
arrows indicate abstract path. Ground-level path shown thinner dashed arrows.
agents position shown goals position G. white cells form corridor
induced abstract path. optimal path shown right.

Figure 21: Abstraction causes suboptimality.
Partial path refinement increase suboptimality. Refining entire abstract path (Figure 22,
left) yield shorter paths refining segment abstract path (Figure 22, right). Solid
arrows indicate abstract path. ground-level path shown thinner dashed arrows.
agents position shown goals position G.
B.2 Abstraction-induced Suboptimality: Upper Bound
two factors contribute suboptimality paths returned PR LRTS. first
factor parameters chosen LRTS, weighted allow suboptimality. effect
analyzed literature (Bulitko & Lee, 2006). analyze suboptimality
introduced abstraction. simplicity analysis consider uniform abstraction
level k states abstracted parent next level abstraction. assumption simplifies analysis enables application analysis non-clique abstraction
mechanism maintain property. proving result, introduce two simple lemmas:
82

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Figure 22: Partial path refinement increases suboptimality.
Lemma B.1 Suppose abstract edges cost. lowest-cost path p states
B j edges lowest-cost abstract path abstract parents A0 B 0
j abstract edges.
Proof. prove contradiction. Suppose lowest-cost abstract path q A0 B 0
> j edges. consider abstract images states p. either abstract
edge coincide due Property 5. Thus form abstract path p0 A0
B 0 due Property 2 j edges. Since assumption theorem
abstract edges cost, lowest-cost path q A0 B 0 must higher
cost path p0 A0 B 0 (Figure 23, right). results contradiction.
Lemma B.2 path created refining abstract edge level ` cannot longer O(k ` )
level 0.
Proof. demonstrated right portion Figure 24. assume every abstract state
exactly k children. So, level ` abstraction state cannot k `
children. Assuming path cannot visit single node once, refined path
therefore O(k ` ) edges.
present main result:
Theorem B.1 Assume every abstract state k children ground level edge costs
[1, e]. level ` abstraction, cost path created refining abstract path
level ` level 0 (the original space) O(ek ` ) times costly optimal path
abstract edges happen uniform cost O(e2 k 2` ) abstract edges costs [1, ek ` ]
(from Lemma B.2).
Proof. First, deal case edges abstract graph uniform cost. Consider
two level-0 states B abstract level-` states A0 , B 0 (left side Figure 23). lowestcost path p B j edges lowest-cost abstract path A0 B 0
j abstract edges Lemma B.1.
83

fiB ULITKO , TURTEVANT, L U , & YAU

path p', j edges

path q, > j edges

A'

B'



B

A'

path p, j edges

B'

path p', j edges

Figure 23: Proving lowest-cost abstract path j edges.
Suppose agent state seeking go state B. agent first computes
lowest-cost abstract path A0 B 0 . worst case, abstract path j edges.
Suppose two abstract paths A0 B 0 : t01 t02 shown Figure 24, left.
j edges and, due uniform abstract edge cost assumption, cost. worst
case scenario, t01 refined lowest-cost path t1 B t02 refined
highest-cost path t2 B. analyzing cost ratio t1 t2 arrive
upper bound theorem.
1 edge

path t'2 : j edges

A'

level !

B'

level 0
path t'1 : j edges

k ! edges

Figure 24: Paths t01 , t02 cost yet refine shortest longest paths.
Due Lemma B.2, one abstract edge level ` refined k ` level-0 edges.
worst case, t1 j edges t2 jk ` 1 edges (the result abstracting ` levels k `
states single state). Furthermore, edges t1 cost 1 leading total cost t1
j. edges t2 cost e leading total cost t2 e(jk ` 1). Thus, ratio
t2 t1 costs higher ek ` proves first statement theorem.
case abstract edges non-uniform costs [1, ek ` ], consider two abstract paths t01 t02 A0 B 0 . cost ejk ` , highest possible
cost level-` image cost-j ground path. path t01 , abstract cost might overestimated
j abstract edges, cost ek ` refine level-0 path t1 j edges
cost 1 each. Thus, total cost t1 j lowest possible cost B.
Path t02 cost t01 ejk ` abstract edges, cost 1. Since
abstract edges refined k ` edges level 0, path t02 refined path t2
ejk ` k ` edges, cost e. Consequently, total cost t2
e ejk ` k ` = je2 k 2` . Thus, ratio costs t1 t2 e2 k 2` .
84

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

t'1
t'1


A'

B



B

B'

w
c

c
t'2

w

w

j

w

w

j

Figure 25: grid-based example achieving worst case suboptimality.
worst-case upper bound tight, occurs severely underestimate cost
suboptimal path overestimate cost optimal path. Figure 25 show
happen practice; level-0 map shown left. lowest-cost path (t1 ) states
B straight line cost j. corridors width 1. length corridors,
w, chosen level ` abstraction, states corridor abstract together
single state. map cliques size two (i.e., k = 2 Theorem B.1).
right part Figure 25 shows level-` abstract graph thick lines original map
light gray. abstraction, path t02 A0 B 0 (the abstract parents
B) goes lower part map. path t02 abstract cost 2c + j + w
abstract edges refine w ground-level edges each. Thus, total cost refined path t2
w (2c + j) = 2cw + jw. Path t01 abstract image t1 abstract cost w = k `
j edges, leading total abstract cost jk ` = jw. shown right side
figure highly zigzagged path.
choose c t02 costs much t01 . agent bad luck
choosing refine t02 . make certainty, make cost t01 slightly higher
cost t02 . accomplished setting 2c + j + w jw. here, 2c jw j w
c jw = jk ` = j2` . result, agent chooses refine t02 t2 , cost
2cw + jw = 2j2` 2` + j2` = O(j22` ). ratio cost t1 22` ,
corresponds bound theorem k = 2, e = 1.
experimental results demonstrate large suboptimality occur practice. illustration, consider histogram suboptimality values 3000 problems
parametrizations PR LRTS Figure 26.
suboptimality become practical concern, one use ideas HPA* (Botea
et al., 2004), optimal path costs within regions pre-computed cached. precomputation help prevent severe over- under-estimation abstract path costs
assumed worst-case analysis Theorem B.1.

Appendix C. Maps Used Empirical Study
four additional maps shown Figure 27.
85

fiB ULITKO , TURTEVANT, L U , & YAU

1

Percentage problems

10

0

10

1

10

2

10

3

10

20

40

60
80
Suboptimality (%)

100

120

Figure 26: Histogram suboptimality experiments.

Figure 27: four additional maps used experiments.

Appendix D. Dominance Average: Plots
Six plots corresponding entries Table 2 shown Figures 28, 29.
86

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

A*
LRTS4(9,0.2,)
(9,0.2,100)
(9,0.4,)
(9,0.4,100)
LRTS
(9,0.2,100)
LRTS33(9,0.2,)
(9,0.4,)
(9,0.4,100)

Dominated
Nondominated

LRTS2(9,0.2,)

Firstmove Lag (states touched)

LRTS
(5,0.2,)
LRTS
(5,0.4,)
(5,0.4,100)
33
3

10

LRTS
LRTS33(3,0.2,)
(3,0.4,)
LRTS (1,0.4,)
4

LRTS3(1,0.4,)
2

10

LRTS2(1,0.4,)

LRTS2(1,0.8,)
LRTS1(1,0.4,)

LRTS1(1,0.8,)

1

10

LRTS(1,0.4,)
3

4

10

10
Convergence Travel

A*

Dominated
Nondominated

LRTS2(9,0.2,)
LRTS2(9,0.2,100)
LRTS (5,0.2,)
3
LRTS (5,0.2,100)
3
LRTS
LRTS44(3,0.2,)
(3,0.4,)

3

Firstmove Lag (seconds)

10

LRTSLRTS
(3,0.2,)
(5,0.4,)
3
2
LRTS4(1,0.4,)
LRTS4(1,0.2,)
LRTS3(1,0.4,)
LRTS (1,0.4,100)
3

4

LRTS
LRTS
(1,0.4,)
(1,0.2,) LRTS (1,0.4,100)
2 2
2

10

LRTS
(1,0.4,)
LRTS
(1,0.2,)
1
1

LRTS(1,0.4,)
3

4

10

10
Convergence Travel

A*

Dominated
Nondominated
3

Firstmove Lag (seconds)

10

LRTS (3,0.2,)
3

LRTS3(1,0.4,)
LRTS (1,0.4,100)
3

4

10

LRTS
LRTS
(1,0.4,)
(1,0.2,) LRTS (1,0.4,100)
2 2
2
LRTS
LRTS11(1,0.4,)
(1,0.2,)

LRTS(1,0.4,)
1

10
Convergence Planning (seconds)

0

10

Figure 28: Dominance several pairs performance measures. Part 1.

Appendix E. Dominance Individual Problems
Section 5.1 introduced concept dominance demonstrated PR LRTS abstraction dominates extreme search algorithms use abstraction. analysis done using cost values averaged 3000 problems. section consider
87

fiB ULITKO , TURTEVANT, L U , & YAU

A*
LRTS4(9,0.2,100)
(9,0.2,)
LRTS (9,0.2,)
(9,0.2,100)
LRTS43(5,0.2,)
(5,0.2,100)
(5,0.4,100)
(5,0.4,)

Dominated
Nondominated

4

Firstmove Lag (states touched)

LRTS3(5,0.2,)
(5,0.2,100)
(5,0.4,)
(5,0.4,100)
3

10

LRTS3(3,0.2,)
(3,0.4,)
LRTS4(1,0.2,)
(1,0.2,100)
(1,0.4,)
(1,0.4,100)
4

LRTS
(1,0.2,100)
LRTS33(1,0.2,)
(1,0.4,)
2

10

LRTS
LRTS22(1,0.2,)
(1,0.4,)

LRTS
(1,0.2,)
LRTS
(1,0.4,)
11

1

10

LRTS(1,0.2,)

0

500

1000

1500

Convergence Memory
A*
LRTS (5,0.2,100)
(5,0.4,!)
4

Dominated
Non!dominated

LRTS3(5,0.2,100)
LRTS4(3,0.2,!)
(3,0.2,100)
LRTS
LRTS4 (3,0.4,!)
4

!3

First!move Lag (seconds)

10

LRTS3(3,0.2,!)
LRTS4(1,0.2,!)
(1,0.2,100)
(1,0.4,100)
4
LRTS
(1,0.2,100)
LRTS333(1,0.2,!)
(1,0.4,100)

!4

LRTS
LRTS22(1,0.2,!)
(1,0.4,100)

10

LRTS1(1,0.2,!)

LRTS(1,0.2,!)
LRTS(1,0.4,!)

0

500

1000

1500

Convergence Memory

Dominated
Nondominated

25
LRTS3(1,0.4,)

Suboptimality (%)

20

LRTS2(1,0.4,)

15

LRTS3(3,0.2,)
LRTS
LRTS
(3,0.4,)
(3,0.4,100)
33

10

LRTS3(5,0.2,)
LRTS3(5,0.4,)
(5,0.4,100)
LRTS
LRTS33(5,0.8,)
(5,0.8,100)

5

0

A*
4

10

5

10
Convergence Planning (states touched)

6

10

Figure 29: Dominance several pairs performance measures. Part 2.
dominance individual problems. Due high variance problems difficulty,
report percentages problems dominance achieved. every pair algorithms,
measure percentage problems first algorithm dominates second.
measure percentage problems second algorithm dominates first. ratio
two percentages call dominance ratio.
88

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

4

10

3

FirstMove Lag

10

2

10

1

10

0

10
2
10

3

4

10

5

10

10

Convergence Travel
4

x 10

Convergence Travel

FirstMove Lag
700

14

600

12
LRTS_3(1,1.0,)

LRTS_3(1,1.0,)

500
10
8
6
4
2

400
300
200
100

5
10
LRTS(5,0.8,)

15

200
400
LRTS(5,0.8,)

4

x 10

600

Figure 30: Top: LRTS3 (1, 1.0, ) shown filled star; LRTS(5, 0.8, ) shown hollow
star. Bottom left: convergence travel. Bottom right: first-move lag.
Table 4: Statistics two algorithms Figure 30.
Algorithm

Convergence travel

First-move lag



LRTS3(1,1.0,!)

72.83%

97.27%

70.97%

LRTS(5,0.8,!)

27.17%

2.67%

0.87%

Dominance ratio
81.89

top Figure 30 see reproduction corresponding plot Figure 28
two particular algorithms marked stars. filled star LRTS3 (1, 1.0, ) uses three
levels abstraction. hollow star LRTS(5, 0.8, ) operates entirely ground level.
Statistics reported Table 4. bottom left figure shows advantages PR LRTS
respect convergence travel. approximately 73% 3000 problems, PR LRTS
travels less LRTS convergence (points 45-degree line). respect
first-move lag, PR LRTS superior LRTS 97% problems (bottom right
figure). Finally, 71% problems PR LRTS dominates LRTS (i.e., outperforms
89

fiB ULITKO , TURTEVANT, L U , & YAU

25

Suboptimality (%)

20
15
10
5
0
3
10

6

4

5

10

10
Convergence Planning

6

Convergence Planning

x 10

7

10

10

Suboptimality (%)

6
80

4

LRTS_3(5,0.8,)

LRTS_3(5,0.8,)

5

3
2
1

1

2
3
4
LRTS(3,0.2,)

5

60

40

20

0

6

0

6

x 10

20

40
60
LRTS(3,0.2,)

80

Figure 31: Top: LRTS3 (5, 0.8, ) shown filled star; LRTS(3, 0.2, ) shown hollow
star. Bottom left: convergence planning. Bottom right: suboptimality.
respect measures). hand, LRTS dominates PR LRTS approximately
1% problems. leads dominance ratio 81.89.
Table 5: Statistics two algorithms Figure 31.
Algorithm

Convergence planning

Suboptimality



LRTS3(5,0.8,!)

80.03%

55.80%

48.97%

LRTS(3,0.2,!)

19.93%

40.97%

12.2%

Dominance ratio
4.01

Similarly, Figure 31 compares two algorithms respect convergence planning suboptimality final solution. top figure, corresponding plot Figure 29
LRTS3 (5, 0.8, ) shown filled star LRTS(3, 0.2, ) shown hollow star. Percent
points domination individual problems found Table 5. plot bottom left
figure shows PR LRTS lower convergence planning cost LRTS 80%
problems. plot bottom right shows suboptimality solutions algorithms
90

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

produced. PR LRTS optimal LRTS 56% time. Finally, PR LRTS
dominates LRTS 49% problems. Domination way (i.e., LRTS dominates
PR LRTS) happens 12.2% problems. leads dominance ratio 4.01.
several factors influence results. First, high variance difficulty
individual problems due distribution five buckets optimal path distance. Consequently, high variance algorithms trade antagonistic performance measures
problems. case large difference mean values,
Figure 30, dominance average supported dominance majority individual problems. Conversely, small difference mean values (e.g., 2.3% suboptimality algorithms
Figure 31) lead overwhelming dominance level individual problems.
extended analysis pairs algorithms displayed Figures 28, 29. convergence travel first-move lag, dominance ratio varies 5.48 values
infinity averaging 534.32 standard error 123.47. convergence planning
suboptimality, dominance ratio varies 0.79 values infinity averaging 5.16 standard error 1.51. Finally, set 181 algorithms tested
study. Therefore, results viewed approximation actual dominance
relationship among algorithms.

Appendix F. Interaction Abstraction LRTS Parameters
Section 5.2 observed general trends influence abstraction five performance measures. abstraction level adds another dimension parameter space LRTS, previously
defined d, , , natural question four parameters interact. order facilitate
comprehensible visualization paper, reduce LRTS parameter space d, ,
d, setting = (i.e., disabling backtracking LRTS). justified two reasons. First,
recent studies (Bulitko & Lee, 2006; Sigmundarson & Bjornsson, 2006) shown effects
backtracking highly domain-specific.
Table 6 gives overview influence abstraction parameters LRTS qualitative level. detailed analysis five performance measures follows.
important note experiments performed set fixed cost paths fixed size
maps. Consequently, map boundary effects observed higher levels abstraction.
detail contribution below.
Table 6: Influence LRTS parameters impact abstraction. cell table represents impact abstraction either amplified (A) diminished (D) increase
. Lower-case indicate minor effect, - indicates effect.
increase






measure / control parameter
convergence travel
first-move lag
convergence planning
convergence memory
suboptimality

increase





Convergence travel: increasing abstraction level generally decreases convergence travel
LRTS learns smaller abstract maps. Independently, increasing lookahead depth LRTS
91

fiB ULITKO , TURTEVANT, L U , & YAU

Convergence Travel
x 10

x 10

Level 2
Level 0
Optimality Weight

4
3
2
1
0
1
0.8
Optimality Weight

4

Difference Convergence Travel
1

4

2

0.8

1.5

1
0.4

9
0.4
0.2

1

3

0.5

5

0.2

Lookahead Depth

1

Convergence Travel

3
5
Lookahead Depth

9

Difference Convergence Travel
2500

1
Level 4
Level 2
Optimality Weight

6000
4000
2000
0
1
0.8
Optimality Weight

2000

0.8

1500
1000
0.4

500

9
0.4
0.2

1

3

5

0.2

Lookahead Depth

1

3
5
Lookahead Depth

9

Figure 32: Convergence travel: impact abstraction function d, . Top two graphs:
LRTS(d, ) vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).
similar effect (Bulitko & Lee, 2006). Convergence travel lower-bounded doubled optimal
cost start goal (as first trial reveal parts map and, consequently,
cannot final). Therefore, decreasing convergence travel via either two mechanisms diminishes
gains mechanism. effect seen Figure 32 noticeable
gap convergence travel abstractions levels 0 2. lookahead 9,
small difference using abstraction levels 2 4. Thus, increasing lookahead
slightly diminishes effect abstraction (hence table). Increasing increases
convergence travel. higher value , gained using abstraction.
increase amplifies advantage abstraction.
First-move lag generally increases abstraction level lookahead depth.
lookahead depth increases, size corridor used A* search increases well. Thus,
increasing amplifies first-move lag due abstraction, PR LRTS must plan within
lookahead space (within LRTS) inside corridor (within A*) (Figure 33).
Deeper lookahead amplifies impact abstraction. simplified analysis below,
assume map obstacle free leads levels abstraction regular grids
(ignoring boundary effects). length path two points (expressed number
actions) is, thus, decreased factor two abstraction level. assumptions,
total number states PR LRTS touches first move (d2 ) abstract graph
92

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

FirstMove Lag

Difference FirstMove Lag
100

1
Level 2
Level 0

200
Optimality Weight

3000
2000
1000
0
1
0.8
Optimality Weight

300

0.8

400
500
600
700
0.4

800

9
0.4
0.2

1

3

900

5

0.2

Lookahead Depth

1

FirstMove Lag

3
5
Lookahead Depth

9

Difference FirstMove Lag
1

500

Level 4
Level 2
Optimality Weight

4000
3000
2000
1000
0
1
0.8
Optimality Weight

0.8
1000

1500
0.4
2000

9
0.4
0.2

1

3

5

0.2

Lookahead Depth

1

3
5
Lookahead Depth

9

Figure 33: First-move lag: impact abstraction function d, . Top two graphs: LRTS(d, )
vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).
(d 2` ) ground graph. latter quantity simply number edges ground
path computed number edges abstract path (d) multiplied reduction factor
2` . Adding abstraction levels increases first-move lag (d 2`+ ). increase
linear function lookahead depth d. Thus, larger values amplify effect adding extra
abstraction levels.
several points glossed simplified analysis. First, reduction
path length always two-fold assumed above. presence walls, higher levels
abstraction less likely locate merge fully-fledged 4-element cliques. Second, boundaries
abstract graph reached LRTS less moves higher abstraction level.
effectively decreases quantity formula size corridor
reduced generous estimate d2` . Finally, feeding A* longer abstract path often improves
performance analyzed previous section (cf. Figure 22). explains
abstraction level 4 deepening lookahead diminishing returns seen Figure 33.
Optimality weight affect number states touched LRTS abstract level.
hand, change cost resulting A* search different abstract path may
computed LRTS. Overall, however, effect first-move lag impact
abstraction inconsequential (Figure 33).
93

fiB ULITKO , TURTEVANT, L U , & YAU

Convergence Planning

6

Difference Convergence Planning

x 10

1

6

x 10

Level 2
Level 0

2
Optimality Weight

3
2
1
0
1
0.8

0.8
1.5

1
0.4

0.5

9

Optimality Weight

0.4
0.2

1

3

5

0.2

Lookahead Depth

1

Convergence Planning

9

Difference Convergence Planning
25000

1

4

x 10

Level 4
Level 2

20000
Optimality Weight

6
4
2
0
1
0.8
Optimality Weight

3
5
Lookahead Depth

0.8

15000
10000
5000

0.4

0

9
0.4
0.2

1

3

5000

5

0.2

Lookahead Depth

1

3
5
Lookahead Depth

9

Figure 34: Convergence planning: impact abstraction function d, . Top two graphs:
LRTS(d, ) vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).
Convergence planning: abstraction level increases, convergence planning generally
decreases. effect complex, deeper lookahead increases cost
individual planning step, overall decreases planning costs convergence faster. interplay
two trends moderates overall influence seen Figure 34.
effect convergence planning non-trivial. general, lower values reduce
convergence planning cost. Note convergence planning cost product average planning
time per unit distance convergence travel. discussed above, optimality weight
amplifies effects abstraction convergence travel. time, substantially
affect increase planning per move abstraction goes up. Combining two influences,
conclude optimality weight amplify effects abstraction convergence planning.
confirmed empirically Figure 34.
Convergence memory: Abstraction decreases amount memory used convergence fewer states learn. effects convergence travel described above. strong correlation convergence
travel convergence memory previously discussed. Visually Figures 32 35
display similar trends.
Suboptimality: Increasing abstraction level increases suboptimality. plain LRTS, lookahead depth effect suboptimality final solution. However, combine deeper
94

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Convergence Memory

Difference Convergence Memory
1000

1
Level 2
Level 0
Optimality Weight

1500
1000
500
0
1
0.8
Optimality Weight

800

0.8

600
400
0.4
200

9
0.4
0.2

1

3

5

0.2

Lookahead Depth

1

Convergence Memory

3
5
Lookahead Depth

9

Difference Convergence Memory
90

1
Level 4
Level 2

80
Optimality Weight

150
100
50
0
1
0.8
Optimality Weight

70

0.8

60
50
40
30
0.4

20

9
0.4
0.2

1

3

10

5

0.2

Lookahead Depth

1

3
5
Lookahead Depth

9

Figure 35: Convergence memory: impact abstraction function d, . Top two graphs:
LRTS(d, ) vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).

lookahead abstraction suboptimality arising abstraction decreases. deeper lookahead abstract goal state seen earlier making PR LRTS corridor-constrained A*. Additionally,
discussed Section 5.2 Figure 22, refining shorter paths (computed LRTS lower
d) introduces additional suboptimality. suboptimality lower bounded 0%, increasing lookahead diminishes effects abstraction suboptimality (Figure 36) hence Table 6.
Increasing decreases amount suboptimality abstraction used. combined abstraction increasing minor amplification effect difference abstraction
makes (Figure 36) two reasons. First, abstract levels graphs fairly small makes
less difference there. Second, degree suboptimality abstract path translate directly
degree suboptimality resulting ground path A* may still find reasonable
ground path. Thus, influence abstract level overshadowed suboptimaly
introduced process refinement (cf. Figure 21).

95

fiB ULITKO , TURTEVANT, L U , & YAU

Suboptimality (%)

Difference Suboptimality (%)
0

1
Level 2
Level 0

2
Optimality Weight

30
20
10
0
0.2
0.4

5

0.8
1

Optimality Weight

9

3

0.8

4
6
8
10

0.4

12

1
0.2

Lookahead Depth

1

Suboptimality (%)

3
5
Lookahead Depth

9

Difference Suboptimality (%)
0

1
Level 4
Level 2

2
Optimality Weight

30
20
10
0
0.2
0.4

5

0.8
Optimality Weight

1

9

14

3

0.8
4
6
8

0.4

10

1
0.2

Lookahead Depth

1

3
5
Lookahead Depth

9

Figure 36: Suboptimality: impact abstraction function d, . Top two graphs: LRTS(d, )
vs. LRTS2 (d, ). Bottom two graphs: LRTS2 (d, ) vs. LRTS4 (d, ).

96

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

References
Aylett, R., & Luck, M. (2000). Applying artificial intelligence virtual reality: Intelligent virtual
environments. Applied Artificial Intelligence, 14(1), 332.
Bacchus, F., & Yang, Q. (1994). Downward refinement efficiency hierarchical problem
solving.. Artificial Intelligence, 71(1), 43101.
BioWare Corp. (1998). Baldurs Gate., Published Interplay, http://www.bioware.com/bgate/,
November 30, 1998.
Blizzard Entertainment (2002). Warcraft III: Reign Chaos., Published Blizzard Entertainment,
http://www.blizzard.com/war3, July 3, 2002.
Botea, A., Muller, M., & Schaeffer, J. (2004). Near Optimal Hierarchical Path-Finding. Journal
Game Development, 1(1), 728.
Bulitko, V. (2004). Learning adaptive real-time search. Tech. rep. http: // arxiv. org / abs / cs.AI
/ 0407016, Computer Science Research Repository (CoRR).
Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. Journal
Artificial Intelligence Research (JAIR), 25, 119 157.
Bulitko, V., Sturtevant, N., & Kazakevich, M. (2005). Speeding learning real-time search via
automatic state abstraction. Proceedings National Conference Artificial Intelligence (AAAI), pp. 1349 1354, Pittsburgh, Pennsylvania.
Culberson, J., & Schaeffer, J. (1996). Searching pattern databases. CSCI (Canadian AI
Conference), Advances Artificial Intelligence, pp. 402416. Springer-Verlag.
Dini, D. M., van Lent, M., Carpenter, P., & Iyer, K. (2006). Building robust planning execution
systems virtual worlds. Proceedings Artificial Intelligence Interactive Digital
Entertainment conference (AIIDE), pp. 2935, Marina del Rey, California.
Ensemble Studios (1999). Age Empires II: Age Kings., Published Microsoft Game Studios,
http://www.microsoft.com/games/age2, June 30, 1999.
Felner, A., Zahavi, U., Schaeffer, J., & Holte, R. (2005). Dual lookups pattern databases.
Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 103
108, Edinburgh, United Kingdom.
Furcy, D. (2006). ITSA*: Iterative tunneling search A*. Proceedings National
Conference Artificial Intelligence (AAAI), Workshop Heuristic Search, Memory-Based
Heuristics Applications, Boston, Massachusetts.
Furcy, D., & Koenig, S. (2000). Speeding convergence real-time search. Proceedings
National Conference Artificial Intelligence (AAAI), pp. 891897.
Furcy, D., & Koenig, S. (2005). Limited discrepancy beam search. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 125131.
Garey, M. R., & Johnson, D. S. (1990). Computers Intractability; Guide Theory
NP-Completeness. W. H. Freeman & Co., New York, NY, USA.
Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial Intelligence
Research (JAIR), 28, 267297.
97

fiB ULITKO , TURTEVANT, L U , & YAU

Hansen, E. A., Zilberstein, S., & Danilchenko, V. A. (1997). Anytime heuristic search: First results.
Tech. rep. CMPSCI 97-50, Computer Science Department, University Massachusetts.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. IEEE Transactions Systems Science Cybernetics, 4(2), 100107.
Hernandez, C., & Meseguer, P. (2005a). Improving convergence LRTA*(k). Proceedings
International Joint Conference Artificial Intelligence (IJCAI), Workshop Planning
Learning Priori Unknown Dynamic Domains, pp. 6975, Edinburgh, UK.
Hernandez, C., & Meseguer, P. (2005b). LRTA*(k). Proceedings International Joint
Conference Artificial Intelligence (IJCAI), pp. 12381243, Edinburgh, UK.
Holte, R., Mkadmi, T., Zimmer, R. M., & MacDonald, A. J. (1996). Speeding problem solving
abstraction: graph oriented approach. Artificial Intelligence, 85(1-2), 321361.
Holte, R., Perez, M., Zimmer, R., & MacDonald, A. (1995). Hierarchical A*: Searching abstraction
hierarchies efficiently. Tech. rep. tr-95-18, University Ottawa.
id Software (1993). Doom., Published id Software, http://en.wikipedia.org/wiki/Doom, December 10, 1993.
Ishida, T. (1992). Moving target search intelligence. National Conference Artificial
Intelligence (AAAI), pp. 525532.
Ishida, T., & Korf, R. (1991). Moving target search. Proceedings International Joint
Conference Artificial Intelligence (IJCAI), pp. 204210.
Kitano, H., Tadokoro, S., Noda, I., Matsubara, H., Takahashi, T., Shinjou, A., & Shimada, S. (1999).
Robocup rescue: Search rescue large-scale disasters domain autonomous agents
research. Proceedings IEEE Conference Man, Systems, Cybernetics, Vol. 4,
pp. 739743.
Koenig, S. (1999). Exploring unknown environments real-time search reinforcement learning. Proceedings Neural Information Processing Systems, pp. 10031009.
Koenig, S. (2004). comparison fast search methods real-time situated agents. Proceedings Int. Joint Conf. Autonomous Agents Multiagent Systems, pp. 864 871.
Koenig, S., & Likhachev, M. (2002a). D* Lite. Proceedings National Conference
Artificial Intelligence (AAAI), pp. 476483.
Koenig, S., & Likhachev, M. (2002b). Incremental A*. Advances Neural Information Processing Systems (NIPS), pp. 15391546.
Koenig, S. (2001). Agent-centered search. Artificial Intelligence Magazine, 22(4), 109132.
Koenig, S., & Likhachev, M. (2006). Real-time adaptive A*. Proceedings International
Joint Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 281288.
Koenig, S., & Simmons, R. (1998). Solving robot navigation problems initial pose uncertainty
using real-time heuristic search. Proceedings International Conference Artificial
Intelligence Planning Systems, pp. 144 153.
Koenig, S., Tovey, C., & Smirnov, Y. (2003). Performance bounds planning unknown terrain.
Artificial Intelligence, 147, 253279.
98

fiG RAPH BSTRACTION R EAL - TIME H EURISTIC EARCH

Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42(2-3), 189211.
Likhachev, M., Ferguson, D., Gordon, G., Stentz, A., & Thrun, S. (2005). Anytime dynamic A*:
anytime, replanning algorithm. Proceedings International Conference Automated
Planning Scheduling (ICAPS).
Likhachev, M., Gordon, G. J., & Thrun, S. (2004). Ara*: Anytime a* provable bounds suboptimality. Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Advances Neural Information
Processing Systems 16. MIT Press, Cambridge, MA.
Lustrek, M., & Bulitko, V. (2006). Lookahead pathology real-time path-finding. Proceedings
National Conference Artificial Intelligence (AAAI), Workshop Learning Search,
pp. 108114, Boston, Massachusetts.
Mero, L. (1984). heuristic search algorithm modifiable estimate. Artificial Intelligence, 23,
1327.
Orkin, J. (2006). 3 states & plan: AI F.E.A.R. Proceedings Game Developers
Conference (GDC). http://www.jorkin.com/gdc2006 orkin jeff fear.doc.
Pearl, J. (1984). Heuristics. Addison-Wesley.
Pohl, I. (1970). First results effect error heuristic search. Meltzer, B., & Michie, D.
(Eds.), Machine Intelligence, Vol. 5, pp. 219236. American Elsevier, New York.
Pohl, I. (1973). avoidance (relative) catastrophe, heuristic competence, genuine dynamic
weighting computaional issues heuristic problem solving. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 1217.
Pottinger, D. C. (2000). Terrain analysis realtime strategy games. Proceedings Computer
Game Developers Conference. www.gamasutra.com/features/gdcarchive/2000/pottinger.doc.
Rayner, D. C., Davison, K., Bulitko, V., Anderson, K., & Lu, J. (2007). Real-time heuristic search
priority queue. Proceedings International Joint Conference Artificial
Intelligence (IJCAI), pp. 23722377, Hyderabad, India.
Reynolds, C. W. (1987). Flocks, herds schools: distributed behavioral model. SIGGRAPH
87: Proceedings 14th Annual Conference Computer Graphics Interactive Techniques, pp. 2534, New York, NY, USA. ACM Press.
Russell, S., & Wefald, E. (1991). right thing: Studies limited rationality. MIT Press.
Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristic search.
Artificial Intelligence, 146(1), 141.
Shue, L.-Y., Li, S.-T., & Zamani, R. (2001). intelligent heuristic algorithm project scheduling
problems. Proceedings 32nd Annual Meeting Decision Sciences Institute.
Shue, L.-Y., & Zamani, R. (1993). admissible heuristic search algorithm. Proceedings
7th International Symposium Methodologies Intelligent Systems (ISMIS-93), Vol. 689
LNAI, pp. 6975.
Sigmundarson, S., & Bjornsson, Y. (2006). Value Back-Propagation vs. Backtracking RealTime Search. Proceedings National Conference Artificial Intelligence (AAAI),
Workshop Learning Search, Boston, Massachusetts, USA. AAAI Press.
99

fiB ULITKO , TURTEVANT, L U , & YAU

Stenz, A. (1995). focussed D* algorithm real-time replanning. Proceedings
International Joint Conference Artificial Intelligence (IJCAI), pp. 16521659.
Stout, B. (1996). Smart moves: Intelligent pathfinding. Game Developer Magazine, October, 2835.
Sturtevant, N. (2005). HOG - Hierarchical Open Graph. http://www.cs.ualberta.ca/nathanst/hog/.
Sturtevant, N. (2007). Memory-efficient abstractions pathfinding. Proceedings third
conference Artificial Intelligence Interactive Digital Entertainment, pp. 3136, Stanford, California.
Sturtevant, N., & Buro, M. (2005). Partial pathfinding using map abstraction refinement.
Proceedings National Conference Artificial Intelligence (AAAI), pp. 13921397,
Pittsburgh, Pennsylvania.
Sturtevant, N., & Jansen, R. (2007). analysis map-based abstraction refinement.
Proceedings 7th International Symposium Abstraction, Reformulation Approximation, Whistler, British Columbia. (in press).
Sutton, R. (1990). Integrated architectures learning, planning, reacting based approximating dynamic programming. Proceedings Seventh International Conference
Machine Learning, pp. 216224. Morgan Kaufmann.
Thalmann, D., Noser, H., & Huang, Z. (1997). Autonomous virtual actors based virtual sensors.
Lecture Notes Computer Science (LNCS), Creating Personalities Synthetic Actors,
Towards Autonomous Personality Agents, Vol. 1195, pp. 2542. Springer-Verlag, London.
Yahja, A., Stentz, A. T., Singh, S., & Brummit, B. (1998). Framed-quadtree path planning mobile
robots operating sparse environments. Proceedings, IEEE Conference Robotics
Automation, (ICRA), Leuven, Belgium.

100


