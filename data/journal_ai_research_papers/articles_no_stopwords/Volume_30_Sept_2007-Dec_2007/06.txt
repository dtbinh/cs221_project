Journal Artificial Intelligence Research 30 (2007) 565-620

Submitted 3/07; published 12/07

Probabilistic Planning via Heuristic Forward Search
Weighted Model Counting
Carmel Domshlak

DCARMEL @ IE . TECHNION . AC . IL

Technion - Israel Institute Technology,
Haifa, Israel

Jorg Hoffmann

J OERG .H OFFMANN @ DERI .

University Innsbruck, DERI,
Innsbruck, Austria

Abstract
present new algorithm probabilistic planning observability. algorithm,
called Probabilistic-FF, extends heuristic forward-search machinery Conformant-FF problems probabilistic uncertainty initial state action effects. Specifically,
Probabilistic-FF combines Conformant-FFs techniques powerful machinery weighted
model counting (weighted) CNFs, serving elegantly define search space
heuristic function. evaluation Probabilistic-FF shows fine scalability range probabilistic domains, constituting several orders magnitude improvement previous results
area. use problematic case point main open issue addressed
research.

1. Introduction
paper address problem probabilistic planning observability (Kushmerick,
Hanks, & Weld, 1995), known AI planning community conditional (Majercik &
Littman, 2003) conformant (Hyafil & Bacchus, 2004) probabilistic planning. problems
given initial belief state form probability distribution world states W ,
set actions (possibly) probabilistic effects, set alternative goal states WG W .
solution problem single sequence actions transforms system one
goal states probability exceeding given threshold . basic assumption
problem system cannot observed time plan execution. setting
useful controlling systems uncertain initial state non-deterministic actions, sensing
expensive unreliable. Non-probabilistic conformant planning may fail due non-existence
plan achieves goals 100% certainty. Even plan, plan
necessarily contain information actions useful achieve requested
threshold .
state-of-the-art performance probabilistic planners advancing much slowly
deterministic planners, scaling 5-10 step plans problems 20 world states
15-20 step plans problems 100 world states (Kushmerick et al., 1995; Majercik &
Littman, 1998; Hyafil & Bacchus, 2004). Since probabilistic planning inherently harder
deterministic counterpart (Littman, Goldsmith, & Mundhenk, 1998), difference evolution
rates surprising. However, recent developments area (Onder, Whelan, & Li,
2006; Bryce, Kambhampati, & Smith, 2006; Huang, 2006), particular work here, show
dramatic improvements probabilistic planning obtained.
c
2007
AI Access Foundation. rights reserved.

fiD OMSHLAK & H OFFMANN

paper introduce Probabilistic-FF, new probabilistic planner based heuristic forward search space implicitly represented probabilistic belief states. planner natural
extension recent (non-probabilistic) conformant planner Conformant-FF (Hoffmann & Brafman, 2006). main trick replace Conformant-FFs SAT-based techniques recent
powerful technique probabilistic reasoning weighted model counting (WMC) propositional CNFs (Sang, Beame, & Kautz, 2005). detail, Conformant-FF forward search
belief space belief state corresponds set world states considered
possible. main trick Conformant-FF use CNF formulas implicit representation belief states. Implicit, context, means formulas (a) encode semantics
executing action sequence initial belief state, propositional variables corresponding
facts time-stamps. actual knowledge belief states (and be) inferred
formulas. particularly, fact p known true belief state
(a) p(m), time endpoint formula. knowledge computed
Conformant-FF belief states known facts, well (symmetrically) facts
known false. suffices STRIPS-style planning, is, determine applicable
actions goal belief states. heuristic function, FFs (Hoffmann & Nebel, 2001) relaxed
planning graph technique enriched approximate SAT reasoning.
basic ideas underlying Probabilistic-FF are:
(i) Define time-stamped Bayesian networks (BNs) describing probabilistic belief states.
(ii) Extend Conformant-FFs belief state CNFs model BNs.
(iii) addition SAT reasoning used Conformant-FF, use weighted model-counting
determine whether probability (unknown) goals belief state high enough.
(iv) Introduce approximate probabilistic reasoning Conformant-FFs heuristic function.
Note synergetic effect: Probabilistic-FF re-uses Conformant-FFs technology recognize
facts true false probability 1. fully serves determine applicable actions,
well detect whether part goal already known. fact, Conformant-FFs CNFbased techniques specifically made suit probabilistic setting: without probabilities
one could imagine successfully replacing CNFs BDDs, probabilities seems much
problematic.
algorithms present cover probabilistic initial belief states given Bayesian networks,
deterministic probabilistic actions, conditional effects, standard action preconditions.
experiments show approach quite effective range domains. contrast
SAT CSP based approaches mentioned (Majercik & Littman, 1998; Hyafil & Bacchus,
2004), Probabilistic-FF find 100-step plans problem instances billions world states.
However, comparison entirely fair due different nature results provided;
SAT CSP based approaches provide guarantees length solution. approach
closely related Probabilistic-FF implemented POND (Bryce et al., 2006): system,
Probabilistic-FF, conformant probabilistic planning threshold , using non-admissible,
planning-graph based heuristic guide search. Hence comparison Probabilistic-FF
POND fair, experiments perform comparative evaluation Probabilistic-FF
POND. two approaches related, significant differences search
566

fiP ROBABILISTIC -FF

space representation, well definition computation heuristic function.1 run
two approaches range domains partly taken probabilistic planning literature,
partly obtained enriching conformant benchmarks probabilities, partly obtained
enriching classical benchmarks probabilistic uncertainty. almost cases, Conformant-FF
outperforms POND least order magnitude. make interesting observations
regarding behavior two planners; particular identify domain derived
classical Logistics domain approaches fail scale. apparent reason neither
approach good enough detecting many times, early point plan, probabilistic
action must applied order sufficiently support high goal threshold end plan.
Devising methods better regard pressing open issue line work.
paper structured follows. next section provides technical background, formally
defining problem address illustrating running example. Section 3 details
probabilistic belief states represented time-stamped Bayesian networks, Bayesian
networks encoded weighted CNF formulas, necessary reasoning performed
representation. Section 4 explains illustrates extension Conformant-FFs heuristic function probabilistic settings. Section 5 provides empirical results, Section 6
concludes. proofs moved Appendix A.

2. Background
probabilistic planning framework consider adds probabilistic uncertainty subset
classical ADL language, namely (sequential) STRIPS conditional effects. STRIPS
planning tasks described set propositions P triples (A, I, G), corresponding
action set, initial world state, goals. G sets propositions, describes
concrete initial state wI , G describes set goal states w G. Actions pairs
(pre(a), E(a)) precondition (conditional) effects. conditional effect e triple
(con(e), add(e), del(e)) (possibly empty) proposition sets, corresponding effects condition, add, delete lists, respectively. precondition pre(a) proposition set,
action applicable world state w w pre(a). applicable w,
result applying w undefined. applicable w, conditional effects
e E(a) w con(e) occur. Occurrence conditional effect e w results world
state w add(e) \ del(e).
action applied w, proposition q q add(e) del(e )
(possibly same) occurring e, e E(a), result applying w undefined. Thus,
require actions self-contradictory, is, A, every e, e E(a),
exists world state w con(e) con(e ), add(e) del(e ) = . Finally, action
sequence plan world state results iterative execution actions, starting
wI , leads goal state w G.
2.1 Probabilistic Planning
probabilistic planning setting extends (i) probabilistic uncertainty
initial state, (ii) actions probabilistic effects. general, probabilistic planning
1. POND use implicit belief states, probabilistic part heuristic function uses sampling techniques,
rather probabilistic reasoning techniques employ.

567

fiD OMSHLAK & H OFFMANN

tasks quadruples (A, bI , G, ), corresponding action set, initial belief state, goals,
acceptable goal satisfaction probability. before, G set propositions. initial state
longer assumed known precisely. Instead, given probability distribution
world states, bI , bI (w) describes likelihood w initial world state.
Similarly classical planning, actions pairs (pre(a), E(a)), effect set E(a)
richer structure semantics. e E(a) pair (con(e), (e)) propositional condition set probabilistic outcomes. probabilistic outcome (e)
triplet (P r(), add(), del()), add delete lists before, P r() probability outcome occurs result effect e. Naturally,
P require probabilistic effects
define probability distributions outcomes, is, (e) P r() = 1. special case
deterministic effects e modeled way via (e) = {} P r() = 1. Unconditional actions
modeled single effect e con(e) = . before, applicable w,
result applying w undefined. Otherwise, applicable w, exists
exactly one effect e E(a) con(e) w, (e), applying w results
w add() \ del() probability P r(). likelihood [b, a] (w ) world state w
belief state [b, a], resulting applying probabilistic action b, given
[b, a] (w ) =

X

wpre(a)

b(w)

X

(e)


P r() w = w \ , add(), del() ,

(1)

e effect con(e) w, () Kronecker step function takes
value 1 argument predicate evaluates TRUE, 0 otherwise.
formalism covers problem-description features supported previously proposed
formalisms conformant probabilistic planning (Kushmerick et al., 1995; Majercik & Littman,
1998; Hyafil & Bacchus, 2004; Onder et al., 2006; Bryce et al., 2006; Huang, 2006), corresponds called Unary Nondeterminism (1ND) normal form (Rintanen, 2003). note
succinct forms specifying probabilistic planning problems (Rintanen, 2003),
yet 1ND normal form appears intuitive perspective knowledge engineering.
Example 1 Say robot block physically one two locations.
information captured propositions r1 , r2 robot, b1 , b2 block, respectively. robot either move one location another, carrying block.
robot moves without block, move guaranteed succeed. provides us
pair symmetrically defined deterministic actions {move-right, move-lef t}. action move-right empty precondition, single conditional effect e = ({r1 }, {})
P r() = 1, add() = {r2 }, del() = {r1 }. robot tries move carrying block,
move succeeds probability 0.7, probability 0.2 robot ends moving
without block, probability 0.1 move robot fails completely. provides us
pair (again, symmetrically defined) probabilistic actions {move-b-right, move-b-lef t}.
action move-b-right empty precondition, two conditional effects specified
Table 1.
specified semantics structure components (A, bI , G, ) ,
ready specify actual task probabilistic planning setting. Recall actions
transform probabilistic belief states belief states. action sequence , belief
568

fiP ROBABILISTIC -FF

E(a)

con(e)

e

r1 b 1

e

r1 b1

(e)

P r()

add()

del()

1
2
3
1

0.7
0.2
0.1
1.0

{r2 , b2 }
{r2 }



{r1 , b1 }
{r1 }



Table 1: Possible effects outcomes action move-b-right Example 1.
state b, new belief state [b, a] resulting applying b given


= hi
b,
[b, a] = [b, a] ,
.
= hai,





[[b, a] , ] , = hai , A, 6=

(2)

setting, achieving G certainty typically unrealistic. Hence, specifies required
lower bound probability achieving G. sequence actions called plan
ba (G) belief state ba = [bI , a].
2.2 Specifying Initial Belief State
Considering initial belief state, practical considerations force us limit attention
compactly representable probability distributions bI . numerous alternatives
compact representation structured probability distributions, Bayes networks (BNs) (Pearl, 1988)
date far popular representation model.2 Therefore, Probabilistic-FF
assume initial belief state bI described BN NbI set propositions P.
excellent introductions BNs abound (e.g., see Jensen, 1996), suffices briefly
define notation. BN N = (G, ) represents probability distribution directed acyclic
graph G, set nodes X stands random variables (assumed discrete paper),
, set tables conditional probabilities (CPTs)one table TX node X X .
possible value x Dom(X) (where Dom(X) denotes domain X), table TX
lists probability event X = x given possible value assignment immediate
ancestors (parents) P a(X) G. Thus, table size exponential in-degree X. Usually,
assumed either in-degree small (Pearl, 1988), probabilistic dependence X
P a(X) induces significant local structure allowing compact representation TX (Shimony,
1993, 1995; Boutilier, Friedman, Goldszmidt, & Koller, 1996). (Otherwise, representation
distribution BN would good idea first place.) joint probability complete
assignment variables X given product |X | terms taken respective
CPTs (Pearl, 1988):


P r ([X] | [P a(X)]) =
TX ([X] | [P a(X)]) ,
P r() =
XX

XX

[] stands partial assignment provided corresponding subset X .
2. BNs choice here, framework support models well, e.g. stochastic decision trees.

569

fiD OMSHLAK & H OFFMANN

Probabilistic-FF allow NbI described multi-valued variables underlying
planning problem. significantly simplifies process specifying NbI since STRIPS
3
propositions P
Sknot correspond true random variables underlying problem specification.
Specifically, let i=1 Pi partition P proposition set Pi uniquely corresponds
domain multi-valued variable underlying problem. is, every world state w
every Pi , |Pi | > 1, exactly one proposition q Pi holds w. variables
BN NbI describing initial belief state bI X = {X1 , . . . , Xk }, Dom(Xi ) = Pi
|Pi | > 1, Dom(Xi ) = {q, q} Pi = {q}.
Example 2 illustration NbI , consider running example, say robot
known initially one two possible locations probability P r(r1 ) = 0.9
P r(r2 ) = 0.1. Suppose correlation belief initial locations robot
block. believe that, robot r1 , P r(b1 ) = 0.7 (and P r(b2 ) = 0.3),
robot r2 , P r(b1 ) = 0.2 (and P r(b2 ) = 0.8). initial belief state BN NbI defined
two variables R (robot) B (block) Dom(R) = {r1 , r2 } Dom(B) = {b1 , b2 },
respectively, depicted Figure 1.
r1
0.9

r2
0.1

R

// B

r1
r2

b1
0.7
0.2

b2
0.3
0.8

Figure 1: Bayes network NbI Example 1.
hard see STRIPS-style actions equivalently specified terms
multi-valued variables X . Specifically, |Pi | > 1, action add proposition
q Pi without deleting proposition q Pi , thus, consider setting
Xi = q. |Pi | = 1, adding deleting q Pi standard semantics setting Xi = q
Xi = q, respectively. simplicity presentation, assume actions selfcontradictory level X wellif two conditional effects e, e E(a) possibly occur
world state w, subsets X affected two effects disjoint. Finally,
goal G directly corresponds partial assignment X (unless G self-contradictory,
requiring q q q, q Pi .)

3. Belief States
section, explain representation of, reasoning about, belief states. first explain
probabilistic belief states represented time-stamped BNs, explain
BNs encoded reasoned form weighted CNF formulas. representation
belief states weighted CNFs illustrated belief state running example
Figure 2. finally provide details works Probabilistic-FF.
3. Specifying NbI directly P would require identifying multi-valued variables anyway, followed connecting
propositions corresponding multi-valued variable complete DAG, normalizing CPTs
propositions certain manner.

570

fiP ROBABILISTIC -FF

1 2
r
3 1 1
r2

r1 r2
0.9 0.1
R(0)



B(0)

II
II
II
II
II
$$
::
uu
uu
u
u
uu
uu

b1 b2
r1 0.7 0.3
r2 0.2 0.8

Y(1)

r1
0
1
0

r2
1
0
1

// R
n66 (1)
n
n
nnn
nnn
n
n
1 2 3 1
nn
nnn
r1 b1 0.7 0.2 0.1 0
PPP
PPP
0 0 0 1
PPP othrw
PPP
PPP
P((
// B(1)

b1 b2
1
0 1
b 1 0
1 1
b2 0 1

r1 r2
r1 1 0
r2 1 0
// R(2)

// B(2)

b1 b2
b1 1 0
b2 0 1

Figure 2: Bayes network Nba running Example 1-2 action sequence
= hmove-b-right, move-lef ti.

3.1 Bayesian Networks
Probabilistic-FF performs forward search space belief states. search states belief
states (that is, probability distributions world states w), search restricted belief
states reachable initial belief state bI sequences actions a. key decision
one make actual representation belief states. Let bI initial belief state
captured BN NbI , let ba belief state resulting applying bI sequence
actions a. One well-known problems area decision-theoretic planning
description ba directly state variables X becomes less less structured number
(especially stochastic) actions increases. overcome limitation, represent belief
states ba BN Nba explicitly captures sequential application starting bI , trading
representation size cost inference, compared representing belief states directly
distributions world states. formally specify structure BN Nba , assuming
actions applicable corresponding belief states application, later
showing Probabilistic-FF makes sure indeed case. note belief-state
BNs similar spirit structure proposed AI literature verifying
probabilistic plan achieves goals certain probability (Dean & Kanazawa, 1989; Hanks &
McDermott, 1994; Kushmerick et al., 1995).
Figure 2 illustrates construction Nba running example = hmove-b-right,
move-lef ti. general, let = ha1 , . . . , sequence actions, numbered according
appearance a. 0 m, let X(t) replica state variables X , X(t) X(t)
571

fiD OMSHLAK & H OFFMANN

corresponding X X . variable set Nba union X(0) , . . . , X(m) , plus
additional variables introduce actions a.
First, X(0) X(0) , set parents P a(X(0) ) conditional probability tables
TX(0) simply copy state variable X NbI . Now, consider action a,
let = a. action introduce discrete variable Y(t)
mediates
variable layers X(t1) X(t) . domain Y(t) set Dom(Y(t) ) = eE(a) (e), is,
union probabilistic outcomes possible effects a. parents Y(t) Nba set
P a(Y(t) ) =

[

eE(a)


X(i1) | con(e) Dom(X) 6= ,

(3)

and, Dom(P a(Y(t) )), set
TY (t) (Y(i)

(
P r(),
= | ) =
0,

con (e())
,
otherwise

(4)

e() denotes effect e (e).
refer set variables Y(t) created actions Y. Now, let EX (a)
E(a) probabilistic effects affect variable X X . EX (a) = , set
P a(X(t) ) = {X(t1) },
(
1, x = x ,
.
(5)
TX(t) (X(t) = x | X(t1) = x ) =
0, otherwise
Otherwise, EX (a) 6= , let x Dom(X) value provided X (e), e EX (a).
Recall outcomes effects E(a) mutually exclusive. Hence, set P a(X(t) ) =
{X(t1) , Y(t1) },



TX(i) (X(i) = x | X(i1) = x , Y(i1)



1,
= ) = 1,


0,

e() EX (a) x = x ,
e() 6 EX (a) x = x , ,
otherwise

(6)

e() denotes effect responsible outcome .
hard verify Equations 4-6 capture frame axioms probabilistic semantics ourSactions. principle, accomplishes construction Nba variables
Xba =
t=0 X(t) . note, however, mediating variable Y(t) really needed
truly probabilistic actions. Specifically, deterministic action a, let EX (a) E(a)
conditional effects add and/or delete propositions associated domain variable X X . EX (a) = , set P a(X(t) ) = {X(t1) }, TX(t) according Equation 5.
Otherwise, set

[n

P a(X(t) ) = {X(t1) }
X(t1)
| con(e) Dom(X) 6= ,
(7)
eEX (a)

specify TX(t) follows. Let xe Dom(X) value (the deterministic outcome
of) effect e EX (a) provides X. Dom(P a(X(t) )), exists e EX (a)
572

fiP ROBABILISTIC -FF

con(e) , set
TX(t) (X(t)

(
1,
= x | ) =
0,

x = xe ,
otherwise

(8)

x = [X(t1) ],
otherwise

(9)

Otherwise, set
TX(t) (X(t)

(
1,
= x | ) =
0,

Due self-consistency action, hard verify Equations 8-9 consistent,
and, together Equation 5, capture semantics conditional deterministic actions.
special treatment deterministic actions illustrated Figure 2 direct dependencies
X(2) X(1) .
Proposition 1 Let (A, NbI , G, ) probabilistic planning problem, m-step sequence
actions applicable bI . Let P r joint probability distribution induced Nba
variables Xba . belief state ba corresponds marginal distribution P r X(m) , is:
ba (X ) = P r(X(m) ), G(m) partial assignment provided G X(m) , probability
ba (G) achieves G starting bI equal P r(G(m) ).
already mentioned, belief-state BNs constructed along principles outlined
used Dean Kanazawa (1989), Hanks McDermott (1994), Kushmerick et al.
(1995), thus correctness Proposition 1 immediate previous results.
point, worth bringing attention fact variables X(1) , . . . , X(m) completely
deterministic. Moreover, CPTs variables Nba compactly representable due
either low number parents, local structure induced large amount context-specific
independence, both. compactness CPTs Nba implied compactness
STRIPS-style specification planning actions. exploiting compactness action
specification, size Nba description kept linear size input
number actions a.
Proposition 2 Let (A, NbI , G, ) probabilistic planning problem described k state variables, m-step sequence actions A. Then, |Nba | = O(|NbI |+m(k+1))
largest description size action A.
proof Proposition 2, well proofs formal claims paper, relegated
Appendix A, pp. 613.
3.2 Weighted CNFs
Given representation belief states BNs, next select mechanism reasoning
BNs. general, computing probability query BNs known #Pcomplete (Roth, 1996). addition, hard verify, using analysis similar ones
Darwiche (2001) Brafman Domshlak (2006), networks arising work
typically exhibit large tree-width. numerous exact algorithms inference BNs
proposed literature (Darwiche, 2000; Dechter, 1999; Zhang & Poole, 1994),
classical algorithms scale well large networks exhibiting high tree-width. positive
573

fiD OMSHLAK & H OFFMANN

side, however, observation guides recent advances area probabilistic reasoning
real-world domains typically exhibit significant degree deterministic dependencies
context-specific independencies problem variables. Targeting property practical
BNs already resulted powerful inference techniques (Chavira & Darwiche, 2005; Sang et al.,
2005). general principle underlying techniques
(i) Compile BN N weighted propositional logic formula (N ) CNF,
(ii) Perform efficient weighted model counting (N ) reusing (and adapting) certain
techniques appear powerful enhancing backtracking DPLL-style search SAT.
One observation early stages developing Probabilistic-FF type
networks type queries problems make machinery solving BNs
weighted CNF model counting attractive needs. First, Section 3.1 already
shown BNs representing belief states exhibit large amount deterministic nodes
context-specific independence. Second, queries interest correspond computing
probability evidence G(m) Nba , type query clear interpretation terms
model counting (Sang et al., 2005). Hence, taking route Probabilistic-FF, compile
belief state BNs weighted CNFs following encoding scheme proposed Sang et al. (2005),
answer probabilistic queries using Cachet (Sang, Bacchus, Beame, Kautz, & Pitassi, 2004), one
powerful systems date exact weighted model counting CNFs.
general, weighted CNFs weights formulas specified follows. Let
V = {V1 , . . . , Vn } set propositional variables Dom(Vi ) = {vi , vi }, let :

0+ non-negative, real-valued weight function literals V.
Dom(Vi ) R
partial assignment V,Q
weight () assignment defined product literals
weights, is, () = l (l). Finally, propositional logic formula called weighted
defined weighted set propositional variables. weighted formula V,
weight () defined sum weights complete assignments V satisfying
, is,
X
() =
() ( |= ),
Dom(V)

Dom(V) = Dom(Vi ). instance, variables Vi (vi ) = (vi ) = 1,
() simply stands number complete assignments V satisfy .
Given initial belief state BN NbI , sequence actions = ha1 , . . . , applicable
bI , describe weighted CNF encoding (Nba ) (or (ba ), short) belief state
ba built used Probabilistic-FF. First, formally specify generic scheme introduced
Sang et al. (2005) encoding BN N variables X weighted CNF (N ).
encoding formula (N ) contains two sets variables. First, variable Z X
value z Dom(Z), formula (N ) contains state proposition literals {z, z}, weighted
(z) = (z) = 1. state propositions act (ba ) regular SAT propositions. Now,
variable Z Xba , let Dom(Z) = {z1 , . . . , zk } arbitrary fixed ordering Dom(Z).
Recall row TZ [i] CPT Z corresponds assignment (or set assignments) P a(Z). Thus, number rows TZ upper bounded number different
assignments P a(Z), (as happens case) significantly lower dependence Z P a(Z) induces substantial local structure. Following ordering Dom(Z)
above, entry TZ [i, j] contains conditional probability P r(zj | ). every CPT entry
574

fiP ROBABILISTIC -FF

procedure basic-WMC()
= return 1
empty clause return 0
select variable V
return basic-WMC(|v ) (v) + basic-WMC(|v ) (v)
Figure 3: Basic DPPL-style weighted model counting.
TZ [i, j] last one (i.e., TZ [i, k]), formula (N ) contains chance proposition literals
{hzji i, hzji i}. chance variables aim capturing probabilistic information CPTs
Nba . Specifically, weight literal hzji set P r(zj | , z1 , . . . , zj1 ),
conditional probability entry true, given row true, prior entry row
true:
TZ [i, j]
Pj1
1 k=1 TZ [i, k]



hzj = 1 hzji

hzji =

(10)

Considering clauses (N ), variable Z X , CPT entry TZ [i, j],
formula (N ) contains clause


hz1i hzj1
hzji zj ,
(11)

conjunction literals forming assignment Dom(P a(Z)). clauses
ensure weights complete assignments variables (N ) equal probability corresponding atomic events postulated BN N . illustrate construction
Equations 10-11, let boolean variables B parents ternary variable C (with
Dom(C) = {C1 , C2 , C3 }) BN, let P r(C1 |A, B) = 0.2, P r(C2 |A, B) = 0.4,
P r(C3 |A, B) = 0.4. Let raw corresponding assignment A, B P a(C) i-th
row CPT TC . encoding BN, first two entries raw TC captured
pair respective chance propositions
hC1i i, hC2i i. According
Equation 10, weights


0.4


propositions set hC1 = 0.2, hC1 = 10.2 = 0.5. Then, according
Equation 11, encoding contains three clauses

B hC1i C1

B hC1i hC2i C2

B hC1i hC2i C3

Finally, variable Z X , formula (N ) contains standard set clauses encoding
exactly one relationship state propositions capturing value Z. accomplishes encoding N (N ). next Section 3.3 illustrate encoding
belief state BN running example.
weighted CNF encoding (ba ) belief state BN Nba provides input weighted
model counting procedure. simple recursive DPPL-style procedure basic-WMC underlying Cachet (Sang et al., 2004) depicted Figure 3, formula |v obtained setting
575

fiD OMSHLAK & H OFFMANN

literal v true. Theorem 3 Sang et al. (2005) shows weighted CNF encoding
BN N , P r(Q|E) general query respect N , query Q, evidence E,
have:
basic-WMC( Q E)
P r(Q|E) =
,
(12)
basic-WMC( E)
query Q evidence E fact arbitrary formulas propositional logic. Note that,
special (and relevant us) case empty evidence, Equation 12 reduces P r(Q) =
basic-WMC(Q), is, single call basic-WMC procedure. Corollary 3 immediate
Proposition 1 Theorem 3 Sang et al. (2005).
Corollary 3 Let (A, bI , G, ) probabilistic planning task BN NbI describing bI ,
m-step sequence actions applicable bI . probability ba (G) achieves G starting
bI given by:
ba (G) = WMC ((ba ) G(m)) ,
(13)
G(m) conjunction goal literals time-stamped time endpoint a.
3.3 Example: Weighted CNF Encoding Belief States
illustrate generic BN-to-WCNF encoding scheme Sang et al. (2005) belief
state BN Nba running example Figure 2.
0 2, introduce time-stamped state propositions r1 (i), r2 (i), b1 (i), b2 (i). Likewise,
introduce four state propositions 1 (1), 2 (1), 3 (1), 1 (1) corresponding values
variable Y(1) . first set clauses (ba ) ensure exactly one relationship
state propositions capturing value variable Nba :

1 (1) 2 (1) 3 (1) 1 (1) ,

1i<j4 :

(yi (1) yj (1)) ,
0i2 :

(14)

(r1 (i) r2 (i)) , (r1 (i) r2 (i))
(b1 (i) b2 (i)) , (b1 (i) b2 (i))
proceed encoding CPTs Nba . root nodes one row
CPTs chance propositions identified corresponding state variables (Sang
et al., 2005). Hence, root variable R(0) need neither additional clauses special
chance propositions, state proposition r1 (0) (ba ) treated chance proposition
(r1 (0)) = 0.9.
Encoding variable B(0) bit involved. CPT TB(0) contains two (content-wise
different) rows corresponding given r1 given r2 cases, cases induce
non-deterministic dependence B(0) R(0) . encode content TB(0) introduce
two chance variables hb1 (0)1 hb1 (0)2 (hb1 (0)1 i) = 0.7 (hb1 (0)2 i) = 0.2.
positive literals hb1 (0)1 hb1 (0)2 capture events b1 given r1 b1 given r2 ,
negations hb1 (0)1 hb1 (0)2 capture complementary events b2 given r2 b2
given r2 , respectively. consider given r1 row TB(0) . encode row, need
576

fiP ROBABILISTIC -FF



(ba ) contain r1 (0) hb1 (0)1 b1 (0) r1 (0) hb1 (0)1 b2 (0). Similar encoding
required row given r2 , thus encoding TB 0 introduces four additional clauses:


r1 (0) hb1 (0)1 b1 (0) , r1 (0) hb1 (0)1 b2 (0)


(15)
r2 (0) hb1 (0)2 b1 (0) , r2 (0) hb1 (0)2 b2 (0)

finished NbI part Nba , proceed encoding variable Y(1) corresponding probabilistic action move-b-right. encode first row TY(1) introduce three chance propositions h1 (1)1 i, h2 (1)1 i, h3 (1)1 i; general, chance variables needed last entries CPT rows. weights chance propositions
0.2
= 0.6(6),
set according Equation 10 h1 (1)1 = 0.7, h2 (1)1 = 10.7

0.1
1
h3 (1) = 10.9 = 0.1. Using chance propositions, add (ba ) four clauses
Equation 11, notably first four clauses Equation 16 below.
Proceeding second row TY(1) , observe value R(0) B(0) case fully
determines value Y(1) . deterministic dependence encoded without using
chance propositions using last two clauses Equation 16.

r1 (0) b1 (0) h1 (1)1 1 (1) ,

r1 (0) b1 (0) h1 (1)1 h2 (1)1 2 (1) ,

r1 (0) b1 (0) h1 (1)1 h2 (1)1 h3 (1)1 3 (1) ,
(16)

r1 (0) b1 (0) h1 (1)1 h2 (1)1 h3 (1)1 1 (1) ,


r1 (0) 1 (1) , b1 (0) 1 (1)

Using state/chance variables introduced R0 , B 0 , Y(1) , encode CPTs R(1)
B(1) as:
R(1) : (1 (1) r2 (1)) , (2 (1) r2 (1)) ,

(3 (1) r1 (0) r1 (1)) , 1 (1) r1 (0) r1 (1) ,

(3 (1) r1 (0) r1 (1)) , 1 (1) r2 (0) r2 (1)

B(1) : (1 (1) b2 (1)) ,

(17)

(1 (1) b1 (0) b1 (1)) ,
(1 (1) b2 (0) b2 (1))
Since CPTs R(1) B(1) completely deterministic, encoding well using
chance propositions. Finally, encode (deterministic) CPTs R(2) B(2) as:
R(2) : (r1 (2))
B(2) : (b1 (1) b1 (2))

(18)

(b2 (1) b2 (2))
unary clause (r1 (2)) reduction (r1 (1) r1 (2)) (r2 (1) r1 (2)). accomplishes encoding (ba ).
577

fiD OMSHLAK & H OFFMANN

3.4 Conformant-FF Probabilistic-FF
Besides fact weighted model counting attractive kinds BNs arising context, weighted CNF representation belief states works extremely well ideas underlying Conformant-FF (Hoffmann & Brafman, 2006). outlined introduction already;
give details.
stated, Conformant-FF forward search non-probabilistic belief space
belief state corresponds set world states considered possible. main trick
Conformant-FF use CNF formulas implicit representation belief states,
formulas (a) encode semantics executing action sequence initial belief state. Facts
known true false inferred formulas. computation partial
knowledge constitutes lazy kind belief state representation, comparison approaches
use explicit enumeration (Bonet & Geffner, 2000) BDDs (Bertoli, Cimatti, Pistore, Roveri,
& Traverso, 2001) fully represent belief states. basic ideas underlying Probabilistic-FF are:
(i) Define time-stamped Bayesian Networks (BN) describing probabilistic belief states (Section 3.1 above).
(ii) Extend Conformant-FFs belief state CNFs model BN (Section 3.2 above).
(iii) addition SAT reasoning used Conformant-FF, use weighted model-counting
determine whether probability (unknown) goals belief state high enough
(directly below).
(iv) Introduce approximate probabilistic reasoning Conformant-FFs heuristic function (Section 4 below).
detail, given probabilistic planning task (A, bI , G, ), belief state ba corresponding
applicable bI m-step action sequence a, proposition q P, say q known
ba ba (q) = 1, negatively known ba ba (q) = 0, unknown ba , otherwise. begin
determining whether q known, negatively known, unknown time m. Re-using
Conformant-FF machinery, classification requires two SAT tests (ba ) q(m)
(ba ) q(m), respectively. information provided classification used threefold. First,
subgoal g G negatively known time m, ba (G) = 0. extreme,
subgoals G known time m, ba (G) = 1. Finally, subgoals
G known rest unknown time m, accomplish evaluating belief state ba
testing whether
ba (G) = WMC ((ba ) G(m)) .

(19)

Note sets (positively/negatively) known propositions time steps
allows us significantly simplify CNF formula (ba ) G(m) inserting
corresponding values known propositions.
evaluating considered action sequence a, get ba (G) , done.
Otherwise, forward search continues, actions applicable ba (and thus used
generate successor belief states) actions whose preconditions known ba .
578

fiP ROBABILISTIC -FF

4. Heuristic Function
key component heuristic search procedure heuristic function. quality (informedness) computational cost function determine performance search.
heuristic function usually obtained solutions relaxation actual problem interest (Pearl, 1984; Russell & Norvig, 2004). classical planning, successful idea
use relaxation ignores delete effects actions (McDermott, 1999; Bonet & Geffner,
2001; Hoffmann & Nebel, 2001). particular, heuristic planning system based
notion relaxed plan, plan achieves goals assuming delete
lists actions empty. relaxed plan computed using Graphplan-style (Blum & Furst,
1997) technique combining forward chaining graph construction phase backward chaining
plan extraction phase. heuristic value h(w) provides world state w encountered
search length relaxed plan w. Conformant-FF, methodology
extended setting conformant planning initial state uncertainty (without uncertainty
action effects). Herein, extend Conformant-FFs machinery handle probabilistic initial
states effects. Section 4.1 provides background techniques used ConformantFF, Sections 4.2 4.4 detail algorithms forward backward chaining phases
Probabilistic-FF, respectively. algorithms two phases Probabilistic-FF heuristic
computation illustrated running example Sections 4.3 4.5, respectively.
4.1 Conformant-FF
specify relaxed plans computed FF; provide coarse sketch
computed Conformant-FF. purpose latter slowly prepare reader
come: Conformant-FFs techniques re-used Probabilistic-FF anyway, hence
described full detail part Sections 4.2 4.4.
Formally, relaxed plans classical planning computed follows. Starting w,
builds relaxed planning graph sequence alternating proposition layers P (t) action
layers A(t), P (0) w, A(t) set actions whose preconditions
contained P (t), P (t + 1) obtained P (t) including add effects (with fulfilled
conditions) actions A(t). is, P (t) always contains facts true one
would execute (the relaxed versions of) actions earlier layers A(t 1). relaxed
planning graph constructed either reaches propositional layer P (m) contains
goals, construction reaches fixpoint P (t) = P (t + 1) without reaching goals.
latter case corresponds (all) situations relaxed plan exist,
existence relaxed plan necessary condition existence real plan, state w
excluded search space setting h(w) = . former case G P (m), relaxed
plan subset actions A(1), . . . , A(m) suffices achieve goals (under ignoring
delete lists), extracted simple backchaining loop: goal P (m), select
action A(1), . . . , A(m) achieves goal, iterate process considering
actions preconditions respective effect conditions new subgoals. heuristic estimate
h(w) set length extracted relaxed plan, is, number actions selected
backchaining process.
Aiming extending machinery conformant planning, Conformant-FF, Hoffmann Brafman (2006) suggested extend relaxed planning graph additional fact layers (t) containing facts unknown time t, reason unknown
579

fiD OMSHLAK & H OFFMANN

facts become known relaxed planning graph. complexity type reasoning
prohibitive, Conformant-FF relaxes planning task ignoring delete lists,
one unknown conditions action effect. is, action appears
layer A(t), effect e con(e) P (t) (t) con(e) (t) 6= ,
con(e) (t) arbitrarily reduced contain exactly one literal, reasoning done
con(e) reduced form beginning.
V
relaxation converts implications ( ccon(e)uP (t) c(t)) q(t + 1) action effects
induce unknown propositions 2-projections take form binary implications c(t) q(t + 1), arbitrary c con(e) (t). Due layered structure
planning graph, set binary implications c(t) q(t + 1) seen forming
directed acyclic graph Imp. given relaxations, graph captures exactly dependencies truth propositions time. Hence, checking whether proposition q becomes
known time done follows. First, backchain implication edges Imp end
q(t), collect set support(q(t)) leafs4 reached. Then, CNF formula
describing possible initial states, test SAT check whether
_

l
lsupport(q(t))

test succeed least one leafs support(q(t)) true every possible
initial state. given relaxations, case if, applying actions
relaxed planning graph, q always true time t.5
process extracting relaxed plan constructed conformant relaxed planning
graph extension FFs respective process machinery selects actions responsible
relevant paths Imp. overall Conformant-FF heuristic machinery sound complete
relaxed tasks, yields heuristic function highly informative across range challenging
domains (Hoffmann & Brafman, 2006).
work, adopt Conformant-FFs relaxations, ignoring delete lists action effects, well one propositions effects condition. Accordingly, adopt
following notations Conformant-FF. Given set actions A, denote |+
1 function
+
set possible actions, |1 maps action similar
empty delete lists one conditioning propositions effect removed;
+
+
|+
denote action set obtained applying |+
1 (a), write a|
1 . A|1
1 actions

+
+


denote

a|
A, is, A|+
=
a|
|



.


action
sequence
1 sequence
1
1
+
actions obtained applying |1 every action along a, is,
(
hi,
= hi
a|+
.
1 =
+
+

ha|1 |1 , = hai
probabilistic planning task (A, bI , G, ), task (A|+
1 , bI , G, ) called relaxation
+
+
(A, bI , G, ). Finally, a|1 plan (A|1 , bI , G, ), called relaxed plan
(A, bI , G, ).
4. Following Conformant-FF terminology, leafs refer nodes zero in-degree.
5. Note would possible full SAT check, without 2-projection (without relying Imp), see
whether q becomes known t. However, indicated above, full check every unknown proposition
every level relaxed planning graph every search state would likely expensive, computationally.

580

fiP ROBABILISTIC -FF

next two sections describe machinery underlying Probabilistic-FF heuristic
estimation. Due similarity conceptual relaxations used Probabilistic-FF
Conformant-FF, Probabilistic-FF inherits almost Conformant-FFs machinery. course,
new contributions algorithms dealing probabilistic belief states probabilistic
actions.
4.2 Probabilistic Relaxed Planning Graphs
Conformant-FF, Probabilistic-FF computes heuristic function two steps, first
one chaining forward build relaxed planning graph, second step chaining backward
extract relaxed plan. section, describe detail Probabilistic-FFs forward chaining step,
building probabilistic relaxed planning graph (or PRPG, short). Section 4.4, show
one extract (probabilistic) relaxed plan PRPG. provide detailed illustration
PRPG construction process basis running example; since illustration
lengthy, moved separate Section 4.3.
algorithms building PRPG quite involved; instructive first consider (some
of) key points delving details. main issue is, course, need
extend Conformant-FFs machinery ability determine goal set sufficiently
likely, rather known true sure. achieve that, must introduce
relaxed planning effective reasoning probabilistic initial state, effects
probabilistic actions. turns reasoning obtained certain weighted
extension implication graph. nutshell, want determine likely fact
q true time t, propagate certain weights backwards implication graph,
starting q(t); weight q(t) set 1, weight p(t ) gives estimate
probability achieving q given p holds . Computing probability exactly would,
course, expensive. estimation based assuming independence various
probabilistic events involved. choice made carefully; experimented widely
various options deciding favor technique.
simplifying assumption weight propagation constitutes, course, another relaxation,
top relaxations already inherited Conformant-FF. particularly problematic
aspect assuming independence under-estimating technique. actual weight
node p(t ) probability achieving q given p holds may lower
estimate. effect, PRPG may decide wrongly relaxed plan exists: even execute
relaxed actions contained successful PRPG, probability achieving goal
execution may less required threshold. words, lose soundness (relative
relaxed tasks) relaxed planning process.
experimented alternative weight propagation method, based opposite assumption, relevant probabilistic events always co-occur, hence weights must
propagated according simple maximization operations. propagation method yielded
uninformative heuristic values, hence inacceptable empirical behaviour Probabilistic-FF,
even simple benchmarks. view, seems unlikely under-estimating yet informative efficient weight computation exists. experimented alternative
non under-estimating propagation schemes, particular one based assuming probabilistic events completely disjoint (and hence weights added); schemes gave better
581

fiD OMSHLAK & H OFFMANN

performance maximization, lagged far behind independence assumption
challenging benchmarks.
Let us get actual algorithm building PRPG. coarse outline algorithm
follows. PRPG built layer-wise fashion, iteration extending PRPG, reaching
time t, another layer, reaching time + 1. actions new step whose
preconditions known hold t. Effects conditioned unknown facts (note reduction
effect conditions single fact) constitute new edges implication graph. difference
Conformant-FF, dont obtain single edge condition add effect; instead, obtain edges
condition chance nodes, chance node represents probabilistic outcome
effect; chance nodes, turn, linked edges respective add effects. weights
chance nodes set probabilities respective outcomes, weights
nodes set 1. weights static weights dynamically modified
weight propagation; rather, static weights form input propagation.
implication graph edges inserted layer, algorithm checks whether new
facts become known. check done much corresponding check Conformant-FF,
testing whether disjunction support leafs proposition p + 1 implied
initial state formula. two differences Conformant-FF are: (1) leafs relevant whose
dynamic weight 1 (otherwise, achieving leaf guaranteed accomplish p + 1). (2)
Another reason p become known may outcomes unconditional effect (or
effect known condition) result achievement p time + 1. elegantly formulate
overall test single implication test support leafs whose dynamic weight equals
weight.
FFs Conformant-FFs algorithms, PRPG process two termination criteria.
PRPG terminates positively goal probability high enough time t; PRPG terminates
negatively if, + 1, nothing changed may result higher goal propability
future . goal probability layer computed based weighted model counting
formula derived support leafs goals known true. criteria negative
termination check: whether new facts become known unknown (not negatively known);
whether possibly relevant new support leafs appeared; whether goal probability
increased. neither case, stop safelyif PRPG terminates unsuccessfully
guarantee relaxed plan, corresponding belief hence
dead end.
Let us get details. Figure 4 depicts main routine building PRPG belief
state ba . already specified, sets P (t), (t), A(t) contain propositions
known hold time (hold probability 1), propositions unknown hold
time (hold probability less 1 greater 0), actions known
applicable time t, respectively. layers 0 PRPG capture applying relaxed actions
starting ba . layers 1 PRPG correspond m-step action sequence leading
initial belief state belief state question ba . inherit latter technique
Conformant-FF; sense, PRPG reasons past. may look confusing first
sight, simple reason. Imagine PRPG starts level 0 instead. Then, check whether
proposition becomes known, SAT tests regarding support leafs belief
state formula, (ba ), instead initial state formula (similarly weighted model counting
test whether goal likely enough). Testing (ba ) possible, expensive
582

fiP ROBABILISTIC -FF

procedure build-PRPG(a, A, (NbI ), G, , |+
1 ),
returns Bool saying relaxed plan belief state
given = ham , . . . , a1 i,
builds data structures relaxed plan extracted
:= (NbI ), Imp :=
P (m) := {p | p known }, (m) := {p | p unknown }
:= 1
A(t) := {at |+
1 } N OOP
build-timestep(t, A(t))
endfor
:= 0
get-P(t, G) <
A(t) := {a|+
1 | A, pre(a) P (t)} N OOP
build-timestep(t, A(t))
P (t + 1) = P (t)
(t + 1) = (t)
p (t + 1) : (m) support(p(t + 1)) = (m) support(p(t))
get-P(t + 1, G) = get-P(t, G)
return FALSE
endif
:= + 1
endwhile
:= t, return TRUE

Figure 4: Main routine building probabilistic relaxed planning graph (PRPG).
computationally.6 negative-index layers chain implication graph way back
initial state, hence enable us perform SAT tests typically much smaller initial
state formula.
Returning Figure 4, PRPG initialized empty implication set Imp, P (m)
(m) assigned propositions known unknown initial belief state,
weighted CNF formula initialized (NbI ). formula implication/weighted model checking tests run asking whether proposition becomes known/whether
goal likely enough. PRPG built, incrementally extended clauses
capture behavior different effect outcomes.
loop builds sets P time steps 1 iterative invocation
build-timestep procedure time expands PRPG single time level.
iteration 1, sets P (t + 1) (t + 1) made contain propositions
known/unknown applying relaxed version action (remember
= ha1 , . . . , i). simplify presentation, action set A(t) contains set dummy
actions N OOP simply
transport

propositions time layer time layer t+1.
formally, N OOP = noopp | p P , pre(noopp ) = , E(noopp ) = {({p}, {})},
= (1.0, {p}, )}).
6. Conformant-FF, configuration implemented option; significantly slows search
domains, brings advantages cases.

583

fiD OMSHLAK & H OFFMANN

subsequent loop constructs relaxed planning graph layer 0 onwards by,
again, iterative invocation build-timestep procedure. actions layer 0
relaxations actions whose preconditions known hold time certainty.
iterative construction controlled two termination tests. First, goal estimated hold
layer probability higher , know relaxed plan estimate extracted.
Otherwise, graph reaches fix point, know relaxed (and thus, real) plan
bI exists. postpone discussion two termination criteria, focus
time layer construction procedure build-timestep.
procedure build-timestep(t, A),
builds P (t + 1), (t + 1), implication edges + 1,
induced action set
P (t + 1) := P (t), (t + 1) :=
effects e action A, con(e) P (t) (t)
(e)
(t + 1) := (t + 1) add()
introduce new fact (t) ((t)) = P r()
Imp := Imp {((t), p(t + 1)) | p add()}
endfor
con(e) (t)
Sthen
Imp := Imp (e) {(con(e)(t), (t))}
else
V
:= (e) (t) , (e) ((t) (t))
endif
endfor
p (t + 1)
build-w-impleafs(p(t + 1), Imp)
support(p(t + 1)) := {l | l leafs(Impp(t+1) ) p(t+1) (l) = (l)}
W
lsupport(p(t+1)) l P (t + 1) := P (t + 1) {p} endif
endfor
(t + 1) := (t + 1) \ P (t + 1)

Figure 5: Building time step PRPG.
build-timestep procedure shown Figure 5. first loop build-timestep proceeds
outcomes (relaxed) actions given set may occur time t.
probabilistic outcome introduce new chance proposition weighted conditional likelihood
outcome.7 that, extend Imp binary implications new chance
proposition add list outcome. uncertain condition con(e)
corresponding effect time t, is, con(e) (t), add implications
con(e) chance propositions created outcomes e. Otherwise, con(e)
known time t, uncertainty ability make effect e hold time
t. case, ground chance propositions created outcomes e
implication graph, simply extend running formula clauses capturing exactly
one relationship chance propositions corresponding alternative outcomes e
7. course, implementation special case treatment deterministic actions, using chance nodes
(rather single chance node static weight 1).

584

fiP ROBABILISTIC -FF

time t. way, probabilistic uncertainty outcome e treated
property initial belief state bI ; type knowledge add knowledge
base formula initializing build-PRPG (NbI ).
Notation
Impvu
Impu
leafs(Imp )
E(Imp )

Description
graph containing exactly paths node v node u Imp.
subgraph Imp formed node u ancestors u Imp.
set zero in-degree nodes subgraph Imp Imp.
set time-stamped action effects responsible implication edges
subgraph Imp Imp.
Table 2: Overview notations around implication graph.

second loop checks whether proposition p, unknown time t, becomes known
time + 1. part build-timestep procedure somewhat involved; Table 2 provides
overview main notations used follows discussing various uses
implication graph Imp.
First thing second loop build-timestep, call build-w-impleafs procedure associates node v(t ) Impp(t+1) estimate p(t+1) (v(t )) probability achieving
p time + 1 effects E(Impv(t )p(t+1) ), given v holds time . words,
dynamic weight (according p(t + 1)) implication graph nodes computed. Note v(t )
either time-stamped proposition q(t ) q P, chance proposition (t )
probabilistic outcome .
discuss build-w-impleafs procedure detail below. proceeding understand
second loop build-timestep, main thing need know following lemma:
Lemma 4 Given node v(t ) Impp(t+1) , p(t+1) (v(t )) = (v(t )) if,
given v time , sequence effects E(Impv(t )p(t+1) ) achieves p + 1 probability 1.
words, v(t ) leads p(t + 1) certainty iff dynamic weight v(t ) equals static
weight. simple consequence weight propagation arranged; hold true
reasonable weight propagation scheme (do mark node certain not). full
proof lemma appears Appendix pp. 613.
Re-consider second loop build-timestep. happens following.
finished build-w-impleafs weight propagation p time + 1,
1. collect leafs support(p(t + 1)) Impp(t) meet criteria Lemma 4,
2. check (by call SAT solver) whether knowledge-base formula implies disjunction leafs.
implication holds, examined fact p time added set facts known time
t. Finally, procedure removes set facts known possibly hold time + 1
facts proven hold time + 1 certainty.
understand above, consider following. Lemma 4, support(p(t + 1)) contains
exactly set leafs achieving lead p(t + 1) certainty. Hence basically
585

fiD OMSHLAK & H OFFMANN

procedure build-w-impleafs (p(t), Imp)
top-down propagation weights p(t) p(t) nodes Impp(t)
p(t) (p(t)) := 1
decreasing time steps := (t 1) . . . (m)
chance nodes (t ) Impp(t)


Q
1 p(t) (r(t + 1))
:= radd(),r(t +1)Imp
p(t)
p(t) ((t )) := ((t )) (1 )
endfor
fact nodes q(t ) Impp(t)
:= 1

A(t
E(a), con(e) = q

h ), eP
p(t) ((t ))
:= 1 (e),(t )Imp
p(t)
endfor
p(t) (q(t )) := 1
endfor
endfor

Figure 6: build-w-impleafs procedure weight back-propagation implication graph.
use implication test Conformant-FF. Note, however, word basically
previous sentence hides subtle important detail. difference situation ConformantFF, support(p(t + 1)) may contain two kinds nodes: (1) proposition nodes start layer
PRPG, i.e., layer corresponding initial belief; (2) chance nodes later layers
PRPG, corresponding outcomes effects unknown conditions. point
discussed updates onWthe formula neededthose keep track alternative
effect outcomes. Hence testing lsupport(p(t+1)) l testing whether either: (1) p
known + 1 always triggered certainty least one proposition true
initial world; (2) p known + 1 triggered outcomes effect
appear certainty. get following result:
Lemma 5 Let (A, NbI , G, ) probabilistic planning task, sequence actions applicable
bI , |+
1 relaxation function A. time step m, proposition p
P, P (t) constructed build-PRPG(a, A, (NbI ), G, , |+
1 ), p time achieved
+
relaxed plan starting a|1
(1) probability > 0 (that is, p negatively known time t) p (t)P (t),

(2) probability 1 (that is, p known time t) p P (t).
consequence arguments outlined above. full proof Lemma 5 given
Appendix pp. 614.
Let us consider weight-propagating8 procedure build-w-impleafs depicted Figure 6.
procedure performs layered, top-down weight propagation given node9 p(t) Imp
8. weight propagation scheme build-w-impleafs procedure similar nature used heuristics
module recent probabilistic temporal planner Prottle Little, Aberdeen, Thiebaux (2005).
9. Note instantiated + 1 called build-timestep.

586

fiP ROBABILISTIC -FF

leafs Impp(t) . order traversal ensures node Impp(t) processed successors Impp(t) . chance nodes (t ), dynamic weight
p(t) ((t )) set
1. probability outcome takes place time given corresponding action
effect e() take place , times
2. estimate probability achieving p time effects E(Imp(t )p(t) ).
first quantity given global, static weight ((t )) assigned (t ) first
loop build-timestep. second quantity derived dynamic weights p(t) (r(t + 1))
r add(), computed previous iteration outermost loop build-w-impleafs.
Making heuristic assumption effect sets E(Impr(t +1)p(t) ) different r add()
pairwise independent, set probability failure achieve p effects
E(Imp(t )p(t) ). computation (t ) decomposed artifacts ,
weight propagation starts taking place. fact nodes q(t ), dynamic weight
p(t) (q(t )) set probability action effect conditioned q time allows
(possibly indirectly) achieving desired fact p time t. Making heuristic assumption
independence various effects conditioned q , computing p(t) (q(t ))
decomposed outcomes effects.
procedure get-P (t, G)
estimates probability achieving G time p.
G 6 P (t) (t) return 0 endif
G P (t) return 1 endif
g G \ P (t)
l leafs(Impg(t) ), introduce chance proposition hlg weight g(t) (l)
W
V
g := ( lleafs(Impg(t) ) l) lleafs(Impg(t) )uP (m) (l hlg i)
endfor
V
return WMC( gG\P (t) g )

Figure 7: Estimating goal likelihood given time step.
remains explained build-PRPG procedure two termination criteria
loop constructing planning graph layer 0 onwards. first test made
call get-P procedure, checks whether PRPG built time layer contains
relaxed plan (A, NbI , G, ). get-P procedure shown Figure 7. First, one
subgoals negatively known time t, then, Lemma 5, overall probability achieving
goal 0. extreme, subgoals known time t, probability
achieving goal 1. correctness latter test implied Lemma 5 non-interference
relaxed actions. leaves us main case uncertain
subgoals. uncertainty either due dependence subgoals actual initial world
state, due achieving subgoals using probabilistic actions, due both. uncertainty
initial state fully captured weighted CNF formula (NbI ) . Likewise,
outcomes chance propositions (t ) introduced implication graph build-timestep
procedure chained Imp propositions add lists outcomes,
587

fiD OMSHLAK & H OFFMANN

chained Imp unknown (relaxed) conditions outcomes, any. Therefore,
action outcome time < relevant achieving subgoal g G time t,
corresponding node (t ) must appear Impg(t) , weight back-propagated
build-w-impleafs(g(t), Imp) leafs Impg(t) . get-P procedure exploits
back-propagated estimates by, again, taking heuristic assumption independence
achieving different subgoals. Namely, probability achieving unknown sub-goals G \ P (t)
estimated weighted model counting formula , conjoined probabilistic theories
g achieving unknown goal g isolation. understand formulas g , consider that,
order make g true t, must achieve least one leafs l Impg(t) ; hence left part
conjunction. hand, make l true, achieves g(t) (estimated)
probability g(t) (l); hence right part conjunction requires us pay price set
l true.10
explained start section, positive PRPG termination test may fire even
real goal probability high enough. is, get-P may return value higher real
goal probability, due approximation (independence assumption) done weight propagation. course, due approximation, may happen get-P returns value lower
real goal probability.
second PRPPG termination test comes check whether reached point
construction PRPG allows us conclude relaxed plan (A, NbI , G, )
starts given action sequence a. termination criterion asks whether, time step
time step + 1, potentially relevant changes occurred. potentially relevant change
would goal-satisfaction probability estimate get-P grows, known unknown
propositions grow, support leafs latter propositions Imp correspond
initial belief state grow.11 none occurs, would hold future iterations > t,
implying required goal satisfaction probability would never reached. words,
PRPG construction complete.
Theorem 6 Let (A, NbI , G, ) probabilistic planning task, sequence actions appli+
cable bI , |+
1 relaxation function A. build-PRPG(a, A, (NbI ), G, , |1 ) returns
+
FALSE, relaxed plan (A, bI , G, ) starts a|1 .
Note Theorem 6 holds despite approximation done weight propagation, making
assumption probabilistic independence. Theorem 6 hold, requirement
weight propagation this: real weight still grows, estimated weight still grows.
requirement met independence assumption. would met assumption
co-occurence, propagating weights maximization operations, thereby conservatively underestimating weights. propagation, PRPG fails cannot conclude
plan respective belief. another good argument (besides bad quality heuristics
observed empirically) using conservative estimation.
10. introduce extra chance propositions hlg i, instead assign weight g(t) (l) l itself,
outcome correct: pay setting l false.
11. understand latter, note PRPG always added replicas probabilistic actions
irrelevant achieving goals, effects known conditions. action effects (since
irrelevant) influence estimate goal-satisfaction probability, chance propositions corresponding
outcomes effects may become support leafs unknown proposition p. latter case,
set support leafs support(p(t )) infinitely grow , projection support(p(t ))
initial belief state (that is, support(p(t)) (t)) guaranteed reach fix point.

588

fiP ROBABILISTIC -FF

full proof Theorem 6 given Appendix pp. 615. theorem finalizes
presentation analysis process constructing probabilistic relaxed planning graphs.
4.3 Example: PRPG Construction
illustrate construction PRPG algorithm Figures 4-7, let us consider simplification running Examples 1-2
(i) actions {move-b-right, move-lef t} constitute action set A,
(ii) goal G = {r1 , b2 }, required lower bound probability success = 0.9,
(iii) initial belief state bI given BN NbI Example 2,
(iv) belief state ba evaluated heuristic function corresponds actions sequence
= hmove-b-righti.
effects/outcomes actions considered construction PRPG described
Table 3, embr re-notation effect e Table 1, effect e Table 1 effectively
ignored due emptiness add effects.


E(a)

con(e)

con(e)|+
1

(e)

P r()

add()

0.7
0.2
0.1
1.0

{r2 , b2 }
{r2 }

{r1 }

1.0
1.0
1.0
1.0

{r1 }
{r2 }
{b1 }
{b2 }

embr

{r1 , b1 }

{r1 }

aml (move-lef t)

eml

{r2 }

{r2 }

mbr
1
mbr
2
mbr
3
ml

noopr1
noopr2
noopb1
noopb2

er1

{r1 }
{r2 }
{b1 }
{b2 }

{r1 }
{r2 }
{b1 }
{b2 }

r1
r2
b1
b2

ambr

(move-b-right)

er2
eb1
eb2

Table 3: Actions |+
1 relaxation PRPG construction example.
initialization phase build-PRPG procedure results = (NbI ), Imp := ,
P (1) = , (1) = {r1 , r2 , b1 , b2 }. content (1) depicted first column
nodes Figure 8. first loop build-PRPG (constructing PRPG past layers
corresponding a) makes single iteration, calls build-timestep procedure = 1
A(-1) = {ambr } N OOP S. (In follows, using names actions refer
mbr empty, thus adds
|+
1 relaxations given Table 3.) add list outcome 3
nodes implication graph. that, chance nodes introduced Imp call
build-timestep appear second column Figure 8. first outer loop build-timestep
results Imp given columns 1-3 Figure 8, (0) = (1), extension .
second outer loop build-timestep, weight propagating procedure build-w-impleafs
called unknown fact p(0) (0) = {r1 (0), r2(0) , b1 (0), b2 (0)}, generating p(0)oriented weights Table 4. p(0) (0), set supporting leafs support(p(0)) =
589

fiD OMSHLAK & H OFFMANN


WV



00 ml (0)

54






mbr (-1)
mbr


1 AA

1AA (0)
ML
ML



]\
]\












mbr
mbr (0)

88 2
q88 2 (-1)

;
;;


;;
qqq
rrrr
;;


;;
qq
;;
rrrr
;;
qqq

r
;
r
01;;

;; // r1 (0)
;; // r1 (1)
// 1
// 1 (-1)
r1 (-1)


(0)
;;
;;

;;
;;

;
RS
HI ;
HI ;;




// r2 (0)
// r2 (-1)
// r2 (0)
// r2 (1)
r2 (-1)





b1 (-1)



// b1 (-1)



b2 (-1)



// b2 (-1)



!

// b1 (0)



// b1 (0)



// b2 (0)



// b2 (0)



!



mbr
1 (1)

ML
]\



mbr
2 (1)
;;
;;
;;
;;
;;
;;
;;
HI ;;
r

// 2
// r2 (2)
(1)

// b1 (1)



// b1 (1)



// b2 (1)



// b2 (1)



// b1 (2)
!

// b2 (2)

Figure 8: implication graph Imp. odd columns nodes depict sets unknown propositions (t). even columns nodes depict change propositions introduced
probabilistic outcomes actions A(t).

{p(1)}, none implied = NbI , thus set known facts P (0) remains equal
P (1) = , (1) equal = (1).

r1 (0)
r2 (0)
b1 (0)
b2 (0)

= 0
= 1
mbr
mbr
r
r
r1 r2 b1 b2 1
2
1 2 b1 b2
1
1
1
0.7 0.2
1
1
1
1 0.7
1

r1 r2 b1 b2
1
0.9 1
1
0.7
1

Table 4: columns table correspond nodes implication graph Imp,
row provides weights p(0) p(0) (0). entry row p(0)
empty node associated corresponding column belong
implication subgraph Impp(0) .
finished loop, build-PRPG procedure proceeds loop
builds future layers PRPG. test goal (un)satisficing get-P(0, G) < evaluates
TRUE get get-P(0, G) = 0.63 < 0.9, thus loop proceeds first iteration.
see former, consider implication graph Imp constructed far (columns 1-3 Fig590

fiP ROBABILISTIC -FF

ure 8). goal G = {r1 , b2 } leafs(Impr1 (0) ) = {r1 (1)}, leafs(Impb2 (0) ) =
{r1 (1), b2 (1)}. {r1 (0), b2 (0)} (0) = (NbI ),
get-P(0, G) = WMC ((NbI ) r1 b2 ) ,

r1 = (hr1,r1 i) (r1 hr1,r1 i) ,
b2 = (hr1,b2 hb2,b2 i) (r1 (1) hr1,b2 i) (b2 (1) hb2,b2 i) ,

(20)


(hr1,r1 i) = r1 (0) (r1 (1)) = 1
(hb2,b2 i) = b2 (0) (b2 (1)) = 1

.

(21)

(hr1,b2 i) = b2 (0) (r1 (1)) = 0.7
Observe two models (NbI ) consistent r2 immediately falsify sub-formula
(NbI ) r1 . Hence,

get-P(0, G) = WMC (NbI ) r1 b2 |r1 (1)=1,b1 (1)=1 +

WMC (NbI ) r1 b2 |r1 (1)=1,b2 (1)=1

= bI (r1 , b1 ) (hr1,r1 i) (hr1,b2 i) + bI (r1 , b2 ) (hr1,r1 i) (hr1,b2 i) (hb2,b2 i)

= 0.63 1 0.7 + 0.27 1 0.7 1
= 0.63
first iteration loop, build-PRPG calls build-timestep procedure
= 0 A(0) = {ambr , aml } N OOP S. chance nodes introduced Imp call
build-timestep appear forth column Figure 8. first outer loop build-timestep
results Imp given columns 1-5 Figure 8, (1) = (0), extension .
before, second loop build-timestep, build-w-impleafs procedure called
unknown fact p(1) (1) = {r1 (1), r2(1) , b1 (1), b2 (1)}, generating p(1)-oriented weights.
interesting case case weight propagation build-w-impleafs(r1 (1), Imp), resulting
weights
r1 (1) (r1 (1)) = 1

r1 (1) (r1 (-1)) = 1

ml

r1 (1) ( (0)) = 1
r1

r1 (1) ( (0)) = 1
r1 (1) (r1 (0)) = 1
r1 (1) (r2 (0)) = 1



r1 (1) (r2 (-1)) = 1
r1 (1) (mbr
1 (-1))
mbr
r1 (1) (2 (-1))

= 0.7



r1 (1) (r1 (-1)) = 1
r1 (1) (r2 (-1)) = 1

= 0.2

nodes Impr1 (1) . that, set supporting leafs r1 (1) assigned support(r1 (1)) =
{r1 (1), r2 (1)}, since = (NbI ) implies r1 (1) r2 (1), fact r1 concluded
known time 1, added P (1). nodes p(1) (1) still
support(p(1)) = {p(1)}, thus remain unknown time = 1 well. Putting
things together, call build-w-impleafs procedure results P (1) = {r1 (1)},
591

fiD OMSHLAK & H OFFMANN

(1) = {r2(1) , b1 (1), b2 (1)}. loop build-PRPG procedure proceeds checking fixpoint termination test, immediately fails due P (1) 6= P (0). Hence,
loop proceeds next iteration corresponding = 1.
test goal (un)satisficing get-P(1, G) < still evaluates TRUE
get-P(1, G) = 0.899 < 0.9. Let us follow evaluation get-P(1, G) detail well. Considering implication graph Imp constructed far time = 1 (columns 1-5 Figure 8),
G (1) = {b2 (1)}, leafs(Impb2 (1) ) = {r1 (1), b2 (1)}, (still) = (NbI ),
obtain
get-P(1, G) = WMC ((NbI ) b2 ) ,

b2 = (hr1,b2 hb2,b2 i) (r1 (1) hr1,b2 i) (b2 (1) hb2,b2 i) ,

(22)

structure b2 Equation 22 identical Equation 20, weights associated
auxiliary chance propositions different, notably
(hb2,b2 i) = b2 (1) (b2 (1)) = 1

.

(hr1,b2 i) = b2 (1) (r1 (1)) = 0.91

(23)

difference (hr1,b2 i) Equation 21 Equation 23 stems fact r1 (1)
supports b2 (1) via effect embr time 1 via different instance
effect time 0. Now, model (NbI ) falsify b2 one sets r1
b2 false. Hence,
get-P(1, G) = bI (r1 , b1 ) (hr1,b2 i) +
bI (r1 , b2 ) (hr1,b2 i) (hb2,b2 i) +
bI (r2 , b2 ) (hb2,b2 i)
= 0.63 0.91 + 0.27 0.91 1 + 0.08 1
= 0.899
verified get-P(1, G) < , loop proceeds construction time = 2,
calls build-timestep procedure = 1 A(1) = {ambr , aml } N OOP S. chance
nodes introduced Imp call build-timestep appear sixth column Figure 8.
first outer loop build-timestep results Imp given columns 1-7 Figure 8,


mbr
mbr
= (NbI ) mbr
(1)


(1)


(1)

1
2
3




mbr
mbr
mbr
mbr
mbr
mbr
(1)


(1)


(1)


(1)


(0)


(0)
1
2
1
3
2
3

(24)

Next, build-w-impleafs procedure called usual unknown fact p(2) (2) =
{r2(2) , b1 (2), b2 (2)}. information worth detailing leafs(Impb2 (2) ) =
mbr
{b2 (1), r1 (1), mbr
1 (1)}, support(b2 (2)) = {b2 (1), 1 (1)}. However, still
W
lsupport(p(2)) l p(2) (2), thus set known facts P (2) remains equal
P (1) = {r1 }.
592

fiP ROBABILISTIC -FF

Returning call build-w-impleafs procedure, build-PRPG proceeds checking
fixpoint termination condition. time, first three equalities condition hold, yet
condition satisfied due get-P(2, G) > get-P(t, G). see latter, notice
get-P(2, G) = WMC ( b2 ) ,
given Equation 24,


b2 = hr1,b2 hb2,b2 mbr
1 (1) (r1 (1) hr1,b2 i) (b2 (1) hb2,b2 i) ,

(25)



(hb2,b2 i) = b2 (1) (b2 (1)) = 1

.

(hr1,b2 i) = b2 (1) (r1 (1)) = 0.91
(mbr
1 (1))

=

b2 (1) (mbr
1 (1))

(26)

= 0.7

hard verify
get-P(2, G) = get-P(1, G) + bI (r2 , b1 ) (mbr
1 (1))
= 0.899 + 0.02 0.7
= 0.913
Note get-P(2, G) , therefore build-PRPG aborts loop
passing goal satisficing test, sets = 2. finalizes construction PRPG, thus,
example.
4.4 Extracting Probabilistic Relaxed Plan
construction PRPG succeeds reaching goals estimated probability success get-P(T, G) exceeding , extract relaxed plan consisting A(0), . . . , A(T
1), use size heuristic value evaluated belief state ba .
get technical details, consider key differences
relaxed (no delete lists) probabilistic planning one hand, relaxed classical relaxed qualitative conformant planning hand. relaxed probabilistic planning, might
make sense execute action numerous times consecutive time steps. fact,
might essential think throwing dice game 6 appears. contrast,
relaxed classical qualitatively uncertain settings needed effect
executed, remains true forever. Another complication probabilistic planning required
goal-achievement probability specified conjunction (or, possibly, complicated
logical combination) different facts. increasing probability achieving individual sub-goal g G relaxed planning always increase overall probability achieving G,
choosing right distribution effort among sub-goals pass required threshold
whole goal G non-trivial problem.
fundamental problem aforementioned lack guarantees weight propagation.
one hand, construction PRPG Lemma 5 imply a|+
1 concatenated
R
arbitrary linearization A(0), . . . , A(T 1) executable bI . hand, due
independence assumption made build-w-impleafs procedure, get-P(T, G)
593

fiD OMSHLAK & H OFFMANN

R
imply probability achieving G a|+
1 concatenated exceeds . real relaxed
plan, sense, might even exist constructed PRPG.
answer difficulties extract relaxed plans correct relative
weight propagation. Namely, use implication graph reduction algorithm computes
minimal subset graph still according weight propagation sufficiently
supports goal. relaxed plan corresponds subset. Obviously, solves
difficulty lack real relaxed plans; relaxed plan extraction according
independence assumption (besides ignoring deletes removing one condition
effect). mechanism naturally takes care need apply action several times:
corresponds several implication graph edges needed order obtain sufficient
weight. choice effort distributed among sub-goals circumvented sense
sub-goals considered conjunction, is, reduction performed all.
course, remains choice parts implication graph removed.
found useful heuristic make choice based actions already
applied path belief. detail below.
Making another assumption top previous relaxations course bad heuristic
quality. relaxed plans extract guaranteed actually achieve desired goal probability. Since relaxed plans used search guidance, per se theoretical weakness
marginal importance. However, over-estimation goal probability might result bad
heuristic relaxed plan include right actions, apply often
enough. Section 5, discuss example domain Probabilistic-FF fails scale
precisely reason.
Figure 9 shows main routine extract-PRPlan extracting relaxed plan given
PRPG (note index highest PRPG layer, c.f. Figure 4). sub-routines
extract-PRPlan shown Figures 10-11. high level, extract-PRPlan procedure consists
two parts:

1. Reduction implication graph, aiming identifying set time-stamped action effects
ignored without decreasing estimate goal-achievement probability get-P(T, G)
desired threshold ,
2. Extraction valid relaxed plan ar (schematically) constructing PRPG ar instead
full set A(0), . . . , A(T ) would still result get-P(T, G) .
first part accomplished reduce-implication-graph procedure, depicted Figure 10.
first step algorithm, procedure considers parts implication graph
relevant achieving unknown sub-goals. Next, reduce-implication-graph performs
greedy iterative elimination actions future layers 0, . . . , 1 PRPG probability estimate get-P(T, G) reduced set actions goes . While, principle, action A(0), . . . , A(T 1) considered elimination, reduce-implication-graph examine repetitions actions already appear a. Specifically, reduce-implication-graph
iterates actions a|+
1 , repeats somewhere future layers PRPG,
one repetition a(t ) considered removal. removing repetition found safe
respect achieving ,12 effectively removed eliminating edges Imp
induced a(t ). procedure considers next repetition a. removing another
12. Note formula WMC constructed exactly get-P function, c.f. Figure 7.

594

fiP ROBABILISTIC -FF

procedure extract-PRPlan(P RP G(a, A, (NbI ), G, , |+
1 )),
selects actions A(0), . . . , A(T 1)
Imp := reduce-implication-graph()
extract-subplan(Imp )
sub-goal(G P (T ))
decreasing time steps := T, . . . , 1
g G(t)
A(t 1), e E(a), con(e) P (t 1), (e) : g add()
add-to-relaxed-plan one time
sub-goal(pre(a) con(e))
else
Imp g(t) := construct-support-graph(support(g(t)))
extract-subplan(Imp g(t) )
endif
endfor
endfor

Figure 9: Extracting probabilistic relaxed plan.
copy safe anymore, procedure breaks inner loop considers next
action.
procedure reduce-implication-graph()
operates PRPG;
returns sub-graph Imp.
Imp := gG\P (T ) Impg(T )
actions a|+
1
edges ((t ), p(t + 1)) Imp , induced a(t ) A(t ), 0
Imp := Imp
remove Imp edges induced A(t )
g G \ P (t)
l leafs(Imp g(T ) ), introduce chance proposition hlg weight g(T ) (l)
V
W
g := ( lleafs(Imp
) l) lleafs(Imp
)uP (m) (l hlg i)
g(T )

g(T )

endfor
V
WMC( gG\P (T ) g ) Imp := Imp else break endif
endfor
endfor
return Imp

Figure 10: procedure reducing implication graph.
illustrate intuition behind focus repetitions actions a, let us consider following example simple logistics-style planning problem probabilistic actions.
Suppose two locations B, truck known initially A, heavy
uneasy grab package known initially truck. goal package
unloaded B reasonably high probability, two actions use moving
truck B (am ), unloading package (au ). Moving truck necessarily
595

fiD OMSHLAK & H OFFMANN

move truck B, extremely high probability. hand, unloading bothersome package succeeds extremely low probability, leaving package
truck otherwise. Given data, consider belief state ba corresponding trying move
truck once, is, action sequence ham i. achieve desired probability success,
PRPG expanded large time horizon , allowing action au
applied sufficiently many times. However, fact truck B known belief state ba ,
thus implication graph contain amount applications . Trimming
away applications still keep probability sufficiently high.
reader might ask point hope achieve trimming away
applications . point is, intuitively, implication graph reduction mechanism
means understand accomplished already, path ba . Without
understanding, relaxed planning quite indiscriminative search states. Consider
example, assume one two troubled packages, P 1 P 2,
truck, unload actions au1 au2 . PRPG ba contains copies au1 au2 layers
large horizon . Now, say search starts unload P 1. resulting belief, PRPG
still steps situation changed P 2. step PRPG still contains
copies au1 au2 hence heuristic value remains before!
words, without implication graph reduction technique, relevant things accomplished
may remain hidden behind things yet accomplished. example,
really critical because, soon tried unload P 1 P 2,
time horizon decreases one step, heuristic value reduced. is, however, often
case sub-task must accomplished sub-task attacked.
situations, without implication graph reduction, search staggers across huge plateau
first task completed. observed variety benchmarks, hence designed
implication graph reduction make relaxed planning aware already done.
course, since weight propagation may over-estimate true probabilities, hence overestimate achieved past, implication graph reduction may conclude prematurely
sub-task completed. leads us main open question research;
get back end Section 5, discuss context example
Probabilistic-FFs performance bad.
Let us get back explaining extract-PRPlan procedure. implication graph reduction, procedure proceeds relaxed plan extraction. process makes use proposition
sets G(1), . . . , G(T ), used store time-stamped sub-goals arising layers 1
relaxed plan extraction. sub-routine extract-subplan (Figure 11)
1. adds constructed relaxed plan time-stamped actions responsible edges
reduced implication graph Imp ,
2. subgoals everything outside implication graph condition applicability effects
responsible edges Imp .
later phases process, sub-goals added sets G(1), . . . , G(T )
sub-goal procedure simply inserts given proposition sub-goal first layer
appearance PRPG. accomplished extract-and-subgoal pass extract-subplan
Imp , subgoal goal conjuncts known time .
next phase process, sub-goals considered layer layer decreasing order
time steps 1. sub-goal g time t, certain supporting actions selected
596

fiP ROBABILISTIC -FF

procedure extract-subplan(Imp )
actions helpful achieving uncertain goals G (T )
subgoals essential conditions actions
edge ((t), p(t + 1)) Imp 0
action effect e E(a) responsible time time
add-to-relaxed-plan time
sub-goal((pre(a) con(e)) P (t))
endif endfor
procedure sub-goal(P )
inserts propositions P sub-goals
layers first appearance PRPG
p P
t0 := argmint {p P (t)}
t0 1 G(t0 ) := G(t0 ) {p} endif
endfor
procedure construct-support-graph(support(g(t)))
takes subset support(g(t)) leafs(Impg(t) ) weighted according g(t);
returns sub-graph Imp Imp.

Imp :=
open := support(g(t))
open 6=
open := open \ {p(t )}
choose A(t ), e E(a), con(e) = {p}
(e) : (p(t ), (t )) Impg(t) g(t) ((t )) = ((t ))
(e)
choose q add() g(t) (q(t + 1)) = 1
Imp := Imp {(p(t ), (t )), ((t ), q(t + 1))}
open := open {q(t + 1)}
endfor endwhile
return Imp

Figure 11: Sub-routines extract-PRPlan.
relaxed plan. action effect e E(a) known applicable
time 1, guarantee achieve g certainty, added constructed relaxed
plan 1. Otherwise,
1. use construct-support-graph procedure extract sub-graph Imp g(t) consisting set
implications together ensure achieving g time t,
2. use already discussed procedure extract-subplan
(a) add constructed relaxed plan time-stamped actions responsible edges
Imp g(t) ,
(b) subgoal everything outside implication graph Imp g(t) condition applicability
effects responsible edges Imp g(t) .
597

fiD OMSHLAK & H OFFMANN

Processing way sub-goals G(1) finalizes extraction relaxed plan
estimate. Section 4.5 provides detailed illustration process PRPG constructed
Section 4.3. event, easy verify relaxed plan extract sound relative
weight propagation, following sense.
Proposition 7 Let (A, NbI , G, ) probabilistic planning task, sequence actions ap+
plicable bI , |+
1 relaxation function build-PRPG(a, A, (NbI ), G, , |1 )
returns TRUE. Let A(0)s , . . . , A(T 1)s actions selected A(0), . . . , A(T 1)
extract-PRPlan. constructing relaxed planning graph using A(0)s , . . . , A(T 1)s ,
get-P(T, G) .
Proof: construction: reduce-implication-graph leaves enough edges graph
weight propagation underlying get-P still concludes goal probability high enough.
4.5 Example: Extracting Relaxed Plan PRPG
illustrate process relaxed plan extraction PRPG Figure 8, constructed
belief state problem specification example Section 4.3. example
= 2, G (2) = {b2 }, thus implication graph Imp gets immediately reduced
sub-graph Imp depicted Figure 12a. plan belief state question consists
single action ambr , action instances considered elimination outer loop
reduce-implication-graph ambr (0) ambr (1). ambr (0) chosen examined,
implication sub-graph Imp = Imp reduced removing edges due ambr (0),
resulting Imp appears13 Figure 12b. b2 components evaluated formula
b2 given Equation 24 Equation 25, respectively, weights associated
chance propositions Equation 25 reduced implication graph Imp
(hb2,b2 i) = b2 (1) (b2 (1)) = 1
(hr1,b2 i) = b2 (1) (r1 (1)) = 0.7

.

(27)

mbr
(mbr
1 (1)) = b2 (1) (1 (1)) = 0.7

weight model counting b2 evaluates 0.724 < , thus Imp replace Imp .
alternative action removal ambr (1), seen example Section 4.3 attempt action elimination result probability estimate lower .
Hence, effect reduce-implication-graph PRPG processed extract-PRPlan
procedure reduction implication graph edges relevant achieving {b2 }
time = 2. reduced implication sub-graph Imp returned reduce-implication-graph
procedure depicted Figure 12a.
Next, extract-subplan procedure iterates edges Imp adds initially
empty relaxed plan applications ambr times 0 1. action ambr preconditions,
E(ambr ) known time 1. Hence, extract-subplan
condition r1 effect mbr
1
invokes sub-goal procedure {r(1)}, latter added proposition set G(1).
subsequent call sub-goal(G P (T )) = sub-goal({r1 }) leads extensions G(2), G(1)
13. dashed edges Figure 12b removed Imp either latter stage Imp chosen replace
Imp .

598

fiP ROBABILISTIC -FF



mbr
88 1 (-1)
qq
]\
qqq
q
q
qq


// r1 (-1)
r1 (-1)



b2 (-1)



// b2 (-1)



// r1 (0)



mbr
88 1 (0)
rrr
]\
rrr
r
r

! //
b2 (0)



// b2 (0)





mbr
1 (1)

! //
b2 (1)

]\



// b2 (1)



! //
b2 (2)

(a)


mbr
88 1 (-1)
qq
]\
qqq
q
q
qq

r
r1 (-1) _ _ _ _// 1 (-1)_ _ _ _// r1 (0)

b2 (-1)



// b2 (-1)



!

// b2 (0)



mbr
1 (1)



// b2 (0)



// b2 (1)



// b2 (1)



]\

!

// b2 (2)

(b)


00 ml
(0)54

r1 (-1)



// r1 (-1)



r2 (-1)



// r2 (-1)



WV

r
01

// r1 (0)
// 1 (0)





RS

// r1 (1)

// r2 (0)

(c)
Figure 12: Illustrations various steps relaxed plan extraction PRPG constructed
Section 4.3, and, particular, implication graph latter, depicted
Figure 8.

already r1 G(1). Hence, outer loop extract-PRPlan starts G(2) = ,
G(1) = {r1 }.
Since G(2) empty, first sub-goal considered extract-PRPlanis r1 G(1). r1
time 1, action effect time 0 passes test statementthe condition r2 ml
known time 0, true14 r1 . Hence, subgoal r1 (1) processed
extracting sub-plan support achieving certainty. First, construct-support-graph
procedure called support(r1 (1)) = {r1 (1), r2 (1)} (see Section 4.3). extracted sub14. fact, easy see construction sub-goal procedure p belongs G(t), condition
noops effect p cannot known time 1.

599

fiD OMSHLAK & H OFFMANN

graph Imp r1 (1) original implication graph Imp depicted Figure 12c, invoking
procedure extract-subplan Imp r1 (1) results adding (i) application aml time 0, (ii)
new subgoals. Hence, proposition sets G(1), G(2) get emptied, thus end
extracting relaxed plan hambr (0), aml (0), ambr (1)i.

5. Empirical Evaluation
implemented Probabilistic-FF C, starting Conformant-FF code. = 1.0,
Probabilistic-FF behaves exactly Conformant-FF (except Conformant-FF cannot handle
non-deterministic effects). Otherwise, Probabilistic-FF behaves described previous sections, uses Cachet (Sang et al., 2005) weighted model counting. better home
strengths weaknesses approach, empirical evaluation Probabilistic-FF
done two steps. Section 5.1 evaluate Probabilistic-FF problems non-trivial uncertain initial states, deterministic actions. Section 5.2 examine Probabilistic-FF
problems probabilistic action effects, sources uncertainty. compare
Probabilistic-FFs performance probabilistic planner POND (Bryce et al., 2006).
reasons choosing POND reference point twofold. First, similarly Probabilistic-FF,
POND constitutes forward-search planner guided non-admissible heuristic function based
(relaxed) planning graph computations. Second, knowledge, POND clearly
efficient probabilistic planner reported literature.15
experiments run PC running 3GHz 2GB main memory 2MB cache
running Linux. Unless stated otherwise, domain/problem pair tried four levels desired probability success {0.25, 0.5, 0.75, 1.0}. run planner time-limited
1800 seconds user time. Probabilistic-FF run default configuration inherited FF,
performing one trial enforced hill-climbing switching best-first search case failure.
domains without probabilistic effects, found Probabilistic-FFs simpler relaxed plan extraction developed case (Domshlak & Hoffmann, 2006), performs better one described
here. hence switch simpler version domains.16
Unlike Probabilistic-FF, heuristic computation POND element randomization;
namely, probability goal achievement estimated via sending set random particles
relaxed planning graph (the number particles input parameter). problem instance, averaged runtime performance POND 10 independent runs. special
cases POND timed runs certain problem instance, yet
10 runs, average report POND uses lower-bounding time threshold 1800s replace missing time points. cases, PONDs best-case performance differs lot
average performance; cases, best-case performance reported. note that,
following suggestion Dan Bryce, POND run default parameter setting, and, par15. experiments used recent version 2.1 POND significantly enhances POND2.0 (Bryce et al.,
2006). authors would thank Dan Bryce Rao Kambhampati providing us binary distribution
POND2.1.
16. Without probabilistic effects, relaxed plan extraction proceeds much Conformant-FF, additional
straightforward backchaining selecting support unknown goals. complicated techniques developed
deal relaxed plan extraction probabilistic effects appear unstable behavior
simpler techniques. probabilistic effects, simple backchaining meaningful
information many times action must applied order sufficiently support goal.

600

fiP ROBABILISTIC -FF

= 0.25
t/|S|/l

= 0.5
t/|S|/l

= 0.75
t/|S|/l

= 1.0
t/|S|/l

70/71/140
70/70/138

1.39/19 /18
0.28/6/5

4.02/36/35
0.76/13/12

8.06/54/53
1.54/22/21

4.62/71 /70
4.32/70/69

Cube-uni-15
Cube-cub-15

6/90/3375
6/90/3375

3.25/145/26
0.56/41/8

3.94/150/34
1.16/70/13

5.00/169/38
1.95/109/18

25.71/296/42
26.35/365/42

Bomb-50-50
Bomb-50-10
Bomb-50-5
Bomb-50-1

2550/200/> 2100
510/120/> 260
255/110/> 255
51/102/> 251

0.01/1/0
0.00/1/0
0.00/1/0
0.00/1/0

0.10/17/16
0.89/248/22
1.70/468/27
2.12/662/31

0.25/37/36
4.04/778/62
4.80/998/67
6.19/1192/71

0.14/51/50
1.74/911/90
2.17/1131/95
2.58/1325/99

Log-2
Log-3
Log-4

3440/1040/> 2010
3690/1260 /> 3010
3960/1480/> 4010

0.90/117/54
2.85/159/64
2.46/138/75

1.07/152/62
8.80/328/98
8.77/391/81

1.69/205/69
4.60/336/99
6.20/377/95

1.84/295/78
4.14/364/105
8.26/554/107

Grid-2
Grid-3
Grid-4

2040/825 /> 3610
2040/841 /> 3610
2040/857 /> 3610

0.07/39/21
16.01/1629/76
28.15/2167/96

1.35/221/48
15.8/1119/89
51.58/2541/111

6.11/1207/69
82.24/3974/123
50.80/2541/115

6.14/1207/69
66.26/3974/123
193.47/6341/155

Rovers-7
RoversP-7
RoversPP-7
RoversPPP-7

393/97 /> 63 38
393/133 /> 63 38
393/133 /> 63 38
395/140 /> 63 38

0.01/ 37/18
2.15/942/65
8.21/948/65
25.77/950/67

0.01/ 37/18
2.23/983/75
12.48/989/75
41.18/996/79

0.01/ 37/18
2.37/1008/83
12.53/994/77
0.01/UNSAT

0.01/ 37/18
2.29/1008/83
16.20/1014/83
0.01/UNSAT

Instance

#actions/#facts/#states

Safe-uni-70
Safe-cub-70

Table 5: Empirical results problems probabilistic initial states. Times seconds, search
space size |S| (number calls heuristic function), plan length l.

ticular, includes number random particles (64) selected computing PONDs heuristic
estimate (Bryce et al., 2006).
5.1 Initial State Uncertainty Deterministic Actions
examine performance Probabilistic-FF POND collection domains
probabilistic initial states, deterministic action effects. consider domains one
one, discussing set runtime plots. problem instances, Table 5 shows
details, providing features instance size well detailed results Probabilistic-FF,
including number explored search states plan length.
first three domains probabilistic versions traditional conformant benchmarks: Safe,
Cube, Bomb. Safe, n combinations one opens safe. given probability
distribution combination right one. type action Safe trying
combination, objective open safe probability . experimented
two probability distributions n combinations, uniform one (Safe-uni) distribution
declines according cubic function (Safe-cub). Table 5 shows Probabilistic-FF
solve efficiently even n = 70. Figure 13 compares Probabilistic-FF
POND, plotting time performance identical linear scale, x-axes show number
combinations.
graphs easy see Probabilistic-FF outperforms POND least order
magnitude Safe-uni Safe-cub. interesting observation necessarily
difference time performance, relative performance planner Safe-uni
Safe-cub. Note Safe-cub somewhat easier Safe-uni sense that, Safe-cub, fewer
combinations must tried guarantee given probability opening safe.
601

fiD OMSHLAK & H OFFMANN

PFF

POND2.1

70

70
p=0.25
p=0.50
p=0.75
p=1.00

60

50

50

40

40

Time (sec)

Time (sec)

60

p=0.25
p=0.50
p=0.75
p=1.00

30

30

20

20

10

10

0

0
10

30

50

70

10

30

#combinations

50

70

#combinations

(a) Uniform prior distribution combinations.
PFF

POND2.1

70

70
p=0.25
p=0.50
p=0.75
p=1.00

60

50

50

40

40

Time (sec)

Time (sec)

60

p=0.25
p=0.50
p=0.75
p=1.00

30

30

20

20

10

10

0

0
10

30

50

70

10

#combinations

30

50

70

#combinations

(b) Cubic decay prior distribution combinations.
Figure 13: Safe domain, Probabilistic-FF (left) vs. POND (right).
dominant part probability mass lies combinations head cubic distribution
(the last combination probability 0 right combination, thus needs tried
even = 1.0). question whether heuristic functions Probabilistic-FF
POND exploit difference Safe-uni Safe-cub. Table 5 Figure 13 provide
affirmative answer question heuristic function Probabilistic-FF. picture
POND less clear times spent POND (otherwise identical) instances Safe-uni
Safe-cub roughly same.17
Another interesting observation that, Probabilistic-FF POND, moving =
1.0 < 1.0, is, planning qualitative uncertainty truly probabilistic planning,
17. Safe-cub n = 70 {0.75, 1.0}, POND undergoes exponential blow-up shown
graphs since data points would obscure data points; anyway, believe blow-up due
unfortunate troubles numerics.

602

fiP ROBABILISTIC -FF

PFF

POND2.1

30

1800
p=0.25
p=0.50
p=0.75
p=1.00

25

p=0.25
p=0.50
p=0.75
p=1.00

1600
1400
1200
Time (sec)

Time (sec)

20

15

10

1000
800
600
400

5
200
0

0
5

7

9
11
N Grid NxNxN

13

15

5

7

9
11
N Grid NxNxN

13

15

13

15

(a) Uniform prior distribution initial position.
PFF

POND2.1

30

1800
p=0.25
p=0.50
p=0.75
p=1.00

25

p=0.25
p=0.50
p=0.75
p=1.00

1600
1400
1200
Time (sec)

Time (sec)

20

15

10

1000
800
600
400

5
200
0

0
5

7

9
11
N Grid NxNxN

13

15

5

7

9
11
N Grid NxNxN

(b) Cubic decay prior distribution initial position.
Figure 14: Cube domain, Probabilistic-FF (left) vs. POND (right).

typically result performance decline. even get improved performance (except
= 0.75 Safe-uni). reason seems plans become shorter. trend
observed domains. trend particularly remarkable Probabilistic-FF, since
moving = 1.0 < 1.0 means move case model counting needed
case needed. (In words, Probabilistic-FF automatically specializes
qualitative uncertainty, using model counting. knowledge, true
POND, uses techniques cases.)
Cube, task move corner 3-dimensional grid, actions correspond
moving current cube cell one (up 6) adjacent cube cells. Again, created
problem instances uniform cubic distributions (over initial position dimension),
again, Probabilistic-FF scales well, easily solving instances 15 15 15 cube. Within
time limit, POND capable solving Cube problems cube width 13. Figure 14
603

fiD OMSHLAK & H OFFMANN

compares Probabilistic-FF POND detail, plotting time performance
different linear scales (with x-axes capturing width grid dimension), showing
least order magnitude advantage Probabilistic-FF. Note that,
Probabilistic-FF generally becomes faster decreasing (with decreasing hardness
achieving objective), seem substantial effect performance
POND,
Probabilistic-FF exploits relative easiness Cube-cub (e.g., see Table 5), time
performance POND Cube-cub Cube-uni qualitatively identical.
tried version Cube task move grid center. Probabilistic-FF
bad so, reaching performance limit n = 7. weakness Cube-center domain
inherited Conformant-FF. detailed Hoffmann Brafman (2006), reason
weakness lies inaccuracy heuristic function domain. two sources
inaccuracy. First, solve Cube-center reality, one must start moving corner
order establish position; relaxation, without delete lists, necessary. Second,
relaxed planning graph computation over-approximates achieved future
steps, already achieved path considered belief state. even
moderately long paths actions, relaxed planning graph comes (wrong) conclusion
goal already achieved, relaxed plan becomes empty heuristic
information.
Next consider famous Bomb-in-the-Toilet domain (or Bomb, short). version
Bomb contains n bombs toilets, bomb may armed armed independently probability 1/n, resulting huge numbers initially possible world states. Dunking
bomb unclogged toilet disarms bomb, clogs toilet. toilet unclogged
flushing it. Table 5 shows Probabilistic-FF scales nicely n = 50, becomes faster
increases. latter logical desirable toilets means disarming
devices, resulting shorter plans needed. Figures 15 16 compare Probabilistic-FF
POND, plotting time performance Probabilistic-FF linear scale, POND
logarithmic scale. four pairs graphs correspond four choices number toilets
{50, 10, 5, 1}. x-axes graphs correspond number potentially armed
bombs, checked problems n {5, 10, 25, 50}. Figure 15 shows time
Probabilistic-FF least four orders magnitude faster POND; extremes,
hardest combination n = 50, = 1, = 0.75 took Probabilistic-FF less 7 seconds,
POND timed-out problem instances. addition,
Bomb well, Probabilistic-FF exhibit nice pattern improved performance
move non-probabilistic ( = 1.0) probabilistic planning (specifically, 0.5;
0.25, initial state good enough already).
performance Probabilistic-FF improves number toilets, POND seems
exhibit inverse dependence, is, sensitive number states
problem (see Table 5) rather optimal solution depth.
Finally, remark that, though length-optimality explicitly required probabilistic conformant planning, Safe, Cube, Bomb, Probabilistic-FFs plans optimal (the shortest
possible).
604

fiP ROBABILISTIC -FF

PFF

POND2.1

10
p=0.25
p=0.50
p=0.75
p=1.00

1000

8
100

Time (sec)

Time (sec)

6

4

10

1

2

0.1
p=0.25
p=0.50
p=0.75
p=1.00

0

0.01
5

10

25
# bombs

50

5

10

25
# bombs

50

(a) 50 toilets
PFF

POND2.1

10
p=0.25
p=0.50
p=0.75
p=1.00

1000

8
100

Time (sec)

Time (sec)

6

4

10

1

2

0.1
p=0.25
p=0.50
p=0.75
p=1.00

0

0.01
5

10

25
# bombs

50

5

10

25
# bombs

50

(b) 10 toilets
Figure 15: Bomb domain, Probabilistic-FF (left) vs. POND (right).

next three domains adaptations benchmarks deterministic planning: Logistics,
Grid, Rovers. assume reader familiar domains. Logistics-x
instance contains 10 cities, 10 airplanes, 10 packages, city x locations.
packages chance 0.88 airport origin city, uniformly
locations city. effects loading unloading actions conditional (right)
position package. Note higher values x increase space world states,
initial uncertainty. Grid complex grid world run AIPS98 planning competition (McDermott, 1998), featuring locked positions must opened matching keys.
Grid-x modification instance nr. 2 (of 5) run AIPS98, 6 6 grid, 8 locked
positions, 10 keys 3 must transported goal position. lock x possible, uniformly distributed shapes, 3 goal keys x possible, uniformly distributed
initial positions. effects pickup-key, putdown-key, open-lock actions conditional.
605

fiD OMSHLAK & H OFFMANN

PFF

POND2.1

10
p=0.25
p=0.50
p=0.75
p=1.00

1000

8
100

Time (sec)

Time (sec)

6

4

10

1

2

0.1
p=0.25
p=0.50
p=0.75
p=1.00

0

0.01
5

10

25
# bombs

50

5

10

25
# bombs

50

(c) 5 toilets
PFF

POND2.1

10
p=0.25
p=0.50
p=0.75
p=1.00

1000

8
100

Time (sec)

Time (sec)

6

4

10

1

2

0.1
p=0.25
p=0.50
p=0.75
p=1.00

0

0.01
5

10

25
# bombs

50

5

10

25
# bombs

50

(d) 1 toilet
Figure 16: Bomb domain, Probabilistic-FF (left) vs. POND (right).

Finally, last set problems comes three cascading modifications instance nr. 7 (of
20) Rovers domain used AIPS02 planning competition. problem instance 6
waypoints, 3 rovers, 2 objectives, 6 rock/soil samples. Rovers RoversPPP modify
instance/domain follows.
Rovers original AIPS02 problem instance nr. 7, use hear mainly comparison.
RoversP, sample chance 0.8 original waypoint, chance 0.1
others two waypoints. objective may visible 3 waypoints
uniform distribution (this probabilistic adaptation domain suggested Bryce &
Kambhampati, 2004).
606

fiP ROBABILISTIC -FF

Sandcastle

Sandcastle

0.5
PFF
POND

PFF
POND (min)
POND (avg)
100

0.4

10
Time (sec)

Time (sec)

0.3

0.2

1

0.1

0.1

0

0.01
0.2

0.3

0.4

0.5

0.6


0.7

0.8

0.9

0.2

(a)

0.3

0.4

0.5

0.6


0.7

0.8

0.9

(b)

Figure 17: Probabilistic-FF POND problems (a) Sand-Castle, (b) SlipperyGripper.

RoversPP enhances RoversP conditional probabilities initial state, stating whether
objective visible waypoint depends whether rock sample (intuition: large piece rock) located waypoint. probability visibility much
higher latter case. Specifically, visibility objective depends
locations two rock samples, rock sample present, visibility probability
drops 0.1.
RoversPPP extends RoversPP introducing need collect data water existence.
soil samples certain probability (< 1) wet. communicated
sample data, additional operator tests whether sample wet. so, fact knowthat-water contained goal set true. probability wet depends
location sample.
show runtime plots Logistics, Grid, Rovers, since POND runs either time
memory considered instances domains. Table 5 shows scaling behavior
Probabilistic-FF three domains similar observed previous domains.
goals RoversPPP problem cannot achieved probabilities {0.75, 1.0}.
proved Probabilistic-FFs heuristic function, providing correct answer split seconds.
5.2 Probabilistic Actions
first two domains probabilistic actions famous Sand-Castle (Majercik & Littman,
1998) Slippery-Gripper (Kushmerick et al., 1995) domains. domains simple,
posed first challenges probabilistic planners; performance domains serves
indicator progress relative previous ideas probabilistic planning.
Sand-Castle, states specified two boolean variables moat castle, state
transitions given two actions dig-moat erect-castle. goal erect castle.
607

fiD OMSHLAK & H OFFMANN

1D-walkgrid

2D-walkgrid

PFF
POND

1000

100

100

10

10

Time (sec)

Time (sec)

1000

1

1

0.1

0.1

0.01

0.01

PFF
POND
5

6

7

8

9

10

3

Grid width

(a)

4

5

6
7
Grid width

8

9

10

(b)

Figure 18: Probabilistic-FF POND problems (a) 1D-WalkGrid = 0.9, (b)
2D-WalkGrid = 0.01.

Building moat dig-moat might fail probability 0.5. Erecting castle erect-castle
succeeds probability 0.67 moat already built, probability 0.25, otherwise. failed, erect-castle destroys moat probability 0.5. Figure 17(a) shows
Probabilistic-FF POND solve problem less second arbitrary high values
, performance planners almost independent required probability
success.
Slippery-Gripper already bit complicated domain. states Slippery-Gripper
specified four boolean variables grip-dry, grip-dirty, block-painted, block-held,
four actions dry, clean, paint, pickup. initial state, block neither painted
held, gripper clean, gripper dry probability 0.7. goal
clean gripper holding painted block. Action dry dries gripper probability 0.8. Action
clean cleans gripper probability 0.85. Action paint paints block probability 1,
makes gripper dirty probability 1 block held, probability 0.1
not. Action pickup picks block probability 0.95 gripper dry,
probability 0.5 gripper wet.
Figure 17(b) depicts (on log-scale) relative performance Probabilistic-FF POND
Slippery-Gripper function growing . performance Probabilistic-FF nicely flat
around 0.06 seconds. time, comparison POND somewhat problematic, because,
fixed , POND Slippery-Gripper exhibited huge variance runtime. Figure 17(b)
plot best runtimes POND, well average runtimes. best run-times POND
different values vary around couple seconds, average runtimes significantly
worse. (For high values POND timed-out sample runs, thus plot provides
lower bound average runtimes.)
next two domains, 1D-WalkGrid 2D-WalkGrid, robot pre-plan sequence conditional movements taking corner grid farthest (from initial
608

fiP ROBABILISTIC -FF

position) corner (Hyafil & Bacchus, 2004). 1D-WalkGrid grid one-dimensional,
2D-WalkGrid grid two-dimensional. Figure 18(a) depicts (on log-scale) snapshot
relative performance Probabilistic-FF POND one-dimensional grids width n
= 0.9. robot initially (1, 1), get (1, n), try moving two
possible directions. two movement actions moves robot right direction
probability 0.8, keeps place probability 0.2. easy see Figure 18(a)
difference two planners domain substantialwhile runtime ProbabilisticFF grows linearly x, dependence POND seemingly exponential.
2D-WalkGrid domain already much challenging probabilistic planning.
2D-WalkGrid problems n n grids robot initially (1, 1), get (n, n),
try moving four possible directions. four movement actions advances
robot right direction probability 0.8, opposite direction probability 0,
either two directions probability 0.1. Figure 18(a) depicts (on log-scale)
snapshot relative performance Probabilistic-FF POND 2D-WalkGrid
low required probability success = 0.01, function grids width n.
plot shows Probabilistic-FF still scales well increasing n (though linearly anymore),
POND time-outs grid widths n > 3. higher values , however, Probabilistic-FF
reach time-out limit rather small grids, notably n = 6 n = 5 = 0.25
= 0.5, respectively. reason Probabilistic-FFs heuristic function good
enough estimating many times, early point plan, probabilistic action must
applied order sufficiently support high goal threshold end plan. explain
phenomenon detail end section, find appears variant
well-known Logistics domain.
last set problems comes standard Logistics domain. problem instance
x-y-z contains x locations per city, cities, z packages. see Probabilistic-FF
scales much worse, Logistics, presence probabilistic effects initial
state uncertainty (we explain reason end section). Hence use much
smaller instances ones used Section 5.1. Namely, allow direct comparison
previous results domain, closely follow specification Hyafil Bacchus (2004).
use instances configurations x-y-z = 2-2-2, 4-2-2, 2-2-4, distinguish two
levels uncertainty.
L-x-y-z correspond problems uncertainty outcome load unload
actions. Specifically, probabilities success load 0.875 trucks 0.9
airplanes, unload, 0.75 0.8, respectively.
LL-x-y-z extends L-x-y-z independent uniform priors initial location
package within start city.
Figure 19 depicts (on log scale) runtimes Probabilistic-FF POND L-2-2-2, L-4-2-2,
L-2-2-4, function growing . problems, planners appear scale well,
runtime Probabilistic-FF optimal runtime POND roughly same,
average runtime POND somewhat degrading 2-2-2 4-2-2 2-2-4. shows
planners much efficient domain previously known SAT CSP
based techniques. However, moving LL-x-y-z changes picture planners. results
follows:
609

fiD OMSHLAK & H OFFMANN

L-2-2-2

L-4-2-2

100

PFF
POND (min)
POND (avg)

1

0.1

10

Time (sec)

10

Time (sec)

Time (sec)

100
PFF
POND (min)
POND (avg)

10

0.01
0.01

L-2-2-4

100
PFF
POND (min)
POND (avg)

1

0.1

0.25

0.5


(a)

0.75

0.95

0.01
0.01

1

0.1

0.25

0.5


(b)

0.75

0.95

0.01
0.01

0.25

0.5

0.75

0.95



(c)

Figure 19: Probabilistic-FF POND problems Logistics (a) L-2-2-2, (b) L-4-2-2,
(c) L-2-2-4.

1. LL-2-2-2, runtimes Probabilistic-FF identical L-2-2-2,
optimal runtimes POND slightly degraded 28 seconds. However, examined
values , runs POND resulted timeouts.
2. LL-4-2-2, runtimes Probabilistic-FF identical L-4-2-2
{0.01, 0.25, 0.5, 0.75}, yet Probabilistic-FF time-outed = 0.95. optimal runtimes
POND degraded L-4-2-2 9 18 seconds, again, values
, runs POND resulted timeouts.
3. LL-2-2-4, Probabilistic-FF experienced hard times, finishing 0.19 seconds =
0.01, time-outing examined values . optimal runtimes POND
degraded L-2-2-4 120 700 seconds, well, values ,
runs POND resulted timeouts.
tried variant LL-x-y-z non-uniform priors initial locations packages, resulted qualitatively similar picture absolute relative performance.
LL-x-y-z domain remains challenging, deserves close attention future developments probabilistic planning. context, interesting close look
reasons failure Probabilistic-FF is. turns Probabilistic-FF good enough
estimating many times, early point plan, probabilistic action must applied
order sufficiently support high goal threshold end plan. make concrete,
consider Logistics example uncertain effects load unload actions. Consider package P must go city city B. Lets say P initially airport.
goal threshold high, means that, able succeed, package brought
airport high probability loading onto airplane. exactly point
Probabilistic-FFs heuristic function fails. relaxed plan contains actions unloading P
airport. effect search proceeds quickly loading P onto plane
bringing B. search gets point B unloaded goal location, goal threshold cannot achieved matter many times one unloads P. point,
610

fiP ROBABILISTIC -FF

Probabilistic-FFs enforced hill-climbing enters loop eventually fails relaxed plan
(which over-estimates past achievements) becomes empty.18
challenge devise methods better recognizing many times P
unloaded airport order sufficiently support goal threshold. error made
Probabilistic-FF lies propagation weights implication graph over-estimates
goal probability. Note much critical actions must applied early
plan, actions applied later. action appears early plan,
relaxed plan, executed, long. Recall weight propagation proceeds
backwards, goal towards current state. single backwards step, propagation
makes approximation might lose precision results. several backwards steps,
imprecisions accumulate. Hence quality approximation decreases quickly
number backwards steps. longer distance goal current state is,
information lost. observed phenomenon detailed experiments different
weight propagation schemes, is, different underlying assumptions. propagation
schemes tried, independence assumption, presented paper, far
accurate one. schemes failed deliver good results even much shorter distances
goal current state.
interesting consider issue affects POND, uses different method
estimating probability goal achievement: instead performing backwards propagation
aggregation weight values, POND sends set random particles relaxed planning
graph forward fashion, stops graph building enough particles end goal.
empirical results, seems method suffers similar difficulties Probabilistic-FF,
large extent. PONDs optimal runtimes LL-x-y-z much higher
L-x-y-z. indicates always challenging POND recognize need
applying action many times early plan. interestingly, POND never times-out
L-x-y-z, often time-out LL-x-y-z. indicates that, extent, matter
chance whether PONDs random particles recognize need applying action
many times early plan. intuitive explanation good cases
sufficiently many particles failed reach goal due taking wrong effect a.
Based intuition, one would expect helps increase number random particles
PONDs heuristic function. so, running POND LL-x-y-z increased number
particles, 200 600 instead default value 64. surprise, qualitative behavior
POND change, time-outing similar number cases. unclear us reason
phenomenon is. Certainly, observed situation encoded LL-x-y-z
solved satisfaction either Probabilistic-FFs weight propagation PONDs random particle
methods, current configurations.
time writing, unclear authors better methods could devised. seems
unlikely weight propagation least one resort expensive reasoning exists
manages long distances better independence assumption. alternative way
might simply define weaker notion plans allows repeat certain kinds actions
18. happen L-2-2-2, L-4-2-2, L-2-2-4 instances simply small
high goal probability achieved without thinking much problem; one increases size
instances, problem appears. problem appears earlier presence initial state uncertainty even
small instances LL-2-2-2, LL-4-2-2, LL-2-2-4 uncertainty start position
packages one needs try unloading start airports often.

611

fiD OMSHLAK & H OFFMANN

throwing dice unloading package arbitrarily many times. However, since assumption
observability plan execution, executing plan would
still arise question often action tried. Since Logistics fairly well-solved
domain simpler formalisms virtue Probabilistic-FF, even probabilistic setting
long effects deterministic consider addressing problem quite pressing open
question.

6. Conclusion
developed probabilistic extension Conformant-FFs search space representation, using
synergetic combination Conformant-FFs SAT-based techniques recent techniques
weighted model counting. provided extension conformant relaxed planning
approximate probabilistic reasoning. resulting planner scales well range benchmark domains. particular outperforms close relative, POND, least order magnitude
almost cases tried.
point may somewhat obvious, would emphasize achievements
solve (this particular) problem all. Probabilistic-FF inherits strengths
weaknesses Conformant-FF, domains FFs Conformant-FFs heuristic
functions yield bad estimates (e.g. mentioned Cube-center variant). Whats more, probabilistic setting introduces several new potential impediments FFs performance. one thing,
weighted model counting inherently harder SAT testing. Though happen
set benchmarks, bound cases cost exact model counting becomes
prohibitive even small examples. promising way address issue lies recent methods
approximate model counting (Gomes, Sabharwal, & Selman, 2006; Gomes, Hoffmann, Sabharwal, & Selman, 2007). methods much efficient exact model counters.
provide high-confidence lower bounds number models. lower bounds used
Probabilistic-FF place exact counts. shown good lower bounds
high confidecne achieved quickly. challenge extend methods
currently designed non-weighted CNFs handle weighted model counting.
importantly perhaps, presence probabilistic effects fundamental weakness Probabilistic-FFs PONDs heuristic information. becomes pitfall performance even straightforward adaptation Logistics domain, otherwise easy
kind planners. outlined, key problem that, obtain high enough confidence
goal achievement, one may apply particular actions several times early plan.
Neither Probabilistic-FFs PONDs heuristics good enough identifying many times.
view, finding techniques address issue currently important open topic
area.
Apart addressing latter challenge, intend work towards applicability real-word
settings. Particularly, look space application settings Rovers domain hints at,
medication-type treatment planning domains, power supply restoration domain (Bertoli,
Cimatti, Slaney, & Thiebaux, 2002).
612

fiP ROBABILISTIC -FF

Acknowledgments
authors would thank Dan Bryce Rao Kambhampati providing binary distribution POND2.1. Carmel Domshlak partially supported Israel Science Foundations
grant 2008100, well C. Wellner Research Fund. major parts research
accomplished time Jorg Hoffmann employed Intelligent Information
Systems Institute, Cornell University.

Appendix A. Proofs
Proposition 2 Let (A, NbI , G, ) probabilistic planning problem described k state variables, m-step sequence actions A. Then, |Nba | = O(|NbI |+m(k+1))
largest description size action A.
Proof: proof rather straightforward, exploits local structure Nba CPTs.
first nodes/CPTs layer X(0) Nba constitutes exact copy NbI . Then, 1 m,
t-th layer Nba contains k + 1 node {Y(t) } X(t) .
First, let us consider action node Y(t) . specifying CPT TY (t) straightforward
manner prescribed Eq. 4 might result exponential blow up, Eq. 4 suggests
original description compact specification TY (t) . Therefore, TY (t)
described space O(), description efficiently used answering queries
TY (t) (Y(i) = | ) Eq. 4. Next, consider CPT TX(t) state-variable node X(t) X(t) .
time, rather evident Eq. 5 TX(t) described space O() queries
TX(t) (X(t) = x | X(t1) = x ) could efficiently answered. Thus, summing layers
1 m, description size |Nba | = O(|NbI | + m(k + 1))
Lemma 4 Given node v(t ) Impp(t) , p(t) (v(t )) = (v(t )) if, given v
time , sequence effects E(Impv(t )p(t) ) achieves p probability 1.
Proof: proof Lemma 4 backward induction time layers Impv(t )p(t) .
time t, node Impp(t) time-stamped p(t) itself. node
p(t) (p(t)) = (p(t)) = 1, but, given p time t, empty plan corresponding (empty)
E(Impp(t)p(t) ) trivially re-establishes p certainty. Assuming claim holds
nodes Impp(t) time stamped + 1, . . . , t, show holds nodes
time stamped .
easy see that, node v(t ) Impp(t) , get p(t) (v(t )) = (v(t ))
goes zero. First, consider chance nodes (t ) Impvp(t) . node, lb
set zero p(t) (r(t + 1)) = 1 r add(). However,
inductive assumption, case effects E(Imp(t )p(t+1) ) achieve p
probability 1, given occurrence time .
Now, consider fact nodes q(t ) Impvp(t) . node, get nullified
effect e E(a), A(t ), con(e) = q. latter happens if, possible outcomes e, (i) node (t ) belongs Impp(t) , (ii) estimate p(t) ((t )) = ((t )).
words, inductive assumption, given outcome (e) time , effects E(Imp(t )p(t) ) achieve p probability 1. Thus, given q time , effects
E(Impq(t )p(t) ) achieve p probability 1 independently actual outcome e. Alternatively, q(t ) lb > 0, effect e conditioned q(t), exists
613

fiD OMSHLAK & H OFFMANN

outcome e that, according proved chance nodes time-stamped
, effects E(Imp(t )p(t+1) ) achieve p probability 1. Hence, whole set
effects E(Impq(t )p(t+1) ) achieve p probability 1.
Lemma 5 Let (A, NbI , G, ) probabilistic planning task, sequence actions applicable
bI , |+
1 relaxation function A. time step m, proposition p
P, P (t) constructed build-PRPG(a, A, (NbI ), G, , |+
1 ), p time achieved
relaxed plan starting a|+
1
(1) probability > 0 (that is, p negatively known time t) p (t)P (t),

(2) probability 1 (that is, p known time t) p P (t).
Proof: proof direction straightforward induction t. = claim
immediate direct initialization (m) P (m). Assume that, < t,
p (t ) P (t ), p negatively known time , p P (t ), p known
time .
First, consider p(t) (t) P (t), suppose p egatively know time t.
inductive assumption, property PRPG construction (t 1) P (t 1)
(t) P (t), p 6 (t 1) P (t 1). Therefore, p added (t) (and
then, possibly, moved P (t)) first loop build-timestep procedure.
However, so, exists action A(t 1), e E(a), (e) (i)
con(e) (t 1) P (t 1), (ii) p add(). Again, assumption induction
pre(a) known time 1, con(e) negatively known time 1. Hence,
non-zero probability occurring time implies p achieved time probability
greater 0, contradicting p negatively know time t.
Now, let us consider p(t) P (t). Notice that, > m, p(t) P (t)

_
l .
(28)

lsupport(p(t))

Thus, world state w consistent bI , either q w fact proposition
q(m) support(p(t)), or, effect e action a(t ) A(t ), < t, con(e)
P (t ) {(t ) | (e)} support(p(t)). first case, Lemma 4 immediately implies
concatenation a|+
1 arbitrary linearization (relaxed) actions A(0), . . . , A(t 1)
achieves p probability 1, thus p known time t. second case, inductive
assumption implies con(e) known time t, together Lemma 4 implies
concatenation a|+
1 arbitrary linearization (relaxed) actions A(0), . . . , A(t 1)
achieves p probability 1.
proof direction induction well. = claim
immediate direct initialization P (m). Assume that, < t, p
negatively known time , p (t ) P (t ), p known time , p P (t ).
First, suppose p negatively known time t, yet p 6 (t) P (t).
inductive assumption plus A(t 1) containing NOOP actions propositions
(t 1) P (t 1), know p negatively known time 1. so, p become
negatively known time due (e), e E(a), pre(a) known
614

fiP ROBABILISTIC -FF

time 1, con(e) negatively known time 1. inductive assumption,
latter conditions imply con(e) (t 1) P (t 1), pre(a) P (t 1). so, p
added (t) P (t) first loop build-timestep procedure, contradicting
assumption p 6 (t) P (t).
Now, let us consider p known time t. inductive assumption, P (t 1) contains
facts known time 1, thus A(t 1) maximal subset actions A|+
1 applicable
time 1. Let us begin exhaustive classification effects e actions A(t 1)
respect p time t.
(I) (e) : p add(), con(e) P (t 1)
(II) (e) : p add(), con(e) (t 1)
(III) (e) : p 6 add() con(e) 6 P (t 1) (t 1)
set (I) empty, then, construction build-w-impleafs(p(t), Imp),
{(t 1) | (e)} support(p(t)),
e (I). Likewise, construction build-timestep (notably, update ),
e (I),
_

(t 1).
{(t1)|(e)}

Putting two facts together, Eq. 28 holds p time t, thus p P (t).
Now, suppose set (I) empty. hard verify subset effects (III)
makes p known time t. Thus, event least one effects (II) occurs must hold
probability 1. First, construction build-w-impleafs(p(t), Imp),
[
support (p(t))
support (con(e)(t 1))
e(II)

Then, 4 Lemma 4 event least one effects (II) occurs holds
probability 1
_

l
e(II)
lsupport(con(e)(t1))

Putting two facts together, Eq. 28 holds p time t, thus p P (t).

Theorem 6 Let (A, NbI , G, ) probabilistic planning task, sequence actions appli+
cable bI , |+
1 relaxation function A. build-PRPG(a, A, (NbI ), G, , |1 ) returns
+
FALSE, relaxed plan (A, bI , G, ) starts a|1 .
Proof: Let > 0 last layer PRPG upon termination build-PRPG. every
t, construction PRPG Lemma 5, sets P (t ) (t ) contain
(and all) propositions known (respectively unknown) executing actions
action layers including A(t 1).
615

fiD OMSHLAK & H OFFMANN

First, let us show build-PRPG returns FALSE, corresponding termination criterion would hold future iterations. P (t + 1) = P (t), A(t + 1) = A(t).
Subsequently, since P (t + 1) (t + 1) = P (t) (t) A(t + 1) = A(t),
P (t + 2) (t + 2) = P (t + 1) (t + 1). Given that, show P (t + 2) = P (t + 1)
(t + 2) = (t + 1).
Assume contrary exists p(t + 2) P (t + 2) p(t + 1) 6 P (t + 1),
p(t + 1) (t + 1). construction sets P (t + 1) P (t + 2) build-timestep
procedure,
_

l ,
lsupport(p(t+2))

_

6

(29)

l

lsupport(p(t+1))

Consider exhaustive classification effects e actions A(t + 1) respect p
time + 2.
(I) (e) : p add(), con(e) P (t + 1)
(II) (e) : p add(), con(e) (t + 1)
(III) (e) : p 6 add() con(e) 6 P (t + 1) (t + 1)
Suppose set (I) empty, let e (I). P (t) = P (t + 1) con(e)
P (t), thus {(t)
W | (e)} support(p(t + 1)).
W update build-timestep
{(t)|(e)} (t), thus lsupport(p(t+1)) l, contradicting Eq. 29.
Alternatively, assume set (I) empty. Using arguments similar proof
Lemma 5, p(t + 2) P (t + 2) p(t + 1) 6 P (t + 1) case imply
_
l

e(II)
lsupport(con(e)(t+1))

_

6

(30)

l

e(II)
lsupport(con(e)(t))

However, A(t + 1) = A(t), (t + 1) = (t), P (t + 1) = P (t) together imply
action effects possibly take place time + 1 feasible take place time
t. Therefore, since e (II) con(e) (t + 1) definition (II), Eq. 30
implies
[
[
support (con(e)(t + 1)) (m) 6=
support (con(e)(t)) (m),
(31)
e(II)

e(II)

contradicting termination condition. Hence, arrived contradiction assumption
p(t + 1) 6 P (t + 1).
shown P (t + 2) = P (t + 1) (t + 2) = (t + 1), show
termination criteria implies that, q(t + 2) (t + 2),
(m) support(p(t + 2)) = (m) support(p(t + 1)).
616

fiP ROBABILISTIC -FF

Let Ep(t+2) set effects actions A(t + 1) con(e) (t + 1), and,
outcome (e), p add(). Given that,
(m) support(p(t + 2)) = (m)

[

support(con(e)(t + 1))

[

support(con(e)(t))

eEp(t+2)

= (m)

,

(32)

eEp(t+2)

= (m) support(p(t + 1))
first third equalities definition support sets via Lemma 4, second
equation termination condition.
last things remains shown termination criteria implies get-P(t +
2, G) =get-P(t + 1, G). Considering simple cases first, G 6 P (t + 1) (t + 1),
P (t + 2) (t + 2) = P (t + 1) (t + 1) get-P(t + 2, G) =get-P(t + 1, G) = 0. Otherwise, G P (t + 1), P (t + 2) = P (t + 1) get-P(t + 2, G) =get-P(t + 1, G) = 1.
leaves us case G P (t + 1) (t + 1) G (t + 1) 6= .
P (t + 2) = P (t + 1), (t + 2) = (t + 1), termination condition,
G (t) = G (t + 1) = G (t + 2).
get-P(t + 1, G) =get-P(t, G) know action effects become feasible A(t)
increase estimate probability achieving g G (t + 1) time time
+ 1. However, P (t + 1) = P (t), (t + 1) = (t), A(t + 1) = A(t),
action effect become feasible time + 1 already feasible time t, thus
get-P(t + 1, G) =get-P(t, G) imply get-P(t + 2, G) =get-P(t + 1, G).
point shown build-PRPG returns FALSE, corresponding termination criterion would hold future iterations. Now, assume contrary claim
theorem build-PRPG returns FALSE iteration t, yet exists relaxed plan
(A, bI , G, ) starts a|+
1 . First, = 1, Lemma 5 implies exists time
G P (T ). so, persistence negative termination condition implies
G P (t). However, case would get-P(t, G) = 1 (see second get-P
procedure), thus build-PRPG would return TRUE ever getting check negative
termination condition iteration t. Alternatively, = 0, build-PRPG would terminated
returning TRUE negative termination condition checked even once.
leaves us case 0 < < 1 get-P(t, G) < . (get-P(t, G)
contradict reaching negative termination condition iteration t.) assume
G P (t) (t) P (t) (t) contains facts negatively known time
t, thus persistence negative termination condition together G 6 P (t) (t) would
imply relaxed plan > 0. Let us consider sub-goals G (t) 6= .
(1) subgoals g G (t), implications Impg(t) due deterministic
outcomes effects E(Impg(t) ), uncertainty achieving G (t) time
due uncertainty initial state. Since initial
V belief state reasoned
relaxation, case get-P(t, G) = WMC( gG\P (t) g ) provides us
upper bound probability achieving goal G a|+
1 concatenated
617

fiD OMSHLAK & H OFFMANN

arbitrary linearization arbitrary subset A(0), . . . , A(t 1). termination subcondition get-P(t + 1, G) =get-P(t, G) persistence action sets A(T ), t,
imply get-P(t, G) provides us upper bound probability achieving G
a|+
1 concatenated arbitrary linearization arbitrary subset A(0), . . . , A(T ),
t. Together get-P(t, G) < , latter conclusion contradicts assumption
desired relaxed plan exists.
(2) exists subgoal g G (t) implications Impg(t) due truly
probabilistic outcomes effects E(Impg(t)
actions A(t)
V ), repeating (relaxed) V
A(t + 1) necessarily result WMC( gG\P (t+1) g ) > WMC( gG\P (t) g ),
contradicting termination sub-condition condition get-P(t + 1, G) =get-P(t, G).
Hence, arrived contradiction assumption build-PRPG returns FALSE time t,
yet exists relaxed plan (A, bI , G, ) starts a|+
1.

References
Bertoli, P., Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2001). MBP: model based planner.
Proc. IJCAI01 Workshop Planning Uncertainty Incomplete Information,
Seattle, WA.
Bertoli, P., Cimatti, A., Slaney, J., & Thiebaux, S. (2002). Solving power supply restoration problems planning via symbolic model-checking. Proceedings 15th European Conference Artificial Intelligence (ECAI), pp. 576580, Lion, France.
Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90(1-2), 279298.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129(12),
533.
Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic search belief
space. Proceedings 5th International Conference Artificial Intelligence Planning
Scheduling Systems (AIPS), pp. 5261, Breckenridge, CO.
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence
Bayesian networks. Proceedings Twelfth Conference Uncertainty Artificial
Intelligence (UAI), pp. 115123, Portland, OR.
Brafman, R. I., & Domshlak, C. (2006). Factored planning: How, when, not. Proceedings 18th National Conference Artificial Intelligence (AAAI), pp. 809814, Boston,
MA.
Bryce, D., & Kambhampati, S. (2004). Heuristic guidance measures conformant planning.
Proceedings 14th International Conference Automated Planning Scheduling
(ICAPS), pp. 365374, Whistler, BC, Canada.
Bryce, D., Kambhampati, S., & Smith, D. (2006). Sequential Monte Carlo probabilistic planning
reachability heuristics. Proceedings 16th International Conference Automated
Planning Scheduling (ICAPS), pp. 233242, Cumbria, UK.
618

fiP ROBABILISTIC -FF

Chavira, M., & Darwiche, A. (2005). Compiling Bayesian networks local structure. Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI), pp.
13061312, Edinburgh, Scotland.
Darwiche, A. (2000). Recursive conditioning. Artificial Intelligence, 125(1-2), 541.
Darwiche, A. (2001). Constant-space reasoning dynamic Bayesian networks. International Journal Approximate Reasoning, 26(3), 161178.
Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation. Computational Intelligence, 5, 142150.
Dechter, R. (1999). Bucket elimination: unified framework reasoning. Artificial Intelligence,
113, 4185.
Domshlak, C., & Hoffmann, J. (2006). Fast probabilistic planning weighted model counting. Proceedings 16th International Conference Automated Planning
Scheduling (ICAPS), pp. 243252, Cumbria, UK.
Gomes, C. P., Hoffmann, J., Sabharwal, A., & Selman, B. (2007). sampling model counting.
Proceedings 20th International Joint Conference Artificial Intelligence (IJCAI07), Hyderabad, India.
Gomes, C. P., Sabharwal, A., & Selman, B. (2006). Model counting: new strategy obtaining good bounds. Proceedings 21th National Conference Artificial Intelligence
(AAAI-06), pp. 5461, Boston, MA.
Hanks, S., & McDermott, D. (1994). Modeling dynamic uncertain world I: Symbolic
probabilistic reasoning change. Artificial Intelligence, 66(1), 155.
Hoffmann, J., & Nebel, B. (2001). planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Hoffmann, J., & Brafman, R. (2006). Conformant planning via heuristic forward search: new
approach. Artificial Intelligence, 170(67), 507541.
Huang, J. (2006). Combining knowledge compilation search efficient conformant probabilistic planning. Proceedings 16th International Conference Automated Planning
Scheduling (ICAPS), pp. 253262, Cumbria, UK.
Hyafil, N., & Bacchus, F. (2004). Utilizing structured representations CSPs conformant
probabilistic planning. Proceedings European Conference Artificial Intelligence
(ECAI), pp. 10331034, Valencia, Spain.
Jensen, F. (1996). Introduction Bayesian Networks. Springer Verlag, New York.
Kushmerick, N., Hanks, S., & Weld, D. (1995). algorithm probabilistic planning. Artificial
Intelligence, 78(1-2), 239286.
Little, I., Aberdeen, D., & Thiebaux, S. (2005). Prottle: probabilistic temporal planner. Proceedings 20th National Conference Artificial Intelligence (AAAI-05), pp. 1181
1186, Pittsburgh, PA.
Littman, M. L., Goldsmith, J., & Mundhenk, M. (1998). computational complexity probabilistic planning. Journal Artificial Intelligence Research, 9, 136.
619

fiD OMSHLAK & H OFFMANN

Majercik, S. M., & Littman, M. L. (1998). MAXPLAN: new approach probabilistic planning. Proceedings 4th International Conference Artificial Intelligence Planning
Systems (AIPS), pp. 8693, Pittsburgh, PA.
Majercik, S. M., & Littman, M. L. (2003). Contingent planning uncertainty via stochastic
satisfiability. Artificial Intelligence, 147(1-2), 119162.
McDermott, D. (1998). 1998 AI Planning Systems Competition. AI Magazine, 2(2), 3555.
McDermott, D. V. (1999). Using regression-match graphs control search planning. Artificial
Intelligence, 109(1-2), 111159.
Onder, N., Whelan, G. C., & Li, L. (2006). Engineering conformant probabilistic planner. Journal
Artificial Intelligence Research, 25, 115.
Pearl, J. (1984). Heuristics - Intelligent Search Strategies Computer Problem Solving. AddisonWesley.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference.
Morgan Kaufmann, San Mateo, CA.
Rintanen, J. (2003). Expressive equivalence formalisms planning sensing. Proceedings 13th International Conference Automated Planning Scheduling (ICAPS),
pp. 185194, Trento, Italy.
Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82(1-2), 273
302.
Russell, S., & Norvig, P. (2004). Artificial Intelligence: Modern Approach (2 edition). Pearson.
Sang, T., Bacchus, F., Beame, P., Kautz, H., & Pitassi, T. (2004). Combining component caching
clause learning effective model counting. (Online) Proceedings 7th International Conference Theory Applications Satisfiability Testing (SAT), Vancouver, BC,
Canada.
Sang, T., Beame, P., & Kautz, H. (2005). Solving Bayes networks weighted model counting.
Proceedings 20th National Conference Artificial Intelligence (AAAI), pp. 475482,
Pittsburgh, PA.
Shimony, S. E. (1993). role relevance explanation I: Irrelevance statistical independence. International Journal Approximate Reasoning, 8(4), 281324.
Shimony, S. E. (1995). role relevance explanation II: Disjunctive assignments approximate independence. International Journal Approximate Reasoning, 13(1), 2760.
Zhang, N. L., & Poole, D. (1994). simple approach Bayesian network computations.
Proceedings 10th Canadian Conference Artificial Intelligence, pp. 171178, Banff,
Alberta, Canada.

620


