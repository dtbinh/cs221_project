journal artificial intelligence

submitted published

probabilistic via heuristic forward search
weighted model counting
carmel domshlak

dcarmel ie technion ac il

technion israel institute technology
haifa israel

jorg hoffmann

j oerg h offmann deri

university innsbruck deri
innsbruck austria

abstract
present probabilistic observability
called probabilistic extends heuristic forward search machinery conformant probabilistic uncertainty initial state action effects specifically
probabilistic combines conformant ffs techniques powerful machinery weighted
model counting weighted cnfs serving elegantly define search space
heuristic function evaluation probabilistic shows fine scalability range probabilistic domains constituting several orders magnitude improvement previous
area use problematic case point main open issue addressed


introduction
address probabilistic observability kushmerick
hanks weld known ai community conditional majercik
littman conformant hyafil bacchus probabilistic
given initial belief state form probability distribution world states w
set actions possibly probabilistic effects set alternative goal states wg w
solution single sequence actions transforms system one
goal states probability exceeding given threshold basic assumption
system cannot observed time plan execution setting
useful controlling systems uncertain initial state non deterministic actions sensing
expensive unreliable non probabilistic conformant may fail due non existence
plan achieves goals certainty even plan plan
necessarily contain information actions useful achieve requested
threshold
state art performance probabilistic planners advancing much slowly
deterministic planners scaling step plans world states
step plans world states kushmerick et al majercik
littman hyafil bacchus since probabilistic inherently harder
deterministic counterpart littman goldsmith mundhenk difference evolution
rates surprising however recent developments area onder whelan li
bryce kambhampati smith huang particular work
dramatic improvements probabilistic obtained
c

ai access foundation rights reserved

fid omshlak h offmann

introduce probabilistic probabilistic planner heuristic forward search space implicitly represented probabilistic belief states planner natural
extension recent non probabilistic conformant planner conformant hoffmann brafman main trick replace conformant ffs sat techniques recent
powerful technique probabilistic reasoning weighted model counting wmc propositional cnfs sang beame kautz detail conformant forward search
belief space belief state corresponds set world states considered
possible main trick conformant use cnf formulas implicit representation belief states implicit context means formulas encode semantics
executing action sequence initial belief state propositional variables corresponding
facts time stamps actual knowledge belief states inferred
formulas particularly fact p known true belief state
p time endpoint formula knowledge computed
conformant belief states known facts well symmetrically facts
known false suffices strips style determine applicable
actions goal belief states heuristic function ffs hoffmann nebel relaxed
graph technique enriched approximate sat reasoning
basic ideas underlying probabilistic
define time stamped bayesian networks bns describing probabilistic belief states
ii extend conformant ffs belief state cnfs model bns
iii addition sat reasoning used conformant use weighted model counting
determine whether probability unknown goals belief state high enough
iv introduce approximate probabilistic reasoning conformant ffs heuristic function
note synergetic effect probabilistic uses conformant ffs technology recognize
facts true false probability fully serves determine applicable actions
well detect whether part goal already known fact conformant ffs cnfbased techniques specifically made suit probabilistic setting without probabilities
one could imagine successfully replacing cnfs bdds probabilities seems much
problematic
present cover probabilistic initial belief states given bayesian networks
deterministic probabilistic actions conditional effects standard action preconditions
experiments quite effective range domains contrast
sat csp approaches mentioned majercik littman hyafil bacchus
probabilistic step plans instances billions world states
however comparison entirely fair due different nature provided
sat csp approaches provide guarantees length solution
closely related probabilistic implemented pond bryce et al system
probabilistic conformant probabilistic threshold non admissible
graph heuristic guide search hence comparison probabilistic
pond fair experiments perform comparative evaluation probabilistic
pond two approaches related significant differences search


fip robabilistic

space representation well definition computation heuristic function run
two approaches range domains partly taken probabilistic literature
partly obtained enriching conformant benchmarks probabilities partly obtained
enriching classical benchmarks probabilistic uncertainty almost cases conformant
outperforms pond least order magnitude make interesting observations
regarding behavior two planners particular identify domain derived
classical logistics domain approaches fail scale apparent reason neither
good enough detecting many times early point plan probabilistic
action must applied order sufficiently support high goal threshold end plan
devising methods better regard pressing open issue line work
structured follows next section provides technical background formally
defining address illustrating running example section details
probabilistic belief states represented time stamped bayesian networks bayesian
networks encoded weighted cnf formulas necessary reasoning performed
representation section explains illustrates extension conformant ffs heuristic function probabilistic settings section provides empirical section
concludes proofs moved appendix

background
probabilistic framework consider adds probabilistic uncertainty subset
classical adl language namely sequential strips conditional effects strips
tasks described set propositions p triples g corresponding
action set initial world state goals g sets propositions describes
concrete initial state wi g describes set goal states w g actions pairs
pre e precondition conditional effects conditional effect e triple
con e add e del e possibly empty proposition sets corresponding effects condition add delete lists respectively precondition pre proposition set
action applicable world state w w pre applicable w
applying w undefined applicable w conditional effects
e e w con e occur occurrence conditional effect e w world
state w add e del e
action applied w proposition q q add e del e
possibly occurring e e e applying w undefined thus
require actions self contradictory every e e e
exists world state w con e con e add e del e finally action
sequence plan world state iterative execution actions starting
wi leads goal state w g
probabilistic
probabilistic setting extends probabilistic uncertainty
initial state ii actions probabilistic effects general probabilistic
pond use implicit belief states probabilistic part heuristic function uses sampling techniques
rather probabilistic reasoning techniques employ



fid omshlak h offmann

tasks quadruples bi g corresponding action set initial belief state goals
acceptable goal satisfaction probability g set propositions initial state
longer assumed known precisely instead given probability distribution
world states bi bi w describes likelihood w initial world state
similarly classical actions pairs pre e effect set e
richer structure semantics e e pair con e e propositional condition set probabilistic outcomes probabilistic outcome e
triplet p r add del add delete lists p r probability outcome occurs effect e naturally
p require probabilistic effects
define probability distributions outcomes e p r special case
deterministic effects e modeled way via e p r unconditional actions
modeled single effect e con e applicable w
applying w undefined otherwise applicable w exists
exactly one effect e e con e w e applying w
w add del probability p r likelihood b w world state w
belief state b resulting applying probabilistic action b given
b w

x

wpre

b w

x

e


p r w w add del



e effect con e w kronecker step function takes
value argument predicate evaluates true otherwise
formalism covers description features supported previously proposed
formalisms conformant probabilistic kushmerick et al majercik littman
hyafil bacchus onder et al bryce et al huang corresponds called unary nondeterminism nd normal form rintanen note
succinct forms specifying probabilistic rintanen
yet nd normal form appears intuitive perspective knowledge engineering
example say robot block physically one two locations
information captured propositions r r robot b b block respectively robot move one location another carrying block
robot moves without block move guaranteed succeed provides us
pair symmetrically defined deterministic actions move right move lef action move right empty precondition single conditional effect e r
p r add r del r robot tries move carrying block
move succeeds probability probability robot ends moving
without block probability move robot fails completely provides us
pair symmetrically defined probabilistic actions move b right move b lef
action move b right empty precondition two conditional effects specified
table
specified semantics structure components bi g
ready specify actual task probabilistic setting recall actions
transform probabilistic belief states belief states action sequence belief


fip robabilistic

e

con e

e

r b

e

r b

e

p r

add

del











r b
r



r b
r



table possible effects outcomes action move b right example
state b belief state b resulting applying b given


hi
b
b b

hai





b hai



setting achieving g certainty typically unrealistic hence specifies required
lower bound probability achieving g sequence actions called plan
ba g belief state ba bi
specifying initial belief state
considering initial belief state practical considerations force us limit attention
compactly representable probability distributions bi numerous alternatives
compact representation structured probability distributions bayes networks bns pearl
date far popular representation model therefore probabilistic
assume initial belief state bi described bn nbi set propositions p
excellent introductions bns abound e g see jensen suffices briefly
define notation bn n g represents probability distribution directed acyclic
graph g set nodes x stands random variables assumed discrete
set tables conditional probabilities cpts one table tx node x x
possible value x dom x dom x denotes domain x table tx
lists probability event x x given possible value assignment immediate
ancestors parents p x g thus table size exponential degree x usually
assumed degree small pearl probabilistic dependence x
p x induces significant local structure allowing compact representation tx shimony
boutilier friedman goldszmidt koller otherwise representation
distribution bn would good idea first place joint probability complete
assignment variables x given product x terms taken respective
cpts pearl


p r x p x
tx x p x
p r
xx

xx

stands partial assignment provided corresponding subset x
bns choice framework support well e g stochastic decision trees



fid omshlak h offmann

probabilistic allow nbi described multi valued variables underlying
significantly simplifies process specifying nbi since strips

propositions p
sknot correspond true random variables underlying specification
specifically let pi partition p proposition set pi uniquely corresponds
domain multi valued variable underlying every world state w
every pi pi exactly one proposition q pi holds w variables
bn nbi describing initial belief state bi x x xk dom xi pi
pi dom xi q q pi q
example illustration nbi consider running example say robot
known initially one two possible locations probability p r r
p r r suppose correlation belief initial locations robot
block believe robot r p r b p r b
robot r p r b p r b initial belief state bn nbi defined
two variables r robot b block dom r r r dom b b b
respectively depicted figure
r


r


r

b

r
r

b



b



figure bayes network nbi example
hard see strips style actions equivalently specified terms
multi valued variables x specifically pi action add proposition
q pi without deleting proposition q pi thus consider setting
xi q pi adding deleting q pi standard semantics setting xi q
xi q respectively simplicity presentation assume actions selfcontradictory level x wellif two conditional effects e e e possibly occur
world state w subsets x affected two effects disjoint finally
goal g directly corresponds partial assignment x unless g self contradictory
requiring q q q q pi

belief states
section explain representation reasoning belief states first explain
probabilistic belief states represented time stamped bns explain
bns encoded reasoned form weighted cnf formulas representation
belief states weighted cnfs illustrated belief state running example
figure finally provide details works probabilistic
specifying nbi directly p would require identifying multi valued variables anyway followed connecting
propositions corresponding multi valued variable complete dag normalizing cpts
propositions certain manner



fip robabilistic


r

r

r r

r



b

ii
ii
ii
ii
ii


uu
uu
u
u
uu
uu

b b
r
r



r




r




r
n
n
n
nnn
nnn
n
n

nn
nnn
r b
ppp
ppp

ppp othrw
ppp
ppp
p
b

b b


b

b

r r
r
r
r

b

b b
b
b

figure bayes network nba running example action sequence
hmove b right move lef ti

bayesian networks
probabilistic performs forward search space belief states search states belief
states probability distributions world states w search restricted belief
states reachable initial belief state bi sequences actions key decision
one make actual representation belief states let bi initial belief state
captured bn nbi let ba belief state resulting applying bi sequence
actions one well known area decision theoretic
description ba directly state variables x becomes less less structured number
especially stochastic actions increases overcome limitation represent belief
states ba bn nba explicitly captures sequential application starting bi trading
representation size cost inference compared representing belief states directly
distributions world states formally specify structure bn nba assuming
actions applicable corresponding belief states application later
showing probabilistic makes sure indeed case note belief state
bns similar spirit structure proposed ai literature verifying
probabilistic plan achieves goals certain probability dean kanazawa hanks
mcdermott kushmerick et al
figure illustrates construction nba running example hmove b right
move lef ti general let ha sequence actions numbered according
appearance let x replica state variables x x x


fid omshlak h offmann

corresponding x x variable set nba union x x plus
additional variables introduce actions
first x x set parents p x conditional probability tables
tx simply copy state variable x nbi consider action
let action introduce discrete variable
mediates
variable layers x x domain set dom ee e
union probabilistic outcomes possible effects parents nba set
p



ee


x con e dom x



dom p set
ty


p r



con e

otherwise



e denotes effect e e
refer set variables created actions let ex
e probabilistic effects affect variable x x ex set
p x x

x x


tx x x x x
otherwise
otherwise ex let x dom x value provided x e e ex
recall outcomes effects e mutually exclusive hence set p x
x



tx x x x x









e ex x x
e ex x x
otherwise



e denotes effect responsible outcome
hard verify equations capture frame axioms probabilistic semantics oursactions principle accomplishes construction nba variables
xba
x note however mediating variable really needed
truly probabilistic actions specifically deterministic action let ex e
conditional effects add delete propositions associated domain variable x x ex set p x x tx according equation
otherwise set

n

p x x
x
con e dom x

eex

specify tx follows let xe dom x value deterministic outcome
effect e ex provides x dom p x exists e ex


fip robabilistic

con e set
tx x



x


x xe
otherwise



x x
otherwise



otherwise set
tx x



x


due self consistency action hard verify equations consistent
together equation capture semantics conditional deterministic actions
special treatment deterministic actions illustrated figure direct dependencies
x x
proposition let nbi g probabilistic step sequence
actions applicable bi let p r joint probability distribution induced nba
variables xba belief state ba corresponds marginal distribution p r x
ba x p r x g partial assignment provided g x probability
ba g achieves g starting bi equal p r g
already mentioned belief state bns constructed along principles outlined
used dean kanazawa hanks mcdermott kushmerick et al
thus correctness proposition immediate previous
point worth bringing attention fact variables x x completely
deterministic moreover cpts variables nba compactly representable due
low number parents local structure induced large amount context specific
independence compactness cpts nba implied compactness
strips style specification actions exploiting compactness action
specification size nba description kept linear size input
number actions
proposition let nbi g probabilistic described k state variables step sequence actions nba nbi k
largest description size action
proof proposition well proofs formal claims relegated
appendix pp
weighted cnfs
given representation belief states bns next select mechanism reasoning
bns general computing probability query bns known pcomplete roth addition hard verify analysis similar ones
darwiche brafman domshlak networks arising work
typically exhibit large tree width numerous exact inference bns
proposed literature darwiche dechter zhang poole
classical scale well large networks exhibiting high tree width positive


fid omshlak h offmann

side however observation guides recent advances area probabilistic reasoning
real world domains typically exhibit significant degree deterministic dependencies
context specific independencies variables targeting property practical
bns already resulted powerful inference techniques chavira darwiche sang et al
general principle underlying techniques
compile bn n weighted propositional logic formula n cnf
ii perform efficient weighted model counting n reusing adapting certain
techniques appear powerful enhancing backtracking dpll style search sat
one observation early stages developing probabilistic type
networks type queries make machinery solving bns
weighted cnf model counting attractive needs first section already
shown bns representing belief states exhibit large amount deterministic nodes
context specific independence second queries interest correspond computing
probability evidence g nba type query clear interpretation terms
model counting sang et al hence taking route probabilistic compile
belief state bns weighted cnfs following encoding scheme proposed sang et al
answer probabilistic queries cachet sang bacchus beame kautz pitassi one
powerful systems date exact weighted model counting cnfs
general weighted cnfs weights formulas specified follows let
v v vn set propositional variables dom vi vi vi let

non negative real valued weight function literals v
dom vi r
partial assignment v q
weight assignment defined product literals
weights l l finally propositional logic formula called weighted
defined weighted set propositional variables weighted formula v
weight defined sum weights complete assignments v satisfying

x


dom v

dom v dom vi instance variables vi vi vi
simply stands number complete assignments v satisfy
given initial belief state bn nbi sequence actions ha applicable
bi describe weighted cnf encoding nba ba short belief state
ba built used probabilistic first formally specify generic scheme introduced
sang et al encoding bn n variables x weighted cnf n
encoding formula n contains two sets variables first variable z x
value z dom z formula n contains state proposition literals z z weighted
z z state propositions act ba regular sat propositions
variable z xba let dom z z zk arbitrary fixed ordering dom z
recall row tz cpt z corresponds assignment set assignments p z thus number rows tz upper bounded number different
assignments p z happens case significantly lower dependence z p z induces substantial local structure following ordering dom z
entry tz j contains conditional probability p r zj every cpt entry


fip robabilistic

procedure basic wmc
return
empty clause return
select variable v
return basic wmc v v basic wmc v v
figure basic dppl style weighted model counting
tz j last one e tz k formula n contains chance proposition literals
hzji hzji chance variables aim capturing probabilistic information cpts
nba specifically weight literal hzji set p r zj z zj
conditional probability entry true given row true prior entry row
true
tz j
pj
k tz k



hzj hzji

hzji



considering clauses n variable z x cpt entry tz j
formula n contains clause


hz hzj
hzji zj


conjunction literals forming assignment dom p z clauses
ensure weights complete assignments variables n equal probability corresponding atomic events postulated bn n illustrate construction
equations let boolean variables b parents ternary variable c
dom c c c c bn let p r c b p r c b
p r c b let raw corresponding assignment b p c th
row cpt tc encoding bn first two entries raw tc captured
pair respective chance propositions
hc hc according
equation weights





propositions set hc hc according
equation encoding contains three clauses

b hc c

b hc hc c

b hc hc c

finally variable z x formula n contains standard set clauses encoding
exactly one relationship state propositions capturing value z accomplishes encoding n n next section illustrate encoding
belief state bn running example
weighted cnf encoding ba belief state bn nba provides input weighted
model counting procedure simple recursive dppl style procedure basic wmc underlying cachet sang et al depicted figure formula v obtained setting


fid omshlak h offmann

literal v true theorem sang et al shows weighted cnf encoding
bn n p r q e general query respect n query q evidence e

basic wmc q e
p r q e


basic wmc e
query q evidence e fact arbitrary formulas propositional logic note
special relevant us case empty evidence equation reduces p r q
basic wmc q single call basic wmc procedure corollary immediate
proposition theorem sang et al
corollary let bi g probabilistic task bn nbi describing bi
step sequence actions applicable bi probability ba g achieves g starting
bi given
ba g wmc ba g

g conjunction goal literals time stamped time endpoint
example weighted cnf encoding belief states
illustrate generic bn wcnf encoding scheme sang et al belief
state bn nba running example figure
introduce time stamped state propositions r r b b likewise
introduce four state propositions corresponding values
variable first set clauses ba ensure exactly one relationship
state propositions capturing value variable nba



j

yi yj




r r r r
b b b b
proceed encoding cpts nba root nodes one row
cpts chance propositions identified corresponding state variables sang
et al hence root variable r need neither additional clauses special
chance propositions state proposition r ba treated chance proposition
r
encoding variable b bit involved cpt tb contains two content wise
different rows corresponding given r given r cases cases induce
non deterministic dependence b r encode content tb introduce
two chance variables hb hb hb hb
positive literals hb hb capture events b given r b given r
negations hb hb capture complementary events b given r b
given r respectively consider given r row tb encode row need


fip robabilistic



ba contain r hb b r hb b similar encoding
required row given r thus encoding tb introduces four additional clauses


r hb b r hb b



r hb b r hb b

finished nbi part nba proceed encoding variable corresponding probabilistic action move b right encode first row ty introduce three chance propositions h h h general chance variables needed last entries cpt rows weights chance propositions


set according equation h h



h chance propositions add ba four clauses
equation notably first four clauses equation
proceeding second row ty observe value r b case fully
determines value deterministic dependence encoded without
chance propositions last two clauses equation

r b h

r b h h

r b h h h


r b h h h


r b

state chance variables introduced r b encode cpts r
b
r r r

r r r r

r r r r

b b



b b
b b
since cpts r b completely deterministic encoding well
chance propositions finally encode deterministic cpts r b
r r
b b b



b b
unary clause r reduction r r r r accomplishes encoding ba


fid omshlak h offmann

conformant probabilistic
besides fact weighted model counting attractive kinds bns arising context weighted cnf representation belief states works extremely well ideas underlying conformant hoffmann brafman outlined introduction already
give details
stated conformant forward search non probabilistic belief space
belief state corresponds set world states considered possible main trick
conformant use cnf formulas implicit representation belief states
formulas encode semantics executing action sequence initial belief state facts
known true false inferred formulas computation partial
knowledge constitutes lazy kind belief state representation comparison approaches
use explicit enumeration bonet geffner bdds bertoli cimatti pistore roveri
traverso fully represent belief states basic ideas underlying probabilistic
define time stamped bayesian networks bn describing probabilistic belief states section
ii extend conformant ffs belief state cnfs model bn section
iii addition sat reasoning used conformant use weighted model counting
determine whether probability unknown goals belief state high enough
directly
iv introduce approximate probabilistic reasoning conformant ffs heuristic function section
detail given probabilistic task bi g belief state ba corresponding
applicable bi step action sequence proposition q p say q known
ba ba q negatively known ba ba q unknown ba otherwise begin
determining whether q known negatively known unknown time
conformant machinery classification requires two sat tests ba q
ba q respectively information provided classification used threefold first
subgoal g g negatively known time ba g extreme
subgoals g known time ba g finally subgoals
g known rest unknown time accomplish evaluating belief state ba
testing whether
ba g wmc ba g



note sets positively negatively known propositions time steps
allows us significantly simplify cnf formula ba g inserting
corresponding values known propositions
evaluating considered action sequence get ba g done
otherwise forward search continues actions applicable ba thus used
generate successor belief states actions whose preconditions known ba


fip robabilistic

heuristic function
key component heuristic search procedure heuristic function quality informedness computational cost function determine performance search
heuristic function usually obtained solutions relaxation actual interest pearl russell norvig classical successful idea
use relaxation ignores delete effects actions mcdermott bonet geffner
hoffmann nebel particular heuristic system
notion relaxed plan plan achieves goals assuming delete
lists actions empty relaxed plan computed graphplan style blum furst
technique combining forward chaining graph construction phase backward chaining
plan extraction phase heuristic value h w provides world state w encountered
search length relaxed plan w conformant methodology
extended setting conformant initial state uncertainty without uncertainty
action effects herein extend conformant ffs machinery handle probabilistic initial
states effects section provides background techniques used conformantff sections detail forward backward chaining phases
probabilistic respectively two phases probabilistic heuristic
computation illustrated running example sections respectively
conformant
specify relaxed plans computed provide coarse sketch
computed conformant purpose latter slowly prepare reader
come conformant ffs techniques used probabilistic anyway hence
described full detail part sections
formally relaxed plans classical computed follows starting w
builds relaxed graph sequence alternating proposition layers p action
layers p w set actions whose preconditions
contained p p obtained p including add effects fulfilled
conditions actions p contains facts true one
would execute relaxed versions actions earlier layers relaxed
graph constructed reaches propositional layer p contains
goals construction reaches fixpoint p p without reaching goals
latter case corresponds situations relaxed plan exist
existence relaxed plan necessary condition existence real plan state w
excluded search space setting h w former case g p relaxed
plan subset actions suffices achieve goals ignoring
delete lists extracted simple backchaining loop goal p select
action achieves goal iterate process considering
actions preconditions respective effect conditions subgoals heuristic estimate
h w set length extracted relaxed plan number actions selected
backchaining process
aiming extending machinery conformant conformant hoffmann brafman suggested extend relaxed graph additional fact layers containing facts unknown time reason unknown


fid omshlak h offmann

facts become known relaxed graph complexity type reasoning
prohibitive conformant relaxes task ignoring delete lists
one unknown conditions action effect action appears
layer effect e con e p con e
con e arbitrarily reduced contain exactly one literal reasoning done
con e reduced form beginning
v
relaxation converts implications ccon e c q action effects
induce unknown propositions projections take form binary implications c q arbitrary c con e due layered structure
graph set binary implications c q seen forming
directed acyclic graph imp given relaxations graph captures exactly dependencies truth propositions time hence checking whether proposition q becomes
known time done follows first backchain implication edges imp end
q collect set support q leafs reached cnf formula
describing possible initial states test sat check whether


l
lsupport q

test succeed least one leafs support q true every possible
initial state given relaxations case applying actions
relaxed graph q true time
process extracting relaxed plan constructed conformant relaxed
graph extension ffs respective process machinery selects actions responsible
relevant paths imp overall conformant heuristic machinery sound complete
relaxed tasks yields heuristic function highly informative across range challenging
domains hoffmann brafman
work adopt conformant ffs relaxations ignoring delete lists action effects well one propositions effects condition accordingly adopt
following notations conformant given set actions denote
function

set possible actions maps action similar
empty delete lists one conditioning propositions effect removed



denote action set obtained applying
write

actions





denote












action
sequence
sequence



actions obtained applying every action along

hi
hi






ha hai
probabilistic task bi g task
bi g called relaxation


bi g finally plan bi g called relaxed plan
bi g
following conformant terminology leafs refer nodes zero degree
note would possible full sat check without projection without relying imp see
whether q becomes known however indicated full check every unknown proposition
every level relaxed graph every search state would likely expensive computationally



fip robabilistic

next two sections describe machinery underlying probabilistic heuristic
estimation due similarity conceptual relaxations used probabilistic
conformant probabilistic inherits almost conformant ffs machinery course
contributions dealing probabilistic belief states probabilistic
actions
probabilistic relaxed graphs
conformant probabilistic computes heuristic function two steps first
one chaining forward build relaxed graph second step chaining backward
extract relaxed plan section describe detail probabilistic ffs forward chaining step
building probabilistic relaxed graph prpg short section
one extract probabilistic relaxed plan prpg provide detailed illustration
prpg construction process basis running example since illustration
lengthy moved separate section
building prpg quite involved instructive first consider
key points delving details main issue course need
extend conformant ffs machinery ability determine goal set sufficiently
likely rather known true sure achieve must introduce
relaxed effective reasoning probabilistic initial state effects
probabilistic actions turns reasoning obtained certain weighted
extension implication graph nutshell want determine likely fact
q true time propagate certain weights backwards implication graph
starting q weight q set weight p gives estimate
probability achieving q given p holds computing probability exactly would
course expensive estimation assuming independence
probabilistic events involved choice made carefully experimented widely
options deciding favor technique
simplifying assumption weight propagation constitutes course another relaxation
top relaxations already inherited conformant particularly problematic
aspect assuming independence estimating technique actual weight
node p probability achieving q given p holds may lower
estimate effect prpg may decide wrongly relaxed plan exists even execute
relaxed actions contained successful prpg probability achieving goal
execution may less required threshold words lose soundness relative
relaxed tasks relaxed process
experimented alternative weight propagation method opposite assumption relevant probabilistic events co occur hence weights must
propagated according simple maximization operations propagation method yielded
uninformative heuristic values hence inacceptable empirical behaviour probabilistic
even simple benchmarks view seems unlikely estimating yet informative efficient weight computation exists experimented alternative
non estimating propagation schemes particular one assuming probabilistic events completely disjoint hence weights added schemes gave better


fid omshlak h offmann

performance maximization lagged far behind independence assumption
challenging benchmarks
let us get actual building prpg coarse outline
follows prpg built layer wise fashion iteration extending prpg reaching
time another layer reaching time actions step whose
preconditions known hold effects conditioned unknown facts note reduction
effect conditions single fact constitute edges implication graph difference
conformant dont obtain single edge condition add effect instead obtain edges
condition chance nodes chance node represents probabilistic outcome
effect chance nodes turn linked edges respective add effects weights
chance nodes set probabilities respective outcomes weights
nodes set weights static weights dynamically modified
weight propagation rather static weights form input propagation
implication graph edges inserted layer checks whether
facts become known check done much corresponding check conformant
testing whether disjunction support leafs proposition p implied
initial state formula two differences conformant leafs relevant whose
dynamic weight otherwise achieving leaf guaranteed accomplish p
another reason p become known may outcomes unconditional effect
effect known condition achievement p time elegantly formulate
overall test single implication test support leafs whose dynamic weight equals
weight
ffs conformant ffs prpg process two termination criteria
prpg terminates positively goal probability high enough time prpg terminates
negatively nothing changed may higher goal propability
future goal probability layer computed weighted model counting
formula derived support leafs goals known true criteria negative
termination check whether facts become known unknown negatively known
whether possibly relevant support leafs appeared whether goal probability
increased neither case stop safelyif prpg terminates unsuccessfully
guarantee relaxed plan corresponding belief hence
dead end
let us get details figure depicts main routine building prpg belief
state ba already specified sets p contain propositions
known hold time hold probability propositions unknown hold
time hold probability less greater actions known
applicable time respectively layers prpg capture applying relaxed actions
starting ba layers prpg correspond step action sequence leading
initial belief state belief state question ba inherit latter technique
conformant sense prpg reasons past may look confusing first
sight simple reason imagine prpg starts level instead check whether
proposition becomes known sat tests regarding support leafs belief
state formula ba instead initial state formula similarly weighted model counting
test whether goal likely enough testing ba possible expensive


fip robabilistic

procedure build prpg nbi g

returns bool saying relaxed plan belief state
given ham
builds data structures relaxed plan extracted
nbi imp
p p p known p p unknown


n oop
build timestep
endfor

get p g

pre p n oop
build timestep
p p

p support p support p
get p g get p g
return false
endif

endwhile
return true

figure main routine building probabilistic relaxed graph prpg
computationally negative index layers chain implication graph way back
initial state hence enable us perform sat tests typically much smaller initial
state formula
returning figure prpg initialized empty implication set imp p
assigned propositions known unknown initial belief state
weighted cnf formula initialized nbi formula implication weighted model checking tests run asking whether proposition becomes known whether
goal likely enough prpg built incrementally extended clauses
capture behavior different effect outcomes
loop builds sets p time steps iterative invocation
build timestep procedure time expands prpg single time level
iteration sets p made contain propositions
known unknown applying relaxed version action remember
ha simplify presentation action set contains set dummy
actions n oop simply
transport

propositions time layer time layer
formally n oop noopp p p pre noopp e noopp p
p
conformant configuration implemented option significantly slows search
domains brings advantages cases



fid omshlak h offmann

subsequent loop constructs relaxed graph layer onwards
iterative invocation build timestep procedure actions layer
relaxations actions whose preconditions known hold time certainty
iterative construction controlled two termination tests first goal estimated hold
layer probability higher know relaxed plan estimate extracted
otherwise graph reaches fix point know relaxed thus real plan
bi exists postpone discussion two termination criteria focus
time layer construction procedure build timestep
procedure build timestep
builds p implication edges
induced action set
p p
effects e action con e p
e
add
introduce fact p r
imp imp p p add
endfor
con e
sthen
imp imp e con e
else
v
e e
endif
endfor
p
build w impleafs p imp
support p l l leafs impp p l l
w
lsupport p l p p p endif
endfor
p

figure building time step prpg
build timestep procedure shown figure first loop build timestep proceeds
outcomes relaxed actions given set may occur time
probabilistic outcome introduce chance proposition weighted conditional likelihood
outcome extend imp binary implications chance
proposition add list outcome uncertain condition con e
corresponding effect time con e add implications
con e chance propositions created outcomes e otherwise con e
known time uncertainty ability make effect e hold time
case ground chance propositions created outcomes e
implication graph simply extend running formula clauses capturing exactly
one relationship chance propositions corresponding alternative outcomes e
course implementation special case treatment deterministic actions chance nodes
rather single chance node static weight



fip robabilistic

time way probabilistic uncertainty outcome e treated
property initial belief state bi type knowledge add knowledge
base formula initializing build prpg nbi
notation
impvu
impu
leafs imp
e imp

description
graph containing exactly paths node v node u imp
subgraph imp formed node u ancestors u imp
set zero degree nodes subgraph imp imp
set time stamped action effects responsible implication edges
subgraph imp imp
table overview notations around implication graph

second loop checks whether proposition p unknown time becomes known
time part build timestep procedure somewhat involved table provides
overview main notations used follows discussing uses
implication graph imp
first thing second loop build timestep call build w impleafs procedure associates node v impp estimate p v probability achieving
p time effects e impv p given v holds time words
dynamic weight according p implication graph nodes computed note v
time stamped proposition q q p chance proposition
probabilistic outcome
discuss build w impleafs procedure detail proceeding understand
second loop build timestep main thing need know following lemma
lemma given node v impp p v v
given v time sequence effects e impv p achieves p probability
words v leads p certainty iff dynamic weight v equals static
weight simple consequence weight propagation arranged hold true
reasonable weight propagation scheme mark node certain full
proof lemma appears appendix pp
consider second loop build timestep happens following
finished build w impleafs weight propagation p time
collect leafs support p impp meet criteria lemma
check call sat solver whether knowledge base formula implies disjunction leafs
implication holds examined fact p time added set facts known time
finally procedure removes set facts known possibly hold time
facts proven hold time certainty
understand consider following lemma support p contains
exactly set leafs achieving lead p certainty hence basically


fid omshlak h offmann

procedure build w impleafs p imp
top propagation weights p p nodes impp
p p
decreasing time steps
chance nodes impp


q
p r
radd r imp
p
p
endfor
fact nodes q impp



e con e q

h ep
p
e imp
p
endfor
p q
endfor
endfor

figure build w impleafs procedure weight back propagation implication graph
use implication test conformant note however word basically
previous sentence hides subtle important detail difference situation conformantff support p may contain two kinds nodes proposition nodes start layer
prpg e layer corresponding initial belief chance nodes later layers
prpg corresponding outcomes effects unknown conditions point
discussed updates onwthe formula neededthose keep track alternative
effect outcomes hence testing lsupport p l testing whether p
known triggered certainty least one proposition true
initial world p known triggered outcomes effect
appear certainty get following
lemma let nbi g probabilistic task sequence actions applicable
bi
relaxation function time step proposition p
p p constructed build prpg nbi g
p time achieved

relaxed plan starting
probability p negatively known time p p

probability p known time p p
consequence arguments outlined full proof lemma given
appendix pp
let us consider weight propagating procedure build w impleafs depicted figure
procedure performs layered top weight propagation given node p imp
weight propagation scheme build w impleafs procedure similar nature used heuristics
module recent probabilistic temporal planner prottle little aberdeen thiebaux
note instantiated called build timestep



fip robabilistic

leafs impp order traversal ensures node impp processed successors impp chance nodes dynamic weight
p set
probability outcome takes place time given corresponding action
effect e take place times
estimate probability achieving p time effects e imp p
first quantity given global static weight assigned first
loop build timestep second quantity derived dynamic weights p r
r add computed previous iteration outermost loop build w impleafs
making heuristic assumption effect sets e impr p different r add
pairwise independent set probability failure achieve p effects
e imp p computation decomposed artifacts
weight propagation starts taking place fact nodes q dynamic weight
p q set probability action effect conditioned q time allows
possibly indirectly achieving desired fact p time making heuristic assumption
independence effects conditioned q computing p q
decomposed outcomes effects
procedure get p g
estimates probability achieving g time p
g p return endif
g p return endif
g g p
l leafs impg introduce chance proposition hlg weight g l
w
v
g lleafs impg l lleafs impg l hlg
endfor
v
return wmc gg p g

figure estimating goal likelihood given time step
remains explained build prpg procedure two termination criteria
loop constructing graph layer onwards first test made
call get p procedure checks whether prpg built time layer contains
relaxed plan nbi g get p procedure shown figure first one
subgoals negatively known time lemma overall probability achieving
goal extreme subgoals known time probability
achieving goal correctness latter test implied lemma non interference
relaxed actions leaves us main case uncertain
subgoals uncertainty due dependence subgoals actual initial world
state due achieving subgoals probabilistic actions due uncertainty
initial state fully captured weighted cnf formula nbi likewise
outcomes chance propositions introduced implication graph build timestep
procedure chained imp propositions add lists outcomes


fid omshlak h offmann

chained imp unknown relaxed conditions outcomes therefore
action outcome time relevant achieving subgoal g g time
corresponding node must appear impg weight back propagated
build w impleafs g imp leafs impg get p procedure exploits
back propagated estimates taking heuristic assumption independence
achieving different subgoals namely probability achieving unknown sub goals g p
estimated weighted model counting formula conjoined probabilistic theories
g achieving unknown goal g isolation understand formulas g consider
order make g true must achieve least one leafs l impg hence left part
conjunction hand make l true achieves g estimated
probability g l hence right part conjunction requires us pay price set
l true
explained start section positive prpg termination test may fire even
real goal probability high enough get p may return value higher real
goal probability due approximation independence assumption done weight propagation course due approximation may happen get p returns value lower
real goal probability
second prppg termination test comes check whether reached point
construction prpg allows us conclude relaxed plan nbi g
starts given action sequence termination criterion asks whether time step
time step potentially relevant changes occurred potentially relevant change
would goal satisfaction probability estimate get p grows known unknown
propositions grow support leafs latter propositions imp correspond
initial belief state grow none occurs would hold future iterations
implying required goal satisfaction probability would never reached words
prpg construction complete
theorem let nbi g probabilistic task sequence actions appli
cable bi
relaxation function build prpg nbi g returns

false relaxed plan bi g starts
note theorem holds despite approximation done weight propagation making
assumption probabilistic independence theorem hold requirement
weight propagation real weight still grows estimated weight still grows
requirement met independence assumption would met assumption
co occurence propagating weights maximization operations thereby conservatively underestimating weights propagation prpg fails cannot conclude
plan respective belief another good argument besides bad quality heuristics
observed empirically conservative estimation
introduce extra chance propositions hlg instead assign weight g l l
outcome correct pay setting l false
understand latter note prpg added replicas probabilistic actions
irrelevant achieving goals effects known conditions action effects since
irrelevant influence estimate goal satisfaction probability chance propositions corresponding
outcomes effects may become support leafs unknown proposition p latter case
set support leafs support p infinitely grow projection support p
initial belief state support p guaranteed reach fix point



fip robabilistic

full proof theorem given appendix pp theorem finalizes
presentation analysis process constructing probabilistic relaxed graphs
example prpg construction
illustrate construction prpg figures let us consider simplification running examples
actions move b right move lef constitute action set
ii goal g r b required lower bound probability success
iii initial belief state bi given bn nbi example
iv belief state ba evaluated heuristic function corresponds actions sequence
hmove b righti
effects outcomes actions considered construction prpg described
table embr notation effect e table effect e table effectively
ignored due emptiness add effects


e

con e

con e


e

p r

add






r b
r

r






r
r
b
b

embr

r b

r

aml move lef

eml

r

r

mbr

mbr

mbr

ml

noopr
noopr
noopb
noopb

er

r
r
b
b

r
r
b
b

r
r
b
b

ambr

move b right

er
eb
eb

table actions
relaxation prpg construction example
initialization phase build prpg procedure nbi imp
p r r b b content depicted first column
nodes figure first loop build prpg constructing prpg past layers
corresponding makes single iteration calls build timestep procedure
ambr n oop follows names actions refer
mbr empty thus adds

relaxations given table add list outcome
nodes implication graph chance nodes introduced imp call
build timestep appear second column figure first outer loop build timestep
imp given columns figure extension
second outer loop build timestep weight propagating procedure build w impleafs
called unknown fact p r r b b generating p oriented weights table p set supporting leafs support p


fid omshlak h offmann


wv



ml








mbr
mbr


aa

aa
ml
ml

















mbr
mbr


q






qqq
rrrr




qq

rrrr

qqq

r

r


r
r


r










rs
hi
hi




r
r
r
r
r





b



b



b



b





b



b



b



b







mbr


ml




mbr








hi
r


r


b



b



b



b



b


b

figure implication graph imp odd columns nodes depict sets unknown propositions even columns nodes depict change propositions introduced
probabilistic outcomes actions

p none implied nbi thus set known facts p remains equal
p equal

r
r
b
b



mbr
mbr
r
r
r r b b

b b










r r b b






table columns table correspond nodes implication graph imp
row provides weights p p entry row p
empty node associated corresponding column belong
implication subgraph impp
finished loop build prpg procedure proceeds loop
builds future layers prpg test goal un satisficing get p g evaluates
true get get p g thus loop proceeds first iteration
see former consider implication graph imp constructed far columns fig

fip robabilistic

ure goal g r b leafs impr r leafs impb
r b r b nbi
get p g wmc nbi r b

r hr r r hr r
b hr b hb b r hr b b hb b




hr r r r
hb b b b





hr b b r
observe two nbi consistent r immediately falsify sub formula
nbi r hence

get p g wmc nbi r b r b

wmc nbi r b r b

bi r b hr r hr b bi r b hr r hr b hb b



first iteration loop build prpg calls build timestep procedure
ambr aml n oop chance nodes introduced imp call
build timestep appear forth column figure first outer loop build timestep
imp given columns figure extension
second loop build timestep build w impleafs procedure called
unknown fact p r r b b generating p oriented weights
interesting case case weight propagation build w impleafs r imp resulting
weights
r r

r r

ml

r
r

r
r r
r r



r r
r mbr

mbr
r





r r
r r



nodes impr set supporting leafs r assigned support r
r r since nbi implies r r fact r concluded
known time added p nodes p still
support p p thus remain unknown time well putting
things together call build w impleafs procedure p r


fid omshlak h offmann

r b b loop build prpg procedure proceeds checking fixpoint termination test immediately fails due p p hence
loop proceeds next iteration corresponding
test goal un satisficing get p g still evaluates true
get p g let us follow evaluation get p g detail well considering implication graph imp constructed far time columns figure
g b leafs impb r b still nbi
obtain
get p g wmc nbi b

b hr b hb b r hr b b hb b



structure b equation identical equation weights associated
auxiliary chance propositions different notably
hb b b b



hr b b r



difference hr b equation equation stems fact r
supports b via effect embr time via different instance
effect time model nbi falsify b one sets r
b false hence
get p g bi r b hr b
bi r b hr b hb b
bi r b hb b


verified get p g loop proceeds construction time
calls build timestep procedure ambr aml n oop chance
nodes introduced imp call build timestep appear sixth column figure
first outer loop build timestep imp given columns figure


mbr
mbr
nbi mbr















mbr
mbr
mbr
mbr
mbr
mbr

























next build w impleafs procedure called usual unknown fact p
r b b information worth detailing leafs impb
mbr
b r mbr
support b b however still
w
lsupport p l p thus set known facts p remains equal
p r


fip robabilistic

returning call build w impleafs procedure build prpg proceeds checking
fixpoint termination condition time first three equalities condition hold yet
condition satisfied due get p g get p g see latter notice
get p g wmc b
given equation


b hr b hb b mbr
r hr b b hb b





hb b b b



hr b b r
mbr




b mbr






hard verify
get p g get p g bi r b mbr



note get p g therefore build prpg aborts loop
passing goal satisficing test sets finalizes construction prpg thus
example
extracting probabilistic relaxed plan
construction prpg succeeds reaching goals estimated probability success get p g exceeding extract relaxed plan consisting
use size heuristic value evaluated belief state ba
get technical details consider key differences
relaxed delete lists probabilistic one hand relaxed classical relaxed qualitative conformant hand relaxed probabilistic might
make sense execute action numerous times consecutive time steps fact
might essential think throwing dice game appears contrast
relaxed classical qualitatively uncertain settings needed effect
executed remains true forever another complication probabilistic required
goal achievement probability specified conjunction possibly complicated
logical combination different facts increasing probability achieving individual sub goal g g relaxed increase overall probability achieving g
choosing right distribution effort among sub goals pass required threshold
whole goal g non trivial
fundamental aforementioned lack guarantees weight propagation
one hand construction prpg lemma imply
concatenated
r
arbitrary linearization executable bi hand due
independence assumption made build w impleafs procedure get p g


fid omshlak h offmann

r
imply probability achieving g
concatenated exceeds real relaxed
plan sense might even exist constructed prpg
answer difficulties extract relaxed plans correct relative
weight propagation namely use implication graph reduction computes
minimal subset graph still according weight propagation sufficiently
supports goal relaxed plan corresponds subset obviously solves
difficulty lack real relaxed plans relaxed plan extraction according
independence assumption besides ignoring deletes removing one condition
effect mechanism naturally takes care need apply action several times
corresponds several implication graph edges needed order obtain sufficient
weight choice effort distributed among sub goals circumvented sense
sub goals considered conjunction reduction performed
course remains choice parts implication graph removed
found useful heuristic make choice actions already
applied path belief detail
making another assumption top previous relaxations course bad heuristic
quality relaxed plans extract guaranteed actually achieve desired goal probability since relaxed plans used search guidance per se theoretical weakness
marginal importance however estimation goal probability might bad
heuristic relaxed plan include right actions apply often
enough section discuss example domain probabilistic fails scale
precisely reason
figure shows main routine extract prplan extracting relaxed plan given
prpg note index highest prpg layer c f figure sub routines
extract prplan shown figures high level extract prplan procedure consists
two parts

reduction implication graph aiming identifying set time stamped action effects
ignored without decreasing estimate goal achievement probability get p g
desired threshold
extraction valid relaxed plan ar schematically constructing prpg ar instead
full set would still get p g
first part accomplished reduce implication graph procedure depicted figure
first step procedure considers parts implication graph
relevant achieving unknown sub goals next reduce implication graph performs
greedy iterative elimination actions future layers prpg probability estimate get p g reduced set actions goes principle action considered elimination reduce implication graph examine repetitions actions already appear specifically reduce implication graph
iterates actions
repeats somewhere future layers prpg
one repetition considered removal removing repetition found safe
respect achieving effectively removed eliminating edges imp
induced procedure considers next repetition removing another
note formula wmc constructed exactly get p function c f figure



fip robabilistic

procedure extract prplan p rp g nbi g

selects actions
imp reduce implication graph
extract subplan imp
sub goal g p
decreasing time steps
g g
e e con e p e g add
add relaxed plan one time
sub goal pre con e
else
imp g construct support graph support g
extract subplan imp g
endif
endfor
endfor

figure extracting probabilistic relaxed plan
copy safe anymore procedure breaks inner loop considers next
action
procedure reduce implication graph
operates prpg
returns sub graph imp
imp gg p impg
actions

edges p imp induced
imp imp
remove imp edges induced
g g p
l leafs imp g introduce chance proposition hlg weight g l
v
w
g lleafs imp
l lleafs imp
l hlg
g

g

endfor
v
wmc gg p g imp imp else break endif
endfor
endfor
return imp

figure procedure reducing implication graph
illustrate intuition behind focus repetitions actions let us consider following example simple logistics style probabilistic actions
suppose two locations b truck known initially heavy
uneasy grab package known initially truck goal package
unloaded b reasonably high probability two actions use moving
truck b unloading package au moving truck necessarily


fid omshlak h offmann

move truck b extremely high probability hand unloading bothersome package succeeds extremely low probability leaving package
truck otherwise given data consider belief state ba corresponding trying move
truck action sequence ham achieve desired probability success
prpg expanded large time horizon allowing action au
applied sufficiently many times however fact truck b known belief state ba
thus implication graph contain amount applications trimming
away applications still keep probability sufficiently high
reader might ask point hope achieve trimming away
applications point intuitively implication graph reduction mechanism
means understand accomplished already path ba without
understanding relaxed quite indiscriminative search states consider
example assume one two troubled packages p p
truck unload actions au au prpg ba contains copies au au layers
large horizon say search starts unload p resulting belief prpg
still steps situation changed p step prpg still contains
copies au au hence heuristic value remains
words without implication graph reduction technique relevant things accomplished
may remain hidden behind things yet accomplished example
really critical soon tried unload p p
time horizon decreases one step heuristic value reduced however often
case sub task must accomplished sub task attacked
situations without implication graph reduction search staggers across huge plateau
first task completed observed variety benchmarks hence designed
implication graph reduction make relaxed aware already done
course since weight propagation may estimate true probabilities hence overestimate achieved past implication graph reduction may conclude prematurely
sub task completed leads us main open question
get back end section discuss context example
probabilistic ffs performance bad
let us get back explaining extract prplan procedure implication graph reduction procedure proceeds relaxed plan extraction process makes use proposition
sets g g used store time stamped sub goals arising layers
relaxed plan extraction sub routine extract subplan figure
adds constructed relaxed plan time stamped actions responsible edges
reduced implication graph imp
subgoals everything outside implication graph condition applicability effects
responsible edges imp
later phases process sub goals added sets g g
sub goal procedure simply inserts given proposition sub goal first layer
appearance prpg accomplished extract subgoal pass extract subplan
imp subgoal goal conjuncts known time
next phase process sub goals considered layer layer decreasing order
time steps sub goal g time certain supporting actions selected


fip robabilistic

procedure extract subplan imp
actions helpful achieving uncertain goals g
subgoals essential conditions actions
edge p imp
action effect e e responsible time time
add relaxed plan time
sub goal pre con e p
endif endfor
procedure sub goal p
inserts propositions p sub goals
layers first appearance prpg
p p
argmint p p
g g p endif
endfor
procedure construct support graph support g
takes subset support g leafs impg weighted according g
returns sub graph imp imp

imp
open support g
open
open open p
choose e e con e p
e p impg g
e
choose q add g q
imp imp p q
open open q
endfor endwhile
return imp

figure sub routines extract prplan
relaxed plan action effect e e known applicable
time guarantee achieve g certainty added constructed relaxed
plan otherwise
use construct support graph procedure extract sub graph imp g consisting set
implications together ensure achieving g time
use already discussed procedure extract subplan
add constructed relaxed plan time stamped actions responsible edges
imp g
b subgoal everything outside implication graph imp g condition applicability
effects responsible edges imp g


fid omshlak h offmann

processing way sub goals g finalizes extraction relaxed plan
estimate section provides detailed illustration process prpg constructed
section event easy verify relaxed plan extract sound relative
weight propagation following sense
proposition let nbi g probabilistic task sequence actions ap
plicable bi
relaxation function build prpg nbi g
returns true let actions selected
extract prplan constructing relaxed graph
get p g
proof construction reduce implication graph leaves enough edges graph
weight propagation underlying get p still concludes goal probability high enough
example extracting relaxed plan prpg
illustrate process relaxed plan extraction prpg figure constructed
belief state specification example section example
g b thus implication graph imp gets immediately reduced
sub graph imp depicted figure plan belief state question consists
single action ambr action instances considered elimination outer loop
reduce implication graph ambr ambr ambr chosen examined
implication sub graph imp imp reduced removing edges due ambr
resulting imp appears figure b b components evaluated formula
b given equation equation respectively weights associated
chance propositions equation reduced implication graph imp
hb b b b
hr b b r





mbr
mbr
b

weight model counting b evaluates thus imp replace imp
alternative action removal ambr seen example section attempt action elimination probability estimate lower
hence effect reduce implication graph prpg processed extract prplan
procedure reduction implication graph edges relevant achieving b
time reduced implication sub graph imp returned reduce implication graph
procedure depicted figure
next extract subplan procedure iterates edges imp adds initially
empty relaxed plan applications ambr times action ambr preconditions
e ambr known time hence extract subplan
condition r effect mbr

invokes sub goal procedure r latter added proposition set g
subsequent call sub goal g p sub goal r leads extensions g g
dashed edges figure b removed imp latter stage imp chosen replace
imp



fip robabilistic



mbr

qq

qqq
q
q
qq


r
r



b



b



r



mbr

rrr

rrr
r
r


b



b





mbr



b





b




b




mbr

qq

qqq
q
q
qq

r
r r

b



b





b



mbr




b



b



b







b

b


ml


r



r



r



r



wv

r


r






rs

r

r

c
figure illustrations steps relaxed plan extraction prpg constructed
section particular implication graph latter depicted
figure

already r g hence outer loop extract prplan starts g
g r
since g empty first sub goal considered extract prplanis r g r
time action effect time passes test statementthe condition r ml
known time true r hence subgoal r processed
extracting sub plan support achieving certainty first construct support graph
procedure called support r r r see section extracted sub fact easy see construction sub goal procedure p belongs g condition
noops effect p cannot known time



fid omshlak h offmann

graph imp r original implication graph imp depicted figure c invoking
procedure extract subplan imp r adding application aml time ii
subgoals hence proposition sets g g get emptied thus end
extracting relaxed plan hambr aml ambr

empirical evaluation
implemented probabilistic c starting conformant code
probabilistic behaves exactly conformant except conformant cannot handle
non deterministic effects otherwise probabilistic behaves described previous sections uses cachet sang et al weighted model counting better home
strengths weaknesses empirical evaluation probabilistic
done two steps section evaluate probabilistic non trivial uncertain initial states deterministic actions section examine probabilistic
probabilistic action effects sources uncertainty compare
probabilistic ffs performance probabilistic planner pond bryce et al
reasons choosing pond reference point twofold first similarly probabilistic
pond constitutes forward search planner guided non admissible heuristic function
relaxed graph computations second knowledge pond clearly
efficient probabilistic planner reported literature
experiments run pc running ghz gb main memory mb cache
running linux unless stated otherwise domain pair tried four levels desired probability success run planner time limited
seconds user time probabilistic run default configuration inherited
performing one trial enforced hill climbing switching best first search case failure
domains without probabilistic effects found probabilistic ffs simpler relaxed plan extraction developed case domshlak hoffmann performs better one described
hence switch simpler version domains
unlike probabilistic heuristic computation pond element randomization
namely probability goal achievement estimated via sending set random particles
relaxed graph number particles input parameter instance averaged runtime performance pond independent runs special
cases pond timed runs certain instance yet
runs average report pond uses lower bounding time threshold replace missing time points cases ponds best case performance differs lot
average performance cases best case performance reported note
following suggestion dan bryce pond run default parameter setting par experiments used recent version pond significantly enhances pond bryce et al
authors would thank dan bryce rao kambhampati providing us binary distribution
pond
without probabilistic effects relaxed plan extraction proceeds much conformant additional
straightforward backchaining selecting support unknown goals complicated techniques developed
deal relaxed plan extraction probabilistic effects appear unstable behavior
simpler techniques probabilistic effects simple backchaining meaningful
information many times action must applied order sufficiently support goal



fip robabilistic


l


l


l


l
















cube uni
cube cub
















bomb
bomb
bomb
bomb


























log
log
log





















grid
grid
grid





















rovers
roversp
roverspp
roversppp



















unsat




unsat

instance

actions facts states

safe uni
safe cub

table empirical probabilistic initial states times seconds search
space size number calls heuristic function plan length l

ticular includes number random particles selected computing ponds heuristic
estimate bryce et al
initial state uncertainty deterministic actions
examine performance probabilistic pond collection domains
probabilistic initial states deterministic action effects consider domains one
one discussing set runtime plots instances table shows
details providing features instance size well detailed probabilistic
including number explored search states plan length
first three domains probabilistic versions traditional conformant benchmarks safe
cube bomb safe n combinations one opens safe given probability
distribution combination right one type action safe trying
combination objective open safe probability experimented
two probability distributions n combinations uniform one safe uni distribution
declines according cubic function safe cub table shows probabilistic
solve efficiently even n figure compares probabilistic
pond plotting time performance identical linear scale x axes number
combinations
graphs easy see probabilistic outperforms pond least order
magnitude safe uni safe cub interesting observation necessarily
difference time performance relative performance planner safe uni
safe cub note safe cub somewhat easier safe uni sense safe cub fewer
combinations must tried guarantee given probability opening safe


fid omshlak h offmann

pff

pond




p
p
p
p











time sec

time sec



p
p
p
p




























combinations





combinations

uniform prior distribution combinations
pff

pond




p
p
p
p











time sec

time sec



p
p
p
p


























combinations







combinations

b cubic decay prior distribution combinations
figure safe domain probabilistic left vs pond right
dominant part probability mass lies combinations head cubic distribution
last combination probability right combination thus needs tried
even question whether heuristic functions probabilistic
pond exploit difference safe uni safe cub table figure provide
affirmative answer question heuristic function probabilistic picture
pond less clear times spent pond otherwise identical instances safe uni
safe cub roughly
another interesting observation probabilistic pond moving
qualitative uncertainty truly probabilistic
safe cub n pond undergoes exponential blow shown
graphs since data points would obscure data points anyway believe blow due
unfortunate troubles numerics



fip robabilistic

pff

pond




p
p
p
p



p
p
p
p




time sec

time sec























n grid nxnxn











n grid nxnxn









uniform prior distribution initial position
pff

pond




p
p
p
p



p
p
p
p




time sec

time sec























n grid nxnxn











n grid nxnxn

b cubic decay prior distribution initial position
figure cube domain probabilistic left vs pond right

typically performance decline even get improved performance except
safe uni reason seems plans become shorter trend
observed domains trend particularly remarkable probabilistic since
moving means move case model counting needed
case needed words probabilistic automatically specializes
qualitative uncertainty model counting knowledge true
pond uses techniques cases
cube task move corner dimensional grid actions correspond
moving current cube cell one adjacent cube cells created
instances uniform cubic distributions initial position dimension
probabilistic scales well easily solving instances cube within
time limit pond capable solving cube cube width figure


fid omshlak h offmann

compares probabilistic pond detail plotting time performance
different linear scales x axes capturing width grid dimension showing
least order magnitude advantage probabilistic note
probabilistic generally becomes faster decreasing decreasing hardness
achieving objective seem substantial effect performance
pond
probabilistic exploits relative easiness cube cub e g see table time
performance pond cube cub cube uni qualitatively identical
tried version cube task move grid center probabilistic
bad reaching performance limit n weakness cube center domain
inherited conformant detailed hoffmann brafman reason
weakness lies inaccuracy heuristic function domain two sources
inaccuracy first solve cube center reality one must start moving corner
order establish position relaxation without delete lists necessary second
relaxed graph computation approximates achieved future
steps already achieved path considered belief state even
moderately long paths actions relaxed graph comes wrong conclusion
goal already achieved relaxed plan becomes empty heuristic
information
next consider famous bomb toilet domain bomb short version
bomb contains n bombs toilets bomb may armed armed independently probability n resulting huge numbers initially possible world states dunking
bomb unclogged toilet disarms bomb clogs toilet toilet unclogged
flushing table shows probabilistic scales nicely n becomes faster
increases latter logical desirable toilets means disarming
devices resulting shorter plans needed figures compare probabilistic
pond plotting time performance probabilistic linear scale pond
logarithmic scale four pairs graphs correspond four choices number toilets
x axes graphs correspond number potentially armed
bombs checked n figure shows time
probabilistic least four orders magnitude faster pond extremes
hardest combination n took probabilistic less seconds
pond timed instances addition
bomb well probabilistic exhibit nice pattern improved performance
move non probabilistic probabilistic specifically
initial state good enough already
performance probabilistic improves number toilets pond seems
exhibit inverse dependence sensitive number states
see table rather optimal solution depth
finally remark though length optimality explicitly required probabilistic conformant safe cube bomb probabilistic ffs plans optimal shortest
possible


fip robabilistic

pff

pond


p
p
p
p






time sec

time sec












p
p
p
p









bombs








bombs



toilets
pff

pond


p
p
p
p






time sec

time sec












p
p
p
p









bombs








bombs



b toilets
figure bomb domain probabilistic left vs pond right

next three domains adaptations benchmarks deterministic logistics
grid rovers assume reader familiar domains logistics x
instance contains cities airplanes packages city x locations
packages chance airport origin city uniformly
locations city effects loading unloading actions conditional right
position package note higher values x increase space world states
initial uncertainty grid complex grid world run aips competition mcdermott featuring locked positions must opened matching keys
grid x modification instance nr run aips grid locked
positions keys must transported goal position lock x possible uniformly distributed shapes goal keys x possible uniformly distributed
initial positions effects pickup key putdown key open lock actions conditional


fid omshlak h offmann

pff

pond


p
p
p
p






time sec

time sec












p
p
p
p









bombs








bombs



c toilets
pff

pond


p
p
p
p






time sec

time sec












p
p
p
p









bombs








bombs



toilet
figure bomb domain probabilistic left vs pond right

finally last set comes three cascading modifications instance nr
rovers domain used aips competition instance
waypoints rovers objectives rock soil samples rovers roversppp modify
instance domain follows
rovers original aips instance nr use hear mainly comparison
roversp sample chance original waypoint chance
others two waypoints objective may visible waypoints
uniform distribution probabilistic adaptation domain suggested bryce
kambhampati


fip robabilistic

sandcastle

sandcastle


pff
pond

pff
pond min
pond avg





time sec

time sec


















































b

figure probabilistic pond sand castle b slipperygripper

roverspp enhances roversp conditional probabilities initial state stating whether
objective visible waypoint depends whether rock sample intuition large piece rock located waypoint probability visibility much
higher latter case specifically visibility objective depends
locations two rock samples rock sample present visibility probability
drops
roversppp extends roverspp introducing need collect data water existence
soil samples certain probability wet communicated
sample data additional operator tests whether sample wet fact knowthat water contained goal set true probability wet depends
location sample
runtime plots logistics grid rovers since pond runs time
memory considered instances domains table shows scaling behavior
probabilistic three domains similar observed previous domains
goals roversppp cannot achieved probabilities
proved probabilistic ffs heuristic function providing correct answer split seconds
probabilistic actions
first two domains probabilistic actions famous sand castle majercik littman
slippery gripper kushmerick et al domains domains simple
posed first challenges probabilistic planners performance domains serves
indicator progress relative previous ideas probabilistic
sand castle states specified two boolean variables moat castle state
transitions given two actions dig moat erect castle goal erect castle


fid omshlak h offmann

walkgrid

walkgrid

pff
pond











time sec

time sec















pff
pond














grid width









grid width







b

figure probabilistic pond walkgrid b
walkgrid

building moat dig moat might fail probability erecting castle erect castle
succeeds probability moat already built probability otherwise failed erect castle destroys moat probability figure shows
probabilistic pond solve less second arbitrary high values
performance planners almost independent required probability
success
slippery gripper already bit complicated domain states slippery gripper
specified four boolean variables grip dry grip dirty block painted block held
four actions dry clean paint pickup initial state block neither painted
held gripper clean gripper dry probability goal
clean gripper holding painted block action dry dries gripper probability action
clean cleans gripper probability action paint paints block probability
makes gripper dirty probability block held probability
action pickup picks block probability gripper dry
probability gripper wet
figure b depicts log scale relative performance probabilistic pond
slippery gripper function growing performance probabilistic nicely flat
around seconds time comparison pond somewhat problematic
fixed pond slippery gripper exhibited huge variance runtime figure b
plot best runtimes pond well average runtimes best run times pond
different values vary around couple seconds average runtimes significantly
worse high values pond timed sample runs thus plot provides
lower bound average runtimes
next two domains walkgrid walkgrid robot pre plan sequence conditional movements taking corner grid farthest initial


fip robabilistic

position corner hyafil bacchus walkgrid grid one dimensional
walkgrid grid two dimensional figure depicts log scale snapshot
relative performance probabilistic pond one dimensional grids width n
robot initially get n try moving two
possible directions two movement actions moves robot right direction
probability keeps place probability easy see figure
difference two planners domain substantialwhile runtime probabilisticff grows linearly x dependence pond seemingly exponential
walkgrid domain already much challenging probabilistic
walkgrid n n grids robot initially get n n
try moving four possible directions four movement actions advances
robot right direction probability opposite direction probability
two directions probability figure depicts log scale
snapshot relative performance probabilistic pond walkgrid
low required probability success function grids width n
plot shows probabilistic still scales well increasing n though linearly anymore
pond time outs grid widths n higher values however probabilistic
reach time limit rather small grids notably n n
respectively reason probabilistic ffs heuristic function good
enough estimating many times early point plan probabilistic action must
applied order sufficiently support high goal threshold end plan explain
phenomenon detail end section appears variant
well known logistics domain
last set comes standard logistics domain instance
x z contains x locations per city cities z packages see probabilistic
scales much worse logistics presence probabilistic effects initial
state uncertainty explain reason end section hence use much
smaller instances ones used section namely allow direct comparison
previous domain closely follow specification hyafil bacchus
use instances configurations x z distinguish two
levels uncertainty
l x z correspond uncertainty outcome load unload
actions specifically probabilities success load trucks
airplanes unload respectively
x z extends l x z independent uniform priors initial location
package within start city
figure depicts log scale runtimes probabilistic pond l l
l function growing planners appear scale well
runtime probabilistic optimal runtime pond roughly
average runtime pond somewhat degrading shows
planners much efficient domain previously known sat csp
techniques however moving x z changes picture planners
follows


fid omshlak h offmann

l

l



pff
pond min
pond avg







time sec



time sec

time sec


pff
pond min
pond avg






l


pff
pond min
pond avg




























b


















c

figure probabilistic pond logistics l b l
c l

runtimes probabilistic identical l
optimal runtimes pond slightly degraded seconds however examined
values runs pond resulted timeouts
runtimes probabilistic identical l
yet probabilistic time outed optimal runtimes
pond degraded l seconds values
runs pond resulted timeouts
probabilistic experienced hard times finishing seconds
time outing examined values optimal runtimes pond
degraded l seconds well values
runs pond resulted timeouts
tried variant x z non uniform priors initial locations packages resulted qualitatively similar picture absolute relative performance
x z domain remains challenging deserves close attention future developments probabilistic context interesting close look
reasons failure probabilistic turns probabilistic good enough
estimating many times early point plan probabilistic action must applied
order sufficiently support high goal threshold end plan make concrete
consider logistics example uncertain effects load unload actions consider package p must go city city b lets say p initially airport
goal threshold high means able succeed package brought
airport high probability loading onto airplane exactly point
probabilistic ffs heuristic function fails relaxed plan contains actions unloading p
airport effect search proceeds quickly loading p onto plane
bringing b search gets point b unloaded goal location goal threshold cannot achieved matter many times one unloads p point


fip robabilistic

probabilistic ffs enforced hill climbing enters loop eventually fails relaxed plan
estimates past achievements becomes empty
challenge devise methods better recognizing many times p
unloaded airport order sufficiently support goal threshold error made
probabilistic lies propagation weights implication graph estimates
goal probability note much critical actions must applied early
plan actions applied later action appears early plan
relaxed plan executed long recall weight propagation proceeds
backwards goal towards current state single backwards step propagation
makes approximation might lose precision several backwards steps
imprecisions accumulate hence quality approximation decreases quickly
number backwards steps longer distance goal current state
information lost observed phenomenon detailed experiments different
weight propagation schemes different underlying assumptions propagation
schemes tried independence assumption presented far
accurate one schemes failed deliver good even much shorter distances
goal current state
interesting consider issue affects pond uses different method
estimating probability goal achievement instead performing backwards propagation
aggregation weight values pond sends set random particles relaxed
graph forward fashion stops graph building enough particles end goal
empirical seems method suffers similar difficulties probabilistic
large extent ponds optimal runtimes x z much higher
l x z indicates challenging pond recognize need
applying action many times early plan interestingly pond never times
l x z often time x z indicates extent matter
chance whether ponds random particles recognize need applying action
many times early plan intuitive explanation good cases
sufficiently many particles failed reach goal due taking wrong effect
intuition one would expect helps increase number random particles
ponds heuristic function running pond x z increased number
particles instead default value surprise qualitative behavior
pond change time outing similar number cases unclear us reason
phenomenon certainly observed situation encoded x z
solved satisfaction probabilistic ffs weight propagation ponds random particle
methods current configurations
time writing unclear authors better methods could devised seems
unlikely weight propagation least one resort expensive reasoning exists
manages long distances better independence assumption alternative way
might simply define weaker notion plans allows repeat certain kinds actions
happen l l l instances simply small
high goal probability achieved without thinking much one increases size
instances appears appears earlier presence initial state uncertainty even
small instances uncertainty start position
packages one needs try unloading start airports often



fid omshlak h offmann

throwing dice unloading package arbitrarily many times however since assumption
observability plan execution executing plan would
still arise question often action tried since logistics fairly well solved
domain simpler formalisms virtue probabilistic even probabilistic setting
long effects deterministic consider addressing quite pressing open
question

conclusion
developed probabilistic extension conformant ffs search space representation
synergetic combination conformant ffs sat techniques recent techniques
weighted model counting provided extension conformant relaxed
approximate probabilistic reasoning resulting planner scales well range benchmark domains particular outperforms close relative pond least order magnitude
almost cases tried
point may somewhat obvious would emphasize achievements
solve particular probabilistic inherits strengths
weaknesses conformant domains ffs conformant ffs heuristic
functions yield bad estimates e g mentioned cube center variant whats probabilistic setting introduces several potential impediments ffs performance one thing
weighted model counting inherently harder sat testing though happen
set benchmarks bound cases cost exact model counting becomes
prohibitive even small examples promising way address issue lies recent methods
approximate model counting gomes sabharwal selman gomes hoffmann sabharwal selman methods much efficient exact model counters
provide high confidence lower bounds number lower bounds used
probabilistic place exact counts shown good lower bounds
high confidecne achieved quickly challenge extend methods
currently designed non weighted cnfs handle weighted model counting
importantly perhaps presence probabilistic effects fundamental weakness probabilistic ffs ponds heuristic information becomes pitfall performance even straightforward adaptation logistics domain otherwise easy
kind planners outlined key obtain high enough confidence
goal achievement one may apply particular actions several times early plan
neither probabilistic ffs ponds heuristics good enough identifying many times
view finding techniques address issue currently important open topic
area
apart addressing latter challenge intend work towards applicability real word
settings particularly look space application settings rovers domain hints
medication type treatment domains power supply restoration domain bertoli
cimatti slaney thiebaux


fip robabilistic

acknowledgments
authors would thank dan bryce rao kambhampati providing binary distribution pond carmel domshlak partially supported israel science foundations
grant well c wellner fund major parts
accomplished time jorg hoffmann employed intelligent information
systems institute cornell university

appendix proofs
proposition let nbi g probabilistic described k state variables step sequence actions nba nbi k
largest description size action
proof proof rather straightforward exploits local structure nba cpts
first nodes cpts layer x nba constitutes exact copy nbi
th layer nba contains k node x
first let us consider action node specifying cpt ty straightforward
manner prescribed eq might exponential blow eq suggests
original description compact specification ty therefore ty
described space description efficiently used answering queries
ty eq next consider cpt tx state variable node x x
time rather evident eq tx described space queries
tx x x x x could efficiently answered thus summing layers
description size nba nbi k
lemma given node v impp p v v given v
time sequence effects e impv p achieves p probability
proof proof lemma backward induction time layers impv p
time node impp time stamped p node
p p p given p time empty plan corresponding empty
e impp p trivially establishes p certainty assuming claim holds
nodes impp time stamped holds nodes
time stamped
easy see node v impp get p v v
goes zero first consider chance nodes impvp node lb
set zero p r r add however
inductive assumption case effects e imp p achieve p
probability given occurrence time
consider fact nodes q impvp node get nullified
effect e e con e q latter happens possible outcomes e node belongs impp ii estimate p
words inductive assumption given outcome e time effects e imp p achieve p probability thus given q time effects
e impq p achieve p probability independently actual outcome e alternatively q lb effect e conditioned q exists


fid omshlak h offmann

outcome e according proved chance nodes time stamped
effects e imp p achieve p probability hence whole set
effects e impq p achieve p probability
lemma let nbi g probabilistic task sequence actions applicable
bi
relaxation function time step proposition p
p p constructed build prpg nbi g
p time achieved
relaxed plan starting

probability p negatively known time p p

probability p known time p p
proof proof direction straightforward induction claim
immediate direct initialization p assume
p p p negatively known time p p p known
time
first consider p p suppose p egatively know time
inductive assumption property prpg construction p
p p p therefore p added
possibly moved p first loop build timestep procedure
however exists action e e e
con e p ii p add assumption induction
pre known time con e negatively known time hence
non zero probability occurring time implies p achieved time probability
greater contradicting p negatively know time
let us consider p p notice p p


l


lsupport p

thus world state w consistent bi q w fact proposition
q support p effect e action con e
p e support p first case lemma immediately implies
concatenation
arbitrary linearization relaxed actions
achieves p probability thus p known time second case inductive
assumption implies con e known time together lemma implies
concatenation
arbitrary linearization relaxed actions
achieves p probability
proof direction induction well claim
immediate direct initialization p assume p
negatively known time p p p known time p p
first suppose p negatively known time yet p p
inductive assumption plus containing noop actions propositions
p know p negatively known time p become
negatively known time due e e e pre known


fip robabilistic

time con e negatively known time inductive assumption
latter conditions imply con e p pre p p
added p first loop build timestep procedure contradicting
assumption p p
let us consider p known time inductive assumption p contains
facts known time thus maximal subset actions
applicable
time let us begin exhaustive classification effects e actions
respect p time
e p add con e p
ii e p add con e
iii e p add con e p
set empty construction build w impleafs p imp
e support p
e likewise construction build timestep notably update
e



e

putting two facts together eq holds p time thus p p
suppose set empty hard verify subset effects iii
makes p known time thus event least one effects ii occurs must hold
probability first construction build w impleafs p imp

support p
support con e
e ii

lemma event least one effects ii occurs holds
probability


l
e ii
lsupport con e

putting two facts together eq holds p time thus p p

theorem let nbi g probabilistic task sequence actions appli
cable bi
relaxation function build prpg nbi g returns

false relaxed plan bi g starts
proof let last layer prpg upon termination build prpg every
construction prpg lemma sets p contain
propositions known respectively unknown executing actions
action layers including


fid omshlak h offmann

first let us build prpg returns false corresponding termination criterion would hold future iterations p p
subsequently since p p
p p given p p

assume contrary exists p p p p
p construction sets p p build timestep
procedure


l
lsupport p







l

lsupport p

consider exhaustive classification effects e actions respect p
time
e p add con e p
ii e p add con e
iii e p add con e p
suppose set empty let e p p con e
p thus
w e support p
w update build timestep
e thus lsupport p l contradicting eq
alternatively assume set empty arguments similar proof
lemma p p p p case imply

l

e ii
lsupport con e







l

e ii
lsupport con e

however p p together imply
action effects possibly take place time feasible take place time
therefore since e ii con e definition ii eq
implies


support con e
support con e

e ii

e ii

contradicting termination condition hence arrived contradiction assumption
p p
shown p p
termination criteria implies q
support p support p


fip robabilistic

let ep set effects actions con e
outcome e p add given
support p



support con e



support con e

eep







eep

support p
first third equalities definition support sets via lemma second
equation termination condition
last things remains shown termination criteria implies get p
g get p g considering simple cases first g p
p p get p g get p g otherwise g p p p get p g get p g
leaves us case g p g
p p termination condition
g g g
get p g get p g know action effects become feasible
increase estimate probability achieving g g time time
however p p
action effect become feasible time already feasible time thus
get p g get p g imply get p g get p g
point shown build prpg returns false corresponding termination criterion would hold future iterations assume contrary claim
theorem build prpg returns false iteration yet exists relaxed plan
bi g starts
first lemma implies exists time
g p persistence negative termination condition implies
g p however case would get p g see second get p
procedure thus build prpg would return true ever getting check negative
termination condition iteration alternatively build prpg would terminated
returning true negative termination condition checked even
leaves us case get p g get p g
contradict reaching negative termination condition iteration assume
g p p contains facts negatively known time
thus persistence negative termination condition together g p would
imply relaxed plan let us consider sub goals g
subgoals g g implications impg due deterministic
outcomes effects e impg uncertainty achieving g time
due uncertainty initial state since initial
v belief state reasoned
relaxation case get p g wmc gg p g provides us
upper bound probability achieving goal g
concatenated


fid omshlak h offmann

arbitrary linearization arbitrary subset termination subcondition get p g get p g persistence action sets
imply get p g provides us upper bound probability achieving g

concatenated arbitrary linearization arbitrary subset
together get p g latter conclusion contradicts assumption
desired relaxed plan exists
exists subgoal g g implications impg due truly
probabilistic outcomes effects e impg
actions
v repeating relaxed v
necessarily wmc gg p g wmc gg p g
contradicting termination sub condition condition get p g get p g
hence arrived contradiction assumption build prpg returns false time
yet exists relaxed plan bi g starts


references
bertoli p cimatti pistore roveri traverso p mbp model planner
proc ijcai workshop uncertainty incomplete information
seattle wa
bertoli p cimatti slaney j thiebaux solving power supply restoration via symbolic model checking proceedings th european conference artificial intelligence ecai pp lion france
blum l furst l fast graph analysis artificial
intelligence
bonet b geffner h heuristic search artificial intelligence

bonet b geffner h incomplete information heuristic search belief
space proceedings th international conference artificial intelligence
scheduling systems aips pp breckenridge co
boutilier c friedman n goldszmidt koller context specific independence
bayesian networks proceedings twelfth conference uncertainty artificial
intelligence uai pp portland
brafman r domshlak c factored proceedings th national conference artificial intelligence aaai pp boston

bryce kambhampati heuristic guidance measures conformant
proceedings th international conference automated scheduling
icaps pp whistler bc canada
bryce kambhampati smith sequential monte carlo probabilistic
reachability heuristics proceedings th international conference automated
scheduling icaps pp cumbria uk


fip robabilistic

chavira darwiche compiling bayesian networks local structure proceedings th international joint conference artificial intelligence ijcai pp
edinburgh scotland
darwiche recursive conditioning artificial intelligence
darwiche constant space reasoning dynamic bayesian networks international journal approximate reasoning
dean kanazawa k model reasoning persistence causation computational intelligence
dechter r bucket elimination unified framework reasoning artificial intelligence

domshlak c hoffmann j fast probabilistic weighted model counting proceedings th international conference automated
scheduling icaps pp cumbria uk
gomes c p hoffmann j sabharwal selman b sampling model counting
proceedings th international joint conference artificial intelligence ijcai hyderabad india
gomes c p sabharwal selman b model counting strategy obtaining good bounds proceedings th national conference artificial intelligence
aaai pp boston
hanks mcdermott modeling dynamic uncertain world symbolic
probabilistic reasoning change artificial intelligence
hoffmann j nebel b system fast plan generation heuristic
search journal artificial intelligence
hoffmann j brafman r conformant via heuristic forward search
artificial intelligence
huang j combining knowledge compilation search efficient conformant probabilistic proceedings th international conference automated
scheduling icaps pp cumbria uk
hyafil n bacchus f utilizing structured representations csps conformant
probabilistic proceedings european conference artificial intelligence
ecai pp valencia spain
jensen f introduction bayesian networks springer verlag york
kushmerick n hanks weld probabilistic artificial
intelligence
little aberdeen thiebaux prottle probabilistic temporal planner proceedings th national conference artificial intelligence aaai pp
pittsburgh pa
littman l goldsmith j mundhenk computational complexity probabilistic journal artificial intelligence


fid omshlak h offmann

majercik littman l maxplan probabilistic proceedings th international conference artificial intelligence
systems aips pp pittsburgh pa
majercik littman l contingent uncertainty via stochastic
satisfiability artificial intelligence
mcdermott ai systems competition ai magazine
mcdermott v regression match graphs control search artificial
intelligence
onder n whelan g c li l engineering conformant probabilistic planner journal
artificial intelligence
pearl j heuristics intelligent search strategies computer solving addisonwesley
pearl j probabilistic reasoning intelligent systems networks plausible inference
morgan kaufmann san mateo ca
rintanen j expressive equivalence formalisms sensing proceedings th international conference automated scheduling icaps
pp trento italy
roth hardness approximate reasoning artificial intelligence

russell norvig p artificial intelligence modern edition pearson
sang bacchus f beame p kautz h pitassi combining component caching
clause learning effective model counting online proceedings th international conference theory applications satisfiability testing sat vancouver bc
canada
sang beame p kautz h solving bayes networks weighted model counting
proceedings th national conference artificial intelligence aaai pp
pittsburgh pa
shimony e role relevance explanation irrelevance statistical independence international journal approximate reasoning
shimony e role relevance explanation ii disjunctive assignments approximate independence international journal approximate reasoning
zhang n l poole simple bayesian network computations
proceedings th canadian conference artificial intelligence pp banff
alberta canada




