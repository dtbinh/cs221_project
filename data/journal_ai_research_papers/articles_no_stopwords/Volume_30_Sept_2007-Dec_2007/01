journal artificial intelligence

submitted published

graph abstraction real time heuristic search
vadim bulitko
nathan sturtevant
jieshan lu
timothy yau

bulitko ualberta ca
nathanst cs ualberta ca
jieshan cs ualberta ca
thyau ualberta ca

department computing science university alberta
edmonton alberta g e canada

abstract
real time heuristic search methods used situated agents applications require
amount per move independent size agents plan
actions time local search space avoid getting trapped local minima improving heuristic function time extend wide class real time search
automatically built state abstraction prove completeness convergence resulting
family analyze impact abstraction extensive empirical study
real time pathfinding abstraction found improve efficiency providing better trading offs
time learning speed negatively correlated performance measures
keywords learning real time heuristic search state abstraction goal directed navigation

introduction motivation
study agent centered real time heuristic search koenig
distinctive property search agent must repeatedly plan execute actions
within constant time interval independent size solved
restriction severely limits range applicable instance static search
e g hart nilsson raphael e g stenz
anytime e g ara likhachev gordon thrun anytime
e g ad likhachev ferguson gordon stentz thrun cannot guarantee
constant bound time per action lrta provides guarantees
actions time updating heuristic function solution quality poor
lengthy convergence process korf ishida
motivating example consider navigation gridworld maps commercial computer
games games agent tasked go location map current
location agent must react quickly users command regardless maps size
complexity consequently game companies impose time per action limit pathfinding example bioware corp major game company limits time ms
pathfinding units many units simultaneously
additional challenge comes form limited sensing virtual reality trainers
artificial intelligence controlled characters may access entire map priori order
avoid unrealistic behavior dini van lent carpenter iyer agents build
internal map model sensing limited amount map around position
efficient search agent would minimize delay incurred actions explore
learn environment quickly discover optimal path goal unfortunately
c

ai access foundation rights reserved

fib ulitko turtevant l u yau

measures negatively correlated antagonistic optimizing performance one
measure worse performance one others instance reducing amount
done action improves agents response time leads slower learning
due lower quality actions taken agent
propose use graph abstraction improve efficiency search agents make
following four contributions first introduce path refinement learning
real time search pr lrts enhances existing real time heuristic search
automatically built graph abstraction pr lrts learns heuristic function abstract space
thereby substantially accelerating learning actions abstract space refined actions
environment allows agents generate actions constant
time explore environment quickly converge near optimal solutions use
previously published clique abstraction sturtevant buro contributions specific
abstraction three fold first introduce initial clique building repair procedure
detail previously published second prove worst case bound suboptimality
path induced abstraction third present first application state abstraction
real time heuristic search
standard practice heuristic search literature promote trading
small amount one performance measure large gain another performance measure
instance state abstraction non real time heuristic search shown trade little solution
quality substantial reduction running time e g holte mkadmi zimmer macdonald
botea muller schaeffer unfortunately clear whether tradeoffs made optimally second contribution demonstrate pr lrts outperforms
number respect two antagonistic measures e g learning speed
amount per action
third contribution analyze effects abstraction search respect commonly
used performance measures solution suboptimality amount per action total travel
total time memory footprint knowing effects deepens understanding realtime heuristic search methods well guides practitioner selecting appropriate
search configuration application fourth theoretically pr lrts
unifies extends several well known existing heuristic search satisfies realtime operation completeness convergence properties contribution viewed
follow previous unification extension efforts bulitko lee
rest organized follows begin formulating real time
heuristic search section pr lrts described section empirical
follow section theoretical presented section review existing
agent centered search well work automatic graph abstraction section
concluded discussion current limitations future

real time heuristic search
defining property real time heuristic search amount performed
agent per action constant upper bound depend size low bounds
preferred applications guarantee agents fast response presented
goal real time search agent plans next action considering states local search space
early version published conference bulitko sturtevant kazakevich



fig raph bstraction r eal time h euristic earch

sc
sc sg

sense environment update agents model

compute partial path p originates current state sc

execute p

update current state sc
end
figure real time heuristic search single trial
surrounding current position heuristic function simply heuristic estimates cumulative
cost state goal used agent rank available actions select
promising one process shown schematically figure agents current state sc
set initial state line long goal sg reached line agent senses
environment around see section details updates model search graph
operating line computes partial path current state toward goal
state line real time property requires lines execute constant bounded time
regardless size accomplished calling real time heuristic search
line discuss three candidate lrta section lrts
section pr lrts section would called line agent
executes path line updates current state line
trial defined agents solving experience traveling start state
goal state goal state reached agent teleported start state next
trial begins convergence process defined first sequence trials agent longer
updates heuristic function model search first trial without updates
final trial learning process said converged
learning real time lrta
first review best known real time heuristic search learning real time
lrta korf shown figure line ply breadth first search
duplicate detection used frontier states precisely actions away current state
standard path max mero technique used deal possible inconsistencies
heuristic function computing g h values value state sum
cost shortest path sc denoted g estimated cost shortest path
sg e heuristic value h sg state minimizes sum identified
line heuristic value current state updated line finally path one action
toward promising frontier state returned line
path lrta sc sg





generate successor states sc actions away
state lowest g sc h sg
update h sc sg g sc h sg greater current h
return first action along optimal path sc
figure lrta



fib ulitko turtevant l u yau

learning real time search lrts
lrts extends lrta three ways puts weight heuristic function uses maxof min learning rule utilizes backtracking review extensions detail
section walk lrts operation lrts three control parameters lookahead
n optimality weight learning quota operates follows
current state sc agent running lrts conducts full width ply lookahead search line
figure ply finds promising state line assuming initial heuristic
h admissible safely increase h sc maximum among f values promising states
levels line total learning amount u updated line exceeds learning quota
agent backtracks previous state planned lines otherwise returns
path moves current state sc promising state level line
learning amount u reset agent start state e beginning trial
path lrts sc sg




generate successor states sc actions away
level state si lowest f si g sc si h si sg
update h sc sg max f si greater current h








increase amount learning u h
u
return path actions sc sd
else
return path actions backtrack previous state set u
end

id

figure lrts
lrts parameters previously studied length bulitko lee summarize trends higher lookahead reduces convergence travel convergence memory suboptimality however increases first move lag lower heuristic weight leads less optimal
solutions generally speaking reduces convergence travel convergence memory first move
lag influenced lower learning quota causes backtracking tends reduce
convergence travel convergence memory affect first move lag
notation
definition search defined tuple g c sg h g e
directed weighted graph henceforth search graph finite set states vertices
e finite set edges edge weights defined cost function
c e c travel cost edge e start
state sg goal state h initial heuristic function assume
h sg edges state called moves actions number edges e
degree state called branching factor state
definition solution search path start state goal state sg
path denoted sg si valid state valid edge
pair states si si travel cost path sum travel costs edges


fig raph bstraction r eal time h euristic earch

definition times search agent resides single search state sc called current
state agent change current state executing actions thus incurring travel
cost initially current state coincides start state agent said succeed
makes current state coincide goal state sg
assume goal state reachable state agent get start
state needed completeness real time heuristic search follow
standard practice real time heuristic search literature assume environment
stationary deterministic additionally support backtracking shue zamani shue
li zamani e reversing agents actions require every action reverse
action needed backtracking enabled
definition travel cost state state denoted dist defined cost
shortest path throughout assume dist satisfies triangle
inequality dist dist dist state h
defined minimal travel cost goal h dist sg heuristic function h
approximation h admissible overestimate h h h value
h state referred heuristic value state assume heuristic
function h sg trivially holds admissible h
experiments break ties moves fixed fashion e g prefer
action north north east east etc entails agents behavior
identical trials final trial necessarily mean entire search graph
explored learned heuristic accurate states
definition convergence travel cumulative cost edges traversed agent
convergence process convergence amount effort expended
agent convergence process first move lag amount effort expended
agent first move final trial convergence memory measured total
number heuristic values stored convergence process standard practice realtime heuristic search literature e g korf shimbo ishida store heuristic
values hash table hash table misses handled procedurally specified initial heuristic h
e g manhattan distance grid pathfinding convergence memory number
entries hash table convergence finally suboptimality defined percentage points
final trial solution cost excess relative shortest path cost instance agent
incurred travel cost shortest path cost suboptimality
measure effort two ways first report number states
touched e considered measure called edges traversed e g holte
et al p second report physical cpu time measured ghz powerpc g
computer gcc mac os measure convergence memory terms
number heuristic values stored meaningful heuristic value stored takes
fixed amount memory e double type c implementation
definition search exhibits real time performance heuristic search
effort per move constant bounded constant independent size
assuming fixed maximum branching factor


fib ulitko turtevant l u yau

objectives real time search agent complete e arrive goal state
every trial converge e finish learning process finite number trials
minimize five performance measures described rest discuss
existing compare terms objectives
application goal directed navigation
one motivating applications heuristic search goal directed navigation known
pathfinding special case heuristic search formalized previous section
search graph e defined terrain map thus states vertices correspond
geographical positions map edges describe passability blocking cost function
represents difficulty time traversing terrain
real time pathfinding motivated primarily time sensitive robotics e g koenig simmons koenig kitano tadokoro noda matsubara takahashi shinjou shimada
koenig tovey smirnov computer games latter include real time strategy
games e g blizzard entertainment first person shooters e g id software roleplaying games e g bioware corp time plays critical role since number
agents perform pathfinding simultaneously gamers would rapid response fluid
gameplay pathfinding become major computational expense age empires
ii ensemble studios takes simulation time pottinger
follow footsteps furcy koenig shimbo ishida
koenig botea et al hernandez meseguer b sigmundarson
bjornsson koenig likhachev situate empirical study navigation
two dimensional grid maps cells square cell connected four cardinally
e west north east south four diagonally neighboring cells cell occupied
agent e free wall e blocked
free grid cell constitutes vertex state search space agent travel
two free neighboring cells edge
added set edges e
set edge costs cardinal moves diagonal moves cell initially
occupied agent target cell sg example converting grid map
search defined g c sg h shown figure note allow
diagonal moves cut corners thus state connected states sg
done non zero size agent able pass zero width bottleneck
formed two diagonally adjacent blocked cells case one corner e g
states
figure allowing cut would lead actual travel distance
exceeding since non zero width agent walk around corner
video games often feature repeated pathfinding experiences map two reasons
units commute source destination e g resource collectors
real time strategy games ii ally units share learning e heuristic
function since trial typically improves heuristic values many states even single trial
single unit use units different start states long share goal
state often case state abstraction entire region map e g room
role playing game players home base real time strategy game mapped
single abstract state thus single trial learning experiences multiple units approximated
multi trial learning experience single unit latter scenario study


fig raph bstraction r eal time h euristic earch

goal





sg



start













figure grid map left converted state search graph right thinner
cardinaldirection edges cost thicker diagonal edges cost
line furcy koenig shimbo ishida sigmundarson bjornsson
others

search graph discovery
require search agent know entirety instead portion
search neighborhood current state sc sensed agent time
step assume agent remember parts sensed far
words times agent internal representation model search space
model updated agent discovers search graph line figure
let us illustrate exploration process goal directed navigation terrain map initially
unknown agent moves around environment grid cells whose coordinates within
fixed visibility radius agents current position sensed formally agent situated cell
x check status free blocked cell x x x r r
r n visibility radius thus two visible cells x x agent tell
edge cost similar virtual sensors used thalmann
noser huang
one common assume regular structure unknown part search
space koenig et al koenig bulitko lee koenig likhachev
instance grid pathfinding agent assume obstacles gridworld
senses otherwise sometimes called free space assumption demonstrate
figure agent assumes space obstacle free builds internal
model accordingly b exploration reveals obstacles environment c cause agent
update model impose restriction search agent never needs add edges
model exploration weights discovered edges never change words agents
initial model optimistic contains superset edges actual search graph adding edges
allowing arbitrary edge weight changes may require agent explore environment explicitly combining exploration exploitation effectively active area early work
refer sutton addressed
map discovery natural robotics sensors limited ranges software domains
agent theoretically access entire environment several types arguments
made justify restricting agents senses software domains first omniscient virtual


fib ulitko turtevant l u yau

actual search space

agent model

explored actual search space

updated agent model



b

c



figure initially part search space shown solid lines sensed agent
shown stick figure agents model assumes regular structure unknown
part b agent moves north east senses additional part search space
c updates model correspondingly
humans tend behave unrealistically thus less suitable virtual reality trainers dini
et al likewise commercial games revealing entire map ai player viewed
negatively cheating second computationally expensive sense orkin
reason entire environment thalmann et al aylett luck consequently
localized sensing used large scale multi unit systems reynolds

path refinement learning real time search pr lrts
real time heuristic search plan small part search graph surrounds
agents current state order avoid getting stuck infinite loops update heuristic
function time guarantees action planned constant bounded
amount time downside slow convergence
central idea pr lrts address downside running real time search
smaller abstract search graph refining produced abstract path ground level path
abstract graph image original graph abstraction operator operator
maps region states original graph single abstract state abstract graph
applied multiple times hierarchy abstractions formed hierarchy forest tree
connected component search graph formalized section
variety terminologies used literature discussing relationship states different levels abstraction different contexts abstract states
referred clusters botea et al sectors regions sturtevant images holte
et al abstraction forest line bacchus yang bulitko
et al sturtevant buro sometimes call image abstraction operator parent
pre image children terms confused successor states lookahead
search first describe pr lrts intuitive level illustrate example section give formal details section describe abstraction operator detail
path refinement
pr lrts computes paths several levels abstraction first path found
abstract search space level abstract path defines region lower level abstract


fig raph bstraction r eal time h euristic earch

path pr lrts sc sg














level sc
return
end
p pr lrts parent sc parent sg
p
sg child end p
end
c parent p
switch level sc
return sc sg c
lrts return lrts sc sg c
pass return p
end switch

figure pr lrts
space searched refining abstract path refinement proceeds incrementally
level e ground search space reached ground path produced order
keep amount per move constant bounded regardless ground space size
need real time abstract search graph use lrts
fixed top level abstraction refinement lower levels abstract levels
left pass merely increase amount state aggregation processing
carried design choice motivated experimentation section
pr lrts operates recursively presented figure line checks states passed
top level abstraction pathfinding occur empty path
returned line otherwise function calls recursively compute path
abstract image sc denoted parent sc line abstract image sg returned
path non empty checked line used derive destination line specifically
destination sg child end abstract path p line compute
corridor c comprised pre images states path p corridor c empty
path p computed line empty finally run assigned current level
abstraction e level sc sg lines lrts tasked
full case partial path case lrts sc sg limited
set states c convention empty corridor c allows lrts search entire
graph note processing happens pass level line
agent explores environment moving actually use local repair instead
described section
child used choices may lead better performance intuitively child chosen
child end p closest representative abstract state end p among children end p
pathfinding implement child return element children geographically closest average coordinates states children goal state sg happens pre image end p
pick child end p
note functions child parent handle pass levels specifically line state sg
computed child first non pass level level path p computed likewise line
states forming corridor c first non pass level level level path p level
j thus parent apply abstraction mapping j times parent p level j



fib ulitko turtevant l u yau

implementation standard hart et al except run line subgraph
defined corridor c line implementation lrts taken literature bulitko
lee described section run lrts corridor c

figure path refinement process original graph level shown bottom
abstract graph level shown top
illustration purposes consider example figure example one
level abstraction shown top used addition ground level shown bottom
sc current state sg destination state lrts assigned level
assigned level subfigure shows ground state space one level abstraction
agent must plan path sc sg located ground level first abstract
parents sc sg parent sc c parent sg g located lrts
plans three steps abstract space ii corridor c ground level comprised children
abstract path built iii child representing end abstract path set
destination sg iv finally run within corridor path sc
destination sg v
agent executing path computed pr lrts areas search graph may
seen causes updates abstraction hierarchy agent maintains pr lrts clears
recomputes abstract paths upon discovering areas search graph ground
path proves invalid e g runs newly discovered obstacle execution stops pr lrts
replans current state updated abstraction hierarchy
graph discovery lead arbitrary updates abstract search graphs agent maintains
implementation lrts operating abstract graph resets heuristic function abstract search graph updated way hand updates ground level graph
limited state edge removals section consequently heuristic learned ground
level remains admissible need reset upon updates
automatic graph abstraction
use term abstraction operator abstraction short mean graph homomorphism
line holte et al namely abstraction many one function maps abstracts
one states single abstract state adjacent vertices mapped adjacent identical
vertices property given graph homomorphism function model search
pr lrts agent builds additional abstract search graphs collectively called abstrac

fig raph bstraction r eal time h euristic earch

tion hierarchy follows first applies graph homomorphism search graph model
called ground level graph abstract search graph level process
repeated abstract search graph level computed homomorphic abstraction
used long resulting hierarchy abstract graphs satisfies several key properties following introduce properties informally illustrate example appendix b
formalize
property every abstract graph search graph sense definition section
property every state unique abstract parent except states top level abstraction
property every state abstract level least one child state
property given heuristic search number children abstract state upperbounded constant independent number states ground level graph
corollary property number ground level states abstract single
state fixed level abstraction constant bounded constant independent
ground level graph size
property graph homomorphism every edge search graph level abstraction
corresponding edge level states connected edge abstract
single abstract state
property abstract edge exists two states edge least
child one state child
property two children abstract state connected path whose states
children abstract state
property abstraction hierarchy consistent agents model search
times properties satisfied respect agents model
use clique abstraction mechanism sturtevant buro operates finding fully connected components cliques search graph mapping
single abstract state method building abstractions favored recent analysis sturtevant
jansen earlier analysis holte et al section showed reduction
search effort due abstraction maximized minimizing edge diameter set children
maximizing size clique edge diameter e maximum number edges
two elements one number states clique maximized
present clique abstraction mechanism developing several stages handtraceable example illustrate properties introduced satisfied
example formal introduction clique abstraction technique complete pseudocode
found appendix review ways building abstraction section note
general clique computation np complete finding cliques two dimensional grid search
graphs done efficiently appendix


fib ulitko turtevant l u yau

single application abstraction procedure illustrated figure cliques size four
first located graph meaning states abstracted
cliques size three already abstracted first step cliques size two
abstracted next includes abstracted
abstracted sg degree add however degree two
abstracted parent adding degree states neighbors reduces number
resulting abstract states increases edge diameter set children becomes
set sg minor detail abstraction happens effective grid
pathfinding one use pure clique abstraction well




sg





















level original graph

level abstract graph

figure clique abstraction original search graph figure shown left abstracted
search graph right





sg



























level original graph

level

level

level

figure three iterations clique abstraction procedure
abstraction process successively applied single abstract state connected component original graph remains figure level illustrate
abstraction properties figure property requires four abstraction levels
figure search graph sense definition section property requires


fig raph bstraction r eal time h euristic earch

state levels unique parent level property requires
state levels non empty set children level property places
upper bound number children abstract state example bound
properties require two abstract states connected path parents
children connected consider instance abstract states
connected level abstract path p thus child
connected child level instance connected property
requires children node connected internal path within form
clique property satisfied
costs abstract edges e g edge figure defined arbitrary way
long resulting search graph satisfies properties section however better performance low cost abstract path abstraction low cost ground path
experiment grid navigation correspondingly define cost edge
euclidean distance average coordinates children children figure

figure coordinates edge costs levels abstraction hierarchy grid level
leftmost illustration vertex
coordinates given column row labels ground
edges cost cardinal diagonal abstract states labeled x abstract
edges labeled approximate cost

practice property satisfied repairing agents abstraction hierarchy upon updates
agents model illustrate imagine agent discovered discrepancies
terrain elevation state figure prevent able traverse edge
update model removing edge additionally degree one state
join clique point agents abstraction hierarchy needs repaired
accomplished replacing abstract states single abstract state edges
removed one level abstraction used repair
propagated higher levels well repair mechanism presented detail appendix
prove section pr lrts operate abstraction mechanism
satisfies properties listed


fib ulitko turtevant l u yau

figure two six maps used experiments

empirical study
empirical evaluation effects state abstraction learning real time heuristic search
presented four parts section introduce concept trading antagonistic
measures demonstrate pr lrts makes trade offs efficiently due use
abstraction consequently investigate effects abstraction independently lrts
control parameters section study pr lrts performance scales
size section finally examine interplay effects abstraction lrts
control parameters domain specific study present details appendix f
experimental setup follows used randomly generated three
maps modeled environments role playing game bioware corp three maps
modeled battlefields real time strategy game blizzard entertainment six
maps states grids
two maps figure four maps shown appendix c
uniformly distributed across five buckets bucket represents range optimal solution
costs first optimal path cost range next
fell bucket last bucket
experimented assignments lrts none levels abstraction experimentation found keeping lrts top bottom level
leaving intermediate levels pass yielded best testbed following present pr lrts configurations denoted lrts
level abstraction lrts control parameters operates running
bottom level run lrts ground level run lrts
parameter space follows lookahead depth optimality
weight learning quota two visibility radii used
analysis focus case visibility radius line
previous publications area bulitko et al bulitko lee experiments
visibility radius yielded similar point reference ran single nonreal time implemented within hierarchical open graph
framework sturtevant c run cluster aggregate years intel
xeon ghz cpu


fig raph bstraction r eal time h euristic earch

antagonistic performance measure trade
practitioners viewpoint section viewed parameter selection guide start
finding sets parameters optimize performance pr lrts along single measure
consider optimizing pairs antagonistic performance measures
optimizing single performance measures within lrts published bulitko
lee table extend include pr lrts best
single performance measure lrta use abstraction exception
convergence interplay per move convergence travel
table optimizing single performance measure
measure
convergence travel
first move lag states touched
conv memory
suboptimality
conv states touched

best

lrta

lrta
lrts lrts

power abstraction comes attempt optimize two negatively correlated
antagonistic performance measures simultaneously consider instance convergence travel
first move lag order lower convergence travel agent needs select better actions
done increasing amount per move turn increases first move
lag measures negatively correlated performance along one measure traded
performance along thus interested make trade offs
efficiently order make analysis specific first introduce concept dominance
respect set parameterized
definition said dominate b respect performance measures
x set p average performance measured x worse
bs avgp x worse avgp x b avgp worse avgp b
c called dominated set set contains another
dominates
definition illustrated figure non dominated shown solid circles dominated shown hollow circles intuitively non dominated
make trade performance measures x efficiently among
set considered practice one wants optimize performance measures dominated safely excluded consideration regardless relative
importance measures x particular application
non dominated ten pairs antagonistic measures summarized table
weighted version korfs lrta extreme cases performance measures
minimizes convergence travel uses heuristic memory lrta minimizes first move lag
non dominated pr lrts abstraction words abstraction
path refinement improve efficiency trading antagonistic performance measures figure
shows dominance plot convergence first move lag pr lrts forms frontier


fiperformance
measure

performance
measure

worse

worse

b ulitko turtevant l u yau

b


better

better

nondominated


better

performance
measure

better

worse

performance
measure

worse

figure left dominates b left right non dominated
shown solid circles dominated shown hollow circles
non dominated rightmost non dominated point weighted lrta
extremely low first move lag plots combinations appendix

firstmove lag states touched

dominated
nondominated





lrts




lrts

lrts





lrts







convergence states touched





figure dominance convergence first move lag
dominance analysis done respect performance measures averaged
benchmark set dominance analysis level individual found
appendix e shows similar trends
effects abstraction individual performance measures
section study effects abstraction individual performance measures arbitrarily choose three diverse lrts parameter combinations lookahead optimality weight
learning quota plots figure qualitative
summary table analysis trends
convergence decreases abstraction level increase per move higher abstraction levels overcompensated decrease convergence
travel exact shape curves due interplay two measures


fig raph bstraction r eal time h euristic earch

table trading antagonistic performance measures
measure
first move lag
states touched
first move lag
states touched
first move lag
states touched
first move lag
time
first move lag
time
first move lag
time
suboptimality
suboptimality
suboptimality
suboptimality

measure
conv travel
conv memory
conv plan
states touched
conv travel
conv memory
conv plan
time
conv plan
states touched
conv plan
time
conv travel
conv memory

non dominated extreme cases italic
lrta
lrts
lrta
lrts
lrts
lrta
lrta
lrts
lrta
lrts
lrta
lrts

lrts




first move lag increases abstraction level due fact corridor
ground level induced abstract path length computed lrts abstract level
increases abstraction level two additional factors affecting shape curves
first average degree abstract states varies abstraction level second boundaries
abstract graphs often seen lookahead higher abstraction level
convergence memory decreases abstraction level learning lrts operates smaller abstract maps incurs smaller travel cost practice amount learning
lrts tends correlate tightly travel instance lrts correlation
convergence memory convergence travel empirically measured
confidence
suboptimality increases abstraction increase due fact abstraction
level progressively simplifies ground graph topology abstract path guaranteed
refinable ground path may lead agent away shortest solution illustrative
example given appendix b refinement complete abstract path longer
optimal ground path derivation theoretical upper bound suboptimality due
abstraction found appendix b second mechanism explains suboptimality rises faster
shallower lrts searches specifically ground level refines abstract step path
finding ground level solution current state ground representative end
abstract path solution guaranteed optimal within corridor necessarily
pass geographically closely intermediate states abstract path thus giving
corridor induced longer abstract path liberates plot path possibly far
intermediate states abstract path phenomenon illustrated appendix b
feeding abstract path small fragments suboptimality giving
big picture abstract path entirety third factor affecting suboptimality curves







x


b ulitko
turtevant l u yau




convergence travel





x














abstraction

level
abstraction
level
abstraction level




first move lag



first move lag
first move lag



























abstraction
level
abstraction
level
abstraction
level









x

x


x



















































abstraction
level
abstraction level











x
x





x





abstraction level




suboptimality
convergence memory
suboptimality

convergence
memory
convergence
memory
suboptimality


convergence travel
convergence travel











x
x




convergence
memory memory
convergence
convergence
memoryconvergence

convergence
convergenceplanning

first move lag
first move
convergence travel
first move lag
lag
convergence
convergencetravel
travel
convergence
convergence

convergence




x
x







abstraction level






abstraction
level
abstraction
level










abstraction
level

level
abstraction
abstraction
level
abstraction
level
abstraction level




abstraction level



























abstraction
level
abstraction
level







abstraction level












level
abstraction
abstraction
level
abstraction
level
abstraction
level
abstraction
level






suboptimality

suboptimality
suboptimality

figure effects abstraction pr lrts
error bars indicate standard errors












small see data points abstraction
level






figure optimality weight setting lower values leads higher suboptimality

independently


abstraction


bulitko lee

abstraction



level
convergence
travel
decreases
abstraction bottom level search constrained within
abstraction
level
abstraction level
narrow corridor induced abstract path decrease noticeable shallow lookahead searches lookahead low convergence
travel even without abstraction convergence travel lower bounded double optimal
solution cost one optimal solution first trial map discovered one
final trial map discovery heuristic learning consequently abstraction diminished
gains deeper lookahead although effect would disappear larger maps
table qualitative effects abstraction general trends
measure parameter
first move lag
convergence
convergence memory
suboptimality
convergence travel








given higher abstraction reduces convergence travel one may ask compares
reducing convergence travel non abstract simply terminating convergence
process final trial figure compare four single
non abstract lrts two abstract versions lrts lrts
left plot figure demonstrates well known fact convergence learning heuristic
search non monotinic e g shimbo ishida right plot shows cost
shortest solution function cumulative travel prefer shorter solutions traveling little possible plot abstract perform better lower


fig raph bstraction r eal time h euristic earch


lrts
lrts

travel trial



lrts












trial




lrts
lrts


shortest solution found












lrts










cumulative travel





figure convergence process level individual trials
curves preferred words single better run abstract non abstract regardless early convergence process terminated
observe case assignments tried
certain cases prematurely terminating convergence process non abstract indeed
beneficial future investigate extent one automatically select best
number trials run
effects abstraction scaling size
section investigate effects abstraction size increases measure
size cost shortest path start goal position henceforth
optimal solution cost
figures five performance measures plotted bucket averages data
point use middle bucket e g horizontal coordinate error bars
indicate standard errors overall demonstrate abstraction enables pr lrts
applied larger significantly dampening increase convergence travel convergence convergence memory advantages come price suboptimality
first move lag former clearly increases abstraction lookahead small figure
virtually bucket independent lookahead figure draws curves together
deeper lookahead diminishes effects abstraction suboptimality cf figure
first move lag virtually bucket independent except case abstraction levels
figure first move lag capped lower buckets goal
seen start state higher levels abstraction consequently lrts computes
abstract path shorter nine moves leads smaller corridor less work
refining path consequently first move lag reduced become
larger lrts room compute full nine move abstract path first move lag increases
abstraction level phenomenon takes place bucket seeing goal state
start state frequent enough make impact happens abstraction level
proximity abstract goal continues cut search short even largest
finally observe minute decrease first move lag larger appears
due fact higher buckets tend start state located cluttered
region map optimal solution cost necessarily higher walls reduce number
states touched agent first move reduce first move lag


fib ulitko turtevant l u yau





x


convergence

convergence travel























optimal solution cost

x

firstmove lag




optimal solution cost








optimal solution cost





suboptimality

convergence memory

l







l
l



l



l









optimal solution cost


optimal solution cost

figure scaling curve shows bucketed means lrtsl error bars indicate standard errors small see data points

theoretical analysis
pr lrts subsumes several known abstraction used clearly lrts bulitko lee special case pr lrts abstraction used lrts subsumes generalizes several real time search including lrta korf weighted
lrta shimbo ishida trap bulitko sla sla shue zamani
shue et al
theorem real time operation heuristic search lrts amount
per action constant bounded constant depends constant control
parameters n independent number states
first prove auxiliary lemma
lemma downward refinement property abstract path p sa sb two
children ends connected path lying entirely corridor induced p means
abstract path refined within corridor formed children formally
k p sa sb p k e k
children b children sm
p b p k e k p sp children




fig raph bstraction r eal time h euristic earch

























optimal solution cost

x

firstmove lag




convergence

convergence travel








optimal solution cost




optimal solution cost

l










optimal solution cost

suboptimality

convergence memory

l



l
l



l






optimal solution cost

figure scaling curve shows bucketed means lrtsl error bars indicate standard errors small see data points
proof proof induction number edges abstract path base case
means two children single abstract state connected path lies entirely
set children abstract state holds due property
suppose statement holds abstract paths length j
holds abstract paths length j consider arbitrary abstract path p k e k k
j edges represent p sj sj consider arbitrary children
children j children sj need path p k
e k lies entirely union children states p let us denote
cp let j arbitrary child state sj since sj j edges apart
inductive supposition path j lies entirely cp left
j j connected within cp j j parent
property guarantees connected different parents property provides
guarantee way induction step completed
prove theorem
proof abstract level lrts considers bd abstract states
design cf section b maximum degree state assumed earlier
maximum degree state depend number states resulting
abstract path longer abstract edges induces corridor ground level corridor
consists ground level states abstract abstract states path size corridor


fib ulitko turtevant l u yau

upper bounded number edges path multiplied maximum number
ground level children abstract state level latter upper bounded constant
independent number ground level states due property running corridor
constant bounded size takes constant bounded time finally abstraction repair
independent graph size appendix
completeness defined ability reach goal state every trial prove completeness lrts following reasoning recall lrts uses
lrts build abstract path level uses corridor restricted
ground level refine abstract path sequence ground level edges due property
section able path ground level states sc sg
lie within corridor c time execution gets line figure due exploration
process agents model search graph may different graph actually
reality consequently path found may contain ground level edge agent believes
exist reality following lemma demonstrates execution failure
possible finite number times given search graph
lemma finite number path execution failures trial
proof contradiction suppose infinite number failures failure due
discovery least one blocked edge vertex ground level graph
infinitely many blocked edges vertices finite graph
direct corollary lemma trial moment time
graph discoveries made trial therefore executing path indeed allow
agent follow abstract path actual map
lemma lrts complete abstract graph
proof first abstract graph satisfies properties lrts shown
complete theorem bulitko lee abstract graph finite action
reversible self loops actions positive cost goal state reachable
every state graph stationary deterministically traversible p bulitko
lee due abstraction mechanism requirements section properties listed
satisfied clique abstraction mechanism long ground level graph satisfies
properties well require section thus lrts running abstract graph
ground graph complete
pr lrts however lrts abstract graph execute actions instead
current abstract state computed abstract parent agents current ground level state
therefore critical question whether agent able ground level path current
state ground level state corresponding end abstract path computed line
figure failure would mean corridor computed line figure
used refine path contain ground level path sc sg due downward
refinement property lemma due graph discovery
according lemma finite number failures operating
ground level guaranteed path reach end abstract path computed lrts
thus lrts effective ability execute abstract actions putting


fig raph bstraction r eal time h euristic earch

together conclude valid parameters lrts abstract graph finds
goal every trial
two lemmas lead directly following statement
theorem lrts complete
proof follows directly lemma lemma
theorem lrts fixed tie breaking converges final solution finite
number trials subsequent trials update search graph model heuristic
follows path
proof follows lemma theorem bulitko lee way
lemma theorem proved
theoretical suboptimality found appendix b

related
existing heuristic search methods situated methods divided two categories full
search real time search full search form entire solution given current
knowledge search graph contrast real time search plans small segment frequently
first action solution executes right away due local nature
real time search need update heuristic function avoid getting stuck local
minima heuristic function
full search
common full search version hart et al called local repair stout
full search conducted agents current state goal state free space
assumption agent executes computed path destination reached
path becomes invalid e g previously unknown wall blocks way latter case agent
replans current position goal local repair suffers two first
searches shortest solution general search may end expanding number
states exponential solution cost due inaccuracies heuristic function pearl
second episodes use previous search
first addressed suboptimal versions frequently implemented
via weighting heuristic function pohl weighted wa usually finds
longer solution less time suboptimal solution found improved upon
conducting additional searches done open list successive
searches hansen zilberstein danilchenko likhachev et al hansen zhou
running tunnel induced suboptimal solution furcy later case
beam search backtracking used place weighted furcy koenig
second addressed incremental search methods stenz
lite koenig likhachev lpa koenig likhachev b reuse
information previous search thus speeding subsequent replanning episodes


fib ulitko turtevant l u yau

full path computed first move executed
agent consequently time per move constant bounded increases
size thus agent centered full search real time
learning real time search
since seminal work lrta korf field learning real time heuristic
search flourished resulting twenty numerous variations
described following four attributes
local search space set states whose heuristic values accessed
stage two common choices full width limited depth lookahead korf shimbo
ishida shue zamani shue et al furcy koenig hernandez
meseguer b sigmundarson bjornsson rayner davison bulitko anderson
lu shaped lookahead koenig koenig likhachev additional
choices decision theoretic shaping russell wefald dynamic lookahead
depth selection bulitko lustrek bulitko
local learning space set states whose heuristic values updated common
choices current state korf shimbo ishida shue zamani shue
et al furcy koenig bulitko states within local search space koenig
koenig likhachev previously visited states neighbors hernandez
meseguer b sigmundarson bjornsson rayner et al
learning rule used update heuristic values states learning space
common choices dynamic programming mini min korf shue zamani shue
et al hernandez meseguer b sigmundarson bjornsson rayner
et al weighted versions shimbo ishida max mins bulitko modified dijkstras koenig updates respect shortest path
current state best looking state frontier local search space koenig likhachev
additionally several learn one heuristic function russell wefald
furcy koenig shimbo ishida
control strategy decides move following learning phases commonly
used strategies include first move optimal path promising frontier state korf
furcy koenig hernandez meseguer b entire path bulitko
backtracking moves shue zamani shue et al bulitko sigmundarson bjornsson
given multitude proposed unification efforts undertaken particular bulitko lee suggested framework called learning real time search lrts
combine extend lrta korf weighted lrta shimbo ishida sla shue
zamani sla shue et al large extent trap bulitko
dimensions described lrts operates follows uses full width fixed depth local search
space transposition tables prune duplicate states lrts uses max mins learning rule
update heuristic value current state local learning space control strategy moves
agent promising frontier state cumulative heuristic function updates
trial user specified quota backtracks previous state otherwise section
within lrts unification several accomplished implementing
several methods local search space selection learning rule control strategy


fig raph bstraction r eal time h euristic earch

methods engaged run time via user specified parameters resulting parameter space contained original plus numerous combinations enabling tuning
performance according specific objective function particular application
demonstration bulitko et al tuned lrts ten maps computer game baldurs
gate bioware corp achieved convergence speed two orders magnitude
faster lrta finding paths within optimal time lrts
five times faster first move incremental despite improvements lrts
real time search converge slowly visually may behave unintelligently
repeatedly revisiting dead ends corners
state abstraction
idea abstraction previously applied full search methods particular hpa
pra botea et al sturtevant buro use abstraction speed search instead
running lowest level graph instead run smaller abstract graph pra
computes abstract path refines similar manner pr lrts however pra
dynamically chooses abstract level use computes path intermediate level
e pass levels pra widens corridors decrease suboptimality
cost lower speed
hpa abstracts map large regions selects connection points gates neighboring regions gates region optimal paths gates pre computed line
stored table means refining abstract path e sequence
region gates done simply concatenating stored optimal paths smoothing applied
post processing step decrease suboptimality resulting path
ideas presented holte et al used
abstraction mechanism similar manner use clique abstraction method
star abstraction described radius abstraction state selected
aggregated together states fixed radius original state holte et al
work initially gain wide acclaim time little interest
small enough fit memory motivating applications pathfinding computer
games resulted resurgence interest techniques
class first plan abstract path refined traversable path
another build abstraction directly used realworld includes methods framed quad trees yahja stentz singh brummit
efficiently represent sparse maps quad trees multi resolution representation
areas map represented high resolution others represented lower resolution
abstraction differs abstractions clique abstraction applied
applications would produce lower resolution maps although clique abstraction
could applied graph implied framed quad tree representation
one common use abstraction provide better heuristics holte perez zimmer
macdonald used abstract search provide accurate heuristic lowlevel search performed path refinement similarly pattern databases abstractions
built solved line abstract solution costs stored used search
heuristic function culberson schaeffer felner zahavi schaeffer holte


fib ulitko turtevant l u yau

pr lrts presented first real time heuristic search use
automatically built state abstraction path refinement listed conduct full search
therefore cannot guarantee constant bounded time agents moves

limitations future work
presented open several directions future first pr lrts
able operate wide class homomorphic graph abstraction techniques thus would
interest investigate extent effects graph abstraction real time search
presented specific clique abstraction mechanism pathfinding domain
recent work shown clique abstraction parameters well tuned minimize
work done traditional path sturtevant jansen experiments pathfinding
suggested clique abstraction well suited map abstraction represents key
properties underlying space well particular branching factor stays roughly constant
higher levels abstraction empty map instance number nodes level
abstraction reduced factor four clique abstraction branching factor
every state stay corner states neighbors edge states
neighbors middle states neighbors may case domains
instance sliding tile puzzle maximum branching factor abstract states quickly increases
abstraction level corridor derived abstract path pr lrts becomes
excessively wide effectively constrain search ground level conjecture
use homomorphic abstractions effective domain abstraction
preserves average minimum maximum branching factor original
level abstraction clique abstraction likely work well three dimensional pathfinding
specific mechanisms would needed permutation type puzzles area
open provide abstraction
second pr lrts uses abstract solution restrict search original ground level
graph interesting combine complementary cost
optimal solution abstract heuristic estimate original search graph
context real time search particular looking effective ways propagating heuristic
values higher lower levels abstraction hierarchy
third state aggregation one way generalizing learning future consider
combining function approximation heuristic function commonly practiced
large scale applications reinforcement learning
fourth presently investigating applications pr lrts dynamic environments
particular studying extent savings memory gained learning higher
abstraction level afford application pr lrts moving target search existing ishida korf requires learning number heuristic values quadratic size
map prohibitive case commercial game maps
finally presently extending graph abstraction method presented
stochastic environments formulated markov decision processes


fig raph bstraction r eal time h euristic earch

conclusions
situated agents real time environments expected act quickly efficiently learning
initially unknown environment response time learning speed antagonistic performance
measures leads better actions consequently faster convergence longer
response time full search local repair converge quickly
constant bounded time per move real time heuristic search constantbounded times per move learn slowly
attempted combine best approaches suggest hybrid pr lrts learns heuristic function smaller abstract space uses corridorrestricted generate partial ground level path large scale empirical study pr lrts
found dominate virtually tested use abstraction respect
several performance measure pairs combination learning brings real time performance much larger search spaces substantially benefiting applications pathfinding
robotics video games

acknowledgments
funding provided national science engineering council canada
alberta ingenuity centre machine learning informatics circle excellence
university alberta appreciate input david thue rich korf rob holte csaba
szepesvari david furcy adi botea special thanks go jonathan schaeffer anonymous reviewers whose detailed comments greatly improved enabled use westgrid computing resources funded part canada foundation innovation alberta innovation science bc advanced education participating
institutions particular would acknowledge help roman baranowski
masao fujinaga doug phillips

appendix clique abstraction
describe clique abstraction mechanism several stages first present
building initial abstraction hierarchy free space assumption
describe repair procedure updates abstract graphs agent explores environment
finally consider suboptimality solution caused abstraction examples derive worstcase upper bound
building initial abstraction hierarchy
pseudo code building initial clique abstraction figure abstract procedure
lines takes set states level maps single abstract state level
involves creating abstract state storing parent child links line
abstract edge added one already exists add extra edge increase
count associated edge counts used facilitate abstraction repair described
next section
general clique finding np complete garey johnson however
eight connected two dimensional grid search graphs largest possible clique size


fib ulitko turtevant l u yau

graph cliqueabstraction graph g

initialize graph g



unabstracted state g

part clique c

g g abstract c

end

end

end

unabstracted state g

degree

set parent parent neighbor

else

g g abstract n

end
end

edge e v v

parent v parent v

g g parent v parent v

end
end
return g
figure building initial clique abstraction
degree
state constant bounded required section time per

clique constant e state accesses check eight neighbors form clique
together current state thus total running time single clique abstraction
number states original search graph abstraction procedure
reduces graph size least constant factor greater one total cost abstracting
graph cost additional abstraction step reduced exponentially
repairing abstraction hierarchy
agent explores environment may edges states blocked cases
remove corresponding states edges model need propagate changes
abstract graphs abstraction hierarchy demonstrate repair code figure
example shows repair procedure amortized constant time cost
figure remove edges level graph bottom left figure right
side figure shows full abstract graph edges removed level
portion abstract graph assume states edges graph
shown schematically level gray
level four states marked form abstract state level
true states marked joined edge level abstracted


fig raph bstraction r eal time h euristic earch

removeedge edge e level l graph g

decrease edge count e

child edge count e return end

e v v

remove e g l

parent v parent v

addtorepairq parent v

else

removeedge parent v parent v l g

end
removestate state level l graph g
edge e incident

removeedge e l g
end
remove g l
addtorepairq parent
handlerepairq
repairq empty

remove state lowest level l g

abstraction properties hold

addtorepairq parent

split state sn abstraction properties holds si

n

merge si existing abstract state

extract si abstract state

end

end
end
figure repairing abstraction hierarchy
four edges level remove edges level graph removeedge
procedure figure first three removals simply decrement count associated
abstract edge line fourth removal however removing
edge line removal recursively propagated line
abstraction hierarchy change abstract graph level edge count
decremented
edges must removed perform full split top bottom
states level figure removing first edge e e level requires
removal underlying edges level correspond edges level edges
b b
state repair first occurs remove edge e e case e e
parent g added repair queue line repair queue processed
set removal operations edge e e removed children g level
longer form clique thus g must split two states h h initially states


fib ulitko turtevant l u yau

removal repair
level

removal repair
h

level

split

split

g

e

h
f

e

level

level

level

split

e

f

b

c





b

c



e

level

split

e

f

f



b

c





b

c



split

e

level edges



f



level

level

split



split

level edges



f

b

c



split



b

c



figure example repairing clique abstraction

edge edge removed last edges level
removed repair code work many abstraction mechanisms specifically
check abstract states children still form clique line changed check
corresponding property non clique abstraction
example amortized cost abstraction repair constant imagine agent traversing graph level left right discovering wall splitting top bottom rows
states shown split label figure step graph sensed
agent edges removed level graph removing three edges b
b level requires removing six edges level similarly removing three edges
e e e f f e requires removing edges level general agent traveling
level must move twice far remove twice many states repair required
additional level abstraction thus number abstraction levels repaired traversing n
ground edges
n
n
n
n
n
log n n




n

consequently example amortized repair cost per edge traveled general
worst case complexity repair pr lrts constant independent graph size
repairs propagated abstraction hierarchy line figure


fig raph bstraction r eal time h euristic earch

appendix b abstraction properties
abstraction properties informally introduced illustrated example section
appendix makes presentation mathematically precise section variables k run
natural numbers including
property agent abstraction maintains hierarchy abstract search graphs addition model environment abstract graphs search graph sense
section following denote abstract search graph level
g c sg h g e
property state search graph level n unique parent state level
n abstract search graph formally


k k k parent

b

property state search graph level least one child
state level notation children represents set children state thus
children


k k k children

b

property given heuristic search instance number
children abstract state upper bounded constant independent number states
search e c sg h
children

b

property graph homomorphism every edge e k k n corresponding abstract edge level k abstract state
k k
e k parent parent e k parent parent b

property edge exists abstract states edge
child child
k k




e k children children e k
last property need following definition


b

fib ulitko turtevant l u yau

definition b path p space k e k k defined ordered sequence
states k whose two sequential states constitute valid edge e k formally p
path k e k
sm k p sm si si e k

b

use notation p k e k indicate vertices edges path p
sets k e k respectively notation p indicates state path p
property two children abstract state connected path whose states
children abstract state
k k children p k e k b
b abstraction induced suboptimality examples
abstraction cause suboptimality figure left refining abstract path solid
arrows indicate abstract path ground level path shown thinner dashed arrows
agents position shown goals position g white cells form corridor
induced abstract path optimal path shown right

figure abstraction causes suboptimality
partial path refinement increase suboptimality refining entire abstract path figure
left yield shorter paths refining segment abstract path figure right solid
arrows indicate abstract path ground level path shown thinner dashed arrows
agents position shown goals position g
b abstraction induced suboptimality upper bound
two factors contribute suboptimality paths returned pr lrts first
factor parameters chosen lrts weighted allow suboptimality effect
analyzed literature bulitko lee analyze suboptimality
introduced abstraction simplicity analysis consider uniform abstraction
level k states abstracted parent next level abstraction assumption simplifies analysis enables application analysis non clique abstraction
mechanism maintain property proving introduce two simple lemmas


fig raph bstraction r eal time h euristic earch

figure partial path refinement increases suboptimality
lemma b suppose abstract edges cost lowest cost path p states
b j edges lowest cost abstract path abstract parents b
j abstract edges
proof prove contradiction suppose lowest cost abstract path q b
j edges consider abstract images states p abstract
edge coincide due property thus form abstract path p
b due property j edges since assumption theorem
abstract edges cost lowest cost path q b must higher
cost path p b figure right contradiction
lemma b path created refining abstract edge level cannot longer k
level
proof demonstrated right portion figure assume every abstract state
exactly k children level abstraction state cannot k
children assuming path cannot visit single node refined path
therefore k edges
present main
theorem b assume every abstract state k children ground level edge costs
e level abstraction cost path created refining abstract path
level level original space ek times costly optimal path
abstract edges happen uniform cost e k abstract edges costs ek
lemma b
proof first deal case edges abstract graph uniform cost consider
two level states b abstract level states b left side figure lowestcost path p b j edges lowest cost abstract path b
j abstract edges lemma b


fib ulitko turtevant l u yau

path p j edges

path q j edges



b



b



path p j edges

b

path p j edges

figure proving lowest cost abstract path j edges
suppose agent state seeking go state b agent first computes
lowest cost abstract path b worst case abstract path j edges
suppose two abstract paths b shown figure left
j edges due uniform abstract edge cost assumption cost worst
case scenario refined lowest cost path b refined
highest cost path b analyzing cost ratio arrive
upper bound theorem
edge

path j edges



level

b

level
path j edges

k edges

figure paths cost yet refine shortest longest paths
due lemma b one abstract edge level refined k level edges
worst case j edges jk edges abstracting levels k
states single state furthermore edges cost leading total cost
j edges cost e leading total cost e jk thus ratio
costs higher ek proves first statement theorem
case abstract edges non uniform costs ek consider two abstract paths b cost ejk highest possible
cost level image cost j ground path path abstract cost might overestimated
j abstract edges cost ek refine level path j edges
cost thus total cost j lowest possible cost b
path cost ejk abstract edges cost since
abstract edges refined k edges level path refined path
ejk k edges cost e consequently total cost
e ejk k je k thus ratio costs e k


fig raph bstraction r eal time h euristic earch







b



b

b

w
c

c


w

w

j

w

w

j

figure grid example achieving worst case suboptimality
worst case upper bound tight occurs severely underestimate cost
suboptimal path overestimate cost optimal path figure
happen practice level map shown left lowest cost path states
b straight line cost j corridors width length corridors
w chosen level abstraction states corridor abstract together
single state map cliques size two e k theorem b
right part figure shows level abstract graph thick lines original map
light gray abstraction path b abstract parents
b goes lower part map path abstract cost c j w
abstract edges refine w ground level edges thus total cost refined path
w c j cw jw path abstract image abstract cost w k
j edges leading total abstract cost jk jw shown right side
figure highly zigzagged path
choose c costs much agent bad luck
choosing refine make certainty make cost slightly higher
cost accomplished setting c j w jw c jw j w
c jw jk j agent chooses refine cost
cw jw j j j ratio cost
corresponds bound theorem k e
experimental demonstrate large suboptimality occur practice illustration consider histogram suboptimality values
parametrizations pr lrts figure
suboptimality become practical concern one use ideas hpa botea
et al optimal path costs within regions pre computed cached precomputation help prevent severe estimation abstract path costs
assumed worst case analysis theorem b

appendix c maps used empirical study
four additional maps shown figure


fib ulitko turtevant l u yau



percentage

























suboptimality





figure histogram suboptimality experiments

figure four additional maps used experiments

appendix dominance average plots
six plots corresponding entries table shown figures


fig raph bstraction r eal time h euristic earch


lrts



lrts

lrts



dominated
nondominated

lrts

firstmove lag states touched

lrts

lrts







lrts
lrts

lrts


lrts




lrts

lrts
lrts

lrts





lrts







convergence travel



dominated
nondominated

lrts
lrts
lrts

lrts

lrts
lrts




firstmove lag seconds



lrtslrts




lrts
lrts
lrts
lrts




lrts
lrts

lrts





lrts

lrts




lrts







convergence travel



dominated
nondominated


firstmove lag seconds



lrts


lrts
lrts






lrts
lrts

lrts


lrts
lrts


lrts



convergence seconds





figure dominance several pairs performance measures part

appendix e dominance individual
section introduced concept dominance demonstrated pr lrts abstraction dominates extreme search use abstraction analysis done cost values averaged section consider


fib ulitko turtevant l u yau


lrts

lrts

lrts




dominated
nondominated



firstmove lag states touched

lrts







lrts

lrts





lrts

lrts





lrts
lrts


lrts

lrts







lrts









convergence memory

lrts



dominated
non dominated

lrts
lrts

lrts
lrts




first move lag seconds



lrts
lrts



lrts

lrts




lrts
lrts




lrts

lrts
lrts









convergence memory

dominated
nondominated


lrts

suboptimality



lrts



lrts
lrts
lrts






lrts
lrts

lrts
lrts














convergence states touched





figure dominance several pairs performance measures part
dominance individual due high variance difficulty
report percentages dominance achieved every pair
measure percentage first dominates second
measure percentage second dominates first ratio
two percentages call dominance ratio


fig raph bstraction r eal time h euristic earch







firstmove lag





























convergence travel


x

convergence travel

firstmove lag







lrts

lrts















lrts





lrts



x



figure top lrts shown filled star lrts shown hollow
star bottom left convergence travel bottom right first move lag
table statistics two figure


convergence travel

first move lag



lrts







lrts







dominance ratio


top figure see reproduction corresponding plot figure
two particular marked stars filled star lrts uses three
levels abstraction hollow star lrts operates entirely ground level
statistics reported table bottom left figure shows advantages pr lrts
respect convergence travel approximately pr lrts
travels less lrts convergence points degree line respect
first move lag pr lrts superior lrts bottom right
figure finally pr lrts dominates lrts e outperforms


fib ulitko turtevant l u yau



suboptimality


















convergence



convergence

x







suboptimality






lrts

lrts












lrts

















x





lrts



figure top lrts shown filled star lrts shown hollow
star bottom left convergence bottom right suboptimality
respect measures hand lrts dominates pr lrts approximately
leads dominance ratio
table statistics two figure


convergence

suboptimality



lrts







lrts







dominance ratio


similarly figure compares two respect convergence suboptimality final solution top figure corresponding plot figure
lrts shown filled star lrts shown hollow star percent
points domination individual found table plot bottom left
figure shows pr lrts lower convergence cost lrts
plot bottom right shows suboptimality solutions


fig raph bstraction r eal time h euristic earch

produced pr lrts optimal lrts time finally pr lrts
dominates lrts domination way e lrts dominates
pr lrts happens leads dominance ratio
several factors influence first high variance difficulty
individual due distribution five buckets optimal path distance consequently high variance trade antagonistic performance measures
case large difference mean values
figure dominance average supported dominance majority individual conversely small difference mean values e g suboptimality
figure lead overwhelming dominance level individual
extended analysis pairs displayed figures convergence travel first move lag dominance ratio varies values
infinity averaging standard error convergence
suboptimality dominance ratio varies values infinity averaging standard error finally set tested
study therefore viewed approximation actual dominance
relationship among

appendix f interaction abstraction lrts parameters
section observed general trends influence abstraction five performance measures abstraction level adds another dimension parameter space lrts previously
defined natural question four parameters interact order facilitate
comprehensible visualization reduce lrts parameter space
setting e disabling backtracking lrts justified two reasons first
recent studies bulitko lee sigmundarson bjornsson shown effects
backtracking highly domain specific
table gives overview influence abstraction parameters lrts qualitative level detailed analysis five performance measures follows
important note experiments performed set fixed cost paths fixed size
maps consequently map boundary effects observed higher levels abstraction
detail contribution
table influence lrts parameters impact abstraction cell table represents impact abstraction amplified diminished increase
lower case indicate minor effect indicates effect
increase






measure control parameter
convergence travel
first move lag
convergence
convergence memory
suboptimality

increase





convergence travel increasing abstraction level generally decreases convergence travel
lrts learns smaller abstract maps independently increasing lookahead depth lrts


fib ulitko turtevant l u yau

convergence travel
x

x

level
level
optimality weight








optimality weight



difference convergence travel



























lookahead depth



convergence travel



lookahead depth



difference convergence travel



level
level
optimality weight







optimality weight























lookahead depth





lookahead depth



figure convergence travel impact abstraction function top two graphs
lrts vs lrts bottom two graphs lrts vs lrts
similar effect bulitko lee convergence travel lower bounded doubled optimal
cost start goal first trial reveal parts map consequently
cannot final therefore decreasing convergence travel via two mechanisms diminishes
gains mechanism effect seen figure noticeable
gap convergence travel abstractions levels lookahead
small difference abstraction levels thus increasing lookahead
slightly diminishes effect abstraction hence table increasing increases
convergence travel higher value gained abstraction
increase amplifies advantage abstraction
first move lag generally increases abstraction level lookahead depth
lookahead depth increases size corridor used search increases well thus
increasing amplifies first move lag due abstraction pr lrts must plan within
lookahead space within lrts inside corridor within figure
deeper lookahead amplifies impact abstraction simplified analysis
assume map obstacle free leads levels abstraction regular grids
ignoring boundary effects length path two points expressed number
actions thus decreased factor two abstraction level assumptions
total number states pr lrts touches first move abstract graph


fig raph bstraction r eal time h euristic earch

firstmove lag

difference firstmove lag



level
level


optimality weight







optimality weight



























lookahead depth



firstmove lag



lookahead depth



difference firstmove lag




level
level
optimality weight








optimality weight




















lookahead depth





lookahead depth



figure first move lag impact abstraction function top two graphs lrts
vs lrts bottom two graphs lrts vs lrts
ground graph latter quantity simply number edges ground
path computed number edges abstract path multiplied reduction factor
adding abstraction levels increases first move lag increase
linear function lookahead depth thus larger values amplify effect adding extra
abstraction levels
several points glossed simplified analysis first reduction
path length two fold assumed presence walls higher levels
abstraction less likely locate merge fully fledged element cliques second boundaries
abstract graph reached lrts less moves higher abstraction level
effectively decreases quantity formula size corridor
reduced generous estimate finally feeding longer abstract path often improves
performance analyzed previous section cf figure explains
abstraction level deepening lookahead diminishing returns seen figure
optimality weight affect number states touched lrts abstract level
hand change cost resulting search different abstract path may
computed lrts overall however effect first move lag impact
abstraction inconsequential figure


fib ulitko turtevant l u yau

convergence



difference convergence

x





x

level
level


optimality weight


















optimality weight












lookahead depth



convergence



difference convergence






x

level
level


optimality weight







optimality weight



lookahead depth

























lookahead depth





lookahead depth



figure convergence impact abstraction function top two graphs
lrts vs lrts bottom two graphs lrts vs lrts
convergence abstraction level increases convergence generally
decreases effect complex deeper lookahead increases cost
individual step overall decreases costs convergence faster interplay
two trends moderates overall influence seen figure
effect convergence non trivial general lower values reduce
convergence cost note convergence cost product average
time per unit distance convergence travel discussed optimality weight
amplifies effects abstraction convergence travel time substantially
affect increase per move abstraction goes combining two influences
conclude optimality weight amplify effects abstraction convergence
confirmed empirically figure
convergence memory abstraction decreases amount memory used convergence fewer states learn effects convergence travel described strong correlation convergence
travel convergence memory previously discussed visually figures
display similar trends
suboptimality increasing abstraction level increases suboptimality plain lrts lookahead depth effect suboptimality final solution however combine deeper


fig raph bstraction r eal time h euristic earch

convergence memory

difference convergence memory



level
level
optimality weight







optimality weight






















lookahead depth



convergence memory



lookahead depth



difference convergence memory



level
level


optimality weight







optimality weight



























lookahead depth





lookahead depth



figure convergence memory impact abstraction function top two graphs
lrts vs lrts bottom two graphs lrts vs lrts

lookahead abstraction suboptimality arising abstraction decreases deeper lookahead abstract goal state seen earlier making pr lrts corridor constrained additionally
discussed section figure refining shorter paths computed lrts lower
introduces additional suboptimality suboptimality lower bounded increasing lookahead diminishes effects abstraction suboptimality figure hence table
increasing decreases amount suboptimality abstraction used combined abstraction increasing minor amplification effect difference abstraction
makes figure two reasons first abstract levels graphs fairly small makes
less difference second degree suboptimality abstract path translate directly
degree suboptimality resulting ground path may still reasonable
ground path thus influence abstract level overshadowed suboptimaly
introduced process refinement cf figure



fib ulitko turtevant l u yau

suboptimality

difference suboptimality



level
level


optimality weight













optimality weight



















lookahead depth



suboptimality



lookahead depth



difference suboptimality



level
level


optimality weight











optimality weight





















lookahead depth





lookahead depth



figure suboptimality impact abstraction function top two graphs lrts
vs lrts bottom two graphs lrts vs lrts



fig raph bstraction r eal time h euristic earch

references
aylett r luck applying artificial intelligence virtual reality intelligent virtual
environments applied artificial intelligence
bacchus f yang q downward refinement efficiency hierarchical
solving artificial intelligence
bioware corp baldurs gate published interplay http www bioware com bgate
november
blizzard entertainment warcraft iii reign chaos published blizzard entertainment
http www blizzard com war july
botea muller schaeffer j near optimal hierarchical path finding journal
game development
bulitko v learning adaptive real time search tech rep http arxiv org abs cs ai
computer science repository corr
bulitko v lee g learning real time search unifying framework journal
artificial intelligence jair
bulitko v sturtevant n kazakevich speeding learning real time search via
automatic state abstraction proceedings national conference artificial intelligence aaai pp pittsburgh pennsylvania
culberson j schaeffer j searching pattern databases csci canadian ai
conference advances artificial intelligence pp springer verlag
dini van lent carpenter p iyer k building robust execution
systems virtual worlds proceedings artificial intelligence interactive digital
entertainment conference aiide pp marina del rey california
ensemble studios age empires ii age kings published microsoft game studios
http www microsoft com games age june
felner zahavi u schaeffer j holte r dual lookups pattern databases
proceedings international joint conference artificial intelligence ijcai pp
edinburgh united kingdom
furcy itsa iterative tunneling search proceedings national
conference artificial intelligence aaai workshop heuristic search memory
heuristics applications boston massachusetts
furcy koenig speeding convergence real time search proceedings
national conference artificial intelligence aaai pp
furcy koenig limited discrepancy beam search proceedings international joint conference artificial intelligence ijcai pp
garey r johnson computers intractability guide theory
np completeness w h freeman co york ny usa
hansen e zhou r anytime heuristic search journal artificial intelligence
jair


fib ulitko turtevant l u yau

hansen e zilberstein danilchenko v anytime heuristic search first
tech rep cmpsci computer science department university massachusetts
hart p nilsson n raphael b formal basis heuristic determination
minimum cost paths ieee transactions systems science cybernetics
hernandez c meseguer p improving convergence lrta k proceedings
international joint conference artificial intelligence ijcai workshop
learning priori unknown dynamic domains pp edinburgh uk
hernandez c meseguer p b lrta k proceedings international joint
conference artificial intelligence ijcai pp edinburgh uk
holte r mkadmi zimmer r macdonald j speeding solving
abstraction graph oriented artificial intelligence
holte r perez zimmer r macdonald hierarchical searching abstraction
hierarchies efficiently tech rep tr university ottawa
id software doom published id software http en wikipedia org wiki doom december
ishida moving target search intelligence national conference artificial
intelligence aaai pp
ishida korf r moving target search proceedings international joint
conference artificial intelligence ijcai pp
kitano h tadokoro noda matsubara h takahashi shinjou shimada
robocup rescue search rescue large scale disasters domain autonomous agents
proceedings ieee conference man systems cybernetics vol
pp
koenig exploring unknown environments real time search reinforcement learning proceedings neural information processing systems pp
koenig comparison fast search methods real time situated agents proceedings int joint conf autonomous agents multiagent systems pp
koenig likhachev lite proceedings national conference
artificial intelligence aaai pp
koenig likhachev b incremental advances neural information processing systems nips pp
koenig agent centered search artificial intelligence magazine
koenig likhachev real time adaptive proceedings international
joint conference autonomous agents multiagent systems aamas pp
koenig simmons r solving robot navigation initial pose uncertainty
real time heuristic search proceedings international conference artificial
intelligence systems pp
koenig tovey c smirnov performance bounds unknown terrain
artificial intelligence


fig raph bstraction r eal time h euristic earch

korf r real time heuristic search artificial intelligence
likhachev ferguson gordon g stentz thrun anytime dynamic
anytime replanning proceedings international conference automated
scheduling icaps
likhachev gordon g j thrun ara anytime provable bounds suboptimality thrun saul l scholkopf b eds advances neural information
processing systems mit press cambridge
lustrek bulitko v lookahead pathology real time path finding proceedings
national conference artificial intelligence aaai workshop learning search
pp boston massachusetts
mero l heuristic search modifiable estimate artificial intelligence

orkin j states plan ai f e r proceedings game developers
conference gdc http www jorkin com gdc orkin jeff fear doc
pearl j heuristics addison wesley
pohl first effect error heuristic search meltzer b michie
eds machine intelligence vol pp american elsevier york
pohl avoidance relative catastrophe heuristic competence genuine dynamic
weighting computaional issues heuristic solving proceedings international joint conference artificial intelligence ijcai pp
pottinger c terrain analysis realtime strategy games proceedings computer
game developers conference www gamasutra com features gdcarchive pottinger doc
rayner c davison k bulitko v anderson k lu j real time heuristic search
priority queue proceedings international joint conference artificial
intelligence ijcai pp hyderabad india
reynolds c w flocks herds schools distributed behavioral model siggraph
proceedings th annual conference computer graphics interactive techniques pp york ny usa acm press
russell wefald e right thing studies limited rationality mit press
shimbo ishida controlling learning process real time heuristic search
artificial intelligence
shue l li zamani r intelligent heuristic project scheduling
proceedings nd annual meeting decision sciences institute
shue l zamani r admissible heuristic search proceedings
th international symposium methodologies intelligent systems ismis vol
lnai pp
sigmundarson bjornsson value back propagation vs backtracking realtime search proceedings national conference artificial intelligence aaai
workshop learning search boston massachusetts usa aaai press


fib ulitko turtevant l u yau

stenz focussed real time replanning proceedings
international joint conference artificial intelligence ijcai pp
stout b smart moves intelligent pathfinding game developer magazine october
sturtevant n hog hierarchical open graph http www cs ualberta ca nathanst hog
sturtevant n memory efficient abstractions pathfinding proceedings third
conference artificial intelligence interactive digital entertainment pp stanford california
sturtevant n buro partial pathfinding map abstraction refinement
proceedings national conference artificial intelligence aaai pp
pittsburgh pennsylvania
sturtevant n jansen r analysis map abstraction refinement
proceedings th international symposium abstraction reformulation approximation whistler british columbia press
sutton r integrated architectures learning reacting approximating dynamic programming proceedings seventh international conference
machine learning pp morgan kaufmann
thalmann noser h huang z autonomous virtual actors virtual sensors
lecture notes computer science lncs creating personalities synthetic actors
towards autonomous personality agents vol pp springer verlag london
yahja stentz singh brummit b framed quadtree path mobile
robots operating sparse environments proceedings ieee conference robotics
automation icra leuven belgium




