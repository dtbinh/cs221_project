Journal Artificial Intelligence Research 30 (2007) 621-657

Submitted 03/07; published 12/07

Query-time Entity Resolution
Indrajit Bhattacharya

indrajbh@in.ibm.com

IBM India Research Laboratory
Vasant Kunj, New Delhi 110 070, India

Lise Getoor

getoor@cs.umd.edu

Department Computer Science
University Maryland, College Park, MD 20742 USA

Abstract
Entity resolution problem reconciling database references corresponding
real-world entities. Given abundance publicly available databases
unresolved entities, motivate problem query-time entity resolution: quick
accurate resolution answering queries unclean databases query-time.
Since collective entity resolution approaches related references resolved jointly
shown accurate independent attribute-based resolution
off-line entity resolution, focus developing new algorithms collective resolution
answering entity resolution queries query-time. purpose, first formally
show that, collective resolution, precision recall individual entities follow
geometric progression neighbors increasing distances considered. Unfolding
progression leads naturally two stage expand resolve query processing strategy.
strategy, first extract related records query using two novel expansion
operators, resolve extracted records collectively. show
strategy adapted query-time entity resolution identifying resolving
database references helpful processing query.
validate approach two large real-world publication databases show
usefulness collective resolution time demonstrate need adaptive
strategies query processing. show queries answered
real-time using adaptive approach preserving gains collective resolution.
addition experiments real datasets, use synthetically generated data empirically
demonstrate validity performance trends predicted analysis collective
entity resolution wide range structural characteristics data.

1. Introduction
growing abundance publicly available data digital form, intense research data integration. critical component data integration process
entity resolution problem, uncertain references data real-world entities
people, places, organizations, events, etc., need resolved according
underlying real-world entities. Entity resolution needed order solve deduplication problem, goal identify consolidate pairs records references
within relational table duplicates other. comes
fuzzy match problem, tuples two heterogeneous databases different keys,
possibly different schemas, need matched consolidated. goes different
c
2007
AI Access Foundation. rights reserved.

fiBhattacharya & Getoor

names even within data mining database communities, including record linkage,
object consolidation, reference reconciliation.
problem long history, recent years seen significant fruitful
research problem. However, spite widespread research interest
practical nature problem, many publicly accessible databases remain unresolved,
partially resolved, best. popular publication databases, CiteSeer PubMed,
representative examples. CiteSeer contains several records paper author,
author names PubMed resolved all. due variety reasons,
ranging rapid often uncontrolled growth databases computational
expenses involved maintaining resolved entities.
Yet, millions users access query databases everyday, mostly seeking information that, implicitly explicitly, requires knowledge resolved entities. example,
may query CiteSeer database computer science publications looking books
Russell (Pasula, Marthi, Milch, Russell, & Shpitser, 2003). query would easy
answer author names CiteSeer correctly mapped entities. But,
unfortunately, case. According CiteSeer records, Stuart Russell Peter
Norvig written 100 different books together. One main reasons behind databases containing unresolved entities entity resolution generally perceived
expensive process large databases. Also, maintaining clean database requires
significant effort keep pace incoming records. Alternatively, may searching
different online social network communities person named Jon Doe. case,
online community may individually records clean. Even then, query
results return records sources aggregated together may multiple
representations Jon Doe entity. Additionally, cases, sufficient
simply return records match query name, S. Russell Jon Doe exactly.
order retrieve references correctly, may need retrieve records similar
names well, Stuart Russel John Doe. And, importantly, results
useful, need partition records returned according real-world
entities correspond. on-the-fly partitioning returned results
necessary accessing third-party external databases provide full access
possibly due privacy concerns, accessed via specific query
interfaces.
paper, propose alternative solution answering entity resolution queries,
obviate need maintaining resolved entities database. Instead,
investigate entity resolution query-time, goal enable users query
unresolved partially resolved database resolve relevant entities fly. user
may access several databases everyday want resolve entities every
database queries. needs resolve entities relevant
particular query. instance, looking books Stuart Russell CiteSeer,
useful resolve authors CiteSeer. Since resolution needs
performed query-time, requirement resolution process needs quick,
even entirely accurate.
Though entity resolution queries addressed literature,
significant progress general entity resolution problem. Recent research focused use additional relational information database references improve
622

fiQuery-time Entity Resolution

resolution accuracy (Bhattacharya & Getoor, 2004; Singla & Domingos, 2004; Dong, Halevy,
& Madhavan, 2005; Ananthakrishna, Chaudhuri, & Ganti, 2002; Kalashnikov, Mehrotra, &
Chen, 2005). improvement made possible resolving related references records
jointly, rather independently. Intuitively, corresponds notion figuring
two records refer underlying entity may turn give us useful information resolving record pairs related. Imagine trying decide
two authors Stuart Russell Russell person. confident
decision already decided co-authors Peter Norvig P.
Norvig person.
others done, earlier work (Bhattacharya & Getoor, 2004, 2007),
demonstrated using extensive experiments multiple real synthetic datasets
collective resolution significantly improves entity resolution accuracy attribute-based
naive relational baselines. However, application query-time entity resolution
straight-forward, precisely problem focus paper.
first difficulty collective resolution works database whole
specific query. Secondly, accuracy improvement comes considerable computation
cost arising dependencies related resolutions. added computational
expense makes application query-time resolution challenging.
paper, builds significantly extends work presented Bhattacharya, Licamele, Getoor (2006), investigate application collective resolution queries. First, formally analyze accuracies different decisions collective
resolution depend structural characteristics data. recursive nature dependency leads naturally recursive expand resolve strategy
processing queries. relevant records necessary answering query extracted
recursive expansion process collective resolution performed extracted records. Using analysis, show recursive expansion process
terminated reasonably small depths accurately answering query; returns fall
exponentially neighbors away considered.
However, problem unconstrained expansion process return many
records even small depths; thus query may still impossible resolve
real-time. address issue using adaptive strategy considers
informative related records answering query. significantly reduces
number records need investigated query time, but, importantly,
compromise resolution accuracy query.
specific contributions paper follows:
1. First, motivate formulate problem query-time entity resolution.
entity resolution approach based relational clustering algorithm. best
knowledge, clustering based queries presence relations received
little attention literature.
2. collective resolution using relational clustering, present analysis
accuracy different resolution decisions depends structural
characteristics data. introduce notion precision recall individual entities, show follow geometric progression neighbors
increasing distances considered resolved. analysis shows collective
623

fiBhattacharya & Getoor

use relationships sometimes hurt entity resolution accuracy.
previously reported literature. analysis additionally demonstrates convergent nature resolution performance recursive query-resolution strategy
propose.
3. resolving queries collectively, propose two-phase expand resolve algorithm. first extracts related records query using two novel expansion
operators, resolves query considering extracted records.
improve algorithm using adaptive approach selectively considers
informative ones among related records query. enables
collective resolution query-time without compromising resolution accuracy
query.
4. present experimental results two large real-world datasets strategy
enables collective resolution seconds. compare multiple baselines
show accuracy achieved using collective query resolution significantly higher
achieved using traditional approaches.
5. use synthetically generated data demonstrate gains collective query
resolution wide range attribute relational characteristics. additionally show empirical results agreement trends predicted
analysis collective resolution.
rest paper organized follows. Section 2, formalize relational
entity resolution problem entity resolution queries, illustrate
example. Section 3, briefly review relational clustering algorithm employ
collective entity resolution then, Section 4, investigate resolution accuracy
related entities depend collective resolution using algorithm.
Section 5, extend collective resolution queries, describe analyze unconstrained recursive strategy collectively resolving query. modify approach
Section 6 present adaptive algorithm extracts informative
references resolving query. present experimental results real synthetic data
Section 7, review related work Section 8 finally conclude Section 9.

2. Entity Resolution Queries: Formulation
section, formally introduce entity resolution problem entity resolution
queries, illustrate using realistic example resolving authors
citation database CiteSeer PubMed.
simplest formulation entity resolution problem, collection
references, R = {ri }, attributes {R.A1 , . . . , R.Ak }. Let E = {ej } unobserved
domain entities. particular reference ri , denote entity maps
E(ri ). say two references ri rj co-referent correspond
entity, E(ri ) = E(rj ). Note case unresolved database,
mapping E(R) provided. Further, domain entities E even number
entities known. However, many domains, may additional information
relationships references. model relationships generic way, use
624

fiQuery-time Entity Resolution

h1

h2

Mouse Immunity Model

r1
W Wang

r2
C Chen

r3

r4

r5

Ansari

W Wang

Ansari

h 3 Measuring Protienbound Fluxetine
r6
r7
r8
L Li

C Chen

Better Mouse Immunity Model

h 4 Autoimmunity Biliary Cirrhosis
r9
r 10
W W Wang

W Wang

Ansari

Figure 1: example set papers represented references connected hyper-edges.
References represented ovals shaded according entities. paper
represented hyper-edge (shown rectangle) spanning multiple references.

set hyper-edges H = {hi }. hyper-edge connects multiple references. capture
this, associate set references hi .R hyper-edge hi . Note reference
may associated zero hyper-edges.
Let us look sample domain see represented framework.
Consider database academic publications similar DBLP, CiteSeer PubMed.
publication database set author names. every author name,
reference ri R. reference ri , ri .N ame records observed name author
publication. addition, attributes R.Email record
information author reference may available paper. come
relationships domain. author references publication connected
co-author relationship. represented using hyper-edge hi H
publication rj hi .R reference rj publication.
publications additional information title, keywords, etc, represented
attributes H.
illustrate, consider following four papers, use running example:
1. W. Wang, C. Chen, A. Ansari, mouse immunity model
2. W. Wang, A. Ansari, better mouse immunity model
3. L. Li, C. Chen, W. Wang,Measuring protein-bound fluxetine
4. W. W. Wang, A. Ansari, Autoimmunity biliary cirrhosis
represent notation, 10 references {r1 , . . . , r10 } R, one
author name, r1 .N ame = W Wang, etc. 4 hyper-edges {h1 , . . . , h4 }
H, one paper. first hyper-edge h1 connects three references r1 , r2
r3 corresponding names W. Wang , C. Chen A. Ansari. represented
pictorially Figure 1.
Given representation, entity resolution task defined partitioning
clustering references according underlying entity-reference mapping E(R).
Two references ri rj assigned cluster
625

fiBhattacharya & Getoor

coreferent, i.e., E(ri ) = E(rj ). illustrate, assume six underlying entities
example. illustrated Figure 1 using different shading entity.
example, Wangs papers 1, 2 4 names individual Wang
paper 3 reference different person. Also, Chens papers 1 3
different individuals. Then, correct entity resolution example database 10
references returns 6 entity clusters: {{r1 , r4 , r9 }, {r8 }, {r2 }, {r7 }, {r3 , r5 , r10 }, {r6 }}.
first two clusters correspond two different people named Wang, next two two
different people named Chen, fifth Ansari last Li.
query database references called entity resolution query answering
requires knowledge underlying entity mapping E(R). consider two different
types entity resolution queries. commonly, queries specified using particular
value attribute R.A references serves quasi-identifier
underlying entities. answer query Q(R.A = a) partition group
references r.A = according underlying entities. references
people, name often serves weak noisy identifier. example bibliographic
domain, consider queries specified using R.N ame. retrieve papers written
person named W. Wang, issue query using R.N ame W. Wang. Since
names ambiguous, treating identifiers leads undesirable results. case,
would incorrect return set {r1 , r4 , r8 } references name W Wang
answer query. answer indicate r8 person
two. Additionally, answer include reference r9 W W Wang,
maps entity author first paper. Therefore, correct answer
entity resolution query W Wang partition {{r1 , r4 , r9 }, {r8 }}.
Entity resolution queries may alternatively specified using specific reference. Imagine CiteSeer user looking paper contains author name. user may
interested looking papers written author, even though may
know author precisely. correct answer query reference
r group references coreferent r, or, words, correspond
underlying entity. example, consider query specified using reference r1
corresponding name W. Wang first paper. correct answer
query set references {r1 , r4 , r9 }. distinguish first type entity
resolution query, note include cluster {r8 } corresponding
entity name W. Wang. second query type may answered first
reducing instance first type Q(R.A = r1 .A), selecting entity
corresponding reference r1 . denote E(R)=E(r1 ) (Q(R.A = r1 .A)). rest
paper, focus queries first type.

3. Collective Entity Resolution Relational Clustering
Although entity resolution queries studied literature, general
entity resolution problem received lot attention. review related work detail
Section 8. section, briefly review different categories proposed approaches
discussing may adapted query-time entity resolution.
entity resolution applications, data labeled underlying entities hard
acquire. focus unsupervised approaches resolving entities. Traditionally,
626

fiQuery-time Entity Resolution

attributes individual references, names, affiliation, etc., person references,
used comparing references. similarity measure generally employed attributes,
pairs references attribute similarity certain threshold
considered co-referent. attribute-based entity resolution approach (A)
often runs problems. example, hard infer attributes
references r1 r8 co-referent although name, r1 r9
co-referent although names different.
relations references available, may taken account
computing similarities naive relational entity resolution approach (NR)
(Ananthakrishna et al., 2002; Bhattacharya & Getoor, 2007). computing similarities
two references, approach additionally considers attributes related
references comparing attributes related references. example,
approach returns higher similarity r1 (W. Wang) r9 (W. W. Wang)
attribute-based approach, since co-authors r3 r10 similar (identical, case) names. Although approach improve performance cases,
always work. instance, two W. Wang references r1 r8
co-referent, though co-authors identical names C. Chen.
Instead considering attribute similarities related references, collective
entity resolution approach (Pasula et al., 2003; Bhattacharya & Getoor, 2004; Singla
& Domingos, 2004; McCallum & Wellner, 2004; Li, Morie, & Roth, 2005; Dong et al.,
2005; Kalashnikov et al., 2005) takes account resolution decisions them.
previous example, correct evidence use pair references r1 r8
co-author references map entity, although similar names.
Therefore, order resolve W. Wang references collective resolution approach,
necessary resolve C. Chen references well, instead considering similarity
attributes. collective entity resolution approach recently shown
improve entity resolution accuracy previous approaches computationally
challenging. references cannot resolved independently. Instead, resolution
decision affected resolutions hyper-edges.
earlier work (Bhattacharya & Getoor, 2004, 2006, 2007), developed relational
clustering algorithm (RC-ER) collective entity resolution using relationships. goal
approach cluster references according entities taking relationships
account. associate cluster label r.C reference denote current
cluster membership. Starting initial set clusters C = {ci } references,
algorithm iteratively merges pair clusters similar. capture
collective nature cluster assignment, similarity measure pairs clusters
considers cluster labels related references. similarity two clusters ci
cj defined linear combination attribute similarity simA relational
similarity simR :
sim(ci , cj ) = (1 ) simA (ci , cj ) + simR (ci , cj )

(1)

(0 1) combination weight. interesting aspect collective
approach dynamic nature relational similarity. similarity two
references depends current cluster labels related references, therefore
changes related references change clusters. example, similarity two
627

fiBhattacharya & Getoor

clusters containing references W. Wang W. W. Wang increases co-author
references named A. Ansari assigned cluster. briefly review
two components similarity measure defined.
Attribute Similarity: reference attribute, use similarity measure
returns value 0 1 two attribute values indicating degree similarity
them. Several sophisticated similarity measures developed names,
popular TF-IDF schemes may used textual attributes keywords.
measure works best attribute may chosen. Finally, weighted linear
combination similarities different attributes yields combined attribute
similarity two reference clusters.
Relational Similarity: Relational similarity two clusters considers similarity cluster neighborhoods. neighborhood cluster defined
hyper-edges associated references cluster. Recall reference r
associated one hyper-edges H. Therefore, hyper-edge set c.H
cluster c references defined
c.H =

[

{h | h H r h.R}

(2)

rRr.C=c

set defines hyper-edges connect cluster c clusters,
ones relational similarity needs consider. illustrate, references
running example correctly clustered Figure 1(b), hyper-edge set
larger Wang cluster {h1 , h2 , h4 }, hyper-edges associated
references r1 , r4 r9 cluster.
Given hyper-edge set cluster c, neighborhood N br(c) cluster c
set clusters labels references spanned hyper-edges:
N br(c) =

[

{cj | cj = r.C}

(3)

hc.H,rh

example Wang cluster, neighborhood consists Ansari cluster one
Chen clusters, connected edge-set. Then, relational similarity
measure two clusters, considers similarity cluster neighborhoods.
neighborhoods essentially sets (or multi-sets) cluster labels many possible ways define similarity two neighborhoods (Bhattacharya & Getoor, 2007).
specific similarity measure use experiments paper Jaccard
similarity1 :
simR (ci , cj ) = Jaccard(N br(ci ), N br(cj ))
(4)
Clustering Algorithm: Given similarity measure pair clusters, greedy
relational clustering algorithm used collective entity resolution. Figure 2 shows
high-level pseudo-code complete algorithm. algorithm first identifies candidate set potential duplicates using blocking approach (Hernandez & Stolfo, 1995;
Monge & Elkan, 1997; McCallum, Nigam, & Ungar, 2000). Next, initializes clusters
1. Jaccard similarity two sets B defined Jaccard(A, B) =

628

|AB|
|AB|

fiQuery-time Entity Resolution

1.
2.

Algorithm RC-ER (Reference set R)
Find similar references R using blocking
Initialize clusters using bootstrapping

3.
4.

clusters ci , cj similar(ci , cj )
Insert hsim(ci , cj ), cj , cj priority queue

5.
6.
7.
8.
9.
10.
11.
12.
13.
14.

priority queue empty
Extract hsim(ci , cj ), ci , cj queue
sim(ci , cj ) less threshold, stop
Merge ci cj new cluster cij
Remove entries ci cj queue
cluster ck similar(cij , ck )
Insert hsim(cij , ck ), cij , ck queue
cluster cn neighbor cij
ck similar(ck , cn )
Update sim(ck , cn ) queue
Figure 2: High-level description relational clustering algorithm

references, identifies similar clusters potential merge-candidates
cluster, inserts merge-candidates priority queue iterates
following steps. step, identifies current closest pair clusters candidate set merges create new cluster. identifies new candidate pairs
updates similarity measures related cluster pairs. key step
evidence flows one resolution decision related ones distinguishes relational clustering traditional clustering approaches. algorithm terminates
similarity closest pair falls threshold list potential candidates exhausted. algorithm efficiently implemented run O(nk log n) time
n references block similar names connected k blocks
hyper-edges.
3.1 Issues Collective Resolution Queries
previous work, (and others) shown collective resolution using relationships
improves entity resolution accuracy significantly offline cleaning databases. So, naturally, would use approach query-time entity resolution well.
However, attribute-based naive relational approaches discussed earlier
applied query-time straight-forward fashion, case collective
resolution. Two issues come using collective resolution queries. First,
set references influence resolution decisions query need identified.
answering resolution query S. Russell using attribute-based approach,
sufficient consider papers S. Russell (or, similar names) author name.
collective resolution, contrast, co-authors author names, P.
629

fiBhattacharya & Getoor

Norvig Peter Norvig, need clustered according entities.
turn requires clustering co-authors on. first task analyze
dependencies collective resolution identify references database
relevant answering query. enough. set references influencing
query may extremely large, query still needs answered quickly even though
answer may completely accurate. second issue performing resolution
task query-time. two problems address next sections.

4. Analysis Collective Resolution using Relational Clustering
collective entity resolution, seen resolution performance query
becomes dependent resolution accuracy related entities. analyze
references influence entity resolution query extent, need
analyze nature dependence collective resolution general. section,
identify structural properties data affect collective entity resolution
formally model interdependent nature resolution performance. analysis
helps us understand collective resolution using relational clustering helps,
and, equally importantly, adverse effect compared traditional
attribute-based resolution.
goal entity resolution algorithm partition set R = {ri } references
set clusters C = {ci } according underlying entities E = {ei }. accuracy resolution depends closely separation references clusters
corresponds underlying entities. consider two different measures performance.
first measure recall entity. entity ei , recall counts many pairs
references corresponding ei correctly assigned computed cluster.
second measure precision computed cluster. cluster ci , precision counts
many pairs references assigned ci truly correspond underlying entity.
(Alternatively, imprecision measures many pairs references assigned cluster
correspond entity.) next two subsections, analyze
two performance metrics influenced, first, attribute values references,
then, observed relationships them.
4.1 Influence Attributes
First, consider entity resolution algorithm follows traditional attribute-based approach analysis performance. algorithm considers attributes
individual references. uses similarity measure defined domain attributes,
considers pair-wise attribute similarity references resolving them. Let us
define two references -similar attribute-similarity least . Then, given
resolution threshold , attribute-based approach assigns pair references
cluster -similar. illustrate using example, using
similarity measure defined names appropriately determined similarity threshold
, attribute-based approach would assign three W. Wang references (r1 , r4 , r8 )
one cluster c1 W. W. Wang reference (r9 ) different cluster c2 . resolution
Wang references perfect terms precision recall, since references r1 , r4
r9 map one entity e1 r8 maps second entity e2 . Cluster c1 precision less
630

fiQuery-time Entity Resolution

1, since incorrectly includes references two different entities, recall less
1 entity e1 , since references dispersed two different clusters.
order analyze performance attribute-based resolution approach given
arbitrary dataset, characterize dataset terms attribute values
references. Intuitively, attribute-based approach works well references
corresponding entity similar terms attributes,
references corresponding different entities not. capture formally, define
two probabilities measure attribute-similarity references map
entity, attribute-similarity map different entities:
attribute identification probability aI (e, ): probability pair references chosen randomly corresponding entity e -similar
other.
attribute ambiguity probability aA (e1 , e2 , ): probability pair references chosen randomly one corresponds entity e1 entity
e2 -similar other.
illustrate using four Wang references, r1 , r4 r9 correspond
entity e1 r8 corresponds different entity e2 . Also, assume similarity
measure names appropriate threshold , references r1 , r4 r8 -similar
other. Then, 3 pairs references corresponding entity e1 , one (r1
r4 ) -similar, attribute identification probability aI (e1 , ) entity e1 0.33.
hand, three pairs references one maps e1
e2 , two (r1 r8 , r4 r8 ) -similar. means attribute ambiguity
probability aA (e1 , e2 , ) e1 e2 0.66.
seen example, performance attribute-based clustering algorithm represented terms two probabilities. specified
threshold , pairs references entity correctly recalled ones
-similar, exactly aI (e, ) captures. Therefore, recall domain
entity e R(e, ) = aI (e, ). hand, consider cluster assignment
references correspond two entities e1 e2 . pairs incorrectly clustered
together correspond two different entities, yet -similar.
aA (e1 , e2 , ) captures. Therefore imprecision cluster assignment reference
pairs corresponding entities e1 e2 I(e1 , e2 , ) = aA (e1 , e2 , ). Alternatively,
precision given P (e1 , e2 , ) 1 I(e1 , e2 , ) = 1 aA (e1 , e2 , ).
4.2 Influence Relationships
Now, consider collective entity resolution approach additionally makes use
relationships, analyze impact entity resolution accuracy. Recall
set H = {hj } observed co-occurrence relationships references. cooccurrences references useful entity resolution result strong
ties relations underlying entities. Specifically, assume references
entity ei co-occur frequently references small set entities {e1i , . . . , eki },
call entity neighbors, denoted N (ei ), entity ei .
631

fiBhattacharya & Getoor

W.W. Wang
W. Wang

h4

A. Ansari
A. Ansari

W. Wang
W. Wang

h1

h1
h3

C. Chen
C. Chen

Figure 3: Illustration (a) identifying relation (b) ambiguous relation running
example. Dashed lines represent co-occurrence relations.

Assuming neighborhood relationship among underlying entities allows us
analyze performance relational clustering approach. reference pairs
-similar terms attributes, attribute evidence enough resolution.
now, unlike attribute-based clustering, pair references -similar terms
attributes, < , considered candidates clustered together.
actually get assigned cluster. reference pairs ring
uncertainty , relationships play role determining similar
enough, consequently, clustered together. Specifically, references ri
rj co-occur hyper-edge h references ri rj co-occur hyper-edge
h , relational similarity pair (ri , ri ) (rj , rj ) belong
cluster. general, multiple relationships may needed tipping balance,
simplicity, assume single pair related references sufficient.
words, ri ri get assigned cluster rj rj cluster.
analyze impact approach entity resolution performance.
Without loss generality, assume (rj , rj ) pair get clustered together first
relational clustering algorithm. results pair (ri , ri ) getting clustered
later iteration considering relational evidence. see accurate,
consider two situations, attribute evidence. first shown Figure 3(a),
pairs truly correspond entity. collective resolution decision
correct say hyper-edges h h identifying relationships entity.
Formally,
IRel(h, h , e) ri , rj h.R, ri , rj h .R,
E(ri ) = E(ri ) = e, E(rj ) = E(rj )

(5)

hand, may different scenario, pairs references correspond two different entities. second scenario depicted Figure 3(b).
first decision resolve (rj , rj ) co-referent incorrect, relational evidence obtained
hyper-edges h h consequently leads incorrect resolution (ri , ri ).
situation, collective resolution hurts accuracy, say h h form ambiguous
relationships pairs entities, whose references may incorrectly clustered
result relationships. Formally,
IAmb(h, h , e, e ) ri , rj h.R, ri , rj h .R,
632

fiQuery-time Entity Resolution

E(ri ) = e, E(ri ) = e , e 6= e ,
E(rj ) 6= E(rj )

(6)

general, reference ri co-occurrence relation h includes
one reference. may think multiple co-occurrence pairs involving ri .
Cluster labels references pairs influence resolution decisions ri .
resolving ri another reference ri participates co-occurrence relation h ,
fraction common cluster labels h h determines whether ri
ri clustered together. assigned cluster, h h labeled
identifying ambiguous relationships based whether ri ri actually co-referent
not.
Formally, define:
identifying relationship probability rI (e, ): probability randomly chosen pair -similar references corresponding entity e identifying relationships
h h entity.
ambiguous relationship probability rA (e1 , e2 , ): probability pair
-similar references, chosen randomly one corresponds entity e1
entity e2 , ambiguous relationships h h pair
entities.
illustrate probabilities using example, two Wang entities, e1
references r1 , r4 r9 , e2 reference r8 . Assume attribute
threshold six pairs considered potential matches. three pairs
references corresponding e1 , identifying relationships Ansari
entity. So, rI (e1 , ) = 1. measure relational ambiguity two Wang
entities, consider 3 possible pairs (r1 r8 , r4 r8 , r9 r8 ).
one (r1 r8 ) pair ambiguous relationships two different Chen entities. So,
rA (e1 , e2 , ) = 0.33.
Given two probabilities, analyze performance relational clustering algorithm combines attribute relational evidence collective entity resolution.
hard see recall entity depends recursively recall
neighbor entities. pair references entity e resolved correctly basis
attributes alone probability aI (e, ) (the identifying attribute probability). Furthermore, may still resolved correctly presence identifying relationships
neighbor entity, related reference pair neighbor resolved correctly. Denoting
R(e, , ) recall entity e neighbors R(N (e), , ), have:
R(e, , ) = aI (e, ) + (1 aI (e, )) rI (e, ) R(N (e), , )

(7)

hand, consider pair entities e1 e2 . cluster assignment
pair references corresponding e1 e2 imprecise basis attributes
alone probability aA (e1 , e2 , ). Even otherwise, cluster assignment go wrong
considering relational evidence. happens presence ambiguous relationships
references corresponding another pair entities, references clustered
633

fiBhattacharya & Getoor

together incorrectly. imprecision I(e1 , e2 , , ) cluster assignment reference
pairs corresponding entities e1 e2 turns be:
I(e1 , e2 , , ) = aA (e1 , e2 , ) + (1 aA (e1 , e2 , )) rA (e1 , e2 , ) I(N (e1 ), N (e2 ), , ) (8)
general, entity e multiple neighbors ei neighborhood N (e). formalize performance dependence multiple neighbors, assume co-occurrence
involving references corresponding e chosen random, probability selecting
co-occurrence reference corresponding ei pei . recall given as:
|N (e)|

R(e) = aI (e) + (1 aI (e)) rI (e)

X

pei R(ei )

(9)

i=1

Note dropped notational brevity. defining imprecision, observe
reference corresponding neighbor ei1 e1 may co-occur reference
neighbor ej2 e2 probability pei 1 pej 2 . imprecision given as:
|N (e1 )| |N (e2 )|

I(e1 , e2 ) = aA (e1 , e2 ) + (1 aA (e1 , e2 )) rA (e1 , e2 )

X

X

i=1

j=1

pei 1 pej 2 I(ei1 , ej2 )

(10)

Given similarity thresholds , relational clustering increases recall beyond
achievable using attributes alone. improvement larger probability identifying relationships higher. flip side, imprecision increases relational
clustering. Typically, low attribute threshold corresponds high precision used,
recall increased using relational evidence. probability ambiguous
relations rA small, accompanying increase imprecision negligible, performance improved overall. However, higher ambiguous relationship probability
rA , less effective relational clustering. Thus balance ambiguous
identifying relations determines overall benefit collective resolution using relational
clustering. rA high compared rI , imprecision increases faster recall,
overall performance adversely affected compared attribute-based clustering. Eq. (9)
Eq. (10) quantify dependence resolution performance entity nature
relationships entities. next section, use equations
design analyze relational clustering algorithm answering entity resolution queries.

5. Collective Resolution Queries
analysis collective resolution using relational clustering showed resolution accuracy underlying entity depends resolution accuracy related/neighboring entities. problem answering entity resolution queries, goal
resolve entities database. need resolve entities
references retrieved query. seen collective resolution leads
potential performance improvements attribute-based resolution. investigate
collective resolution applied answering queries get similar improvements.
obvious hurdle illustrated expressions performance metrics Eq. (9)
Eq. (10). show order get performance benefits resolving query using
634

fiQuery-time Entity Resolution

relational clustering, need resolve neighboring entities well. Furthermore,
resolve neighboring entities, need resolve neighboring entities, on.
entities need resolved large number, resolving
expensive terms query-processing time. Also, none actually going
retrieved part answer query. critical identify resolve
entities contribute improving resolution accuracy query.
propose two-stage query processing strategy, consisting extraction phase,
identifying relevant references need resolved answering query,
resolution phase, relevant references extracted collectively
resolved using relational clustering. Unfolding Eq. (9) Eq. (10) starting query
entities leads natural expansion process. section, describe extraction
process using two novel expansion operators and, parallel, analyze improvement
resolution accuracy obtained considering co-occurrences.
Recall entity resolution query Q(R.A = a) specified using attribute
value it. answer query consists partitioning references
r r.A = value -similar a. correct answer query,
general, involves references multiple entities {eq }. measure resolution accuracy
query using two metrics before. query entities eq , measure recall
R(eq ) imprecision I(eq , e ) respect entity e . Entity e may may
belong {eq }.
going details algorithm collective resolution queries,
briefly recall accuracy attribute-based strategy resolving query. approach
considers references r r.A -similar a, resolves using attributes
only. recall results approach R(eq , ) = aI (eq , ), imprecision
given I(eq , e , ) = aA (eq , e , ).
propose two expansion operators constructing relevant set entity
resolution query. denote level-0 references references -similar
query attribute. references user interested in, goal
resolve correctly. first operator introduce attribute expansion
operator XA , A-expansion short. Given attribute value
attribute, XA (a, ) returns references r whose attributes r.A exactly match similar a. query Q(R.A = a), level-0 references retrieved expanding
Q as:
Rel0 (Q) = XA (a, )
first step Figure 4 shows A-expansion query Q(R.N ame = W.W ang)
example. retrieves four references (r1 ,r4 ,r8 ,r9 ) name W. Wang W. W.
Wang.
consider co-occurrence relations, construct level-1 references including
references co-occur level-0 references. this, use second operator,
call hyper-edge expansion XH , H-expansion. reference r, XH (r)
returns references share hyper-edge r, set R references XH (R)

returns rR XH (r). Collective entity resolution requires consider co-occurring
references reference. achieved performing H-expansion references
635

fiBhattacharya & Getoor

Q
R.Name=W_Wang

1

r 11 A_Ansari

Rel (Q)

0

Rel (Q)

r 9 W_W_Wang

r 10 A_Ansari

r 4 W_Wang

r 5 A_Ansari

r 54 A_Ansari

r 3 A_Ansari

r 23 C_Chen
...

r 1 W_Wang

r 2 C_Chen

r 8 W_Wang

r 7 C_Chen
r 6 L_Li

Rel2 (Q)

...

r 89 C_Chen
r 16 L_Li
...
r 66 L_Li

Figure 4: Relevant set query Q(R.N ame = W.W ang) using H-expansion Aexpansion alternately

level-0 retrieve level-1 references:
Rel1 (Q) = XH (Rel0 (Q))
Figure 4 illustrates operation example, XH (r1 ) retrieves references C.
Chen (r2 ) A. Ansari (r3 ), on.
perform collective resolution query, additionally need resolve references level-1. One option level-1 references attribute-based resolution using
conservative -similarity keep imprecision minimum. use analysis technique evaluate performance approach. Expanding Eq. (9),
substituting aI (eiq , ) recall neighboring entity eiq eq , recall
query entity is:
R(eq , , ) = aI (eq , ) + (1 aI (eq , )) rI (eq , )

k
X

e

pi q aI (eiq , )

i=1

Similarly, substituting aA (eiq , ej , ) Eq. (10) imprecision neighboring
entity eiq , get following expression imprecision:
I(eq , e , , ) = aA (eq , e , ) + (1 aA (eq , e , )) rA (eq , e , )

k X
l
X

e





pi q pej aA (eiq , e j , )

i=1 j=1

appreciate easily implications considering first-order neighbors, may
assume attribute identification probability attribute ambiguity probability
entities involved, i.e., aI (e, ) = aI () aA (e, e , ) = aA (). Then,
P
using ki=1 pei = 1 entity e, expression recall simplifies
R(eq , , ) = aI () + (1 aI ()) rI () aI ()
= aI ()[1 + (1 aI ())rI ()]
636

fiQuery-time Entity Resolution

Similarly, expression imprecision simplifies
I(eq , e , , ) = aA ()[1 + (1 aA ())rA ()]
see attribute-clustering first level neighbors potentially increases
recall query entity eq , imprecision goes well. However, balance rA rI favorable, increase imprecision insignificant much
smaller corresponding increase recall, overall performance
improvement.
better this? go step consider co-occurrence
relations resolving level-1 references well. So, instead considering attributebased resolution references level-1 before, perform collective resolution them.
consider -similar references, call level-2 references (Rel2 (Q)), using
A-expansion:
Rel2 (Q) = XA (Rel1 (Q))
Note overloaded A-expansion operator set R references: XA (R) =
rR XA (r.A). level-3 references second order neighbors co-occur
level-2 references. retrieved using H-expansion level-2 references:



Rel3 (Q) = XH (Rel2 (Q))
Finally, level-1 references earlier, resolve level-3 references using similarity attributes alone.
order evaluate impact resolution accuracy query, unfold
recursions Eq. (9) Eq. (10) two levels, substitute aI (eiq , ) recall
aA (ei , ej , ) imprecision second order neighbors. trend expressions
becomes clearly visible assume, before, aI aA identical entities, and,
additionally, rI rA same, i.e., rI (e1 , e2 , ) = rI () rA (e1 , e2 , ) = rA ().
Then, work algebraic steps get following expressions recall
precision query entity eq :
R(eq ) = aI [1 + (1 aI )rI + (1 aI )2 rI2 ]


I(eq , e ) = aA [1 + (1 aA )rA + (1

2
aA )2 rA
]

(11)
(12)

continue unfold recursion grow relevant set query.
Formally, expansion process alternates A-expansion H-expansion:
Reli (Q) = XA (Q)
XH (Reli1 (Q))
XA (Reli1 (Q))

= 0
odd
even

proceed recursively consider higher order co-occurrences query, additional terms appear expressions precision recall. imply
need continue process arbitrary levels get optimum benefit. Using
simplifying assumptions attribute relational probabilities, expressions recall imprecision nth order co-occurrences turns geometric
637

fiBhattacharya & Getoor

progressions n + 1 terms. common ratio two geometric progressions
(1 aI ())rI () (1 aA ())rA () respectively. Typically, ratios significantly smaller 1, therefore converge quickly increasing co-occurrence
level. improvement resolution accuracy query Q falls quickly
expansion depth, terminate expansion process cut-off depth
without compromising accuracy:


Rel(Q) =


[

Reli (Q)

i=0

course, assumptions attribute relational probabilities entityindependent hold practice, performance trends increasing levels
co-occurrence cannot exactly captured geometric progressions common ratio
successive terms. converging trends still hold general,
rate convergence still determined four probabilities aI , aA , rI rA
entities encountered expansion process. Intuitively, smaller values
rI rA indicate less sensitivity co-occurrences, convergence quicker.
hand, higher values aI aA mean entities resolved based
attributes alone correctly incorrectly impact co-occurrence relations
smaller. Therefore convergence quicker higher values aI aA .
Apart imposing cutoff expansion depth, size relevant set
significantly reduced restricting attribute expansion beyond level-0 exact
e (r). considers references exactly attribute
A-expansion XA
r disregards -similar references. Interestingly, show restricted
strategy alternates exact A-expansion H-expansion reduce recall
significantly.

6. Adaptive Query Expansion
limited depth query expansion strategy proposed previous section effective
approach able answer queries quickly accurately many domains. However,
domains, size relevant set generated extremely large even
small expansion depths, result, retrieved references cannot resolved
query-time. section, propose adaptive strategies based estimating
ambiguity individual references makes algorithm even efficient
preserving accuracy.
main reason behind explosive growth relevant set increasing levels
query expansion strategy previous section unconstrained treats
co-occurrences equally important resolving entity. blindly expands
references current relevant set, includes new references generated
expansion operation. Given limited time process query, approach infeasible
domains dense relationships. solution identify references
likely helpful resolving query, focus references.
illustrate using example Figure 4, observe Chen Li significantly
common ambiguous names Ansari even different W. Wang entities
likely collaborators named Chen Li. Therefore, h-expanding Rel0 (rq )
638

fiQuery-time Entity Resolution

W. Wang, Ansari informative Chen Li. Similarly, n-expanding
Rel1 (rq ), choose expand name A. Ansari further, since two A.
Ansari references likely coreferent. need evidence
Chens Lis.
describe formally, ambiguity value attribute probability two references ri rj database ri .A = rj .A =
coreferent: Amb(a) = P (E(ri ) 6= E(rj ) | ri .A = rj .A = a). goal adaptive expansion
add less ambiguous references relevant set expand ambiguous
references currently relevant set. first define adaptive versions two expansion operators treating ambiguity estimation process black-box, look
ways estimate ambiguity references.
6.1 Adaptive Expansion Operators
goal adaptive expansion selectively choose references expand
current relevant set, new references included every expansion step.
adaptive hyper-edge expansion, set upper-bound hmax number new
references h-expansion particular level generate. Formally, want
|XH (Reli (Q))| hmax |Reli (Q)|. value hmax may depend depth
small enough rule full h-expansion current relevant set. Then, given hmax ,
strategy choose least ambiguous references XH (Reli (Q)), since provide
informative evidence resolving references Reli (Q). achieve this,
sort h-expanded references increasing order ambiguity select first k
them, k = hmax |Reli (Q)|.
i1

Reladapt
(Q, hmax ) = LeastAmb(k, XH (Reladapt
(Q)))

(13)

setting adaptive attribute expansion similar. positive number amax , exact a-expansion Reli (Q) allowed include amax |Reli (Q)| references. Note selection preference needs flipped ambiguous names
e (Reli (Q)) decreasing
need evidence, expanded first. sort XA
order ambiguity select first k sorted list, k = amax |Reli (Q)|.
could potentially retrieve references ambiguous name, totally ignoring
references name. avoid this, choose top k ambiguous references
Reli (Q) expansion, expand references chosen.

e

Reladapt
(Q, nmax ) = XA
(M ostAmb(k, Reladapt
(Q)))

(14)

Though cannot directly control number new references added, r k reasonable estimate, r average number references per name.
6.2 Ambiguity Estimation
adaptive expansion scheme proposed section crucially dependent estimates name ambiguity. describe one possible scheme worked quite well.
Recall want estimate probability two randomly picked references
value attribute correspond different entities. reference attribute A1 , denoted
639

fiBhattacharya & Getoor

1.
2.

Algorithm Query-time Resolve (R.Name name)
RSet = RelevantFrontier(name)
RC-ER(RSet)

1.
5.
3.
4.
5.
6.
7.
8.
9.
10.
10.
11.

Algorithm FindRelevantRefs(R.Name name)
Initialize RSet {}
Initialize depth 0
Initialize FrontierRefs {}
depth < d*
depth even 0
R = XA (FrontierRefs)
else
R = XH (FrontierRefs)
FrontierRefs = R
Add FrontierRefs RSet
Increment depth
Return RSet
Figure 5: High-level description query-time entity resolution algorithm

R.A1 , naive estimate ambiguity value n attribute is:
Amb(r.A1 ) =

|R.A1 =r.A1 (R)|
,
|R|

|R.A1 =r.A1 (R)| denotes number references value r.A1 A1 . estimate clearly good since number references certain attribute value
always match number different entity labels attribute. much
better additional attribute A2 . Given A2 , ambiguity value A1
estimated
|(R.A2 (R.A1 =r.A1 (R)))|
Amb(r.A1 | r.A2 ) =
,
|R|
|(R.A2 (R.A1 =r.A1 (R)))| number distinct values observed A2 references R.A1 = r.A1 . example, estimate ambiguity last name
counting number different first names observed it. provides better estimate
ambiguity value attribute A1 , A2 correlated A1 .
multiple uncorrelated attributes Ai available references, approach
generalized obtain better ambiguity estimates.
Putting everything together, high-level pseudo code query-time entity resolution
algorithm shown Figure 5. algorithm works two stages first, identifies
relevant set references given entity name query, performs relational
clustering extracted relevant references. relevant references extracted using
recursive process already seen. relevant references depth
obtained expanding relevant references depth i1, expansion dependent
640

fiQuery-time Entity Resolution

whether odd step even step. actual expansion operator used
may either unconstrained adaptive.

7. Empirical Evaluation
experimental evaluation query-time resolution strategies, used realworld synthetically generated datasets. First, describe real datasets
experiments performed move experiments synthetic data.
7.1 Experiments Real Data
real-world data, used two citation datasets different characteristics.
first dataset, arXiv, contains papers high energy physics used KDD Cup
20032 . 58,515 references 9,200 authors, contained 29,555 publications. number author references per publication ranges 1 10 average 1.90.
second dataset Elsevier BioBase database3 publications biology used
recent IBM KDD-Challenge competition. includes publications Immunology
Infectious Diseases years 1998 2001. dataset contains 156,156 publications 831,991 author references. number author references per publication
significantly higher arXiv ranges 1 100 (average 5.3). names
database initials first middle names (if available), unlike arXiv,
initialed complete names. number distinct names BioBase 303,693,
number references name ranging 1 193 (average 2.7). Unlike
arXiv, BioBase includes keywords, topic classification, language, country correspondence
affiliation corresponding author attributes paper, use
attributes resolution addition author names. BioBase diverse terms
attributes, covering 20 languages, 136 countries, 1,282 topic classifications 7,798
keywords.
entity resolution queries arXiv, selected ambiguous names correspond
one author entity. gave us 75 queries, number true entities
selected names varying 2 11 (average 2.4). BioBase, selected
queries top 100 author names highest number references. average
number references 100 names 106, number entities
selected names ranges 1 100 (average 32), thereby providing wide variety entity
resolution settings queries.
7.1.1 Relevant Set Size Vs. Resolution Time
begin exploring growth rate relevant set query expansion depth
two datasets. Figure 6(a) plots size relevant set sample query
name T. Lee arXiv M. Yamashita BioBase. growth rate arXiv
query moderate. number references name T. Lee 7, number
relevant references depth 0, size grows 7,500 depth 7. contrast,
BioBase plots clearly demonstrate exponential growth relevant references
2. http://www.cs.cornell.edu/projects/kddcup/index.html
3. http://help.sciencedirect.com/robo/projects/sdhelp/about biobase.htm

641

fiBhattacharya & Getoor

800

900

BioBase: similar
BioBase: exact
arXive: exact

700

700
time (secs)

# references
(in thousands)

600
500
400
300

600
500
400
300

200

200

100

100

0

0
0

(a)

BioBase
arXiv

800

1

2

3

4

expansion depth

5

6

7

0
(b)

10

20
30
40
50
#references (in thousands)

60

70

Figure 6: (a) Size relevant set increasing expansion depth sample queries
arXiv BioBase (b) Execution time RC-ER increasing number
references

depth name expansion strategies. 84 relevant references depth
0. references expanded using name similarity expansion, 722 relevant
references depth 1, 65,000 depth 3 586,000 depth 5.
restricted similarity measure two names considered similar first
initials match, last names first character differ overall
2 characters. liberal measure would result significantly faster growth.
observe exact expansion, growth slower still 45,000 references
depth 3, 384,000 depth 5 783,000 depth 7. interesting note growth
slows beyond depth 5; references entire dataset
already covered depth (BioBase 831,991 references total). growth
rates two examples arXiv BioBase typical queries
two datasets.
Next, Figure 6(b), observe relational clustering algorithm RC-ER scales
increasing number references relevant set. execution times reported
Dell Precision 870 server 3.2GHz Intel Xeon processor 3GB memory.
plot shows algorithm scales well increasing references, gradient
different two datasets. mainly due difference average number
references per hyper-edge. suggests arXiv, RC-ER capable handling
relevant sets generated using unconstrained expansion. BioBase, would require
600 secs 40,000 references, 900 secs 65,000. clearly
possible use RC-ER unconstrained expansion query-time resolution BioBase
even depth 3.
7.1.2 Entity Resolution Accuracy Queries
next experiment, evaluate several algorithms entity resolution queries.
compare entity resolution accuracy pair-wise co-reference decisions using F1
measure (which harmonic mean precision recall). fair comparison,
consider best F1 algorithms possible thresholds determining
642

fiQuery-time Entity Resolution

Table 1: Average entity resolution accuracy (F1) different algorithms 75 arXiv
queries 100 BioBase queries


A*
NR
NR*
RC-ER Depth-1
RC-ER Depth-3

arXiv
0.721
0.778
0.956
0.952
0.964
0.970

BioBase
0.701
0.687
0.710
0.753
0.813
0.820

duplicates. algorithms, compare attribute-based entity resolution (A), naive
relational entity resolution (NR) uses attributes related references, relational
clustering algorithm collective entity resolution (RC-ER) using unconstrained expansion
depth 3. consider transitive closures pair-wise decisions first
two approaches (A* NR*). attribute similarity, use Soft TF-IDF
Jaro-Winkler similarity names, shown perform best namebased resolution (Bilenko, Mooney, Cohen, Ravikumar, & Fienberg, 2003), TF-IDF
similarity textual attributes.
average F1 scores queries shown Table 1 algorithm
two datasets. shows RC-ER improves accuracy significantly baselines.
example BioBase, improvement 21% NR, 25% A* 13%
NR*. demonstrates potential benefits collective resolution answering
queries, validates recent results context offline entity resolution (Bhattacharya
& Getoor, 2004, 2007; Singla & Domingos, 2004; Dong et al., 2005; McCallum & Wellner,
2004). earlier work (Bhattacharya & Getoor, 2007) demonstrated using
extensive experiments real synthetic datasets relational clustering algorithm
(RC-ER) improves entity resolution performance traditional baselines context
offline data cleaning, entire database cleaned whole. numbers
Table 1 confirm similar improvements obtained localized resolution
well. predicted analysis, accuracy improvement comes
depth-1 relevant references. 56 100 BioBase queries, accuracy
improve beyond depth-1 relevant references. remaining 44 queries, average
improvement 2%. However, 8 ambiguous queries, accuracy improves
5%, biggest improvement high 27% (from 0.67 0.85 F1).
instances fewer arXiv, biggest improvement 37.5% (from 0.727 1.0).
one hand, shows considering related records resolving collectively
leads significant improvement accuracy. hand, demonstrates
potential benefits considering higher order neighbors, fall quickly
beyond depth 1. serves validate analysis collective query resolution
Section 4.
643

fiBhattacharya & Getoor

Table 2: Average query processing time unconstrained expansion


A*
NR
NR*
RC-ER Depth-1
RC-ER Depth-3

1

arXiv
0.41
0.41
0.43
0.428
0.45
1.36

BioBase
9.35
9.59
28.54
28.69
11.88
606.98

1

depth 1
depth 2

depth 1
depth 2

0.9

0.7
recall

precision

0.8
0.9

0.6
0.5

0.8

0.4
0.3
0.7

0.2
1

0.8

0.6

0.4

0.2

0

1

0.8

similarity threshold

(a)

0.6
0.4
similarity threshold

0.2

0

(b)
1

1

0.9
0.8
recall

precision

0.9

0.8

0.7
0.6
0.5

0.7

0.4

depth 1
depth 2

0.6
1

0.8

depth 1
depth 2

0.3
0.6

0.4

0.2

0

1

similarity threshold

(c)

0.8

0.6
0.4
similarity threshold

0.2

0

(d)

Figure 7: Average precision recall different similarity thresholds (a-b) BioBase
(c-d) arXiv

last two rows Table 1 show converging nature entity resolution performance
increasing depth. verify explicitly precision recall Figure 7.
top two plots show average precision recall BioBase queries different similarity
thresholds RC-ER. bottom two plots show arXiv. see
precision curve depth 1 coincides stays marginally precision curve
depth 3 BioBase arXiv. recall curves show opposite trend recall
644

fiQuery-time Entity Resolution

marginally improves depth 3. agreement derived expressions
precision recall increasing depth Eq. (12). difference recall depths
2.
1 3 quantified aI (1 aI )2 rI2 , difference precision aA (1 aA )2 rA
explanation small difference average precision recall two
plots factors, averaged queries, significantly smaller
1 arXiv BioBase. investigate converging nature performance
detail varying structural properties experiments synthetic data
Section 7.2.
7.1.3 Reducing Time Adaptive Expansion
first set experiments show effectiveness two-phase query processing strategy
terms entity resolution performance. challenge, described earlier,
obtaining benefits real-time. So, next, focus time required
process queries two datasets using unconstrained expansion depth 3.
results shown Table 2. arXiv, average processing time depth-3 expansion
1.36 secs, 406 relevant references average. shows two-phase strategy
unconstrained expansion practical processing strategy entity resolution queries
resolves query entities accurately, extremely quickly well. However,
BioBase, average number references reached depth 3 44,000,
time taken resolve collectively 10 minutes. unacceptable
answering queries, next focus processing time improved using
proposed adaptive strategies. Note time taken depth-1 expansion around 12
secs, close attribute-based baseline (A) less time
naive relational algorithm (NR).
Since unconstrained expansion effective arXiv, focus BioBase evaluating adaptive strategies. estimating ambiguity references, use last names
first initial secondary attribute. results good estimates ambiguity ambiguity estimate name strongly correlated (correlation coeff. 0.8)
number entities name. First, evaluate adaptive H-expansion. Since
H-expansion occurs first depth 1, query, construct relevant set cutoff
depth = 1, use adaptive H-expansion depth 1. expansion upper-bound hmax
set 4. compare three different adaptive H-expansion strategies: (a) choosing
least ambiguous references, (b) choosing ambiguous references (c) random
selection. Then, query, evaluate entity resolution accuracy using RC-ER
relevant sets constructed using three adaptive strategies. average accuracies
three strategies 100 queries shown first column Table 3. Least
ambiguous selection, strategy propose, clearly shows biggest improvement ambiguous smallest, random selection between. Notably,
even without many depth-1 references, improve accuracy NR*
virtue collective resolution.
perform similar set experiments evaluating adaptive attribute expansion.
Recall depth 2 lowest depth adaptive attribute expansion performed.
query, construct relevant set = 3 using adaptive A-expansion
depth 1 unconstrained H-expansion depths 1 3. expansion upper-bound
645

fiBhattacharya & Getoor

Table 3: Avg. resolution accuracy F1 different adaptive expansion strategies

Least Ambiguous
Ambiguous
Random

H-expansion
0.790
0.761
0.770

A-expansion
0.815
0.821
0.820

amax set 0.2, average 1 5 names expanded. Again, compare three
strategies: (a) expanding least ambiguous names, (b) expanding ambiguous
names (c) random expansion. average accuracies three schemes
100 queries listed second column Table 3. experiment adaptive Aexpansion bring difference three schemes clearly adaptive
H-expansion. comparing A-expansion depth 2 and, average,
much improvement obtained beyond depth 1 ceiling effect.
shows almost benefit depth 3 comes proposed strategy
expanding ambiguous names.
two experiments demonstrate effectiveness two adaptive expansion
schemes isolation. Now, look results use together.
100 queries, construct relevant set Rel(rq ) = 3 using adaptive Hexpansion adaptive exact A-expansion. Since improvement collective
resolution comes depth-1 references, consider two different experiments.
first experiment (AX-2), use adaptive expansion depths 2 beyond,
unconstrained H-expansion depth 1. second experiment (AX-1), use adaptive
H-expansion even depth 1, hmax = 6. them, use adaptive expansion
higher depths 2 3 parameters hmax = 3 3 amax = 0.2 2.
Table 4: Comparison unconstrained adaptive expansion BioBase

relevant-set size
time (cpu secs)
accuracy (F1)

Unconstrained
44,129.5
606.98
0.821

AX-2
5,510.52
43.44
0.818

AX-1
3,743.52
31.28
0.820

Table 4, compare two adaptive schemes unconstrained expansion
= 3 queries. Clearly, accuracy remains almost unaffected schemes.
First, note AX-2 matches accuracy unconstrained expansion, shows
almost improvement depth 1. accuracy achieved even though
uses adaptive expansion expands small fraction Rel1 (Q), thereby reduces
average size relevant set 44,000 5,500. significantly, AX-1 matches
improvement even without including many depth-1 references. reduction
size relevant set immense impact query processing time. average
processing time drops 600 secs unconstrained expansion 43 secs


646

fi1.1
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2

1

pR=0.2
pR=0.5
pR=1.0

0.9
0.8
Precision

Recall

Query-time Entity Resolution

0.7
0.6
0.5

pRa=0.0
pRa=0.3
pRa=0.6

0.4
0.3
0.7

0.6
0.5
Sim. Threshold

0.4

0.7

0.65

0.6
0.55
0.5
Sim. Threshold

0.45

Figure 8: Effect (a) identifying relations recall (b) ambiguous relations precision collective clustering. Error bars show standard deviation.

AX-2, 31 secs AX-1, thus making possible use collective entity
resolution query-time resolution.
7.1.4 Adaptive Depth Selection
improvement, investigate processing time reduced setting
expansion depth adaptively, depending ambiguity query name, compared
fixed queries. simple setup, set 1 queries number
different first initials last name less 10 (out 26), explore depth 2
ambiguous queries. reduces expansion depth 2 1 18 100
queries. result, average processing time queries reduced 35% 11.5
secs 17.7 secs reduction accuracy. three queries, original
processing time depth 2 greater 30 secs. preliminary experiments,
evaluated original set 100 queries inherently ambiguous. general
setting, bigger fraction queries lower ambiguity, impact expected
even significant.
7.2 Experiments using Synthetic Data
addition experiments real datasets, performed experiments synthetically
generated data. enables us reason beyond specific datasets, empirically
verify performance analysis relational clustering general, specifically
entity resolution queries. designed generator synthetic data (Bhattacharya
& Getoor, 2007) allows us control different properties underlying entities
relations them, observed co-occurrence relationships
entity references. Among properties, control number entities,
average number neighbor entities per entity, number average size
observed co-occurrences. Additionally, control ambiguity entity attributes,
number ambiguous relationships entities. present overview
synthetic data generation process Appendix A.
647

fiBhattacharya & Getoor

1

0.9
0.85
Precision

0.8
Recall

0.95

t=0.9
t=0.6
t=0.5

0.9
0.7
0.6
0.5

0.8
0.75
0.7

0.4

0.65

0.3

0.6

0.2

t=0.9
t=0.6
t=0.5

0.55
0

1
2
Expansion Level

3

0

1
2
Expansion Level

3

Figure 9: Change (a) precision (b) recall increasing expansion levels used
collective clustering. Error bars show standard deviation.

performed number different experiments synthetic data. first set
experiments, investigate influence identifying relationships collective resolution using relational clustering. generate 500 co-occurrence relations
100 entities 200 entity-entity relationships, using varying probability co-occurrences
pR = {0.2, 0.5, 1.0} data. probability ambiguous relationships held fixed,
higher pR translates higher probability identifying co-occurrences data.
Figure 8(a) shows recall different similarity thresholds three different co-occurrence
probabilities. results confirm recall increases progressively identifying
relationships thresholds. curves pR = 0.5 pR = 1.0 flatten
recall achievable.
Next, observe effect ambiguous relations precision collective resolution using relational clustering. add 200 binary relationships 100 entities
three stages increasing ambiguous relationship probability (pR
= {0, 0.3, 0.6}).
perform collective resolution 500 co-occurrence relations generated
three settings. Figure 8(b) plot precision different similarity threshold three different values pR
. plots confirm progressive decrease precision thresholds
higher pR
.

experiments, results averaged 200 different runs.

Next, evaluate collective resolution queries. Recall last two rows Table 1 clearly demonstrate converging nature performance increasing expansion
levels queries real datasets. ran experiments synthetic data verify
trend. run, generated 2,500 co-occurrence relations 500 entities
average 2 neighbors per entity. performed localized collective clustering
case, using query ambiguous attribute value (that corresponds
highest number underlying entities). Figure 9(c) (d), show recall precision change increasing expansion level query. Recall improves increasing
expansion level, precision decreases overall, predicted analysis. Importantly, recall increases significantly faster rate decrease precision.
general, rate increase/decrease depends structural properties data,
shown analysis. experiments, seen different rates
648

fiQuery-time Entity Resolution

change, overall trend remains same. analysis showed precision
recall converge quickly increasing expansion levels. confirmed
two plots curves flatten level 3.
7.3 Current Limitations
Finally, discuss two current limitations collective entity resolution approach.
Recall similarity measure Eqn. 1 involves weighting parameter combining
attribute relational similarity. experiments, report best accuracy
values query. Selecting optimal value query
unresolved issue. However, experiments reveal even fixed ( = 0.5)
queries brings significant improvements baselines.
second issue determination termination threshold RC-ER. Note
issue baselines well, report best accuracy
thresholds. area ongoing research. Preliminary experiments shown
best threshold often query specific setting threshold depending
ambiguity query results significantly better accuracy fixed threshold
queries. empirical evaluation, cleaned entire arXiv dataset offline running
RC-ER references together, terminated threshold maximizes
resolution accuracy references. results overall accuracy (F1) 0.98.
However, average accuracy measured 75 queries test set 0.87.
comparison, best obtainable accuracy resolving queries individually
different threshold 0.97. suggests may potential benefits localized
cleaning global counterpart offline setting.

8. Related Work
entity resolution problem studied many different areas different
names deduplication, record linkage, co-reference resolution, reference reconciliation,
object consolidation, etc. Much work focused traditional attribute-based
entity resolution. Extensive research done defining approximate string similarity
measures (Monge & Elkan, 1996; Navarro, 2001; Bilenko et al., 2003; Chaudhuri, Ganjam,
Ganti, & Motwani, 2003) may used unsupervised entity resolution.
approach uses adaptive supervised algorithms learn similarity measures labeled
data (Tejada, Knoblock, & Minton, 2001; Bilenko & Mooney, 2003).
Resolving entities optimally known computationally hard even attributes considered (Cohen, Kautz, & McAllester, 2000). Therefore, efficiency
received lot attention attribute-based data cleaning. goal essentially avoid
irrelevant expensive attribute similarity computations using blocking approach without affecting accuracy significantly (Hernandez & Stolfo, 1995; Monge & Elkan, 1997; McCallum et al., 2000). merge/purge problem posed Hernandez Stolfo (1995)
efficient schemes retrieve potential duplicates without resorting quadratic complexity. use sorted neighborhood method appropriate key chosen
matching. Records sorted grouped according key potential matches
identified using sliding window technique. However, keys may badly distorted
matches cannot spanned window cases retrieved.
649

fiBhattacharya & Getoor

solution propose multi-pass method different keys merging
results using transitive closure. Monge Elkan (1997) combine union find algorithm
priority queue look-up find connected components undirected graph. McCallum et al. (2000) propose use canopies first partition data overlapping
clusters using cheap distance metric use accurate expensive distance
metric data pairs lie within canopy. Chaudhuri et al. (2003) use
error tolerant index data warehousing applications probabilistically looking
small set candidate reference tuples matching incoming tuple.
considered probabilistically safe since closest tuples database retrieved
high probability. efficient since small number matches needs
performed. Swoosh (Benjelloun, Garcia-Molina, Su, & Widom, 2005) recently
proposed generic entity resolution framework considers resolving merging
duplicates database operator goal minimize number record-level
feature-level operations. alternative approach reduce complexity individual similarity computations. Gravano, Ipeirotis, Koudas, Srivastava (2003) propose
sampling approach quickly compute cosine similarity tuples fast text-joins
within SQL framework. approaches enable efficient data cleaning
attributes references considered.
Many recently proposed approaches take relations account data integration
(Ananthakrishna et al., 2002; Bhattacharya & Getoor, 2004, 2005; Kalashnikov et al., 2005;
Dong et al., 2005). Ananthakrishna et al. (2002) introduce relational deduplication data
warehouse applications dimensional hierarchy relations. Kalashnikov et al. (2005) enhance attribute similarity ambiguous reference
many entity choices relationship analysis entities, affiliation
co-authorship. earlier work, proposed different measures relational similarity relational clustering algorithm collective entity resolution using relationships
(Bhattacharya & Getoor, 2004, 2007). Dong et al. (2005) collectively resolve entities multiple types propagating relational evidences dependency graph, demonstrate
benefits collective resolution real datasets. Long, Zhang, Wu, Yu (2006) proposed model general multi-type relational clustering, though applied
specifically entity resolution. perform collective factorization related matrices
using spectral methods identify cluster space minimizes distortion relationships individual features time. approaches make use
relationships either entity matching (where domain entities known) entity
resolution (where underlying entities need discovered) shown
increase performance significantly attribute-based solutions problems.
However, price pay terms computational complexity increases due
couple different reasons. Firstly, number potential matches increases
relationships considered individual similarity computations become expensive. Secondly, collective resolution using relationships necessitates iterative solutions
make multiple passes data. approaches still
shown scalable practice, cannot employed query-time cleaning
straight-forward manner.
idea multi-relational clustering comes Inductive Logic Programming
(ILP) literature. Emde Wettschereck (1996) used multi-relational similarity
650

fiQuery-time Entity Resolution

instance-based classification representations first order logic. define similarity
two objects, e.g., two people, combination similarity attribute
values, age, weight, etc., similarity objects
related to, companies work for. similar naive relational
similarity discussed earlier, except similarity connected objects
defined recursively terms connected objects. Kirsten Wrobel (1998)
used recursive relational similarity measure agglomerative clustering first
order representations. recursive comparison neighbors shown effective
terms accuracy results, computational challenge major drawback.
Probabilistic approaches cast entity resolution classification problem
extensively studied. groundwork done Fellegi Sunter (1969). Others (Winkler, 2002; Ravikumar & Cohen, 2004) recently built upon work. Adaptive
machine learning approaches proposed data integration (Sarawagi & Bhamidipaty, 2002; Tejada et al., 2001), active learning requires user label informative
examples. Probabilistic models use relationships collective entity resolution
applied named entity recognition citation matching (Pasula et al., 2003; McCallum & Wellner, 2004; Li et al., 2005; Singla & Domingos, 2004). probabilistic
approaches superior similarity-based clustering algorithms associate
degree confidence every decision, learned models provide valuable insight
domain. However, probabilistic inference collective entity resolution known
scalable practice, particularly relationships considered. approaches mostly shown work small datasets, significantly slower
clustering counterparts.
Little work done literature query-centric cleaning relational approaches answering queries, execution time important accuracy resolution. Approaches proposed localized evaluation Bayesian networks (Draper
& Hanks, 1994), clustering problems. Recently, Chandel, Nagesh, Sarawagi
(2006) addressed efficiency issues computing top-k entity matches dictionary context entity extraction unstructured documents. process top-k
searches batches speed-up achieved sharing computation different
searches. Fuxman, Fazli, Miller (2005) motivate problem answering queries
databases violate integrity constraints address scalability issues resolving inconsistencies dynamically query-time. However, relational aspect problem,
major scalability issue address, come settings. earlier work relational clustering(Bhattacharya & Getoor, 2007), used
idea relevant references experimental evaluation BioBase dataset.
discussed here, dataset entity labels 100 frequent
names. Therefore, instead running collective resolution entire BioBase dataset,
evaluated 100 names separately, using relevant references case.
relevant references ones directly connected references names
interest. concept focused cleaning, performance analysis relational clustering, expand-resolve strategy and, importantly, idea adaptive expansion
query-time resolution addressed paper.
One first papers make use relational features classification problem
Chakrabarti, Dom, Indyk (1998). showed problem classifying
651

fiBhattacharya & Getoor

hyper-linked documents, naive use relationships hurt performance. Specifically,
key terms neighboring documents thrown document whose topic
classified, classification accuracy degrades instead improving. parallel scenario
clustering using relationships naive relational model (NR) may perform worse
attribute model (A) presence highly ambiguous relationships. Chakrabarti
et al. (1998) showed relationships however used improved classification
topic labels neighboring documents used evidence instead naively
considering terms contain. earlier work (Bhattacharya & Getoor, 2004,
2007), shown similar results collective clustering using relationships,
cluster labels neighboring labels lead improved clustering performance compared
naive relational attribute-based clustering. interesting result shown
paper theory empirically even collective use relationships
hurt clustering accuracy compared attribute-based clustering. happens
relationships references dense ambiguous, errors propagate
relationships exceed identifying evidence provide.

9. Conclusions
paper, motivated problem query-time entity resolution accessing
unresolved third-party databases. answering entity resolution queries, addressed challenges using collective approaches, recently shown significant
performance improvements traditional baselines offline setting. first hurdle
collective resolution arises interdependent nature resolution decisions.
first formally analyzed recursive nature dependency, showed precision recall individual entities grow geometric progression increasing levels
neighbors considered collectively resolved. proposed two-stage expand
resolve strategy answering queries based analysis, using two novel expansion
operators. showed using analysis sufficient consider neighbors small
expansion depths, since resolution accuracy query converges quickly increasing
expansion level. second challenge answering queries computation
quick. achieve this, improved unconstrained expansion strategy propose
adaptive algorithm, dramatically reduces size relevant references
and, result, processing time identifying informative references
query. demonstrated using experiments two real datasets strategies
enable collective resolution query-time, without compromising accuracy. additionally performed various experiments synthetically generated data wide range
settings verify trends predicted analysis. summary, addressed
motivated critical data integration retrieval problem, proposed algorithms
solving accurately efficiently, provided theoretical analysis validate approach
explain works, and, finally, shown experimental results multiple real-world
synthetically generated datasets demonstrate works extremely well practice. presented results bibliographic data, techniques applicable
relational domains.
shown dramatic reduction query processing time comes
adaptive expansion, research necessary able answer entity resolution queries
652

fiQuery-time Entity Resolution

order milli-seconds, may demanded many scenarios. Interesting directions
future research include exploring stronger coupling extraction resolution
phases query processing, expansion happens on-demand
resolution process finds residual ambiguity high requires additional evidence
taking decisions. would directly address problem determining
expansion depth. reported preliminary experiments paper,
work needs done adaptive depth determination depending ambiguity.
context, may imagine soft thresholds adaptive expansion, expansion
operator automatically determines number hyper-edges names expanded
residual ambiguity falls specified level. interesting extensions
include caching intermediate resolutions, related resolutions performed
query stored retrieved required answering future queries.

Acknowledgments
wish thank anonymous reviewers constructive suggestions greatly
improved paper. work supported National Science Foundation, NSF
#0423845 NSF #0438866, additional support ITIC KDD program.

Appendix
Synthetic Data Generator
designed synthetic data generator allows us control different structural
attribute-based characteristics data(Bhattacharya & Getoor, 2007).
present overview generation algorithm.
generation process two stages. first stage, create collaboration
graph among underlying entities entity attributes. second, generate
observed co-occurrence relations collaboration graph. high level description
generative process shown Figure 10. Next, describe two stages
generation process greater detail.
graph creation stage, turn, two sub-stages. First, create domain
entities attributes add relationships them. creating entities,
control number entities ambiguity attributes. create N entities
attributes one another. simplicity without losing generality,
entity e single floating point attribute e.x, instead character string. parameter
pa controls ambiguity entity attributes; probability pa attribute new
entity chosen values already use existing entities. binary
relationships added created entities. attributes,
parameter controlling ambiguity relationships, defined Section 4.
binary relationship (ei , ej ), first ei chosen randomly ej sampled (ei , ej )
ambiguous relationship probability pR
a.
describing process generating co-occurrence relationships graph,
let us consider little detail issue attribute ambiguity. finally needs
controlled ambiguity reference attributes. depend
entity attributes, completely determined entities. Taking example
653

fiBhattacharya & Getoor

1.
2.
3.
4.
5.
6.
7.

Creation Stage
Repeat N times
Create random attribute x ambiguity pa
Create entity e attribute x
Repeat times
Choose entity ei randomly
Choose entity ej prob pR
ambiguous relationship (ei , ej )
Set ei = N br(ej ) ej = N br(ei )

8.
9.
10.
11.
12.
13.
14.
15.
16.

Generation Stage
Repeat R times
Randomly choose entity e
Generate reference r using N (e.x, 1)
Initialize hyper-edge h = hri
Repeat probability pc
Randomly choose ej N br(e) without replacement
Generate reference rj using N (ej .x, 1)
Add rj hyper-edge h
Output hyper-edge h

Figure 10: High-level description synthetic data generation algorithm

names, two people names John Michael Smyth James Daniel Smith
still ambiguous terms observed names data depending
generation process observed names. words, attribute ambiguity references
depends separation entity attributes dispersion created
generation process. make assumption entity e attribute e.x,
references generated Gaussian distribution mean x variance 1.0. So,
high probability, reference attribute generated e.x range
[e.x 3, e.x + 3]. range attribute domain considered occupied
entity e. entity ambiguous attribute occupied range intersects
another entity.
come generation co-occurrence relationships entity collaboration graph. stage, R co-occurrence relationships hyper-edges generated,
references. hyper-edge hri , ri1 , . . . , rik i, two aspects need controlled many references references included hyper-edge.
done follows. First, sample entity ei serves initiator entity
hyper-edge. entities eij hyper-edge repeatedly sampled (without replacement) neighbors initiator entity ei . size hyper-edge
determined using parameter pc . sampling step hyper-edge terminated
probability pc selection eij . process terminated neighbors
initiator entity exhausted. Finally, references rij need generated
selected entities eij . done entity e sampling Gaussian
distribution N (e.x, 1).
654

fiQuery-time Entity Resolution

References
Ananthakrishna, R., Chaudhuri, S., & Ganti, V. (2002). Eliminating fuzzy duplicates
data warehouses. International Conference Large Databases (VLDB),
Hong Kong, China.
Benjelloun, O., Garcia-Molina, H., Su, Q., & Widom, J. (2005). Swoosh: generic approach
entity resolution. Tech. rep., Stanford University.
Bhattacharya, I., & Getoor, L. (2004). Iterative record linkage cleaning integration. SIGMOD Workshop Research Issues Data Mining Knowledge
Discovery (DMKD), Paris, France.
Bhattacharya, I., & Getoor, L. (2005). Relational clustering multi-type entity resolution. ACM SIGKDD Workshop Multi Relational Data Mining (MRDM),
Chicago, IL, USA.
Bhattacharya, I., & Getoor, L. (2006). Mining Graph Data (L. Holder D. Cook, eds.),
chap. Entity Resolution Graphs. Wiley.
Bhattacharya, I., & Getoor, L. (2007). Collective entity resolution relational data. ACM
Transactions Knowledge Discovery Data (TKDD), 1 (1).
Bhattacharya, I., Licamele, L., & Getoor, L. (2006). Query-time entity resolution.
ACM International Conference Knowledge Discovery Data Mining (SIGKDD),
Philadelphia, PA, USA.
Bilenko, M., & Mooney, R. (2003). Adaptive duplicate detection using learnable string
similarity measures. ACM International Conference Knowledge Discovery
Data Mining (SIGKDD), Washington DC, USA.
Bilenko, M., Mooney, R., Cohen, W., Ravikumar, P., & Fienberg, S. (2003). Adaptive name
matching information integration.. IEEE Intelligent Systems, 18 (5), 1623.
Chakrabarti, S., Dom, B., & Indyk, P. (1998). Enhanced hypertext categorization using
hyperlinks. Proceedings ACM International Conference Management
Data (SIGMOD).
Chandel, A., Nagesh, P. C., & Sarawagi, S. (2006). Efficient batch top-k search
dictionary-based entity recognition. IEEE International Conference Data
Engineering (ICDE), Washington, DC, USA.
Chaudhuri, S., Ganjam, K., Ganti, V., & Motwani, R. (2003). Robust efficient fuzzy
match online data cleaning. ACM International Conference Management
Data (SIGMOD), San Diego, CA, USA.
Cohen, W., Kautz, H., & McAllester, D. (2000). Hardening soft information sources.
ACM International Conference Knowledge Discovery Data Mining (SIGKDD),
Boston, MA, USA.
Dong, X., Halevy, A., & Madhavan, J. (2005). Reference reconciliation complex information spaces. ACM International Conference Management Data
(SIGMOD), Baltimore, MD, USA.
655

fiBhattacharya & Getoor

Draper, D., & Hanks, S. (1994). Localized partial evaluation belief networks.
Annual Conference Uncertainty Artificial Intelligence (UAI), Seattle, WA, USA.
Emde, W., & Wettschereck, D. (1996). Relational instance based learning. Proceedings
International Conference Machine Learning (ICML).
Fellegi, I., & Sunter, A. (1969). theory record linkage. Journal American
Statistical Association, 64, 11831210.
Fuxman, A., Fazli, E., & Miller, R. (2005). Conquer: Efficient management inconsistent
databases. ACM International Conference Management Data (SIGMOD), Baltimore, MD, USA.
Gravano, L., Ipeirotis, P., Koudas, N., & Srivastava, D. (2003). Text joins data cleansing integration rdbms. IEEE International Conference Data
Engineering (ICDE), Bangalore, India.
Hernandez, M., & Stolfo, S. (1995). merge/purge problem large databases.
ACM International Conference Management Data (SIGMOD), San Jose, CA,
USA.
Kalashnikov, D., Mehrotra, S., & Chen, Z. (2005). Exploiting relationships domainindependent data cleaning. SIAM International Conference Data Mining (SIAM
SDM), Newport Beach, CA, USA.
Kirsten, M., & Wrobel, S. (1998). Relational distance-based clustering. Proceedings
International Workshop Inductive Logic Programming (ILP).
Li, X., Morie, P., & Roth, D. (2005). Semantic integration text: ambiguous names
identifiable entities. AI Magazine. Special Issue Semantic Integration, 26 (1).
Long, B., Zhang, Z. M., Wu, X., & Yu, P. S. (2006). Spectral clustering multi-type relational data. Proceedings 23rd International Conference Machine Learning
(ICML).
McCallum, A., Nigam, K., & Ungar, L. (2000). Efficient clustering high-dimensional data
sets application reference matching. ACM International Conference
Knowledge Discovery Data Mining (SIGKDD), Boston, MA, USA.
McCallum, A., & Wellner, B. (2004). Conditional models identity uncertainty application noun coreference. Advances Neural Information Processing Systems
(NIPS), Vancouver, BC, Canada.
Monge, A., & Elkan, C. (1996). field matching problem: Algorithms applications.
ACM International Conference Knowledge Discovery Data Mining
(SIGKDD), Portland, OR, USA.
Monge, A., & Elkan, C. (1997). efficient domain-independent algorithm detecting
approximately duplicate database records. SIGMOD Workshop Research
Issues Data Mining Knowledge Discovery (DMKD), Tuscon, AZ, USA.
Navarro, G. (2001). guided tour approximate string matching. ACM Computing
Surveys, 33 (1), 3188.
656

fiQuery-time Entity Resolution

Pasula, H., Marthi, B., Milch, B., Russell, S., & Shpitser, I. (2003). Identity uncertainty
citation matching. Advances Neural Information Processing Systems (NIPS),
Vancouver, BC, Canada.
Ravikumar, P., & Cohen, W. (2004). hierarchical graphical model record linkage.
Conference Uncertainty Artificial Intelligence (UAI), Banff, Alberta,
Canada.
Sarawagi, S., & Bhamidipaty, A. (2002). Interactive deduplication using active learning.
Proceedings Eighth ACM International Conference Knowledge Discovery
Data Mining (SIGKDD), Edmonton, Alberta, Canada.
Singla, P., & Domingos, P. (2004). Multi-relational record linkage. SIGKDD Workshop Multi-Relational Data Mining (MRDM), Seattle, WA, USA.
Tejada, S., Knoblock, C., & Minton, S. (2001). Learning object identification rules
information integration. Information Systems Journal, 26 (8), 635656.
Winkler, W. (2002). Methods record linkage Bayesian networks. Tech. rep., Statistical Research Division, U.S. Census Bureau, Washington, DC.

657


