Journal Artificial Intelligence Research 7 (1997) 47-66

Submitted 10/96; published 9/97

New Look Easy-Hard-Easy Pattern
Combinatorial Search Diculty
Dorothy L. Mammen

mammen@cs.umass.edu

Tad Hogg

hogg@parc.xerox.com

Department Computer Science
University Massachusetts
Amherst, 01003, U.S.A.
Xerox Palo Alto Research Center
3333 Coyote Hill Road
Palo Alto, CA 94304, U.S.A.

Abstract

easy-hard-easy pattern diculty combinatorial search problems constraints added explained due competition decrease
number solutions increased pruning. test generality explanation
examining one predictions: number solutions held fixed choice
problems, increased pruning lead monotonic decrease search cost.
Instead, find easy-hard-easy pattern median search cost even number
solutions held constant, search methods. generalizes previous observations
pattern shows existing theory explain full range
peak search cost. cases pattern appears due changes size
minimal unsolvable subproblems, rather changing numbers solutions.

1. Introduction

Recently, many authors shown solution cost various kinds combinatorial
search problems follows pattern easy-hard-easy function tightly constrained
problems are. example, pattern appears graph coloring function
average graph connectivity (Cheeseman, Kanefsky, & Taylor, 1991; Hogg & Williams,
1994), propositional satisfiability (SAT) function ratio number clauses
number variables (Cheeseman et al., 1991; Mitchell, Selman, & Levesque, 1992; Crawford
& Auton, 1993; Gent & Walsh, 1994b), constraint satisfaction problems (CSPs)
function number nogoods (Williams & Hogg, 1994) constraint tightness (Smith,
1994; Prosser, 1996).
regularity raises possibility determining, prior search, likely diculty
problems. Unfortunately, yet possible high variance associated observations. compounded fact single problem
viewed belonging variety problem classes, somewhat different transition points. Thus one important direction improvement investigate whether
simple additional parameters reduce variance allow predictions
higher confidence.
One approach question based explanation easy-hard-easy pattern
competition changes number solutions pruning unproductive
c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiMammen & Hogg

search paths function measure degree problems constrained. particular predicts problems many solutions tend easier,
average, fewer given number constraints. Thus, least one
aspect high variance search cost appears due variance number
solutions problems fixed degree constraint. observation motivated
introduction additional parameters describing problem structure based
precise specification number solutions (Hogg, 1996).
paper investigate generality explanation examining problems
number solutions restricted, including cases number specified
exactly either zero one. peak search cost fact arises generally
competition changes number solutions pruning, cases fixed
number solutions show peak. However, find peak continues
appear cases sophisticated search algorithms, fails appear
cases. calls question generality explanation based number
solutions, suggests search additional problem structure parameters based
solely reducing variance number solutions likely sucient
accurately predict search cost. However, structural aspect problems likely
involved. Specifically, present data showing smallest problem's minimal
unsolvable subproblems correlates well search cost.
next section describe classes search problems. review
pattern search behavior current theoretical explanation it. following
section uncover limitations explanation examining problems
specification number solutions. shows easy-hard-easy pattern
general phenomenon suggested current explanations. suggest alternative explanation related problem structure, present data unsolvable problems
showing positive relationship problem structure parameter, minimum
size minimal unsolvable subproblem, search cost. problem structure parameter may explain differences search cost among solvable problems equal numbers
solutions, well. Finally, discuss implications observations
make suggestions obtaining better understanding greater predictability hard
search problems.

2. Classes Search Problems

common many previous studies transition phenomenon, use random binary
CSPs graph coloring example classes search problems. section describes
problems generated searched.

2.1 Random CSPs

constraint satisfaction problems used experimental results consist 10
variables three possible values one, cases, repeated experiments
problems 20 variables. Problem constraints specified number binary
nogoods, i.e., assignments pair variables considered inconsistent.
search problem find consistent complete assignment, i.e., value
variable include inconsistent pairs.
48

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

generated problems number ways fully sample range behaviors.
first method (\generate-select") generate CSPs randomly selecting specified
number binary nogoods. produce classes problems restrictions number
solutions, determine number solutions randomly generated problems
retain satisfying restrictions. example, produce class
solvable problems, solution included. Similarly, produce class
problems fixed number solutions, problems exactly specified
number solutions retained.
random generation method gives simple, uniform selection various problem classes. However, inecient generating problems. instance,
nogoods, randomly generated problems solvable, hence requiring large
number random trials obtain even unsolvable cases.
address problem, used ecient (\hill-climbing") methods. Specifically, generating solvable problems many nogoods, starting randomly generated unsolvable problem, removed constraints random problem became
solvable, restored number constraints removed constraints chosen randomly,
requirement problem become unsolvable again.
generating unsolvable problems nogoods, hill-climbing method started
randomly generated solvable problem, removed constraint constrained
problem least (the one whose removal increased number solutions least),
added randomly chosen constraint resulted problem fewer solutions
problem constraint removal. If, removed one constraint,
constraint could decrease number solutions, constraint increased number
solutions least chosen { slightly backwards step. speed process up,
checked one third possible constraints giving up, choosing one
increased number solutions least, starting another iteration.
methods generating problems specified requirements number
solutions studied. One popular method solvable problems randomly
select assignment variables (a pre-specified solution) then,
random selection nogoods, avoid inconsistent pre-specified solution.
tends emphasize problems many solutions results instances
somewhat easier uniform random selection. Cha & Iwama (1995) used
approach generating problems specific attributes, SAT problems, using AIM
generators (Asahiro, Iwama, & Miyano, 1993).
solved problems using dynamic backtracking (Ginsberg, 1993) cases,
using random variable value ordering. comparison, searches
simple chronological backtrack instead. search cost measured number nodes
explored.

2.2 Graph Coloring

experimented 3-coloring problem. constraint satisfaction problem
consists graph requirement assign node one three colors
pair nodes linked edge color. edge graph defines
binary nogoods problem, namely pairs assignments giving color
49

fiMammen & Hogg

two nodes connected edge. Thus edge graph gives three binary nogoods.
convenient measure number constraints , connectivity average degree
nodes graph. equal twice number edges graph divided
number nodes, edge incident two nodes. 100-node
graphs studied, number binary nogoods given 150 .
case, used simple chronological backtrack search combination
Brelaz heuristic variable value ordering (Johnson, Aragon, McGeoch, & Schevon,
1991). heuristic assigns constrained nodes first (i.e.,
distinctly colored neighbors), breaking ties choosing nodes uncolored
neighbors, remaining ties broken randomly. colors considered
fixed ordering nodes search. simple optimization, search never
changes colors selected first two nodes. changes would amount
unnecessarily repeating search permutation colors unsolvable cases.
Search cost measured number nodes explored.

3. Easy-Hard-Easy Pattern

section, present example search cost varies tightness
constraints class problems, describe behavior understood
terms changes structure problems, independent particular search
algorithms. review summary previous studies transition forms
basis comparison new results presented subsequent sections.

3.1 Example

Figure 1 shows typical example easy-hard-easy pattern function constrainedness problem. Problems many constraints tend easy
solve intermediate number dicult. fraction solvable
problems shown Figure 1, scaled 1.0 left 0.0 right.
illustrates hard problems concentrated so-called \mushy region" (Smith
& Dyer, 1996) probability solution changing 1.0 0.0. particular,
peak search cost near \crossover point," point half problems
solvable half unsolvable. problem class, crossover point occurs
75 binary nogoods, peak dynamic backtracking solution cost occurs
85 binary nogoods.
results paper, include 95% confidence intervals (Snedecor &
Cochran, 1967). intervals estimate p
median obtained samples
given approximately percentiles 50 100= N data, N
number
samples. estimate fractions intervals given approximately
p
fraction. Finally, estimate
f 2 f (1 , f )=N , f estimated value p
means intervals approximately x 1:96= N x estimate mean
standard deviation sample. many cases paper, sucient
samples make intervals smaller size plotted points.
key point examples dicult instances within class
search problems tend concentrated near particular value constraint tightness
(here measured number binary nogoods). behavior seen
50

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Cost
200

150

100

50

20

40

60

80

100

120

140

Nogoods

Figure 1: Typical transition pattern. Median solution cost dynamic backtracking (solid line)

probability solution (dashed line) function number nogoods.
point represents 1000 problems 10 variables domain size 3, solved 100 times.
Error bars showing 95% confidence intervals included, cases smaller
size plotted points.

variety search methods, indicates concentration depend much
details search algorithm. Instead, appears associated change
properties problems themselves, namely solvability.

3.2 Explanation

observations raise number questions, peak search cost exists,
peak occurs near transition mostly solvable mostly unsolvable problems
thus independent particular search algorithm, behavior seen
large variety constraint satisfaction problems.
existing explanation concentration hard problems relies competition
changes number solutions amount pruning provided
problem constraints (Williams & Hogg, 1994). constraints, many solutions search usually easy. constraints added number solutions drops
rapidly, making problems harder. new constraints increase pruning unproductive search choices, tending make search easier. constraints,
decrease number solutions overwhelms increase pruning, giving harder
problems average. Eventually last solution eliminated remains
increased pruning additional constraints, leading easier problems. Thus phase
transition, point precipitous change solvability unsolvability, less coincides peak solution cost. effects become
pronounced larger problems considered, leading sharper peaks abrupt
51

fiMammen & Hogg

transitions. qualitative description explains many features observed behavior.
pruning explanation offered Cheeseman et al. (1991) respect
finding Hamiltonian circuits highly constrained problems.
explanation used obtain quantitative understanding behavior.
instance, location transition region understood approximate
theory predicting cost peak occurs expected number solutions equals
one (Smith & Dyer, 1996; Williams & Hogg, 1994). example
310 possible
,10 2
assignments 10 variables problem. 2 3 = 405 possible binary
nogoods problem, counts number ways select pair variables
different assignments pair. given complete assignment 10 variables
solution provided selected binary nogoods use the,
assignment

pair variables given complete assignment. leaves 102 (32 , 1) = 360
possible choices binary nogoods. Thus expected number solutions given
,360
10

3 ,405


problems randomly selected binary nogoods. expression equals one
= 82:9, location observed cost peak. Furthermore, expected
number solutions grows exponentially number variables smaller
threshold value decreases exponentially zero larger, range
values expected number solutions near one rapidly decreases
variables added. accounts observed sharpening transition larger
problems.
quantitative success relating search cost peak transition phenomena
evaluation scaling behavior transition search cost peak (Kirkpatrick &
Selman, 1994; Gent, MacIntyer, Prosser, & Walsh, 1995).

4. Search Diculty Solvability

section take closer look behavior search cost, specifically,
examining behavior depends whether problem solution and, so,
number solutions.

4.1 Search Behavior

Figure 2 shows median dynamic backtracking solution cost solvable unsolvable
random CSPs generated described above, problems number variables n = 10
n = 20, domain size three. Except specified otherwise figure caption,
problems 10 variables generated 1000 solvable 1000 unsolvable problems
point, problems 20 variables generated 500 solvable 500 unsolvable
problems point, using \generate-select" method. generated unsolvable
problems 10 variables 10 70 nogoods using \hill-climbing" method.
overlap range problems generated two methods show different
generation methods affect search cost.
figure clearly shows easy-hard-easy pattern solution cost solvable
unsolvable problems, problem sizes. two methods generating unsolvable
52

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Cost

3
10

2
10

2

4

6

8

10

12

14

m/n

Figure 2: Median solution cost using dynamic backtracking solvable (solid lines) unsolvable
(dashed dotted lines) problems number variables n = 10 (black lines)
n = 20 (gray lines) function number nogoods divided problem size, m=n.

problems generated using \generate-select" method except unsolvable problems shown dotted line, generated using \hill-climbing"
method. problems size 10, point median 1000 problems solved 100
times, except unsolvable problems generated \generate-select" m=n = 3 (30
nogoods) solvable problems m=n = 14 (140 nogoods), based 100
problems. problems size 20, point median 500 problems solved 100
times, except unsolvable problems m=n = 5 (100 nogoods) solvable problems
m=n = 12 (240 nogoods), based 15 35 problems, respectively. Error
bars showing 95% confidence intervals included, cases smaller
size plotted points.

problems give distinct curves: unsolvable problems generated \hill-climbing"
method harder generated \generate-select" method. Nonetheless,
sets problems show easy-hard-easy pattern.
Another example behavior shown Figure 3 median search
cost instances 3-coloring random graphs. contrast Figure 2, solvable
unsolvable cases similar median search costs near peaks. because,
described above, graph coloring searches unsolvable cases used symmetry
respect permutations colors avoid unnecessary search. Without optimization, costs unsolvable cases would six times greater values shown
figure. Similar peaks seen classes graphs, connected ones, although
somewhat different values .
data show random CSPs graph coloring problems exhibit easyhard-easy pattern solvable unsolvable problems considered separately.
53

fiMammen & Hogg

Cost
250
200
150
100
50
0

1

2

3

4

5

6

7



Figure 3: Median solution cost 3-coloring random graphs 100 nodes function connectivity using backtrack search Brelaz heuristic. solid dashed curves

correspond solvable unsolvable cases respectively. results started
100,000 random graphs value , additional samples generated
extremes produce least 100 samples point. random graphs,
crossover mostly solvable mostly unsolvable occurs around connectivity 4.5.
Error bars showing 95% confidence intervals included.

4.2 Solvable Problems

peak search cost solvable problems observed seen extensively studies local-repair search methods problems generated prespecified solution (Yugami, Ohta, & Hara, 1994; Kask & Dechter, 1995; Williams & Hogg,
1994). search methods start assignment variables
problem attempt adjust solution found. Generally, methods systematic searches: never determine problem solution.
Thus empirical studies methods restricted consider solvable problems
incidentally provide useful examination properties solvable problems.
Furthermore, study satisfiability problems backtracking search consistent
peak cost solvable problems (Mitchell et al., 1992), insucient
highly constrained solvable problems make definite conclusion behavior
many constraints.
existence peak solvable problems fit explanation given
above? Certainly explanation based transition solvable unsolvable problems
cannot apply directly class solvable problems. However, competition
increased pruning decreased number solutions still applies. shown Figure 4,
number solutions solvable random CSPs size 10 first decreases rapidly
constraints added nears minimum value one, giving slower decrease.
54

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Solutions
4
10

1
10
0

20

40

60

80

100

120

140

Nogoods

Figure 4: Mean (solid) median (dashed) number solutions log scale function

number binary nogoods, solvable problems 10 variables, 3 values each, based
1000 problems generated \generate-select" method multiple 10 binary
nogoods, except 140 nogoods, based 100 problems. 0 nogoods
310 = 59049 solutions. Error bars showing 95% confidence intervals included.

Except change minimum value 0 1 solution, behavior number
solutions qualitatively similar general case including solvable
unsolvable problems. additional constraints continue increase pruning
unproductive search paths. Thus explanation given might continue apply
predicts peak point solutions drop (i.e., one
solution) rather becoming unsolvable (i.e., zero solutions).
Figure 5 evaluates idea. figure shows fraction problems
least two solutions changes function number nogoods divided problem
size random CSPs 10 20 variables. problems size 10, second
last solution disappears, average, 90 100 nogoods: median number
solutions dropped 2 90 nogoods, 1 100 nogoods (Figure 4).
peak solution cost solvable problems slightly lower this, 80
90 nogoods, close crossover point Figure 5 half solvable problems
one solution. perhaps close enough consistent explanation given
above. However, relationship hold problems size 20. class
problems, cost peak solvable problems around 180 nogoods (m=n = 9), whereas
point half problems one solution still reached
240 nogoods (m=n = 12). 180 nogoods, median number solutions 4 (mean
10.0), 240 nogoods, median still 2 (mean 1.83). inconsistent
explanation cost peak solvable problems due increasing effect
pruning given possible decrease number solutions.
55

fiMammen & Hogg

Fraction
1
0.8
0.6
0.4
0.2

2

4

6

8

10

12

14

m/n

Figure 5: Fraction problems least two solutions function number nogoods di-

vided problem size, problems size 10 (black line) size 20 (gray line). Data
problems size 10 based 1000 solvable problems created \generate-select"
method point, except 100 solvable problems m=n = 14 (140 nogoods).
Data problems size 20 based 500 solvable problems point, except
20 solvable problems m=n = 12 (240 nogoods), created \generate-select"
method. Error bars showing 95% confidence intervals included.

Since explanation depending change insolubility apply,
pruning versus number solutions explanation fit data, factors
must work produce easy-hard-easy pattern solvable problems. suspect explanation related idea minimal unsolvable subproblems. minimal
unsolvable subproblem subproblem unsolvable, subset variables associated constraints solvable; Gent & Walsh (1996) referred
aspect SAT problems minimal unsatisfiable subset. idea
bad choices made initially, remainder problem becomes
unsolvable, unsolvability much harder determine problems others.
particular, variables involved minimal unsolvable subproblem,
harder determine subproblem unsolvable. make conjecture
cost peak solvable problems tied average size minimal unsolvable subproblem choice made results remaining problem
unsolvable.

4.3 Problems Fixed Number Solutions

interesting case behavior problems solutions shown Figures
2 3. example, Figure 6 shows solution cost problems exactly
one solution. shows peak. observations problems zero one
56

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Cost
160
140
120
100
80
60
40

60

80

100

120

140

Nogoods

Figure 6: Median solution cost function number nogoods problems 10 variables,

3 values each, exactly one solution, generated using \generate-select" method
(solid line), hill-climbing one solution starting solvable problems
many solutions produced using \generate-select" (dotted line), solved using dynamic
backtracking. point median 1000 problems solved 100 times, except
hill-climbing generated problems 25, 30 35 nogoods \generate-select"
generated problems 140 nogoods, 100. Error bars showing 95%
confidence intervals included.

solution show even number solutions held constant, problems exhibit
easy-hard-easy pattern solution cost.
According explanation transition, number solutions held constant
increase pruning factor, giving rise monotonic decrease
search cost constraints added. Instead, see Figures 2, 3 6 even
number solutions held fixed zero one, still peak solution
cost, smaller number nogoods. Thus existing explanation capture
full range behaviors. Instead, appears factors work
producing hard problems. focusing closely factors hope gain
better understanding structure hard problems, may lead precise
predictions search cost.
investigated effect algorithm pattern solution cost unsolvable
problems repeating search random CSPs using chronological backtrack. comparison chronological backtracking search previous dynamic backtrack search
results unsolvable problems shown Figure 7. figure, curves dynamic backtracking unsolvable problems shown Figure 2,
except cost curves shown logarithmic scale. Interestingly,
see peak search cost unsolvable problems using less sophisticated method
chronological backtrack.
57

fiMammen & Hogg

Cost
4
10

3
10

2
10
20

40

60

80

100

120

140

Nogoods

Figure 7: Comparison median solution cost log scale using sets unsolvable

problems chronological backtracking (black) dynamic backtracking (gray). Dotted
lines problems generated using \hill-climbing" method, solid lines
\generate-select" method. point median 1000 problems solved 100
times, except \generate-select" method 30 nogoods, based 100
problems. Error bars showing 95% confidence intervals included, smaller
size plotted points.

observation raises important point: easy-hard-easy pattern universal
feature search algorithms problems restricted fixed number solutions.
suggests competition number solutions pruning, occurs,
suciently powerful affect search algorithms (very simple methods,
generate-and-test, make use pruning show monotonic increase search
cost number solutions decreases), algorithms able
exploit features weakly constrained problems fixed number solutions
make easy.
contrast observations, monotonic decrease cost reported
unsolvable binary random constraint problems (Smith & Dyer, 1996) unsolvable
3SAT problems (Mitchell et al., 1992). case 3SAT, explanation may well
choice algorithm. Indeed, Bayardo & Schrag (1996) recently found incorporating
con ict-directed backjumping learning Tableau algorithm made difference
many orders magnitude problem diculty specifically rare, \exceptionally hard,"
unsatisfiable problems underconstrained region. would interesting see whether
easy-hard-easy pattern unsolvable problems would appear using algorithm.
respect Smith & Dyer's (1996) observations, difference may due
range problems generated, resulting different problem generation methods. Smith
Dyer used method akin \random" generation method, is, generating
58

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

problems without regard solvability, separating unsolvable ones.
method, \hit rate" unsolvable problems underconstrained region low.
possible Smith Dyer's data extend point cost
unsolvable problems begins decrease simply stopped finding unsolvable
problems point.
two possible reasons might found unsolvable problems using
random generation underconstrained region, Smith Dyer
not. One possibility since specifically interested unsolvable problems
far underconstrained region possible, may spent computational
effort generating region. Indeed, 40 nogoods, unsolvable problems occurred
frequency 4:5 10,5 , 30 nogoods, frequency 7:75 10,7 . rate, problems
30 nogoods took six hours apiece generate.
second possibility relates details generation methods. Smith
Dyer's random generation method, every pair variables exactly number
inconsistent value pairs them. implies degree homogeneity
distribution nogoods. hand, random generation method,
variable-value pair equal probability selected nogood, independent
one another. Thus least possible generation method, though still low
likelihood, nogoods occasionally clump, produce unsolvable problem.
idea discussed Section 5.
difference observation Smith & Dyer's (1996) reinforces important
point: relatively subtle difference generation methods affect class
problems generated. nogoods less evenly distributed average
using generation method, clumped probability, whereas
Smith Dyer's generation method, homogeneous distribution variable pairs
guaranteed. types problems could different enough sometimes produce
different behavior.

5. Minimal Unsolvable Subproblems

observations classes problems restrictions number solutions
may shows common identification peak solution cost
algorithm-independent transition solvability seen general problem classes
capture full generality easy-hard-easy pattern.
solvable problems, explanation could readily modified use transition
existence solutions beyond specified construction class
problems symmetries problems might constrain allowable range
solutions. modification simple generalization existing explanation based
competition number solutions pruning. However, data
solvable problems support explanation, search cost peak
disappearance second last solution coincide roughly n = 10,
n = 20.
Furthermore, number solutions held constant, competition increased pruning decreasing number solutions cannot possibly responsible
peak solution cost. decrease search cost highly constrained problems (to
59

fiMammen & Hogg

right peak) adequately explained prevailing explanation, based
increase pruning additional constraints. explain weakly constrained problems found easy, least search methods. low cost
unsolvable problems underconstrained region new unexpected observation
light previous studies easy-hard-easy pattern explanation. raises
question whether different aspect problem structure account
peak search cost problems fixed number solutions.
One possibility often mentioned context notion critically constrained problems. problems boundary solvable unsolvable problems, i.e., neither underconstrained (with many solutions) overconstrained
(with none). notion forms basis another common interpretation cost
peak. is, critically constrained problems typically hard search (because constraints must instantiated unproductive search paths
identified) and, since concentrated transition (Smith & Dyer, 1996),
give rise search peak. explanation include discussion changes
pruning capability constraints added. Taken face value, explanation would
predict peak solvable problems number solutions held constant,
classes transition solvable unsolvable problems. Moreover,
description critically constrained problems simply characteristic individual problem rather partly dependent class problems consideration
exact location transition depends method problems
generated. observation makes dicult characterize degree
individual problem critically constrained purely terms structural characteristics
problem. contrast, measure number solutions well defined
individual problem instances, facilitates using average behavior various classes
problems approximately locate transition region. Thus, currently described,
notion critically constrained problems explain observations
give explicit way characterize individual problems.
precisely defined alternative characteristic size minimal unsolvable subproblems. mentioned Section 4.2, minimal unsolvable subproblem subproblem
unsolvable, subset variables associated constraints
solvable.
problems one minimal unsolvable subproblem. example,
problem might one minimal unsolvable subproblem five variables, another, different one, say, six. computed minimal unsatisfiable subproblems
10-variable unsolvable problems generated. found monotonic positive relationship mean number minimal unsolvable subproblems number nogoods.
example, problems 140 nogoods average 35 minimal unsolvable subproblems
(range 4 64, standard deviation 8.7); 90 nogoods six (range 1
23, standard deviation 3.6); problems 50 fewer nogoods rarely
one minimal unsolvable subproblem. Similarly, Gent & Walsh (1996) observed unsatisfiable problems underconstrained region tend small unique minimal
unsatisfiable subsets.
behavior size smallest minimal unsolvable subproblem function
number nogoods shown Figure 8. Comparing Figure 2, see peak
60

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Size
10
9
8
7
6
5
4
3

20

40

60

80

100

120

Nogoods
140

Figure 8: Mean size smallest minimal unsolvable subproblem function number nogoods, unsolvable problems generated using \hill-climbing" (dotted line)
\generate-select" (solid line) methods. point based 1000 problems, except
\generate-select" method 30 nogoods, based 100 problems. Error bars
showing 95% confidence intervals included.

minimum size minimal unsolvable subproblems matches location search
cost peak unsolvable problems. result independent whether plot smallest
minimal unsolvable subproblem size, shown Figure 8, medians means,
shown here. Moreover, location peaks minimal unsolvable subproblem
size different generation methods correspond location respective
search cost peaks. peak search cost minimal unsolvable subproblem size
occurs around 40 nogoods problems generated using \hill-climbing" method,
significantly higher, around 60 nogoods, problems generated using \generateselect" method. strong correspondence minimal unsolvable subproblem size
search cost suggestive minimal unsolvable subproblem size structural
characteristic problems plays important role search cost. contrast, number
minimal unsolvable subproblems match pattern search cost. mentioned
above, increases monotonically number nogoods, suggesting play
primary role explaining search cost unsolvable problems.
behavior minimal unsolvable subproblem size function number
constraints simple explanation. Unsolvable weakly constrained problems generally need concentrate available constraints variables order
make assignments inconsistent. tend give one small minimal unsolvable
subproblem. constraints added, concentration longer required and,
since problems randomly selected constraints happen concentrated
variables rare, expect larger minimal unsolvable subproblems.
61

fiMammen & Hogg

Cost
350

300

250

200

150

4

6

8

10

Size

Figure 9: Mean solution cost function size smallest minimal unsolvable subproblem,
unsolvable problems 60 nogoods generated using \generate-select" method.
point mean median solution costs, based solving problem 100 times,
set problems corresponding smallest minimal unsolvable subproblem
size. points based following numbers problems smallest minimal
unsolvable subproblem size, totaling 1000 problems: 3 { 1; 4 { 17; 5 { 71; 6 { 156; 7 {
253; 8 { 283; 9 { 165; 10 { 54. Error bars showing 95% confidence intervals included,
except single problem size 3 confidence intervals cannot calculated.

Finally, constraints added, increased pruning equivalent
notion instantiating variables required find inconsistency.
means expect large number small unsolvable subproblems. qualitative
description corresponds observe Figure 8.
observations weakly constrained problems suggest search algorithms,
dynamic backtracking, able rapidly focus one unsolvable subproblems hence avoid extensive thrashing, high search cost, seen methods.
cases, one would expect smaller unsolvable subproblem, easier
search determine solutions.
order examine role minimal unsolvable subproblem search cost
closely, plotted mean search cost versus size smallest minimal unsolvable subproblem
unsolvable problems 10 variables multiple 10 nogoods 30 140
nogoods. every case, mean search cost increased function size smallest minimal
unsolvable subproblem. Figure 9 shows example one plots, peak
solution cost class problems, 60 nogoods. makes sense smallest
minimal unsolvable subproblem, easiest detect, would play significant role
search cost. However, situation surely complicated this, suggested
fact still variation among problems size smallest minimal
62

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

unsolvable subproblem. could due, example, one problem several
small minimal unsolvable subproblems, another might one minimal unsolvable
subproblem, even smaller. Number size minimal unsolvable subproblems
likely play role search cost.
Number minimal unsolvable subproblems seem play significant role
size smallest minimal unsolvable subproblem, effect demonstrated.
sets unsolvable problems above, multiple 10 nogoods
80 140 nogoods, search cost correlates negatively number minimal unsolvable
subproblems. However, unsolvable problems 30 70 nogoods, variance
number minimal unsolvable subproblems lower (but variance search cost higher),
relationship search cost number minimal unsolvable subproblems. Additional clarification role search cost size number minimal
unsolvable subproblems left investigation. size smallest minimal unsolvable subproblem, correlates strongly search cost (1) unsolvable problems
taken whole (see Figures 2 8) (2) unsolvable problems fixed number
nogoods full range number nogoods, appears primary effect.
discussion minimal unsolvable subproblems relevant solvable problems:
series choices precludes solution made search, remaining subproblem unsolvable one. example, 10-variable CSP, suppose values
given first two variables incompatible solutions problem.
means context two assignments, remaining eight variables constitute unsolvable subproblem. number search steps required determine
subproblem fact unsolvable cost added search backtracking
original two variables trying new assignment one them. Thus, cost
identifying unproductive search choices solvable problems determined rapidly
associated unsolvable subproblem searched. described above,
constraints expect unsolvable subproblems small
minimal unsolvable subproblems hence easy search methods able
focus subproblems. unsolvable subproblems associated incorrect
variable choices solvable problems may different structure, argument suggests changes minimal unsolvable subproblems may explain behavior solvable
problems fixed number solutions well. could explain observations
thrashing behavior rare exceptionally hard solvable problems underconstrained
region (Gent & Walsh, 1994a; Hogg & Williams, 1994); would expect problems
relatively large unsolvable subproblem detect given initial variable assignments. Finally, would interesting study behavior local repair search methods
problems single solution see affected change minimal
subproblem size.

6. Conclusions

presented evidence explanation easy-hard-easy pattern solution
cost based competition changes number solutions pruning
insucient explain phenomenon completely sophisticated search methods.
explain overall pattern problems restricted solvability number
63

fiMammen & Hogg

solutions. However, explanation fails number solutions held constant
sophisticated search methods used. cases solution cost peak
disappear would predicted. Alternatively, view explanation adequate
less sophisticated methods able readily focus unsolvable subproblems
encountered search.
considering relatively small search problems, able exhaustively examine
properties search space. allowed us definitively demonstrate importance search behavior aspect problem structure: size minimal unsolvable
subproblems. approach contrasts much work area involves solving
problems large feasible within reasonable time bounds. latter approach
gives better indication asymptotic behavior transition, suitable
exhaustive evaluation nature search spaces encountered, detailed
analysis aspects individual problem structure.
believe detailed examination structure combinatorial problems
yield information certain types problems dicult easy. class, graph
coloring random CSPs NP-complete, yet practice many problems actually
easy. addition, theoretical work area produced predictions
asymptotically correct average, variance among individual problems predicted
class enormous. Increased understanding relationships problem structure,
problem solving algorithm, solution cost important determining whether, so,
how, determine prior problem solving problems easy versus infeasibly
hard. contrast previous theoretical studies focus number solutions,
work suggests size minimal unsolvable subproblems alternate characteristic
study potential producing precise characterization transition
behavior nature hard search problems.

Acknowledgements
Much research carried first author summer intern Xerox
Palo Alto Research Center. research partially supported National
Science Foundation Grant No. IRI-9321324 Victor R. Lesser. opinions,
findings, conclusions recommendations expressed material
authors necessarily ect views National Science Foundation.

References

Asahiro, Y., Iwama, K., & Miyano, E. (1993). Random generation test instances
controlled attributes. Second DIMACS Challenge Workshop.
Bayardo, Jr., R. J., & Schrag, R. (1996). Using CSP look-back techniques solve exceptionally hard SAT instances. Freuder, E. C. (Ed.), Principles Practice
Constraint Programming { CP96, pp. 46{60 Cambridge, MA. Springer.
Cha, B., & Iwama, K. (1995). Performance test local search algorithms using new
types random CNF formulas. Proceedings Fourteenth International Joint
64

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Conference Artificial Intelligence, pp. 304{310 Montreal, Quebec, Canada.

Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.
Proceedings Twelfth International Joint Conference Artificial Intelligence,
pp. 331{337 Sydney, Australia.
Crawford, J. M., & Auton, L. D. (1993). Experimental results cross-over point
satisfiability problems. Proceedings Eleventh National Conference
Artificial Intelligence, pp. 21{27 Washington, DC, USA.
Gent, I. P., MacIntyre, E., Prosser, P., & Walsh, T. (1995). Scaling effects CSP phase
transition. Montanari, U., & Rossi, F. (Eds.), Proc. Principles Practices
Constraint Programming PPCP95, pp. 70{87. Springer-Verlag.
Gent, I. P., & Walsh, T. (1994a). Easy problems sometimes hard. Artificial Intelligence,
70, 335{345.
Gent, I. P., & Walsh, T. (1994b). SAT phase transition. Cohn, A. (Ed.), Proceedings
ECAI-94, pp. 105{109. John Wiley Sons.
Gent, I. P., & Walsh, T. (1996). satisfiability constraint gap. Artificial Intelligence,
81 (1-2), 59{80.
Ginsberg, M. L. (1993). Dynamic backtracking. Journal Artificial Intelligence Research,
1, 25{46.
Hogg, T. (1996). Refining phase transitions combinatorial search. Artificial Intelligence, 81, 127{154.
Hogg, T., & Williams, C. P. (1994). hardest constraint problems: double phase
transition. Artificial Intelligence, 69, 359{377.
Johnson, D. S., Aragon, C. R., McGeoch, L. A., & Schevon, C. (1991). Optimization
simulated annealing: experimental evaluation; part II, Graph coloring number
partitioning. Operations Research, 39 (3), 378{406.
Kask, K., & Dechter, R. (1995). GSAT local consistency. Proceedings Fourteenth International Joint Conference Artificial Intelligence, pp. 616{622 Montreal,
Quebec, Canada.
Kirkpatrick, S., & Selman, B. (1994). Critical behavior satisfiability random
boolean expressions. Science, 264, 1297{1301.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SAT
problems. Proceedings Tenth National Conference Artificial Intelligence,
pp. 459{465 San Jose, CA, USA.
Prosser, P. (1996). empirical study phase transitions binary constraint satisfaction
problems. Artificial Intelligence, 81, 81{109.
65

fiMammen & Hogg

Smith, B. M. (1994). Phase transition mushy region constraint satisfaction
problems. Cohn, A. (Ed.), Proceedings ECAI-94, pp. 100{104. John Wiley
Sons.
Smith, B. M., & Dyer, M. E. (1996). Locating phase transition binary constraint
satisfaction problems. Artificial Intelligence, 81, 155{181.
Snedecor, G. W., & Cochran, W. G. (1967). Statistical Methods (6th edition). Iowa State
Univ. Press, Ames, Iowa.
Williams, C. P., & Hogg, T. (1994). Exploiting deep structure constraint problems.
Artificial Intelligence, 70, 73{117.
Yugami, N., Ohta, Y., & Hara, H. (1994). Improving repair-based constraint satisfaction
methods value propagation. Proceedings Twelfth National Conference
Artificial Intelligence, pp. 344{349 Seattle, WA, USA.

66


