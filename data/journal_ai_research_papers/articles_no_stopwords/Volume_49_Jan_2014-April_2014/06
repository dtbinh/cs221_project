journal artificial intelligence

submitted published

large scale optimization evaluation functions
minimax search
kunihito hoki

hoki cs uec ac jp

department communication engineering informatics
university electro communications

tomoyuki kaneko

kaneko acm org

department graphics computer sciences
university tokyo

abstract
presents method minimax tree optimization mmto learn
heuristic evaluation function practical alpha beta search program evaluation
function may linear non linear combination weighted features weights
parameters optimized control search move decisions agree game records human experts well modeled objective function
minimized designed moreover numerical iterative method used local
minima objective function forty million parameters adjusted
small number hyper parameters method applied shogi major
variant chess evaluation function must handle larger state space
chess experimental large scale optimization evaluation
function improves playing strength shogi programs method performs
significantly better methods implementation method shogi
program bonanza made substantial contributions programs first place finish
world computer shogi championship additionally present preliminary evidence
broader applicability method two player games chess

introduction
heuristic search powerful method artificial intelligence chess playing
computer deep blue defeated world chess champion garry kasparov campbell hoane
hsu computer decided moves making large number searches
minimax game tree heuristic evaluation functions framework
artificial intelligence heuristic evaluation functions well search methods
crucial making strong computer players thus researchers working games
made substantial efforts quest create effective evaluation functions machine learning techniques furnkranz however fully automated learning
heuristic evaluation functions remains challenging goal chess variants example developers reported majority features weights deep blue
created tuned hand campbell et al said recent top level chess
programs tune parameters automatically although yet
publication describing methods use moreover reinforcement learning
applied chess baxter tridgell weaver veness silver uther blair
c

ai access foundation rights reserved

fihoki kaneko

however best authors knowledge evaluation functions learned
methods reported literature still weaker best hand crafted functions
terms chess playing strength
revisit idea behind earlier learning chess evaluation
functions marsland hsu anantharaman campbell nowatzyk tesauro
reformulate task optimization alternative learning
method called minimax tree optimization mmto objective optimize
full set parameters evaluation function search match
desired move decisions e g recorded moves grandmaster games evaluation
functions learned iteration two procedures shallow heuristic search
training positions current parameters parameter update guided
approximation gradient objective function achieve scalability stability
introduce combination optimization techniques simplified loss function gridadjacent update equality constraint l regularization one resulting merits
mmto ensure existence local minimum within convenient range
parameters
study demonstrates performance mmto shogi variant chess
evaluation functions need handle wider variety features positions western
chess implementation mmto shogi program bonanza described section
made substantial contribution programs first place finish world computer shogi championship rules shogi well survey approaches artificial
intelligence described literature iida sakuta rollason basic techniques minimax search guided heuristic evaluation functions effective
shogi chess however drop rule allows player reuse captured pieces
significantly changes properties number legal moves well average
game length greater chess endgame databases available
material balance less important chess especially endgame thus
performance shogi program dependent quality evaluation function
experiments first full set parameters evaluation
functions optimized respect rate agreement training set
examine performance learned evaluation functions terms
rates agreement test positions win rates references scalability
demonstrated forty million parameters far many tune
hand features used piece values extended versions piece square tables
commonly used learn evaluation functions chess tesauro baxter et al
veness et al briefly examine performance mmto chess
catch glimpse applicability mmto games
rest organized follows next section reviews related
third section presents mmto method fourth section shows experimental
forty million parameters adjusted better performance compares
performance method existing methods last section presents
concluding remarks incorporates extends previous work hoki
kaneko kaneko hoki


filarge scale optimization evaluation functions minimax search

related work
section reviews related learning evaluation functions first describe
supervised learning methods use desired moves second discuss learning
methods including regression reinforcement learning third briefly discuss difficulty supervised learning terms numerical optimization although machine learning
components besides evaluation functions game programs would interesting
topic bjornsson marsland tsuruoka yokoyama chikayama
coulom silver tesauro review focuses
done learning evaluation functions
learning desired moves chess
grandmaster games popular source information learning chess let us say
set positions p desired moves position p typically
positions moves sampled grandmaster games chess program
evaluation function e p w p game position feature weight vector w
contains parameters adjusted
let us assume evaluation function e p w partially differentiable respect
wi wi th component w
p example function could
linear combination weighted features e e p w wi p p th
feature value position p aim learning better weight vector w
strengthening play program hypothesis behind kind learning
computer play agrees desired moves better plays
let us begin simple intuitive goal make one ply search agree
desired moves simplicity let us assume maximizing player moves first
root position p one ply search move highest evaluation value
selected thus w adjusted desired move highest evaluation
moves goal formally written mathematical minimization
objective function
p
w
jh
w

x x

h e p w e p dp w



pp mm p

p position move position p dp desired move position p p
set legal moves p excluding dp h x heaviside step function e
h x equals x otherwise objective function counts number
moves evaluation value greater equal desired move
better w found minimizing eq although several studies attempted
machine learning basis framework nitsche van der meulen
anantharaman numerical procedures complicated adjustment
large scale vector w seemed present practical difficulties
marsland presented notable extension wherein continuous function used
conventional optimization techniques exploited continuous function
difference substituted non continuous step function eq interesting


fihoki kaneko

modified function
w
j p w

x x

max e p w e p dp w



pp mm p

meaning function value different eq e function
count number moves evaluation value greater equal
w helps reduce function
desired move however gradient vector w j p w
value numerically marsland introduced inequality constraints order keep
evaluation right range however literature provide experimental
practical chess programs
second notable extension proposed early development chess machines
deep thought nowatzyk hsu et al positions compared
p rather wp one leaves principal variations pvs possibly
several plies p extension carries least square fitting evaluation
w instead biases
values therefore max function j p w
p dp
value e w w used least square fitting evaluation value
p
p
desired move dp e w p w lower another move e w
w
third notable extension comparison training proposed tesauro
tesauro modified objective function
x x
p
p
p
w
jct
w
tct e w p w e w
w
pp mm p

tct x r x



standard sigmoid function r heuristic rescaling factor positive
differences e r x x x r x cx constant c otherwise note
r x still continuous function important property modified objective
function value derivative zero limit difference x goes
positive infinity respectively one zero limit difference
x goes negative infinity therefore tct x eq continuous approximation
h x eq note property explicitly stated tesauro
notably distinct work number feature weights adjusted
method less two hundred tesauro mentioned application small bit
integers used adjust weights deep blue however neither
clarified procedure mentioned whether weights automatically adjusted
experiment
table summarizes related work existing methods possesses least
one three important properties optimization e continuity minimax searches
assured local minimum however none three properties
existing methods nowatzyk hsu et al tesauro try
decrease functions iteration much possible revisit issues
section hand method mmto scalability high dimensional
learning moreover empirically decrease objective function value
leads increase playing strength existing methods shown
property


filarge scale optimization evaluation functions minimax search

method
nitsche
marsland
van der meulen
hsu et al
anantharaman
comparison training
mmto

continuity

search

assured local minimum












yes


yes

yes
yes
yes
yes



yes
yes

yes


yes

table summary learning methods desired moves training positions
adjust feature weights evaluation functions first column name
method piece literature second column describes continuity
objective functions respect feature weights yes means
continuity depends kind search method used third column indicates
whether objective functions use minimax searches depths
instead comparisons legal moves root position fourth column
shows whether hyper parameters objective functions assure local
minimum found

methods learning evaluation functions
many researchers utilized information sources desired moves
example studies othello dating compare desired moves
moves fawcett however practical famous machine learning
method yielded strong programs regression desired value
million features buro othello different evaluation functions
used game stages determined basis number discs play thus
desired values training positions obtained complete endgame search
well heuristic search evaluation functions learned later game stages
method successfully applied card games buro long furtak sturtevant
chess variants best authors knowledge learning
regression win loss labeled data yielded decent evaluation functions chess
variants except desired moves buros method properties
similar listed table objective function continuity well assured
local minimum method scalable gomboc buro marsland proposed
learn game records annotated human experts however feature weights
adjusted experiments small part full evaluation functions
reinforcement learning sutton barto especially temporal difference learning
famous success backgammon tesauro considered promising
way avoid difficulty finding desired values regression
applied chess shown improve strength programs baxter
et al levinson weber veness et al knightcap program
achieved rating points free internet chess server fics
free internet chess server http www freechess org last access



fihoki kaneko

easy


single minimum

dicult
b

c



smooth non dieren able

e

narrow trough non con nuous

figure example illustrating difficulties facing minimization procedure
points highest peak internet chess club icc baxter et al
another program achieved points highest peak icc veness et al
however strong human players ratings points icc
difference means programs reached top level chess programs
evaluation functions tuned reinforcement learning yet reached level
best handcrafted evaluation functions chess moreover number feature
weights adjusted order thousands checkers evaluation functions
trained temporal difference learning reportedly comparable best handcrafted
efforts schaeffer hlynka jussila reported player stronger
expert human checker players created neural networks trained
evolutionary strategy chellapilla fogel features beyond piece
differentials given neural network priori
many machine learning techniques baxter et al veness et al
applied shogi however despite efforts many programmers researchers adjustment full weight vector evaluation function remains challenging goal
studies published far adjusted piece values small part feature
weights evaluation functions beal smith ugajin kotani
learning numerical optimization
learning methods reviewed section objective functions decrease
learning process extended numerical optimization functions
performance numerical optimization sensitive surface objective function
figure shows properties particular sorts functions difficulties regarding
numerical minimization easiest one among convex function local
minimum exists global minimum function b multiple local minima however still thought easy minimization
gradients hessian matrices effective would desirable design
learning method say linear logistic regression uses one two types
objective function buro
contrast non differentiable functions c e often difficult
minimize differentiable ones quadratic model hessian
approximation conjugated gradient method bertsekas bertsekas
appropriate functions function difficult target
important local minimum hidden inside deep narrow trough quite difficult
numerical iteration methods difficult example minimization


filarge scale optimization evaluation functions minimax search

non continuous function e even primitive iterative methods gradient decent
capable finding minimum extreme case would function
analytical formula gradient unavailable case learning method would
able use partial derivatives minima would obtained
derivative free methods e g sampling methods bjornsson marsland coulom

theorems appendix minimax value continuous
partially differentiable thus existing methods incorporate minimax search
hsu et al tesauro mmto listed table type c moreover
certain forward pruning techniques may cause discontinuities therefore even learning
methods type e overcome difficulty mmto well modeled objective
function updates feature weights careful manner

minimax tree optimization
minimax tree optimization mmto extension comparison training reach
first intuitive goal embodied eq purpose extension overcome
practical difficulties stabilize mathematical optimization procedure largescale feature weight vector w given set training positions p desired move dp
position p mmto optimizes weight vector w minimax search
w better agrees desired moves
weight vector w improved iteration sub procedures see figure
iteration first step consists tree searches identify one leaves
pvs w legal moves training positions p pv leaf w depends
feature weights w evaluation function pv obtained
w updated discuss issue section second step calculation
approximate partial derivatives depends pv weight vector
last step update weight vector numerical stability difference
w w must kept small distorted drastic changes
w
partial derivatives section shows grid adjacent update ensures
objective function minimized
objective function
p
w j p w jc w
w jr w
w
jmmto
w



first term j p w right side main part terms jc
jr constraint regularization terms respectively defined section
first term
x x
j p w
p dp w p w

pp mm p

p w minimax value identified tree search position p x
exp ax horizontally mirrored sigmoid function slope x
controlled constant parameter large limit x becomes heaviside


fihoki kaneko





wp

perform game tree search identify pv leaves
child positions
p position p training set p w weight vector
th iteration w initial guess
calculate partial derivative approximation well modeled objective
p
w
function defined section w
objective
function employs differentiable approximation h x see section
well constraint regularization term see section



obtain weight vector w w grid adjacent update
guided partial derivatives computed step see section go
back step terminate optimization objective function
value converges see section



figure minimax tree optimization iteration searches update partial
derivatives

step function h x thus main differences first intuitive objective function
p w
w eq use x smooth approximation h x use
jh
w
search p w instead raw evaluation e p w difference j p w
p
w
w
eq jct w eq j p simpler closer first intuitive one
w jr w
w eq
eq moreover none existing studies incorporate jc w
minimax value p w equals raw evaluation value e wp w e p w
evaluation position p wp one pv leaves identified tree search rooted
p weight vector w cases derivatives p w equal derivatives
e wp w reasons pv leaves identified step figure
constraint regularization terms
computer programs chess variants evaluation values typically represented
integers signed bit integers especially preferred corresponding transposition tables memory efficient thus restrict range absolute
value evaluation function e p w moreover search change
w constant factor restriction
one uses scaled weight vector w
stabilizes numerical optimization procedure value uncertain
w g w
w eq
restriction introduce constraint term jc w

w equality constraint lagrange multiplier
subset w g w
w see
addition constraint term introduce regularization term jr w
w w
w
last term eq use l regularization jr w
constant variable w subset w l regularization widely used deal highdimensional parameters whereas l regularization used avoid fitting tibshirani


w



filarge scale optimization evaluation functions minimax search

p w
w exists
constraint regularization terms ensure local minimum jmmto
finite range w hand depending p distribution dp
p w
w eq jct
w eq
property true j p w j p w
constraint l regularization terms similar functionalities e restrict
range absolute value evaluation function e p w however distinctions important practice l regularization makes weight vector w sparse
whereas constraint term thus regularization term suitable minor
features rarely seen whereas constraint term suitable major features
appear often training set moreover terms useful controlling
strength restriction major feature values usually change often
minor feature values magnitudes partial derivatives respect major feature
weights usually greater respect minor feature weights adjust
strength l regularization term weaker constraint term
example experiments used constraint term piece values
feature values e number pieces owned black white change single games
shogi many weights penalized l regularization weight
w w
controlled constraint l regularization term e w w
partial derivatives respect major minor feature weights differed several
orders magnitude difficult stabilize optimization procedure means
single hyper parameter

partial derivative approximation
iteration feature weights updated basis partial derivatives
p w
w defined eq partial derivative exists
objective function jmmto
p



w
w
w
jmmto w
j p w
jc w
jr w
wi
wi
wi
wi




w right side treated intuitive manner sgn wi
last term w
jr w


wi w otherwise function sgn x x x x

w wi
jc w
w case wi w
partial derivative constraint term w

discussed section
partial derivative j p w exist minimax value
p w differentiable instead use approximation


j p w
wi


x x
p dp w p w
wi






x x
p
e w p w e wp w
wi




pp mmp

pp mmp



x x

p

e w p w e wp w

pp mm p


p p
e w w e wp w
wi

x ddx x approximation eq eq makes computation
tractable identify pv leaves step figure stated appendix


fihoki kaneko

minimax value p w found search continuous therefore function
j p w continuous moreover approximate value equivalent partial
derivative unique pv exists position appendix discusses con
ditions w
p w exists note found errors caused

approximation sufficiently small shogi application kaneko hoki
previous studies baxter et al tesauro use approximation well
grid adjacent update
numerical stability grid adjacent update step see figure used get
w w consider simple n dimensional grid distance two
adjacent points h suppose h integer e g h grid adjacent update
feature vector w one points grid th component
wi adjacent wi
wi wi h sgn

p w
w
jmmto

wi

thus wi wi wi h update decrease objective
p w
p w
w w
w w jmmto
w errors approximation see
function jmmto
eq negligible moreover h must small enough update
p
p
change pv e w
w majority positions p searched step
although mmto focuses optimization weight vectors represented integers
noted gradient descent update suitable even one uses floatingpoint feature weights preliminary experiments indicate partial derivatives
j p w respect major minor feature weights differ seven orders
w proportional gradient vector may
magnitude thus update vector w
appropriate updating minor feature weights small step thus step
size component weight vector fixed grid adjacent update
might able controlled ways see e g duchi hazan singer
combination techniques practical issues
mmto combination described techniques subsection discusses
practical issues combination alternatives relate external constraints
learning e g many weeks wait depend properties domain mmto applied
lagrange multiplier grid adjacent update
numerical stability mmto explores restricted parameter space constraint
w lagrange multiplier jc w
w set
satisfied e jc w
w
j p w

median partial derivatives wi wi w order maintain constraint
w iteration wi h n feature weights h n feature
g w
weights one feature weight number feature weights w n
w constant iterations
hand regularization term jr w


filarge scale optimization evaluation functions minimax search

search depth
game tree searches step figure time consuming step mmto
tesauro shown use quiescence search yields better evaluation
functions thus expected deeper searches mmto yield better evaluation
functions hand must handle large amount training positions
search time tends grow exponentially increase search depth therefore
experiments use ply standard search together quiescence search
quiescence search called every frontier node standard search observed
evaluation functions learned shallow searches still effective playing games
deep searches see section similar reported tesauro
reuse pv efficiency learning
step figure time consuming part worth considering omitting
assuming wp wp certain frequency experiments steps
repeated times without running step counted number iterations
run step iteration ran single step pairs steps
number would domain dependent set small enough update
change pv positions
pruning trees
pruning techniques dramatically reduce number searched nodes hence speed
learning fortunately pruning introduce discontinuities objective
function hand pruning methods including futility pruning schaeffer
may introduce discontinuities see appendix therefore robustness
whole learning procedure examined pruning techniques used
far authors experience goes objective function futility pruning seems
continuous see section
convergence performance measurement
termination criteria usually difficult determine iterative computations
case learning shogi evaluation function convergence objective function
mmto seems significant criteria rate agreement test set
elo rating learned evaluation function converge converges note
rate agreement measured separate test set training set
order detect overfitting see section
duplication positions alternative moves
game records usually duplications positions desired moves opening
phase although ideal distributions positions desired moves unknown
decided remove duplications training test sets simplicity
use pair hposition movei iteration duplications
detected zobrist hashing note two different moves may
suggested position training test sets objective function


fihoki kaneko

becomes smaller tree search rooted position matches one moves
conflicting goals move better move b vice versa
independently augmented objective function cancel
moves played position experience adaptation seems work
reasonably well shogi best solution may depend target game

experiments
evaluated effectiveness mmto experiments number feature
weights evaluation function varied thirteen forty million
found mmto works better comparison training intuitive modifications
terms rate agreement speed convergence game playing strength
w regularization term jr w
w help inalso observed constraint term jc w
crease performance evaluation functions terms rate agreement
test set see numerical convergence investigated surfaces objective
function mmto limited number feature weights experimentally found
mmto finds local minima reasonable range feature weights finally carried
preliminary experiments chess well experiments data quality dependence
setup evaluation functions features game records
experiments described section used bonanza whose source code
available online hoki muramatsu performance bonanza major tournaments discussed section bonanza uses techniques mmto pvs pearl
marsland campbell reinefeld capture search frontier nodes
quiescence search transposition tables zobrist russell norvig static exchange evaluation reul killer history heuristics akl newborn schaeffer null move pruning adelson velskiy arlazarov donskoy heinz
futility pruning schaeffer heinz late move reductions romstad
uses opening book database randomly chose opening lines
self play experiments game records training test sets exclusively
chosen games played famous tournaments game records
total games played professional players standard
time controls e one ten hours side byoyomi period time
abbreviated tournament name number games used date range games juni
kisei ryuo osho oui
ouza nhk cup ginga kio
shinjino zen nihon proshogi hayazashi shogi senshuken
judan meisho joryu meijin meijin
star kachinuki rating senshuken asahi open
heisei saikyo teno joryu osho
kurashiki touka nihon series dan league ladiesopen joryu oui shoureikai gakusei osho
hayazashi shinei gakusei ouza asahi amashogi
wakajishi kudan gakusei meijin shogi renmei cup
tatsujin kinsho cup amateur meijin
kashima cup grand champion saikyosya kettei miscellaneous



filarge scale optimization evaluation functions minimax search

evaluation function

x



e
p fia p wia

x
b
b
b
eb
fkj
p fkj
p wkj
ec
ed

k j
x

l
k k
x

dimension



c
c
c
fkk
l p fkk l p wkk l






fkjj p fkjj
p wkjj



k jj

table dimensions evaluation functions evaluation function linear combination weighted features ea evaluates material balance others
evaluate variety positional scores extended piece square tables

expired player move within sixty seconds tournaments employed rapid
time controls seconds per move top level amateur players participants
table shows four basic evaluation functions ea material balance
others positional scores experiments used sum functions e
ea eab ea eb eabc eab ec eabcd eabc ed evaluation functions
anti symmetric respect exchange black white e p w e p w
p complete reversal black white sides position p black plays
white white plays black reversal pieces owned black white
p regarded white black pieces p respectively evaluation functions
symmetric respect right left mirroring position e p w e p w p
mirror image p along file e
function ea p w used evaluate material balance types
pieces shogi iida et al feature fia p represents number th
type owned black position p wia relative value th type piece
partial derivative evaluation function respect wia ea p w wia
fia p fia p
function eb p w b linear combination weighted two piece square features
natural extensions one piece square features employed recent
machine learning studies chess evaluations baxter et al tesauro veness
et al two piece square features used evaluate conditions
b p indicator function returns one
king another piece feature fkj
conditions k j exist position p otherwise returns zero condition
k represents location black king squares j represents
type owner black white location piece different
conditions j minor conditions merged thus total number
kingpiece conditions mirror symmetric conditions
merged
following shogi notation black white refer players plays first second respectively



fihoki kaneko

similarly functions ec p w c ed p w used evaluate kingking
c p
piece features kingpiecepiece features respectively indicator function fkk
l
represents location two kings k k condition type location
p represents location black king k
black piece l indicator function fkjj

conditions two black white pieces j j
game tree searches required identify pv leaf positions mmto obtain
best moves measure rate agreement purposes nominal depth
search used together quiescence search normalize objective function
values objective function values divided total number move pairs z p
p

pp mp constraint function set


w
g w


x


wia







accordance magnitude constraint horizontally mirrored
sigmoid function x exp ax set x would vary signifiw w
wb
cantly x changed hundred regularization term jr w
c

w w
w intuitive explanation penalty strength absolute value
w
wi increased improves relationship evaluation
values desired move another legal move sums eb ec ed computed
bit integers divided order fit evaluation value
bit integer step h grid adjacent update set smallest integer value
learning piece values
first feature weights w w evaluation function ea adjusted mmto
comparison training starting initial value wia tesauro
used floating point feature weights conventional gradient descent method
weight vector w updated
p
w
w w rw jct
w



r constant training rate hand tuned components w used tree
search rounded nearest integer values rescaling factor r eq set
p
accordance range difference e w p w e wp w
experiment piece values adjusted w
game records used compose training set p set desired moves
z p move pairs removing duplications handicapped games
one observed comparison training slow learning shown figure phase iterative procedure iteration mainly adjusting
pawn value partial differential value eq pawns largest
phase good pawn value found phase ii iteration
mainly adjusting promoted rook promoted bishop values values
highest second highest reasonable game play long period time taken
w eq scales poorly general
phase ii indicates jctp w
gradient descent methods multiple degrees freedom nocedal wright


filarge scale optimization evaluation functions minimax search

pro rook



phase ii

phase

phase iii
pro bishop

piece weight


gold
bishop
rook
pro pawn
pro knight
silver
pro silver
pro lance
knight
lance







pawn




























iteration

figure comparison training piece weights shogi horizontal axis
plots number iterations logarithmic scale

cope learning rate r cannot greater accordance largest
partial derivative experiments
second convergence phase iii iteration figure
piece values keep increasing without changing ratio piece values even though
relative ratios piece values room improvement inherent
objective function comparison training eq explicit term
avoid extreme case training data satisfy inequality condition
p
e w p w e wp w moves position p piece values diverge infinity
w minimized fact found training data
value jctp w
experiment satisfied condition pairs best another legal move
moreover extreme case training satisfy inequality
condition move position p eq piece values shrink zero
mmto deals making grid adjacent updates keeping
w weighted vector w converged
magnitudes constant constraint term jc w
iterations see figure value promoted rook
pawn note number iterations counted number step
throughout experiments
scalability learning practical evaluation functions
learning piece values adjusted weight vectors positional scores
time large number training records used cope high dimensional weight
vectors main training set p desired moves z p


fihoki kaneko

pro rook
pro bishop
rook
bishop
gold
pro knight
silver
pro pawn
pro lance
pro silver
knight
lance
pawn

piece weight





















iteration









figure mmto piece weights
move pairs removing duplications handicap games game records
test set desired moves removing duplications handicap games
another game records feature weights eab adjusted mmto
comparison training intuitive modifications initial feature weights
w w b used three methods w optimized mmto
w
previous experiment w b scalability feature weights
eabc eabcd optimized mmto order adjust feature weights
eabc optimized feature weights eab used initial feature weights w
w b used w c similarly eabcd optimized feature weights
eabc used initial feature weights w w b w c used
w
comparison training eabc eabcd tested learning eab yielded
small improvements rate r eq hand tuned example
intuitive modifications stabilize iterative procedure constant step update
tested learning eab case training rate r substituted r

p
w
r rc w jct
w
constant step modification conservatively updated w constant step rc
hand tuned value r rc best five trials another
intuitive modification reuse pv explained section pvs
used times rate r eq rescaling factor r eq
set value satisfactory previous experiment shown
figure although three methods different iterations consumed almost
amount time time consuming step experiments
game tree search identify pv leaf positions
rate agreement test set shown figure agreement means
legal move obtained highest value tree search desired move


filarge scale optimization evaluation functions minimax search



b c h
b c b




b f


b c b
f c



positional weight

agreement





abcd

mmto e

abc
mmto e
ab
mmto e
ab
ct e reuse pv
ab
ct e constant step
ab
ct e

























b c
f b



b b c


b c




b c





iteration







iteration



figure left panel improvement rate agreement test set mmto
comparison training ct right panel improvement feature weights
positional features ed feature weight b c b indicates black king
b two gold generals c b similarly feature weights b c h
b c b b c b b c b c b c indicate two gold generals
king b feature weight b f indicates black king
opponents two gold generals b f similarly feature weights
f b f c indicate opponents two gold generals king
value divided

rate calculated excluding positions one legal move positions
easy checkmate sequence identified shallow depth
search tied values counted
performances mmto comparison training variations compared
case learning eab see figure agreement rates comparison
training constant step modification unstable substantially lower
mmto see reuse pv modification increases stability
reduces step length reduces computation time learning
almost times reduces number time consuming pv updates
mmto full evaluation function eabcd highest rate largescale optimization weight vector wd increased level agreement iterations


fihoki kaneko

without constraint
constraint

pawn value













iteration







figure effect constraint term mmto eab
computation took week intel x workstation agreement ratio
test set converged iterations however feature weights converge
w eq improves stability mmto
figure shows constraint jc w
response pawn value changes eab learning see value keeps
w turned converges iterations
increasing jc w
constraint turned one feature weights overflowed comparison training
eabc another reason eabc shown comparison
w little effect learning eab
training regularization term jr w
improvement agreement rates mmto mainly due use constraint
w grid adjacent updates
jc w
w important optimizing larger weight vectors figthe regularization term jr w
w eq improves weight vector enlarged evaluation
ure shows jr w
function eabcd without regularization term objective function value rate
agreement training set increase number iterations however
linear increment absolute value weight vectors distorts
rate agreement test set th iteration th iteration
components w zero hand components
w zero regularization term indicate mmto without
regularization suffers overfitting training set large scale weight vector
used similar effect regularization occurs mmto used eabc
learning though effect smaller eabcd
improvements strength
analyze relationship agreement rate strength programs learned mmto comparison training figure play games
reference shogi program many times reference program version gps shogi
released kaneko open source program finalist past
world computer shogi championships completely different evaluation function
majority parameters hand tuned version gps shogi
serves reference program popular game server shogi programs matches
follows reference program nodes move vs four learned programs
http wdoor c u tokyo ac jp shogi last access japanese



fiobjective function

large scale optimization evaluation functions minimax search







agreement



l regularization
without l regularization




training set



test set







b





c





























iteration

figure effect regularization term mmto eabcd
reference program nodes move vs two learned programs evaluation
function ea eab reference program nodes move vs two learned
programs evaluation functions eabc eabcd games played
match weight vectors obtained
iterations tested learning configuration thus total
games played learned programs searched nodes per move programs
ran single thread searched similar numbers nodes second
measured playing strength terms elo rating popular way
represent relative strength two player games winning probability two
players estimated difference ratings
example rating player higher player b winning
percentage player ratings determined maximum
likelihood estimation games
figure shows elo rating player see mmto eab significantly outperformed comparison training initial feature weights
mmto used eab winning percentage reference k move stably increased elo points elo points contrast comparison


fielo rating

hoki kaneko













mmto abcd
mmto abc
mmto ab
comparison training ab
reference k
reference k
reference k




iteration



figure improvements strength elo rating achieved mmto comparison training

opponent
player
player

depth



depth



depth



depth



depth



depth



depth



table winning percentages program learned game tree search
depths opponent player program search depth reduced
opponent player program uses weight vector
learning

training elo points games shown figs
indicate mmto outperforms comparison training
large number features contributed playing strength programs
learned mmto although eabc showed small improvement terms agreement
rate elo rating eabcd consistently yielded significant improvements two criteria thus concluded mmto scales well forty million features note
computational cost eabcd reasonably small practical game play
number features appear position less even total
number features forty million summations table maintained incremental manner program makes unmakes move sort
feature design similar famous othello program buro
bonanza eabcd searched nodes sec intel xeon x
threads speed slower many chess programs average
strong shogi programs addition found bonanza eabcd trained
mmto played better comparable top shogi programs actual
tournaments details discussed section
two additional fixed depth self play experiments conducted see evaluation
functions trained shallow searches depth quiescence search effective
deep searches table shows winning percentages learned program


filarge scale optimization evaluation functions minimax search

search depths game play learned program eabcd evaluation function yielded
th iteration figure winning percentages program
player search depth reduced around thus see
deeper learned program searched stronger program tesauro
reported similar comparison training addition winning percentage
program player searched depth used eabc
th iteration thus use eabcd trained iterations effective
even program searched deeper winning percentages computed
thousand games seventy six games less ending draws exceeding moves
counted fifty megabytes memory assigned transposition table
program uncertainties indicated estimated conducting two sided test
significance level one thousand games
numerical stability convergence
investigated continuity partial differentiability objective function
convergence feature weights empirical manner forward pruning techniques game tree searches speed mmto practical applications methods
maintain continuous search values shown appendix moreover
objective function contains large number search values means difficult
estimate properties theoretical manner
make empirical investigation manageable used smallest evaluation
function ea deals thirteen shogi piece values moreover reduced number
game records game records desired moves z p
move pairs removing duplications handicapped games
surface objective function
investigated function surface main part objective function j p w
mmto eq generating contour maps millions sampling vectors w
note contour line isovalue surface curve along functions take
value contour lines certain properties gradient function
perpendicular lines magnitude gradient large two lines
close together addition closed loop contour line indicates location local
minimum maximum
two thirteen piece values weight vector w sampled order draw
contour maps two dimensional functions interval piece value
remaining eleven pieces assigned reasonable values pawn lance
knight silver general gold general bishop rook promoted
pawn promoted lance promoted knight promoted silver promoted
w ignored w
bishop promoted rook constraint term jc w
w turned piece values
could freely changed regularization term jr w
nominal depth search together quiescence search used
analyzed two pairs hgold bishopi hpawn promoted lancei figure shows
enlargement contour map j p wgold wbishop contour interval
map computed ranges bishop


fihoki kaneko

bishop pro bishop

bishop dragon
gold bishop

bishop rook

bishop silver

gold general weight

gold pro bishop

gold rook



x x





objective function

gold pro rook





gold silver





bishop weight



















bishop weight


gold general weight

figure upper panel enlarged contour map j p wgold wbishop dashed lines
indicate critical boundaries two dimensional function
partially differentiable two minima indicated x bottom panel
cross sections contour map left one shows intersection
map line wgold shows wbishop

gold general note function simply increases interesting
structures outside enlarged map figure shows enlargement contour
map j p wpawn wpro lance contour interval map computed
ranges pawn promoted lance
see maps local minima within reasonable ranges
sudden changes function values although function depends large
number empirical search values p w approximately continuous amenable
optimization basis gradients approximated mmto
hand maps illustrate three difficulties first difficulty clear
edges contour lines indicate function partially differentiable
points edges dashed lines maps critical boundaries
profit loss ratio material exchanges inverts example silver usually


filarge scale optimization evaluation functions minimax search

pro lance lance pro lance knight pro lance silver
pawn silver

pawn weight


pawn knight


pawn lance
lance promotion pawn


x









x







objective function

promoted lance weight








promoted lance weight











pawn weight

figure upper panel enlarged contour map j p wpawn wpro lance dashed
lines indicate critical boundaries two dimensional function
partially differentiable two minima indicated x bottom panel
cross sections contour map left one shows intersection
map line wpawn shows wpro lance

less valuable bishop capturing silver becomes profitable capturing
bishop bishop value smaller boundary labeled bishop silver
figure discussed appendix function partially differentiable
critical boundaries multiple moves share best value note
boundaries theory e g bishop promoted knight boundary whether
boundary visible depends training set evaluation features addition
boundaries become winding curves non linear evaluation function used instead
linear weighted sum
second difficulty scaling illustrated figure map
see scales two piece values differ two orders magnitude
pawn value variation five hundred changes function value whereas
promoted lance value variation five hundred changes function value
difference scaling surface along promoted lance almost flat
property explains pawn value optimized earlier pieces
comparison training shown figure property ill scaling disadvantageous
comes optimizing promoted lance value naive gradient decent method


fihoki kaneko

methods second order partial derivatives approximations hessian matrix
resolve however behave poorly non partially differentiable points
many boundaries two difficulties point grid adjacent update mmto
effective
third difficulty multiple local minima two maps
means mmto depend initial values chance ending
local rather global minimum investigate next
subsection
empirical convergence local minima properties
previous subsection examined two dimensional cross sections function
j p w subsection loosen restriction two thirteen dimensions
sufficiently large express piece values shogi aim experiment
catch glimpse global map numerical convergences arbitrary initial
guesses values pieces
purpose monte carlo sampling initial guess w carried
enumerate local minima analyze optimized vectors ran mmto
randomized initial values uniformly distributed integer range
assigned vector component resulting vector scaled satisfy
w
equality condition g w
figure shows cosine similarity objective function value hundred
runs cosine similarity weight vector measured relative best vector
whose objective function smallest among vectors iterations
majority runs see function values weight vectors converged
numerically iterations regard iteration procedure converged
function values similarities oscillate neither steady increase
decrease th th iteration although convergence almost assured
mmto thirteen piece values would difficult achieve feature weights
optimized example figure shows convergence twothousand iterations eabcd iterations took week intel
x workstation could afford investigate convergence eabcd
current hardware however iterations nonetheless achieved significant improvement
strength shown figure
see trials mmto ended multiple local minima
although multiplicity minima generally undesirable optimization
favorable properties first property run mmto changed
weight vector components sufficient amount cosine similarity
optimized vectors localized range random
initial vectors widely spread see top panel figure second property
weak correlation cosine similarities initial optimized
vectors means starting better initial vector terms cosine similarity
beneficial see top panel figure however starting better initial
vector terms objective function value beneficial see middle panel
figure third distribution local minima formed structures see


filarge scale optimization evaluation functions minimax search







similarity

cosine similarity weight vector










objective function



objective function









iteration














iteration











figure hundred runs mmto weight vector w consisting thirteen piece
values initial vectors set pseudo random numbers inset
enlargement showing appearance numerical convergences
top panel shows cosine similarities relative best weight vector
bottom panel shows values objective function

bottom panel figure lower local minimum similar
becomes best vector moreover number local minima decreases weight
vector gets farther away best
investigated dependence performance nominal search depth
step shown figure similar terms convergence distribution
local minima obtained deeper search nominal depth
mmto depth consumes time mmto depth number


fiinitial objective function

cosine similarity initial vector

hoki kaneko








corr






corr

optimized objective function






corr








cosine similarity optimized vector

figure scatter plots trials thirteen dimensional weight vectors vector
expresses thirteen piece values cosine similarity vector measured
relative best vector initial vector consists uniform pseudo random
numbers optimized one th vector mmto iterations
starting initial one inset shows correlation coefficient
scatter plot

random initial vectors reduced number iterations reduced
sixty sake speed majority runs function values weight
vectors converged iterations figure shows strength elo rating objective

filarge scale optimization evaluation functions minimax search


depth corr
depth corr

elo rating




















objective function

figure scatter plots thirteen dimensional weight vectors vectors indicated
crosses learned nominal depth search step
vectors indicated squares learned depth search

function value runs depth squares runs depth crosses
elo ratings identified maximum likelihood estimation
random pairing games nodes move elo rating depth
average depth average correlation coefficient
elo rating objective function value depth depth
moreover compared performance two best vectors gave
smallest objective function values computed winning probability
best depth player allowed use one second move
one core intel xeon x fifty megabytes memory assigned
transposition table excluding two drawn games two games exceeding thousand
moves obtained winning rate program best
depth indicate mmto better depth depth
performance mmto tournament conditions
mmto invented developer bonanza made one best programs
shogi moreover ideas behind earlier versions mmto published japanese
hoki adopted many developers dramatically changed shogi
programs
one authors started developing bonanza published program files
web published source codes web hoki
gives detailed descriptions evaluation function learning whereas literature hoki
muramatsu gives detailed descriptions game tree pruning bonanza
addition learning method mmto bonanza uses evaluation function eabcd
shown table earlier versions used subset eabcd modified


fihoki kaneko







may
bonanza
yss
kcc shogi
tacos
gekisashi

may
yss
tanase shogi
gekisashi
bonanza
bingo shogi

may
gekisashi
tanase shogi
bonanza
yss
bingo shogi

may
gps shogi
otsuki shogi
monju
kcc shogi
bonanza







may
gekisashi
shueso
gps shogi
bonkras
bonanza feliz

may
bonkras
bonanza
shueso
gekisashi
ponanza

may
gps shogi
puella
tsutsukana
ponanza
shueso

may
bonanza
ponanza
gps shogi
gekisashi
ninedayfever

table program names recent world computer shogi championship
mmto earlier version variant mmto learning method
influenced mmto used

l regularization hoki subsequent versions fully evaluate eabcd learned l regularization
table shows world computer shogi championships since
performance bonanza examined several computer shogi tournaments
participant connects server program plays shogi time control
minutes side bonanza received first prize twice second prize third
prize moreover players entitled bonanza feliz monju used evaluation functions obtained mmto thus claim bonanza uses mmto
plays better comparable top programs shogi including commercial ones method clearly plays level handcrafted shogi programs moreover
descriptions learning shogi evaluation functions earlier version mmto
published hoki japanese quickly recognized significant advances fact shogi program conventional handcrafted evaluation functions
broken top five last five years tournaments one interesting case
gps shogi kaneko winner tournaments
source codes available online tanaka kaneko
program uses handcrafted evaluation function used variant mmto
dramatically improved variants mmto used program differ
accordance content policy program example tanase shogi
runner program used learning method mmto handcrafted
evaluation functions bonkras ponanza puella ninedayfever used variants mmto excellent make clear mmto outperforms conventional
programs use handcrafted evaluation functions played extremely well recent
shogi tournaments


filarge scale optimization evaluation functions minimax search

noted versions bonanza add small amount randomness
grid adjacent updates however omitted discussion randomness
clear whether added randomness improved quality
evaluation function source codes versions bonanza available
online hoki source code mmto two files learn c learn c
preliminary experiments chess
far discussed performance mmto shogi expect mmto
would effective two player perfect information games provided certain
conditions met sufficient number game records available minimax
searches guided heuristic evaluations effective analytic partial derivatives
evaluation function respect variables available example mmto
would yield interesting applied game solved
means e g van den herik uiterwijk van rijswijck would yield
interesting game go monte carlo tree searches effective
minimax searches guided heuristic evaluation function kocsis szepesvari
gelly silver browne powley whitehouse lucas cowling rohlfshagen tavener
perez samothrakis colton gelly kocsis schoenauer sebag silver szepesvari
teytaud moreover simpler learning method e g regression method othello
buro would preferable mmto sufficiently effective
conducted preliminary experiments chess catch glimpse applicability
mmto games note already evaluation functions chess
outplay grandmasters whereas none shogi thus might difficult
improve well crafted chess evaluation functions experiment chose opensource program crafty fair implementation chess program hyatt
original evaluation function tightly tuned simple multivariable
function thus sake simplicity modify way except add
linear combination weighted two pieces square features features used
evaluate conditions king another piece eb section
mirror symmetric property described section applied features
pawn exists eighth rank counted total number added
weights w b chess position possesses thirty fewer two piecessquare features additional computational time due modification became
almost negligible help pawn hash table lazy evaluation technique
come original
training test sets composed game records free internet
chess server fics games played standard time control server
two players ratings training set p desired
moves z p move pairs removing duplications game
records whereas test set p desired moves z p move pairs
removing duplications game records
figure shows rate agreement test set number correct answers
chess iteration sigmoid function set
w b w
w b
equality constraint used regularization term jr w


fihoki kaneko

agreement










agreement
number correct answers


































number correct answers



iteration

figure improvement rate agreement test set solid line number
correct answers dashed line chess two piece square
weights w b adjusted mmto

rating
win
















table dependence strength winning percentages learned programs
quality ratings players training set uncertainty indicated
estimated conducting two sided test significance level
games

total chess encyclopedia chess middlegames second
section win chess winning chess sacrifices
used krogius livsic parma taimanov reinfeld
learned program searched nodes per eight megabytes
memory assigned transposition table see agreement rate well
number correct answers tends improve number iterations grows though
differences moderate means mmto found room improvement
well implemented chess program indicate mmto useful way
learn heuristic evaluation functions chess especially one design evaluation
features suitable learning
data quality dependence
assess importance quality game records conducted additional experiments game records players levels experience shogi
eabcd learned eabc figure initial value
summarized table training set composed records
rapid time control seconds per move games played amateurs popular internet
shogi site shogi club first line table shows ratings amateur
players second line shows winning percentages learned evaluation function
shogi club http www shogidojo com last access



filarge scale optimization evaluation functions minimax search

evaluation function trained grandmaster game records evaluation function learned iterations winning percentages computed
averaging thousand games drawn games games exceeding
moves counted player allowed use one second one core
intel xeon x move fifty megabytes memory assigned
transposition table table shows significance quality training set use
game records stronger players made program stronger

conclusion
presented method minimax tree optimization mmto uses game records
adjust full set feature weights evaluation function two player game
learning mmto designed search match desired moves
e g recorded moves grandmaster games mmto consists two procedures
shallow heuristic search training positions current feature weights
update guided approximation gradient objective function
combination simple smooth approximation step function grid adjacent
updates standard techniques e gradient guided optimization constraints regularization contributed scalability stability mmto led showing
substantial improvements existing methods
performance mmto demonstrated experiments shogi variant chess
larger number legal moves mmto clearly outperformed existing methods
addition experimental rate agreement playing strength indicate
mmto adjust forty million parameters possible future work would automated
adjustment step length theoretical convergence analysis

acknowledgments
grateful dr masakazu muramatsu support work

appendix notes continuity partial differentiability
minimax value
saw section objective function mmto piecewise smooth surface
appendix theoretically discuss continuity partial differentiability
w respect w rn w vector parameters
minimax value vp w
evaluation function e p w p position continuity minimax value
ensures continuity main part objective function mmto defined eq
partial differentiability analysis gives conditions approximation inside
mmto described section valid first analyze single minimax tree assuming
tree known fixed extend discussion game tree search
methods possibly explore different trees different w
definition evaluation function e p rn r function p set
positions target game r set real numbers rn n dimensional


fihoki kaneko

euclidean space evaluation function e p w continuous respect parameters w position p p w rn moreover evaluation function
e p w partially differentiable respect component w w rn
continuity partial differentiability evaluation function feasible assumptions note evaluation ordinary piece square table
properties recent machine learning evaluation functions baxter et al
veness et al buro
definition theoretical game graph g finite directed acyclic connected graph
representing possible transitions states target game node resp edge
represents position resp move set nodes g corresponds p v g p
minimax graph finite connected sub graph g convention use term
minimax tree minimax graph even tree denote set minimax
trees g node called maximizing resp minimizing node corresponding
position maximizing resp minimizing player move destination edge
maximizing resp minimizing node source edge minimizing
resp maximizing node clearly assume node n single position p
denote evaluation function e n w
let lr set leaf nodes entire sub tree tr tr rooted node r
omit tree use lr obvious denote set immediate successors
children node n tree cn cn note cn n leaf
standard notation node vertex graph denoted n v however
appendix omit v write n obvious
w value associated node n minimax
definition minimax value vn w
tree defined recursively tree structure static evaluation function
e n w follows

n leaf
e n w
w n non leaf maximizing node
w
maxccn vc w
vn w


w
minccn vc w n non leaf minimizing node
w obvious two minimax values b
omit tree use vn w
maximizing resp minimizing node say better b b resp b
continuity minimax value
continuity minimax value follows continuity evaluation function
w continuous respect w minimax
theorem minimax value vn w
w vn w
w equivalently
tree w rn limw w
w vn w
w w logically implies
w rn exists w

w vn w
w
vn w
following assertion ordinary properties basic functions max
min common sense analysis rather difficult however suitable
reference containing therefore give proof useful subsequent
discussion


filarge scale optimization evaluation functions minimax search

x fk x
x continuous function
proposition let k natural number f x
x continuous function rn similarly mini x
x
rn r maxi x
n
continuous function r
x continuous x rn exists
proof x
x x implies x
x x
x hence choose mini
x


x x implies x
x x
x k
x
x x
x x
x
x

k

note ai bi k obviously implies maxi ai maxi bi thus
inequalities obtain
x max x
x max x
x
max x








x max x
x
max x




x proof similar mini x
x
implies continuity maxi x
let r root given tree prove theorem basis
mathematical induction leaf nodes lr root r leaf node
n lr minimax value continuous continuity evaluation
w e n w internal node n assume continuity holds
function vn w
child c cn induction hypothesis proposition ensure continuity
w
vn w
stability principal variations
subsection showed continuity minimax values continuity
min max functions best moves principal variations
stable changes leaves small enough analyze stability order
discuss partial differentiability

w hereafter called best children denotes set
w
definition symbol cn
children node n tree minimax value n

w c cn vc w
w vn w
w
w
cn


w b denotes
w cn cn
w
w
denote rest children cn
set difference e e e e
b

child considered best choice parent node minimax value
child parent node two children share value
w contains one child otherwise number nodes cn w
w greater
cn w
one
definition let r root tree principal variation abbreviated pv
w tree sub tree obtained closure best children
short w
root
w r
w


w c cn
w n w
w
w
w
w
w




w
w





fihoki kaneko

n



n n n



n n n

figure example minimax tree graph transposition n



w cn
w cn
w n w
w denote leaves
note cn
w
w
w



w l w
w w
w lr
w

example figure shows small minimax tree two best children root n
maximizing minimizing nodes denoted boxes circles respectively
cn n n cn n principal variation tree n n n n
lemma internal node n tree w rn exists
w w n set best
positive number n w satisfying w


children node n w subset one w


w w w
w w n
w cn
w
w
cn

w empty assertion trivial
proof child values e cn w
otherwise let minimum absolute difference best value
w vc w
w continuity minimax
values e minccn w
w vn w
w w n
values ensures existence n w satisfying w




w vc w
w vn w
w vn w
w definition
maxccn vc w


w satisfies
n triangle inequalities c cn w
w vn w
w
vc w
w vc w
w vc w
w vn w
w
vc w
w vc w
w vc w
w vn w
w vn w
w vn w
w
vc w


w vn w
w
vc w




w vn w
w
vc w
w vn w
w namely vc w
w vn w
w implies definition
thus vc w

w
irrespective whether n max min node c cn
w
definition tree stability tree minimum value n among
nodes n n positive number satisfying lemma note minimum
value exists finite
example reference figure suppose leaf value changes
w vn w
w internal node n heights
proven vn w
order obvious n n n proven n n n
finally n see neither n n become best node
change


filarge scale optimization evaluation functions minimax search


p

vn


u






w
vn w

w
w
j

w
vc w
c cn
h
w c
vc w
cn
q



w maximizing node n w changes along th comfigure sketch vn w

w n equals vc w
w one old best
ponent wi h w vn w


w
children c cn w

partial differentiability
partial differentiability well partial derivative minimax
value node tree depends principal variations denote right
left partial derivatives function rn r point x
f
x
x
x


f x x h x n f x x n

h
h



f
x
x
x


f x x h x n f x x n

h
h



lim
lim

let us pay attention single parameter xi changes h limit opf

erations hereafter parameters held constant often omitted x
x
x one dimensional parameter interest use symbol
analogy partial derivative order forget parameters
omitted
w tree
theorem node n principal variation w
w partial derivative evaluation
w rn exists leaf la l w

w vn w
w w
function equals right partial derivative vn w
e la w similarly

w


w partial derivative evaluation function equals
exists leaf lb l w

w vn w
w w
left partial derivative vn w
e lb w

w


proof theorem given end subsection stability
w
w w h
best moves assume w w wi h wn
sufficiently small appendix consequently h node n
tree w rn


n leaf

e n w
n maximizing node

w
max
v
w


c
w
w
vn w
ccn w

min
w n minimizing node
w vc w
cc
w
n





fihoki kaneko

w changing h n maxexample figure sketches example vn w
w h value
imizing node three best children value vn w
continuously linearly changes h best child depends sign
w h less minimax
h one c cn w
w sufficiently less least vn w
w
values children c cn w
h
w given
next goal right left partial derivatives vn w
w respectively
right left partial derivatives one best children cn w
following propositions describe ordinary properties right left limits
basic functions max min similar arguments found comprehensive textbook
calculus give detailed proof however rather difficult
precisely assertion textbook
proposition let k natural number f x fk x continuous
function r r suppose functions value point x e


maxi x mini x right partial derivative x
x

right partial derivative minimum maximum x point x exists
equal minimum maximum right partial derivatives x respectively
maxi

mini

x max x
x min x


x
x
x
x
proof let h landaus symbol let us use denote residual terms converging


faster h e limh h
h recall x f x k
positive h




max x h max x max x h x h max x




x



max f x h x h f x

x



h max x h
x




eq function maxi x point x right partial derivative maxi
argument applies right partial derivative mini x


x
x

proposition suppose functions value point x


functions left derivative x
x left partial derivative minimum
maximum x point x equal maximum minimum left partial
derivatives x
maxi

mini

x min x
x max x


x
x
x
x


filarge scale optimization evaluation functions minimax search

proof similar algebra proof proposition negative h





max x h max x h min x h


x


eq function maxi x point x left partial derivative mini x
x
note min max switched algebra negativity h
argument applies left partial derivative mini x

lemma let gi n w

vn
w
w
wi

resp gi n w

vn
w right resp
w
wi
w rn internal

left

w
partial derivative minimax value vn w
node
w tree exist right left partial derivatives
n principal variation w
w respect n right left partial
gi n w gi n w vn w
derivatives


maxcc w
w gi c w n maximizing node
n

gi n w

mincc w
w gi c w n minimizing node
n


mincc w
w gi c w n maximizing node
n

gi n w

n minimizing node
maxcc w
w gi c w
n

proof prove equalities basis mathematical induction leaf nodes
w definition evaluation function
lr root r leaf n l w
w clearly continuous partially differentiable respect
minimax value vn w
component w rn internal node n assume induction hypothesis
right partial derivative gi c w left partial derivative gi c w exist
w cn w
w h eq
child c cn recall cn w
induction hypothesis proposition
maxccn w
w vc
wi

minccn w
vc
vc
w vc
w
w min
w
w
w


w


w
w
w
w
w
ccn w
ccn w




w max
w

similarly proposition
maxccn w
w vc
wi

minccn w
vc
vc
w vc
w
w max
w
w
w


w


w
w
w
w
w
ccn w
ccn w




w min
w

w obvious gi n w
prove theorem leaf n l w

w lemma ensures left
w
e n w internal node n w

right partial derivatives gi n w gi n w given one best children
w
thus root r exist leaves la lb l w
gi n w

gi r w


wi

gi r w

e la w



wi

e lb w



fihoki kaneko


g n w
g n w

wi

e w
e w

n






g r w g r w
w
vr w

r

c
b


wi

e c w
e c w


wi

e b w
e b w

w exists w equal partial
figure although partial derivative vr w


derivative pv leaf wi e w

w
remark definition gi n w gi n w partial derivative vn w



w satisfying
respect wi exists point w leaf l l w


w
vn w
e l w
wi
wi



w respect
remark n partial derivative minimax value vn w




w
wi exists w equals wi e l w l unique element l w
w partial derivative
remark exists tree tr minimax value vn w

w
respect wi w even leaves l pv unique l w


give different partial derivatives wi e l w example sketched figure
partial derivative b c
game tree search pruning techniques
consider game tree search function takes root position r evaluationw minimax values
function parameters w inputs yields minimax tree trs w
w
w
w
vn tr w
w



n




call

game tree
search

static
provided yields
w
r



w v tr w
w root r
constant tree respect w e v tr w
w yielded static game tree
theorems apply minimax value vr trs w
search example fixed depth minimax search minimax search considering limited
types moves e g capture promotion static game tree search minimax search
stand pat used quiescence search beal static note stand
pat node n equivalent virtual move adding evaluation function e n w
w eq even n leaf node
candidate node value vn w
pruning techniques incorporated part tree pruned explored

w trs w
w yielded
consider static search pruning tree trs w

call pruning conservative provided yields minimax value
w vr w
w theorem applies minimax
root r w rn vr trs w
w w
r
w
value root r vr w
w

yielded



static
game tree search conservative
w
r
pruning standard pruning knuth moore conservative pruning however
many pruning techniques e g static exchange evaluation reul extended futility
pruning heinz null move pruning adelson velskiy et al late move
reductions romstad prune sub tree without prove sub

filarge scale optimization evaluation functions minimax search

tree irrelevant minimax value root thus pruning techniques
generally conservative
summary
minimax value root tree explored game tree search wellconfigured pruning techniques continuous suggests continuity
objective function mmto eq empirically observed section
partial differentiability theorem suggest feasible consider leaves
principal variations search tree one principal variation stated
remark use partial derivative unique leaf introduced section
correct otherwise e multiple principal variations partial derivative
may exist different partial derivative one leaves stated
remark although frequency cases depends target game
evaluation features almost negligible experiments discussed previous work
kaneko hoki

references
adelson velskiy g arlazarov v l donskoy v methods
controlling tree search chess programs artificial intelligence
akl g newborn principal continuation killer heuristic
proceedings annual conference acm pp york ny
usa acm
anantharaman evaluation tuning computer chess linear discriminant methods icca journal
baxter j tridgell weaver l learning play chess temporaldifferences machine learning
beal f generalised quiescence search artificial intelligence

beal f smith c temporal difference learning applied game playing
application shogi theoretical computer science

bertsekas p bertsekas p nonlinear programming nd edition athena
scientific
bjornsson marsland learning control search extensions caulfield
h j chen h cheng h duro r j honavar v kerre e e lu
romay g shih k ventura wang p p yang eds jcis pp
jcis association intelligent machinery inc
browne c powley e whitehouse lucas cowling p rohlfshagen p tavener
perez samothrakis colton survey monte carlo tree
search methods computational intelligence ai games ieee transactions



fihoki kaneko

buro improving heuristic mini max search supervised learning artificial
intelligence
buro long j r furtak sturtevant n r improving state evaluation
inference search trick card games ijcai pp
buro statistical feature combination evaluation game positions
journal artificial intelligence
campbell hoane jr j hsu f h deep blue artificial intelligence

chellapilla k fogel evolving neural networks play checkers without
relying expert knowledge neural networks ieee transactions

coulom r computing elo ratings move patterns game go icga
journal
coulom r clop confident local optimization noisy black box parameter tuning
herik h plaat eds advances computer games lncs
pp springer verlag
duchi j hazan e singer adaptive subgradient methods online learning
stochastic optimization journal machine learning
fawcett e feature discovery solving systems ph thesis department computer science university massachusetts amherst
furnkranz j machine learning games survey machines learn play
games pp nova science publishers commack ny usa
gelly kocsis l schoenauer sebag silver szepesvari c teytaud
grand challenge computer go monte carlo tree search extensions
commun acm
gelly silver monte carlo tree search rapid action value estimation
computer go artificial intelligence
gomboc buro marsland tuning evaluation functions maximizing concordance theoretical computer science
heinz e extended futility pruning icca journal
heinz e adaptive null move pruning icca journal
hoki k bonanza computer shogi program http www geocities jp bonanza
shogi last access japanese
hoki k optimal control minimax search learn positional evaluation
th game programming workshop gpw pp kanagawa japan
japanese
hoki k kaneko global landscape objective functions optimization shogi piece values game tree search van den herik h j
plaat eds advances computer games lncs pp
springer verlag


filarge scale optimization evaluation functions minimax search

hoki k muramatsu efficiency three forward pruning techniques shogi
futility pruning null move pruning late move reduction lmr entertainment
computing
hsu f h anantharaman campbell nowatzyk deep thought
marsland schaeffer j eds computers chess cognition pp
springer verlag
iida h sakuta rollason j computer shogi artificial intelligence

kaneko recent improvements computer shogi gps shogi ipsj magazine japanese
kaneko hoki k analysis evaluation function learning comparison
sibling nodes van den herik h j plaat eds advances computer
games lncs pp springer verlag
knuth e moore r w analysis alpha beta pruning artificial
intelligence
kocsis l szepesvari c bandit monte carlo machine learning ecml vol pp springer
krogius n livsic parma b taimanov encyclopedia chess middlegames combinations chess informant
levinson r weber r chess neighborhoods function combination reinforcement learning marsland frank eds computer games
lncs pp springer verlag
marsland evaluation function factors icca journal
marsland campbell parallel search strongly ordered game trees
acm computing surveys
nitsche learning chess program advances computer chess pp
pergamon press
nocedal j wright numerical optimization springer verlag
nowatzyk http tim mann org dt eval tune txt
pearl j scout simple game searching proven optimal properties
proceedings first annual national conference artificial intelligence
pp
reinefeld improvement scout tree search icca journal

reinfeld f winning chess sacrifices combinations wilshire book
company
reinfeld f win chess dover books chess dover publications
reul f static exchange evaluation icga journal


fihoki kaneko

romstad introduction late move reductions http www glaurungchess com
lmr html last access
russell j norvig p artificial intelligence modern nd edition
prentice hall
schaeffer j experiments search knowledge ph thesis department
computing science university waterloo canada
schaeffer j history heuristic alpha beta search enhancements practice
ieee transactions pattern analysis machine intelligence pami

schaeffer j hlynka jussila v temporal difference learning applied
high performance game playing program ijcai proceedings th
international joint conference artificial intelligence pp san francisco
ca usa morgan kaufmann publishers inc
silver tesauro g monte carlo simulation balancing icml proceedings th annual international conference machine learning pp
acm
sutton r barto g reinforcement learning introduction adaptive
computation machine learning mit press
tanaka kaneko gps shogi http gps tanaka ecc u tokyo ac jp
gpsshogi last access japanese
tesauro g comparison training chess evaluation functions machines
learn play games pp nova science publishers
tesauro g programming backgammon self teaching neural nets artificial
intelligence
tibshirani r regression shrinkage selection via lasso j royal statist
soc b
tsuruoka yokoyama chikayama game tree search
realization probability icga journal
ugajin kotani learning evaluation function tree strap shogi
th game programming workshop pp japanese
van den herik h j uiterwijk j w h van rijswijck j games solved
future artif intell
van der meulen weight assessment evaluation functions beal ed
advances computer chess pp
veness j silver uther w blair bootstrapping game tree search
advances neural information processing systems pp
zobrist l hashing method application game playing icca
journal




