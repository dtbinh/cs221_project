Journal Artificial Intelligence Research 49 (2014) 323-361

Submitted 08/13; published 02/14

Symmetric Subgame-Perfect Equilibria
Resource Allocation
Ludek Cigler
Boi Faltings

ludek.cigler@epfl.ch
boi.faltings@epfl.ch

Artificial Intelligence Laboratory
Ecole Polytechnique Federale de Lausanne
CH-1015 Lausanne, Switzerland

Abstract
analyze symmetric protocols rationally coordinate asymmetric, efficient
allocation infinitely repeated N -agent, C-resource allocation problems,
resources homogeneous. Bhaskar proposed one way achieve 2-agent, 1resource games: Agents start symmetrically randomizing actions, soon
choose different actions, start follow potentially asymmetric convention prescribes actions on. extend concept convention
general case infinitely repeated resource allocation games N agents C
resources. show convention, exists symmetric subgame-perfect
equilibrium implements it. present two conventions: bourgeois, agents
stick first allocation; market, agents pay use resources,
observe global coordination signal allows alternate different allocations. define price anonymity convention ratio maximum
social payoff (asymmetric) strategy profile expected social payoff
subgame-perfect equilibrium implements convention. show
price anonymity bourgeois convention infinite, market convention decreases
price reducing conflict agents.

1. Introduction
many situations, agents coordinate use resource. One wireless channel used one device, one parking slot may occupied one vehicle,
etc. problem often, agents identical preferences: Everyone prefers
access rather yield. Similarly, everyone prefers parking slot rather leave
car home. However, multiple agents try use one resource simultaneously,
collide everyone loses.
Consider simple example: two agents want access single resource. describe
problem game. agents two actions: yield (Y ) access (A). agent
yields, gets payoff 0. agent accesses resource agent
yields, gets payoff 1. agents access resource time,
incur cost > 0.
normal form game looks follows:



c
2014
AI Access Foundation. rights reserved.


0, 0
1, 0


0, 1
,

fiCigler & Faltings

symmetric game, two efficient Nash equilibria (NE) asymmetric:
either one agent yields one accesses resource, vice versa.
symmetric equilibrium outcome mixed NE agents access resource
1
probability Pr(A) := ||+1
. However, mixed equilibrium efficient,
expected payoff agents 0.
Asymmetric equilibria symmetric games undesirable two reasons: First,
fair. example, one agent access resource. Second, coordinating
asymmetric equilibrium difficult. Imagine agents identical
anonymous, i.e. cannot observe identity, identity agent.
cannot prescribe different strategy agents. Agents peer-to-peer
file-sharing networks assumed anonymous (Chothia & Chatzikokolakis, 2005),
well agents wireless sensor networks (Durresi, Paruchuri, Durresi, & Barolli,
2005).
Consider following example: Millions wireless sensors produced
pipeline. take two randomly, put room. one
frequency sensors transmit measurements. sensor know
transmit stay quiet? factory could program half sensors
transmit odd slots, half transmit even slots. Nevertheless,
would likely odd-even pair sensors, would pair
sensors transmit time.
Aumann (1974) proposed notion correlated equilibria fixes issues
Nash equilibria resource allocation game above. correlated equilibrium
(CE) probability distribution joint strategy profiles game. correlation
device samples distribution recommends action agent play.
probability distribution CE agents incentive deviate
recommended action. correlation device takes away burden coordination
anonymous agents. follow strategy: correlation
device told me.
smart correlation device, send agent different private
signal, available? still reach correlated equilibrium outcome, one
anonymous agents play identical strategies, yet achieve efficient fair allocation? previous work (Cigler & Faltings, 2011), proposed algorithm
allows agents learn correlated equilibrium outcome repeated play.
considered special case resource allocation problem. proposed use global
coordination signal multi-agent learning reach symmetric, fair efficient outcome (Wang et al. (2011) later implemented approach actual wireless network
achieved throughput 3 higher standard ALOHA protocols).
coordination signal previous work (Cigler & Faltings, 2011) differ
smart correlation device assumed Aumann (1974)? Firstly, public
cannot send private signals agents. private signals necessary anonymous
agents implement desirable correlated equilibrium single stage resource allocation
game. anonymous agents follow strategy given public signal
value. Secondly, coordination signal specific game. requirement
ergodic, i.e. regularly sends possible values. example
324

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

signal day week, decimal value price certain stock, even noise
frequency.
However, previous solution major limitation: learning algorithm
equilibrium repeated game. selfish agent could force everyone else yield
accessing time, securing resource herself. Therefore, paper, focus
learning algorithms equilibria repeated game. propose
distributed algorithm find allocation set resources symmetric
fair, equilibrium. draw inspiration works Bhaskar (2000)
Kuzmics, Palfrey, Rogers (2010) symmetric equilibria symmetric repeated
games.
Assume agents play infinitely repeated game, discount future payoffs
common discount factor 0 < < 1. strategy agent mapping
history play probability distribution actions. goal find
symmetric subgame perfect equilibrium. subgame perfect equilibrium strategy profile
(vector strategies every agent) NE history, including
cannot occur equilibrium path.
symmetric subgame perfect equilibria study following form:
agents start choosing actions randomly, according given probability distribution. soon play (asymmetric) pure-strategy Nash equilibrium
game, adopt convention, prescribes actions deterministically
on. Bhaskar (2000) gives two examples conventions symmetric 2-agent, 2-action
games:
Bourgeois Agents keep using action played last round;
Egalitarian Agents play action opponent last round.
paper, extend notion convention arbitrary resource allocation problems N agents C homogeneous resources, show convention,
exists symmetric subgame-perfect equilibrium reaches convention. give
closed form expression calculate subgame-perfect equilibrium bourgeois convention, show small number resources C, convention leads zero
expected payoff. means price anonymity bourgeois convention .
present market convention generalization egalitarian convention
Bhaskar (2000). main idea 1) agents pay price successful access
resource, 2) round game, observe global coordination
signal k {1, . . . , K}, based decide whether resource access.
agents decreasing marginal utility accessing often. price helps
decrease demand resources, global coordination signal effectively
increases capacity K-times. show compared bourgeois convention,
market convention improves expected payoff. price anonymity therefore finite.
paper structured follows: Section 2, review basic notions game
theory, present general definitions conventions implementations.
Section 3, formally define resource allocation game N players C resources,
show convention, exists symmetric subgame-perfect equilibrium
implements it. Section 4 present two concrete examples convention: bourgeois
325

fiCigler & Faltings

market conventions discuss properties. Section 5 discuss relationship
work work folk theorems game theory. Finally, Section 6 concludes.

2. Preliminaries
section, first introduce basic concepts game theory going
use throughout paper. Then, define notion price anonymity. Finally,
give general definition convention implementation.
2.1 Game Theory
Game theory study interactions among independent, self-interested agents.
agent participates game called player. player utility function
associated state world. Self-interested players take actions achieve
state world maximizes utility. Game theory studies attempts
predict behaviour, well final outcome interactions. Leyton-Brown
Shoham (2008) give complete introduction game theory.
basic way represent strategic interaction (game) using so-called normal
form.
Definition 1. (Normal form game) finite, N -person normal-form game tuple
G = (N, A, u),
N set N players;
= A1 A2 . . . , Ai set actions available player i. vector
= (a1 , a2 , . . . , ) called action profile;
u = (u1 , u2 , . . . , uN ), ui : R utility function player assigns
action vector certain utility (payoff).
paper, studying symmetric games. games, players
anonymous, thing influences outcome number agents
took certain action.
Definition 2. (Symmetric game) say normal-form game G = (N, A, u)
symmetric game, permutation vector players : N N, holds
strategy vector = (1 , 2 , . . . , N ) N,
ui (1 , 2 , . . . , N ) = u(i) ((1) , (2) , . . . , (N ) ).
Besides playing single deterministic action, player choose action
randomly certain probability distribution.
Definition 3. (Mixed strategy) mixed strategy selects probability distribution
entire action space, i.e. (Ai ). mixed strategy profile vector mixed
strategies player. mixed strategy , define support supp(i )
supp(i ) = {ai Ai : (ai ) > 0} .
326

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Given game specified using normal form, players choose
strategy? players know strategies others, choose action
quite easily: pick strategy maximizes payoff given everyone else
playing:
Definition 4. (Best response) say mixed strategy player best
response strategy profile opponents strategy i0 ,
ui (i , ) ui (i0 , ).
mentioned earlier, one basic goals game theory predict outcome
strategic interaction. outcome stable therefore, usually called
equilibrium. One requirement outcome equilibrium none
players incentive change strategy, i.e. players play best-response
strategies others. defines perhaps important equilibrium concept,
Nash equilibrium:
Definition 5. (Nash equilibrium) strategy profile = (1 , 2 , . . . , N ) Nash
equilibrium (NE) every player i, strategy best response strategies
others .
Correlated equilibrium extends notion Nash equilibrium. canonical interpretation, assumes central correlation device samples space
possible outcomes game according probability distribution, recommends action play player. player incentive deviate
recommended action. formal definition follows:
Definition 6. (Correlated equilibrium) Given N -player game G = (N, A, u),
correlated equilibrium tuple (v, , ), v tuple random variables v =
(v1 , v2 , . . . , vN ) domains = (D1 , D2 , . . . , DN ), joint probability distribution
v, = (1 , 2 , . . . , N ) vector mappings : Di 7 Ai , player
every mapping 0i : Di 7 Ai case
X

(d)ui (1 (d1 ), 2 (d2 ), . . . , N (dN ))

dD

X


(d)ui 01 (d1 ), 02 (d2 ), . . . , 0N (dN ) .

dD

equilibrium, agent chooses best strategy himself. Oftentimes, end
result best agents whole. analyze overall utility game
outcome agents, define social payoff:
Definition 7. (Social payoff ) (mixed) strategy P
vector (1 , 2 , . . . , N ), define
social payoff sum utilities players, N
i=1 ui (1 , 2 , . . . , N ).
2.2 Repeated Game
repeated game, players play given game (for example specified normal
form) repeatedly. call normal form game played round
stage game.
327

fiCigler & Faltings

(1)

(2)

Definition 8. (Future discounted payoff ) Given infinite sequence payoffs ri , ri , . . .
player discount factor , 0 < < 1, future discounted payoff player
Ei :=


X

(j)

j ri .

j=1

Definition 9. (Infinitely repeated game) Let G = (N, A, u) normal form game.
infinitely repeated version G game G discounting game players
play normal form game G infinite number rounds. payoff player
game G defined future discounted reward ri ().
paper, study symmetric equilibria extended version repeated
game, so-called augmented game. assume every round game, players
observe common coordination signal, condition strategy
use. general, coordination signal random integer taken set
{0, 1, . . . , K 1}. practice, piece information observable everyone:
price certain stock given time, temperature room, day week, etc.
signal allow agents coordinate efficiently, time
realistic general correlation device recommends actions agents,
assumed definition correlated equilibria.
Definition 10. (Augmented repeated game) Let G = (N, A, u) normal form
game, let K := {0, 1, . . . , K 1} set coordination signals. augmented infinitely
repeated version G game G discounting game players play normal
form game G infinite number rounds. round t, players observe
coordination signal kt K. coordination signal chosen uniform distribution
K. players discount future payoff discount factor .
W.l.o.g., always assume repeated games augmented, since ordinary
repeated game, assume one coordination signal. Therefore,
rest paper, whenever refer repeated game strategy etc., always
assume game augmented coordination signal.
Definition 11. (History repeated game) Let G infinitely repeated game
discounting. define history ht play round 0

t1
t1
ht := ((a01 , a02 , . . . , a0N ), k0 ), . . . , ((at1
1 , a2 , . . . , ), kt1 )
ati action taken player round t, kt signal players
observe round t.
Definition 12. (Strategy repeated game) strategy repeated game
player function history ht currently observed coordination signal kt
probability distribution action space,
: (ht , kt ) 7 (Ai ).
define Nash equilibrium repeated game way
stage game (we treat repeated game normal form game
players commit strategy entire game front).
328

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Definition 13. (Nash equilibrium repeated game) strategy profile =
(1 , 2 , . . . , N ) Nash equilibrium infinitely repeated game player
i,
Ei (i , ) Ei (0i , )
(1)
alternative strategy repeated game 0i . Ei ((i , ), ht , kt ) future
discounted payoff player adopts strategy players adopt
strategy vector .
following text, use notion future discounted social payoff:
Definition 14. (Future discounted social payoff ) Given strategy profile
infinitely repeated game G, future discounted social payoff defined
E() :=

N
X

Ei ().

(2)

i=1

repeated games, exists stronger notion equilibria, refinement
standard Nash equilibrium definition.
Definition 15. (Subgame-perfect equilibrium) Let G infinitely repeated game
discount factor 0 < < 1. strategy vector = (1 , 2 , . . . , N ) subgame-perfect
equilibrium game G player i,
Ei ((i , ), ht , kt ) Ei ((0i , ), ht , kt )
strategy 0i , history ht coordination signal kt .
subgame-perfect equilibrium, players play best-response strategy given
history play, including histories cannot occur follow equilibrium
strategy beginning. notion subgame-perfect equilibria eliminates way
non-credible threats, equilibria player threatens someone else strategy
player might prefer avoid supposed executed.
2.3 Price Anonymity
Section 1, seen simple resource-allocation game, symmetric
equilibrium leads significantly lower payoff asymmetric equilibria. Symmetry
equilibria natural requirement players same, i.e. anonymous.
much social payoff sacrifice requirement symmetry? Inspired
price anarchy Koutsoupias Papadimitriou (1999), propose price
anonymity measure efficient given symmetric strategy vector (the term
price anonymity used previously different context Bonnet & Raynal, 2011).
given symmetric strategy vector stage game , calculate ratio
social payoff efficient (potentially asymmetric) Nash equilibrium
game, social payoff strategy vector . formal definition follows:
329

fiCigler & Faltings

Definition 16. (Price anonymity Nash equilibrium) Let G symmetric
game, let = (1 , 2 , . . . , N ) symmetric Nash equilibrium (that i, j : = j ),
let (mixed) Nash equilibrium game G maximum social payoff.
define price anonymity strategy vector follows:
RG () :=

E( )
.
E()

Definition 17. (Price anonymity stage game) Let G symmetric game,
) symmetric Nash equilibrium minimal social payoff,
let = (1 , 2 , . . . , N
let (mixed) Nash equilibrium game G maximum social payoff.
define price anonymity game G follows:
RG :=

E( )
.
E( )

infinitely repeated games, define price anonymity subgame-perfect
equilibria:
Definition 18. (Price anonymity repeated game) Let G symmetric game,
let = (1 , 2 , . . . , N ) symmetric subgame-perfect equilibrium minimal social
payoff, let subgame-perfect equilibrium game G maximum social
payoff. define price anonymity game G follows:
RG :=

E()
.
E( )

2.4 Conventions Implementations
shown example 2-agent, 1-resource allocation game Section 1,
exist symmetric games nevertheless asymmetric efficient equilibria.
allow central coordination device, agents play symmetric efficient
correlated equilibrium selects randomly set efficient Nash equilibria. Without device, stage game, way reach symmetric efficient outcome
equilibrium.
However, agents play game repeatedly, use history play
condition strategy. two agents different histories, take different
actions future. first round game though, history empty
everyone. Therefore, symmetric strategy players randomize order ever
reach point histories agents distinct.
Bhaskar (2000) considered problem playing asymmetric outcomes stage
game using symmetric strategy repeated game. work considers games 2
players 2 actions, 1-resource allocation game. idea two players start playing randomly, using probability distribution actions.
randomize reach round happen play pure-strategy Nash
equilibrium (that is, take different action each). call round asynchrony
round. Then, agents start following so-called convention. convention maps
asymmetric pure-strategy Nash equilibrium (potentially asymmetric) strategy vector
agents adopt.
330

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

already mentioned two basic conventions proposed Bhaskar (2000):
bourgeois egalitarian convention. 1-resource allocation game, asynchrony
round, one agent chooses action one chooses . call agent
chose asynchrony round winner. agent loser. bourgeois
convention guarantees agents keep playing NE forever after. way,
winner forever guaranteed higher payoff loser. egalitarian
convention, players alternate two pure-strategy Nash equilibria. way
payoffs winner loser closer.
infinitely repeated game discounting, social payoff depend two
things: discount factor , probability collision, probability
players play action A. big difference winner loser
payoff, losers fight back harder, play preferred action
higher probability. increase probability collision. egalitarian
convention, payoffs loser closer winner. Therefore, agents
collide less often, reach asynchrony faster.
another example convention, Kuzmics et al. (2010) analyze Nash demand
game. Nash demand game game N players choose N actions
labeled 1, . . . , N . players choose distinct action, player receives payoff
equal label chosen action. two players chose
action, every player (including chose action alone) receives zero payoff.
pure-strategy Nash equilibrium, players choose different action. Naturally,
player prefers equilibrium one chose action N .
Nash demand game, define bourgeois egalitarian conventions.
Kuzmics et al. (2010) define three notions payoff symmetry:
Ex-ante agents expected payoffs game starts.
Ex-post agents expected payoffs asynchrony occurs (regardless
winner).
Strong ex-post agents payoff along realization play.
bourgeois convention ex-ante payoff symmetric, since asynchrony occurs, winner gets higher payoff loser. egalitarian convention strong
ex-post payoff symmetric. fact, Kuzmics et al. (2010) show Nash demand
game, convention socially efficient, must strong ex-post payoff symmetric.
intuition order maximize social efficiency, want reach asynchrony fast
possible. possible agents choose actions uniformly random.
indifferent action choose moment
asynchrony occurs.
formally define convention augmented repeated game N agents.
Definition 19. (Convention) Let G = (N , A, u)
let G repeated version game G.
maps vector pure-strategy Nash equilibria
= (a1 , a2 , . . . , aK ) vector strategies
331

symmetric normal form game
define convention function
game G signal value
repeated game G,

fiCigler & Faltings

permutation : N N set players,
(((a1 ), . . . , (aK ))) = ((a1 , a2 , . . . , aK ))

(3)

is, convention permutation permutation convention (here denotes
strategy player i). strategies different coordination signal value.

use notation (a) := a(1) , . . . , a(N ) , ((a)) := (1) (a), . . . , (N ) (a)
denote permutation history vector using , permutation strategy
vectors respectively.
definition convention generalizes definition Bhaskar (2000) gave symmetric
games 2 players two actions , . Bhaskar defined convention mapping
set Nash equilibrium action profiles {(, ), (, )} set strategies
players alternate strategy profiles (, ) (, ) order. definition,
convention maps Nash equilibrium stage game strategy profile, provided
satisfies permutation condition.
Intuitively, convention prescribes agent potentially different role. problem
anonymous agents learn role. call learning algorithm
use implementation convention.
Definition 20. (Implementation) Let G infinitely repeated game, let
convention defined game. implementation convention strategy
vector infinitely repeated game, function assigns
: (ht , kt ) 7 (A1 ) . . . (AN ),
satisfies following conditions:
Let ht history game time t.
1. players already played pure-strategy Nash equilibrium coordination signals k K round t0 < (t0 round played
NE last signal), follow strategy prescribed convention
history ht \ ht0 (that is, history round t0 + 1 onwards).
2. Otherwise, let kt signal observed current round, let vector =
(a1 , a2 , . . . , aK ) ak action vector last round signal
k observed (if signal k observed yet, define ak = ). Then, actions
players current round depend vector (abusing notation,
write (ht , kt ) = (a, kt )), permutation : {1, 2, . . . , N }
{1, 2, . . . , N },

(,1 ((a), kt ), . . . , ,N ((a), kt )) = ,(1) (a, kt ), . . . , ,(N ) (a, kt ) ,
strategy current round depends actions played
last round signal observed, current coordination signal.
Section 3, concerned equilibrium strategies resource allocation
game. is, look symmetric subgame-perfect equilibria. construct
equilibria, define concepts equilibrium convention, equilibrium
implementation.
332

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Definition 21. (Equilibrium convention) Let G infinitely repeated game, let
convention. say convention equilibrium convention
every vector pure-strategy Nash equilibria = (a1 , . . . , aK ), (a) vector subgameperfect equilibria game G.
Definition 22. (Equilibrium implementation) Let G infinitely repeated game,
equilibrium convention, implementation convention . say
equilibrium implementation subgame-perfect equilibrium.

3. Resource Allocation Game
section, first formally define resource allocation game, discuss
Nash equilibria. show equilibrium convention resource
allocation game, exists equilibrium implementation.
3.1 Definitions
first define resource allocation game, restricted notions uniform convention uniform implementation.
Definition 23. (Resource allocation game) resource allocation game GN,C game
N agents. agent access one C identical resources. agent chooses
action ai Ai = {Y, A1 , A2 , . . . , AC }, action ai = means yield, action
ai = Ac means access resource c. resources identical, define
special meta-action ai = A. take action means choose access, choose
resource uniformly random set available resources.
payoff function agent defined follows:

0
ai =



1
ai 6= Y,
ui (a1 , . . . , ai , . . . , ) :=
(4)
j
6= i, aj 6= ai



< 0 otherwise
game set pure strategy NEs C agents access resource ci
N C agents not. symmetric mixed strategy NE agent
decides play action probability

(
! )
||
Pr(ai > 0) := min C 1 N 1
,1 .
(5)
1 + ||
Note high enough values C, agents always choose access. 1
Since assume resources identical, agents start following
convention, expected future payoff shouldnt depend resource
1. resource allocation game defined instance class games known potential games
(Monderer & Shapley, 1996). (exact) potential game, exists potential function : R
00
ai Ai , a0i , ai Ai ,
(a0i , ai ) (a00i , ai ) = ui (a0i , ai ) ui (a00i , ai ).

333

fiCigler & Faltings

accessed Nash equilibrium. therefore restrict so-called uniform
conventions:
Definition 24. (Uniform convention) Let GN,C resource allocation game, GN,C
infinitely repeated version. Let convention. say convention
uniform convention, following holds: Let = (a1 , a2 , . . . , aK ) vector purestrategy Nash equilibria coordination signal. Let player i, ci number
signals player accesses resource action vector a.
i, j : ci = cj = Ei ((a)) = Ej ((a)).
is, number signals two players access resource
same, expected payoff remainder game too.
Definition 25. (Losers, winners, claimed unclaimed resources) Let GN,C
infinitely repeated resource allocation game, let ht history play round t,
let ak = (ak1 , ak2 , . . . , akN ) action vector played last round signal k
observed.
Player winner signal k aki = Ai players j 6= i, akj 6= Ai ;
Player loser signal k otherwise;
Resource c claimed signal k, exists exactly one player aki = Ac ;
Resource c unclaimed signal k otherwise.
signal k never observed before, players losers resources
unclaimed signal k.
Definition 26. (Uniform implementation) Let GN,C infinitely repeated resource
allocation game, let uniform convention. uniform implementation defined
follows: Let ht history game time t, let kt signal observed
current round.
1. players already played pure-strategy Nash equilibrium coordination signals follow strategy prescribed convention .
2. Otherwise, let n number losers signal kt , let c number
unclaimed resources signal k. strategy prescribed implementation
round following:
action vector co occupied resources, nA agents access resource,
exact potential function resource allocation game
(a) := co + (nA co ).
Exact potential games referred congestion games (Rosenthal, 1973). Finite versions
games always guaranteed pure-strategy Nash equilibrium. Moreover, agents
reach pure-strategy Nash equilibrium starting arbitrary action vector a0 iteratively
playing best-response action, one one. players anonymous update strategies
simultaneously, study paper, doesnt hold. Hence, theory potential games cannot
applied scenario study paper.

334

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Agents follow implementation

Asynchrony

Initial state

Agents follow
convention

n=4
c=3

n=3
c=2

n=2
c=1

n=1
c=0

Figure 1: Learning play convention resource allocation game N = 4 agents
C = 3 resources. state, denote number losers
current state n, number unclaimed resources c. Winners denoted
black circles, losers light grey circles. asynchrony state,
3 winners one loser. Arrows indicate possible transitions
states. players reach asynchrony state, start following
convention next round on.

player winner signal kt , access resource
last time signal kt observed.
player loser, access choose access unclaimed resource r
p
probability 0 (n,c)
1. probability accessing claimed resource
c
zero.
remainder section, instead studying general strategies repeated
game, limit strategies uniform implementation.
Figure 1 shows agents learn follow convention N = 4 C = 3.
Assume players adopt convention , use implementation . Initially,
losers, implementation prescribes strategy them.
agent accesses resource alone, becomes winner access
resource agents reach asynchrony round (a state resource accessed
exactly one agent).
Definition 27. (Expected payoff functions EA EY ) Let GN,C infinitely
repeated resource allocation game, let uniform convention equilibrium
implementation. Let ht history game round t, k K,
Nash equilibrium reached (and convention activated yet).
Let nk number losers signal k K ck number unclaimed resources
signal k K. Let p = (pn1 ,c1 , . . . , pnK ,cK ) access probability losers
335

fiCigler & Faltings

signal k K. Let kt currently observed coordination signal. Let w (nw )
expected payoff new winner (player loser previous rounds becomes
winner round t) given nw new winners round t. Let l (nw )
expected payoff player stays loser, nw new winners round t.
Assume player loser signal kt . define expected payoff functions EA
EY takes action (or ) signal kt , adopts strategy prescribed
implementation signals:
EA (p, kt ) :=
min(n,c)

X

[Pr( wins & nw winners|A)w (nw ) + Pr( loses & nw winners|A)( + l (nw ))]

nw =1







K
X






+ Pr(0 winners|A) +
E
(p,
k)
+
(p
E
(p,
l)
+
(1

p
)E
(p,
l))
n
,c
n
,c



l
l
l
l

K
l=1
l6=k

(6)
min(n,c)

EY (p, k) :=

X

Pr(nw winners|Y ) l (nw )

nw =1





K
X


EY (p, k) +
(pnl ,cl EA (p, l) + (1 pnl ,cl )EY (p, l))
+ Pr(0 winners|Y )


K

(7)

l=1
l6=k

3.2 Existence Equilibrium Implementation
ready prove uniform equilibrium convention, exists
equilibrium implementation.
Lemma 1. signal k K, functions EA EY continuous p h0, 1iK .
Proof. probabilities Pr(nw winners|A) Pr(nw winners|Y ) continuous.
functions EA EY sums products continuous functions, must continuous.
Lemma 2. Functions EA EY well-defined k K p h0, 1iK .
Proof. fixed p, , functions EA EY define system 2K linear equations.
write system (I A)E = b, E = (EA,1 , . . . , EA,K , EY,1 , . . . , EY,K )
vector variables corresponding payoff functions, b R2K 2K 2K unit
matrix. matrix defined follows: first K rows correspond variables EA,k
second K rows correspond variables EY,k .
elements row k corresponding EA,k defined as:

l = k
Pr(0 winners|A, pnk ,ck ) K



0
l = K + k
Ak,l :=

Pr(0
winners|A,
p
)


p
l K, l 6= k

nk ,ck
nl ,cl

K


Pr(0 winners|A, pnk ,ck ) K (1 pnl ,cl ) K < l 2K, l 6= K + k
336

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

elements row K + k corresponding EY,k defined as:

AK+k,l


Pr(0 winners|Y, pnk ,ck )



0
:=
Pr(0
winners|Y, pnk ,ck )



Pr(0 winners|Y, pnk ,ck )


K

K

K




pnl ,cl
(1 pnl ,cl )

l =K +k
l=k
l K, l 6= k
K < l 2K, l 6= K + k

system equations unique solution matrix non-singular.
equivalent saying det(A) 6= 0.
PK
matrix diagonally dominant, aii >
j=1,j6=i |aij |.
P2K
0 < < 1, rows matrix sum l=1 Ak,l = Pr(0 winners|A, pnk ,ck )
P
1 < k K, 2K
l=1 AK+k,l = Pr(0 winners|Y, pnk ,ck ) K < K + k 2K.
known diagonally dominant matrices non-singular (Taussky, 1949). Therefore, unique solution E system exists functions EA , EY well-defined
fixed p, .
Lemma 3. exists p k K, one following true:
1. pk = 0 EY (p , k) > EA (p , k);
2. pk = 1 EA (p , k) > EY (p , k);
3. 0 < pk < 1 EA (p , k) = EY (p , k).
p defines symmetric best-response strategy losers.
Proof. Fix . show arbitrary p every signal k K,
exists p0k satisfies one three conditions Lemma 3 above.
contradiction, assume p0k = 0, EY (p0 , k) EA (p0 , k) p0k = 1,
EA (p0 , k) EY (p0 , k). fact functions EA EY well-defined
continuous 0 pk 1, must intersect 0 < p0k < 1.
this, must exist vector p k K, conditions
Lemma 3 satisfied.
Corollary 1. Let GN,C infinitely repeated resource allocation game. uniform
equilibrium convention game GN,C , exists equilibrium implementation .
illustrate different equilibrium payoffs agents get adopt different
conventions, consider resource allocation game N = 4 agents C = 1 (to
simplify presentation, assume K = 1). Assume round t, resource
claimed yet, n = 4 losers c = 1 unclaimed resource.
agent becomes winner round t, agents adopt extended uniform convention
prescribes strategies on.
comparison, assume agents adopt either convention 1 , convention

2 . adopt convention 1 , winners expected payoff w1 = 4, losers
expected payoff l = 0. hand, adopt convention 2 , winners
1

expected payoff w2 = 2, losers expected payoff l2 = 1.
337

fiCigler & Faltings

(a) Convention 1

(b) Convention 2

Figure 2: Example expected payoff functions resource allocation game N = 4
agents, C = 1 resources, cost collision = 2 discount factor = 0.8,
1 E 1 expected payoff
given access probability p. function EA

functions accessing yielding, agents use extended convention
2 E 2 expected payoff functions agents use
1 . Similarly, EA

extended convention 2 . Convention 1 expected winner payoff w1 = 4,
expected loser payoff l = 0. Convention 2 expected winner payoff
1

w2 = 2 expected loser payoff l2 = 1.
equilibrium implementation 1 convention 1 , agents access
resource probability p1 , expected payoff E1 = 0.
equilibrium implementation 2 convention 2 , agents access resource
probability p2 < p1 , expected payoff E2 > E1 = 0.

1 E 1 convention , E 2
Figure 2 shows expected payoff functions (EA
1


2

EY convention 2 ), depending access probability p. see
equilibrium implementation payoff E2 convention 2 higher equilibrium
payoff E1 convention 1 , even though sum winner loser payoffs higher
convention 1 . loser receives positive payoff agents adopt
convention 2 ; agents less likely fight become winner, access
resource lower probability p2 < p1 . way, less collisions,
agents receive higher expected social payoff adopt convention 2 .

3.3 Calculating Equilibrium
symmetric subgame-perfect equilibrium guaranteed exist, order actually
play it, agents need able calculate it. always possible obtain
338

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

closed form probability accessing resource. Therefore, show
calculate equilibrium strategy numerically.
Let p probability vector k signal. Let p0 := (p1 , p2 , . . . , pk = 0, . . . , pK ), i.e.
vector p pk set 0. Let p1 := (p1 , p2 , . . . , pk = 1, . . . , pK ). Lemma 3 know
either EY (p0 , k) > EA (p0 , k), EA (p1 , k) > EY (p1 , k) two functions intersect
0 pk 1. Furthermore, know EA (p0 , k) = w (c) since probability
successfully claiming resource 1 everyone else yields, EY (p0 , k) = 0.
Therefore, EY (p0 , k) > EA (p0 , k) iff w (c) > 0.
W.l.o.g, assume w (c) > 0. Algorithm 1 shows calculate
probability vector.
Algorithm 1 Calculating equilibrium probabilities
subset {1, 2, . . . , K}
Let system equations

/ S, contains two equations E(p, i). One corresponding EA (p, i), one
EY (p, i) (see Equations 6 7).
j S, set pj := 1. contains one equation E(p, j), corresponding
EA (p, j).
system 2K |S| equations 2K |S| variables.
Solve numerically system equations .
exists solution
/ S, 0 pi 1
found solution
break;
end
end
numerical algorithm complexity exponential K, therefore suitable small K. Section 4.2.3, show conditions access probabilities easy compute define -equilibrium repeated game. is,
agent gain factor deviating prescribed strategy.

4. Actual Conventions
previous section, shown find symmetric way reach
convention, provided agents access resources certain probability.
shown calculate resource access probability every stage game.
section, would show specific examples conventions agents
adopt, discuss properties.
4.1 Bourgeois Convention
bourgeois convention simplest one. agent accessed resource
successfully first time, keep accessing forever. say agent
claimed resource. dont need coordination signal implement it, set
K := 1.
339

fiCigler & Faltings

describe decision problem point view agent . Assume
N agents C resources. round t, let ct number resources
claimed yet, nt := N C +ct number players claimed
resource yet. Assume players besides use following strategy:
player claimed resource previously, keep accessing it;
player hasnt claimed resource yet (she loser), choose access
probability pct choose actual resource access uniformly random.
Definition 28. (Expected payoff function Bourgeois convention) Let p :=
(p1 , p2 , . . . , pC ) probability vector, pc probability
losers access c unclaimed resources. define expected payoff
function player choose access (play A, choose access
choose resource uniformly random) yield (play ), respectively:



p n1
1
p n1
EA (p, c) := 1

+ 1 1
()
c
1
c
c
X
Pr( loses nw = l|A) E(p, c l);
+


l=0

EY (p, c) :=

c
X

Pr(nw = l|Y ) E(p, c l);

l=0

equations, E(p, c) = max {EA (p, c), EY (p, c)}.
Lemma 4. p 1 c C, E(p, c) 0.
Proof. matter strategy opponents, agent chooses always yield,
payoff 0.
Lemma 5. Let p probability vector defines strategies losers,
let ct number unclaimed resources round t. c ct , EA (p, c) = EY (p, c),
c ct , E(p, c) = 0.
Proof. ct unclaimed resources round t, every following round t0
c ct unclaimed resources (in bourgeois convention, agents never release
claimed resources). agent indifferent actions every round
following round t, means indifferent strategy subgame
prescribes every round strategy. (expected) payoff strategy
prescribes always 0. Therefore, expected payoff subgame strategy
must 0 well.
purpose problem, unclaimed resources identical. Therefore
parameter losers strategy probability agents decide
access resource chosen uniformly random. Lemma 5 shows necessary
condition p agent indifferent. following lemma shows p exists
unique.
340

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Lemma 6. Assumeat timer

ct unclaimed resources. Let c ct unclaimed
||
resources pc = c 1 n1 ||+ 1
probability losers play A.
1

c ct unclaimed resources, agent indifferent yielding accessing.
given c, probability unique interval [0, c].
Proof. Lemma 5 know agent indifferent (i.e. EA (p, c) = EY (p, c)),
must E(p, c) = 0 1 c ct .
Definition 28, expected profit agent playing following
best-response strategy (with zero payoff)




pc n1
1
pc n1
EA (p, c) = 1

+ 1 1
()
c
1
c
(8)
+ Pr( loses nw = 0|A) E(p, c).
pc probability losers access. want EA (p, c) =
EY (p, c) = 0. holds pc defined lemma above.
Function EA decreasing pc interval [0, c], function EY constantly 0.
Therefore, intersection unique interval [0, c].
Lemma 7. Assume opponents havent claimed resource access resource probability p < pc . best-response agent access.
Proof. probability agent claims successfully resource playing

p n1
Pr(claim resource|A) := 1
(9)
c
probability increases p decreases. Therefore expected profit playing
increasing p decreases, whereas profit playing stays 0.
Theorem 8. Define agents strategy follows: c unclaimed resources,
play probability pc := min (1, pc ) (where pc defined Lemma 6). joint
strategy profile = (1 , 2 , . . . , N ) c, c = subgame-perfect equilibrium
infinitely repeated resource allocation game.
Proof. Lemma 6, pc < 1, agent indifferent playing playing A,
therefore happily follow strategy . Lemma 7, pc = 1 < pc , best response
agent play A, strategy prescribes.
Theorem 9. c N, pc = pc , E(p, c) = 0.
Proof. proceed induction.
c = 0, expected payoff trivially E(p, 0) = 0, free resources.
Let j < c, E(p, j) = 0 pc = pc . agent plays , expected payoff clearly 0
(it 0 0 future induction hypothesis). agent plays A,
expected payoff (by Definition 28):

pc n1
1

EA (p, c) := 1
c
1


c
(10)


X
pc n1
Pr( loses nw = l|A) E(p, c l)
+ 1 1
() +
c
l=0

341

fiCigler & Faltings

way pc defined, induction hypothesis E(p, j) = 0
j < c, get
EA (p, c) := Pr( loses nw = 0|A) E(c, )
= Pr( loses nw = 0|A) max{EA (p, c), EY (p, c)}

(11)

Since Pr( loses nw = 0|A) < 1, must EA (p, c) = 0.
Theorem 10. pc < pc , E(p, c) > 0.
Proof. Lemma 7 know pc < pc , best response access,
E(p, c) = EA (p, c). Lemma 4 know j, E(p, j) 0. pc < pc ,
Definition 28 see E(p, c) > 0.
Theorem 10 shows enough resources pc 1, expected payoff
agents, even access time, positive.
Given number agents N , discount factor collision cost , necessary
number resources c expected payoff positive is:
c :=
1

1
r
n1

||
1
||+ 1

(12)

Figure 3 illustrates value c depending N , , respectively. Figure 3a shows
number resources c increases N increases naturally, agents need
resources.
Figure 3b shows hand increasing discount factor , necessary number resources drops. high , agents almost indifferent
winning winning later. Section 4.2.3, explore idea
detail show high enough delta, strategy prescribes agents
access constant probability reach asynchrony -equilibrium
resource allocation game.
Finally, Figure 3c shows increasing number resources necessary
bourgeois convention positive payoff, collision cost increases. increase
almost linear . higher cost collision, lower expected
payoff accessing EA . bourgeois convention positive expected payoff,
need EA > 0 0 p 1.
Let us look price anonymity bourgeois convention (as defined
Definition 16).
Theorem 11. price anonymity bourgeois convention infinite.
Proof. highest social payoff strategy profile achieve N -agent, C-resource
allocation game (N C)
C
max E( ) :=
.
(13)
1
achieved every round, every resource accessed exactly one agent.
strategy profile obviously asymmetric.
342

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

25

20

200

20
15

150

15
C*

C*
10

C*
100

10
5
0
0

50

5
5

10
N

15

20

0
0

0.5


(a) N

1

0
0

50


(b)

100

(c)

Figure 3: Minimum number resources c needed expected payoff bourgeois
convention positive, depending N , , . One parameter varying,
parameters set N = 10, = 0.8, = 2. varying N ,
dashed line shows c = N .

3.5
N=3
N=4
3

2.5
R
2

1.5

1
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Figure 4: Market convention: Price anonymity C = 1, K = N , = 0.5 varying .

agent knew part bourgeois convention play beginning
game, convention would socially efficient. However, agents anonymous,
learn part convention play randomization.
bourgeois convention small C relative N , randomization
agents indifferent accessing resource yielding, expected
payoff zero. Therefore, price anonymity infinite.
4.2 Market Convention
saw bourgeois convention leads zero expected social payoff small
number resources. would improve expected payoff here. bourgeois
convention, agents receive zero expected payoff demand resources
high compared supply. need decrease demand, increasing
343

fiCigler & Faltings

2.5
N=3
N=4

2
R

1.5

1
0

1

2

3

4

5

Figure 5: Market convention: Price anonymity C = 1, K = N , = 0.9 varying .

supply. often achieved markets. Shneidman et al. (2005) present
reasons markets might appropriate resource allocation.
assume following:
Agents observe K 1 coordination signals.
Agents decreasing marginal utility access resource often.
pay fixed price per successful access, point agent prefers
access resource one signal K. practice, could implemented central authority observes convergence rate agents,
dynamically increases decreases price achieve convergence.
assumptions define call market convention, winners access claimed resource signals observed first claimed it.
price agents pay serves decrease demand. coordination signal effectively increases supply resources K-times, resource allocation may
different signal values.
know implement convention C 1 resources using symmetric
play (see Section 3). small K, use Algorithm 1 calculate access
probabilities. ease exposition, first describe market convention
C = 1 resource. generalize description C > 1 resources.
4.2.1 One Resource
agent accesses resource one signal, need K = N signals make
sure everyone gets access once.
N -agent, 1-resource case, imagine still n agents playing (N n)
agents already claimed resource signal. Imagine n agents
observe one n signals resource claimed.
344

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Assume agents access resource probability pn . expected payoff
accessing resource agent



1
EA (pn , n) := (1 pn )
1+

N 1




n
+ 1 (1 pn )n1 +
EA (pn , n)
N (N n)
n1



(14)

expected payoff yielding agent

EY (pn , n) := (n 1)pn (1 pn )n2 E(n 1)


n
EY (pn , n)
+ 1 (n 1)pn (1 pn )n2
N (N n)

(15)

pn = 1, accessing resource always lead collision, payoff
accessing negative. pn = 0, accessing resource always claim it,
payoff accessing positive. equilibrium, agents indifferent
accessing yielding. Therefore, want find pn EA (pn , n) =
EY (pn , n) = E(n).
Finding closed form expression pn difficult, use Algorithm 1
calculate probability, well expected payoff E(n), numerically (albeit practice
small K).
Figures 4 5 show price anonymity market convention (as defined
Definition 16) varying discount factor , varying cost collision , respectively.
Section 4.1, price anonymity C = 1 . contrast, market
convention price cases finite relatively small.
4.2.2 Multiple Resources
Assume C 1. given round, denote c := (c1 , c2 , . . . , cK )
vector resources claimed yet value coordination
signal k {1, 2, . . . , K}. denote n number players claimed
resource yet signal value. Finally, let p := (pn,c1 , pn,c2 , . . . , pn,cK ) vector
probabilities, pn,ck denotes probability loser access resource
signal k K, given ck resources available.
Corollary 1, know market convention, exists equilibrium
implementation. look exactly? order able express (albeit
numerically), need define expected payoff functions players receive
action.
345

fiCigler & Faltings

number losers n, observed coordination signal k vectors p c,
define expected payoff functions player takes action , respectively:
EA (p, c, n, k) := Pr( wins|A) w + (1 Pr( wins|A)) ()
min(ck ,n)

+

X

Pr( loses, nw winners|A) E(p, (ck nw , ck ), n nw )

nw =1

+ Pr(nw = 0|A)


EA (p, c, n, k)
K



+ Pr(nw = 0|A)
K

K
X
l=1
l6=k

(16)



(pn,cl EA (p, c, n, l) + (1 pn,cl )EY (p, c, n, l))


min(n,c)

EY (p, c, n, k) :=

X

Pr(nw winners|Y ) E(p, (ck nw , ck ), n nw )

nw =1


+ Pr(nw = 0|Y )



K
X


EY (p, c, n, k) +
(pn,cl EA (p, c, n, l) + (1 pn,cl )EY (p, c, n, l))


K
l=1
l6=k

(17)
equations above, E(p, c, n) expected payoff players observe
coordination signal. defined
E(p, c, n) :=

K
1 X
E(p, c, n, k).
K
k=1


winner payoff w defined w := 1 + K(1)
. winner
access one signal: current round, future round
probability K1 .
probabilities nw winners cases?
start simplest case, Pr(nw winners|Y ), given n agents (including
agent ), ck resources agents except play action probability pk .
problem calculating probability similar well-known balls-andbins problem (Raab & Steger, 1998). balls-and-bins problem assume
n balls randomly assigned one c bins. goal find
probability bins exactly one ball them. express probability
(n, c, i).
Ni ways pick balls, place bins bin
one ball, place remaining n balls remaining c bins randomly,


c n
Ni :=
i! (c i)ni


346

(18)

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

total cn ways arrange n balls c bins. Therefore, probability
(n, c, i) total number ways place n balls c bins exactly one
ball obtained generalized inclusion-exclusion principle:
1
(n, c, i) := n
c
1
= n
c
=

min(c,n)

X

ji

(1)

j=i
min(c,n)

X

ji

(1)

j=i


j
Nj



j
c n
j! (c j)nj

j
j

(19)



min(c,n)
nj
X
n! c
ji c (c j)
(1)
.
j (n j)!
cn
j=i


ci
simplification above, use absorption identity ji jc = ci ji
.
use function calculate Pr(nw winners|Y )? n 1 agents (other
) decide play action probability pk , choose resource access
randomly. agents choose access resource correspond balls-and-bins
problem. Therefore,
Pr(nw winners|Y ) :=

n1
X


n1
pk (1 pk )n1i (i, c, nw ).


i=0

(20)

calculate probability Pr( wins|A), proceed follows. assume w.l.o.g
accesses resource 1. agents (out n 1) choose action
A. need choose resource 1. Therefore,
Pr( wins|A) :=

n1
X
i=0




n1
1

n1i
pk (1 pk )
1
c


(21)

Finally, calculate probability Pr( loses, nw winners|A), use
balls-and-bins problem. Given 0 n 1 agents choose action A,
0 j agents choose resource agent . remaining
(i j) agents face balls-and-bins problem c 1 bins (1 bin already occupied
agent ). Therefore,
Pr( loses, nw winners|A) :=

n1
j
X n 1
X

1
1 ij
1
(i j, c 1, nw )
pik (1 pk )n1i

j
c
c
i=1

j=1

(22)
expressed expected payoff functions EA EY explicitly,
use Algorithm 1 calculate equilibrium access probabilities expected payoffs.
Figures 6 7 show price anonymity market convention C = 3, K = 2
N = C K = 6. discount factor grows, price anonymity decreases
347

fiCigler & Faltings

600

Price anonymity

500

400

300

200

100

0
0.1

0.2

0.3

0.4

0.5


0.6

0.7

0.8

0.9

Figure 6: Market convention: Price anonymity N = 6, C = 3, K = 2, = 0.5
varying .

2.6
2.5

Price anonymity

2.4
2.3
2.2
2.1
2
1.9
1.8
1.7
0

1

2

3

4

5



Figure 7: Market convention: Price anonymity N = 6, C = 3, K = 2, = 0.9
varying .

(note Figure 6 y-axis logarithmic). small , benefit
winning resource right away much higher payoff winning later.
hand, gets closer 1, agents dont care whether win later.
Since market convention guarantees everyone able access resource
signal value, 1, expected payoff winner losers
same. Also, 1, cost agents pay learning convention decreases
compared payoff obtain learnt it.
increases, price anonymity increases. cost collision direct
effect expected payoff functions EA EY . Therefore, expected equilibrium
348

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

payoff higher cost lower. Changing effect optimal
asymmetric outcome though, since agents dont pay cost
collisions.
4.2.3 -equilibrium
Calculating equilibrium access probabilities market convention difficult
need use numerical algorithm, number signals K grows, number
equations grows exponentially. Therefore, would find access probabilities
easy compute agents incentive deviate small. Indeed,
game theory often interested -equilibria, agent improve payoff
> 0.
market pricing ensures agent wants access resource one signal
value. doesnt depend access probabilities agents, utility
functions. agents converge asynchrony round (i.e. pure-strategy NE
resource allocation every signal value), future expected payoff
K 1
,
1

(23)

agent improve payoff deviating since players playing PSNE
stage game round.
agents havent claimed resource yet play action constant
probability 0 < pconst < 1, expected time reach asynchrony finite.
(from properties balls-and-bins problem, see Section 4.3, Raab & Steger,
1998). prove following theorem:
Theorem 12. Suppose N -agent, C-resource allocation game, agents adopt
market convention following implementation: agents havent claimed
resource yet play action constant probability pconst (we call constantprobability implementation). Let E() expected payoff agent case
given discount factor . Let E 0 () expected payoff best-response strategy
convention implementation.
> 0, exists 0 < 0 < 1 , 0 < 1,
E()
> 1 .
E 0 ()

(24)

Proof. market pricing, agent wants access one resource one
value coordination signal. best-response payoff E 0
E 0 ()

K 1
,
1

(25)

matter strategy agents play.
agents adopt market convention constant-probability implementation, every round converge PSNE, receive payoff
< 0 (the collision cost) 1. reach PSNE, expected payoff
K 1
1
349

(26)

fiCigler & Faltings

stated above. therefore say
E()


X
i=0


1
+ K 1
Pr(agents reach PSNE steps)
1
1



(27)

define random variable X X = agents reach PSNE
exactly steps. properties expected value, ee


(1 E X ) + K 1 E X
E()
.
(28)
1
function (x) := x convex function. Jensens inequality (1906), know


E X E[X] .
(29)
Therefore,

1 E[X] + K 1 E[X]
E()

.
E 0 ()
K 1

(30)

expected time E[X] reach PSNE finite doesnt depend ,
treat constant. E[X] continuous , monotonous lim1 E[X] = 1,
see given > 0, exists 0 < 0 < 1 , 0 < 1,
E()
> 1 .
E 0 ()

(31)

ensuring agent wants access resource one signal value,
market convention makes cooperative strategy previous work (Cigler &
Faltings, 2011) almost rational.
4.3 Expected Convergence Time
section, analyze expected number rounds agents need
converge perfect allocation resources (one resources used exactly one,
collisions). first prove upper bound expected number
steps convergence bourgeois convention, present experiments
market convention.
4.3.1 Bourgeois Convention
order prove convergence bourgeois convention, describe execution
Markov chain. Markov chain describing execution bourgeois convention
N -agent, C-resource allocation game chain whose state round Xt {0, 1, . . . , C},
Xt = c means c unclaimed resources round t.
interested expected number rounds take Markov chain
reach state 0 started state C. called expected hitting time:
350

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Definition 29. (Norris, 1998) (Hitting time) Let (Xt )t0 Markov chain state
space I. Given probability space (, , Pr), hitting time subset random
variable H : {0, 1, . . .} {} given
H () = inf{t 0 : Xt () A}
general, expected hitting time set states found solving
system linear equations:
Theorem 13. vector mean hitting times k = E(H ) = (kiA : I) minimal
non-negative solution system linear equations

ki = 0 P

(32)

kiA = 1 + j
p
k
/A
ij j
/
Solving analytically Markov chain however difficult. Fortunately,
Markov chain one absorbing state = 0, move state
j j, use following theorem derive upper bound hitting time
(proved Rego, 1992):
Theorem 14. Let = {0}.
1 : E(Xt+1 |Xt = i) <
> 1,


kiA < log +





1

order use Theorem 14, need calculate expected state E(Xt+1 |Xt = c).
Lemma 15. Let Xt = c, let n := N C + c agents claimed
n1
resource claimed
resource yet. Let us denote q(n, c) = pc n 1 pc
round agents play subgame-perfect equilibrium strategy vector described above.
next expected state
E(Xt+1 |Xt = c) := (1 q(n, c)) c
Proof. resource i, denote Wi random variable, Wi = 1 resource
claimed round t, Wi = 0 otherwise. random variable Wi Bernoullidistributed probability q(n, c).
next expected state
" c
#
c
X
X
E(Xt+1 |Xt = c) = c E
Wi = c
E[Wi ] = (1 q(n, c)) c,
(33)
i=1

i=1

E[Wi ] = q(n, c).
following lemmas, denote
:=

||
1
|| + 1
351

(34)

fiCigler & Faltings

Lemma 16. given collision cost discount factor , exists constant
0 < < 1 c n, p < 1.
Proof. According
definition subgame-perfect equilibrium strategy, p := c


n1
1
.
want p < 1, equivalent


n1
c 1
<1
(35)


1 n1
1
<
(36)
c
(37)
know c n,



n1
1 n1
1
1
1
e .
c
n

(38)

therefore set e < , access probability p < 1.
Lemma 17. given , exists 0 < < 1 c,
E(Xt+1 |Xt = c) (1 ) c

Proof. prove lemma two cases: p <
1 andwhen
p = 1.
First, let us prove case p < 1, p = c 1 n1 . Therefore, q(n, c) =


1 n1 n . shown n,


q(n, c) = 1


n log .

n1

let p = 1. Lemma 16 must c > n.



n1
c
1 n1
1
q(n, c) := 1
1
,
n
c
n
q(n, c) increasing c.


1

1
n

n1

e .

(39)

(40)

(41)

fixed , , constants, set
:= min( e , log ).

(42)

above, proves lemma.
Theorem 18. expected time agents converge resource allocation
resources claimed O(log C).
352

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Proof. shown express expected convergence time expected
hitting time certain Markov chain.
Lemma 17 saw exists c,
E(Xt+1 |Xt = c) (1 ) c.
combine result Theorem 14 show expected hitting
time state C state 0


1
1
0
kN < dlog 1 Ce +
log C = O(log C),
(43)
1


constant.

4.3.2 Market Convention
market convention, unfortunately difficult express expected number
convergence steps closed-form expression. However, use linear programming
calculate expected number convergence steps given parameters N , C, K,
.
Markov chain market convention K signals C resources looks
follows: state time Vt {0, 1, . . . , C}K , Vtk denotes many resources
claimed signal k. initial state V0 V0k = C
k {1, . . . , K}. N C K,Pthe final state Vtk = 0 k. N < C K,
final states k{1,...,K} Vtk = C K N .
transition probabilities two states Vi Vj , Vi 6= Vj , following:
Suppose k : Vjk < Vik l 6= k : Vjl 6= Vil . Let us denote c := Vik , i.e. number
unclaimed resources state Vi signal k, n := N (C Vik ) number agents
claimed resource signal k state Vi .
Pr(Vt+1

n
1 X n
= Vj |Vt = Vi ) :=
p (1 pk )nm (m, c, Vik Vjk )
K
k

(44)

m=0

Otherwise Vj 6= Vi , Pr(Vt+1 = Vj |Vt = Vi ) := 0.
Figure 8 shows expected number rounds converge varying discount factor
. Generally, would expect access probability increase increasing , since
profit winning resource increases. increase convergence
time. However, experiments influence convergence time negligible,
although observe slight increase increases. Figure 9 shows convergence
varying collision cost . close 0, convergence time remains stable. However,
high cost , convergence time increases linearly . case, high cost
collision drives resource access probability low, agents try avoid collisions
costs.
Figure 10 shows expected convergence increase number resources C
number agents N proportionally. increase convergence time still sub-linear
increase C.
353

fiCigler & Faltings

7.8

Convergence steps

7.78
7.76
7.74
7.72
7.7
7.68
7.66
0

0.2

0.4

0.6

0.8

1



Figure 8: Market convention: Expected number convergence steps given N = 6, C = 3,
K = 2, = 1.0 varying .

50
45

Convergence steps

40
35
30
25
20
15
10
5 4
10

2

10

0

10


2

10

4

10

Figure 9: Market convention: Expected number convergence steps given N = 6, C = 3,
K = 2, = 0.9 varying .

354

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

13
12

Convergence steps

11
10
9
8
7
6
5
4
1

1.5

2

2.5

3
C

3.5

4

4.5

5

Figure 10: Market convention: Expected number convergence steps given K = 2, = 0.9,
= 1.0 varying number resources C agents N = 2 C.

C&F11
Bourgeois
Egalitarian2
Market

ex-post fair
(X)1

X
X

efficient
X

X
?

equilibrium

X
X
X

Table 1: Properties conventions
4.4 Convention Properties
compare properties following conventions: C&F11, channel allocation
algorithm presented previous work (Cigler & Faltings, 2011); bourgeois egalitarian
conventions, presented Bhaskar (2000); market convention, presented above.
compare conventions according following properties:
Ex-post fairness expected payoff agents even asynchrony?
Efficiency convention maximize social welfare among possible conventions?
Equilibrium convention equilibrium implementation?
Table 1 summarizes properties conventions. C&F11 convention
approximately ex-post fair. fairness improving number coordination signals
increases, agents might worse payoff others. hand,
efficient, least discounting ( = 1). However, equilibrium
1. Fair asymptotically, N .
2. 2-agents, 1-resource games.

355

fiCigler & Faltings

repeated game. bourgeois convention neither fair efficient, fact
expected payoff agents 0 (for small number resources). equilibrium
implementation though, since agents indifferent winner loser.
egalitarian convention fair, efficient equilibrium implementation. However,
defined games 2 agents 1 resource. Finally, market convention fair
equilibrium implementation. clearly efficient bourgeois
convention. Nevertheless, finding efficient convention remains open problem.

5. Folk Theorems Symmetric Equilibria
previous sections, analyzed special kind symmetric equilibria
resource allocation game. agents first followed Markovian implementation,
soon play pure-strategy NE, adopted convention. infinitely repeated
game discounting, set Nash equilibria characterized using so-called folk
theorem. name indicates known used well
first published, follow version described Fudenberg Maskin (1986).
Informally, folk theorem states infinitely repeated game, every feasible
individually rational payoff vector stage game, exists Nash equilibrium
repeated game average payoffs per round correspond stage game
payoff vector.
payoff vector individually rational Pareto-dominates minimax payoff
stage game. player i, minimax payoff
vi := min max ui (i , ).




(45)

simplify notation, Fudenberg Maskin (1986) normalize payoffs
) = (0, 0, . . . , 0). Let
minimax payoffs, (v1 , v2 , . . . , vN
U := {(v1 , . . . , vN )|(a1 , . . . , ) . . . s.t. u(a1 , . . . , ) = (v1 , . . . , vN )},
V := convex hull U,
V := {(v1 , . . . , vN ) V |vi > 0 i}.
set V set feasible payoffs stage games (that is, payoffs
achieved playing mixed correlated strategy). set V subset feasible
payoffs individually rational.
Theorem 19. (Fudenberg & Maskin, 1986) (v1 , . . . , vN ) V , discount
factor close enough 1, exists Nash equilibrium infinitely repeated game
discounting where, i, average payoff player vi .
idea proof follows: agents cycle prescribed sequence
game outcomes achieve desired payoffs. one player deviates, others
punish playing minimax strategy forever after.
focus far finding symmetric equilibrium strategies. folk theorem doesnt say anything whether equilibrium strategy symmetric, even
payoff vector symmetric. Nevertheless, define another class symmetric
356

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

strategies infinitely repeated game, one based conventions
implementations. strategies following form: players follow symmetric
(mixed) strategy stage game. one player deviates strategy, players
punish following minimax strategy. resource allocation game, minimax payoff (0, 0, . . . , 0) achieved mixed strategy Nash equilibrium.
Folk theorem, strategy sustained Nash equilibrium repeated
game (though necessarily subgame-perfect equilibrium).
symmetric strategy stage resource allocation game vector access probabilities q = (q1 , q2 , . . . , qC ) qc probability agent access resource c.
interested finding access probability vector q achieves highest expected
payoff.
given access probability vector q, expected payoff agent receives
follows:
C
X



E(q) :=
qj (1 qj )N 1 1 1 (1 qj )N 1 ||
(46)
j=1

Theorem 20. resource allocation game N = 2 agents C = 1 resource,
resource access probability maximizes expected payoff stage game
q =

1
1

.
2 1 + ||

(47)

Proof. calculate derivative expected payoff function Equation 46 N = 2
C = 1:
E(q)
= 1 2q (1 + ||)
q
Setting first derivative equal 0, get
q =

1
1

.
2 1 + ||

Since second derivative
2 E(q)
= 1 || < 0,
2q
probability q local maximum expected payoff function E(q).
Corollary 2. resource allocation game N = 2 agents C = 1 resource,
highest expected payoff symmetric strategy stage game
E =

1
1

.
4 1 + ||

(48)

Corollary 3. resource allocation game N = 2 agents C = 1 resource,
price anonymity strategy accesses optimal access probability q
4 (1 + ||).
357

fiCigler & Faltings

2

10

Folk theorem
Market convention

R 1
10

0

10

0

1

2

3

4

5



Figure 11: Price anonymity symmetric strategy following folk theorem,
compared price anonymity market convention N = 3, C = 1
varying cost collision .

general case resource allocation game N agents C resources,

46 (given constraint
PC find probability vector maximizes Equation
2
j=1 qj 1) using method Lagrangian multipliers .
P
2. goal maximize E(q1 , q2 , . . . , qC ) q0 + C
i=1 qi = 1 qi 0, q0
probability agent yields. Lagrangian function
(q0 , q1 , . . . , qC , ) := E(q1 , q2 , . . . , qC ) +

q0 +

C
X

!
qi 1 .

i=1

first partial derivatives

:=
q0

E
:=
+
qi
qi

(49)
(50)

= (1 ||) (1 qi )N 1 qi (1 + ||) (N 1) (1 qi )N 2 || + 1 C

:= q0 +


C
X

1.

(51)
(52)

i=1

necessary condition solution maximum
partial derivatives Lagrangian
P
function 0. Therefore, := 0 q0 := 1 C
i=1 qi . qi , 1 C find solution

= 0 using numerical root-finding algorithm. point partial derivatives
qi
zero, compare E(q) (finite) number extreme points.

358

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Figure 11 compares price anonymity folk-theorem-based symmetric strategy
price anonymity market convention, N = 3 agents C = 1 resource.
Since price anonymity folk theorem strategy doesnt depend discount
factor (it needs high enough strategy equilibrium), show
graph varying collision cost . price anonymity folk-theorem strategy
order magnitude higher price anonymity market convention.

6. Conclusions
paper, considered symmetric protocols rationally coordinate asymmetric,
efficient allocation infinitely repeated resource allocation game discounting N agents
C resources. assumed agents identical, resources
homogeneous. based work idea Bhaskar (2000): let agents choose
actions randomly, adopt certain convention. generalize work
Bhaskar arbitrary resource allocation problem N agents C resources.
show convention, exists symmetric subgame-perfect equilibrium
implements it. presented two conventions repeated resource allocation
game: bourgeois market convention. defined price anonymity ratio
expected social payoff best asymmetric strategy profile expected
social payoff given symmetric Nash equilibrium. showed price
anonymity bourgeois convention infinite (at least small number resources),
price anonymity market convention finite relatively small.
market convention reduces demand imposing price successful access,
time increasing supply agents condition strategy
global coordination signal k {1, . . . , K}. way, conflict agents
reduced. showed analytically agents adopt bourgeois convention,
converge perfect resource allocation polynomial time.
market convention, calculating equilibrium access probabilities difficult.
need use numerical algorithm, whose complexity exponential number
coordination signals K. However, market mechanism already makes sure agent
wants access resource one coordination signal. Therefore, showed
cooperative solution agents access resources constant probability
-equilibrium, given discount factor high enough.
future work, would investigate whether exist efficient conventions market convention (i.e. conventions smaller price anonymity).
general, finding optimal convention NP-hard problem (Balan, Richards, & Luke,
2011), restricted set infinitely repeated resource allocation games, might
able find optimal convention, similar Thue-Morse sequence (Richman, 2001)
used Kuzmics et al. (2010) Nash demand game.

Acknowledgements
particularly thankful David Parkes giving first author unique opportunity spend weeks lab Harvard. Davids openness unparalleled
knowledge really helped originate work. would thank Kate
359

fiCigler & Faltings

Larson reading draft paper helping make theoretical analysis much
readable.

References
Aumann, R. (1974). Subjectivity correlation randomized strategies. Journal
Mathematical Economics, 1 (1), 6796.
Balan, G., Richards, D., & Luke, S. (2011). Long-term fairness bounded worst-case
losses. Autonomous Agents Multi-Agent Systems, 22 (1), 4363.
Bhaskar, V. (2000). Egalitarianism efficiency repeated symmetric games. Games
Economic Behavior, 32 (2), 247262.
Bonnet, F., & Raynal, M. (2011). price anonymity: Optimal consensus despite
asynchrony, crash, anonymity. ACM Trans. Auton. Adapt. Syst., 6 (4), 23:1
23:28.
Chothia, T., & Chatzikokolakis, K. (2005). survey anonymous peer-to-peer filesharing. Embedded Ubiquitous ComputingEUC 2005 Workshops, pp. 744755.
Springer.
Cigler, L., & Faltings, B. (2011). Reaching correlated equilibria multi-agent learning. 10th International Conference Autonomous Agents Multiagent
Systems-Volume 2, pp. 509516. International Foundation Autonomous Agents
Multiagent Systems.
Durresi, A., Paruchuri, V., Durresi, M., & Barolli, L. (2005). hierarchical anonymous
communication protocol sensor networks. Embedded Ubiquitous Computing
EUC 2005, pp. 11231132. Springer.
Fudenberg, D., & Maskin, E. (1986). folk theorem repeated games discounting
incomplete information. Econometrica, 54 (3), 533554.
Jensen, J. L. (1906). Sur les fonctions convexes et les inegalites entre les valeurs moyennes.
Acta Mathematica, 30 (1), 175193.
Koutsoupias, E., & Papadimitriou, C. (1999). Worst-case equilibria. Proceedings
16th annual conference Theoretical aspects computer science, STACS99, pp.
404413, Berlin, Heidelberg. Springer-Verlag.
Kuzmics, C., Palfrey, T., & Rogers, B. (2010). Symmetric players repeated games: Theory
evidence..
Leyton-Brown, K., & Shoham, Y. (2008). Essentials Game Theory: Concise, Multidisciplinary Introduction. Morgan & Claypool, San Rafael, CA.
Monderer, D., & Shapley, L. S. (1996). Potential games. Games economic behavior,
14 (1), 124143.
Norris, J. R. (1998). Markov Chains (Cambridge Series Statistical Probabilistic
Mathematics). Cambridge University Press.
360

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Raab, M., & Steger, A. (1998). Balls Bins Simple Tight Analysis, Vol. 1518
Lecture Notes Computer Science, chap. 13, pp. 159170. Springer Berlin Heidelberg,
Berlin, Heidelberg.
Rego, V. (1992). Naive asymptotics hitting time bounds markov chains. Acta Informatica, 29 (6), 579594.
Richman, R. M. (2001). Recursive binary sequences differences. Complex Systems, 13 (4),
381392.
Rosenthal, R. W. (1973). class games possessing pure-strategy nash equilibria. International Journal Game Theory, 2 (1), 6567.
Shneidman, J., Ng, C., Parkes, D. C., Auyoung, A., Snoeren, A. C., Vahdat, A., & Chun, B.
(2005). markets could (but dont currently) solve resource allocation problems
systems. USENIX 05: Proceedings 10th USENIX Workshop Hot
Topics Operating Systems, p. 7.
Taussky, O. (1949). recurring theorem determinants. American Mathematical
Monthly, 56 (10), 672676.
Wang, L., Wu, K., Hamdi, M., & Ni, L. M. (2011). Attachment learning multi-channel
allocation distributed OFDMA networks. Parallel Distributed Systems, International Conference on, 0, 520527.

361


