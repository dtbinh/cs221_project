Journal Artificial Intelligence Research 39 (2010) 745774

Submitted 03/10; published 12/10

Intrusion Detection using Continuous Time Bayesian Networks
Jing Xu
Christian R. Shelton

JINGXU @ CS . UCR . EDU
CSHELTON @ CS . UCR . EDU

Department Computer Science Engineering
University California, Riverside
Riverside, CA 92521, USA

Abstract
Intrusion detection systems (IDSs) fall two high-level categories: network-based systems
(NIDS) monitor network behaviors, host-based systems (HIDS) monitor system calls.
work, present general technique systems. use anomaly detection,
identifies patterns conforming historic norm. types systems, rates change
vary dramatically time (due burstiness) components (due service difference).
efficiently model systems, use continuous time Bayesian networks (CTBNs) avoid
specifying fixed update interval common discrete-time models. build generative models
normal training data, abnormal behaviors flagged based likelihood
norm. NIDS, construct hierarchical CTBN model network packet traces
use Rao-Blackwellized particle filtering learn parameters. illustrate power
method experiments detecting real worms identifying hosts two publicly
available network traces, MAWI dataset LBNL dataset. HIDS, develop novel
learning method deal finite resolution system log file time stamps, without losing
benefits continuous time model. demonstrate method detecting intrusions
DARPA 1998 BSM dataset.

1. Introduction
Misuse abuse computer systems critical issue system administrators. goal
detect attacks attempt compromise performance quality particular host machine.
time-consuming error-prone acquire labeled data contains good bad
behaviors build classifier. Additionally, frequency attacks developed make maintaining database previously seen attacks inefficient even infeasible.
Anomaly detection identify new attacks even attack type unknown beforehand. Unsupervised learning allows anomaly detector adapt changing environments, thereby extending
domain usefulness. modeling normal behavior historic clean data, identify
abnormal activity without direct prior model attack simply comparing deviation
learned norm.
network-based intrusion detection system (NIDS), network packet traces monitored.
Network traffic traces collect information networks data stream provide external
view network behavior. host-based intrusion detection system (HIDS), internal state
computing system analyzed. System call logs convenient way monitoring executing
programs behavior operating system calls.
systems composed activities happen dramatically different time granularity.
Users alternate busily using computer resting. busy period, burst
action may cause peak network traffic flow operating system usage. However,
c
2010
AI Access Foundation. rights reserved.

fiX U & HELTON

resting period, computer maintains regular running pattern, network system activities much less intense, e.g. automatically checking email every minutes. Even within
global modes variations. Therefore, dynamic model requires discretizing
time efficient. develop intrusion detection techniques using continuous time Bayesian
networks (CTBNs) (Nodelman, Shelton, & Koller, 2002) data types. Although two
data completely different formats semantic meaning, demonstrate flexibility
continuous time generative model (such CTBN) describe either.
first effort detect anomalies network traffic traces (NIDS). Abnormal traffic must
differ way normal traffic patterns. difference may subtle
difficult detect, subtle attack, longer attack take
stress patience attacker. Looking summarized information flow statistics
helpful, especially stealthy worms mingle well normal traffic sacrificing
spreading speed scale. We, therefore, feel looking abnormalities detailed network
traffic flow level utile method finding attacks. network flow given host machine
sequence continuous-time asynchronous events. Furthermore, events form complex
structured system, statistical dependencies relate network activities packet emissions
connections. employ CTBNs reason structured stochastic network processes.
CTBN model contains number observed network events (packet emissions concurrent port connections changes). allow model descriptive, add latent
variables tie activity variables together. Exact inference method longer feasible.
Therefore, use Rao-Blackwellized particle filtering (RBPF) estimate parameters.
second effort detect intrusions using system call logs (HIDS). system log file contains ordered list calls made computers operating system executing program.
focus analyzing ordering context sequence, rather simply counting
overall statistics. CTBN natural way modeling sequential data. finite
resolution computer clock, system calls issued within clock tick assigned
time stamp. Therefore data stream consists long periods time activity, followed
sequences calls order correctly recorded, exact timing information lost.
poses new challenge CTBN reasoning. present learning method type
data without resorting time discretization.
validate NIDS technique MAWI dataset LBNL dataset, HIDS
technique DARPA 1998 BSM dataset. applications give good results compared
method.
Section 2 discuss related work intrusion detection. Section 3 review continuoustime Markov processes continuous time Bayesian networks. Section 4 describe CTBN
model RBPF inference algorithms NIDS problem. Section 5 describe
CTBN model parameter estimation algorithm HIDS, including deal imprecise timing measurements. Section 6 show experimental results applications.

2. Related Work
Much previous work intrusion detection focuses one area either detecting
network traffic mining system call logs. work Eskin, Arnold, Prerau, Portnoy,
Stolfo (2002) similar approach apply method kinds
746

fiI NTRUSION ETECTION USING CTBN

data. map data elements feature space detect anomalies determining points
lie sparse regions using cluster-based estimation, K-nearest neighbors one-class SVM.
use data-dependent normalization feature map network traffic data spectrum kernel
system call traces.
2.1 NIDS
network traffic data, build upon previous work (Xu & Shelton, 2008). made
assumption network activities independent across different ports. allowed us
factorize model port-level submodels standard exact inference techniques could used
parameter learning. paper, remove restriction. application-specific
reason traffic independent ports. tying traffic together, model describes
complicated structural dependencies among variables. derive Rao-Blackwellized particle
filtering algorithm estimate parameters model. work differs
interested intrusion detection problem, host identity recognition well.
signature-based detection algorithm, share many assumptions Karagiannis,
Papagiannaki, Faloutsos (2005). particular, assume access
internals machines networks, rules methods Malan
Smith (2005), Cha (2005), Qin Lee (2004), Eskin et al. (2002). However, differ
approach rely preset values, require human intervention interpretation,
assume access network-wide traffic information. Network-wide data human
intervention advantages, lead difficulties (data collation face
attack increased human effort), chose leave solution.
Many learning, adaptive, methods proposed network data.
example, Zuev Moore (2005) Soule, Salamatian, Taft, Emilion, Papagiannali (2004) approach problem classification task requires labeled data. Dewaele,
Fukuda, Borgnat (2007) profile statistical characteristics anomalies using random projection techniques (sketches) reduce data dimensionality multi-resolution non-Gaussian
marginal distribution extract anomalies different aggregation levels. goal papers
usually detect attacks rather classify non-attacks traffic type; applied attack
detection, would risk missing new types attacks. Furthermore, frequently treat
network activity separately, instead considering temporal context.
Lakhina, Crovella, Diot (2005) nice summary adaptive (or statistical) methods
look anomaly detection (instead classification). use entropy-based method
entire network traffic. Many methods, Ye, Emran, Chen, Vilbert
(2002), use either statistical tests subspace methods assume features connections
packets distributed normally. Rieck Laskov (2007) model language features
n-grams words connection payloads. Xu, Zhang, Bhattacharyya (2005) use
unsupervised methods, concentrate clustering traffic across whole network. Similarly,
Soule, Salamatian, Taft (2005) build anomaly detector based Markov models,
network traffic patterns whole function host level.
work Soule et al. (2004) similar statistical flavor work.
fit distribution (in case, histogram modeled Dirichlet distribution) network data.
However, model flow-level statistics, whereas work level individual connections.
Additionally, attempting network-wide clustering flows instead anomaly detection.
747

fiX U & HELTON

work Moore Zuev (2005), approach, models traffic graphical models,
particular, Naive Bayes networks. goal categorize network traffic instead detecting
attacks. Kruegel, Mutz, Robertson, Valeur (2003) present Bayesian approach detecting
problem event classification task care whether host attack
interval.
work Lazarevic, Ertoz, Kumar, Ozgur, Srivastava (2003) similar work.
one papers attempt find attacks host level. employ nearest neighbor,
Mahalanobis distance approach, density-based local outliers method, using 23 features
connections. Although methods make standard i.i.d. assumption data
(and therefore miss temporal context connection) use 23 features (compared
features), compare results Section 6, closest prior work. Agosta,
Duik-Wasser, Chandrashekar, Livadas (2007) present adaptive detector whose threshold
time-varying. similar work rely model-based algorithms.
employ host internal states CPU loads available us.
great variety previous work, work novel detects
anomalies host level using timing features network activities. consider
connection (or packet) isolation, rather complex context. capture statistical
dynamic dependencies packets connections find sequences network traffic
anomalous group.
2.2 HIDS
Previous work detecting intrusions system call logs roughly grouped two categories: sequence-based feature-based. Sequence-based methods focus sequential order
events feature-based methods treat system calls independent data elements.
method belongs former category since use CTBN model dynamics sequences.
Time-delay embedding (tide) sequence time-delay embedding (stide) two examples
sequence based methods (Forrest, A.Hofmeyr, Somayaji, & A.Longstaff, 1996; A.Hofmeyr, Forrest, & Somayaji, 1998). generalize data building database storing previously seen
system call sub-sequences, test looking subsequences database. methods
straightforward often achieve good results. compare experiments. Tandon
Chan (2005) look richer set attributes return value arguments associated
system call make use system call names.
Feature based methods Hu, Liao, Vemuri (2003) use dataset use,
DARPA 1998 BSM dataset, training data noisy try find classification
hyperplane using robust support vector machines (RSVMs) separate normal system call profiles
intrusive ones. Eskin (2000) works noisy data. make assumption
training data contains large portion normal elements anomalies. present mixture
distribution normal abnormal data calculate likelihood change data point
moved normal part abnormal part get optimum data partition.
Yeung Ding (2002) try use techniques. provide dynamic static behavioral models system call data. dynamic method, hidden Markov model (HMM)
used model normal system events likelihood calculated testing sequence
compared certain threshold. work system call traces problem close
748

fiI NTRUSION ETECTION USING CTBN

framework since build dynamic model sequential data compute
likelihood testing example score. different CTBN models continuous time dynamics rather time-sliced behaviors. static method, represent
normal behavior command occurrence frequency distribution measure distance
testing example norm cross entropy. dataset use KDD archive dataset.
2.3 Work
Simma et al. (2008) use continuous-time model reason network traffic. apply
method find dependences exterprise-level services. model non-Markovian,
deals network events basic observational unit.
estimate parameters large network build network traffic data, use
Rao-Blackwellized particle filters (RBPFs). Doucet, de Freitas, Murphy, Russel (2000) propose
RBPF algorithm dynamic Bayesian networks works discrete time fashion exploiting
structure DBN. Ng, Pfeffer, Dearden (2005) extend RBPF continuous time dynamic systems apply method K-9 experimental Mars rover NASA Ames Research
Center. model hybrid system containing discrete continuous variables.
use particle filters discrete variables unscented filters continuous variables.
work similar apply RBPF CTBN. model contains discrete
variables evidence continuous time (as opposed snapshots system
state).

3. Continuous Time Bayesian Networks
begin briefly reviewing definition Markov processes continuous time Bayesian
networks (CTBNs).
3.1 Homogeneous Markov Process
finite-state, continuous-time, homogeneous Markov process Xt described initial distribution PX0 and, given state space V al(X) = {x1 , ..., xn }, n n matrix transition intensities:



QX =


qx1
q x2 x1
..
.

q x1 x2
qx2
..
.

q xn x1

q xn x2

. . . q x1 xn
. . . q x2 xn
..
..
.
.
. . . qxn




.


P
qxi xj intensity (or rate) transition state xi state xj qxi = j6=i qxi xj .
transient behavior Xt described follows. Variable X stays state x time
exponentially distributed parameter qx . probability density function f Xt remaining
x duration fx (q, t) = qx exp(qx t) 0. expected time next transition
given state currently x 1/qx . Upon transitioning, X shifts state x0 probability
xx0 = qxx0 /qx . Note given qx , xx0 qxx0 iosmorphic. sometime gives formulae
terms xx0 simplifies expression.
distribution state process X future time t, Px (t), computed
directly QX . PX0 distribution X time 0 (represented vector), then, letting
749

fiX U & HELTON

exp matrix exponential,
PX (t) = PX0 exp(QX t) .
3.2 Complete Data
Complete data HMP represented set trajectories = {1 , ...n }. trajectory
complete set state transitions: = {(xd , td , x0d )}, meaning X stayed state xd
duration td , transitioned state x0d . Therefore know exact state variable
X time 0 .
3.3 Sufficient Statistics Likelihood
Given HMP full data D, likelihood single state transition = {(xd , td , x0d )}

LX (q, : d) = (qxd exp(qxd td ))(xd x0d ) .
likelihood function decomposed transition:


LX (q, : D) = (
LX (q : d))(
LX ( : d))
dD

dD


[x,x0 ]
= ( qxM [x] exp(qx [x]))(
xx0
).
x x0 6=x

x

take log function, get log likelihood:
lX (q, : D) = lX (q : D) + lX ( : D)
X
X
=
(M [x] ln(qx ) qx [x] +
[x, x0 ] ln(xx0 )) .
x0 6=x

x

[x, x0 ]


[x] sufficient statistics HMP
model. [x, x0 ] number
P
times X transitions state x x0 . denote [x] = x0 [x, x0 ], total number
times system leaves state x. [x] total duration X stays state x.
3.4 Learning Complete Data
estimate parameters transition intensity matrix Q, maximize log likelihood function. yields maximum likelihood estimates:
qx =

[x]
,
[x]

xx0 =

[x, x0 ]
.
[x]

3.5 Incomplete Data
Incomplete data HMP composed partially observed trajectories = {1 , ...n }.
trajectory consists set = {(Sd , td , dt)} observations, Sd subsystem (a
nonempty subset states X) process. triplets specifies interval
evidence. states variable X subsystem Sd time td time td + dt.
observations may duration-free. i.e., observe X Sd time t, know
long stayed there. called point evidence generalized using triplet
notation described setting duration 0. partially observed trajectory,
observe sequences subsystems, observe state transitions within subsystems.
750

fiI NTRUSION ETECTION USING CTBN

3.6 Expected Sufficient Statistics Expected Likelihood
consider possible completions partially observed trajectory specify transitions
consistent partial trajectory. combining partial trajectory completion,
get full trajectory. define D+ = {1+ , ..., n+ } completions partial trajectories
D. Given model, distriubtion D+ , given D.
data D+ , expected sufficient statistics respect probability density possible completions data [x], [x, x0 ] [x]. expected log likelihood
E[lX (q, : D+ )] = E[lX (q : D+ )] + E[lX ( : D+ )]
X
X
(M [x] ln(qx ) qx [x] +
=
[x, x0 ] ln(xx0 )) .
x0 6=x

x

3.7 Learning Incomplete Data
expectation maximization (EM) algorithm used find local maximum likelihood
partial trajectory. EM algorithm iterates following E step step
convergence derived likelihood function.
E step: Given current HMP parameters, compute expected sufficient statistics: [x],
[x, x0 ] [x] data set D. complex part algorithm. give
details below.
step: computed expected sufficient statistics, update new model parameters
next EM iteration:
[x, x0 ]
[x]
, xx0 =
.
qx =
[x]
[x]
show calculate expected sufficient statistics using forward-backward
message passing method.
trajectory devided N intervals interval separated
adjacent event changes. Assume trajectory spans time interval [0, ), let [v, w]
observed evidence time v w, including events time stamp v w, let
(v, w) set evidence excluding v w. Let subsystem states
restricted interval.
define
= P (Xt , [0, t]), = P ( [t, ] | Xt )
vectors (indexed possible assignments Xt ). Similarly, define corresponding
distribution excludes certain point evidence follows.
= P (Xt , [0, t)),

t+ = P ( (t, ] | Xt ) .

Denote j vector 0s except j-th position 1, denote ij matrix
0s except element i-th row j-th column 1.
able show derived expected sufficient statistics. time,
Z
E[T [x]] =
P (Xt | [0, ])x dt
0
N
1 Z ti+1
X
1
=
P (Xt , [0, ])x dt .
P ( [0, ])
ti
i=0

751

fiX U & HELTON

constant fraction beginning last line serves make total expected time
j sum . integral interval expressed
Z

w

Z

w

v exp(QS (t v))xx exp(QS (w t))w dt ,

P (Xt , [0, ])x dt =
v

v

QS QX except elements correspond transitions set
0.
equation expected transition counts similarly defined:
N 1

E[M [x, x0 ]] =

X
qx,x0
+
[
ti x,x0 t+i
P ( [0, ])
i=1
N
1 Z ti+1
X
+
ti exp(QS (t ti ))x,x0 exp(QS (ti+1 t))ti+1 dt] .
i=0

ti

integrals appearing E[T ] E[M ] computed via standard ODE solver,
Runge-Kutta method (Press, Teukolsky, Vetterling, & Flannery, 1992). method uses
adaptive step size move quickly times expected changes slowly
times rapid transitions.
remaining problem calculate . Let QSS0 transitioning intensity
matrix HMP one subsystem another 0 . matrix QX ,
elements corresponding transitions 0 non-zero.
ti = ti1 exp(QSi1 (ti ti1 )) ,
ti = ti QSi1 Si ,
ti = exp(QSi (ti+1 ti ))ti+1 ,
ti = QSi1 Si ti .
forward-backward calculation, trivial answer queries
P (Xt = x | [0, ]) =

1
xx .
P ( )

3.8 Continuous Time Bayesian Networks
HMPs good modeling many dynamic systems, limitations
systems multiple components state space grows exponentially number
variables. HMP model variable independencies therefore use unified
state X represent joint behavior involving components system.
section, show continuous time Bayesian network used address issue.
Nodelman et al. (2002) extend theory HMPs present continuous time Bayesian networks (CTBNs), model joint dynamics several local variables allowing transition
model local variable X Markov process whose parametrization depends
subset variables U .
752

fiI NTRUSION ETECTION USING CTBN

3.9 Definition
first give definition inhomogeneous Markov process called conditional Markov process. critical concept us formally introduce CTBN framework.
Definition 1 (Nodelman, Shelton, & Koller, 2003) conditional Markov process X inhomogeneous Markov process whose intensity matrix varies function current values set
discrete conditioning variables U . parametrized using conditional intensity matrix (CIM)
QX|U set homogeneous intensity matrices QX|u , one instantiation values u U .
call U parents X. set U empty, CIM simply standard intensity
matrix.
CIMs provide way model temporal behavior one variable conditioned
variables. putting local models together, joint structured model continuous
time Bayesian network.
Definition 2 (Nodelman et al., 2003) continuous time Bayesian network N set stochastic processes X consists two components: initial distribution PX0 , specified Bayesian
network B set random variables X, continuous transition model, specified using
directed (possibly cyclic) graph G whose nodes X X; UX denotes parents X G.
variable X X associated conditional intensity matrix, QX|UX .
dynamics CTBN quantitatively defined graph. instantaneous evolution
variable depends current value parents graph. quantitative description
variables dynamics given set intensity matrices, one value parents.
means transition behavior variable controlled current values parents.
standard notion d-separation Bayesian networks carries CTBNs.
graphs cyclic variables represent processes (not single random variables), implications
little different. variable (process) still independent non-descendants given parents,
still independent everything given Markov blanket (any variable either parent,
child, parent child). Cycles cause parents children, provided
considered both, definitions still hold. importantly, notion given works
full trajectory variable question known. Therefore, X grandchildren
independent given Xs childrens values single instant. Rather, independent
given Xs childrens full trajectories time 0 last time interest.
amalgamate variables CTBN together, get single homogeneous Markov
process joint state space. joint state intensity matrix, rate 0 assigned
transition involves changing one variables value exact time.
intensities found looking value corresponding conditional intensity matrix
variable changes. diagonal elements negative row sums.
Forward sampling done quickly CTBN without generating full joint intensity
matrix. keep track next event time variable (sampled relevant exponential distribution given current values parent). select earliest
event time change variable (sampling multinomial distribution implied row
variables relevant intensity matrix). next event time variable changed
children must resampled, variables time must resampled due
memoriless property exponential distribution. way sequence events (a trajectory)
sampled.
753

fiX U & HELTON

3.10 Learning
context CTBNs, model parameters consist CTBN structure G, initial distribution P0 parameterized regular Bayesian network, conditional intensity matrices (CIMs)
variable network. section, assume CTBN structure known us,
focus parameter learning. assume model irreducible. initial
distribution P0 becomes less important context CTBN inference learning, especially
time range becomes significantly large. Therefore, parameter learning context
estimate conditional intensity matrices QXi |Ui variable Xi , Ui set
parent variables Xi .
3.10.1 L EARNING C OMPLETE DATA
Nodelman et al. (2003) presented efficient way learn CTBN model fully observed
trajectories. complete data, know full instantiations variables whole
trajectory. know CIM governing transition dynamics variable
time. sufficient statistics [x, x0 |u] number times X transitions state x
x0 given parent instantiation u [x|u] P
total duration X stays state x
given parent instantiation u. denote [x|u] = x0 [x, x0 |u].
likelihood function decomposed

LN (q, : D) =
LXi (qXi |Ui : D)LXi (Xi |Ui : D))
(1)
Xi X


LX (qX|U : D) =

YY
u

[x|u]

qx|u

exp(qx|u [x|u])

(2)

x


LX ( : D) =

YY
u


0
xx
0 |u [x, x |u] .

(3)

x x0 6=x

put functions together take log, get log likelihood component
single variable X:
lX (q, : D) = lX (q : D) + lX ( : D)
XX
=
[x|u] ln(qx |u) q[x|u] [x|u]
u

+

x

XX X
u

[x, x0 |u] ln(xx0 |u )).

(4)

x x0 6=x

maximizing log likelihood function, model parameters estimated
qx|u =

[x|u]
,
[x|u]

xx0 |u =

754

[x, x0 |u]
.
[x|u]

(5)

fiI NTRUSION ETECTION USING CTBN

3.10.2 L EARNING NCOMPLETE DATA
Nodelman, Shelton, Koller (2005) present expectation maximization (EM) algorithm
learn CTBN model partially observed trajectories D. expected sufficient statistics
[x, x0 |u], expected number times X transitions state x x0 parent set
U takes values u, [x|u], expected P
amount time X stays state x
parent instantiation u. denote [x|u] x0 [x, x0 |u]. expected log likelihood
decomposed way Equation 4, except sufficient statistics [x, x0 |u], [x|u]
[x|u] replaced expected sufficient statistics [x, x0 |u], [x|u] [x|u].
EM algorithm CTBN works essentially way HMP. expectation step calculate expected sufficient statistics using inference method (will described
Section 3.11). maximization step update model parameters:

qx|u =

[x|u]
,
[x|u]

xx0 |u =

[x, x0 |u]
.
[x|u]

3.11 Inference
given CTBN model (partially) observed data, would query model.
example, may wish calculate expected sufficient statistics EM algorithm.
3.11.1 E XACT NFERENCE
Nodelman et al. (2005) provide exact inference algorithm using expectation maximization
reason learn parameters partially observed data. exact inference algorithm requires flattening variables single Markov process performing inference
HMP. problem makes state space grow exponentially large. Therefore, exact
inference method feasible problems small state spaces.
3.11.2 PPROXIMATE NFERENCE
issue addressed below, much work done CTBN approximate inference. Nodelman, Koller, Shelton (2005) present expectation propagation algorithm. Saria,
Nodelman, Koller (2007) give another message passing algorithm adapts time granularity. Cohn, El-Hay, Friedman, Kupferman (2009) provide mean field variational approach.
El-Hay, Friedman, Kupferman (2008) show Gibbs sampling method approach using Monte
Carlo expectation maximization. Fan Shelton (2008) give another sampling based approach
uses importance sampling. El-Hay, Cohn, Friedman, Kupferman (2010) describe different expectation propagation approach.
estimate parameters models build two applications (NIDS HIDS),
employ inference algorithms including exact inference Rao-Blackwellized particle filtering
(RBPF) algorithm, depending model size. Ng et al. (2005) extended RBPF CTBNs.
model hybrid system containing discrete continuous variable. used particle
filters discrete variables unscented filters continuous variable. work
similar work method applying RBPF CTBNs, model contains discrete
variables evidence continuous intervals.
755

fiX U & HELTON

PORT
80
8080
443
113
5101
995
51730
59822

DESCRIPTION
World Wide Web HTTP
HTTP Alternate
HTTP protocol TLS/SSL
Authentication Service
Talarian TCP
pop3 protocol TLS/SSL
unknown
unknown

PORT
80
139
443
445
1863
2678
1170
110

DESCRIPTION
World Wide Wed HTTP
NETBIOS Session Service
HTTP protocol TLS/SSL
Microsoft-DS
MSNP
Gadget Gate 2 Way
AT+C License Manager
Post Office Protocol - Version 3

Figure 1: Ranking frequent ports MAWI dataset (left) LBNL dataset (right).

3.12 CTBN Applications
Although inference learning algorithms well developed CTBNs,
applications real world problems. Nodelman Horvitz (2003) used CTBNs
reason users presence availability time. Ng et al. (2005) used CTBNs monitor
mobile robot. Nodelman et al. (2005) used CTBNs model life event history. Fan Shelton
(2009) modeled social networks via CTBNs. previous work (Xu & Shelton, 2008) presented
NIDS host machine using CTBNs, include HIDS.

4. Anomaly Detection Using Network Traffic
section, present algorithm detect anomalies network traffic data using CTBNs.
focus single host network. sequence timing events (e.g. packet
transimission connection establishment) important network traffic flow. matters
many connections initiated past minute, timing:
evenly spaced trace probably normal, came quick burst suspicious.
Similarly, sequence important. connections made sequentially increasing ports
likely scanning virus, whereas set ports random order likely
normal traffic. merely simple examples. would detect complex
patterns.
typical machine network may diverse activities various service types (e.g.
HTTP, SMTP). destination port number roughly describes type service particular network activity belongs. worms propagate malicious traffic toward certain well known
ports affect quality associated services. looking traffic associated different
ports sensitive subtle variations appear aggregate trace information
across ports. Figure 1 shows popular ports ranked frequencies network
traffic datasets use (described depth later). services are, extent,
independent other. therefore model ports traffic CTBN submodel.
denote whole observed traffic sequences particular host, j traffic
associated port j.
756

fiI NTRUSION ETECTION USING CTBN

G

N
H

Pin

Pout

Cinc

Cdec

Figure 2: CTBN model network traffic plate model. N number port .

4.1 CTBN Model Network Traffic
use port-level submodel previous work (Xu & Shelton, 2008). latent
variable H four fully observed toggle variables: Pin , Pout , Cinc , Cdec .
nodes packet-in, Pin , packet-out, Pout , represent transmission packet
host. intrinsic state: transmission packet essentially instantaneous
event. Therefore events (or transitions) without state. modeled using
toggle variable event evidence change state variable rate
transition associated state required same.
nodes connection-increase Cin connection-decrease Cdec together describe status
number concurrent connections C active host. Notice C increase
decrease one given event (the beginning ending time connection). assume
arrival new connection termination existing connection independent
number connections. Thus intensity connection starts (or stops)
connections. Therefore, modeled toggle variables.
Node H 8 states represent different abstract attributes machines internal state.
toggle variables (Pin , Pout , Cinc Cdec ) allowed change 2 states
H required rate states. 2 hidden states per toggle
variable chosen balance expressive power model efficiency.
previous work, assumed traffic associated different ports independent
other, port-level submodels isolated. remove restriction introducing
another latent variable G ties port submodels together. full model shown Figure 2.
4.2 Parameter Learning Using RBPF
calculate expected sufficient statistics E-step EM parameter learning, exact
inference algorithm Nodelman et al. (2002) flattens variables joint intensity matrix
reasons resulting homogeneous Markov process. time complexity exponential
number variables. example, 9 port models, network contains 46 variables
total. Approximate inference techniques clique tree algorithm (Nodelman et al., 2002),
message passing algorithms (Nodelman et al., 2005; Saria et al., 2007), importance sampling (Fan
757

fiX U & HELTON

& Shelton, 2008) Gibbs sampling (El-Hay et al., 2008) overcome problem sacrificing
accuracy.
notice model nice tree structure makes Rao-Blackwellized particle
filtering (RBPF) perfect fit. RBPF uses particle filter sample portion variables
analytically integrates rest. decomposes model structure efficiently thus reduces
sampling space.
denote N port-level hidden variables H1 , ..., HN , posterior
distribution
QN
whole model factorized P (G, H1 , ..., HN | ) = P (G | ) i=1 P (Hi | G, ). Note
G Hi processes, probability density complete trajectories. use
particle filter estimate Gs conditional distribution P (G | ) set sampled trajectories
G. difficult sample directly posterior distribution, use importance sampler
sample particle proposal distribution particles weighted ratio
likelihood posterior distribution likelihood proposal distribution (Doucet
et al., 2000). Since variable G latent parents, use forward sampling
sample particles P (G) weight particle simply likelihood
conditioned trajectory G (Fan & Shelton, 2008). port-level submodel dseparated rest network, given full trajectory G (see Section 3.9 d-separation
CTBNs). Since small (only 8 hidden states), marginalized exactly.
is, calculate P (i | G) (where portion trajectory submodel i) exactly,
marginalizing Hi - recursions Section 3.7.
expected sufficient statistics (ESS) variable X CTBN TX|U [x|u], expected amount time X stays state x given parent instantiation u, MX|U [x, x0 |u],
expected number transitions state x x0 given Xs parent instantiation u. Let g P (G),
)
= 1, . . . , particles. define likelihood weights wi = PP(g(g|
) let
P
W = wi sum weights. general importance sampling allows expected
sufficient statistic estimated following way, SS sufficient statistic:

E(g,h1 ,...,hN )P (G,H1 ,...,HN | ) [SS(g, h1 , . . . , hN )]
= EgP (G| ) Eh1 ,...,hN P (H1 ,...,HN |g, ) [SS(g, h1 , . . . , hN )]
1 X
wi Eh1 ,...,hN P (H1 ,...,HN |gi , ) [SS(g , h1 , . . . , hN )] .

W


expected sufficient statistics whole model two categories: depend
g, ESS(g), depend port model k, ESS(g, hk , k ). ESS(g) simply
summation counts (the amount time G stays state, number times G
transitions one state another) particles, weighted particle weights:

EgP (G| ) [SS(g)]

1 X
wi SS(g ) .
W


758

(6)

fiI NTRUSION ETECTION USING CTBN

Function Wholemodel Estep
input: current model , evidence
output: Expected sufficient statistics ESS
ESS := {ESS(g), ESS(s1 , g), . . . , ESS(sn , g)}
Initialize ESS empty
particle g {g 1 , . . . , g }, g P (G)
Sj {S1 , . . . , SN }
[P (j |g ), ESS(sj , g )] = Submodel Estep(g , [Sj ], j )
Sj {S1 , . . . , SN }
Q
ESS(sj , g) = ESS(sj , g) + k6=j P (k |g ) ESS(sj , g )
i)
ESSgi = CountGSS(gQ
ESS(g) = ESS(g) + j P (j |g ) ESSgi
Return ESS

Figure 3: Rao-Blackwellized particle filtering Estep whole model
ESS(g, hk , k ) calculated submodel independently:
Eg,h1 ,...,hN P (G,H1 ,...,HN | ) [SS(g, hk , k )]
Z
1 X
wi

P (hk |g , k )SS(g , hk , k ) dhk
W
hk

Q
Z
1 X j P (j |g )
P (hk |g , k )SS(g , hk , k ) dhk
=
W
P ( )
hk

Z
X

1

P (j |g )
P (hk , k |g )SS(g , hk , k ) dhk .
W
hk


(7)

j6=k

integrals possible trajectories hidden process Hk . first line holds
d-separation (we need average submodel k, given assignment G). second
line expands weight. last line combines weight term submodel k terms
integral get likelihood hk submodel data. constant proportionality
P
cancel subsequent maximization, reconstructed noting x TX|U [x|u]
total time
R interval.
last integral, hk P (hk , k |g )SS(g , hk , k ) dhk , P (j |g ) calculated using
technique described Nodelman et al. (2005), exact ESS calculation. calculations
similar integrals Section 3.7, except intensity matrices change interval
interval (they function sampled trajectory gi ).
full E-step algorithm shown Figure 3 (sk represents variables submodel
k). Function Submodel Estep calculates expected sufficient statistics likelihood
subnet model (Equation 7). Function CountGSS counts empirical time transition statistics
sampled trajectory G (Equation 6).
EM, use ESS true sufficient statistics maximize likelihood
respect parameters. regular CTBN variable X (such hidden variable G
H), Equation 5 performs maximization. toggle variables, e.g. Pi , likelihood
759

fiX U & HELTON

component toggle variable


MP

QPi |ui exp(QPi |u [U = u])

u

found setting qx|u value (QPi |u ) x (tieing parameters)
simplifying product x Equation 2. Thus maximum likelihood parameter estimate
QPi |u =

MPi
[U = u]

MPi number events variable Pi QPi |u parameter: rate
switching.
synchronize particles end window (see Section 6.1) resample
normal particle filter points. is, propagate particles forward, stop
end window, resample based weights, continue new set
particles. general, particles aligned time, except resampling points.
4.3 Online Testing Using Likelihood
CTBN model fitted historic data, detect attacks computing likelihood
window data (see Section 6.1) model. likelihood falls threshold,
flag window anomalous. Otherwise, mark normal.
experiments, fix window fixed time length, Tw . Therefore,
window interest starts time , wish calculate p( [T, + Tw ] | [0, ]) [s, t]
represents observed connections packets time time t. Again, use RBPF
estimate probability. samples time represent prior distribution P (G | [0, ]).
Propagating forward across window length Tw produces set trajectories G,
g . submodel k evalute P (k [T, + Tw ] | g ) exact marginalization (the sum
vector +Tw , forward message). weighted average (over samples g k ) product
submodel probabilities estimate P ( [T, + Tw ] | [0, ]).

5. Anomaly Detection Using System Calls
turn problem detecting anomalies using system call logs.
5.1 CTBN Model System Calls
System call logs monitor kernel activities machines. record detailed information
sequence system calls operating system. Many malicious attacks host revealed
directly internal logs.
analyze audit log format SUNs Solaris Basic Security Module (BSM) praudit audit
logs. user-level kernel event record least three tokens: header, subject, return.
event begins header format of: header, record length bytes, audit record version
number, event description, event description modifier, time date. subject line consists of:
subject, user audit ID, effective user ID, effective group ID, real user ID, real group ID, process
ID, session ID, terminal ID consisting device machine name. return return
value indicating success event closes record.
760

fiI NTRUSION ETECTION USING CTBN

H

S1

S2

Sn

Figure 4: CTBN model system call data

}

s1, s2, ..., sk

ti-1 ti-1+t

ti+t

ti

ti+1 ti+1+t

time

Figure 5: System call traces finite resolution clock (resolution = )
construct CTBN model similar port-level network model. Individual system calls
S1 , ..., SN , event description fields header token, transiently observed:
happen instantaneously duration. treat toggle variables packets
network model. introduce hidden variable H parent system calls variables
allow correlations among them. hidden variable designed model internal state
machine, although semantic meaning imposed method. Put together, system
call model looks Figure 4.
state space hidden variable H size m, transition rate matrix H



QH =


qh1
q h2 h1
..
.

q h1 h2
qh2
..
.

q hm h1

q hm h2

. . . q h1 hm
. . . q h2 hm
..
..
.
.
. . . qhm




.


transition intensity rate toggle variable given current value parent H
qs|hi , = 1, ..., m.
estimate CTBN model parameters, use expectation maximization (EM)
algorithm. expected sufficient statistics need calculate model
Mhi hj , expected number times H transitions state j;
Thi , expected amount time H stays state i;
Ms|hi , expected number times system call evoked H state i.
761

fiX U & HELTON

maximum likelihood parameters
Mhi hj
Thi
Ms|hi
=
.
Thi

q hi hj =
qs|hi

5.2 Parameter Estimation Finite Resolution Clocks
finite resolution computer clocks, multiple instantaneous events (system calls)
occur within single clock tick. Therefore audit logs, batch system calls may recorded
executed time point, rather real time stamp, result finite
time accuracy. However, correct order events kept logs. is, know exactly
system call S2 follows S1 recorded order audit logs. Thus system
call timings partially observed. type partial observation previously
considered CTBN inference. typical trajectory [0, ] system call data shown
Figure 5: batch system calls evoked time ti next clock tick,
followed quiet period arbitrary length, yet another bunch events time
ti+1 on.
Let t1:t2 denote evidence interval [t1, t2), t1:t2+ denote evidence [t1, t2],
t1 :t2 denote evidence (t1, t2). define vectors
ti = p(Ht , 0:ti )


t+i = p(t+ :T |Ht+ )




Ht value H prior transition ti , Ht+ value afterward.


define vectors
ti = p(Hti , 0:t+ )


ti = p(ti :T |Hti )
evidence transition time ti included. follow forward-backward algorithm
compute ti ti ti event. this, split interval [ti , ti+1 )
spike period [ti , ti + ) (t one resolution clock), batch
system calls, quite period [ti + , ti+1 ) events exist, propagations
separately.
spike period [ti , ti + ), observed event sequence s1 , s2 , ..., sk , construct
artificial Markov process X following intensity matrix.




QX =



QH Q1 0
...
0
0 QH Q2 . . .
0
..
..
..
..
..
.
.
.
.
.
0
0
. . . QH Qk
0
0
...
0 QH
762





.



fiI NTRUSION ETECTION USING CTBN





QH =


P
qh1 sS qs|h1
q h2 h1
..
.

qh2

q hm h1

q h1 h2
P
sS qs|h2
..
.

...
...
..
.
. . . qhm

q hm h2

q h1 hm
q h2 hm
..
.
P
sS qs|hm











Qi =


qsi |h1
0
..
.
0

0
qsi |h2
..
.

...
...
..
.

0
0
..
.

0

0

qsi |hm







X tracks evidence sequence s1 s2 ... sk . QX square block matrix dimension
(k + 1). block matrix. subsystem X k + 1 blocks states.
first block represents state H events. second block represents H exactly
one event, s1 , happens. third block represents H s1 followed s2 happens,
on. last block represents H events finish executing order. subsystem
zero transition intensities everywhere except along sequence pass. diagonal QH
matrix QH except transition intensities system call variables
subtracted. full system includes transitions observed.
transition rates set zero (to force system agree evidence), conditioning
change diagonal elements rate matrix (Nodelman et al., 2002). Within
k + 1 states block, H freely change value. Therefore, non-diagonal elements
QH intensities QH . Upon transitioning, X transit state
another according event sequence. Therefore, blocks 0 matrices except
immediate right diagonal blocks. transition behavior described matrix
Qi . Qi 0 intensities non-diagonal entries H change simultaneously.
diagonal element Qi (h, h) intensities event si happening, given current value
hidden state h.
take forward pass example describe propagation; backward pass
performed similarly. Right ti , ti dimensions. expand m(k + 1) dimensions
form ti non-zero probabilities first states. ti describes
distribution subsystem X. ti eQX represents probability distribution time ti + ,
given prefix observed sequence occurred. take last state probabilities
condition entire sequence happening, thus resulting m-dimensional vector, ti +t .
quiet period [ti + , ti+1 ), evidence observed. Therefore ti +t propagated
ti+1 using QH , rate matrix conditioned H events occuring:
ti+1 = ti +t exp(QH (ti+1 ti )) .
done full forward-backward pass whole trajectory, calculate expected sufficient statistics Mhi hj , Thi Ms|hi . Again, refer work Nodelman
et al. (2005) algorithm.
763

fiX U & HELTON

5.3 Testing Using Likelihood
learned model normal process system call logs, calculate
log-likelihood future process model. log-likelihood compared
predefined threshold. threshold, possible anomaly indicated. single
hidden variable, calculations done exactly.

6. Evaluation
evaluate methodology, constructed experiments two different types data: network
traffic traces system call logs. following sections, show experiment results
tasks.
dynamic Bayesian network (DBN) another popular technique graphical modeling
temporal data. slice time, events without state changes (instantaneous events)
difficult model. reasonable time resolution result multiple events
variable one time period. standard way encoding DBN. use toggle
variable, records parity number events time interval. Furthermore,
NIDS, events bursty. active times, multiple packets emited per second.
inactive times, may activity hours. Finding suitable sampling rate
maintains efficency model difficult. HIDS, problem acute.
know way modeling timing ambiguity DBN without throwing away timing
information adding mathematical framework essentially turns DBN CTBN
described here. general, could find suitable way apply DBN problems
without essentially turning DBN CTBN finely slicing time applying
numeric tricks speed inference amount converting stochastic matrices rate
matrices using numeric integration matrix exponential.
compared current adaptive methods problem individually. include nearest neighbor, support vector machines, sequence time-delaying embedding. give
details methods below.
6.1 Experiment Results Network Traffic
section, present experiment results NIDS.
6.1.1 DATASETS
verify approach two publicly available real network traffic trace repositories: MAWI
working group backbone traffic MAWI LBNL/ICSI internal enterprise traffic LBNL.
MAWI backbone traffic part WIDE project collected raw daily packet
header traces since 2001. records network traffic inter-Pacific tunnel
Japan USA. dataset uses tcpdump IP anonymizing tools record 15-minute
traces every day, consists mostly traffic Japanese universities. experiment,
use traces January 1st 4th 2008, 36,592,148 connections total time
one hour.
LBNL traces recorded medium-sized site, emphasis characterizing internal enterprise traffic. Publicly released anonymized form, LBNL data collects
764

fiI NTRUSION ETECTION USING CTBN

# packets flowing source destination
# packets flowing destination source
# connections source last 5 seconds
# connections destination last 5 seconds
# different services source last 5 seconds
# different services destination last 5 seconds
# connections source last 100 connections
# connections destination last 100 connections
# connections port source last 100 connections
# connections port destination last 100 connections
Figure 6: Features nearest neighbor approach work (Lazarevic et al., 2003).
100 hours network traces thousands internal hosts. publicly released, take
one hour traces January 7th, 2005 (the latest date available), 3,665,018 total connections.
6.1.2 W ORM ETECTION
start problem worm detection. split traffic traces host: half training
half testing. learn CTBN model training data hosts. Since
network data available clean traffic known intrusions, inject real attack traces
testing data. particular, inject IP Scanner, W32.Mydoom, Slammer. slide
fixed-time window testing traces, report single log-likelihood value sliding
window, compare predefined threshold. threshold, predict
abnormal time period. define ground truth window abnormal attack
traffic exists interval, normal otherwise. window size use 50 seconds.
consider windows contain least one network event.
compare method employing RBPF previous factored CTBN model (Xu &
Shelton, 2008), connection counting, nearest neighbor, Parzen-window detector (Yeung & Chow,
2002), one-class SVM spectrum string kernel (Leslie, Eskin, & Noble, 2002).
connection counting method straightforward. score window number
initiated connections window. worms aggregate many connections short time,
method captures particular anomaly well.
make nearest neighbor competitive, try extract reasonable set features. follow
feature selection work Lazarevic et al. (2003), use total 23 features.
features available data. available shown Figure 6. Notice
features associated connection record. apply nearest neighbor method
window based testing framework, first calculate nearest distance connection inside
window training set (which composed normal traffic only), assign maximum
among score window. Similarly, Parzen window approach, apply
feature set assign maximum density among connections inside window
score window.
Besides feature-based algorithms, would see sequence-based
approaches compare methods. algorithms widely used network anomaly
detection. approach, treat traffic traces stream data sequential contexts
765

fiX U & HELTON

1

1

0.8

0.8

0.8

0.6

0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0.2

0
0

0.02

0.04
0.06
False Positive Rate

0.08

0.6

0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0.2

0
0

0.1

0.02

0.08

0.6

0.4

0
0

0.1

1

0.8

0.8

0.8

0.6

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0
0

0.02

0.04
0.06
False Positive Rate

IP Scanning

0.08

0.1

0.6

0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0.2

0
0

0.02

0.04
0.06
False Positive Rate

Mydoom

0.08

0.1

True Positive Rate

1

0.2

0.02

0.04
0.06
False Positive Rate

0.08

0.1

Slammer

1

0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0.2

Mydoom

True Positive Rate

True Positive Rate

LBNL

IP Scanning

0.04
0.06
False Positive Rate

True Positive Rate

1

True Positive Rate

True Positive Rate

MAWI

explored. One-class SVM spectrum string kernel chosen comparison.
implemented spectrum kernel LIBSVM library (Chang & Lin, 2001). give network
activities (such connection starting ending, packet emmision receipt) inside portlevel submodel distinct symbol. sequence symbols fed algorithm inputs.
decision surface trained normal training traffic. testing, sliding window,
distance window string decision hyperplane reported window score.
tried experiments using edit distance kernel, results dominated spectrum
kernel, report here.

0.6

0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF100

0.2

0
0

0.02

0.04
0.06
False Positive Rate

0.08

0.1

Slammer

Figure 7: ROC curves testing results IP scanning attack, Mydoom attack Slammer attack.
= 0.001. Top: MAWI. Bottom: LBNL.

injecting attack traffic, randomly pick starting point somewhere first half
test trace insert worm traffic duration equal times length full testing
trace. shorter is, harder detect anomaly. choose 0.02%
experiments work challenge detection tasks. scaled back rates
worms. running full speed, worm easy detect method. slows
(and thus blends background traffic better), becomes difficult detect. let
scaling rate (e.g. 0.1 indicates worm running one-tenth normal speed).
method, set state space variable G 4 variable H 8. use
100 samples particle filtering, resample particles every 50 seconds. SVM
spectrum kernel method, choose sub-sequence length 5 parameter 0.8.
show ROC curves methods Figure 7. curves show overall performance 10 active hosts dataset. point curves corresponds
766

fiI NTRUSION ETECTION USING CTBN

1

1

0.8

0.8
True Positive Rate

True Positive Rate

different threshold algorithm. CTBN method out-performs algorithms except
single case Mydoom attack background LBNL traffic. many cases,
advantages CTBN approach pronounced.
MAWI data, factored non-factored CTBN models perform comparably.
believe data captures connections traverse trans-Pacific link.
Therefore, connections machine represented. makes reasoning
global pattern interaction machine difficult. LBNL data, one attack (IP
scanning) shows advantage non-factored model. One attack (Mydoom) shows distinct
advantage. one attack (Slammer) indicates advantage, depending desired false
positive rate. demonstrate advantage jointly modeling traffic across ports,
although clear advantage uniform traffic patterns attack types.

0.6

0.4

0.2

0.6

0.4

0.2
Connection Count
CTBN, RBPF100

0
0

0.02

0.04
0.06
False Positive Rate

0.08

Connection Count
CTBN, RBPF100

0.1

0
0

0.02

0.04
0.06
False Positive Rate

0.08

0.1

Figure 8: ROC curves testing results Slammer attack MAWI dataset demonstrating
effect slowing attack rate. Left: = 0.01. Right: = 0.001

show ROC curves shift scale back worm running speed Figure 8.
firewalls built sensitive block malicious traffic, worms act stealthy
sneak through. demonstrate robustness method compared best competitor
(connection counts) speed worms attack.
6.1.3 H OST DENTIFICATION
Identifying individual hosts based network traffic patterns another useful application
model. instance, household usually installs network router. family members
computer connected router. outside Internet, network traffic going
router behaves coming one peer, actually coming different people.
Dad possibly read sports news kids surf social networks. interesting well
useful tell family member contributing current network traffic. Host identification
used combat identity theft. network identity abused attacker, host
identification techniques help network administrator tell whether current network traffic
host consistent usual pattern not.
767

fiX U & HELTON

first set experiments construct host model fitting competition. 10
hosts picked worm detection tasks LBNL dataset compose testing pool. learn
coupled CTBN model host. split test traces (clean) particular host
segments lengths 15 seconds. segments, compute log-likelihood
segment learned model hosts (including own), label segment
host achieves highest value. compute confusion matrix C whose element Cij
equals fraction test traces host model j highest log-likelihood. expect
see highest hit rates fall diagonals ideally host best described
model. Table 9 shows results dataset LBNL. vast majority traffic windows
assigned correct host. exception host 1, diagonals distinctly higher
elements row. comparison, performed experiment using SVM
spectrum kernel method. Again, selected sub-sequence length 5 parameter
0.8. tried multiple methods normalization (of distance hyperplane)
variations parameters. produced poor results almost windows assigned
single host. omit table results.
Host
1
2
3
4
5
6
7
8
9
10

1
0.09
0.06
0
0
0
0
0.25
0
0.04
0

2
3
4
0.41 0.47 0
0.50 0.31 0
0
1
0
0
0
1
0.08 0.13 0
0.20 0.03 0
0
0.06 0.02
0.08 0.28 0
0.05 0.13 0.01
0.03 0.18 0.01

5
6
7
8
9
10
0
0
0
0.03 0
0
0
0.13 0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.68 0.06 0.03 0.01 0
0.01
0.01 0.74 0
0.02 0
0
0
0
0.66 0
0
0.01
0
0.05 0
0.59 0
0
0.01 0.01 0.02 0
0.73 0
0
0.15 0.03 0.03 0
0.57

Figure 9: Confusion matrix LBNL host identification using CTBN
second experiment host traffic differentiation task. mingle network traffic
another host analyzed host. expect detection method successfully tell apart
two. verify idea, pick one host among 10 choose LBNL dataset
split traffic evenly training testing. learn model training data.
testing data, randomly choose period inject another hosts traffic worm.
goal identify period abnormal since hosts traffic longer behavior.
Figure 10 displays results two combination tests. parameters injecting
traffic worm = 0.02, = 0.001. left graph, nearest neighbor Parzen
window curve overlap, CTBN curves overlap. right graph, coupled CTBN curve
substantially outperforms curves.
6.2 Experiment Results System Call Logs
section, present experiment results HIDS.
768

fi1

1

0.8

0.8

0.6
0.4

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF10

0.2
0
0

0.02

0.04
0.06
False Positive Rate

0.08

True Positive Rate

True Positive Rate

NTRUSION ETECTION USING CTBN

Nearest Neighbor
Connection Count
Parzen Window
SVMSpectrum
CTBN, factored
CTBN, RBPF10

0.6
0.4
0.2
0
0

0.1

0.02

0.04
0.06
False Positive Rate

0.08

0.1

Figure 10: ROC curves testing results host identification LBNL data. Left: host 1,
Nearest neighbor curve Parzen window curve overlap, CTBN curves overlap.
Right: host 2.

Week
1
2
3
4
5
6
7

# normal
processes
786
645
775
615
795
769
584

# attack
processes
2
4
20
331
10
24
0

System Call
close
ioctl
mmap
open
fcntl
stat
access

# occurrence
123403
68849
60886
42479
7416
6429
2791

System Call
execve
chdir
chroot
unlink
chown
mkdir
chmod

# occurrence
1741
1526
328
26
23
4
1

Figure 11: Left: DARPA BSM process summary. Right: DARPA BSM system call summary
6.2.1 DATASET
dataset used 1998 DARPA Intrusion Detection Evaluation Data Set MIT Lincoln
Laboratory. Seven weeks training data contain labeled network-based attacks midst
normal background data publicly available DARPA website. Solaris Basic Security
Module (BSM) praudit audit data system call logs provided research analysis. follow
Kang, Fuller, Honavar (2005) cross-index BSM logs produce labeled list file
labels individual processes. resulting statistics shown left table Figure 11.
frequency system calls appearing dataset summarized descending order
right Figure 11.
6.2.2 NOMALY ETECTION
experimental goal detect anomalous processes. train CTBN model normal
processes test mixture normal attack processes. state space
769

fi1

1

0.8

0.8
True Positive Rate

True Positive Rate

X U & HELTON

0.6
0.4
CTBN
SVMSpectrum
Stide
Nearest Neighbor

0.2
0
0

0.01

0.02
0.03
False Positive Rate

0.04

0.6
0.4
CTBN
SVMSpectrum
Stide
Nearest Neighbor

0.2

0.05

0
0

0.01

0.02
0.03
False Positive Rate

0.04

0.05

Figure 12: ROC curves BSM data detection. Left: Training week 1 combined testing
results week 2 7; Right: Training week 3 test week 4, Stide curve
CTBN curve overlap

hidden variable H set 2. log-likelihood whole process learned model
represents score process. compare score predefined threshold classify
process normal one system abuse.
implement sequence time-delaying embedding (stide) stide frequency threshold
(t-stide) comparison (Warrender, Forrest, & Pearlmutter, 1999). two algorithms build
database previously seen normal sequences system calls compare testing sequences
it. straightforward perform well empirically system call log
datasets. choose parameter k, sequence length 5, h, locality frame length,
50. results t-stide shown following resulting graphs since overlapped
stide almost cases.
approaches compare nearest neighbor one-class SVM spectrum
string kernel edit distance kernel. follow Hu et al. (2003) transform process
feature vector, consisting occurrence numbers system call process. nearest
distance testing process training set processes assigned score.
one-class SVM, processes composed strings system calls. Normal processes used
learning bounding surface signed distance assigned score. set subsequence length 5 parameter 0.5. Again, since edit distance kernel results
dominated spectrum kernel, show them.
Figure 12 displays results two experiment settings. left graph, train
model normal processes week 1 test processes weeks 2 7.
right graph, train normal processes week 3 test processes week
4, richest attack processes volume. attacks relatively rare compared normal
traffic, interested region ROC curves small false positive rates.
show curves area false positive rate falls region [0, 0.05].
CTBN method beats nearest neighbor SVM spectrum kernel experiments. stide
performs slightly better method combined test, achieves accuracy
770

fiI NTRUSION ETECTION USING CTBN

experiment using week 3 testing week 4. advantage CTBN model
stide easily combined prior knowledge data sources (such
network data NIDS). demonstrate loss performance flexibility.

7. Conclusions
realm temporal reasoning, introduced two additions CTBN literature. First,
demonstrated Rao-Blackwellized particle filter continuous evidence. Second, demonstrated learn reason data contains imprecise timings, still refraining
discretizing time.
realm intrusion detection, demonstrated framework performs well two
related tasks different data types. concentrating purely event timing, without
consideration complex features, able out-perform existing methods. continuoustime nature model aided greatly modeling bursty event sequences occur systems
logs network traffic. resort time slicing, either producing rapid slices
inefficient quite periods, lengthy slices miss timing bursty events.
combination two sources information (system calls network events) would
straight-forward model produced. believe would result accurate
detection. collection data difficult, however; leave interesting next step.

Acknowledgments
project supported Intel Research UC MICRO, Air Force Office Scientific
Research (FA9550-07-1-0076), Defense Advanced Research Project Agency (HR001109-1-0030).

References
Agosta, J. M., Duik-Wasser, C., Chandrashekar, J., & Livadas, C. (2007). adaptive anomaly
detector worm detection. Workshop Tackling Computer Systems Problems
Machine Learning Techniques.
A.Hofmeyr, S., Forrest, S., & Somayaji, A. (1998). Intrusion detection using sequences system
calls. Journal Computer Security, 6, 151180.
Cha, B. (2005). Host anomaly detection performance analysis based system call neuro-fuzzy
using soundex algorithm n-gram technique. Systems Communications (ICW).
Chang, C.-C., & Lin, C.-J. (2001). LIBSVM: library support vector machines. http://
www.csie.ntu.edu.tw/cjlin/libsvm.
Cohn, I., El-Hay, T., Friedman, N., & Kupferman, R. (2009). Mean field variational approximation
continous-time Bayesian networks. Uncertainty Artificial Intelligence.
Dewaele, G., Fukuda, K., & Borgnat, P. (2007). Extracting hidden anomalies using sketch non
Gaussian multiresulotion statistical detection procedures. ACM SIGCOMM.
Doucet, A., de Freitas, N., Murphy, K., & Russel, S. (2000). Rao-Blackwellised particle filtering
dynamic Bayesian networks. Uncertainty Artificial Intelligence.
771

fiX U & HELTON

El-Hay, T., Cohn, I., Friedman, N., & Kupferman, R. (2010). Continuous-time belief propagation.
Proceedings Twenty-Seventh International Conference Machine Learning.
El-Hay, T., Friedman, N., & Kupferman, R. (2008). Gibbs sampling factorized continous-time
Markov processes. Uncertainty Artificial Intelligence.
Eskin, E. (2000). Anomaly detection noisy data using learned probability distributions.
International Conference Machine Learning.
Eskin, E., Arnold, A., Prerau, M., Portnoy, L., & Stolfo, S. (2002). geometric framework
unsupervised anomaly detection: Detecting intrusions unlabeled data. Barbara, D., &
Jajodia, S. (Eds.), Applications Data Mining Computer Security. Kluwer.
Fan, Y., & Shelton, C. R. (2008). Sampling approximate inference continuous time Bayesian
networks. Symposium Artificial Intelligence Mathematics.
Fan, Y., & Shelton, C. R. (2009). Learning continuous-time social network dynamics. Proceedings Twenty-Fifth International Conference Uncertainty Artificial Intelligence.
Forrest, S., A.Hofmeyr, S., Somayaji, A., & A.Longstaff, T. (1996). sense self unix processes. IEEE Symposium Security Privacy, pp. 120128.
Hu, W., Liao, Y., & Vemuri, V. (2003). Robust support vector machines anomaly detection
computer security. International Conference Machine Learning Applications.
Kang, D.-K., Fuller, D., & Honavar, V. (2005). Learning classifiers misuse detetction using
bag system calls representation. IEEE International Conferences Intelligence
Security Informatics.
Karagiannis, T., Papagiannaki, K., & Faloutsos, M. (2005). BLINC: Multilevel traffic classification
dark. ACM SIGCOMM.
Kruegel, C., Mutz, D., Robertson, W., & Valeur, F. (2003). Bayesian event classification intrusion
detection. Annual Computer Security Applications Conference.
Lakhina, A., Crovella, M., & Diot, C. (2005). Mining anomalies using traffic feature distributions.
ACM SIGCOMM, pp. 2126.
Lazarevic, A., Ertoz, L., Kumar, V., Ozgur, A., & Srivastava, J. (2003). compare study anomaly
detection schemes network intrusion detection. SIAM International Conference Data
Mining.
LBNL.
LBNL/ICSI enterprise tracing project..
enterprise-tracing/Overview.html/.

http://www.icir.org/

Leslie, C., Eskin, E., & Noble, W. S. (2002). spectrum kernel: string kernel SVM protein
classification. Pacific Symposium Biocomputing 7:566-575.
Malan, D. J., & Smith, M. D. (2005). Host-based detection worms peer peer cooperation. Workshop Rapid Malcode.
MAWI. MAWI working group traffic archive.. http://mawi.nezu.wide.ad.jp/mawi/.
Moore, A. W., & Zuev, D. (2005). Internet traffic classification using Bayesian analysis techniques.
ACM SIGMETRICS.
Ng, B., Pfeffer, A., & Dearden, R. (2005). Continuous time particle filtering. National Conference
Artificial Intelligence, pp. 13601365.
772

fiI NTRUSION ETECTION USING CTBN

Nodelman, U., & Horvitz, E. (2003). Continuous time Bayesian networks inferring users presence activities extensions modeling evaluation. Tech. rep. MSR-TR-2003-97,
Microsoft Research.
Nodelman, U., Koller, D., & Shelton, C. R. (2005). Expectation propagation continuous time
Bayesian networks. Uncertainty Artificial Intelligence, pp. 431440.
Nodelman, U., Shelton, C. R., & Koller, D. (2002). Continuous time Bayesian networks. Uncertainty Artificial Intelligence, pp. 378387.
Nodelman, U., Shelton, C. R., & Koller, D. (2003). Learning continuous time Bayesian networks.
Uncertainty Artificial Intelligence, pp. 451458.
Nodelman, U., Shelton, C. R., & Koller, D. (2005). Expectation maximization complex duration
distributions continuous time Bayesian networks. Uncertainty Artificial Intelligence,
pp. 421430.
Press, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. (1992). Numerical Recipes C
(Second edition). Cambridge University Press.
Qin, X., & Lee, W. (2004). Attack plan recognition prediction using causal networks. Annual
Computer Security Application Conference, pp. 370379.
Rieck, K., & Laskov, P. (2007). Language models detection unknown attacks network
traffic. Journal Computer Virology.
Saria, S., Nodelman, U., & Koller, D. (2007). Reasoning right time granularity. Uncertainty
Artificial Intelligence.
Simma, A., Goldszmidt, M., MacCormick, J., Barham, P., Black, R., Isaacs, R., & Mortier, R.
(2008). CT-NOR: Representing reasoning events continuous time. Uncertainty Artificial Intelligence.
Soule, A., Salamatian, L., Taft, N., Emilion, R., & Papagiannali, K. (2004). Flow classification
histogram. ACM SIGMETRICS.
Soule, A., Salamatian, K., & Taft, N. (2005). Combining filtering statistical methods
anomaly detection. Internet Measurement Conference, pp. 331344.
Tandon, G., & Chan, P. K. (2005). Learning useful system call attributes anomaly detection.
Florida Artificial Intelligence Research Society Conference, pp. 405-410.
Warrender, C., Forrest, S., & Pearlmutter, B. (1999). Detecting intrusions using system calls: Alternative data models. IEEE Symposium Security Privacy, IEEE Computer Society.
Xu, J., & Shelton, C. R. (2008). Continuous time Bayesian networks host level network intrusion
detection. European Conference Machine Learning.
Xu, K., Zhang, Z.-L., & Bhattacharyya, S. (2005). Profiling internet backbone traffic: Behavior
models applications. ACM SIGCOMM.
Ye, N., Emran, S. M., Chen, Q., & Vilbert, S. (2002). Multivariate statistical analysis audit trails
host-based intrusion detection. IEEE Transactions Computers, 51(7), 810820.
Yeung, D.-Y., & Chow, C. (2002). Parzen-window network intrusion detectors. International
Conference Pattern Recognition.
773

fiX U & HELTON

Yeung, D.-Y., & Ding, Y. (2002). User profiling intrusion detection using dynamic static
behavioral models. Advances Knowledge Discovery Data Mining, 2336, 494505.
Zuev, D., & Moore, A. (2005). Internet traffic classification using Bayesian analysis techniques.
ACM SIGMETRICS.

774


