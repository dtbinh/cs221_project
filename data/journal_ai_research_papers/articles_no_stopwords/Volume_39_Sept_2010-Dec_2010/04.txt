Journal Artificial Intelligence Research 39 (2010) 689743

Submitted 05/10; published 12/10

Best-First Heuristic Search Multicore Machines
Ethan Burns
Sofia Lemons
Wheeler Ruml

EABURNS CS . UNH . EDU
SOFIA . LEMONS CS UNH . EDU
RUML CS . UNH . EDU

Department Computer Science
University New Hampshire
Durham, NH 03824 USA

Rong Zhou

RZHOU PARC . COM

Embedded Reasoning Area
Palo Alto Research Center
Palo Alto, CA 94304 USA

Abstract
harness modern multicore processors, imperative develop parallel versions fundamental algorithms. paper, compare different approaches parallel best-first search
shared-memory setting. present new method, PBNF, uses abstraction partition state
space detect duplicate states without requiring frequent locking. PBNF allows speculative
expansions necessary keep threads busy. identify fix potential livelock conditions
approach, proving correctness using temporal logic. approach general, allowing
extend easily suboptimal anytime heuristic search. empirical comparison STRIPS
planning, grid pathfinding, sliding tile puzzle problems using 8-core machines, show
A*, weighted A* Anytime weighted A* implemented using PBNF yield faster search
improved versions previous parallel search proposals.

1. Introduction
widely anticipated future microprocessors faster clock rates, instead
computing cores per chip. Tasks exist effective parallel algorithms
suffer slowdown relative total system performance. artificial intelligence, heuristic
search fundamental widely-used problem solving framework. paper, compare
different approaches parallelizing best-first search, popular method underlying algorithms
Dijkstras algorithm A* (Hart, Nilsson, & Raphael, 1968).
best-first search, two sets nodes maintained: open closed. Open contains search
frontier: nodes generated yet expanded. A*, open nodes sorted
f value, estimated lowest cost solution path going node. Open typically
implemented using priority queue. Closed contains previously generated nodes, allowing
search detect states reached via multiple paths search space avoid expanding
multiple times. closed list typically implemented hash table. central challenge
parallelizing best-first search avoiding contention threads accessing open
closed lists. look variety methods parallelizing best-first search, focusing
algorithms based two techniques: parallel structured duplicate detection parallel
retracting A*.
c
2010
AI Access Foundation. rights reserved.

fiB URNS , L EMONS , RUML , & Z HOU

Parallel structured duplicate detection (PSDD) originally developed Zhou Hansen
(2007) parallel breadth-first search, order reduce contention shared data structures
allowing threads enjoy periods synchronization-free search. PSDD requires user supply
abstraction function maps multiple states, called nblock, single abstract state.
present new algorithm based PSDD called Parallel Best-N Block-First (PBNF1 ). Unlike PSDD,
PBNF extends easily domains non-uniform non-integer move costs inadmissible
heuristics. Using PBNF infinite search space give rise livelock, threads continue
search goal never expanded. discuss condition avoided
PBNF using method call hot nblocks, well use bounded model checking test
effectiveness. addition, provide proof correctness PBNF framework, showing
liveness completeness general case.
Parallel retracting A* (PRA*) created Evett, Hendler, Mahanti, Nau (1995). PRA*
distributes search space among threads using hash nodes state. PRA*, duplicate
detection performed locally; communication peers required transfer generated
search-nodes home processor. PRA* sensitive choice hashing function used
distribute search space. show new hashing function, based state space
abstraction used PSDD, give PRA* significantly better performance domains.
Additionally, show communication cost incurred naive implementation PRA*
prohibitively expensive. Kishimoto, Fukunaga, Botea (2009) present method helps
alleviate cost communication PRA* using asynchronous message passing primitives.
evaluate PRA* (and variants), PBNF algorithms empirically using dual quadcore Intel machines. study behavior three popular search domains: STRIPS planning,
grid pathfinding, venerable sliding tile puzzle. empirical results show simplest
parallel search algorithms easily outperformed serial A* search even run
eight threads. results indicate adding abstraction PRA* algorithm give
larger increase performance simply using asynchronous communication, although using
modifications together may outperform either one used own. Overall, PBNF
algorithm often gives best performance.
addition finding optimal solutions, show adapt several algorithms
bounded suboptimal search, quickly finding w -admissible solutions (with cost within factor w
optimal). provide new pruning criteria parallel suboptimal search prove algorithms using retain w -admissibility. results show that, sufficiently difficult problems,
parallel search may significantly outperform serial weighted A* search. found
advantage parallel suboptimal search increases problem difficulty.
Finally, demonstrate parallel searches, PBNF PRA*, lead naturally
effective anytime algorithms. evaluate obvious parallel anytime search strategies
running multiple weighted A* searches parallel different weights. show
parallel anytime searches able find better solutions faster serial counterparts
able converge quickly optimal solutions.

1. Peanut Butter N (marshmallow) Fluff, known fluffernutter, well-known childrens sandwich
USA.

690

fiB EST-F IRST EARCH ULTICORE ACHINES

2. Previous Approaches
much previous work parallel search. briefly summarize selected proposals
turning foundation work, PRA* PSDD algorithms.
2.1 Depth- Breadth-first Approaches
Early work parallel heuristic search investigated approaches based depth-first search. Two
examples distributed tree search (Ferguson & Korf, 1988), parallel window search (Powley
& Korf, 1991).
Distributed tree search begins single thread, given initial state expand.
time node generated unused thread assigned node. threads allocated
tree depth-first manner free threads assign. occurs,
thread continue searching children depth-first search. solution
subtree found passed tree parent thread child thread becomes free
re-allocated elsewhere tree. Parent threads go sleep children search,
waking children terminate, passing solutions upward parents recursively.
keep closed list, depth-first search cannot detect duplicate states give
good search performance domains many duplicate states, grid pathfinding
planning domains.
Parallel window search parallelizes iterative deepening A* (IDA*, see Korf, 1985) algorithm. parallel window search, thread assigned cost-bound perform costbounded depth-first search search space. problem approach IDA*
spend least half search time final iteration since every iteration still performed
single thread, search limited speed single thread. addition, nonuniform costs foil iterative deepening, may good way choose new
upper-bounds give search geometric growth.
Holzmann Bosnacki (2007) able successfully parallelize depth-first search
model checking. authors able demonstrate technique distributes nodes
based search depth able achieve near linear speedup domain model checking.
research used graphics processing units (GPUs) parallelize breadth-first search
use two-player games (Edelkamp & Sulewski, 2010). following sections describe
algorithms intent parallelizing best-first search.
2.2 Simple Parallel Best-first Search
simplest approach parallel best-first search open closed lists shared
among threads (Kumar, Ramesh, & Rao, 1988). maintain consistency data structures,
mutual exclusion locks (mutexes) need used ensure single thread accesses data
structure time. call search parallel A*. Since node expanded taken
open list node generated looked closed list every thread,
approach requires lot synchronization overhead ensure consistency data structures.
see Section 4.3, naive approach performs worse serial A*.
much work designing complex data structures retain correctness
concurrent access. idea behind special wait-free data structures many threads
use portions data structure concurrently without interfering one another.
691

fiB URNS , L EMONS , RUML , & Z HOU

approaches use special compare-and-swap primitive ensure that, modifying
structure, get modified another thread. implemented simple parallel A* search,
call lock-free parallel A*, threads access single shared, concurrent priority
queue concurrent hash table open closed lists, respectively. implemented
concurrent priority queue data structure Sundell Tsigas (2005). closed list, used
concurrent hash table implemented array buckets, concurrent
ordered list developed Harris (2001). lock-free data structures used implement LPA*
require special lock-free memory manager uses reference counting compare-and-swap
based stack implement free list (Valois, 1995). see that, even sophistocated
structures, straightforward parallel implementation A* give competitive performance.
One way avoiding contention altogether allow one thread handle synchronization
work done threads. K -Best-First Search (Felner, Kraus, & Korf, 2003) expands
best k nodes once, handled different thread. implementation,
master thread takes k best nodes open gives one worker. workers expand
nodes master checks children duplicates inserts open list.
allows open closed used without locking, however, order adhere strict
k -best-first ordering approach requires master thread wait workers finish
expansions handing new nodes. domains used paper, node expansion
particularly slow, show method scale well.
One way reduce contention search access closed list less frequently. technique called delayed duplicate detection (DDD) (Korf, 2003), originally developed externalmemory search, used temporarily delay access closed list. several variations proposed, basic principle behind DDD generated nodes added
single list certain condition met (a depth level fully expanded, maximum list
size reached (Stern & Dill, 1998), etc.) condition met, list sorted
draw duplicate nodes together. nodes list checked closed list,
best version kept inserted onto open list. initial DDD algorithm used
breadth-first frontier search therefore previous depth-layer required duplicate
detection. parallel version later presented Niewiadomski, Amaral, Holte (2006a),
split depth layer sections maintained separate input output lists each.
later merged order perform usual sorting duplicate detection methods.
large synchronization step, however, incur costs similar KBFS. depends upon
expensive workload distribution scheme ensure processors work do, decreasing bottleneck effect nodes distributed unevenly, increasing algorithms
overhead. later parallel best-first frontier search based DDD presented (Niewiadomski,
Amaral, & Holte, 2006b), incurs even overhead requiring synchronization
threads maintain strict best-first ordering.
Jabbar Edelkamp (2006) present algorithm called parallel external A* (PEA*) uses
distributed computing nodes external memory perform best-first search. PEA* splits
search space set buckets contain nodes g h values.
algorithm performs best-first search exploring buckets lowest f value beginning
one lowest g. master node manages requests distribute portions current
bucket various processing nodes expanding single bucket performed parallel.
avoid contention, PEA* relies operating system synchronize access files
shared among nodes. Jabbar Edelkamp used PEA* algorithm parallelize
692

fiB EST-F IRST EARCH ULTICORE ACHINES

model-checker achieved almost linear speedup. partitioning g h works
domains general nodes g h values. tends case
domains real-valued edge costs. turn attention two algorithms reappear
throughout rest paper: PRA* PSDD.
2.3 Parallel Retracting A*
PRA* (Evett et al., 1995) attempts avoid contention assigning separate open closed lists
thread. hash state representation used assign nodes appropriate thread
generated. (Full PRA* includes retraction scheme reduces memory use
exchange increased computation time; consider feature paper.)
choice hash function influences performance algorithm, since determines way
work distributed. Note standard PRA*, thread may communicate
peers, thread needs synchronized message queue peers add nodes.
multicore setting, implemented requiring thread take lock message queue.
Typically, requires thread sending (or receiving) message wait operation
complete continue searching. less bottleneck single
global, shared open list, see still expensive. interesting
note PRA* variants mentioned practice type delayed duplicate detection,
store duplicates temporarily checking thread-local closed list
possibly inserting open list.
2.3.1 MPROVEMENTS
Kishimoto et al. (2009) note original PRA* implementation improved removing synchronization requirement message queues nodes. Instead, use
asynchronous send receive functionality MPI message passing library (Snir & Otto,
1998) implement asynchronous version PRA* call Hash Distributed A* (HDA*).
HDA* distributes nodes using hash function way PRA*, except sending
receiving nodes happens asynchronously. means threads free continue searching
nodes communicated peers transit.
contact authors HDA*, created implementation HDA* multicore
machines extra overhead message passing asynchronous communication threads shared memory setting. Also, implementation HDA* allows us
make fair comparison algorithms sharing common data structures priority
queues hash tables.
implementation, HDA* thread given single queue incoming nodes one
outgoing queue peer thread. queues implemented dynamically sized arrays
pointers search nodes. generating nodes, thread performs non-blocking call
acquire lock2 appropriate peers incoming queue, acquiring lock available
immediately returning failure busy, rather waiting. lock acquired simple
pointer copy transfers search node neighboring thread. non-blocking call fails
nodes placed outgoing queue peer. operation require lock
outgoing queue local current thread. certain number expansions, thread
attempts flush outgoing queues, never forced wait lock send nodes.
2. One non-blocking call pthread mutex trylock function POSIX standard.

693

fiB URNS , L EMONS , RUML , & Z HOU

Figure 1: simple abstraction. Self-loops eliminated.
attempts consume incoming queue waits lock open list empty,
case work do. Using simple efficient implementation,
confirmed results Kishimoto et al. (2009) show asynchronous version
PRA* (called HDA*) outperforms standard synchronous version. Full results presented
Section 4.
PRA* HDA* use simple representation-based node hashing scheme one,
example, used look nodes closed lists. present two new variants, APRA*
AHDA*, make use state space abstraction distribute search nodes among processors.
Instead assigning nodes thread, thread assigned set blocks search space
block corresponds state abstract space. intuition behind approach
children single node assigned small subset remote threads
and, fact, often assigned back expanding thread itself. reduces number
edges communication graph among threads search, reducing chances thread
contention. Abstract states distributed evenly among threads using modulus operator
hope open nodes always available thread.
2.4 Parallel Structured Duplicate Detection
PSDD major previously-proposed alternative PRA*. intention PSDD avoid
need lock every node generation avoid explicitly passing individual nodes
threads. builds idea structured duplicate detection (SDD), originally developed external memory search (Zhou & Hansen, 2004). SDD uses abstraction function,
many-to-one mapping states original search space states abstract space.
abstract node state mapped called image. nblock set nodes
state space image abstract space. abstraction function creates abstract graph nodes images nodes state space. two states successors
state space, images successors abstract graph. Figure 1 shows state space
graph (left) consisting 36 nodes abstract graph (right) consists nine nodes.
node abstract graph represents grouping four nodes, called nblock, original state
space, shown dotted lines state space graph left.
694

fiB EST-F IRST EARCH ULTICORE ACHINES

Figure 2: Two disjoint duplicate detection scopes.

nblock open closed list. avoid contention, thread acquire exclusive
access nblock. Additionally, thread acquires exclusive access nblocks correspond successors abstract graph nblock searching. nblock
call set nblocks successors abstract graph duplicate detection scope.
abstract nodes access required order perform
perfect duplicate detection expanding nodes given nblock. thread expands
node n nblock b children n must fall within b one nblocks successors
b abstract graph. Threads determine whether new states generated expanding
n duplicates simply checking closed lists nblocks duplicate detection scope.
require synchronization thread exclusive access set nblocks.
PSDD, abstract graph used find nblocks whose duplicate detection scopes disjoint. nblocks searched parallel without locking node expansions.
Figure 2 shows two disjoint duplicate detection scopes delineated dashed lines different
patterns. nblock use thread whose duplicate detection scope
use considered free. free nblock available thread acquire searching. Free nblocks found explicitly tracking, nblock b, (b), number nblocks
among bs successors use another thread. nblock b acquired
(b) = 0.
advantage PSDD requires single lock, one controlling manipulation
abstract graph, lock needs acquired threads finding new free
nblock search. means threads need synchronize expanding nodes,
common operation.
Zhou Hansen (2007) used PSDD parallelize breadth-first heuristic search (Zhou & Hansen,
2006). algorithm, nblock two lists open nodes. One list contains open nodes
current search depth contains nodes next search depth. thread,
nodes current search depth acquired nblock expanded. children
generated put open list next depth nblock map (which
duplicate detection scope nblock searched) long duplicates.
current nblock nodes current depth, swapped free nblock
695

fiB URNS , L EMONS , RUML , & Z HOU

open nodes depth. nblocks open nodes current depth,
threads synchronize progress together next depth. admissible heuristic used
prune nodes fall current solution upper bound.
2.4.1 MPROVEMENTS
PSDD viewed general framework parallel search, terminology, PSDD
refers instance SDD parallel setting uses layer-based synchronization breadthfirst search. subsection, present two algorithms use PSDD framework attempt
improve PSDD algorithm specific ways.
implemented Zhou Hansen (2007), PSDD algorithm uses heuristic estimate
node pruning; effective tight upper bound already available.
cope situations good bound available, implemented novel algorithm
using PSDD framework uses iterative deepening (IDPSDD) increase bound.
report below, approach effective domains grid pathfinding
geometrically increasing number nodes within successive f bounds.
Another drawback PSDD breadth-first search cannot guarantee optimality domains
operators differing costs. anticipation problems, Zhou Hansen (2004)
suggest two possible extensions work, best-first search speculative best-first layering
approach allows larger layers cases nodes (or nblocks)
f value. knowledge, first implement test algorithms.
Best-first PSDD (BFPSDD) uses f value layers instead depth layers. means
nodes expanded given layer (lowest) f value. BFPSDD provides bestfirst search order, may incur excessive synchronization overhead nodes
f layer. ameliorate this, loosen best-first ordering enforcing least nodes
expanded abandoning non-empty nblock. (Zhou & Hansen, 2007 credit Edelkamp &
Schrodl, 2000 idea.) Also, populating list free nblocks layer,
nblocks nodes current layers f value used minimum k nblocks
added k four times number threads. (This value k gave better performance
values tested.) allows us add additional nblocks small layers order amortize
cost synchronization. addition, tried alternative implementation BFPSDD used
range f values layer. parameter f used proscribe width (in f values)
layer search. implementation perform well present results
it. either enhancements, threads may expand nodes f values greater
current layer. first solution found may optimal, search continues
remaining nodes pruned incumbent solution.
surveyed existing approaches parallel best-first search, present new
approach comprises main algorithmic contribution paper.

3. Parallel Best-N Block-First (PBNF)
ideal scenario, threads would busy expanding nblocks contain nodes lowest
f values. approximate this, combine PSDDs duplicate detection scopes idea
Localized A* algorithm Edelkamp Schrodl (2000). Localized A*, designed
improve locality external memory search, maintains sets nodes reside
memory page. decision set process next made help heap sets
696

fiB EST-F IRST EARCH ULTICORE ACHINES

1. nblock open nodes
2. lock; b best free nblock; unlock
3. b worse best free nblock weve done fewer min expansions
4.
best open node b
5.
f (m) f (incumbent), prune open nodes b
6.
else goal
7.
f (m) < f (incumbent)
8.
lock; incumbent m; unlock
9.
else child c
10.
c closed list nblock
11.
insert c open list appropriate nblock
Figure 3: sketch basic PBNF search, showing locking.
ordered minimum f value set. maintaining heap free nblocks ordered
nblocks best f value, approximate ideal parallel search. call algorithm Parallel
Best-N Block-First (PBNF) search.
PBNF, threads use heap free nblocks acquire free nblock best open
node. thread search acquired nblock long contains nodes better
nblock front heap. acquired nblock becomes worse best free
one, thread attempt release current nblock acquire better one contains
open nodes lower f values. layer synchronization, threads need wait
unless nblocks free. first solution found may suboptimal, search must continue
open nodes f values worse incumbent solution. Figure 3 shows high-level
pseudo-code algorithm.
PBNF designed tolerate search order approximately best-first,
freedom introduce optimizations reduce overhead. possible nblock
small number nodes better best free nblock, avoid excessive switching
requiring minimum number expansions. Due minimum expansion requirement
possible nodes expanded thread arbitrarily worse frontier node
minimum f . refer expansions speculative. viewed trading node
quality reduced contention abstract graph. Section 4.1 shows results experiment
evaluates trade off.
implementation attempts reduce time thread forced wait lock
using non-blocking operations acquire lock whenever possible. Rather sleeping lock
cannot acquired, non-blocking lock operation (such pthread mutex trylock)
immediately return failure. allows thread continue expanding current nblock lock
busy. optimizations introduce additional speculative expansions would
performed serial best-first search.
3.1 Livelock
greedy free-for-all order PBNF threads acquire free nblocks lead livelock
domains infinite state spaces. threads always acquire new nblocks without waiting
open nodes layer expanded, possible nblock containing goal
697

fiB URNS , L EMONS , RUML , & Z HOU

never become free. assurance nblocks duplicate detection
scope ever unused time. example, imagine situation threads
constantly releasing acquiring nblocks prevent goal nblock becoming free.
fix this, developed method called hot nblocks threads altruistically release
nblock interfering better nblock. call enhanced algorithm Safe PBNF.
use term interference scope b refer set nblocks that, acquired,
would prevent b free. interference scope includes bs successors
abstract graph, predecessors too. Safe PBNF, whenever thread checks heap
free nblocks determine release current nblock, ensures acquired
nblock better interferes (nblocks whose interference scope
acquired nblock in). finds better one, flags nblock hot. thread finds
blocking hot nblock release nblock attempt free hot nblock.
nblock b define h (b) number hot nblocks b interference scope of.
h (b) 6= 0, b removed heap free nblocks. ensures thread acquire
nblock preventing hot nblock becoming free.
Consider, example, abstract graph containing four nblocks connected linear fashion:
B C . possible execution PBNF alternate thread expanding
nblocks C . situation arrises nblocks B never considered free.
goals located nblock B then, infinite search space may livelock.
Safe variant PBNF, however, expanding either C thread make sure
check f value best open node nblock B periodically. best node B seen
better nodes C B flagged hot nblocks C
longer eligable expansion nblock B acquired.
formally, let N set nblocks, Predecessors(x ) Successors(x ) sets
predecessors successors abstract graph nblock x , H set hot nblocks,
IntScope(b) = {l N : x Successors(b) : l Predecessors(x )} interference scope
nblock b x partial order nblocks x iff minimum f
value open nodes x lower y. three cases consider
attempting set nblock b hot undirected abstract graph:
1. H IntScope(b) = {} H {x N : b IntScope(x )} = {}; none nblocks b
interferes interfere b hot, b set hot.
2. x H : x IntScope(b) x b; b interfered better nblock already
hot, b must set hot.
3. x H : x IntScope(b) b x ; b interfered nblock x worse
b x already hot. x must un-flagged hot (updating h values appropriately)
place b set hot.
Directed abstract graphs two additional cases:
4. x H : b IntScope(x ) b x ; b interfering nblock x b better x
un-flag x hot set b hot.
5. x H : b IntScope(x ) x b; b interfering nblock x x better b
set b hot.
698

fiB EST-F IRST EARCH ULTICORE ACHINES

scheme ensures never two hot nblocks interfering one another
nblock set hot best nblock interference scope. verify below,
approach guarantees property nblock flagged hot eventually become free.
Full pseudo-code Safe PBNF given Appendix A.
3.2 Correctness PBNF
Given complexity parallel shared-memory algorithms, reassuring proofs
correctness. subsection verify PBNF exhibits various desirable properties:
3.2.1 OUNDNESS
Soundness holds trivially solution returned pass goal test.
3.2.2 EADLOCK
one lock PBNF thread currently holds never attempts acquire
second time, deadlock cannot arise.
3.2.3 L IVELOCK
interaction different threads PBNF quite complex, modeled
system using TLA+ (Lamport, 2002) specification language. Using TLC model checker
(Yu, Manolios, & Lamport, 1999) able demonstrate sequence states give rise
livelock plain PBNF. Using similar model unable find example livelock
Safe PBNF using three threads 12 nblocks undirected ring-shaped abstract
graph three threads eight nblocks directed graph.
model state system represented four variables: state, acquired, isHot
Succs. state variable contains current action thread performing (either search
nextblock). acquired variable function thread ID acquired nblock
value None currently nblock. variable isHot function
nblocks either TRUE FALSE depending whether given nblock flagged hot.
Finally, Succs variable gives set successor nblocks nblock order build
nblock graph.
model two actions: doSearch doNextBlock. doSearch action models search
stage performed PBNF thread. Since interested determining livelock,
action abstracts away search procedure merely models thread may
choose valid nblock flag hot. setting nblock hot, thread changes state
next time selected perform action try acquire new nblock.
doNextBlock simulates thread choosing next nblock one available. thread
acquires nblock (if one free) sets state next time selected perform
action search.
TLA+ source model located Appendix B.
Formal proof: addition model checking, TLA+ specification language designed
allow formal proofs properties. allows properties proved unbounded space.
Using model completed formal proof hot nblock eventually become free
699

fiB URNS , L EMONS , RUML , & Z HOU

regardless number threads abstract graph. present English summary.
First, need helpful lemma:
Lemma 1 nblock n hot, least one nblock interference scope
use. Also, n interfering hot nblocks.
Proof: Initially nblocks hot. change thread searches releases
nblock. search, thread set n hot acquired nblock
interference scope n. Additionally, thread may set n hot create
interference another hot nblock. release, n hot, either final acquired nblock
interference scope released n longer hot, n still least one busy nblock
interference scope.
2
ready key theorem:
Theorem 1 nblock n becomes hot, eventually added free list
longer hot.
Proof: show number acquired nblocks interference scope hot nblock
n strictly decreasing. Therefore, n eventually become free.
Assume nblock n hot. Lemma 1, thread p nblock interference scope n, n interfering interfered hot nblocks. Assume
thread q nblock interference scope n. four cases:
1. p searches nblock. p acquire new nblock therefore number nblocks
preventing n becoming free increase. p sets nblock hot,
interference scope n Lemma 1. p release nblock sees n hot
(see case 2).
2. p releases nblock acquires new nblock free list. number acquired
nblocks interference scope n decreases one p releases nblock. Since m,
new nblock acquired p, free list, interference scope n.
3. q searches nblock. q acquire new nblock therefore number nblocks
preventing n becoming free increase. q sets nblock hot,
interference scope n Lemma 1.
4. q releases nblock (if one) acquires new nblock free list. Since m,
new nblock acquired q, free list, interference scope n
number nblocks preventing n becoming free increase.
2
prove progress property really care about:
Theorem 2 node n minimum f value eventually expanded.
Proof: consider ns nblock. three cases:
1. nblock expanded. n minimum f , front open
expanded.
700

fiB EST-F IRST EARCH ULTICORE ACHINES

2. nblock free. holds node minimum f value, front
free list selected next expansion, reducing case 1.
3. nblock free list interference scope another nblock
currently expanded. thread expanding nblock checks interference
scope, mark better nblock hot. Theorem 1, eventually reach case 2.
2
3.2.4 C OMPLETENESS
follows easily liveness:
Corollary 1 heuristic admissible search space finite, goal returned one
reachable.
Proof: heuristic admissible, inherit completeness serial A* (Nilsson, 1980)
Theorem 2. Nodes re-expanded g value improved, happen
finite number times, finite number expansions suffice exhaust search space. 2
3.2.5 PTIMALITY
PBNFs expansion order strictly best-first, operates anytime algorithm,
optimality follows argument algorithms Anytime A* (Hansen &
Zhou, 2007).
Theorem 3 PBNF return optimal solutions.
Proof: finding incumbent solution, search continues expand nodes minimum
f value among frontier nodes greater equal incumbent solution cost. means
search terminate optimal solution.
2
discussing adapt PBNF suboptimal anytime search, first evaluate
performance optimal problem solving.

4. Empirical Evaluation: Optimal Search
implemented tested parallel heuristic search algorithms described three
different benchmark domains: grid pathfinding, sliding tile puzzle, STRIPS planning.
discuss domain turn. exception planning domain, algorithms
programmed C++ using POSIX threading library run dual quad-core Intel Xeon E5320
1.86GHz processors 16Gb RAM. planning results algorithms written independently C pseudo code Appendix A. gives us additional confidence
correctness pseudo code performance claims. planning experiments run
dual quad-core Intel Xeon X5450 3.0GHz processors limited roughly 2GB RAM. open
lists free lists implemented binary heaps except PSDD IDPSDD used
queue giving less overhead since require access minimum valued elements.
closed lists implemented hash tables. PRA* APRA* used queues incoming nodes,
hash table used detect duplicates open closed. grids sliding tiles,
701

fiB URNS , L EMONS , RUML , & Z HOU

used jemalloc library (Evans, 2006), special multi-thread-aware malloc implementation,
instead standard glibc (version 2.7) malloc, found latter scales poorly
6 threads. configured jemalloc use 32 memory arenas per CPU. planning, custom
memory manager used thread-aware uses memory pool thread.
grids sliding tiles abstractions hand-coded and, nblock data structures created
lazily, visited part abstract graph instantiated. time taken create
abstraction accounted wall time measurements two domains. STRIPS
planning abstractions created automatically creation times abstractions
reported separately described Section 4.5.
4.1 Tuning PBNF
section present results set experiments designed test behavior
PBNF parameters changed. study effects two important parameters
PBNF algorithm: minimum expansions required switching search new nblock
size abstraction. study used twenty 5000x5000 four-connected grid pathfinding
instances unit cost moves cell 0.35 probability obstacle.
heuristic used Manhattan distance goal location. Error bars plots show 95%
confidence intervals legends sorted mean dependent variable plot.
PBNF algorithm, thread must perform minimum number expansions
able acquire new nblock searching. Requiring expansions switches
expected reduce contention nblock graphs lock could increase total number
expanded nodes. created instrumented version PBNF algorithm tracks
time threads spent trying acquire lock amount time threads
spent waiting free nblock. fixed size abstraction 62,500 nblocks
varied number threads (from 1 8) minimum expansions (1, 8, 16, 32 64 minimum
expansions).
upper left panel Figure 4 shows average amount CPU time seconds
thread spent waiting acquire lock (y-axis) minimum expansions parameter increased (x-axis). line plot represents different number threads. see
configuration used amount time trying acquire lock eight threads
one minimum expansion. number threads decreased, less contention
lock fewer threads take it. number minimum required expansions
increased contention reduced. Around eight minimum expansions benefit increasing value seemed greatly diminish.
upper right panel Figure 4 shows results CPU time spent waiting free
nblock (y-axis) minimum expansions increased (x-axis). different amount
time waiting lock because, case, thread successfully acquired lock
found free nblocks available search. see configuration
eight threads one minimum expansions caused longest amount time waiting
free nblock. number threads decreased required number minimum
expansions increased wait time decreased. amount time spent waiting, however, seems
fairly insignificant order magnitude smaller lock time. Again, see
around eight minimum expansions benefit increasing seemed diminish.
702

fi8
7
6
5
4
3
2
1

0.3

average time waiting (seconds)

average time acquiring locks (seconds)

B EST-F IRST EARCH ULTICORE ACHINES

0.2

0.1

8
7
6
5
4
3
2
1

0.02

0.01

0.0
20

40

60

20

total nodes expanded (1K nodes)

minimum expansions

40

60

minimum expansions

2,600

2,500

8
7
6
5
4
3
2
1

2,400

20

40

60

minimum expansions

Figure 4: PBNF locking behavior vs minimum expansions grid pathfinding 62,500
nblocks. line represents different number threads.

final panel, bottom Figure 4, shows total number nodes expanded (y-axis,
thousands nodes) minimum expansions increased. Increasing minimum
number expansions thread must make switching nblock better nodes
caused search algorithm explore space may covered strict
best-first search. speculative expansions performed total number
nodes encountered search increased. see adding threads increased
number expanded nodes too.
results experiment appears requiring eight expansions switching nblocks decreasing benefit respect locking waiting time.
non-instrumented implementation PBNF found slightly greater values minimum
expansion parameter lead best total wall times. domain use value
gave best total wall time non-instrumented PBNF implementation.
703

fiB URNS , L EMONS , RUML , & Z HOU

0.9

8
7
6
5
4
3
2
1

8
7
6
5
4
3
2
1

0.08

average time waiting (seconds)

average time acquiring locks (seconds)

1.2

0.6

0.3

0.06

0.04

0.02

0.0
50

100

150

200

250

50

total nodes expanded (1K nodes)

abstraction size (1K nblocks)

100

150

200

250

abstraction size (1K nblocks)

2,600

2,500

8
7
6
5
4
3
2
1

2,400

50

100

150

200

250

abstraction size (1K nblocks)

Figure 5: PBNF abstraction size: 5000x5000 grid pathfinding, 32 minimum expansions.

Since PBNF uses abstraction decompose search space important understand
effect abstraction size search performance. hypothesis using abstract
states would lead small number free nblocks therefore making threads spend lot
time waiting nblock become free. hand, many abstract states
nodes nblock. happens, threads perform small
amount work exhausting open nodes nblock forced switch
new portion search space. time thread must switch nblocks contention
lock increased. Figure 5 shows results experiment performed verify
theory. plot fixed minimum expansions parameter 32 (which gave best
total wall time grid pathfinding) varied number threads (from 1 8) size
abstraction (10,000, 62,500 250,000 nblocks).
upper left panel Figure 5 shows plot amount CPU seconds spent trying acquire lock (y-axis) versus size abstraction (x-axis). expected, abstraction
coarse little time spent waiting lock, size abstraction grew
704

fiB EST-F IRST EARCH ULTICORE ACHINES

number threads increased amount time spent locking increased. eight threads
250,000 nblocks 1 second CPU time spent waiting acquire lock. suspect
threads exhausting open nodes nblocks were, therefore,
forced take lock acquire new portion search space.
upper right panel Figure 5 shows amount time threads spent waiting
nblock become free successfully acquired lock find nblocks
available. Again, suspected, amount time threads wait free nblock decreases
abstraction size increased. available nblocks, disjoint portions
search space available. experiments minimum expansions, amount
time spent waiting seems relatively insignificant compared time spent acquiring locks.
bottom panel Figure 5 shows number nodes expanded increased
size abstraction increased. finer grained abstractions algorithm expanded
nodes. time thread switches new nblock forced perform
least minimum number expansions, therefore switches, forced expansions.
4.2 Tuning PRA*
turn looking performance impact PRA* abstraction asynchronous communication. First, compare PRA* without asynchronous communication. Results
set experiments twenty 5000x5000 grid pathfinding set 250 random 15-puzzle instances solvable A* 3 million expansions shown Figure 6. line labeled
sync. (PRA*) used synchronous communication, async. sends, used synchronous receives asynchronous sends, async. receives, used synchronous sends asynchronous receives async.
(HDA*), used asynchronous communication sends receives. before, legend
sorted mean performance error bars represent 95% confidence intervals
mean. vertical lines plots life cost grid pathfinding domains show
configurations unable solve instances within 180 second time limit.
combination asynchronous sends receives provided best performance.
see plots making sends asynchronous provided benefit
making receives asynchronous. because, without asynchronous sends, node generated stop generating thread order communicate. Even communication batched,
send may required go separate neighbor therefore single send operation may
required per-generation. receives, worst case receiving thread must stop
expansion receive next batch nodes. Since branching factor typical search space
approximately constant approximately constant factor send communications
receive communications worst case. Therefore, making sends asynchronous reduces
communication cost receives.
Figure 7 shows results experiment compares PRA* using abstraction distribute
nodes among threads versus PRA* asynchronous communication. lines labeled
follows: sync. (PRA*) used synchronous communication, async. (HDA*) used asynchronous communication sync. abst. (APRA*) used synchronous communication
used abstraction distribute nodes among threads async. abst. (AHDA*) used combination asynchronous communication abstraction. Again, vertical lines plots
life cost grid pathfinding domains show configurations unable solve instances
within 180 second time limit.
705

fiB URNS , L EMONS , RUML , & Z HOU

Grid Unit Four-way
sync. (PRA*)
async. receives
async. sends
async. (HDA*)

sync. (PRA*)
async. receives
async. sends
async. (HDA*)

30

wall time (seconds)

30

wall time (seconds)

Grid Unit Eight-way

20

20

10

10

2

4

6

8

2

4

threads
Grid Life Four-way
200

6

8

threads
Grid Life Eight-way
200

sync. (PRA*)
async. receives
async. sends
async. (HDA*)

sync. (PRA*)
async. receives
async. sends
async. (HDA*)

wall time (seconds)

wall time (seconds)

160

120

80

100

40
0
2

4

6

8

threads

2

6

8

threads

sync. (PRA*)
async. receives
async. sends
async. (HDA*)

10

wall time (seconds)

4

15-Puzzles: 250 easy

8

6

4

2

4

6

8

threads

Figure 6: PRA* synchronization: 5000x5000 grids easy sliding tile instances.

clear plots configurations PRA* used abstraction gave better
performance PRA* without abstraction grid pathfinding domain. reason
706

fiB EST-F IRST EARCH ULTICORE ACHINES

Grid Unit Four-way
sync. (PRA*)
async. (HDA*)
sync. abst. (APRA*)
async. abst. (AHDA*)

sync. (PRA*)
async. (HDA*)
sync. abst. (APRA*)
async. abst. (AHDA*)

30

wall time (seconds)

30

wall time (seconds)

Grid Unit Eight-way

20

20

10

10

2

4

6

8

2

4

threads
Grid Life Four-way
200

6

8

threads
Grid Life Eight-way
200

sync. (PRA*)
async. (HDA*)
sync. abst. (APRA*)
async. abst. (AHDA*)

sync. (PRA*)
async. (HDA*)
sync. abst. (APRA*)
async. abst. (AHDA*)

wall time (seconds)

wall time (seconds)

160

120

80

100

40

0
2

4

6

8

threads

4

6

8

threads

sync. (PRA*)
async. (HDA*)
sync. abst. (APRA*)
async. abst. (AHDA*)

10

wall time (seconds)

2

15 Puzzles: 250 easy

8

6

4

2

4

6

8

threads

Figure 7: PRA* abstraction: 5000x5000 grids easy sliding tile instances.

abstraction grid pathfinding often assign successors node expanded
back thread generated them. happens communication required
707

fiB URNS , L EMONS , RUML , & Z HOU

nodes simply checked local closed list placed local open list
duplicates. abstraction, time communication required
node edge abstract state expanded. case, children map
different abstract state communication required. experiment shows
benefits abstraction greater benefits asynchronous communication grid
pathfinding problems. see trends sliding tile instances, however
quite pronounced; confidence intervals often overlap.
Overall, appears combination PRA* abstraction distributing nodes
among different threads using asynchronous communication gave best performance.
following section show results comparison variant PRA*, Safe
PBNF algorithm best-first variant PSDD.
4.3 Grid Pathfinding
section, evaluate parallel algorithms grid pathfinding domain. goal
domain navigate grid initial location goal location avoiding
obstacles. used two cost models (discussed below) four-way eight-way movement.
four-way grids, cells blocked probability 0.35 eight-way grids
cells blocked probability 0.45. abstraction function used maps blocks
adjacent cells abstract state, forming coarser abstract grid overlaid original
space. heuristic Manhattan distance goal location. hash values states
(which used distribute nodes PRA* HDA*) computed as: x ymax + state
location. gives minimum perfect hash value state. domain able
tune size abstraction results show execution best abstraction size
algorithm relevant.
4.3.1 F -WAY U NIT C OST
unit-cost model, move cost: one.
Less Promising Algorithms Figure 8, shows performance comparison algorithms that,
average, slower serial A*. algorithms tested 20 unit-cost four-way
movement 1200x2000 grids start location bottom left corner goal location
bottom right. x-axis shows number threads used solve instance y-axis
shows mean wall clock time seconds. error bars give 95% confidence interval
mean wall clock time legend sorted mean performance.
figure see PSDD gave worst average solution times. suspect
lack tight upper bound PSDD uses pruning. see A*
shared lock-free open closed list (LPA*) took, average, second longest amount time
solve problems. LPA*s performance improved 5 threads started drop
threads added. overhead special lock-free memory manager along
fact access lock-free data structures may require back-offs retries could account
poor performance compared serial A*. next algorithm, going top
legend, KBFS slowly increased performance threads added however
able beat serial A*. simple parallel A* implementation (PA*) using locks
open closed lists performed worse threads added four started
give slow performance increase matching KBFS. PRA* algorithm using simple
708

fiB EST-F IRST EARCH ULTICORE ACHINES

15

PSDD
LPA*
KBFS
PA*
PRA*
Serial A*

wall time (seconds)

12

9

6

3

2

4

6

8

threads

Figure 8: Simple parallel algorithms unit cost, four-way 2000x1200 grid pathfinding.

state representation based hashing function gave best performance graph fairly
erratic number threads changed, sometimes increasing sometimes decreasing. 6
8 threads, PRA* faster serial A*.
implemented IDPSDD algorithm tries find upper bound
PSDD search using iterative deepening, results shown grid pathfinding domains. non-geometric growth number states increasing cost bound leads
poor performance iterative deepening grid pathfinding. Due poor performance
algorithms, show results remaining grid, tiles planning domains
(with exception PSDD makes reappearance STRIPS planning evaluation
Section 4.5, supply upper bound).
Promising Algorithms upper left plot Figure 9 shows performance algorithms
unit-cost four-way grid pathfinding problems. y-axis represents speedup serial A*
x-axis shows number threads use data point. Error bars indicate 95%
confidence intervals mean 20 different instances. Algorithms legend ordered
average performance. line labeled Perfect speedup shows perfect linear speedup
additional thread increases performance linearly.
practical reference point speedup shown Achievable speedup line.
perfect machine n processors, running n cores take time decreases linearly
n. real machine, however, hardware considerations memory bus contention prevent n-fold speedup. estimate overhead machines, ran sets
n independent A* searches parallel 1 n 8 calculated total time set
finish. perfect machine sets would take time set n = 1.
compute Achievable speedup ratio actual completion times time
709

fiB URNS , L EMONS , RUML , & Z HOU

Grid Unit Four-way

Grid Unit Eight-way
8

Perfect speedup
Achievable speedup
Safe PBNF
AHDA*
BFPSDD

6

speedup serial A*

speedup serial A*

8

4

Perfect speedup
Achievable speedup
Safe PBNF
AHDA*
BFPSDD

6

4

2

2

2

4

6

8

2

threads
Grid Life Four-way

6

8

6

8

threads
Grid Life Eight-way
8

Perfect speedup
Achievable speedup
Safe PBNF
AHDA*
BFPSDD

6

speedup serial A*

speedup serial A*

8

4

4

2

Perfect speedup
Achievable speedup
AHDA*
Safe PBNF
BFPSDD

6

4

2

2

4

6

8

threads

speedup serial A*

8

2

4

threads

15 Puzzles: 250 easy
Perfect speedup
Achievable speedup
Safe PBNF
AHDA*

6

4

2

2

4

6

8

threads

Figure 9: Speedup results grid pathfinding sliding tile puzzle.

set n = 1. threads given completion times sets, hC1 , C2 , ..., Cn i,
1
achievable speedup(t) = tC
Ct .
710

fiB EST-F IRST EARCH ULTICORE ACHINES

upper left panel shows comparison AHDA* (PRA* asynchronous communication abstraction), BFPSDD Safe PBNF algorithm larger (5000x5000) unit-cost
four-way problems. Safe PBNF superior algorithms, steadily decreasing solution times threads added average speedup serial A* 6x
using eight threads. AHDA* less stable performance, sometimes giving sharp speedup
increase sometimes giving decreased performance threads added. seven
threads AHDA* gave best performance, able reach 6x speedup serial A*
search. BFPSDD algorithm solved problems faster threads added however
competitive PBNF AHDA* giving 3x speedup serial A* eight
threads.
4.3.2 F -WAY L IFE C OST
Moves life cost model cost row number state move
performedmoves top grid free, moves bottom cost 4999 (Ruml & Do,
2007). differentiates shortest cheapest paths shown
important distinction (Richter & Westphal, 2010; Cushing, Bentor, & Kambhampati, 2010).
left center plot Figure 9 shows results format unit-cost variant
number threads x axis speedup serial A* axis. average, Safe PBNF
gave better speedup AHDA*, however AHDA* outperformed PBNF six seven threads.
eight threads, however, APRA* perform better seven threads. algorithms achieve speedups close Achievable speedup domain.
BFPSDD gave worst performance increase threads added reaching 3x
speedup.
4.3.3 E IGHT-WAY U NIT C OST
eight-way movement path
planning problems, horizontal vertical moves cost 1,
diagonal movements cost 2. real-valued costs make domain different previous
two path planning domains. upper right panel Figure 9 shows number threads x
axis speedup serial A* axis unit cost eight-way movement domain. see
Safe PBNF gave best average performance reaching 6x speedup eight threads.
AHDA* outperform Safe PBNF average, however able achieve 6x
speedup serial A* seven threads. however, see AHDA* give
stable performance increases threads. BFPSDD improved threads added
eight never reached 3x speedup.
4.3.4 E IGHT-WAY L IFE C OST
model combines eight-way movement life cost models; tends difficult path planning domain presented paper. right center panel Figure 9 shows threads
x axis speedup serial A* axis. AHDA* gave best average speedup
serial A* search, peaking 6x speedup seven threads. Although outperformed Safe
PBNF average eight threads AHDA* sharp decrease performance reaching
almost 5x speedup Safe PBNF around 6x speedup serial A*. BFPSDD peaks
3x speedup eight threads.
711

fiB URNS , L EMONS , RUML , & Z HOU

AHDA* minus Safe PBNF wall time (seconds)

15 puzzles 250 easy AHDA* vs Safe PBNF paired difference
(AHDA*) - (Safe PBNF)
zero

2

1

0
2

4

6

8

threads

Figure 10: Comparison wall clock time Safe PBNF versus AHDA* sliding tile puzzle.

4.4 Sliding Tile Puzzle
sliding tile puzzle common domain benchmarking heuristic search algorithms.
results, use 250 randomly generated 15-puzzles serial A* able solve within 3 million
expansions.
abstraction used sliding tile puzzles ignores numbers set tiles.
example, results shown Safe PBNF bottom panel Figure 9 use abstraction
looks position blank, one two tiles. abstraction gives 3360 nblocks. order
AHDA* get maximum amount expansions map back expanding thread (as
described grids), abstraction uses one, two three tile. Since position
blank ignored, state generation move one, two three tiles generate
child nblock parent therefore requiring communication. heuristic
used algorithms Manhattan distance heuristic. hash value used tiles states
perfect hash value based techniques presented Korf Schultze (2005).
bottom panel Figure 9 shows results AHDA*, Safe PBNF sliding
tiles puzzle instances. plot number threads x axis speedup serial
A* axis. Safe PBNF best mean performance overlap confidence
intervals AHDA*. BFPSDD unable show speedup serial A* performance
shown plot.
sliding tile puzzles vary much difficulty, domain paireddifference test, shown Figure 10. data used Figure 10 collected set
runs shown bottom panel Figure 9. y-axis figure, however, average,
instances, time AHDA* took instance minus time Safe PBNF
took. paired test gives powerful view algorithms relative performance. Values
greater 0.0 represent instances Safe PBNF faster AHDA* values lower
712

fiB EST-F IRST EARCH ULTICORE ACHINES

0.0 represent instances AHDA* faster. error bars show 95% confidence
interval mean. clearly see Safe PBNF algorithm significantly faster
AHDA* across numbers threads 1 8.
4.5 STRIPS Planning
addition path planning sliding tiles domains, algorithms embedded
domain-independent optimal sequential STRIPS planner. contrast previous two domains
node expansion quick therefore difficult achieve good parallel speedup,
node expansion STRIPS planning relatively slow. planner used experiments uses
regression max-pair admissible heuristic Haslum Geffner (2000). abstraction
function used domain generated dynamically per-problem basis and, following Zhou
Hansen (2007), time taken account solution times presented
algorithms. abstraction function generated greedily searching space possible
abstraction functions (Zhou & Hansen, 2006). algorithm needs evaluate one candidate abstraction unselected state variables, trivially parallelized
multiple threads work different candidate abstractions.
Table 1 presents results A*, AHDA*, PBNF, Safe PBNF, PSDD (given optimal upper
bound pruning using divide-and-conquer solution reconstruction), APRA* BFPSDD.
values cell total wall time seconds taken solve instance. value
indicates program ran memory. best result problem results
within 10% best marked bold. Generally, parallel algorithms able
solve instances faster allowed threads. parallel algorithms
able solve instances much faster serial A* seven threads. PBNF algorithm (either
PBNF Safe PBNF) gave best solution times three domains. Interestingly,
plain PBNF often little faster safe version, failed solve two problems.
likely due livelock, although could simply hot nblocks fix forces
Safe PNBF follow different search order PBNF. AHDA* tended give second-best
solution times, followed PSDD given optimal solution cost up-front pruning.
BFPSDD often better APRA*,
column, labeled Abst. shows time taken parallel algorithms serially
generate abstraction function. Even abstraction generation time added solution
times parallel algorithms outperform A* seven threads, except block-14 domain
time taken generate abstraction actually longer time A* took solve
problem.
4.6 Understanding Search Performance
seen PBNF algorithm tends better performance AHDA* algorithm
optimal search. section show results set experiments attempts
determine factors allow PBNF perform better domains. considered three
hypotheses. First, PBNF may achieve better performance expands fewer nodes f
values greater optimal solution cost. Second, PBNF may achieve better search performance
tends many fewer nodes priority queue AHDA*. Finally, PBNF
may achieve better search performance spends less time coordinating threads.
following subsections show results experiments performed test
713

fiB URNS , L EMONS , RUML , & Z HOU

threads
logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8

threads
logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8

threads
logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8

A*
1
2.30
5.19
117.78
130.85
335.74
199.06




1
1.17
6.21
39.58
77.02
150.39
127.07
156.36
154.15
235.46

1
1.44
7.37
62.61
95.11
215.19
153.71
319.48
334.28
569.26

AHDA*
1
3
5
7
1.44
0.70 0.48 0.40
7.13
5.07 2.25 2.13
59.51 33.95 15.97 12.69
95.50 33.59 24.11 18.24
206.16 96.82 67.68 57.10
147.96 93.55 38.24 27.37
299.66 126.34 50.97 39.10
315.51 85.17 51.28 48.91
532.51 239.22 97.61 76.34
SafePBNF
3
5
0.64
0.56
2.69
2.20
16.87
11.23
24.09
17.29
53.45
34.23
47.10
38.07
63.04
42.91
59.98
38.84
98.21
63.65

7
0.62
2.02
9.21
13.67
27.02
37.02
34.66
31.22
51.50

APRA*
3
5
7
0.75
1.09
0.81
5.30
3.26
2.92
43.13 37.62 26.78
42.85 67.38 52.82
243.24 211.45 169.92
122.00 63.47 37.94
138.30 67.24 49.58
99.37 89.73 104.87
351.87 236.93 166.19

1
1.20
6.36
65.74
61.53
162.76
126.31
159.98
155.93
387.81

1
1.27
6.28
39.66
68.14
156.64
185.68


229.88

PBNF
3
5
0.72 0.58
3.76 2.70
16.43 10.92
34.15 20.84
56.25 34.84
64.06 44.05




95.63 60.87

PSDD
3
5
0.78
0.68
3.57
2.96
29.37
21.88
23.56
16.71
62.68
43.34
53.76
45.47
73.00
57.65
63.20
41.85
172.01
120.79

BFPSDD
1
3
5
2.11
1.06 0.79
7.78
4.32 3.87
41.56 18.02 12.21
62.01 24.06 20.43
151.50 58.52 40.95
131.30 57.14 47.74
167.24 66.89 48.32
152.08 61.63 42.81
243.44 101.11 70.84

Table 1: Wall time STRIPS planning problems.

714

7
0.53
2.63
8.57
16.57
26.72
36.08


48.32

7
0.64
2.87
19.19
13.26
36.66
43.71
54.70
34.02
105.54
Abst.

7
0.71
3.40
10.20
13.54
32.48
45.07
42.68
34.70
59.18

1
0.42
7.9
0.8
1
0.7
17
3.6
9.7
1.1

fiB EST-F IRST EARCH ULTICORE ACHINES

AHDA*
Safe PBNF

AHDA*
Safe PBNF

6e+08

4e+07

Cumulative expansions

Cumulative expansions

5e+07

3e+07

2e+07

4e+08

2e+08

1e+07

0

0
0.7

0.8

0.9

1

Factor optimal cost

0.6

0.9

1.2

Factor optimal cost

Figure 11: Cumulative normalized f value counts nodes expanded eight threads unitcost four-way grid pathfinding (left) 15-puzzle (right).

three hypotheses. results experiments agree first two hypotheses, however,
appears third hypothesis hold and, fact, PBNF occasionally spends time
coordinating threads AHDA*.
4.6.1 N ODE Q UALITY
PBNF AHDA* merely approximate best-first order, may expand
nodes f values greater optimal solution cost. thread expands node
f value greater optimal solution cost effort waste nodes
must expanded searching optimal solution f values less
optimal cost. addition this, search algorithms may re-expand nodes lower
cost path found. happens work wasted first sub-optimal expansion
node.
Threads PBNF able choose nblock expand based quality nodes
free nblocks. AHDA*, however, thread must expand nodes assigned
it. hypothesized PBNF may expand fewer nodes f values greater
optimal solution cost threads control quality nodes
choose expand.
collected f value node expanded PBNF AHDA*. Figure 11 shows
cumulative counts f values nodes expanded PBNF AHDA* set
unit-cost four-way 5000x5000 grid pathfinding instances used Section 4.3 (right)
15-puzzle instances used Section 4.4 (left). plots, x axis shows f value
expanded nodes factor optimal solution cost given instance. axis shows
cumulative count nodes expanded given normalized f set instances.
715

fiMean CPU time (seconds)

B URNS , L EMONS , RUML , & Z HOU

3e-05

2e-05

1e-05

0

SafePBNF
AHDA*
Grid pathfinding

SafePBNF
AHDA*
15-puzzle

Figure 12: Mean CPU time per open list operation.
looking y-location right-most tip line find total number nodes
expanded algorithm summed instances.
left panel Figure 11 see algorithms tended expand
small number nodes f values greater optimal solution cost grid
pathfinding domain. AHDA* algorithm expanded nodes total set instances.
PBNF AHDA* must expand nodes optimal solution cost.
this, way AHDA* greater number expansions nodes factor
1 re-expanded nodes. appears AHDA* re-expanded nodes PBNF
seems account fact AHDA* expanded nodes total.
right half Figure 11 shows results 15-puzzle. see that, again, AHDA*
expanded nodes total PBNF. domain algorithms expanded approximately
number nodes f values less optimal solution cost. see
plot AHDA* expanded many nodes f values greater equal
optimal solution cost. summary, PBNF expanded fewer nodes better quality nodes
AHDA* grid pathfinding sliding tiles domains. speculate may happen
PBNF threads allowed choose portion space search
choose based low f value. AHDA* threads must search nodes map
nodes may good.
4.6.2 PEN L IST IZES
found that, since PBNF breaks search space many different nblocks, tends
data structures many fewer entries AHDA*, breaks search space
based number threads. Since interested general-purpose algorithms handle
domains real-valued costs (like eight-way grid pathfinding) PBNF AHDA* use binary
heaps implement open lists. PBNF one heap per nblock (that one per abstract state)
whereas AHDA* one heap per thread. number nblocks greater
716

fiB EST-F IRST EARCH ULTICORE ACHINES

number threads AHDA* many nodes PBNF heaps. causes
heap operations AHDA* take longer heap operations PBNF.
cost operations large heaps shown greatly impact overall performance
algorithm (Dai & Hansen, 2007). order determine extent large heaps effect
performance AHDA* added timers heap operations algorithms. Figure 12
shows mean CPU time single open list operation unit-cost four-way grid pathfinding
domain 15-puzzle. boxes show second third quartiles line drawn
across median. whiskers show extremes data except data points residing
beyond first third quartile 1.5 times inter-quartile range signified
circle. shaded rectangle shows 95% confidence interval mean. see that,
cases, AHDA* tended spend time performing heap operations PBNF
typically spent nearly time per heap operation. Heap operations must performed
node expanded may required node generation. Even though times
tens microseconds frequency operations high single search.
Finally, described Hansen Zhou (2007), reduction open list sizes explain good single thread performance PBNF experiences STRIPS planning (see Table 1).
Hansen Zhou point that, although A* optimally efficient terms node expansions,
necessarily optimal respect wall time. found benefit managing smaller
open lists enabled Anytime weighted A* algorithm outperform A* wall time even though
expanded nodes converging optimal solution. describe Section 9,
good single thread performance may caused speculative expansions pruning.
4.6.3 C OOORDINATION OVERHEAD
third hypothesis amount time algorithm spent coordination overhead might differ. parallel algorithms must spend time accessing data structures
shared among multiple threads. cause overhead two places. first place coordination overhead seen synchronization access shared data structures. PBNF
two modes locking nblock graph. First, thread ownership nblock open
nodes remain expanded use try lock work could
done fails acquire lock. Otherwise, nodes thread could expand
attempt acquire lock nblock graph using normal operation blocks
failure. AHDA* use try lock receive queue expansion nodes
queue open list. implementation AHDA* use blocking lock
operation thread nodes remaining expand nodes remaining send
receive buffers.
second place overhead may incurred threads nodes expand.
PBNF occurs thread exhausts current nblock free nblocks
acquire. thread must wait new nblock becomes free. AHDA* open nodes map
thread may nodes expand. situation thread busy-wait
node arrives receive queue. either situation, locking waiting, time wasted
threads actively searching space.
evaluating coordination overhead, combine amount time spent waiting
lock amount time waiting without nodes expand. Figure 13 shows per-thread
coordination times locks, waiting sum two normalized total wall time.
717

fipercentage wall time

B URNS , L EMONS , RUML , & Z HOU

8

4

percentage wall time

SafePBNF AHDA*
Locks

SafePBNF AHDA*
Wait

SafePBNF AHDA*
Sum

SafePBNF AHDA*
Wait

SafePBNF AHDA*
Sum

80

40

SafePBNF AHDA*
Locks

Figure 13: Per-thread ratio coordination time wall time unit-cost four-way pathfinding (top)
15-puzzle (bottom).

Unlike previous set boxplots, individual data points residing extremes signified
circles order improve readability. Locks column plot shows distribution
times spent thread waiting lock, Wait column shows distribution times
threads spent waiting without nodes available expand Sum column shows
distribution sum mean lock wait times.
left side Figure 13 shows results grid pathfinding. Locks column see
threads AHDA* spent almost time acquiring locks. expected AHDA*
uses asynchronous communication. appears amount time threads PBNF spent
acquiring locks significantly greater AHDA*. Wait column plot
shows PBNF AHDA* appeared threads spend nearly amount time
waiting without nodes expand. Finally, Sum column shows threads PBNF
spent time overall coordinating threads.
bottom half Figure 13 shows coordination overhead 15-puzzle domain. Again,
see threads AHDA* spent almost time acquiring lock. Individual threads PBNF,
however, tended spend larger fraction time waiting locks sliding tiles domain
718

fiB EST-F IRST EARCH ULTICORE ACHINES

grid pathfinding. Wait column figure see AHDA* spent
time PBNF without nodes expand. Finally, see that, all, PBNF spent time
coordinating threads AHDA*.
Overall experiments verified first two hypotheses PBNF expanded better
quality nodes AHDA* spent less time performing priority queue operations
AHDA*. found third hypothesis hold threads PBNF tended
coordination overhead AHDA* seems out-weighed two
factors.
4.7 Summary
section shown results empirical evaluation optimal parallel best-first
search algorithms. shown several simple parallel algorithms actually slower
serial A* search even offered computing power. Additionally showed empirical results set algorithms make good use parallelism outperform serial A*.
Overall Safe PBNF algorithm gave best consistent performance latter set
algorithms. AHDA* variant PRA* second fastest mean performance domains.
shown using abstraction PRA* style search distribute nodes among
different threads give significant boost speed reducing amount communication. modification PRA* appears lot helpful simply using asynchronous
communication. Using improvements conjunction (AHDA*), yields competitive
algorithm additional feature relying shared memory.
Finally, performed set experiments attempt explain Safe PBNF tended
give better search performance AHDA*. experiments looked three factors: node quality,
open list sizes thread-coordination overhead. concluded PBNF faster
expands fewer nodes suboptimal f values takes less time perform priority queue
operations.

5. Bounded Suboptimal Search
Sometimes acceptable even preferable search solution optimal. Suboptimal
solutions often found much quickly lower memory requirements optimal
solutions. section show create bounded-suboptimal variants best
optimal parallel search algorithms.
Weighted A* (Pohl, 1970), variant A* orders search f (n) = g(n) + w h(n),
w > 1, probably popular suboptimal search. guarantees that, admissible
heuristic h weight w , solution returned w -admissible (within w factor
optimal solution cost) (Davis, Bramanti-Gregor, & Wang, 1988).
possible modify AHDA*, BFPSDD, PBNF use weights find suboptimal solutions, call algorithms wAHDA*, wBFPSDD wPBNF. optimal search,
parallelism implies strict f search order followed. proof weighted A*s
w -optimality depends crucially following strict f order, parallel variants must
prove quality solution either exploring pruning nodes. Thus finding effective
pruning rules important performance. assume throughout h admissible.
719

fiB URNS , L EMONS , RUML , & Z HOU

5.1 Pruning Poor Nodes
Let current incumbent solution w suboptimality bound. node n clearly
pruned f (n) g(s). according following theorem, need retain n
optimal path solution factor w better s. much stronger rule.
Theorem 4 prune node n w f (n) g(s) without sacrificing w -admissibility.
Proof: incumbent w -admissible, safely prune node, consider case
g(s) > w g(opt), opt optimal goal. Note without pruning, always exists
node p open list (or generated) best path opt. Let f cost
optimal solution. admissibility h definition p, w f (p) w f (p) = w g(opt).
pruning rule discards p, would imply g(s) w f (p) thus g(s) w g(opt),
contradicts premise. Therefore, open node leading optimal solution pruned
incumbent w -admissible. search terminate open empty
terminate incumbent w -admissible replaced optimal solution.
2
make explicit useful corollary:
Corollary 2 prune node n f (n) g(s) without sacrificing w -admissibility.

Proof: Clearly w f (n) f (n), Theorem 4 applies.
2
corollary, use pruning shortcut: open list sorted increasing f
node front f g(s), prune entire open list.
5.2 Pruning Duplicate Nodes
searching inconsistent heuristic, weighted A*, possible search
find better path already-expanded state. Likhachev, Gordon, Thrun (2003) noted that,
provided underlying heuristic function h consistent, weighted A* still return w admissible solution duplicate states pruned search. ensures state
expanded search. Unfortunately, proof depends expanding
exactly best-first order, violated several parallel search algorithms consider
here. However, still prove duplicates dropped. Consider expansion
node n re-generates duplicate state already expanded. propose
following weak duplicate dropping criterion: new copy pruned old g(d )
g(n) + w c (n, ), c (n, ) optimal cost node n node .
Theorem 5 Even weak dropping rule applied, always node p optimal
solution path open g(p) w g (p).
Proof: proceed induction iterations search. theorem clearly holds expansion
initial state. induction step, note node p removed open
expanded. child pi lies along optimal path added open, theorem holds.
way wont added exists previous duplicate copy pi pruning rule holds,
i.e., g(pi ) g(pi1 ) + w c (pi1 , pi ). inductive hypothesis, g(pi1 ) w g (pi1 ),
2
definition g (pi1 ) + c (pi1 , pi ) = g (pi ), g(pi ) w g (pi ).
Note use technique prohibits using global minimum f value lower bound
optimal solutions cost, g values inflated factor w . However,
incumbent search global minimum f value g(s), serial
weighted A* search, w -admissibility assured:
720

fiB EST-F IRST EARCH ULTICORE ACHINES

Corollary 3 minimum f value g(s), incumbent, g(s)
w g (opt)
Proof: Recall node p Theorem 5. g(s) f (p) = g(p) + w h(p) w (g (p) + h(p))
w g (opt).
2
remains empirical question whether pruning rather weak criterion lead better
performance practice. results indicate provide advantage grid pathfinding
domain. Results presented Section 6.1. noted that, extra pruning
preserve w -admissibility, may result solutions lower quality resulting search
without pruning.
5.3 Optimistic Search
Korf (1993) showed weighted A* typically returns solutions better bound, w ,
would suggest. take advantage this, Thayer Ruml (2008) use optimistic approach
bounded suboptimal search works two stages: aggressive search using weight greater
desired optimality bound find incumbent solution cleanup phase prove
incumbent indeed within bound. intuition behind approach wA*
find solution within tight bound (much tighter w g(opt)), search continue
looking nodes f order bound proved. Thayer Ruml show that, indeed,
approach surpass speed wA* given optimality bound. implemented
optimistic version PBNF (oPBNF).
One requirements oPBNF must access minimum f value
nodes order prove bound incumbent solution. aggressive search stage,
open lists heap free nblocks sorted f instead f couple additions need
made. First, nblock additional priority queue containing open search nodes sorted
f . call queue openf . openf queue simply maintained adding removing
nodes nodes added removed f ordered open list nblock. Second,
priority queue, called minf , nblocks maintained, sorted lowest f value
nblock time last release. minf used track lower bound minimum f value
nodes. accomplished lazily updating minf nblock released
thread. thread releases nblock, sifts released nblock successors
new positions minf queue. nblocks whose minimum f values could
changed releasing thread. Since global minimum f value nodes strictly
increasing (assuming consistent heuristic) guarantee f value front
minf queue strictly increasing lower bound global minimum f value
given time. Using lower bound, able prove whether incumbent solution
properly bounded.
oPBNF needs decide switch aggressive search phase cleanup
phase optimistic search. originally proposed, optimistic search performs aggressive search
first incumbent found switches cleanup (when f (n) g(s), n
best node based f incumbent solution) aggressive search (when f (n) <
g(s)) hedge case current incumbent within bound. oPBNF,
left choice: switch aggressive search cleanup global basis
per-nblock basis. choose switch per-nblock basis assumption
threads could cleaning areas search space low f values threads look
721

fiB URNS , L EMONS , RUML , & Z HOU

better solutions areas search space low f values. oPBNF, deciding
one nblock better another (when deciding switch set nblock hot), choice
longer based solely best f value given nblock, instead based f
value first, f value break ties best f value bound incumbent.
acquiring new nblock, thread takes either free nblock best f value best f
value depending nblock better (where notion better described previous
sentence). Finally, expanding nodes, thread selects aggressive search cleanup based
criteria standard optimistic search nodes within acquired nblock.

6. Empirical Evaluation: Bounded Suboptimal Search
implemented tested weighted versions parallel search algorithms discussed above:
wAHDA*, wAPRA*, wBFPSDD, wPBNF oPBNF. algorithms prune nodes based
w f criterion presented Theorem 4 prune entire open lists f Corollary 2. Search
terminates nodes pruned incumbent solution. experiments
run three benchmark domains optimal search: grid pathfinding, sliding tile
puzzle, STRIPS planning.
6.1 Grid Pathfinding
Results presented Table 2 show performance parallel search algorithms terms
speedup serial weighted A* grid pathfinding problems. Duplicate states already
expanded dropped serial wA* algorithm, discussed Likhachev et al. (2003).
rows table show number threads different algorithms whereas columns
weights used various domains. entry shows mean speedup serial weighted
A*. performed Wilcoxon signed-rank test determine mean values significantly
different; elements bold represent values significantly different (p < 0.05)
best mean value given column. general, parallel algorithms show increased
speedup threads added low weights, decreased speedup weight increased.
unit-cost four-way movement grids, weights 1.1, 1.2 wPBNF algorithm
fastest algorithms tested reaching five times speed wA* weight
1.1 4.5x weight 1.2 . weight 1.4 wPBNF, wBFPSDD wAHDA*
show significant difference performance 8 threads. wAHDA* best speed
algorithms weight 1.8. wAPRA* never gave best performance domain.
eight-way movement grids wPBNF gave best performance weight 1.1 1.4,
although latter case best performance decrease speed wA*
achieved 1 thread. wAHDA* fastest weight 1.2, however, scale
expected number threads increased. Finally wAPRA* gave least performance
decrease weighted A* weight 1.8 1 thread. case, algorithms slower
serial weighted A* wAPRA* gave closest performance serial search. wBFPSDD
never gave best performance domain.
life-cost domain wPBNF outperformed algorithms weights 1.1, 1.2 1.4.
weight 1.8, wPBNFs performance quickly dropped, however wAHDA* best results
4x speedup wA*, although performance appears inconsistent significantly different much lower speedup values weight.
wAPRA* never gave best performance domain.
722

fiwAPRA*

wAHDA*

threads

wBFPSDD

wPBNF

B EST-F IRST EARCH ULTICORE ACHINES

1
2
3
4
5
6
7
8
1
2
3
4
5
6
7
8
1
2
3
4
5
6
7
8
1
2
3
4
5
6
7
8

Unit Four-way Grids
1.1
1.2
1.4
1.8
0.98 0.91 0.51 0.73
1.74 1.65 1.07 0.87
2.47 2.33 1.62 0.89
3.12 2.92 2.13 0.90
3.76 3.52 2.48 0.91
4.30 3.99 2.80 0.89
4.78 4.40 3.01 0.88
5.09 4.66 3.11 0.87
0.82 0.84 0.96 0.94
1.26 1.26 1.45 0.91
1.65 1.65 1.90 0.84
1.93 1.92 2.09 0.79
2.24 2.24 2.36 0.75
2.51 2.51 2.58 0.71
2.73 2.69 2.63 0.67
2.91 2.84 2.68 0.63
0.87 0.79 0.32 0.56
1.35 1.17 0.63 0.84
1.90 1.69 1.30 1.30
2.04 2.10 1.57 1.30
1.77 2.08 1.79 0.97
3.23 3.03 2.18 1.33
3.91 3.78 2.56 1.30
3.79 3.64 3.02 1.13
0.88 0.81 0.32 0.56
0.51 0.44 0.22 0.36
0.36 0.32 0.20 0.26
0.50 0.44 0.30 0.41
0.55 0.56 0.39 0.48
0.52 0.49 0.31 0.30
0.73 0.67 0.40 0.36
1.09 1.07 0.82 0.77

weight
Unit Eight-way Grids
1.1
1.2
1.4
1.8
0.93 1.37 0.73 0.74
1.65 1.82 0.57 0.66
2.36 1.77 0.55 0.61
2.97 1.72 0.53 0.58
3.55 1.67 0.52 0.56
4.04 1.61 0.50 0.54
4.40 1.55 0.49 0.51
4.70 1.49 0.45 0.46
0.87 0.79 0.43 0.33
1.37 1.10 0.43 0.35
1.80 1.22 0.41 0.33
2.13 1.25 0.42 0.33
2.47 1.31 0.39 0.32
2.74 1.21 0.36 0.30
2.94 1.26 0.34 0.29
3.10 1.23 0.32 0.26
0.79 1.10 0.66 0.76
1.04 1.99 0.62 0.61
2.08 2.93 0.64 0.62
2.48 2.84 0.56 0.54
2.49 2.52 0.42 0.41
3.73 2.83 0.49 0.45
4.45 2.89 0.45 0.41
4.39 2.58 0.37 0.38
0.80 1.11 0.67 0.77
0.35 0.69 0.31 0.28
0.41 0.65 0.23 0.22
0.43 0.73 0.22 0.19
0.49 0.87 0.23 0.19
0.50 0.65 0.16 0.14
0.62 0.73 0.17 0.14
0.89 1.38 0.28 0.22

Life Four-way Grids
1.1
1.2
1.4
1.8
0.65 0.66 0.84 0.67
1.15 1.17 1.59 0.39
1.65 1.67 2.32 0.39
2.08 2.10 2.96 0.49
2.53 2.55 3.63 1.49
2.94 2.95 4.20 1.64
3.31 3.33 4.63 2.12
3.61 3.64 5.11 1.06
0.52 0.53 0.58 0.60
0.83 0.83 0.92 0.76
1.10 1.09 1.26 0.84
1.29 1.29 1.48 0.89
1.53 1.51 1.61 0.93
1.73 1.72 1.78 0.93
1.91 1.89 1.94 0.91
2.06 2.03 2.10 0.85
0.56 0.55 0.71 0.22
0.88 0.86 1.29 0.32
1.09 1.39 1.86 0.56
1.60 1.64 2.24 0.56
1.88 1.92 2.58 0.41
2.15 2.17 3.02 1.50
2.39 2.41 3.50 1.07
2.38 2.42 3.55 4.16
0.56 0.56 0.72 0.23
0.35 0.34 0.46 0.12
0.23 0.26 0.32 0.10
0.42 0.43 0.55 0.16
0.54 0.56 0.67 0.20
0.39 0.39 0.49 0.13
0.49 0.49 0.65 0.18
1.00 0.98 1.22 0.42

Table 2: Grid Pathfinding: Average speedup serial weighted A* various numbers
threads.

723

fiB URNS , L EMONS , RUML , & Z HOU

threads
1
2
3
4
5
6
7
8

1.4
0.68
1.35
1.48
1.70
2.04
2.16
2.55
2.71

wPBNF
1.7
2.0
0.44 0.38
0.81 1.00
0.97 0.85
1.20 0.93
1.38 0.97
1.30 1.19
1.46 1.04
1.71 1.10

3.0
0.69
0.63
0.56
0.60
0.74
0.67
0.62
0.60

1.4
0.61
1.18
1.53
1.91
2.33
2.28
2.71
2.70

wAHDA*
1.7
2.0
0.60 0.59
1.11 1.32
1.30 1.40
1.57 1.55
1.70 1.27
1.72 1.24
1.50 1.03
1.51 1.24

3.0
0.54
0.78
0.73
0.74
0.66
0.52
0.44
0.44

threads
1
2
3
4
5
6
7
8

1.4
0.65
0.87
1.05
1.09
1.27
1.33
1.49
1.53

wBFPSDD
1.7
2.0
0.61 0.44
0.74 0.49
0.72 0.63
1.00 0.57
0.97 0.65
1.17 0.61
1.10 0.59
1.08 0.62

3.0
0.35
0.43
0.46
0.45
0.40
0.39
0.34
0.33

1.4
0.61
1.18
1.45
1.77
2.32
2.18
2.63
2.34

wAPRA*
1.7
2.0
0.59 0.59
1.08 1.36
1.25 1.32
1.50 1.36
1.62 1.26
1.54 1.83
1.40 1.09
1.61 1.22

3.0
0.54
0.78
0.78
0.62
0.64
0.47
0.43
0.41

Table 3: 15-puzzle: Average speedup serial weighted A* various numbers threads.

oPBNF

threads
1
2
3
4
5
6
7
8

Unit Four-way Grids
1.1
1.2
1.4
1.8
0.54 0.99 0.74 0.47
0.99 2.00 1.05 0.45
1.40 2.89 1.19 0.45
1.76 3.62 1.26 0.44
2.11 4.29 1.33 0.43
2.43 4.84 1.35 0.44
2.70 5.44 1.37 0.43
2.97 6.01 1.39 0.42

Unit Eight-way Grids
1.1
1.2
1.4
1.8
0.74 0.76 0.09 0.05
1.26 0.71 0.09 0.05
1.64 0.70 0.09 0.05
1.90 0.69 0.09 0.05
2.09 0.68 0.08 0.05
2.21 0.68 0.08 0.05
2.29 0.67 0.08 0.04
2.30 0.67 0.08 0.04

250 easy 15-puzzles
1.4
1.7
2.0
3.0
0.56 0.58 0.77 0.60
0.85 1.07 0.83 0.72
1.06 0.94 0.79 0.80
1.01 0.82 0.93 0.69
1.20 1.21 0.97 0.74
1.32 0.83 0.99 0.67
1.14 0.93 0.88 0.71
1.33 0.87 0.81 0.64

Table 4: Average speedup serial optimistic search various numbers threads.

724

fiB EST-F IRST EARCH ULTICORE ACHINES

Overall, see wPBNF often best speedup results eight threads weights
less 1.8. wAHDA*, however, gave best performance weight 1.8 across grid
pathfinding domains. wBFPSDD often gave speedup serial weighted A*, however
quite competitive wPBNF wAHDA*. wAPRA* rarely able outperform
serial search.
Table 4 shows results optimistic variant PBNF algorithm (oPBNF). cell
table shows mean speedup oPBNF serial optimistic search. again, bold
cells entries significantly different best value column. unit-cost
four-way pathfinding problems oPBNF gave performance increase optimistic search two
threads weights less 1.8. weight 1.2, oPBNF tended give
best speedup, may optimistic search performed poorly particular weight.
unit-cost eight-way pathfinding, see oPBNF performs comparably unit-cost domain
weight 1.1, however, higher weights algorithm slower serial optimistic
search.
6.2 Sliding Tile Puzzles
sliding tiles domain, used standard Korf 100 15-puzzles (Korf, 1985). Results
presented Table 3. wPBNF, wAHDA* wAPRA* tended give comparable performance
sliding tile puzzle domain values significantly different weights
1.4 1.7. weight 3.0, wAHDA* gave least performance decrease weighted A*
2 threads.
right-most column Table 4 shows results optimistic PBNF 250 15-puzzle
instances solvable A* fewer 3 million expansions. oPBNF gave best performance weight 1.4. weights greater 1.4 oPBNF unable outperform serial
counterpart. greater weights oPBNF tended perform better smaller numbers threads.
One trend seen sliding tiles domain grid pathfinding domain
speedup parallel algorithms serial suboptimal search decreases weight
increased. suspect decrease relative performance due problems becoming
sufficiently easy (in terms node expansions) overhead parallelism becomes harmful
overall search. problems require many node expansions cost parallelism (additional
expansions, spawning threads, synchronization albeit small, waiting threads complete, etc.)
amortized search effort. problems require small number expansions,
however, overhead accounts total search time serial algorithm could
potentially faster.
confirm understanding effect problem size speedup, Figure 14 shows comparison wPBNF weighted A* 100 Korf 15-puzzle instances using eight threads.
point represents run one instance particular weight, y-axis represents wPBNF
speedup relative serial wA*, x-axis represents number nodes expanded wA*.
Different glyphs represents different weight values used wPBNF wA*. figure
shows that, wPBNF outperform wA* easier problems, benefits wPBNF
wA* increased problem difficulty increased. speed gain instances run
weight 1.4 (the lowest weight tested) leveled 10 times faster wA*.
machine eight cores. instances seem speedup greater
10x. explained speculative expansions wPBNF performs may
725

fiB URNS , L EMONS , RUML , & Z HOU

Sliding Tiles wPBNF v.s. wA*
W

log10(Times faster wA*)

1
W



WW W
W
W
W

WW
W
W
WS
W WW
WSS W WW
W W W WW
SS
W
W
W
W
W
W W
W W WW
SS

W
W
WSW SWWW
W
SS
WS SSW
W

SW W
WWW
WW
SW
W WW WWW

W


W WW WW
SS
SS
W W
SS SSSSSW
W


W
W
SSS SW
WS
W
WW

SS SSS


SS W
W
W




W
W


WS
WS
W

SS
SS SS
W


SS
SSS SS
SS
SW

W
W

0

-1

W



3

4

5

W
W

W

wPBNF-1.4
wPBNF-1.7
wPBNF-2.0
wPBNF-3.0
wPBNF-5.0

W



6

log10(Nodes expanded wA*)

Figure 14: wPBNF speedup wA* function problem difficulty.
find bounded solution faster weighted A* due pruning nodes f values
equal resulting solution. poor behavior wPBNF easy problems
likely due overhead described above. effect problem difficulty means wPBNF
outperformed wA* often low weights, problems required expansions,
less often higher weights, problems completed quickly.
6.3 STRIPS Planning
Table 5 shows performance parallel search algorithms STRIPS planning problems,
terms speedup versus serial weighted A*. table columns represent various weights
rows represent different planning problems two seven threads. Bold values represent table entries within 10% best performance given domain.
algorithms better speedup seven threads two. wPBNF gave best speedup
number domains followed wAHDA* fastest three domains
seven threads. two threads couple domains (satellite-6 freecell-3)
wBFPSDD gave speedup, however never seven threads. wAPRA* always
slower three remaining algorithms. one problem, freecell-3, serial weighted A* performs much worse weight increases. Interestingly, wPBNF wBFPSDD show
pathology, thus record speedups 1,700 times.
6.4 Summary
section, seen bounded suboptimal variants parallel searches give
better performance serial progenitors. shown that, sliding tile puzzle,
parallel search gives advantage serial search problem difficulty increases
suspect result holds domains too. suspect overhead
using parallelism amortized search time easy problems.
726

fi7 threads

2 threads

7 threads

2 threads

B EST-F IRST EARCH ULTICORE ACHINES

logistics-8
blocks-16
gripper-7
satellite-6
elevator-12
freecell-3
depots-13
driverlog-11
gripper-8
logistics-8
blocks-16
gripper-7
satellite-6
elevator-12
freecell-3
depots-13
driverlog-11
gripper-8

logistics-8
blocks-16
gripper-7
satellite-6
elevator-12
freecell-3
depots-13
driverlog-11
gripper-8
logistics-8
blocks-16
gripper-7
satellite-6
elevator-12
freecell-3
depots-13
driverlog-11
gripper-8

1.5
0.99
1.29
0.76
0.68
0.65
1.03
0.73
0.91
0.63
3.19
3.04
1.71
1.11
0.94
3.09
2.38
1.90
1.70

1.5
2.68
0.93
2.01
2.02
2.02
2.06
2.70
0.85
2.06
7.10
2.87
5.67
4.42
6.32
7.01
3.12
1.72
5.85

wAPRA*
2
3
1.02
0.59
0.88
4.12
0.76
0.77
0.93
0.70
0.72
0.71
1.00
1.78
1.25
0.97
0.79
0.94
0.61
0.62
3.10
3.26
1.37
1.08
1.74
1.73
1.01
1.29
0.97
1.04
7.99
2.67
5.36
1.13
1.25
0.93
1.68
1.68

5
1.37
0.30
0.77
0.75
0.77
1.61
1.08
0.93
0.62
2.58
0.37
1.82
1.44
1.02
2.93
1.17
0.92
1.74

1.5
1.25
1.52
1.36
1.15
1.16
1.49
0.92
1.30
1.14
4.59
3.60
3.71
3.22
2.77
4.77
2.98
3.52
3.71

wAHDA*
2
3
1.11
0.80
1.09
4.86
1.35
1.33
1.09
1.28
1.20
1.27
1.20
7.56
1.29
0.96
0.97
0.96
1.16
1.15
4.60
3.61
1.62
0.56
3.66
3.74
3.57
3.05
2.88
2.98
2.71
48.66
6.09
1.22
1.48
0.95
3.63
3.67

wPBNF
3
4.06
0.48
1.99
5.90
2.21
8.11
0.82
0.69
2.08
1.91
0.37
5.07
2.68
6.60
131.12
0.87
0.67
5.40

5
1.00
1.32
2.02
3.04
2.15
10.69
0.81
0.62
2.07
0.46
1.26
5.18
5.89
7.10
1,721.33
0.88
0.42
5.44

1.5
1.86
0.34
1.91
1.71
1.76
1.42
1.48
0.85
2.00
3.17
0.49
4.33
3.13
3.68
2.12
1.88
1.26
4.62

wBFPSDD
2
3
5
2.12
1.14
0.15
0.19
0.16
0.32
1.89
1.86
1.84
2.22
7.50
2.80
1.76
1.81
2.18
0.54 16.88
55.75
1.58
0.18
0.14
0.11
0.19
0.21
1.96
1.97
1.98
3.59
0.62
0.10
0.22
0.11
0.32
4.28
4.14
4.05
2.31
3.01
1.05
3.78
4.04
3.95
0.70 44.49 137.19
1.87
0.15
0.12
0.21
0.30
0.23
4.55
4.55
4.51

2
2.27
0.54
1.99
1.53
2.08
0.84
4.49
0.19
2.04
6.88
0.70
5.09
2.85
6.31
2.31
1.80
0.43
5.31

5
1.51
0.38
1.30
1.44
1.22
1.40
1.09
0.93
1.16
2.58
0.32
3.83
3.60
3.03
4.77
1.17
0.92
4.00

Table 5: Speed-up serial weighted A* STRIPS planning problems various weights.

727

fiB URNS , L EMONS , RUML , & Z HOU

7. Anytime Search
popular alternative bounded suboptimal search anytime search, highly suboptimal
solution returned quickly improved solutions returned time algorithm
terminated (or incumbent solution proved optimal). two popular anytime
heuristic search algorithms Anytime weighted A* (AwA*) (Hansen & Zhou, 2007) anytime
repairing A* (ARA*) (Likhachev, Gordon, & Thrun, 2003). AwA* weighted A* search
allowed continue finding first solution, pruning unweighted f (n) g(s)
incumbent solution n node considered expansion. ARA* uses weighted
search weight lowered solution meeting current suboptimality bound
found special INCONS list kept allows search expand node
search weight.
section present anytime versions best performing parallel searches
previous sections. used PBNF framework implement Anytime weighted PBNF (AwPBNF) Anytime Repairing PBNF (ARPBNF). use PRA* framework create anytime
weighted AHDA* (AwAHDA*). show performance simple algorithm
runs parallel weighted A* searches differing weights. planning domain, implemented anytime weighted BFPSDD (AwBFPSDD) comparison well.
parallel searches inherently continue searching first solutions found,
serve naturally anytime algorithms style Anytime weighted A*. main
difference standard, optimal versions algorithms anytime variants
anytime versions sort open lists heap free nblocks f (n) = g(n) +
w h(n). fact, cases optimal search degenerate case anytime search
w = 1. approach (simply using w > 1) used implement algorithms except
ARPBNF multi-weighted A*.
Next, discuss details ARPBNF algorithm. Following that, introduce
new parallel anytime algorithm called multi-weighted A*. Finally, show results set
comparisons performed anytime algorithms discussed sections.
7.1 Anytime Repairing PBNF
ARPBNF parallel anytime search algorithm based ARA* (Likhachev et al., 2003).
ARPBNF, open lists heap nblocks sorted f AwPBNF, instead merely
continuing search incumbent proved optimal, ARPBNF uses weight schedule.
time incumbent found, weight heuristic value lowered specified amount,
open lists resorted search continues. final iteration, weight 1.0
optimal solution found.
following procedure used resort nblocks parallel incumbent solutions:
1. thread calling resort (the one found goal) becomes leader taking
lock nblock graph setting resort flag. (If flag already set,
another thread already leader current thread becomes worker). flag
set leader thread releases lock nblock graph waits nblocks
values zero (no nblocks acquired).
2. Threads check resort flag expansion, set threads release nblocks
become worker threads wait leader set start flag.
728

fiB EST-F IRST EARCH ULTICORE ACHINES

3. nblocks = 0, leader re-takes lock nblock graph ensures
values still zero (if not, releases lock retries). leader sets
global weight value next weight weight schedule populates lock-free
queue nblocks. queue populated, leader sets start flag.
4. threads greedily dequeue nblocks resort queue empty.
5. nblocks resorted, leader thread clears resort flag start flag
releases lock nblock graph. threads acquire new nblocks
search continue.
modeled procedure TLA+ showed live-lock dead-lock free
4 threads 5 nblocks use TLC model checker (Yu et al., 1999). model
simple include appendix.
7.2 Multi-weighted A*
section introduce new simple parallel anytime algorithm called multi-weighted A*.
PBNF PRA* frameworks parallelizing anytime algorithms thought one
end spectrum parallel anytime algorithms. PBNF PRA* threads working
finding single solution given quality; opposite end spectrum thread would
working find solution. compare algorithm end spectrum
implemented algorithm call multi-weighted A* allocates available threads
weighted A* searches. thread finishes first generally thread searching
greatest weight therefore solution worst quality. next thread
finish next greatest weight, on. final thread complete generally
searching weight 1.0, performing standard A* search, return optimal solution.
algorithm given schedule weighs decreasing order. largest weights
schedule distributed among available threads. threads begin searching using wA*
given weight values. thread finds new solution better current one,
updates incumbent shared threads allow pruning. thread
finds better incumbent solution, w -admissible respect weight thread
searching with. thread finishes (either finding solution pruning entire open list), takes
highest unclaimed weight schedule starts fresh search using weight.
weights left schedule, thread terminates. threads terminated,
search complete. final weight schedule 1.0, last solution found
optimal.
One benefits multi-weighted A* simple algorithm implement.
However, see below, doesnt benefit much added parallelism. reason
may because, weight schedule exhausted (a thread searching lowest
weight, 1.0) threads complete searches sit idle entire search terminates. Since
final weight take longest, may majority search time. dynamic
schedule could used keep threads busy optimal solution found. One could
attempt use threads using multi-threaded search weight,
wPBNF wAHDA*. leave extensions future work.
729

fiB URNS , L EMONS , RUML , & Z HOU

Solution Cost (factor optimal)

1.1

1.0

1.1

1.0
0.2

0.4

0.6

0.8

1.0

wt sched 1
wt sched 2
wt sched 3
wt sched 4

1.1

1.0
0.2

0.4

0.6

0.8

1.0

0.2

0.4

0.6

0.8

Wall time relative serial A*

Wall time relative serial A*

Wall time relative serial A*

Grid Unit Four-way AwA* lower hull

Grid Unit Four-way AwPBNF (8 threads) lower hull

Grid Unit Four-way ARA* lower hull

1.2

1.2

AwA*
Solution Cost (factor optimal)

Solution Cost (factor optimal)

Grid Unit Four-way ARA* raw data
1.2

3.4
1.8
1.4
1.1
1.2

1.1

1.0

1.2

AwPBNF 8 threads
Solution Cost (factor optimal)

Solution Cost (factor optimal)

Grid Unit Four-way AwPBNF (8 threads) raw data
1.2

3.4
1.8
1.4
1.2
1.1

Solution Cost (factor optimal)

Grid Unit Four-way AwA* raw data
1.2

1.1

1.0
0.2

0.4

0.6

0.8

Wall time relative serial A*

1.0

1.0

ARA*

1.1

1.0
0.2

0.4

0.6

0.8

Wall time relative serial A*

1.0

0.2

0.4

0.6

0.8

Wall time relative serial A*

Figure 15: Raw data profiles (top) lower hull profiles (bottom) AwA* (left), AwPBNF (center), ARA* (right). Grid unit-cost four-way pathfinding.

8. Empirical Evaluation: Anytime Search
implementation empirical setup similar used suboptimal search. ARA*,
ARPBNF Multi-wA* considered four different weight schedules: {7.4, 4.2, 2.6, 1.9, 1.5,
1.3, 1.1, 1}, {4.2, 2.6, 1.9, 1.5, 1.3, 1.1, 1.05, 1}, {3, 2.8, . . . , 1.2, 1}, {5, 4.8, . . . , 1.2, 1}. AwA*
anytime parallel algorithms consider weights of: 1.1, 1.2, 1.4, 1.8 3.4 grid
pathfinding 1.4, 1.7, 2.0, 3.0 5.0 sliding tiles domain. fully evaluate anytime
algorithms, necessary consider performance profile, i.e., expected solution quality
function time. easily plotted, ignores fact anytime algorithms
considered paper free parameter, namely weight schedule weights used
accelerate search. order compare algorithms, make assumption that,
particular application, user attempt find parameter setting giving good performance
timescale interested in. assumption, plot performance
anytime algorithm computing, time point, best performance achieved
parameter settings tried algorithm minimum solution cost parameter
settings given algorithm given time point. refer concept lower hull
profiles, takes minimum profiles parameter setting.
730

1.0

fiB EST-F IRST EARCH ULTICORE ACHINES

Grid Unit Four-way 2 threads

Grid Unit Four-way 8 threads
1.2

ARA*
ARPBNF 2 threads
AwA*
Multi wA* 2 threads
AwAHDA* 2 threads
AwPBNF 2 threads

Solution Cost (factor optimal)

Solution Cost (factor optimal)

1.2

1.1

1.0

ARA*
AwA*
Multi wA* 8 threads
ARPBNF 8 threads
AwAHDA* 8 threads
AwPBNF 8 threads

1.1

1.0
0.4

0.8

1.2

1.6

2.0

Wall time relative serial A*

0.4

0.8

1.2

1.6

2.0

Wall time relative serial A*

Figure 16: Grid unit-cost four-way pathfinding lower hull anytime profiles.
top row Figure 15 shows example raw data three algorithms
5000x5000 unit-cost four-way grid pathfinding problems. y-axis plots solution quality factor optimal x-axis wall clock time relative amount
time A* took find optimal solution. bottom row figure shows lower hull
respective data displayed above. comparing two images left display data
AwA* algorithm, one see three big steps lower hull plot different weight used hull found better solution time bound.
center panel Figure 15 shows AwPBNF algorithm gives similar performance AwA*,
however often faster. surprising since AwPBNF based AwA* approach
running eight threads instead one. final panel Figure 15 shows ARA*, uses
weight schedules instead single weight.
Figures 16-17 present lower hulls serial parallel algorithms grid pathfinding
sliding tile puzzle. panel, y-axis represents solution cost factor optimal
cost. Figure 16 x-axis represents wall time relative amount time serial A* took
find optimal solution. allows comparison anytime algorithms standard
serial A*. Since A* able solve Korfs 100 15-puzzle instances machine,
x-axis Figure 17 absolute wall time seconds. serial parallel algorithms
plotted. profiles start algorithm first returns solution ends algorithm
proved optimality 180 second cutoff (since Multi-wA* consume memory
quickly algorithms, gave 120 second cutoff sliding tile puzzle prevent
thrashing).
8.1 Four-Way Unit Cost Grids
Figure 16 shows anytime performance unit cost four-way movement grid pathfinding problems. AwAHDA* AwPBNF found best solutions quicker algorithms.
731

fiB URNS , L EMONS , RUML , & Z HOU

Korfs 100 15-puzzles 2 threads

1.016

1.012

1.008

1.004

40

80

120

ARA*
Multi wA* 8 threads
ARPBNF 8 threads
AwA*
AwPBNF 8 threads
AwAHDA* 8 threads

1.02

Solution Cost (factor optimal)

ARA*
Multi wA* 2 threads
ARPBNF 2 threads
AwAHDA* 2 threads
AwA*
AwPBNF 2 threads

1.02

Solution Cost (factor optimal)

Korfs 100 15-puzzels 8 threads

160

1.016

1.012

1.008

1.004

40

Wall time (seconds)

80

120

160

Wall time (seconds)

Figure 17: Korfs 100 15-puzzles lower hull anytime profiles.
algorithms improved amount time taken find better solutions threads
added. AwPBNF converged quickly threads added. Even two threads
AwPBNF first algorithm converge optimal solution 60% time serial A*.
next two algorithms Multi-wA* anytime repairing PBNF (ARPBNF). Multi-wA* converged quickly threads added, performance finding intermediate solutions
change much different numbers threads. ARPBNF, hand, took longer
find good solutions low thread counts, threads added started perform better,
eventually matching Multi wA* eight threads. algorithms improved solution
quality steadily AwPBNF AwAHDA* large jumps lower hulls.
jumps corresponds hull switching different weight value (compare
raw data AwPBNF Figure 15). parallel algorithms found good solutions faster
serial AwA* serial ARA*. parallel algorithms, however, took longer prove optimality
AwA* domain.
8.2 Sliding Tile Puzzles
Figure 17 presents lower hulls anytime algorithms Korfs 100 instances 15-puzzle.
figure, x-axes show total wall clock time seconds. times normalized
A* able solve instances. panels, see AwAHDA* tended
find good solutions faster algorithms. AwA* AwPBNF performed similarly
two threads number threads increased AwPBNF begun find better solutions faster
AwA*. ARPBNF took longer find good solutions AwPBNF AwAHDA*
able find better solutions faster serial counterpart. simple Multi wA* algorithm
performed worst parallel algorithms. Increasing number threads used Multi-wA*
seem increase solution quality. ARA* gave worst performance domain;
profile curve seen top three panels.
732

fi7 threads

2 threads

7 threads

2 threads

B EST-F IRST EARCH ULTICORE ACHINES

logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8
logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11

1.5
1.09
1.36
0.78
0.77
0.64
1.37
1.24
1.15
0.61
1.45
2.54
1.77
1.22
0.93
3.64
3.60
3.04

logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8
logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11

1.5
1.06
1.91
2.05
1.58
2.01
1.93
1.94
1.95
2.04
2.04
3.72
5.61
5.96
6.18
3.54
5.74
5.78

AwAPRA*
2
3
1.06
1.40
7.76 56.41
0.77
0.76
0.78
0.78
0.67
0.69
1.43
4.61
1.30
1.30
1.19
1.11
0.62
0.62
1.43
1.81
15.63 98.52
1.68
1.71
1.22
1.26
0.93
0.95
3.75 11.59
3.64
3.65
3.20
3.05
AwPBNF
2
3
1.35
1.94
1.99
13.22
1.96
1.99
1.96
1.98
2.07
2.13
1.06
2.78
2.00
2.01
2.10
1.99
2.05
2.09
2.46
4.19
22.37
25.69
5.05
5.03
4.66
5.74
6.03
6.20
1.50
15.32
5.52
5.48
5.83
5.73

5
1.40
>90.16
0.75
0.76
0.70
1.37
2.68
1.20
0.62
1.81
>177.08
1.73
1.26
0.94
4.44
7.60
3.17

5
1.98
>22.36
1.95
1.91
2.07
6.23
4.10
0.77
2.06
4.21
>7.20
5.06
4.70
6.05
11.46
10.84
2.18

1.5
1.23
1.62
1.35
1.26
1.20
1.66
1.51
1.50
1.16
2.87
3.30
3.75
3.56
2.77
5.00
4.41
4.74

1.5
0.68
1.02
1.94
1.85
1.74
1.45
1.44
1.73
2.01
1.02
1.60
4.30
4.10
3.71
1.78
2.02
2.58

AwAHDA*
2
3
1.21
1.59
9.90
63.60
1.33
1.32
1.23
1.24
1.19
1.16
1.68
5.65
1.51
1.50
1.55
1.46
1.11
1.14
2.81
3.65
19.91 132.97
3.69
3.61
3.46
3.51
2.75
2.79
4.97
16.36
4.42
4.40
4.82
4.66
AwBFPSDD
2
3
0.91
0.91
1.18
7.71
1.89
1.94
1.87
1.49
1.74
1.75
1.46
1.97
1.45
1.32
1.78
1.59
2.00
1.98
1.35
1.37
1.96
12.10
4.24
4.16
3.54
4.16
3.74
3.73
1.82
2.59
1.96
1.92
2.86
2.57

5
1.66
>110.16
1.33
1.23
1.17
1.95
3.18
1.54
1.11
3.74
>231.45
3.67
3.50
2.77
21.57
9.25
4.87

5
0.56
>11.92
1.82
1.80
1.69
3.08
2.40
1.41
1.96
0.92
>19.94
3.96
3.88
3.38
4.14
3.68
2.34

Table 6: Speed-up anytime search optimality serial AwA* STRIPS planning using
various weights.

8.3 STRIPS Planning
Table 6 shows speedup parallel anytime algorithms serial anytime A*. algorithms
run optimal solution proved. (For weight 5, AwA* ran memory
blocks-14, speedup values weight instance lower bounds.) bold entries
733

fi7 Threads

B URNS , L EMONS , RUML , & Z HOU

logistics-6
blocks-14
gripper-7
satellite-6
elevator-12
freecell-3
depots-7
driverlog-11
gripper-8

1.5
1.48
1.24
1.07
1.10
1.06
1.05
1.20
1.16
1.06

AwPBNF
2
3
1.84 2.36
1.22 0.21
0.99 0.99
0.87 1.08
1.04 1.04
0.44 0.99
1.15 1.15
1.15 1.19
0.99 0.99

5
2.27
0.03
1.00
0.88
1.03
0.29
1.08
0.43
1.00

1.5
0.68
0.87
0.93
0.88
0.77
0.64
0.54
0.53
0.99

AwBFPSDD
2
3
0.93 0.71
0.18 0.16
0.95 0.93
0.77 0.91
0.78 0.76
0.64 0.20
0.53 0.52
0.58 0.54
0.98 0.99

5
0.54
0.16
0.92
0.90
0.73
0.14
0.49
0.50
0.97

1.5
1.12
1.46
0.99
0.99
1.02
1.13




AwAPRA*
2
3
1.08 1.08
1.46 1.42
1.03 1.01
1.00 1.01
1.00 1.00
1.16 0.82







5
0.98
0.94
0.99
1.02
1.00
0.10




Table 7: Speed-up anytime search optimality PBNF STRIPS planning problems using
various weights.

table represent values within 10% best performance given domain.
algorithms, speedup serial generally increased threads higher weight.
PBNF gave fastest performance except two domains (blocks-14 freecell-3).
two domains AwAHDA* gave best performance least factor 10x AwPBNF.
Hansen Zhou (2007) show AwA* lead speedup A* weight values
certain domains. Finding suboptimal solution quickly allows f pruning keeps open list
short quick manipulate, resulting faster performance even though AwA* expands
nodes A*. found similar phenomenon corresponding parallel case. Table 7 shows
speedup unweighted optimal PBNF using various weights anytime algorithms.
significant fraction values greater 1, representing speedup using anytime
algorithm instead standard optimal parallel search. general, speedup seems variable
weight increases. weight 1.5, AwPBNF always provides speedup.
8.4 Summary
part paper shown create new parallel anytime search algorithms
based frameworks introduced previous sections. created new parallel
anytime algorithm simply runs many weighted A* searches differing weights.
experiments, seen AwPBNF AwAHDA* found higher quality solutions faster
algorithms showed improved performance threads added.
Additionally, ARPBNF, parallel algorithm based ARA*, improved threads
tended give smoother increase solution quality former two algorithms, although
find solutions quite quickly unable converge optimal solution
sliding tiles domain within given time limit. Running multiple weighted A* searches
give solutions faster number threads increased, convergence performance
mixed.

9. Discussion
explored set best-first search algorithms exploit parallel capabilities modern
CPUs. First looked parallel optimal search (Safe) PBNF, several variants PRA*
734

fiB EST-F IRST EARCH ULTICORE ACHINES

set simpler previously proposed algorithms. Overall, Safe PBNF gave best performance
optimal search. Next created set bounded-suboptimal search algorithms based PBNF,
successful variants PRA*, BFPSDD algorithm. PBNF PRA* asynchronous
communication abstraction (AHDA*) gave best performance all, PBNF
slightly better average. addition, showed results suggest boundedsuboptimal PBNF advantage serial weighted A* search problem difficulty
increases. Finally converted PBNF PRA* anytime algorithms compared
serial anytime algorithms new algorithm called multi-weighted A*. found
anytime weighted PBNF anytime variant AHDA* gave best anytime performance
occasionally able find solutions faster non-anytime counterparts.
results show PBNF outperforms PSDD. believe lack
layer-based synchronization better utilization heuristic cost-to-go information. fact
BFPSDD got better f layers widened suggestive evidence. Another less obvious
reason PBNF may perform better best-first search larger frontier size
breadth-first heuristic search used PSDD. larger frontier size tend create
nblocks containing open search nodes. disjoint duplicate detection scopes
nodes open lists and, therefore, potential increased parallelism.
results show that, even single thread, PBNF outperform serial A* search
(see Table 1). may attributed part speculative behavior PBNF algorithm.
Since PBNF uses minimum number expansions testing switch nblock
better f values, search sub-optimal nodes A* would search. order
get optimal solutions, PBNF acts anytime algorithm; stores incumbent solutions prunes
prove optimal solution. Zhou Hansen show approach
ability perform better A* (Hansen & Zhou, 2007) upper bound pruning,
reduces number expansions nodes f value equal optimal solution
cost reduce number open nodes, increasing speed operations open list.
PBNF may give good single thread performance breaks search frontier
many small open lists (one nblock). this, priority queue operations
PBNF performs much smaller queues A*, uses one big single queue (see
Section 4.6.2).
9.1 Possible Extensions
basic guideline creating good abstractions SDD (and PBNF) minimize
connectivity abstract states, aspects abstraction could explored.
instance, discovering features good include abstract away may helpful
users PBNF. much focus one feature could cause good nodes focused small
subset nblocks (Zhou & Hansen, 2009). Likewise, size abstraction could examined
detail. Although always use constant abstraction size current work simplicity
seems likely abstraction size change number threads changes perhaps even
based features domain problem instance. guideline could devised, ratio
number nblocks threads h value start state, problem-adaptive abstraction
size would much simpler real world use. Additionally, edge partitioning (Zhou & Hansen,
2007) could allow us reduce connectivity abstraction used PBNF, study
necessary discover full impact technique PBNFs behavior.
735

fiB URNS , L EMONS , RUML , & Z HOU

possible future extensions PBNF include adaptive minimum expansion values, use
external memory, extension distributed setting. preliminary work adapting minimum expansion values indicated simply increasing decreasing based lock failures
successes either neutral negative effect performance. One reason may
minimum expansions parameter adds speculation.
may possible combine PBNF PRA* distributed memory setting. algorithm
may use technique based PRA* distribute portions search space among different nodes
cluster work stations using multicore search PBNF node.
additional technique explored paper running multicore search algorithms threads available cores. technique used improve
performance parallel delayed duplicate detection (Korf, 1993; Korf & Schultze, 2005)
heavily I/O intensive. Using approach, one thread blocked I/O another thread
make use newly available processing core. Even without disk I/O technique may
useful threads spend lot time waiting acquire locks.

10. Conclusions
paper investigated algorithms best-first search multicore machines.
shown set previously proposed algorithms parallel best-first search much slower
running A* serially. presented novel hashing function PRA* takes advantage
locality search space gives superior performance. Additionally, verified results presented Kishimoto et al. (2009) using asynchronous communication PRA* allows
perform better using synchronous communication. present new algorithm, PBNF,
approximates best-first search ordering trying keep threads busy. proved
correctness PBNF search framework used derive new suboptimal anytime
algorithms.
performed comprehensive empirical comparison optimal, suboptimal anytime variations parallel best-first search algorithms. results demonstrate using good
abstraction distribute nodes PRA* beneficial asynchronous communication,
two techniques used together (yielding AHDA*). found original breadth-first PSDD algorithm give competitive behavior without tight upper bound
pruning. implemented novel extension PSDD, BFPSDD, gives reasonable performance domains tested. experiments, however, demonstrate new PBNF
AHDA* algorithms outperformed algorithms. PBNF performs best optimal
bounded-suboptimal search PBNF AHDA* gave competitive anytime performance.

Acknowledgments
gratefully acknowledge support NSF (grant IIS-0812141), DARPA CSSG program
(grant HR0011-09-1-0021) helpful suggestions Jordan Thayer. results
previously reported Burns, Lemons, Zhou, Ruml (2009b) Burns, Lemons, Ruml,
Zhou (2009a).
736

fiB EST-F IRST EARCH ULTICORE ACHINES

Appendix A. Pseudo-code Safe PBNF
following pseudo code three global structures. first pointer current
incumbent solution, incumbent, second done flag set true thread recognizes
search complete third nblock graph. nblock graph structure contains
list free nblocks, freelist along h values nblock. simplicity,
code uses single lock access either structure. thread local exp count. best
function set nblocks results nblock containing open node lowest f value.
EARCH ( INITIAL NODE )
1. insert initial node open
2. p processors, HREAD EARCH()
3. threads still running, wait()
4. return incumbent
HREAD EARCH ()
1. b NULL
2. done
3.
b N EXT N BLOCK(b)
4.
exp 0
5.
HOULD WITCH(b, exp)
6.
best open node b
7.
> incumbent prune
8.
goal
9.
< incumbent
10.
lock; incumbent m; unlock
11.
else duplicate
12.
children expand(m)
13.
child children
14.
insert child open appropriate nblock
15.
exp exp + 1
HOULD WITCH ( B , EXP )
1. b empty return true
2. exp < min-expansions return false
3. exp 0
4. best(freelist) < b best(interferenceScope(b)) < b
5.
best(interferenceScope(b)) < best(freelist)
6.
ET H OT(best(interferenceScope(b)))
7.
return true
8. lock
9. b interferenceScope(b)
10.
hot(b ) ET C OLD(b )
11. unlock
12. return false

737

fiB URNS , L EMONS , RUML , & Z HOU

ET H OT ( B )
1. lock
2. hot(b) (b) > 0
3.
interferenceScope(b) : < b hot(i )
4.
hot(b) true
5.
interferenceScope(b)
6.
hot(m ) ET C OLD(m )
7.
(m ) = 0 h (m ) = 0
8.
empty
9.
freelist freelist \ {m }
10.
h (m ) h (m ) + 1
11. unlock
ET C OLD ( B )
1. hot(b) false
2. interferenceScope(b)
3.
h (m ) h (m ) 1
4.
(m ) = 0 h (m ) = 0 empty
5.
hot(m )
6.
ET C OLD(m )
7.
freelist freelist {m }
8.
wake sleeping threads
R ELEASE ( B )
1. b interferenceScope(b)
2.
(b ) (b ) 1
3.
(b ) = 0 h (b ) = 0 b empty
4.
hot(b )
5.
ET C OLD(b )
6.
freelist freelist {b }
7.
wake sleeping threads
N EXT N BLOCK ( B )
1. b open nodes b set hot lock
2. else trylock() fails return b
3. b 6= NULL
4.
bestScope best(interferenceScope(b))
5.
b < bestScope b < best(freelist)
6.
unlock; return b
7.
R ELEASE(b)
8. (l nblocks : (l ) = 0) freelist empty
9.
done true
10.
wake sleeping threads
11. freelist empty done, sleep
12. done n NULL
738

fiB EST-F IRST EARCH ULTICORE ACHINES

13. else
14.
best(freelist)
15.
b interferenceScope(m)
16.
(b ) (b ) + 1
17. unlock
18. return

739

fiB URNS , L EMONS , RUML , & Z HOU

Appendix B. TLA+ Model: Hot N blocks
present model used show Safe PBNF live-lock free. Refer Section 3.2.3.
MODULE HotNblocks
FiniteSets, Naturals
CONSTANTS nnblocks, nprocs, search, nextblock , none
VARIABLES state, acquired , isHot, Succs

Vars = hstate, acquired , isHot, Succsi

States = {search, nextblock }

Nblocks = 0 . . nnblocks 1

Procs = 0 . . nprocs 1
ASSUME nnblocks nprocs nprocs > 0 nnblocks > 1 none
/ Nblocks Cardinality(States) = 2

Preds(x ) = {y Nblocks : x Succs[y]} Set predecessors Nblock x

IntScope(x ) = Preds(x ) UNION {Preds(y) : Succs[x ]} interference scope x

IntBy(x ) = {y Nblocks : x IntScope(y)} Set Nblocks x interferes.

Busy(A) = UNION {Succs[x ] : x A} Set Nblocks busy given set acquired nblocks

Overlap(x , A) = IntScope(x ) Set Busy Nblocks overlapping successors x

Hot(A) = {x Nblocks : isHot[x ] Overlap(x , A) 6= {}} Set hot nblocks given set acquired nblocks

HotInterference(A) = UNION {IntScope(x ) : x Hot(A)} Set Nblocks interference scopes hot nblocks

Free(A) = {x Nblocks : Overlap(x , A) = {} x
/ HotInterference(A)} Free Nblocks

Acquired = {acquired [x ] : x Procs} \ {none} Set Nblocks currently acquired

OverlapAmt(x ) = Cardinality(Overlap(x , Acquired )) number nblocks overlapping x .

doNextBlock (x ) = UNCHANGED hSuccsi
state[x ] = nextblock acquired [x ] = none Free(Acquired ) 6= {}
Free(Acquired \ {acquired [x ]}) 6= {}
Free(Acquired \ {acquired [x ]}) : acquired = [acquired EXCEPT ! [x ] = y]
state = [state EXCEPT ! [x ] = search]
isHot = [y Nblocks 7 Free(Acquired \ {acquired [x ]})
FALSE ELSE isHot[y]]
ELSE acquired = [acquired EXCEPT ![x ] = none]
isHot = [y Nblocks 7 Free(Acquired )
FALSE ELSE isHot[y]]
UNCHANGED hstatei

doSearch(x ) = UNCHANGED hacquired , Succsi
state[x ] = search state = [state EXCEPT ![x ] = nextblock ]
UNCHANGED hisHoti
IntBy(acquired [x ]) : isHot[y]
IntScope(y) Hot(Acquired ) = {}

/ HotInterference(Acquired )
isHot = [isHot EXCEPT ![y] = TRUE]

Init = state = [x Procs 7 nextblock ] acquired = [x Procs 7 none]
isHot = [x Nblocks 7 FALSE]
EXTENDS

basic graph nblock connected neighbors forming loop.

Succs = [x Nblocks 7

x = 0 {nnblocks 1, x + 1}
x = nnblocks 1 {0, x 1} ELSE {x 1, x + 1}]

Next = x Procs : (doNextBlock (x ) doSearch(x ))

Fairness = x Procs : WFVars (doNextBlock (x ) doSearch(x ))

Prog = Init 2[Next]Vars Fairness

HotNblocks = x Nblocks : isHot[x ] ; isHot[x ] property prove


ELSE

740

fiB EST-F IRST EARCH ULTICORE ACHINES

References
Burns, E., Lemons, S., Ruml, W., & Zhou, R. (2009a). Suboptimal anytime heuristic search
multi-core machines. Proceedings Seventeenth International Conference Automated Planning Scheduling (ICAPS-09).
Burns, E., Lemons, S., Zhou, R., & Ruml, W. (2009b). Best-first heuristic search multi-core
machines. Proceedings 14th International Joint Conference Artificial Intelligence
(IJCAI-09).
Cushing, W., Bentor, J., & Kambhampati, S. (2010). Cost based search considered harmful.
2010 International Symposium Combinatorial Search (SOCS-10).
Dai, P., & Hansen, E. A. (2007). Prioritizing bellman backups without priority queue. Proceedings Nineteenth International Conference Automated Planning Scheduling
(ICAPS-09).
Davis, H. W., Bramanti-Gregor, A., & Wang, J. (1988). advantages using depth breadth
components heuristic search. Methodologies Intelligent Systems 3, pp. 1928.
Edelkamp, S., & Schrodl, S. (2000). Localizing A*. Proceedings Seventeenth National
Conference Artificial Intelligence (AAAI-00), pp. 885890. AAAI Press.
Edelkamp, S., & Sulewski, D. (2010). GPU exploration two-player games perfect hash
functions. 2010 International Symposium Combinatorial Search (SOCS-10).
Evans, J. (2006). scalable concurrent malloc(3) implementation FreeBSD. Proceedings
BSDCan 2006.
Evett, M., Hendler, J., Mahanti, A., & Nau, D. (1995). PRA* - massively-parallel heuristic-search.
Journal Parallel Distributed Computing, 25(2), 133143.
Felner, A., Kraus, S., & Korf, R. (2003). KBFS: K-best-first search. Annals Mathematics
Artificial Intelligence, 39(1-2), 1939.
Ferguson, C., & Korf, R. E. (1988). Distributed tree search applications alpha-beta pruning. Proceedings Seventh National Conference Artificial Intelligence (AAAI-88).
Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial Intelligence
Research, 28, 267297.
Harris, T. L. (2001). pragmatic implementation non-blocking linked-lists. Lecture Notes
Computer Science, Vol. 2180/2001, pp. 300314. Springer Berlin / Heidelberg.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. IEEE Transactions Systems Science Cybernetics, SSC-4(2),
100107.
Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings
Fifth Internationas Conference Artificial Intelligence Planning Scheduling Systems
(AIPS-00), pp. 140149.
Holzmann, G. J., & Bosnacki, D. (2007). design multicore extension SPIN model
checker. IEEE Transactions Software Engineering, 33(10), 659674.
741

fiB URNS , L EMONS , RUML , & Z HOU

Jabbar, S., & Edelkamp, S. (2006). Parallel external directed model checking linear I/O.
Emerson, E., & Namjoshi, K. (Eds.), Verification, Model Checking, Abstract Interpretation, Vol. 3855 Lecture Notes Computer Science, pp. 237251. Springer Berlin / Heidelberg.
Kishimoto, A., Fukunaga, A., & Botea, A. (2009). Scalable, parallel best-first search optimal
sequential planning. Proceedings Nineteenth International Conference Automated
Planning Scheduling (ICAPS-09).
Korf, R. E. (1985). Iterative-deepening-A*: optimal admissible tree search. Proceedings
International Joint Conference Artificial Intelligence (IJCAI-85), pp. 10341036.
Korf, R. E. (1993). Linear-space best-first search. Artificial Intelligence, 62(1), 4178.
Korf, R. E. (2003). Delayed duplicate detection: extended abstract. Proceedings Eighteenth
International Joint Conference Articial Intelligence (IJCAI-03), pp. 15391541.
Korf, R. E., & Schultze, P. (2005). Large-scale parallel breadth-first search. Proceedings
Twentieth National Conference Articial Intelligence (AAAI-05), pp. 13801385.
Kumar, V., Ramesh, K., & Rao, V. N. (1988). Parallel best-first search state-space graphs: summary results. Proceedings Seventh National Conference Artificial Intelligence
(AAAI-88), pp. 122127.
Lamport, L. (2002). Specifying Systems: TLA+ Language Tools Hardware Software
Engineers. Addison-Wesley.
Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Anytime A* provable bounds
sub-optimality. Proceedings Seventeenth Annual Conference Neural Information
Porcessing Systems (NIPS-03).
Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Formal analysis. Tech. rep. CMU-CS-03148, Carnegie Mellon University School Computer Science.
Niewiadomski, R., Amaral, J., & Holte, R. (2006a). parallel external-memory frontier breadthfirst traversal algorithm clusters workstations. Proceedings 2006 International
Conference Parallel Processing (ICPP-06), pp. 531538.
Niewiadomski, R., Amaral, J. N., & Holte, R. C. (2006b). Sequential parallel algorithms
frontier A* delayed duplicate detection. Proceedings 21st national conference
Artificial intelligence (AAAI-06), pp. 10391044. AAAI Press.
Nilsson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Co.
Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence, 1, 193
204.
Powley, C., & Korf, R. E. (1991). Single-agent parallel window search. IEEE Transactions Pattern
Analysis Machine Intelligence, 13(5), 466477.
Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime planning
landmarks. Journal Artificial Intelligence Research, 39.
Ruml, W., & Do, M. B. (2007). Best-first utility-guided search. Proceedings IJCAI-07, pp.
23782384.
742

fiB EST-F IRST EARCH ULTICORE ACHINES

Snir, M., & Otto, S. (1998). MPI-The Complete Reference: MPI Core. MIT Press, Cambridge,
MA, USA.
Stern, U., & Dill, D. L. (1998). Using magnetic disk instead main memory mur verifier.
Computer Aided Verification, pp. 172183. Springer.
Sundell, H., & Tsigas, P. (2005). Fast lock-free concurrent priority queues multi-thread
systems. Parallel Distributed Processing Symposium, International, 65(5), 609627.
Thayer, J. T., & Ruml, W. (2008). Faster weighted A*: optimistic approach bounded
suboptimal search. Proceedings Eighteenth International Conference Automated
Planning Scheduling (ICAPS-08).
Valois, J. D. (1995). Lock-Free Data Structures. Ph.D. thesis, Rensselaer Polytechnic Institute.
Yu, Y., Manolios, P., & Lamport, L. (1999). Model checking TLA+ specifications. Correct
Hardware Design Verification Methods, pp. 5466. Springer Berlin / Heidlberg.
Zhou, R., & Hansen, E. (2006). Domain-independent structured duplicate detection. Proceedings
Twenty-First National Conference Artificial Intelligence (AAAI-06), pp. 10821087.
Zhou, R., & Hansen, E. (2007). Edge partitioning external-memory graph search. Proceedings
Twentieth International Joint Conference Artificial Intelligence (IJCAI-07).
Zhou, R., & Hansen, E. (2009). Dynamic state-space partitioning external-memory graph search.
2009 International Symposium Combinatorial Search (SOCS-09).
Zhou, R., & Hansen, E. A. (2004). Structured duplicate detection external-memory graph search.
Proceedings Nineteenth National Conference Artificial Intelligence (AAAI-04).
Zhou, R., & Hansen, E. A. (2006). Breadth-first heuristic search. Artificial Intelligence, 170(45),
385408.
Zhou, R., & Hansen, E. A. (2007). Parallel structured duplicate detection. Proceedings
Twenty-Second Conference Artificial Intelligence (AAAI-07).

743


