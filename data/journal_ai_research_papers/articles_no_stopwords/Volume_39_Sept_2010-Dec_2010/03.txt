Journal Artificial Intelligence Research 39 (2010) 581632

Submitted 12/09; published 11/10

Clustering Want?
Inducing Ideal Clustering Minimal Feedback
Sajib Dasgupta
Vincent Ng

sajib@hlt.utdallas.edu
vince@hlt.utdallas.edu

Human Language Technology Research Institute
University Texas Dallas
800 West Campbell Road; Mail Station EC31
Richardson, TX 75080-3021 U.S.A.

Abstract
traditional research text clustering largely focused grouping documents
topic, conceivable user may want cluster documents along dimensions,
authors mood, gender, age, sentiment. Without knowing users intention,
clustering algorithm group documents along prominent dimension,
may one user desires. address problem clustering documents
along user-desired dimension, previous work focused learning similarity metric
data manually annotated users intention human construct
feature space interactive manner clustering process. goal
reducing reliance human knowledge fine-tuning similarity function selecting
relevant features required approaches, propose novel active clustering
algorithm, allows user easily select dimension along wants
cluster documents inspecting small number words. demonstrate
viability algorithm variety commonly-used sentiment datasets.

1. Introduction
Text clustering one major application domains demonstrating viability
clustering algorithm. traditional research text clustering largely focused
grouping documents topic, conceivable user may want cluster documents along dimensions, authors mood, gender, age, sentiment. Since
virtually existing text clustering algorithms produce one clustering given
set documents, natural question is: clustering necessarily one user desires? words, text clustering algorithm always produce clustering along
user-desired dimension?
answer question depends large extent whether user successfully communicate intention clustering algorithm. Traditionally,
achieved designing good similarity function capture similarity
pair documents, ideal clustering produced. typically involves
identify set features useful inducing desired clusters (Liu, Li,
Lee, & Yu, 2004). However, manually identifying right set features timeconsuming knowledge-intensive, may even require lot domain expertise.
fact resulting similarity function typically easily portable domains
particularly unappealing machine-learning perspective. overcome weakness,
c
2010
AI Access Foundation. rights reserved.

fiDasgupta & Ng

researchers attempted learn similarity metric side information (Xing, Ng,
Jordan, & Russell, 2002), constraints pairs documents must must
appear cluster (Wagstaff, Cardie, Rogers, & Schrodl, 2001).
contrast, recent work focused active clustering, clustering algorithm
incorporate user feedback clustering process help ensure documents grouped according user-desired dimension. One way
user incrementally construct set relevant features interactive fashion (Bekkerman, Raghavan, Allan, & Eguchi, 2007; Raghavan & Allan, 2007; Roth & Small, 2009).
Another way user correct mistakes made clustering algorithm
clustering iteration specifying whether two existing clusters merged
split (Balcan & Blum, 2008). major drawback associated active clustering
algorithms involve considerable amount human feedback, needs
provided iteration clustering process. Furthermore, identifying clusters
merging splitting Balcan Blums algorithm may easy appears:
merge split decision user makes, sample large number
documents cluster(s), read documents, base decision
extent documents (dis)similar other.
article, attack problem clustering documents according user interest
different angle. aim knowledge-lean approach problem
approach produce clustering documents along user-desired dimension
without relying human knowledge fine-tuning similarity function selecting
relevant features, unlike existing approaches. end, propose novel active
clustering algorithm, assumes input simple feature representation (composed
unigrams only) simple similarity function (i.e., dot product), operates
(1) inducing important clustering dimensions1 given set documents,
clustering dimension represented (small) number automatically selected words
representative dimension; (2) user choose dimension along
wants cluster documents examining automatically selected words.
comparison aforementioned feedback mechanisms, arguably much simpler:
require user cursory look small number features
dimension all, opposed user generate feature space
interactive manner identify clusters need merged split clustering
iteration.
evaluate active clustering algorithm task sentiment-based clustering,
goal cluster set documents (e.g., reviews) according polarity
(e.g., thumbs thumbs down) expressed author without using labeled
data. decision focus sentiment-based clustering motivated several reasons.
One reason relatively little work sentiment-based clustering.
mentioned before, existing work text clustering focused topic-based clustering,
high accuracies achieved even datasets large number classes
(e.g., 20 Newsgroups); despite large amount recent work sentiment analysis
1. use term clustering dimension refer dimension along set documents
clustered. example, set movie reviews clustered according genre (e.g., action, romantic,
documentary) sentiment (e.g., positive, negative, neutral).

582

fiInducing Ideal Clustering Minimal Feedback

Review 1
sound system seem little better
(the CDs skipping much). bottom line
didnt fix problem CDs still skipping noticeably,
although bad before. ...
Review 2
John Lynch wrote classic Spanish-American Revolutions 1808-1826.
describes events led independence Latin America Spain.
book starts Rio de La Plata ends Mexico Central America.
Curiously one note common pattern highly stratified societies lead Spanish ...
reluctance Spanish Monarchy (and later even liberals) led independence ...
interested better understanding Latin ??this great book must.
Lynch cleverly combines historical economic facts Hispanic American societies ...

Table 1: Snippets two reviews illustrate two challenges polarity classification.
One reviews sentimentally ambiguous (Review 1),
objective materials review significantly outnumber subjective counterparts
(Review 2).

opinion mining, much focused supervised methods (see Pang & Lee, 2008,
comprehensive survey field).
Another equally important reason focus sentiment-based clustering concerned challenges task presents natural language processing (NLP)
researchers. Broadly speaking, complexity sentiment-based clustering arises
two sources. First, reviews sentimentally ambiguous, containing positive negative sentiment-bearing words phrases. Review 1 Table 1 shows snippet
review DVD domain illustrates sentimental ambiguity problem:
phrases little better, skipping, bad convey positive sentiment,
phrases didnt fix skipping noticeably negative sentiment-bearing. Hence,
unless sentiment analyzer performs deeper linguistic analysis, difficult
analyzer determine polarity review. Second, objective materials review tend significantly outnumber subjective counterparts, reviewer typically
devotes large portion review describing features product assigning rating it; consequently, sentiment analyzer uses word- phrase-based
feature representation composed mostly features irrelevant respect
polarity determination. Shown Review 2 Table 1 snippet book review
illustrates problem. see, three words/phrases (classic, great
book, cleverly) review correspond objective materials.
aforementioned complications present significant challenges even supervised polarity classification systems, let alone sentiment-based clustering algorithms,
access labeled data. illustrate difficulty two complications impose sentiment-based clustering, consider task clustering set movie
reviews. Since review may contain description plot authors sentiment,
clustering algorithm may cluster reviews along either plot dimension sentiment
dimension; without knowing users intention, clustered along
583

fiDasgupta & Ng

prominent dimension. Assuming usual bag-of-words representation, prominent
dimension likely plot, uncommon review devoted almost
exclusively plot, author briefly expressing sentiment end
review. Even reviews contain mostly subjective materials, prominent
dimension may still sentiment owing aforementioned sentimental ambiguity
problem: presence positive negative sentiment-bearing words reviews renders sentiment dimension hidden (i.e., less prominent) far clustering
concerned.
sum, contributions article five-fold.
propose novel active clustering algorithm cluster set documents
along user-desired dimension without labeled data side information
manually specified automatically acquired must-link cannot-link constraints.
comparison existing active clustering approaches, algorithm appeal
requiring much simpler human feedback.
demonstrate viability algorithm evaluating performance
sentiment datasets, via set human experiments, typically
absent papers involve algorithms incorporating user feedback.
results led deeper understanding spectral clustering. Specifically,
propose novel application top eigenvectors produced spectral clustering
algorithm, use unveil important clustering dimensions text
collection.
results implications domain adaptation, topic recently
received lot attention NLP community. Specifically, show
sentiment dimension manually identified one domain used automatically
identify sentiment dimension new, similar, domain.
Preliminary results datasets possess one clustering dimension (e.g.,
collection book DVD reviews, clustered sentiment
type product concerned) indicate algorithm capable producing
multiple clusterings dataset, one along dimension. Hence, algorithm
potentially reveal information dataset possible traditional
clustering algorithms, produce single clustering data.
ability produce multiple clusterings particularly useful feature user
idea wants documents clustered (due
lack knowledge data, instance). Even user knowledge
data knows wants documents clustered, algorithm help
unveil hidden dimensions previously aware may
interest her.
rest article organized follows. Section 2 presents basics spectral
clustering, facilitate discussion active clustering algorithm Section
3. describe human experiments evaluation results several sentiment datasets
Section 4 significance work Section 5. Finally, discuss related work
Section 6 conclude Section 7.
584

fiInducing Ideal Clustering Minimal Feedback

2. Spectral Clustering
given clustering task, important question ask is: clustering algorithm
use? popular choice k-means. Nevertheless, well-known k-means
major drawback able separate data points linearly separable
given feature space (e.g., see Dhillon, Guan, & Kulis, 2004; Cai, He, & Han, 2005).
Moreover, since k-means clusters documents directly given feature space,
text applications typically comprises hundreds thousands features, performance
could adversely affected curse dimensionality. Spectral clustering algorithms
developed response problems k-means. section, first present
one commonly-used algorithms spectral clustering (Section 2.1). Then,
provide intuition behind spectral clustering (Section 2.2). Finally, describe two ways
use resulting eigenvectors produce clustering (Section 2.3).
2.1 Algorithm
Let X={x1 , . . . , xn } set n data points clustered, : X X similarity
function defined X, similarity matrix captures pairwise similarities
(i.e., Si,j = s(xi , xj )). many clustering algorithms, spectral clustering algorithm
takes input outputs k-way partition C = {C1 , C2 , .., Ck } (i.e., ki=1 Ci = X
i, j : 6= j = Ci Cj = ). Equivalently, one think spectral clustering learning
partitioning function f , which, rest article, represented vector
f (i) {1, . . ., k} indicates cluster xi assigned. Note
cluster labels interchangeable even renamed without loss
generality.
Among well-known spectral clustering algorithms (e.g., Weiss, 1999; Shi & Malik,
2000; Kannan, Vempala, & Vetta, 2004), adopt one proposed Ng, Jordan,
Weiss (2001), arguably widely-used. main steps Ng et
al.s spectral clustering algorithm:
1. Create diagonal matrix whose (i,i)-th entry sum i-th row S,
construct Laplacian matrix2 L = 1/2 SD 1/2 .
2. Find eigenvalues eigenvectors L.
3. Create new matrix eigenvectors correspond largest eigenvalues.
4. data point rank-reduced point m-dimensional space. Normalize
point unit length (while retaining sign value).
5. Apply k-means cluster data points using resulting eigenvectors.
words, spectral clustering clusters data points low-dimensional space,
dimension corresponds top eigenvector Laplacian matrix.
2. follow Ng et al. (2001) employ normalized dual form usual Laplacian S.

585

fiDasgupta & Ng

2.2 Intuition behind Spectral Clustering
may immediately clear spectral clustering produces meaningful partitioning set points. theoretical justifications behind spectral clustering,
since mathematics quite involved, provide intuitive justification
clustering technique way sufficient reader understand active
clustering algorithm Section 3, refer interested reader Shi Maliks (2000)
seminal paper spectral clustering details. Since apply spectral clustering
produce 2-way clustering given set data points rest article,
center discussion 2-way clustering subsection.
Spectral clustering employs graph-theoretic notion grouping. Specifically, set
data points arbitrary feature space represented undirected weighted graph,
node corresponds data point, edge weight two nodes xi
xj similarity, Si,j .
Given graph formulation, reasonable way produce 2-way partitioning
data points minimize similarity resulting two clusters, C1 C2 .
Hence, reasonable objective function minimize cut value,
X
Cut(C1 , C2 ) =
Si,j (f (i) f (j))2 .
i,j

Without loss generality, define f follows.

1 : C1
f (i) =
1 : C2
mentioned before, use 1 1 cluster labels here, interchangeable
fact renamed whatever way want.
One problem minimizing cut value, noticed Wu Leahy (1993),
objective favors producing unbalanced clusters one contains
small number nodes. words, bias towards isolating small set
nodes. mentioned Shi Malik (2000), surprising, since
number edges involved cut (and hence cut value) tends increase sizes
two clusters become relatively balanced.
closer examination minimum cut criterion reveals problem: minimizes inter-cluster similarity, makes attempt maximize intra-cluster similarity.
address weakness, Shi Malik (2000) propose minimize instead normalized
cut value, N Cut, takes account inter-cluster dissimilarity intra-cluster
similarity. specifically,
Cut(C1 , C2 )
Cut(C1 , C2 )
+
,
assoc(C1 , C1 C2 ) assoc(C2 , C1 C2 )
P
assoc(A, B), computed xi A,xj B Si,j , total connection nodes
nodes B. Given definition, cut resulting unbalanced clusters
longer small N Cut value. see reason, consider case C1 consists
one node. case, assoc(C1 , C1 C2 ) = Cut(C1 , C2 ), making N Cut(C1 , C2 ) large.
N Cut(C1 , C2 ) =

586

fiInducing Ideal Clustering Minimal Feedback

algebra, express N Cut follows:
N Cut(C1 , C2 ) =

f (D S)f
f Df

subject constraints (Df )T 1 = 0
rP
d(i)


PiC2

iC1 d(i)
rP
f (i) =
d(i)


PiC1 d(i)
iC2

: C1
: C2

d(i) = D(i, i), defined Section 2.1.3 first constraint, specifies
Df orthogonal 1, intuitively understood follows: since 1, constant
vector entries 1, cannot used induce partition, constraint
avoids trivial solution points assigned cluster.
Unfortunately, Papadimitriou proves minimizing normalized cut NP-complete
problem, even special case graphs regular grids (see Shi & Malik, 2000,
proof). Hence, following Shi Malik, relax minimization problem dropping
second constraint allowing entry f take real value rather one
two discrete values, seeking real-valued solution following problem:
minn

f

f (D S)f
f Df

(1)

subject
Df 1.
Assuming g = 1/2 f , rewrite Problem (1)
minn

g

gT 1/2 (D S)D 1/2 g
gT g

(2)

subject
g 1/2 1.
Following standard Rayleigh-Ritz theorem, one prove solution
Problem (2), g, eigenvector corresponds second smallest eigenvalue
1/2 (D S)D 1/2 , equivalently, eigenvector corresponds second largest
eigenvector D1/2 SD 1/2 , Laplacian matrix L defined Section 2.1.
simplicity, henceforth refer eigenvector corresponds n-th largest
eigenvalue L simply n-th eigenvector denote en .4
3. Besides normalized cut, ratio cut (Chan, Schlag, & Zien, 1994), average association (Shi & Malik, 2000),
min-max cut (Ding, He, Zha, Gu, & Simon, 2001) used objective functions
spectral clustering algorithms.
4. Given Problem (2) involves minimizing Rayleigh quotient, may seem somewhat unintuitive
solution second eigenvector L rather first eigenvector. reason attributed
constraint associated problem, specifies solution g perpendicular
D1/2 1, first eigenvector L.

587

fiDasgupta & Ng

idea behind spectral clustering: second eigenvector L approximate solution problem minimizing normalized cut.5 course, since second
eigenvector real-valued solution, convert partitioning function
used cluster data points. Section 2.3 explains two simple ways
converting eigenvector partitioning function.
turns eigenvectors L convey useful information
data. Specifically, impose additional constraint Problem (2) forcing solution orthogonal second eigenvector L, solution becomes third
eigenvector. Hence, third eigenvector thought suboptimal solution
Problem (2), meaning used impose reasonably good partition
data points. Perhaps importantly, since eigenvectors L orthogonal
(because L symmetric), clustering produced using third eigenvector
likely correspond different dimension data produced second
eigenvector.
generally, limit solution space real-valued vectors
orthogonal first eigenvectors L, solution constrained optimization
problem (m + 1)-th eigenvector L. words, top eigenvectors
L intuitively thought revealing important dimension data, although
subsequent eigenvectors progressively less ideal far clustering concerned.
2.3 Clustering Eigenvectors
Ng et al. (2001) point out, different authors still disagree eigenvectors
use, derive clusters them. subsection, describe two common
methods determining eigenvectors use, method, show
derive clusters using selected eigenvector(s). methods serve baselines
evaluation.
2.3.1 Method 1: Using Second Eigenvector
Since Shi Malik (2000) show second eigenvector, e2 , approximate solution
problem minimizing normalized cut, perhaps surprising
e2 commonly chosen eigenvector deriving partition. However, since e2
real-valued solution constrained optimization problem, need specify
derive clusters it.
Clustering using e2 trivial: since linearization points, one simple way
determine threshold partitioning them. However, follow Ng et al. (2001)
cluster points using 2-means one-dimensional space.
2.3.2 Method 2: Using Top Eigenvectors
Recall Section 2.1 eigen-decomposing Laplacian matrix, data point
represented co-ordinates. second method, use 2-means cluster data
points m-dimensional space, effectively exploiting top eigenvectors.
5. fact, since f = D1/2 g, pre-multiply second eigenvector L D1/2 get
solution Problem (1), following Ng et al. (2001), employ second eigenvector L directly
clustering, ignoring term D1/2 .

588

fiInducing Ideal Clustering Minimal Feedback

3. Active Clustering Algorithm
mentioned before, sentiment-based clustering challenging, part due fact
reviews clustered along one dimension. section, describe
active clustering algorithm, makes easy user specify dimension
along wants cluster data points sentiment. Recall algorithm first
applies spectral clustering reveal important dimensions data,
lets user select desired dimension (i.e., sentiment). motivate importance
user feedback, helps understand two baseline clustering algorithms described
Section 2.3, based spectral methods rely user feedback, may always yield sentiment-based clustering. begin with, consider first
method, second eigenvector used induce partition. Recall
second eigenvector reveals prominent dimension data. Hence, sentiment
prominent dimension (which happen non-sentiment-bearing words
outnumber sentiment-bearing words bag-of-words representation review),
resulting clustering reviews may sentiment-oriented. similar line
reasoning used explain second baseline clustering algorithm,
clusters based top eigenvectors, may always work well. Since eigenvector corresponds different dimension (and, particular, correspond
non-sentiment dimensions), using represent review may hamper accurate computation similarity two reviews far clustering along sentiment
dimension concerned. rest section, discuss detail major steps
active clustering algorithm, allows easy incorporation user feedback.
3.1 Step 1: Identify Important Clustering Dimensions
rely simple method identifying important clustering dimensions given
text collection: employ top eigenvectors Laplacian important clustering dimensions. method motivated fact e2 , second eigenvector
Laplacian, optimal real-valued solution objective function spectral
clustering minimizes (i.e., normalized cut, Shi & Malik, 2000), therefore optimal
clustering dimension. importantly, exploit rarely-utilized observation discussed
Section 2.2: remaining eigenvectors suboptimal solutions (with ei suboptimal increases), top eigenvectors (i.e., small values),
less suboptimal, may still yield reasonably good (though optimal) clusterings
data therefore serve good clustering dimensions. Existing applications
spectral clustering mainly clustered data points space defined top
eigenvectors, attempted use ei (with > 2) separately
produce clusterings, unlike ours. Note first eigenvector, constant vector,
simply assigns data points cluster therefore typically ignored.
3.2 Step 2: Identify Relevant Features Partition
Given eigen-decomposition Step 1, first obtain second m-th
eigenvectors, correspond important dimensions data. next
question is: determine dimension captures user interest? One way
589

fiDasgupta & Ng

user inspect m1 partitions reviews decide
corresponds closely sentiment-based clustering. main drawback associated
kind user feedback user may read large number reviews
order make decision. Hence, reduce human effort, employ alternative
procedure: (1) identify informative features characterizing partition,
(2) user inspect features rather reviews. make easy
human identify clustering dimension, features chosen
useful distinguishing reviews two clusters.
identify rank informative features, employ method call maximum
margin feature ranking (MMFR).6 Recall maximum margin classifier (e.g., support
vector machine) separates data points two classes maximizing margin
separation. Specifically, maximum margin hyperplane defined w x b = 0,
x feature vector representing arbitrary data point, w (a weight vector) b (a
scalar) parameters learned solving following constrained optimization
problem:
X
1

min kwk2 + C
2

subject
ci (w xi b) 1 ,

1 n,

ci {+1, 1} class i-th training point xi , degree misclassification xi , C regularization parameter balances training error model
complexity.
use w identify informative features partition. Note
informative features large absolute weight values: feature large
positive (negative) weight strongly indicative positive (negative) class.7 exploit
observation identify informative features partition (1) training
binary SVM classifier8 partition, data points cluster assumed
class value; (2) sorting features according SVM-learned feature
weights; (3) generating two ranked lists informative features using top bottom
F features, respectively.
Given ranked lists generated 1 partitions, user select one
partitions/dimensions relevant sentiment inspecting many features
ranked lists needed. picking relevant dimension, user
label one two feature lists associated dimension positive
negative. Since feature list represents one clusters, cluster associated
positive list labeled positive cluster associated negative list
labeled negative.
6. Note commonly-used feature selection techniques log-likelihood ratio information
gain applied identify informative features (see Yang & Pedersen, 1997,
overview).
7. notion using SVM feature weights measures feature informativeness explored
work. See, instance, work Fung (2003), Gilad-Bachrach, Navot, Tishby (2004),
Kugler, Aoki, Kuroyanagi, Iwata, Nugroho (2005) details.
8. SVM classifiers article trained using SVMlight package (Joachims, 1999a),
learning parameters set default values.

590

fiInducing Ideal Clustering Minimal Feedback

comparison existing user feedback mechanisms assisting clustering algorithm,
requires comparatively little human intervention: require user select
dimension examining small number features, opposed user construct
feature space identify clusters need merged split required
methods.
3.3 Step 3: Identify Unambiguous Reviews
caveat, however. mentioned introduction, many reviews contain
positive negative sentiment-bearing words. ambiguous reviews likely
clustered incorrectly unambiguous counterparts. Since ranked lists
features derived partition, presence ambiguous reviews
adversely affect identification informative features using MMFR. result,
remove ambiguous reviews deriving informative features partition.
employ simple method identifying unambiguous reviews. computation
eigenvalues, data point factors orthogonal projections
data points affinity. Ambiguous data points receive orthogonal
projections positive negative data points, hence near zero
values pivot eigenvectors. words, points near zero values
eigenvectors ambiguous large absolute values. therefore sort
data points according corresponding values eigenvector, keep
top n/8 bottom n/8 data points. induce informative features
resulting 25% data points, present user select
desired partition.9
3.4 Step 4: Cluster Along Selected Eigenvector
Finally, employ 2-means cluster reviews along eigenvector selected
user, regardless whether review ambiguous not.

4. Evaluation
section, describe experiments aim evaluate effectiveness active
clustering algorithm provide insights it.
4.1 Experimental Setup
begin discussing details datasets, document preprocessing method,
implementation spectral clustering, evaluation metrics.
9. Note 25% somewhat arbitrary choice. Underlying choice merely assumption
fraction reviews unambiguous. see evaluation section, reviews
classified according polarity high accuracy; consequently, features induced
resulting clusters high quality. Additional experiments revealed list top-ranking
features change significantly induced smaller number unambiguous reviews.

591

fiDasgupta & Ng

4.1.1 Datasets
use five sentiment datasets, including widely-used movie review dataset [MOV]
(Pang, Lee, & Vaithyanathan, 2002) well four datasets containing reviews four
different types products Amazon [Books (BOO), DVDs (DVD), Electronics (ELE),
Kitchen Appliances (KIT)] (Blitzer, Dredze, & Pereira, 2007). dataset 2000
labeled reviews (1000 positives 1000 negatives). illustrate difference
topic-based clustering sentiment-based clustering, show topic-based clustering results POL, dataset created taking documents two sections
20 Newsgroups discuss issues cryptography politics, namely, sci.crypt
talks.politics.
4.1.2 Document Preprocessing
preprocess document, first tokenize downcase it, represent
vector unstemmed unigrams, assumes value 1 0 indicates
presence absence document. addition, remove vector punctuation,
numbers, words length one, words occur single review.
Following common practice information retrieval community, exclude
words high document frequency, many stopwords domain-specific
general-purpose words (e.g., movies movie domain). preliminary examination
evaluation datasets reveals words typically comprise 12% vocabulary.
decision exactly many terms remove dataset subjective: large
corpus typically requires removals small corpus. consistent, simply
sort vocabulary document frequency remove top 1.5%. henceforth
refer document representation bag-of-words (BOW) representation.
4.1.3 Spectral Learning Setup
Following common practice spectral learning text domains (e.g., Kamvar, Klein,
& Manning, 2003; Cai et al., 2005), compute similarity two reviews
taking dot product feature vectors. Ng et al.s (2001) spectral clustering
algorithm, set diagonal entries similarity matrix 0. addition, set
5. words, consider second fifth eigenvectors, assuming
sufficient capturing desired clusterings.10
4.1.4 Evaluation Metrics
employ two evaluation metrics. First, report results dataset terms
accuracy, percentage documents label assigned system
gold-standard label. Second, following Kamvar et al. (2003), evaluate
clusters produced approach gold-standard clusters using Adjusted
Rand Index (ARI), corrected-for-chance version Rand Index.
specifically, given set N data points two clusterings points, U V ,
10. Note setting 5 somewhat arbitrary choice, number eigenvectors
used active clustering algorithm.

592

fiInducing Ideal Clustering Minimal Feedback

U = {U1 , U2 , . . . , Um } clusters V = {V1 , V2 , . . . , Vn } n clusters, ARI
computed follows:
nij
2

P bj
P
[ a2i
j 2 ]/
ARI(U, V ) = 1 P P b
P
ai P
j

j 2 ][ 2
j
2[ 2 +
P

ij

N
2
bj
N
2 ]/ 2



formula, nij number common objects Ui Vj ; whereas ai bj
number objects Ui Vj , respectively. ARI ranges 1 1; better clusterings
higher ARI values.
4.2 Baseline Systems
subsection, describe baseline results. first two baseline systems
ones described Section 2.3, last two arguably sophisticated clustering
algorithms employed attempt strengthen baseline results.
4.2.1 Clustering Using Second Eigenvector
first baseline, adopt Shi Maliks (2000) approach cluster reviews
using second eigenvector, e2 , described Section 2.3. Results POL
sentiment datasets, expressed terms accuracy ARI, shown row 1 Tables 2a
2b, respectively. Owing randomness choice seeds 2-means,
experimental results involving 2-means averaged ten independent runs.11
see, baseline achieves accuracy 93.7% POL, much lower
accuracies (of 5070%) sentiment datasets. performance trend
observed ARI. results provide suggestive evidence producing sentimentbased clustering requires different features producing topic-based clustering,
many cases, salient features tend topic-based. difference
sentiment-based clustering topic-based clustering illuminated
experiments Section 4.7.
addition, worth noting baseline achieves much lower accuracies
ARI values BOO, DVD, ELE remaining two sentiment datasets. Since
e2 captures prominent dimension, results suggest sentiment dimension
prominent dimension three datasets. fact, intuitively
plausible. instance, book domain, positive book reviews typically contain
short description content, reviewer briefly expressing sentiment
somewhere review. Similarly electronics domain: electronic product reviews
typically aspect-oriented, reviewer talking pros cons
aspect product (e.g., battery, durability). Since reviews likely contain
positive negative sentiment-bearing words, sentiment-based clustering unlikely
captured e2 .
11. Note clustering one-dimensional space (as baseline) yields stable results regardless
choice seeds: results ten runs exhibit nearly zero variance.

593

fiDasgupta & Ng

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

POL
93.7
95.9
98.7
70.3
93.7

MOV
70.9
58.9
61.8
71.3
70.9

Accuracy
KIT BOO
69.7 58.9
64.0 59.9
62.2 52.5
66.9 52.1
69.7 69.5

DVD
55.3
60.4
50.6
50.3
70.8

ELE
50.8
63.8
50.2
63.8
65.8

(ARI)
DVD
0.01
0.03
0.01
0.01
0.17

ELE
0.01
0.07
0.01
0.08
0.10

(a)

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

POL
0.76
0.84
0.94
0.16
0.76

Adjusted Rand Index
MOV KIT BOO
0.17 0.15 0.03
0.03
0.05 0.04
0.05
0.06 0.01
0.18 0.11 0.01
0.17 0.15 0.15

(b)

Table 2: Results terms (a) accuracy (b) Adjusted Rand Index six datasets
obtained using bag-of-words document representation. strongest result(s)
dataset boldfaced.

4.2.2 Clustering Using Top Five Eigenvectors
second baseline, represent data point using top five eigenvectors (i.e., e1
e5 ), cluster using 2-means five-dimensional space, described
Section 2.3. Hence, thought ensemble approach, clustering
decision collectively made five eigenvectors.12
Results shown row 2 Tables 2a 2b.13 comparison first baseline,
see improvements accuracy ARI POL three sentiment datasets
first baseline performs poorly (i.e., BOO, DVD, ELE), drastic
improvement observed ELE. However, performance remaining two sentiment
datasets deteriorates. results attributed fact BOO, DVD,
ELE, e2 capture sentiment dimension, since eigenvector
ensemble does, see improvements. hand, e2 already captured
sentiment dimension MOV KIT; result, employing additional dimensions,
may sentiment-related, may introduce noise computation
similarities reviews.
12. first eigenvector produce trivial clustering data points reside
cluster, commonly used combination top eigenvectors create low-dimensional
space data points clustered. See work Ng et al. (2001) details.
13. clustering five-dimensional space, observe results highly sensitive
choice seeds. instance, variances accuracy observed ten runs POL, MOV,
KIT, BOO, DVD, ELE 0, 2.38, 19.90, 24.70, 12.76, 4.43, respectively.

594

fiInducing Ideal Clustering Minimal Feedback

4.2.3 Clustering Using Interested Reader Model
third baseline Kamvar et al.s (2003) unsupervised clustering algorithm, which, according authors, ideally suited text clustering, recently proved
special case ratio-cut optimization (Kulis, Basu, Dhillon, & Mooney, 2009). Specifically, introduce new Laplacian inspired Interested Reader Model.
Laplacian computed (S + dmax D)/dmax , defined Section
2.1, except Si,j =0 one js k nearest neighbors j one k
nearest neighbors; dmax maximum rowsum S; identity matrix. Since
performance highly sensitive k, tested values 10, 15, . . ., 500 k report row 3 Tables 2a 2b best results. Somewhat disappointingly, despite
algorithmic sophistication fact reporting best results, baseline
offer consistent improvements previous two. comparison first
baseline, achieves better performance POL worse performance sentiment
datasets. first baseline, results BOO, DVD ELE particularly poor.
4.2.4 Clustering Using Non-Negative Matrix Factorization
Non-negative matrix factorization (NMF) recently shown Xu, Liu, Gong
(2003) effective document clustering. re-implementing algorithm,
evaluate six datasets.14 Shown row 4 Tables 2a 2b best results obtained running algorithm five times. comparison first baseline,
NMF achieves better performance ELE, comparable performance MOV, worse
performance remaining datasets.
4.3 Active Clustering Algorithm
subsection, describe human automatic experiments evaluating active
clustering algorithm.
4.3.1 Human Experiments
Unlike four baselines, active clustering algorithm requires users specify
four dimensions (defined second fifth eigenvectors) closely
related sentiment inspecting set features derived unambiguous reviews
dimension using MMFR. better understand easy human select
desired dimension given features, performed experiment independently
five humans (all computer science graduate students affiliated
research) computed agreement rate.
Specifically, dataset, showed human judge top 100 features
cluster according MMFR (see Tables 38 subset 100 features induced
six datasets, lightly shared columns correspond sentiment
dimension selected majority human judges).15 addition, informed
14. matrix factorization use code downloaded http://www.csie.ntu.edu.tw/cjlin/nmf/index.html.
15. human judges reported inspecting top 100 features sufficient identifying
sentiment dimension, note user clustering algorithm may request inspect many
features wants.

595

fiDasgupta & Ng

e2
C1
serder
armenian
turkey
armenians
muslims
sdpa
argic
davidian
dbd@ura
troops
C2
sternlight

pgp
crypto
algorithm

likely
access
idea
cryptograph

POL
e3
e4
C1
C1
beyer
serbs
arabs
palestinians
andi
muslims
research
wrong
israelis
department
tim
bosnia
uci
live
ab
matter
z@virginia
freedom
holocaust
politics
C2
escrow
sternlight
algorithm
access
net
des
privacy
uk
systems
pgp

C2
standard
sternlight
des
escrow
employer
net
york
jake
code
algorithm

e5
C1
escrow
serial
algorithm
chips
ensure
care
strong
police
omissions
excepted
C2
internet
uucp
uk
net
quote
ac
co

ai
mit

Table 3: Top ten features induced dimension POL domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

596

fiInducing Ideal Clustering Minimal Feedback

e2
C1
relationship
son
tale
husband
perfect
drama
focus
strong
beautiful
nature
C2
worst
stupid
waste
bunch

video
worse
boring
guess
anyway

MOV
e3
e4
C1
C1
production
jokes
earth
kids
sequences
live
aliens
animation
war
disney
crew
animated
alien
laughs
planet
production
horror
voice
evil
hilarious
C2
sex
romantic
school
relationship
friends
jokes
laughs
sexual
cute
mother

C2
thriller
killer
murder
crime
police
car
dead
killed
starts
violence

e5
C1
starts
person
saw
feeling
lives
told
happen

felt
happened
C2
comic
sequences
michael
supporting
career
production
peter
style
latest
entertaining

Table 4: Top ten features induced dimension MOV domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

597

fiDasgupta & Ng

BOO
e2
C1
history
must
modern
important
text
reference
excellent
provides
business


e3
C1
series
man
history
character
death

war
seems
political
american

e4
C1
loved
highly
easy
enjoyed
children

although
excellent
understand
three

e5
C1
must
wonderful
old
feel
away
children
year
someone
man
made

C2
plot

thought
boring
got
character


ending
fan

C2
buy
bought
information
easy
money
recipes
pictures
look
waste
copy

C2
money
bad
nothing
waste
buy
anything

already
instead
seems

C2
boring
series
history
pages
information

highly
page
excellent


Table 5: Top ten features induced dimension BOO domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

598

fiInducing Ideal Clustering Minimal Feedback

ELE
e2
C1
mouse
cable
cables
case
red
monster
picture
kit
overall
paid

e3
C1
music
really
ipod

little
headphones
hard
excellent
need
fit

e4
C1
easy
used
card
fine
using
problems
fine
drive
computer
install

e5
C1
amazon
cable
card
recommend
dvd
camera
fast
far
printer
picture

C2
working
never

phone
days
headset
money
months
return
second

C2
worked
problem
never
item
amazon
working
support
months
returned
another

C2
money
worth
amazon

return
years
much
headphones
sony
received

C2
phone

worked
power
battery
unit
set
phones
range
little

Table 6: Top ten features induced dimension ELE domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

599

fiDasgupta & Ng

e2
C1
love
clean
nice
size
set
kitchen
easily
sturdy
recommend
price
C2
months
still
back
never
worked
money

amazon
return
machine

KIT
e3
e4
C1
C1
works
really
water
nice
clean
works
work

ice
quality
makes
small
thing
sturdy
need
little
keep
think
best
item
C2
price
item
set
ordered
amazon
gift
got
quality
received
knives

C2

years
love
never
clean
months

pan

pans

e5
C1
pan
oven
cooking
made
pans
better
heat
cook
using
clean
C2
love
coffee

recommend
makes

size
little
maker
cup

Table 7: Top ten features induced dimension KIT domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

600

fiInducing Ideal Clustering Minimal Feedback

e2
C1
worth
bought
series
money
season
fan
collection
music
tv
thought
C2
young

actors
men
cast
seems
job
beautiful
around
director

DVD
e3
e4
C1
C1
music
video
collection
music
excellent
found
wonderful
feel
must
bought
loved
workout
perfect
daughter
highly
recommend
makes

special
disappointed
C2
worst
money
thought
boring
nothing
minutes
waste
saw
pretty
reviews

C2
series
cast
fan
stars
original
comedy
actors
worth
classic
action

e5
C1
money
quality
video
worth
found
version
picture
waste
special
sound
C2
saw
watched
loved
enjoy
whole
got
family
series
season
liked

Table 8: Top ten features induced dimension DVD domain. shaded
columns correspond dimensions selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

601

fiDasgupta & Ng

Judge
1
2
3
4
5
Agreement

POL
2,3,4
2,4
4
2,3
2
80%

MOV
2
2
2,4
2
2
100%

KIT
2
2
4
2
2
80%

BOO
4
4
4
4
4
100%

DVD
3
3
3
3
3
100%

ELE
3
3
3
3,4
3
100%

Table 9: Human agreement rate. shown eigenvectors selected five judges.
intended dimension: example, POL, judge told intended
clustering Politics vs. Science. Also, determined one dimension
relevant intended clustering, instructed rank dimensions
terms relevance, relevant one would appear first list.
dimensions (expressed terms IDs eigenvectors) selected
five judges dataset shown Table 9. agreement rate (shown
last row table) computed based highest-ranked dimension selected
judge. see, perfect agreement achieved four five sentiment
datasets, remaining two datasets, near-perfect agreement achieved.
results, together fact took five six minutes identify relevant
dimension, indicate asking human determine intended dimension based
solely informative features viable task.
4.3.2 Clustering Results
Next, cluster 2000 documents dataset using dimension selected
majority human judges. clustering results shown row 5 Tables 2a
2b. comparison best baseline dataset, see algorithm
performs substantially better BOO, DVD ELE, almost level MOV
KIT, slightly worse POL. Note improvements observed BOO, DVD
ELE attributed failure e2 capture sentiment dimension. Perhaps
importantly, exploiting human feedback, algorithm achieved stable
performance across datasets four baselines.16
4.3.3 Identification Unambiguous Documents
Recall features largest MMFR computed unambiguous
documents only. get idea accurate algorithm identifying unambiguous
documents is, show Table 10 accuracy obtained unambiguous documents
dataset clustered using eigenvector selected majority judges.
see, accuracy dataset higher corresponding accuracy
shown row 5 Table 2a. fact, accuracy 85% achieved
16. first baseline, since clustering one-dimensional space here, results
sensitive choice seeds, yielding zero variance ten independent runs.

602

fiInducing Ideal Clustering Minimal Feedback

Accuracy

POL
99.8

MOV
87.0

KIT
87.6

BOO
86.2

DVD
87.4

ELE
77.6

Table 10: Accuracies unambiguous documents.

# labels

POL
400

MOV
150

KIT
200

BOO
350

DVD
350

ELE
200

Table 11: Transductive SVM results.
one dataset. suggests method identifying unambiguous documents
reasonably accurate.
Note crucial able achieve high accuracy unambiguous documents: clustering accuracy low, features induced clusters may
accurate representation corresponding dimension, human judge may
difficult time identifying intended dimension. fact, human judges reported difficulty identifying correct dimension ELE dataset, attributed
part low accuracy achieved unambiguous documents.
4.3.4 User Feedback Versus Labeled Data
Recall four baselines unsupervised, whereas algorithm characterized
semi-supervised, relies user feedback select intended dimension. Hence,
surprising see average clustering performance algorithm
better baselines.
fairer comparison, conduct another experiment compare
algorithm semi-supervised sentiment classification system, uses transductive SVM underlying semi-supervised learner. specifically, goal
experiment determine many labeled documents needed order transductive learner achieve level performance algorithm. answer
question, first give transductive learner access 2000 documents
dataset unlabeled data. Next, randomly sample 50 unlabeled documents assign
true label. re-train classifier compute accuracy 2000
documents. keep adding labeled data (50 iteration) reaches
accuracy achieved algorithm. Results experiment shown Table 11.
Owing randomness involved selection unlabeled documents, results
averaged ten independent runs. see, user feedback equivalent
effort hand-annotating 275 documents per dataset average.
4.3.5 Multiple Relevant Eigenvectors
seen Table 9, human judges selected one eigenvector
datasets (e.g., {2,3,4} POL; {2,4} MOV; {3,4} ELE). However, never took
account extra eigenvectors previous experiments. better understand
603

fiDasgupta & Ng

system

POL
Acc ARI
95.9 0.84

MOV
Acc ARI
69.1 0.16

ELE
Acc ARI
65.1 0.10

Table 12: Results obtained using multiple relevant eigenvectors POL, MOV
ELE datasets.

Accuracy

POL
99.3

MOV
86.1

KIT
81.7

BOO
79.3

DVD
77.6

ELE
80.6

Table 13: Supervised classification accuracies.
whether extra eigenvectors help improve accuracy ARI, conduct another
experiment apply 2-means cluster documents space defined
selected eigenvectors. Table 12 shows accuracy ARI results averaged
ten independent runs. see, results POL considerably better
obtained highest-ranked eigenvector used, suggesting
extra eigenvectors contain useful information. However, results MOV ELE drop
slightly addition extra eigenvectors, indicating extra sentiment
dimensions useful.
4.3.6 Supervised Classification Results
Next, present results supervised classification five sentiment datasets.
one expect largely unsupervised approach offer comparable performance
fully-supervised approach, believe fully-supervised results enable
reader get sense work stands among existing work identifying
sentiment datasets. Specifically, report Table 13 averaged 10-fold crossvalidation accuracies, SVM classifier trained nine folds tested
remaining fold fold experiment. see, results lag behind supervised
results 8.115.2% datasets.
4.4 Alternative Document Representations
experiments, represented document bag words
frequent 1.5% words removed. is, course, way represent
document. subsection, examine two alternative document representations
attempt better understand effect document representation classification results.
first document representation, represent document using unigrams
appear remove frequent words document vector.
bag-of-all-words (BOAW) representation motivated fact frequencies
function words shown many studies useful features various kinds non-topic-based classification (e.g., Finn & Kushmerick, 2006; Stein, Argamon,
& Frieder, 2006; Abbasi, Chen, & Salem, 2008; Koppel, Schler, & Argamon, 2009).
604

fiInducing Ideal Clustering Minimal Feedback

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

POL
70.6
94.7
61.2
59.2
84.3

MOV
54.3
60.6
61.1
54.6
65.9

Accuracy
KIT BOO
51.6 52.4
58.0 56.1
57.8 52.4
50.8 50.1
64.8 60.1

DVD
51.2
53.7
50.4
52.9
58.6

ELE
53.1
57.1
50.3
51.4
64.1

(a)

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

POL
0.17
0.80
0.05
0.03
0.47

Adjusted Rand Index (ARI)
MOV KIT
BOO DVD
0.01
0.01
0.01
0.01
0.04
0.03
0.01
0.01
0.05
0.02
0.01
0.01
0.01 0.01 0.01 0.01
0.10
0.09
0.04 0.03

ELE
0.01
0.03
0.01
0.01
0.08

(b)

Table 14: Results terms (a) accuracy (b) Adjusted Rand Index six datasets
obtained using bag-of-all-words document representation. strongest result(s)
dataset boldfaced.

accuracy ARI results obtained re-running four baselines well system
using document representation shown Tables 14a 14b, respectively. Comparing Tables 2a 14a, see words used features, best
accuracy achieved dataset drops 311% high-frequency words
removed spectral clustering applied. Similar trends observed ARI
results shown Tables 2b 14b. Overall, results substantiate hypothesis
retaining high-frequency words document representation adverse effect
performance clustering algorithms.
Next, experiment another representation, specifically one document represented using sentiment-bearing words contains. understand
motivation behind bag-of-sentiment-words (BOSW) representation, recall introduction one way encourage clustering algorithm produce user-desired
clustering design feature space contains features
useful producing user-desired clustering. Since desire sentiment-based clustering, design feature space composed solely sentiment-bearing words. Since
hand-crafted subjectivity lexicon (i.e., lexicon word manually labeled
prior polarity17 ) English readily available, automatically construct feature
space consists words (positive negative) polarity according
subjectivity lexicon, represent document using resulting feature space.
17. prior polarity word polarity computed without regard context word
appears.

605

fiDasgupta & Ng

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

MOV
69.1
60.7
54.6
68.8
69.1

KIT
62.3
57.9
50.3
59.0
62.3

Accuracy
BOO DVD
60.2 61.4
57.6
63.1
54.4
56.0
59.2 63.3
60.2 61.4

ELE
63.9
62.7
50.6
60.5
63.9

(a)

System Variation
2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

Adjusted Rand Index (ARI)
MOV KIT BOO DVD ELE
0.15 0.06 0.04 0.05 0.08
0.04
0.03 0.03 0.07 0.06
0.01
0.01 0.01
0.01 0.01
0.14
0.03 0.03 0.07 0.04
0.15 0.06 0.04 0.05 0.08
(b)

Table 15: Results terms (a) accuracy (b) Adjusted Rand Index five
sentiment datasets obtained using bag-of-sentiment-words document representation.
strongest result(s) dataset boldfaced.

goal, then, determine whether BOSW document representation improve
sentiment-based clustering results obtained using BOW representation.
identify sentiment-bearing words experiment, employ subjectivity lexicon introduced work Wilson, Wiebe, Hoffmann (2005).18 lexicon contains
8221 words, hand-labeled prior polarity Positive, Negative,
Neutral. create new subjectivity lexicon L retain words
Wilson et al.s lexicon either Positive Negative polarity. BOSW
representation document composed words appear
L document.
accuracy ARI results baselines system obtained employing
BOSW representation shown Tables 15a 15b, respectively. Consider first
second eigenvector baseline, NMF, Interested Reader Model. comparison
corresponding results Tables 2a 2b, BOW representation
used, see performance improves BOO, DVD, ELE datasets
cases, drops MOV KIT datasets. top five eigenvectors baseline,
performance increases DVD slightly MOV, drops remaining datasets.
Finally, using BOSW representation causes performance system drop
datasets.
Overall, results seem suggest whether BOSW representation document yields better clustering results BOW representation rather dependent
underlying domain clustering algorithm. Nevertheless, see best
18. See http://www.cs.pitt.edu/mpqa/.

606

fiInducing Ideal Clustering Minimal Feedback

clustering accuracy/ARI achieved sentiment dataset using BOSW representation significantly lower obtained using BOW representation. speculate
two reasons poorer results. First, general-purpose subjectivity lexicon
cover sentiment-bearing words. particular, words sentiment-oriented
context particular domain neutral polarity otherwise may omitted BOSW document representation. Second, non-sentiment-bearing words
might useful identifying sentiment.
4.5 Domain Adaptation
mentioned introduction, majority existing approaches sentiment classification supervised. One weakness supervised approaches given
new domain, one needs go expensive process collecting large amount
annotated data order train accurate polarity classifier.19 One may argue
active clustering algorithm suffers weakness: user needs identify
sentiment dimension domain. One way address weakness domain
adaptation. Specifically, investigate whether sentiment dimension manually identified one domain (henceforth source domain) used automatically identify
sentiment dimension new domain (henceforth target domain). hypothesize
domain adaptation feasible, especially two domains sentimentally similar (i.e., significant overlap features characterize sentiment
dimensions two domains).
result, propose following method automatically identifying sentiment
dimension target domain, y, using sentiment dimension manually identified
source domain, x. Assume sentiment dimension domain x defined
x
x
eigenvector ex . Moreover, assume C1e C2e two vectors top-ranked
features (obtained using MMFR) characterize two clusters induced ex (with 100
features cluster). Now, given target domain y, first compute similarity
ex ys top eigenvectors, ey2 , . . ., ey5 , similarity two
eigenvectors ex ey defined
x



x



x



x



max((C1e , C1e ) + (C2e , C2e ), (C1e , C2e ) + (C2e , C1e ))
Here, similarity function computes similarity two feature vectors.
experiments, simply set dot product, allows us capture
degree overlap two feature vectors. Then, posit eigenvector
{ey2 , . . . , ey5 } highest overlap one defines sentiment dimension.20
determine effectiveness method, compare automatically selected
eigenvector human-selected eigenvector domain. Results shown
Table 16, row column j indicates sentiment dimension
target domain j successfully identified using sentiment dimension manually
19. collecting annotated data trivial dealing review data, necessarily
true kinds data. instance, people express opinions sentiment political blogs
floor debates, associated postings transcripts may explicitly annotated
sentiment labels.
20. Note two arguments max function correspond two different ways creating
mapping feature vectors two domains.

607

fiDasgupta & Ng

Domain
MOV
DVD
BOO
ELE
KIT

MOV


N
N
N

DVD



N


BOO
N


N
N

ELE
N
N
N



KIT
N





Table 16: Domain adaptation results.

identified source domain i, N indicates failure. instance, know
sentiment dimension DVD domain (through human feedback), domain
adaptation method used correctly identify sentiment domain MOV
vice versa. However, domain adaptation using method always successful.
instance, knowing sentiment dimension MOV allow us correctly predict
sentiment dimension ELE. Interestingly, ignore BOO/KIT pair, domain
adaptation exhibits symmetry. symmetry, mean domain x used
identify correct sentiment dimension domain y, domain used
identify correct sentiment dimension domain x. intuitively makes sense:
x successfully used identify sentiment dimension y, likely
two domains share lot sentiment words. Consequently, using adapt x
likely successful. BOO/KIT pair represents case domain adaptation
successful one direction: domain adaptation successful BOO KIT,
similarity sentiment dimensions two domains high (see
discussion next paragraph details), contributes failure adaptation
direction.
mentioned beginning subsection, hypothesize domain adaptation likely successful two domains consideration similar
other. test hypothesis, show Table 17a similarity manually
identified eigenvector corresponding automatically identified eigenvector
pair domains. Three points deserve mention. First, long similarity value
least 14, domain adaptation successful; also, long similarity value 6,
domain adaptation unsuccessful. Hence, results substantiate hypothesis
domain adaptation likely successful two domains consideration
similar other. would interesting see two thresholds
used predict whether domain adaptation successful given new pair domains.
Second, domain adaptation directions likely successful similarity
value sufficiently high. mentioned before, similarity value high,
two domains share many sentiment words common, may turn contribute
successful domain adaptation directions. five domains considering,
long similarity value least 14, domain adaptation directions
successful. Third, worth reiterating even similarity value falls
threshold, imply domain adaptation fail. mentioned before,
sentiment dimension domain (correctly) identified long similarity
608

fiInducing Ideal Clustering Minimal Feedback

Domain
MOV
DVD
BOO
ELE
KIT

MOV

14
(6)
(3)
(1)

DVD
14

21
(8)
10

BOO
(6)
21

(6)
(11)

ELE
(2)
(10)
(10)

32

KIT
(3)
10
8
32


BOO
(4)
13

(5)
(8)

ELE
(2)
(9)
(6)

27

KIT
(3)
7
6
23


BOO
(2)
8

(1)
(3)

ELE
(0)
(1)
(4)

5

KIT
(0)
3
2
9


(a)

Domain
MOV
DVD
BOO
ELE
KIT

MOV

5
(4)
(2)
(1)

DVD
10

14
(8)
7
(b)

Domain
MOV
DVD
BOO
ELE
KIT

MOV

9
(2)
(0)
(1)

DVD
4

7
(0)
3
(c)

Table 17: Similarity results domain adaptation. (a) shows similarity
sentiment eigenvector source domain eigenvector similar target
domain. (b) shows similarity sentiment eigenvector source domain
second similar eigenvector target domain. (c) shows similarity gap,
difference corresponding entries (a) (b).

sentiment dimension domain x highest among four eigenvectors y,
case BOO/KIT domain pair.
far attempted correlate success domain adaptation similarity manually selected eigenvector source domain eigenvector
similar target domain. may worth consider similarity
manually selected eigenvector second similar eigenvector
target domain, gap similarity may give indication success domain adaptation. determine whether better correlation success
domain adaptation similarity gap, compute (1) similarity
eigenvector manually selected source domain second similar eigenvector
target domain (see Table 17b) well (2) similarity gap (see Table 17c),
simply difference corresponding entries Tables 17a 17b.
see Table 17c, appears correlation success
domain adaptation gap values. particular, gap value least 5, domain
609

fiDasgupta & Ng

adaptation successful; however, gap value 1, domain adaptation unsuccessful. Nevertheless, gap values help predict domain pairs
success domain adaptation cannot predicted using similarity values Table 17a
(e.g., domain pairs low similarity yet domain-adaptable). Moreover,
fail predict success domain adaptation many domain pairs, specifically
gap value 1 5.
4.6 Subjectivity Lexicon versus Human Feedback
One might argue access subjectivity lexicon, could use automatically identify right sentiment dimension, thus obviating need human feedback
altogether. subsection, investigate whether indeed feasible use handbuilt general-purpose sentiment lexicon identify eigenvector corresponds
sentiment dimension new domain.
experiment, use subjectivity lexicon L described Section 4.4.
mentioned before, L contains words Wilson et al.s (2005) subjectivity
lexicon marked prior polarity Positive Negative. procedure
automatically identifying sentiment dimension using L similar one described
domain adaptation section: second fifth eigenvectors, first
compute similarity eigenvector L, choose eigenvector
highest similarity L. domain adaptation, compute similarity
L eigenvector ex
x

x

x

x

max((C1L , C1e ) + (C2L , C2e ), (C1L , C2e ) + (C2L , C1e ))
C1L C2L represent words L labeled positive negative rex
x
spectively, C1e C2e top-ranked features (obtained using MMFR)
characterize two clusters induced ex (with 100 features cluster). similarity function computes similarity two feature vectors. domain
adaptation, simply set dot product.
results indicate successfully identified right eigenvector using L
five domains. Note L general-purpose (i.e., domain-independent)
lexicon containing generic sentiment-bearing words, good enough identify
correct sentiment dimension five different domains. worth noting sentiment
dimension MOV domain highest similarity L (i.e., 34) five
domains, suggesting highest-ranked sentiment features MOV domain (according MMFR) largely generic. DVD second largest similarity L (33),
followed BOO (26), KIT (16) ELE (16). comparatively low similarity values
KIT ELE indicative fact highest-ranked sentiment features
largely domain-specific.
Finally, although subjectivity lexicon obviates need human feedback,
emphasize undermine contribution feedback-oriented clustering
technique, following reasons. First, thinking text mining perspective, would
good approach knowledge-free possible. Employing handcrafted subjectivity lexicon makes system resource-dependent; fact, subjectivity
lexicon may readily available vast majority natural languages. Second,
610

fiInducing Ideal Clustering Minimal Feedback

want method potentially applicable non-sentiment domains (e.g., spam vs.
spam), faced problem hand-built lexicon may
available.
4.7 Single Data, Multiple Clusterings
mentioned previously, set documents clustered along different dimensions.
example, movie reviews clustered sentiment (positive vs. negative) genre
(e.g., action, romantic documentary). natural question is: produce different
clusterings given set documents, corresponds different dimension?
vast majority existing text clustering algorithms, answer no:
cluster along exactly one dimension, typically prominent dimension.
hand, since algorithm induces important clustering dimensions
dataset, principle used produce (distinct) clustering,
hypothesize generate multiple clusterings given dataset along important
dimensions.
test claim algorithm produce multiple clusterings, evaluate
four datasets possess multiple clustering dimensions, namely MOV-DVD, BOODVD, DVD-ELE, MOV-KIT.21 example, BOO-DVD dataset consists
reviews taken BOO DVD domains. Hence, augmented dataset
composed 4000 reviews (2000 two contributing domains),
clustered according either topic (e.g., Book vs. DVD) sentiment.22 Note
four pairs domains used create augmented datasets chosen carefully.
Specifically, two augmented datasets (MOV-DVD BOO-DVD) created
constituent domains mutually domain-adaptable according Table 16,
remaining two (DVD-ELE MOV-KIT) created constituent domains
domain-adaptable. goal see whether active clustering algorithm able
produce topic- sentiment-based clusterings datasets different levels
sentimental similarity.
clustering procedure almost identical one described Section 3. essence,
(1) compute top five eigenvectors Laplacian matrix; (2) learn top-ranked
features corresponding e2 e5 according MMFR; (3) ask human judges
identify eigenvectors corresponding topic dimension sentiment
dimension; (4) use 2-means produce two clusterings reviews, one according
selected topic dimension selected sentiment dimension.
Section 4.3, conducted human automatic experiments determine viability
algorithm.
21. reason employing augmented datasets obviate need
additional human annotations, guarantee least two dimensions along
clusters formed, thus allowing us directly test ability produce multiple clusterings.
possible evaluate algorithms ability generate multiple clusterings using MOV
dataset (by clustering along genre sentiment), decided leave future investigation, since
documents MOV annotated genre information.
22. confused topic-sentiment mixture models (Mei, Ling, Wondra, Su, & Zhai, 2007),
goal first use topic models mine major aspects product online review
assign ratings extracted aspect. hand, goal design clustering
algorithm capable generating multiple clusterings dataset.

611

fiDasgupta & Ng

Judge
1
2
3
4
5
Agreement

MOV-DVD
2
2
2
2
2
100%

BOO-DVD
2
2
2
2
2
100%

DVD-ELE
2
2
2
2
2
100%

MOV-KIT
2
2
2
2
2
100%

DVD-ELE
3
3,5
5,3
3
3
80%

MOV-KIT
3
3,5
3
5
3
80%

(a)

Judge
1
2
3
4
5
Agreement

MOV-DVD
3
3,4
3,4
3
3
100%

BOO-DVD
4,5
4,5
4,5
4,5
4,5
100%
(b)

Table 18: Human agreement rate selecting (a) topic dimension (b) sentiment
dimension augmented datasets. shown eigenvectors selected
human judges.

4.7.1 Human Experiments
employed five human judges involved human experiments Section 4.3
independently determine topic dimension sentiment dimension
four augmented datasets using top features according MMFR. before,
human judge identifies one relevant eigenvector particular dimension,
ask rank eigenvectors according relevance. Finally, take topic/sentiment
dimension ranked first largest number judges human-selected
topic/sentiment dimension.
Tables 18a 18b show respectively topic sentiment dimensions (expressed
terms IDs eigenvectors) selected five judges augmented
dataset. shown tables human agreement rate, computed
based highest-ranked dimension selected judge. Several points
human experiments deserve mention.
First, dataset, human judges managed find one eigenvector (out
top five) corresponds topic least one eigenvector corresponds
sentiment. Perhaps importantly, human agreement rate least 80%
achieved four datasets respect selecting eigenvector(s) correspond
topic sentiment dimensions. results together provide suggestive evidence
(1) eigen-decomposition procedure active clustering algorithm effective
enough unearth topic sentiment dimensions present
612

fiInducing Ideal Clustering Minimal Feedback

dataset, (2) proposal incorporating user feedback via inspecting small
number features viable.
Second, topic sentiment prominent dimensions datasets,
fact second eigenvector captures topic dimension four datasets suggests
topic prominent dimension sentiment. fact, human judges
reported topic dimension identified quite easily, achieving perfect agreement
identifying topic dimension. provides empirical evidence speculation
topic typically (though always) prominent dimension sentiment
dimensions exist dataset.
Third, reasonably high human agreement rate identifying sentiment dimension achieved (perfect agreement two datasets 80% agreement rate
remaining two; see Table 18b details), human judges reported difficult identify sentiment dimension(s), especially two datasets composed
sentimentally dissimilar domains.
attempt gain insight judges found difficult identify
sentiment dimension(s), show Tables 1922 top-ranked features induced
dimension using MMFR four augmented datasets, lightly shaded columns
correspond eigenvectors chosen topic dimension darkly shaded columns
correspond eigenvectors chosen sentiment dimension. examining
results, believe points deserve mention.
First, top features generated sentiment eigenvector(s) MOV-DVD
BOO-DVD, two datasets composed sentimentally similar constituent domains,
clearly sentiment-oriented, making relatively easy human judges determine
sentiment eigenvector(s). case DVD-ELE MOV-KIT, two datasets
composed dissimilar domains, top features noisier (i.e., many
necessarily sentiment-oriented), thus making tougher judges locate
sentiment eigenvector(s). fact, one see top features generated
sentiment eigenvector(s) Tables 1922 MOV-DVD BOO-DVD
clearly sentiment-oriented DVD-ELE MOV-KIT.
surprising sentimentally dissimilar constituent domains are, noisier top features generated sentiment eigenvector(s) are,
however. constituent domains sentimentally similar, tend many
sentiment-bearing words common. implies sentiment-bearing words
appear frequently augmented datasets constituent datasets.
Hence, combining two domains helps boost influence sentiment-bearing
words, increasing chance appearing higher list features ranked
MMFR. reinforcement effect intuitively explains sentiment eigenvector
clearly dominated sentiment words datasets composed sentimentally similar domains. hand, constituent domains sentimentally dissimilar, tend
many sentiment-bearing words common. result, influence
sentiment-bearing words present one two constituent domains
diluted larger number non-sentiment-bearing words result combining
two domains. words, features clearly sentiment-oriented
one rather domains may longer appear sufficiently high ranked list
features. fact, saw Tables 21 22, sentiment eigenvector contaminated
613

fiDasgupta & Ng

e2
C1
roles
drama
murder
meets
crime
supporting
involving
convincing
tale
lead
C2
bought
season
buy
disappointed
fan
amazon
buying
copy
dvds
watched

MOV-DVD
e3
e4
C1
C1
wonderful recommend
excellent
fan
beautiful
liked
personal
book
collection
read
view
excellent
art
amazing
highly
definitely
fantastic
highly
deal
absolutely
C2
stupid
boring
dull
mean
terrible
save
lame
run
guys
except

C2
buy
house
rent
waste
wait
kill
murder
obvious
season
dvds

e5
C1
kids
children
loved
child
son
daughter
boy
school
wonderful
heart
C2
quality
dark
war
horror
release
fan
earth
production
suspense
sound

Table 19: Top ten features induced dimension MOV-DVD domain.
lightly darkly shaded columns correspond topic sentiment dimensions respectively
selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

614

fiInducing Ideal Clustering Minimal Feedback

e2
C1
reader
important
subject
understanding
modern
information
examples
political
business
nature
C2
saw
watched
actors
liked
music
season
humor
comedy
favorite
ending

BOO-DVD
e3
e4
C1
C1
bought
excellent
disappointed wonderful
easy
highly
information collection
price
music
waste
special
workout
classic
helpful
video
expected
perfect
reviews
amazing

e5
C1
loved
enjoyed
children
year
wonderful
child
fun
son
friends
highly

C2
young
men
cast
role
actors
script
scene
war
performance
action

C2
version
quality
waste
worst
review
original
edition
collection
amazon
format

C2
boring
ending
waste
reviews

novel
maybe
pages
stupid
finish

Table 20: Top ten features induced dimension BOO-DVD domain.
lightly darkly shaded columns correspond topic sentiment dimensions respectively
selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

615

fiDasgupta & Ng

e2
C1
funny
acting
family
actors
action
plot
enjoy
young
wonderful
comedy
C2
unit
battery
purchased
device
problems
tried
working
plug
charge
computer

DVD-ELE
e3
e4
C1
C1
easy
fine
small
problems
perfect
worked
excellent
months
highly
easy
nice
working
low
computer
comfortable
day
ipod
card
headphones
drive
C2
amazon
item
review
company
return
took
check
saw
card
worked

C2
amazon
tv
purchase
disappointed
item
purchased
reviews
wanted
received
ipod

e5
C1
video
card
camera
fast
easy
cable
picture
pictures
paper
digital
C2
phone
waste
unit
battery
getting
low
power
hear
worst
batteries

Table 21: Top ten features induced dimension DVD-ELE domain.
lightly darkly shaded columns correspond topic sentiment dimensions respectively
selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

616

fiInducing Ideal Clustering Minimal Feedback

e2
C1
james
directed
sex
hour
drama
relationship
death
direction
tv
michael
C2
food
recommend
pot
purchased
mine
kitchen
mixer
handle
size
store

MOV-KIT
e3
e4
C1
C1
pan
coffee
cooking
clean
clean
machine
pans
ice
cook
maker
heat
plastic
oven
cup
heavy
fill
food
months
stick
working
C2
months
purchased
worked
broke
amazon
coffee
replacement
month
tried
service

C2
item
price
sheets
ordered
amazon
received
beautiful
dishes
arrived
sets

e5
C1
price
clean
kitchen
knife
knives
size
sharp
dishwasher
cutting
attractive
C2
pan
toaster
oven
pans
heat
return
bottom
worked
read
toast

Table 22: Top ten features induced dimension MOV-KIT domain.
lightly darkly shaded columns correspond topic sentiment dimensions respectively
selected human judges. e2 , . . ., e5 top eigenvectors; C1 C2 clusters.

617

fiDasgupta & Ng

2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

MOV-DVD
Acc ARI
77.1 0.29
62.4 0.08
84.2 0.53
56.3 0.02
77.1 0.29

BOO-DVD
Acc ARI
77.8 0.31
77.2 0.31
63.1 0.07
69.2 0.15
77.8 0.31

DVD-ELE
Acc ARI
94.2 0.78
93.9 0.78
94.8 0.80
94.4 0.79
94.2 0.78

MOV-KIT
Acc ARI
99.3 0.97
99.3 0.97
99.6 0.99
70.6 0.17
99.3 0.97

DVD-ELE
Acc ARI
50.9 0.00
50.4 0.00
50.9 0.00
51.1 0.00
61.1 0.05

MOV-KIT
Acc ARI
50.0 0.00
50.0 0.00
50.1 0.00
61.6 0.05
59.2 0.03

(a)

2nd eigenvector
Top five eigenvectors
Interested Reader Model
NMF
system

MOV-DVD
Acc ARI
54.4 0.01
68.3 0.13
53.4 0.01
66.9 0.11
71.4 0.18

BOO-DVD
Acc ARI
52.3 0.01
52.0 0.00
52.1 0.01
51.7 0.00
68.8 0.14
(b)

Table 23: Results (a) topic-based clustering (b) sentiment-based clustering
four augmented datasets. strongest results dataset boldfaced.

number features necessarily sentiment-bearing, make difficult
human judges identify sentiment dimension.
Another interesting point note datasets, seems
one eigenvector correspond sentiment. instance, BOO-DVD dataset,
five human judges agreed e4 e5 correspond sentiment dimension.
closer examination two eigenvectors (shown Table 20) reveals interesting
pattern: e4 , positive features (in C1 ) came DVD domain negative
features (in C2 ) came BOO domain; whereas e5 , positive features (in
C1 ) came BOO domain negative features (in C2 ) came DVD.
words, e4 partitions reviews according positive DVD negative
BOO, whereas e5 reverse. suggests eigen-decomposition procedure
smart enough merge positive negative sentiment-bearing words
two domains together. Perhaps even importantly, e4 e5
partitioning reviews along sentiment dimension topic dimension.
4.7.2 Clustering Results
Rows 14 Tables 23a 23b show topic- sentiment-based clustering results
four baseline text clustering algorithms described Section 4.2. Note
baselines produce one clustering documents per dataset.
Hence, baseline, topic-based clustering results produced comparing
clustering gold-standard topic-based clustering, sentiment-based
618

fiInducing Ideal Clustering Minimal Feedback

clustering results produced comparing clustering gold-standard
sentiment-based clustering.
see topic-based results Table 23a, baseline cluster
using second eigenvector achieves best average clustering results four
augmented datasets. potentially attributed fact e2 corresponds
topic dimension four datasets according human judges, described
human experiments. However, clustering using e2 produce best clustering
results four datasets. fact, Interested Reader Model achieves best results
MOV-DVD, DVD-ELE, MOV-KIT. Nevertheless, results BOO-DVD
worst among baselines. true top five eigenvectors baseline
NMF: yielded poor results MOV-DVD; addition, NMFs results
BOO-DVD MOV-KIT promising either.
far sentiment-based baseline clustering results concerned (see rows 14
Table 23b), best average performance achieved NMF. Except three cases
(NMF MOV-DVD MOV-KIT, well top five eigenvectors MOV-DVD),
baseline results particularly promising, accuracy results low fifties
ARI results close zero.
topic- sentiment-based clustering results produced algorithm shown
row 5 Tables 23a 23b. Specifically, results obtained grouping
reviews according eigenvectors manually selected topic sentiment dimensions, respectively. Hence, unlike baselines, topic-based clustering
sentiment-based clustering produced algorithm different other.
before, cases human judges selected one eigenvector dimension, use eigenvector ranked first frequently. see,
accuracies topic-based clustering reasonably high, ranging 77.1% 99.3%.
results suggest possible achieve high-performance topic-based (or
precisely, domain-based) clustering dataset even another prominent clustering dimension (i.e., sentiment) present. hand, despite existence eigenvectors
clearly capture sentiment dimension datasets (e.g., e3 MOV-DVD
dataset), sentiment-based clustering accuracies ARI values lower
topic-based clustering. potentially attributed reason mentioned
introduction: fact reviews sentimentally ambiguous makes non-trivial
classify. comparison four baselines, algorithm achieves best
average performance four datasets comparatively stable performance
across datasets.
worth noting sentiment-based clustering results produced algorithm
MOV-DVD BOO-DVD higher DVD-ELE MOV-KIT.
perhaps surprising: discussed before, human judges found difficult
identify sentiment eigenvector DVD-ELE MOV-KIT MOV-DVD
BOO-DVD, owing part fact many top-ranked features sentiment
eigenvector DVD-ELE MOV-KIT sentiment-oriented, turn
attributed fact datasets correspond domain pairs
sentimentally dissimilar. mentioned above, two sentimentally dissimilar constituent
domains tend many sentiment-bearing words common, consequently,
influence sentiment-bearing words present one two constituent
619

fiDasgupta & Ng

domains diluted larger number non-sentiment-bearing words result
combining two domains, making difficult produce good sentiment-based
clustering. hand, combining two domains helps boost influence
sentiment-bearing words, increasing chance appearing higher
list features ranked MMFR producing good sentiment-based clustering.
Interestingly, algorithm achieves better topic-based clustering results two
datasets DVD-ELE MOV-KIT achieves poorer sentiment-based clustering results. fact, topic-based clustering accuracies DVD-ELE MOV-KIT
near perfect: 94.2% 99.3% DVD-ELE MOV-KIT respectively.
means coincidence: constituent domains augmented dataset highly
dissimilar (i.e., word usage tends differ considerably other), topic clusters well-separated hence high topic-based clustering results
achieved. similar line reasoning explain algorithm finds comparatively
difficult produce good topic-based clustering MOV-DVD BOO-DVD,
constituent domains similar.
results seem suggest higher topic-based accuracy/ARI implies lower
sentiment-based accuracy/ARI vice versa. speculate constituent
domains similar, sentiment-bearing features tend similar result,
sentiment-based results tend good topic-based results tend poor. Additional
experiments needed determine reason.
Overall, results provide supporting evidence feedback-oriented algorithm
produce multiple clusterings dataset. particular, even though sentimentbased clustering accuracies high topic-based clustering accuracies
augmented datasets, current level performance algorithm arguably reasonable, especially considering fact sentiment-based clustering challenging task
traditional clustering algorithms fail even produce one clustering.
4.7.3 Multiple Relevant Eigenvectors
Recall Table 18b four augmented datasets, least one
judge indicated one eigenvector relevant sentiment dimension.
However, producing sentiment-based clustering results using system Table 23b, used eigenvector ranked frequently human judges.
better understand whether using relevant eigenvectors help improve results sentiment-based clustering, repeat experiment apply 2-means
cluster documents space defined eigenvectors determined
relevant least one judge. specifically, cluster following set
eigenvectors: {3,4} MOV-DVD, {4,5} BOO-DVD, {3,5} DVD-ELE, {3,5}
MOV-KIT.
accuracy ARI results experiment shown Table 24. comparison
results last row Table 23b, see using additional relevant eigenvectors
yields better results BOO-DVD dataset. may easy
determine reason, believe poorer results observed BOO-DVD
attributed impurity e5 , captures sentiment topic,
discussed before. hand, additional sentiment eigenvectors chosen
620

fiInducing Ideal Clustering Minimal Feedback

system

MOV-DVD
Acc ARI
72.2 0.19

BOO-DVD
Acc ARI
55.7 0.01

DVD-ELE
Acc ARI
66.2 0.10

MOV-KIT
Acc ARI
59.8 0.04

Table 24: Results sentiment-based clustering obtained using multiple relevant eigenvectors four augmented datasets.
three augmented datasets seem impurity problem,
capture sentiment dimension one constituent domains.

5. Significance Work
believe approach significant following aspects.
1. Producing clustering according user interest. proposed novel framework enabled spectral clustering algorithm take account human
feedback produce clustering along dimension interest user.
particularly appealing aspect approach concerned relatively minimal human feedback demands, user needs take cursory look
small number features representative induced dimension.
worth noting human inspect select automatically induced
clustering dimension new form interaction human clustering
algorithm. enables human easily engage various clustering tasks help improve performance easy, low-effort manner. believe approach,
belongs emerging family interactive algorithms allows user
make small, guiding tweaks thereby get results much better would otherwise
possible, future information retrieval.
2. Inducing human-interpretable clustering dimensions. dimensions produced spectral clustering dimensionality reduction algorithms (e.g., Latent
Semantic Indexing (LSI), Deerwester, Dumais, Furnas, Landauer, & Harshman, 1990)
generally considered non-interpretable (Sebastiani, 2002), unlike dimension
original feature space, typically corresponds word type therefore interpreted human easily. results preliminary study challenge
common wisdom. show context text clustering dimension
low-dimensional space induced spectral clustering interpreted
human. believe ability produce human-interpretable dimensions enables us
employ spectral clustering (and perhaps dimensionality reduction-based clustering algorithms) text processing intelligent manner. especially
case respect selecting dimensions pertinent task
hand. example, existing applications spectral clustering topic-based
clustering task (e.g., Xu et al., 2003; He, Cai, Liu, & Ma, 2004; Hu, Deng, Guo, & Xu,
2007), dimensions low-dimensional space typically used. Since
showed dimensions produced spectral clustering dataset
necessarily topic-related, potentially improve topic-based clustering results
621

fiDasgupta & Ng

employing non-topic-related dimensions clustering process. addition,
since induced dimensions correspond non-topic dimensions,
use produce non-topic-based clusterings. particular, given recent surge
interest NLP community text classification along non-topic dimensions
sentiment gender (e.g., Garera & Yarowsky, 2009; Jurafsky, Ranganath, &
McFarland, 2009), approach offers solution tasks rely
labeled data, unlike majority existing approaches non-topic-based text classification, supervised nature. Overall, believe NLP researchers
fully exploited power spectral clustering, hence rewards
understanding spectral clustering light results may significant.
3. Producing multiple clusterings. majority existing text clustering
algorithms produce single clustering dataset, approach potentially
used produce multiple clusterings, one along important clustering
dimensions induced via novel application spectral clustering.
Finally, worth mentioning task inducing clustering dimensions reminiscent influential topic modeling task (Blei, Ng, & Jordon, 2003), whose goal
discover major topics set documents unsupervised manner. Note
two tasks fundamentally different: topic model attempts discover major
topics set documents, dimension model aims discover major clustering
dimensions. Nevertheless, two models bear resemblance many ways.
First, employ clustering discover information text collection unsupervised manner. Second, display learned information human using
representative words: topic model represents induced topic using words
representative topic, dimension model represents induced clustering
dimension using words representative two document clusters involved dimension. Finally, induced topics clustering dimensions human-recognizable,
are, human needed assign labels them. believe induction
clustering dimensions potential substantially enhance capability existing
text analysis algorithms discover knowledge text collection unsupervised
manner complementing information induced topic model.

6. Related Work
introduction, discussed related work producing user-desired clustering.
section, focus discussing related work topic-based clustering classification, sentiment classification, active learning, producing multiple clusterings computational
stylistics.
Topic-based text clustering. Traditional research text clustering focused primarily topic-based clustering, owing large part DARPAs Topic Detection
Tracking initiative 1990s. Many different clustering algorithms used, including non-hierarhical algorithms k-means Expectation-Maximization (EM)
hierarchical algorithms single-link, complete-link, group-average, singlepass (Hatzivassiloglou, Gravano, & Maganti, 2000). algorithms cluster given set
622

fiInducing Ideal Clustering Minimal Feedback

documents feature space typically spanned unigrams. However,
clustering high-dimensional space allow distance two documents reliably computed due curse dimensionality. Consequently,
recent work focused development algorithms cluster documents lowdimensional space constructed via dimensionality reduction. Representative members
family dimensionality reduction-based clustering algorithms include traditional algorithms based LSI (Deerwester et al., 1990), well recently proposed
(and arguably better performing) algorithms spectral clustering (Shi & Malik, 2000;
Ng et al., 2001), non-negative matrix factorization (Xu et al., 2003), locality preserving indexing (He et al., 2004), locality discriminating indexing (Hu et al., 2007). Despite
development new clustering algorithms, primarily evaluated
respect ability produce topic-based clusterings.
Topic-based text classification. Yang Liu (1999) put it, text classification
inherently supervised learning task. fact, arguably one popular
tasks supervised learning techniques applied information retrieval
community 1990s (see Sebastiani, 2002, comprehensive overview related work
machine learning text classification). Nevertheless, annotated documents
needed training high-performance supervised text classifier expensive
obtain. result, researchers investigated possibility performing text
classification little even labeled data. attempts led development
general-purpose semi-supervised text classification algorithms combine labeled
unlabeled data using transduction (Joachims, 1999b) EM (Nigam, McCallum, Thrun, &
Mitchell, 2000), latter used combination active learning (McCallum & Nigam, 1998). recently, Sandler (2005) proposed unsupervised text
classification algorithm based mixture modeling LSI-based dimensionality
reduction.
Sentiment classification. mentioned introduction, despite large amount
recent work sentiment analysis opinion mining, much focused supervised
methods (see Pang & Lee, 2008, comprehensive survey field). One weakness existing supervised polarity classification systems typically
domain- language-specific. Hence, given new domain language, one needs
go expensive process collecting large amount annotated data order
train high-performance polarity classifier. recent attempts made
leverage existing sentiment corpora lexicons automatically create annotated resources
new domains languages. However, methods require existence either
parallel corpus/machine translation engine projecting/translating annotations/lexicons
resource-rich language target language (Banea, Mihalcea, Wiebe, & Hassan,
2008; Wan, 2008), domain similar enough target domain (Blitzer et al.,
2007). target domain language fails meet requirement, sentiment-based
clustering unsupervised polarity classification become appealing alternatives. Unfortunately, exceptions (e.g., semi-supervised sentiment analysis, Riloff & Wiebe,
2003; Sindhwani & Melville, 2008; Dasgupta & Ng, 2009a; Li, Zhang, & Sindhwani, 2009),
tasks largely under-investigated NLP community. Turneys (2002) work
perhaps one notable examples unsupervised polarity classification. However,
623

fiDasgupta & Ng

system learns semantic orientation phrases review unsupervised manner, information used predict polarity review heuristically.
Domain adaptation. Domain adaptation, known transfer learning, one
focal research areas machine learning NLP recent years, goal
leverage labeled data available one domain (the source domain) build
classifier another domain (the target domain). Techniques domain adaptation
applied various NLP tasks, including part-of-speech tagging, noun phrase chunking,
syntactic parsing, named entity recognition, word sense disambiguation (e.g., Daume III
& Marcu, 2006; Chan & Ng, 2007; Duame III, 2007; Jiang & Zhai, 2007a, 2007b).
particular relevance work domain adaptation techniques specifically developed
text sentiment classification (e.g., Blitzer, McDonald, & Pereira, 2006; Finn &
Kushmerick, 2006; Blitzer et al., 2007; Gao, Fan, Jiang, & Han, 2008; Ling, Dai, Xue, Yang,
& Yu, 2008; Tan, Cheng, Wang, & Xu, 2009). worth noting domain adaptation
setting different traditional setting. Traditionally, sophisticated classifiers and/or
automatically constructed mapping features two domains used
adaptation process. setting, however, simply utilize sentiment dimension
manually selected source domain automatically identify sentiment
dimension target domain.
Active clustering. Active learning heavily investigated machine learning paradigm
aims achieve better generalization bounds lower annotation costs (Cohn, Atlas,
& Ladner, 1994). traditional active learning setting, human requested
annotate data points classifier uncertain (e.g., Cohn et al., 1994),
recent research active learning involved asking human identify label
features useful classification task hand (e.g., Bekkerman et al., 2007;
Raghavan & Allan, 2007; Druck, Settles, & McCallum, 2009; Roth & Small, 2009).
mentioned introduction, active learning applied clustering setting,
goal encouraging algorithm produce user-intended clustering
data clustered along multiple dimensions. Different variants active clustering
proposed. request human label pair data points must-link
cannot-link indicate whether two points must must reside cluster
(e.g., Wagstaff et al., 2001; Bilenko, Basu, & Mooney, 2004), others human
determine whether two clusters merged split hierarchical clustering
process (e.g., Balcan & Blum, 2008). active clustering algorithm yet another variant:
ask human select clustering desires set automatically produced
clusterings.
Generation multiple clusterings. notion text collections may clustered
multiple independent ways discussed literature computational stylistics
(see Lim, Lee, & Kim, 2005; Biber & Kurjian, 2006; Grieve-Smith, 2006; Tambouratzis &
Vassiliou, 2007; Gries, Wulff, & Davies, 2010, example). machine learning,
attempts design algorithms producing multiple clusterings dataset.
operate semi-supervised setting (e.g., Gondek & Hofmann, 2004;
Davidson & Qi, 2007), totally unsupervised (e.g., Caruana, Elhawary, Nguyen,
& Smith, 2006; Jain, Meka, & Dhillon, 2008). instance, Caruana et al.s (2006) meta
clustering algorithm produces different clusterings dataset running k-means
624

fiInducing Ideal Clustering Minimal Feedback

times, time random selection seeds random weighting features.
goal present local minimum found k-means possible clustering. However,
propose mechanism determining clusterings one
user desires. approach, relies spectral clustering rather k-means
producing multiple clusterings, fills gap soliciting user feedback determine
user-desired clustering.

7. Conclusions Future Work
Unsupervised clustering algorithms typically group objects along prominent dimension, part owing objective simultaneously maximizing inter-cluster similarity intra-cluster dissimilarity. Hence, users intended clustering dimension
prominent dimension, unsupervised clustering algorithms fail
miserably. address problem, proposed active clustering algorithm,
allows us mine user-intended, possibly hidden, dimension data produce
desired clustering. mechanism differs competing methods requires
limited feedback: select intended dimension, user needs inspect
small number features. demonstrated viability via set human automatic
experiments challenging, yet under-investigated task sentiment-based clustering, obtaining promising results. Additional experiments provided suggestive evidence
(1) domain adaptation successfully applied identify sentiment dimension
new domain domains consideration sentimentally similar; (2) hand-crafted
subjectivity lexicon, available, used replace user feedback needed select
sentiment eigenvector domain; (3) algorithm potentially used
produce multiple clusterings datasets possess multiple clustering dimensions.
Equally importantly, empirically demonstrated possible human
interpret dimension produced spectral clustering algorithm, contrary common
wisdom dimensions automatically constructed rank-reduced space noninterpretable. believe NLP researchers fully exploited power spectral
clustering, hence rewards understanding spectral clustering light results
may significant. Finally, proposal represent induced clustering dimension
sets informative features facilitates exploratory text analysis, potentially enhancing
capability existing text analysis algorithms complementing information provided
unsupervised models (e.g., topic model).
future work, plan explore several extensions active clustering algorithm.
First, active clustering algorithm potentially used produce multiple clusterings dataset, one interesting future direction would examine theoretical
guarantees, determining whether able produce distinct clusterings qualitatively strong (see Dasgupta & Ng, 2010a, 2010b, example). Second, plan use
algorithm combination existing feedback-oriented methods (e.g., Bekkerman et al.,
2007; Roth & Small, 2009) improving performance. instance, instead
user construct relevant feature space scratch, simply extend set
informative features identified user-selected dimension. Third, since none
steps algorithm specifically designed sentiment classification, plan apply
non-topic-based text classification tasks recently received lot in625

fiDasgupta & Ng

terest NLP community, gender classification (i.e., task determining
gender author document). Finally, plan adopt richer representation
document exploits features polarity-oriented words obtained hand-built
machine-learned sentiment lexicons (e.g., Hu & Liu, 2004; Wiebe, Wilson, Bruce, Bell,
& Martin, 2004; Andreevskaia & Bergler, 2006; Mohammad, Dunne, & Dorr, 2009; Rao
& Ravichandran, 2009), derived finer-grained (i.e., sentential, sub-sentential,
phrase-based) sentiment analysis methods (e.g., Wilson et al., 2005; Kennedy & Inkpen,
2006; Polanyi & Zaenen, 2006; McDonald, Hannan, Neylon, Wells, & Reynar, 2007; Choi
& Cardie, 2008), richer features may make easier user identify
desired dimension using method.

Bibliographic Note
Portions work previously presented conference publication (Dasgupta &
Ng, 2009b). current article extends work several ways, notably: (1)
detailed introduction spectral clustering (Section 2.2); (2) inclusion two
baseline systems (Section 4.2); (3) investigation effect document representation
clustering performance (Section 4.4); (4) addition three new sections focusing
issues domain adaptation (Section 4.5), employing manually constructed subjectivity
lexicon (Section 4.6), producing multiple clusterings dataset (Section 4.7); well
(5) description significance work (Section 5).

Acknowledgments
authors acknowledge support National Science Foundation (NSF) grant IIS0812261. thank four anonymous reviewers helpful comments
unanimously recommending article publication JAIR. opinions, findings,
conclusions recommendations expressed article authors
necessarily reflect views official policies, either expressed implied, NSF.

References
Abbasi, A., Chen, H., & Salem, A. (2008). Sentiment analysis multiple languages: Feature
selection opinion classification web forums. ACM Transactions Information
Systems, 26 (3).
Andreevskaia, A., & Bergler, S. (2006). Mining WordNet fuzzy sentiment: Sentiment
tag extraction WordNet glosses. Proceedings 11th Conference
European Chapter Association Computational Linguistics (EACL), pp. 209
216.
Balcan, M.-F., & Blum, A. (2008). Clustering interactive feedback. Proceedings
19th International Conference Algorithmic Learning Theory (ALT), pp. 316
328.
Banea, C., Mihalcea, R., Wiebe, J., & Hassan, S. (2008). Multilingual subjectivity analysis using machine translation. Proceedings 2008 Conference Empirical
Methods Natural Language Processing (EMNLP), pp. 127135.
626

fiInducing Ideal Clustering Minimal Feedback

Bekkerman, R., Raghavan, H., Allan, J., & Eguchi, K. (2007). Interactive clustering
text collections according user-specified criterion. Proceedings 20th
International Joint Conference Artificial Intelligence (IJCAI), pp. 684689.
Biber, D., & Kurjian, J. (2006). Towards taxonomy web registers text types:
multidimensional analysis. Language Computers, 59 (1), 109131.
Bilenko, M., Basu, S., & Mooney, R. J. (2004). Integrating constraints machine learning
semi-supervised clustering. Proceedings 21st International Conference
Machine Learning (ICML), pp. 8188.
Blei, D. M., Ng, A. Y., & Jordon, M. I. (2003). Latent Dirichlet Allocation. Journal
Machine Learning Research, 3, 9931022.
Blitzer, J., Dredze, M., & Pereira, F. (2007). Biographies, bollywood, boom-boxes
blenders: Domain adaptation sentiment classification. Proceedings 45th
Annual Meeting Association Computational Linguistics (ACL), pp. 440447.
Blitzer, J., McDonald, R., & Pereira, F. (2006). Domain adaptation structural correspondence learning. Proceedings 2006 Conference Empirical Methods
Natural Language Processing (EMNLP), pp. 120128.
Cai, D., He, X., & Han, J. (2005). Document clustering using locality preserving indexing.
IEEE Transactions Knowledge Data Engineering, 17 (12), 16241637.
Caruana, R., Elhawary, M. F., Nguyen, N., & Smith, C. (2006). Meta clustering.
Proceedings 6th IEEE International Conference Data Mining (ICDM), pp. 107
118.
Chan, P. K., Schlag, D. F., & Zien, J. Y. (1994). Spectral k-way ratio-cut partitioning
clustering. IEEE Transactions Computer-Aided Design, 13, 10881096.
Chan, Y. S., & Ng, H. T. (2007). Domain adaptation active learning word sense
disambiguation. Proceedings 45th Annual Meeting Association
Computational Linguistics (ACL), pp. 4956.
Choi, Y., & Cardie, C. (2008). Learning compositional semantics structural inference subsentential sentiment analysis. Proceedings 2008 Conference
Empirical Methods Natural Language Processing (EMNLP), pp. 793801.
Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization active learning.
Machine Learning, 15 (2), 201221.
Dasgupta, S., & Ng, V. (2009a). Mine easy, classify hard: semi-supervised approach automatic sentiment classification. Proceedings Joint Conference
47th Annual Meeting ACL 4th International Joint Conference
Natural Language Processing AFNLP (ACL-IJCNLP), pp. 701709.
Dasgupta, S., & Ng, V. (2009b). Topic-wise, sentiment-wise, otherwise? Identifying
hidden dimension unsupervised text classification. Proceedings 2009
Conference Empirical Methods Natural Language Processing (EMNLP), pp.
580589.
Dasgupta, S., & Ng, V. (2010a). Mining clustering dimensions. Proceedings 27th
International Conference Machine Learning (ICML), pp. 263270.
627

fiDasgupta & Ng

Dasgupta, S., & Ng, V. (2010b). Towards subjectifying text clustering. Proceedings
33rd Annual International ACM SIGIR Conference Research Development
Information Retrieval (SIGIR), pp. 483490.
Daume III, H., & Marcu, D. (2006). Domain adaptation statistical classifiers. Journal
Artificial Intelligence Research, 26, 101126.
Davidson, I., & Qi, Z. (2007). Finding alternative clusterings using constraints. Proceedings 8th IEEE International Conference Data Mining (ICDM), pp. 773778.
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990).
Indexing latent semantic analysis. Journal American Society Information
Science, 41 (6), 391407.
Dhillon, I., Guan, Y., & Kulis, B. (2004). Kernel k-means, spectral clustering normalized cuts. Proceedings 10th ACM SIGKDD International Conference
Knowledge Discovery Data Mining (KDD), pp. 551556.
Ding, C., He, X., Zha, H., Gu, M., & Simon, H. D. (2001). min-max cut algorithm
graph partitioning data clustering. Proceedings 2001 International
Conference Data Mining (ICDM), pp. 107114.
Druck, G., Settles, B., & McCallum, A. (2009). Active learning labeling features. Proceedings 2009 Conference Empirical Methods Natural Language Processing
(EMNLP), pp. 8190.
Duame III, H. (2007). Frustratingly easy domain adaptation. Proceedings 45th
Annual Meeting Association Computational Linguistics (ACL), pp. 256263.
Finn, A., & Kushmerick, N. (2006). Learning classify documents according genre.
Journal American Society Information Science Technology, 57 (11),
15061518.
Fung, G. (2003). disputed Federalist Papers: SVM feature selection via concave minimization. Proceedings 2003 Conference Diversity Computing, pp.
4246.
Gao, J., Fan, W., Jiang, J., & Han, J. (2008). Knowledge transfer via multiple model local
structure mapping. Proceeding 14th ACM SIGKDD International Conference
Knowledge Discovery Data Mining (KDD), pp. 283291.
Garera, N., & Yarowsky, D. (2009). Modeling latent biographic attributes conversational
genres. Proceedings Joint Conference 47th Annual Meeting
ACL 4th International Joint Conference Natural Language Processing
AFNLP (ACL-IJCNLP), pp. 710718.
Gilad-Bachrach, R., Navot, A., & Tishby, N. (2004). Margin based feature selection theory
algorithms. Proceedings 21st International Conference Machine
Learning (ICML), pp. 4350.
Gondek, D., & Hofmann, T. (2004). Non-redundant data clustering. Proceedings
4th IEEE International Conference Data Mining (ICDM), pp. 7582.
Gries, S., Wulff, S., & Davies, M. (2010). Corpus-linguistic Applications: Current Studies,
New Directions. Rodopi.
628

fiInducing Ideal Clustering Minimal Feedback

Grieve-Smith, A. (2006). envelope variation multidimensional register genre
analyses. Language Computers, 60 (1), 2142.
Hatzivassiloglou, V., Gravano, L., & Maganti, A. (2000). investigation linguistic
features clustering algorithms topical document clustering. Proceedings
23rd Annual International ACM SIGIR Conference Research Development
Information Retrieval (SIGIR), pp. 224231.
He, X., Cai, D., Liu, H., & Ma, W.-Y. (2004). Locality preserving indexing document
representation. Proceedings 27th Annual International ACM SIGIR Conference Research Development Information Retrieval (SIGIR), pp. 96103.
Hu, J., Deng, W., Guo, J., & Xu, W. (2007). Locality discriminating indexing document
classification. Proceedings 30th Annual International ACM SIGIR Conference
Research Development Information Retrieval (SIGIR) (Poster), pp. 689
690.
Hu, M., & Liu, B. (2004). Mining opinion features customer reviews. Proceedings
19th National Conference Artificial Intelligence (AAAI), pp. 755760.
Jain, P., Meka, R., & Dhillon, I. S. (2008). Simultaneous unsupervised learning disparate
clusterings. Proceedings SIAM International Conference Data Mining (SDM),
pp. 858869.
Jiang, J., & Zhai, C. (2007a). Instance weighting domain adaptation NLP. Proceedings 45th Annual Meeting Association Computational Linguistics
(ACL), pp. 254271.
Jiang, J., & Zhai, C. (2007b). two-stage approach domain adaptation statistical
classifiers. Proceedings 16th Conference Information Knowledge
Management (CIKM), pp. 401410.
Joachims, T. (1999a). Making large-scale SVM learning practical. Scholkopf, B., &
Smola, A. (Eds.), Advances Kernel Methods - Support Vector Learning, pp. 4456.
MIT Press.
Joachims, T. (1999b). Transductive inference text classification using support vector
machines. Proceedings 16th International Conference Machine Learning
(ICML), pp. 200209.
Jurafsky, D., Ranganath, R., & McFarland, D. (2009). Extracting social meaning: Identifying interactional style spoken conversation. Proceedings Human Language
Technologies: 2009 Annual Conference North American Chapter
Association Computational Linguistics (NAACL HLT), pp. 638646.
Kamvar, S., Klein, D., & Manning, C. (2003). Spectral learning. Proceedings 19th
International Joint Conference Artificial Intelligence (IJCAI), pp. 561566.
Kannan, R., Vempala, S., & Vetta, A. (2004). clusterings: Good, bad spectral.
Journal ACM, 51 (3), 497515.
Kennedy, A., & Inkpen, D. (2006). Sentiment classifiation movie reviews using contextual
valence shifters. Computational Intelligence, 22 (2), 110125.
629

fiDasgupta & Ng

Koppel, M., Schler, J., & Argamon, S. (2009). Computational methods authorship attribution. Journal American Society Information Science Technology,
60 (1), 926.
Kugler, M., Aoki, K., Kuroyanagi, S., Iwata, A., & Nugroho, A. (2005). Feature subset
selection support vector machines using confident margin. Proceedings
2005 IEEE International Joint Conference Neural Networks (IJCNN), pp. 907912.
Kulis, B., Basu, S., Dhillon, I., & Mooney, R. (2009). Semi-supervised graph-based clustering: kernel approach. Machine Learning, 74 (1), 122.
Li, T., Zhang, Y., & Sindhwani, V. (2009). non-negative matrix tri-factorization approach
sentiment classification lexical prior knowledge. Proceedings Joint
Conference 47th Annual Meeting ACL 4th International Joint
Conference Natural Language Processing AFNLP (ACL-IJCNLP), pp. 244
252.
Lim, C., Lee, K., & Kim, G. (2005). Multiple sets features automatic genre classification web documents. Information Processing Management, 41 (5), 12631276.
Ling, X., Dai, W., Xue, G., Yang, Q., & Yu, Y. (2008). Spectral domain-transfer learning.
Proceeding 14th ACM SIGKDD International Conference Knowledge
Discovery Data Mining (KDD), pp. 488496.
Liu, B., Li, X., Lee, W. S., & Yu, P. S. (2004). Text classification labeling words.
Proceedings 19th National Conference Artificial Intelligence (AAAI), pp.
425430.
McCallum, A. K., & Nigam, K. (1998). Employing EM pool-based active learning
text classification. Proceedings 15th International Conference Machine
Learning (ICML), pp. 350358, Madison, WI. Morgan Kaufmann.
McDonald, R., Hannan, K., Neylon, T., Wells, M., & Reynar, J. (2007). Structured models
fine-to-coarse sentiment analysis. Proceedings 45th Annual Meeting
Association Computational Linguistics (ACL), pp. 432439.
Mei, Q., Ling, X., Wondra, M., Su, H., & Zhai, C. (2007). Sentiment mixture: Modeling
facets opinions weblogs. Proceedings 16th World Wide Web Conference
(WWW), pp. 171180.
Mohammad, S., Dunne, C., & Dorr, B. (2009). Generating high-coverage semantic orientation lexicons overtly marked words thesaurus. Proceedings
2009 Conference Empirical Methods Natural Language Processing (EMNLP),
pp. 599608.
Ng, A., Jordan, M., & Weiss, Y. (2001). spectral clustering: Analysis algorithm.
Advances Neural Information Processing Systems 14 (NIPS).
Nigam, K., McCallum, A., Thrun, S., & Mitchell, T. (2000). Text classification labeled
unlabeled documents using EM. Machine Learning, 39 (2/3), 103134.
Pang, B., & Lee, L. (2008). Opinion mining sentiment analysis. Foundations Trends
Information Retrieval, 2 (12), 1135.
630

fiInducing Ideal Clustering Minimal Feedback

Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment classification using
machine learning techniques. Proceedings 2002 Conference Empirical
Methods Natural Language Processing (EMNLP), pp. 7986. Association Computational Linguistics.
Polanyi, L., & Zaenen, A. (2006). Contextual valence shifters. Computing Attitude
Affect Text: Theory Applications. Springer Verlag.
Raghavan, H., & Allan, J. (2007). interactive algorithm asking incorporating
feature feedback support vector machines. Proceedings 30th Annual
International ACM SIGIR Conference Research Development Information
Retrieval (SIGIR), pp. 7986.
Rao, D., & Ravichandran, D. (2009). Semi-supervised polarity lexicon induction. Proceedings 12th Conference European Chapter Association Computational Linguistics (EACL), pp. 675682.
Riloff, E., & Wiebe, J. (2003). Learning extraction patterns subjective expressions.
Proceedings 2003 Conference Empirical Methods Natural Language
Processing (EMNLP), pp. 105112.
Roth, D., & Small, K. (2009). Interactive feature space construction using semantic information. Proceedings 13th Conference Computational Natural Language
Learning (CoNLL), pp. 6674.
Sandler, M. (2005). use linear programming unsupervised text classification.
Proceedings 11th ACM SIGKDD International Conference Knowledge
Discovery Data Mining (KDD), pp. 256264.
Sebastiani, F. (2002). Machine learning automated text categorization. ACM Computing
Surveys, 34 (1), 147.
Shi, J., & Malik, J. (2000). Normalized cuts image segmentation. IEEE Transactions
Pattern Analysis Machine Intelligence, 22 (8), 888905.
Sindhwani, V., & Melville, P. (2008). Document-word co-regularization semi-supervised
sentiment analysis. Proceedings 8th IEEE International Conference Data
Mining (ICDM), pp. 10251030.
Stein, S., Argamon, S., & Frieder, O. (2006). effect OCR errors stylistic text
classification. Proceedings 29th Annual International ACM SIGIR conference
Research Development Information Retrieval (SIGIR) (Poster), pp. 701
702.
Tambouratzis, G., & Vassiliou, M. (2007). Employing thematic variables enhancing classification accuracy within author discrimination experiments. Literary Linguistic
Computing, 22 (2), 207224.
Tan, S., Cheng, X., Wang, Y., & Xu, H. (2009). Adapting naive Bayes domain adaptation
sentiment analysis. Proceedings 31st European Conference Information
Retrieval (ECIR), pp. 337349.
Turney, P. (2002). Thumbs thumbs down? Semantic orientation applied unsupervised classification reviews. Proceedings 40th Annual Meeting
Association Computational Linguistics (ACL), pp. 417424.
631

fiDasgupta & Ng

Wagstaff, K., Cardie, C., Rogers, S., & Schrodl, S. (2001). Constrained k-means clustering
background knowledge. Proceedings 18th International Conference
Machine Learning (ICML), pp. 577584.
Wan, X. (2008). Using bilingual knowledge ensemble techniques unsupervised Chinese sentiment analysis. Proceedings 2008 Conference Empirical Methods
Natural Language Processing (EMNLP), pp. 553561.
Weiss, Y. (1999). Segmentation using eigenvectors: unifying view. Proceedings
International Conference Computer Vision (ICCV), pp. 975982.
Wiebe, J. M., Wilson, T., Bruce, R., Bell, M., & Martin, M. (2004). Learning subjective
language. Computational Linguistics, 30 (3), 277308.
Wilson, T., Wiebe, J. M., & Hoffmann, P. (2005). Recognizing contextual polarity
phrase-level sentiment analysis. Proceedings Joint Human Language Technology Conference 2005 Conference Empirical Methods Natural Language
Processing (HLT/EMNLP), pp. 347354.
Wu, Z., & Leahy, R. M. (1993). optimal graph theoretic appproach data clustering
application image segmentation. IEEE Transactions Pattern Analysis
Machine Intelligence, 15 (11), 11011113.
Xing, E. P., Ng, A. Y., Jordan, M. I., & Russell, S. J. (2002). Distance metric learning
application clustering side-information. Advances Neural Information
Processing Systems 15 (NIPS), pp. 505512.
Xu, W., Liu, X., & Gong, Y. (2003). Document clustering based non-negative matrix
factorization. Proceedings 26th Annual International ACM SIGIR Conference
Research Development Information Retrieval (SIGIR), pp. 267273.
Yang, Y., & Liu, X. (1999). re-examination text categorization methods. Proceedings 22nd Annual International ACM SIGIR Conference Research
Development Information Retrieval (SIGIR), pp. 4249.
Yang, Y., & Pedersen, J. O. (1997). comparative study feature selection text categorization. Proceedings 14th International Conference Machine Learning
(ICML), pp. 412420.

632


