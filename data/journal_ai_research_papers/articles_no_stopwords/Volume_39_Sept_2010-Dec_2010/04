journal artificial intelligence

submitted published

best first heuristic search multicore machines
ethan burns
sofia lemons
wheeler ruml

eaburns cs unh edu
sofia lemons cs unh edu
ruml cs unh edu

department computer science
university hampshire
durham nh usa

rong zhou

rzhou parc com

embedded reasoning area
palo alto center
palo alto ca usa

abstract
harness modern multicore processors imperative develop parallel versions fundamental compare different approaches parallel best first search
shared memory setting present method pbnf uses abstraction partition state
space detect duplicate states without requiring frequent locking pbnf allows speculative
expansions necessary keep threads busy identify fix potential livelock conditions
proving correctness temporal logic general allowing
extend easily suboptimal anytime heuristic search empirical comparison strips
grid pathfinding sliding tile puzzle core machines
weighted anytime weighted implemented pbnf yield faster search
improved versions previous parallel search proposals

introduction
widely anticipated future microprocessors faster clock rates instead
computing cores per chip tasks exist effective parallel
suffer slowdown relative total system performance artificial intelligence heuristic
search fundamental widely used solving framework compare
different approaches parallelizing best first search popular method underlying
dijkstras hart nilsson raphael
best first search two sets nodes maintained open closed open contains search
frontier nodes generated yet expanded open nodes sorted
f value estimated lowest cost solution path going node open typically
implemented priority queue closed contains previously generated nodes allowing
search detect states reached via multiple paths search space avoid expanding
multiple times closed list typically implemented hash table central challenge
parallelizing best first search avoiding contention threads accessing open
closed lists look variety methods parallelizing best first search focusing
two techniques parallel structured duplicate detection parallel
retracting
c

ai access foundation rights reserved

fib urns l emons ruml z hou

parallel structured duplicate detection psdd originally developed zhou hansen
parallel breadth first search order reduce contention shared data structures
allowing threads enjoy periods synchronization free search psdd requires user supply
abstraction function maps multiple states called nblock single abstract state
present psdd called parallel best n block first pbnf unlike psdd
pbnf extends easily domains non uniform non integer move costs inadmissible
heuristics pbnf infinite search space give rise livelock threads continue
search goal never expanded discuss condition avoided
pbnf method call hot nblocks well use bounded model checking test
effectiveness addition provide proof correctness pbnf framework showing
liveness completeness general case
parallel retracting pra created evett hendler mahanti nau pra
distributes search space among threads hash nodes state pra duplicate
detection performed locally communication peers required transfer generated
search nodes home processor pra sensitive choice hashing function used
distribute search space hashing function state space
abstraction used psdd give pra significantly better performance domains
additionally communication cost incurred naive implementation pra
prohibitively expensive kishimoto fukunaga botea present method helps
alleviate cost communication pra asynchronous message passing primitives
evaluate pra variants pbnf empirically dual quadcore intel machines study behavior three popular search domains strips
grid pathfinding venerable sliding tile puzzle empirical simplest
parallel search easily outperformed serial search even run
eight threads indicate adding abstraction pra give
larger increase performance simply asynchronous communication although
modifications together may outperform one used overall pbnf
often gives best performance
addition finding optimal solutions adapt several
bounded suboptimal search quickly finding w admissible solutions cost within factor w
optimal provide pruning criteria parallel suboptimal search prove retain w admissibility sufficiently difficult
parallel search may significantly outperform serial weighted search found
advantage parallel suboptimal search increases difficulty
finally demonstrate parallel searches pbnf pra lead naturally
effective anytime evaluate obvious parallel anytime search strategies
running multiple weighted searches parallel different weights
parallel anytime searches able better solutions faster serial counterparts
able converge quickly optimal solutions

peanut butter n marshmallow fluff known fluffernutter well known childrens sandwich
usa



fib est f irst earch ulticore achines

previous approaches
much previous work parallel search briefly summarize selected proposals
turning foundation work pra psdd
depth breadth first approaches
early work parallel heuristic search investigated approaches depth first search two
examples distributed tree search ferguson korf parallel window search powley
korf
distributed tree search begins single thread given initial state expand
time node generated unused thread assigned node threads allocated
tree depth first manner free threads assign occurs
thread continue searching children depth first search solution
subtree found passed tree parent thread child thread becomes free
allocated elsewhere tree parent threads go sleep children search
waking children terminate passing solutions upward parents recursively
keep closed list depth first search cannot detect duplicate states give
good search performance domains many duplicate states grid pathfinding
domains
parallel window search parallelizes iterative deepening ida see korf parallel window search thread assigned cost bound perform costbounded depth first search search space ida
spend least half search time final iteration since every iteration still performed
single thread search limited speed single thread addition nonuniform costs foil iterative deepening may good way choose
upper bounds give search geometric growth
holzmann bosnacki able successfully parallelize depth first search
model checking authors able demonstrate technique distributes nodes
search depth able achieve near linear speedup domain model checking
used graphics processing units gpus parallelize breadth first search
use two player games edelkamp sulewski following sections describe
intent parallelizing best first search
simple parallel best first search
simplest parallel best first search open closed lists shared
among threads kumar ramesh rao maintain consistency data structures
mutual exclusion locks mutexes need used ensure single thread accesses data
structure time call search parallel since node expanded taken
open list node generated looked closed list every thread
requires lot synchronization overhead ensure consistency data structures
see section naive performs worse serial
much work designing complex data structures retain correctness
concurrent access idea behind special wait free data structures many threads
use portions data structure concurrently without interfering one another


fib urns l emons ruml z hou

approaches use special compare swap primitive ensure modifying
structure get modified another thread implemented simple parallel search
call lock free parallel threads access single shared concurrent priority
queue concurrent hash table open closed lists respectively implemented
concurrent priority queue data structure sundell tsigas closed list used
concurrent hash table implemented array buckets concurrent
ordered list developed harris lock free data structures used implement lpa
require special lock free memory manager uses reference counting compare swap
stack implement free list valois see even sophistocated
structures straightforward parallel implementation give competitive performance
one way avoiding contention altogether allow one thread handle synchronization
work done threads k best first search felner kraus korf expands
best k nodes handled different thread implementation
master thread takes k best nodes open gives one worker workers expand
nodes master checks children duplicates inserts open list
allows open closed used without locking however order adhere strict
k best first ordering requires master thread wait workers finish
expansions handing nodes domains used node expansion
particularly slow method scale well
one way reduce contention search access closed list less frequently technique called delayed duplicate detection ddd korf originally developed externalmemory search used temporarily delay access closed list several variations proposed basic principle behind ddd generated nodes added
single list certain condition met depth level fully expanded maximum list
size reached stern dill etc condition met list sorted
draw duplicate nodes together nodes list checked closed list
best version kept inserted onto open list initial ddd used
breadth first frontier search therefore previous depth layer required duplicate
detection parallel version later presented niewiadomski amaral holte
split depth layer sections maintained separate input output lists
later merged order perform usual sorting duplicate detection methods
large synchronization step however incur costs similar kbfs depends upon
expensive workload distribution scheme ensure processors work decreasing bottleneck effect nodes distributed unevenly increasing
overhead later parallel best first frontier search ddd presented niewiadomski
amaral holte b incurs even overhead requiring synchronization
threads maintain strict best first ordering
jabbar edelkamp present called parallel external pea uses
distributed computing nodes external memory perform best first search pea splits
search space set buckets contain nodes g h values
performs best first search exploring buckets lowest f value beginning
one lowest g master node manages requests distribute portions current
bucket processing nodes expanding single bucket performed parallel
avoid contention pea relies operating system synchronize access files
shared among nodes jabbar edelkamp used pea parallelize


fib est f irst earch ulticore achines

model checker achieved almost linear speedup partitioning g h works
domains general nodes g h values tends case
domains real valued edge costs turn attention two reappear
throughout rest pra psdd
parallel retracting
pra evett et al attempts avoid contention assigning separate open closed lists
thread hash state representation used assign nodes appropriate thread
generated full pra includes retraction scheme reduces memory use
exchange increased computation time consider feature
choice hash function influences performance since determines way
work distributed note standard pra thread may communicate
peers thread needs synchronized message queue peers add nodes
multicore setting implemented requiring thread take lock message queue
typically requires thread sending receiving message wait operation
complete continue searching less bottleneck single
global shared open list see still expensive interesting
note pra variants mentioned practice type delayed duplicate detection
store duplicates temporarily checking thread local closed list
possibly inserting open list
mprovements
kishimoto et al note original pra implementation improved removing synchronization requirement message queues nodes instead use
asynchronous send receive functionality mpi message passing library snir otto
implement asynchronous version pra call hash distributed hda
hda distributes nodes hash function way pra except sending
receiving nodes happens asynchronously means threads free continue searching
nodes communicated peers transit
contact authors hda created implementation hda multicore
machines extra overhead message passing asynchronous communication threads shared memory setting implementation hda allows us
make fair comparison sharing common data structures priority
queues hash tables
implementation hda thread given single queue incoming nodes one
outgoing queue peer thread queues implemented dynamically sized arrays
pointers search nodes generating nodes thread performs non blocking call
acquire lock appropriate peers incoming queue acquiring lock available
immediately returning failure busy rather waiting lock acquired simple
pointer copy transfers search node neighboring thread non blocking call fails
nodes placed outgoing queue peer operation require lock
outgoing queue local current thread certain number expansions thread
attempts flush outgoing queues never forced wait lock send nodes
one non blocking call pthread mutex trylock function posix standard



fib urns l emons ruml z hou

figure simple abstraction self loops eliminated
attempts consume incoming queue waits lock open list empty
case work simple efficient implementation
confirmed kishimoto et al asynchronous version
pra called hda outperforms standard synchronous version full presented
section
pra hda use simple representation node hashing scheme one
example used look nodes closed lists present two variants apra
ahda make use state space abstraction distribute search nodes among processors
instead assigning nodes thread thread assigned set blocks search space
block corresponds state abstract space intuition behind
children single node assigned small subset remote threads
fact often assigned back expanding thread reduces number
edges communication graph among threads search reducing chances thread
contention abstract states distributed evenly among threads modulus operator
hope open nodes available thread
parallel structured duplicate detection
psdd major previously proposed alternative pra intention psdd avoid
need lock every node generation avoid explicitly passing individual nodes
threads builds idea structured duplicate detection sdd originally developed external memory search zhou hansen sdd uses abstraction function
many one mapping states original search space states abstract space
abstract node state mapped called image nblock set nodes
state space image abstract space abstraction function creates abstract graph nodes images nodes state space two states successors
state space images successors abstract graph figure shows state space
graph left consisting nodes abstract graph right consists nine nodes
node abstract graph represents grouping four nodes called nblock original state
space shown dotted lines state space graph left


fib est f irst earch ulticore achines

figure two disjoint duplicate detection scopes

nblock open closed list avoid contention thread acquire exclusive
access nblock additionally thread acquires exclusive access nblocks correspond successors abstract graph nblock searching nblock
call set nblocks successors abstract graph duplicate detection scope
abstract nodes access required order perform
perfect duplicate detection expanding nodes given nblock thread expands
node n nblock b children n must fall within b one nblocks successors
b abstract graph threads determine whether states generated expanding
n duplicates simply checking closed lists nblocks duplicate detection scope
require synchronization thread exclusive access set nblocks
psdd abstract graph used nblocks whose duplicate detection scopes disjoint nblocks searched parallel without locking node expansions
figure shows two disjoint duplicate detection scopes delineated dashed lines different
patterns nblock use thread whose duplicate detection scope
use considered free free nblock available thread acquire searching free nblocks found explicitly tracking nblock b b number nblocks
among bs successors use another thread nblock b acquired
b
advantage psdd requires single lock one controlling manipulation
abstract graph lock needs acquired threads finding free
nblock search means threads need synchronize expanding nodes
common operation
zhou hansen used psdd parallelize breadth first heuristic search zhou hansen
nblock two lists open nodes one list contains open nodes
current search depth contains nodes next search depth thread
nodes current search depth acquired nblock expanded children
generated put open list next depth nblock map
duplicate detection scope nblock searched long duplicates
current nblock nodes current depth swapped free nblock


fib urns l emons ruml z hou

open nodes depth nblocks open nodes current depth
threads synchronize progress together next depth admissible heuristic used
prune nodes fall current solution upper bound
mprovements
psdd viewed general framework parallel search terminology psdd
refers instance sdd parallel setting uses layer synchronization breadthfirst search subsection present two use psdd framework attempt
improve psdd specific ways
implemented zhou hansen psdd uses heuristic estimate
node pruning effective tight upper bound already available
cope situations good bound available implemented novel
psdd framework uses iterative deepening idpsdd increase bound
report effective domains grid pathfinding
geometrically increasing number nodes within successive f bounds
another drawback psdd breadth first search cannot guarantee optimality domains
operators differing costs anticipation zhou hansen
suggest two possible extensions work best first search speculative best first layering
allows larger layers cases nodes nblocks
f value knowledge first implement test
best first psdd bfpsdd uses f value layers instead depth layers means
nodes expanded given layer lowest f value bfpsdd provides bestfirst search order may incur excessive synchronization overhead nodes
f layer ameliorate loosen best first ordering enforcing least nodes
expanded abandoning non empty nblock zhou hansen credit edelkamp
schrodl idea populating list free nblocks layer
nblocks nodes current layers f value used minimum k nblocks
added k four times number threads value k gave better performance
values tested allows us add additional nblocks small layers order amortize
cost synchronization addition tried alternative implementation bfpsdd used
range f values layer parameter f used proscribe width f values
layer search implementation perform well present
enhancements threads may expand nodes f values greater
current layer first solution found may optimal search continues
remaining nodes pruned incumbent solution
surveyed existing approaches parallel best first search present
comprises main algorithmic contribution

parallel best n block first pbnf
ideal scenario threads would busy expanding nblocks contain nodes lowest
f values approximate combine psdds duplicate detection scopes idea
localized edelkamp schrodl localized designed
improve locality external memory search maintains sets nodes reside
memory page decision set process next made help heap sets


fib est f irst earch ulticore achines

nblock open nodes
lock b best free nblock unlock
b worse best free nblock weve done fewer min expansions

best open node b

f f incumbent prune open nodes b

else goal

f f incumbent

lock incumbent unlock

else child c

c closed list nblock

insert c open list appropriate nblock
figure sketch basic pbnf search showing locking
ordered minimum f value set maintaining heap free nblocks ordered
nblocks best f value approximate ideal parallel search call parallel
best n block first pbnf search
pbnf threads use heap free nblocks acquire free nblock best open
node thread search acquired nblock long contains nodes better
nblock front heap acquired nblock becomes worse best free
one thread attempt release current nblock acquire better one contains
open nodes lower f values layer synchronization threads need wait
unless nblocks free first solution found may suboptimal search must continue
open nodes f values worse incumbent solution figure shows high level
pseudo code
pbnf designed tolerate search order approximately best first
freedom introduce optimizations reduce overhead possible nblock
small number nodes better best free nblock avoid excessive switching
requiring minimum number expansions due minimum expansion requirement
possible nodes expanded thread arbitrarily worse frontier node
minimum f refer expansions speculative viewed trading node
quality reduced contention abstract graph section shows experiment
evaluates trade
implementation attempts reduce time thread forced wait lock
non blocking operations acquire lock whenever possible rather sleeping lock
cannot acquired non blocking lock operation pthread mutex trylock
immediately return failure allows thread continue expanding current nblock lock
busy optimizations introduce additional speculative expansions would
performed serial best first search
livelock
greedy free order pbnf threads acquire free nblocks lead livelock
domains infinite state spaces threads acquire nblocks without waiting
open nodes layer expanded possible nblock containing goal


fib urns l emons ruml z hou

never become free assurance nblocks duplicate detection
scope ever unused time example imagine situation threads
constantly releasing acquiring nblocks prevent goal nblock becoming free
fix developed method called hot nblocks threads altruistically release
nblock interfering better nblock call enhanced safe pbnf
use term interference scope b refer set nblocks acquired
would prevent b free interference scope includes bs successors
abstract graph predecessors safe pbnf whenever thread checks heap
free nblocks determine release current nblock ensures acquired
nblock better interferes nblocks whose interference scope
acquired nblock finds better one flags nblock hot thread finds
blocking hot nblock release nblock attempt free hot nblock
nblock b define h b number hot nblocks b interference scope
h b b removed heap free nblocks ensures thread acquire
nblock preventing hot nblock becoming free
consider example abstract graph containing four nblocks connected linear fashion
b c possible execution pbnf alternate thread expanding
nblocks c situation arrises nblocks b never considered free
goals located nblock b infinite search space may livelock
safe variant pbnf however expanding c thread make sure
check f value best open node nblock b periodically best node b seen
better nodes c b flagged hot nblocks c
longer eligable expansion nblock b acquired
formally let n set nblocks predecessors x successors x sets
predecessors successors abstract graph nblock x h set hot nblocks
intscope b l n x successors b l predecessors x interference scope
nblock b x partial order nblocks x iff minimum f
value open nodes x lower three cases consider
attempting set nblock b hot undirected abstract graph
h intscope b h x n b intscope x none nblocks b
interferes interfere b hot b set hot
x h x intscope b x b b interfered better nblock already
hot b must set hot
x h x intscope b b x b interfered nblock x worse
b x already hot x must un flagged hot updating h values appropriately
place b set hot
directed abstract graphs two additional cases
x h b intscope x b x b interfering nblock x b better x
un flag x hot set b hot
x h b intscope x x b b interfering nblock x x better b
set b hot


fib est f irst earch ulticore achines

scheme ensures never two hot nblocks interfering one another
nblock set hot best nblock interference scope verify
guarantees property nblock flagged hot eventually become free
full pseudo code safe pbnf given appendix
correctness pbnf
given complexity parallel shared memory reassuring proofs
correctness subsection verify pbnf exhibits desirable properties
oundness
soundness holds trivially solution returned pass goal test
eadlock
one lock pbnf thread currently holds never attempts acquire
second time deadlock cannot arise
l ivelock
interaction different threads pbnf quite complex modeled
system tla lamport specification language tlc model checker
yu manolios lamport able demonstrate sequence states give rise
livelock plain pbnf similar model unable example livelock
safe pbnf three threads nblocks undirected ring shaped abstract
graph three threads eight nblocks directed graph
model state system represented four variables state acquired ishot
succs state variable contains current action thread performing search
nextblock acquired variable function thread id acquired nblock
value none currently nblock variable ishot function
nblocks true false depending whether given nblock flagged hot
finally succs variable gives set successor nblocks nblock order build
nblock graph
model two actions dosearch donextblock dosearch action search
stage performed pbnf thread since interested determining livelock
action abstracts away search procedure merely thread may
choose valid nblock flag hot setting nblock hot thread changes state
next time selected perform action try acquire nblock
donextblock simulates thread choosing next nblock one available thread
acquires nblock one free sets state next time selected perform
action search
tla source model located appendix b
formal proof addition model checking tla specification language designed
allow formal proofs properties allows properties proved unbounded space
model completed formal proof hot nblock eventually become free


fib urns l emons ruml z hou

regardless number threads abstract graph present english summary
first need helpful lemma
lemma nblock n hot least one nblock interference scope
use n interfering hot nblocks
proof initially nblocks hot change thread searches releases
nblock search thread set n hot acquired nblock
interference scope n additionally thread may set n hot create
interference another hot nblock release n hot final acquired nblock
interference scope released n longer hot n still least one busy nblock
interference scope

ready key theorem
theorem nblock n becomes hot eventually added free list
longer hot
proof number acquired nblocks interference scope hot nblock
n strictly decreasing therefore n eventually become free
assume nblock n hot lemma thread p nblock interference scope n n interfering interfered hot nblocks assume
thread q nblock interference scope n four cases
p searches nblock p acquire nblock therefore number nblocks
preventing n becoming free increase p sets nblock hot
interference scope n lemma p release nblock sees n hot
see case
p releases nblock acquires nblock free list number acquired
nblocks interference scope n decreases one p releases nblock since
nblock acquired p free list interference scope n
q searches nblock q acquire nblock therefore number nblocks
preventing n becoming free increase q sets nblock hot
interference scope n lemma
q releases nblock one acquires nblock free list since
nblock acquired q free list interference scope n
number nblocks preventing n becoming free increase

prove progress property really care
theorem node n minimum f value eventually expanded
proof consider ns nblock three cases
nblock expanded n minimum f front open
expanded


fib est f irst earch ulticore achines

nblock free holds node minimum f value front
free list selected next expansion reducing case
nblock free list interference scope another nblock
currently expanded thread expanding nblock checks interference
scope mark better nblock hot theorem eventually reach case

c ompleteness
follows easily liveness
corollary heuristic admissible search space finite goal returned one
reachable
proof heuristic admissible inherit completeness serial nilsson
theorem nodes expanded g value improved happen
finite number times finite number expansions suffice exhaust search space
ptimality
pbnfs expansion order strictly best first operates anytime
optimality follows argument anytime hansen
zhou
theorem pbnf return optimal solutions
proof finding incumbent solution search continues expand nodes minimum
f value among frontier nodes greater equal incumbent solution cost means
search terminate optimal solution

discussing adapt pbnf suboptimal anytime search first evaluate
performance optimal solving

empirical evaluation optimal search
implemented tested parallel heuristic search described three
different benchmark domains grid pathfinding sliding tile puzzle strips
discuss domain turn exception domain
programmed c posix threading library run dual quad core intel xeon e
ghz processors gb ram written independently c pseudo code appendix gives us additional confidence
correctness pseudo code performance claims experiments run
dual quad core intel xeon x ghz processors limited roughly gb ram open
lists free lists implemented binary heaps except psdd idpsdd used
queue giving less overhead since require access minimum valued elements
closed lists implemented hash tables pra apra used queues incoming nodes
hash table used detect duplicates open closed grids sliding tiles


fib urns l emons ruml z hou

used jemalloc library evans special multi thread aware malloc implementation
instead standard glibc version malloc found latter scales poorly
threads configured jemalloc use memory arenas per cpu custom
memory manager used thread aware uses memory pool thread
grids sliding tiles abstractions hand coded nblock data structures created
lazily visited part abstract graph instantiated time taken create
abstraction accounted wall time measurements two domains strips
abstractions created automatically creation times abstractions
reported separately described section
tuning pbnf
section present set experiments designed test behavior
pbnf parameters changed study effects two important parameters
pbnf minimum expansions required switching search nblock
size abstraction study used twenty x four connected grid pathfinding
instances unit cost moves cell probability obstacle
heuristic used manhattan distance goal location error bars plots
confidence intervals legends sorted mean dependent variable plot
pbnf thread must perform minimum number expansions
able acquire nblock searching requiring expansions switches
expected reduce contention nblock graphs lock could increase total number
expanded nodes created instrumented version pbnf tracks
time threads spent trying acquire lock amount time threads
spent waiting free nblock fixed size abstraction nblocks
varied number threads minimum expansions minimum
expansions
upper left panel figure shows average amount cpu time seconds
thread spent waiting acquire lock axis minimum expansions parameter increased x axis line plot represents different number threads see
configuration used amount time trying acquire lock eight threads
one minimum expansion number threads decreased less contention
lock fewer threads take number minimum required expansions
increased contention reduced around eight minimum expansions benefit increasing value seemed greatly diminish
upper right panel figure shows cpu time spent waiting free
nblock axis minimum expansions increased x axis different amount
time waiting lock case thread successfully acquired lock
found free nblocks available search see configuration
eight threads one minimum expansions caused longest amount time waiting
free nblock number threads decreased required number minimum
expansions increased wait time decreased amount time spent waiting however seems
fairly insignificant order magnitude smaller lock time see
around eight minimum expansions benefit increasing seemed diminish













average time waiting seconds

average time acquiring locks seconds

b est f irst earch ulticore achines



























total nodes expanded k nodes

minimum expansions





minimum expansions






















minimum expansions

figure pbnf locking behavior vs minimum expansions grid pathfinding
nblocks line represents different number threads

final panel bottom figure shows total number nodes expanded axis
thousands nodes minimum expansions increased increasing minimum
number expansions thread must make switching nblock better nodes
caused search explore space may covered strict
best first search speculative expansions performed total number
nodes encountered search increased see adding threads increased
number expanded nodes
experiment appears requiring eight expansions switching nblocks decreasing benefit respect locking waiting time
non instrumented implementation pbnf found slightly greater values minimum
expansion parameter lead best total wall times domain use value
gave best total wall time non instrumented pbnf implementation


fib urns l emons ruml z hou























average time waiting seconds

average time acquiring locks seconds


























total nodes expanded k nodes

abstraction size k nblocks









abstraction size k nblocks


























abstraction size k nblocks

figure pbnf abstraction size x grid pathfinding minimum expansions

since pbnf uses abstraction decompose search space important understand
effect abstraction size search performance hypothesis abstract
states would lead small number free nblocks therefore making threads spend lot
time waiting nblock become free hand many abstract states
nodes nblock happens threads perform small
amount work exhausting open nodes nblock forced switch
portion search space time thread must switch nblocks contention
lock increased figure shows experiment performed verify
theory plot fixed minimum expansions parameter gave best
total wall time grid pathfinding varied number threads size
abstraction nblocks
upper left panel figure shows plot amount cpu seconds spent trying acquire lock axis versus size abstraction x axis expected abstraction
coarse little time spent waiting lock size abstraction grew


fib est f irst earch ulticore achines

number threads increased amount time spent locking increased eight threads
nblocks second cpu time spent waiting acquire lock suspect
threads exhausting open nodes nblocks therefore
forced take lock acquire portion search space
upper right panel figure shows amount time threads spent waiting
nblock become free successfully acquired lock nblocks
available suspected amount time threads wait free nblock decreases
abstraction size increased available nblocks disjoint portions
search space available experiments minimum expansions amount
time spent waiting seems relatively insignificant compared time spent acquiring locks
bottom panel figure shows number nodes expanded increased
size abstraction increased finer grained abstractions expanded
nodes time thread switches nblock forced perform
least minimum number expansions therefore switches forced expansions
tuning pra
turn looking performance impact pra abstraction asynchronous communication first compare pra without asynchronous communication
set experiments twenty x grid pathfinding set random puzzle instances solvable million expansions shown figure line labeled
sync pra used synchronous communication async sends used synchronous receives asynchronous sends async receives used synchronous sends asynchronous receives async
hda used asynchronous communication sends receives legend
sorted mean performance error bars represent confidence intervals
mean vertical lines plots life cost grid pathfinding domains
configurations unable solve instances within second time limit
combination asynchronous sends receives provided best performance
see plots making sends asynchronous provided benefit
making receives asynchronous without asynchronous sends node generated stop generating thread order communicate even communication batched
send may required go separate neighbor therefore single send operation may
required per generation receives worst case receiving thread must stop
expansion receive next batch nodes since branching factor typical search space
approximately constant approximately constant factor send communications
receive communications worst case therefore making sends asynchronous reduces
communication cost receives
figure shows experiment compares pra abstraction distribute
nodes among threads versus pra asynchronous communication lines labeled
follows sync pra used synchronous communication async hda used asynchronous communication sync abst apra used synchronous communication
used abstraction distribute nodes among threads async abst ahda used combination asynchronous communication abstraction vertical lines plots
life cost grid pathfinding domains configurations unable solve instances
within second time limit


fib urns l emons ruml z hou

grid unit four way
sync pra
async receives
async sends
async hda

sync pra
async receives
async sends
async hda



wall time seconds



wall time seconds

grid unit eight way





















threads
grid life four way






threads
grid life eight way


sync pra
async receives
async sends
async hda

sync pra
async receives
async sends
async hda

wall time seconds

wall time seconds



















threads







threads

sync pra
async receives
async sends
async hda



wall time seconds



puzzles easy















threads

figure pra synchronization x grids easy sliding tile instances

clear plots configurations pra used abstraction gave better
performance pra without abstraction grid pathfinding domain reason


fib est f irst earch ulticore achines

grid unit four way
sync pra
async hda
sync abst apra
async abst ahda

sync pra
async hda
sync abst apra
async abst ahda



wall time seconds



wall time seconds

grid unit eight way





















threads
grid life four way






threads
grid life eight way


sync pra
async hda
sync abst apra
async abst ahda

sync pra
async hda
sync abst apra
async abst ahda

wall time seconds

wall time seconds




















threads







threads

sync pra
async hda
sync abst apra
async abst ahda



wall time seconds



puzzles easy















threads

figure pra abstraction x grids easy sliding tile instances

abstraction grid pathfinding often assign successors node expanded
back thread generated happens communication required


fib urns l emons ruml z hou

nodes simply checked local closed list placed local open list
duplicates abstraction time communication required
node edge abstract state expanded case children map
different abstract state communication required experiment shows
benefits abstraction greater benefits asynchronous communication grid
pathfinding see trends sliding tile instances however
quite pronounced confidence intervals often overlap
overall appears combination pra abstraction distributing nodes
among different threads asynchronous communication gave best performance
following section comparison variant pra safe
pbnf best first variant psdd
grid pathfinding
section evaluate parallel grid pathfinding domain goal
domain navigate grid initial location goal location avoiding
obstacles used two cost discussed four way eight way movement
four way grids cells blocked probability eight way grids
cells blocked probability abstraction function used maps blocks
adjacent cells abstract state forming coarser abstract grid overlaid original
space heuristic manhattan distance goal location hash values states
used distribute nodes pra hda computed x ymax state
location gives minimum perfect hash value state domain able
tune size abstraction execution best abstraction size
relevant
f way u nit c ost
unit cost model move cost one
less promising figure shows performance comparison
average slower serial tested unit cost four way
movement x grids start location bottom left corner goal location
bottom right x axis shows number threads used solve instance axis
shows mean wall clock time seconds error bars give confidence interval
mean wall clock time legend sorted mean performance
figure see psdd gave worst average solution times suspect
lack tight upper bound psdd uses pruning see
shared lock free open closed list lpa took average second longest amount time
solve lpa performance improved threads started drop
threads added overhead special lock free memory manager along
fact access lock free data structures may require back offs retries could account
poor performance compared serial next going top
legend kbfs slowly increased performance threads added however
able beat serial simple parallel implementation pa locks
open closed lists performed worse threads added four started
give slow performance increase matching kbfs pra simple


fib est f irst earch ulticore achines



psdd
lpa
kbfs
pa
pra
serial

wall time seconds

















threads

figure simple parallel unit cost four way x grid pathfinding

state representation hashing function gave best performance graph fairly
erratic number threads changed sometimes increasing sometimes decreasing
threads pra faster serial
implemented idpsdd tries upper bound
psdd search iterative deepening shown grid pathfinding domains non geometric growth number states increasing cost bound leads
poor performance iterative deepening grid pathfinding due poor performance
remaining grid tiles domains
exception psdd makes reappearance strips evaluation
section supply upper bound
promising upper left plot figure shows performance
unit cost four way grid pathfinding axis represents speedup serial
x axis shows number threads use data point error bars indicate
confidence intervals mean different instances legend ordered
average performance line labeled perfect speedup shows perfect linear speedup
additional thread increases performance linearly
practical reference point speedup shown achievable speedup line
perfect machine n processors running n cores take time decreases linearly
n real machine however hardware considerations memory bus contention prevent n fold speedup estimate overhead machines ran sets
n independent searches parallel n calculated total time set
finish perfect machine sets would take time set n
compute achievable speedup ratio actual completion times time


fib urns l emons ruml z hou

grid unit four way

grid unit eight way


perfect speedup
achievable speedup
safe pbnf
ahda
bfpsdd



speedup serial

speedup serial





perfect speedup
achievable speedup
safe pbnf
ahda
bfpsdd



















threads
grid life four way









threads
grid life eight way


perfect speedup
achievable speedup
safe pbnf
ahda
bfpsdd



speedup serial

speedup serial









perfect speedup
achievable speedup
ahda
safe pbnf
bfpsdd















threads

speedup serial







threads

puzzles easy
perfect speedup
achievable speedup
safe pbnf
ahda















threads

figure speedup grid pathfinding sliding tile puzzle

set n threads given completion times sets hc c cn

achievable speedup tc
ct


fib est f irst earch ulticore achines

upper left panel shows comparison ahda pra asynchronous communication abstraction bfpsdd safe pbnf larger x unit cost
four way safe pbnf superior steadily decreasing solution times threads added average speedup serial x
eight threads ahda less stable performance sometimes giving sharp speedup
increase sometimes giving decreased performance threads added seven
threads ahda gave best performance able reach x speedup serial
search bfpsdd solved faster threads added however
competitive pbnf ahda giving x speedup serial eight
threads
f way l ife c ost
moves life cost model cost row number state move
performedmoves top grid free moves bottom cost ruml
differentiates shortest cheapest paths shown
important distinction richter westphal cushing bentor kambhampati
left center plot figure shows format unit cost variant
number threads x axis speedup serial axis average safe pbnf
gave better speedup ahda however ahda outperformed pbnf six seven threads
eight threads however apra perform better seven threads achieve speedups close achievable speedup domain
bfpsdd gave worst performance increase threads added reaching x
speedup
e ight way u nit c ost
eight way movement path
horizontal vertical moves cost
diagonal movements cost real valued costs make domain different previous
two path domains upper right panel figure shows number threads x
axis speedup serial axis unit cost eight way movement domain see
safe pbnf gave best average performance reaching x speedup eight threads
ahda outperform safe pbnf average however able achieve x
speedup serial seven threads however see ahda give
stable performance increases threads bfpsdd improved threads added
eight never reached x speedup
e ight way l ife c ost
model combines eight way movement life cost tends difficult path domain presented right center panel figure shows threads
x axis speedup serial axis ahda gave best average speedup
serial search peaking x speedup seven threads although outperformed safe
pbnf average eight threads ahda sharp decrease performance reaching
almost x speedup safe pbnf around x speedup serial bfpsdd peaks
x speedup eight threads


fib urns l emons ruml z hou

ahda minus safe pbnf wall time seconds

puzzles easy ahda vs safe pbnf paired difference
ahda safe pbnf
zero














threads

figure comparison wall clock time safe pbnf versus ahda sliding tile puzzle

sliding tile puzzle
sliding tile puzzle common domain benchmarking heuristic search
use randomly generated puzzles serial able solve within million
expansions
abstraction used sliding tile puzzles ignores numbers set tiles
example shown safe pbnf bottom panel figure use abstraction
looks position blank one two tiles abstraction gives nblocks order
ahda get maximum amount expansions map back expanding thread
described grids abstraction uses one two three tile since position
blank ignored state generation move one two three tiles generate
child nblock parent therefore requiring communication heuristic
used manhattan distance heuristic hash value used tiles states
perfect hash value techniques presented korf schultze
bottom panel figure shows ahda safe pbnf sliding
tiles puzzle instances plot number threads x axis speedup serial
axis safe pbnf best mean performance overlap confidence
intervals ahda bfpsdd unable speedup serial performance
shown plot
sliding tile puzzles vary much difficulty domain paireddifference test shown figure data used figure collected set
runs shown bottom panel figure axis figure however average
instances time ahda took instance minus time safe pbnf
took paired test gives powerful view relative performance values
greater represent instances safe pbnf faster ahda values lower


fib est f irst earch ulticore achines

represent instances ahda faster error bars confidence
interval mean clearly see safe pbnf significantly faster
ahda across numbers threads
strips
addition path sliding tiles domains embedded
domain independent optimal sequential strips planner contrast previous two domains
node expansion quick therefore difficult achieve good parallel speedup
node expansion strips relatively slow planner used experiments uses
regression max pair admissible heuristic haslum geffner abstraction
function used domain generated dynamically per basis following zhou
hansen time taken account solution times presented
abstraction function generated greedily searching space possible
abstraction functions zhou hansen needs evaluate one candidate abstraction unselected state variables trivially parallelized
multiple threads work different candidate abstractions
table presents ahda pbnf safe pbnf psdd given optimal upper
bound pruning divide conquer solution reconstruction apra bfpsdd
values cell total wall time seconds taken solve instance value
indicates program ran memory best
within best marked bold generally parallel able
solve instances faster allowed threads parallel
able solve instances much faster serial seven threads pbnf
pbnf safe pbnf gave best solution times three domains interestingly
plain pbnf often little faster safe version failed solve two
likely due livelock although could simply hot nblocks fix forces
safe pnbf follow different search order pbnf ahda tended give second best
solution times followed psdd given optimal solution cost front pruning
bfpsdd often better apra
column labeled abst shows time taken parallel serially
generate abstraction function even abstraction generation time added solution
times parallel outperform seven threads except block domain
time taken generate abstraction actually longer time took solve

understanding search performance
seen pbnf tends better performance ahda
optimal search section set experiments attempts
determine factors allow pbnf perform better domains considered three
hypotheses first pbnf may achieve better performance expands fewer nodes f
values greater optimal solution cost second pbnf may achieve better search performance
tends many fewer nodes priority queue ahda finally pbnf
may achieve better search performance spends less time coordinating threads
following subsections experiments performed test


fib urns l emons ruml z hou

threads
logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog
gripper

threads
logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog
gripper

threads
logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog
gripper



































ahda















safepbnf
































apra







































pbnf














psdd





















bfpsdd















table wall time strips
























abst























fib est f irst earch ulticore achines

ahda
safe pbnf

ahda
safe pbnf

e

e

cumulative expansions

cumulative expansions

e

e

e

e

e

e












factor optimal cost







factor optimal cost

figure cumulative normalized f value counts nodes expanded eight threads unitcost four way grid pathfinding left puzzle right

three hypotheses experiments agree first two hypotheses however
appears third hypothesis hold fact pbnf occasionally spends time
coordinating threads ahda
n ode q uality
pbnf ahda merely approximate best first order may expand
nodes f values greater optimal solution cost thread expands node
f value greater optimal solution cost effort waste nodes
must expanded searching optimal solution f values less
optimal cost addition search may expand nodes lower
cost path found happens work wasted first sub optimal expansion
node
threads pbnf able choose nblock expand quality nodes
free nblocks ahda however thread must expand nodes assigned
hypothesized pbnf may expand fewer nodes f values greater
optimal solution cost threads control quality nodes
choose expand
collected f value node expanded pbnf ahda figure shows
cumulative counts f values nodes expanded pbnf ahda set
unit cost four way x grid pathfinding instances used section right
puzzle instances used section left plots x axis shows f value
expanded nodes factor optimal solution cost given instance axis shows
cumulative count nodes expanded given normalized f set instances


fimean cpu time seconds

b urns l emons ruml z hou

e

e

e



safepbnf
ahda
grid pathfinding

safepbnf
ahda
puzzle

figure mean cpu time per open list operation
looking location right tip line total number nodes
expanded summed instances
left panel figure see tended expand
small number nodes f values greater optimal solution cost grid
pathfinding domain ahda expanded nodes total set instances
pbnf ahda must expand nodes optimal solution cost
way ahda greater number expansions nodes factor
expanded nodes appears ahda expanded nodes pbnf
seems account fact ahda expanded nodes total
right half figure shows puzzle see ahda
expanded nodes total pbnf domain expanded approximately
number nodes f values less optimal solution cost see
plot ahda expanded many nodes f values greater equal
optimal solution cost summary pbnf expanded fewer nodes better quality nodes
ahda grid pathfinding sliding tiles domains speculate may happen
pbnf threads allowed choose portion space search
choose low f value ahda threads must search nodes map
nodes may good
pen l ist izes
found since pbnf breaks search space many different nblocks tends
data structures many fewer entries ahda breaks search space
number threads since interested general purpose handle
domains real valued costs eight way grid pathfinding pbnf ahda use binary
heaps implement open lists pbnf one heap per nblock one per abstract state
whereas ahda one heap per thread number nblocks greater


fib est f irst earch ulticore achines

number threads ahda many nodes pbnf heaps causes
heap operations ahda take longer heap operations pbnf
cost operations large heaps shown greatly impact overall performance
dai hansen order determine extent large heaps effect
performance ahda added timers heap operations figure
shows mean cpu time single open list operation unit cost four way grid pathfinding
domain puzzle boxes second third quartiles line drawn
across median whiskers extremes data except data points residing
beyond first third quartile times inter quartile range signified
circle shaded rectangle shows confidence interval mean see
cases ahda tended spend time performing heap operations pbnf
typically spent nearly time per heap operation heap operations must performed
node expanded may required node generation even though times
tens microseconds frequency operations high single search
finally described hansen zhou reduction open list sizes explain good single thread performance pbnf experiences strips see table
hansen zhou point although optimally efficient terms node expansions
necessarily optimal respect wall time found benefit managing smaller
open lists enabled anytime weighted outperform wall time even though
expanded nodes converging optimal solution describe section
good single thread performance may caused speculative expansions pruning
c ooordination overhead
third hypothesis amount time spent coordination overhead might differ parallel must spend time accessing data structures
shared among multiple threads cause overhead two places first place coordination overhead seen synchronization access shared data structures pbnf
two modes locking nblock graph first thread ownership nblock open
nodes remain expanded use try lock work could
done fails acquire lock otherwise nodes thread could expand
attempt acquire lock nblock graph normal operation blocks
failure ahda use try lock receive queue expansion nodes
queue open list implementation ahda use blocking lock
operation thread nodes remaining expand nodes remaining send
receive buffers
second place overhead may incurred threads nodes expand
pbnf occurs thread exhausts current nblock free nblocks
acquire thread must wait nblock becomes free ahda open nodes map
thread may nodes expand situation thread busy wait
node arrives receive queue situation locking waiting time wasted
threads actively searching space
evaluating coordination overhead combine amount time spent waiting
lock amount time waiting without nodes expand figure shows per thread
coordination times locks waiting sum two normalized total wall time


fipercentage wall time

b urns l emons ruml z hou





percentage wall time

safepbnf ahda
locks

safepbnf ahda
wait

safepbnf ahda
sum

safepbnf ahda
wait

safepbnf ahda
sum





safepbnf ahda
locks

figure per thread ratio coordination time wall time unit cost four way pathfinding top
puzzle bottom

unlike previous set boxplots individual data points residing extremes signified
circles order improve readability locks column plot shows distribution
times spent thread waiting lock wait column shows distribution times
threads spent waiting without nodes available expand sum column shows
distribution sum mean lock wait times
left side figure shows grid pathfinding locks column see
threads ahda spent almost time acquiring locks expected ahda
uses asynchronous communication appears amount time threads pbnf spent
acquiring locks significantly greater ahda wait column plot
shows pbnf ahda appeared threads spend nearly amount time
waiting without nodes expand finally sum column shows threads pbnf
spent time overall coordinating threads
bottom half figure shows coordination overhead puzzle domain
see threads ahda spent almost time acquiring lock individual threads pbnf
however tended spend larger fraction time waiting locks sliding tiles domain


fib est f irst earch ulticore achines

grid pathfinding wait column figure see ahda spent
time pbnf without nodes expand finally see pbnf spent time
coordinating threads ahda
overall experiments verified first two hypotheses pbnf expanded better
quality nodes ahda spent less time performing priority queue operations
ahda found third hypothesis hold threads pbnf tended
coordination overhead ahda seems weighed two
factors
summary
section shown empirical evaluation optimal parallel best first
search shown several simple parallel actually slower
serial search even offered computing power additionally showed empirical set make good use parallelism outperform serial
overall safe pbnf gave best consistent performance latter set
ahda variant pra second fastest mean performance domains
shown abstraction pra style search distribute nodes among
different threads give significant boost speed reducing amount communication modification pra appears lot helpful simply asynchronous
communication improvements conjunction ahda yields competitive
additional feature relying shared memory
finally performed set experiments attempt explain safe pbnf tended
give better search performance ahda experiments looked three factors node quality
open list sizes thread coordination overhead concluded pbnf faster
expands fewer nodes suboptimal f values takes less time perform priority queue
operations

bounded suboptimal search
sometimes acceptable even preferable search solution optimal suboptimal
solutions often found much quickly lower memory requirements optimal
solutions section create bounded suboptimal variants best
optimal parallel search
weighted pohl variant orders search f n g n w h n
w probably popular suboptimal search guarantees admissible
heuristic h weight w solution returned w admissible within w factor
optimal solution cost davis bramanti gregor wang
possible modify ahda bfpsdd pbnf use weights suboptimal solutions call wahda wbfpsdd wpbnf optimal search
parallelism implies strict f search order followed proof weighted
w optimality depends crucially following strict f order parallel variants must
prove quality solution exploring pruning nodes thus finding effective
pruning rules important performance assume throughout h admissible


fib urns l emons ruml z hou

pruning poor nodes
let current incumbent solution w suboptimality bound node n clearly
pruned f n g according following theorem need retain n
optimal path solution factor w better much stronger rule
theorem prune node n w f n g without sacrificing w admissibility
proof incumbent w admissible safely prune node consider case
g w g opt opt optimal goal note without pruning exists
node p open list generated best path opt let f cost
optimal solution admissibility h definition p w f p w f p w g opt
pruning rule discards p would imply g w f p thus g w g opt
contradicts premise therefore open node leading optimal solution pruned
incumbent w admissible search terminate open empty
terminate incumbent w admissible replaced optimal solution

make explicit useful corollary
corollary prune node n f n g without sacrificing w admissibility

proof clearly w f n f n theorem applies

corollary use pruning shortcut open list sorted increasing f
node front f g prune entire open list
pruning duplicate nodes
searching inconsistent heuristic weighted possible search
better path already expanded state likhachev gordon thrun noted
provided underlying heuristic function h consistent weighted still return w admissible solution duplicate states pruned search ensures state
expanded search unfortunately proof depends expanding
exactly best first order violated several parallel search consider
however still prove duplicates dropped consider expansion
node n generates duplicate state already expanded propose
following weak duplicate dropping criterion copy pruned old g
g n w c n c n optimal cost node n node
theorem even weak dropping rule applied node p optimal
solution path open g p w g p
proof proceed induction iterations search theorem clearly holds expansion
initial state induction step note node p removed open
expanded child pi lies along optimal path added open theorem holds
way wont added exists previous duplicate copy pi pruning rule holds
e g pi g pi w c pi pi inductive hypothesis g pi w g pi

definition g pi c pi pi g pi g pi w g pi
note use technique prohibits global minimum f value lower bound
optimal solutions cost g values inflated factor w however
incumbent search global minimum f value g serial
weighted search w admissibility assured


fib est f irst earch ulticore achines

corollary minimum f value g incumbent g
w g opt
proof recall node p theorem g f p g p w h p w g p h p
w g opt

remains empirical question whether pruning rather weak criterion lead better
performance practice indicate provide advantage grid pathfinding
domain presented section noted extra pruning
preserve w admissibility may solutions lower quality resulting search
without pruning
optimistic search
korf showed weighted typically returns solutions better bound w
would suggest take advantage thayer ruml use optimistic
bounded suboptimal search works two stages aggressive search weight greater
desired optimality bound incumbent solution cleanup phase prove
incumbent indeed within bound intuition behind wa
solution within tight bound much tighter w g opt search continue
looking nodes f order bound proved thayer ruml indeed
surpass speed wa given optimality bound implemented
optimistic version pbnf opbnf
one requirements opbnf must access minimum f value
nodes order prove bound incumbent solution aggressive search stage
open lists heap free nblocks sorted f instead f couple additions need
made first nblock additional priority queue containing open search nodes sorted
f call queue openf openf queue simply maintained adding removing
nodes nodes added removed f ordered open list nblock second
priority queue called minf nblocks maintained sorted lowest f value
nblock time last release minf used track lower bound minimum f value
nodes accomplished lazily updating minf nblock released
thread thread releases nblock sifts released nblock successors
positions minf queue nblocks whose minimum f values could
changed releasing thread since global minimum f value nodes strictly
increasing assuming consistent heuristic guarantee f value front
minf queue strictly increasing lower bound global minimum f value
given time lower bound able prove whether incumbent solution
properly bounded
opbnf needs decide switch aggressive search phase cleanup
phase optimistic search originally proposed optimistic search performs aggressive search
first incumbent found switches cleanup f n g n
best node f incumbent solution aggressive search f n
g hedge case current incumbent within bound opbnf
left choice switch aggressive search cleanup global basis
per nblock basis choose switch per nblock basis assumption
threads could cleaning areas search space low f values threads look


fib urns l emons ruml z hou

better solutions areas search space low f values opbnf deciding
one nblock better another deciding switch set nblock hot choice
longer solely best f value given nblock instead f
value first f value break ties best f value bound incumbent
acquiring nblock thread takes free nblock best f value best f
value depending nblock better notion better described previous
sentence finally expanding nodes thread selects aggressive search cleanup
criteria standard optimistic search nodes within acquired nblock

empirical evaluation bounded suboptimal search
implemented tested weighted versions parallel search discussed
wahda wapra wbfpsdd wpbnf opbnf prune nodes
w f criterion presented theorem prune entire open lists f corollary search
terminates nodes pruned incumbent solution experiments
run three benchmark domains optimal search grid pathfinding sliding tile
puzzle strips
grid pathfinding
presented table performance parallel search terms
speedup serial weighted grid pathfinding duplicate states already
expanded dropped serial wa discussed likhachev et al
rows table number threads different whereas columns
weights used domains entry shows mean speedup serial weighted
performed wilcoxon signed rank test determine mean values significantly
different elements bold represent values significantly different p
best mean value given column general parallel increased
speedup threads added low weights decreased speedup weight increased
unit cost four way movement grids weights wpbnf
fastest tested reaching five times speed wa weight
x weight weight wpbnf wbfpsdd wahda
significant difference performance threads wahda best speed
weight wapra never gave best performance domain
eight way movement grids wpbnf gave best performance weight
although latter case best performance decrease speed wa
achieved thread wahda fastest weight however scale
expected number threads increased finally wapra gave least performance
decrease weighted weight thread case slower
serial weighted wapra gave closest performance serial search wbfpsdd
never gave best performance domain
life cost domain wpbnf outperformed weights
weight wpbnfs performance quickly dropped however wahda best
x speedup wa although performance appears inconsistent significantly different much lower speedup values weight
wapra never gave best performance domain


fiwapra

wahda

threads

wbfpsdd

wpbnf

b est f irst earch ulticore achines


































unit four way grids





































weight
unit eight way grids





































life four way grids





































table grid pathfinding average speedup serial weighted numbers
threads



fib urns l emons ruml z hou

threads



















wpbnf































wahda





















threads



















wbfpsdd































wapra





















table puzzle average speedup serial weighted numbers threads

opbnf

threads









unit four way grids













unit eight way grids













easy puzzles













table average speedup serial optimistic search numbers threads



fib est f irst earch ulticore achines

overall see wpbnf often best speedup eight threads weights
less wahda however gave best performance weight across grid
pathfinding domains wbfpsdd often gave speedup serial weighted however
quite competitive wpbnf wahda wapra rarely able outperform
serial search
table shows optimistic variant pbnf opbnf cell
table shows mean speedup opbnf serial optimistic search bold
cells entries significantly different best value column unit cost
four way pathfinding opbnf gave performance increase optimistic search two
threads weights less weight opbnf tended give
best speedup may optimistic search performed poorly particular weight
unit cost eight way pathfinding see opbnf performs comparably unit cost domain
weight however higher weights slower serial optimistic
search
sliding tile puzzles
sliding tiles domain used standard korf puzzles korf
presented table wpbnf wahda wapra tended give comparable performance
sliding tile puzzle domain values significantly different weights
weight wahda gave least performance decrease weighted
threads
right column table shows optimistic pbnf puzzle
instances solvable fewer million expansions opbnf gave best performance weight weights greater opbnf unable outperform serial
counterpart greater weights opbnf tended perform better smaller numbers threads
one trend seen sliding tiles domain grid pathfinding domain
speedup parallel serial suboptimal search decreases weight
increased suspect decrease relative performance due becoming
sufficiently easy terms node expansions overhead parallelism becomes harmful
overall search require many node expansions cost parallelism additional
expansions spawning threads synchronization albeit small waiting threads complete etc
amortized search effort require small number expansions
however overhead accounts total search time serial could
potentially faster
confirm understanding effect size speedup figure shows comparison wpbnf weighted korf puzzle instances eight threads
point represents run one instance particular weight axis represents wpbnf
speedup relative serial wa x axis represents number nodes expanded wa
different glyphs represents different weight values used wpbnf wa figure
shows wpbnf outperform wa easier benefits wpbnf
wa increased difficulty increased speed gain instances run
weight lowest weight tested leveled times faster wa
machine eight cores instances seem speedup greater
x explained speculative expansions wpbnf performs may


fib urns l emons ruml z hou

sliding tiles wpbnf v wa
w

log times faster wa


w



ww w
w
w
w

ww
w
w
ws
w ww
wss w ww
w w w ww
ss
w
w
w
w
w
w w
w w ww
ss

w
w
wsw swww
w
ss
ws ssw
w

sw w
www
ww
sw
w ww www

w


w ww ww
ss
ss
w w
ss sssssw
w


w
w
sss sw
ws
w
ww

ss sss


ss w
w
w




w
w


ws
ws
w

ss
ss ss
w


ss
sss ss
ss
sw

w
w





w









w
w

w

wpbnf
wpbnf
wpbnf
wpbnf
wpbnf

w





log nodes expanded wa

figure wpbnf speedup wa function difficulty
bounded solution faster weighted due pruning nodes f values
equal resulting solution poor behavior wpbnf easy
likely due overhead described effect difficulty means wpbnf
outperformed wa often low weights required expansions
less often higher weights completed quickly
strips
table shows performance parallel search strips
terms speedup versus serial weighted table columns represent weights
rows represent different two seven threads bold values represent table entries within best performance given domain
better speedup seven threads two wpbnf gave best speedup
number domains followed wahda fastest three domains
seven threads two threads couple domains satellite freecell
wbfpsdd gave speedup however never seven threads wapra
slower three remaining one freecell serial weighted performs much worse weight increases interestingly wpbnf wbfpsdd
pathology thus record speedups times
summary
section seen bounded suboptimal variants parallel searches give
better performance serial progenitors shown sliding tile puzzle
parallel search gives advantage serial search difficulty increases
suspect holds domains suspect overhead
parallelism amortized search time easy


threads

threads

threads

threads

b est f irst earch ulticore achines

logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog
gripper
logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog
gripper

logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog
gripper
logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog
gripper









































wapra















































































wahda







































wpbnf




























































wbfpsdd































































































table speed serial weighted strips weights



fib urns l emons ruml z hou

anytime search
popular alternative bounded suboptimal search anytime search highly suboptimal
solution returned quickly improved solutions returned time
terminated incumbent solution proved optimal two popular anytime
heuristic search anytime weighted awa hansen zhou anytime
repairing ara likhachev gordon thrun awa weighted search
allowed continue finding first solution pruning unweighted f n g
incumbent solution n node considered expansion ara uses weighted
search weight lowered solution meeting current suboptimality bound
found special incons list kept allows search expand node
search weight
section present anytime versions best performing parallel searches
previous sections used pbnf framework implement anytime weighted pbnf awpbnf anytime repairing pbnf arpbnf use pra framework create anytime
weighted ahda awahda performance simple
runs parallel weighted searches differing weights domain implemented anytime weighted bfpsdd awbfpsdd comparison well
parallel searches inherently continue searching first solutions found
serve naturally anytime style anytime weighted main
difference standard optimal versions anytime variants
anytime versions sort open lists heap free nblocks f n g n
w h n fact cases optimal search degenerate case anytime search
w simply w used implement except
arpbnf multi weighted
next discuss details arpbnf following introduce
parallel anytime called multi weighted finally set
comparisons performed anytime discussed sections
anytime repairing pbnf
arpbnf parallel anytime search ara likhachev et al
arpbnf open lists heap nblocks sorted f awpbnf instead merely
continuing search incumbent proved optimal arpbnf uses weight schedule
time incumbent found weight heuristic value lowered specified amount
open lists resorted search continues final iteration weight
optimal solution found
following procedure used resort nblocks parallel incumbent solutions
thread calling resort one found goal becomes leader taking
lock nblock graph setting resort flag flag already set
another thread already leader current thread becomes worker flag
set leader thread releases lock nblock graph waits nblocks
values zero nblocks acquired
threads check resort flag expansion set threads release nblocks
become worker threads wait leader set start flag


fib est f irst earch ulticore achines

nblocks leader takes lock nblock graph ensures
values still zero releases lock retries leader sets
global weight value next weight weight schedule populates lock free
queue nblocks queue populated leader sets start flag
threads greedily dequeue nblocks resort queue empty
nblocks resorted leader thread clears resort flag start flag
releases lock nblock graph threads acquire nblocks
search continue
modeled procedure tla showed live lock dead lock free
threads nblocks use tlc model checker yu et al model
simple include appendix
multi weighted
section introduce simple parallel anytime called multi weighted
pbnf pra frameworks parallelizing anytime thought one
end spectrum parallel anytime pbnf pra threads working
finding single solution given quality opposite end spectrum thread would
working solution compare end spectrum
implemented call multi weighted allocates available threads
weighted searches thread finishes first generally thread searching
greatest weight therefore solution worst quality next thread
finish next greatest weight final thread complete generally
searching weight performing standard search return optimal solution
given schedule weighs decreasing order largest weights
schedule distributed among available threads threads begin searching wa
given weight values thread finds solution better current one
updates incumbent shared threads allow pruning thread
finds better incumbent solution w admissible respect weight thread
searching thread finishes finding solution pruning entire open list takes
highest unclaimed weight schedule starts fresh search weight
weights left schedule thread terminates threads terminated
search complete final weight schedule last solution found
optimal
one benefits multi weighted simple implement
however see doesnt benefit much added parallelism reason
may weight schedule exhausted thread searching lowest
weight threads complete searches sit idle entire search terminates since
final weight take longest may majority search time dynamic
schedule could used keep threads busy optimal solution found one could
attempt use threads multi threaded search weight
wpbnf wahda leave extensions future work


fib urns l emons ruml z hou

solution cost factor optimal


















wt sched
wt sched
wt sched
wt sched






















wall time relative serial

wall time relative serial

wall time relative serial

grid unit four way awa lower hull

grid unit four way awpbnf threads lower hull

grid unit four way ara lower hull





awa
solution cost factor optimal

solution cost factor optimal

grid unit four way ara raw data














awpbnf threads
solution cost factor optimal

solution cost factor optimal

grid unit four way awpbnf threads raw data








solution cost factor optimal

grid unit four way awa raw data













wall time relative serial





ara












wall time relative serial











wall time relative serial

figure raw data profiles top lower hull profiles bottom awa left awpbnf center ara right grid unit cost four way pathfinding

empirical evaluation anytime search
implementation empirical setup similar used suboptimal search ara
arpbnf multi wa considered four different weight schedules
awa
anytime parallel consider weights grid
pathfinding sliding tiles domain fully evaluate anytime
necessary consider performance profile e expected solution quality
function time easily plotted ignores fact anytime
considered free parameter namely weight schedule weights used
accelerate search order compare make assumption
particular application user attempt parameter setting giving good performance
timescale interested assumption plot performance
anytime computing time point best performance achieved
parameter settings tried minimum solution cost parameter
settings given given time point refer concept lower hull
profiles takes minimum profiles parameter setting




fib est f irst earch ulticore achines

grid unit four way threads

grid unit four way threads


ara
arpbnf threads
awa
multi wa threads
awahda threads
awpbnf threads

solution cost factor optimal

solution cost factor optimal







ara
awa
multi wa threads
arpbnf threads
awahda threads
awpbnf threads














wall time relative serial











wall time relative serial

figure grid unit cost four way pathfinding lower hull anytime profiles
top row figure shows example raw data three
x unit cost four way grid pathfinding axis plots solution quality factor optimal x axis wall clock time relative amount
time took optimal solution bottom row figure shows lower hull
respective data displayed comparing two images left display data
awa one see three big steps lower hull plot different weight used hull found better solution time bound
center panel figure shows awpbnf gives similar performance awa
however often faster surprising since awpbnf awa
running eight threads instead one final panel figure shows ara uses
weight schedules instead single weight
figures present lower hulls serial parallel grid pathfinding
sliding tile puzzle panel axis represents solution cost factor optimal
cost figure x axis represents wall time relative amount time serial took
optimal solution allows comparison anytime standard
serial since able solve korfs puzzle instances machine
x axis figure absolute wall time seconds serial parallel
plotted profiles start first returns solution ends
proved optimality second cutoff since multi wa consume memory
quickly gave second cutoff sliding tile puzzle prevent
thrashing
four way unit cost grids
figure shows anytime performance unit cost four way movement grid pathfinding awahda awpbnf found best solutions quicker


fib urns l emons ruml z hou

korfs puzzles threads















ara
multi wa threads
arpbnf threads
awa
awpbnf threads
awahda threads



solution cost factor optimal

ara
multi wa threads
arpbnf threads
awahda threads
awa
awpbnf threads



solution cost factor optimal

korfs puzzels threads













wall time seconds







wall time seconds

figure korfs puzzles lower hull anytime profiles
improved amount time taken better solutions threads
added awpbnf converged quickly threads added even two threads
awpbnf first converge optimal solution time serial
next two multi wa anytime repairing pbnf arpbnf multi wa converged quickly threads added performance finding intermediate solutions
change much different numbers threads arpbnf hand took longer
good solutions low thread counts threads added started perform better
eventually matching multi wa eight threads improved solution
quality steadily awpbnf awahda large jumps lower hulls
jumps corresponds hull switching different weight value compare
raw data awpbnf figure parallel found good solutions faster
serial awa serial ara parallel however took longer prove optimality
awa domain
sliding tile puzzles
figure presents lower hulls anytime korfs instances puzzle
figure x axes total wall clock time seconds times normalized
able solve instances panels see awahda tended
good solutions faster awa awpbnf performed similarly
two threads number threads increased awpbnf begun better solutions faster
awa arpbnf took longer good solutions awpbnf awahda
able better solutions faster serial counterpart simple multi wa
performed worst parallel increasing number threads used multi wa
seem increase solution quality ara gave worst performance domain
profile curve seen top three panels


threads

threads

threads

threads

b est f irst earch ulticore achines

logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog
gripper
logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog




















logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog
gripper
logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog




















awapra

































awpbnf

















































































































awahda



































awbfpsdd











































































table speed anytime search optimality serial awa strips
weights

strips
table shows speedup parallel anytime serial anytime
run optimal solution proved weight awa ran memory
blocks speedup values weight instance lower bounds bold entries


threads

b urns l emons ruml z hou

logistics
blocks
gripper
satellite
elevator
freecell
depots
driverlog
gripper












awpbnf


































awbfpsdd


































awapra


























table speed anytime search optimality pbnf strips
weights

table represent values within best performance given domain
speedup serial generally increased threads higher weight
pbnf gave fastest performance except two domains blocks freecell
two domains awahda gave best performance least factor x awpbnf
hansen zhou awa lead speedup weight values
certain domains finding suboptimal solution quickly allows f pruning keeps open list
short quick manipulate resulting faster performance even though awa expands
nodes found similar phenomenon corresponding parallel case table shows
speedup unweighted optimal pbnf weights anytime
significant fraction values greater representing speedup anytime
instead standard optimal parallel search general speedup seems variable
weight increases weight awpbnf provides speedup
summary
part shown create parallel anytime search
frameworks introduced previous sections created parallel
anytime simply runs many weighted searches differing weights
experiments seen awpbnf awahda found higher quality solutions faster
showed improved performance threads added
additionally arpbnf parallel ara improved threads
tended give smoother increase solution quality former two although
solutions quite quickly unable converge optimal solution
sliding tiles domain within given time limit running multiple weighted searches
give solutions faster number threads increased convergence performance
mixed

discussion
explored set best first search exploit parallel capabilities modern
cpus first looked parallel optimal search safe pbnf several variants pra


fib est f irst earch ulticore achines

set simpler previously proposed overall safe pbnf gave best performance
optimal search next created set bounded suboptimal search pbnf
successful variants pra bfpsdd pbnf pra asynchronous
communication abstraction ahda gave best performance pbnf
slightly better average addition showed suggest boundedsuboptimal pbnf advantage serial weighted search difficulty
increases finally converted pbnf pra anytime compared
serial anytime called multi weighted found
anytime weighted pbnf anytime variant ahda gave best anytime performance
occasionally able solutions faster non anytime counterparts
pbnf outperforms psdd believe lack
layer synchronization better utilization heuristic cost go information fact
bfpsdd got better f layers widened suggestive evidence another less obvious
reason pbnf may perform better best first search larger frontier size
breadth first heuristic search used psdd larger frontier size tend create
nblocks containing open search nodes disjoint duplicate detection scopes
nodes open lists therefore potential increased parallelism
even single thread pbnf outperform serial search
see table may attributed part speculative behavior pbnf
since pbnf uses minimum number expansions testing switch nblock
better f values search sub optimal nodes would search order
get optimal solutions pbnf acts anytime stores incumbent solutions prunes
prove optimal solution zhou hansen
ability perform better hansen zhou upper bound pruning
reduces number expansions nodes f value equal optimal solution
cost reduce number open nodes increasing speed operations open list
pbnf may give good single thread performance breaks search frontier
many small open lists one nblock priority queue operations
pbnf performs much smaller queues uses one big single queue see
section
possible extensions
basic guideline creating good abstractions sdd pbnf minimize
connectivity abstract states aspects abstraction could explored
instance discovering features good include abstract away may helpful
users pbnf much focus one feature could cause good nodes focused small
subset nblocks zhou hansen likewise size abstraction could examined
detail although use constant abstraction size current work simplicity
seems likely abstraction size change number threads changes perhaps even
features domain instance guideline could devised ratio
number nblocks threads h value start state adaptive abstraction
size would much simpler real world use additionally edge partitioning zhou hansen
could allow us reduce connectivity abstraction used pbnf study
necessary discover full impact technique pbnfs behavior


fib urns l emons ruml z hou

possible future extensions pbnf include adaptive minimum expansion values use
external memory extension distributed setting preliminary work adapting minimum expansion values indicated simply increasing decreasing lock failures
successes neutral negative effect performance one reason may
minimum expansions parameter adds speculation
may possible combine pbnf pra distributed memory setting
may use technique pra distribute portions search space among different nodes
cluster work stations multicore search pbnf node
additional technique explored running multicore search threads available cores technique used improve
performance parallel delayed duplicate detection korf korf schultze
heavily intensive one thread blocked another thread
make use newly available processing core even without disk technique may
useful threads spend lot time waiting acquire locks

conclusions
investigated best first search multicore machines
shown set previously proposed parallel best first search much slower
running serially presented novel hashing function pra takes advantage
locality search space gives superior performance additionally verified presented kishimoto et al asynchronous communication pra allows
perform better synchronous communication present pbnf
approximates best first search ordering trying keep threads busy proved
correctness pbnf search framework used derive suboptimal anytime

performed comprehensive empirical comparison optimal suboptimal anytime variations parallel best first search demonstrate good
abstraction distribute nodes pra beneficial asynchronous communication
two techniques used together yielding ahda found original breadth first psdd give competitive behavior without tight upper bound
pruning implemented novel extension psdd bfpsdd gives reasonable performance domains tested experiments however demonstrate pbnf
ahda outperformed pbnf performs best optimal
bounded suboptimal search pbnf ahda gave competitive anytime performance

acknowledgments
gratefully acknowledge support nsf grant iis darpa cssg program
grant hr helpful suggestions jordan thayer
previously reported burns lemons zhou ruml b burns lemons ruml
zhou


fib est f irst earch ulticore achines

appendix pseudo code safe pbnf
following pseudo code three global structures first pointer current
incumbent solution incumbent second done flag set true thread recognizes
search complete third nblock graph nblock graph structure contains
list free nblocks freelist along h values nblock simplicity
code uses single lock access structure thread local exp count best
function set nblocks nblock containing open node lowest f value
earch initial node
insert initial node open
p processors hread earch
threads still running wait
return incumbent
hread earch
b null
done

b n ext n block b

exp

hould witch b exp

best open node b

incumbent prune

goal

incumbent

lock incumbent unlock

else duplicate

children expand

child children

insert child open appropriate nblock

exp exp
hould witch b exp
b empty return true
exp min expansions return false
exp
best freelist b best interferencescope b b

best interferencescope b best freelist

et h ot best interferencescope b

return true
lock
b interferencescope b

hot b et c old b
unlock
return false



fib urns l emons ruml z hou

et h ot b
lock
hot b b

interferencescope b b hot

hot b true

interferencescope b

hot et c old

h

empty

freelist freelist

h h
unlock
et c old b
hot b false
interferencescope b

h h

h empty

hot

et c old

freelist freelist

wake sleeping threads
r elease b
b interferencescope b

b b

b h b b empty

hot b

et c old b

freelist freelist b

wake sleeping threads
n ext n block b
b open nodes b set hot lock
else trylock fails return b
b null

bestscope best interferencescope b

b bestscope b best freelist

unlock return b

r elease b
l nblocks l freelist empty

done true

wake sleeping threads
freelist empty done sleep
done n null


fib est f irst earch ulticore achines

else

best freelist

b interferencescope

b b
unlock
return



fib urns l emons ruml z hou

appendix b tla model hot n blocks
present model used safe pbnf live lock free refer section
module hotnblocks
finitesets naturals
constants nnblocks nprocs search nextblock none
variables state acquired ishot succs

vars hstate acquired ishot succsi

states search nextblock

nblocks nnblocks

procs nprocs
assume nnblocks nprocs nprocs nnblocks none
nblocks cardinality states

preds x nblocks x succs set predecessors nblock x

intscope x preds x union preds succs x interference scope x

intby x nblocks x intscope set nblocks x interferes

busy union succs x x set nblocks busy given set acquired nblocks

overlap x intscope x set busy nblocks overlapping successors x

hot x nblocks ishot x overlap x set hot nblocks given set acquired nblocks

hotinterference union intscope x x hot set nblocks interference scopes hot nblocks

free x nblocks overlap x x
hotinterference free nblocks

acquired acquired x x procs none set nblocks currently acquired

overlapamt x cardinality overlap x acquired number nblocks overlapping x

donextblock x unchanged hsuccsi
state x nextblock acquired x none free acquired
free acquired acquired x
free acquired acquired x acquired acquired except x
state state except x search
ishot nblocks free acquired acquired x
false else ishot
else acquired acquired except x none
ishot nblocks free acquired
false else ishot
unchanged hstatei

dosearch x unchanged hacquired succsi
state x search state state except x nextblock
unchanged hishoti
intby acquired x ishot
intscope hot acquired

hotinterference acquired
ishot ishot except true

init state x procs nextblock acquired x procs none
ishot x nblocks false
extends

basic graph nblock connected neighbors forming loop

succs x nblocks

x nnblocks x
x nnblocks x else x x

next x procs donextblock x dosearch x

fairness x procs wfvars donextblock x dosearch x

prog init next vars fairness

hotnblocks x nblocks ishot x ishot x property prove


else



fib est f irst earch ulticore achines

references
burns e lemons ruml w zhou r suboptimal anytime heuristic search
multi core machines proceedings seventeenth international conference automated scheduling icaps
burns e lemons zhou r ruml w b best first heuristic search multi core
machines proceedings th international joint conference artificial intelligence
ijcai
cushing w bentor j kambhampati cost search considered harmful
international symposium combinatorial search socs
dai p hansen e prioritizing bellman backups without priority queue proceedings nineteenth international conference automated scheduling
icaps
davis h w bramanti gregor wang j advantages depth breadth
components heuristic search methodologies intelligent systems pp
edelkamp schrodl localizing proceedings seventeenth national
conference artificial intelligence aaai pp aaai press
edelkamp sulewski gpu exploration two player games perfect hash
functions international symposium combinatorial search socs
evans j scalable concurrent malloc implementation freebsd proceedings
bsdcan
evett hendler j mahanti nau pra massively parallel heuristic search
journal parallel distributed computing
felner kraus korf r kbfs k best first search annals mathematics
artificial intelligence
ferguson c korf r e distributed tree search applications alpha beta pruning proceedings seventh national conference artificial intelligence aaai
hansen e zhou r anytime heuristic search journal artificial intelligence

harris l pragmatic implementation non blocking linked lists lecture notes
computer science vol pp springer berlin heidelberg
hart p e nilsson n j raphael b formal basis heuristic determination
minimum cost paths ieee transactions systems science cybernetics ssc

haslum p geffner h admissible heuristics optimal proceedings
fifth internationas conference artificial intelligence scheduling systems
aips pp
holzmann g j bosnacki design multicore extension spin model
checker ieee transactions software engineering


fib urns l emons ruml z hou

jabbar edelkamp parallel external directed model checking linear
emerson e namjoshi k eds verification model checking abstract interpretation vol lecture notes computer science pp springer berlin heidelberg
kishimoto fukunaga botea scalable parallel best first search optimal
sequential proceedings nineteenth international conference automated
scheduling icaps
korf r e iterative deepening optimal admissible tree search proceedings
international joint conference artificial intelligence ijcai pp
korf r e linear space best first search artificial intelligence
korf r e delayed duplicate detection extended abstract proceedings eighteenth
international joint conference articial intelligence ijcai pp
korf r e schultze p large scale parallel breadth first search proceedings
twentieth national conference articial intelligence aaai pp
kumar v ramesh k rao v n parallel best first search state space graphs summary proceedings seventh national conference artificial intelligence
aaai pp
lamport l specifying systems tla language tools hardware software
engineers addison wesley
likhachev gordon g thrun ara anytime provable bounds
sub optimality proceedings seventeenth annual conference neural information
porcessing systems nips
likhachev gordon g thrun ara formal analysis tech rep cmu cs carnegie mellon university school computer science
niewiadomski r amaral j holte r parallel external memory frontier breadthfirst traversal clusters workstations proceedings international
conference parallel processing icpp pp
niewiadomski r amaral j n holte r c b sequential parallel
frontier delayed duplicate detection proceedings st national conference
artificial intelligence aaai pp aaai press
nilsson n j principles artificial intelligence tioga publishing co
pohl heuristic search viewed path finding graph artificial intelligence

powley c korf r e single agent parallel window search ieee transactions pattern
analysis machine intelligence
richter westphal lama planner guiding cost anytime
landmarks journal artificial intelligence
ruml w b best first utility guided search proceedings ijcai pp



fib est f irst earch ulticore achines

snir otto mpi complete reference mpi core mit press cambridge
usa
stern u dill l magnetic disk instead main memory mur verifier
computer aided verification pp springer
sundell h tsigas p fast lock free concurrent priority queues multi thread
systems parallel distributed processing symposium international
thayer j ruml w faster weighted optimistic bounded
suboptimal search proceedings eighteenth international conference automated
scheduling icaps
valois j lock free data structures ph thesis rensselaer polytechnic institute
yu manolios p lamport l model checking tla specifications correct
hardware design verification methods pp springer berlin heidlberg
zhou r hansen e domain independent structured duplicate detection proceedings
twenty first national conference artificial intelligence aaai pp
zhou r hansen e edge partitioning external memory graph search proceedings
twentieth international joint conference artificial intelligence ijcai
zhou r hansen e dynamic state space partitioning external memory graph search
international symposium combinatorial search socs
zhou r hansen e structured duplicate detection external memory graph search
proceedings nineteenth national conference artificial intelligence aaai
zhou r hansen e breadth first heuristic search artificial intelligence

zhou r hansen e parallel structured duplicate detection proceedings
twenty second conference artificial intelligence aaai




