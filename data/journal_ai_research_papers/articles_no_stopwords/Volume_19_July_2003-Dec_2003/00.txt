Journal Artificial Intelligence Research 19 (2003) 1-10

Submitted 10/02; published 7/03

Research Note
New Polynomial Classes Logic-Based Abduction
Bruno Zanuttini

zanutti@info.unicaen.fr

GREYC, Universite de Caen, Boulevard du Marechal Juin
14032 Caen Cedex, France

Abstract
address problem propositional logic-based abduction, i.e., problem
searching best explanation given propositional observation according given
propositional knowledge base. give general algorithm, based notion projection; study restrictions representations knowledge base
query, find new polynomial classes abduction problems.

1. Introduction
Abduction consists searching plausible explanation given observation.
instance, p |= q p plausible explanation observation q. generally,
abduction process searching set facts (the explanation, p) that,
conjointly given knowledge base (here p q), imply given query (q). process
constrained set hypotheses among explanations chosen,
preference criterion among them.
problem abduction proved practical interest many domains. instance,
used formalize text interpretation (Hobbs et al., 1993), system (Coste-Marquis
& Marquis, 1998; Stumptner & Wotawa, 2001) medical diagnosis (Bylander et al., 1989,
Section 6). closely related configuration problems (Amilhastre et al., 2002),
ATMS/CMS (Reiter & de Kleer, 1987), default reasoning (Selman & Levesque,
1990) even induction (Goebel, 1997).
interested complexity propositional logic-based abduction, i.e.,
assume knowledge base query represented propositional formulas.
Even framework, many different formalizations proposed literature,
mainly differing definition hypothesis best explanation (Eiter
& Gottlob, 1995). assume hypotheses conjunctions literals
formed upon distinguished subset variables involved, best explanation
one proper subconjunction explanation (subset-minimality criterion).
purpose exhibit new polynomial classes abduction problems. give
general algorithm finding best explanation framework defined above, independently syntactic form formulas representing knowledge base
query. explore syntactic forms allow polynomial running time
algorithm. find new polynomial classes abduction problems, among one
restricting knowledge base given Horn DNF query positive CNF,
one restricting knowledge base given affine formula query
disjunction linear equations. algorithm unifies several previous results.
c
2003
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBruno Zanuttini

note organized follows. first recall useful notions propositional
logic (Section 2), formalize problem (Section 3) briefly survey previous work
complexity abduction (Section 4). give algorithm (Section 5)
explore polynomial classes (Section 6). Finally, discuss results perspectives
(Section 7). lack space cannot detail proofs, longer version work,
containing detailed proofs examples, available (Zanuttini, 2003).

2. Preliminaries
assume countable number propositional variables x1 , x2 . . . standard connectives , , , , , . literal either variable xi (positive literal) negation
xi (negative literal). propositional formula well-formed formula built finite
number variables connectives; V ar() denotes set variables occur
propositional formula . clause finite disjunction literals, propositional formula Conjunctive Normal Form (CNF) written finite conjunction
clauses. instance, = (x1 x2 ) (x1 x2 x3 ) CNF. dual notions
clause CNF notions term (finite conjunction literals) Disjunctive
Normal Form (DNF) (finite disjunction terms).
assignment set variables V set literals contains exactly one
literal per variable V , model propositional formula assignment
V ar() satisfies usual way, assigns 1 xi iff xi m;
write tuple, e.g., 0010 {x1 , x2 , x3 , x4 }. write m[i] value assigned
xi m, M() set models propositional formula ;
said satisfiable M() 6= . formula said imply propositional formula 0
(written |= 0 ) M() M(0 ). generally, identify sets models Boolean
functions, use notations (negation), M0 (disjunction) on.
notion projection important rest paper. assignment
set variables V V , write SelectA (m) set literals
formed upon A, e.g., Select{x1 ,x2 } (0110) = 01. Projecting set assignments onto subset
variables intuitively consists replacing assignment SelectA (m);
sake simplicity however, define projection set models built upon
set variables M. yields following definition.
Definition 1 (projection) Let V = {x1 , . . . , xn } set variables, set assignments V V . projection onto set assignments V
M|A = {m | m0 M, SelectA (m0 ) = SelectA (m)}.
instance, let = {0001, 0010, 0111, 1100, 1101} set assignments V =
{x1 , x2 , x3 , x4 }, let = {x1 , x2 }. easily seen
M|A = {0000, 0001, 0010, 0011} {0100, 0101, 0110, 0111} {1100, 1101, 1110, 1111}
since {SelectA (m) | M} = {00, 01, 11}.
Remark projection set models formula onto set variables
set models general consequence independent
variables A. Note projection M() onto set models
formula obtained forgetting variables occurring A. details
2

fiLogic-Based Abduction

variable forgetting independence refer reader work Lang et
al. (Lang et al., 2002).
useful note straightforward properties projection. Let M, M0 denote
two sets assignments set variables V , let V . First, projection
distributive disjunction, i.e., (M M0 )|A = M|A M0 |A . distributive
conjunction depend variables M0 depends on, i.e., exist
A, A0 V , A0 = M|A = (M depend V \A) M0 |A0 = M0 ,
(M M0 )|A = M|A M0 |A holds; note true general case. Note finally
general (M)|A M|A .

3. Model Abduction
formalize model; sake simplicity, first define abduction problems
notions hypothesis explanation.
Definition 2 (abduction problem) triple = (, , A) called abduction problem satisfiable propositional formulas set variables
V ar(), V ar(); called knowledge base , query set
abducibles.
Definition 3 (hypothesis,explanation) Let = (, , A) abduction problem.
hypothesis set literals formed upon (seen conjunction),
hypothesis E explanation E satisfiable E |= .
proper subconjunction E explanation , E called best explanation .
Note framework allow one specify variable must occur unnegated
(resp. negated) explanation. think prohibiting restriction, since
abducibles intuitively meant represent variables whose values be, e.g., modified, observed repaired, matter sign explanation. note
restriction, general framework defined abducibles
literals hypotheses, conjunctions abducibles (Marquis, 2000).
interested computational complexity computing best explanation
given abduction problem, asserting none all. Following usual model,
establish complexities respect size representations
number abducibles; hardness results, following associated decision problem
usually considered: least one explanation ? Obviously, latter problem
hard, function problem is.

4. Previous Work
main general complexity results propositional logic-based abduction subsetminimality preference stated Eiter Gottlob (1995). authors show
deciding whether given abduction problem solution P2 -complete problem,
even V ar() = V ar() CNF. stated well Selman Levesque
(1990), establish problem becomes NP-complete Horn,
even acyclic Horn. Note SAT deduction polynomial
problem obviously NP.
3

fiBruno Zanuttini

fact, classes abduction problems known polynomial
search explanations. far know, classes defined
following restrictions (once refer reader references definitions):
2CNF 2DNF (Marquis, 2000, Section 4.2)
given monotone CNF clause (Marquis, 2000, Section 4.2)
given definite Horn CNF conjunction positive literals (Selman
& Levesque, 1990; Eiter & Gottlob, 1995)
given acyclic Horn CNF pseudo-completion unit-refutable
variable (Eshghi, 1993)
bounded induced kernel width given literal (del Val, 2000)
represented set characteristics models (with respect particular basis)
variable (Khardon & Roth, 1996); note set characteristic models
propositional formula, result however similar ones
represented set models, or, equivalently, DNF every variable
occurring term, propositional formula.
first two classes proved polynomial general method solving abduction
problems notion prime implicants, last one obvious since information
explicitely given input, four others exhibited ad hoc algorithms.
Let us mention Amilhastre et al. (2002) study related problems
general framework multivalued theories instead propositional formulas, i.e.,
domain variables restricted {0, 1}. authors mainly show,
far note concerned, deciding whether exists explanation still
P2 -complete problem (Amilhastre et al., 2002, Table 1).
Note results stated exact framework papers cited
above, still hold it. Let us mention problem enumerating
best explanations given abduction problem great interest; Eiter Makino
(2002) provide discussion first results it, mainly case
knowledge base Horn.

5. General Algorithm
give principle algorithm. Let us stress first that, well as, e.g., Marquis
construction (Marquis, 2000, Section 4.2), outline matches point point definition
best explanation; ideas Marquis anyway rather close.
first interested hypotheses every abducible x occurs (either
negated unnegated); let us call full hypotheses. Note indeed every explanation
E abduction problem subconjunction full explanation F ; indeed, since E
definition E satisfiable implies , suffices let F SelectA (m)
model E . Minimization F discussed later on.
4

fiLogic-Based Abduction

Proposition 1 Let = (, , A) abduction problem, F full hypothesis .
F explanation exists assignment V ar()
F = SelectA (m) M() (M( ))|A .
Proof Assume first F explanation . (i) exists assignment
V ar() |= F , thus F = SelectA (m) M(), (ii) F |= , i.e.,
F unsatisfiable, thus F
/ {SelectA (m) | M( )}, thus
/ (M( ))|A ,
thus (M( ))|A . Conversely, M() (M( ))|A let F = SelectA (m).
(i) since M(), F satisfiable, (ii) since
/ (M( ))|A ,
0
0
M( ) SelectA (m ) = F , thus F unsatisfiable, thus
F |= .

Thus characterized full explanations given abduction problem.
minimizing explanation F problem, since following greedy procedure,
given Selman Levesque (1990) reduces F best explanation :
every literal ` F
F \{`} |= F F \{`} endif;
Endfor;
Note depending order literals ` F considered result may
different, cases best explanation .
Finally, give general algorithm computing best explanation given
abduction problem = (, , A); correctness follows directly Proposition 1:
0 propositional formula M(0 ) = M() (M( ))|A ;
0 unsatisfiable return explanation;
Else
model 0 ;
F SelectA (m);
minimize F ;
return F ;
Endif;

6. Polynomial Classes
explore new polynomial classes abduction problems algorithm allows
exhibit. Throughout section, n denotes number variables V ar().
6.1 Affine Formulas
propositional formula said affine (or XOR-CNF ) (Schaefer, 1978; Kavvadias &
Sideri, 1998; Zanuttini, 2002) written finite conjunction linear equations
two-element field, e.g., = (x1 x3 = 1) (x1 x2 x4 = 0). seen, equations
play role affine formulas clauses CNFs; roughly, affine formulas represent
conjunctions parity equivalence constraints. class proves interesting knowledge
representation, since one hand tractable common reasoning tasks,
5

fiBruno Zanuttini

hand affine approximations knowledge base made small
efficiently learnable (Zanuttini, 2002). show projecting affine formula onto
subset variables quite easy too, enabling algorithm run polynomial time.
proof following lemma easily obtained gaussian elimination (Curtis, 1984):
triangulate variables put rightmost, keep equations
formed upon A; full details given technical report version (Zanuttini, 2003).
Lemma 1 Let affine formula containing k equations, V ar().
affine formula M() = (M())|A containing k equations
computed time O(k 2 |V ar()|).
Proposition 2 represented affine formula containing k equations
disjunction k 0 linear equations, subset V ar(), searching best
explanation = (, , A) done time O((k + k 0 )((k + 1)2 + |A|(k + k 0 ))n).
Sketch proof easily seen affine formula (containing k 0 + k equations
n variables) computed time linear size ; formula
projected onto time O((k + k 0 )2 n), straightforwardly get disjunction
k + k 0 linear equations (M( ))|A . use distributivity
solving satisfiability problem algorithm; recall SAT solved time
O(k 2 n) affine formula k equations n variables elimination method
Gauss (Curtis, 1984). remaining operations straightforward.

Note variables, literals clauses special cases disjunctions linear equations.
6.2 DNFs
Though class DNF formulas good computational properties, abduction
remains hard problem whole, even additional restrictions. Recall
TAUTOLOGY problem one deciding whether given DNF formula represents
identically true function, problem coNP-complete.
Proposition 3 Deciding whether least one explanation given abduction
problem (, , A) NP-complete given DNF, even variable
{} = V ar().
Sketch proof Membership NP obvious, since deduction DNFs polynomial;
easily seen tautological abduction problem (
(x), x, V ar()) explanation, x variable occuring (see DNF
(x) implication x); (x) DNF, get result.

However, represented DNF projecting onto easy; indeed, properties projection show suffices cancel literals formed upon A.
Consequently, DNF containing k terms, DNF M() = (M())|A
containing k terms computed time O(k|V ar()|).
Thus show subclasses class DNFs allow polynomial
abduction. state first result quite generally, note assumptions
satisfied natural classes DNFs: e.g., Horn DNFs, i.e., DNFs
6

fiLogic-Based Abduction

one positive literal per term; similarly, Horn-renamable DNFs, i.e.,
turned Horn DNF replacing variables negation,
simplifying double negations, everywhere formula; 2DNFs, DNFs
two literals per term. omit proof following proposition, since essentially
Proposition 2 (simply follow execution algorithm).
Proposition 4 Let class DNFs stable removal occurrences
literals TAUTOLOGY problem polynomial. restricted belong
D, clause subset V ar(), searching best explanation
= (, , A) done polynomial time.
Thus establish abduction tractable (among others) Horn-renamable
DNF (including Horn reverse Horn cases) 2DNF, clause.
Finally, let us point similar proof obtain polynomiality
problems obtained strengthening restriction Proposition 4 ,
weakening .
Proposition 5 represented Horn (resp. reverse Horn) DNF k terms
positive (resp. negative) CNF k 0 clauses, subset V ar(),
searching best explanation = (, , A) done time O((k + |A|)kk 0 n).
holds represented positive (resp. negative) DNF k terms
Horn (resp. reverse Horn) CNF k 0 clauses.
note variables, literals terms special cases (reverse) Horn
CNFs, variables, positive (resp. negative) clauses positive (resp. negative)
terms special cases positive (resp. negative) CNFs.

7. Discussion Perspectives
general algorithm presented note allows us derive new polynomial restrictions
abduction problems; even discussed here, lack space, allows
unify previously known restrictions (such 2CNF 2DNF,
monotone CNF given clause). following list summarizes main new
polynomial restrictions:
given affine formula disjunction linear equations (Proposition 2)
Horn-renamable DNF given clause (Proposition 4)
2DNF given clause (Proposition 4)
Horn (reverse Horn) DNF positive (negative) CNF (Proposition 5)
negative (positive) DNF reverse Horn (Horn) CNF (Proposition 5).
Moreover, even guarantee efficiency general case presentation
algorithm depend syntactic form , uses standard
operations Boolean functions (projection, conjunction, negation).
7

fiBruno Zanuttini

Another interesting feature algorithm minimization computes
explanations intentionnally. Consequently, full explanations enumerated
roughly delay models formula representing (0 ). However,
course, guarantee two would minimized
best explanation, prevents concluding algorithm enumerate
best explanations; trying extend direction would interesting problem.
details enumeration refer reader Eiter Makinos work (Eiter
& Makino, 2002).
identified Selman Levesque (1990), central task notion projection set variables, algorithm isolates subtask. However, notion
projection concerns variables, literals, prevents imposing sign
literals hypotheses formed upon, contrariwise general formalizations
proposed abduction, Marquis (Marquis, 2000). Even think prohibiting restriction, would interesting try fix weakness algorithm
preserving polynomial classes.
Another problem interest behaviour algorithm
propositional formulas, generally multivalued theories, domain
variables restricted {0, 1}: e.g., signed formulas (Beckert et al., 1999).
framework used, instance, configuration problems Amilhastre et al. (2002).
easily seen algorithm still correct framework; however, still left
study cases running time polynomial.
Finally, problems great interest deciding relevance necessity
abducible (Eiter & Gottlob, 1995). abducible x said relevant abduction
problem least one best explanation containing x x, necessary
best explanations contain x x. easily seen x necessary
= (, , A) 0 = (, , A\{x}) explanation, hence showing
polynomial restrictions search explanations polynomial well deciding
necessity hypothesis soon stable substitution A\{x}
A, case restrictions considered note. Contrastingly,
know relation relevance, study problem would
great interest.

Acknowledgments
author wishes thank anonymous referees version previous
one (Proc. JNPC02, French), well Jean-Jacques Hebrard, valuable
constructive comments.

References
Amilhastre, J., Fargier, H., & Marquis, P. (2002). Consistency restoration explanations
dynamic CSPs application configuration. Artificial Intelligence, 135 (12),
199234.
8

fiLogic-Based Abduction

Beckert, B., Hahnle, R., & Manya, F. (1999). Transformations signed classical clause logic. Proc. 29th International Symposium Multiple-Valued Logics
(ISMVL99), pp. 248255. IEEE Computer Society Press.
Bylander, T., Allemang, D., Tanner, M., & Josephson, J. (1989). results concerning
computational complexity abduction. Proc. 1st International Conference
Principles Knowledge Representation Reasoning (KR89), pp. 4454. Morgan
Kaufmann.
Coste-Marquis, S., & Marquis, P. (1998). Characterizing consistency-based diagnoses.
Proc. 5th International Symposium Artificial Intelligence Mathematics
(AIMATH98).
Curtis, C. (1984). Linear algebra. introductory approach. Springer Verlag.
del Val, A. (2000). complexity restricted consequence finding abduction.
Proc. 17th National Conference Artificial Intelligence (AAAI00), pp. 337342.
AAAI Press/MIT Press.
Eiter, T., & Gottlob, G. (1995). complexity logic-based abduction. Journal
ACM, 42 (1), 342.
Eiter, T., & Makino, K. (2002). computing abductive explanations. Proc. 18th
National Conference Artificial Intelligence (AAAI02), pp. 6267. AAAI Press.
Eshghi, K. (1993). tractable class abduction problems. Proc. 13th International
Joint Conference Artificial Intelligence (IJCAI93), pp. 38. Morgan Kaufmann.
Goebel, R. (1997). Abduction relation constrained induction. Proc. IJCAI97
workshop abduction induction AI.
Hobbs, J., Stickel, M., Appelt, D., & Martin, P. (1993). Interpretation abduction. Artificial Intelligence, 63, 69142.
Kavvadias, D., & Sideri, M. (1998). inverse satisfiability problem. SIAM Journal
Computing, 28 (1), 152163.
Khardon, R., & Roth, D. (1996). Reasoning models. Artificial Intelligence, 87, 187213.
Lang, J., Liberatore, P., & Marquis, P. (2002). Conditional independence propositional
logic. Artificial Intelligence, 141, 79121.
Marquis, P. (2000). Consequence finding algorithms. Handbook Defeasible Reasoning
Uncertainty Management Systems (DRUMS), Vol. 5, pp. 41145. Kluwer Academic.
Reiter, R., & de Kleer, J. (1987). Foundations assumption-based truth maintenance systems: preliminary report. Proc. 6th National Conference Artificial Intelligence
(AAAI87), pp. 183188. AAAI Press/MIT Press.
Schaefer, T. (1978). complexity satisfiability problems. Proc. 10th Annual ACM
Symposium Theory Computing (STOC78), pp. 216226. ACM Press.
Selman, B., & Levesque, H. (1990). Abductive default reasoning: computational core.
Proc. 8th National Conference Artificial Intelligence (AAAI90), pp. 343348.
AAAI Press.
9

fiBruno Zanuttini

Stumptner, M., & Wotawa, F. (2001). Diagnosing tree-structured systems. Artificial Intelligence, 127, 129.
Zanuttini, B. (2002). Approximating propositional knowledge affine formulas.
Proc. 15th European Conference Artificial Intelligence (ECAI02), pp. 287291.
IOS Press.
Zanuttini, B. (2003). New polynomial classes logic-based abduction. Tech. rep., Universite de Caen, France.

10


