journal artificial intelligence

submitted published

efficient solution factored mdps
carlos guestrin

guestrin cs stanford edu

computer science dept stanford university

daphne koller

koller cs stanford edu

computer science dept stanford university

ronald parr

parr cs duke edu

computer science dept duke university

shobha venkataraman

shobha cs cmu edu

computer science dept carnegie mellon university

abstract
addresses uncertainty large markov decision
processes mdps factored mdps represent complex state space state variables
transition model dynamic bayesian network representation often allows
exponential reduction representation size structured mdps complexity exact
solution mdps grow exponentially representation size
present two approximate solution exploit structure factored mdps
use approximate value function represented linear combination basis functions
basis function involves small subset domain variables key contribution
shows basic operations performed efficiently
closed form exploiting additive context specific structure factored mdp
central element novel linear program decomposition technique analogous
variable elimination bayesian networks reduces exponentially large lp provably
equivalent polynomial sized one one uses approximate linear programming
second approximate dynamic programming dynamic programming novel
uses approximation max norm technique directly minimizes terms
appear error bounds approximate mdp provide experimental
states demonstrating promising indication scalability
compare existing state art showing
exponential gains computation time

introduction
last years markov decision processes mdps used basic
semantics optimal decision theoretic agents stochastic environments
mdp framework system modeled via set states evolve stochastically
main representation virtually real life domain
state space quite large however many large mdps significant internal structure
modeled compactly structure exploited representation
factored mdps boutilier dearden goldszmidt one representing large structured mdps compactly framework state implicitly described
assignment set state variables dynamic bayesian network dbn dean
kanazawa allow compact representation transition model
exploiting fact transition variable often depends small number
c

ai access foundation morgan kaufmann publishers rights reserved

figuestrin koller parr venkataraman

variables furthermore momentary rewards often decomposed
sum rewards related individual variables small clusters variables
two main types structure simultaneously exploited factored
mdps additive context specific structure additive structure captures fact
typical large scale systems often decomposed combination locally interacting components example consider management large factory many
production cells course long run cell positioned early production line
generates faulty parts whole factory may affected however quality
parts cell generates depends directly state cell quality
parts receives neighboring cells additive structure present
reward function example cost running factory depends among things
sum costs maintaining local cell
context specific structure encodes different type locality influence although
part large system may general influenced state every part
system given point time small number parts may influence directly
factory example cell responsible anodization may receive parts directly
cell factory however work order cylindrical part may restrict
dependency cells lathe thus context producing cylindrical
parts quality anodized parts depends directly state cells
lathe
even large mdp represented compactly example factored
representation solving exactly may still intractable typical exact mdp solution require manipulation value function whose representation linear
number states exponential number state variables one
approximate solution approximate value function compact representation common choice use linear value functions approximation value
functions linear combination potentially non linear basis functions bellman
kalaba kotkin sutton tsitsiklis van roy b work builds
ideas koller parr factored linear value functions
basis function restricted small subset domain variables
presents two computing linear value function approximations factored mdps one uses approximate dynamic programming another
uses approximate linear programming use factored linear value functions highly expressive function approximation method
representation allows take advantage additive context specific
structure order produce high quality approximate solutions efficiently capability exploit types structure distinguishes differ earlier
approaches boutilier et al exploit context specific structure provide
detailed discussion differences section
factored mdp factored value functions critical operations implemented closed form without necessarily
enumerating entire state space particular build upon
novel linear programming decomposition technique technique reduces structured lps
exponentially many constraints equivalent polynomially sized ones decomposition follows procedure analogous variable elimination applies additively


fiefficient solution factored mdps

structured value functions bertele brioschi value functions exploit context specific structure zhang poole basic operations
implemented efficiently even though size state space
grows exponentially number variables
first method approximate linear programming schweitzer
seidmann generates linear approximate value function
solving single linear program unfortunately number constraints lp proposed
schweitzer seidmann grows exponentially number variables lp
decomposition technique exploit structure factored mdps represent exactly
optimization exponentially fewer constraints
terms approximate dynamic programming makes twofold contribution
first provide approximately solving mdps linear value
function previous approaches linear function approximation typically utilized
least squares l norm approximation value function least squares approximations
incompatible convergence analyses mdps max norm
provide first mdp solution value iteration policy iteration
use linear max norm projection approximate value function thereby directly
optimizing quantity appears provided error bounds second
exploit structure apply technique factored mdps
leveraging lp decomposition technique
although approximate dynamic programming currently possesses stronger theoretical
guarantees experimental suggest approximate linear programming
good alternative whereas former tends generate better policies set
basis functions due simplicity computational advantages approximate linear
programming add basis functions obtaining better policy still requiring
less computation approximate dynamic programming
finally present experimental comparing work boutilier
et al illustrating tradeoffs two methods particular
significant context specific structure value function
faster due efficient handling value function representation however
cases significant context specific structure rather
value function requires exponentially large value function
representation classes demonstrate value function exploits additive context specific structure obtain
polynomial time near optimal approximation true value function
starts presentation factored mdps approximate solution mdps section describe basic operations used
including lp decomposition technique section present first two
approximate linear programming factored mdps second
approximate policy iteration max norm projection presented section
section describes efficiently computing bounds policy quality
bellman error section shows extend methods deal context specific
structure concludes empirical evaluation section discussion
related work section


figuestrin koller parr venkataraman

greatly expanded version work published guestrin
et al work presented guestrin et al b

factored markov decision processes
markov decision process mdp mathematical framework sequential decision
stochastic domains thus provides underlying semantics task
uncertainty begin concise overview mdp framework
describe representation factored mdps
markov decision processes
briefly review mdp framework referring reader books bertsekas
tsitsiklis puterman depth review markov decision process
mdp defined tuple x r p x finite set x n states
finite set actions r reward function r x r r x represents
reward obtained agent state x taking action p markovian
transition model p x x represents probability going state x state
x action assume rewards bounded exists rmax
rmax r x x
example consider optimizing behavior system administrator
sysadmin maintaining network computers network machine
connected subset machines possible network topologies
defined manner see figure examples one simple network might
connect machines ring machine connected machines
example assume addition subtraction performed modulo
machine associated binary random variable xi representing whether
working failed every time step sysadmin receives certain amount
money reward working machine job sysadmin decide
machine reboot thus possible actions time step reboot one
machines nothing one machine rebooted per time step machine
rebooted working high probability next time step every machine
small probability failing time step however neighboring machine fails
probability increases dramatically failure probabilities define transition model
p x x x particular assignment describing machines working
failed current time step sysadmins choice machine reboot x
resulting state next time step
assume mdp infinite horizon future rewards discounted
exponentially discount factor stationary policy mdp
mapping x x action agent takes state x computer
network possible configuration working failing machines policy
would tell sysadmin machine reboot policy associated value
function v rn v x discounted cumulative value agent gets
starts state x follows policy precisely value v state x


fiefficient solution factored mdps

server

server

star

bidirectional ring

ring star

server

legs

ring rings

figure network topologies tested status machine influence status
parent network

policy given
v x e


x









r x x







x x


x random variable representing state system steps
running example value function represents much money sysadmin expects
collect starts acting according network state x value function
fixed policy fixed point set linear equations define value
state terms value possible successor states formally define
definition dp operator stationary policy
v x r x x

x

p x x x v x

x

value function policy v fixed point operator v v
optimal value function v describes optimal value agent achieve
starting state v defined set non linear equations case
value state must maximal expected value achievable policy starting
state precisely define
definition bellman operator
v x max r x


x

p x x v x

x

optimal value function v fixed point v v
value function v define policy obtained acting greedily relative
v words state agent takes action maximizes one step


figuestrin koller parr venkataraman

utility assuming v represents long term utility achieved next state
precisely define
greedy v x arg max r x


x

p x x v x



x

greedy policy relative optimal value function v optimal policy
greedy v
factored mdps
factored mdps representation language allows us exploit structure
represent exponentially large mdps compactly idea representing large
mdp factored model first proposed boutilier et al
factored mdp set states described via set random variables x
x xn xi takes values finite domain dom xi state x
defines value xi dom xi variable xi general use upper case letters
e g x denote random variables lower case e g x denote values
use boldface denote vectors variables e g x values x instantiation
dom subset variables z use z denote value
variables z instantiation
factored mdp define state transition model dynamic bayesian
network dbn dean kanazawa let xi denote variable xi current
time xi variable next step transition graph dbn
two layer directed acyclic graph g whose nodes x xn x xn denote
parents xi graph parents xi simplicity exposition assume
parents xi x thus arcs dbn variables consecutive
time slices assumption used expository purposes intra time slice arcs
handled small modification presented section node xi associated
conditional probability distribution cpd p xi parents xi transition
probability p x x defined
p x x



p x ui



ui value x variables parents xi
example consider instance sysadmin four computers labelled
unidirectional ring topology shown figure first task
modeling factored mdp define state space x machine
associated binary random variable xi representing whether working
failed thus state space represented four random variables x x x x
next task define transition model represented dbn parents
next time step variables xi depend network topology specifically probability
machine fail next time step depends whether working current
time step status direct neighbors parents topology network
current time step shown figure b parents xi example xi
xi cpd xi xi false xi false high probability


fiefficient solution factored mdps

x

x
r

x



r











x
r

x
r





p xi xi xi
h


h



x

x
h



x
h



b

action reboot
machine machine



xi
xi
xi
xi
xi
xi
xi
xi

f
f
f


f
























c

figure factored mdp example network topology obtain factored
mdp representation b cpds described c

failures tend persist xi true xi noisy parents
unidirectional ring topology xi one parent xi failure
neighbors independently cause machine fail
described represent factored markovian transition dynamics arising
mdp dbn directly addressed representation actions
generally define transition dynamics mdp defining separate dbn
model hga pa action
example system administrator example action ai rebooting
one machines default action nothing transition model
described corresponds nothing action transition model ai
different transition model variable xi xi true
probability one regardless status neighboring machines figure c shows
actual cpd p xi w orking xi xi one entry assignment
state variables xi xi action
fully specify mdp need provide compact representation reward
function assume reward function factored additively set localized
reward functions depends small set variables example
might reward function associated machine depends xi
sysadmin paid per machine basis every time step receives money
machine working formalize concept localized functions
definition function f scope scope f c x f dom c r
f scope z use f z shorthand f part
instantiation z corresponds variables


figuestrin koller parr venkataraman

characterize concept local rewards let r rra set
functions scope ria restricted variable cluster uai x xn
p
reward taking action state x defined ra x ri ria uai r
example reward function ri associated machine depends
xi depend action choice local rewards represented
diamonds figure b usual notation influence diagrams howard
matheson

approximate solution
several compute optimal policy mdp three
commonly used value iteration policy iteration linear programming key component three computation value functions defined section
recall value function defines value state x state space
explicit representation value function vector values different states
solution implemented series simple algebraic steps thus
case three implemented efficiently
unfortunately case factored mdps state space exponential number
variables domain sysadmin example state x system
assignment describing machines working failed state x
assignment random variable xi thus number states exponential
number machines network x n hence even representing
explicit value function ten machines infeasible one
might tempted believe factored transition dynamics rewards would
factored value function thereby represented compactly unfortunately even
trivial factored mdps guarantee structure model preserved
value function koller parr
section discuss use approximate value function admits
compact representation describe approximate versions exact
use approximate value functions description section somewhat abstract
specify basic operations required performed
explicitly later sections elaborate issues describe
detail brevity choose focus policy iteration linear programming
techniques easily extend value iteration
linear value functions
popular choice approximating value functions linear regression first
proposed bellman et al define space allowable value functions
v h rn via set basis functions
definition linear value function set basis functions h h hk
p
function v written v x kj wj hj x coefficients w
w wk
define h linear subspace rn spanned basis functions h
useful define n k matrix h whose columns k basis functions viewed


fiefficient solution factored mdps

vectors compact notation approximate value function represented
hw
expressive power linear representation equivalent example
single layer neural network features corresponding basis functions defining
h features defined must optimize coefficients w order obtain
good approximation true value function view separating
defining reasonable space features induced space h
searching within space former typically purview
domain experts latter focus analysis algorithmic design clearly
feature selection important issue essentially areas learning approximation
offer simple methods selecting good features mdps section
goal address large important topic
chosen linear value function representation set basis functions
becomes one finding values weights w hw yield
good approximation true value function consider two
approaches approximate dynamic programming policy iteration approximate
linear programming section present two approaches section
exploit structure transform approaches practical
deal exponentially large state spaces
policy iteration
exact
exact policy iteration iterates policies producing improved policy
iteration starting initial policy iteration consists two phases
value determination computes policy value function v finding
fixed point equation v v unique solution set linear
equations
x
p x x x v x x
v x r x x
x

policy improvement step defines next policy
greedy v
shown process converges optimal policy bertsekas tsitsiklis
furthermore practice convergence optimal policy often quick
approximate policy iteration
steps policy iteration require manipulation value functions
policies often cannot represented explicitly large mdps define
version policy iteration uses approximate value functions use
following basic idea restrict value functions within
provided h whenever takes step value function v
outside space project back space finding value function
within space closest v precisely


figuestrin koller parr venkataraman

definition projection operator mapping rn h said
projection w r norm kk v hw w arg minw khw vk
v linear combination basis functions closest v respect
chosen norm
approximate policy iteration performs policy improvement step exactly value determination step value function value acting according
current policy approximated linear combination basis functions
consider value determination policy point
useful introduce notation although rewards function state
action choice policy fixed rewards become function state
denote r r x r x x similarly transition
model p x x p x x x rewrite value determination step
terms matrices vectors view v r n vectors p
n n matrix equations
v r p v
system linear equations one equation state
solved exactly relatively small n goal provide approximate solution within
h precisely want
w arg min khw r p hw k
w







arg min h p h w r
w

thus approximate policy iteration alternates two steps
w arg min khw r p hw k
w

greedy hw




max norm projection
along lines described used papers several
recent theoretical algorithmic schweitzer seidmann tsitsiklis van
roy b van roy koller parr however approaches suffer
might call norm incompatibility computing projection
utilize standard euclidean projection operator respect l norm
weighted l norm hand convergence error analyses mdp
utilize max norm l incompatibility made difficult provide
error guarantees
tie projection operator closely error bounds use
projection operator l norm minimizing l norm
studied optimization literature finding chebyshev solution
weighted l norm projections stable meaningful error bounds weights correspond
stationary distribution fixed policy evaluation value determination van roy
stable combined averagers gordon stable non expansive
l require mixture weights determined priori thus general
minimize l error
chebyshev norm referred max supremum l norms minimax solution



fiefficient solution factored mdps

overdetermined linear system equations cheney defined
finding w
w arg min kcw bk

w

use due stiefel solves linear programming
variables w wk
minimize
p

subject kj cij wj bi
pk
bi j cij wj n



p


constraints linear program imply kj cij wj bi
equivalently kcw bk objective lp minimize thus
solution w linear program w solution equation l
projection error
use l projection context approximate policy iteration
obvious way implementing projection operation equation use
l projection equation c h p h b r
minimization solved linear program
key point lp k variables however n constraints
makes impractical large state spaces sysadmin example
number constraints lp exponential number machines network
total constraints machines section factored mdps
linear value functions n constraints represented efficiently leading
tractable
error analysis
motivated use max norm projection within approximate policy iteration
via compatibility standard error analysis techniques mdp
provide careful analysis impact l error introduced projection step analysis provides motivation use projection step directly
minimizes quantity acknowledge however main impact analysis
motivational practice cannot provide priori guarantees l projection
outperform methods
goal analyze approximate policy iteration terms amount error
introduced step projection operation error zero
performing exact value determination error accrue error small
get approximation accurate follows analysis
precisely define projection error error resulting approximate
value determination step








hw r p hw


note max norm projection finding set weights w
exactly minimizes one step projection error choosing best


figuestrin koller parr venkataraman

possible weights respect error measure furthermore exactly error
measure going appear bounds theorem thus make
bounds step tight possible
first projection error accrued step bounded
lemma value determination error bounded exists constant p rmax
p iterations
proof see appendix
due contraction property bellman operator overall accumulated error
decaying average projection error incurred throughout iterations
definition discounted value determination error iteration defined









lemma implies accumulated error remains bounded approximate policy


iteration p
bound loss incurred acting according
policy generated approximate policy iteration opposed
optimal policy
theorem approximate policy iteration let policy generated
iteration furthermore let v actual value acting according policy
loss incurred policy opposed optimal policy value v
bounded





kv v k kv v k



proof see appendix
words equation shows difference approximation iteration
optimal value function bounded sum two terms first term
present standard policy iteration goes zero exponentially fast second
discounted accumulated projection error lemma shows bounded second
term minimized choosing w one minimizes





hw r p hw





exactly computation performed max norm projection therefore
theorem motivates use max norm projections minimize error term appears
bound
bounds provided far may seem fairly trivial provided
strong priori bound fortunately several factors make bounds interesting despite lack priori guarantees approximate policy iteration converges
b policy
occurred experiments obtain much tighter bound
convergence



v v b

b


b one step max norm projection error associated estimating value
b since max norm projection operation provides b

easily obtain


fiefficient solution factored mdps

posteriori bound part policy iteration procedure details provided
section
one could rewrite bound theorem terms worst case projection error p worst projection error cycle policies approximate policy iteration
gets stuck cycle formulations would closer analysis bertsekas
tsitsiklis proposition p however consider case policies
policies final cycle low projection error policies
cannot approximated well projection operation large
one step projection error worst case bound would loose would
dictated error difficult policy approximate hand
discounted accumulated error formulation errors introduced policies hard
approximate decay rapidly thus error bound represents average case
analysis decaying average projection errors policies encountered successive iterations convergent case bound computed
easily part policy iteration procedure max norm projection used
practical benefit posteriori bounds give meaningful feedback
impact choice value function approximation architecture
explicitly addressing difficult general feature selection
error bounds motivate aim minimize error given approximation
architecture provide feedback could useful future efforts automatically
discover improve approximation architectures
approximate linear programming
exact
linear programming provides alternative method solving mdps formulates
finding value function linear program lp lp variables
v vn vi represents v xi value starting ith state system
lp given
variables v vn
p
minimize
xi xi vi
p
subject vi r xi j p xj xi vj xi x



state relevance weights positive note exact case solution
obtained positive weight vector interesting note steps
simplex correspond policy changes single states steps policy
iteration involve policy changes multiple states practice policy iteration tends
faster linear programming puterman
approximate linear program
approximate formulation lp first proposed schweitzer seidmann restricts space allowable value functions linear space spanned
basis functions approximate formulation variables w wk
weights basis functions lp given


figuestrin koller parr venkataraman

variables w wk
p
p
minimize
x wi hi x
px
p
p


subject
wi hi x r x
x p x x
wi hi x x x

words formulation takes lp substitutes explicit state
p
value function linear value function representation wi hi x compact
notation v replaced hw linear program guaranteed feasible constant
function function constant value states included set
basis functions
approximate linear programming formulation choice state relevance weights
becomes important intuitively constraints lp binding
constraints tighter states others state x relevance
weight x indicates relative importance tight constraint therefore unlike
exact case solution obtained may differ different choices positive weight vector
furthermore general guarantee quality greedy policy
generated approximation hw however recent work de farias van
roy provides analysis error relative best possible approximation subspace guidance selecting improve quality
approximation particular analysis shows lp provides best
approximation hw optimal value function v weighted l sense subject
constraint hw hw weights l norm state relevance
weights
transformation exact approximate formulation effect reducing number free variables lp k one basis function
coefficient number constraints remains n sysadmin
example number constraints lp number
machines network thus process generating constraints solving
lp still seems unmanageable machines next section discuss
use structure factored mdp provide compact representation
efficient solution lp

factored value functions
linear value function described section apply
choice basis functions context factored mdps koller parr suggest
particular type basis function particularly compatible structure
factored mdp suggest although value function typically structured
many cases might close structured might wellapproximated linear combination functions refers small
number variables precisely define
definition factored linear value function linear function basis set
h hk scope hi restricted subset variables ci
value functions type long history area multi attribute utility theory keeney raiffa example might basis function hi


fiefficient solution factored mdps

machine indicating whether working basis function scope restricted
xi represented diamonds next time step figure b
factored value functions provide key performing efficient computations
exponential sized state spaces factored mdps main insight restricted scope functions including basis functions allow certain basic operations
implemented efficiently remainder section structure
factored mdps exploited perform two crucial operations efficiently one step
lookahead backprojection representation exponentially many constraints
lps use basic building blocks formulate efficient approximation factored mdps presented self contained section
approximate linear programming factored mdps section approximate policy
iteration max norm projection section
one step lookahead
key step computation one step lookahead value
action necessary example computing greedy policy
equation lets consider computation q function qa x represents
expected value agent obtains taking action current time step receiving
long term value v thereafter q function computed
qa x r x

x

p x x v x



x

qa x given current reward plus discounted expected future value
notation express greedy policy greedy v x maxa qa x
recall estimating long term value policy set basis
p
functions v x wi hi x thus rewrite equation
qa x r x

x

p x x

x

x

wi hi x





p

size state space exponential computing expectation x p x
p
x wi hi x seems infeasible fortunately discussed koller parr
expectation operation backprojection performed efficiently transition
model value function factored appropriately linearity value
function permits linear decomposition summand expectation
viewed independent value function updated manner similar value
iteration procedure used boutilier et al recap construction briefly
first defining
ga x

x
x

p x x

x

wi hi x



x


wi

x

p x x hi x

x

thus compute expectation basis function separately
gia x

x

p x x hi x

x



figuestrin koller parr venkataraman

p

weight wi obtain total expectation ga x wi gia x
intermediate function gia called backprojection basis function hi
transition model pa denote gia pa hi note factored mdps
transition model pa factored represented dbn basis functions hi
scope restricted small set variables two important properties allow us
compute backprojections efficiently
restricted scope function h basis functions
backprojected transition model p represented dbn
h scope restricted goal compute g p h define backprojected scope set parents transition graph g
yi parents yi intra time slice arcs included parents xi
x xn x xn change definition backprojected scope definition includes direct parents
variables x xn ancestors
xj exist directed path xj xi
thus backprojected scope may become larger functions still factored
h scope restricted backprojection g
scope restricted parents e furthermore backprojection
computed enumerating settings variables rather settings
variables x
g x p h x


x

p x x h x

x



x

p x x h

x



x




x

x

p x h

p u x

u x

p z h



g z
p

z value x term u x p u x
sum probability distribution complete domain therefore see p h
function whose scope restricted note cost computation depends
linearly dom depends scope h complexity
process dynamics backprojection procedure summarized figure
returning example consider basis function hi indicator variable xi
takes value ith machine working otherwise hi scope restricted
xi thus backprojection gi scope restricted parents xi xi xi xi
representing exponentially many constraints
seen section approximation require solution linear programs lp approximate policy iteration lp approximate


fiefficient solution factored mdps

backproja h

basis function h scope c

define scope backprojection c xi c parentsa xi

assignment
p
q c

g c c x c pa c xi h c


return g

figure backprojection basis function h
linear programming lps common characteristics
small number free variables k basis functions k free variables approximate policy iteration k approximate linear programming number
constraints still exponential number state variables however factored mdps
lp constraints another useful property functionals constraints
restricted scope key observation allows us represent constraints
compactly
first observe constraints linear programs form


x

wi ci x b x x





w wk free variables lp x ranges states
general form represents type constraint max norm projection lp
approximate linear programming formulation
first insight construction replace entire set constraints
equation one equivalent non linear constraint
max
x

x

wi ci x b x





second insight non linear constraint implemented set
linear constraints construction follows structure variable elimination
cost networks insight allows us exploit structure factored mdps represent
constraint compactly
tackle representing constraint equation two steps
first computing maximum assignment fixed set weights representing
non linear constraint small set linear constraints construction call
factored lp
maximizing state space
key computation represent non linear constraint form
equation efficiently small set linear constraints presenting construction lets first consider simpler given fixed weights wi would
p
compute maximization maxx wi ci x b x state x
p

complementary constraints b x wi ci x formulated analogous
construction one present section changing sign ci x b x approximate
linear programming constraints formulated form section



figuestrin koller parr venkataraman

p

difference wi ci x b x maximal however cannot explicitly enumerate exponential number states compute difference fortunately
structure factored mdps allows us compute maximum efficiently
case factored mdps state space set vectors x assignments state variables x x xn view cw b functions
state variables hence difference thus define function
p
f w x xn f w x wi ci x b x note executed
representation shift viewing f w function variables x parameterized w recall size state space exponential number
variables hence goal section compute maxx f w x without explicitly
considering exponentially many states solution use fact f w
p
factored representation precisely cw form wi ci zi zi
subset x example might c x x takes value states
x true x false otherwise similarly vector b case sum
p
restricted scope functions thus express f w sum j fjw zj fjw may
may depend w future sometimes drop superscript w
clear context
p
compact notation goal simply compute maxx wi ci x
b x maxx f w x state x f w maximized recall
p
w
fw
j fj zj maximize function f without enumerating every state
non serial dynamic programming bertele brioschi idea virtually
identical variable elimination bayesian network review construction
central component solution lp
goal compute
x
max
fj x zj
x xn

j

main idea rather summing functions maximization
maximize variables one time maximizing xl summands
involving xl participate maximization
example assume
f f x x f x x f x x f x x
therefore wish compute
max

x x x x

f x x f x x f x x f x x

first compute maximum x functions f f irrelevant
push get
max f x x f x x max f x x f x x

x x x

x

internal maximization depends values x x thus introduce function e x x whose value point x x value internal
max expression reduces computing
max f x x f x x e x x

x x x



fiefficient solution factored mdps

variableelimination f
f f fm set functions maximized
stores elimination order

number variables
select next variable eliminated

let l
select relevant functions

let e el functions f whose scope contains xl
maximize current variable xl

define function e maxxl
l
j scope ej xl

pl

j ej

note scope e

update set functions

update set functions f f e e el
functions empty scope
p sum maximum value f fm

return maximum value

ei f

ei

figure variable elimination procedure computing maximum value f fm
restricted scope function

one fewer variable next eliminate another variable say x resulting
expression reducing
max f x x e x x
x x



e x x max f x x e x x
x

finally define
e max f x x e x x
x x

point number desired maximum x x
naive enumerating states requires arithmetic operations variables
binary variable elimination need perform operations
general variable elimination described figure inputs
functions maximized f f fm elimination
ordering variables returns ith variable eliminated
example variable xl eliminated select relevant functions
e el whose scope contains xl functions removed set f
p
introduce function e maxxl l
j ej point scope functions
f longer depends xl xl eliminated procedure repeated
variables eliminated remaining functions f thus empty
scope desired maximum therefore given sum remaining functions
computational cost linear number function
values introduced elimination process precisely consider computation
function e whose scope z compute function need compute dom z
different values cost linear overall number values
introduced throughout execution shown dechter cost exponential


figuestrin koller parr venkataraman

induced width cost network undirected graph defined variables
x xn edge xl xm appear together one original
functions fj complexity course dependent variable
elimination order structure computing optimal elimination order
np hard arnborg corneil proskurowski elimination orders
yielding low induced tree width exist issues
confronted successfully large variety practical bayesian network
community benefited large variety good heuristics
developed variable elimination ordering bertele brioschi kjaerulff
reed becker geiger
factored lp
section present centerpiece general
compactly representing exponentially large sets lp constraints
factored structure functions constraints decomposed
sum restricted scope functions consider original representing
non linear constraint equation compactly recall wish represent
p
non linear constraint maxx wi ci x b x equivalently maxx f w x
without generating one constraint state equation key insight
non linear constraint implemented construction follows
structure variable elimination cost networks
consider function e used within f including original let z scope
assignment z z introduce variable uez whose value represents ez
linear program initial functions fiw include constraint ufzi fiw z
fiw linear w constraint linear lp variables consider function
e introduced f eliminating variable xl let e el functions extracted
f let z scope resulting e introduce set constraints
uez



l
x
ej
j

u z xl zj

xl



let en last function generated elimination recall scope empty
hence single variable uen introduce additional constraint uen
complete presented figure divided three parts first
generate equality constraints functions depend weights wi basis functions
second part add equality constraints functions depend
weights target functions equality constraints let us abstract away differences
two types functions manage unified fashion third
part third part follows procedure similar variable elimination
described figure however unlike standard variable elimination would inp
troduce function e e maxxl l
j ej factored lp procedure
introduce lp variables uez enforce definition e maximum xl
pl
j ej introduce lp constraints equation
example understand construction consider simple example
assume want express fact maxx f w x first introduce set


fiefficient solution factored mdps

factoredlp c b
c c ck set basis functions
b b bm set target functions
stores elimination order
p
p
return polynomial set constraints equivalent wi ci x j bj x x
data structure constraints factored lp

let
data structure intermediate functions generated variable elimination

let f
generate equality constraint abstract away basis functions

ci c
let z scope ci
assignment z z create lp variable ufzi add
constraint
ufzi wi ci z
store function use variable elimination step f f
generate equality constraint abstract away target functions

bj b
let z scope bj
f
assignment z z create lp variable uzj add
constraint
f
uzj bj z
store function fj use variable elimination step f f fj
f contains functions involved lp constraints become
p
e x x represent compactly variable elimination procedure
e f


number variables

select next variable eliminated

let l
select relevant functions

let e el functions f whose scope contains xl let
zj scope ej
introduce linear constraints maximum current variable xl

define function e scope z l
j zj xl represent
pl
maxxl j ej
add constraints enforce maximum assignment z z
uez

l
x

e

j
u z x
l zj

xl

j

update set functions

update set functions f f e e el
variables eliminated functions empty scope

add last constraint


x

ei

ei f

return

figure factored lp compact representation exponential set
p
p
constraints wi ci x j bj x x


figuestrin koller parr venkataraman

variables ufx x every instantiation values x x variables x x thus
x x binary four variables introduce constraint
defining value ufx x appropriately example f uft
uft f w similar variables constraints fj value z
zj note constraints simple equality constraint involving numerical
constants perhaps weight variables w
next introduce variables intermediate expressions generated variable elimination example eliminating x introduce set lp variables
uex x set constraints
uex x ufx x ufx x
one value x x similar set constraint uex x terms
ufx x uex x note constraint simple linear inequality
prove factored lp construction represents constraint
non linear constraint equation
theorem constraints generated factored lp construction equivalent
non linear constraint equation assignment w satisfies
factored lp constraints satisfies constraint equation
proof see appendix
p
returning original formulation j fjw cw b original
set constraints hence set constraints equivalent original set
p
maxx wi ci x b x equation turn equivalent exponential
p
set constraints wi ci x b x x equation thus represent
exponential set constraints set constraints lp variables size
set variable elimination exponential induced width cost
network rather total number variables
section presented general compactly representing exponentially large sets lp constraints factored structure remainder
exploit construction design efficient factored
mdps
factored max norm projection
use procedure representing exponential number constraints
equation compactly compute efficient max norm projections equation
w arg min kcw bk
w

max norm projection computed linear program two sets
p
p
constraints lp kj cij wj bi bi kj cij wj
sets instance constraints equation addressed
previous section thus k basis functions c restricted scope
function target function b sum restricted scope functions
use factored lp technique represent constraints max norm projection lp
compactly correctness corollary theorem


fiefficient solution factored mdps

corollary solution w linear program minimizes subject
constraints factoredlp c b factoredlp c b elimination
order satisfies
w arg min kcw bk
w



min kcw bk
w

original max norm projection lp k variables two constraints
state x thus number constraints exponential number state variables
hand factored max norm projection lp variables
exponentially fewer constraints number variables constraints factored
lp exponential number state variables largest factor cost
network rather exponential total number state variables
section exponential gain allows us compute max norm projections efficiently
solving large factored mdps

approximate linear programming
begin simplest approximate mdp solution
approximate linear programming formulation section basic operations
described section formulate simple efficient

discussed section approximate linear program formulation linear
programming solving mdps presented section however approximate version restrict space value functions linear space defined
basis functions precisely approximate lp formulation variables
w wk weights basis functions lp given
variables w wk
p
p
minimize
x wi hi x
x
p
p
p


subject
wi hi x r x
x p x x
wi hi x x x

words formulation takes lp substitutes explicit state value
p
function linear value function representation wi hi x transformation
exact approximate formulation effect reducing number
free variables lp k one basis function coefficient number
constraints remains x sysadmin example number
constraints lp number machines
network however representing exponentially large constraint sets
compactly able compute solution approximate linear programming
closed form exponentially smaller lp section
p
p
first consider objective function x x wi hi x lp naively
representing objective function requires summation exponentially large state
space however rewrite objective obtain compact representation
first reorder terms


figuestrin koller parr venkataraman

factoredalp p r h
p factored transition model
r set factored reward functions
discount factor
h set basis functions h h hk
stores elimination order
state relevance weights
return basis function weights w computed approximate linear programming
cache backprojections basis functions

basis function hi h action
let gia backproja hi
compute factored state relevance weights

basis function hi compute factored state relevance weights
equation
generate approximate linear programming constraints

let
action
ra
let factoredlp g h gka hkp

p

far constraints guarantee r x x p x x wi hi x
p
w hi x satisfy approximate linear programming solution must add

final constraint

let
obtain solution weights solving lp

let w solution linear program minimize
constraints
return w

p


wi subject

figure factored approximate linear programming



fiefficient solution factored mdps

x

x

x

x

wi hi x

x



x

wi

x hi x

x



consider state relevance weights x distribution states x
p
x x backprojections write


x

x

x hi x

x

ci hi ci



ci ci

ci represents marginal state relevance weights domain
dom ci basis function hi example use uniform state relevance weights

experiments x x
marginals become ci c thus
p
rewrite objective function wi basis weight computed shown
equation state relevance weights represented marginals cost
computing depends exponentially size scope ci rather
exponentially number state variables hand state relevance
weights represented arbitrary distributions need obtain marginals
ci may efficient computation thus greatest efficiency achieved
compact representation bayesian network state relevance weights
second note right side constraints lp correspond qa
functions
x
x
qa x ra x
p x x
wi hi x
x



efficient backprojection operation factored mdps described section
rewrite qa functions
qa x ra x

x

wi gia x



gia


backprojection basis function hi transition model pa
discussed hi scope restricted ci gia restricted scope function c
precompute backprojections gia basis relevance weights
approximate linear programming lp written
variables w wk
p
minimize
w
pi
p


subject
w
hi x r x
wi gi x x x



finally rewrite lp use constraints form one equation
variables w wk
p
minimize
wi
p
subject maxx ra x wi gia x hi x



use factored lp construction section represent non linear
constraints compactly basically one set factored lp constraints action
specifically write non linear constraint form equation expressing functions c ci x hi x gia x ci x restricted


figuestrin koller parr venkataraman

scope function hi x scope restricted ci gia x scope restricted
c means ci x scope restricted ci c next target
function b becomes reward function ra x assumption factored finally
constraint equation free variable hand lp
maximum right hand side must less zero final condition
achieved adding constraint thus generates set factored
lp constraints one action total number constraints variables
lp linear number actions exponential induced width
cost network rather total number variables complete factored
approximate linear programming outlined figure
example
present complete example operations required approximate lp solve factored mdp shown figure presentation follows four steps
representation basis function selection backprojections lp construction
representation first must fully specify factored mdp model
structure dbn shown figure b structure maintained
action choices next must define transition probabilities action
actions nothing reboot one machines
network cpds actions shown figure c finally must define
reward function decompose global reward sum local reward functions
one machine reward machine working specifically
ri xi true ri xi false breaking symmetry setting r x true
use discount factor
simple example use five simple basis functions
basis function selection
first include constant function h next add indicators machine
take value machine working hi xi true hi xi false
backprojections
first algorithmic step computing backprojection
basis functions defined section backprojection constant basis
simple
g

x

pa x x h

x



x

pa x x

x


next must backproject indicator basis functions hi
gia

x
x



pa x x hi x

x



pa x j xj xj hi x

x x x x j



fiefficient solution factored mdps



x
x



x

x

pa x xi xi hi x



pa x j xj xj

x x xi j

pa x xi xi hi x

x

pa xi true xi xi pa xi false xi xi
pa xi true xi xi
thus gia restricted scope function xi xi use cpds figure c specify gia
reboot

xi xi

reboot

xi xi

gi

gi

xi true xi false
xi true



xi false


xi true
xi false

xi true xi false






lp construction
illustrate factored lps constructed
define constraints approximate linear programming presented
first define functions cai gia hi shown equation example
functions ca constant basis indicator bases
reboot

xi xi

reboot

xi xi

ci

ci

xi true xi false
xi true



xi false


xi true
xi false

xi true xi false






definition cai approximate linear programming constraints given
max
x

x

ri

x



wj caj



j

present lp construction one actions reboot analogous constructions
made actions
first set constraints abstract away difference rewards basis
functions introducing lp variables u equality constraints begin reward
functions
r

ur
x ux

r

ur
x ux

r

ur
x ux

r

ur
x ux

represent equality constraints caj functions reboot action note
appropriate basis function weight equation appears constraints



figuestrin koller parr venkataraman

uc w
ucx x w
ucx x w
ucx x w
ucx x w
c
c
c
ux x w ux x w ux x w ucx x w
ucx x w ucx x w ucx x w ucx x w
ucx x w ucx x w ucx x w ucx x w
lp variables lp constraint equation reboot action
becomes


max

x x x x



x
x
c
c

ur

u

uxjj xj
xi


j

ready variable elimination process illustrate elimination
variable x


max

x x x



h

x
x
c
ri
c
c
c

uxi u
uxjj xj max ur
x ux x ux x


x

j

h



c
c

represent term maxx ur
x ux x ux x set linear constraints
one assignment x x lp variables uex x represent
maximum

uex x

c
c

ur
x ux x ux x

uex x

c
c

ur
x ux x ux x

uex x

c
c

ur
x ux x ux x

uex x

c
c

ur
x ux x ux x

uex x

c
c

ur
x ux x ux x

uex x

c
c

ur
x ux x ux x

uex x

c
c

ur
x ux x ux x

uex x

c
c

ur
x ux x ux x

eliminated variable x global non linear constraint becomes




x
x
c
c

ur

u

uxjj xj uex x
xi
x x x

max

j



next eliminate variable x lp constraints variables form
c
e

uex x ur
x ux x ux x x x x

thus removing x global non linear constraint

x
c
e
c

ur
xi u ux x ux x
x x

max





fiefficient solution factored mdps



number lp constraints



explicit constraints
n n

explicit lp
factored lp






factored constraints
n n










number machines ring







figure number constraints lp generated explicit state representation
versus factored lp construction solution ring
basis functions single variables approximate linear programming
solution

eliminate x generating linear constraints
c
e

uex ur
x ux x ux x x x

global non linear constraint involves x
e
c

max ur
x u ux
x

x last variable eliminated scope lp variable empty
linear constraints given
e

u e u r
x ux x

state variables eliminated turning global non linear constraint
simple linear constraint
uc ue
completes lp description approximate linear programming solution
figure
small example four state variables factored lp technique generates
total equality constraints inequality constraints lp variables
explicit state representation equation generates inequality constraints
lp variables however size increases number constraints
lp variables factored lp grow n explicit state
grows exponentially n n scaling effect illustrated figure

approximate policy iteration max norm projection
factored approximate linear programming described previous section
elegant easy implement however cannot general provide strong


figuestrin koller parr venkataraman

guarantees error achieves alternative use approximate policy
iteration described section offer certain bounds error however
shall see significantly complicated requires place
additional restrictions factored mdp
particular approximate policy iteration requires representation policy
iteration order obtain compact policy representation must make additional
assumption action affects small number state variables first state
assumption formally obtain compact representation greedy
policy respect factored value function assumption finally describe
factored approximate policy iteration max norm projections
default action model
section presented factored mdp model action associated
factored transition model represented dbn factored reward
function however different actions often similar transition dynamics differing effect small set variables particular many cases variable
default evolution model changes action affects directly boutilier
et al
type structure turns useful compactly representing policies property important approximate policy iteration thus section
restrict attention factored mdps defined default transition model hgd pd koller parr action define effects x
variables next state whose local probability model different e
variables xi pa xi parentsa xi pd xi parentsd xi
example system administrator example action ai rebooting
one machines default action nothing transition model
described corresponds nothing action default transition
model transition model ai different transition model
variable xi xi true probability one regardless status
neighboring machines thus example effects ai xi
transition dynamics define notion default reward model
p
case set reward functions ri ri ui associated default action
addition action reward function ra ua extra reward
action scope restricted rewards uai x xn thus total reward
p
associated action given ra ri ri note ra factored
linear combination smaller terms even compact representation
build additional assumption define complete
recall approximate policy iteration iterates two steps policy
improvement approximate value determination discuss steps
computing greedy policies
policy improvement step computes greedy policy relative value function v
greedy v


fiefficient solution factored mdps

recall value function estimates linear form hw described
section greedy policy type value function given
greedy hw x arg max qa x


p

qa represented qa x r x wi gia x
attempt represent policy naively faced
exponentially large state spaces fortunately shown koller parr
greedy policy relative factored value function form decision list
precisely policy written form ht ht htl al ti
assignment values small subset ti variables ai action
greedy action take state x action aj corresponding first event tj
list x consistent completeness review construction
decision list policy
critical assumption allows us represent policy compact decision list
default action assumption described section assumption qa
functions written


qa x r x

r
x

ri x



x

wi gia x



ra scope restricted ua q function default action
p
p
qd x ri ri x wi gid x
set linear q functions implicitly describes policy
immediately obvious q functions compactly expressible policy
important insight components weighted combination
identical gia equal gid intuitively component gia corresponding
backprojection basis function hi ci different action influences
one variables ci formally assume effects ci case
variables ci transition model thus
gia x gid x words ith component qa function irrelevant
deciding whether action better default action define
components actually relevant let ia set indices effects ci
indices basis functions whose backprojection differs pa pd
example dbn figure actions basis functions involve single variables
iai
let us consider impact taking action default action
define impact difference value
x qa x qd x
ra x

x

h



wi gia x gid x



iia

analysis shows x function whose scope restricted




ta ua iia c




figuestrin koller parr venkataraman

decisionlistpolicy qa
qa set q functions one action
return decision list policy
initialize decision list

let
compute bonus functions

action default action
compute bonus taking action
x qa x qd x
equation note scope restricted ta
equation
add states positive bonuses unsorted decision list

assignment ta
add branch decision list
ht
add default action unsorted decision list

let h
sort decision list obtain final policy

sort decision list decreasing order element ht
return

figure method computing decision list policy factored representation
qa functions

example dbn ta x x
intuitively situation baseline value function qd x
defines value state x action changes baseline adding
subtracting amount state point amount depends ta
states variables ta take values
define greedy policy relative q functions action define
set conditionals ht assignment values variables ta
sort conditionals actions order decreasing
ht ht htl al l
consider optimal action state x would get largest possible bonus
default value x consistent clearly take action
gives us bonus try get thus check x
consistent take procedure compute decisionlist policy associated linear estimate value function complete
computing decision list policy summarized figure
p
note number conditionals list dom ta ta turn depends
set basis function clusters intersect effects thus size
policy depends natural way interaction structure


fiefficient solution factored mdps

process description structure basis functions actions
modify large number variables policy representation could become unwieldy
approximate linear programming section appropriate cases
require explicit representation policy
value determination
approximate value determination step computes
w arg min khw r p hw k
w

rearranging expression get
w arg min k h p h w r k
w

equation instance optimization equation p factored
conclude c h p h matrix whose columns correspond restrictedscope functions specifically


ci x hi x gi x


gi backprojection basis function hi transition model p
described section target b r corresponds reward function
moment assumed factored thus apply factored lp
section estimate value policy
unfortunately transition model p factored decision list representation policy general induce transition model p cannot
represented compact dbn nonetheless still generate compact lp exploiting decision list structure policy basic idea introduce cost networks
corresponding branch decision list ensuring additionally states
consistent branch considered cost network maximization specifically
factored lp construction branch hti ai ith cost network
considers subset states consistent ith branch decision list
let si set states x ti first event decision list x
consistent state x si x consistent ti consistent
tj j
recall equation lp construction defines set constraints
p
imply wi ci x b x state x instead separate set
constraints states subset si state si know action ai
taken hence apply construction pai transition model
factored assumption place non factored p similarly reward function
p
becomes rai x ri ri x subset states
issue guarantee cost network constraints derived transition model applied states si specifically must guarantee
applied states consistent ti states consistent
tj j guarantee first condition simply instantiate variables ti
take values specified ti cost network considers variables


figuestrin koller parr venkataraman

factoredapi p r h tmax
p factored transition model
r set factored reward functions
discount factor
h set basis functions h h hk
stores elimination order
bellman error precision
tmax maximum number iterations
return basis function weights w computed approximate policy iteration
initialize weights

let w
cache backprojections basis functions

basis function hi h action
let gia backproja hi
main approximate policy iteration loop

let
repeat
policy improvement part loop
compute decision list policy iteration weights

let decisionlistpolicy ra

p





wi gia

value determination part loop
initialize constraints max norm projection lp

let
initialize indicators

let
every branch decision list policy generate relevant set constraints
update indicators constraint state space future branches

branch htj aj decision list policy
instantiate variables tj assignment given tj




instantiate set functions h g j hk gk j
partial state assignment tj store c
instantiate target functions raj partial state assignment tj store b
instantiate indicator functions partial state assignment tj store
generate factored lp constraints current decision list branch

let factoredlp c b
let factoredlp c b
update indicator functions

let ij x x tj update indicators ij
obtain set weights solving lp corresponds
max norm projection

let w solution linear program minimize subject
constraints
let
bellmanerr hw tmax w w
return w

figure factored approximate policy iteration max norm projection



fiefficient solution factored mdps

x xn ti computes maximum states consistent ti ti
guarantee second condition ensure impose constraints
states associated previous decisions achieved adding indicators ij
previous decision tj weight specifically ij function takes value
states consistent tj zero assignments tj constraints
ith branch form
r x ai

x

wl gl x ai h x

x

x tj

x ti



j

l

x ti defines assignments x consistent ti introduction
indicators causes constraints associated ti trivially satisfied states sj
j note indicators restricted scope function tj
handled fashion terms factored lp thus decision
list size l factored lp contains constraints l cost networks complete
approximate policy iteration max norm projection outlined figure
comparisons
instructive compare max norm policy iteration l projection
policy iteration koller parr terms computational costs per
iteration implementation complexity computing l projection requires among
things series dot product operations basis functions backprojected
basis functions hhi gj expressions easy compute p refers transition
model particular action however policy represented decision list
policy improvement step step becomes much complicated
particular every branch decision list every pair basis functions j
assignment variables scope hi scope gja requires solution
counting p complete general although koller parr
computation performed bayesian network bn inference
still requires bn inference one assignments branch decision
list makes difficult implement efficiently practice
max norm projection hand relies solving linear program every
iteration size linear program depends cost networks generated
discuss two cost networks needed point decision list complexity
cost networks approximately one bn inferences
counting l projection overall branch decision
list total two inferences opposed one assignment
scope hi scope gja every pair basis functions j thus max norm policy
iteration substantially less complex computationally
l projection furthermore use linear programming allows us rely existing
lp packages cplex highly optimized
interesting compare approximate policy iteration approximate linear programming presented section approximate
linear programming never need compute decision list policy
policy represented implicitly qa functions thus


figuestrin koller parr venkataraman

require explicit computation manipulation greedy policy difference two
important consequences one computational terms generality
first compute consider decision lists makes approximate linear
programming faster easier implement generate single lp
one cost network action never need compute decision list policy
hand iteration approximate policy iteration needs generate two lps
every branch decision list size l usually significantly longer
total l cost networks terms representation require policies
compact thus need make default action assumption therefore
approximate linear programming deal general class
action independent dbn transition model hand
described section approximate policy iteration stronger guarantees terms
error bounds differences highlighted experimental
presented section

computing bounds policy quality
presented two computing approximate solutions factored mdps
b w
b
generate linear value functions denoted hw
resulting basis function weights practice agent define behavior
b one issue remains
b greedy hw
acting according greedy policy

b compares true optimal policy actual value vb
policy
policy
b compares v

section showed priori bounds quality policy another
possible procedure compute posteriori bound given resulting weights
b compute bound loss acting according greedy policy
b rather
w
optimal policy achieved bellman error analysis williams
baird
bellman error defined bellmanerr v kt v vk given greedy
b greedy v analysis provides bound
policy


v v bellmanerr v
b





b evaluate quality resulting
thus use bellman error bellmanerr hw
greedy policy
note computing bellman error involves maximization state space
thus complexity computation grows exponentially number state
variables koller parr suggested structure factored mdp
exploited compute bellman error efficiently error bound
computed set cost networks similar construction one maxb represented
norm projection technique used
decision list depend used determine policy thus
apply technique solutions determined approximate linear programming
action descriptions permit decision list representation policy
b bellman error given
set weights w


fiefficient solution factored mdps

b
factoredbellmanerr p r h w
p factored transition model
r set factored reward functions
discount factor
h set basis functions h h hk
stores elimination order
w
b weights linear value function
return bellman error value function hw
b
cache backprojections basis functions

basis function hi h action
let gia backproja hi
compute decision list policy value function
hw
b

b decisionlistpolicy ra p w
let
bi gi
initialize indicators

let
initialize bellman error

let
every branch decision list policy generate relevant cost networks solve
variable elimination update indicators constraint state space future branches

b
branch htj aj decision list policy

instantiate variables tj assignment given tj




instantiate set functions w
b h g j w
bk hk gk j
partial state assignment tj store c
instantiate target functions raj partial state assignment
tj store b
instantiate indicator functions partial state assignment
tj store
use variable elimination solve first cost network update bellman error error
branch larger

let max variableelimination c b
use variable elimination solve second cost network update bellman error error
branch larger

let max variableelimination c b
update indicator functions

let ij x x tj update indicators ij
return
b
figure computing bellman error factored value function hw



figuestrin koller parr venkataraman

b
b hwk
b
bellmanerr hw
kt hw


max

p

p

p

maxx wi hi x rb x x pb x x j wj hj x
p
p
p
maxx rb x x pb x x j wj hj x wi hi x



rewards rb transition model pb factored appropriately
compute one two maximizations maxx variable elimination cost
b decision list policy
network described section however
induce factored transition model fortunately approximate policy iteration
section exploit structure decision list perform
maximization efficiently particular approximate policy iteration generate
two cost networks branch decision list guarantee maximization
performed states branch relevant include type
indicator functions force irrelevant states value thus guaranteeing point decision list policy obtain corresponding state
maximum error state overall largest bellman error maximum
ones generated point decision list policy complete factored
computing bellman error outlined figure
one last interesting note concerns approximate policy iteration maxnorm projection section experiments converged
w w iterations convergence occurs objective function
linear program last iteration equal bellman error final
policy
lemma approximate policy iteration max norm projection converges
w w iteration max norm projection error last
b hw
iteration equal bellman error final value function estimate hw
b
bellmanerr hw

proof see appendix
thus bound loss acting according final policy substituting


bellman error bound
corollary approximate policy iteration max norm projection converges
b associated greedy policy
b
iterations final value function estimate hw
b
b instead optimal policy
greedy hw
loss acting according
bounded



v v

b



b
vb actual value policy

therefore approximate policy iteration converges obtain bound
quality resulting policy without needing compute bellman error explicitly




fiefficient solution factored mdps

exploiting context specific structure
thus far presented suite exploit additive structure
reward basis functions sparse connectivity dbn representing transition
model however exists another important type structure
exploited efficient decision making context specific independence csi example
consider agent responsible building maintaining house painting task
completed plumbing electrical wiring installed
probability painting done contexts plumbing electricity
done independently agents action representation used far
would use table represent type function table exponentially
large number variables scope function ignores context specific
structure inherent definition
boutilier et al boutilier et al dearden boutilier boutilier dean
hanks boutilier et al developed set exploit csi
transition reward perform efficient approximate although
often successful value function contains sufficient
context specific structure able exploit additive structure
often present real world
section extend factored mdp model include context specific structure
present simple yet effective extension exploit csi
additive structure obtain efficient approximations factored mdps first extend
factored mdp representation include context specific structure
basic operations section required performed efficiently
representation
factored mdps context specific additive structure
several representations context specific functions common
decision trees boutilier et al algebraic decision diagrams adds hoey st aubin
hu boutilier rules zhang poole choose use rules
basic representation two main reasons first rule representation allows
fairly simple variable elimination key operation framework
second rules required mutually exclusive exhaustive requirement
restrictive want exploit additive independence functions
represented linear combination set non mutually exclusive functions
begin describing rule representation along lines zhang
pooles presentation probabilistic transition model particular cpds
dbn model roughly speaking rule corresponds set cpd entries
associated particular probability value entries
value referred consistent contexts
definition let c x x c dom c say c consistent
b dom b b x x c b assignment variables
c b
probability consistent contexts represented probability rules


figuestrin koller parr venkataraman

electrical

electrical

done

done

done

done

plumbing

p painting

plumbing

p painting
done

done

done

painting

p painting

done

done

p painting

p painting

p painting



done
p painting

b

helectrical
helectrical plumbing
helectrical plumbing painting
helectrical plumbing painting


helectrical
helectrical plumbing
helectrical plumbing
c

figure example cpds variable painting true represented decision trees
action paint b action paint cpds
represented probability rules shown c respectively

definition probability rule hc pi function x x
context c dom c c x x p x x p x x
consistent c equal otherwise
case convenient require rules mutually exclusive exhaustive cpd entry uniquely defined association single rule
definition rule conditional probability distribution rule cpd pa function pa xi x composed set probability rules whose
contexts mutually exclusive exhaustive define
pa x x j x x
j unique rule pa cj consistent x x require
x
x
pa x x
x

define parentsa xi union contexts rules pa xi x
example cpd represented set probability rules shown figure
rules used represent additive functions reward basis functions
represent context specific value dependencies value rules


fiefficient solution factored mdps

definition value rule hc vi function x r x v
x consistent c otherwise
note value rule hc vi scope c
important note value rules required mutually exclusive
exhaustive value rule represents weighted indicator function takes
value v states consistent context c states given state
values zero rules consistent state simply added together
example construction example might set rules
hplumbing done
helectricity done
hpainting done
haction plumb


summed together define reward function r
general reward function ra represented rule function
definition rule function f x r composed set rules n
p
f x ni x
manner one basis functions hj represented rule
function
notion rule function related tree structure functions used
boutilier et al substantially general tree structure value functions rules corresponding different leaves mutually exclusive exhaustive
thus total number different values represented tree equal number
leaves rules rule function representation rules mutually
exclusive values added form overall function value different settings
variables different rules added different settings fact k rules
one easily generate k different possible values demonstrated section thus
rule functions provide compact representation much richer class
value functions
rule representation exploit csi additive independence
representation factored mdp basis functions basic
operations section adapted exploit rule representation
adding multiplying maximizing consistent rules
table relied standard sum product operators applied
tables order exploit csi rule representation must redefine
standard operations particular need add multiply rules
ascribe values overlapping sets states
start defining operations rules context


figuestrin koller parr venkataraman

definition let hc v hc v two rules context c define
rule product hc v v rule sum hc v v
note definition restricted rules context address
issue moment first introduce additional operation maximizes
variable set rules otherwise share common context
definition let variable dom yk let
k rule form hc yi vi rule function
f k define rule maximization maxy f hc maxi vi
operation maximized scope function f
three operations described applied sets rules
satisfy stringent conditions make set rules amenable application
operations might need refine rules therefore define
following operation
definition let hc vi rule variable define rule split
split variable follows scope c split
otherwise
split hc yi vi yi dom
thus split rule variable scope context
generate set rules one assignment domain
general purpose rule splitting extend context c one rule coincide
context c another consistent rule naively might take variables
scope c scope c split recursively one however process
creates unnecessarily many rules variable scope c scope c split
one dom rules generated remain consistent
one assignment one c thus consistent rule
needs split define recursive splitting procedure achieves
parsimonious representation
definition let hc vi rule b context b dom b
define recursive rule split split b context b follows
c consistent b else
scope b scope c else
split b split variable scope b scope c

definition variable scope b scope c leads generation k
dom rules step split however one k rules used
next recursive step one consistent b therefore size
p
split set simply scope b scope c dom size independent
order variables split within operation


fiefficient solution factored mdps

note one rules split b consistent b one context
c b thus want add two consistent rules hc v hc v
need replace rules set
split c split c
simply replace resulting rules hc c v hc c v sum
hc c v v multiplication performed analogous manner
example consider adding following set consistent rules
ha b
ha c
rules context c b context c c
rules consistent therefore must split perform addition
operation


ha b c
ha b c
split c

ha b c
likewise



split

c

ha b c
ha b c

adding rules
ha b c
ha b c
ha b c
ha b c

rule one step lookahead
compact rule representation able compute one step lookahead
plan efficiently significant context specific additive independence
section table case rule qa function represented
sum reward function discounted expected value next state
due linear approximation value function expectation term turn
represented linear combination backprojections basis functions
exploit csi representing rewards basis functions rule functions
represent qa rule function sufficient us represent
backprojection gj basis function hj rule function
p h
hj rule
function
written hj x j x

e
h
h
h
j form ci j vi j rule restricted scope function thus
simplify backprojection


figuestrin koller parr venkataraman

rulebackproja

given hc vi c dom c

let g
select set p relevant probability rules
p j p xi parents xi xi c c consistent cj
remove x assignments context rules p
multiply consistent rules
two consistent rules hc p hc p
c c replace two rules hc p p
else replace two rules set split c split c
generate value rules
rule p
update backprojection g g hci pi vi
return g

figure rule backprojection
gja x

x

pa x x hj x

x



x

pa x x

x



xx




x hj



x


hj



pa x x

x

x

x hj

vi

hj

pa ci

x


h

h

term vi j pa ci j x written rule function denote back h
projection operation rulebackproja j
backprojection procedure described figure follows three steps first
relevant rules selected cpds variables appear context
select rules consistent context rules play role
backprojection computation second multiply consistent probability rules
form local set mutually exclusive rules procedure analogous addition
procedure described section represented probabilities
affect mutually exclusive set simply represent backprojection
product probabilities value backprojection
rule function one rule one mutually exclusive probability rules
context value rule value product
probability value
example example consider backprojection simple rule
h painting done
cpd figure c paint action
rulebackprojpaint

x

ppaint x x x

x



fiefficient solution factored mdps

x



ppaint painting x painting

painting






painting done x



note product simple rules equivalent decision tree cpd shown
figure hence product equal contexts example electricity
done time product non zero one context context associated
rule thus express backprojection operation rule
function single rule
rulebackprojpaint hplumbing electrical
similarly backprojection action paint represented
single rule
rulebackprojpaint hplumbing electrical painting
write backprojection rule basis function hj
gja x

x

hj

rulebackproja







gja sum rule functions therefore rule function
simplicity notation use gja rulebackproja hj refer definition backprop
jection notation write qa x ra x j wj gja x
rule function
rule maximization state space
second key operation required extend exploit csi
modify variable elimination section handle rule representation section showed maximization linear combination
table functions restricted scope performed efficiently non serial
dynamic programming bertele brioschi variable elimination exploit structure rules use similar variable elimination bayesian network
context specific independence zhang poole
intuitively operates selecting value rules relevant variable
maximized current iteration local maximization performed
subset rules generating set rules without current variable
procedure repeated recursively variables eliminated
precisely eliminates variables one one elimination process performs maximization step variables domain suppose
eliminating xi whose collected value rules lead rule function f f involves
additional variables set b f scope b xi need compute
maximum value xi choice b dom b use maxout f xi denote procedure takes rule function f b xi returns rule function g b


figuestrin koller parr venkataraman

maxout f b
let g
add completing rules f hb bi k
summing consistent rules
two consistent rules hc v hc v
c c replace two rules hc v v
else replace two rules set split c split c
maximizing variable b
repeat f empty
rules hc b bi vi bi dom b
remove rules f add rule hc maxi vi g
else select two rules hci b bi vi j hcj b bj vj
ci consistent cj identical replace
split cj split j ci
return g

figure maximizing variable b rule function f
g b maxxi f b xi procedure extension variable elimination
zhang poole zhang poole
rule variable elimination maintains set f value rules initially
containing set rules maximized repeats following steps
variable xi variables eliminated
collect rules depend xi hc vi f xi c
remove rules f
perform local maximization step xi gi maxout xi
add rules gi f xi eliminated
cost polynomial number rules generated
maximization operation maxout xi number rules never larger many
cases exponentially smaller complexity bounds table maximization
section turn exponential induced width cost network
graph dechter however computational costs involved managing sets rules
usually imply computational advantage rule tablebased one significant possess fair amount context specific
structure
remainder section present computing local
maximization maxout xi next section ideas applied
extending section exploit csi lp representation
factored mdps
procedure presented figure divided two parts first consistent
rules added together described section variable b maximized
maximization performed generating set rules one assignment b whose
contexts assignment variables except b definition
set substituted single rule without b assignment context value
equal maximum values rules original set note simplify


fiefficient solution factored mdps

initially need add set value rules value guarantee
rule function f complete e least one rule consistent every
context
correctness procedure follows directly correctness rule
variable elimination procedure described zhang poole merely replacing summations product max products products sums conclude
section small example illustrate
example suppose maximizing following set rules





ha
ha b
ha b c
ha b

add completing rules get
ha
ha
first part need add consistent rules add
remains unchanged combine split context
get following inconsistent set rules






ha b
ha b c
ha b
adding consistent rule split b
ha b
split b
ha b c
split b c

note several rules value generated shown
added rules consistent contexts move second stage repeat loop
maxout remove maximize give
hb
select rules split c split empty set
changed
ha b c
ha b c
maximizing rules get
hb c
left maximized counterpart gives
hb c
notice throughout maximization split variable c b ci
giving us distinct rules final possible table
representation since functions would variables b c therefore
must entries


figuestrin koller parr venkataraman

rule factored lp
section showed lps used exponentially many
p
constraints form wi ci x b x x substituted single
p
equivalent non linear constraint maxx wi ci x b x showed
variable elimination represent non linear constraint equivalent set
linear constraints construction called factored lp number constraints
factored lp linear size largest table generated variable elimination
procedure table exploit additive independence
extend section exploit additive context specific structure
rule variable elimination described previous section
suppose wish enforce general constraint maxy f w f w
p w
j fj fj rule table version superscript w means
fj might depend w specifically fj comes basis function hi multiplied
weight wi fj rule reward function
rule factored linear program generate lp variables associated
contexts call lp rules lp rule form hc ui associated
context c variable u linear program begin transforming original
rules fjw lp rules follows rule fj form hcj vj comes basis
function hi introduce lp rule ej hcj uj equality constraint uj wi vj
fj form comes reward function introduce lp rule
form equality constraint becomes uj vj
p
lp rules need represent constraint maxy j ej
represent constraint follow similar variable elimination procedure section main difference occurs maxout f b operation
figure instead generating value rules generate lp rules associated
variables constraints simplest case occurs computing split
adding two lp rules example add two value rules original
instead perform following operation associated lp rules lp rules
hc ui hc uj replace rule hc uk associated lp
variable uk context c whose value ui uj enforce value constraint
simply add additional constraint lp uk ui uj similar procedure
followed computing split
interesting constraints generated perform maximization
rule variable elimination figure maximization occurs
replace set rules
hc b bi vi bi dom b
rule





c max vi


following process lp rule summation maximizing
ei hc b bi ui bi dom b
generate lp variable uk associated rule ek hc uk however
cannot add nonlinear constraint uk maxi ui add set equivalent linear


fiefficient solution factored mdps

constraints
uk ui
therefore simple operations exploit structure rule functions
p
represent nonlinear constraint en maxy j ej en last lp
rule generate final constraint un implies representing exactly
constraints equation without enumerate every state
correctness rule factored lp construction corollary theorem
correctness rule variable elimination zhang poole

corollary constraints generated rule factored lp construction
equivalent non linear constraint equation assignment w
satisfies rule factored lp constraints satisfies constraint
equation
number variables constraints rule factored lp linear
number rules generated variable elimination process turn number rules
larger often exponentially smaller number entries table

illustrate generation lp constraints described present small
example
example let e e e e set lp rules depend variable
b maximized rule ei associated lp variable ui
e
e
e
e

ha b u
ha b c u
ha b u
ha b c u

set note rules e e consistent combine generate
following rules
e ha b c u
e ha b c u
constraint u u u similarly e e may combined resulting
e ha b c u
constraint u u u following three inconsistent rules
maximization
e ha b u
e ha b c u
e ha b c u
following maximization procedure since pair rules eliminated right away
split e e generate following rules
e ha b c u
e ha b c u
e ha b c u


figuestrin koller parr venkataraman

maximize b e e resulting following rule constraints
respectively
e ha c u
u u
u u
likewise maximizing b e e get
e ha c u
u u
u u
completes elimination variable b rule factored lp
presented exploiting additive context specific structure lp construction steps rule factored lp
applied directly approximate linear programming approximate policy iteration presented sections
additional modification required concerns manipulation decision
list policies presented section although approximate linear programming
require explicit policy representation default action model approximate policy iteration require us represent policy fortunately major modifications
required rule case particular conditionals hti ai decision
list policies already context specific rules thus policy representation
section applied directly rule representation therefore
complete framework exploiting additive context specific structure
efficient factored mdps

experimental
factored representation value function appropriate certain types
systems systems involve many variables strong interactions
variables fairly sparse decoupling influence variables
induce unacceptable loss accuracy argued herbert simon
architecture complexity many complex systems nearly decomposable
hierarchical structure subsystems interacting weakly
evaluate selected believe exhibit type structure
section perform experiments intended explore performance
first compare factored approximate linear programming lp
approximate policy iteration pi compare l projection
koller parr second evaluation compares table implementation rule implementation exploit csi finally present
comparisons boutilier et al
approximate lp approximate pi
order compare approximate lp approximate pi tested
sysadmin described detail section relates system


fiefficient solution factored mdps

administrator maintain network computers experimented
network architectures shown figure machines fail randomly faulty machine
increases probability neighboring machines fail every time step
sysadmin go one machine reboot causing working next time
step high probability recall state space grows exponentially
number machines network machines states
machine receives reward working except ring one machine
receives reward introduce asymmetry zero reward given faulty
machines discount factor optimal strategy rebooting machines
depend upon topology discount factor status machines
network machine machine j faulty benefit rebooting must
weighed expected discounted impact delaying rebooting j js successors
topologies rings policy may function status every single
machine network
basis functions used included independent indicators machine value
working zero otherwise e one restricted scope function single
variable constant basis whose value states selected straightforward
variable elimination orders star three legs topologies first eliminated
variables corresponding computers legs center computer server
eliminated last ring started arbitrary computer followed ring
order ring star ring machines eliminated first center one
finally ring rings topology eliminated computers outer rings
first ones inner ring
implemented factored policy iteration linear programming
matlab cplex lp solver experiments performed sun ultrasparcii mhz mb ram evaluate complexity approximate policy
iteration max norm projection tests performed increasing
number states increasing number machines network figure shows
running time increasing sizes architectures simplest one
star backprojection basis function scope restricted two
variables largest factor cost network scope restricted two variables
difficult one bidirectional ring factors contain five variables
note number states growing exponentially indicated log scale
figure running times increase logarithmically number states
polynomially number variables illustrate behavior figure
fit rd order polynomial running times unidirectional ring note
size description grows quadratically number variables adding
machine network adds possible action fixing machine

computation
cost factored empirically grows approximately


n n variables opposed exponential complexity
poly n explicit
evaluation measured error approximate value function relative
true optimal value function v note possible compute v small
case able go machines comparison
evaluated error approximate value function produced l projection


figuestrin koller parr venkataraman





ring
legs



ring rings


total time minutes

total time minutes



star



ring star









e

e

e

e e e
number states

e



e





number states








fitting polynomial



time x x
x



ring

total time minutes

total time minutes

e

b







unidirectional
bidirectional








quality fit r








e

e

e

e

e

e

e

e




number state

c






number variables x







figure c running times policy iteration max norm projection variants
sysadmin fitting polynomial running time
ring topology

koller parr discussed section l projections
factored mdps koller parr difficult time consuming hence
able compare two smaller equivalent l projection
implemented explicit state space formulation
presented figure showing relative error approximate solutions
true value function increasing sizes indicate larger
max norm formulation generates better approximation true optimal
value function v l projection used two types basis functions
single variable functions pairwise basis functions pairwise basis functions
contain indicators neighboring pairs machines e functions two variables
expected use pairwise basis functions resulted better approximations


fiefficient solution factored mdps



max norm single basis
l single basis



bellman error rmax

max norm pair basis
l pair basis

relative error






















number variables





ring
legs




e

star

e

e

e

e

e

e

e

numbe r sta tes



b

figure relative error optimal value function v comparison l projection
ring b large measuring bellman error convergence

small compare actual value policy generated
value optimal policy value policy generated
much closer value optimal policy error implied
difference approximate value function v example star
architecture one server clients approximation single variable
basis functions relative error policy generated value
optimal policy case true policy generated l
projection unidirectional ring machines pairwise basis relative
error approximation v resulting policy
loss optimal policy l approximation value
function error true policy loss words methods induce
policies lower errors errors approximate value function least
small however continues outperform l
even respect actual policy loss
large longer compute correct value function cannot
evaluate computing kv hwk fortunately discussed section
bellman error used provide bound approximation error
computed efficiently exploiting specific structure figure b shows
bellman error increases slowly number states
valuable look actual decision list policies generated experiments
first noted lists tended short length final decision list policy
grew approximately linearly number machines furthermore policy
often fairly intuitive ring star architecture example decision list
says server faulty fix server else another machine faulty fix
thus far presented scaling running times approximation error
approximate pi compare simpler approximate


figuestrin koller parr venkataraman





pi single basis
pi single basis



lp single basis



lp pair basis



lp triple basis

discounted reward final policy
averaged trials steps

total running time minutes

























numbe r machine

lp single basis
lp pair basis



lp triple basis
















numbe r machine



b

figure approximate lp versus approximate pi sysadmin ring
topology running time b estimated value policy

lp section shown figure approximate lp
factored mdps significantly faster approximate pi fact approximate pi single variable basis functions variables costly computationally
lp basis functions consecutive triples variables shown
figure b singleton basis functions approximate pi policy obtains slightly better
performance sizes however increase number basis functions
approximate lp formulation value resulting policy much better thus
factored approximate linear programming formulation allows us use
basis functions obtain resulting policy higher value still maintaining
faster running time along simpler implementation suggest
practice one may first try apply approximate linear programming
deciding move elaborate approximate policy iteration
comparing table rule implementations
next evaluation compares table representation exploits additive
independence rule representation presented section exploit
additive context specific independence experiments implemented
factored approximate linear programming table rule
representations c cplex lp solver experiments performed
sun ultrasparc ii mhz gb ram
evaluate compare utilized complex extension
sysadmin dubbed process sysadmin contains three
state variables machine network loadi statusi selectori computer runs processes receives rewards processes terminate processes
represented loadi variable takes values idle loaded success
computer receives reward assignment loadi success statusi variable


fitotal running time minutes

efficient solution factored mdps


table single basis
rule single basis



table pair basis


rule pair basis



e

e

e

e

e

e

e

number states

total running time minutes





table single basis
rule single basis



table pair basis

rule pair basis


e e e e e e e e
number states

b

total running time minutes



x

x

e x e x


r



table single basis
rule single basis








x x
x
r









number machines





c
figure running time process sysadmin topologies star
b ring c reverse star fit function



figuestrin koller parr venkataraman

cplex time total time



table single basis

rule single basis













number machines

figure fraction total running time spent cplex process sysadmin ring topology

representing status machine takes values good faulty dead value
faulty processes smaller probability terminating value dead
running process lost loadi becomes idle status machine become faulty eventually dead random however machine receives packet
dead machine probability statusi becomes faulty dead increases
selectori variable represents communication selecting one neighbors
uniformly random every time step sysadmin select one computer
reboot every time step computer rebooted status becomes good
probability running process lost e loadi variable becomes idle
thus sysadmin must balance several conflicting goals rebooting
machine kills processes rebooting machine may cause cascading faults network
furthermore sysadmin choose one machine reboot imposes additional tradeoff selecting one potentially many faulty dead machines
network reboot
experimented two types basis functions single includes indicators
joint assignments loadi statusi selectori pair addition
includes set indicators statusi statusj selectori j neighbor j
machine network discount factor variable elimination
order eliminated loadi variables first followed patterns
simple sysadmin eliminating first statusi selectori machine
eliminated
figure compares running times table implementation ones
rule representation three topologies star ring reverse star
reverse star topology reverses direction influences star rather
central machine influencing machines topology machines influence
central one three topologies demonstrate three different levels csi


fiefficient solution factored mdps

star topology factors generated variable elimination small thus although
running times polynomial number state variables methods tablebased representation significantly faster rule one due overhead
managing rules ring topology illustrates intermediate behavior single
basis functions induce relatively small variable elimination factors thus table
faster however pair basis factors larger rule
starts demonstrate faster running times larger finally reverse star topology represents worst case scenario table
scope backprojection basis function central machine involve
computers network machines potentially influence central one
next time step thus size factors table variable elimination exponential number machines network illustrated
exponential growth figure c rule exploit csi
example status central machine status depends machine
j value selector j e selector j exploiting csi solve
polynomial time number state variables seen second curve
figure c
instructive compare portion total running time spent cplex
table compared rule figure illustrates
comparison note amount time spent cplex significantly higher
table two reasons difference first due csi lps
generated rule smaller table ones second rulebased variable elimination complex table one due overhead
introduced rule management interestingly proportion cplex time increases
size increases indicating asymptotic complexity lp solution
higher variable elimination thus suggesting larger additional
large scale lp optimization procedures constraint generation may helpful
comparison apricodd
closely related work line began work
boutilier et al particular approximate apricodd hoey et
al uses analytic decision diagrams adds represent value function
strong alternative solving factored mdps discussed detail section apricodd successfully exploit context specific structure
value function representing set mutually exclusive exhaustive branches
add hand exploit additive context specific
structure linear combination non mutually exclusive rules
better understand difference evaluated rule approximate linear
programming apricodd two linear expon designed
boutilier et al illustrate respectively best case worst case behavior
experiments used web distributed version apricodd hoey st aubin hu boutilier running locally linux pentium iii
mhz gb ram


figuestrin koller parr venkataraman



rule








x x x


r



apricodd


x x




apricodd


time seconds

time seconds



x



x

e
r




rule
x x
x
r





r













number variables













number variables



b

figure comparing apricodd rule approximate linear programming
linear b expon

two involve n binary variables x xn n deterministic actions
reward variables xk true otherwise
discounted factor difference linear expon
transition probabilities linear action ak sets
variable xk true makes succeeding variables xi k false state space
linear seen binary number optimal policy set repeatedly
largest bit xk variable preceding bits set true add optimal
value function represented linear space n leaves boutilier
et al best case apricodd compute value
function quite efficiently figure compares running time apricodd
one indicator basis functions pairs consecutive variables
note obtain policy polynomial time number
variables however structured efficient implementation add
package used apricodd makes faster
hand expon illustrates worst case apricodd
action ak sets variable xk true preceding variables xi k
true makes preceding variables false state space seen binary number
optimal policy goes binary numbers sequence repeatedly setting
largest bit xk variable preceding bits set true due discounting
n
optimal value function assigns value j jth binary number
value function contains exponentially many different values add optimal
value function requires exponential number leaves boutilier et al
illustrated exponential running time figure b however
value function approximated compactly factored linear value
function n basis functions indicator variable xk constant
base shown figure b representation factored approximate linear
programming computes value function polynomial time furthermore


fiefficient solution factored mdps





running time minutes

discounted value policy
avg runs steps

rule lp



apricodd






rule lp



apricodd













number machines












number machines









b







rule lp

rule lp



discounted value policy
avg runs steps

running time minutes



apricodd










apricodd

















number machines





c








number machines



figure comparing apricodd rule approximate linear programming single basis functions process sysadmin ring topology
running time b value resulting policy star topology
c running time value resulting policy

policy obtained optimal thus
ability exploit additive independence allows efficient polynomial time solution
compared apricodd rule approximate linear programming
process sysadmin significant additive structure reward function factorization transition model although type
structure exploited directly apricodd add approximation steps performed
principle allow apricodd approximate solutions spent significant amount time attempting best set parameters
apricodd settled sift method variable reordering
round approximation method size maximum add size criteria
grateful jesse hoey robert st aubin assistance selecting parameters



figuestrin koller parr venkataraman

allow value function representation scale size set maximum
add size n network n machines experimented variety
different growth rates maximum add size parameters
selected choice gave best apricodd compared apricodd
parameters rule approximate linear programming
single basis functions pentium iii mhz gb ram
summarized figure
small machines performance two
fairly similar terms running time quality policies generated
however size grows running time apricodd increases rapidly
becomes significantly higher furthermore size
increases quality policies generated apricodd deteriorates difference
policy quality caused different value function representation used two
adds used apricodd represent k different values k leaves thus
forced agglomerate many different states represent single value
smaller agglomeration still represent good policies unfortunately
size increases state space grows exponentially apricodds policy
representation becomes inadequate quality policies decreases
hand linear value functions represent exponentially many values k basis
functions allows scale significantly larger

related work
closely related work line began work
boutilier et al address comparison separately begin
section broader background references
approximate mdp solutions
field mdps popularly known formalized bellman
importance value function approximation recognized early stage
bellman early mdp framework recognized ai
researchers formal framework could used address
uncertainty dean kaelbling kirman nicholson
within ai community value function approximation developed concomitantly
notion value function representations markov chains suttons seminal
temporal difference learning addressed use value functions prediction
assumed general representation value function noted
connection general function approximators neural networks however
stability combination directly addressed time
several important developments gave ai community deeper insight relationship function approximation dynamic programming tsitsiklis van
roy independently gordon popularized analysis approximate
mdp methods via contraction properties dynamic programming operator
function approximator tsitsiklis van roy b later established general convergence linear value function approximators bertsekas


fiefficient solution factored mdps

tsitsiklis unified large body work approximate dynamic programming
name neuro dynamic programming providing many novel general error
analyses
approximate linear programming mdps linear value function approximation
introduced schweitzer seidmann although somewhat
deprecated fairly recently due lack compelling error analyses lack
effective method handling large number constraints recent work de farias
van roy b started address concerns error bounds
constraint sampling methods rather sampling constraints utilizes
structure model value function represent constraints compactly
factored approaches
tatman shachter considered additive decomposition value nodes influence diagrams number approaches factoring general mdps explored
literature techniques exploiting reward functions decompose additively
studied meuleau et al singh cohn
use factored representations dynamic bayesian networks pioneered
boutilier et al developed steadily recent years methods rely
use context specific structures decision trees analytic decision diagrams
adds hoey et al represent transition dynamics dbn
value function use dynamic programming partition state space
representing partition tree structure branches state variables
assigns values leaves tree grown dynamically part dynamic programming process creates leaves needed leaf split
application dp operator two states associated leaf turn
different values backprojected value function process interpreted
form model minimization dean givan
number leaves tree used represent value function determines computational complexity limits number distinct values
assigned states since leaves represent partitioning state space every state
maps exactly one leaf however recognized early trivial mdps
require exponentially large value functions observation led line approximation
aimed limiting tree size boutilier dearden later limiting
add size st aubin hoey boutilier kim dean explored
techniques discovering tree structured value functions factored mdps
methods permit good approximate solutions large mdps complexity still
determined number leaves representation number distinct values
assigned states still limited well
tadepalli ok first apply linear value function approximation
factored mdps linear value function approximation potentially expressive
approximation method assign unique values every state mdp without
requiring storage space exponential number state variables expressive
power tree k leaves captured linear function approximator k basis
functions basis function hi indicator function tests state belongs


figuestrin koller parr venkataraman

partition leaf thus set value functions represented
tree k leaves subset set value functions represented
value function k basis functions experimental section highlight
difference showing example requires exponentially many leaves
value function approximated well linear value function
main advantage tree value functions structure determined
dynamically solution mdp principle value function representation derived automatically model description requires less insight
user value function well approximated relatively small number values provides excellent solution
method linear value function approximation aims address believe
common case large range distinct values required achieve good
approximation
finally note schuurmans patrascu earlier work
max norm projection cost networks linear programs independently developed
alternative approximate linear programming cost network
method embeds cost network inside single linear program contrast method
constraint generation cost network detect constraint
violations constraint violations found constraint added repeatedly
generating attempting solve lps feasible solution found interestingly
schuurmans patrascu uses multiple calls variable elimination
order speed lp solution step successful time spent
solving lp significantly larger time required variable elimination
suggested section lp solution time larger table thus
schuurmans patrascus constraint generation method probably successful
table rule ones

conclusions
presented approximate linear programming approximate dynamic programming value policy iteration factored mdps
leverage novel lp decomposition technique analogous variable elimination cost networks reduces exponentially large lp provably
equivalent polynomial sized one
approximate dynamic programming motivated error analyses
showing importance minimizing l error efficient
substantially easier implement previous l projection
experimental suggest perform better practice
approximate linear programming factored mdps simpler easier
implement general dynamic programming approaches unlike policy
iteration rely default action assumption states
actions affect small number state variables although
theoretical guarantees max norm projection approaches empirically seems
favorable option experiments suggest approximate policy iteration tends
generate better policies set basis functions however due computa

fiefficient solution factored mdps

tional advantages add basis functions approximate linear programming
obtaining better policy still maintaining much faster running time
approximate policy iteration
unlike previous approaches exploit additive contextspecific structure factored mdp model typical real world systems possess
types structure thus feature increase applicability factored mdps practical demonstrated exploiting
context specific independence rule representation instead standard
table one yield exponential improvements computational time significant amounts csi however overhead managing sets rules make
less well suited simpler compared work
boutilier et al exploits context specific structure
significant context specific structure value function faster due
efficient handling add representation however
significant context specific structure representation rather value
function require exponentially large adds demonstrated linear value function obtain polynomial time
near optimal approximation true value function
success depends ability capture important
structure value function linear factored approximation ability turn
depends choice basis functions properties domain
currently require designer specify factored basis functions
limitation compared boutilier et al fully automated
however experiments suggest simple rules quite successful designing basis first ensure reward function representable basis
simple basis addition contained separate set indicators variable often
quite well add indicators pairs variables simply choose
according dbn transition model indicator added variables
xi one variables parents xi thus representing one step influences
procedure extended adding basis functions represent influences
required thus structure dbn gives us indications choose basis
functions sources prior knowledge included specifying
basis
nonetheless general choosing good factored basis functions still
exist however potential approaches first csi one
could apply boutilier et al iterations generate partial treestructured solutions indicators defined variables backprojection leaves
could turn used generate basis set second bellman
error computation performed efficiently shown section
provide bound quality policy actual state error
largest knowledge used create mechanism incrementally increase
basis set adding basis functions tackle states high bellman error
many possible extensions work already pursued extensions collaborative multiagent systems multiple agents act simultaneously
maximize global reward guestrin et al b factored pomdps


figuestrin koller parr venkataraman

full state observed directly indirectly observation variables guestrin
koller parr c however settings remain explored
particular hope address learning factored mdp
competitive multiagent system
additionally tackled induced width cost
network sufficiently low possess sufficient context specific structure allow
exact solution factored lps unfortunately practical may
prohibitively large induced width plan leverage ideas loopy belief propagation approximate inference bayesian networks pearl yedidia
freeman weiss address issue
believe methods described herein significantly extend efficiency
applicability general usability factored value functions control
practical dynamic systems

acknowledgements
grateful craig boutilier dirk ormoneit uri lerner many useful
discussions anonymous reviewers detailed thorough comments
would thank jesse hoey robert st aubin alan hu craig boutilier
distributing useful assistance apricodd
selecting parameters work supported dod muri program administered office naval grant n air force contract
f darpas task program sloan foundation first
author supported siebel scholarship

appendix proofs
proof lemma
exists setting weights zero setting yields bounded maxnorm projection error p policy p rmax max norm projection operator
chooses set weights minimizes projection error policy thus
projection error must least low one given zero weights p
bounded thus error remains bounded iterations
proof theorem
first need bound approximation v




v hw












hw hw




v hw










hw hw v hw






triangle inequality

contraction

moving second term right hand side dividing obtain




v hw











hw hw







fiefficient solution factored mdps

next part proof adapt lemma bertsekas tsitsiklis lemma
p fit framework manipulation lemma reformulated
kv v k kv v k





v hw





proof concluded substituting equation equation finally induction
proof theorem
first note equality constraints represent simple change variable thus
rewrite equation terms lp variables ufzii
max

x

x

ufzii





assignment weights w implies assignment ufzii stage
lp variables
remains factored lp construction equivalent constraint
equation system n variables x xn assume without loss
generality variables eliminated starting xn x prove
equivalence induction number variables
base case n functions ci x b x equation
empty scope case equation written


x

uei





case transformation done constraint equivalence immediate
assume holds systems variables prove equivalence
system variables system maximization decomposed
two terms one factors depend xi irrelevant
maximization xi another term factors depend xi
decomposition write equation




max

x ej

x xi

uzj

j

max

x xi




x

x

uezll max
xi

l xi zl

e
uzjj



j xi zj

point define lp variables uez corresponding second term
right hand side constraint lp variables must satisfy following
constraint
uez max
xi

x ej
j



u z xi zj



figuestrin koller parr venkataraman

non linear constraint represented factored lp construction
set equivalent linear constraints
uez

x ej
j

u z xi zj z xi



equivalence non linear constraint equation set linear constraints equation shown considering binding constraints
lp variable created uez xi constraints created one value xi xi
assignment lp variables right hand side constraint equap
ej
tion one xi constraints relevant one j u z x
zj
maximal corresponds maximum xi value z
one assignment xi achieves maximum constraints
corresponding maximizing assignments could binding thus equation
equation equivalent
substituting lp variables uez equation get


max

x xi

x

uezll uez

l xi zl

depend xi anymore thus equivalent system variables
concluding induction step proof
proof lemma
first note iteration objective function max norm projection
lp given








hw r p hw


however convergence value function estimates equal iterations
w w









hw r p hw


operator notation term equivalent






hw hw


note greedy hw definition thus
hw hw
finally substituting previous expression obtain






hw hw




fiefficient solution factored mdps

references
arnborg corneil g proskurowski complexity finding embeddings
k tree siam journal algebraic discrete methods
becker geiger sufficiently fast finding close optimal
clique trees artificial intelligence
bellman r kalaba r kotkin b polynomial approximation computational technique dynamic programming math comp
bellman r e dynamic programming princeton university press princeton
jersey
bertele u brioschi f nonserial dynamic programming academic press
york
bertsekas tsitsiklis j neuro dynamic programming athena scientific
belmont massachusetts
boutilier c dean hanks decision theoretic structural assumptions computational leverage journal artificial intelligence

boutilier c dearden r approximating value trees structured dynamic
programming proc icml pp
boutilier c dearden r goldszmidt exploiting structure policy construction proc ijcai pp
boutilier c dearden r goldszmidt stochastic dynamic programming
factored representations artificial intelligence
cheney e w approximation theory nd edition chelsea publishing co
york ny
de farias van roy b linear programming approximate
dynamic programming submitted operations
de farias van roy b b constraint sampling linear programming approximate dynamic programming appear mathematics
operations
dean kaelbling l p kirman j nicholson deadlines
stochastic domains proceedings eleventh national conference artificial
intelligence aaai pp washington c aaai press
dean kanazawa k model reasoning persistence causation
computational intelligence
dean givan r model minimization markov decision processes
proceedings fourteenth national conference artificial intelligence aaai pp providence rhode island oregon aaai press
dearden r boutilier c abstraction approximate decision theoretic artificial intelligence


figuestrin koller parr venkataraman

dechter r bucket elimination unifying framework reasoning artificial
intelligence
gordon g stable function approximation dynamic programming proceedings
twelfth international conference machine learning pp tahoe
city ca morgan kaufmann
guestrin c e koller parr r max norm projections factored mdps
proceedings seventeenth international joint conference artificial intelligence ijcai pp seattle washington morgan kaufmann
guestrin c e koller parr r b multiagent factored mdps
th neural information processing systems nips pp vancouver
canada
guestrin c e koller parr r c solving factored pomdps linear value
functions seventeenth international joint conference artificial intelligence
ijcai workshop uncertainty incomplete information
pp seattle washington
guestrin c e venkataraman koller context specific multiagent coordination factored mdps eighteenth national conference
artificial intelligence aaai pp edmonton canada
hoey j st aubin r hu boutilier c spudd stochastic decision diagrams proceedings fifteenth conference uncertainty
artificial intelligence uai pp stockholm sweden morgan kaufmann
hoey j st aubin r hu boutilier c stochastic decision
diagrams c implementation http www cs ubc ca spider staubin spudd
howard r matheson j e influence diagrams howard r matheson j e eds readings principles applications decision analysis
pp strategic decisions group menlo park california
keeney r l raiffa h decisions multiple objectives preferences
value tradeoffs wiley york
kim k e dean solving factored mdps non homogeneous partitioning proceedings seventeenth international joint conference artificial
intelligence ijcai pp seattle washington morgan kaufmann
kjaerulff u triangulation graphs giving small total state space
tech rep tr r department mathematics computer science strandvejen aalborg denmark
koller parr r computing factored value functions policies structured
mdps proceedings sixteenth international joint conference artificial
intelligence ijcai pp morgan kaufmann
koller parr r policy iteration factored mdps proceedings
sixteenth conference uncertainty artificial intelligence uai pp
stanford california morgan kaufmann


fiefficient solution factored mdps

meuleau n hauskrecht kim k peshkin l kaelbling l dean boutilier c
solving large weakly coupled markov decision processes proceedings
th national conference artificial intelligence pp madison wi
pearl j probabilistic reasoning intelligent systems networks plausible inference morgan kaufmann san mateo california
puterman l markov decision processes discrete stochastic dynamic programming wiley york
reed b finding approximate separators computing tree width quickly
th annual symposium theory computing pp acm
schuurmans patrascu r direct value approximation factored mdps
advances neural information processing systems nips pp
vancouver canada
schweitzer p seidmann generalized polynomial approximations markovian decision processes journal mathematical analysis applications

simon h sciences artificial second edition mit press cambridge
massachusetts
singh cohn dynamically merge markov decision processes
jordan kearns j solla eds advances neural information
processing systems vol mit press
st aubin r hoey j boutilier c apricodd approximate policy construction decision diagrams advances neural information processing systems
proceedings conference pp denver colorado mit press
stiefel e note jordan elimination linear programming tchebycheff approximation numerische mathematik
sutton r learning predict methods temporal differences machine
learning
tadepalli p ok scaling average reward reinforcmeent learning approximating domain value function proceedings thirteenth
international conference machine learning bari italy morgan kaufmann
tatman j shachter r dynamic programming influence diagrams
ieee transactions systems man cybernetics
tsitsiklis j n van roy b feature methods large scale dynamic
programming machine learning
tsitsiklis j n van roy b b analysis temporal difference learning
function approximation technical report lids p laboratory information
decision systems massachusetts institute technology
van roy b learning value function approximation complex decision
processes ph thesis massachusetts institute technology


figuestrin koller parr venkataraman

williams r j baird l c tight performance bounds greedy policies
imperfect value functions tech rep college computer science northeastern
university boston massachusetts
yedidia j freeman w weiss generalized belief propagation advances
neural information processing systems proceedings conference
pp denver colorado mit press
zhang n poole role context specific independence probabilistic
reasoning proceedings sixteenth international joint conference artificial
intelligence ijcai pp morgan kaufmann




