journal artificial intelligence

submitted published

graphical model inference optimal control stochastic
multi agent systems
bart van den broek
wim wiegerinck
bert kappen

b vandenbroek science ru nl
w wiegerinck science ru nl
b kappen science ru nl

snn radboud university nijmegen geert grooteplein
nijmegen netherlands

abstract
article consider issue optimal control collaborative multi agent
systems stochastic dynamics agents joint task
reach number target states dynamics agents contains additive control
additive noise autonomous part factorizes agents full observation
global state assumed goal minimize accumulated joint cost consists
integrated instantaneous costs joint end cost joint end cost expresses joint
task agents instantaneous costs quadratic control factorize
agents optimal control given weighted linear combination single agent
single target controls single agent single target controls expressed terms
diffusion processes controls closed form expressions formulated
terms path integrals calculated approximately metropolis hastings
sampling weights control interpreted marginals joint distribution
agent target assignments structure latter represented graphical
model marginals obtained graphical model inference exact inference
graphical model break large systems approximate inference methods
needed use naive mean field approximation belief propagation approximate
optimal control systems linear dynamics compare approximate inference
methods exact solution accurately compute optimal
control finally demonstrate control method multi agent systems nonlinear
dynamics consisting agents reach equal number target states

introduction
topic control multi agent systems characterized many issues originating
sources including wide variety possible execution plans uncertainties
interaction environment limited operation time supporting resources
demand robustness joint performance agents issues encountered
example air traffic management tomlin pappas sastry van leeuwen
hesseling rohling formation flight ribichini frazzoli hu prandini
tomlin radar avoidance unmanned air vehicles fighter aircraft pachter
pachter kamal gu postlethwaite larson pachter mears shi
wang liu wang zu persistent area denial subramanian cruz
liu cruz schumacher castanon pachter chandler
many control approaches multi agent systems stochastic influences dynamics
agents taken account assumed negligible dynamics
c

ai access foundation rights reserved

fivan den broek wiegerinck kappen

modeled deterministically system truly deterministic agents
optimally controlled open loop controls however stochastic influences
dynamics large ignored open loop controls become far optimal
multi agent system longer modeled deterministically
usual
control multi agent systems stochastic dynamics model system
markov decision processes mdp boutilier sadati elhamifar
principle solved discrete space time backward dynamic programming
however discretization make joint state space multi agent system increase
exponentially number agents basic dynamic programming
generally infeasible boutilier attempt overcome exploit structures
describe system factored mdp general structures
conserved value functions exact computations remain exponential
system size guestrin koller parr guestrin venkataraman koller
b assumed predefined approximate structure value functions thereby
provided efficient approximate mdp model multi agent systems similar
taken becker zilberstein lesser goldman assuming independent
collaboration agents global reward function resulting transition independent
decentralized mdps
concentrate multi agent systems agents joint task
reach number target states model multi agent system
continuous space time following wiegerinck van den broek
kappen make following assumptions agents assumed
complete accurate knowledge global state system assumption
dynamics agent additive control disturbed additive wiener noise
assumption performance agents valued global cost function
integral instantaneous costs plus end cost joint task agents modeled
end cost instantaneous costs assumed quadratic control
assumption noise level dynamics agents inversely proportional
control cost assumption finally assume autonomous dynamics
instantaneous costs factorize agents assumption
assumptions optimal control partially solved finding
optimal expected cost go satisfies called stochastic hamilton jacobibellman shjb equation optimal expected cost go given optimal
control provided gradient optimal expected cost go adopting assumption shjb equation nonlinear partial differential equation pde
nonlinearity makes difficult solve common solving shjb equation
assume addition assumption instantaneous costs end cost
cost function quadratic state dynamics linear
state wellthis known linear quadratic control optimal expected cost go
quadratic state time varying coefficients reduces
solving riccati equations coefficients satisfy stengel ksendal
otherwise approximation methods needed approximate given
iterative linear quadratic gaussian method todorov li yields locally optimal feedback control valid case little noise instead follow
fleming adopt assumption assumption shjb equation


figraphical model inference mas optimal control

transformed linear pde performing logarithmic transformation solution
equals expectation value stochastic integral diffusion process general
closed form expression estimate expression formulating
path integral kappen b estimate latter metropolishastings sampling several ways estimate path integral
hamilton monte carlo sampling laplace approximation covered

structure optimal expected cost go generally complex due
dynamic couplings agents adopting assumption agents
coupled joint end cost solely determines structure
optimal expected cost go state transition probabilities factorize
agents follows optimal control becomes weighted combination
single agent single target controls weights given joint distribution
agent target assignments joint distribution structure joint end
cost structure joint distribution representable factor graph
optimal control becomes graphical model inference wiegerinck et al
complexity graphical model inference exponential tree width
factor graph exact inference possible junction tree
given graph sufficiently sparse number agents large
complex situations approximate inference methods necessary
optimal control accurately approximated polynomial time naive mean
field mf approximation belief propagation bp makes distributed coordination
possible multi agent systems much larger could treated
exact inference
organized follows sections provide review
single multi agent stochastic optimal control framework developed kappen b wiegerinck et al example rederive linear
quadratic control general solution given terms path integral explain
approximated metropolis hastings sampling
section give factor graph representation end cost function discuss two graphical model approximate inference methods naive mean field approximation
belief propagation approximation optimal control
methods obtained replacing exact weights controls respective
approximations
section present numerical make comparison approximate
optimal controls infered naive mean field approximation belief propagation
greedy method exact optimal control multi agent system
agents linear dynamics two dimensional state space two target
states furthermore present control multi agent systems nonlinear
dynamics four dimensional state space agents control forward velocity
driving direction controls approximated combination metropolishastings sampling infer path integrals naive mean field approximation infer
agent target assignments allowed us control systems agents
target states regarding nonlinear dynamics illustrative
purpose


fivan den broek wiegerinck kappen

stochastic optimal control single agent
consider agent k dimensional continuous state space rk state x evolving
time according controlled stochastic differential equation
dx b x dt u x dt dw



accordance assumptions introduction control agent
rk valued function u x noise dynamics modeled wiener
process w e normally distributed k dimensional stochastic process continuous
time mean variance k k matrix represents variance
noise autonomous dynamics modeled b rk valued function
x state change dx sum noisy control autonomous
dynamics
behavior agent valued cost function given agents state x x
present time control u expected future cost agent



z


c u x eux x
kru x k v x



expectation eux taken respect probability measure x
solution given control law u condition x x cost
combination end cost x function end state x
integral instantaneous costs instantaneous cost sum state control
dependent term state dependent term v x cost state x
time function v arbitrary represents environment agent
control dependent term kru x k cost control state x time
kzk z z euclidean norm r full rank k k matrix quadratic
control accordance assumption introduction assumption
r related variance noise control via relation
r r



scalar
expected cost go time minimized controls u defines optimal
expected cost go
j x min c u x

u

appendix explained due linear quadratic form optimization
problemthe dynamics linear action u cost function quadratic
actionthe minimization performed explicitly yielding nonlinear partial differential equation j called stochastic hamilton jacobi bellman shjb equation
minimum attained
u x r r x j x



optimal control note explicitely depends state x agent
time making feedback control


figraphical model inference mas optimal control

optimal expected cost go expressed terms diffusion process
derivation refer appendix
j x log z x



z x expectation value



z


z x ex exp
v





diffusion process x satisfying uncontrolled dynamics
dy b dw



substituting relations optimal control terms z x
u x x log z x



example consider agent one dimension state x described dynamical equation without autonomous dynamics b instantaneous cost v zero
end cost quadratic function around target state






diffusion process satisfies uncontrolled dynamics normally distributed
around agents state x time variance hence state
transition probability agent go x space time given
gaussian density


x
x p

exp




expectation value given integral

z x

z





dy x e







r
x
exp

r
r

relation used optimal control follows reads
u x

x

r

well known stengel




fivan den broek wiegerinck kappen

path integral formulation
example shows simple system autonomous dynamics b costs
due environment v write control explicitly
uncontrolled dynamics normally distributed consequently expectation value
quadratic end cost closed form expression general situation b
v arbitrary longer exists explicit expression expectation value
optimal control obtained approximation discuss
done taking path integral kleinert detailed derivation
expressions presented given appendix b
path integral write expectation value path integral
z x lim z x





x x


z x p
det n

z

dx

z



dx tn e x x tn

integral paths x x tn discrete time start x kept fixed
n taken continuous time limit sending length time steps
ti ti zero note limit n goes infinity paths become infinite
dimensional objects function exponent cost path
x x tn
x

n

x

v x ti ti

n

x








x ti x ti

r
b x ti ti




optimal control becomes weighted average controls derived single
path
u x lim


z

dx

z

dx tn p x x tn u x x tn

weights given


p x x tn p

e x x tn
det n z x



control derived path x x tn reads
u x x tn

x x
b x


note depends first two entries x x path




figraphical model inference mas optimal control

path integration metropolis hastings sampling
path integral formulation optimal control generally computed
integral uncountably many paths exist several ways
approximate natural goes stochastic sampling paths several methods
stochastic sampling exist one use known metropolis hastings
sampling hastings implementation time discretized take
limit decreasing zero instead keep fixed value sample path
sequence xs xs tn vectors state space rk x x
current state agent current time according equation
need xs xs derive control sample path x x tn
metropolis hastings sampling ensures different paths properly weighted hence
optimal control approximated follows
u x

hx x
b x




hx mean value xs taken sample paths pseudo code
given
metropolis hastings sampling
input initial path x x tn

repeat times
define gaussian proposal distribution centered around x x tn
variance equal noise
draw sample path x x tn proposal distribution

exp x x x tn x x x tn


set x x tn x x tn
else

set x x tn x x tn probability
end
xs xs tn x x tn

end repeat
compute approximate control equation

stochastic optimal control multi agent system
turn issue optimally controlling multi agent system n agents
principle theory developed single agent straightforwardly generalizes multiagent situation agent k dimensional state xa satisfies dynamics similar

dxa ba xa dt ua x dt dwa

accordance assumptions introduction note control
agent depends state xa joint state x x xn


fivan den broek wiegerinck kappen

system system joint cost function similar depending joint
state x joint control u u un system



n z
x

u
u


c x ex x
kra ua x k v xa




expectation eux taken respect probability measure x
solution given control law u condition x x cost
combination joint end cost x function joint end state x
integral instantaneous costs instantaneous cost factorizes agents
accordance assumption introduction agent sum state
dependent term v xa control dependent term kra ua xa k similar
single agent case accordance assumption introduction control cost
agent related noise agents dynamics via relation
ra ra
agent joint cost function minimized joint
control yielding optimal expected cost go j optimal expected cost go
expressed terms diffusion process via relation
j x log z x
z x joint expectation value


n z
x

v ya
z x ex exp








yn diffusion processes yn x satisfying
uncontrolled dynamics
dya ba ya dwa

n



multi agent equivalent optimal control reads
ua x xa log z x



optimal control agent understood expected
control integral target states ya transition probability target
times optimal control target end write expectation
integral end state
z
n


z x dye
za ya xa



za ya xa implicitly defined



z
z

v ya
dya za ya xa f ya exa f ya exp



figraphical model inference mas optimal control

arbitrary functions f substituting yields
z
ua x dya pa ya x ua ya xa




ua ya xa xa log za ya xa



optimal control agent go state xa current time state ya
end time pa ya x marginal
n




p x
za ya xa
e
z x


discrete end states
agents fulfill task arriving number target states end time
according initially specified way example arrive
target arrive different targets targets considered regions
g gm state space end cost modeled follows


e

x


w

n


wa ya sa



wa ya sa e ya sa





sum runs assignments sn agents regions gsa ya sa
cost function associated region gsa returning low cost end state ya agent
lies region gsa high cost otherwise w weight grading assignments
thereby specifying joint task agents assignments better
fulfillment task higher weight situation agents go
target example vector assigns agent different target
low weight w
choice end cost equation factorizes
z x

x



za sa xa

z

w

n


za sa xa



dya za ya xa wa ya sa



interpretation za sa xa log za sa xa expected cost agent
move xa target sa optimal control single agent becomes
ua x


x

p sa x ua sa xa



sa


ua sa xa xa log za sa xa




fivan den broek wiegerinck kappen

control agent go target sa weights p sa x single agent
marginals
x
p x

p sa x
sa

joint distribution
n



p x
za sa xa

w
z x





weight p x
pnt equals ratio exp j x exp j x j x
log w log za sa x optimal expected cost go case agents
predetermined targets specified assignment assignment agents
targets low expected cost j x yield high weight p x
associated single agent single target controls ua sa xa predominant
optimal controls ua x
metropolis hastings sampling multi agent systems
general controls ua sa xa marginals p sa x optimal control closed form solution inferred approximately
controls ua sa xa approximated metropolis hastings sampling discussed
section inference marginals involves inference path integral formulations za sa xa
z
z


za sa xa lim p
dxa dxa tn e xa xa tn sa

n

det
xa xa

xa xa tn sa xa sa


n

x

v xa ti ti



n

x






xa ti xa ti

ra
ba xa ti ti




value za sa xa generally hard determine mackay possible approximations include maximum posteriori map estimate inclusion variance
sample paths third approximation take average path costs
estimate log za sa xa means entropy distribution path
integral neglected

graphical model inference
additional computational effort multi agent control compared single agent control
lies computation marginals p sa x joint distribution p x
involves sum mn assignments small systems feasible large
systems summation performed efficiently efficient
provided graphical model inference relies factor graph representation
joint distribution


figraphical model inference mas optimal control



















figure example factor graph multi agent system four agents couplings
represented factors

factor graph representation joint distribution
complexity joint distribution part determined weights w end
cost function weights determine agents consider states
agents complex case way one agent takes state another agent
account depend states agents situation less complicated
agent considers states agents independently states others
means joint end cost factorized form

w
wa sa



subsets agents structure represented graphically called factor
graph kschischang frey loeliger see figure example agents
factors nodes factor graph represented circles squares respectively
edge agent factor member subset
wa factorization w depends sa immediate
joint distribution p x factorizes according factor graph
junction tree
efficient inference distribution p x means factor graph representation
accomplished junction tree lauritzen spiegelhalter
complexity exponential induced tree width graph small
tree width expected systems factor graph sparse case
agents take states account limited number agents
implies multi agent systems sparse graphs limited number targets
tractable wiegerinck et al factor graph figure example sparse
graph hand agent take state agent account
junction tree really help underlying factor graph fully
connected tree width graph equals number agents system
exact computation optimal control intractable large complex multiagent systems since junction tree requires memory exponential tree
width factor graph instead use graphical model approximate inference
methods approximately infer marginals proceed discussion
two methods naive mean field mf approximation jordan ghahramani jaakkola
saul belief propagation bp kschischang et al yedidia freeman
weiss


fivan den broek wiegerinck kappen

naive mean field approximation
starting point note optimal expected cost go log partition sum
known free energy consider variational free energy
x
f q h log wiq
hlog za iqa h q


h iq h iqa denote expectation values respect distribution q marginals
qa respectively h q entropy q
x
h q
q log q


optimal expected cost go equals variational free energy minimized distributions q naive mean field approximation
one considers variational free energy
q
restricted factorized distributions q qa sa minimum
f q
jmf min
q
q

qa

upper bound optimal expected cost go j equals j case agents
uncoupled f zero gradient local minima


f q qn sn
qa sa

n



additional constraints normalization distributions qa solutions set
equations implicitly given mean field equations
za sa hw sa iq
qa sa pn


sa za sa hw sa iq



hw sa iq conditional expectation w q given sa

x
qa sa w sn
hw sa iq
sn sa



mean field equations solved means iteration procedure
convergence local minimum free energy
mean field approximation optimal control found taking gradient
respect x minimum jmf free energy similar exact case
optimal control gradient optimal expected cost go equation

x

ua x xa jmf x
qa sa ua xa sa




similar exact case average single agent single target optimal controls
ua xa sa given equation average taken respect mean
field approximate marginal qa sa agent


figraphical model inference mas optimal control

belief propagation
belief propagation approximate free energy bethe free energy
minimize latter bethe free energy defined
fbethe qa qa

x

h log wa iqa



x

h log za iqa



x

h qa



x

na h qa




function beliefs qa sa qa sa non negative normalized functions
satisfy consistency relations


x

qa sa qa sa

sa

h qa h qa entropies beliefs qa qa na denotes number
neighbors node factor graph
belief propagation computes beliefs kschischang et al
case joint distribution p factor graph representation tree belief propagation converge beliefs exact marginals p bethe free energy
beliefs equals optimal expected cost go j factor graph representation
p contains cycles may still apply belief propagation yedidia et al showed
fixed points correspond local extrema bethe free energy
particular advanced variations heskes albers kappen
teh welling yuille guaranteed converge local minima bethe
free energy heskes
bp approximation optimal control taking gradient
minimum jbethe bethe free energy
x

ua x xa jbethe x
qa sa ua xa sa




ua xa sa given equation similar exact case mean field
approximation bp approximation optimal control average single agent
single target optimal controls average taken respect belief qa sa

numerical
section present numerical simulations optimal control multiagent systems computing optimal controls consists two parts
inference single agent single target controls inference
marginals global distribution agent target assignments dynamics linear instantaneous costs v zero single agent single target
controls given closed form multi agent systems therefore know issue
infering marginal distributions section consider multi agent systems
kind section deals general infering optimal controls
dynamics nonlinear instantaneous costs v nonzero sections


fiexpected target

van den broek wiegerinck kappen

position









time










positions




time





b expected targets

figure two agents noise control positions need reach target locations end time agent different target location
positions expected targets b time

joint end cost given equation
w

n

b

wa b sa sb

c

wa b sa sb exp sa sb
n








ya sa ya sa
wa ya sa exp ya sa


c determines coupling strength agents sa target
states
linear dynamics
begin illustration optimal control showing simulation exactly
solvable stochastic multi agent system system two agents one dimension
agents satisfy dynamics ba equal zero two target states x
x task agents one go different target
instantaneous costs v cost function zero end cost function given
equations c negative sign coupling
strength c implies repulsion agents control cost parameter r equals
noise level lies agents start x time end time lies
prevent overshooting targets udt small compared distance
target states done choosing dt
p
figure shows agents positions expected targets
sa p sa x sa
time see time agents decided target
go remain two targets final decision
seems made delayed choice due symmetry breaking cost togo time increases symmetry breaking better keep options open
see effect noise symmetry breaking time short wait
longer choice made phenomenon typical multi modal
proceed quantitative comparison different control methods arise
exact approximate inferences marginals joint distribution


figraphical model inference mas optimal control









cpu time

cost difference
























noise







costs






noise





b cpu time

figure deviation optimal cost required cpu time seconds
b functions noise lines represent exact greedy mf
bp control

example consider multi agent system n agents two dimensional
state space zero instantaneous costs v autonomous dynamics ba
end cost function given equations two targets located
c control cost matrix r equals
identity matrix agents start time end time lies
time steps size dt
approximations naive mean field approximation belief propagation described section greedy control greedy control mean time step
agent chooses go nearest target include approximation
simple requires little computation time reasons obvious choice
naive approximation greedy control policy neglects choices
agents expect give inferior performance
approximation figure shows cost approximate optimal
control minus cost exact optimal control averaged simulations
different noise levels noise samples used approximate exact
control see naive mean field approximation belief propagation yield
costs average coincide cost exact control average cost difference
methods significantly differ zero greedy control
hand yields costs significantly higher costs exact control
deterministic limit converge cost exact control controls
coincide figure b shows cpu time required calculation controls
different control methods average cpu time entire simulation
simulation consists time steps time step control calculated
agent observe greedy control least times faster methods
exact control nearly times time consuming methods belief
propagation gives performance considered noise levels bit quicker
naive mean field approximation may implementation details
done simulations attractive coupling c returned similar
ones repulsive coupling c presented


ficumulative control cost

van den broek wiegerinck kappen











time





figure cumulative control cost time case strong repulsive coupling
c low noise level curves represent exact mf
bp control

although figure suggests belief propagation naive mean field approximation
perform equally well case since certain combinations noise
level coupling strength bp control costly mf control exact
control origin difference lies symmetry breaking tends occur
later bp earlier mf compared exact control observe
figure shows cumulative cost time control methods
multi agent system coupling strength c fixed noise level
cumulative costs averages simulations cost mf control lies
bit higher cost exact control whereas cost bp control initially
lower cost control methods starts increase
much faster eventually ends higher including end costs found total costs
exact control mf control bp
control suggests better early symmetry breaking late
symmetry breaking
time required computing control methods depends
number agents multi agent system figure shows required cpu time
function number agents n two dimensional multi agent system considered
see exact method requires cpu time increases exponentially
number agents may expected theory
exact method uses junction tree complexity exponential
tree width underlying graph e exponential n greedy method
cpu time increases linearly number agents agreement
fact greedy control coupling agents required cpu
time increases polynomially mean field approximation belief propagation
nonlinear dynamics
turn multi agent systems nonlinear dynamics control systems
must approximate graphical model inference well single agent singletarget control consider multi agent system agents move


figraphical model inference mas optimal control




cpu time






















agents





figure required cpu time seconds calculation controls different
number agents exact greedy mf bp control

two dimensions four dimensional state specified agents location
xa ya forward velocity va driving direction dynamics agent
given equations
dxa va cos dt
dya va sin dt
dva ua dt dwa
da dt da
first two equations model kinematics agents position given forward
velocity driving direction last two equations describe control speed
driving direction application forward acceleration ua angular velocity
noise control modeled standard normal wiener processes wa
noise level parameters note noise act dimensions
control although control space counts less dimensions
state space example fit general framework refer appendix c
details
look two different tasks first task obstacle avoidance multiagent system three agents agents reach one three target locations
avoid obstacles environment target location reached precisely
one agent model end cost function given equations
c targets located
agents arrive zero velocity control cost matrix r identity matrix
instantaneous cost v equaled locations obstacles zero
otherwise agents start time end time lies time steps dt
size starting locations agents
agents start zero velocity sample paths discrete time paths twodimensional space forward velocity v driving direction specified
values times ti n nt
n value
time equals current state one agents value time tn equals
one target end states control agent one targets computed


fivan den broek wiegerinck kappen





































trajectories













b sample paths

figure three agents noise control forward velocities driving directions reach three targets marked x environment containing
number walls agent starts different location marked
zero forward velocity agent arrive different target
zero velocity without hitting walls trajectories agents
followed reach targets b sample paths

metropolis hastings sampling paths according subsection proposal
distribution n dimensional gaussian centered around agents current planned
path variance equal noise level agents dynamics expectation
values za sa xa estimated average costs sample paths
tried map estimation za sa xa inclusion variance sample paths
former significant difference latter returned estimates
fluctuated heavily figure shows environment trajectories agents
starting locations targets agent manages avoid obstacles
arrive one targets zero velocity target reached different
agent
second task coordination multi agent system shown figure system instantaneous costs v agents move
initial positions number target locations arrive
locations zero velocity horizontal driving direction equal number
agents target locations agent reach different target initial
locations aligned vertically target locations vertical displacement two thus agents coordinate movements order
reach targets satisfactory way
agents start time end time lies make time steps size

dt n
n dt time step controls computed
metropolis hastings sampling paths naive mean field approximation infer
marginals pa sa x weigh single agent single target controls equations
sample paths discretized seven equidistant time points
present time end time proposal distribution taken gaussian


figraphical model inference mas optimal control

centered around agents current planned path variance equal noise
level agents dynamics figure shows example trajectories system
agents obtained sample paths per agent target combination
observe agents reach targets target reached precisely one
agent required due noise second order dynamics agents takes
agents less effort target remain since former allows
exploitation noise latter requires constant correction state changes
caused noise trajectories agents curved
elongated would expected situation without noise simulation
carried well larger number agents figure b shows required cpu time
function number agents exact mf inference marginals
agents note complexity graphical model inference scales
nn n number agents exact inference junction tree
feasible n

discussion
studied use graphical model inference methods optimal control stochastic
multi agent systems continuous space time agents joint task
reach number target states rather discretizing commonly done typically
makes large systems intractable due curse dimensionality followed
developed wiegerinck et al modeling system continuous space time
certain assumptions dynamics cost function solution given
terms path integral
path integral computed closed form special cases
linear quadratic case general approximated done
variety methods method considered mcmc sampling
dimension sample paths kept low n limit curvature sample
paths gain limiting curvature variance samples reduced
less samples needed limiting curvature however introduce bias
addition presence obstacles insufficient curvature would make sampler return
sample paths run obstacles believe advanced mcmc
methods hybrid mc sampling duane kennedy pendleton roweth
overrelaxation neal improve inference path integrals
apart mcmc sampling approximation methods one could
consider laplace approximation variational approximation laplace
approximation becomes exact noiseless limit could useful low noise regimes
well variational approximation approximates path integral gaussian
process archambeau opper shen cornford shawe taylor could particularly useful high noise regime drawback variational however
cannot straightforwardly applied situations infinite instantaneous costs
hard obstacles environment considered
wiegerinck et al showed systems sufficiently sparse
single agent single target controls determined closed form e g linearquadratic control time independent coefficients exact inference achieved


fivan den broek wiegerinck kappen






































trajectories






cpu time





















number agents



b cpu time

figure trajectories agents starting locations targets x b
required cpu time seconds function number agents
number targets equal number agents lines represent exact
mf inference marginals



figraphical model inference mas optimal control

junction tree van den broek wiegerinck kappen considered
multi agent system second order dynamics linear autonomous dynamics zero
instantaneous costs showed graphical model inference naive mean field approximation significantly outperformed greedy inference showed close
optimal achieved well dense systems graphical model approximate
inference methods approximation methods considered naive mean field
approximation belief propagation demonstrated performances example
system exact inference significantly time consuming mean field approximation showed work well returning costs control equal optimal ones belief
propagation performed similarly certain value ratio coupling strength
noise level symmetry breaking control process takes place earlier
mean field approximation compared exact inference later belief propagation early symmetry breaking increase costs coordination much
however late symmetry breaking making performance belief propagation
suboptimal
variations considered case possible within general framework
wiegerinck van den broek kappen discuss situations agents sequentially
visit number targets end time fixed focusses prefered
trajectories state space time instead prefered states end time
achieved modeling path cost way similar modeled end cost
agents intercept moving target noisy dynamics
covered
control formalism developed kappen b applied multi agent
coordination wiegerinck et al article demands noise
control act dimensions one way satisfy constraint assume
agents identical addition single agent dynamics
noise control act dimensions saw two dimensional
second order system section condition satisfied natural way however
general one think examples control equation violated
interesting future direction investigate extend path integral
used approximation cases
assumes joint state space agents observable agents
large multi agent systems however realistic agent observes
state states agents physically nearby
directly apply situations depending joint task agents may
valid approximation optimal control sub system consisting agents
one agent observe task agents avoid collisions
sufficient consider states agents nearby task go
target crucial information states
agents natural alternative deal partial observability describe multi agent
system decentralized pomdp seuken zilberstein clear however
would combine path integral formalism
topic learning addressed clearly great
interest however one could argue sampling procedure compute path integral


fivan den broek wiegerinck kappen

corresponds learning environment discussion line thought
found kappen
many possible model extensions worthwhile exploring future
obvious examples bounded controls limited observation global state
system issues already interest study single agent situation others
apply typically multi agent situation context physical agents introducing penalties collisions agents would become relevant typically types
model extensions solution closed form require additional
approximate numerical methods suggestions given kappen b
acknowledgments
thank reviewers useful comments thank joris mooij making
available useful software www mbfys ru nl jorism libdai part
interactive collaborative information systems icis project supported dutch
ministry economic affairs grant bsik

appendix stochastic optimal control
appendix give derivation starting
detailed discussions found many works stochastic optimal control
example kushner fleming rishel fleming ksendal
stengel kappen b
optimal expected cost go j state x time defined
j x min c u x
u


u

c x

eux


z
x












kru x k v x






expected cost given control law u equations
main text first j satisfies stochastic hamilton jacobi bellman shjb
equation






j min
kruk b u x j tr x j v

u



boundary condition j x x equation derived following way
moment time holds


z


u
ds
kru x k v x
j x
c x




z


u
kru x k v x
ds
min ex j x
u


min eux
u

first line follows dividing integral two integrals one
one definition cost function c second line


figraphical model inference mas optimal control

follows definition j rewriting yields


z
j x j x


u

min ex
ds

kru x k v x
u



taking limit obtain


dj x

u
kru x k v x
min ex
u
dt




subsequently apply dj x well known chain rule diffusion processes
dj x

x j x


xi

dxi

j x
x j x
dt
dxi dxj


xi xj
j

differs chain rule deterministic processes contains term
quadratic dx extra term vanish wiener process appearing
dynamics quadratic variation increases linear time
eux dwi dwj ij dt



follows expectation dxi dxj equal ij dt substituting dynamics taking expectation values obtain



j x
j x
j x
u
dt b x u x
dt tr
dt
ex dj x

x
xx
substitution equation yields equation
minimum right hand side equation given
u r r x j
optimal control
minimization removed inserting optimal control yields
nonlinear equation j remove nonlinearity logarithmic transformation introduce constant define z x j x log z x



u r ru u x j z x z r r x z







tr x j

z x z x z z tr x z




terms quadratic x z vanish r related via equation
r r
relation satisfied shjb equation becomes



v



z
b x tr x z


hz




fivan den broek wiegerinck kappen

h linear operator acting function z
equation must solved backwards time boundary condition z x


e x present solution terms forward diffusion process common theory stochastic processes give solutions partial differential equations
terms diffusion processes solution equation expectation value



z


z x ex exp
v





process satisfies uncontrolled dynamics
dy b dw
x expectation ex taken respect probability measure
satisfies uncontrolled dynamics condition x clear
matches boundary condition verify satisfies equation let


z

v
exp

see


v dt


let f function f exp use chain rule stochastic
processes apply f
di

k
k
x
f
x f
dyi
dyi dyj
df
yi

yi yj

j


f
b dw






f
tr


yy

choose dt combine identity previous one
obtain
df f di df
hf dt f dw
taking expectation value sides makes term f dw disappear
remaining part
de f f dt
equation


figraphical model inference mas optimal control

appendix b path integral formulation
going write expectation value path integral partitioning time
interval n intervals equal length tn
expectation value written follows
z x

z

dx

z



dxn e xn

n



z xi ti xi ti





x x z xi ti xi ti implicitly defined




z
z

ti

dxi z xi ti xi ti f xi e f xi exp
v fiy ti xi
ti

arbitrary functions f limit infinitesimal z xi ti xi ti satisfy



z xi ti xi ti xi ti xi ti exp v xi ti



xi ti xi ti transition probability uncontrolled dynamics go
xi ti xi ti space time transition probability given



k xi xi b xi ti k

xi ti xi ti p
exp

det
follows dynamics

xi xi b xi ti w
infinitesimal time interval observation wiener process w normally distributed around zero variance equation may rewrite
transition probability





x

x


exp
xi ti xi ti p
r
b xi ti






det

obtain path integral representation z x combining equations
limit going zero
z x lim z x





x x




z x p
det n

x xn xn

n

x

z

dx

v xi ti

z

n

x








dxn e x xn




xi xi


b xi ti
r




fivan den broek wiegerinck kappen

optimal control given equation proportional gradient
log z x substituting path integral representation z x
u x lim


lim


z

z

dx
dx

z

z



e x xn

dxn p
x
det n z x





x xn


dxn p x xn u x xn


u x xn




x x
b x



e x xn
p x xn p

det n z x

note control u x xn path x xn depends
first two entries x x path

appendix c dimension reduction
derivation path integral appendix b given case
state control k dimensional particular case dimensions
state controlled deduced taking limit infinite control cost along
dimensions without control control along latter dimensions becomes zero
seen equation noise dimensions equal zero accordance
relation path integral formalism transition probabilities
reduce delta functions along dimensions without control implications
mcmc sampling dimension space sample reduced
since sampling performed dimensions noise

references
archambeau c opper shen cornford shawe taylor j variational inference
diffusion processes advances neural information processing systems
becker r zilberstein lesser v goldman c v transition independent decentralized markov decision processes proceedings second international joint conference
autonomous agents multiagent systems pp
becker r zilberstein lesser v goldman c v solving transition independent
decentralized markov decision processes journal artificial intelligence

boutilier c learning coordination multiagent decision processes
proceedings sixth conference theoretical aspects rationality knowledge pp

castanon pachter chandler p r game deception proceedings
rd ieee conference decision control pp
duane kennedy pendleton b roweth hybrid monte carlo physics letters
b


figraphical model inference mas optimal control

fleming w h exit probabilities optimal stochastic control applied mathematics
optimization
fleming w h rishel r w deterministic stochastic optimal control springerverlag york
guestrin c koller parr r multiagent factored mdps advances
neural information processing systems vol pp
guestrin c venkataraman koller b context specific multiagent coordination
factored mdps eighteenth national conference artificial intelligence
pp
hastings w monte carlo sampling methods markov chains applications
biometrika
heskes stable fixed points loopy belief propagation minima bethe free
energy advances neural information processing systems vol pp
heskes albers k kappen b approximate inference constrained optimization
proceedings th conference uncertainty artificial intelligence pp
hu j prandini tomlin c conjugate points formation constrained optimal
multi agent coordination case study siam journal control optimization

jordan ghahramani z jaakkola saul l introduction variational methods
graphical learning graphical mit press cambridge
kamal w gu w postlethwaite real time trajectory uavs
milp proceedings th ieee conference decision control european
control conference pp
kappen h j path integrals symmetry breaking optimal control theory journal
statistical mechanics theory experiment p
kappen h j b linear theory control nonlinear stochastic systems physical review
letters
kappen h j introduction stochastic control theory path integrals reinforcement
learning aip conference proceedings vol pp
kleinert h path integrals quantum mechanics statistics polymer physics financial markets world scientific singapore
kschischang f r frey b j loeliger h factor graphs sum product
ieee transactions information theory
kushner h j stochastic stability control academic press inc york
larson r pachter mears path unmanned air vehicles
engaging integrated radar network proceedings aiaa guidance navigation
control conference exhibit
lauritzen spiegelhalter local computations probabilities graphical structures application expert systems discussion j royal statistical society
series b
liu cruz j b schumacher c j pop threat persistent area denial
ieee transactions aerospace electronic systems
mackay j information theory inference learning cambridge university press
neal r learning graphical pp kluwer academic publishers


fivan den broek wiegerinck kappen

ksendal b stochastic differential equations introduction applications springerverlag
pachter l pachter optimal paths avoiding radiating source proceedings
th ieee conference decision control pp
ribichini g frazzoli e efficient coordination multiple aircraft systems proceedings
nd ieee conference decision control vol pp
sadati n elhamifar e semi decentralized control multi agent systems
redundant manipulator optimization methods proceedings th ieee international
workshop advanced motion control pp
seuken zilberstein formal decentralized decision making
uncertainty journal autonomous agents multi agent systems
shi x wang x liu wang c zu c optimization fighter aircraft evasive trajectories radar threats avoidance proceedings ieee international conference
control automation pp
stengel r optimal control estimation dover publications york
subramanian k cruz j b adaptive pop threats multi agent
persistent area denial proceedings nd ieee conference decision control
pp
teh welling unified propagation scaling advances
neural information processing systems vol pp
todorov e li w generalized iterative lqg method locally optimal feedback
control constrained nonlinear stochastic systems proceedings american control
conference pp
tomlin c pappas g j sastry conflict resolution air traffic management study
multiagent hybrid systems ieee transactions automatic control
van den broek b wiegerinck w kappen b optimal control large stochastic multiagent systems proceedings seventh symposium adaptive learning agents
multi agent systems pp
van leeuwen p hesseling h rohling j scheduling aircraft constraint satisfaction
electronic notes theoretical computer science
wiegerinck w van den broek b kappen b stochastic optimal control continuous
space time multi agent systems proceedings nd conference uncertainty
artificial intelligence pp
wiegerinck w van den broek b kappen b optimal line scheduling stochastic
multi agent systems continuous space time proceedings sixth international joint
conference autonomous agents multiagent systems pp
yedidia j freeman w weiss generalized belief propagation advances neural
information processing systems vol pp
yuille cccp minimize bethe kikuchi free energies convergent
alternatives belief propagation neural computation




