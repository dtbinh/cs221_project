journal artificial intelligence

submitted published

location reasoning complex multi agent behavior
adam sadilek
henry kautz

sadilek cs rochester edu
kautz cs rochester edu

department computer science university rochester
rochester ny usa

abstract
recent shown surprisingly rich human activity learned
gps positional data however effort date concentrated modeling single individuals statistical properties groups people moreover prior work focused solely modeling
actual successful executions failed attempted executions activities interest
contrast take task understanding human interactions attempted interactions
intentions noisy sensor data fully relational multi agent setting use real world
game capture flag illustrate well defined domain involves many
distinct cooperative competitive joint activities model domain markov logic
statistical relational language learn theory jointly denoises data infers occurrences high level activities player capturing enemy unified model combines
constraints imposed geometry game area motion model players
rules dynamics game probabilistically logically sound fashion
may impossible directly detect multi agent activity due sensor noise malfunction occurrence activity still inferred considering impact
future behaviors people involved well events could preceded
given model successfully performed multi agent activities along set
examples failed attempts activities system automatically learns augmented
model capable recognizing success failure well goals peoples actions
high accuracy compare alternatives unified model
takes account relationships among individual players relationships
among activities entire length game although computationally costly significantly accurate finally demonstrate explicitly modeling unsuccessful attempts
boosts performance important recognition tasks

introduction
society founded interplay human relationships interactions since every person tightly embedded social structure vast majority human behavior fully
understood context actions others thus surprisingly evidence shows want model behavior person single best predictor often
behavior people social network instance behavioral patterns people taking taxis
rating movies choosing cell phone provider sharing music best explained predicted
habits related people rather single person attributes age race
education bell koren volinsky pentland
contrast observations effort activity recognition date concentrated modeling single individuals bui liao fox kautz statistical
properties aggregate groups individuals abowd atkeson hong long kooper pinkerton
horvitz apacible sarin liao combinations eagle pentland
c

ai access foundation rights reserved

fis adilek k autz

notable exceptions isolated individuals includes work kamar horvitz
gupta srinivasan shi davis simple relationships among people
starting explicitly considered leveraged instance eagle pentland
elegantly model location individuals multi modal sensory data
oblivious explicit effects ones friends relatives etc ones behavior isolated individuals approximations often made sake tractability representational convenience
considering individuals independently sufficient constrained tasks
many interesting domains discards wealth important information inefficient unnatural data representation hand decomposing domain set
entities representing instance people objects environment activities linked
relationships e g involved natural clear way representing
data
address shortcomings nonrelational behavior modeling introduce capture
flag domain described argue statistical relational learning
multi agent behavior raw gps data ctf dataset one hand quite complex
recorded real world sensors time well defined per rules game
thereby allowing unambiguous evaluation
able recognize peoples activities reason behavior necessary precondition intelligent helpful machines aware going
human machine well human human relationships many exciting practical applications activity recognition potential fundamentally change peoples lives
example cognitive assistants help people teams productive provide support
groups disabled individuals efficiently summarize long complex event busy person
without leaving essential information important applications include intelligent navigation security physical well digital human computer interaction crowdsourcing
applications myriad others build top multi agent activity recognition therefore require necessary stepping stone furthermore consequence anthropocentrism
technology modeling human behavior playsperhaps surprisinglya significant role even
applications directly involve people e g unmanned space probes
furthermore reasoning human intentions essential element activity recognition
since recognize person group people wants proactively
try help orin adversarial situationshinder intent notoriously problematic
quantify e g baldwin baird capture flag domain notion
naturally captured process learning structure failed activities know perhaps
well successful action often precededand unfortunately sometimes followedby
multiple failed attempts therefore reasoning attempts typically entails high practical utility
relatively high frequency consider example task real time analysis
security video system detecting person group people relations
intend steal something much important useful recognizing theft taken
even taking place certainly late entirely prevent incident
may late harder merely stop believe recognition attempts peoples
activities severely underrepresented topic artificial intelligence needs explored
since opens realm interesting possibilities
delve details sections briefly introduce
ctf dataset section highlight main contributions work section review


fil ocation r easoning c omplex ulti agent b ehavior

background material section discuss related work conclude outline future work
sections respectively
incorporates extends previous work sadilek kautz b

capture flag domain
imagine two teamsseven players eachplaying capture flag ctf university campus
player carries consumer grade global positioning system gps logs location
plus noise every second see figure primary goal enter opponents flag area
players captured enemy territory tagged enemy upon
captured must remain place freed tagged teammate game ends
games involve many competitive cooperative activities focus successful
attempted capturing freeing visualization games available first authors
website
collected four games ctf portion university rochester campus
acres columbus v gps loggers one per player gb memory card
set sampling rate hz durations games ranged approximately
minutes
work primarily motivated annotating strategy games although
obvious applications sports combat situations generally exploring relational learning inference methods recognizing multi agent activities
location data accept fact gps data disposal inherently unreliable
ambiguous one individual therefore focus methods jointly simultaneously
localize recognize high level activities groups individuals
although ctf domain doesnt capture intricacies life contains many complex interesting yet well defined multi agent activities moreover extensive
real world gps data total data points thus addressing clearly direct analogs everyday life situations ubiquitous computing needs
addressimagine people going daily lives city instead ctf players
smart phones instead gps loggers
one main challenges overcome successfully model ctf
severe noise present data accuracy gps data varies meters
open areas readings typically meters discrepancy much higher locations
tall buildings present within game area obstructions compare
scale error granularity activities concern capturing
freeing involves players within reaching distance less meter apart therefore
signal noise ratio domain daunting
error systematic component well significant stochastic component errors
devices poorly correlated subtle differences players angle
device sits players pocket dramatically affect accuracy moreover since
consider multi agent scenarios errors individual players readings add thereby
creating large discrepancy reality recorded dataset players
move freely open areas cannot reduce data error assuming players move
along road walkways done much work gps activity recognition e g liao
et al finally traditional techniques denoising gps data kalman filtering



fis adilek k autz

figure snapshot game capture flag shows game area players
represented pins letters version ctf two flags stationary
shown white circles near top bottom figure horizontal road middle image territory boundary data shown prior
denoising corrections map errors videos games available
http www cs rochester edu u sadilek


fil ocation r easoning c omplex ulti agent b ehavior

little help due low data rate sample per second relative small amount time
required player completely change speed direction
reliably recognize events happen games presence severe
noise need consider player relationships among
actions extended periods time possibly whole length game consider concrete
task inferring individual joint activities intentions ctf players gps
traces example suppose gps data shows player running toward stationary teammate
b moving away occurred possibly player freed player b gps error
hidden fact player actually reached b another possibility player
intention freeing player b scared opponent last second yet another possibility freeing occurred even intended player b previously
captured
understanding game thus consists inferring complex set interactions among
players well players intentions conclusions drawn occurs one point
time affect affected inferences past future events example given
recognizing player b moving future reinforces conclusion player freeing
player b failing recognize past event player b captured decreases confidence
conclusion game ctf illustrates understanding situation much
recognizing attempts intentions recognizing successfully executed actions
example course minute game handful capture freeing events occur however
dozens cases one player unsuccessfully tries capture opponent free
teammate description game restricted actually occurred would
pale reflection original

figure three snapshots game situation successful failed capturing occur
example illustrates need exploits relational
far reaching temporal structure domain see text explanation

concrete example consider real game situation illustrated figure see three
snapshots game projected map campus modification gps data
game time shown snapshot players f g allies currently
home territory near flag whereas players l enemies first snapshot
players l head opponents flag thenin second framethey intercepted
g point unclear happening substantial error gps data



fis adilek k autz

three players appear close actuality could
meters apart however see third snapshot note tens seconds passed
realize player g actually captured player didnt capture l since g evidently
still chasing l fact player remains stationary coupled fact neither f
attempt capture suggests indeed captured possible infer
occurrences capturing events even complex situations whereas limited approaches
largely fail however need able recognize individual events need
discover activities identify respective goals distinguish events
whether outcomes favorable negative instance second frame player g tries
capture l although succeeded former case failed latter
many different kinds cooperative competitive multi agent activities occur games
lowest level joint activities location movement include approaching
location note noise gps data often makes difficult impossible
directly detect simple activities next level come competitive multi agent activities
including capturing attacking cooperative activities include freeing activities
chasing guarding may belong category categories
abstract tactical activities making sacrifice overall strategies
playing defensively concentrate activities first two levels

contributions
main contributions follows first present novel method simultaneously denoises positional data learns model multi agent activities occur
subsequently evaluate model ctf dataset achieves high accuracy
recognizing complex game events
however creating model manually writing rules editing existing axioms
laborious prone introduction errors unnecessarily complex theories thus would
automate process learning inducing axioms training data people
much easier provide validate concrete examples directly modify model
leads us second contribution automatically augment preexisting model
joint activities capable recognizing successful actions identifies
failed attempts types activities line work demonstrates explicitly
modeling attempted interactions unified way improves overall model performance
third contribution demonstrate difference discussed
newly learned definitions failed activity original definition corresponding successful activity directly corresponds goal given activity instance per rules
capture flag game captured player cannot move freed system induces
definition failed capture theory contain constraint movement
almost captured player thereby allowing move freely

background
cores described implemented markov logic ml statisticalrelational language section provide brief overview ml extends finite firstorder logic fol probabilistic setting detailed excellent treatment fol



fil ocation r easoning c omplex ulti agent b ehavior

ml inductive logic programming see work shoenfield domingos kok lowd
poon richardson singla de raedt kersting respectively
order compare markov logic alternative approaches consider
dynamic bayesian network dbn model experiments one baselines
therefore review relevant aspects dbns section well
markov logic
given inherent uncertainty involved reasoning real world activities observed
noisy sensor readings looked methodology would provide elegant combination
probabilistic reasoning expressive relatively natural compact unfortunately strictly
true false formulas first order logic exactly markov logic provides thus
allows us elegantly model complex finite relational non domains markov logic network
mln consists set constants c set pairs hfi wi fol formula
weight wi r associated optionally weight scaled
real valued function subset variables appear corresponding formula markov
logic networks contain functions called hybrid mlns wang domingos
mln viewed template markov network mn follows mn contains
one node possible ground atom mln value node corresponding
atom false otherwise two nodes connected edge corresponding atoms
appear formula thus mn distinct clique corresponding grounding
g
formula j denote j th grounding formula mn feature value j
gj


g
j true
j
otherwise
weight wi intuitively represents relative importance satisfying violating
weight negative corresponding formula formally weight scales difference
log probability world satisfies n groundings corresponding formula one
true groundings formula else equal cf equation thus
satisfiability relaxed mlns longer search satisfying truth assignment
traditional fol instead looking truth assignment maximizes sum
weights satisfied formulas
weights specified knowledge base engineer
learned training data provide learning labeled capture instances pairs raw corresponding denoised trajectories along labeled instances
game events finds optimal set weights maximize likelihood training
data weight learning done generative discriminative fashion generative training maximizes joint probability observed evidence well hidden query predicates
whereas discriminative learning directly maximizes conditional likelihood hidden predicates given observed predicates since prior work demonstrated markov network
learned discriminatively consistently outperform generatively trained counterparts singla
domingos focus discriminative learning activity recognition domain
knowledge base weights specified ask questions state
hidden atoms given state observed atoms let x vector random variables
one random variable possible ground atom mn let set possible


fis adilek k autz

instantiations x x represents possible world x pr x x
holds probability distribution worlds defined

x


pr x x exp
wi ni x

z


ni x number true groundings th formula wi weight world x


x
x

z
exp
wi ni x

x



equation viewed assigning score possible world dividing score
sum scores possible worlds constant z order normalize
maximum posteriori map inference markov logic given state observed atoms
reduces finding truth assignment hidden atoms weighed sum satisfied
clauses maximal even though general p complete achieve reasonable
run times applying cutting plane map inference cpi riedel cpi thought
meta solver incrementally grounds markov logic network step creating markov
network subsequently solved applicable methodsuch maxwalksat via
reduction integer linear program cpi refines current solution searching additional
groundings could contribute objective function
point focused first order markov logic first order ml variable
ranges objects present domain e g apples players cars hand finite
second order markov logic variabilize objects predicates relations kok domingos ctf model contains predicate variable type activity example one variable capturetype whose domain capturing failedcapturing
analogously freeing events grounding second order ml ground predicate
variables well object variables preliminary work generalizing ml
well defined infinite domains would indeed give full power fol singla
domingos
implementations markov logic include alchemy thebeast experiments used
modified version thebeast
dynamic bayesian networks
bayesian network bn directed probabilistic graphical model jordan nodes
graph represent random variables edges represent conditional dependencies cf figure
bn n nodes joint probability distribution given
pr x xn

n



http alchemy cs washington edu
http code google com p thebeast




pr xi pa xi



fil ocation r easoning c omplex ulti agent b ehavior

pa xi denotes parents node xi typical setting subset random variables
observed know actual values others hidden values need
inferred
dynamic bayesian network dbn bn sequential data dbn composed
slicesin case slice represents one second time interval order specify dbn
write learn intra inter slice conditional probability distributions cpds
intra slice cpds typically constitute observation model inter slice cpds model
transitions hidden states extensive treatment dbns see work murphy

number parameter learning inference techniques dbns match
markov logic framework experiments dbn model presented focus
supervised learning scenario hidden labels known training time therefore
maximum likelihood estimate calculated directly
set parameters discrete probability distributions maximize log likelihood
training data achieved optimizing following objective function

argmax log pr x





x represent sequence observed hidden values respectively
times set optimal model parameters implementation represent
probabilities likelihoods log counterparts avoid arithmetic underflow
testing time interested likely explanation observed data
want calculate likely assignment states hidden nodes e viterbi decoding
dbn given




argmax log pr x


pr x conditional probability sequence hidden states given concrete
sequence observations x times calculate viterbi decoding efficiently
dynamic programming jordan

methodology
section describe three major components short first manually
construct model captures freeings ctf optimize parameters supervised
learning framework section constitutes seed theory used denoising raw
location data recognition successful multi agent activities section
automatically extend seed theory inducing structure learning importance
failed captures freeings well relationships successful counterparts finally
section use augmented theory recognize richer set multi agent activitiesboth
successful failed attemptsand extract goals activities
specifically investigate following four questions
q reliably recognize complex multi agent activities ctf dataset even presence severe noise
q attempted activities automatically learned leveraging existing
successfully performed actions


fis adilek k autz

q modeling success failure allow us infer respective goals activities
q modeling failed attempts activities improve performance recognizing activities
elaborate three components system turn subsequently
discuss light experimental lessons learned answers
questions
recognition successful activities
section present unified framework intelligent relational denoising raw gps
data simultaneously labeling instances player captured enemy freed
ally denoising labeling cast learning inference markov
logic denoising mean modifying raw gps trajectories players final
trajectories satisfy constraints imposed geometry game area motion model
players well rules dynamics game refer trajectory
modification snapping since tile game area meter cells snap raw
gps reading appropriate cell creating cells unobstructed space ensure final
trajectory consistent map area
begin modeling domain via markov logic theory write logical formulas express structure model hand learn optimal set weights
formulas training data supervised discriminative fashion details experimental setup section following two subsections augment seed
markov logic theory recognize richer set events extract goals players multi agent
activities
order perform data denoising recognition successful capturing freeing
model game weighted formulas markov logic formulas hard
sense interested solutions satisfy hard formulas capture basic
physical constraints e g player one location time inviolable rules game
e g captured player must stand still freed game ends rest formulas
soft meaning finite weight associated one soft constraints
correspond traditional low level data filter expressing preferences smooth trajectories
close raw gps readings soft constraints capture high level constraints concerning
individual multi agent activities likely occur example soft constraint states
player encounters enemy enemys territory player likely captured
exact weights soft constraints learned labeled data described
distinguish two types atoms observed e g gps p
hidden e g freeing p p observed predicates ctf domain gps enemies adjacent onhometer onenemyter whereas capturing freeing iscaptured isfree
sameplace snap hidden additionally set hidden predicates expanded structure learning described see table predicate semantics training phase
cheating occur ctf games principle could accommodated making rules highlyweighted soft constraints rather hard constraints
noise gps data introduces ambiguity last two observed predicates still reliably
generate since road marks boundary territories constitutes neutral zone



fil ocation r easoning c omplex ulti agent b ehavior

hard rules
h raw gps reading snapped exactly one cell
h

player frees player b involved players must snapped common cell
time
b player freed free ally
c player freed currently captured
immediately freeing event freed player transitions free state
e player freed enemy territory

h

player captures player b involved players must snapped common cell
time
b player captured free enemy
c player captured currently free
immediately capture event captured player transitions captured state
e player captured standing enemy territory

h players free beginning game
h given time player captured free
h player transitions captured state free state via freeing event
h player transitions free state captured state via capture event
h player captured must remain location

soft rules
minimize distance raw gps reading snapped cell
minimize projection variance e two consecutive snappings generally correlated
maximize smoothness terms space time final player trajectories
players b enemies enemy territory b b captured already
close probably captures b
players b allies enemy territory b currently captured
close probably frees b
capture events generally rare e typically captures within game
freeing events generally rare

figure descriptions hard soft rules capture flag
learning access known truth assignment atoms testing phase
still access state observed atoms infer assignment hidden
atoms
figure gives english description hard soft rules low level movement
player interactions within capture flag corresponding formulas language ml
shown figures


fis adilek k autz

predicate
capturing b
enemies b
adjacent c c
failedcapturing b
failedfreeing b
freeing b
iscaptured
isfailedcaptured

type
hidden
observed
observed
hidden
hidden
hidden
hidden
hidden

isfailedfree

hidden

isfree

hidden

onenemyter
onhometer
sameplace b

observed
observed
hidden

snap c

hidden

meaning
player capturing b time
players b enemies
cells c c mutually adjacent c c
player unsuccessfully capturing b time
player unsuccessfully freeing b time
player freeing b time
player captured state time
time player state follows
unsuccessful attempt capturing
state capabilities free
time player state follows
unsuccessful attempt freeing
state capabilities captured
player free state time
isfree iscaptured
player enemy territory time
player home territory time
players b snapped common cell
two adjacent cells time
player snapped cell c time

table summary logical predicates use predicate names containing word
failed introduced markov logic theory augmentation method described
section

compare unified four alternative first two baseline
baseline states purely deterministic separate denoising gps data
labeling game events implemented perl involve
training phase third alternative model dynamic bayesian network shown figure
finally two cast markov logic two step ml model unified ml
model unified model handles denoising labeling joint fashion whereas
two step first performs snapping given geometric constraints subsequently labels
instances capturing freeing latter three evaluated four fold crossvalidation order test given game first train model three games
access following observed data raw gps position player
time indication whether enemy home territory location meter
cell cell adjacency list pairs players enemies tested five
observed data following describes model detail
baseline model b
model two separate stages first snap reading nearest cell afterward label instances player capturing player b labeling rule simple


fil ocation r easoning c omplex ulti agent b ehavior

loop whole discretized via snapping data set output capturing b every
time encounter pair players b snapped first step
cell two mutually adjacent cells time enemies
home territory b freeing recognition considered simple model
since need notion persisting player states captured free order model
freeing meaningful way
baseline model states b
second model builds top previous one introducing notion players states player captures player b time b enters captured state logic
iscaptured b b remains captured state moves snapped different cell later time game ends per rules ctf player captured
state cannot captured
thus model works previous one except whenever label
capturing event checks states involved players outputs capturing b
b captured state
freeing recognition implemented analogous way capturing recognition namely
every time captured player b transition free state check b
free teammate nearby within adjacent cells case output
freeing b
dynamic bayesian network model dbn
dynamic bayesian network model viewed probabilistic generalization
baseline model states structure dbn model one player shown
figure time slice one hidden node four observed nodes
represent binary random variables want infer likely state
player given time course game state free captured
hidden testing time four observed random variables per time step model
players motion presence absence least one enemy en ally player
nearby finally players location home enemy territory et player
modeled separate dbn therefore fourteen instantiated dbns game
within one game dbns share set parameters
note dbn model perform gps trajectory denoising make fair
comparison markov logic use denoising component markov
logic theory constraints h figure produces denoised
discretization data subsequently fed dbn model random variables
within dbn capture notion player movement players nearby one
another defined occupancy grid game area two deterministic
baseline namely player said moving time
snapped two different nonadjacent cells times similarly two players
nearby snapped cell two adjacent cells
two step ml model sml
two step two separate theories markov logic first theory
used perform preliminary snapping player trajectories individually us

fis adilek k autz

ett



ent

ant

ett

ent

st

st

mt

mt

ant



figure two consecutive time slices dynamic bayesian network modeling state
individual player p observations shaded nodes represent observed random
variables unfilled denote hidden variables random variables binary ett
p enemy territory time ent enemy nearby time
ant ally nearby time finally mt p moved
time value hidden state st p captured time
p free

ing constraints h figure theory identical one used
discretization step dbn model
second theory takes preliminary denoising list observed atoms
form preliminarysnap c meaning player snapped cell c time uses
remaining constraints label instances capturing freeing considering cell adjacency manner previous three two step model constitutes
decomposition unified model see overall contains virtually formulas except sml operates observed preliminarysnap predicate whereas unified
model contains hidden snap predicate instead thus omit elaborating
unified ml model uml
unified express hard constraints h h soft constraints
figure markov logic single theory jointly denoises data labels game
events selected interesting formulas shown figure labels correspond
listing figure note formulas contain real valued functions
respectively returns distance agent cell c time similarly returns
dissimilarity two consecutive snapping vectors given agent position time
location centers two cells c c finally since people prefer
move straight lines function quantifies lack smoothness three consecutive
segments trajectory since wp ws wt assigned negative values
training formulas effectively softly enforce corresponding geometric constraints
initial point snapping projection vector raw gps reading terminal point center
cell snap reading



fil ocation r easoning c omplex ulti agent b ehavior

presence functions renders formulas hybrid formulas means
inference time instantiated logical part formula evaluates true
false turn multiplied product corresponding function value
formula weight
see train test evaluate four perform
multi agent activity recognition task section next turn supervised learning method
augmenting unified ml model order recognize successful failed attempts
multi agent activities
hard formulas
c snap c


h




c c snap c c c snap c
freeing sameplace isfree

h

enemies iscaptured isfree

onenemyter onenemyter

capturing sameplace isfree

h

enemies isfree iscaptured

onhometer onenemyter

sameplace c c snap c snap c adjacent c c



isfree

h

iscaptured isfree

h

isfree iscaptured capturing

h

iscaptured isfree freeing

h

c iscaptured iscaptured snap c snap c

h

figure hard formulas markov logic see corresponding rules figure english
description table explanation predicates implementation
actual rules written syntax used thebeast markov logic toolkit
denotes unique existential quantification designates exclusive

learning failed attempts
work described manually designed structure markov logic network
capture flag domain allows us jointly denoise raw gps data recognize


fis adilek k autz

soft formulas


c snap c c wp





c c snap c snap c c c ws





c c c snap c snap c snap c c c c wt
enemies onhometer




onenemyter isfree
sameplace capturing wc
enemies onenemyter



onenemyter sameplace isfree
iscaptured freeing wf


c capturing c wcb



c freeing c wf b



figure soft formulas markov logic see corresponding rules figure english description soft formula
written

traditional quantified finite first order logic
formula e g c snap c followed optional function e g c
followed weight formula e g wp syntax denotes inference
time instantiated logical part formula evaluates true false
effectively multiplied product corresponding function value
formula weight

instances actual capturing freeing automaticallyin supervised
learning settingextend theory encompass correctly label successful actions
failed attempts interactions given raw gps data represent
ctf games want model label instances player captures frees player
b successful captures successful frees instances player almost captures frees
player b failed captures failed frees example failed capturing mean instance
players interactions whereup pointit appeared capturing b carefully
consider events potentially preceded well impacts supposed capture
future unfolding game conclude false alarm capture actually
occurred words conditions capture right later pivotal
moment foiled capturing agents attempt
activities capturing freeing model jointly finds optimal separation success failure note since cast model second order markov logic
learn e g isolated rule separates successful freeing failed attempt freeing
rathersince capturing freeing events actual failed related thus labeling
activity say successful capturing far reaching impact past present future


fil ocation r easoning c omplex ulti agent b ehavior

labelingwe learn separations joint unified way namely structure logical
form importance weight formula theory considered consequences
influence axioms theory system thus finds optimal balance success failure capturing freeing activities respect training data
heory augmentation lgorithm
follows describe markov logic theory augmentation
clarity explain works concrete context ml capture flag
discussed previous sections however underlying assumption successful actions
many ways similar failed counterparts minorbut crucialdeviations cause
failure occur often hold beyond capture flag therefore applicable
domains different activities long modeled markov logic
extend ml theory model successful well failed activities
input set activities
ms ml theory successful instances activities
set examples successful activities
f set examples failed activities
output ms f augmented ml model learned weights successful
attempted activities
intended goals activities








lifttosecondorderml ms
instantiate
findincompatibleformulas f
ms f
ms f learnweights f ms f
ms f removezeroweightedformulas ms f
return ms f

high level augmentation belongs family structure learning methods starting seed model successful actions searches formulas
added seed theory order jointly model successfully unsuccessfully carried
actions declarative language biasessentially rules exploring hypothesis space candidate structuresis defined implicitly notion given activity structure
unsuccessful attempts similar successful attempts therefore augmentation algoritm
goes inflation stage formulas seed theory generalized followed
refinement stage superfluous incompatible formulas inflated model pruned
away refinement step optimizes weights within newly induced theory
discuss process detail
input theory augmentation consists initial first order ml theory ms
successful capturing freeing unified ml model defined section
contains formulas shown figures set activities interest set
examples successful well failed f captures frees ms need
weights soft formulas specified case missing learn scratch



fis adilek k autz

final steps augmentation weights specified final weight learning
step ms f leverage estimate initial weight values specified
set predicate names e g capturing freeing example sets f describes game
segment constitutes truth assignment appropriate literals instantiated ms table
shows two toy examples sets f three time steps since goal learn model
failed successful attempts supervised way example game segment f contain
activities labeled predicates failedcapturing failedfreeing
ms contains hybrid formulas formulas figure appropriate function
definitions provided part f well definition consists implicit mapping
input arguments function values instance function formula quantifies l
distance
agent cell c time projected mercator space c
p
gpsxt c gpsx gpsyt c gpsy
system goes following process order induce theory ms f
augments ms definition failed attempts activity already defined ms
first lift ms second order markov logic variabilizing predicates correspond
activities interest step yields lifted theory concretely order apply technique domain introduce predicate variables capturetype whose domain capturing failedcapturing freetype freeing failedfreeing
statetype iscaptured isfailedcaptured isfree isfailedfree instance variabilizing first order ml formula freeing b enemies b yields second order ml formula
freetype b enemies b note freetype variable instantiating back
first order yields two formulas freeing b enemies b failedfreeing b
enemies b
far agents behavior concerned ctf domain iscaptured equivalent isfailedfree isfree equivalent isfailedcaptured soon see theory augmentation
process learns equivalence classes relationships states training examples expanding subsequently refining formula h figure could work
iscaptured predicate negation represent agents states feel explicit failure states makes discussion clearer furthermore future work need address
hierarchies activities including failures context representation explicit failure
states may convenient may necessary
next instantiate predicate variables produce first order ml theory
contains original theory ms entirety plus formulas correspond failed captures frees step since events e g near captures appear similar actual successful
captures hypothesis need drastically modify original successful formulas order model failed activities well practice process lifting
instantiating indeed good seed theory could emulate lifting grounding
steps scheme copying formulas renaming predicates duplicates appropriately
cast principled second order markov logic ties work closely
previous extensible framework specifically second order markov
logic successfully used deep transfer learning davis domingos predicate invention kok domingos therefore interesting direction future work
combine theory augmentation refinement transfer inductive learningoperating
second order mlto jointly induce failed attempts different activities different
domains starting single model successful activities source domain


fil ocation r easoning c omplex ulti agent b ehavior

set successful capture
enemies p p
enemies p p
onenemyter p
onenemyter p
capturing p p
isfree p
isfree p
isfree p
isfree p
isfree p
iscaptured p
snap p c
snap p c
snap p c
snap p c
snap p c
snap p c
sameplace p p
sameplace p p
sameplace p p
sameplace p p

set f failed capture
enemies p p
enemies p p
onenemyter p
onenemyter p
onenemyter p
failedcapturing p p
isfree p
isfailedcaptured p
isfree p
isfailedcaptured p
isfree p
isfailedcaptured p
isfree p
isfailedcaptured p
isfree p
isfailedcaptured p
isfree p
isfailedcaptured p
snap p c
snap p c
snap p c
snap p c
snap p c
snap p c
sameplace p p
sameplace p p

table two examples logical representation successful well failed f capture
events input closed world assumption applied therefore
atoms listed assumed false clarity omit listing adjacent
predicate

typical structure learning inductive logic programming techniques start initial perhaps empty theory iteratively grow refine order form fits training data
well order avoid searching generally huge space hypotheses declarative bias
specified hand mined data declarative bias restricts set possible refinements formulas search apply common restrictions include limiting
formula length adding predicate formula shares least one variable
predicate already present formula hand first
generate seed theory instantiating activity related predicate variables put


fis adilek k autz

context structure learning expand input model order generate large seed theory
apply bottom data driven learning prune seed theory whereby training data
guides search formulas remove well optimal set weights remaining
formulas conjecture failed attempt activity violates least one constraint
holds successful executions activity experiments support conjecture
pruning done steps function findincompatibleformulas f
returns set hard formulas incompatible set examples failed
interactions f say formula c compatible respect set examples f f
logically entails c f c conversely f entail c say c incompatible w r
f explain incompatible formulas next section
step simply remove incompatible formulas theory
point ms f model hard formulas guaranteed logically consistent
examples failed activities removed incompatible hard formulas well
successful activities logically consistent start however
soft formulas ms f missing properly updated weights markov logic weight
hard formula simply set therefore run markov logic weight learning thebeast
package step
recall thebeast implements cutting plane meta solving scheme inference markov
logic ground ml network reduced integer linear program subsequently
solved lpsolve ilp solver chose opposed e g maxwalksat
may solution merely locally optimal since resulting run times still relatively
short hour even training testing even complex model weights
learned discriminatively directly model posterior conditional probability hidden predicates given observed predicates set thebeast optimize weights soft
formulas via supervised line learning margin infused relaxed mira weight
updates loss function computed number false positives false negatives
hidden atoms note soft formulas truly irrelevant respect
training examples picked findincompatibleformulas function
weights set zero close zero weight learning step line
zero weighted formulas subsequently removed following step note weight
learning process need experience cold start initial setting weights
inherited input theory ms
finally return learned theory ms f whose formulas optimally weighted respect training examples experiments section use ms f
recognize successful failed activities returns incompatible hard formulas see used extract intended goal activities section
first let us discuss step detail
c onsistency c heck f inding ncompatible f ormulas
turn method finding incompatible formulas summarized since
method leverages satisfiability testing determine consistency candidate theories
possible worlds examples viewed instance learning
interpretationsa learning setting inductive logic programming literature de raedt
often referred covers relation inductive logic programming



fil ocation r easoning c omplex ulti agent b ehavior

findincompatibleformulas formulas ml theory logically inconsistent examples execution failed activities
input f set examples failed activities
unrefined ml theory successful failed activities
output smallest set formulas appear unsatisfiable worlds f














extractobjects f
thard tsoft
integer n
boolean false
false
c thard
remove n tuple formulas c
current n n tuples tested
nn
end
testsat f c
end
return thard c

input take set examples failed activities f seed theory e g produced
step output smallest set hard formulas appear
logically inconsistent f first extracts set objects appear
f step keeping track type object example suppose two example worlds f shown table extractobjects f returns
p p p p c c
example
snap p c
snap p c
failedcapturing p p

example
snap p c
snap p c
failedfreeing p p

table two simple examples logical representation failed capture event

step limit hard formulas testing compatibility since
prove incompatibility hard formulas soft constraints violated many times
data yet may want eliminate instead want merely adjust
weights exactly therefore thard contains hard formulas
appear next lines check entire unmodified thard compatible
since n remove formulas compatible return empty set
indicating hard formulas original seed theory compatible examples
detect incompatibility need remove perhaps even hard formulas
order arrive logically consistent theory therefore incrementally start removing n tuples
formulas subsequent thard iterations loop determine


fis adilek k autz

restore consistency removing one hard formulas thard return
set thard identified removed incompatible formula consistency cannot
restored removing single formula turn begin considering pairs formulas n
triples n etc pruned theory c consistent examples
general need consider n tuples formulas rather testing formula
isolation due disjunctive formulas conjunction possibly incomplete truth
assignment training data consider following theory propositional logic
f b
f b c
data c
following closed world assumption negated atom c would actually appear training data explicitly include example clarity f f individually consistent data f f inconsistent data complicated examples
constructed every group k formulas inconsistent data even though
individual formulas special case truth values atoms training examples known formulas tested consistency individually reduces original
exponential number iterations executes worst case linear complexity
interesting direction future work explore applications logical methods lower
computational cost general case partially observed data
note hard formulas model physical constraints inviolable rules capture
flag therefore hold universally appropriately formulas eliminated example consider formula h figure asserts player occupies
exactly one cell given time formula satisfied games include successful failed activities hand consider formula h figure contains
captured player cell captured following captured players cannot move rule
ctf holds successful capturing events necessarily hold failed
attempts capturing therefore rule h expanded via second order ml
derived formulas going consistent observations
specifically candidate formula equation pruned away inconsistent
training examples e players nearly captured continue free move
however remaining three variants formula h pruned away equation
evaluate true since someone attempts capture already captured player
indeed remain stationary similarly equation consistent example ctf games
failed attempt capture immediately followed successful capture
captured player remain place time onward finally equation compatible well
since original formula h consistent observations

c isfailedcaptured isfailedcaptured snap c snap c


c iscaptured isfailedcaptured snap c snap c



fil ocation r easoning c omplex ulti agent b ehavior


c isfailedcaptured iscaptured snap c snap c


c iscaptured iscaptured snap c snap c



function testsat line checks whether given candidate theory c
compatible examples f following process first ground c objects
thereby creating ground theory g example c p x q x b w
grounding would g p b q b p w q w check g fhidden
satisfiable minisat solver fhidden simply set hidden atoms appear
f intuitively corresponds testing whether plug worlds f c
satisfying hard constraints though satisfiability np complete practice
testsat completes within tenths second even largest ctf domain
instance suppose fhidden p b q b test satisfiability formula



p b q b p w q w p b q b
case cannot satisfy since forced set p b true q b false
renders first clauseand therefore whole formulafalse
alternative pruning formulas via satisfiability testing described
would treat types formulas hard soft inflated theory strictly soft
formulas learning weight formula examples successful failed game
events however introduces several complications negatively impact systems performance well model clarity first number formulas inflated theory
exponentially larger seed theory instantiation second order ml representation quantified limit expansion still worst case exponential blow
treating formulas soft ones need potentially learn many weights
especially problematic activities occur rarely may enough training data
properly learn weights eliminating hard candidate formulas proving inconsistent
dramatically reduces number parameters model satisfiability testing
np complete weight learning markov logic entails running inference multiple times
p complete
second reason distinguishing soft hard formulas resulting clarity
elegance final learned model ms f even situations enough training data
properly learn large number weights run overfitting neither
structure parameters model represent domain natural way experiments
shown skip pruning stage steps recognition
performance differ pruned model significant way p value
however end large number soft formulas mixture positive negative
weights learning carefully tuned balanced fit training data
however bear little relationship concepts underlying domain make
hard human expert analyze model makes even harder modify
model


fis adilek k autz

reasons softening hard formulas general infeasible interesting direction
future work identify small amount key inconsistent hard formulas soften
eliminating rest inconsistent hard formulas however entails searching large
space candidate subsets softened formulas iteration requires expensive learning
weights
note terminates soon finds compatible theory requires smallest
number formula removals experimented active learning component
system modify present several possible refinements
theory user selects one looks best proposed modifications
shown ml theory level modified sections formulas highlighted well
data level program shows inferred consequences modifications
candidate modification corresponding consequences displayed collection animations
animation shows activity recognition would committed
particular candidate theory note even people background ml
interact system since visualization easy understand interestingly case
captures frees least modified theory line version finds
best one therefore need query user one view differential
variant occams razor however different activities domains active learning
may worth revisiting leave exploration future work
finally general structure learning techniques statistical relational ai inductive
logic programming applicable substitute theory augmentation
several reasons main reason efficiency reasons existing techniques literature
typically operate restricted set formula templates consider horn
clauses formulas without existential quantifier formulas k literals
l variables set restrictions part language bias given
principle structure learning possible without language bias one often
carefully define one sake tractability see section details
language bias defined implicitly discussed section
extracting goal success failure
recall applying theory augmentation process ctf seed theory
successful interactions shown figures induces set formulas capture
structure failed activities ties together existing formulas seed theory
logically inconsistent formulas returns ones satisfiable
worlds failed activities time variants formulas consistent
examples successful actions occurring games therefore represents difference
theory successful activities augmented theory successful
failed actions derived intuitively difference success
failure viewed intended purpose given activity rational agent executes
consequently goal agent mind engages particular activity
next section explore goals extracted ctf domain fashion
concludes discussion methodology turn experimental
evaluation framework presented



fil ocation r easoning c omplex ulti agent b ehavior

experiments
evaluate along three major directions outlined section methodology
focusing answering four questions formulated ibidem structure
section closely follows methodology section
nutshell first interested markov logic perform standard
multi agent activity recognition tasklabeling successful activitiesand performance
compares alternative second examine augmented model captures
successful failed attempts activities model ms f induced
lets us extract intended goal activities question third compare performance
ms f task jointly recognizing four activities alternative model
finally investigate extent reasoning failed attempts help recognition
successfully executed activities
experiments performed capture flag dataset consisting four separate games
dataset summarized table game list number raw gps readings
number instances activity interest evaluate via four fold crossvalidation training three games training required model testing
fourth experimental condition report precision recall f scores attained
respective model four cross validation runs purposefully chosen
split data cross validation fold directly corresponds separate game ctf
conceptual convenience clarity discussed events occurring games often
far reaching consequences example captured players never freed allies
therefore capture beginning game typically profoundly influences entire rest
game reason splitting games randomly even manually would introduce unnecessary
complications segments would dependencies segments enforcing
fold exactly corresponds different game make fold self contained
quantify statistical significance pair wise differences use
generalized probabilistic interpretation f score goutte gaussier namely express
f scores terms gamma variates derived true positives false positives false
negatives h cf goutte gaussier makes possible
compare future work may apply alternative similar identical
datasets future comparison may instance include additional games introduce random
splits data note standard statistical significance tests cannot applied situations p values reported one sided interested performance significantly
improves level sophistication increases
recognition successful activities
recall two step sml unified uml markov logic specify
markov logic formulas hand optimize weights soft formulas via supervised online learning run modified version thebeast software package perform weight learning
map inference thebeast implements cutting plane meta solving scheme inference
markov logic ground ml network reduced integer linear program subsequently solved lpsolve ilp solver chose opposed e g maxwalksat
get stuck local optimum since resulting run times still relatively short
hour even training testing even complex model


fis adilek k autz

game
game
game
game
total

gps






ac






fc






af













table ctf dataset overview gps total number raw gps readings ac fc
number actual successful failed captures respectively analogously freeings
af

weight learning time use margin infused relaxed mira weight updates loss function computed number false positives false negatives
hidden atoms described methodology section discretization step
dynamic bayesian network model dbn implemented markov logic executed
fashion dbn model trained via maximum likelihood described section
two deterministic baselines b b require training phase
inference time interested likely explanation data markov logic
maximum posteriori inference reduces finding complete truth assignment satisfies
hard constraints maximizing sum weights satisfied soft formulas testing
time thebeast markov logic solver finds likely truth assignment hidden atoms
described section specifically interested values capturing
freeing atoms
dbns likely explanation observations equivalent viterbi decoding
dbn model assigns free captured state player every time step label
transitions free captured state capturing transitions captured free
freeing note dbn model capable determining player freed captured
model player freeing capturing evaluation give
benefit doubt assume outputs correct actor
inference done simultaneously entire game average
minutes worth data note restrict inference small sliding time window
experiments described many events domain definitely recognized
long occur example gps noise may make impossible determine whether player
captured moment encounter enemy player thereafter remains
place long time possibility capture becomes certain
figures summarize performance successful capturing freeing
terms precision recall f score calculated four cross validation runs clarity
present two separate plots model jointly labeling capturing
freeing activities consider baseline model freeing recognition activity
makes little sense without notion player state captured free
see unified yields best activities let us focus
capturing first figure overall unified model labels captures correctlythere



fil ocation r easoning c omplex ulti agent b ehavior

capturing recogni





















precision





recall







b

b

f

dbn

sml

uml

figure comparison performance five capturing recognition joint
inference capturing freeing events see table statistical significance
analysis pairwise differences b baseline model b baseline
model states sml two step markov logic model uml unified markov logic
model

two false negatives fact two capture events missed
involve two enemies appear unusually far apart meters raw data even
unified fails instance since cost adjusting players trajectoriesthereby
losing score due violation geometry constraintsis compensated
potential gain labeling additional capture
note even two step recognizes captures compared
unified model misses one additional instance involved players moderately
far apart snapped mutually nonadjacent cells hand unified model
fail situation limited prior nonrelational snapping nearby cells
however difference performance dataset statistically significant even
level p value
deterministic baseline b b perform poorly although yield
respectable recall produce overwhelming amount false positives shows even
relatively comprehensive pattern matching work domain interestingly
performance dbn model leaves much desired well especially terms precision
dbn model significantly better baselines p value less
achieves significantly worse performance markov logic p value less
see table
table summarizes p values pairwise differences actual e successful
capturing difference markov logic sml uml



fis adilek k autz

freeing recogni

























precision



recall



f


b

dbn

sml

uml

figure comparison performance three freeing recognition joint
inference capturing freeing events see table statistical significance
analysis pairwise differences b baseline model states
sml two step markov logic model uml unified markov logic model

b
b
dbn
sml

b



dbn




sml





uml





table summary statistical significance one sided p values pairwise differences f scores actual capturing b baseline model b baseline
model states dbn dynamic bayesian network model sml two step markov
logic model uml unified markov logic model

statistically significant p value pairwise differences f scores
significant level often even much lower p values
though unified model still outperforms alternatives case freeing recognition
well performance ideal compared capture recognition case figure
correctly identifies freeing events games produce false
positives partly due dependency freeing capturing failure model
recognize capture precludes recognition future freeing another reason extreme
sparseness freeing events five datapoints finally



fil ocation r easoning c omplex ulti agent b ehavior

b
dbn
sml

dbn



sml




uml




table summary statistical significance one sided p values pairwise differences f scores actual freeing b baseline model states dbn
dynamic bayesian network model sml two step markov logic model uml unified
markov logic model

instances players barely move freed may occur number reasons
ranging already occupying strategic spot simply tired freeing instances
challenging automated system even people familiar game recognize
several situations would extremely hard disambiguate didnt access
notes data collection
two step ml model slightly worse job unified model freeing recognition
correctly identifies freeings reasons capturing recognition
case similarly actual captures difference unified two step freeing
statistically significant p value
table summarizes p values pairwise differences actual e successful freeing see difference b uml statistically
significant p value whereas differences rest model pairs
statistically significant since five instances successful freeing sml model
perform significantly better b model significance level p value
however uml model achieves better recognition even dbn model
high confidence p value less therefore see although sml model strictly
dominates non markov logic evaluated capturing recognition need full
power unified ml model strictly outperform nonrelational alternatives freeing
suggests move complex interdependent activities relational unified
modeling approaches winning larger larger margins
even though statistical significance tests suggest sml likely give similar
uml important note sml design precludes recognition activities question
certain situations namely experiments demonstrate players snapped cells
far apart two step model even consider instances candidates
labeling inevitably fails recognizing therefore one needs look beyond p values
obtained comparing fully unified alternatives
expected experiments capturing recognition deterministic baseline perform poorly freeing recognition well produce overwhelming
amount false positives fail recognize freeing events
thus see cast markov logic perform significantly better
deterministic baseline better probabilistic nonrelational dbn model
note dbn model potential quite powerful similar dbns
applied great success previous work activity recognition location data eagle


fis adilek k autz

pentland liao patterson fox kautz many similarities twostep ml model share denoising discretization step operate
observed data key difference dbn model considers players individually
whereas two step ml model performs joint reasoning
looking actual ctf game data see several concrete examples hurts dbns
labeling accuracy instance consider situation two allies captured near
performing inference individual players isolation allows dbn model infer
two players effectively free even though reality captured cannot
occurs dbn model oblivious explicit states ones teammates
well opponents since capturing freeing interdependent obliviousness dbn
model state actors negatively impacts recognition performance activities
example gave illustrates one type freeing false positives hallucinated freeings
create opportunities often lead false positives captures creating vicious cycle false
negatives freeing capturing events often occur players model incorrectly believes
already freed captured prior time
since markov logic significantly betterwith high level confidence
alternatives fully relational experiments validate hypothesis
need exploit rich relational temporal structure domain probabilistic way
time affirmatively answer question q reliably recognize complex
multi agent activities ctf dataset even presence severe noise namely
although relatively powerful probabilistic sufficient achieve high labeling
accuracy gain significant improvements formulating recognition learning
inference markov logic networks
turn evaluation method learning success failure
peoples activities
learned formulas intentions
applying theory augmentation process ctf seed theory shown figures induces set formulas capture structure failed activities ties
together existing formulas theory call model ms f figure shows
examples weighted formulas modeling failed freeing capturing attempts appear
ms f
first note system correctly carries basic preconditions activity contrast
formulas figures respectively allows reliably
recognize successful failed actions instead e g merely labeling events
point time appear resemble capture near capture use preconditions directly
follows language bias theory augmentation
turning attention learned hard formulas observe system correctly induced
equivalence classes states derived mutual exclusion relationships h
furthermore tied failure states corresponding instantaneous interactions h
h
finally correctly discovers rule player captured
must remain location h figure key distinction successful
failed capture since players actually captured still move therefore introduces



fil ocation r easoning c omplex ulti agent b ehavior

appropriate rule failed captures h figure explicitly stating failed capturing
confine near captured player remain stationary analogous process yields fitting
separation failed successful freeings namely model learns unsuccessfully
freed player remains stationary learned difference success failure players
actions directly corresponds goal activity consequently intent rational actors difference system outputs intended goal capturing activity
analogously freeing
experimental provide evidence resounding yes q
attempted activities automatically learned leveraging existing successfully performed actions q modeling success failure allow us infer respective
goals activities within ctf domain
note instead applying automated theory augmentation method person could
principle manually formulate markov logic theory successful well failed activities
observing games designed initial seed model successful
events however process extremely time consuming one tends omit encoding facts
us humans seem self evident need explicitly articulated machine e g
single person cannot ten different places player free captured
surprisingly easy introduce errors theory difficult debug
mostly complex weight learning techniques involved therefore believe
theory augmentation method significant step forward enhancing capabilities
requiring small amounts human effort complexity domains increases
advantage gain larger larger importance
recognition successful failed activities
compare performance model ms f alternative baseline method
labels four activities following way similarly baseline states model successful interactions defined section two separate stages first snap gps
reading nearest cell applying geometric constraints h theory afterward label instances activities following labeling rule applied
loop whole discretized via snapping data set look instances pair
players b snapped first step cell two adjacent cells
time enemies b captured already home territory b
b moves snapped different cell later time without ally nearby output
failedcapturing b otherwise output capturing b labeling rule freeing defined analogously four events tied together tested variant dbn model
introduced section two additional hidden state values node st isfailedfree
isfailedcaptured however difference obtained model statistically significant p value therefore focus conceptually straightforward
baseline model described
model ms f evaluated four fold cross validation training three games
testing fourth figure compares terms precision recall f
score note four activities modeled jointly f score augmented
model significantly better baseline four target activities p value less




fis adilek k autz

enemies onhometer



onenemyter sameplace isfree
isfree failedcapturing
enemies onenemyter



onenemyter sameplace isfree
iscaptured failedfreeing
failedcapturing



failedfreeing



isfailedcaptured isfree

h

iscaptured isfailedfree
isfailedcaptured isfree
iscaptured isfailedfree
isfree isfailedcaptured failedcapturing
iscaptured isfailedfree failedfreeing

h
h

c isfailedcaptured isfailedcaptured snap c snap c
h

figure example formulas learned model unsuccessful capturing freeing events crucial intent recognition formula h highlighted bold formulas
eliminated preceded symbol included
induced model ms f identity iscaptured isfree applied throughout refining formulas intuitive fashion concreteness sake
values learned weights come one cross validation run similar
runs

see baseline model general respectable recall produces large
number false positives activities false positives stem fact
greedy typically labels situation several players appear close
certain period time sequence many captures subsequent frees even though none
actually occurred model ms f gives significantly better takes full
advantage structure game probabilistic fashion similar labeling
tendency case failed captures single capture attempt often labeled
several consecutive attempts hurts precision score significant deficiency



fil ocation r easoning c omplex ulti agent b ehavior



baseline

ac



fc






af







augmented ml model





f





recall




ac


fc



af

























precision












figure performance baseline augmented ms f joint recognition
successful failed capturing freeing f score augmented model
significantly better baseline four target activities p value less
ac actual successful capturing fc failed capturing af
actual freeing failed freeing

practice small number short game segments labeled possible near captures
useful well
note even though original model uml contain information
failed capturing failed freeing performance ms f respectable even two
newly introduced activities provided examples game situations attempts
occur system augmented subsequently labeled four activities thus see
indeed extend preexisting automated fashion unified model
capable recognizing individual activities success failure peoples
behavior
effect modeling failed attempts recognition successful activities
address question q modeling failed attempts activities improve performance recognizing activities want see much recognition
attempted activities help modeling successful actions latter standard activity



fis adilek k autz

capturing

f



recall



precision





f
freeing





recall







precision













without modeling failure













modeling failure

figure considering unsuccessfully attempted activities strictly improves performance standard activity recognition blue bars scores obtained unified markov logic
model considers successful activities ms red bars indicate additive improvement provided augmented model considers successful
failed activities ms f output model labels target activities jointly separate capturing freeing plot clarity precision value
f scores obtained explicitly modeling failed attempts
statistically different f scores obtained without modeling attempts high
confidence level p value however still importance
reasoning peoples attempts recognizing activities see text details

recognition toward end compare markov logic model ms jointly labels
successful capturing freeing model ms f jointly labels successful
failed attempts capturing freeing see section detailed description two
however evaluate terms precision recall f score successful
interactions four types activities
figure summarizes see evaluated actual capturing ms f
performs better ms similarly freeing however difference f scores
model captures attempted successful activities ms f model successful activities ms statistically significant p value partly ms
already produces solid leaving little room improvement additionally ctf
dataset contains relatively events interest terms labeling performance testing time
difference two ms ms f recognize respectively


fil ocation r easoning c omplex ulti agent b ehavior

successful activities correctly thus believe trends shown figure
promising modeling attempted actions improve recognition performance capturing freeing evaluation dataset larger number events needed
difference statistically significant higher confidence level however mean
recognizing attempts unimportant induced augmented model
recognize failed well successful activities complex ctf domain high accuracy
argue significant contribution
finally comparison ms ms f shows applying learning augments model recognition capabilities hurt model labeling performance
fact binary classification typically easier solve multi class counterparts well reported machine learning literature allwein schapire singer
therefore introducing activities model especially automated way likely degrade performance contrary intuition experiments ms f worse
ms successful activity recognition e intersection high confidence even though
ms f clearly richer useful

related work
world single agent location reasoning work bui presents evaluates system probabilistic plan recognition cast abstract hidden markov memory model
subsequently work liao et al implements system denoising raw gps traces
simultaneously inferring individuals mode transportation car bus etc goal destination cast learning inference dynamic bayesian network achieve
encouraging follow work liao et al introduce framework locationbased activity recognition implemented efficient learning inference relational
markov network
work ashbrook starner focuses inferring significant locations raw
gps logs via clustering transition probabilities important places subsequently
used number user modeling tasks including location prediction work eagle
pentland explores harnessing data collected regular smart phones modeling human
behavior specifically infer individuals general location nearby cell towers bluetooth devices times day applying hidden markov model hmm
predicting person home work someplace else achieved accuracy similarly work eagle pentland extracts significant patterns signatures
peoples movement applying eigenanalysis smart phone logs
work hu pan zheng liu yang concentrates recognition interleaving
overlapping activities publicly available academic datasets contain significant
number instances activities formulate conditional random field crf model
capable detecting high accuracy however focus solely
single agent household activities
peoples conversation primary focus multi agent modeling effort barbuceanu
fox fields multi agent activity recognition studies human behavior researchers modeled conversation explicitly e g busetta serafini singh zini
leveraged peoples communication implicitly via call location logs mobile phones
data successfully used infer social networks user mobility patterns model socially



fis adilek k autz

significant locations dynamics others eagle pentland eagle pentland
lazer arguably excellent stepping stone full fledged multi agent activity
recognition since location times practically synonymous ones activity e g
store often implies shopping tang lin hong siewiorek sadeh social networks
tremendous influence behavior pentland
additionally number researchers machine vision worked recognizing events videos sporting events impressive recent work learning
baseball plays gupta et al work area focused recognizing individual
actions e g catching throwing state art beginning consider relational
actions e g ball thrown player player b computational challenges dealing
video data make necessary limit time windows seconds contrast
demonstrate work many events capture flag data disambiguated
considering arbitrarily long temporal sequences general however work
machine vision rely upon similar probabilistic already evidence
statistical relational techniques similar markov logic used activity recognition
video biswas thrun fujimura tran davis
looking beyond activity recognition recent work relational spacial reasoning includes
attempt locateusing spacial abductioncaches weapons iraq information
attacks area shakarian subrahmanian spaino additionally work abowd
et al presents location context aware system cyberguide helps people explore
fully experience foreign locations researchers explore intelligent nonintrusive
navigation system takes advantage predictions traffic conditions along model
users knowledge competence horvitz et al finally work kamar horvitz
explore automatic generation synergistic plans regarding sharing vehicles across multiple
commuters
interesting line work cognitive science focuses intent goal recognition probabilistic framework baker tenenbaum saxe specifically cast goal inference
inverse markov decision processes bayesian inversion used estimate posterior distribution possible goals recent extensions work begin consider
simulated multi agent domains baker goodman tenenbaum ullman baker macindoe
evans goodman tenenbaum baker saxe tenenbaum comparison
computational human judgement synthetic domains shows strong correlation
peoples predicted actual behavior however computational challenges involved
dealing underlying partially observable markov decision processes prohibitive
complex domains large state spaces
focus work different aspect reasoning peoples goals rather
inferring distribution possible priori known goals automatically induce goals
complex multi agent activities
researchers concentrated modeling behavior people general agents reinforcement learning single agent multi agent settings work
proposes system household activity recognition cast single agent markov decision process
subsequently solved probabilistic model checker wilson colleagues address learning agents roles multi agent domain derived real time strategy
computer game wilson fern ray tadepalli wilson fern tadepalli experiments synthetic domain strongly encouraging perform role


fil ocation r easoning c omplex ulti agent b ehavior

learning anticipate work wilson et al going play important role
learning hierarchies peoples activities capture flag domain one imagine automatically identifying particular player example defender subsequently leveraging
information model behavior personalized way
work hong concentrates recognizing goal agent course
activities deterministic relational setting interesting work goal recognition
applied computer aided monitoring complex multi agent systems relationships
agents leveraged compensate noise sparse data kaminka tambe pynadath
tambe contrast work focus learning respective goals given set
multi agent activities probabilistic setting knowledge turn leveraged achieve
stronger robustness recognition tasks similarly hong system
need supplied plan library
work touches anomaly detection since system reasons failed attempts
players anomaly detection concerns revealing segments data
way violate expectations excellent survey subject refer reader
chandola banerjee kumar realm anomaly detection within peoples
activities work moore essa addresses error detection recovery
card games involve two players recorded video system domain
stochastic context free grammar achieves excellent
note recognizing failed attempt activity fine grained
anomaly detection failed event anomalous general rather specific
distinction success failure human activities interested distinction lies fact unsuccessful attempt yield certain desired state whereas
successful action desired state exactly extracts activity
question knowledge exists prior work explicit modeling recognition
attempted activities learning intended purpose activity multi agent setting
one components contribution focuses joint learning inference across multiple tasks capturing freeing respective attempted counterparts contrast
traditional pipeline learning architecture system decomposed series modules module performs partial computation passes next stage
main benefits set reduced computational complexity often higher modularity
however since stage myopic may take full advantage dependencies broader
patterns within data additionally even though errors introduced module may small
accumulate beyond tolerable levels data passes pipeline
extensive body work shown joint reasoning improves model performance
number natural language processing data mining tasks including information extraction e
text segmentation coupled entity resolution poon domingos co reference resolution poon domingos information extraction coupled co reference resolution wellner mccallum peng hay temporal relation identification yoshikawa riedel asahara
matsumoto ling weld record de duplication domingos culotta
mccallum similarly work cast markov logic
however prior work uses sampling techniques perform learning inference whereas apply
situation player ctf moves campus speed mph way passes enemy
player certainly anomalous probably caused gps sensor noise want say failed
attempt capturing



fis adilek k autz

reduction integer linear programming interestingly work denis baldridge
jointly addresses anaphoricity co reference via manual formulation
integer linear program
joint activity modeling shown yield better recognition accuracy compared
pipeline baselines well baselines make strong inter activity independence assumptions
work wu lian hsu performs joint learning inference concurrent singleagent activities factorial conditional random field model similarly work helaoui
niepert stuckenschmidt interleaved activities markov logic distinguish
foreground background activities infer time window activity takes
place rfid sensory data contrast focus joint reasoning multi agent activities
attempts fully relationaland arguably significantly noisysetting
work manfredotti hamilton zilles propose hierarchical activity recognition
system formulated learning inference relational dynamic bayesian networks model
jointly leverages observed interactions individual objects domain relationships
objects since method outperforms hidden markov model significant margin
contributes additional experimental evidence relational decomposition domain improves
model quality
work landwehr gutmann thon philipose de raedt casts single agent
activity recognition relational transformation learning building transformationbased tagging natural language processing system induces set transformation rules
used infer activities sensory data since transformation rules applied
adaptively step system leverages observed data currently assigned
labels inferred activities however transformation rules learned greedy fashion
experiments model perform significantly better simple hmm
hand representation quite general intuitive extensible see
markov logic model similar level representational convenience performing global
instead greedyoptimization significantly complex domain
denoising component model formulated tracking prior work
proposed relational dynamic bayesian network model multi agent tracking manfredotti
messina evaluation shows considering relationships tracked entities
significantly improves model performance compared nonrelational particle filter baseline
contrast work explores joint tracking activity recognition however gps reading
annotated identity corresponding agent work manfredotti messina
suggests model generalized associations gps agent
identities inferred need observed
markov logic theory viewed template conditional random field lafferty
undirected graphical model captures conditional probability hidden labels
given observations rather joint probability labels observations one would
typically directed graphical model relational world directed formalisms include
relational bayesian networks jaeger dynamic counterparts manfredotti
probabilistic relational koller friedman getoor koller pfeffer bayesian
logic programs kersting de raedt first order conditional influence language natarajan tadepalli altendorf dietterich fern restificar conditional random fields
extensively applied activity recognition superior labeling performance generative
demonstrated number single agent multi agent domains liao


fil ocation r easoning c omplex ulti agent b ehavior

et al limketkai fox liao vail vail veloso hu et al
since mlns often solved propositionalized crfs directed alternatives compiled bayesian network expected discriminative relational generally
outperform generative counterparts labeling tasks however work needs done
answer question entirety
since markov logic fact subsumes finite first order logic immediately
gain access number techniques developed rich field traditional logic current markov
logic solvers take advantage underlying logical structure perform powerful optimizations alchemys lifted inference belief propagation mc sat poon domingos
additionally domain pruning one uses hard constraints infer reduced domains
predicates shown lead significant speed ups papai singla kautz
leverage relationship markov first order logic inducing augmented model furthermore presence dependency cycles introduces additional
directed graphical relational thus fact markov logic knowledge
expressed weighted first order formulas combined factors make powerful
framework best suited multi agent reasoning tasks considered work
traditional hidden markov operate alphabet unstructured e flat symbols makes relational reasoning difficult one propositionalize domain
thereby incurring combinatorial increase number symbols model parameters ignore
relational structure sacrifice information logical hidden markov lhmms
proposed address kersting de raedt raiko lhmms generalization standard hmms compactly represents probability distributions sequences
logical atoms rather flat symbols lhmms proven strictly powerful
propositional counterparts hmms applying techniques logic reasoning
unification leveraging logical structure component model kersting et al
lhmms often require fewer parameters achieve higher accuracy hmms
lhmms recently applied activity recognition context intelligent user interfaces work shen designs evaluates lhmm model recognition peoples
activities workflows carried desktop computer researchers proposed hierarchical extension lhmms along efficient particle filter inference technique
apply activity recognition synthetic domains natarajan bui tadepalli kersting
wong lines work lhmms learned applied efficiently
perform better plain hmms
however lhmms generative model therefore ideal pure labeling
recognition tasks typically want make strong independence assumptions
observations want explicitly model dependencies input space tildecrfa
relational extension traditional conditional random fieldshas introduced address
issue gutmann kersting tildecrf allows discriminative learning inference crfs
encode sequences logical atoms opposed sequences unstructured symbols tildecrf
specifically focuses efficient learning sequential data via boosting subsumed
markov logic produce discriminative generative cast model
latter framework make general extensible interpretable
prism probabilistic extension prolog shown subsume wide variety generative including bayesian networks probabilistic context free grammars hmms along
logical extension sato kameya however since focus prism


fis adilek k autz

representational elegance generality rather scalability sheer size state space
complexity ctf domain precludes application
finally markov logic theory augmentation process related structure learning transfer learning inductive logic programming fact implements special case
structure learning search target theory explains training data well
declarative bias forces target theory differ source theory much necessary
intuition failed attempts similar failed counterparts number
researchers focused structure learning specifically markov logic networks includes
early work top structure learning clauses knowledge base greedily modified adding flipping deleting logical literals kok domingos search guided
likelihood training data current model work mihalkova mooney
exploit patterns ground markov logic networks introduce bottom declarative
bias makes less susceptible finding local optima compared alternative greedy methods similarly work kok domingos introduce bottom
declarative bias lifted hypergraph representation relational database bias
guides search clauses fit data since hypergraph lifted relational path finding
tractable interesting work predicate invention applies relational clustering technique formulated
second order markov logic discover predicates relational databases kok domingos systems capable modeling relatively rich family logical formulas
approaches perform discriminative structure learning achieve excellent focus
restricted set types formulas e g horn clauses huynh mooney biba ferilli
esposito work davis domingos successfully uses second order markov
logic deep transfer learning lift model source domain second order ml
identify high level structural patterns subsequently serve declarative bias structure
learning target domain
nature inductive logic programming discipline extensively studied structure
learning deterministic well probabilistic settings e g muggleton de raedt
de raedt frasconi kersting muggleton fact theory augmentation
viewed efficient markov logic version theory refinement well established ilp
technique aims improve quality theory terms simplicity fit newly acquired
data efficiency factors wrobel
differs work three main points first declarative bias defined
implicitly seed theory successful activities therefore theory augmentation
limited hard wired set formula types consider rather search space
defined run time extracting motifs seed theory second distinction lies computational tractability exactness distinguishing soft hard formulas
able search candidate formulas systematic rather greedy manner consequently final learned model requires fewer parameters especially important
amount training data relatively small additionally weight learning experience cold starts leverage seed theory final difference knowledge
first explore structure learning context interplay success failure
relationship intended goals peoples actions



fil ocation r easoning c omplex ulti agent b ehavior

conclusions
took task understanding game capture flag gps data
exemplar general inferring human interactions intentions sensor data
presented novel methodologycast markov logicfor effectively combining data
denoising higher level relational reasoning complex multi agent domain specifically
demonstrated given raw noisy data automatically reliably detect
recognize successful failed interactions adversarial well cooperative settings
additionally shown success failure goal activity intimately tied
together model successful events allows us naturally learn
two important aspects life specifically demonstrated intentions rational
agents automatically discovered process resolving inconsistencies theory
successful instances set activities examples failed attempts activities
formulated four questions designed experiments within ctf domain
empirically answer compared alternative approaches solving multi agent activity recognition augmented markov logic model takes account
relationships among individual players relationships among activities entire length
game although computationally costly significantly accurate real world data
furthermore illustrated explicitly modeling unsuccessful attempts boosts performance
important recognition tasks

future work
multi agent activity recognition especially interesting context current unprecedented
growth line social networksin terms size popularity impact offline lives location information alone allows rich peoples
interactions case line social networks additionally access content
users posts explicit implicit network interactions instance recent
study shows interestingly twitter status updates reveal authors location
sadilek kautz bigham data sources available machines massive
volumes ever increasing real time streaming rate note substantial fraction posts
services facebook twitter talk everyday activities users naaman boase
lai information channel become available community
recently thus able reason human behavior interactions automated
way tap colossal amounts knowledge isat presentdistributed across whole
population
currently extending model handle explicit gps traces able
infer location people broadcast gps coordinates basic idea
leverage structure relationships among people vast majority us participate line
social networks typically friends location thus view
gps enabled people noisy location sensors use network interactions dynamics
estimate location rest users present testing public
tweets



fis adilek k autz

acknowledgments
thank anonymous reviewers constructive feedback thank sebastian riedel
help thebeast radka sadlkova wendy beatty helpful comments
work supported aro grant w nf darpa sbir contract w p q c gift kodak

references
abowd g atkeson c g hong j long kooper r pinkerton cyberguide
mobile context aware tour guide wirel netw
allwein e schapire r singer reducing multiclass binary unifying
margin classifiers journal machine learning
ashbrook starner gps learn significant locations predict movement
across multiple users personal ubiquitous comput
baker c tenenbaum j saxe r bayesian human action understanding
advances neural information processing systems
baker c goodman n tenenbaum j theory social goal inference proceedings thirtieth annual conference cognitive science society pp
baker c saxe r tenenbaum j bayesian theory mind modeling joint belief desire
attribution proceedings thirty second annual conference cognitive science
society
baker c tenenbaum j saxe r goal inference inverse proceedings
th annual meeting cognitive science society
baldwin baird j discerning intentions dynamic human action trends
cognitive sciences
barbuceanu fox cool language describing coordination multi
agent systems proceedings first international conference multi agent systems
icmas pp
bell r koren volinsky c modeling relationships multiple scales improve
accuracy large recommender systems kdd pp york ny usa acm
biba ferilli esposito f discriminative structure learning markov logic
networks pp springer
biswas r thrun fujimura k recognizing activities multiple cues workshop human motion pp
bui h h general model online probabilistic plan recognition eighteenth international joint conference artificial intelligence ijcai
busetta p serafini l singh zini f extending multi agent cooperation overhearing cooperative information systems pp springer
chandola v banerjee kumar v anomaly detection survey acm comput
surv


fil ocation r easoning c omplex ulti agent b ehavior

culotta mccallum joint deduplication multiple record types relational data
proceedings th acm international conference information knowledge
management pp acm
davis j domingos p deep transfer via second order markov logic proceedings
th annual international conference machine learning pp acm
de raedt l logical relational learning springer verlag york inc
de raedt l frasconi p kersting k muggleton eds probabilistic inductive
logic programming theory applications vol lecture notes computer
science springer
de raedt l kersting k probabilistic inductive logic programming de raedt et al
pp
denis p baldridge j joint determination anaphoricity coreference resolution
integer programming proceedings naacl hlt pp
domingos p multi relational record linkage proceedings kdd workshop
multi relational data mining
domingos p kok lowd poon h richardson singla p markov logic
de raedt et al pp
eagle n pentland reality mining sensing complex social systems personal
ubiquitous computing
eagle n pentland eigenbehaviors identifying structure routine behavioral
ecology sociobiology
eagle n pentland lazer inferring social network structure mobile phone
data proceedings national academy sciences
friedman n getoor l koller pfeffer learning probabilistic relational
international joint conference artificial intelligence vol pp
goutte c gaussier e probabilistic interpretation precision recall f score
implication evaluation pp springer
gupta srinivasan p shi j davis l understanding videos constructing plots
learning visually grounded storyline model annotated videos cvpr
gutmann b kersting k tildecrf conditional random fields logical sequences
machine learning ecml pp springer
helaoui r niepert stuckenschmidt h statistical relational activity recognition
framework ambient assisted living systems ambient intelligence future trendsinternational symposium ambient intelligence isami pp springer
hong j goal recognition goal graph analysis journal artificial intelligence

horvitz e apacible j sarin r liao l prediction expectation surprise methods designs study deployed traffic forecasting service twenty first conference
uncertainty artificial intelligence



fis adilek k autz

hu pan zheng v liu n yang q real world activity recognition multiple
goals ubicomp vol pp
huynh mooney r discriminative structure parameter learning markov
logic networks proceedings th international conference machine learning
pp acm
jaeger relational bayesian networks proceedings th conference uncertainty artificial intelligence pp
jordan learning graphical kluwer academic publishers
kamar e horvitz e collaboration shared plans open world studies
ridesharing ijcai
kaminka g tambe v p pynadath v tambe monitoring teams
overhearing multi agent plan recognition journal artificial intelligence

kersting k de raedt l bayesian logic programs proceedings work inprogress track th international conference inductive logic programming
kersting k de raedt l raiko logical hidden markov journal artificial
intelligence
kok domingos p learning structure markov logic networks proceedings
nd international conference machine learning pp acm
kok domingos p statistical predicate invention proceedings th international conference machine learning pp acm
kok domingos p learning markov logic network structure via hypergraph lifting
proceedings th annual international conference machine learning pp
acm
kok domingos p statistical predicate invention icml proceedings
th international conference machine learning pp york ny usa
acm
koller probabilistic relational inductive logic programming pp
springer
lafferty j conditional random fields probabilistic segmenting labeling
sequence data international conference machine learning icml pp
morgan kaufmann
landwehr n gutmann b thon philipose de raedt l relational
transformation tagging human activity recognition proceedings th international workshop multi relational data mining mrdm pp
liao l patterson fox kautz h learning inferring transportation routines
artificial intelligence
liao l fox kautz h learning inferring transportation routines proceedings nineteenth national conference artificial intelligence



fil ocation r easoning c omplex ulti agent b ehavior

liao l fox kautz h location activity recognition relational markov
networks ijcai
limketkai b fox liao l crf filters discriminative particle filters sequential
state estimation robotics automation ieee international conference pp

ling x weld temporal information extraction proceedings twenty fifth
national conference artificial intelligence
z modelling prism intelligent system msc thesis linacre college university oxford
manfredotti c modeling inference relational dynamic bayesian networks
advances artificial intelligence pp springer
manfredotti c messina e relational dynamic bayesian networks improve multitarget tracking advanced concepts intelligent vision systems pp springer
manfredotti c hamilton h zilles learning rdbns activity recognition
neural information processing systems
mihalkova l mooney r bottom learning markov logic network structure
proceedings th international conference machine learning pp acm
moore essa recognizing multitasked activities stochastic context free grammar proceedings aaai conference
muggleton learning structure parameters stochastic logic programs proceedings th international conference inductive logic programming pp
springer verlag
murphy k p dynamic bayesian networks representation inference learning ph
thesis university california berkeley
naaman boase j lai c h really message content social
awareness streams cscw proceedings acm conference computer
supported cooperative work pp york ny usa acm
natarajan tadepalli p altendorf e dietterich fern restificar learning
first order probabilistic combining rules proceedings nd international conference machine learning pp acm
natarajan bui h h tadepalli p kersting k wong w logical hierarchical
hidden markov modeling user activities proc ilp
papai singla p kautz h constraint propagation efficient inference markov
logic seventeenth international conference principles practice constraint
programming
pentland honest signals shape world mit press
poon h domingos p sound efficient inference probabilistic deterministic
dependencies proceedings national conference artificial intelligence vol
p menlo park ca cambridge london aaai press mit press



fis adilek k autz

poon h domingos p joint inference information extraction proceedings
nd national conference artificial intelligence pp aaai press
poon h domingos p joint unsupervised coreference resolution markov logic
proceedings conference empirical methods natural language processing pp
association computational linguistics
riedel improving accuracy efficiency map inference markov logic
proceedings proceedings twenty fourth conference annual conference uncertainty artificial intelligence uai pp corvallis oregon auai press
sadilek kautz h modeling reasoning success failure intent
multi agent activities mobile context awareness workshop twelfth acm international
conference ubiquitous computing
sadilek kautz h b recognizing multi agent activities gps data twentyfourth aaai conference artificial intelligence
sadilek kautz h bigham j p finding friends following
fifth acm international conference web search data mining wsdm
sato kameya parameter learning logic programs symbolic statistical modeling journal artificial intelligence
sato kameya advances logic probabilistic modeling prism
probabilistic inductive logic programming pp springer
shakarian p subrahmanian v spaino l scare case study baghdad
proceedings third international conference computational cultural dynamics
aaai
shen j activity recognition desktop environments ph thesis oregon state university
shoenfield j r mathematical logic addison wesley
singla p domingos p discriminative training markov logic networks proceedings national conference artificial intelligence vol p menlo park ca
cambridge london aaai press mit press
singla p domingos p markov logic infinite domains uai
tang k lin j hong j siewiorek sadeh n rethinking location sharing exploring implications social driven vs purpose driven location sharing proceedings
th acm international conference ubiquitous computing pp acm
tran davis l visual event modeling recognition markov logic networks
proceedings th european conference computer vision
ullman baker c macindoe evans goodman n tenenbaum j help
hinder bayesian social goal inference advances neural information
processing systems nips vol
vail conditional random fields activity recognition ph thesis carnegie mellon
university



fil ocation r easoning c omplex ulti agent b ehavior

vail veloso feature selection activity recognition multi robot domains
proceedings aaai vol
wang j domingos p hybrid markov logic networks proceedings rd
national conference artificial intelligence pp aaai press
wellner b mccallum peng f hay integrated conditional model information extraction coreference application citation matching proceedings
th conference uncertainty artificial intelligence pp auai press
wilson fern ray tadepalli p learning transferring roles multi agent
mdps proceedings aaai
wilson fern tadepalli p bayesian role discovery multi agent reinforcement learning proceedings th international conference autonomous agents
multiagent systems pp international foundation
autonomous agents multiagent systems
wrobel first order theory refinement advances inductive logic programming pp
ios press amsterdam
wu lian c hsu j joint recognition multiple concurrent activities factorial
conditional random fields proc nd conf artificial intelligence aaai
yoshikawa k riedel asahara matsumoto jointly identifying temporal relations markov logic proceedings joint conference th annual meeting
acl th international joint conference natural language processing
afnlp pp association computational linguistics




