journal artificial intelligence

submitted published

learning win reading manuals
monte carlo framework
r k branavan

branavan csail mit edu

computer science artificial intelligence laboratory
massachusetts institute technology

david silver

silver cs ucl ac uk

department computer science
university college london

regina barzilay

regina csail mit edu

computer science artificial intelligence laboratory
massachusetts institute technology

abstract
domain knowledge crucial effective performance autonomous control systems
typically human effort required encode knowledge control
present language grounding automatically interprets
text context complex control application game uses domain
knowledge extracted text improve control performance text analysis
control strategies learned jointly feedback signal inherent application
effectively leverage textual information method automatically extracts text
segment relevant current game state labels task centric predicate
structure labeled text used bias action selection policy game
guiding towards promising regions action space encode model text
analysis game playing multi layer neural network representing linguistic decisions
via latent variables hidden layers game action quality via output layer
operating within monte carlo search framework estimate model parameters
feedback simulated games apply complex strategy game
civilization ii official game manual text guide
linguistically informed game playing agent significantly outperforms language unaware
counterpart yielding absolute improvement winning games
playing built ai civilization

introduction
study task grounding document content control applications
computer games applications agent attempts optimize utility
function e g game score learning select situation appropriate actions complex
domains finding winning strategy challenging even humans therefore human
players typically rely manuals guides describe promising tactics provide
general advice underlying task surprisingly textual information never
utilized control despite potential greatly improve performance
goal therefore develop methods achieve automatic fashion
c

ai access foundation rights reserved

fibranavan silver barzilay

natural resources available population settles aects ability produce food
goods cities built near water sources irrigate increase crop yields
cities near mineral resources mine raw materials build city plains grassland
square river running possible

figure excerpt user manual game civilization ii
explore question context strategy games challenging class large scale
adversarial
consider instance text shown figure excerpt user
manual game civilization ii text describes game locations action
build city effectively applied stochastic player access
text would gain knowledge hard way would repeatedly attempt
action myriad states thereby learning characterization promising state action
pairs observed game outcomes games large state spaces long
horizons high branching factors prohibitively slow ineffective
access text however could learn correlations words
text game attributes e g word river places rivers game
thus leveraging strategies described text select better actions
improve performance control applications domain knowledge automatically extracted text need address following challenges
grounding text state action space control application text
guides provide wealth information effective control strategies including
situation specific advice well general background knowledge benefit
information learn mapping text
guide states actions control application mapping allows
state specific advice matching state attributes verbal
descriptions furthermore relevant sentence found mapping biases
select action proposed guide document mapping
modeled word level ideally would use information encoded
structure sentence predicate argument structure instance
explicitly identify predicates state attribute descriptions
map directly structures inherent control application
annotation free parameter estimation text analysis tasks relate
well known methods information extraction prior work primarily focused
supervised methods setup text analysis state dependent therefore annotations need representative entire state space given enormous state
space continually changes game progresses collecting annotations
impractical instead propose learn text analysis feedback signal
inherent control application e g game score feedback computed
automatically step game thereby allowing continuously
adapt local observed game context
http en wikipedia org wiki civilization ii



filearning win reading manuals monte carlo framework

effective integration extracted text information control application text guides provide complete step step advice situations player may encounter even advice available learned
mapping may noisy resulting suboptimal choices therefore need design method achieve effective control absence textual advice
robustly integrating automatically extracted information available
address challenge incorporating language analysis monte carlo search
state art framework playing complex games traditionally framework
operates state action features extending monte carlo search
include textual features integrate two sources information principled
fashion
summary
address challenges unified framework markov decision processes
mdp formulation commonly used game playing setup consists
game stochastic environment goal player maximize given
utility function r state players behavior determined action value
function q assesses goodness action state attributes

incorporate linguistic information mdp formulation expand action
value function include linguistic features state action features known
point computation relevant words semantic roles observed
therefore model text relevance hidden variable similarly use hidden variables
discriminate words describe actions describe state attributes
rest sentence incorporate hidden variables action value function
model q non linear function approximation multi layer neural network
despite added complexity parameters non linear model effectively learned monte carlo search framework monte carlo search actionvalue function estimated playing multiple simulated games starting current
game state use observed reward simulations update parameters
neural network via backpropagation focuses learning current game state
allowing method learn language analysis game play appropriate observed
game context
evaluation
test method strategy game civilization ii notoriously challenging game
immense action space source knowledge guiding model use
official game manual baseline employ similar monte carlo search player
access textual information demonstrate linguisticallyinformed player significantly outperforms baseline terms number games
moreover modeling deeper linguistic structure sentences improves performance full length games yields improve civilization ii igns list top video games time
http top ign com ign top game html



fibranavan silver barzilay

ment language unaware baseline wins games built
hand crafted ai civilization ii video method playing game available
http groups csail mit edu rbg code civ video code data work along
complete experimental setup preconfigured environment virtual machine
available http groups csail mit edu rbg code civ
roadmap
section provide intuition benefits integrating textual information
learning control section describes prior work language grounding emphasizing unique challenges opportunities setup section positions
work large body monte carlo players section presents
background monte carlo search applied game playing section present
multi layer neural network formulation action value function combines information text control application next present monte carlo method
estimating parameters non linear function sections focus application game civilization ii section compare method
range competitive game playing baselines empirically analyze properties finally section discuss implications
conclude

learning game play text
section provide intuitive explanation textual information help improve action selection complex game clarity first discuss benefits textual
information supervised scenario thereby decoupling questions concerning modeling
representation related parameter estimation assume every state
represented set n features sn given state goal select
best possible action aj fixed set model task multiclass classification choice aj represented feature vector aj aj sn aj
si aj n represents feature created taking cartesian product sn aj learn classifier effectively need training set
sufficiently covers possible combinations state features actions however domains complex state spaces large number possible actions many instances
state action feature values unobserved training
generalization power classifier improved textual information assume training example addition state action pair
contains sentence may describe action taken given state attributes intuitively want enrich basic classifier features capture correspondence
states actions words describe given sentence w composed
word types w w wm features form si wk aj wk
every n k aj assuming action described similar words throughout guide expect text enriched classifier would able
learn correspondence via features aj wk similar intuition holds learning
correspondence state attributes descriptions represented features
si wk features classifier connect state action aj


filearning win reading manuals monte carlo framework

evidence provided guiding sentence occurrences contexts
throughout training data text free classifier may support association
action appear similar state context training set
benefits textual information extend trained control
feedback rather supervised data training scenario assesses
goodness given state action combination simulating limited number game turns
action taken observing control feedback provided underlying
application built mechanism see section employs
observed feedback learn feature weights intelligently samples space search
promising state action pairs access collection sentences
similar feedback mechanism used sentences match given stateaction pair section state action description features si wk
aj wk jointly learns identify relevant sentences map actions
states descriptions note used classification basis
discussion section reality methods learn regression function

related work
section first discuss prior work field grounded language acquisition
subsequently look two areas specific application domain e natural language
analysis context games monte carlo search applied game playing
grounded language acquisition
work fits broad area grounded language acquisition
goal learn linguistic analysis non linguistic situated context oates
barnard forsyth siskind roy pentland yu ballard chen
mooney zettlemoyer collins liang jordan klein branavan
chen zettlemoyer barzilay branavan zettlemoyer barzilay vogel jurafsky clarke goldwasser chang roth tellex kollar dickerson walter
banerjee teller roy chen mooney liang jordan klein goldwasser reichart clarke roth appeal formulation lies reducing
need manual annotations non linguistic signals provide powerful albeit
noisy source supervision learning traditional grounding setup assumed
non linguistic signals parallel content input text motivating machine
translation view grounding task alternative grounding
control framework learner actively acquires feedback non linguistic environment uses drive language interpretation summarize approaches
emphasizing similarity differences work
learning grounding parallel data
many applications linguistic content tightly linked perceptual observations providing rich source information learning language grounding examples parallel
data include images captions barnard forsyth robocup game events paired
text commentary chen mooney sequences robot motor actions de

fibranavan silver barzilay

scribed natural language tellex et al large diversity properties
parallel data resulted development tailored specific grounding
contexts instead application independent grounding nevertheless existing
grounding approaches characterized along several dimensions illuminate
connection
representation non linguistic input first step grounding words
perceptual data discretize non linguistic signal e g image representation facilitates alignment instance barnard forsyth segment images regions subsequently mapped words approaches
intertwine alignment segmentation single step roy pentland
two tasks clearly interrelated application segmentation required
state action representation nature discrete
many approaches move beyond discretization aiming induce rich hierarchical structures non linguistic input fleischman roy chen mooney
instance fleischman roy parse action sequences
context free grammar subsequently mapped semantic frames chen
mooney represent action sequences first order logic contrast
capitalizes structure readily available data state action
transitions inducing richer structure state action space may benefit mapping difficult right field hierarchical
barto mahadevan
representation linguistic input early grounding approaches used bagof words represent input documents yu ballard barnard
forsyth fleischman roy recent methods relied richer
representation linguistic data syntactic trees chen mooney
semantic templates tellex et al method incorporates linguistic information multiple levels feature representation encodes words
well syntactic information extracted dependency trees shown
richer linguistic representations significantly improve model performance
alignment another common feature existing grounding training
procedure crucially depends well words aligned non linguistic structures
reason assume alignment provided part training
data fleischman roy tellex et al grounding
alignment induced part training procedure examples approaches
methods barnard forsyth liang et al
jointly generate text attributes grounding context treating
alignment unobserved variable
contrast explicitly model alignment model due lack
parallel data instead aim extract relevant information text infuse
control application


filearning win reading manuals monte carlo framework

learning grounding control feedback
recent work moved away reliance parallel corpora control feedback primary source supervision assumption behind setup
textual information used drive control application applications performance
correlate quality language analysis assumed performance measurement obtained automatically setup conducive reinforcement learning
approaches estimate model parameters feedback signal even noisy
delayed
one line prior work focused task mapping textual instructions
policy control application assuming text fully specifies actions executed environment example previous work branavan et al
applied task translating instructions computer manual
executable gui actions vogel jurafsky demonstrate grounding
framework effectively map navigational directions corresponding path map
second line prior work focused full semantic parsing converting given text
formal meaning representation first order logic clarke et al
methods applied domains correctness output accurately evaluated control feedback example output database
query executed provides clean oracle feedback signal learning line
work assumes text fully specifies required output
method driven control feedback language interpretation task
fundamentally different assume given text document provides highlevel advice without directly describing correct actions every potential game state
furthermore textual advice necessarily translate single strategy fact
text may describe several strategies contingent specific game states
reason strategy text cannot simply interpreted directly policy therefore
goal bias learned policy information extracted text end
aim achieve complete semantic interpretation rather use partial text analysis
compute features relevant control application
language analysis games
even though games provide rich domain situated text analysis
prior attempts leveraging opportunity gorniak roy eisenstein
clarke goldwasser roth
eisenstein et al aim automatically extract information collection
documents help identify rules game information represented predicate logic formulae estimated unsupervised fashion via generative model
extracted formulae along observed traces game play subsequently fed inductive logic program attempts reconstruct rules game
high level goal similar e extract information text useful external
task several key differences firstly eisenstein et al analyze
text game two disjoint steps model tasks integrated fashion
allows model learn text analysis pertinent game play time
text guide game play secondly method learns text analysis game


fibranavan silver barzilay

play feedback signal inherent game avoiding need pre compiled game
traces enables method operate effectively complex games collecting
sufficiently representative set game traces impractical
gorniak roy develop machine controlled game character responds
spoken natural language commands given traces game actions manually annotated
transcribed speech method learns structured representation text
aligned action sequences learned model used interpret spoken instructions
grounding actions human player current game state
method learn play game enables human control additional game
character via speech contrast gorniak roy aim develop
fully autonomously control actions one player game furthermore
method operates games user manual rather human provided contextually
relevant instructions requires model identify text contains information
useful current game state addition mapping text productive actions
finally method learns game feedback collected via active interaction without
relying manual annotations allows us effectively operate complex games
collecting traditional labeled traces would prohibitively expensive
monte carlo search game ai
monte carlo search mcs state art framework successfully
applied prior work playing complex games go poker scrabble real time
strategy games gelly wang munos teytaud tesauro galperin billings
castillo schaeffer szafron sheppard schafer sturtevant balla
fern framework operates playing simulated games estimate goodness value different candidate actions games state action spaces
complex number simulations needed effective play become prohibitively large
previous application mcs addressed issue two orthogonal techniques
leverage domain knowledge guide prune action selection estimate
value untried actions observed outcomes simulated games estimate used bias action selection mcs games relies
techniques describe differences application
techniques prior work
leveraging domain knowledge
domain knowledge shown critically important achieving good performance mcs complex games prior work achieved manually
encoding relevant domain knowledge game playing example via
manually specified heuristics action selection billings et al gelly et al
hand crafted features tesauro galperin value functions encoding expert
knowledge sturtevant contrast approaches goal automatically extract use domain knowledge relevant natural language documents thus
bypassing need manual specification method learns text interpretation
game action selection outcomes simulated games mcs allows
identify leverage textual domain knowledge relevant observed game context


filearning win reading manuals monte carlo framework

action selection
according
policy function

stochastic state
transition according
distribution

figure markov decision process actions selected according policy function
given current state execution selected action ai e g causes
mdp transition state according stochastic state transition
distribution

estimating value untried actions
previous approaches estimating value untried actions relied two techniques
first upper confidence bounds tree uct heuristic used concert
monte carlo tree search variant mcs augments actions value exploration
bonus rarely visited state action pairs resulting better action selection better
overall game performance gelly et al sturtevant balla fern
second technique learn linear function approximation action values current
state game feedback tesauro galperin silver sutton muller
even though method follows latter model action value q via
non linear function approximation given complexity application domain
non linear approximation generalizes better linear one shown
significantly improves performance importantly non linear model enables
method represent text analysis latent variables allowing use textual information
estimate value untried actions

monte carlo search
task leverage textual information help us win turn strategy game
given opponent section first describe monte carlo search framework
within method operates details linguistically informed monte carlo
search given section
game representation
formally represent given turn stochastic game markov decision process
mdp mdp defined tuple hs ri
state space set possible states state represents complete
configuration game player turns
action space set possible actions turn strategy game
player controls multiple game units turn thus action represents
joint assignment unit actions executed current player turn


fibranavan silver barzilay

transition distribution probability executing action state
state next game turn distribution encodes way
game state changes due game rules opposing players actions
reason stochastic shown figure executing
action given state different outcomes
reward function r r immediate reward received transitioning
state value reward correlates goodness actions executed
higher reward indicating better actions
aspects mdp representation game e r
defined implicitly game rules step game game playing
agent observe current game state select best possible action
agent executes action game state changes according state transition
distribution known priori state transitions sampled
distribution invoking game code black box simulator e playing
game action agent receives reward according reward function r
game playing setup value reward indication chances winning
game state crucially reward signal may delayed e r may
non zero value game ending states win loss tie
game playing agent selects actions according stochastic policy
specifies probability selecting action state expected total reward
executing action state following policy termed action value function
q goal optimal policy maximizes expected
total reward e maximizes chances winning game optimal action value

function q known optimal game playing behavior would select action

highest q may computationally hard optimal policy

q many well studied available estimating effective
approximation sutton barto
monte carlo framework computer games
monte carlo search shown figure simulation search paradigm
dynamically estimating action values q given state st see
pseudo code estimate rewards observed multiple roll outs
simulated game starting state st specifically roll
starts state st repeatedly selects executes actions according
simulation policy sampling state transitions game completion
time final reward r measured action value function updated
accordingly monte carlo control sutton barto updated action value
monte carlo search assumes possible play simulated games simulations may
played heuristic ai player experiments built ai game used
opponent
general roll outs run game completion simulations expensive case
domain roll outs truncated fixed number steps however depends availability
approximate reward signal truncation point experiments use built score
game reward reward noisy available every stage game



filearning win reading manuals monte carlo framework

game

copy game
state
simulator

apply action
best simulation
outcome game
single
simulation
rollout

update rollout
policy
game feedback
rollout

simulation

simulation

figure overview monte carlo search game state st independent set simulated games roll outs done best possible game
action roll starts state st actions selected according
simulation policy policy learned roll outs
roll outs improving policy turn improves roll action selection process repeated every actual game state simulation
policy relearned scratch time

function q used define improved simulation policy thereby directing subsequent roll outs towards higher scoring regions game state space fixed number
roll outs performed action highest average final reward
simulations selected played actual game state st process repeated
state encountered actual game action value function
relearned scratch game state simulation policy usually selects
actions maximize action value function however sometimes valid actions
randomly explored case valuable predicted current es conceivable sharing action value function across roll outs different game states
would beneficial empirically case experiments one possible reason
domain game dynamics change radically many points game e g
technology becomes available change occurs may actually detrimental play
according action value function previous game step note however action value
function indeed shared across roll outs single game state st parameters updated
successive roll outs learned model helps improve roll action selection thereby
improves game play setup relearning scratch game state shown
beneficial even stationary environments sutton koop silver



fibranavan silver barzilay

timate q accuracy q improves quality action selection
improves vice versa cycle continual improvement sutton barto
success monte carlo search depends ability make fast local estimate
action value function roll outs collected via simulated play however games
large branching factors may feasible collect sufficient roll outs especially
game simulation computationally expensive thus crucial learned
action value function generalizes well small number roll outs e observed
states actions rewards one way achieve model action value function
linear combination state action attributes
q w
f
f rn real valued feature function w
weight vector prior work
shown linear value function approximations effective monte carlo search
framework silver et al
note learning action value function q monte carlo search related
reinforcement learning rl sutton barto fact use
standard gradient descent updates rl estimate parameters q
however one crucial difference two techniques general goal rl
q applicable state agent may observe existence
monte carlo search framework aim learn q specialized current state
essence q relearned every observed state actual game
states actions feedback simulations relearning may seem suboptimal
two distinct advantages first since q needs model current state
representationally much simpler global action value function second due
simpler representation learned fewer observations global actionvalue function sutton et al properties important state
space extremely large case domain

adding linguistic knowledge monte carlo framework
goal work improve performance monte carlo search framework
described information automatically extracted text section
describe achieve terms model structure parameter estimation
model structure
achieve aim leveraging textual information improve game play method
needs perform three tasks identify sentences relevant current game state
label sentences predicate structure predict good game actions combining
game features text features extracted via language analysis steps first describe
tasks modeled separately showing integrate
single coherent model


filearning win reading manuals monte carlo framework

procedure playgame
initialize game state fixed starting state


run n simulated games
n
ai ri simulategame st
end
compute average observed utility action
x
arg max
ri
na

ai

execute selected action game
st st
end

procedure simulategame st
u
compute q function approximation
q su w
f su
sample action action value function greedy fashion

uniform
probability
au su

arg max q su otherwise


execute selected action game
su su au
game lost
break
end
update parameters w
q st
return action observed utility
return r
general monte carlo


fibranavan silver barzilay

modeling sentence relevance
discussed section small fraction strategy document likely provide
guidance relevant current game context therefore effectively use information
given document first need identify sentence yi relevant
current game state action model decision log linear distribution
defining probability yi relevant sentence


p yi e u yi



rn feature function u parameters need estimate


function
encodes features combine attributes sentence yi
attributes game state action features allow model learn correlations
game attributes attributes relevant sentences
modeling predicate structure
text guide action selection addition word level correspondences
would leverage information encoded structure sentence
example verbs sentence might likely describe suggested game actions
aim access information inducing task centric predicate structure
sentences label words sentence action description statedescription background given sentence precomputed dependency parse q
model word word labeling decision log linear fashion e distribution
predicate labeling z sentence given
p z q p e q


p ej j q



j


p ej j q e v ej j q
j j q rn
ej predicate label j th word feature function e
addition encoding word type part speech tag includes dependency parse
information word features allow predicate labeling decision condition
syntactic structure sentence
modeling action value function
relevant sentence identified labeled predicate structure
needs use information along attributes current game state
select best possible game action end redefine action value function
q weighted linear combination features game text information
q w
f yi zi



use approximation selecting single relevant sentence alternative combining
features sentences text weighted relevance probability p yi
setup computationally expensive one used



filearning win reading manuals monte carlo framework

input layer

deterministic feature
layer

output layer

hidden layer encoding
sentence relevance
hidden layer encoding
predicate labeling

figure structure neural network model rectangle represents collection
units layer shaded trapezoids connections layers
fixed real valued feature function x transforms game state action
strategy document input vector x second layer contains
two disjoint sets hidden units z encodes sentence relevance
decisions z predicate labeling softmax layers one
unit active time units third layer f yi zi set
fixed real valued feature functions active units yi zi
z respectively

hs di ha yi zi w
weight vector f yi zi rn feature
function state action relevant sentence yi predicate labeling zi
structure action value function allows explicitly learn correlations
textual information game states actions action maximizes q
selected best action state
arg max q


complete joint model
two text analysis action value function described form three
primary components text aware game playing construct single
principled model components representing via different layers
multi layer neural network shown figure essentially text analysis decisions
modeled latent variables second hidden layer network final
output layer action value function
note select action q depends relevant sentence yi sentence
selected conditioned action may look cyclic dependency actions
sentence relevance however case since q therefore sentence relevance
p computed every candidate action actual game action selected
estimate q



fibranavan silver barzilay

input layer x neural network encodes inputs model e
current state candidate action document second layer consists two
disjoint sets hidden units z set operates stochastic n softmax
selection layer bridle activation function units layer standard
softmax function
x
p yi x e ui x
e uk x
k

ith

yi
hidden unit ui weight vector corresponding yi k
number units layer given activation function mathematically
equivalent log linear distribution layers z operate log linear
node activation softmax layer simulates sampling log linear distribution
use layer replicate log linear model sentence relevance equation
node yi representing single sentence similarly unit zi layer z represents
complete predicate labeling sentence equation
third feature layer f neural network deterministically computed given
active units yi zi softmax layers values input layer unit
layer corresponds fixed feature function fk yi zi r finally output layer
encodes action value function q weighted linear combination units
feature layer thereby replicating equation completing joint model
example kind correlations learned model consider figure
relevant sentence already selected given game state predicate
labeling sentence identified words irrigate settler describing
action take game roll outs return higher rewards irrigate action
settler unit model learn association action words
describe similarly learn association state description words
feature values current game state e g word city binary feature nearcity allows method leverage automatically extracted textual information
improve game play
parameter estimation
learning method performed online fashion game state st
performs simulated game roll observes outcome simulation
updates parameters u v w
action value function q st shown
figure three steps repeated fixed number times actual game state
information roll outs used select actual game action
relearns parameters action value function every game state
st specializes action value function subgame starting st learning
specialized q st game state common useful games complex
state spaces dynamics learning single global function approximation
particularly difficult sutton et al consequence function specialization
need online learning since cannot predict games states seen
intention incorporate action value function information relevant
sentence therefore practice perform predicate labeling sentence selected
relevance component model



filearning win reading manuals monte carlo framework

settlers unit candidate action
plains

features
action irrigate action word irrigate
action irrigate state word land
action irrigate terrain plains
action irrigate unit type settler
state word city near city true

city

settlers unit candidate action

settler unit

relevant text use settlers irrigate land near city
predicted action words

irrigate settler

predicted state words

land near city

irrigate

features
action build city
action build city
action build city
action build city
state word city







build city

action word irrigate
state word land
terrain plains
unit type settler
near city true

figure example text game attributes resulting candidate action features
left portion game state arrows indicating game attributes
left sentence relevant game state along action
state words identified predicate labeling right two candidate
actions settler unit along corresponding features mentioned
relevant sentence irrigate better two actions executing
lead future higher game scores feedback features shown
allow model learn effective mappings actionword irrigate action irrigate state word city game
attribute near city

testing function specialization states cannot done priori ruling
traditional training test separation
since model non linear approximation underlying action value function
game learn model parameters applying non linear regression observed final
utilities simulated roll outs specifically adjust parameters stochastic
gradient descent minimize mean squared error action value q
final utility r observed game state action resulting update
model parameters form

r q

r q q
learning rate parameter minimization performed via standard error
backpropagation bryson ho rumelhart hinton williams resulting
following online parameter updates
w
w
w q r f yi zj
ui ui u q r q x p yi
vi vi v q r q x p zi


fibranavan silver barzilay

w learning rate q q w
ui vi parameters
final layer sentence relevance layer predicate labeling layer respectively
derivations update equations given appendix

applying model
game test model civilization ii multi player strategy game set
earth randomly generated world player acts ruler one civilization
starts game units e two settlers two workers one explorer
goal expand civilization developing technologies building cities
units win game controlling entire world successfully sending
spaceship another world map game world divided grid typically
squares grid location represents tile land sea figure shows
portion world map particular instance game along game
units one player experiments consider two player game civilization ii
map squares smallest map allowed freeciv map size used
novice human players looking easier game well advanced players wanting
game shorter duration test built ai player
game difficulty level default normal setting
game states actions
define game state monte carlo search map game world along
attributes map tile location attributes players cities
units examples attributes shown figure space possible
actions city unit defined game rules given current game state
example cities construct buildings harbors banks create units
types individual units move around grid perform unit
specific actions irrigation settlers military defense archers since
player controls multiple cities units players action space turn defined
combination possible actions cities units experiments
average player controls approximately units unit possible actions
resulting action space player large e effectively deal
large action space assume given state actions individual city
unit independent actions cities units player
time maximize parameter sharing single action value function
cities units player

freeciv five difficulty settings novice easy normal hard cheating evidenced discussions games online forum http freeciv wikia com index php title forum playing freeciv
human players game even novice setting hard
since player executes game actions turn e opposing units fixed individual players
turn opponents moves enlarge players action space



filearning win reading manuals monte carlo framework

figure portion game map one instance civilization ii game three
cities several units single player visible map visible
different terrain attributes map tiles grassland hills mountains
deserts

nation attributes


city attributes


amount gold treasury
world controlled
number cities
population
known technologies

map tile attributes


city population
surrounding terrain resources
amount food resources produced
number units supported city
number type units present

unit attributes

terrain type e g grassland mountain etc
tile resources e g wheat coal wildlife etc
tile river
construction tile city road rail etc
types units enemy present



unit type e g worker explorer archer etc
unit health hit points
unit experience
unit city
unit fortied

figure example attributes game state



fibranavan silver barzilay

utility function
critically important monte carlo search availability utility
function evaluate outcomes simulated game roll outs typical application final game outcome terms victory loss used
utility function tesauro galperin unfortunately complexity civilization
ii length typical game precludes possibility running simulation roll outs
game completion game however provides player real valued game
score noisy indicator strength civilization since playing
two player game players score relative opponents used utility
function specifically use ratio game score two players
features
components method operate features computed basic set text
game attributes text attributes include words sentence along
parts speech dependency parse information dependency types parent
words basic game attributes encode game information available human players
via games graphical user interface examples attributes shown
figure
identify sentence relevant current game state candidate action
sentence relevance component computes features combined basic attributes
two types first
game sentence text features
computes cartesian product attributes game attributes
candidate sentence second type consists binary features test overlap
words candidate sentence text labels current game state
candidate action given word tokens manual overlap
labels game similarity features highly sparse however serve
signposts guide learner shown method able operate
effectively even absence features performs better present
predicate labeling unlike sentence relevance purely language task
compute
operates basic text attributes features component
cartesian product candidate predicate label words type part speech
tag dependency parse information final component model action value
approximation operates attributes game state candidate action
sentence selected relevant predicate labeling sentence features
layer f compute three way cartesian product attributes candidate
action attributes game state predicate labeled words relevant

f compute approximately features
sentence overall
respectively resulting total features full model figure shows
examples features

difference players scores used utility function however practice
score ratio produced better empirical performance across baselines



filearning win reading manuals monte carlo framework

sentence relevance features
action build city
tile river true
word build

action irrigate
tile next city true
word irrigate

otherwise

otherwise

predicate labeling features
label action
word city
parent word build

label state
word city
parent label near

otherwise

otherwise

action value features
action build city
tile river true
action word build
state word river

action irrigate
tile terrain plains
action word irrigate
state word city

otherwise

otherwise

figure examples features used model feature conditions
test game attributes highlighted blue test words
game manual highlighted red

experimental setup
section describe datasets evaluation metrics experimental framework
used test performance method baselines
datasets
use official game manual civilization ii strategy guide document
text manual uses vocabulary word types composed sentences
average words long manual contains information rules
game game user interface basic strategy advice different aspects
game use stanford parser de marneffe maccartney manning
default settings generate dependency parse information sentences game
manual
experimental framework
apply method civilization ii game use games open source reimplementation freeciv instrumented freeciv allow method programmatically
www civfanatics com content civ reference civ manual zip
http freeciv wikia com game version



fibranavan silver barzilay

primary game
monte carlo
player

game
server

modied game
gui client

memory
file system

game simulation

game
strategy guide

game
server

modied game
gui client

game state

game simulation
game
server

modied game
gui client

game simulation
game
server

modied game
gui client

figure diagram experimental framework showing monte carlo player
server primary game playing aims win multiple game
servers simulated play communications multiple processes comprising framework via unix sockets memory file system

control game e measure current game state execute game actions
save load current game state start end games
across experiments start game initial state run
steps step perform monte carlo roll outs roll run
simulated game steps halting simulation evaluating outcome note
simulated game step needs select action game unit
given average number units per player decisions
roll outs pairing decisions corresponding roll
outcome used datapoint update model parameters use fixed learning rate
experiments method baselines run
independent games manner evaluations averaged across runs
use experimental settings across methods model parameters
initialized zero
experimental setup consists monte carlo player primary game
aim play win set simulation games primary game simula addition instrumentation code freeciv server client changed increase
simulation speed several orders magnitude remove bugs caused game crash
best knowledge game rules functionality identical unmodified freeciv
version



filearning win reading manuals monte carlo framework

tions simply separate instances freeciv game instance freeciv game
made one server process runs actual game one client process
controlled monte carlo player start roll simulations
initialized current state primary game via game save reload functionality
freeciv figure shows diagram experimental framework
experiments run typical desktop pcs single intel core cpus
hyper threaded cores per cpu implemented execute simulation
roll outs parallel connecting independent simulation games computational
setup approximately simulation roll outs executed per second full model
single game steps runs hours since treat freeciv game code
black box special care taken ensure consistency across experiments code
compiled one specific machine single fixed build environment gcc
experiments run identical settings fixed set machines running fixed
os configuration linux kernel libc

evaluation metrics

wish evaluate two aspects method well improves game play leveraging textual information accurately analyzes text learning game feedback
evaluate first aspect comparing method baselines terms
percentage games built ai freeciv ai fixed heuristic
designed extensive knowledge game intention challenging human players provides good open reference baseline evaluate
method measuring percentage games averaged independent runs
however full games sometimes last multiple days making difficult extensive analysis model performance contributing factors reason primary
evaluation measures percentage games within first game steps averaged
independent runs evaluation underestimate model performance
game player gaining control entire game map within
steps considered loss since games remain tied steps two equally
matched average players playing likely win rate close
zero evaluation



adequately characterize performance method evaluate respect
several different aspects section first describe game playing performance
analyze impact textual information investigate quality text
analysis produced model terms sentence relevance predicate labeling


fibranavan silver barzilay

method
random
built ai
game
latent variable
full model
randomized text

win







loss







std err







table win rate method several baselines within first game steps
playing built game ai games neither lost still
ongoing win rate statistically significant baselines
averaged across independent game runs standard errors shown
percentage wins

method
game
latent variable
full model

wins




standard error




table win rate method two text unaware baselines built ai
averaged across independent game runs

game performance
table shows performance method several baselines primary step
evaluation scenario language aware monte carlo wins average
games substantially outperforming baselines best non languageaware method win rate dismal performance random baseline
games built ai playing indications difficulty
winning games within first steps shown table evaluated full length
games method win rate compared best text unaware
baseline

ai constrained follow rules game access information typically
available human players information technology cities units opponents
methods hand restricted actions information available human players
note performance methods full games different listed previous
publications branavan silver barzilay b previous numbers biased
code flaw freeciv caused game sporadically crash middle game play
originally believed crash random subsequently discovered happen often losing
games thereby biasing win rates methods upwards numbers presented
game bug fixed crashes observed experiments



fiobserved game score

learning win reading manuals monte carlo framework

monte carlo rollouts

figure observed game score function monte carlo roll outs text aware
full model text unaware latent variable model model parameters
updated roll thus performance improves roll outs
seen full performance improves dramatically small number
roll outs demonstrating benefit derives textual information

textual advice game performance
verify characterize impact textual advice performance
compare several baselines access textual information
simplest methods game action value function q linear
approximation games state action attributes non text aware method wins
games see table confirm methods improved performance
simply due inherently richer non linear approximation evaluate two
ablative non linear baselines first latent variable extends linear actionvalue function game set latent variables essence four layer
neural network similar full model second layers units activated
game information baseline wins games table significantly
improving linear game baseline still trailing text aware method
second ablative baseline randomized text identical model
except given randomly generated document input generate document
randomly permuting locations words game manual thereby maintaining
documents statistical properties terms type frequencies ensures
number latent variables baseline equal full model thus
baseline model capacity equal text aware method access
textual information performance baseline wins games
confirms information extracted text indeed instrumental performance
method


fibranavan silver barzilay

figure provides insight textual information helps improve game performance
shows observed game score monte carlo roll outs full model
latent variable baseline seen figure textual information guides
model high score region search space far quicker non text aware
method thus resulting better overall performance evaluate performance
method varies amount available textual information conduct
experiment random portions text given shown
figure methods performance varies linearly function amount text
randomized text experiment corresponding point information
available text
impact seed vocabulary performance
sentence relevance component model uses features compute similarity
words sentence text labels game state action assumes
availability seed vocabulary names game attributes domain
unique text labels present game occur vocabulary game manual
sparse seed vocabulary words covering word types
word tokens manual despite sparsity seed vocabulary
potentially large impact model performance since provides initial set word
groundings evaluate importance initial grounding test method
empty seed vocabulary setup full model wins games showing
seed words important method operate effectively
absence
linguistic representation game performance
characterize contribution language game performance conduct series
evaluations vary type complexity linguistic analysis performed
method evaluation shown table first sentence
relevance highlights contributions two language components model
identical full model lacks predicate labeling component
wins games showing essential identify textual advice relevant
current game state deeper syntactic analysis extracted text substantially
improves performance
evaluate importance dependency parse information language analysis
vary type features available predicate labeling component model
first ablative experiments dependency information removes dependency
features leaving predicate labeling operate word type features performance
baseline win rate clearly shows dependency features crucial
model performance remaining three methods dependency label dependency
parent pos tag dependency parent word drop dependency feature
named contribution features model performance seen
table


fiwin rate

learning win reading manuals monte carlo framework

random
text

percentage document text given model

figure performance text aware model function amount text
available construct partial documents randomly sub sampling sentences full game manual x axis shows amount sentences
given method ratio full text leftmost extreme
performance randomized text baseline showing fits
performance trend point useful textual information
method
full model
sentence relevance
dependency information
dependency label
depend parent pos tag
depend parent word

win







loss







std err







table win rates several ablated versions model showing contribution
different aspects textual information game performance sentence relevance
identical full model except lacks predicate labeling component
four methods bottom table ablate specific dependency features
indicated methods name predicate labeling component
full model

model complexity vs computation time trade
one inherent disadvantage non linear compared simpler linear
increase computation time required parameter estimation monte carlo
search setup model parameters estimated simulated roll therefore
given fixed amount time roll outs done simpler faster model
nature performance monte carlo search improves number rollouts trade model complexity roll outs important since simpler


fibranavan silver barzilay


full model
latent variable
game
ro
llo

ut









ts







ut

r
oll
ou





win rate




llro























computation time per game step seconds

figure win rate function computation time per game step montecarlo search method win rate computation time measured
roll outs per game step respectively

model could compensate roll outs thereby outperform complex
ones scenario particularly relevant games players limited amount
time turn
explore trade vary number simulation roll outs allowed
method game step recording win rate average computation time per
game figure shows evaluation roll outs
complex methods higher computational demands clearly
even given fixed amount computation time per game step text aware
model still produces best performance wide margin
learned game strategy
qualitatively methods described learn basic rush strategy essentially
attempt develop basic technologies build army take opposing cities
quickly possible performance difference different essentially
due well learn strategy
two basic reasons learn rush strategy first since
attempting maximize game score methods implicitly biased towards finding
fastest way win happens rush strategy playing
built ai civilization second complex strategies typically require
coordination multiple game units since assume game units independent


filearning win reading manuals monte carlo framework

phalanxes twice eective defending cities warriors
build city plains grassland river running




rename city refer washington
many dierent strategies dictating order
advances researched

road built use settlers start improving terrain
















settlers becomes active chose build road












use settlers engineers improve terrain square within city radius
























figure examples methods sentence relevance predicate labeling decisions
box shows two sentences identified green check marks
predicted relevant two box shows
predicted predicate structure three sentences indicating state
description action description background words unmarked mistakes
identified crosses

cannot explicitly learn coordination putting many complex strategies beyond
capabilities
accuracy linguistic analysis
described section text analysis method tightly coupled game playing
terms modeling terms learning game feedback seen
thus far text analysis indeed help game play section
focus game driven text analysis investigate well conforms
common notions linguistic correctness comparing model predictions
sentence relevance predicate labeling manual annotations
sentence relevance
figure shows examples sentence relevance decisions produced method
evaluate accuracy decisions would ideally use ground truth
relevance annotation games user manual however impractical since
relevance decision dependent game context hence specific time step
game instance therefore evaluate sentence relevance accuracy synthetic
document create document combining original game manual equal


fisentence relevance accuracy

branavan silver barzilay





sentence relevance
moving average














game step

figure accuracy methods sentence relevance predictions averaged independent runs

number sentences known irrelevant game sentences
collected randomly sampling wall street journal corpus marcus santorini
marcinkiewicz evaluate sentence relevance synthetic document
measuring accuracy game manual sentences picked relevant
evaluation method achieves average accuracy given
model differentiate game manual text wall street journal
number may seem disappointing furthermore seen figure
sentence relevance accuracy varies widely game progresses high average
initial game steps reality pattern high initial accuracy followed lower average entirely surprising official game manual civilization
ii written first time players focuses initial portion game
providing little strategy advice relevant subsequent game play reason
observed sentence relevance trend would expect final layer neural
network emphasize game features text features first steps game
indeed case seen figure
test hypothesis perform experiment first n steps
game played full model subsequent n steps played without
textual information evaluation several values n
given figure showing initial phase game indeed information
game manual useful fact hybrid method performs well
full model n achieving win rate shows method
note sentences wsj corpus contain words city potentially confuse
causing select sentences relevant game play
reminiscent opening books games chess go aim guide player
playable middle game without providing much information subsequent game play



filearning win reading manuals monte carlo framework



game features dominate



text features dominate

text feature importance














game step

figure difference norms text features game features
output layer neural network beyond initial steps game
method relies increasingly game features

win rate


















initial game steps text information used

figure graph showing availability textual information initial steps
game affects performance full model textual information
given model first n steps x axis beyond point
access text becomes equivalent latent variable
model e best non text model

able accurately identify relevant sentences information contain
pertinent game play likely produce better game performance


fibranavan silver barzilay

method
random labeling
model first steps
model first steps

b









table predicate labeling accuracy method random baseline column
b shows performance three way labeling words state action
background column shows accuracy task differentiating
state action words
game attribute

word

state grassland

city

state grassland

build

state hills

build

action settlers build city

city

action set

discovery

action settlers build city

settler

action settlers goto location

build

action city build barracks

construct

action alphabet

develop

action set

discovery

figure examples word game attribute associations learned via feature
weights model
predicate labeling
figure shows examples predicate structure output model evaluate
accuracy labeling comparing gold standard annotation game
manual table shows performance method terms accurately labels
words state action background accurately differentiates state
action words addition showing performance improvement random
baseline display clear trend evaluations labeling accuracy
higher initial stages game expected since model relies
heavily textual features beginning game see figure
verify usefulness methods predicate labeling perform final set
experiments predicate labels selected uniformly random within full model
random labeling win rate performance similar sentence
relevance model uses predicate information confirms method
able identify predicate structure noisy provides information relevant
game play figure shows examples textual information grounded
game way associations learned words game attributes final
layer full model example model learns strong association
note ground truth labeling words action description state description background
purely semantics sentence independent game state reason
manual annotation feasible unlike case sentence relevance



filearning win reading manuals monte carlo framework

game state attribute grassland words city build indicating textual
information building cities maybe useful players unit near grassland

conclusions
presented novel improving performance control
applications leveraging information automatically extracted text documents
time learning language analysis control feedback model biases
learned strategy enriching policy function text features thereby modeling
mapping words manual state specific action selection effectively learn
grounding model identifies text relevant current game state induces
predicate structure text linguistic decisions modeled jointly
non linear policy function trained monte carlo search framework
empirical model able significantly improve game win rate
leveraging textual information compared strong language agnostic baselines
demonstrate despite increased complexity model knowledge
acquires enables sustain good performance even number simulations
reduced moreover deeper linguistic analysis form predicate labeling text
improves game play information syntactic structure
text crucial analysis ignoring information large impact
model performance finally experiments demonstrate tightly coupling control
linguistic features model able deliver robust performance presence
noise inherent automatic language analysis

bibliographical note
portions work previously presented two conference publications branavan
et al b article significantly extends previous work notably
providing analysis model properties impact linguistic representation
model performance dependence model bootstrapping conditions tradeoff representational power empirical complexity section
significantly increases experiments base
conclusions addition provide comprehensive description model providing
full mathematical derivations supporting section appendix

acknowledgments
authors acknowledge support nsf career grant iis grant iis darpa bolt program hr darpa machine reading
program fa c po batelle po microsoft
faculty fellowship thanks anonymous reviewers michael collins
tommi jaakkola leslie kaelbling nate kushman sasha rush luke zettlemoyer
mit nlp group suggestions comments opinions findings conclusions
recommendations expressed authors necessarily
reflect views funding organizations


fibranavan silver barzilay

appendix parameter estimation
parameter model estimated via standard error backpropagation bryson
ho rumelhart et al derive parameter updates consider slightly
simplified neural network shown network identical model
sake clarity single second layer instead two parallel second layers
z parameter updates parallel layers z similar therefore
derivation addition updates final layer

model nodes yi network activated via softmax function
third layer f computed deterministically active nodes second layer
via function g yi x output q linear combination f weighted w

p yi x ui

e ui x
x

e uk x
k

f

x

g x yi p yi x ui



q w
f
goal minimize mean squared error e gradient descent achieve
updating model parameters along gradient e respect parameter
general term indicate parameters update takes form

q r

e


q
q r



e


equation updates final layer parameters given
q
wi

q r
w
f
wi
q r

wi q r





filearning win reading manuals monte carlo framework

since model samples one relevant sentence yi best predicate labeling
zi resulting online updates output layer parameters w

w
w
w q r f yi zj
w learning rate q q updates second layers parameters similar somewhat involved equation
ui j

q
ui j

q r
w
f
ui j
x

w

g x yk p yi x uk
q r
ui j
q r

k

q r w
g x yi


p yi x ui
ui j



considering final term equation separately

p yi x ui
ui j

e ui x

ui j z




z

x

e uk x

k

eu x
e ui x ui j z
u x
e
z
z








e ui x

ui x

e
log
z
ui j
z
ui x

e

xj
log z
z
ui j
ui x

e
z
xj
z
z ui j


ui x
e
x uk x
xj
e
z
z ui j
k
ui x

e


uk
x
xj xj e
z
z
ui x

e
e ui x
xj

z
z






fibranavan silver barzilay

therefore equation
ui j


p yi x ui
ui j
ui x


e
e ui x
q r w
g x yi
xj
z
z
q r xj w
g x yi p yi x ui p yi x ui
q r w
g x yi

q r xj q p yi x ui
q w
g x yi p yi x ui

resulting online updates sentence relevance predicate labeling parameters
u v
ui ui u q r q x p yi
vi vi v q r q x p zi



filearning win reading manuals monte carlo framework

appendix b example sentence relevance predictions
shown portion strategy guide civilization ii sentences
identified relevant text aware model highlighted green

choosing location
building city carefully plan place citizens
work terrain surrounding city square x shaped pattern see
city radius diagram showing exact dimensions area called
city radius terrain square settlers standing
becomes city square natural resources available
population settles affect ability produce food goods cities built
near water sources irrigate increase crop yields cities
near mineral outcroppings mine raw materials hand
cities surrounded desert handicapped aridness
terrain cities encircled mountains arable cropland
premium addition economic potential within city radius
need consider proximity cities strategic value
location ideally want locate cities areas offer combination
benefits food population growth raw materials production
river coastal areas trade possible take advantage
presence special resources terrain squares see terrain movement
details benefits
strategic value
strategic value city site final consideration city square
underlying terrain increase defender strength city
comes attack circumstances defensive value
particular city terrain might important economic value
consider case continent narrows bottleneck rival
holds side good defensive terrain hills mountains jungle
generally poor food production inhibits early growth city
need compromise growth defense build city
plains grassland square river running possible
yields decent trade production gains percent defense bonus
regardless city built city square easier defend
unimproved terrain city build city walls
improvement triples defense factors military units stationed
units defending city square destroyed one time
lose outside cities units stacked together destroyed
military unit stack defeated units fortresses
exception see fortresses placing cities seacoast gives
access ocean launch ship units explore world
transport units overseas coastal cities sea power
inhibited



fibranavan silver barzilay

appendix c examples predicate labeling predictions
listed predicate labellings computed text aware method example
sentences game manual predicted labels indicated words
letters b action description state description background respectively
incorrect labels indicated red check mark along correct label brackets
road built use settlers start improving terrain
















settlers becomes active chose build road












use settlers engineers improve terrain square within city radius





















bronze working allows build phalanx units


b









order expand civilization need build cities







b

b



order protect city phalanx must remain inside

b

b









b

soon found decent site want settlers build

b

b



b

b





permanent settlement city





city build city walls improvement



b







city undefended move friendly army city capture


b











b

build city terrain square except ocean




b







launch ship units explore world transport units overseas








b

b



b

city disorder disband distant military units return home cities

















change home cities






build wonder discovered advance makes possible














filearning win reading manuals monte carlo framework

appendix examples learned text game attribute mappings
shown examples word game attribute associations learned
model top ten game attributes strongest association feature weight
listed three example words attack build grassland fourth
word settler seven attributes non zero weights experiments used collect
statistics

attack

build

phalanx unit

worker goto action

warriors unit

settler autosettle action

colossus wonder

worker autosettle action

city walls city improvement

pheasant terrain attribute

archers unit

settler irrigate action

catapult unit

worker mine action

palace city improvement

build city walls action

coinage city production

build catapult action

city build warriors action

swamp terrain attribute

city build phalanx action

grassland terrain attribute

grassland

settler

settler build city action

settlers state attribute

worker continue action action

settler build city action

pheasant terrain attribute

city state attribute

city build improvement action

grassland terrain attribute

city max production action

plains terrain attribute

settlers state attribute

road terrain attribute

city max food action

workers state attribute

settler goto action
worker build road action
pyramids city attribute



fibranavan silver barzilay

appendix e features used model
features used predict sentence relevance
following templates used compute features sentence relevance
word w present sentence
number words match text label current unit attribute
immediate neighborhood unit action consideration
units type u e g worker word w present sentence
action type e g irrigate word w present sentence
features used predict predicate structure
following templates used compute features predicate labeling words
label considered word e action state background denoted
l
label l word type w
label l part speech tag word
label l parent word dependency tree w
label l dependency type dependency parent word
label l part speech dependency parent word
label l word leaf node dependency tree
label l word leaf node dependency tree
label l word matches state attribute name
label l word matches unit type name
label l word matches action name
features used model action value function
following templates used compute features action value approximation
unless otherwise mentioned features look attributes player controlled
model
percentage world controlled
percentage world explored
players game score
opponents game score
number cities
average size cities
total size cities


filearning win reading manuals monte carlo framework

number units
number veteran units
wealth gold
excess food produced
excess shield produced
excess trade produced
excess science produced
excess gold produced
excess luxury produced
name technology currently researched
percentage completion current
percentage remaining current
number game turns current completed
following feature templates applied city controlled player
current size city
number turns city grows size
amount food stored city
amount shield stored city shields used construct buildings
units city
turns remaining current construction completed
surplus food production city
surplus shield production city
surplus trade production city
surplus science production city
surplus gold production city
surplus luxury production city
distance closest friendly city
average distance friendly cities
city governance type
type building unit currently construction
types buildings already constructed city
type terrain surrounding city
type resources available citys neighborhood


fibranavan silver barzilay

another city neighborhood
enemy unit neighborhood
enemy city neighborhood
following feature templates applied unit controlled player
type unit
moves left unit current game turn
current health unit
hit points unit
unit veteran
distance closest friendly city
average distance friendly cities
type terrain surrounding unit
type resources available units neighborhood
enemy unit neighborhood
enemy city neighborhood
following feature templates applied predicate labeled word sentence
selected relevant combined current state action attributes
word w present sentence action considered
word w predicate label p present sentence action considered

word w present sentence current units type u action
considered
word w predicate label p present sentence current units type u
action considered
word w present sentence current units type u
word w predicate label p present sentence current units type
u
word w present sentence attribute text label present
current units neighborhood
word w predicate label p present sentence attribute text label
present current units neighborhood



filearning win reading manuals monte carlo framework

references
balla r fern uct tactical assault real time strategy games
proceedings ijcai pp
barnard k forsyth learning semantics words pictures
proceedings iccv pp
barto g mahadevan recent advances hierarchical reinforcement
learning discrete event dynamic systems
billings castillo l p schaeffer j szafron probabilistic knowledge
simulation play poker proceedings aaai iaai pp
branavan chen h zettlemoyer l barzilay r reinforcement learning
mapping instructions actions proceedings acl pp
branavan silver barzilay r learning win reading manuals
monte carlo framework proceedings acl pp
branavan silver barzilay r b non linear monte carlo search civilization
ii proceedings ijcai pp
branavan zettlemoyer l barzilay r reading lines learning
map high level instructions commands proceedings acl pp
bridle j training stochastic model recognition networks lead
maximum mutual information estimation parameters advances nips pp

bryson e ho c applied optimal control optimization estimation
control blaisdell publishing company
chen l mooney r j learning sportscast test grounded language
acquisition proceedings icml pp
chen l mooney r j learning interpret natural language navigation
instructions observations proceedings aaai pp
clarke j goldwasser chang w roth driving semantic parsing
worlds response proceedings connl pp
de marneffe c maccartney b manning c generating typed dependency parses phrase structure parses proceedings lrec pp
eisenstein j clarke j goldwasser roth reading learn constructing
features semantic abstracts proceedings emnlp pp
fleischman roy intentional context situated natural language learning
proceedings conll pp
gelly wang munos r teytaud modification uct patterns
monte carlo go tech rep inria
goldwasser reichart r clarke j roth confidence driven unsupervised
semantic parsing proceedings acl pp



fibranavan silver barzilay

gorniak p roy speaking sidekick understanding situated speech
computer role playing games proceedings aiide pp
liang p jordan klein learning semantic correspondences less
supervision proceedings acl pp
liang p jordan klein learning dependency compositional
semantics proceedings acl pp
marcus p santorini b marcinkiewicz building large annotated
corpus english penn treebank computational linguistics
oates j grounding knowledge sensors unsupervised learning language
ph thesis university massachusetts amherst
roy k pentland p learning words sights sounds computational model cognitive science
rumelhart e hinton g e williams r j learning representations
back propagating errors nature
schafer j uct applied games imperfect information
diploma thesis otto von guericke universitat magdeburg
sheppard b world championship caliber scrabble artificial intelligence

silver sutton r muller sample learning search permanent transient memories proceedings icml pp
siskind j grounding lexical semantics verbs visual perception
force dynamics event logic journal artificial intelligence
sturtevant n analysis uct multi player games proceedings iccg
pp
sutton r barto g reinforcement learning introduction mit
press
sutton r koop silver role tracking stationary environments proceedings icml pp
tellex kollar dickerson walter r banerjee g teller roy n
understanding natural language commands robotic navigation mobile
manipulation proceedings aaai pp
tesauro g galperin g line policy improvement monte carlo search
advances nips pp
vogel jurafsky learning follow navigational directions proceedings
acl pp
yu c ballard h integration grounding language learning
objects proceedings aaai pp
zettlemoyer l collins learning context dependent mappings sentences
logical form proceedings acl pp




