journal artificial intelligence

submitted published

variational probabilistic inference
qmr dt network

tommi jaakkola

tommi ai mit edu

artificial intelligence laboratory
massachusetts institute technology
cambridge usa

michael jordan

computer science division department statistics
university california
berkeley ca usa

jordan cs berkeley edu

abstract

describe variational approximation method ecient inference large scale
probabilistic variational methods deterministic procedures provide approximations marginal conditional probabilities interest provide alternatives approximate inference methods stochastic sampling search describe
variational diagnostic inference quick medical reference qmr network qmr network large scale probabilistic graphical model
built statistical expert knowledge exact probabilistic inference infeasible
model small set cases evaluate variational inference
large set diagnostic test cases comparing state art stochastic
sampling method

introduction
probabilistic become increasingly prevalent ai recent years beyond
significant representational advantages probability theory including guarantees
consistency naturalness combining diverse sources knowledge pearl
discovery general exact inference principally responsible
rapid growth probabilistic ai see e g lauritzen spiegelhalter pearl
shenoy exact inference methods greatly expand range
treated within probabilistic framework provide unifying perspective
general probabilistic computation graphical
probability theory viewed combinatorial calculus instructs us
merge probabilities sets events probabilities composites key operation marginalization involves summing integrating values
variables exact inference essentially ways perform sums
possible marginalization operations terms graphical representation
probability distributions random variables correspond nodes conditional
independencies expressed missing edges nodes exact inference
define notion locality example cliques appropriately defined graph
attempt restrict summation operators locally defined sets nodes
c ai access foundation morgan kaufmann publishers rights reserved

fijaakkola jordan

manages stave exponential explosion exact probabilistic
computation exponential explosion inevitable calculus explicitly
performs summations sets nodes interest
local overly large see jordan et al press point view perhaps
surprising exact inference np hard cooper
discuss inference particular large scale graphical
model quick medical reference qmr model qmr model consists combination statistical expert knowledge approximately significant diseases
approximately findings probabilistic formulation model qmr dt
diseases findings arranged bi partite graph diagnosis
infer probability distribution diseases given subset findings given
finding generally relevant wide variety diseases graph underlying
qmr dt dense ecting high order stochastic dependencies computational complexity treating dependencies exactly characterized terms size
maximal clique moralized graph see e g dechter lauritzen spiegelhalter particular running time exponential measure size
qmr dt considering standardized clinocopathologic conference cpc cases
discuss median size maximal clique moralized graph
nodes rules use general exact qmr dt
general take advantage particular parametric form
probability distributions nodes graph conceivable additional
factorizations might found take advantage particular choice made
qmr dt factorization fact found heckerman quickscore
provides exact inference tailored qmr dt unfortunately however run time still exponential number positive
findings cpc cases estimate would require average
years solve inference current computers
faced apparent infeasibility exact inference large scale
qmr dt many researchers investigated approximation methods one general
developing approximate perform exact inference
partially one consider partial sets node instantiations partial sets hypotheses
partial sets nodes point view led development
approximate inference heuristic search another developing approximation exploit averaging phenomena dense graphs particular laws
large numbers tell us sums random variables behave simply converging
predictable numerical thus may need perform sums explicitly
exactly partially point view leads variational approximate
inference finally yet another approximate inference stochastic
sampling one sample simplified distributions obtain information
complex distribution interest discuss methods turn
horvitz suermondt cooper developed partial evaluation
known bounded conditioning works considering partial sets node instan acronym qmr dt use refers decision theoretic reformulation
qmr shwe et al shwe et al replaced heuristic representation employed
original qmr model miller fasarie myers probabilistic representation



fivariational probabilistic inference qmr dt

tiations notion cutset subset nodes whose
removal renders remaining graph singly connected ecient exact exist
singly connected graphs pearl summing instantiations cutset one
calculate posterior probabilities general graphs ecient
subroutine unfortunately however exponentially many cutset instantiations bounded conditioning aims forestalling exponential growth
considering partial sets instantiations although promise graphs
nearly singly connected seems unlikely provide solution dense graphs
qmr dt particular median cutset size qmr dt across
cpc cases yielding unmanageably large number cutset instantiations
another approximate inference provided search methods
consider node instantiations across entire graph cooper henrion
peng reggia general hope methods relatively small fraction
exponentially many node instantiations contains majority probability mass
exploring high probability instantiations bounding unexplored
probability mass one obtain reasonable bounds posterior probabilities qmrdt search space huge containing approximately disease hypotheses however
one considers cases small number diseases hypotheses involving
small number diseases contain high probability posteriors may
possible search significant fraction relevant portions hypothesis space
henrion fact able run search qmr dt inference
set cases characterized small number diseases cases
however exact quickscore ecient general corpus
cpc cases discuss current characterized small number
diseases per case general even impose assumption patients limited
number n diseases cannot assume priori model sharp cutoff
posterior probability disease n finally high dimensional search
often necessary allow paths limited target hypothesis subspace
particular one would able arrive hypothesis containing diseases
pruning hypotheses containing additional diseases peng reggia imposing
limitation lead failure search
recent partial evaluation methods include localized partial evaluation method
draper hanks incremental spi ambrosio
probabilistic partial evaluation method poole mini buckets
dechter former considers partial sets nodes latter three
consider partial evaluations sums emerge exact inference run
promising methods partial evaluation methods yet clear
restrict exponential growth complexity ways yield realistic accuracy time
tradeoffs large scale qmr dt
variational methods provide alternative approximate inference
similar spirit partial evaluation methods particular incremental spi
mini buckets aim avoid performing sums exponentially
ambrosio reports mixed incremental spi qmr dt somewhat
dicult set cases heckerman henrion still restricted number
positive findings



fijaakkola jordan

many summands come different point view
variational point view sum avoided contains sucient number terms
law large numbers invoked variational inference
replaces quantities expected beneficiary averaging process
surrogates known variational parameters inference manipulates
parameters directly order good approximation marginal probability
interest qmr dt model turns particularly appealing architecture
development variational methods variational methods simple
graphical interpretation case qmr dt
final class methods performing approximate inference stochastic sampling methods stochastic sampling large family including techniques rejection
sampling importance sampling markov chain monte carlo methods mackay
many methods applied approximate probabilistic inference graphical analytic available dagum horvitz
particular shwe cooper proposed stochastic sampling method known
likelihood weighted sampling qmr dt model promising date inference qmr dt able produce reasonably
accurate approximations reasonable time two dicult cpc cases consider
shwe cooper later particular compare
empirically variational across entire corpus cpc cases
although important compare approximation methods emphasized
outset think goal identify single champion
approximate inference technique rather different methods exploit different structural
features large scale probability expect optimal solutions involve
combination methods return point discussion section
consider promising hybrids approximate exact inference
general approximate inference np hard dagum luby
provides additional reason doubt existence single champion approximate
inference technique think important stress however hardness
together cooper hardness exact inference cited
taken suggest exact inference approximate inference equally hard
take example related field exist large domains solid uid mechanics
exact solutions infeasible approximate techniques finite element
methods work well similarly statistical physics exactly solvable
exist approximate methods mean field methods renormalization group methods
work well many cases feel goal probabilistic inference
similarly identifying effective approximate techniques work well
large classes

qmr dt network
qmr dt network shwe et al two level bi partite graphical model see
figure top level graph contains nodes diseases bottom level
contains nodes findings


fivariational probabilistic inference qmr dt

number conditional independence assumptions ected bi partite
graphical structure particular diseases assumed marginally independent
e independent absence findings note diseases assumed
mutually exclusive patient multiple diseases given states
disease nodes findings assumed conditionally independent
discussion regarding medical validity diagnostic consequences
assumptions embedded qmr dt belief network see shwe et al
diseases



f

dn

fm
findings

figure qmr belief network two level graph dependencies
diseases associated findings modeled via noisy gates
state precisely probability model implied qmr dt model write
joint probability diseases findings

p f p f jd p










p jd p dj

j



f binary vectors referring presence absence states diseases
positive negative states outcomes findings respectively conditional
probabilities p jd represented noisy model pearl

p jd p jl p jdj

qi





j

qij dj

j
p

j ij dj
e





set diseases parents finding qmr graph qij
p jdj probability disease j present could alone cause
finding positive outcome qi p jl leak probability e
probability finding caused means diseases included
qmr model final line reparameterize noisy probability model
exponentiated notation notation model parameters given
ij log qij


fijaakkola jordan

inference
carrying diagnostic inference qmr model involves computing posterior
marginal probabilities diseases given set observed positive negative
findings note set observed findings considerably smaller set
possible findings note moreover bi partite structure qmr dt graph
unobserved findings effect posterior probabilities diseases
brevity adopt notation corresponds event refers
positive negative findings respectively thus posterior probabilities
interest p dj jf f f f vectors positive negative findings
negative findings f benign respect inference
incorporated posterior probability linear time number associated diseases
number negative findings discuss seen
fact probability negative finding eq exponential expression
linear dj positive findings hand problematic
worst case exact calculation posterior probabilities exponentially costly
number positive findings heckerman ambrosio moreover practical
diagnostic situations number positive findings often exceeds feasible limit
exact calculations
let us consider inference calculations detail posterior probability
p djf f first absorb evidence negative findings e compute p djf
p f jd p normalization since p f jd p factorize
diseases see eq eq posterior p djf must factorize well
normalization p f jd p therefore reduces independent normalizations
disease carried time linear number diseases negative
findings remainder concentrate solely positive findings
pose real computational challenge unless otherwise stated assume
prior distribution diseases already contains evidence negative findings
words presume updates p dj p dj jf already made
turn question computing p dj jf posterior marginal probability
positive findings formally obtaining posterior involves marginalizing
p f jd p across remaining diseases

p dj jf

x

dndj

p f jd p



summation possible configurations disease variables
dj use shorthand summation index n dj qmr model
p f jd p form

p f jd p












p jd p dj

j




e j ij dj p dj







p

j





fivariational probabilistic inference qmr dt

follows eq fact p jd p f jd perform
summation eq diseases would multiply terms efg
corresponding conditional probabilities positive finding number
terms exponential number positive findings exist
attempt exploit factorizations expression particular pattern
observed evidence cf heckerman ambrosio limited
roughly positive findings current computers seems unlikely sucient
latent factorization qmr dt model able handle full cpc corpus
median number positive findings per case maximum number positive
findings

variational methods
exact inference perform many millions arithmetic operations applied
complex graphical qmr dt proliferation terms expresses
symbolic structure model necessarily express numeric structure
model particular many sums qmr dt inference sums
large numbers random variables laws large numbers suggest sums
may yield predictable numerical ensemble summands fact
might enable us avoid performing sums explicitly
exploit possibility numerical regularity dense graphical develop
variational approximate probabilistic inference variational methods
general class approximation techniques wide application throughout applied mathematics variational methods particularly useful applied highly coupled systems introducing additional parameters known variational parameters
essentially serve low dimensional surrogates high dimensional couplings
system methods achieve decoupling system mathematical machinery
variational provides finding values variational parameters decoupled system good approximation original coupled
system
case probabilistic graphical variational methods allow us simplify
complicated joint distribution one eq achieved via parameterized transformations individual node probabilities see later node
transformations interpreted graphically delinking nodes graph
appropriate transformations variational methods consider
come convex analysis see appendix let us begin considering methods
obtaining upper bounds probabilities well known fact convex analysis
concave function represented solution minimization

f x min
f x f g




f conjugate function f x function f obtained
solution minimization

f min
x f x f x g





fijaakkola jordan

formal identity pair minimization expresses duality f
conjugate f
representation f eq known variational transformation parameter known variational parameter relax minimization fix
variational parameter arbitrary value obtain upper bound

f x x f



bound better values variational parameter others
particular value bound exact
want obtain lower bounds conditional probabilities straightforward
way obtain lower bounds appeal conjugate duality express functions terms maximization principle representation however applies convex
functions current require lower bounds concave functions concave functions however special form allows us exploit conjugatepduality
different way particular require bounds functions form f j zj
f concave function zj f ng non negative variables
constant variables zj expression effectively coupled impact
changing one variable contingent settings remaining variables use
jensen inequality however obtain lower bound variables decoupled
particular

f

x

j

qj zqj
j
j
x

qj f zqj
j
j

zj f

x




qj viewed defining probability distribution variables zj
variational parameter case thep probability distribution q optimal setting
parameter given qj zj k zk easily verified substitution
eq demonstrates lower bound tight

variational upper lower bounds noisy

let us return computing posterior probabilities qmr
model recall conditional probabilities corresponding positive findings
need simplified end write
p

p jd e

j ij dj

e log e x



p

x j ij dj consider exponent f x log e x noisy
well many conditional involving compact representations e g logistic
regression exponent f x concave function x discussion
p

p

jensen inequality states f j qj xj j qj f xj concave
f
p
qj simple consequence eq x taken j qj xj



p

qj



fivariational probabilistic inference qmr dt

previous section know must exist variational upper bound function
linear x

f x x f



eq evaluate conjugate function f noisy obtain

f log log



desired
bound obtained substituting eq recalling definition
x pj ij dj

p jd






p

e f pj ij dj

e j ij dj f
p jd





note variational evidence p jd exponential term linear
disease vector negative findings implies variational
evidence incorporated posterior time linear number diseases
associated finding
graphical way understand effect transformation rewrite
variational evidence follows
p



p jd e j ij dj f
id
yh
e f e iij j
j




note first term constant note moreover product factorized
across diseases latter factors multiplied pre existing
prior corresponding disease possibly modulated factors negative
evidence constant term viewed associated delinked finding node
indeed effect variational transformation delink finding node
graph altering priors disease nodes connected finding node
graphical perspective important presentation variational
able view variational transformations simplifying graph point
exact methods run
turn
lower bounds conditional probabilities p jd expop
nent f j ij dj exponential representation form applied
jensen inequality previous section indeed since f concave need identify
non negative variables zj case ij dj constant
applying bound eq

p jd



p

e f j ij dj

e

ij dj
j qjji f io qjji

p








fijaakkola jordan

e
e

h

p





ij
j qjji dj f io qjji dj f io




ij
j qjji dj f io qjji f io f io

p

h






allowed different variational distribution qji finding note
bound linear exponent case upper bound
implies variational evidence incorporated posterior distribution
time linear number diseases moreover view variational
transformation terms delinking finding node graph

p jd qji

approximate inference qmr

previous section described variational transformations derived individual findings qmr model discuss utilize transformations
context overall inference
conceptually overall straightforward transformation involves
replacing exact conditional probability finding lower bound upper
bound
p jd qji p jd p jd

given transformations viewed delinking ith finding node
graph see transformations yield bounds yield simplified graphical structure imagine introducing transformations sequentially
graph sparse enough exact methods become feasible point stop
introducing transformations run exact
however need decide step
node transform requires assessment effect overall accuracy
transforming node might imagine calculating change probability interest
given transformation choosing transform node
yields least change target probability unfortunately unable calculate
probabilities original untransformed graph thus unable assess effect
transforming one node unable get started
suppose instead work backwards introduce transformations
findings reducing graph entirely decoupled set nodes optimize
variational parameters fully transformed graph optimization
variational parameters graph inference trivial moreover easy
calculate effect reinstating single exact conditional one node choose
reinstate node yields change
consider particular case upper bounds lower bounds analogous
transformation introduces upper bound conditional probability p jd thus
likelihood observing positive findings p f upper bounded variational
counterpart p f j
x
x
p f p f jd p p f jd p p f j







fivariational probabilistic inference qmr dt

assess accuracy variational transformation introducing optimizing variational transformations positive findings separately
positive finding replace variationally transformed conditional probability p jd
corresponding exact conditional p jd compute difference
resulting bounds likelihood observations

p f j p f j n



p f j n computed without transforming ith positive finding larger
difference worse ith variational transformation therefore
introduce transformations ascending order put another way
treat exactly transform conditional probabilities whose measure large
practice intelligent method ordering transformations critical figure
compares calculation likelihoods measure opposed method
chooses ordering transformations random plot corresponds representative diagnostic case shows upper bounds log likelihoods observed
findings function number conditional probabilities left intact e
transformed note upper bound must improve decrease fewer transformations striking choice ordering large effect accuracy
note plot log scale


loglikelihood















exactly treated findings



figure upper bound log likelihood delta method removing transformations solid line method bases choice random ordering
dashed line
note curve proposed ranking convex thus bound improves
less fewer transformations left first remove worst
transformations replacing exact conditionals remaining transformations better indicated delta measure thus bound improves less
replacements
make claims optimality delta method simply useful heuristic
allows us choose ordering variational transformations computationally
ecient way note implementation method optimizes variational
parameters outset chooses ordering transformations
fixed parameters parameters suboptimal graphs


fijaakkola jordan

substantial numbers nodes reinstated found practice
simplified still produces reasonable orderings
decided nodes reinstate approximate inference
run introduce transformations nodes left transformed
ordering product exact conditional probabilities graph
transformed conditional probabilities yields upper lower bound overall
joint probability associated graph product bounds bound sums
bounds still bounds thus likelihood marginal probability findings
bounded summing across bounds joint probability particular upper
bound likelihood obtained via
x
x
p f p f jd p p f jd p p f j









dndj

dndj

corresponding lower bound likelihood obtained similarly
x
x
p f p f jd p p f jd q p p f jq



cases assume graph suciently simplified variational
transformations sums performed eciently
expressions eq eq yield upper lower bounds arbitrary
values variational parameters q wish obtain tightest possible bounds
thus optimize expressions respect q minimize respect
maximize respect q appendix discusses optimization
detail turns upper bound convex thus adjustment
variational parameters upper bound reduces convex optimization
carried eciently reliably local minima lower bound
turns maximization carried via em
finally although bounds likelihood useful ultimate goal approximate
marginal posterior probabilities p dj jf two basic approaches utilizing
variational bounds eq eq purpose first method
emphasis current involves transformed probability model
model upper lower bounds computationally ecient surrogate
original probability model tune variational parameters transformed
model requiring model give tightest possible bound likelihood
use tuned transformed model inference engine provide approximations
probabilities interest particular marginal posterior probabilities p dj jf
approximations found manner bounds computationally ecient
approximations provide empirical data following section
indeed yields good approximations marginal posteriors qmr dt
network
ambitious goal obtain interval bounds marginal posterior probabilities end let p f dj j denote combined event qmr dt
model generates observed findings f j th disease takes value dj
bounds follow directly
x
x
p f dj p f jd p p f jd p p f dj j



fivariational probabilistic inference qmr dt

p f jd product upper bound transformed conditional probabilities
exact untransformed conditionals analogously compute lower bound p f dj jq
applying lower bound transformations

p f dj

x

dndj

p f jd p

x

dndj

p f jd q p p f dj jq



combining bounds obtain interval bounds posterior marginal probabilities diseases cf draper hanks

p f dj j
p f dj jq


p


j
f
j
p f dj j p f dj jq
p f dj j p f dj jq
dj binary complement dj



experimental evaluation

diagnostic cases used evaluating performance variational techniques cases abstracted clinocopathologic conference cpc cases cases
generally involve multiple diseases considered clinically dicult cases
cases middleton et al importance sampling method
work satisfactorily
evaluation variational methodology consists three parts first part
exploit fact subset cpc cases cases
suciently small number positive findings calculate exact values
posterior marginals quickscore four cases
able obtain gold standard comparison provide assessment accuracy
eciency variational methods four cpc cases present variational
upper lower bounds likelihood well scatterplots compare variational
approximations posterior marginals exact values present comparisons
likelihood weighted sampler shwe cooper
second section present remaining intractable cpc cases
use lengthy runs shwe cooper sampling provide surrogate
gold standard cases
finally third section consider obtaining interval bounds
posterior marginals

comparison exact marginals

four cpc cases fewer positive findings see table cases
possible calculate exact values likelihood posterior marginals
reasonable amount time used heckerman quickscore heckerman tailored qmr dt architecture perform exact
calculations
figure shows log likelihood four tractable cpc cases figure shows
variational lower upper bounds calculated variational bounds twice
differing numbers positive findings treated exactly two cases treated exactly


fijaakkola jordan

case pos findings neg findings























loglikelihood

loglikelihood

table description cases evaluated exact posterior marginals




















sorted cases



b









sorted cases





figure exact values variational upper lower bounds log likelihood
log p f j four tractable cpc cases positive findings
treated exactly b positive findings treated exactly
simply means finding transformed variationally panel
positive findings treated exactly b positive findings treated exactly
expected bounds tighter positive findings treated exactly
average running time across four tractable cpc cases seconds
exact method seconds variational method positive findings treated
exactly seconds variational method positive findings treated exactly
obtained mhz dec alpha computer
although likelihood important quantity approximate particularly applications parameters need estimated interest qmr dt setting
posterior marginal probabilities individual diseases discussed
previous section simplest obtaining variational estimates quantities define approximate variational distribution distribution
p f j upper bounds likelihood distribution p f jq lowerbounds likelihood fixed values variational parameters chosen provide
tight bound likelihood distributions provide partially factorized approximations joint probability distribution factorized forms exploited
given significant fraction positive findings treated exactly simulations one
may wonder additional accuracy due variational transformations address
concern later section demonstrate variational transformations fact responsible
significant portion accuracy cases



fivariational probabilistic inference qmr dt








variational estimates

variational estimates

ecient approximate inference engines general posterior probabilities particular
use provide approximations posterior marginals individual diseases
practice found distribution p f j yielded accurate posterior
marginals distribution p f jq restrict presentation p f j figure displays scatterplot approximate posterior marginals panel corre






















exact marginals



b










exact marginals





figure scatterplot variational posterior estimates exact marginals
positive findings treated exactly b positive findings
treated exactly
sponding case positive findings treated exactly panel b case
positive findings treated exactly plots obtained first extracting
highest posterior marginals case exact methods computing
approximate posterior marginals corresponding diseases approximate
marginals fact correct points figures align along diagonals
shown dotted lines see reasonably good correspondence variational
appears provide good approximation largest posterior marginals
quantify correspondence ranking measure later section
current state art qmr dt enhanced version likelihoodweighted sampling proposed shwe cooper likelihood weighted sampling
stochastic sampling method proposed fung chang shachter peot
likelihood weighted sampling basically simple forward sampling method
weights samples likelihoods enhanced improved utilizing selfimportance sampling see shachter peot version importance sampling
importance sampling distribution continually updated ect current
estimated posterior distribution middleton et al utilized likelihood weighted sampling self importance sampling well heuristic initialization scheme known
iterative tabular bayes qmr dt model found work satisfactorily subsequent work shwe cooper however used additional
enhancement known markov blanket scoring see shachter peot
distributes fractions samples positive negative values node
proportion probability values conditioned markov blanket
node combination markov blanket scoring self importance sampling yielded


fijaakkola jordan

effective particular modifications place shwe cooper
reported reasonable accuracy two dicult cpc cases
implemented likelihood weighted sampling shwe cooper
incorporating markov blanket scoring heuristic self importance sampling
utilize iterative tabular bayes instead utilized related initialization scheme
heuristic tabular bayes discussed shwe cooper section discuss
running four tractable cpc cases comparing
variational inference following section present fuller comparative
analysis two cpc cases
likelihood weighting sampling indeed sampling realizes timeaccuracy tradeoff taking additional samples requires time improves accuracy
comparing sampling variational ran sampling
several different total time periods accuracy achieved
sampling roughly covered range achieved variational
shown figure right hand curve corresponding sampling runs
figure displays mean correlations approximate exact posterior
marginals across ten independent runs four tractable cpc cases


mean correlation
















execution time seconds





figure mean correlation approximate exact posterior marginals
function execution time seconds solid line variational estimates
dashed line likelihood weighting sampling lines sampling represent standard errors mean ten independent
runs sampler
variational characterized time accuracy tradeoff particular
accuracy method generally improves findings treated exactly
cost additional computation figure shows variational
left hand curve three points curve correspond
initialization method proved little effect inference
investigated gibbs sampling pearl gibbs sampling good
likelihood weighted sampling report latter remainder




fivariational probabilistic inference qmr dt

positive findings treated exactly note variational estimates deterministic
thus single run made
figure shows achieve roughly equivalent levels accuracy sampling
requires significantly computation time variational method
although scatterplots correlation measures provide rough indication accuracy approximation deficient several respects particular
diagnostic practice interest ability rank diseases correctly
avoid false positives diseases fact significant included
set highly ranked diseases false negatives significant diseases omitted set highly ranked diseases defined ranking measure follows see
middleton et al consider set n highest ranking disease hypotheses
ranking correct posterior marginals corresponding set
diseases smallest set n approximately ranked diseases includes
n significant ones words n true positives approximate method
produces n n false positives plotting false positives function true positives
provides meaningful useful measure accuracy approximation scheme
extent method provides nearly correct ranking true positives plot
increases slowly area curve small significant disease appears
late approximate ordering plot increases rapidly near true rank missed
disease area curve large
plot number false negatives set top n highly ranked diseases
false negatives refer number diseases n highest ranking diseases
appear set n approximately ranked diseases note unlike
previous measure measure reveal severity misplacements
frequency
improved diagnostic measure hand let us return evaluation
inference beginning variational figure provides plots








false negatives

false positives























true positives



b










approximate ranking





figure average number false positives function true positives variational method solid lines partially exact method dashed line b false
negatives set top n approximately ranked diseases figures
positive findings treated exactly
false positives panel false negatives panel b true positives


fijaakkola jordan












false negatives

false positives

























true positives



b










approximate ranking





figure average number false positives function true positives variational method solid line partially exact method dashed line b false
negatives set top n approximately ranked diseases figures
positive findings treated exactly
tractable cpc cases eight positive findings treated exactly simulation shown
figure figure displays positive finding treated exactly
noted earlier positive findings comprise significant fraction
total positive findings tractable cpc cases thus important verify
variational transformations fact contributing accuracy posterior
approximations beyond exact calculations comparing
variational method method call partially exact method
posterior probabilities obtained findings treated exactly
variational calculations e findings transformed
variational transformations contribute accuracy approximation
performance partially exact method comparable
variational method figure figure clearly indicate case
difference accuracy methods substantial computational load
comparable seconds mhz dec alpha
believe accuracy portrayed false positive plots provides good indication potential variational providing practical solution
approximate inference qmr dt figures number
false positives grows slowly number true positives example shown
figure eight positive findings treated exactly likely diseases
would need entertain top diseases list approximately ranked
diseases compared partially exact method
ranking plot likelihood weighted sampler shown figure
curve variational method figure included comparison make
plots ran likelihood weighted sampler amount time seconds
noted conservative comparison partially exact method fact
benefits variational transformation set exactly treated positive findings selected
basis accuracy variational transformations accuracies correlate
diagnostic relevance findings



fivariational probabilistic inference qmr dt




false positives














true positives





figure average number false positives function true positives likelihoodweighted sampler dashed line variational method solid line
positive findings treated exactly
comparable time allocated slowest variational method seconds
case positive findings treated exactly recall time required
variational positive findings treated exactly seconds
plots tractable cpc cases variational method significantly
accurate sampling comparable computational loads

full cpc corpus

consider full cpc corpus majority cases cases
positive findings thus appear beyond reach exact methods
important attraction sampling methods mathematical guarantee accurate
estimates limit suciently large sample size gelfand smith thus
sampling methods promise providing general methodology approximate
inference two caveats number samples needed dicult
diagnosis many samples may required obtain accurate estimates
real time applications latter issue rule sampling solutions however long term
runs sampler still provide useful baseline evaluation accuracy faster
approximation begin considering latter possibility context
likelihood weighted sampling qmr dt turn comparative evaluation
likelihood weighted sampling variational methods time limited setting
explore viability likelihood weighted sampler providing surrogate
gold standard carried two independent runs consisting samples
figure shows estimates log likelihood first sampling run
cpc cases variational upper lower bounds cases
cases sorted according lower bound note bounds
rigorous bounds true log likelihood thus provide direct indication
accuracy sampling estimates although see many estimates lie
bounds see many cases sampling estimates deviate substantially
bounds suggests posterior marginal estimates obtained
samples likely unreliable well indeed figure b presents scatterplot


fijaakkola jordan






sampling estimates

loglikelihood

























sorted cases





b








sampling estimates





figure upper lower bounds solid lines corresponding sampling estimates dashed line log likelihood observed findings cpc cases
b correlation plot posterior marginal estimates two independent sampling runs
estimated posterior marginals two independent runs sampler although
see many cases lie diagonal indicating agreement
two runs see many pairs posterior estimates far diagonal
cast doubt viability likelihood weighted sampler
general approximator full set cpc cases even problematically appear
without reliable surrogate gold standard cases making dicult
evaluate accuracy real time approximations variational method note
however estimates figure seem fall two classes estimates
lie within variational bounds estimates rather far bounds
suggests possibility distribution sampled multi modal
estimates falling within correct mode providing good approximations
others falling spurious modes providing seriously inaccurate approximations
situation holds accurate surrogate gold standard might obtained
variational bounds filter sampling retaining estimates
lie bounds given variational
figure provides evidence viability
cpc cases independent runs sampler resulted estimates loglikelihood lying approximately within variational bounds recomputed posterior
marginal estimates selected cases plotted figure
scatterplot shows high degree correspondence posterior estimates
cases thus tentatively assume estimates accurate enough serve
surrogate gold standard proceed evaluate real time approximations
figure plots false positives true positives selected cpc
cases variational method twelve positive findings treated exactly
simulation obtaining variational estimates took seconds computer time per
case although curve increases rapidly tractable cpc cases
variational still appears provide reasonably accurate ranking posterior
marginals within reasonable time frame


fivariational probabilistic inference qmr dt



sampling estimates
















sampling estimates





figure correlation plot selected posterior marginal estimates two
independent sampling runs selection variational
upper lower bounds



false positives













true positives





figure average number false positives function true positives variational method solid line likelihood weighted sampler dashed line
variational method positive findings treated exactly
sampler averages across ten runs
compare variational time limited version likelihood weighted
sampler ran latter period time seconds per case roughly comparable running time variational seconds per case figure
shows corresponding plot false positives true positives averaged ten independent runs see curve increases significantly steeply
variational curve likely diseases variational method
would need entertain top diseases list approximately ranked
diseases sampling method would need entertain top approximately
ranked diseases

interval bounds marginal probabilities

thus far utilized variational produce approximations posterior marginals approximations discussed originate upper lower


fijaakkola jordan

bounds likelihood bounds guaranteed lie true posteriors see figure discussed
section however possible induce upper lower bounds posterior
marginals upper lower bounds likelihood cf eq section
evaluate interval bounds qmr dt posterior marginals
figure displays histogram interval bounds four tractable cpc cases
selected cpc cases previous section cpc cases histograms
include diseases qmr dt network case tractable cases























frequency



frequency



frequency













interval size





b












interval size





c












interval size

figure histograms size interval bounds diseases qmrdt network four tractable cpc cases b selected cpc cases
previous section c cpc cases
variational method run positive findings treated exactly remaining
cpc cases variational method run positive findings treated exactly
running time less seconds computer time per cpc case
tractable cpc cases interval bounds tight nearly diseases
network however positive findings treated variationally
cases need practice compute variational bounds cases
get somewhat better picture viability variational interval bounds
figure b figure c picture decidedly mixed selected
cases tight bounds provided approximately half diseases bounds
vacuous approximately quarter diseases range diseases
consider cpc cases approximately third bounds
tight nearly half vacuous
although may indicate limitations variational approximation
another immediate appears responsible looseness
bounds many cases particular recall use quickscore
heckerman handle exact calculations within framework variational
unfortunately quickscore suffers vanishing numerical precision large
numbers positive findings general begin run numerical
resulting vacuous bounds positive findings incorporated exactly
variational approximation thus although clearly interest run variational
longer durations thereby improve bounds unable
within current implementation exact subroutine




fivariational probabilistic inference qmr dt

clearly worth studying methods quickscore treating exact findings within variational interest consider combining
variational methods methods search partial evaluation
methods intervals methods may help simplifying posterior
obviating need improving exact calculations
worth emphasizing positive aspect potential
practical utility previous section showed variational method provide accurate approximations posterior marginals combined interval bounds
section calculated eciently user obtain guarantees approximately third approximations given relatively benign rate increase false
positives function true positives figure guarantees may suce finally
diseases bounds loose perturbation methods available
jaakkola help validate approximations diseases

discussion
let us summarize variational inference method evaluate
obtained
variational method begins parameterized upper lower bounds individual conditional probabilities nodes model qmr dt bounds
exponentials linear functions introducing model corresponds
delinking nodes graph sums products bounds yield bounds thus
readily obtain parameterized bounds marginal probabilities particular upper
lower bounds likelihood
exploited likelihood bounds evaluating output likelihood weighted
sampling although sampling yield reliable across
corpus cpc cases utilized variational upper lower bounds select
among samples able obtain sampling consistent
runs suggests general procedure variational bounds used assess
convergence sampling one imagine intimate relationship
variational bounds used adjust line
course sampler
fact bounds likelihood marginal probabilities
critical bounding property allows us optimizing values variational parameters minimizing upper bounding variational distribution maximizing
lower bounding variational distribution case qmr dt network bipartite noisy graph minimization convex optimization
maximization solved via em
variational parameters optimized resulting variational distribution
exploited inference engine calculating approximations posterior probabilities
technique focus graphically variationally transformed
model viewed sub graph original model finding
nodes delinked sucient number findings delinked variationally
possible run exact resulting graph yields
approximations posterior marginals disease nodes


fijaakkola jordan

found empirically approximations appeared provide good approximations true posterior marginals case tractable set cpc cases
cf figure subject assumption obtained good surrogate
gold standard via selected output sampler case full cpc
corpus cf figure
compared variational state art qmrdt likelihood weighted sampler shwe cooper found variational outperformed likelihood weighted sampler tractable cases
full corpus particular fixed accuracy requirement variational significantly faster cf figure fixed time allotment variational
significantly accurate cf figure figure
less satisfactory interval bounds posterior marginals
across full cpc corpus found approximately one third disease
bounds tight half diseases bounds vacuous major impediment
obtaining tighter bounds appears lie variational approximation per se
rather exact subroutine investigating exact methods improved
numerical properties
although focused detail qmr dt model worth
noting variational probabilistic inference methodology considerably general
specifically methods described limited bi partite
graphical structure qmr dt model necessary employ noisy nodes
jaakkola jordan case type transformations
exploited qmr dt setting extend larger class dependence relations
generalized linear jaakkola finally review applications
variational methods variety graphical model architectures see jordan et al

promising direction future appears integration
kinds approximate exact methods see e g dagum horvitz jensen kong
kjrulff particular search methods cooper peng reggia
henrion variational methods yield bounds probabilities
indicated introduction seem exploit different aspects structure complex probability distributions may possible combine bounds
variational bounds might used guide search searchbased bounds might used aid variational approximation similar comments
made respect localized partial evaluation methods bounded conditioning
methods draper hanks horvitz et al seen variational
bounds used assessing whether estimates monte carlo sampling
converged interesting hybrid would scheme variational approximations refined treating initial conditions sampler
even without extensions appear quite promising
presented runs real time large scale graphical model
exact general infeasible obtained appear
reasonably accurate across corpus dicult diagnostic cases work
needed believe indicate promising role variational inference
developing critiquing exploiting large scale probabilistic qmr dt


fivariational probabilistic inference qmr dt

acknowledgements
would thank university pittsburgh randy miller use
qmr dt database want thank david heckerman suggesting attack
qmr dt variational methods providing helpful counsel along way

appendix duality
upper lower bounds individual conditional probability distributions form
basis variational method dual conjugate representations
convex functions present brief description convex duality appendix
refer reader rockafellar extensive treatment
let f x real valued convex function defined convex set x example
x rn simplicity exposition assume f well behaved differentiable
function consider graph f e points x f x n dimensional space
fact function f convex translates convexity set f x f x g
called epigraph f denoted epi f figure elementary property
f x
epi f

x f

x f

x

figure half spaces containing convex set epi f conjugate function f
defines critical half spaces whose intersection epi f equivalently
defines tangent planes f x
convex sets represented intersection half spaces
contain see figure parameterizing half spaces obtain dual
representations convex functions end define half space condition
x xt



parameterize non vertical half spaces interested characterizing half spaces contain epigraph f require therefore points
epigraph must satisfy half space condition x epi f must
xt holds whenever xt f x points epigraph
property f x since condition must satisfied x x follows


fijaakkola jordan


max
f xt f x g
x x



well equivalently

max
f xt f x g
x x



right hand side equation defines function known
dual conjugate function f function convex function defines
critical half spaces needed representation epi f intersection
half spaces figure
clarify duality f x f x let us drop maximum rewrite
inequality

xt f x f



equation roles two functions interchangeable may suspect
f x obtained dual function f x optimization procedure
fact case

f x max
f xt f g




equality states dual dual gives back original function provides
computational tool calculating dual functions
concave convex functions analogous replace max
min lower bounds upper bounds

appendix b optimization variational parameters

variational method described involves replacing selected local conditional
probabilities upper bounding lower bounding variational transformations
product bounds bound variationally transformed joint probability
distribution bound upper lower true joint probability distribution moreover sums bounds bound sum obtain bounds marginal
probabilities marginalizing variationally transformed joint probability distribution
particular provides method obtaining bounds likelihood marginal
probability evidence
note variationally transformed distributions bounds arbitrary values
variational parameters individually transformed node conditional probability bound arbitrary values variational parameter obtain optimizing
values variational parameters take advantage fact transformed
distribution bound minimize case upper bounds maximize
case lower bounds transformed distribution respect variational
parameters optimization process provides tight bound marginal
probability interest e g likelihood thereby picks particular variational
distribution subsequently used approximate inference


fivariational probabilistic inference qmr dt

appendix discuss optimization must solve case
noisy networks consider upper lower bounds separately beginning
upper bound

upper bound transformations

goal ispto compute tight upper bound likelihood observed findings
p f p f jd p discussed section obtain upper bound
p f jd introducing upper bounds individual node conditional probabilities
represent upper bound p f jd product across individual variational transformations may contain contributions due findings treated
exactly e transformed marginalizing across obtain bound

p f

x



p f jd p p f j



latter quantity wish minimize respect variational parameters

simplify notation assume first positive findings transformed therefore need optimized remaining conditional probabilities
treated exactly notation p f j given

p f j






x









p jd
p jd p dj

j
im




e p jd
im




expectation taken respect posterior distribution diseases
given positive findings plan treat exactly note proportionality
constant depend variational parameters likelihood exactly
treated positive findings insert explicit forms transformed conditional
probabilities see eq eq

p f j




p f

e e j ij j

im
p

p

e im f e e j im ij dj




simply converted products sums exponent pulled
terms constants respect expectation log scale
proportionality becomes equivalence constant
p

x




ij
j


j


log p f j c f log e e
im





fijaakkola jordan

several observations order recall f conjugate concave function
f exponent therefore concave reason f convex
appendix c prove remaining term
p

log e e

j im iij dj





convex function variational parameters since sum convex
functions convex conclude log p f j convex function variational
parameters means local minima optimization
may safely employ standard newton raphson procedure solve r log p f j
alternatively utilize fixed point iterations particular calculate derivatives
variational form iteratively solve individual variational parameters k
derivatives zero derivatives given follows




log p f j log k e x
k
kj j

k
k
j



log p f j var x
j kj j
k
k k







expectation variance respect posterior approximation
p djf derivatives computed time linear number associated diseases finding benign scaling variance calculations comes
exploiting special properties noisy dependence marginal independence
diseases
calculating expectations eq exponentially costly number exactly
treated positive findings large number positive findings
recourse simplified procedure optimize variational parameters
transformed positive findings resulting variational parameters
suboptimal found practice incurred loss accuracy typically quite
small simulations reported optimized variational parameters
approximately half exactly treated findings introduced precise
case total findings treated exactly optimized parameters
findings respectively introduced

lower bound transformations

mimicking case upper bounds replace individual conditional probabilities
findings lower bounding transformations resulting lower bounding expression
p f jd q taking product p marginalizing yields lower bound
likelihood
x
p f p f jd q p p f jq



wish maximize p f jq respect variational parameters q obtain
tightest possible bound


fivariational probabilistic inference qmr dt

mapped onto standard optimization statistics
particular treating latent variable f observed variable q parameter
vector optimization p f jq logarithm viewed standard maximum
likelihood estimation latent variable model solved em
dempster laird rubin yields sequence variational
parameters monotonically increase objective function log p f jq within em
framework obtain update variational parameters maximizing expected
complete log likelihood




e log p f jd q p

x



n



e log p jd qji constant



q old denotes vector variational parameters update constant term independent variational parameters q expectation
respect posterior distribution p djf q old p f jd q old p since variational
parameters associated conditional probabilities p jd qji independent one
another maximize term sum separately recalling form
variational transformation see eq






e

qjji e fdjg f io qij f io
j ji
j
f io

maximize respect qj ji keeping expectations e fdj g fixed
n

log p jd qji



x

optimization solved iteratively monotonically performing
following synchronous updates normalization

qj ji







e fdj g qjji f io qij ij f io qij qjji f io
j ji
j ji





f denotes derivative f update guaranteed non negative
easily extended handle case positive
findings transformed feature conditional
probabilities products p f jd q old p f jd q left intact e
transformed optimization respect variational parameters corresponding
transformed conditionals proceeds

appendix c convexity

purpose appendix demonstrate function
p

log e e

j im iij dj





convex function variational parameters note first
ane transformap
tions change convexity properties thus convexity x j im ij dj implies


fijaakkola jordan

convexity variational parameters remains
n



log e e x log

x



pi e xi f x



convex function vector x fx xn gt indicated discrete
values range random variable x xi denoted probability measure
values pi taking gradient f respect xk gives

f x ppk e xk q
k
xk
pi e xi




hkl x x f x kl qk qk ql



x
x
x
z hz qk zk qk zk ql zl varfz g



qk defines probability distribution convexity revealed positive semidefinite hessian h whose components case
k

l

see h positive semi definite consider
k

k

l

varfz g variance discrete random variable z takes values zi
probability qi

references

ambrosio b incremental probabilistic inference proceedings ninth
conference uncertainty artificial intelligence san mateo ca morgan kaufmann
ambrosio b symbolic probabilistic inference large bn networks proceedings tenth conference uncertainty artificial intelligence san mateo
ca morgan kaufmann
cooper g nestor computer medical diagnostic aid integrates
causal probabilistic knowledge ph dissertation medical informatics sciences
stanford university stanford ca available umi
http wwwlib umi com dissertations main
cooper g computational complexity probabilistic inference bayesian
belief networks artificial intelligence
dagum p horvitz e reformulating inference selective
conditioning proceedings eighth annual conference uncertainty
artificial intelligence
dagum p horvitz e bayesian analysis simulation inference
belief networks networks


fivariational probabilistic inference qmr dt

dagum p luby approximate probabilistic reasoning bayesian belief
networks np hard artificial intelligence
dechter r mini buckets general scheme generating approximations automated reasoning proceedings fifteenth international joint conference
artificial intelligence
dechter r bucket elimination unifying framework probabilistic inference
jordan ed learning graphical cambridge mit press
dempster laird n rubin maximum likelihood incomplete data
via em journal royal statistical society b
draper hanks localized partial evaluation belief networks proceedings tenth annual conference uncertainty artificial intelligence
fung r chang k c weighting integrating evidence stochastic simulation bayesian networks proceedings fifth conference uncertainty
artificial intelligence amsterdam elsevier science
gelfand smith sampling approaches calculating marginal densities journal american statistical association
heckerman tractable inference diagnosing multiple diseases
proceedings fifth conference uncertainty artificial intelligence
henrion search methods bound diagnostic probabilities large
belief nets proceedings seventh conference uncertainty artificial intelligence
horvitz e suermondt h cooper g bounded conditioning flexible inference
decisions scarce resources proceedings fifth conference uncertainty artificial intelligence
jaakkola variational methods inference learning graphical
phd thesis department brain cognitive sciences massachusetts institute
technology
jaakkola jordan recursive approximating probabilities
graphical advances neural information processing systems cambridge mit press
jensen c kong kjrulff u blocking gibbs sampling large
probabilistic expert systems international journal human computer studies

jensen f introduction bayesian networks york springer


fijaakkola jordan

jordan ghaharamani z jaakkola saul l press introduction
variational methods graphical machine learning
lauritzen spiegelhalter local computations probabilities graphical structures application expert systems discussion journal
royal statistical society b
mackay j c introduction monte carlo methods jordan ed
learning graphical cambridge mit press
middleton b shwe heckerman henrion horvitz e lehmann h cooper
g probabilistic diagnosis reformulation internist qmr
knowledge base ii evaluation diagnostic performance section medical informatics technical report smi stanford university
miller r fasarie f e myers j quick medical reference qmr
diagnostic assistance medical computing
pearl j probabilistic reasoning intelligent systems san mateo ca morgan
kaufmann
peng reggia j probabilistic causal model diagnostic solving
part diagnostic strategy ieee trans systems man cybernetics special
issue diagnosis
poole probabilistic partial evaluation exploiting rule structure probabilistic
inference proceedings fifteenth international joint conference artificial
intelligence
rockafellar r convex analysis princeton university press
shachter r peot simulation approaches general probabilistic inference
belief networks proceedings fifth conference uncertainty artificial
intelligence elsevier science amsterdam
shenoy p p valuation systems bayesian decision analysis operations

shwe cooper g empirical analysis likelihood weighting simulation
large multiply connected medical belief network computers biomedical

shwe middleton b heckerman henrion horvitz e lehmann h g
cooper probabilistic diagnosis reformulation internist qmr knowledge base probabilistic model inference methods
information medicine




