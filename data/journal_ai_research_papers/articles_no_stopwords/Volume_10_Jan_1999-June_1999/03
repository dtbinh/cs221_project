journal artificial intelligence

submitted published

ecient heuristic hypothesis ranking
steve chien jpl nasa gov
andre stechert jpl nasa gov
darren mutz jpl nasa gov

steve chien
andre stechert
darren mutz
jet propulsion laboratory
california institute technology
oak grove drive
pasadena ca

abstract

considers learning ranking set stochastic alternatives upon incomplete information e limited number samples describe
system decision cycle outputs complete ordering hypotheses
decides gather additional information e observations cost ranking
generalization previously studied hypothesis selection selection must select single best hypothesis ranking
must order hypotheses
central address achieving desired ranking quality minimizing cost acquiring additional samples describe two hypothesis
ranking application probably approximately correct pac expected
loss el learning criteria empirical provided demonstrate effectiveness
ranking procedures synthetic real world datasets
introduction

many applications cost information quite high imposing requirement
learning glean much usable information possible minimum
data example



data may scarce making learning possible limited training data
key



speedup learning minimizing processing time critical reducing number
necessary training examples key since expense processing example
significant tadepalli



decision tree learning cost available training examples evaluating potential attributes partitioning computationally expensive musick
catlett russell



evaluating medical treatment policies acquiring additional training examples might
imply human subjects exposed experimental treatment longer
period necessary

one wishes sort guarantee quality solution statistical decision
theoretic framework useful framework answers questions much information

c ai access foundation morgan kaufmann publishers rights reserved

fichien stechert mutz
enough point adequate information rank alternatives
requested confidence
focuses parametric ranking general class statistical machine learning goal rank set alternative hypotheses
goodness hypothesis function set parameters whose values unknown
e g chien stechert mutz gratch greiner jurisica kaelbling
moore lee musick et al learning system determines refines estimates parameters training examples secondary goal
minimizing learning cost
principal contributions



define two families hypothesis ranking recursive selection
adjacency respectively provide specific details apply
probably approximately correct pac expected loss el decision criteria



provide empirical demonstrating effectiveness
achieving requested decision criteria synthetic data



provide empirical showing significantly outperform
existing statistical methods real world data spacecraft design optimization
image compression applications

remainder structured follows first describe hypothesis ranking formally including definitions probably approximately
correct pac expected loss el decision criteria define two
establishing criteria hypothesis ranking recursive hypothesis selection adjacent comparison next describe empirical tests
demonstrating effectiveness well documenting improved
performance standard statistical ranking literature finally
describe related work future extensions
hypothesis ranking

hypothesis ranking abstract class learning
given set hypotheses rank ranking desired orders hypotheses
expected utility determined hypothesis underlying probability
distribution expected utilities unknown must estimated
training data
hypothesis ranking extension hypothesis selection chien
gratch burl learning system attempts select best alternative
set hypotheses distinction hypothesis ranking hypothesis selection selection learning interested single best hypothesis
ranking learning must determine relative order hypotheses
hypothesis selection ranking important aspect many machine learning
example utility speedup learning viewed selection
described extend straightforward fashion hybrid rankingselection system must select rank top n hypotheses



fiefficient heuristic hypothesis ranking
single solving heuristic strategy chosen larger set
candidates case expected utility typically defined average time solve
gratch greiner jurisica minton attribute selection
machine learning viewed hypothesis selection
one must select best attribute split set possible attribute splits utility
often measured information gain musick et al reinforcement learning
system must learn appropriate action context utility interpreted
expected reward kaelbling
key observation regarding learning general could viewed optimization utility
function optimized application traditional non traditional
optimization methods yield good within guarantees provided depending features landscape optimized however
addition model sampling cost degree freedom added
cost samples high traditional optimization fare poorly
additionally many mentioned applications system chooses single
alternative never revisits decision many cases system
want investigate several prioritized options serially parallel hence
ranking useful motivation provided following scenarios



upper lower bounds span minimax search use metaknowledge

upper lower bounds node pruning parts tree
times knowing span expected utilities candidate set
useful e g checking convergence conditions adaptive
ga



augmenting external knowledge another area hypothesis ranking may



entire ranking cases entire ranking significant instance

important applications hypothesis selection human supervision
stochastic objective function e hypothesis represents part ranking used augment external knowledge
example engineering simulations usually capture physical properties candidate designs usually choose forego details manufacturing logistics
economics
evolutionary individuals propagated future generations
often selected likelihood proportionate rank current
generation goldberg another example arises case search
take advantage node ordering heuristics beam search iterative
broadening ginsberg harvey

hypothesis evaluation achieving correct ranking impossible
practice exact underlying probability distributions unknown thus
perhaps vanishingly small chance unlucky
note analogous reinforcement learning one learning appropriate action immediate feedback rather delayed feedback



fichien stechert mutz
finite number samples taken consequently rather
requiring output correct ranking impose probabilistic criteria
rankings produced several families requirements exist
examine two criteria probably approximately correct pac model selecting
hypothesis function approximates well target function valiant
expected loss el requirement frequently used decision theory gaming
russell wefald informally satisfy pac requirement must
produce high probability close correct e g incorrect orderings
likely occur hypotheses similar expected utilities satisfy
el requirement hand bound must established expected loss
loss difference utilities two incorrectly ordered hypothese
incorrect ranking
expected utility hypothesis estimated observing values
finite set training examples however satisfy decision criteria must
able reason potential difference estimated true utilities
hypotheses let ui denote true expected utility hypothesis let u
estimated expected utility hypothesis without loss generality let us presume
proposed ranking hypotheses u u uk uk
pac requirement states user specified probability
k

ui max ui uk





context pac criterion number called indifference interval

overall ranking error total error rate

issue allocate overall ranking error among many possible pairwise
comparisons hypotheses discussed next section
correspondingly selecting hypothesis h best set k hypotheses h hk let selection loss l follows
l h fh hk g max max u uk

u



ranking loss rl ranking h hk would
rl h hk

k
x

l hi fhi hk g





distinction betwen true means estimated means use sample means
confusing one assessing validity ranking produced one would use
true means distributions available test distributions accurate estimation
possible edxtremely large sampling distribution however ranking
uses estimated parameters including sample mean estimate error estimation single
mean estimate mean normally distributed around true mean usage
justified however proven indeed unsure whether estimate
complex ranking selection contexts guaranteed correct see later section heuristic nture




fiefficient heuristic hypothesis ranking
hypothesis ranking obeys expected loss requirement must produce
rankings average less ranking loss requested expected loss bound
policy loss allocation discussed next section
example consider ranking hypotheses expected utilities u u
u ranking u u u valid pac ranking indifference
interval observed ranking loss
however confidence pairwise comparison two hypotheses well
understood complement probability comparison
error less clear define ensure desired confidence met set
comparisons required selection even complex set comparisons required
ranking equation defines confidence ui uj utilities
normally distributed unknown unequal variances

pn



u

j


si



j

represents cumulative standard normal distribution function n u j
j size sample mean sample standard deviation blocked differential
distribution respectively
likewise computation expected loss asserting ordering pair
hypotheses well understood estimation expected loss entire ranking
less clear equation defines expected loss drawing conclusion ui uj
assumption normality see chien et al details
el ui uj



je

u j

j

n
si

p

n



u

p

j



z



u j pn
j

e

z

dz



next two subsections describe two interpretations estimating likelihood
overall ranking satisfies pac el requirements estimating combining
pairwise pac errors el estimates interpretations lends directly
algorithmic implementation described
ranking recursive selection

one obvious way determine ranking h hk view ranking recursive selection
set remaining candidate hypotheses view overall ranking error
specified desired confidence pac loss threshold el
first distributed among k selection errors subdivided
pairwise comparison errors figure data sampled estimates
pairwise comparison error dictated equation satisfy bounds set

note block match examples reduce sampling complexity blocking
makes estimates difference utility competing hypotheses observed example blocking significantly reduce variance data hypotheses independent
differential distribution formed taking differences blocked individual samples form
distribution trivial modify formulas address cases possible
block data see moore lee chien et al details



fichien stechert mutz

h

h

h

h

h

h

h

h

h

h

h

h

h

h




figure computing overall error recursive ranking per comparison errors
summed level recursion overall sum across levels
compared specified total error

thus another degree freedom design recursive ranking
method overall ranking error ultimately distributed among individual pairwise comparisons hypotheses two factors uence way compute
error distribution first model error combination determines error allocated
individual comparisons selections combines overall ranking error therefore
many candidates available distribution error
bonferroni inequality asserts probability union events
greater sum probabilities individual events one would inclined
combine errors additively however following conservative one
assert predicted best hypothesis may change sampling
worst case conclusion might dependon possible pairwise comparisons
error distributed among n pairs hypotheses
second policy respect allocation error among candidate comparisons
selections determines samples distributed example contexts
consequences early selections far outweigh later selections scenarios
implemented ranking divide overall ranking error unequally
note simplest bonferonni inequalities fall clean correspondence
terms expansion probability union events according principle
inclusion exclusion natural way
discussion issue see pp gratch



fiefficient heuristic hypothesis ranking
favor earlier selections possible divide selection error pairwise error
unequally estimates hypothesis parameters order reduce sampling cost
example gratch chien dejong allocates error rationally
within scope consider combine pairwise
error selection error additively ii combine selection error overall ranking error
additively iii allocate error equally level
one disadvantage recursive selection hypothesis selected
removed pool candidate hypotheses issue rare cases
sampling increase confidence later selection estimate hypothesis
mean changes enough previously selected hypothesis longer dominates
however remains original hypotheses shown dominate others
specified level certainty
assumptions following formulations u fu uk g
used denote error due action selecting hypothesis equation
set fh hk g u fu uk g denotes error due selection loss
situations equation applies
rec u u uk

rec u u uk
u fu uk g



rec uk base case recursion selection error defined
chien et al
u fu uk g

k
x







equation compute pairwise confidence

algorithmically implement following pseudo code

ensure n samples per hypothesis
distribute error individual selections
stopping criteria met
take samples
means ordered differently ranking
restart
analogous recursive selection expected loss defined follows
elrec u u uk

elrec u u uk
el u fu uk g



elrec uk selection el defined chien et al
el u fu uk g

k
x


space constraints preclude description



el u ui



fichien stechert mutz







h



h

k k

h

hk



hk

figure computing overall error adjacent ranking per comparison errors neighboring hypotheses proposed ranking summed compared
required total error

ranking adjacency comparison

another interpretation ranking confidence loss adjacent elements
ranking need compared case overall ranking error divided directly
k pairwise comparison errors figure leads following confidence equation
pac criteria
adj u u uk

k
x







following equation el criteria
eladj u u uk

k
x

el ui ui





ranking comparison adjacent hypotheses establish dominance
loss bounds non adjacent hypotheses hypotheses ordered
observed mean utility advantage requiring fewer comparisons recursive
selection thus may require fewer samples recursive selection however
reason adjacency may less likely recursive selection
bound probability correct ranking average loss correctly case
pac dominance necessarily transitive case
el expected loss necessarily additive considering two
hypothesis comparisons sharing common hypothesis
example ranking loss non adjacent hypotheses exceeds desired loss bound
ranking even though sum adjacent losses occurs blocked differential
distribution induced two non adjacent hypotheses high variance relative hypothesis adjacent



fiefficient heuristic hypothesis ranking
heuristic nature

recusrsive selection adjacency heuristic sense
proven statistically meet specified decision criteria e pac criteria
select ranking satisfies equation probability similarly el
criteria average ranking loss specified equation less requested bound
indeed several aspects make extremely dicult prove
would probabilistically achieve corresponding decision criteria aspects include



sharing samples order n samples differential distribution e



heuristic error combination recursive selection adjacency error com



ignorance lead switches multiple comparison paths sampling pro



blocking h h takes n samples h n samples
h reduce sampling cost reusing
samples differential distributions comparing h hypotheses h
hypotheses makes errors derived samples independent
hence traded accuracy ease analysis heuristic
eciency particularly recursive selection samples lowest
ranking hypothesis would used k differential comparisons
bination heuristic means combining pairwise errors
pairwise errors independent see empirically observed
pairwise errors tend overestimated error combination function
tends combine overall empirically combined error estimates tend
reasonably accurate remaining sections
cess ordering hypotheses may change e g ordering sample means
may change means implicitly decision depended additional
pairwise comparison may ected final set comparisons contributing pairwise error complexity could avoided fixing order
hypotheses n samples however would require samples would
involve showing dominance hypothesis higher sample mean hypothesis
indeed may never converge choose ignore complexity base
combined error used stopping condition final ordering

use non normal distributions many applications described

mainder article real world data distributed manner simlar
normal distributions investigate issue later article
describe heuristic presume data normally
distributed even though case

e currently ranked variance differential distribution makes
maximum contribution sample set small e g n
n exists configuration
expected losses el h h el h h el h h



fichien stechert mutz
relevant approaches

standard statistical ranking selection approaches make strong assumptions
form e g variances associated underlying utility distribution
hypotheses might assumed known equal among method turnbull
weiss turnbull weiss comparable pac
turnbull weiss sequential interval procedure selecting
member population largest mean treat hypotheses normally
distributed random variables unknown mean unknown possibly unequal
variance carries additional stipulation hypotheses
independent procedure consists taking initial sample n observations
hypotheses taking samples sequentially according stopping criteria
stopping criteria satisfied hypothesis highest sample mean

chosen stopping criteria inequality snii n satisfied si
ni sample mean number samples ith hypothesis n chosen

according indifference
interval confidence level particular n
r
chosen satisfy f k f dy f f cumulative
distribution function probability density function standard normal distribution
still reasonable use candidate hypotheses
independent excessive statistical error unnecessarily large training set sizes may
case hypotheses truly independent turnbull weiss technique
able exploit knowledge outperform methods adopt
assumption
empirical performance evaluation

turn empirical evaluation hypothesis ranking techniques synthetic
real world datasets evaluation serves three purposes first demonstrates
techniques perform predicted terms bounding probability incorrect selection expected loss second validates performance techniques compared
standard statistical literature third evaluation demonstrates
robustness approaches real world hypothesis ranking
experimental trial consists solving hypothesis ranking given
technique given set control parameters measure performance
well satisfy respective criteria number
samples taken alternatively cost seconds executing since
performance statistical single trial provides little information
overall behavior trial repeated multiple times averaged
across trials synthetic experimental trials repeated times trials
real world data repeated times pac expected loss criteria
directly comparable approaches analyzed separately
pac approaches investigated extensively statistical ranking selection literature topic confidence interval see haseeb review recent
literature



fiefficient heuristic hypothesis ranking
hk

h

h

h

h

k









utility

figure stepped means hypothesis configuration
evaluation synthetic datasets

evaluation synthetic data used techniques correctly bound probability incorrect ranking expected loss predicted underlying assumptions
valid even underlying utility distributions inherently hard rank
pac techniques compare favorably turnbull weiss
wide variety circumstances
synthetic datasets utility distributions hypotheses modeled
random variables defined underlying parameterized distribution thus characterizing ranking consists choosing number hypotheses rank
assigning values parameters representing utility distributions hypotheses case model utilities independent normal random variables
mean standard deviation thus let k number hypotheses hypothesis ranking described k parameters specifying expected utility
utility standard deviation hypothesis general several parameters may required characterize ranking fully number hypotheses
choices parameters utility distributions underlying hypotheses
characterize overall diculty ranking
statistical ranking selection community uses standard family selection
known diculty analyze performance hypothesis selection strategies
method called least favorable configuration lfc population means
assignment parameters distributions likely cause technique
choose wrong hypothesis thus provides severe test technique abilities
configuration utilities independent normally distributed variables equal
variance k hypotheses utilities equal expectation remaining
hypothesis expected utility
interested hypothesis ranking rather selection
use generalization lfc call stepped means configuration one
hypotheses assigned expected utility successive hypotheses assigned
expected utility k figure
general least favorable configuration become dicult
e require samples number hypotheses k increases common utility
variance increases difference means utility distributions decreases
standard methodology technique evaluated ability achieve confidence
configurations contain hypotheses high variance relative separation means
dicult rank
instance samples allocated rationally chien et al becomes necessary assign
parameters cost distribution well candidate hypotheses ranked
number hypotheses rank would another parameter



fichien stechert mutz
correct selection several settings k last ratio combines
single quantity increases makes dicult methodology
extends stepped means directly
hypothesis ranking strategies control parameters
govern attack pac techniques three control parameters
initial sample size n desired confidence correct ranking indifference setting
expected loss techniques two control parameters initial sample size n
loss threshold h
observed number samples required achieved accuracy pac techniques
stepped means configuration shown table indicate
systems roughly comparable number examples required choose hypotheses
expected number examples increases k p acadj
required least number samples inconsistent meeting desired accuracy
bound indicated failure meet prescribed error bound several cases
interesting turnbull weiss method significantly outperform pac
techniques despite fact assumes hypotheses independent
case stepped means configuration pac approaches make
assumption comparison principal performance metric number
samples required achieve requested ranking methods effective achieving
requested accuracy
expected loss experiments ran expected loss hypothesis ranking
stepped means configurations described range expected loss
bounds table shows experiment displaying number samples
required produce ranking average observed loss configuration
elrec correctly bounded loss eladj required less samples elrec correctly bound
expected loss since observed loss greater loss bound h
evaluation real datasets

test real world applicability data drawn several datasets relating
spacecraft design processing science data gathered context planetary
exploration first two datasets investigate relate spacecraft design optimization
hypotheses wish rank candidate solutions design
third last dataset examine involves ranking lossless image
compression approaches performance large set terrestrial images collected spacecraft galileo cost evaluation given seconds empirical data
note formulation stepped means test pac approaches difference
expected mean successive hypotheses indifference interval thus
plays roles parameter control parameter
one confusing point identical hypothesis ranking settings one observe
lower loss ranking larger number hypotheses first divides
loss number pirwise comparisons thus overall error expected loss bound
hypotheses pairwise expected error loss smaller hypotheses
ranking loss defined previously thus possible observed loss increase decrease
compared settings fewer hypotheses



fiefficient heuristic hypothesis ranking

k






























































turnbull



















p acrec




















p acadj




















table estimated expected total number observations pac
stepped means configuration achieved probability correct ranking shown
parenthesis

parameters
k h













elrec

samples













loss













eladj

samples













loss













table estimated expected total number observations el stepped
means configuration observed average loss produced rankings



fichien stechert mutz
unlike synthetic cost sampling hypothesis constant
domains table gives summary three ranking considered
dataset
ds penetrator

fixed parameters
penetrator diameter
penetrator length

ds aeroshell

fore body overlap
nose cone angle
bluntness ratio
fillet radius
outer diameter
tail geometry
compression method

lossless image comp

random variables
impact orientation
impact velocity
soil density
stagnation pressure coef

optimization criteria
maximize penetration probability
maximize penetration depth

randomly selected test image

maximize compression ratio

minimize weight
achieve target entry velocity

table description datasets used evaluation

ds penetrator

goal millennium deep space two ds mission deliver pair
microprobes planet mars scientific study martian soil probes
released orbit travel martian atmosphere embed
soil near southern polar ice cap primary science objectives mission
balacuit





determine ice present surface mars
measure local atmospheric pressure
characterize thermal properties martian subsurface soil

goal spacecraft design determine good set physical dimensions penetrator small robust probe designed impact surface extremely
high velocity operate extreme cold specifically use design simulation
data ds mission penetrator design
casting design hold shape penetrator constant
generate design candidates different values variables penetrator diameter
length specific design sample taken acquiring impact orientation impact
velocity soil density parameterized multivariate distribution calling
complex physical simulation determine depth penetrator bored
martian surface goal penetrator design determine physical
dimensions penetrator maximize probability penetration cases
penetration maximize penetration depth
tables applying pac turnbull expected loss
ranking system requested rank penetrator
designs utility function depth penetration penetrator
true expected utility values computed performing samples sample mean
large sample ground truth expected utilities used compute pac validity
rankings observed loss provided definitions



fiefficient heuristic hypothesis ranking
cases penetrator penetrate assigned zero utility
shown table pac significantly outperformed turnbull
expected hypotheses somewhat correlated via impact orientations soil densities table shows elrec expected loss effectively
bounded actual loss eladj inconsistent
k

















turnbull




p acrec





p acadj





table estimated expected total number observations rank ds spacecraft designs
achieved probability correct ranking shown parenthesis

parameters
k
h







elrec

samples




loss




eladj

samples




loss




table estimated expected total number observations expected loss incorrect
ranking ds penetrator designs

ds aeroshell design ranking

objective design aeroshell soil penetrator described
previous section gives appropriate entry velocity minimum weight design
candidates defined six continuous variables represent geometric quantities extent fore body overlaps aftbody nose cone angle bluntness
ratio fillet radius outer diameter tail geometry candidate designs hypotheses
evaluated running simple physical simulation aeroshell behavior
sample taken running simulation fixed design variables hypothesis
value stagnation pressure coecient taken normal distribution
simulation computes values achieved entry velocity mass aeroshell
weighted sum reciprocals values maximized
give ranking three five ten hypotheses turnbull pac
expected loss tables
previous experiment pac outperformed turnbull
cases p acadj represents significant increase
deep sampling samples performed obtain correct ranking
compared



fichien stechert mutz
performance note achieve desired level confidence cases
turnbull p acrec achieve required confidence

k






























































turnbull



















p acrec




















p acadj




















table estimated expected cost seconds rank aeroshell designs achieved probability correct ranking shown parenthesis

parameters
k
h



















elrec

execution cost










loss










eladj

execution cost










loss










table estimated expected cost seconds expected loss incorrect ranking
ds aeroshell designs



fiefficient heuristic hypothesis ranking
lossless image compression galileo image data

utilizes large set raw image data acquired galileo spacecraft
images size made greyscale pixels ranging
intensity goal select lossless compression method performs best
class images performance image compression particular image
could measured number ways example execution time compression ratio
image quality case lossy compression methods considered could
define performance tests chose consider compression ratio
achieved given compression method utility function sample method
hypothesis image randomly selected method applied image
achieved compression ratio recorded
given tables ranking three five seven hypotheses
turnbull pac expected loss ranking correctness determined
comparison correct ranking established sampling compression method
set distinct images
note substantial performance improvement pac
turnbull although turnbull pac
table achieved desired confidence level adjacent version el
table failed bound loss specified level half cases
interesting consider presented section light fact
statistical techniques used makes form normality assumption
fact three domains investigate number hypotheses whose
utility functions normally distributed past experience known utility
functions ds penetrator domain section highly non normal figure
illustrates difference data normally distributed data


























































figure comparison data normally distributed high likelihood b
data likely normally distributed case histogram
experimental data shown solid boxes data drawn normal distribution
mean standard deviation shown dashed lines
determine extent utilities hypotheses remaining two domains normally distributed applied kolmogorov smirnov test see appendix
seven compression methods considered calic lossless jpeg gif tiff pack gzip
compress



fichien stechert mutz

k






























































turnbull



















p acrec




















p acadj




















table estimated expected cost seconds rank lossless image compression approaches galileo image data achieved probability correct ranking shown
parenthesis

parameters
k
h



















elrec

execution cost










loss










eladj

execution cost










loss










table estimated expected cost seconds expected loss incorrect ranking
ds penetrator designs



fiefficient heuristic hypothesis ranking
details test determined none ten hypotheses ds aeroshell
domain section normally distributed utility additionally two seven
hypotheses image compression domain section shown greater
likelihood normally distributed utility functions reasons
evaluating ranking strategies datasets provides particularly strong test
applicability techniques
draw reader attention particularly large disparity performance
turnbull pac image compression domain
especially apparent number hypotheses confidence level high
additionally domain two hypotheses normally distributed utility
five non normal observations suggest pac
perform better relative terms faced domain violates assumption
normality
discussion conclusions

number areas related work first considerable analysis
hypothesis selection selection formalized bayesian
framework moore lee rivest sloan require initial
sample uses rigorous encoding prior knowledge howard howard
details bayesian framework analyzing learning cost selection one
uses hypothesis selection framework ranking allocation pairwise errors
performed rationally gratch et al reinforcement learning work kaelbling
immediate feedback viewed hypothesis selection
framework presented invites future work number directions currently
stopping criteria used relaxations ranking requirement another
could used bound resources available ranking limiting number
samples sample cost high limiting time computation
anytime two straightforward application areas
another area future work discovery composite strategies hypotheses thus
far examined ranking articles selection hypothesis highest expected value entire distribution example learning scheduling control
strategy well distribution however likely
distributions exists composite strategy would outperform
single strategy example single strategy might apply method solve
composite strategy would test feature x x true apply method else apply method b composite strategies correspond
portfolios named operations indeed applying methods could
viewed strategies one might composite strategy trying method
cpu seconds fails trying method b course composition portfolio approaches diculty iseciently proposing evaluating plausible
compositions even small set base strategies number copositions enormous
reference data figure normally distributed likelihood according
kolmogorov smirnov test



fichien stechert mutz
summary described hypothesis ranking extension
hypothesis selection defined application two decision criteria probably approximately correct expected loss defined two families
recursive selection adjacency solution hypothesis ranking
finally demonstrated effectiveness synthetic realworld datasets documenting improved performance existing statistical approaches
acknowledgments

work performed jet propulsion laboratory california institute technology contract national aeronautics space administration
appendix applying k test real datasets

kolmogorov smirnov test statistical means accepting certain level
confidence hypothesis sampleset fits parametric distribution given
set parameters method compares cdf generated empirical distribution
corresponding parametric distribution e estimated parameters
k test gives confidence maximum discrepancies
two cdfs
maxjf x

f x j

purposes wish determine hypothesis given domain whether
values utility function normally distributed case half
utility samples taken used compute mean standard deviation normal
remaining half used compute cdf
ds penetrator

samples taken
design number











maxjf x

f x j













normally distributed
likely
likely
likely
likely
likely
likely
likely
likely
likely
likely

fiefficient heuristic hypothesis ranking
ds aeroshell design ranking

samples taken
design number











maxjf x

f x j












normally distributed
likely
likely
likely
likely
likely
likely
likely
likely
likely
likely

lossless image compression galileo image data

samples taken
compression method
gif
compress
calic
gzip
jpegls
pack
tiff

maxjf x

f x j









normally distributed
likely
likely
likely
likely
likely
likely
likely

references

balacuit c p deep space mars microprobe home page mission objectives
statement tech rep http nmp jpl nasa gov ds nasa jpl
chien gratch j burl c ecient allocation resources
hypothesis evaluation statistical ieee trans pattern analysis
machine intelligence
chien stechert mutz h ecient heuristic ranking hypotheses advances neural information processing systems jordan kearns
solla eds pp denver colorado nips
ginsberg harvey w iterative broadening artificial intelligence journal



fichien stechert mutz
goldberg genetic search optimization machine learning
addison wesley
gratch j composer probabilistic solution utility speed
learning proceedings tenth national conference artificial intelligence
pp san jose ca aaai
gratch j composer decision theoretic adaptive solving tech rep uiucdcs r department computer science university
illinois
gratch j chien dejong g improving learning performance
rational resource allocation proceedings twelfth national conference
artificial intelligence pp seattle wa aaai
greiner r jurisica statistical solving ebl utility
proceedings tenth national conference artificial intelligence
pp san jose ca aaai
haseeb r modern statistical selection american sciences press columbus
oh
howard r decision analysis perspectives inference decision experimentation proceedings ieee
kaelbling l p learning embedded systems mit press cambridge
minton learning search control knowledge explanation
kluwer academic publishers norwell
moore w lee ecient minimizing cross validation
error proceedings international conference machine learning
brunswick
musick r catlett j russell decision theoretic subsampling induction large databases proceedings international conference machine
learning pp amherst
rivest r l sloan r model inductive inference proceedings
second conference theoretical aspects reasoning knowledge
russell wefald e right thing studies limited rationality mit
press cambridge
tadepalli p theory unsupervised speedup learning proc tenth
national conference artificial intelligence pp san jose ca aaai
turnbull b w weiss l class sequential procedures k sample
concerning normal means unknown equal variances santner
j tamhane c eds design experiments ranking selection pp
marcel dekker


fiefficient heuristic hypothesis ranking
valiant l g theory learnable communications acm





