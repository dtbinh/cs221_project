journal artificial intelligence

submitted published

anytime induction low cost low error classifiers
sampling
saher esmeir
shaul markovitch

esaher cs technion ac il
shaulm cs technion ac il

computer science department
technionisrael institute technology
haifa israel

abstract
machine learning techniques gaining prevalence production wide range
classifiers complex real world applications nonuniform testing misclassification
costs increasing complexity applications poses real challenge resource
management learning classification work introduce act anytime
cost sensitive tree learner novel framework operating complex environments
act anytime allows learning time increased return lower
classification costs builds tree top exploits additional time resources
obtain better estimations utility different candidate splits sampling
techniques act approximates cost subtree candidate split favors
one minimal cost stochastic act expected able
escape local minima greedy methods may trapped experiments
variety datasets conducted compare act state art cost sensitive
tree learners majority domains act produces significantly
less costly trees act exhibits good anytime behavior diminishing returns

introduction
traditionally machine learning focused induction
low expected error many real word applications however several additional constraints
considered assume example medical center decided use machine learning techniques build diagnostic tool heart disease comprehensibility
decision tree hastie tibshirani friedman chap makes preferred choice base tool figure shows three possible trees first tree
upper left makes decisions cardiac catheterization heart cath
tree expected highly accurate nevertheless high costs risks associated heart cath procedure make decision tree impractical second tree
lower left dispenses need cardiac catheterization reaches decision
single simple inexpensive test whether patient complains chest pain
tree would highly accurate people experience chest pain
indeed healthy tree however distinguish costs different types
errors false positive prediction might extra treatments false negative
prediction might put persons life risk therefore third tree right preferred one
attempts minimize test costs misclassification costs simultaneously
c

ai access foundation rights reserved

fiesmeir markovitch

heart cath


normal

chest pain


yes

yes

blood
pressure

alerting



blood
pressure


yes

cardiac
stress

normal

normal



normal

normal

heart cath

yes





yes

yes

alerting

yes

normal

alerting

normal

heart cath

chest pain


yes

alerting

figure three possible decision trees diagnosis heart diseases upper left tree
bases decision solely heart cath therefore accurate prohibitively
expensive lower left tree dispenses need heart cath reaches
decision single simple inexpensive test whether patient
complains chest pain tree would highly accurate
distinguish costs different error types third right hand
tree preferable attempts minimize test costs misclassification costs
simultaneously

cost


















cost
cost






















figure left example difficulty greedy learners might face right example
importance context feature evaluation

finding tree lowest expected total cost least np complete
cost insensitive case greedy heuristic used bias search towards low cost trees
decision trees minimal cost dtmc greedy method attempts minimize
finding smallest consistent tree easier np complete hyafil rivest



fianytime induction low cost low error classifiers

types costs simultaneously recently introduced ling yang wang
zhang sheng ling ni zhang tree built top greedy split
criterion takes account testing misclassification costs used basic
idea estimate immediate reduction total cost split prefer
split maximal reduction split reduces cost training data
induction process stopped
although efficient dtmc trapped local minimum
produce trees globally optimal example consider concept costs
described figure left attributes relevant
cost however significantly higher others high costs may
hide usefulness mislead learner repeatedly splitting
would large expensive tree would intensified
interdependent low immediate information gain e g
case even costs uniform local measure might fail recognize relevance

dtmc appealing learning resources limited however requires
fixed runtime cannot exploit additional resources escape local minima many
real life applications willing wait longer better tree induced esmeir
markovitch example importance model saving patients lives may
convince medical center allocate month learn exploit
additional time produce better solutions called anytime boddy dean

icet turney pioneer non greedy search tree
minimizes test misclassification costs icet uses genetic search produce
set costs reflects original costs contribution attribute
reducing misclassification costs builds tree eg nunez
evolved costs instead original ones eg greedy cost sensitive
builds tree top evaluates candidate splits considering
information gain yield measurement costs however take
account misclassification cost
icet shown significantly outperform greedy tree learners producing trees
lower total cost icet use additional time resources produce generations
hence widen search space costs genetic operations randomized
icet likely escape local minima eg original costs might
trapped nevertheless two shortcomings limit icets ability benefit extra time
first search phase uses greedy eg build final tree
eg prefers attributes high information gain low test cost
usefulness highly relevant attributes may underestimated greedy measure
case hard learn concepts attribute interdependency hidden
expensive trees second even icet overcomes randomly
reweighting attributes searches space parameters globally regardless
context tree imposes attribute important one subtree
useless another better understand shortcomings consider concept described
tree figure right attributes similar costs value
determines whether target concept interdependencies


fiesmeir markovitch

low gain attributes icet assigns costs globally attributes
similar costs well therefore icet able recognize one relevant
context irrelevant attributes cheaper intensified
model might end relying irrelevant attributes
recently introduced cost insensitive lsid induce
accurate trees allocated time esmeir markovitch evaluates candidate split estimating size smallest consistent tree
estimation sampling space consistent trees size
sample determined advance according allocated time lsid designed
however minimize test misclassification costs work build lsid
propose act anytime cost sensitive tree learner exploit additional time
produce lower cost trees applying sampling mechanism cost sensitive setup
however trivial imposes three major challenges produce sample
evaluate sampled trees prune induced trees section
obstacles may overcome
section report extensive set experiments compares act several
decision tree learners variety datasets costs assigned human experts
automatically act significantly better majority
addition act shown exhibit good anytime behavior diminishing
returns

cost sensitive classification
offline concept learning consists two stages learning stage set labeled
examples used induce classifier classification stage induced
classifier used classify unlabeled instances two stages involve different types
costs turney primary goal work trade learning speed
reduction test misclassification costs make well defined need
specify misclassification costs represented test costs calculated
combine types cost
answer questions adopt model described turney
c different classes misclassification cost matrix c c matrix whose mi j
entry defines penalty assigning class ci instance actually belongs
class cj typically entries main diagonal classification cost matrix error
zero
classifying example e tree propagate e tree along
single path root one leaves let e set tests along
path denote cost cost administering test testing cost e
p
therefore tcost e cost note use sets notation tests
appear several times charged addition model described turney
handles two special test types namely grouped delayed tests
grouped tests tests share common cost would charge
typically test extra possibly different cost example consider
tree path tests cholesterol level glucose level values measured
blood test needed taking blood samples measure cholesterol level clearly lowers


fianytime induction low cost low error classifiers

cost measuring glucose level formally test possibly belongs group
first test group administered charge full cost another
test group already administered earlier decision path
charge marginal cost
delayed tests sometimes outcome test cannot obtained immediately e g
lab test tests called delayed tests force us wait outcome
available alternatively turney suggests taking account possible outcomes
delayed test encountered tests subtree administered
charged delayed test available prediction hand
one setup follows paths subtree regardless
outcome non delayed costs moreover possible distinguish delays
different tests impose example one might ready several minutes
another days work handle delayed tests
explain act modified take account
test misclassification costs measured important question
remains combine following turney assume
cost types given scale general model would require utility function
combines types qin zhang zhang presented method handle
two kinds cost scales setting maximal budget one kind cost minimizing
one alternatively patient preferences elicited summarized utility
function lenert soetikno
note introduce adapted cost model
important property cost sensitive setup maximizing generalization accuracy
goal existing learners viewed special case accuracy
objective test costs ignored misclassification cost uniform

act
act proposed anytime framework induction cost sensitive decision trees builds
recently introduced lsid lsid adopts general top scheme
induction decision trees tdidt starts entire set training examples
partitions subsets testing value attribute recursively builds
subtrees unlike greedy inducers lsid invests time resources making better split
decisions every candidate split lsid attempts estimate size resulting
subtree split take place following occams razor blumer ehrenfeucht haussler warmuth esmeir markovitch b favors one smallest
expected size
estimation biased sample space trees rooted evaluated
attribute sample obtained stochastic version id quinlan
call sid sid rather choosing attribute maximizes information
gain id choose splitting attribute semi randomly likelihood
attribute chosen proportional information gain due randomization
model test may belong single group however easy extend work allow
tests belong several groups



fiesmeir markovitch

procedure lsid choose attribute e r
r
return id choose attribute e
foreach
foreach vi domain
ei e e e vi
mini
repeat r times
sid ei
mini min mini size
p domain
totala
mini
return totala minimal
figure attribute selection lsid
repeated invocations sid different trees candidate attribute lsid
invokes sid r times form sample r trees rooted uses size smallest
tree sample evaluate obviously r larger resulting size estimations
expected accurate improving final tree consider example xor
concept several additional irrelevant attributes lsid prefer one relevant
attributes root one trees samples relevant attributes must
smallest probability event increases increase sample size
lsid contract anytime parameterized r sample size additional
time resources utilized forming larger samples figure lists procedure
attribute selection applied lsid let e number examples
n number attributes runtime complexity lsid rmn lsid
shown exhibit good anytime behavior diminishing returns applied
hard concepts produced significantly better trees id c
act takes sampling lsid three major components
lsid need replaced order adapt cost sensitive
sampling space trees evaluating tree pruning tree
obtaining sample
lisd uses sid bias samples towards small trees act however would
bias sample towards low cost trees purpose designed stochastic version
eg attempts build low cost trees greedily eg tree
built top test maximizes icf chosen splitting node
icf



cost w

information gain id parameter w controls bias
towards lower cost attributes w test costs ignored icf relies solely


fianytime induction low cost low error classifiers

procedure seg choose attribute e
foreach
information gain e
c cost

p c
w
choose attribute random
attribute probability
selecting proportional p
return
figure attribute selection seg
information gain larger values w strengthen effect test costs icf
discuss setting value w section
stochastic eg seg choose splitting attributes semi randomly proportionally
icf seg stochastic expect able escape local minima
least trees sample figure formalizes attribute selection component
seg obtain sample size r act uses eg seg r times eg
seg given direct access context costs e attribute already
tested cost zero another attribute belongs group
tested group discount applied
evaluating subtree
lsid cost insensitive learning main goal maximize
expected accuracy learned tree occams razor states given two consistent
hypotheses smaller one likely accurate following occams razor lsid
uses tree size preference bias favors splits expected reduce final
size
cost sensitive setup however goal minimize expected total cost
classification therefore rather choosing attribute minimizes size
would choose one minimizes total cost given decision tree need
come procedure estimates expected cost tree classify
future case cost two components test cost misclassification cost
estimating test costs
assuming distribution future cases would similar learning
examples estimate test costs training data given tree calculate
average test cost training examples use estimate test cost
cases sub tree built e set training examples denote average
cost traversing example e
tcost e

x
tcost e
ee


fiesmeir markovitch


estimated test cost unseen example e therefore tcost
e tcost e
observe costs calculated relevant context attribute already
tested upper nodes charge testing similarly attribute
group g already tested apply group discount attributes
g delayed attribute encountered sum cost entire subtree

estimating misclassification costs
go estimating cost misclassification obvious tree size
longer used heuristic predictive errors occams razor allows comparison
two consistent trees provides means estimating accuracy moreover tree size
measured different currency accuracy hence cannot easily incorporated
cost function
rather tree size propose different estimator expected error
quinlan leaf training examples misclassified
expected error defined upper limit probability error e ee cf
bin cf confidence level u bin upper limit confidence
ucf
interval binomial distribution expected error tree sum expected
errors leaves
originally expected error used c error pruning predict whether
subtree performs better leaf although lacking theoretical basis shown
experimentally good heuristic act use expected error approximate
misclassification cost assume c classes misclassification cost
matrix let c class label leaf l let ml total number examples
l mil number examples l belong class penalties
predictive errors uniform mi j mc estimated misclassification cost l
l ee ml ml mc cf mc
mcost
l

nonuniform misclassification costs mc replaced cost
actual errors leaf expected make errors obviously unknown
learner one solution estimate error type separately confidence intervals
multinomial distribution multiply associated cost
l
mcost

x

mul
ucf
ml mil c mc

c

however would overly pessimistic approximation mainly
many classes alternatively compute expected error uniform
case propose replacing mc weighted average penalty classifying
instance c belongs another class weights derived proportions
mil
ml mc generalization laplaces law succession good chap
l

l ee ml ml mc cf
mcost
l

x
c





mil
mc
ml mcl c

note c classes average c possible penalties
mc c hence two classes c c leaf marked c mc


fianytime induction low cost low error classifiers

procedure act choose attribute e r
r
return eg choose attribute e
foreach
foreach vi domain
ei e e e vi
eg ei
mini total cost ei
repeat r times
seg ei
mini min mini total cost ei
p domain
mini
totala cost
return totala minimal
figure attribute selection act
would replaced classifying instance expected misclassification
cost tree built examples sum expected misclassification costs
leaves divided
x

mcost l
mcost


l set leaves hence expected total cost classifying
single instance



total
e tcost
e mcost


alternative intend explore future work estimate cost
sampled trees cost set aside validation set attractive
mainly training set large one afford setting aside significant part

choosing split
decided sampler tree utility function ready formalize
tree growing phase act tree built top procedure selecting
splitting test node listed figure illustrated figure give
detailed example act chooses splits explain split selection procedure
modified numeric attributes
choosing split illustrative examples
acts evaluation cost senstive considers test error costs simultaneously
take account different error penalties illustrate let us consider
two class mc uniform attributes whose costs
training data contains examples positive
negative


fiesmeir markovitch



g
se
st


co


cost eg

cost seg


cost eg


figure attribute evaluation act assume cost current context
estimated cost subtree rooted therefore min
min

test costs






mc costs
fp
fn

r









ee










ee




ee





ee



mcost
tcost
total


ee






ee




ee




ee



mcost
tcost
total

figure evaluation tree samples act leftmost column defines costs
attributes identical cost uniform error penalties sampled
ee stands expected error total cost
lower act would prefer split

assume choose r let trees
figure denoted sampled respectively expected
error costs

mcost



mcost






ee




ee ee





test error costs involved act considers sum since test
cost trees identical act would prefer split however cost
example set cf c section discuss tune cf



fianytime induction low cost low error classifiers

test costs






mc costs
fp
fn

r
















ee


ee



ee


ee









mcost
tcost
total






ee


ee


ee


ee







mcost
tcost
total

figure evaluation tree samples act leftmost column defines costs
attributes identical cost except expensive uniform error
penalties sampled total cost
lower act would prefer split

test costs






mc costs
fp
fn

r









ee










ee




ee





ee



mcost
tcost
total


ee






ee




ee




ee



mcost
tcost
total

figure evaluation tree samples act leftmost column defines costs
attributes identical cost nonuniform error penalties sampled
total cost lower act would prefer
split

figure tcost would become total cost would
become would remain hence case act would split

illustrate act handles nonuniform error penalties let us assume cost
attributes cost false positive fp cost
false negative f n let trees figure denoted sampled
respectively first example misclassification costs play role
test costs trees although average misclassification


fiesmeir markovitch

cost act evaluates trees differently

mcost





mcost





ee ee





ee ee





therefore nonuniform setup act would prefer makes sense
given setup prefer trees may false positives reduce number
expensive false negatives
choosing split attributes numeric
selection procedure formalized figure must modified slightly attribute numeric rather iterating values attribute take first pick
r tests split points highest information gain invoke eg
split point guarantees numeric nominal attributes get resources
chickering meek rounthwaite introduced several techniques generating
small number candidate split points dynamically little overhead future
intend apply techniques select r points evaluated
single invocation eg
cost sensitive pruning
pruning plays important role decision tree induction cost insensitive environments
main goal pruning simplify tree order avoid overfitting training
data subtree pruned resulting tree expected yield lower error
test costs taken account pruning another important role reducing
test costs tree keeping subtree worthwhile expected reduction misclassification costs larger cost tests subtree misclassification
cost zero makes sense keep split tree hand misclassification cost much larger test costs would expect similar behavior
cost insensitive setup
handle challenge propose novel cost sensitive pruning
error pruning quinlan scan tree bottom compare
expected total cost subtree leaf leaf expected perform better
subtree pruned
cost subtree estimated described section formally let e
set training examples reach subtree let size e assume
examples e belong default class let l set leaves
misclassification costs uniform default class majority class otherwise class
minimizes misclassification cost node



fianytime induction low cost low error classifiers

prune leaf
x



mcost l
ee cf mc tcost
e



assumes uniform misclassification cost mc case nonuniform penalties
multiply expected error average misclassification cost
alternative post pruning early stopping growing phase
example one could limit depth tree require minimal number examples
child c prevent splitting nodes splitting criterion fails exceed
predetermined threshold dtmc obviously pre pruning condition
applied part post pruning procedure advantage post pruning however
ability estimate effect split entire subtree
immediate successors horizon effect
consider example xor b splitting neither b would
positive gain hence growing would stopped pre pruning allowed
optimal tree would found would post pruned utility
splits correctly measured frank reports comprehensive study pruning
decision trees compared pre post pruning empirically cost insensitive
setup findings advantage post pruning variety uci datasets
significant pre pruning computationally efficient frank concluded
practice might viable alternative post pruning despite
decided use post pruning act following reasons
several concepts represented uci repository may appear real world
example parity functions naturally arise real world
drosophila survival concept page ray
costs involved horizon effect may appear frequently high
costs may hide good splits
anytime setup user willing wait longer order obtain good tree
since post pruning takes even less time induction single greedy tree
extra cost post pruning minor
future plan add pre pruning parameter allow early stopping
resources limited another interesting direction future work would postprune final tree pre prune lookahead trees form samples would
reduce runtime cost less accurate estimations utility candidate
split
setting parameters act
addition r sample size act parameterized w controls weight
test costs eg cf confidence factor used pruning error
estimation icet tunes w cf genetic search act considered three different
alternatives keeping eg c default values w cf tuning


fiesmeir markovitch

values cross validation setting values priori function
costs
first solution simplest exploit potential adapting
sampling mechanism specific costs although tuning values
grid search would achieve good may costly terms runtime example
values parameter used fold cross validation would need
run act times sake tuning alone anytime setup time could
invested invoke act larger r hence improve furthermore
would able output valid solution tuning stage finished
alternatively could try tune parameters invoking much faster eg
would good optimal values eg necessarily
good act
third chose experiments set w cf advance
according specific costs w set inverse proportionally misclassification cost high misclassification cost smaller w reducing effect attribute
costs split selection measure exact formula
w ex
x average misclassification cost non diagnoal entries divided
c cost take tests formally
x

p

mi j

c c c
j

c default value cf larger cf values less pruning smaller
cf values lead aggressive pruning therefore act set cf value
range exact value depends cost test costs dominant
prefer aggressive pruning hence low value cf test costs negligible
prefer prune less value cf used estimate expected error
test costs dominant afford pessimistic estimate error
misclassification costs dominant would prefer estimate closer
error rate training data exact formula setting cf
x
cf

x

empirical evaluation
conducted variety experiments test performance behavior act
first introduce novel method automatic adaption existing datasets costsensitive setup describe experimental methodology motivation finally
present discuss
datasets
typically machine learning researchers use datasets uci repository asuncion
newman five uci datasets however assigned test costs include
costs datasets assigned human experts turney



fianytime induction low cost low error classifiers

datasets experiments nevertheless gain wider perspective
developed automatic method assigns costs existing datasets method
parameterized
cr cost range
g number desired groups percentage number attributes
attributes g groups probability attribute

probability belong
belong groups g
groups
number delayed tests percentage number attributes
group discount percentage minimal cost group ensure
positive costs
binary flag determines whether costs drawn randomly uniformly
semi randomly cost test drawn proportionally information
gain simulating common case valuable features tend higher costs
case assume cost comes truncated normal distribution
mean proportional gain
method assigned costs datasets arbitrarily chosen uci datasets
datasets represent hard concepts used previous appendix gives detailed descriptions datasets
due randomization cost assignment process set parameters
defines infinite space possible costs datasets sampled space
times
cr g
parameters chosen attempt assign costs manner similar
real costs assigned total datasets assigned human experts
automatically generated costs
cost insensitive learning focus accuracy therefore expected perform well testing costs negligible relative misclassification costs however
testing costs significant ignoring would expensive classifiers therefore
evaluating cost sensitive learners requires wide spectrum misclassification costs
created instances uniform misclassification costs
mc later consider nonuniform misclassification
costs
methodology
start experimental evaluation comparing act given fixed resource allocation several cost sensitive cost insensitive next compare
anytime behavior act icet finally evaluate
chosen uci datasets vary size type attributes dimension
additional datasets available http www cs technion ac il esaher publications cost



fiesmeir markovitch

two modifications instances random test cost assignment nonuniform
misclassification costs
compared
act compared following
c cost insensitive greedy decision tree learner reimplemented following details quinlan default parameters
used
lsid cost insensitive anytime decision tree learner uses extra time
induce trees higher accuracy able however exploit additional allotted
time reduce classification costs
idx greedy top learner prefers splits maximize
c norton
take account misclassification costs idx implemented top c modifying split selection criteria


csid greedy top learner prefers splits maximize ic tan
schlimmer take account misclassification costs
csid implemented top c modifying split selection criteria
eg greedy top learner prefers splits maximize



w

cost
nunez take account misclassification costs
eg implemented top c modifying split selection criteria

dtmc dtmc implemented following original pseudo code ling et al
sheng et al however original pseudo code support continuous attributes multiple class added support continuous
attributes c dynamic binary cut discretization cost reduction
replacing gain ratio selecting cutting points extension multiple class straightforward note dtmc post prune trees
pre prunes
icet icet reimplemented following detailed description given
turney verify reimplementation compared
reported literature followed experimental setup
used datasets indeed similar basic version icet
achieved average cost reimplementation vs reported originally
one possible reason slight difference may initial population
genetic randomized genetic operators process
partitioning data training validating testing sets turney
introduced seeded version icet includes true costs initial
population reported perform better unseeded version therefore
use seeded version comparison parameters icet
default ones


fianytime induction low cost low error classifiers

normalized cost
turney points average cost classification dataset
problematic cost differences become relatively small
misclassification cost increases difficult combine multiple
datasets fair manner e g average difficult combine average
different misclassification costs overcome turney suggests normalizing
average cost classification dividing standard cost let c cost
take tests let frequency class data error response
class therefore standard cost defined
c mini maxi j mi j
standard cost approximation maximal cost given
consists two components maximal test cost misclassification cost
classifier achieves baseline accuracy e g majority classifier error
costs uniform classifiers may perform even worse baseline
accuracy standard cost strictly upper bound real cost
experiments however exceeded
statistical significance
single fold cross validation experiment conducted
partition train test sets used compared determine
statistical significance performance differences act icet dtmc
used two tests
paired test confidence
pair pairs obtained fold cross
validation runs used paired test determine weather difference
two given significant rejecting null hypothesis
differ performance count
many times significant winner
wilcoxon test demsar compares classifiers multiple datasets
states whether one method significantly better
fixed time comparison
instances ran different including act
r chose r average runtime act would shorter icet
methods much shorter runtime due greedy nature
table summarizes pair numbers represents average normalized
cost associated confidence interval figure illustrates average
plots normalized costs different misclassification costs
statistical significance test act icet dtmc given table
compared test wilcoxon test table lists
full available http www cs technion ac il esaher publications cost



fiesmeir markovitch

table average cost classification percentage standard cost classification
different mc values numbers represent average datasets
associated confidence intervals
mc






c






lsid













idx













csid



















eg






dtmc



















icet












act












table dtmc vs act icet vs act statistical tests mc first
column lists number test significant wins second column gives
winner implied wilcoxon test datasets
test wins
mc






dtmc vs act












w ilcoxon winner

icet vs act












dtmc vs act

icet vs act

dtmc
act
act
act
act

act
act
act
act


number test wins datasets well winner
wilcoxon test applied
misclassification cost relatively small mc act clearly outperforms
icet significant wins opposed icets significant wins significant
difference found remaining runs setup act able produce
small trees sometimes consisting one node accuracy learned model ignored
setup icet contrary produced datasets larger
costly trees dtmc achieved best outperformed act times
wilcoxon test indicates dtmc better act act better
icet investigation showed datasets act produced unnecessarily
larger trees believe better tuning cf would improve act scenario
making pruning aggressive
extreme misclassification costs dominate mc performance dtmc worse act icet test indicates act
significantly better icet times significantly worse times according
wilcoxon test difference act icet significant
taking however would turn favor act observe dtmc
winner mc becomes worst mc one reason


fianytime induction low cost low error classifiers

average standard cost








c
lsid
eg
dtmc
icet
act







misclassification cost



act cost

figure average normalized cost function misclassification cost








































icet cost












icet cost











icet cost





figure illustration differences performance act icet mc
left right point represents dataset x axis
represents cost icet axis represents act dashed
line indicates equality points act performs better
icet better

phenomenon dtmc introduced ling et al perform
post pruning although might improve accuracy domains
two extremes less interesting first could use
outputs tree size second could use cost insensitive learners
middle range mc requires learner carefully balance
two types cost cases act lowest average cost largest
number test wins moreover wilcoxon test indicates superior icet
second best method reported turney icet clearly better
greedy methods eg idx csid
note eg idx csid insensitive misclassification cost produced trees values mc trees however judged differently
change misclassification cost
figure illustrates differences icet act mc
point represents one datasets x axis represents cost icet
axis represents act dashed line indicates equality see


fiesmeir markovitch



average accuracy






c
lsid
eg
dtmc
icet
act







misclassification cost



figure average accuracy function misclassification cost

majority points equality line indicating act performs better
mc see points located close x axis large x
value points represent difficult domains xor icet could
learn act could
comparing accuracy learned
misclassification costs low optimal would produce shallow
tree misclassification costs dominant optimal would produce
highly accurate tree see acts normalized cost increases increase
misclassification cost relatively easy produce shallow trees concepts
easily learnable even cost insensitive fail achieve perfect accuracy
hence importance accuracy increases normalized cost increases
predictive errors affect dramatically
learn effect misclassification costs accuracy compare
accuracy built trees different misclassification costs figure shows
important property dtmc icet act ability compromise accuracy needed produce inaccurate trees accuracy insignificant much
accurate trees penalty error high acts flexibility however
noteworthy second least accurate method becomes accurate one
interestingly accuracy extremely important icet act achieve even
better accuracy c reason non greedy nature icet performs
implicit lookahead reweighting attributes according importance act performs
lookahead sampling space subtrees every split two
indicate acts lookahead efficient terms accuracy dtmc less accurate
c reason different split selection criterion different pruning
mechanism
comparison anytime cost insensitive lsid act produced less
accurate trees mc relatively low mc set however act
achieved comparable accuracy lsid slightly outperformed mc
statistical tests found differences accuracy two


fianytime induction low cost low error classifiers


eg
dtmc
icet
act



average cost

average cost



eg
dtmc
icet
act
























time sec



















time sec















average cost

average cost




eg
dtmc
icet
act




eg
dtmc
icet
act

















time sec












time sec







figure average normalized cost function time top left bottom right
breast cancer monks multi xor xor

case insignificant acts small advantage datasets indicates
expected error better heuristic tree size maximizing accuracy
comparison anytime behavior
icet act typical anytime perform better increased
resource allocation icet expected exploit extra time producing generations hence better tuning parameters final invocation eg act
use extra time acquire larger samples hence achieve better cost estimations
examine anytime behavior icet act ran
namely breast cancer monks multi xor xor exponentially increasing
time allocation mc set icet run generations act
sample size fixed time comparison used instances
figure plots averaged instances included
greedy methods eg dtmc
good anytime behavior icet act generally worthwhile allocate time act dominates icet four domains able
produce less costly trees shorter time
one advantage act icet able consider context
attribute judged icet contrary reassigns cost attributes globally


fiesmeir markovitch

average standard cost





dtmc

icet

act
















dtmc
icet
act

misclassification cost







































figure average cost test costs assigned randomly

attribute cannot assigned high cost one subtree low cost another multixor dataset exemplifies concept whose attributes important one sub concept
concept composed four sub concepts relies different attributes
see appendix details expected act outperforms icet significantly
latter cannot assign context costs allowing icet produce
generations trees comparable obtained act
random costs
costs datasets assigned semi random mechanism
gives higher costs informative attributes ensure acts success due
particular cost assignment scheme repeated experiments costs drawn
randomly uniformly given cost range cr e set figure shows
see act maintains advantage methods dominates
along scale mc values
nonuniform misclassification costs
far used uniform misclassification cost matrices e cost
error type identical explained section act handle
complex misclassification cost matrices penalty one type error might
higher penalty another type next experiment examines act
nonuniform scenario let fp denote penalty false positive fn penalty
false negative classes split classes equal groups
according order randomly order exists assign penalty fp
misclassifying instance belongs first group fn one belongs
second group
obtain wide view vary ratio fp fn examine different
absolute values table figure give average table lists number
test significant wins achieved easy see act consistently
outperforms methods


fianytime induction low cost low error classifiers
























c
eg
dtcm
icet
act













































table comparison c eg dtmc act icet misclassification costs
nonuniform fp denotes penalty false positive fn penalty
false negative denotes basic mc unit

c
eg
dtcm
icet
act











































fp
fn

table comparing dtmc act icet misclassification costs nonuniform
f p f n ratio columns list number test significant wins
fp denotes penalty false positive fn penalty
false negative denotes basic mc unit

f p f n








dtmc vs act


















icet vs act
















dtmc vs act
















icet vs act
















interestingly graphs slightly asymmetric reason could
datasets example medical ones difficult reduce negative errors positive
ones vice versa similar phenomenon reported turney
highest cost observed f p f n
ratio fp fn extremely large extremely small learner easily
build small tree whose leaves labeled class minimizes costs
misclassification costs balanced however learning process becomes much
complicated









average standard cost

average standard cost

esmeir markovitch





c
eg
dtmc
icet
act











misclassification cost fp fn








c
eg
dtmc
icet
act
















misclassification cost fp fn





figure comparison c eg dtmc act icet misclassification costs
nonuniform misclassification costs represented pair f p f n
fp denotes penalty false positive fn penalty false
negative denotes basic mc unit figures plot average cost
function ratio fp fn left
right

related work
addition works referred earlier several related works warrant
discussion
cost sensitive trees subject many efforts several works proposed learning consider different misclassification costs breiman friedman olshen stone pazzani merz murphy ali hume brunk provost
buchanan bradford kunz kohavi brunk brodley domingos
elkan zadrozny langford abe lachiche flach abe zadrozny
langford vadera margineantu zhu wu khoshgoftaar yong
sheng ling methods however consider test costs hence
appropriate mainly domains test costs constraint
davis ha rossbach ramadan witchel presented greedy cost sensitive
decision tree forensic classification classifying irreproducible
events setup assume tests might used testing must
acquired hence charged classification
one way exploit additional time searching less costly tree widen
search space bayer zubek dietterich formulated cost sensitive learning
markov decision process mdp used systematic search
ao heuristic search procedure solve mdp make ao efficient
uses two step lookahead heuristic limited lookahead
informed immediate heuristics still insufficient complex domains might
cause search go astray esmeir markovitch shown
output better diagnostic policies several greedy methods reasonable resources
optimal solution however could found due time memory limits
nice property serve anytime computing


fianytime induction low cost low error classifiers

best complete policy found far anytime behavior nevertheless problematic
policies optimal respect train data tend overfit
performance eventually start degrade
arnt zilberstein tackled time cost sensitive classification
tcsc tcsc utility labeling instance depends correctness
labeling amount time takes therefore total cost function
additional component reflects time needed measure attribute typically
super linear form cost quick small fairly constant
waiting time increases time cost grows increasing rate
complicated sequence time sensitive classification instances considered
time spent administering tests one case adversely affect costs future
instances arnt zilberstein suggest solving extending decision
theoretic introduced bayer zubek dietterich work
assume time takes administer test incorporated cost
future intend extend framework support time sensitive classification
individual cases sequences
fan lee stolfo miller studied cost sensitive intrusion detection systems ids goal maximize security minimizing costs
prediction action cost features categorized three cost levels according
amount information needed compute values reduce cost ids high
cost rules considered predictions low cost rules sufficiently
accurate
costs involved learning phase example acquisition
model learning budgeted learning studied lizotte madani
greiner cost associated obtaining attribute value
training example task determine attributes test given budget
related active feature value acquisition setup one tries reduce
cost improving accuracy identifying highly informative instances melville saartsechansky provost mooney introduced instances
selected acquisition accuracy current model confidence
prediction
greiner grove roth pioneers studying classifiers actively decide
tests administer defined active classifier classifier given
partially specified instance returns class label strategy specifies
test performed next greiner et al analyzed theoretical aspects
learning optimal active classifiers variant probably approximately correct
pac model showed task learning optimal cost sensitive active classifiers
often intractable however task shown achievable active classifier
allowed perform constant number tests limit provided
learning setup proposed taking dynamic programming
build trees depth
setup assumed charged acquiring feature values test
cases term test strategy sheng ling yang describes process feature
values acquisition values query order several test strategies
studied including sequential single batch multiple batch sheng et al


fiesmeir markovitch

corresponds different diagnosis policy strategies orthogonal
work assume given decision tree
bilgic getoor tackled feature subset selection costs
involved objective minimize sum information acquisition cost
misclassification cost unlike greedy approaches compute value features one
time used novel data structure called value information lattice voila
exploits dependencies missing features makes possible share information value computations different feature subsets possible viola shown
empirically achieve dramatic cost improvements without prohibitive computational
costs comprehensive search

conclusions
machine learning techniques increasingly used produce wide range classifiers complex real world applications involve nonuniform testing misclassification costs increasing complexity applications poses real challenge
resource management learning classification work introduced novel
framework operating complex environments framework four major
advantages
uses non greedy build decision tree therefore able overcome
local minima
evaluates entire trees search thus adjusted cost scheme
defined trees
exhibits good anytime behavior allows learning speed traded classification costs many applications willing allocate time
would allocate greedy methods proposed framework exploit extra
resources
sampling process easily parallelized method benefit distributed computer power
evaluate act designed extensive set experiments wide range
costs since publicly available cost oriented datasets designed
parametric scheme automatically assigns costs existing datasets experimental
act superior icet dtmc existing cost sensitive
attempt minimize test costs misclassification costs simultaneously significance
tests found differences statistically strong act exhibited good anytime
behavior increase time allocation cost learned decreased
act contract anytime requires sample size predetermined
future intend convert act interruptible anytime adopting
iidt general framework esmeir markovitch addition plan apply
monitoring techniques hansen zilberstein optimal scheduling act
examine strategies evaluating subtrees


fianytime induction low cost low error classifiers

table characteristics datasets used

dataset
breast cancer
bupa
car
flare
glass
heart
hepatitis
iris
krk
monks
monks
monks
multiplexer
multi xor
multi
nursery
pima
tae
tic tac toe
titanic
thyroid
voting
wine
xor
xor

instances


























attributes
nominal binary numeric




















































max attribute
domain

classes















































acknowledgments
work partially supported funding ec sponsored muscle network
excellence fp

appendix datasets
table lists characteristics datasets used give detailed
description non uci datasets used experiments
multiplexer multiplexer task used several researchers evaluating classifiers e g quinlan instance series bits length
positive integer first bits represent index remaining bits
label instance value indexed bit experiments considered
multiplexer dataset contains randomly drawn instances
boolean xor parity functions known problematic many learning
however naturally arise real world data drosophila
survival concept page ray considered xor five variables five
additional irrelevant attributes


fiesmeir markovitch

numeric xor xor numeric dataset used evaluate learning
e g baram el yaniv luz example consists values
x coordinates example labeled product x positive
otherwise generalized domain three dimensions added irrelevant
variables make concept harder
multi xor multi concepts defined binary attributes
cases target concept composed several subconcepts first
two attributes determines considered attributes
used form subconcepts multi xor dataset subconcept xor
multi dataset subconcept

references
abe n zadrozny b langford j iterative method multi class costsensitive learning proceedings th acm sigkdd international conference
knowledge discovery data mining kdd seattle wa usa
arnt zilberstein learning policies sequential time cost sensitive
classification proceedings st international workshop utility data
mining ubdm held kdd pp york ny usa acm press
asuncion newman
uci machine learning repository
university california irvine school information computer sciences
http www ics uci edu mlearn mlrepository html
baram el yaniv r luz k online choice active learning
proceedings international conference machine learning icml
pp washington dc usa
bayer zubek v dietterich integrating learning examples search
diagnostic policies artificial intelligence
bilgic getoor l voila efficient feature value acquisition classification
proceedings nd national conference artificial intelligence aaai
blumer ehrenfeucht haussler warmuth k occams razor
information processing letters
boddy dean l deliberation scheduling solving time
constrained environments artificial intelligence
bradford j kunz c kohavi r brunk c brodley c pruning decision
trees misclassification costs proceedings th european conference
machine learning ecml pp
breiman l friedman j olshen r stone c classification regression
trees wadsworth brooks monterey ca
chickering meek c rounthwaite r efficient determination dynamic
split points decision tree proceedings st ieee international conference


fianytime induction low cost low error classifiers

data mining icdm pp washington dc usa ieee computer
society
davis j v ha j rossbach c j ramadan h e witchel e cost sensitive
decision tree learning forensic classification proceedings th european
conference machine learning ecml pp berlin germany
demsar j statistical comparisons classifiers multiple data sets journal
machine learning
domingos p metacost general method making classifiers cost sensitive
proceedings th international conference knowledge discovery data
mining kdd pp
elkan c foundations cost sensitive learning proceedings th
international joint conference artificial intelligence ijcai pp
seattle washington usa
esmeir markovitch decision tree learner plenty time
proceedings st national conference artificial intelligence aaai
boston usa
esmeir markovitch anytime learning decision trees journal machine
learning
esmeir markovitch b occams razor got sharper proceedings
th international joint conference artificial intelligence ijcai
hyderabad india
fan w lee w stolfo j miller multiple model cost sensitive
intrusion detection proceedings th european conference machine
learning ecml pp barcelona catalonia spain
frank e pruning decision trees lists ph thesis department computer
science university waikato
good estimation probabilities essay modern bayesian methods
mit press usa
greiner r grove j roth learning cost sensitive active classifiers
artificial intelligence
hansen e zilberstein monitoring control anytime
dynamic programming artificial intelligence
hastie tibshirani r friedman j elements statistical learning
data mining inference prediction york springer verlag
hyafil l rivest r l constructing optimal binary decision trees npcomplete information processing letters
lachiche n flach p improving accuracy cost two class multiclass probabilistic classifiers roc curves proceedings th international
conference machine learning icml


fiesmeir markovitch

lenert l soetikno r automated computer interviews elicit utilities potential applications treatment deep venous thrombosis american medical
informatics association
ling c x yang q wang j zhang decision trees minimal costs
proceedings st international conference machine learning icml
lizotte j madani greiner r budgeted learning naive bayes classifiers
proceedings th conference uncertainty artificial intelligence uai acapulco mexico
margineantu active cost sensitive learning proceedings th international joint conference artificial intelligence ijcai edinburgh scotland
melville p saar tsechansky provost f mooney r j active feature acquisition classifier induction proceedings th ieee international conference
data mining icdm pp brighton uk
norton w generating better decision trees sridharan n ed proceedings eleventh international joint conference artificial intelligence pp
detroit michigan usa
nunez use background knowledge decision tree induction machine
learning
page ray skewing efficient alternative lookahead decision
tree induction proceedings th international joint conference artificial
intelligence ijcai acapulco mexico
pazzani merz c murphy p ali k hume brunk c reducing
misclassification costs knowledge intensive approaches learning noisy data
proceedings th international conference machine learning icml
provost f buchanan b inductive policy pragmatics bias selection
machine learning
qin z zhang zhang c cost sensitive decision trees multiple cost
scales lecture notes computer scienc ai advances artificial intelligence

quinlan j r induction decision trees machine learning
quinlan j r c programs machine learning morgan kaufmann san
mateo ca
sheng ling c x ni zhang cost sensitive test strategies
proceedings st national conference artificial intelligence aaai
boston usa
sheng ling c x yang q simple test strategies cost sensitive decision
trees proceedings th european conference machine learning ecml pp porto portugal


fianytime induction low cost low error classifiers

sheng v ling c x roulette sampling cost sensitive learning
proceedings th european conference machine learning ecml
pp warsaw poland
tan schlimmer j c cost sensitive concept learning sensor use recognition proceedings th international workshop machine
learning pp ithaca ny
turney p types cost inductive concept learning proceedings
workshop cost sensitive learning held th international conference
machine learning icml stanford ca
turney p cost sensitive classification empirical evaluation hybrid genetic
decision tree induction journal artificial intelligence

vadera inducing cost sensitive non linear decision trees technical report school computing science engineering university salford
zadrozny b langford j abe n cost sensitive learning cost proportionate
example weighting proceedings rd ieee international conference data
mining icdm melbourne florida usa
zhu x wu x khoshgoftaar yong empirical study noise
impact cost sensitive learning proceedings th international joint conference artificial intelligence ijcai hyderabad india




