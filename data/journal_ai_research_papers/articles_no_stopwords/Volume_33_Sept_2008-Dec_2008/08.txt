Journal Artificial Intelligence Research 33 (2008) 285-348

Submitted 4/08; published 11/08

Computational Logic Foundations KGP Agents
Antonis Kakas

antonis@ucy.ac.cy

Department Computer Science, University Cyprus
75 Kallipoleos Str., P.O. Box 537, CY-1678 Nicosia, Cyprus

Paolo Mancarella

paolo.mancarella@unipi.it

Dipartimento di Informatica, Universita di Pisa
Largo B. Pontecorvo, 3 - 56127 Pisa, Italy

Fariba Sadri

fs@doc.ic.ac.uk

Department Computing, Imperial College London
South Kensington Campus, London SW72AZ, UK

Kostas Stathis

kostas@cs.rhul.ac.uk

Department Computer Science, Royal Holloway
University London, Egham, Surrey TW20 0EX, UK

Francesca Toni

ft@doc.ic.ac.uk

Department Computing, Imperial College London
South Kensington Campus, London SW72AZ, UK

Abstract
paper presents computational logic foundations model agency called
KGP (Knowledge, Goals Plan) model. model allows specification
heterogeneous agents interact other, exhibit proactive
reactive behaviour allowing function dynamic environments adjusting
goals plans changes happen environments. KGP provides highly
modular agent architecture integrates collection reasoning physical capabilities, synthesised within transitions update agents state response reasoning,
sensing acting. Transitions orchestrated cycle theories specify order
transitions executed taking account dynamic context agent
preferences, well selection operators providing inputs transitions.

1. Introduction
widely acknowledged concept agency provides convenient powerful
abstraction describe complex software entities acting certain degree autonomy
accomplish tasks, often behalf user (Wooldridge, 2002). agent context
understood software component capabilities reacting, planning
(inter) acting achieve goals environment situated. paper,
present model agency, called KGP (Knowledge, Goals Plan). model
hierarchical highly modular, allowing independent specifications collection
reasoning physical capabilities, used equip agent intelligent decision making
adaptive behaviour. model particularly suited open, dynamic environments
agents adapt changes environment function
circumstances information incomplete.
c
2008
AI Access Foundation. rights reserved.

fiKakas, Mancarella, Sadri, Stathis & Toni

development KGP model originally motivated existing gap modal logic specifications (Rao & Georgeff, 1991) BDI agents (Bratman, Israel, &
Pollack, 1988) implementation (for example see issues raised Rao, 1996).
Another motivation development KGP comes participation SOCS
project (SOCS, 2007), need agent model satisfies several requirements. specifically, aimed agent model rich enough allow
intelligent, adaptive heterogeneous behaviour, formal could lent well
formal analysis, implementable way implementation sufficiently
close formal specification allow verification. Although several models agency
proposed, none satisfies requirements once.
bridge gap specification implementation KGP model based
computational logic (CL). focus work extend synthesise number
useful computational logic techniques produce formal executable specifications
agents. purpose, model integrates abductive logic programming (ALP) (Kakas,
Kowalski, & Toni, 1992), logic programming priorities (Kakas, Mancarella, & Dung,
1994; Prakken & Sartor, 1997) constraint logic programming (Jaffar & Maher, 1994).
techniques explored right, modular integration
within KGP model explores extensions each, well providing high level agent
reasoning capabilities.
KGP model provides hierarchical architecture agents. specifies collection
modular knowledge bases, formalised CL. knowledge bases support collection reasoning capabilities, planning, reactivity, goal decision,
given formal specifications. model includes specification physical capabilities,
comprising sensing actuating. capabilities utilised within transitions,
model state agent changes result reasoning, sensing acting.
Transitions use selection operators providing inputs. control component, called
cycle theory, formalised CL, specifies order transitions executed, depending environment, state agent, preferences agent.
cycle theory takes agent control beyond one-size-fits-all approach used
agent models, allows us specify agents different preferences profiles behaviour (Sadri & Toni, 2005). particular, whereas majority existing agent models
rely upon observe-plan-act, means cycle theory model behaviours
observe-revise goals-planact observe-plan-sense action preconditions-act
observe-plan-act-plan-act. provide one example cycle theory, refer
normal, allowing behaviours depending different circumstances (the environment agent situated preferences). Note that, respect
agent models, KGP model allows agents revise goals life-time,
observing environment according two modalities: active passive observation.
agent built KGP architecture dynamically determines goals, plans (partially) achieve goals, interleaves planning action executions making
observations environment receiving messages agents, adapts
goals plans new information receives, changes observes, generates appropriate reactions.
number publications already described aspects (an initial version of)
KGP agents. precursor overall model described Kakas, Mancarella,
286

fiComputational Logic Foundations KGP Agents

Sadri, Stathis, Toni (2004b), planning component presented Mancarella,
Sadri, Terreni, Toni (2004), cycle theory developed Kakas, Mancarella,
Sadri, Stathis, Toni (2004a) implementation discussed Stathis et al.
(2004), Yip, Forth, Stathis, Kakas (2005), Bracciali, Endriss, Demetriou,
Kakas, Lu, Stathis (2006). paper, provide full formal specification
components KGP model, thus offering complete technical account
KGP one place. providing full formal specification, adjusted
developed model. particular, notion state definition novel,
reasoning capabilities simplified added, physical
capabilities extended (to include actuating) formally defined, transitions
selection operators formally defined full.
rest paper structured follows. Sections 2 3 give outline
model review background information necessary full description.
Sections 4, 5, 6 7, respectively, describe internal state KGP agents, reasoning physical capabilities, transitions. Section 8 describe selection
operators used cycle theory described Section 9. Following
detailed description KGP agents illustrate model series examples
Section 10, compare model others literature Section 11. Finally,
conclude paper Section 12.

2. KGP Model: Outline
Section give overview KGP agent model components,
provide informal examples functioning. model relies upon
internal (or mental) state, holding agent Knowledge base (beliefs), Goals (desires) Plans (intentions),
set reasoning capabilities,
set physical capabilities,
set transition rules, defining state agent changes, defined
terms capabilities,
set selection operators, enable provide appropriate inputs transitions,
cycle theory, providing control deciding transitions applied
when.
model defined modular fashion, different activities encapsulated
within different capabilities transitions, control separate module.
model hierarchical structure, depicted Figure 1.
2.1 Internal State
tuple hKB0 , F, C, i, where:
287

fiKakas, Mancarella, Sadri, Stathis & Toni

CYCLE
THEORY

TRANSITIONS




SELECTION
OPERATORS


E
REASONING

CAPABILITIES

PHYSICAL CAPABILITIES

Figure 1: graphical overview KGP model
KB0 holds beliefs agent external world situated
(including past communications), well record actions already
executed.
F forest trees whose nodes goals, may executable not.
tree forest gives hierarchical presentation goals, tree represents
construction plan root tree. set leaves tree F
forms currently chosen plan achieving root tree. Executable goals
actions may physical, communicative, sensing. simplicity, assume
actions atomic duration. Non-executable goals may
mental sensing. non-executable mental goals may children, forming
(partial) plans them. Actions children tree F. goal
associated time variable, implicitly existentially quantified within overall
state serves two purposes: (1) indicating time goal achieved,
instantiated goal achieved appropriate time, (2) providing
unique identifier goal. remainder paper, often use
following terminology goals F, want emphasise role and/or
nature: roots trees F referred top-level goals, executable
goals referred actions, non-executable goals top-level
goals referred sub-goals. Top-level goals classified reactive
non-reactive, explained later. 1 Note top-level (reactive) goals
may actions.
1. Roughly speaking, reactive goals generated response observations, e.g. communications received
agents changes environment, example repair plans already
generated. Non-reactive goals, hand, chosen desires agent.

288

fiComputational Logic Foundations KGP Agents

C Temporal Constraint Store, namely set constraint atoms given
underlying constraint language. constrain time variables goals F.
example, may specify time window time action
instantiated, execution time.
set equalities instantiating time variables time constants. example,
time variables actions instantiated action execution time, records
instantiations kept .
2.2 Reasoning Capabilities
KGP supports following reasoning capabilities:
Planning, generates plans mental goals given input. plans consist
temporally constrained sub-goals actions designed achieving input goals.
Reactivity, used provide new reactive top-level goals, reaction
perceived changes environment current plans held agent.
Goal Decision, used revise non-reactive top-level goals, adapting
agents state changes environment.
Identification Preconditions Identification Effects actions, used
determine appropriate sensing actions checking whether actions may safely
executed (if preconditions known hold) whether recently executed
actions successful (by checking known effects hold).
Temporal Reasoning, allows agent reason evolving environment,
make predictions properties, including non-executable goals, holding
environment, based (partial) information agent acquires lifetime.
Constraint Solving, allows agent reason satisfiability
temporal constraints C .
concrete realisation KGP model provide paper, chosen
realise capabilities various extensions logic programming paradigm.
particular, use (conventional) logic programming Identification Preconditions
Effects, abductive logic programming constraints (see Section 3.2) Planning,
Reactivity Temporal Reasoning, logic programming priorities (see Section 3.3)
Goal Decision.
2.3 Physical Capabilities
addition reasoning capabilities, KGP agent equipped physical capabilities, linking agent environment, consisting
Sensing capability, allowing agent observe properties hold
hold, agents executed actions.
Actuating capability, executing (physical communicative) actions.
289

fiKakas, Mancarella, Sadri, Stathis & Toni

2.4 Transitions
state hKB0 , F, C, agent evolves applying transition rules, employ
capabilities follows:
Goal Introduction (GI), possibly changing top-level goals F, using Goal
Decision.
Plan Introduction (PI), possibly changing F C using Planning.
Reactivity (RE), possibly changing reactive top-level goals F C, using
Reactivity capability.
Sensing Introduction (SI), possibly introducing new sensing actions F checking
preconditions actions already F.
Passive Observation Introduction (POI), updating KB0 recording unsolicited information coming environment, using Sensing.
Active Observation Introduction (AOI), possibly updating KB0 , recording
outcome (actively sought) sensing actions, using Sensing.
Action Execution (AE), executing types actions consequence updating
KB0 , using Actuating.
State Revision (SR), possibly revising F, using Temporal Reasoning Constraint Solving.
2.5 Cycle Selection Operators
behaviour agent given application transitions sequences, repeatedly
changing state agent. sequences determined fixed cycles behaviour, conventional agent architectures, rather reasoning cycle theories.
Cycle theories define preference policies order application transitions,
may depend environment internal state agent. rely upon
use selection operators detecting transitions enabled inputs
be, follows:
action selection inputs AE; selection operator uses Temporal Reasoning
Constraint Solving capabilities;
goal selection inputs PI; selection operator uses Temporal Reasoning
Constraint Solving capabilities;
effect selection inputs AOI; selection operator uses Identification
Effect reasoning capability;
precondition selection inputs SI; selection operator uses Identification
Preconditions, Temporal Reasoning Constraint Solving capabilities;
290

fiComputational Logic Foundations KGP Agents

provision declarative control agents form cycle theories highly
novel feature model, could, principle, imported agent systems.
concrete realisation KGP model provide paper, chosen
realise cycle theories framework logic programming priorities
constraints (see Section 3.3) use Goal Decision.
relationships capabilities, transitions selection operators
summarised Tables 2.5 2 below. Table 2.5 indicates capabilities (rows)
used transitions selection operators. Table 2 indicates selection
operators used compute possible inputs transitions cycle theory.

sensing
actuating
|=plan
|=pre
|=GD
|=react
|=T R
|=cs
|=ef f

AE
x
x

Transitions
AOI GI P OI
x
x

PI



SR

SI

Selection operators
fGS fAS fES fP

x
x

x

x
x

x
x

x
x
x

x
x

x

x
x

x

Table 1: tabular overview use capabilities transitions selection operators.
Here, |=plan , |=pre , |=GD , |=react , |=T R , |=cs |=ef f , stand for, respectively,
planning, identification preconditions, goal decision, reactivity, temporal reasoning, constraint solving identification effects (reasoning) capabilities,
fGS , fAS , fES , fP stand for, respectively, goal, action, effect precondition
selection operators.

AE
fGS
fAS
fES
fP

AOI

GI

P OI

PI
x



SR

SI

x
x
x

Table 2: tabular overview connections selection operators transitions,
required cycle theory. Here, fGS , fAS , fES , fP stand for, respectively,
goal, action, effect precondition selection operators.
provide components, though, introduce informally scenario
examples used illustrate technical details KGP agent
291

fiKakas, Mancarella, Sadri, Stathis & Toni

model throughout paper. full, formal presentation well additional
examples given throughout paper Section 10.
2.6 Examples
draw examples ubiquitous computing scenario call San
Vincenzo scenario, presented de Bruijn Stathis (2003) summarised follows.
businessman travels work purposes Italy and, order make trip easier,
carries personal communicator, namely device hybrid mobile phone
PDA. device businessmans KGP agent. agent considered
personal service agent (Mamdani, Pitt, & Stathis, 1999) (or psa short)
provides proactive information management flexible connectivity smart services
available global environment within businessman travels within.
2.6.1 Setting 1
businessmans psa requests San Vincenzo Station agent, svs, arrival time
train tr01 Rome. svs information answers
refusal. later, svs receives information arrival time tr01 train
Central Office agent, co. psa requests arrival time tr01 again, svs
accept request provide information.
first example requires one use Reactivity capability model rules interaction transition (a) achieve interaction amongst agents, (b) specify
dynamic adjustments agents behaviour changes, allowing different reactions
request, depending current situation agent. Here, interaction
form negotiation resources amongst agents, resources items information.
Thus, current situation agents amounts resources/information agents
currently own.
example requires combination transitions RE, POI, AE achieve
expected agents behaviours, follows:
1. psa makes initial request applying AE
2. svs becomes aware request performing POI (and changing KB0 accordingly)
3. svs decides reply refusal performing (and adding corresponding
action plan F)
4. svs utters refusal performing AE
5. svs becomes aware, POI, arrival time (modifying KB0 accordingly)
6. psa makes second request applying AE
7. svs decides reply requested information performing (and adding
corresponding action plan F) communicates information
performing AE.
292

fiComputational Logic Foundations KGP Agents

sequence transitions given so-called normal cycle theory
see Section 9.
2.6.2 Setting 2
preparation businessmans next trip, psa aims getting plane ticket
Madrid Denver well obtaining visa USA. One possible way buy plane
tickets internet. Buying tickets way usually possible,
destinations (depending whether airlines flying destinations sell tickets
internet not) without internet connection. psa currently
connection, information Denver indeed destination tickets
bought online. plans buy ticket internet nonetheless, conditionally,
checks conditions executing planned action. successfully buying
ticket, psa focuses second goal, obtaining visa. achieved
applying USA embassy Madrid, application requires address
USA. address obtained arranging hotel Denver.
example illustrates form partial planning adopted KGP model
(where non-executable sub-goals well actions may part plans) shows
combination transition PI SI AE allows psa agent deal partial
information, generate conditional plans plans several layers, follows:
1. psa initially equipped top-level goals get ticket Denver
obtain visa (through earlier application GI)
2. PI first goal, psa adds partial plan F, buying ticket online
subject sub-goals internet connection available online
tickets bought Denver; sub-goals sensing goals
3. SI, sensing actions added F evaluate sensing sub-goals environment
4. sensing actions executed AE (and KB0 modified accordingly)
5. depending sensed values sensing sub-goals buying action may
may executed AE; let us assume remainder example
action executed
6. SR applied eliminate actions (since already executed), subgoals top-level goal getting ticket Denver (since achieved)
7. PI remaining top-level goal obtaining visa, psa adds plan fill
application form (action) acquiring residence address Denver (sub-goal)
8. action cannot executed, psa knows businessman resident
USA; PI introduces plan sub-goal booking hotel (action)
subgoal acquiring residence address Denver
9. AE executes booking action
293

fiKakas, Mancarella, Sadri, Stathis & Toni

10. AE executes action applying visa
11. SR eliminates actions (since already executed), sub-goal toplevel goal getting visa (since achieved).

3. Background
section give necessary background reasoning capabilities cycle
theory KGP agents, namely:
Constraint Logic Programming, pervasive whole model,
Abductive Logic Programming, heart Planning, Reactivity Temporal
Reasoning capabilities,
Logic Programming Priorities, heart Goal Decision capability
Cycle Theories.
3.1 Constraint Logic Programming
Constraint Logic Programming (CLP) (Jaffar & Maher, 1994) extends logic programming
constraint predicates processed ordinary logic programming predicates,
defined rules, checked satisfiability simplified means built-in,
black-box constraint solver. predicates typically used constrain values
variables conclusion rule take (together unification
treated via equality constraint predicate). KGP model, constraints used
determine value time variables, goals actions, suitable temporal
constraint theory.
CLP framework defined structure < consisting domain D(<) set
constraint predicates includes equality, together assignment relations
D(<) constraint predicate. CLP, constraints built first-order
formulae usual way primitive constraints form c(t1 , . . . , tn ) c
constraint predicate symbol t1 , . . . , tn terms constructed domain, D(<),
values. rules constraint logic program, P , take form rules
conventional logic programming given
H L1 , . . . , Ln
H (ordinary) atom, L1 , . . . , Ln literals, n 0. Literals positive, namely
ordinary atoms, negative, namely form B, B ordinary atom,
constraint atoms <. negation symbol indicates negation failure (first
introduced Clark, 1978). variables H Li implicitly universally quantified,
scope entire rule. H called head (or conclusion) L1 , . . . , Ln called
body (or conditions) rule form above. n = 0, rule called fact.
valuation, , set variables mapping variables domain
D(<) natural extension maps terms D(<). valuation , set
variables appearing set constraints C, called <-solution C iff C, obtained
applying C, satisfied, i.e. C evaluates true given interpretation
294

fiComputational Logic Foundations KGP Agents

constraint predicates terms. denoted |=< C. set C called <-solvable
<-satisfiable, denoted |=< C, iff least one <-solution, i.e. |=< C
valuation .
One way give meaning constraint logic program P consider grounding program Herbrand base possible valuations, D(<),
constraint variables. rule, ground constraints C body evaluated true rule kept constraints C dropped, otherwise whole
rule dropped. Let ground(P ) resulting ground program. meaning P
given meaning |=LP ground(P ), many different possible
choices (Kakas, Kowalski, & Toni, 1998). resulting overall semantics constraint
logic program P referred |=LP (<) . precisely, given constraint logic
program P conjunction N C (where N conjunction non-constraint literals
C conjunction constraint atoms), remainder paper write
P |=LP (<) N C
denote exists ground substitution variables N C that:
|=< C
ground(P ) |=LP N .
3.2 Abductive Logic Programming Constraints
abductive logic program constraints tuple h<, P, A, Ii where:
< structure Section 3.1
P constraint logic program, namely set rules form
H L1 , . . . , Ln
Section 3.1
set abducible predicates language P . predicates
occurring head clause P (without loss generality, see (Kakas et al.,
1998)). Atoms whose predicate abducible referred abducible atoms
simply abducibles.
set integrity constraints, is, set sentences language P .
integrity constraints KGP model implicative form
L1 , . . . , Ln A1 . . . (n 0, > 0)
Li literals (as case rules) 2 , Aj atoms (possibly special
atom f alse). disjunction A1 . . . referred head constraint
conjunction L1 , . . . , Ln referred body. variables integrity
constraint implicitly universally quantified outside, except variables
occurring head, implicitly existentially quantified scope
head itself.
2. n = 0, L1 , . . . , Ln represents special atom true.

295

fiKakas, Mancarella, Sadri, Stathis & Toni

Given abductive logic program constraints h<, P, A, Ii formula (query)
Q, (implicitly existentially quantified) conjunction literals language
P , purpose abduction find (possibly minimal) set (ground) abducible
atoms which, together P , entails (an appropriate ground instantiation of) Q,
respect notion entailment language P equipped with,
extension P satisfies (see (Kakas et al., 1998) possible notions
integrity constraint satisfaction). Here, notion entailment combined
semantics |=LP (<) , discussed Section 3.1.
Formally, given query Q, set (possibly non-ground) abducible atoms,
set C (possibly non-ground) constraints, pair (, C) abductive answer (with
constraints) Q, respect abductive logic program constraints h<, P, A, Ii,
iff groundings variables Q, , C |=< C, holds
(i) P |=LP (<) Q,
(ii) P |=LP (<) I, i.e. B H I, P |=LP (<) B P |=LP (<) H.
Here, plays role earlier informal description abductive answer. Note
that, (ii), integrity constraints classical implications.
Note that, representing knowledge abductive logic program, one needs
decide go logic program, integrity constraints
abducibles. Intuitively, integrity constraints normative need
enforced, making sure head holds whenever body (by condition (ii)
above), whereas logic programming rules enable, help abducibles, derivation
given goals (by condition (i) above). Finally, abducibles chosen amongst literals
cannot derived means logic programming rules. paper, represent reactive constraints (that condition-action rules forcing reactive behaviour
agents) integrity constraints, thus extent addressing knowledge representation challenge posed abductive logic programming imposing sort structure
abductive logic programs use.
notion abductive answer extended take account initial set
(possibly non-ground) abducible atoms 0 initial set (possibly non-ground)
constraint atoms C0 . extension, abductive answer Q, respect
(h<, P, A, Ii, 0 , C0 )
pair (, C)
(i) 0 = {}
(ii) C C0 = {},
(iii) ( 0 , C C0 ) abductive answer Q respect h<, P, A, Ii (in
earlier sense).
worth noticing abductive answer (, C) query true respect
(h<, P, A, Ii, 0 , C0 )
296

fiComputational Logic Foundations KGP Agents

read fact abducibles 0 , along constraints
C0 C, guarantee overall consistency respect integrity constraints given
I. used specification capabilities KGP agents.
remainder paper, simplicity, omit < abductive logic
programs, written simply triples hP, A, Ii. addition, abductive logic
programs present KGP variants core event calculus (Kowalski & Sergot,
1986), define Section 5.1.1.
3.3 Logic Programming Priorities
purposes paper, logic program priorities constraint structure
<, referred , consists four parts:
(i) low-level basic part P , consisting logic program constraints; rule
P assigned name, term; e.g. one rule could
n(X, ) : p(X) q(X, ), r(Y )
name n(X, ) naming ground instance rule;
(ii) high-level part H, specifying conditional, dynamic priorities amongst rules P
H; e.g. one priority could
h(X) : m(X) n(X) c(X)
read: (some instance of) condition c(X) holds, (the corresponding instance of) rule named m(X) given higher priority (the
corresponding instance of) rule named n(X). rule named h(X);
(iii) auxiliary part A, constraint logic program defining (auxiliary) predicates
occurring conditions rules P, H conclusions rule
P H;
(iv) notion incompatibility which, purposes, assumed given
set rules defining predicate incompatible/2, e.g.
incompatible(p(X), p0 (X))
read: instance literal p(X) incompatible corresponding
instance literal p0 (X). assume incompatibility symmetric always
includes r incompatible r two rule names r, s. refer
set incompatibility rules I.
concrete LPP framework equipped notion entailment, denote |=pr , defined top underlying logic programming constraints
semantics |=LP (<) . defined differently different approaches LPP
share following pattern. Given logic program priorities = hP, H, A, Ii
conjunction ground (non-auxiliary) atoms, |=pr iff
(i) exists subset P 0 basic part P P 0 |=LP (<) ,
297

fiKakas, Mancarella, Sadri, Stathis & Toni

(ii) P 0 preferred wrt H subset P 00 P derives (under |=LP (<) )
conclusion incompatible, wrt I, .
framework way specifying meant one sub-theory P 0
preferred another sub-theory P 00 . example, existing literature (Kakas et al.,
1994; Prakken & Sartor, 1996; Kowalski & Toni, 1996; Kakas & Moraitis, 2003), |=pr
defined via argumentation. approach adopt, relying notion
admissible argument sub-theory (i) consistent (does incompatible
conclusions) (ii) whose rules lower priority, respect high-level
part H theory, sub-theory incompatible conclusions
it. precise definition sets rules compared matter
choice specific framework LPP.
Given concrete definition admissible sub-theories, preference entailment,
|=pr , given by:
(i) exists (maximal) admissible sub-theory 0 0 |=LP (<) ,
(ii) incompatible exist admissible sub-theory
00 00 |=LP (<) .
first condition satisfied say theory credulously prefers possibly prefers . conditions satisfied say
theory sceptically prefers .

4. State KGP Agents
Section define formally concept state KGP agent. introduce
notation use rest paper order refer state components.
necessary, try exemplify discussion simple examples.
4.1 Preliminaries
KGP model assume (possibly infinite) vocabularies of:
fluents, indicated f, f 0 , . . .,
action operators, indicated a, a0 , . . .,
time variables, indicated , 0 , . . .,
time constants, indicated t, t0 , . . . , 1, 2, . . ., standing natural numbers (we
often use constant indicate current time)
names agents, indicated c, c0 , . . . .
constants, ones mentioned above, normally indicated lower case
letters, e.g. r, r1 , . . .
298

fiComputational Logic Foundations KGP Agents

given constraint language, including constraint predicates <, , >, , =, 6=, respect structure < (e.g. natural numbers) equipped notion
constraint satisfaction |=< (see Section 3.1).
assume set fluents partitioned two disjoint sets:
mental fluents, intuitively representing properties agent able plan
satisfied, observed,
sensing fluents, intuitively representing properties control
agent observed sensing external environment.
example, problem f ixed resource may represent mental fluents, namely
properties (given) problem fixed (given) resource obtained, whereas request accepted connection may represent sensing fluents, namely
properties request (given) resource accepted (given)
connection active. Note important distinguish mental sensing
fluents treated differently control agent: mental fluents need
planned for, whereas sensing fluents observed. clarified later
paper.
assume set action operators partitioned three disjoint sets:
physical action operators, representing actions agent performs order
achieve specific effect, typically causes changes environment;
communication action operators, representing actions involve communications
agents;
sensing action operators, representing actions agent performs establish
whether fluent (either sensing fluent expected effect action)
holds environment, whether agent performed action.
example, sense(connection on, ) action literal representing act sensing whether network connection time , do(clear table, ) action literal representing physical action removing every item given table,
tell(c1 , c2 , request(r1 ), d, ) action literal representing communication action
expresses agent c1 requesting agent c2 resource r1 within dialogue
identifier d, time 3 .
fluent action operator associated arity: assume arity
greater equal 1, one argument (the last one, convention) always
time point given fluent holds given action takes place. time point
may time variable time constant. Given fluent f arity n > 0, refer
f (s1 , . . . , sn1 , x) f (s1 , . . . , sn1 , x), si constant x time
variable time constant (timed) fluent literals 4 . Given fluent literal `, denote `
3. role dialogue identifier become clearer Section 10. Intuitively, used link
communication actions occurring within dialogue.
4. Note represents classical negation. Negation failure occurs model within
knowledge bases agents, supporting reasoning capabilities cycle theory. negations
state understood classical negations.

299

fiKakas, Mancarella, Sadri, Stathis & Toni

complement, namely f (s1 , . . . , sn1 , x) ` f (s1 , . . . , sn1 , x), f (s1 , . . . , sn1 , x)
` f (s1 , . . . , sn1 , x). Examples fluent literals resource(pen, ), representing
certain resource pen obtained time , well (the ground)
on(box, table, 10), representing time 10 (a certain) box (a certain)
table.
Note assume fluent literals ground except time parameter.
allow us keep notation simpler highlight crucial role played
time parameter. Given simplification, often denote timed fluent literals simply
`[x].
Given action operator arity n > 0, refer a(s1 , . . . , sn1 , x), si
constant x time variable time constant, (timed) action literal. Similarly
case fluent literals, simplicity, assume timed action literals
ground except possibly time. Hence, often denote timed action literals
a[x].
adopt special syntax sensing actions, always form (x
either time variable time constant):
sense(f, x), f fluent,
sense(c : a, x), c name agent action operator.
first case, sensing action allows agent inspect external environment
order check whether fluent f holds time x sensing. second
case, sensing action allows agent determine whether, time x, another agent c
performed action a.
define formally concept state hKB0 , F, C, agent.
4.2 Forest: F
node tree F is:
either non-executable goal, namely (non-ground) timed fluent literal,
executable goal, namely (non-ground) timed action literal.
example tree F given Figure 2, p2 given problem
agent (c1 ) needs fix getting two resources r1 r2 , agent
already decided get r1 agent c2 already planned ask c2
communication action tell(c1 , c2 , request(r1 ), d, 4 ). example, San Vincenzo
scenario, p2 may transfer airport needs arranged, r1 may taxi, c2
taxi company, needed transportation train station, finally r2 may
train ticket.
Note time variable non-executable goals `[ ] actions a[ ] (any tree
in) F understood variable existentially quantified within whole state
agent. Whenever goal action introduced within state, time variable
understood distinguished, fresh variable, serving identifier.
300

fiComputational Logic Foundations KGP Agents

problem f ixed(p2, 1 )





PPP

PP


P

PP
PP

resource(r1 , 2 )

resource(r2 , 3 )

tell(c1 , c2 , request(r1 ), d, 4 )

Figure 2: example tree F
indicated Section 2, roots trees referred top-level goals, executable
goals often called simply actions, non-executable goals may top-level goals subgoals. example, Figure 2, node identifier 1 top-level goal, nodes
identifiers 2 , 3 sub-goals node identifier 4 action.
Notation 4.1 Given forest F tree F:
node n , parent(n, ), children(n, ), ancestors(n, ), siblings(n, ),
descendents(n, ), indicate parent node n , children n ,
etc. leaf (n, ) value true n leaf , false otherwise.
node n F, parent(n, F), children(n, F), ancestors(n, F), siblings(n, F),
descendents(n, F), leaf (n, F) indicate parent(n, ) tree F
n occurs, etc. (T unique, due uniqueness time variable identifying
nodes).
nodes(T ) represent set nodes , nodes(F) represent set

nodes(F) = F nodes(T ).
Again, indicated Section 2, top-level goal tree F either
reactive non-reactive. see, Section 7, reactive top-level goals introduced state transition whereas non-reactive top-level goals introduced GI transition. example, F agent c1 may consist tree
Figure 2, root non-reactive goal, well tree root reactive goal (action)
301

fiKakas, Mancarella, Sadri, Stathis & Toni

tell(c1 , c2 , accept request(r3 ), d0 , 5 ). action may reply (planned agent c1 )
request resource r3 agent c2 (for example, San Vincenzo scenario, r3
may meeting requested colleague).
Notation 4.2 Given forest F
Rootsr (F) (resp. Rootsnr (F)) denote set reactive (resp. non-reactive)
top-level goals F
nodesr (F) (resp. nodesnr (F)) denote subset nodes(F) consisting nodes
trees whose root Rootsr (F) (resp. Rootsnr (F))
r(F) (resp. nr(F)) stands reactive (resp. non-reactive) part F, namely
set trees F whose root Rootsr (F) (resp. Rootsnr (F)).
Trivially, r(F) nr(F) disjoint, F= r(F) nr(F).
4.3 Temporal Constraint Store: C
set constraint atoms, referred temporal constraints, given underlying
constraint language. Temporal constraints refer time constants well time variables
associated goals (currently previously) state.
example, given forest tree Figure 2, C may contain 1 > 10, 1 20,
indicating top-level goal (of fixing problem p2) needs achieved within time
interval (10, 20], 2 < 1 , 3 < 1 , indicating resources r1 r2 need acquired
top-level goal deemed achieved, 4 < 2 , indicating
agent needs ask agent c2 first. Note need impose 2 3
executed order, namely C may contain neither 2 < 3 , 3 < 2 .
4.4 Agents Dynamic Knowledge Base: KB0
KB0 set logic programming facts state agent, recording actions
executed (by agent others) time execution, well
properties (i.e. fluents negation) observed time
observation. Formally, facts following forms:
executed(a, t) a[t] ground action literal, meaning action
executed agent time t.
observed(`, t) `[t] ground fluent literal, meaning ` observed
hold time t.
observed(c, a[t0 ], t) c agents name, different name agent
whose state defining, t0 time constants, a[t0 ] (ground) action
literal. means given agent observed time agent c
executed action time t0 5 .
5. see that, construction, always case t0 t. Note time executed
actions, t0 , time observation, t, typically different concrete implementation
KGP model, depend, example, time execution transitions within
operational trace agent.

302

fiComputational Logic Foundations KGP Agents

Note facts KB0 variable-free, time variables occur them. Facts
first kind record actions executed agent itself. Facts
second kind record observations made agent environment, excluding actions
executed agents, represented instead facts third kind.
example, action labelled 4 Figure 2 executed (by AE transition)
time 7 executed(tell(c1 , c2 , request(r1 ), d), 7) added KB0 . Moreover, if,
time 9, c1 observes (e.g. transition POI) resource r2 , observation
observed(have resource(r2 ), 9) added KB0 . Finally, KB0 may contain
observed(c2 , tell(c2 , c1 , request(r3 ), d0 , 1), 6)
represent agent c1 become aware, time 6, agent c2 requested,
earlier time 1, resource r3 c1 .
4.5 Instantiation Time Variables:
time variable occurring non-executable goal `[ ] action a[ ] F
instantiated time constant (e.g. action execution time), actual instantiation
= recorded component state agent. example, action
labelled 4 Figure 2 executed time 7, 4 = 7 added .
use allows one record instantiation time variables
time keeping different goals fluent distinguished. Clearly, time
variable exists one equality = .
Notation 4.3 Given time variable , denote ( ) time constant t, any,
= .
worth pointing valuation temporal constraint c C always
take equalities account. Namely, ground valuation temporal
variables c must agree temporal variables assigned .
example, given = { = 3} C = {1 > }, 1 = 10 suitable valuation,
whereas 1 = 1 not.

5. Reasoning Capabilities
section, give detailed specifications various reasoning capabilities, specified within framework ordinary logic programming (for Temporal Reasoning
Identification Preconditions Effects), Abductive Logic Programming Constraints (Section 3.2, Planning Reactivity), Logic Programming Priorities
Constraints (Section 3.3, Goal Decision), constraint programming (Section 3.1,
Constraint Solving).
reasoning capabilities defined means notion entailment respect
appropriate knowledge base (and time point now, appropriate), follows:
303

fiKakas, Mancarella, Sadri, Stathis & Toni

|=T R KBT R Temporal Reasoning, KBT R constraint logic program
variant framework Event Calculus (EC) reasoning actions,
events changes (Kowalski & Sergot, 1986) 6 ;
|=now
plan KBplan Planning, KBplan abductive logic program
constraints, extending KBT R ;
|=now
react KBreact Reactivity, KBreact extension KBplan , incorporating additional integrity constraints representing reactive rules;
|=pre KBpre , KBpre logic program contained KBT R ;
|=ef f KBef f , KBef f logic program contained KBT R ;
|=now
GD KBGD , KBGD logic program priorities constraints.
constraint solving capability defined terms entailment |=cs
basically |=< defined Section 3.1.
5.1 Temporal Reasoning, Planning, Reactivity, Identification Preconditions
Effects: EC-based Capabilities
reasoning capabilities specified within framework event calculus
(EC) reasoning actions, events changes (Kowalski & Sergot, 1986). Below,
first give core EC show use define various capabilities
section.
5.1.1 Preliminaries: Core Event Calculus
nutshell, EC allows one write meta-logic programs talk objectlevel concepts fluents, events (that interpret action operators) 7 , time points.
main meta-predicates formalism are:
holds at(F, ) - fluent F holds time ;
clipped(T1 , F, T2 ) - fluent F clipped (from holding holding) times
T1 T2 ;
declipped(T1 , F, T2 ) - fluent F declipped (from holding holding)
times T1 T2 ;
initially(F ) - fluent F holds initial time, say time 0;
happens(O, ) - operation happens time ;
initiates(O, T, F ) - fluent F starts hold operation time ;
6. sophisticated, abductive logic programming version |=T R KBT R given Bracciali
Kakas (2004).
7. section use original event calculus terminology events instead operators,
rest paper.

304

fiComputational Logic Foundations KGP Agents

terminates(O, T, F ) - fluent F ceases hold operation time .
Roughly speaking, last two predicates represent cause-effects links operations fluents modelled world. use meta-predicate
precondition(O, F ) - fluent F one preconditions executability
operation O.
Fluent literals agents state mapped onto EC follows. EC-like representation fluent literal f [ ] (resp. f [ ]) agents state atom holds at(f, )
(resp. holds at(f, )). Moreover, arguments time variable need
considered, EC representation fluent literal f (x1 , . . . , xn , ) (resp. f (x1 , . . . , xn , ))
holds at(f (x1 , . . . , xn ), ) (resp. holds at(f (x1 , . . . , xn ), ). 8
Similarly, action literals state agent represented EC
straightforward way. Given action literal a[ ] EC representation happens(a, ).
arguments time considered, e.g. a(x1 , . . . , xn , ), EC representation given happens(a(x1 , . . . xn ), ).
remainder paper, abuse terminology, sometimes refer
f (x1 , . . . , xn ) f (x1 , . . . , xn ) interchangeably fluent literals fluents (although
strictly speaking fluent literals), a(x1 , . . . xn ) interchangeably action
literals action operators (although strictly speaking action literals).
EC allows one represent wide variety phenomena, including operations
indirect effects, non-deterministic operations, concurrent operations (Shanahan, 1997).
core EC use paper consists two parts: domain-independent rules
domain-dependent rules. basic domain-independent rules, directly borrowed
original EC, are:
holds at(F, T2 )
holds at(F, T2 )
holds at(F, )
holds at(F, )
clipped(T1 , F, T2 )
declipped(T1 , F, T2 )

happens(O, T1 ), initiates(O, T1 , F ),
T1 < T2 , clipped(T1 , F, T2 )
happens(O, T1 ), terminates(O, T1 , F ),
T1 < T2 , declipped(T1 , F, T2 )
initially(F ), 0 T, clipped(0, F, )
initially(F ), 0 T, declipped(0, F, )
happens(O, ), terminates(O, T, F ), T1 < T2
happens(O, ), initiates(O, T, F ), T1 < T2

domain-dependent rules define initiates, terminates, initially, e.g. case
setting 2.6.1 Section 2.6 may
initiates(tell(C, svs, inf orm(Q, I), D), T, inf o(svs, Q, I))
holds at(trustworthy(C), )
initially(have inf o(svs, arrival(tr01), I)
8. Note write holds at(f (x1 , . . . , xn ), ) instead holds at(f (x1 , . . . , xn ), ), done e.g.
Shanahan, 1997, want reason object-level properties true false
environment. use within meta-level axioms event calculus (see below) implement
persistence.

305

fiKakas, Mancarella, Sadri, Stathis & Toni

initially(trustworthy(co))
Namely, action agent C providing information concerning query Q
agent svs (the San Vincenzo station agent) initiates agent svs information
Q, provided C trustworthy. Moreover, initially agent co (the Central Office
agent) trustworthy, agent svs information arrival time tr01.
conditions rule defining initiates seen preconditions effects
operator tell take place. Preconditions executability operators specified
means set rules (facts) defining predicate precondition, e.g.
precondition(tell(svs, C, inf orm(Q, I), D), inf o(svs, Q, I))
namely precondition agent svs inform agent C Q svs indeed
information Q.
Notice presence language fluents negation, e.g. f f ,
poses problem inconsistencies, i.e. may case holds at(f, t)
holds at(f, t) derived axioms set events (i.e. given set
happens atoms). However, easily shown never case, provided
domain-dependent part contain two conflicting statements form
initially(f ) initially(f ) since inconsistencies cannot caused except initial
time point (see e.g. Miller & Shanahan, 2002, p. 459).
remainder paper assume domain-dependent part always
consistent agents.
allow agents draw conclusions contents KB0 , represents
narrative part agents knowledge, add domain-independent rules
following bridge rules:
holds at(F, T2 )
holds at(F, T2 )
happens(O, )
happens(O, )

observed(F, T1 ), T1 T2 , clipped(T1 , F, T2 )
observed(F, T1 ), T1 T2 , declipped(T1 , F, T2 )
executed(O, )
observed( , O[T ], )

Notice bridge rules make explicit translation state representation
EC representation fluents actions mentioned earlier section.
Note assume fluent holds time observed hold.
choice dictated rationale observations considered reasoned
upon moment agent makes them. hand, actions agents
effect time executed 9 .
introduced ability reason narratives events observations,
need face problem inconsistency due conflicting observations, e.g. agent
may observe fluent negation hold time. done
9. time action unknown observation time, last rule may replaced
happens(O, ) observed( , O[ ], )
namely value fluent changed according observations moment observations
made.

306

fiComputational Logic Foundations KGP Agents

set initially atoms, assume external world consistent
too, i.e. never happen observed(f, t) observed(f, t) belong KB0 ,
fluent f time point t.
However, still need cope frame consistency problem, arises, e.g.
given observations observed(f, t) observed(f, t0 ), 6= t0 . issue analogous
case two different events happen time point initiate
terminate fluent. original EC suitable axioms predicates clipped
declipped added, given above, avoid fluent negation holding
time happening two events time. adopt
similar solution cope observations, namely adding following two axioms
domain-independent part:
clipped(T1 , F, T2 )
declipped(T1 , F, T2 )

observed(F, ), T1 < T2
observed(F, ), T1 < T2

solution may naive circumstances sophisticated solutions may
adopted, e.g. one proposed Bracciali Kakas (2004).
5.1.2 Temporal Reasoning
temporal reasoning capability invoked components KGP model
(namely Goal Decision capability, State Revision transition selection operators, see Section 7) prove disprove given (possibly temporally
constrained) fluent literal holds, respect given theory KBT R . purposes
paper KBT R EC theory composed domain-independent domaindependent parts given Section 5.1.1, narrative part given KB0 . Then,
given state S, fluent literal `[ ] possibly empty set 10 temporal constraints C,
temporal reasoning capability |=T R defined
|=T R `[ ] C iff KBT R |=LP (<) holds at(`, ) C.
example, given EC formulation Section 5.1.1 setting 2.6.1 Section 2.6,
state = hKB0 , F, C, agent svs contains
KB0 = {observed(co, tell(co, svs, inf orm(arrival(tr01), 18), d, 15), 17)},
|=T R inf o(svs, arrival(tr01), 18, ) > 20.
5.1.3 Planning
number abductive variants EC proposed literature deal
planning problems, e.g. one proposed Shanahan, 1989. Here, propose novel
variant, somewhat inspired E-language (Kakas & Miller, 1997), allow situated
agents generate partial plans dynamic environment.
refer KBplan = hPplan , Aplan , Iplan abductive logic program where:
10. remainder paper sets seen conjunctions, appropriate.

307

fiKakas, Mancarella, Sadri, Stathis & Toni

Aplan = {assume holds, assume happens}, namely consider two abducible predicates, corresponding assuming fluent holds action occurs, respectively, certain time point;
Pplan obtained adding core EC axioms narrative given KB0
following rules
happens(O, ) assume happens(O, )
holds at(F, ) assume holds(F, )
Iplan contains following set integrity constraints
holds at(F, ), holds at(F, ) f alse
assume happens(O, ), precondition(O, P ) holds at(P, )
assume happens(O, ), executed(O, ), time now(T 0 ) > 0
integrity constraints Iplan prevent generation (partial) plans
unfeasible. first integrity constraint makes sure plan generated entails
fluent negation hold time. second integrity constraint makes
sure that, plan requires action occur certain time point, goal
enforcing preconditions action hold time point taken account
plan. means that, preconditions already known hold,
plan need accommodate actions guarantee hold time
execution action. Finally, last integrity constraint forces assumed unexecuted
actions plan executable future, predicate time now( ) meant
return current time.
worth recalling that, concrete situations, Pplan Iplan contain domaindependent rules constraints. Domain-dependent rules may needed define
initiates, terminates, initially precondition, may contain additional
rules/integrity constraints expressing ramifications, e.g.
holds at(f, ) holds at(f1 , ) . . . holds at(fn , )
specific fluents domain. Moreover, integrity constraints may represent
specific properties actions fluents domain. example, domain-dependent
constraint could express two actions type cannot executed time,
e.g.
holds at(tell(c, X, accept request(R), D), ),
holds at(tell(c, X, ref use request(R), D), ) f alse
Intuitively, constructing (partial) plan goal (that given leaf node
current forest) amounts identifying actions sub-goals allowing achieve
goal, assuming nodes forest, executable non-executable,
feasible. Concretely, abductive logic program KBplan supports partial planning
follows. Whenever plan given goal requires agent execute action, a[ ] say,
corresponding atom assume happens(a, ) assumed, amounts intending
execute action (at concrete time instantiating ). hand,
plan given goal requires plan sub-goal, `[ ] say, corresponding atom
assume holds(`, ) may assumed, amounts setting requirement
planning needed sub-goal itself. Notice total plans taken
account, atoms form assume holds( , ) ever generated.
308

fiComputational Logic Foundations KGP Agents

KB
Formally, let KBplan
plan {time now(now)}, time constant (intuitively, time planning capability invoked). Then, planning capability
11 .
|=now
plan specified follows

Let = hKB0 , F, C, state, G = `[ ] mental goal labeling leaf node
tree F. Let
CA = {assume happens(a, 0 ) | a[ 0 ] nodes(F)},
CG = {assume holds(`0 , 0 ) | `0 [ 0 ] nodes(F) \ {`[ ]}}

0 = CA CG
C0 = C .
Then,
S, G |=now
plan (Xs , C)
iff
Xs = {a[ 0 ] | assume happens(a, 0 ) } {`0 [ 0 ] | assume holds(`0 , 0 ) }
, , C ).
(, C) abductive answer holds at(`, ), wrt (KBplan
0
0
abductive answer exists, S, G |=now
,



used


indicate
failure
plan
(i.e. abductive answer exists).

example, consider setting 2.6.2 Section 2.6. domain-dependent part
KBplan agent psa (looking businessman scenario) contains
initiates(buy ticket online(F rom, o), T, ticket(F rom, o))
precondition(buy ticket online(F rom, o), available connection)
precondition(buy ticket online(F rom, o), available destination(T o))
goal G ticket(madrid, denver, ). Assume F consists single tree
consisting solely root G, thus CA = CG = {}. Then, S, G |=now
plan (Xs , C)
Xs = {buy ticket online(madrid, denver, 0 ),
available connection( 00 ), available destination(denver, 000 )}
C = { 0 < , 0 = 00 = 000 , 0 > now}.
5.1.4 Reactivity
capability supports reasoning reacting stimuli external environment
well decisions taken planning.
knowledge base KBreact supporting reactivity adopt extension knowledge
base KBplan follows. KBreact = hPreact , Areact , Ireact
Preact = Pplan
11. simplicity present case planning single goals only.

309

fiKakas, Mancarella, Sadri, Stathis & Toni

Areact = Aplan
Ireact = Iplan RR
RR set reactive constraints, form
Body Reaction, C

Reaction either assume holds(`, ), `[T ] timed fluent literal,
assume happens(a, ), a[T ] timed action literal, 12
Body non-empty conjunction items form (where `[X] timed fluent
literal a[X] timed action literal, X):
(i) observed(`, 0 ),
(ii) observed(c, a[T 0 ], 00 ),
(iii) executed(a, 0 ),
(iv) holds at(`, 0 ),
(v) assume holds(`, 0 ),
(vi) happens(a, 0 ),
(vii) assume happens(a, 0 ),
(viii) temporal constraints (some of) T, 0 , 00
contains least one item one (i), (ii) (iii).
C temporal constraints (some of) T, 0 , 00 .
integrity constraints abductive logic programming, variables Body
implicitly universally quantified whole reactive constraint, variables
Reaction, C occurring Body implicitly existentially quantified righthand
side reactive constraint. 13
Notice Body must contain least trigger, i.e. condition evaluated
KB0 . Intuitively, reactive constraint Body Reaction, C interpreted
follows: (some instantiation of) observations Body hold KB0 (some
corresponding instantiation of) remaining conditions Body hold, (the appropriate instantiation of) Reaction, associated (the appropriate instantiation of)
12. below, abuse notation, use notions timed fluent action literals liberally
allow non-ground, even though defined timed fluent action literals ground
except possibly time parameter.
13. Strictly speaking, syntactically reactive constraints integrity constraints (due presence
conjunction, represented ,, rather disjunction head). However, reactive constraint
Body Reaction, C transformed integrity constraint Body N ew new clause
N ew Reaction, C Preact . Thus, abuse notation, treat reactive constraints
integrity constraints.

310

fiComputational Logic Foundations KGP Agents

temporal constraints C, added F C, respectively. Notice Reaction
abducible planning performed reactivity capability.
theory KB
Formally, let KBreact
react {time now(now)}, time
constant (intuitively, time capability invoked). Then, reactivity capability |=now
react specified follows. Let = hKB0 , F, C, state. Let

CA = {assume happens(a, ) | a[ ] nodesnr (F)},
CG = {assume holds(`, ) | `[ ] nodesnr (F)}

0 = CA CG
C0 = C .
Then,
|=now
react (Xs , C)
iff
Xs = {a[ ] | assume happens(a, ) } {`[ ] | assume holds(`, ) }
, , C ).
(, C) abductive answer query true wrt (KBreact
0
0

abductive answer exists, |=react , used indicate failure
(i.e. abductive answer exists).

example, consider setting 2.6.1 Section 2.6, KBplan given Sections 5.1.1
5.1.3. Let RR agent svs consist of:
observed(C, tell(C, svs, request(Q), D, 0), ), holds at(have inf o(svs, Q, I), )
assume happens(tell(svs, C, inf orm(Q, I), D), 0 ), 0 >
observed(C, tell(C, svs, request(Q), D, 0), ), holds at(no inf o(svs, Q), )
assume happens(tell(svs, C, ref use(Q), D), 0 ), 0 >
Then, given = 30 = hKB0 , F, C,
KB0 = {observed(co, tell(co, svs, inf orm(arrival(tr01), 18), d1, 15), 17),
observed(psa, tell(psa, svs, request(arrival(tr01)), d2, 20), 22)}
obtain
|=now
react ({tell(svs, psa, inf orm(arrival(tr01), 18), d2, )}, > 30).
5.1.5 Identification Preconditions
capability used KGP agents determine preconditions executability
actions planned for. preconditions defined domain-dependent
part EC means set rules form precondition(O, F ), representing
fluent F precondition executability action action operator (see
5.1.1). Let KBpre subset KBT R containing rules defining precondition( , ).
311

fiKakas, Mancarella, Sadri, Stathis & Toni

identification preconditions capability |=pre specified follows. Given state
= hKB0 , F, C, timed action literal a[ ]
S, a[ ] |=pre Cs
iff
Cs =

V

{`[ ] | KBpre |=LP precondition(a, `)}14 .

5.1.6 Identification Effects
capability used KGP agents determine effects actions already
executed, order check whether actions successful. Note
actions may unsuccessful could executed, executed
expected effect. possible situations agent
full knowledge environment situated.
effects defined domain-dependent part EC means set
rules defining predicates initiates terminates. Let KBef f theory consisting
domain-dependent domain-independent parts EC, well narrative
part KB0 . Then, identification effects |=ef f specified follows. Given state
= hKB0 , F, C, action operator a[t],
S, a[t] |=ef f `
iff
` = f KBef f |=LP initiates(a, t, f )
` = f KBef f |=LP terminates(a, t, f )
5.2 Constraint Solving
Constraint Solving capability simply defined terms structure <
|=< notion presented Section 3.1. Namely, given state = hKB0 , F, C,
set constraints C:
|=cs C iff |=< C C;
exists total valuation S, |=cs C iff exists total valuation
|=< C C.
5.3 Goal Decision
Goal Decision reasoning capability allows agent decide, given time point,
(non-reactive) top-level goals pursued, go generate
plans aiming achieving them. generated goals goals current preferred
interest interest may change time.
14. assume

V

{} = true.

312

fiComputational Logic Foundations KGP Agents

Goal Decision capability operates according theory, KBGD , agent
represents goal preference policy. KBGD includes KBT R thus dynamic, observed
knowledge, KB0 , current state agent. KBGD expressed variant LPP
described Section 3.3, whereby rules lower basic part P LPP theory
form (T possibly empty sequence variables):
n(, ) : G[, ] B[T ], C[T ]

time variable, existentially quantified scope head rule
member ;
variables except universally quantified scope rule;
head G[, ] rule consists fluent literal conjoined (possibly
empty) set temporal constraints, represented h`[ ], C[, ]i;
B(T ) non-empty conjunction literals set auxiliary predicates
include atoms form holds at(`, 0 ), `[T 0 ] timed fluent literal,
atom time now(T 00 ) variables 0 , 00 ;
conditions rule constrained (possibly empty) temporal constraints
C[T ].
rule represents ground instances total valuation
variables satisfies constraints C[T ]. ground instance named
corresponding ground instance n(, ). Intuitively, conditions one rule
satisfied time grounds variable 00 current time
capability applied, goal head rule sanctioned one goals
agent would possibly prefer achieve time. decision whether
goal indeed preferred would depend high-level strategy part H KBGD ,
containing priority rules, described Section 3.3, rules lower-part
rules H. priority rules include temporal atoms form
holds at(`, 0 ) atom time now(T 00 ) conditions.
accommodate form rules need extend notion incompatibility
defined conclusions h`( ), C[, ]i. simplify notation,
remainder often write h`( ), Ci instead h`( ), C[, ]i.
incompatibility defined different ways. example, (relatively) weak
notion incompatibility given follows. Two pairs h`1 (1 ), C1 h`2 (2 ), C2
incompatible iff every valuation C1 C2 satisfied, ground
instances `1 (1 ) `2 (2 ) incompatible. stronger notion would require
sufficient one valuation exist makes corresponding ground
literals incompatible.
theory KB
Let us denote KBGD
GD {time now(now)}, time
constant. Then, goal decision capability, |=now
GD , defined directly terms
preference entailment, |=pr , LPP (see Section 3.3), follows.
Given state = hKB0 , F, C, i,
|=now
GD Gs
313

fiKakas, Mancarella, Sadri, Stathis & Toni


Gs = {G1 , G2 , . . . , Gn }, n 0, Gi = h`i (i ), Ci = 1, . . . , n
iff Gs maximal set

KBGD
|=pr h`1 (1 ), C1 . . . h`n (n ), Cn i.

means new set goals Gs generated currently (sceptically) preferred
goal preference policy represented KBGD current information KB0 .
Note two goals Gs necessarily compatible other. two
special cases sceptically preferred goals time now. first one
concerns case goals currently sanctioned (lower-part)
KBGD . |=now
GD returns empty set goals (n = 0). second special
case occurs least two goals separately credulously preferred
goals incompatible other. |=now
GD , used
indicate failure identifying new goals pursued.
example, consider San Vincenzo scenario psa agent needs decide whether return home recharge battery. agents goals categorised
assigned priority according category possibly factors. KBGD
expressing given follows:
low-level part contains rules:

n(rh, 1 ) : hreturn home(1 ), {1 < 0 }i
holds at(f inished work, ),
holds at(at home, ),
time now(T ),
T0 = + 6
n(rb, 2 ) : hrecharge battery(2 ), {2 < 0 }i
holds at(low battery, ),
time now(T ),
T0 = + 2
auxiliary part contains, addition KBT R KB0 , following rules
specify category goal relative urgency categories:

typeof (return home, required)
typeof (recharge battery, operational)
urgent wrt type(operational, required)

314

fiComputational Logic Foundations KGP Agents

incompatibility part consists
incompatible(return home(T ), recharge battery(T ))
Namely, two goals pairwise incompatible, i.e. agent one
goals time.
high-level part contains following priority rule:

gd pref (X, ) : n(X, ) n(Y, ) typeof (X, XT ),
typeof (Y, ),
urgent wrt type(XT, ).
Then, = 1 current state = hKB0 , F, C, finished work
away home hold (by temporal reasoning) time now,
|=now
GD {hreturn home(1 ), {1 < 7}i}.
Suppose instead KB0 contains observed(low battery, 1). Then, using weak
notion incompatibility, requiring
every |=cs {1 < 7, 2 < 3}
holds incompatible(return home(1 ), recharge battery(2 ))
have:
|=now
GD {hreturn home(1 ), {1 < 7}i, hrecharge battery(2 ), {2 < 3}i}.
Indeed, = {1 = 3, 2 = 2}, incompatible(return home(3), recharge battery(2))
hold. However, using stronger notion incompatibility, requiring
exists |=cs {1 < 7, 2 < 3}
holds incompatible(return home(1 ), recharge battery(2 ))
have:
|=now
GD {hrecharge battery(2 ), {2 < 3}i}.
Suppose KBGD contains second operational goal hreplace part(3 ), {3 < 5}i
sanctioned rule lower part time = 1. stronger
form incompatibility goal decision capability = 1 return
operational goals credulously preferred none sceptically preferred.
315

fiKakas, Mancarella, Sadri, Stathis & Toni

6. Physical Capabilities
addition reasoning capabilities defined far, agent equipped
physical capabilities allow experience world situated; world
consists agents and/or objects provide environment agents
interact communicate.
identify two types physical capabilities: sensing actuating. representing
capabilities abstract away sensors actuators agent would
typically rely upon access affect environment. assume
sensors actuators part agents body, classify implementation
issue (Stathis et al., 2004).
physical sensing capability models way agent interacts external
environment order inspect it, e.g. find whether fluent holds
given time. hand, physical actuating capability models way
agent interacts external environment order affect it, physically executing
actions.
represent sensing physical capability agent function form:
sensing(L, t) = L0
where:
L (possibly empty) set
fluent literals f ,
terms form c : (meaning agent c performed action a),
sensed concrete time t,
L0 (possibly empty) set elements s0
s0 term f : v, f fluent v {true, f alse}, meaning fluent f
observed value v (namely true f alse) time t,

s0 term form c : a[t0 ], c agent name action,
meaning agent c performed action time t0 .
Note physical sensing requires time-stamp specify time
applied within transitions. Note that, given non-empty set L, sensing(L, t) may
partial, e.g. fluent f L, neither f : true L0 , f : f alse L0 .
Similarly, represent physical actuating capability function
actuating(As, t) = As0
where:
set action literals {a1 , , }, n > 0, agent instructs body
actuate time t;
316

fiComputational Logic Foundations KGP Agents

As0 subset actions body actually managed perform.
meaning action belonging belonging As0 physical
actuators agents body able perform current situation. worth
pointing action belongs As0 necessarily mean effects
successfully reached. Indeed, preconditions executed
action (i) may wrongly believed agent true execution time (as
agents may interfered them) (ii) agent may unaware
preconditions. example, confirmed availability, agent may
booked hotel sending e-mail, (i) agent booked last available
room meanwhile, (ii) agent provide credit card number secure
booking. words, beliefs agent (as held KB0 ) may incorrect and/or
incomplete.
Section 7 Section 8 below, see AOI (Active Observation Introduction)
used check effects actions (identified fES effect selection operator,
turn using |=ef f reasoning capability) actions executed. Moreover, SI
(Sensing Introduction) used check preconditions actions (identified fP
precondition selection operator, turn using |=pre reasoning capability)
executed, make sure actions indeed executable. Overall, following
cases may occur:
action belongs As0 executed
preconditions held time execution effects hold environment execution;
preconditions wrongly believed hold time execution (because
agent partial knowledge environment KBplan incorrect)
consequence effects hold execution;
preconditions known hold time execution (e.g.
agent observed planned hold,
time -replan) consequence effects hold execution;
action belongs \ As0 executed (the body could execute
it).
actuating physical capability check preconditions/effects: left
capabilities called within transitions and/or transition invoking
actuating, show below. before, way body carry actions
implementation issue (Stathis et al., 2004).

7. Transitions
KGP model relies upon state transitions GI, PI, RE, SI, POI, AOI, AE, SR, defined
using following representation
(T)

hKB0 , F, C,
X

0
0
0
0
hKB0 , F , C ,
317

fiKakas, Mancarella, Sadri, Stathis & Toni

name transition, hKB0 , F, C, agents state transition applied, X input transition, time application
transition, hKB00 , F 0 , C 0 , 0 revised state, resulting application transition input X time state hKB0 , F, C, i. Please note transitions
modify components state. Also, transitions (namely GI,
RE, POI, SR) input X always empty omitted. transitions
(namely PI, SI, AOI, AE) input always non-empty (see Section 9) selected
appropriate selection operator (see Section 8).
define transition formally, defining hKB00 , F 0 , C 0 , 0 i. Note
assume transition takes care possible renaming time variables output
capabilities (if capability used transition), order guarantee
goal/action forest univocally identified time variable.
7.1 Goal Introduction
transition takes empty input. calls Goal Decision capability determine
new (non-reactive) top-level goals agent. capability returns set goals,
means circumstances possibly changed preferred top-level goals
agent transition reflect changing forest new state
consist one tree new (non-reactive) goal. hand, Goal Decision
capability return (non-reactive) goals (namely returns ) state left
unchanged, as, although goals current state longer sceptically preferred
may still credulously preferred and, since others replace them,
agent carry current plans achieve them.
(GI)

hKB0 , F, C,

hKB0 , F 0 , C 0 ,

where, given = hKB0 , F, C,
(i) |=now
GD ,
F0 = F
C0 = C
(ii) otherwise, |=now
GD Gs Gs 6= ,
F 0 defined follows:
nr(F 0 ) = {Tg[ ] | hg[ ], Gs} Tg[ ] tree consisting solely
root g[ ]
r(F 0 ) = {}
C 0 = {T C | h , Ci Gs}
transition drops (top-level) goals become semantically irrelevant (due
changed circumstances agent changes environment), replaces
new relevant goals. see, Section 7.8, goals dropped
318

fiComputational Logic Foundations KGP Agents

book-keeping activities State Revision (SR) transition, transition
never add set goals.
Note that, GI replace whole forest old state new forest,
possible agent looses valuable information achieving goals,
one new preferred goals agent (or equivalent to) current goal.
effect though minimized calling (in cycle theory) GI transition
certain times, e.g. current goals achieved timed-out. Alternatively,
earlier formalisation GI transition could modified that, case (ii),
goals Gs already occur (modulo temporal variables associated temporal
constraints) roots (non-reactive) trees F, trees kept F 0 . simple way
characterise (some of) goals follows. Let

Xs = {hg[ ], C, = 0 |

hg[ ], Ci Gs,
g[ 0 ] Rootsnr (F)
|=cs C iff |=cs (C C { = 0 })}

Gs0 = {hg[ ], Ci |

hg[ ], C, = 0 Xs}

new constraints goals Gs0 equivalent old constraints C. example,
Gs may contain
G = hhave ticket(madrid, denver, 2 ), {2 < 12}i
ticket(madrid, denver, 1 ) Rootsnr (F) C = {1 < 12}.
Then, G definitely belongs Gs0 . Let
newC =

[

C { = 0 }.

h ,T C, = 0 iXs

Case (ii) redefined follows, using definitions Xs, Gs0 newC:
(ii0 ) otherwise, |=now
GD Gs Gs 6= , then, case |=cs C newC,
F 0 C 0 defined earlier case (ii), otherwise (if |=cs C newC):
F 0 defined follows:
nr(F 0 ) = {Tg[ ] | hg[ ], Gs \ Gs0 } F(Xs)
Tg[ ] tree consisting solely root g[ ]
F(Xs) set trees F roots goals form g[ 0 ]
hg[ ], , = 0 Xs
r(F 0 ) = {}
C 0 = C {T C | h , Ci Gs \ Gs0 } newC.
Note keep temporal constraints state, prior application GI,
force variables new goals remain state GI rewritten
using old identifiers goals.
319

fiKakas, Mancarella, Sadri, Stathis & Toni

7.2 Reactivity
transition takes empty input. calls Reactivity capability order determine
new top-level reactive goals state (if any), leaving non-reactive part unchanged.
new reactive goals exist, reactive part new state empty.
hKB0 , F, C,

hKB0 , F 0 , C 0 ,

(RE)
where, given = hKB0 , F, C, i:
(i) |=now
react ,
F 0 defined follows:
r(F 0 ) = {}
nr(F 0 ) = nr(F)
C0 = C

(ii) otherwise, |=now
react (X s, C),
F 0 defined follows:
nr(F 0 ) = nr(F)
r(F 0 ) = {Tx[ ] | x[ ] X s}
Tx[ ] tree consisting solely root x[ ]
C0 = C C
Note asymmetry case (ii) GI case (ii) RE, GI
eliminates reactive goals case, whereas leaves non-reactive goals unchanged.
Indeed, reactive goals may due choice specific non-reactive goals,
latter change former need re-evaluated. Instead, non-reactive goals affected
newly acquired reactive goals (that outcome enforcing reactive rules).
Note case (ii), similarly GI, replaces whole (reactive) forest
old state new (reactive) forest, possible agent loses valuable
information achieving reactive goals, one new reactive goals
(or equivalent to) current goal. variant case (ii) RE, mirroring
variant given earlier GI using |=cs well, defined avoid problem.
7.3 Plan Introduction
transition takes input non-executable goal state (that selected
goal selection operator, see Section 8) produces new state calling agents
Planning capability, selected goal mental goal, simply introducing new
sensing action, goal sensing goal.
(PI)

hKB0 , F, C,
G

0
0
hKB0 , F , C ,

G input goal (selected planning tree F, thus leaf, see
Section 8)
320

fiComputational Logic Foundations KGP Agents

F 0 = (F \ {T | G leaf }) N ew
C0 = C C
N ew C obtained follows, hKB0 , F, C, i.
(i) G mental goal: let S, G |=now
plan P . Then,
either P =
N ew = {T } C = {},
P = (X s, C)
N ew = {T 0 } 0 obtained adding element X
child G.
(ii) G = `[ ] sensing goal, child goal G0 :
N ew = {T 0 } 0 (a node labelled by) sense(`, 0 ) new child G0
(here 0 new time variable)
C = { 0 }.
(iii) G = `[ ] sensing goal, root :
N ew = {T , 0 } 0 tree consisting solely root (labelled by) sense(`, 0 )
(here 0 new time variable)
C = { 0 }.
7.4 Sensing Introduction
transition takes input set fluent literals preconditions actions
state produces new state adding sensing actions leaves (appropriate)
trees forest component. Note that, SI invoked, input fluent literals
selected precondition selection operator, chosen amongst preconditions
actions already known true (see Section 8).
(SI)

hKB0 , F, C,
SP

0
0
hKB0 , F , C ,

SP non-empty set preconditions actions (in form pairs precondition,
action) trees F, where, given that:
- N ew = {h`[ ], A, sense(`, 0 )i | h`[ ], Ai SP 0 fresh variable}
- addSibling(T , A, SA) denotes tree obtained adding elements SA new
siblings tree leaf (A, )

F 0 = F \ {T | leaf (A, ) h`[ ], Ai SP s}
{addSibling(T , A, SA) | leaf (A, )
SA = {sense(`, 0 )|h`[ ], A, sense(`[ 0 ])i N ew}}
C 0 = C { 0 < | h`[ ], , sense(`[ 0 ])i N ew}
321

fiKakas, Mancarella, Sadri, Stathis & Toni

Basically, fluent literal selected precondition selection operator
precondition action A, new sensing action added sibling A,
constraint expressing sensing action must performed added
current set temporal constraints.
7.5 Passive Observation Introduction
transition updates KB0 adding new observed facts reflecting changes environment. observations deliberately made agent, rather,
forced upon agent environment. observations may properties
form positive negative fluents (for example battery running out) actions
performed agents (for example messages addressed agent).
hKB0 , F, C,

hKB00 , F, C,

(POI)
where, sensing(, now) = L,
KB00 = KB0

{observed(f, now) | f : true L}
{observed(f, now) | f : f alse L}
{observed(c, a[t], now) | c : a[t] L}.
7.6 Active Observation Introduction
transition updates KB0 adding new facts deliberately observed agent,
seeks establish whether given fluents hold given time. fluents
selected effect selection operator (see Section 8) given input transition.
Whereas POI decided agent (the agent interrupted forced
observation environment), AOI deliberate. Moreover, POI may observe fluents
actions, whereas AOI considers fluents (that effects actions executed
agent, see Section 8 Section 9).
(AOI)

hKB0 , F, C,
SF

0
hKB0 , F, C,

SF = {f1 , . . . , fn }, n > 0, set fluents selected actively sensed (by
effect selection operator), and, sensing(SF s, now) = L,
KB00 = KB0
{observed(f, now) | f : true L}
{observed(f, now) | f : f alse L}.
7.7 Action Execution
transition updates KB0 , recording execution actions agent. actions
executed selected action selection operator (see Section 8) prior
transition, given input transition.
322

fiComputational Logic Foundations KGP Agents

(AE)

hKB0 , F, C,
SAs

hKB00 , F, C, 0

SAs non-empty set actions selected execution (by action selection
operator),
let subset non-sensing actions SAs subset sensing
actions SAs;
let sensing(S 0 , now) = L0 , 0 = {f | sense(f, ) S}
let sensing(S 00 , now) = L00 , 00 = {c : | sense(c : a, ) S}
let actuating(A0 , now) = A00 , A0 = {a | a[ ] A}.
Then:
KB00 = KB0
{executed(a, now) | A00 }
{observed(f, now) | f : true L0 }
{observed(f, now) | f : f alse L0 }
{observed(c, a[t], now) | c : a[t] L00
|=cs C = sense(c : a, ) S}

0 = { = | a[ ] SAs A00 }
{ = | sense(f, ) SAs (f : ) L0 }
{ = | c : a[t] L00 |=cs C = sense(c : a, ) S}.
7.8 State Revision
SR transition revises state removing timed-out goals actions goals
actions become obsolete one ancestors already believed
achieved. make use following terminology.
Notation 7.1 Given state S, timed fluent literal `[ ], timed fluent literal action
operator x[ ], time-point now:
achieved(S, `[ ], now) stands
exists total valuation S, |=cs |=T R `[ ]
timed out(S, x[ ], now) stands
exists total valuation S, |=cs > now.
323

fiKakas, Mancarella, Sadri, Stathis & Toni

Then, specification transition follows.
(SR)

hKB0 , F, C,

hKB0 , F 0 , C,

F 0 set trees F pruned nodes(F 0 ) biggest subset
nodes(F) consisting goals/actions x[ ] tree F (here =
hKB0 , F, C, i):
(i) timed out(S, x[ ], now),
(ii) x action operator, case executed(x, t) KB0 ( = t) ,

(iii) x fluent literal, achieved(S, x[ ], now),
(iv) every y[ 0 ] siblings(x[ ], F)
either y[ 0 ] siblings(x[ ], F 0 ),
y[ 0 ] 6 siblings(x[ ], F 0 )
fluent literal achieved(S, y[ 0 ], now),
action literal executed(y, t) KB0 0 = ,

(v) x sensing action operator, x[ ] = sense(`, ),
either exists a[ 0 ] siblings(x[ ], F 0 ) ` precondition (i.e.
S, a[ 0 ] |=pre Cs `[ 0 ] Cs) < 0 C,
exists `[ 0 ] siblings(x[ ], F 0 ) ` sensing fluent <
0 C,
(vi) x[ ] top-level goal parent(x[ ], F) = P P nodes(F 0 ).
conditions specify SR keeps trees forest state. Intuitively, conditions may understood terms prevent remaining
trees:
condition (i) removes timed-out goals actions,
condition (ii) removes actions already executed,
condition (iii) removes goals already achieved,
condition (iv) removes goals actions whose siblings already timed
thus deleted, condition (i),
condition (v) removes sensing actions preconditions actions
deleted sensing goals deleted,
condition (vi) recursively removes actions goals whose ancestors removed.
following example illustrates SR used provide adjustment agents
goals plans light newly acquired information.
324

fiComputational Logic Foundations KGP Agents

7.9 Setting 3
agent psa goal museum ticket (state-run) museum
businessman wants visit, plan buy ticket. executing plan psa
observes European Heritage day (ehd short), via appropriate message
another agent mus (representing museum), stating state-run museums
Europe give free tickets anybody walking day. Then, psas goal
already achieved goal plan deleted state.
Let agents initial state hKB0 , F, C, with:
= { } = KB0
F

= {T }

C = {1 10, 2 = 3 , 3 < 1 }
consists top-level goal g1 = have(ticket, 1 ), two children,
g2 = money(2 ) a1 = buy(ticket, 3 ),

15

assuming KBT R contains
initiates(ehd, T, have(ticket))
initiates(buy(O), T, have(O))
precondition(buy(O), money).
remaining knowledge bases play useful role purposes
example, therefore considered empty. message museum
agent mus added KB0 via POI, e.g. time 6, following form:
observed(mus, ehd(5), 6)
i.e. time 6 observed time 5 mus announced state-run museums
Europe free day. Then, via SR, time 8 say, g1 , g2 a1 eliminated
F, g1 already achieved.

8. Selection Operators
KGP model relies upon selection operators:
fGS (goal selection, used provide input PI transition);
fP (precondition selection, used provide input SI transition);
fES (effect selection, used provide input AOI transition);
fAS (action selection, used provide input AE transition).
15. g1 a1 reactive not, matter example.

325

fiKakas, Mancarella, Sadri, Stathis & Toni

Selection operators defined terms (some the) capabilities (namely Temporal
Reasoning, Identification Preconditions Effects Constraint Solving).
high-level description, selection operators seen returning set
items given initial set satisfy certain number conditions. example,
given state hKB0 , F, C, i, goal selection operator returns set non-executable
goals trees F satisfy conditions; precondition selection operator returns
set pairs, consisting (i) timed fluent literal precondition
action tree F (ii) action, satisfying conditions; effect
selection operator returns set fluent literals effects actions already
executed (as recorded KB0 ) satisfy conditions; action selection operator
returns set actions trees F satisfy conditions.
selection operators formally defined below.
8.1 Goal Selection
Informally, set conditions goal selection operator follows. Given state
= hKB0 , F, C, time-point t, set goals selected fGS singleton set
consisting non-executable goal G tree F time t:
1. G timed out,
2. ancestor G timed out,
3. child ancestor G timed out,
4. neither G, ancestor G tree F already achieved.
5. G leaf
Intuitively, condition 1 ensures G already timed-out, conditions 2-3 impose
G belongs still feasible plan top-level goal F, condition 4 makes
sure considering G wasteful.
Note that, already mentioned Section 5.1.3, simplicity select single goal.
Formally, given state = hKB0 , F, C, time-point t, let G(S, t) set
non-executable goals `[ ] nodes(F) that:
1. timed out(S, `[ ], t)
2. timed out(S, G, t) G ancestors(`[ ], F),
3. timed out(S, X, t) X nodes(F) X child P
ancestors(`[ ], F)
4. achieved(S, G, t) G {`[ ]} ancestors(`[ ], F)
5. leaf (G, F)
Then, G(S, t) 6= {}:
fGS (S, t) = {G} G G(S, t).
Otherwise, fGS (S, t) = {}.
326

fiComputational Logic Foundations KGP Agents

8.2 Effect Selection
Informally, set conditions effect selection operator follows. Given state
= hKB0 , F, C, time-point t, fES selects fluents f f f one
effects action a[ ] recently executed.
Note f (or f ) may occur F could (observable)
effect executed action, necessarily goal action
contributes achieving. example, order check whether internet connection
available, agent may want observe access skype network even though
really interested opening browser (as needs browser order perform
booking online).
Formally, given state = hKB0 , F, C, time-point now, set (timed)
fluents selected fES set (timed) fluents f [ ] action
operator
1. executed(a, t0 ) KB0 , t0 = < t0 < now, sufficiently
small number (that left parameter here),
2. S, a[ ] |=ef f `, ` = f ` = f .
8.3 Action Selection
Informally, set conditions action selection operator follows. Given state
= hKB0 , F, C, time-point t, set actions selected fAS defined
follows. Let X (S, t) set actions trees F that:
1. executed,
2. ancestor timed out,
3. child ancestor timed out,
4. ancestor already satisfied,
5. precondition known false,
6. already executed.
fAS (S, t) X (S, t) actions fAS (S, t) executable concurrently
t.
Intuitively, conditions 2-4 impose belongs still feasible plan toplevel goals F. Note condition 1 definition X (S, t) logically redundant,
re-imposed definition fAS (S, t). However, condition serves first
filter thus useful practice.
Formally, given state = hKB0 , F, C, i, time-point t, set actions
selected fAS defined follows. Let X (S, t) set actions a[ ] occurring
leaves trees F that:
327

fiKakas, Mancarella, Sadri, Stathis & Toni

1. exists total valuation S, |=cs = t,
2. timed out(S, G, t) G ancestors(a[ ], F),
3. timed out(S, X, t) X children(G, F) G ancestors(a[ ], F),
4. achieved(S, G, t) G ancestors(a[ ], F),
5. let S, a[ ] |=pre Cs Cs = `1 [ ] . . . `n [ ];
n > 0, = 1, . . . , n exists total valuation S, |=cs
= |=T R `i [ ],
6. exists t0 = t0 executed(a, t0 ) KB0 .
formalisation condition 6 allows instances action
executed. Then,
fAS (S, t) = {a1 [1 ], . . . , [m ]} X (S, t)
(where 0), exists total valuation variables C
S, |=cs 1 = . . . = t.
Note definition action selection operator extended take
account notion urgency respect temporal constraints. However,
extension beyond scope work.
8.4 Precondition Selection
Informally, set conditions precondition selection operator follows. Given
state = hKB0 , F, C, time-point t, set preconditions (of actions
F) selected fP set pairs hC, Ai (timed) preconditions C actions
nodes(F) that:
1. C precondition
2. C known true t,
3. one actions could selected execution fAS would called
current time.
reason selection operator returns pairs, rather simply preconditions,
transition SI, makes use outputs selection operator, needs
know actions associated preconditions. SI introduces sensing
actions precondition returned place sensing actions siblings
associated actions F, seen Section 7.4.
Formally, given state = hKB0 , F, C, time-point t, set preconditions
actions selected fP set pairs hC, Ai (timed) preconditions C actions
nodes(F) that:
1. = a[ ], S, a[ ] |=pre Cs C conjunct Cs,
328

fiComputational Logic Foundations KGP Agents

2. exists total valuation variables C S, |=cs =
|=T R C,
3. X (S, t), X (S, t) defined Section 8.3.

9. Cycle Theory
behaviour KGP agents results application transitions sequences,
repeatedly changing state agent. sequences fixed priori,
conventional agent architectures, determined dynamically reasoning
declarative cycle theories, giving form flexible control. Cycle theories given
framework Logic Programming Priorities (LPP) discussed Section 3.
9.1 Formalisation Cycle Theories.
use following new notations:
(S, X, 0 , t) represent application transition time state given
input X resulting state 0 ,
(S, X) represent transition potentially chosen next transition
state S, input X.
Recall that, transitions, X may empty set {}, indicated Section 7.
Formally, cycle theory Tcycle consists following parts.
initial part Tinitial , determines possible transitions agent could
perform starts operate. Concretely, Tinitial consists rules form
(S0 , X) C(S0 , X)
refer via name R0|T (S0 , X). rules sanction that, conditions
C hold initial state S0 initial transition could , applied state
S0 input X. example, rule
R0|GI (S0 , {}) : GI(S0 , {}) empty f orest(S0 )
sanctions initial transition GI, forest initial state S0
empty.
Note C(S0 , X) may empty, and, non-empty, C(S0 , X) may refer
current time via condition time now(t). example, rule
R0|P (S0 , G) : P I(S0 , G) Gs = fGS (S0 , t), Gs 6= {}, G Gs, time now(t)
sanctions initial transition PI, forest initial state S0
contains goal planned current time (in goal
selection operator picks goal).
basic part Tbasic determines possible transitions following given transitions,
consists rules form
0 (S 0 , X 0 ) (S, X, 0 , t), EC(S 0 , X 0 )
329

fiKakas, Mancarella, Sadri, Stathis & Toni

refer via name RT |T 0 (S 0 , X 0 ). rules sanction that, transition executed, starting time state resulting state 0 ,
conditions EC evaluated 0 satisfied, transition 0 could
next transition applied 0 , input X 0 .16 EC enabling conditions
determine 0 applied . determine input X 0 0 ,
via calls selection operators. initial part Tcycle , EC may empty
and, not, may refer current time. example, rule
RAE|P (S 0 , G) : P I(S 0 , G) AE(S, As, 0 , t),
Gs = fGS (S 0 , t0 ), Gs 6= {}, G Gs, time now(t0 )
sanctions PI follow AE current time goal
current state selected goal selection function.
behaviour part Tbehaviour contains rules describing dynamic priorities amongst
rules Tbasic Tinitial . Rules Tbehaviour form
RT |T 0 (S, X 0 ) RT |T 00 (S, X 00 ) BC(S, X 0 , X 00 )
0 6= 00 , refer via name PTT0 00 . Recall RT |T 0 ()
RT |T 00 () (names of) rules Tbasic Tinitial . Note that, abuse notation,
could 0 case one rule used specify priority first
transition take place, words, priority rules Tinitial .
rules Tbehaviour sanction that, transition , conditions BC hold,
prefer next transition 0 00 . conditions BC behaviour
conditions give behavioural profile agent. example, rule

PGIT
0 : RT |GI (S, {}) RT |T 0 (S, X) empty f orest(S)

sanctions GI preferred transition transition
results state empty forest. components Tcycle ,
conditions BC may refer current time.
auxiliary part including definitions predicates occurring enabling
behaviour conditions.
incompatibility part, effect expressing one (instance a) transition
chosen one time.
Hence, Tcycle LPP-theory where: (i) P = Tinitial Tbasic , (ii) H = Tbehaviour .
9.2 Operational Trace
cycle theory Tcycle agent responsible behaviour, induces
operational trace agent, namely (typically infinite) sequence transitions
T1 (S0 , X1 , S1 , t1 ), . . . , Ti (Si1 , Xi , Si , ti ), Ti+1 (Si , Xi+1 , Si+1 , ti+1 ), . . .

16. Note order determine 0 possible transition , rule earlier form,
one needs know applied resulted state 0 . conveyed
choice name: RT |T 0 (S 0 , X 0 ). words, using Prolog notation, could represented
rule 0 (S 0 , X 0 ) ( , , 0 , ), EC(S 0 , X 0 ). Thus, rule Markovian.

330

fiComputational Logic Foundations KGP Agents

S0 given initial state;
1, ti given clock system (ti < ti+i );
(Tcycle Tbasic ) {time now(t1 )} |=pr T1 (S0 , X1 );
1
(Tcycle Tinitial ) {Ti (Si1 , Xi , Si , ti ), time now(ti+1 )} |=pr Ti+1 (Si , Xi+1 )
namely (non-final) transition sequence followed preferred transition,
specified Tcycle . If, stage, preferred transition determined |=pr
unique, choose one arbitrarily.
9.3 Normal Cycle Theory
normal cycle theory concrete example cycle theory, specifying pattern
operation agent prefers follow sequence transitions allows achieve
goals way matches expected normal behaviour. examples possible
cycle theories found literature (Kakas, Mancarella, Sadri, Stathis, & Toni,
2005; Sadri & Toni, 2006).
Basically, normal agent first introduces goals (if none start with) via GI,
reacts them, via RE, repeats process planning them, via PI,
executing (part of) chosen plans, via AE, revising state, via SR, goals
dealt (successfully revised away). point agent returns introducing
new goals via GI repeating process. Whenever process agent
interrupted via passive observation, via POI, chooses introduce new goals via
GI, take account changes environment. Whenever actions
unreliable, sense preconditions definitely need checked,
agent senses (via SI) executing action. Whenever actions
unreliable, sense effects definitely need checked, agent actively
introduces actions aim sensing effects, via AOI, executed
original actions. initially agent equipped goals, would plan
straightaway PI.
full definition normal cycle theory given appendix. used
provide control examples next section. Here, note that, although normal
cycle theory based classic observe-plan-act cycle agent control, generalises
several ways giving flexibility agent behaviour adapt changing
environment. example, goals agent need fixed dynamically
changed depending newly acquired information. Let us illustrates feature
brief example here. Suppose current state agent contains top-level nonreactive goal hreturn home(1 ), {1 < 7}i POI occurs adds observation
observed(low battery, 2) time 2. subsequent GI transition generated normal
cycle theory introduces new goal hrecharge battery(2 ), {2 < 3}i which, depending
details KBGD , either replaces previous goal adds additional goal.
normal cycle theory next choose PI transition new urgent
goal recharging battery.
331

fiKakas, Mancarella, Sadri, Stathis & Toni

10. Examples
section revisit examples introduced Section 2.6 used throughout
paper illustrate various components KGP model. Overall, aim
illustrate interplay transitions, interplay provides variety
behaviours afforded KGP model, including reaction observations, generation
execution conditional plans, dynamic adjustment goals plans.
Unless specified differently, assume Tcycle normal cycle theory
presented Section 9.3. provide domain-dependent definition auxiliary
part Tcycle explicitly, required.
10.1 Setting 1 Formalised
formalise initial state, knowledge bases behaviour svs Setting 1
described Section 2.6.1.
10.1.1 Initial State
simplicity, observations, goals plan svs assumed empty
initially. concretely let (initial) state svs
KB0 = { }
F

= {}

C = {}
= {}

10.1.2 Knowledge Bases
Following Section 5.1.4, formulate reactivity knowledge base agent svs terms
utterances query ref, ref use, inf orm inspired FIPA specifications communicative acts (FIPA, 2001a, 2001b). However, although use names
communicative acts FIPA specification, adopt mentalistic
svs formulated
semantic interpretation terms pre- post-conditions. Thus, KBreact
as:
observed(C, tell(C, svs, query ref (Q), D, 0), ), holds at(have inf o(Q, I), )
assume happens(tell(svs, C, inf orm(Q, I), D), 0 ), 0 >
observed(C, tell(C, svs, query ref (Q), D, 0), ), holds at(no inf o(Q), )
assume happens(tell(svs, C, ref use(Q), D), 0 ), 0 >
assume happens(tell(svs, C, inf orm(Q, I), D), ),
assume happens(tell(svs, C, ref use(Q), D), 0 )
f alse
assume happens(A, ), executable(A) f alse
executable(tell(svs, C, S, D)) C 6= svs
332

fiComputational Logic Foundations KGP Agents

initially(no inf o(arrival(tr01))
precondition(tell(svs, C, inf orm(Q, I), D), inf o(Q, I))
initiates(tell(C, svs, inf orm(Q, I), D), T, inf o(Q, I))
terminates(tell(C, svs, inf orm(Q, I), D), T, inf o(Q))
10.1.3 Behaviour
illustrate behaviour psa assume agent requests svs,
time 3, say, arrival time tr01. svs receives request psa time 5 arrival
time tr01. Via POI time 5 svs records KB0 :
observed(psa, tell(psa, svs, query ref (arrival(tr01)), d, 3), 5)
dialogue identifier. Then, via RE, time 7, say, svs modifies state
adding F tree rooted action a1 answer psa. action a1 refusal
represented as:
a1 = tell(svs, psa, ref use(arrival(tr01)), d, ),
temporal constraint > 7 added C.
refusal action generated via Reactivity capability svs
information requested arrival time. svs executes planned action a1 time
10, say, via AE transition, instantiating execution time, adding following record
KB0 :
executed(tell(svs, psa, ref use(arrival(tr01)), d), 10),
updating adding = 10 it.
Suppose svs makes two observations follows. time 17 svs receives
information arrival time (18) tr01 train co. Via POI, svs records
KB0 17 :
observed(co, tell(co, svs, inf orm(arrival(tr01), 18), d0 , 15), 17).
Assume time 25 svs receives another request psa arrival
time tr01 and, via POI, svs records KB0 :
observed(psa, tell(psa, svs, query ref (arrival(tr01)), d00 , 20), 25)
new dialogue identifier d00 . leads different answer svs query
psa. svs adds action state answer psa arrival time. done
via RE, say time 28. new tree added F rooted (reactive) action
tell(svs, psa, inf orm(arrival(tr01), 18), d00 , 0 ),
new temporal constraint 0 > 28 added C.
Via AE, svs executes action, instantiating execution time 30, say, adding
following record
17. d0 identifier dialogue within utterance performed, would typically
different earlier d.

333

fiKakas, Mancarella, Sadri, Stathis & Toni

executed(tell(svs, psa, inf orm(arrival(tr01), 18), d00 ), 30)
KB0 , adding 0 = 30 .
Eventually, SR clear planned (and executed) actions F component
state svs.
10.2 Setting 2 Formalised
formalise initial state, knowledge bases behaviour psa Setting 2
described Section 2.6.2.
10.2.1 Initial State
Let us assume initially state psa follows:
KB0 = { }
F

= {T1 , T2 }

C = {1 < 15, 2 < 15}
= {}
T1 T2 consist goals (respectively):
g1 = ticket(madrid, denver, 1 )
g2 = visa(usa, 2 ).
10.2.2 Knowledge Bases
psa
plan goal g1 , KBplan
contains:

initiates(buy ticket online(F rom, o), T, ticket(F rom, o))
precondition(buy ticket online(F rom, o), available connection)
precondition(buy ticket online(F rom, o), available destination(T o)).
psa
plan goal g2 , KBplan
contains:

initiates(apply visa(usa), T, visa(usa))
precondition(apply visa(usa), address(usa))
initiates(book hotel(L), T, address(usa)) holds(in(L, usa), ).
10.2.3 Behaviour
PI called state, time 2, say, generates partial plan goal,
changing state follows. goal g1 acquires three children T1 . are:
g11 = available connection(11 ),
g12 = available destination(denver, 12 ),
a13 = buy ticket online(madrid, denver, 13 ).
Also, consequently, set temporal constraints updated to:
C = {1 < 15, 2 < 15, 11 = 13 , 12 = 13 , 13 < 1 , 1 > 2}.
334

fiComputational Logic Foundations KGP Agents

action a13 generated action initiates goal g1 . Moreover, every plan
generated must satisfy integrity constraints KBplan . particular, precondition
actions tree already hold must generated sub-goals tree.
g11 g12 generated tree above.
via transition SI, following sensing actions added T1 siblings
action a13 18 :
a14 = sense(available connection, 14 )
a15 = sense(available destination(denver), 15 )
constraints
14 = 15 , 14 < 13
added C.
Then, via AE, two sensing actions executed (before original action a1 ),
KB0 updated result sensing follows. Suppose two actions
executed time 5. Consider first action senses fluent available connection.
fluent confirmed physical sensing capability, i.e. available connection : true
X
sensing({available connection, available destination}, 5) = X,
observed(available connection, 5) added KB0 . hand,
available connection : f alse
X above, observed(available connection, 5) added KB0 . cases
14 = 5 added .
neither cases occurs, i.e. sensing capability cannot confirm either
available connection available connection, fact added KB0 . Similarly
precondition, available destination. Let us assume step AE,
KB0 becomes
observed(available connection, 5)
observed(available destination(denver), 5)
AE execute original action a13 . Note agent might decide execute
action even one preconditions known satisfied sensing.
g1 achieved, SR eliminate a13 , a14 , a15 , g11 , g12 state.
resulting state, F = {T2 }, PI called, say time 6. results generating
partial plan g2 , changing state T2 root g2 children
a21 = apply visa(usa, 21 )
g22 = address(usa, 22 )
21 < 2 , 22 = 21 added C. Then, PI, say time 7, introduces
a23 = book hotel(denver, 23 )
18. assume auxiliary part Tcycle contains rule
unreliable pre(As) buy ticket online( , , )

335

fiKakas, Mancarella, Sadri, Stathis & Toni

child g22 T2 , adding 23 < 22 C. Then, AE time 8 executes a23 , adding
KB0 , AE time 9 executes a22 , updating KB0 . Finally, SR eliminates
actions goals T2 returns empty F state.

11. Related Work
Many proposals exist models architectures individual agents based computational logic foundations (see e.g. survey Fisher, Bordini, Hirsch, & Torroni,
2007). proposals based logic programming, example IMPACT (Arisha, Ozcan, Ross, Subrahmanian, Eiter, & Kraus, 1999; Subrahmanian, Bonatti, Dix,
Eiter, Kraus, Ozcan, & Ross, 2000), AAA (Balduccini & Gelfond, 2008; Baral & Gelfond,
2001), DALI (Costantini & Tocchio, 2004), MINERVA (Leite, Alferes, & Pereira, 2002),
GOLOG (Levesque, Reiter, Lesperance, Lin, & Scherl, 1997), IndiGolog (De Giacomo,
Levesque, & Sardina, 2001). proposals based modal logic first-order logic
approaches, example BDI model (Bratman et al., 1988; Rao & Georgeff, 1997)
extensions deal normative reasoning (Broersen, Dastani, Hulstijn, Huang, &
van der Torre, 2001), Agent0 (Shoham, 1993), AgentSpeak (Rao, 1996) variants,
3APL (Hindriks, de Boer, van der Hoek, & Meyer, 1999) variants (Dastani, Hobo,
& Meyer, 2007).
high level comparison similarities objectives existing
computational logic models agency KGP, aim specifying knowledgerich agents certain desirable behaviours. similarities finer
details KGP model related work, well differences.
feature KGP which, best knowledge, novel declarative
context-sensitive specification agents cycle. avoid static cycle control
(Rao & Georgeff, 1991; Rao, 1996), KGP relies upon cycle theory determines,
run time, given circumstances individual profile agent, next
step be. cycle theory sensitive solicited unsolicited information
agent receives environment, helps agent adapt behaviour
changes experiences. approach closest work 3APL (Hindriks
et al., 1999) extended Dastani, de Boer, Dignum, Meyer (2003), provides
meta-programming constructs specifying cycle agent goal selection,
plan expansion, execution, well if-then-else while-loop statements. Unlike
imperative constructs 3APL, KGP uses set selection operators extended
model different behaviours types agents. flexible ordering transitions
obtained using preference reasoning transitions applied specific
point time. preferences may change according external events changes
knowledge agent.
Another central distinguishing feature KGP model, comparison existing
models, including based logic programming, modular integration within
single framework abductive logic programming, temporal reasoning, constraint logic
programming, preference reasoning based logic programming priorities, order
support diverse collection capabilities. one specified declaratively
equipped provably correct computational counterpart (see Bracciali,
336

fiComputational Logic Foundations KGP Agents

Demetriou, Endriss, Kakas, Lu, Mancarella, Sadri, Stathis, Terreni, & Toni, 2004,
detailed discussion).
Compared existing logic programming approaches KGP two main similarities
MINERVA (Leite et al., 2002), architecture exploits computational logic
gives declarative operational semantics agents. Unlike KGP, MINERVA
agent consists several specialised, possibly concurrent, sub-agents performing various
tasks, relies upon MDLP (Multidimensional Dynamic Logic Programming) (Leite et al.,
2002). MDLP basic knowledge representation mechanism agent MINERVA,
based extension answer-set programming explicit rules updating
agents knowledge base. KGP instead integrate abductive logic programming
logic programming priorities combined temporal reasoning.
Closely related work KGP logic-based agent architecture reasoning
agents Baral Gelfond (2001). architecture assumes state agents
environment described set fluents evolve time terms transitions
labelled actions. agent assumed capable correctly observing state
environment, performing actions, remembering history happened
it. agents knowledge base consists action description part specifying internal
agent transitions, domain specific generic KGP. knowledge
base contains agent observes environment including actions,
KGPs KB0 . temporal aspects agent transitions specified action
language AL implemented A-Prolog, language logic programs answerset programming semantics. answer sets domain specific programs specified AL
correspond plans KGP hypothetical narratives abductive event calculus.
control agent based static observe-think-act cycle, instance KGP
cycle theories. recent refined account overall approach given rise
AAA Architecture, see (Balduccini & Gelfond, 2008) overview.
DALI (Costantini & Tocchio, 2004) logic programming language designed executable specification logical agents. KGP, DALI attempts provide constructs
represent reactivity proactivity agent using extended logic programs. DALI
agent contains reactive rules, events, actions aimed interacting external
environment. Behaviour (in terms reactivity proactivity) DALI agent triggered
different event types: external, internal, present, past events. events
actions time stamped record occur. External events
observations KGP, past events past observations. However, KGP
support internal events instead idea transitions called cycle
theory trigger reactive proactive behaviour.
IndiGolog (De Giacomo et al., 2001) high-level programming language robots
intelligent agents supports, KGP, on-line planning, sensing plan execution
dynamic incompletely known environments. member Golog family
languages (Levesque et al., 1997) use Situation Calculus theory action perform
reasoning required executing program. Instead KGP model rely
abductive logic programming logic programming priorities combined temporal reasoning. Instead Situation Calculus KGP use Event Calculus
temporal reasoning, use Event Calculus prerequisite model
InterRaP (Muller, Fischer, & Pischel, 1998), replaced another temporal
337

fiKakas, Mancarella, Sadri, Stathis & Toni

reasoning framework, needed. Apart difference use Situation Event Calculi, IndiGolog goals cannot decided dynamically, whereas
KGP model change dynamically according specifications Goal Decision
capability.
obvious similarity KGP model BDI model (Bratman et al.,
1988) given correspondence KGPs knowledge, goals plan BDIs
beliefs, desires intentions, respectively. Apart fact BDI model
based modal logic, KGP knowledge (beliefs BDI) partitioned modules,
support various reasoning capabilities. KGP tries bridge gap
specification practical implementation agent. gap criticized
BDI Rao (1996), developed AgentSpeak(L) language. computational
model AgentSpeak(L) formally studied dInverno Luck (1998),
recent implementations AgentSpeak interpreter incorporated Jason
platform (Bordini & Hubner, 2005). KGP implementation PROSOCS (Bracciali
et al., 2006), Jason implementation seeks narrow gap specification
executable BDI agent programs. Jason extends BDI new features belief
revision (Alechina, Bordini, Hubner, Jago, & Logan, 2006).
particular line work BDI Padgham Lambrix (2005), investigate
notion capability integrated BDI Logic Rao Georgeff (1991),
BDI agent reason capabilities. capability work
informally understood ability act rationally towards achieving particular goal,
sense abstract plan type believed achieve goal. Formally,
BDI logic Rao Georgeff extended incorporate modality capabilities
constrains agent goals intentions compatible agent believes
capabilities. set compatibility axioms presented detailing semantic
conditions capture desired inter-relationships among agents beliefs, capabilities,
goals, intentions. work summarises extensions BDI model
implemented adapting BDI interpreter include capabilities, arguing
benefits extension original BDI Interpreter Rao Georgeff (1992).
KGP capabilities equate reasoning capabilities agent allow agent
plan actions given state, react incoming observations, decide upon
goals adopt. However, KGP, use capabilities level agents
domain specific knowledge guide agent determining whether rational
adopt particular goal.
issue separation specification implementation exists
KGP model Agent0 (Shoham, 1993), later refinement PLACA (Thomas,
1995). Two differences KGP Agent0 PLACA explicit
links exist KGP model amongst goals (in structuring forest
agent state) richer theories KGP specify priorities amongst potential
goals restricted temporal orderings. explicit links exploited
revising goals state, via Revision transition, light new information
passage time.
BOID architecture (Broersen et al., 2001) extends well known BDI model (Rao
& Georgeff, 1992) obligations, thus giving rise four main components representing
agent: beliefs, obligations, intentions desires. focus BOID find ways
338

fiComputational Logic Foundations KGP Agents

resolving conflicts amongst components. order define agent types,
including well known types agent theories realistic, selfish, social simple
minded agents. agent types differ give different priorities rules
four components. instance, simple minded agent gives higher priority
intentions, compared desires obligations, whereas social agent gives higher priority
obligations desires. use priorities propositional logic formulae specify
four components agent types.
existing KGP model already resolves conflicts BOID tries address. example, conflict belief prior intention, means
intended action longer executed due changes environment,
KGP agent notice give higher priority belief prior
intention, allowing agent effect retract intended action and, time permitting,
replan goals. KGP model includes notion priority used Goal
Decision capability cycle theory controls behaviour agent.
KGP model extended deal normative concepts, extended model
known N-KGP (Sadri, Stathis, & Toni, 2006). N-KGP common BOID
seeks extend KGP addition obligations. N-KGP model
extends notion priorities incorporating amongst different types goals
actions. detailed comparison N-KGP related work presented Sadri, Stathis,
Toni (2006).
features included approaches absent
KGP model. BDI and, so, IMPACT system (Arisha et al., 1999; Subrahmanian
et al., 2000) allow agents knowledge bases representations knowledge
agents. systems allow agents degree introspection
ability reason agents beliefs reasoning. KGP model date
include features. IMPACT allows incorporation legacy systems, possibly using diverse languages, richer knowledge base language including
deontic concepts probabilities. Similarly, 3APL, system based combination
imperative logic programming languages, includes optimisation component
absent KGP. component 3APL includes rules identify given
situation agent pursuing suboptimal plan, help agent find better way
achieving goals. 3APL includes additional functionalities learning (van
Otterlo, Wiering, Dastani, & Meyer, 2003), model currently support.
2APL (Dastani et al., 2007) extension 3APL goals goal-plan rules well
external internal events. 2APL customisable (via graphical interface) cycle
fixed customised.

12. Conclusions
presented computational logic foundations KGP model agency.
model allows specification heterogeneous agents interact other,
exhibit proactive reactive behaviour allowing function dynamic
environments adjusting goals plans changes happen environments. KGP incorporates highly modular agent architecture integrates collection
339

fiKakas, Mancarella, Sadri, Stathis & Toni

reasoning sensing capabilities, synthesised within transitions, orchestrated cycle
theories take account dynamic context agent preferences.
formal specification KGP components within computational logic
major advantage facilitating formal analysis model direct verifiable
implementation. formal analysis started Sadri Toni (2006),
give formal analysis KGP agents exploring effectiveness terms goal
achievement, reactive awareness, impact reasoning capabilities towards
progress goal achievement. implementation precursor model, described
Kakas et al. (2004b), already developed within PROSOCS platform
Stathis et al. (2004) upon provably correct computational counterparts defined
component model given Kakas et al. (2004b). Concrete choices
computational counterparts described Bracciali et al. (2004). resulting
development framework allows deployment testing functionality earlier
variant KGP agents. Deployment agents relies upon agent template designed
Stathis et al. (2002), builds upon previous work head/body metaphor
described Steiner et al. (1991) Haugeneder et al. (1994), mind/body architecture introduced Bell (1995) recently used Huang, Eliens, de Bra (2001).
development platform applied number practical applications, and,
particular, ambient intelligence Stathis Toni (2004). Also, Sadri (2005)
provided guidelines specifying applications using KGP agents. Future work includes implementing deploying revised KGP model given paper: envisage
pose limited conceptual challenges, able capitalise experience
implementing deploying precursor model.
Sadri, Stathis, Toni (2006) explored precursor KGP agent
model augmented normative features allowing agents reason
choose social personal goals, prohibitions obligations. would
interesting continue work finalised KGP model given paper.
Sadri Toni (2005) developed number different profiles behaviour,
defined terms specific cycle theories, formally proved advantages given
circumstances. would interesting explore dimension further, characterise
different agent personalities provide guidance, formal properties,
type personality needed applications.
Future work includes extending model incorporate (i) reasoning capabilities, including knowledge revision (e.g. Inductive Logic Programming),
sophisticated forms temporal reasoning, including identifying explanations unexpected
observations, (ii) introspective reasoning reasoning beliefs agents,
(iii) experimentation model via implementation, (iv) development
concurrent implementation.

Acknowledgments
work supported EU FET Global Computing Initiative, within SOCS
project (IST-2001-32530). wish thank colleagues SOCS useful discussions
development KGP. grateful Chitta Baral anonymous
referees helpful comments earlier version paper.
340

fiComputational Logic Foundations KGP Agents

Appendix A. Normal Cycle Theory
give main parts normal Tcycle , exclude others, example
definitions incompatible auxiliary part, including definitions predicates
empty f orest, unreliable pre etc. details see (Kakas et al., 2005).
Tinitial : consists following rules:
R0|GI (S0 , {}) : GI(S0 , {}) empty f orest(S0 )
R0|AE (S0 , As) : AE(S0 , As) empty non executable goals(S0 ), = fAS (S0 , t),
6= {}, time now(t)
R0|P (S0 , G) : P I(S0 , G) Gs = fGS (S0 , t), Gs 6= {}, G Gs, time now(t)
Tbasic : consists following rules:
rules deciding might follow AE transition follows:
RAE|P (S 0 , G) : P I(S 0 , G) AE(S, As, 0 , t), Gs = fGS (S 0 , t0 ), Gs 6= {},
G Gs, time now(t0 )
0
0
RAE|AE (S , ) : AE(S 0 , As0 ) AE(S, As, 0 , t), As0 = fAS (S 0 , t0 ),
As0 6= {}, time now(t0 )
RAE|AOI (S 0 , F s) : AOI(S 0 , F s) AE(S, As, 0 , t), F = fES (S 0 , t0 ),
F 6= {}, time now(t0 )
RAE|SR (S 0 ) : SR(S 0 , {}) AE(S, As, 0 , t)
RAE|GI (S 0 , {}) : GI(S 0 , {}) AE(S, As, 0 , t)
Namely, AE could followed another AE, PI, AOI, SR,
GI, POI.
rules deciding might follow SR follows
RSR|P (S 0 , G) : P I(S 0 , G) SR(S, {}, 0 , t), Gs = fGS (S 0 , t0 ), Gs 6= {}, G Gs,
time now(t0 )
RSR|GI (S 0 , {}) : GI(S 0 , {}) SR(S, {}, 0 , t), Gs = fGS (S 0 , t0 ), Gs = {},
time now(t0 )
0
RSR|AE (S , As) : AE(S 0 , As) SR(S, {}, 0 , t), = fGS (S 0 , t0 ), 6= {},
time now(t0 )
Namely, SR followed PI GI AE, depending whether
goals plan state.
rules deciding might follow PI follows
RP I|AE (S 0 , As) : AE(S 0 , As) P I(S, G, 0 , t), = fAS (S 0 , t0 ), 6= {},
time now(t0 )
0
RP I|SI (S , P s) : SI(S 0 , P s) P I(S, G, 0 , t), P = fP (S 0 , t0 ), P 6= {}, time now(t0 )
second rule allow possibility sensing preconditions action
execution.
rules deciding might follow GI follows
RGI|RE (S 0 , {}) : RE(S 0 , {}) GI(S, {}, 0 , t)
RGI|P (S 0 , G) : P I(S 0 , G) GI(S, {}, 0 , t), Gs = fGS (S 0 , t0 ), Gs 6= {}, G Gs,
time now(t0 )
Namely, GI followed PI, goals plan for.
rules deciding might follow follows
341

fiKakas, Mancarella, Sadri, Stathis & Toni

RRE|P (S 0 , G) : P I(S 0 , G) RE(S, {}, 0 , t), Gs = fGS (S 0 , t0 ), Gs 6= {}, G Gs,
time now(t0 )
RRE|SI (S 0 , P s) : SI(S 0 , P s) RE(S, {}, 0 , t), P = fP (S 0 , t0 ), P 6= {},
time now(t0 )
rules deciding might follow SI follows
RSI|AE (S 0 , As) : AE(S 0 , As) SI(S, P s, 0 , t), = fAS (S 0 , t0 ), 6= {},
time now(t0 )
0
RSI|SR (S , {}) : SR(S 0 , {}) SI(S, P s, 0 , t)
rules deciding might follow AOI follows
RAOI|AE (S 0 , As) : AE(S 0 , As) AOI(S, F s, 0 , t), = fAS (S 0 , t0 ), 6= {},
time now(t0 )
0
RAOI|SR (S , {}) : SR(S 0 , {}) AOI(S, F s, 0 , t)
RAOI|SI (S 0 , P s) : SI(S 0 , P s) AOI(S, F s, 0 , t), P = fP (S 0 , t0 ), P 6= {},
time now(t0 )
rules deciding might follow POI follows
RP OI|GI (S 0 , {}) : GI(S 0 , {}) P OI(S, {}, 0 , t)
Tbehaviour : consists following rules:
GI given higher priority trees state:

PGIT
0 : RT |GI (S, {}) RT |T 0 (S, X) empty f orest(S)
transitions T, 0 , 0 6= GI, possibly 0 (indicating
trees initial state agent, GI first transition).
GI given higher priority POI:
P OI : R
0
0
PGIT
P OI|GI (S , {}) RP OI|T (S, {}, )
transitions 6= GI.
GI, transition given higher priority:
GI
PRET
: RGI|RE (S, {}) RGI|T (S, X)
transitions 6= RE.
RE, transition PI given higher priority:
PPRE
: RRE|P (S, G) RRE|T (S, X)
transitions 6= P I.
PI, transition AE given higher priority, unless actions
actions selected execution whose preconditions unreliable need checking,
case SI given higher priority:
PI
PAET
: RP I|AE (S, As) RP I|T (S, X) unreliable pre(As)
transitions 6= AE.
PI
: RP I|SI (S, P s) RP I|AE (S, As) unreliable pre(As)
PSIAE
SI, transition AE given higher priority
SI
: RSI|AE (S, As) RSI|T (S, X)
PAET
transitions 6= AE.
AE, transition AE given higher priority
actions execute state, case either AOI SR given higher
priority, depending whether actions unreliable, sense
effects need checking, not:
342

fiComputational Logic Foundations KGP Agents

AE
PAET
: RAE|AE (S, As) RAE|T (S, X)
transitions 6= AE. Note that, definition Tbasic , transition AE applicable
still actions executed state.
AE
AE
PAOIT
: RAE|AOI (S, F s) RAE|T (S, X)) BCAOI|T
(S, F s, t), time now(t)
AE
transitions 6= AOI, behaviour condition BCAOI|T (S, F s, t) defined (in
auxiliary part) by:
AE
BCAOI|T
(S, F S, t) empty executable goals(S, t), unreliable ef f ect(S, t)
Similarly, have:
AE (S, t), time now(t)
AE
: RAE|SR (S, {}) RAE|T (S, X)) BCSR|T
PSRT
transitions 6= SR where:
AE (S, t) empty executable goals(S, t), unreliable ef f ect(S, t)
BCSR|T
Here, assume auxiliary part Tcycle specifies whether given set actions
contains unreliable action, sense expressed unreliable ef f ect, defines
predicate empty executable goals.

SR, transition PI higher priority:
PPSR
: RSR|P (S, G) RSR|T (S, X))
transitions 6= P I.
Note that, definition Tbasic , transition PI applicable still goals
plan state. actions goals left state, rule RGI|T
would apply.
initial state PI given higher priority:
PP0 : R0|P (S, G) R0|T (S, X)
transitions 6= P I. Note that, definition Tinitial below, transition PI
applicable initially goals plan initial state.

343

fiKakas, Mancarella, Sadri, Stathis & Toni

References
Alechina, N., Bordini, R. H., Hubner, J. F., Jago, M., & Logan, B. (2006). Belief Revision
AgentSpeak Agents. Nakashima, H., Wellman, M. P., Weiss, G., & Stone, P.
(Eds.), 5th International Joint Conference Autonomous Agents Multiagent
Systems (AAMAS 2006), pp. 12881290, Hakodate, Japan. ACM.
Arisha, K. A., Ozcan, F., Ross, R., Subrahmanian, V. S., Eiter, T., & Kraus, S. (1999).
IMPACT: Platform Collaborating Agents. IEEE Intelligent Systems, 14 (2),
6472.
Balduccini, M., & Gelfond, M. (2008). AAA Architecture: Overview. AAAI
Spring Symposium Architectures Intelligent Theory-Based Agents (AITA08).
Baral, C., & Gelfond, M. (2001). Reasoning agents dynamic domains. Logic-based
artificial intelligence, pp. 257279. Kluwer Academic Publishers, Norwell, MA, USA.
Bell, J. (1995). Planning Theory Practical Rationality. Proceedings AAAI95
Fall Symposium Rational Agency, pp. 14. AAAI Press.
Bordini, R. H., & Hubner, J. F. (2005). BDI Agent Programming AgentSpeak using Jason
(Tutorial Paper). Toni, F., & Torroni, P. (Eds.), Computational Logic MultiAgent Systems, 6th International Workshop, CLIMA VI, Lecture Notes Computer
Science, pp. 143164. Springer.
Bracciali, A., & Kakas, A. (2004). Frame consistency: Reasoning explanations.
Proceedings 10th International Workshop Non-Monotonic Reasoning
(NMR2004), Whistler BC, Canada.
Bracciali, A., Demetriou, N., Endriss, U., Kakas, A. C., Lu, W., Mancarella, P., Sadri, F.,
Stathis, K., Terreni, G., & Toni, F. (2004). KGP Model Agency Global
Computing: Computational Model Prototype Implementation. Priami, C., &
Quaglia, P. (Eds.), Global Computing, pp. 340367, Rovereto, Italy. Springer.
Bracciali, A., Endriss, U., Demetriou, N., Kakas, A. C., Lu, W., & Stathis, K. (2006).
Crafting Mind PROSOCS Agents. Applied Artificial Intelligence, 20 (2-4), 105
131.
Bratman, M., Israel, D., & Pollack, M. (1988). Plans resource-bounded practical reasoning. Computational Intelligence, 4.
Broersen, J., Dastani, M., Hulstijn, J., Huang, Z., & van der Torre, L. (2001). BOID
Architecture: conficts Beliefs, Obligations, Intentions Desires. Proceedings Fifth International Conference Autonomous Agents (Agents 2001), pp.
916. ACM Press, Montreal, Canada.
Clark, K. L. (1978). Negation Failure. Gallaire, H., & Minker, J. (Eds.), Logic
Data Bases, pp. 293322. Plenum Press.
Costantini, S., & Tocchio, A. (2004). DALI Logic Programming Agent-Oriented Language. Alferes, J. J., & Leite, J. A. (Eds.), Proceedings 9th European Conference Logics Artificial Intelligence, (JELIA 2004), Vol. 3229 Lecture Notes
Computer Science, pp. 685688. Springer.
344

fiComputational Logic Foundations KGP Agents

Dastani, M., de Boer, F., Dignum, F., & Meyer, J.-J. (2003). Programming Agent Deliberation: approach illustrated using 3APL Language. Autonomous Agents
Mult-agent Systems (AAMAS03), pp. 97104, Australia.
Dastani, M., Hobo, D., & Meyer, J.-J. (2007). Practical Extensions Agent Programming
Languages. Proceedings Sixth International Joint Conference Autonomous
Agents Multiagent Systems (AAMAS07). ACM Press.
de Bruijn, O., & Stathis, K. (2003). Socio-Cognitive Grids: Net Universal Human
Resource. Kameas, A., & Streitz, N. (Eds.), Proceedings Conference Tales
Disappearing Computer, pp. 211218, Santorini. CTI Press.
De Giacomo, G., Levesque, H. J., & Sardina, S. (2001). Incremental execution guarded
theories. ACM Transactions Computational Logic, 2 (4), 495525.
dInverno, M., & Luck, M. (1998). Engineering AgentSpeak(L): Formal Computational
Model. J. Log. Comput., 8 (3), 233260.
FIPA Communicative Act Library Specification (2001a). Experimental specification
XC00037H. Foundation Intelligent Physical Agents, http://www.fipa.org.
FIPA Query Interaction Protocol (2001b). Experimental specification XC00027F. Foundation Intelligent Physical Agents, http://www.fipa.org.
Fisher, M., Bordini, R., Hirsch, B., & Torroni, P. (2007). Computational Logics Agents:
Road Map Current Technologies Future Trends. Computational Intelligence,
23 (1), 6191.
Haugeneder, H., Steiner, D., & McCabe, F. (1994). IMAGINE: framework building
multi-agent systems. Deen, S. M. (Ed.), Proceedings 1994 International
Working Conference Cooperating Knowledge Based Systems (CKBS-94), pp. 31
64, DAKE Centre, University Keele, UK.
Hindriks, K. V., de Boer, F. S., van der Hoek, W., & Meyer, J. C. (1999). Agent programming 3APL. Autonomous Agents Multi-Agent Systems, 2(4), 357401.
Huang, Z., Eliens, A., & de Bra, P. (2001). Architecture Web Agents. Proceedings
EUROMEDIA01. SCS.
Jaffar, J., & Maher, M. (1994). Constraint logic programming: survey. Journal Logic
Programming, 19-20, 503582.
Kakas, A. C., Kowalski, R. A., & Toni, F. (1998). role abduction logic programming. Gabbay, D. M., Hogger, C. J., & Robinson, J. A. (Eds.), Handbook Logic
Artificial Intelligence Logic Programming, Vol. 5, pp. 235324. Oxford University
Press.
Kakas, A. C., Mancarella, P., & Dung, P. M. (1994). acceptability semantics logic
programs. Proceedings eleventh international conference Logic programming, pp. 504519, Cambridge, MA, USA. MIT Press.
Kakas, A. C., & Miller, R. (1997). simple declarative language describing narratives
actions. Logic Programming, 31.
345

fiKakas, Mancarella, Sadri, Stathis & Toni

Kakas, A. C., & Moraitis, P. (2003). Argumentation based decision making autonomous
agents. Rosenschein, J. S., Sandholm, T., Wooldridge, M., & Yokoo, M. (Eds.),
Proceedings Second International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS-2003), pp. 883890, Melbourne, Victoria. ACM Press.
Kakas, A., Mancarella, P., Sadri, F., Stathis, K., & Toni, F. (2005). Declarative Agent
Control. Leite, J., & Torroni, P. (Eds.), CLIMA V: Computational Logic MultiAgent Systems, Vol. 3487 Lecture Notes Artificial Intelligence (LNAI), pp. 96
110. Springer Verlag.
Kakas, A. C., Kowalski, R. A., & Toni, F. (1992). Abductive Logic Programming. J. Log.
Comput., 2 (6), 719770.
Kakas, A. C., Mancarella, P., Sadri, F., Stathis, K., & Toni, F. (2004a). Declarative Agent
Control. Leite, J. A., & Torroni, P. (Eds.), Computational Logic Multi-Agent Systems, 5th International Workshop, CLIMA V, Vol. 3487 Lecture Notes Computer
Science, pp. 96110. Springer.
Kakas, A. C., Mancarella, P., Sadri, F., Stathis, K., & Toni, F. (2004b). KGP Model
Agency. de Mantaras, R. L., & Saitta, L. (Eds.), Proceedings 16th Eureopean
Conference Artificial Intelligence (ECAI 2004), pp. 3337. IOS Press.
Kowalski, R. A., & Sergot, M. (1986). logic-based calculus events. New Generation
Computing, 4 (1), 6795.
Kowalski, R., & Toni, F. (1996). Abstract argumentation. Artificial Intelligence Law
Journal, Special Issue Logical Models Argumentation, 4 (3-4), 275296. Kluwer
Academic Publishers.
Leite, J. A., Alferes, J. J., & Pereira, L. M. (2002). MIN ERVA: dynamic logic programming agent architecture. Intelligent Agents VIII: 8th International Workshop,
ATAL 2001, Seattle, WA, USA, Revised Papers, Vol. 2333 Lecture Notes Artificial Intelligence, pp. 141157.
Levesque, H. J., Reiter, R., Lesperance, Y., Lin, F., & Scherl, R. B. (1997). GOLOG:
logic programming language dynamic domains. Journal Logic Programming,
31 (1-3), 5983.
Mamdani, E. H., Pitt, J., & Stathis, K. (1999). Connected Communities Standpoint
Multi-agent Systems. New Generation Computing, 17 (4), 381393.
Mancarella, P., Sadri, F., Terreni, G., & Toni, F. (2004). Planning partially situated
agents. Leite, J. A., & Torroni, P. (Eds.), Computational Logic Multi-Agent Systems, 5th International Workshop, CLIMA V, Vol. 3487 Lecture Notes Computer
Science, pp. 230248. Springer.
Miller, R., & Shanahan, M. (2002). alternative formulations event calculus.
Kakas, A. C., & Sadri, F. (Eds.), Computational Logic: Logic Programming
Beyond - Essays Honour Robert A. Kowalski, Vol. 2408 Lecture Notes
Computer Science, pp. 452490. Springer.
Muller, J., Fischer, K., & Pischel, M. (1998). Pragmatic BDI Architecture. Huhns,
M. N., & Singh, M. P. (Eds.), Readings Agents, pp. 217225. Morgan Kaufmann
Publishers.
346

fiComputational Logic Foundations KGP Agents

Padgham, L., & Lambrix, P. (2005). Formalisations capabilities BDI-agents. Autonomous Agents Multi-Agent Systems, 10 (3), 249271.
Prakken, H., & Sartor, G. (1996). system defeasible argumentation, defeasible
priorities. International Conference Formal Applied Practical Reasoning,
Springer Lecture Notes AI 1085, pp. 510524.
Prakken, H., & Sartor, G. (1997). Argument-based extended logic programming defeasible priorities. Journal Applied Non-Classical Logics, 7 (1), 2575.
Rao, A. S. (1996). AgentSpeak(L): BDI agents speak logical computable language.
van Hoe, R. (Ed.), Agents Breaking Away, 7th European Workshop Modelling
Autonomous Agents Multi-Agent World, MAAMAW96, Eindhoven, Netherlands, January 22-25, 1996, Proceedings, Vol. 1038 Lecture Notes Computer
Science, pp. 4255. Springer-Verlag.
Rao, A. S., & Georgeff, M. P. (1991). Modeling Rational Agents within BDI-architecture.
Fikes, R., & Sandewall, E. (Eds.), Proceedings Knowledge Representation
Reasoning (KR&R-91), pp. 473484. Morgan Kaufmann Publishers.
Rao, A. S., & Georgeff, M. P. (1997). Modeling rational agents within BDI-architecture.
Huhns, M. N., & Singh, M. P. (Eds.), Readings Agents, pp. 317328. Morgan
Kaufmann Publishers, San Francisco, CA, USA.
Rao, A. S., & Georgeff, M. P. (1992). abstract architecture rational agents. Nebel,
B., Rich, C., & R.Swartout, W. (Eds.), 3rd International Conference Principles
Knowledge Representation Reasoning (KR92), pp. 439449, Cambridge, MA,
USA. Morgan Kaufmann.
Sadri, F. (2005). Using KGP model agency design applications (Tutorial Paper).
Toni, F., & Torroni, P. (Eds.), Computational Logic Multi-Agent Systems, 6th
International Workshop, CLIMA VI, Vol. 3900 Lecture Notes Computer Science,
pp. 165185. Springer.
Sadri, F., Stathis, K., & Toni, F. (2006). Normative KGP agents. Computational & Mathematical Organization Theory, 12 (2-3), 101126.
Sadri, F., & Toni, F. (2005). Variety behaviours profiles logic-based agents.
Toni, F., & Torroni, P. (Eds.), Computational Logic Multi-Agent Systems, 6th
International Workshop, CLIMA VI, Vol. 3900 Lecture Notes Computer Science,
pp. 206225. Springer.
Sadri, F., & Toni, F. (2006). Formal Analysis KGP agents. Fisher, M., van der Hoek,
W., Konev, B., & Lisitsa, A. (Eds.), Logics Artificial Intelligence, 10th European
Conference, JELIA 2006, Vol. 4160 Lecture Notes Computer Science, pp. 413
425. Springer.
Shanahan, M. (1997). Solving Frame Problem. MIT Press.
Shanahan, M. (1989). Prediction deduction explanation abduction. Proceedings
11th International Joint Conference Artificial Intelligence, pp. 10551060.
Shoham, Y. (1993). Agent-oriented programming. Artificial Intelligence, 60 (1), 5192.
347

fiKakas, Mancarella, Sadri, Stathis & Toni

SOCS (2007). Societies ComputeeS: computational logic model description,
analysis verification global open societies heterogeneous computees.
http://lia.deis.unibo.it/research/socs/.
Stathis, K., Child, C., Lu, W., & Lekeas, G. K. (2002). Agents Environments.
Tech. rep. Technical Report IST32530/CITY/005/DN/I/a1, SOCS Consortium, 2002.
IST32530/CITY/005/DN/I/a1.
Stathis, K., Kakas, A., Lu, W., Demetriou, N., Endriss, U., & Bracciali, A. (2004).
PROSOCS: platform programming software agents computational logic.
Muller, J., & Petta, P. (Eds.), Proceedings Agent Theory Agent Implementation (AT2AI-4 EMCSR2004 Session M), pp. 523528, Vienna, Austria.
Stathis, K., & Toni, F. (2004). Ambient Intelligence using KGP Agents. Markopoulos, P.,
Eggen, B., Aarts, E. H. L., & Crowley, J. L. (Eds.), Ambient Intelligence: Proceedings
Second European Symposium, EUSAI 2004, Vol. 3295 Lecture Notes Computer
Science, pp. 351362. Springer.
Steiner, D. E., Haugeneder, H., & Mahling, D. (1991). Collaboration knowledge bases
via knowledge based collaboration. Deen, S. M. (Ed.), CKBS-90 Proceedings
International Working Conference Cooperating Knowledge Based Systems, pp.
113133. Springer Verlag.
Subrahmanian, V. S., Bonatti, P., Dix, J., Eiter, T., Kraus, S., Ozcan, F., & Ross, R. (2000).
Heterogeneous Agent Systems. MIT Press/AAAI Press, Cambridge, MA, USA.
Thomas, S. R. (1995). PLACA agent programming language. Wooldridge, M. J., &
Jennings, N. R. (Eds.), Intelligent Agents, pp. 355370, Berlin. Springer-Verlag.
van Otterlo, M., Wiering, M., Dastani, M., & Meyer, J.-J. (2003). Characterization
Sapient Agents. Hexmoor, H. (Ed.), International Conference Integration
Knowledge Intensive Multi-Agent Systems (KIMAS-03), pp. 172177, Boston, Massachusetts. IEEE.
Wooldridge, M. (2002). Introduction Multiagent Systems. John Wiley & Sons.
Yip, A., Forth, J., Stathis, K., & Kakas, A. C. (2005). Software Anatomy KGP Agent.
Gleizes, M. P., Kaminka, G. A., Nowe, A., Ossowski, S., Tuyls, K., & Verbeeck, K.
(Eds.), EUMAS 2005 - Proceedings Third European Workshop Multi-Agent
Systems, pp. 459472. Koninklijke Vlaamse Academie van Belie voor Wetenschappen
en Kunsten.

348


