Journal Artificial Intelligence Research 33 (2008) 349-402

Submitted 05/08; published 11/08

Learning Partially Observable Deterministic Action Models
EYAL @ ILLINOIS . EDU

Eyal Amir
Computer Science Department
University Illinois, Urbana-Champaign
Urbana, IL 61801, USA

ALLENC 256@ YAHOO . COM

Allen Chang
2020 Latham st., apartment 25
Mountainview, CA 94040, USA

Abstract
present exact algorithms identifying deterministic-actions effects preconditions
dynamic partially observable domains. apply one know action model (the
way actions affect world) domain must learn partial observations time.
scenarios common real world applications. challenging AI tasks
traditional domain structures underly tractability (e.g., conditional independence) fail
(e.g., world features become correlated). work departs traditional assumptions
partial observations action models. particular, focuses problems actions
deterministic simple logical structure observation models features observed
frequency. yield tractable algorithms modified problem domains.
algorithms take sequences partial observations time input, output deterministic action models could lead observations. algorithms output one
models (depending choice), exact model misclassified given
observations. algorithms take polynomial time number time steps state features
traditional action classes examined AI-planning literature, e.g., STRIPS actions.
contrast, traditional approaches HMMs Reinforcement Learning inexact exponentially intractable domains. experiments verify theoretical tractability guarantees,
show identify action models exactly. Several applications planning, autonomous
exploration, adventure-game playing already use results. promising
probabilistic settings, partially observable reinforcement learning, diagnosis.

1. Introduction
Partially observable domains common real world. involve situations one
cannot observe entire state world. Many examples situations available
walks life, e.g., physical worlds (we observe position items rooms),
Internet (we observe web pages time), inter-personal communications (we observe state mind partners).
Autonomous agents actions involve special kind partial observability domains.
agents explore new domain (e.g., one goes building meets new person),
limited knowledge action models (actions preconditions effects). action models change time, may depend state features. agents act
intelligently, learn actions affect world use knowledge respond
goals.
c
2008
AI Access Foundation. rights reserved.

fiA MIR & C HANG

Learning action models important goals change. agent acted while,
use accumulated knowledge actions domain make better decisions. Thus, learning
action models differs Reinforcement Learning. enables reasoning actions instead
expensive trials world.
Learning actions effects preconditions difficult partially observable domains.
difficulty stems absence useful conditional independence structures domains.
fully observable domains include structures, e.g., Markov property (independence
state time + 1 state time 1, given (observed) state time t).
fundamental tractable solutions learning decision making.
partially observable domains structures fail (e.g., state world time + 1
depends state time 1 observe state time t), complex
approximate approaches feasible path. reasons, much work far
limited fully observable domains (e.g., Wang, 1995; Pasula, Zettlemoyer, & Kaelbling, 2004),
hill-climbing (EM) approaches unbounded error deterministic domains (e.g., Ghahramani, 2001; Boyen, Friedman, & Koller, 1999), approximate action models (Dawsey, Minsker,
& Amir, 2007; Hill, Minsker, & Amir, 2007; Kuffner. & LaValle, 2000; Thrun, 2003).
paper examines application old-new structure learning partially observable
domains, namely, determinism logical formulation. focuses deterministic domains tractable learning feasible, shows traditional assumption form
determinism (the STRIPS assumption, generalized ADL, Pednault, 1989) leads tractable
learning state estimation. Learning domains immediate applications (e.g., exploration planning, Shahaf, Chang, & Amir, 2006; Chang & Amir, 2006) serve
basis learning stochastic domains. Thus, fundamental advance application
structure important opening field new approaches broader applicability.
following details technical aspects advance.
main contribution paper approach called SLAF (Simultaneous Learning
Filtering) exact learning actions models partially observable deterministic domains.
approach determines set possible transition relations, given execution sequence actions
partial observations. example, input could come watching another agent act
watching results actions execution. approach online, updates
propositional logical formula called Transition Belief Formula. formula represents possible
transition relations world states every time step. way, similar spirit Bayesian
learning HMMs (e.g., Ghahramani, 2001) Logical Filtering (Amir & Russell, 2003).
algorithms present differ range applicability computational
complexity. First, present deduction-based algorithm applicable nondeterministic
learning problem, takes time worst-case exponential number domain fluents.
Then, present algorithms update logical encoding consistent transition relations
polynomial time per step, limited applicability special classes deterministic
actions.
One set polynomial-time algorithms present applies action-learning scenarios
actions ADL (Pednault, 1989) (with conditional effects) one following
holds: (a) action model already preconditions known, observe action failures (e.g.,
perform actions domain), (b) actions execution always succeeds (e.g.,
expert tutor performs actions).
350

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

algorithms output transition belief formula represents possible transition relations
states partial observations state actions. updating component
formula separately linear time. Thus, updating transition belief formula every
action execution observation takes linear time size input formula.
Processing sequence action executions observations takes time O(T 2 n) case
(b). main reason linear growth representation size transition belief
formula: time t, iterative process updates formula would process formula
size linear t.
case (a) processing sequence length takes polynomial time O(T n k )),
observe every feature domain every k steps expectation, fixed k. reason
transition belief formula kept k-CNF (k Conjunctive Normal
V Form),
W thus
size O(nk ). (Recall propositional formula k-CNF, form im jk li,j ,
every li,j propositional variable negation.) Case (b) takes time O(T n)
assumption.
Another set polynomial-time algorithms present takes linear time representation
size. case actions known injective, i.e., map states 1:1. There, bound
computation time steps O(T nk ), approximate transition-belief formula
representation k-CNF formula.
contrast, work learning Dynamic Bayesian Networks (e.g., Boyen et al., 1999), reinforcement learning POMDPs (e.g., Littman, 1996), Inductive Logic Programming (ILP)
(e.g., Wang, 1995) either approximate solution unbounded error deterministic domains,
n
take time (22 ), inapplicable domains larger 10 features. algorithms
better respect, scale polynomially practically domains 100s features
more. Section 8 provides comparison works.
conduct set experiments verify theoretical results. experiments show
algorithms faster better qualitatively related approaches. example,
learn ADL actions effects domains > 100 features exactly efficiently.
important distinction must made learning action models traditional creation
AI-Planning operators. perspective AI Planning, action models result
explicit modeling, taking account modeling decisions. contrast, learning action models
deducing possible transition relations compatible set partially observed
execution trajectories.
particular, action preconditions typically used knowledge engineer control
granularity action model leave aside specification unwanted cases. example,
driving truck insufficient fuel one site another might generate unexpected situations
modeller want consider, simple precondition used avoid considering case. intention paper mimic modeling perspective, instead
find action models generate sound states starting sound state. Sound state
state system practice, namely, ones observations real executions
reflect.
technical advance deterministic domains important many applications
automatic software interfaces, internet agents, virtual worlds, games. applications,
robotics, human-computer interfaces, program machine diagnosis use deterministic
action models approximations. Finally, understanding deterministic case better help us
351

fiA MIR & C HANG

develop better results stochastic domains, e.g., using approaches Boutilier,
Reiter, Price (2001), Hajishirzi Amir (2007).
following, Section 2 defines SLAF precisely, Section 3 provides deduction-based exact
SLAF algorithm, Section 4 presents tractable action-model-update algorithms, Section 5 gives sufficient conditions algorithms keeping action-model representation compact (thus, overall
polynomial time), Section 7 presents experimental results.

2. Simultaneous Learning Filtering (SLAF)
Simultaneous Learning Filtering (SLAF) problem tracking dynamic system
sequence time steps partial observations, systems complete
dynamics initially. solution SLAF representation combinations action models
could possibly given rise observations input, representation
corresponding states system may (after sequence time steps
given input occurs).
Computing (the solution for) SLAF done recursive fashion dynamic programming
determine SLAF time step t+1 solution SLAF time t. section
define SLAF formally recursive fashion.
Ignoring stochastic information assumptions, SLAF involves determining set possible
ways actions change world (the possible transition models, defined formally below)
set states system might in. transition model determines set possible states,
solution SLAF transition model associated possible states.
define SLAF following formal tools, borrowing intuitions work Bayesian
learning Hidden Markov Models (HMMs) (Ghahramani, 2001) Logical Filtering (Amir &
Russell, 2003).
Definition 2.1 transition system tuple hP, S, A, Ri,
P finite set propositional fluents;
P ow(P) set world states.
finite set actions;
R transition relation (transition model).
Thus, world state, S, subset P contains propositions true state (omitted
propositions false state), R(s, a, s0 ) means state s0 possible result action
state s. goal paper find R, given known P, S, A, sequence actions
partial observations (logical sentences subset P).
Another, equivalent, representation use paper following.
literal proposition, p P, negation, p. complete term P conjunction
literals P every fluent appears exactly once. Every state corresponds complete
term P vice versa. reason, sometime identify state term. E.g.,
states s1 , s2 , s1 s2 disjunction complete terms corresponding 1 , s2 , respectively.
transition belief state set tuples hs, Ri state R transition relation.
Let R = P ow(S S) set possible transition relations S, A. Let = R.
hold transition belief state consider every tuple hs, Ri possible.

352

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

Figure 1: Locked door unknown key domain.
Example 2.2 Consider domain agent room locked door (see Figure 1).
possession three different keys, suppose agent cannot tell observation
key opens door. goal agent unlock door.
domain represented follows: let set variables defining state space
P = {locked} locked true door locked. Let set states
= {s1 , s2 } s1 = {locked} (the state door locked) s2 = {} (here
door unlocked). Let = {unlock1 , unlock2 , unlock3 } three actions wherein agent
tries unlocking door using three keys.
Let R1 = {hs1 , unlock1 , s2 i, hs1 , unlock2 , s1 i, hs1 , unlock3 , s1 i} represent transition relation key 1 unlocks door keys not. Define R 2 R3 similar
fashion (e.g., R2 key 2 unlocks door keys 1 3 not). transition belief state
represents set possibilities consider consistent observations far. Consider
transition belief state given = {hs1 , R1 i, hs1 , R2 i, hs1 , R3 i}, i.e., state world
fully known action model partially known.
would agent able open door despite knowing key opens it.
this, agent learn actual action model (i.e., key opens door). general,
learning action model useful achieving immediate goal, knowledge
useful agent attempts perform tasks domain.2
Definition 2.3 (SLAF Semantics) Let transition belief state. SLAF
actions observations haj , oj i1jt defined
1. SLAF [a]() =
{hs0 , Ri | hs, a, s0 R, hs, Ri };
2. SLAF [o]() = {hs, Ri | true s};
3. SLAF [haj , oj iijt ]() =
SLAF [haj , oj ii+1jt ](SLAF [oi ](SLAF [ai ]())).
Step 1 progression a, Step 2 filtering o.
Example 2.4 Consider domain Example 2.2. progression action unlock 1
given SLAF [unlock1 ]() = {hs2 , R1 i, hs1 , R2 i, hs1 , R3 i}. Likewise, filtering
observation locked (the door became unlocked) given SLAF [locked]() = {hs 2 , R1 i}.2
353

fiA MIR & C HANG

Example 2.5 slightly involved example following situation presented Figure 2.
There, two rooms, light bulb, switch, action flipping switch, observation, E (we east room). real states world action, s2, s2 0 ,
respectively (shown top part), known us.
West

East


PSfrag replacements

West


s2 = sw lit E



=
sw-on

<s1,R1>

1

East

s20 = sw lit E
<s1,R1>

<s3,R3>

<s1,R1>
<s3,R3>

<s2,R2>



<s2,R2>

2

Figure 2: Top: Two rooms flipping light switch. Bottom: SLAF semantics; progressing
action (the arrows map state-transition pairs) filtering observation
(crossing pairs).
bottom Figure 2 demonstrates knowledge evolves performing action sw-on.
There, 1 = {hs1 , R1 i, hs2 , R2 i, hs3 , R3 i} s1 , R1 , s3 , R3 , s2 = {E}, R2 includes hs2 , sw-on, s02 (the identity full details R1 , R2 , R3 irrelevant here, omit
them). 2 resulting transition belief state action sw-on observation E: 2 =
SLAF [sw-on, E](1 ). 2
assume observations (and observation model relating observations state fluents)
given us logical sentences fluents performing action. denoted
o.
approach transition belief states generalizes Version Spaces action models (e.g.,
Wang, 1995) follows: current state, s, known, version spaces lattice contains
set transition relations = {R | hs, Ri }. Thus, perspective version spaces,
SLAF semantics equivalent set version spaces, one state might be.
semantics generalizes belief states: transition relation, R, known,
belief state (set possible states) R = {s | hs, Ri } (read restricted R), Logical
Filtering (Amir & Russell, 2003) belief state action equal (thus, define as)
F ilter[a]() = (SLAF [a]({hs, Ri | }))R .
Thus, SLAF semantics equivalent holding set belief states, conditioned transition
relation, similar saying transition relation R, belief state (set states) R .

3. Learning Logical Inference
Learning transition models using Definition 2.3 directly intractable requires space (2 2 )
many cases. reason explicit representation large set possible
transition-state pairs. Instead, section rest paper represent transition belief states compactly using propositional logic. many scenarios amount
structure exploited make propositional representation compact.
|P|

354

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

combinatorial argument implies encoding compact sets. Nonetheless,
motivated success propositional (logical) approaches logical filtering (Amir & Russell,
2003; Shahaf & Amir, 2007) logical-database regression (Reiter, 1991, 2001), observe
propositional logic represents compactly natural sets exponential size.
section re-define SLAF operation propositional logical formulas
propositional formula output. SLAFs input propositional formula represents transition
belief state, SLAF computes new transition belief formula input sequence
actions observations.
want find algorithms SLAF manipulate input formula produce correct
output. use general-purpose logical inference task section. later sections
sidestep expensive general-purpose inference, make assumptions lead tractable algorithms. rest paper focus deterministic transition relations, namely, transition
relations partial functions (every action one outcome state every state).
3.1 Representing Transition Relations Logic
initial algorithm solving SLAF (to presented momentarily) compact
representation transition belief states. present logical encoding transition belief states
first, define deduction-based algorithm next section.
use following general terminology propositional logical languages (all terminological conventions apply without subscripts superscripts). L denotes vocabulary, i.e.,
set propositional variables use present context. L denotes language, i.e., set
propositional sentences. , , script Greek letters stand propositional formulas
language present context. F, G stand formulas, restricted context
(see below). L() denotes vocabulary . L(L) denotes language built propositions
L using standard propositional connectives (, , ,...). L() shorthand L(L()).
represent deterministic transition relations propositional vocabulary, L , whose
propositions form aFG , A, F literal P, G logical formula. F
effect aFG , G precondition aFG . proposition aFG takes truth value TRUE,
intended meaning G holds present state, F holds state
results executing a.
let F P {p | p P} set effects, F , consider. let G
set preconditions, G, consider. rest section Section 4 assume
G represents single state S. Recall identify state complete term
conjunction literals hold state. use representation states write Fs
instead aFG . Later build definition consider Gs general formulas.
assumption (G now, stated above) conclude L O(2|P| 2|P|
|A|) propositional variables. prove fundamental results language set axioms,
disregarding size language moment. Section 5 focuses decreasing language
size computational efficiency.
semantics vocabulary LA lets every interpretation (truth assignment), , LA correspond transition relation, RM . Every transition relation least one (possibly more)
interpretation corresponds it, correspondence surjective (onto) injective
(1-to-1). Every propositional sentence L(LA ) specifies set transition models follows:
355

fiA MIR & C HANG

set models1 (satisfying interpretations) , I[] = {M interpretation LA | |= },
specifies corresponding set transition relations, {RM | I[]}.
Informally, assume propositions aFs 1 , ...aFs k LA take value TRUE ,
propositions precondition
V take value FALSE. Then, R (with action0 a) takes
0
state state satisfies ik , identical otherwise. exists (e.g.,
= Fj , i, j k), RM takes s0 (thus, executable according
RM ).
following paragraphs show interpretations L correspond transition relations.
culminate precise definition correspondence formulas L(L P)
transition belief states S.
E NTERPRETATION LA C ORRESPONDS U NIQUE RANSITION R ELATION
Every interpretations LA defines unique transition relation RM follows. Let interpretation LA . every state action either define unique state 0
hs, a, s0 RM decide s0 hs, a, s0 RM .
gives interpretation every proposition aFs , F fluent negation.
fluent p P, [aps ] = [ap
] = TRUE (M [] truth value according interpretation
), decide s0 hs, a, s0 RM . Otherwise, define
s0 = {p P | |= aps } {p | |= ap
}
left-hand side consider cases p P [a ps ] 6= [ap
],
right-hand side treat cases p P [aps ] = [ap
] = F ALSE (this
called inertia p keeps previous value lack specifications). Put another way,
0
s0 [p] = [aps ] (s[p] [ap
]), view interpretation P. RM well defined, i.e.,
one RM every .
E RANSITION R ELATION
LA



L EAST NE C ORRESPONDING NTERPRETATION



possible RM = RM 0 6= 0 . occurs two circumstances: (a) cases
hs, a, s0 RM s, (b) [aps ] = [ap
] = F ALSE (inertia)
p
p
0
0
[as ] = s[p], [as ] = s[p] (not inertia).
example first circumstance, let p fluent, let interpretation
0
[aps ] = [ap
] G. Define interpretation identical propositions
p p
p
0
besides , follows. Define [as ] opposite truth assignment [aps ] (FALSE
p
instead TRUE, TRUE instead FALSE). Define 0 [ap
] = [as ].
Then, RM = RM 0 map pairs s, way. particular, state
corresponds G, hs, a, s0 RM similarly hs, a, s0 RM 0 .
Finally, every transition relation R least one interpretation R = R . see
this, define MR every hs, a, s0 R interpretation aps (p fluent) MR [aps ] = RU E iff
/ s0 . Finally, s,
p s0 . Also, hs, a, s0 define MR [ap
] = F ALSE iff p
p
p
s0 , define MR [as ] = MR [as ] = RU E. Then, R = RMR .
1. overload word model multiple related meanings. model refers satisfying interpretation logical
formula. Transition model defined Definition 2.1 transition relation transition system. Action model
define Introduction section well-defined specification actions preconditions effects.

356

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

E RANSITION R ELATION EFINES F ORMULA LA
Every deterministic transition relation R defines logical formula whose set models map
R. many possible formulas, define general one (up logical
equivalence) make use inertia.
Define h(R) follows.
F
0
0
h0 (R) = {aFs , aF
| LA , hs, a, R, |= F }
p
p
h1 (R) = {as | p P, S}

W
0
0
h2 (R) = { pP (aps ap
) | , hs, a, R}
h(R) = h0 (R) h1 (R) h2

h0 addresses fluent changes, h1 addresses fluent innertia (effectively disallowing innertia
definition), h2 addresses conditions actions executable. Thus, h(R)
includes model every interpretation satisfies RM = R requires inertia
definition RM . represents R models satisfies RM = R.
illuminating see modeling decisions (above throughout section) lead
last definition. one hand, choose every interpretation L correspond
transition relation (we simplify later arguments logical entailment). Consequently, associate interpretations [aFs ] = [aF
] = F ALSE transition relations R(s, a, s0 ) keep value F fixed s, s0 (this inertia F a, s).
hand, define h(R) above, choose axioms exclude models (thus,
avoid models include inertia) simplifies later discussion learning algorithms.
summary, consider every interpretation LA representing exactly one transition relation, consider set axioms defining R define directly, i.e., without inertia
(without [aFs ] = [aF
] = F ALSE).
RANSITION B ELIEF TATES C ORRESPOND F ORMULAS LA P
Thus, every
W transition belief state define formula L(L P) corresponds
it: h() = hs,Ri (s h(R)). formulas exist would characterize similar way,
equivalent. stronger formulas L(L )
|= h(R) h(R) 6|= every model, , satisfies RM = R.
Similarly, every formula L(LA P) define transition belief state () = {hM P
, RM | |= , }, i.e., state-transition pairs satisfy (M P restricted
P, viewed complete term P). say formula transition belief formula,
h(()) (note: (T h()) = always holds).
3.2 Transition-Formula Filtering
section, show computing transition belief formula SLAF [a]() successful
action transition belief formula equivalent logical consequence finding operation.
characterization SLAF consequence-finding permits using consequence finding
algorithm SLAF, important later paper proving correctness
tractable, specialized algorithms.
Let CnL () denote set logical consequences restricted vocabulary L. is,
L
Cn () contains set prime implicates contain propositions set L.
357

fiA MIR & C HANG

Recall implicate formula clause entailed ( |= ). Recall prime implicate formula implicate subsumed (entailed) implicates
.
Consequence finding process computes CnL () input, . example, propositional resolution (Davis & Putnam, 1960; Chang & Lee, 1973) efficient consequence finder
used properly (Lee, 1967; del Val, 1999) (Marquis, 2000, surveys results prime implicates consequence finding algorithms). Thus, Cn L () { L(L)| |= }.
set propositions P, let P 0 represent set propositions every proposition primed (i.e., proposition f annotated become f 0 ). Typically, use primed
fluent denote value unprimed fluent one step future taking action. Let
[P 0 /P] denote formula , primed fluents replaced unprimed counterparts. example, formula (a b0 )[P 0 /P] equal b b P. (See Section 8
discussion comparison relevant formal verification techniques.)
following lemma shows logical equivalence existential quantification quantified
boolean formulas consequence finding restricted vocabulary. Recall quantified boolean
formulas (QBF) propositional formulas addition existential universal quantifiers
propositions. Informally, QBF x. true given interpretation
exists true/false valuation x makes true assignment. lemma prove
useful showing equivalence SLAF consequence-finding.
Lemma 3.1 x. CnL()\{x} (), propositional logic formula propositional variable x.
P ROOF
See Section B.1. 2
lemma extends easily case multiple variables:
Corollary 3.2 formula set propositional variables X, X. Cn L()\X ().
present algorithm updating transition belief formulas whose output equivalent
SLAF (when SLAF applied equivalent transition belief state). algorithm applies
consequence finding input transition belief formula together set axioms define
transitions time steps. present set axioms first.
deterministic (possibly conditional) action, a, action model (for time t) axiomatized
V
Teff (a) = lF ,GG ((alG G) l0 )
W
V
(1)
l
0
lF (l ( GG (aG G)))

first part (1) says assuming executes time t, causes l G holds, G
holds time t, l holds time + 1. second part says l holds execution,
must alG holds G holds current state. two parts similar
(in fact, somewhat generalize) effect axioms explanation closure axioms used Situation
Calculus (see McCarthy & Hayes, 1969; Reiter, 2001).
Now, ready describe zeroth-level algorithm (SLAF 0 ) SLAF transition
belief formula. Let L0 = P 0 LA vocabulary includes fluents time t+1 effect
propositions LA . Recall (Definition 2.3) SLAF two operations: progression (with
action) filtering (with observation). time apply progression given action
current transition belief formula, , apply filtering current observations:
358

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

0

t+1 = SLAF0 [at , ot ](t ) = (CnL (t Teff (at )))[P 0 /P] ot

(2)

identical Definition 2.3 (SLAF semantics), replacing 1 2.
0
stated above, SLAF0 implement CnL () using consequence finding algorithms
resolution variants (e.g., Simon & del Val, 2001; McIlraith & Amir, 2001;
Lee, 1967; Iwanuma & Inoue, 2002). following theorem shows formula-SLAF algorithm correct exact.
Theorem 3.3 (Representation) transition belief formula, action,
SLAF [a]({hs, Ri | hs, Ri satisfies }) =
{hs, Ri | hs, Ri satisfies SLAF0 [a]()}
P ROOF
See Section B.2. 2
theorem allows us identify SLAF0 SLAF , throughout rest
paper. particular, show polynomial-time algorithms SLAF special cases correct
showing output logically equivalent SLAF 0 .
U SING



UTPUT



SLAF0

output algorithm SLAF transition belief formula logical formula. way
use formula answering questions SLAF depends query form
output formula. wish find transition model state possible, wish see
|= , interpretation L = P LA output SLAF0 .
answer found simple model-checking algorithm 2 . example, check
interpretation satisfies logical formula assign truth values variables interpretation formula; computing truth value formula done linear time.
Thus, type query SLAF takes linear time size output formula
SLAF final query propositional interpretation propositional formula.
wish find transition model possible state possible,
propositional satisfiability (SAT) solver algorithms (e.g., Moskewicz, Madigan, Zhao, Zhang, &
Malik, 2001). Similarly, wish answer whether possible models satisfy property
use SAT solver.
Example 3.4 Recall Example 2.4 discuss locked door three combinations. Let
0 = locked, let 1 = SLAF0 [unlock2 , locked](0 ). wish find 1 implies trying
unlock door key 2 fails open it. equivalent asking models consistent
1 give value TRUE unlock2locked
locked .
answer query taking SLAF0 output formula, 1 , checking 1
unlock2locked
locked SAT (has model). (Follows Deduction Theorem propositional logic:
|= iff SAT.)
One example application approach goal achievement algorithm Chang Amir
(2006). relies SAT algorithms find potential plans given partial knowledge encoded
transition belief formula.
2. model checking sense used Formal Verification literature. There, model transition
model, checking done updating formula OBDD transformations

359

fiA MIR & C HANG

zeroth-level algorithm may enable compact representation, guarantee
it, guarantee tractable computation. fact, algorithm maintain compact representation tractable computation general. Deciding clause true result SLAF
coNP-hard similar decision problem Logical Filtering coNP-hard (Eiter & Gottlob, 1992; Amir & Russell, 2003) even deterministic actions. (The input representation
problems includes initial belief state formula CNF. input representation Filtering
includes propositional encoding CNF (known) transition relation.)
Also, representation transition belief states uses poly(|P|) propositions grows exponentially (in number time steps |P|) starting transition belief states action
sequences, actions allowed nondeterministic 3 . question whether exponential growth must happen deterministic actions flat formula representations (e.g., CNF,
DNF, etc.; see Darwiche & Marquis, 2002) open (logical circuits known give solution
deterministic actions, representation given terms fluents time 0, Shahaf et al.,
2006).

4. Factored Formula Update
Update representation hard must consider set interactions parts
representation. Operations used SLAF 0 consider interactions, manipulate
them, add many interactions result. processing broken independent
pieces, computation scales linearly number pieces (i.e., computation time
total times takes piece separately). So, important find decompositions
enable independent pieces computation. Hereforth examine one type decomposition,
namely, one follows logical connectives.
Learning world models easier SLAF distributes logical connectives. function,
f , distributes logical connective, {, , ...}, f ( ) f () f (). Computation
SLAF becomes tractable, distributes , . bottleneck computation case
becomes computing SLAF part separately.
section examine conditions guarantee distribution, present linear-time
algorithm gives exact solution cases. show algorithm
gives weaker transition belief formula distribution possible.
Distribution properties always hold SLAF follow set theoretical considerations
Theorem 3.3:
Theorem 4.1 , transition belief formulas, action,
SLAF [a]( ) SLAF [a]() SLAF [a]()
|= SLAF [a]( ) SLAF [a]() SLAF [a]()
P ROOF
See Appendix B.3. 2
Stronger distribution properties hold SLAF whenever hold Logical Filtering.
Theorem 4.2 Let 1 , 2 transition belief states.
SLAF [a](1 2 ) = SLAF [a](1 ) SLAF [a](2 )
3. follows theorem filtering Amir Russell (2003), even provide proper axiomatization
(note axiomatization deterministic actions only).

360

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

iff every R
R
R
R
F ilter[a](R
1 2 ) = F ilter[a](1 ) F ilter[a](2 ).

conclude following corollary Theorems 3.3, 4.2 theorems Amir Russell
(2003).
Corollary 4.3 , transition belief formulas, action, SLAF [a]( ) SLAF [a]()
SLAF [a]() every relation R , one following holds:
1. R maps states 1:1
2. R conditional effects, includes prime implicates, observe
fails
3. state known R: one s, hs, Ri .
Condition 2 combines semantics syntax. particularly useful correct computation
SLAF later sections. states particular syntactic form (namely, together
include joint prime implicates), simple enough (but necessarily 1:1),
computation SLAF broken separate SLAF .
Figure 3 presents Procedure Factored-SLAF, computes SLAF exactly conditions Corollary 4.3 hold. Consequently, Factored-SLAF returns exact solution whenever
actions known 1:1. actions conditional effects success/failure
observed, modified Factored-SLAF solve problem exactly (see Section 5).
PROCEDURE Factored-SLAF(hai , oi i0<it ,)
i, ai action, oi observation, transition belief formula.
1. 1 do,
(a) Set Step-SLAF(oi ,ai ,).
(b) Eliminate subsumed clauses .
2. Return .
PROCEDURE Step-SLAF(o,a,)
observation formula L(P), action, transition belief formula.
1. literal, return oLiteral-SLAF(a,).
2. = 1 2 , return Step-SLAF(o,a,1 )Step-SLAF(o,a,2 ).
3. = 1 2 , return Step-SLAF(o,a,1 )Step-SLAF(o,a,2 ).
PROCEDURE Literal-SLAF(a,)
action, proposition Lt negation.
0
1. Return CnL ( Teff (a))[P 0 /P ] .

Figure 3: SLAF using distribution ,
pre-compute (and cache) 2n possible responses Literal-SLAF, every time step
procedure requires linear time representation size , transition belief formula
time step. significant improvement (super exponential) time taken
straightforward algorithm, (potentially exponential) time taken general-purpose
consequence finding used zeroth-level SLAF procedure above.
Theorem 4.4 Step-SLAF(a, o, ) returns formula 0 SLAF [a, o]() |= 0 . every run
Literal-SLAF takes time c, Step-SLAF takes time O(||c). (recall || syntactic,
representation size .) Finally, assume one assumptions Corollary 4.3,
0 SLAF [a, o]().
361

fiA MIR & C HANG

belief-state formula transition belief formula effect propositions, i.e., includes fluent variables propositions form FG . identical traditional
use term belief-state formula, e.g., (Amir & Russell, 2003). give closed-form solution SLAF belief-state formula (procedure Literal-SLAF Figure 3). makes
procedure Literal-SLAF tractable, avoiding general-purpose inference filtering single literal,
allows us examine structure belief state formulas detail.
V
Theorem 4.5 belief-state formula L(P), action a, Ca = GG,lF (alG al
G ),
G1 , ..., Gm G terms G Gi |= ,
SLAF [a]()

^


_

li
(li aG
) Ca


l1 ,...,lm F i=1

V

Here, l1 ,...,lm F means conjunction possible (combinations of) selections literals
F.
P ROOF
See Appendix B.4. 2
theorem significant says write result SLAF
prescribed form. form still potentially exponential size, boils simple
computations. proof follows straightforward (though little long) derivation possible
prime implicates SLAF [a](t ).
consequence Theorem 4.5 implement Procedure Literal-SLAF using
equivalence


Theorem 4.5
L(l) P
SLAF [a](l)
l SLAF [a](TRUE) otherwise

Notice computation Theorem 4.5 = l literal simple G 1 , ..., Gm
complete terms L(P) include l. computation require general-purpose
consequence finder, instead need answer 2n+1 queries initialization phase, namely,
storing table values SLAF [a](l) l = p l = p p P
l = TRUE.
general, could high 2|P| , number complete terms G, finding G1 , ..., Gm
may take time exponential |P|. Still, simplicity computation formula provide
basic ingredients needed efficient computations following sections restricted cases.
give guidelines future developments SLAF algorithms.

5. Compact Model Representation
Previous sections presented algorithms potentially intractable long sequences actions
observations. example, Theorem 4.5, could high 2 |P| , number complete
terms G. Consequently, clauses may exponential length (in n = |P|) may
super-exponential number clauses result.
section focus learning action models efficiently presence action preconditions failures. important agents partial domain knowledge
therefore likely attempt inexecutable actions.
restrict attention deterministic actions conditional effects, provide
overall polynomial bound growth representation, size many steps,
362

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

time taken compute resulting model. class actions generalizes STRIPS (Fikes, Hart,
& Nilsson, 1972), results apply large part AI-planning literature.
give efficient algorithm learning non-conditional deterministic action effects
preconditions, well efficient algorithm learning actions effects presence
action failures.
5.1 Actions Limited Effect
many domains assume every action affects k fluents, small k > 0.
common assume actions STRIPS, may fail without us knowing,
leaving world unchanged. assumptions together allow us progress SLAF limited
(polynomial factor) growth formula size.
use language similar one Section 3, uses action propositions
alG G
fluent term size k (instead fluent term size n G). Semantically,
V
l
al1 ...lk lk+1 ,...,ln all1 ...ln .
Theorem 5.1 Let L(P) belief-state formula, STRIPS action k fluents
affected precondition term. Let G k set terms k fluents L(P)
consistent . Then,
SLAF [a]()

^

k
_

li
(li aG
) Ca


i=1
G1 , ..., Gk G k
G1 ... Gk |=
l1 , ..., lk F

V
Here, ... refers conjunction possible (combinations of) selections literals
F G1 , ..., Gk G k G1 ... Gk |= .
P ROOF
See Section B.5. 2
main practical difference theorem Theorem 4.5 smaller number
terms need checked practical computation. limited language enables entails
limited number terms play here. Specifically, k literals
preconditions, need check combinations k terms G 1 , ..., Gk G k , computation
bounded O(exp(k)) iterations.
proof uses two insights. First, one case change occurs, every
clause Theorem 4.5 subsumed clause entailed SLAF [a]( ), one
alGi per literal li (i.e., li 6= lj 6= j) Gi fluent term (has disjunctions). Second, every
alG G term equivalent formula alGi Gi terms length k, affects k
fluents.
Thus, encode clauses conjunction using subset (extended) action
effect propositions, alG , G term size k. O(nk ) terms, O(nk+1 )
propositions. Every clause length 2k, identity clause determined
2
first half (the set action effect propositions). Consequently, SLAF [a]( ) takes O(nk +k k 2 )
2
space represent using O(nk +k ) clauses length 2k.
363

fiA MIR & C HANG

5.2 Actions Conditional Effects: Revised Language
thisSsection reformulate representation presented Section 3.1. Let
L0f = aA {af , af , af , a[f ] , a[f ] } every f P. Let vocabulary formulas representing transition belief states defined L = P L0f . intuition behind propositions
vocabulary follows:
V
al causes l literal l. Formally, al sS als .
V
af keeps f . Formally, af sS ((s f ) afs ) ((s f ) af
).
V
).
(Thus, l
a[l] causes FALSE l. Formally, a[l] sS (s l) (als al

precondition executing a, must hold executes.)
model transition belief formula L, valuation fluents P defines
state. valuation propositions L0f defines unconditional deterministic transition
relation follows: action proposition af (af ) true action transition
relation causes f (f ) hold executed. Action proposition f true
action affect fluent f . Action proposition a[f ] (a[f ] ) true f (f )
precondition a. assume existence logical axioms disallow inconsistent
impossible models. axioms are:
1. af af af
2. (af af ) (af af ) (af af )


3. a[f ] a[f ]

possible f P. first two axioms state every action model, exactly one
af , af , af must hold (thus, causes f , negation, keeps f unchanged). last axiom
disallows interpretations a[f ] a[f ] hold. state axioms
need represent constraints explicitly transition belief formula itself.
use set theoretic propositional logic notations transition belief states interchangeably. Note vocabulary defined sufficient describing unconditional
STRIPS action model, deterministic action model general.
Example 5.2 Consider domain Example 2.2. transition belief state represented transition belief formula:
locked
((unlock1locked unlock2locked unlock3locked )
(unlock1locked unlock2locked unlock3locked )
(unlock1locked unlock2locked unlock3locked )).
2
provide axiomatization equivalent SLAF special case eff (1)
notation above. P P 0 . Recall intend primed fluents represent
value fluent immediately action taken.
364

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

eff (a)

^

Prea,f Effa,f

f P

Prea,f



^

(a[l] l)

l{f,f }

Effa,f



^

((al (af l)) l0 ) (l0 (al (af l))).

l{f,f }

Prea,f describes precondition action a. states literal l occurs precondition
literal l must held state taking a. formula Eff a,f describes effects
action a. states fluents taking action must consistent according
action model defined propositions af , af , af .
show revised axiomatization action models, eff , leads equivalent
definition SLAF within restricted action models.
0

Theorem 5.3 successful action a, SLAF [a]() Cn LP ( eff (a))[P 0 /P] .
P ROOF

See Appendix B.6. 2

5.3 Always-Successful Non-Conditional Actions
ready present algorithm learns effects actions conditional
effects. algorithm allows actions preconditions fully known. Still,
assumes filtered actions executed successfully (without failures), cannot effectively
learn preconditions (e.g., would know knew originally
preconditions seeing sequence events). sequence actions might, example,
generated expert agent whose execution traces observed.
algorithm maintains transition belief formulas special fluent-factored form, defined below. maintaining formulas special form, show certain logical consequence
finding operations performed efficiently. formula fluent-factored, conjunction formulas f f concerns one fluent, f , action propositions.
Also, every fluent, f , f conjunction positive element, negative element,
neutral one f (f explf ) (f explf ) Af , explf , explf , Af formulae action
propositions af , af , a[f ] , a[f ] , af (possibly multiple different actions). intuition
explf explf possible explanations f true false, respectively.
Also, Af holds knowledge actions effects preconditions f , knowledge
depend f current value. Note formula L(L f ) represented fluentfactored formula. Nonetheless, translation sometimes leads space blowup, maintain
representation form construction.
new learning algorithm, AS-STRIPS-SLAF4 , shown Figure 4. simplify exposition,
described case single action-observation pair, though obvious
apply algorithm sequences actions observations. Whenever action taken, first
subformulas Af , explf , explf f updated according steps 1.(a)-(c). Then,
4. AS-STRIPS-SLAF extends AE-STRIPS-SLAF (Amir, 2005) allowing preconditions actions

365

fiA MIR & C HANG

Algorithm AS-STRIPS-SLAF[ha, oi]()
Inputs:
V Successful action a, observation term o, fluent-factored transition belief formula =
f P f .

Returns: Fluent-factored transition belief formula SLAF [ha, oi]()
1. every f P
(a) Set Af (a[f ] explf ) (a[f ] explf ) Af
(b) Set explf (af (af a[f ] explf ))
(c) Set explf (af (af a[f ] explf ))

(d) |= f (f observed) seta , f (f >) (f ) Af explf
(e) |= f set f (f ) (f >) Af explf [Note: 6|= f
6|= f , nothing beyond earlier steps.]
2. Simplify (e.g., eliminate subsumed clauses ).
3. Return
a. term (f >) new explf , (f ) new explf . appear without simplification
conform Step 1a algorithm. emphasizes syntactic nature procedure,
implicit logical simplification assumed.

Figure 4: SLAF algorithm always successful STRIPS actions.
observation received, f updated according observation according steps
1.(d)-(e). Step 2 merely indicates implementations, likely simplification
procedure used formula subsumption elimination. However, use
simplification procedure strictly necessary order theoretical guarantees
algorithm hold.
example, know nothing actions affect f (e.g., start exploration),
f = (f RU E) (f RU E) RU E. representation, SLAF [a](f )
conjunction (f explf )(f explf )Af computed step 1 Procedure AS-STRIPS-SLAF.
similar formula holds observations.
following theorem shows correctness algorithm. shows steps taken
algorithm produce result equivalent logical consequence-finding characterization
SLAF Theorem 5.3.
Theorem 5.4 SLAF[ha, oi]() AS-STRIPS-SLAF[ha, oi]() fluent-factored formula ,
successfully executed action a, observation term o.
P ROOF
See Appendix B.7 2
time space complexity procedure AS-STRIPS-SLAF given following
theorem. time guarantee, shown procedure takes linear time size input
formula. condition algorithm receives observations often enoughspecifically
366

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

every fluent observed least every k calls procedureit possible show
transition belief formula remains k-CNF indefinitely (recall k-CNF
fixed k, conjunction clauses size k). Thus, regardless length actionobservation input sequence, output AS-STRIPS-SLAF value throughout
computation k-CNF. amounts space guarantee size formula.
Theorem 5.5 following true AS-STRIPS-SLAF:
1. procedure takes linear time size input formula single action, observation
pair input.
2. every fluent every k steps observation fluent one steps,
input formula k-CNF, resulting formula (after arbitrary number
steps) k-CNF.
3. input AS-STRIPS-SLAF fluent-factored, output.
P ROOF
See Appendix B.8 2
following corollary follows immediately above.
Corollary 5.6 order process steps actions observations, AS-STRIPS-SLAF requires
(T |P|) time. Additionally,
every fluentis observed every k steps, resulting
formula always size |P| |A|k .
Corollary holds Theorem 5.5(2) guarantees bound size belief-state
formula point algorithm.

5.4 Learning Actions May Fail
many partially observable domains, decision-making agent cannot know beforehand whether
action decides take fail succeed. section consider possible action failure,
assume agent knows whether action attempts fails succeeds trying
action.
precisely, assume additional fluent OK observed agent
OK true action succeeded. failed action, case, may viewed
extra observation agent preconditions action met. is,
action failure equivalent observation
^

(a[f ] f ) (a[f ] f ).
(3)
f P

Action failures make performing SLAF operation considerably difficult. particular,
observations form (3) cause interactions fluents value particular fluent
might longer depend action propositions fluent, action propositions
fluents well. Transition belief states longer represented convenient fluentfactored formulas cases, becomes difficult devise algorithms give
useful time space performance guarantees.
367

fiA MIR & C HANG

Algorithm PRE-STRIPS-SLAF[a, o]()
Inputs: Action observation
term o. transition belief formula following facV W
tored form: = j i,j , i,j fluent-factored formula.
Returns: Filtered transition belief formula
1. |= OK:
W
(a) Set F (li ) li literals appearing precondition,
F (l) V
fluent-factored formula equivalent l (i.e., F (l) = ((l >) (l
) >) f P ((f >) (f >) >))

(b) Set i,j AS-STRIPS-SLAF[o](i,j ) i,j
2. Else (o |= OK):
(a) i,j

i. Set i,j AS-STRIPS-SLAF[P ](i,j ), P precondition
ii. Set i,j AS-STRIPS-SLAF[ha, oi](i,j )
3. i,j factored Ai,j Bi,j Bi,j contains (and only) clauses containing
fluent P.
W exists B j, B i,j B, replace
W


B

j Ai,j
j i,j
4. Simplify i,j (e.g. remove subsumed clauses)
5. Return
Figure 5: Algorithm handling action failures preconditions known.
shall demonstrate, action failures dealt tractably assume action
preconditions known agent. is, agent must learn effects actions
take, need learn preconditions actions. particular, means
action a, algorithm given access formula (more precisely, logical term) P describing
precondition action a. Clearly, algorithm need learn preconditions
actions, restrict action proposition vocabulary used describe belief states
ones forms af , af , af , longer need action propositions forms a[f ]
a[f ] .
present procedure PRE-STRIPS-SLAF5 (Figure 5) performs SLAF transition belief
formulas presence action failures actions non-conditional effects. maintains transition belief
conjunctions disjunctions fluent-factored formulas (formulas
V formulas
W
form = j i,j i,j fluent factored). Naturally, formulas superset
fluent-factored formulas.
5. PRE-STRIPS-SLAF essentially identical CNF-SLAF (Shahaf et al., 2006)

368

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

algorithm operates follows: action executes successfully (and ensuing observation received), component fluent-factored formulas i,j filtered separately
according AS-STRIPS-SLAF procedure action-observation pair (Step 2).
hand, action fails, disjunction fluent-factored formulas appended transition
belief formula (Step 1). component disjunction corresponds one possible reasons action failed (i.e., one literals occurring actions precondition). Finally,
observations accumulated learning algorithm, collapses disjunctions fluent-factored
formulas occurring belief formula together (Step 3) simplifies generally (Step 4),
decreasing total size formula. case AS-STRIPS-SLAF, simplification
steps necessary order time space guarantees hold.
proof correctness Algorithm PRE-STRIPS-SLAF relies distribution results
Section 4, Theorem 4.1 Corollary 4.3.
proceed show correctness PRE-STRIPS-SLAF. following theorem shows
procedure always returns filtered transition belief formula logically weaker
exact result, always produces safe approximation. Additionally, theorem shows
conditions Corollary 4.3, filtered transition belief formula exact result.
Theorem 5.7 following true:
1. SLAF[a, o]() |= PRE-STRIPS-SLAF[a, o]()
2. PRE-STRIPS-SLAF[a, o]() SLAF[a, o]() Corollary 4.3 holds.
P ROOF
See Appendix B.9. 2
consider time space complexity algorithm. following theorem shows
(1) procedure time efficient, (2) given frequent enough observations (as Theorem
5.5), algorithm space efficient transition belief formula stays indefinitely compact.
Theorem 5.8 following true PRE-STRIPS-SLAF:
1. procedure takes time linear size formula single action, observation pair
input.
2. every fluent observed every k steps input formula k-CNF,
filtered formula k-CNF, maximum number literals action
precondition.
P ROOF
See Appendix B.10 2
Therefore, get following corollary:
Corollary 5.9 order process steps actions observations, PRE-STRIPS-SLAF requires
(T |P|) time. every fluent
observed least
frequently every k steps, resulting
mk
formula always size |P| |A|
.

6. Building Results
section describe briefly one might extend approach include elaborate
observation model, bias, parametrized actions.
369

fiA MIR & C HANG

6.1 Expressive Observation Model
observation model use throughout paper simple: every state, fluent
observed value v, value current state. consider observation
model general.
observation model, O, set logical sentences relates propositions set Obs
fluents P. Obs includes propositions appear P, independent
previous following state (times 1 + 1) given fluents time t.
SLAF result conjoining CnLt (oO), i.e., finding prime implicates
conjoining . embed extension SLAF algorithms above,
maintain structures algorithms use. k-CNF every step
observe (at most) 1 variable, finding prime implicates easy. Embedding
transition-belief formula done conjunction prime implicates formula,
removal subsumed clauses. resulting formula still fluent factored, input
fluent factored. Then, algorithms remain applicable time complexity,
replacing ot prime implicates ot Ot .
Using Model algorithms described provide exact solution SLAF,
tuples hs, Ri solution consistent observations. compute
solution SLAF represented logical formula. use SAT solver (e.g., Moskewicz
et al., 2001) answer queries formula, checking entails f , action
fluent f . would show consistent models action makes f value TRUE.
number variables result formula always independent , linear |P|
algorithms. Therefore, use current SAT solvers treat domains 1000
features more.
Preference Probabilistic Bias Many times information leads us prefer
possible action models others. example, sometimes assume actions change
fluents, suspect action (e.g., open-door) affect features (e.g.,
position) normally. represent bias using preference model (e.g., McCarthy, 1986;
Ginsberg, 1987) probabilistic prior transition relations (e.g., Robert, Celeux, & Diebolt,
1993).
add bias end SLAF computation, get exact solution
compute effect bias together logical formula efficiently. Preferential biases
studied fit easily result algorithms (e.g., use implementations
Doherty, Lukaszewicz, & Szalas, 1997, inference bias).
Also, algorithms inference probabilistic bias logical sentences emerging
used (Hajishirzi & Amir, 2007). There, challenge enumerate
tentative models explicitly, challenge overcome success work Hajishirzi
Amir (2007) similar task filtering. use algorithms apply probabilistic
bias resulting logical formula.
example, given probabilistic graphical model (e.g., Bayesian Networks) set propositional logical sentences, consider logical sentences observations. approach,


logical sentence gives rise characteristic function (
x ) 1
x satisfies
0 otherwise. conjunction clauses get set functions (one per clause). Thus,
inference combined probabilistic-logical system probabilistic inference. example,
370

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

one consider variable elimination (e.g., Dechter, 1999) additional potential
functions.
Parametrized Actions many systems situations natural use parametrized actions.
action schemas whose effect depend parameters, definition applies
identically instantiations.
example, move(b, x, y) action moves b position x position y,
b, x, parameters action. common planning systems (e.g., STRIPS,
PDDL, Situation Calculus). complete treatment parameterized actions outside scope
paper, give guidelines generalization current approach actions.
Consider domain set fluent predicates universe named objects. propositional fluents defined domain ground instantiations predicate fluents. SLAF
work set propositional fluents instantiated actions manner


rest paper. action propositions a( X )lG instantiated every vector object names


X.




)lG .
different treatment comes additional axioms say
x,
.a(
x )lG a(
Inference transition belief state axioms able join information collected
different instantiations actions. expect thorough treatment
able provide efficient algorithms whose time complexity depend number action
schemas instead number instantiated actions.
Several approaches already start address problem, including work Nance, Vogel,
Amir (2006) filtering work Shahaf Amir (2006) SLAF.

7. Experimental Evaluation
Previous sections discussed problem settings consider algorithms solutions. showed modifying traditional settings learning dynamic partially observable
domains important. Determinism alone lead tractability, additional assumptions simple, logical action structure bounded 0 frequency observations fluents
do. Specifically, far showed time space computing SLAF length-T time
sequence n fluents polynomial n.
section considers practical considerations involved using SLAF procedures.
particular, examines following questions:
much time space SLAF computations take practice?
much time required extract model logical formula result
SLAF procedures?
quality learned model (taking arbitrary consistent model)? far
true (generating) model?
conditions algorithms correctness hold practice?
learned model used successful planning execution? learning
procedures fit planning execution?
implemented algorithms ran experiments AS-STRIPS-SLAF following domains taken 3rd International Planning Competition (IPC): Drivelog, Zenotravel,
Blocksworld, Depots (details domains learning results appear Appendix C).
371

fiA MIR & C HANG

experiment involves running chosen algorithm sequence randomly generated
action-observation sequences 5000 steps. Information recorded every 200 steps.
random-sequence generator receives correct description domain, specified
PDDL (Ghallab, Howe, Knoblock, McDermott, Ram, Veloso, Weld, & Wilkins, 1998; Fox & Long,
2002) (a plannig-domain description language), size domain, starting state. (The
size domain number propositional fluents it. set specification
number objects domain number arity predicates domain.) generates
valid sequence actions observations domain starting state, i.e., sequence
consistent input PDDL generator actions may fail (action failure
consistent PDDL action attempted state canot execute).
experiments, chose observations follows: every time step select 10
fluents uniformly random observe. applied additional restrictions (such making sure
fluent observed every fixed k steps).
SLAF algorithm receives sequences actions observations, domain
information otherwise (e.g., receive size domain, fluents, starting state,
PDDL). starting knowledge algorithm empty knowledge, TRUE.
domain ran algorithm different numbers propositional fluents (19 250
fluents). collected time space taken SLAF computation plotted
function input-sequence length (dividing total computation time steps).
time space results shown Figures 6, 7, 8, 9. graphs broken different
domains compare time space taken different domain sizes. time SLAF-time
without CNF simplification (e.g. remove subsumed clauses)
much time space SLAF computations take practice? answer first
question now. observe figures time per step remains relatively constant
throughout execution. Consequently, time taken perform SLAF different domains grows
linearly number time steps. Also, see time SLAF grows domain
size, scales easily moderate domain sizes (1ms per step SLAF domains 200 fluents).
much time required extract model logical formula result
SLAF procedures? SLAF procedures return logical formula sequence actions
observations. need apply work extract candidate (consistent) model
formula. computation done SAT solver CNF formulas.
quality learned model (taking arbitrary consistent model)? far
true (generating) model? sometimes many possible models, little
bias must consider possible likely. decided introduce one
bias, namely, actions instances actions schemas. Thus, actions assumed
effect parameters (or objects), given properties parameters. Thus,
actions effects assumed independent identity parameter.
So, vanilla implementation, propositions look
((STACK
((STACK
((STACK
((STACK
etc.

E
E



G)
G)
B)
A)

CAUSES
CAUSES
CAUSES
CAUSES

(ON
(ON
(ON
(ON

E
G



G))
E))
B))
A))

372

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

SLAF Time/Step: Blocksworld Domain
1.6

1.4

1.2

Time (ms)

1

19 fluents
41 fluents
71 fluents
131 fluents
209 fluents

0.8

0.6

0.4

0.2

0
200

1000

1800

2600

3400

4200

5000

Input Sequence Length

SLAF Time/Step: Depots Domain
1.6

1.4

1.2

Time (ms)

1

58 fluents
94 fluents
138 fluents
190 fluents
250 fluents

0.8

0.6

0.4

0.2

0
200

1000

1800

2600

3400

4200

5000

Input Sequence Length

Figure 6: SLAF-time without CNF simplification domains Blocksworld Depots

Instead, replace ground propositions schematized propositions:
((STACK ?X ?Y) CAUSES (ON ?X ?Y))
((STACK ?X ?Y) CAUSES (ON ?Y ?X))
((STACK ?X ?Y) CAUSES (ON ?X ?Y))
etc.
Thus, belief-state formula looks something like:
373

fiA MIR & C HANG

SLAF Time/Step: Driverlog Domain
1.8
1.6
1.4

Time (ms)

1.2
31 fluents
76 fluents
122 fluents
186 fluents
231 fluents

1
0.8
0.6
0.4
0.2
0
200

1000

1800

2600

3400

4200

5000

Input Sequence Length

SLAF Time/Step: Zeno-Travel Domain
0.8

0.7

0.6

Time (ms)

0.5
58 fluents
91 fluents
134 fluents

0.4

0.3

0.2

0.1

0
200

1000

1800

2600

3400

4200

5000

Input Sequence Length

Figure 7: SLAF-time without CNF simplification domains Driverlog Zeno-Travel

(AND
(AND
(OR (ON E G)
(OR ((STACK ?X ?Y) CAUSES (NOT (ON ?X ?Y)))
(AND ((STACK ?X ?Y) KEEPS (ON ?X ?Y))
(NOT ((STACK ?X ?Y) NEEDS (ON ?X ?Y))))))
...
374

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

SLAF Space: Blocksworld Domain
300K

Space (#lisp symbols)

250K

200K
19 fluents
41 fluents
71 fluents
131 fluents
209 fluents

150K

100K

50K

K
200

1000

1800

2600

3400

4200

5000

Input Sequence Length

SLAF Space: Depots Domain
160K

140K

Space (#lisp symbols)

120K

100K

58 fluents
94 fluents
138 fluents
190 fluents
250 fluents

80K

60K

40K

20K

K
200

1000

1800

2600

3400

4200

5000

Input Sequence Length

Figure 8: SLAF space domains Blocksworld Depots

example fragment model (the complete output given Appendix C) consistent
training data
Blocksworld domain:
* 209 fluents
* 1000 randomly selected actions
* 10 fluents observed per step
* "schematized" learning
375

converting CNF
clause count: 235492
variable count: 187
adding clauses
calling zchaff

fiA MIR & C HANG

SLAF Space: Driverlog Domain
250K

Space (#lisp symbols)

200K

150K

31 fluents
76 fluents
122 fluents
186 fluents
231 fluents

100K

50K

K
200

1000

1800

2600

3400

4200

5000

Input Sequence Length

SLAF Space: Zeno-Travel Domain
60K

Space (#lisp symbols)

50K

40K
58 fluents
91 fluents
134 fluents

30K

20K

10K

K
200

1000

1800

2600

3400

4200

5000

Input Sequence Length

Figure 9: SLAF space domains Driverlog Zeno-Travel

* 1:1 precondition heuristics

parsing result
SLAF time: 2.203
Inference time: 42.312
Learned model:

(UNSTACK NEEDS (NOT (CLEAR ?UNDEROB)))
(UNSTACK NEEDS (CLEAR ?OB))
(UNSTACK NEEDS (ARM-EMPTY))
376

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

(UNSTACK
(UNSTACK
(UNSTACK
(UNSTACK
(UNSTACK
(UNSTACK
(UNSTACK
(UNSTACK
(UNSTACK
(UNSTACK
(UNSTACK
(UNSTACK
(UNSTACK
...

NEEDS (NOT (HOLDING ?OB)))
NEEDS (ON ?OB ?UNDEROB))
CAUSES (CLEAR ?UNDEROB))
CAUSES (NOT (CLEAR ?OB)))
CAUSES (NOT (ARM-EMPTY)))
CAUSES (HOLDING ?OB))
CAUSES (NOT (ON ?OB ?UNDEROB)))
KEEPS (ON-TABLE ?UNDEROB))
KEEPS (ON-TABLE ?OB))
KEEPS (HOLDING ?UNDEROB))
KEEPS (ON ?UNDEROB ?UNDEROB))
KEEPS (ON ?OB ?OB))
KEEPS (ON ?UNDEROB ?OB))

Sometimes, multiple possible schematized propositions correspond ground
action proposition, case disjoin propositions together replacement
(i.e., single ground propositional symbol gets replaced disjunction schema propositions).
replacement simple procedure, one effective deriving information fewer steps speeding model finding SLAF formula. implemented
run SLAF runs. One could SAT-solving portion algorithm,
equivalent result.
Regarding latter, ran scaling issues SAT solver (ZChaff , Moskewicz et al.,
2001; Tang, Yinlei Yu, & Malik, 2004) common lisp compiler large experiments. got
around issues applying replacement scheme above, thus reducing greatly number
variables SAT solver handles.
Another issue ran SAT solver tended choose models blank preconditions (the sequences used experiments include action failure, preconditions never eliminated algorithm). add bias extracted action model,
added axioms following form:
(or (not (,a causes ,f)) (,a needs (not ,f)))
(or (not (,a causes (not ,f))) (,a needs ,f))
axioms state action causes fluent f hold, requires f hold
precondition (similarly, analagous axiom f ). Intuitively, axioms cause
sat solver favor 1:1 action models. got idea heuristic work Wu,
Yang, Jiang (2007), uses somewhat similar set axioms bias results terms
learning preconditions. Clearly, axioms dont always hold, results, one see
learned preconditions often inaccurate.
inaccuracies learned action models reasonable. example, fluent
never changes course action sequence, algorithm may infer arbitrary action
causes fluent hold.
conditions algorithms correctness hold practice? scenarios
report here, conditions guarantee correctness algorithms hold. experiments assumed main conditions algorithms hold, namely, actions
377

fiA MIR & C HANG

deterministic preconditions. enforce observations every fluent
every (fixed) k steps. latter condition necessery correctness algorithm,
necessary guarantee polynomial-time computation. experiments verify necessary practice, indeed case algorithms polynomial-time guarantee
modified observation
earlier work Hlubocky Amir (2004) included modified version AS-STRIPSSLAF architecture tested suite adventure-game-like virtual environments
generated random. include arbitrary numbers places, objects various kinds,
configurations settings those. There, agents task exit house, starting
knowledge state space, available actions effects, characteristics objects.
experiments show agent learns effects actions efficiently. agent
makes decisions using learned knowledge, inference resulting representation fast
(a fraction second per SAT problem domains including 30 object, modes,
locations).
learned model used successful planning execution? learning
procedures fit planning execution? learned model used planning
translating PDDL. However, model always correct one domain,
plan may feasible may lead required goal. cases, interleave
planning, execution, learning, described work Chang Amir (2006). There,
one finds short plan consistent action model, executes plan, collects observations,
applies SLAF those. plan failure detected (e.g., goal achieved),
results Chang Amir (2006) guarantee joint planning-execution-learning procedure
would reach goal bounded amount time. bounded time fact linear length
longest plan needed reaching goal, exponential complexity action
model need learn.

8. Comparison Related Work
HMMs (Boyen & Koller, 1999; Boyen et al., 1999; Murphy, 2002; Ghahramani, 2001) used
estimate stochastic transition model observations. Initially, expected compare
work HMM implementation Murphy (2002), uses EM (a hill-climbing approach).
Unfortunately, HMMs require explicit representation state space, smallest domain (31 features) requires transition matrix (231 )2 entries. prevents initializing HMMs
procedures current computer.
Structure learning approaches Dynamic Bayes Nets (DBNs) (e.g., Ghahramani & Jordan,
1997; Friedman, Murphy, & Russell, 1998; Boyen et al., 1999) use EM additional approximations (e.g., using factoring, variation, sampling), tractable. However, still
limited small domains (e.g., 10 features , Ghahramani & Jordan, 1997; Boyen et al., 1999),
unbounded errors discrete deterministic domains, usable settings.
simple approach learning transition models devised work Holmes
Charles Lee Isbell (2006) deterministic POMDPs. There, transition observation models
deterministic. approach close represents hidden state possible models using finite structure, Looping Prediction Suffix Tree. structure seen
related representation grow models relate action histories possible
transition models. work interactions realized recursive structure
378

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

transition-belief formula built AS-STRIPS-SLAF, e.g.,
(af (af a[f ] explf ))
explf refers similar formula created previous time step.
main difference draw work Holmes Charles
Lee Isbell (2006) latter refers states explicitly, whereas work refers features.
Consequently, representation (provably) compact procedures scale larger
domains theoretically practice. Furthermore, procedure provably maintains reference possible models data insufficient determine single model, whereas
work Holmes Charles Lee Isbell (2006) focuses limit case enough information determining single consistent model. down-side, procedure consider
stochasticity belief state, remains area development.
similar relationship holds work Littman, Sutton, Singh (2002).
work, model representation given size linear number states. model,
predictive state representation (PSR), based action/observation histories predicts behavior based histories. work prefers low-dimensional vector basis instead featurebased representation states (one traditional hallmarks Knowledge Representation
approach). necessary correspondence basis vectors intuitive features real world necessarily. enables representation world closely
based behavior.
Learning PSRs (James & Singh, 2004) nontrivial one needs find good lowdimensional vector basis (the stage called discovery tests). stage learning PSRs requires
matrices size (n2 ), states spaces size n.
work advances line work providing correct results time polylogarithmic number states. Specifically, work learns (deterministic) transition models
polynomial time state features, thus taking time O(poly(log n)).
Reinforcement Learning (RL) approaches (Sutton & Barto, 1998; Bertsekas & Tsitsiklis, 1996)
compute mapping world states preferred actions. highly intractable
partially observable domains (Kaelbling, Littman, & Cassandra, 1998), approximation (e.g.,
Kearns, Mansour, & Ng, 2000; Meuleau, Peshkin, Kim, & Kaelbling, 1999; Even-Dar, Kakade, &
Mansour, 2005; McCallum, 1995) practical small domains (e.g., 10-20 features)
small horizon time .
contrast HMMs, DBNs, RL, algorithms exact tractable large domains (>
300 features). take advantages properties common discrete domains, determinism,
limited effects actions, observed failure.
Previous work learning deterministic action models AI-Planning literature assumes
fully observable deterministic domains. learn parametrized STRIPS actions using, e.g., version spaces (Gil, 1994; Wang, 1995), general classifiers (Oates & Cohen, 1996), hill-climbing
ILP (Benson, 1995). Recently, work Pasula et al. (2004) gave algorithm learns stochastic actions conditional effects. work Schmill, Oates, Cohen (2000) approximates
partial observability assuming world fully observable. apply partially
observable learning problems (sometimes) using space belief states instead world states,
increases problem size exponentially, practical problem.
Finally, recent research learning action models partially observable domains includes
works Yang, Wu, Jiang (2005) Shahaf Amir (2006). works Yang et al.
379

fiA MIR & C HANG

(2005), example plan traces encoded weighted maximum SAT problem,
candidate STRIPS action model extracted. general, may many possible action models
given set example traces, therefore approach nature approximate (in contrast
ours, always identifies exact set possible action models). work introduces
additional approximations form heuristic rules meant rule unlikely action models.
work Shahaf Amir (2006) presents approach solving SLAF using logicalcircuit encodings transition belief states. approach performs tractable SLAF general deterministic models present Section 5, requires SAT solvers
logical circuits. SAT solvers optimized nowadays comparison CNF SAT
solvers, overall performance answering questions SLAF lower ours.
importantly, representation given Shahaf Amir (2006) grows (linearly) number
time steps, still hinder long sequences actions observations. comparison,
transition belief formula bounded size independent number time steps
track.
encoding language, LA typical methods software hardware verification
testing. Relevant books methods (e.g., Clarke, Grumberg, & Peled, 1999) closely related
representation, results achieve applicable vice versa.
main distinction draw work done Formal Methods (e.g., Model
Checking Bounded Model Checking) able conclude size bounds logical formulas involved computation. OBDDs used success Model Checking,
CNF representations used success Bounded Model Checking, little
bounds sizes formulas theory practice. conditions available AI applications
used current manuscript deliver bounds yield tractability scalability results
theoretical practical significance.
Interestingly, methods use Linear Temporal Logics (LTL) cannot distinguish
happen actually happens (Calvanese, Giacomo, & Vardi, 2002). Thus, cannot
consider causes occurence. method similar consider alternate
futures state explicitly. However, use extended language, namely L , makes
alternatives explicit. allows us forego limitations LTL produce needed result.

9. Conclusions
presented framework learning effects preconditions deterministic actions
partially observable domains. approach differs earlier methods focuses determining exact set consistent action models (earlier methods not). showed several
common situations done exactly time polynomial (sometime linear) number time steps features. add bias compute exact solution large domains
(hundreds features), many cases. Furthermore, show number action-observation
traces must seen convergence polynomial number features domain.
positive results contrast difficulty encountered many approaches learning
dynamic models reinforcement learning partially observable domains.
results presented promising many applications, including reinforcement
learning, agents virtual domains, HMMs. Already, work applied autonomous
agents adventure games, exploration guided transition belief state compute
380

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

information gain criteria. future plan extend results stochastic domains,
domains continuous features.

Acknowledgments
wish thank Megan Nance providing code samples sequence generator,
wish thank Dafna Shahaf encouraging collaboration enhanced development understanding results. first author wishes acknowledge stimulating
discussion Brian Hlubocky related topics. wish acknowledge support DAF
Air Force Research Laboratory Award FA8750-04-2-0222 (DARPA REAL program). second
author wishes acknowledge support University Illinois Urbana-Champaign, College
Engineering fellowship. Finally, first author acknowledges support joint Fellowship
(2007-2008) Center Advanced Studies Beckman Institute University
Illinois Urbana-Champaign.
Earlier versions results manuscript appeared conference proceedings (Amir,
2005; Shahaf et al., 2006).

Appendix A. Representation Domain Descriptions
transition relation RM interpretation LA defined Section 3.1 way
similar interpretation Domain Descriptions. Domain Descriptions common method
specifying structured deterministic domains (Fagin, Ullman, & Vardi, 1983; Lifschitz, 1990;
Pednault, 1989; Gelfond & Lifschitz, 1998). methods equivalent contexts
include Successor-State Axioms (Reiter, 2001) Fluent Calculus (Thielscher, 1998).
relevance influence work merit separate exposition relationship work.
domain description finite set effect rules form causes F G describe effects actions, F G state formulas (propositional combinations fluent
names). say F head effect G precondition rule. write
causes F , causes F TRUE. denote ED (a) set effect rules action
A. effect rule e, let Ge precondition Fe effect. Rule e active state s,
|= Ge (s taken interpretation P).
Every domain description defines unique transition relation R (s, a, s0 ) follows.
V
Let F (a, s) conjunction effects rules active a, i.e., {Fe | e
ED (a), |= Ge }. set F (a, s) = RU E rule active s.
Let I(a, s) set fluents affected s, i.e., I(a, s) = {f P | e
ED (a) (s |= Ge ) (f
/ L(Fe ))}.
Define (recalling world states sets fluents)
0



0 (s I(a, s)) = (s I(a, s))
RD = hs, a,
(4)
s0 |= F (a, s)

Thus, action effect FALSE s, cannot execute s.
definition applies inertia (a fluent keeps value) fluents appear active rule.
contexts useful specify inertia explicitly extra effect rules form
keeps f G, fluent f P. shorthand writing two rules causes f f G
causes f f G. includes inertia (keeps) statements, say
complete domain description.
381

fiA MIR & C HANG

Example A.1 Consider scenario Figure 2 assume actions observations occur
Figure 10. Actions assumed deterministic, conditional effects, preconditions
must holds execute successfully. Then, every action affects every fluent either negatively,
positively, all. Thus, every transition relation complete domain description
includes rules form causes l keeps l, l fluent literal (a fluent
negation).
Time step
Action
Location
Bulb
Switch

1

go-W

E
?
sw

2
E
lit
?

go-E

3
E
?
sw

sw-on

4
E
?
sw

go-W

5
E
lit
?

go-E

6
E
?
sw

Figure 10: action-observation sequence (table entries observations). Legend: E: east; E:
west; lit: light on; lit: light off; sw: switch on; sw: switch off.

Consequently, every transition relation R completely defined domain description
(viewing tuple set elements)




causes E, causes sw, causes lit,

causes E causes sw causes lit
R



9 keeps E
8
keeps lit
keeps sw
> go-W >


>
<

>
=

go-E >
>
>
;
: sw-on >

Say initially know effects go-E, go-W, know sw-on does. Then,
transition filtering starts product set R (of 27 possible relations) possible 2 3
states. Also, time step 4 know world state exactly {E, lit, sw}. try sw-on
get F ilter[sw-on](4 ) includes set transition relations
transition relations projecting state {E, lit, sw} appropriate choice S.
receive observations o5 = E sw time step 5, 5 = F ilter[o5 ](F ilter[sw-on](4 ))
removes transition belief state relations gave rise E sw. left
transition relations satisfying one tuples




sw-on causes lit


sw-on causes E,
sw-on causes lit
sw-on causes sw
sw-on keeps E


sw-on keeps lit

Finally, perform action go-W, update set states associated every
transition relation set pairs 5 . receive observations time step 6,
conclude 6 = F ilter[o6 ](F ilter[go-W](5 )) =





sw-on keeps E,
sw-on causes E,

+
+ *E
*E










sw-on causes sw,
sw-on causes sw,
lit
lit
(5)
,
,
,
sw-on causes lit,
sw-on causes lit,










sw
sw





go-E...
go-E...
2
382

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

Appendix B. Proofs
B.1 Proof Lemma 3.1: Consequence Finding Existential Quantification
P ROOF
Consider CNF form . Suppose clauses containing literal x x
1 , . . . , x 1 , . . . , clauses. Suppose clauses containing literal x
x 1 , . . . , x b . V
Suppose clauses
containing x x 1 , . . . , c . note
V
L()\{x}
Cn
() ( 1ic ) ( 1ia,1jb j ) (the formula produced adding
resolvents variable x removing clauses belonging L(L()\{x})), since
resolution complete consequence finding.
Necessity. (x. |= CnL()\{x} ()) Consider model x.. definition,
extended L() (i.e., assigning value m(x)) m() = 1. Extend
case. suppose contradiction model Cn L()\{x} (). cannot
case m(k ) = 0 k, m() = 0, contradiction. Then, must case
m(i j ) = 0 1 1 j b. Therefore, m(i ) = 0 m(j ) = 0.
model , m(x ) = 1 m(x j ) = 1. Thus either m(i ) = 1
m(j ) = 1, contradiction.
Sufficiency. (CnL()\{x} () |= x.) Consider model CnL()\{x} (). Suppose
contradiction m(x.) = 0. is, extended L(), m() = 0. Now, extend
L() m(x) = 0. cannot case m(k ) = 0 k since models
CnL()\{x} (). m(x) = 1, cannot case m(x j ) = 0 j.
Therefore m(x ) = 0 1 a. Therefore, m(i ) = 0. m(i j ) = 1
1 j n, must m(j ) = 1 j. alter m(x) = 1,
satisfies , contradiction. 2
B.2 Proof Theorem 3.3
P ROOF
sides equality relation sets state-transition-relation pairs. show
two sets elements. show first left-hand side equality
contained right-hand side.
Take hs0 , Ri SLAF [a]({hs, Ri | hs, Ri satisfies }). Definition 2.3
{s | hs, Ri satisfies } hs, a, s0 R. words,
hs, Ri satisfies hs, a, s0 R.
prove hs0 , Ri satisfies SLAF0 [a]() need show Teff (at ) model
RM = R s0 interprets P 0 . Let interprets P, s0 interprets P 0 , MR
interpreting LA previous
section. interpretation

Wsatisfy formula
V
V
one conjuncts lF ,GG ((alG G) l0 ) lF (l0 ( GG (alG G))) falsified.
cannot case choice s.
Assume contradiction (alG G) l0 ) fails l. Then, (alG G) hold l0
FALSE. portion interprets LA built according MR , R. Since hs, R, s0
know s0 satisfies l, construction MR . contradicts l 0 FALSE
(M interprets P 0 according s0 ), therefore conclude (alG G) l0 ) every l0 .
W
Similarly, assume contradiction (l 0 ( GG (alG G))) fails l. Then, l 0 holds
s0 , als fails. Again, way constructed MR must als takes value
corresponds l 0 truth value s0 . Thus, must als takes value TRUE ,
done first direction.
383

fiA MIR & C HANG

opposite direction (showing right-hand side contained left-hand side), take
hs0 , Ri satisfies SLAF [a](). show
hs0 , Ri SLAF [a]({hs, Ri | hs, Ri satisfies }).
hs0 , Ri |= SLAF [a]() implies (Corollary 3.2) hs 0 , R, si |=
Teff (a) (s0 , R, interpreting P 0 , LA , P, respectively). similar argument one give
first part shows hs, a, s0 R, hs0 , Ri SLAF [a]({hs, Ri | hs, Ri satisfies }).
2
B.3 Proof Theorem 4.1: Distribution SLAF Connectives
first part, show sets models SLAF [a]( ) SLAF [a]()
SLAF [a]() identical.
Take model SLAF [a]( ). Let 0 model SLAF [a](M 0 ) =
. Then, 0 model model . Without loss generalization, assume
model . Thus, |= SLAF [a](), follows model SLAF [a]()
SLAF [a]().
direction, take model SLAF [a]() SLAF [a](). Then, model
SLAF [a]() model SLAF [a](). Without loss generalization assume
model SLAF [a](). Take 0 model = SLAF [a](M 0 ). So, 0 |= .
follows |= SLAF [a]( ).
similar argument follows case. Take model SLAF [a]( ). Let 0
model SLAF [a](M 0 ) = . Then, 0 model . Thus, |=
SLAF [a]() |= SLAF [a](). follows model SLAF [a]()SLAF [a]().
2
B.4 Proof Theorem 4.5: Closed form SLAF belief state formula
P ROOF SKETCH
follow characterization offered Theorem 3.3 Formula (1).
take Teff (a, t) resolve literals time t. resolution guaranteed generate
set consequences equivalent CnLt+1 (t Teff (a, t)).
V
Assuming , Teff (a, t) logically equivalent Teff (a, t)| = lF ,GG,G|= ((alG Gt )
V
lt+1 ) lF ,GG,G|= (lt+1 (Gt alG )). follows two observations. First, notice
implies G G G 6|= get Gt alG (alG Gt ) lt+1 (the
antecedent notWhold, formula true). Second, notice that,
V second part
original Teff (a, t), ( GG,G|= (alG Gt )) equivalent (assuming ) ( GG,G|= (Gt alG )).
Now, resolving literals time Teff (a, t)| consider
resolutions clauses (Gt term) form alG Gt lt+1 clauses form
lt+1 (Gt alG ) other. yields equivalent
^


_

[ lit+1
i=1
G1 , ...,
WGm G
|= im Gi
l1 , ..., lm F


_
li
alGi )]
(aG

i=1

eliminate W
literals time resolve together sets clauses matching Gi |= Gi . formula encodes resulting clauses chosen
384

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

li

set G1 , ..., Gm chosen set literals l1 , ..., lm . reason including (al
Gi aGi )
always choose clause Gi , li specific type (either one includes alG
one produces al
G.
Finally, get formula theorem aFG aF
G (G characterizes exactly one
state S), fact one set G1 , ..., Gm stronger rest (it entails
rest) G1 , ..., Gm complete terms. set complete fluent assignments G
satisfy . 2

B.5 Proof Theorem 5.1: Closed form k affected fluents
P ROOF SKETCH
literal l clause C conjunction Theorem 4.5, aggregate
action propositions single action proposition alGl , G disjunction complete
preconditions l C (notice cannot ls negation C tautology).
Lemma B.2 shows Gl equivalent fluent term. First prove restricted Lemma
B.1.
W
li
t+1
) clause formula Theorem 4.5, let Gl =
Lemma B.1 Let C =
aG
i=1 (li

W
{Gi | li = l, Gi |= li }, literal l6 . Assume effect deterministic
one case term precondition (if case hold, nothing changes). Then, G l
equivalent term.
P ROOF
Gl disjunction complete state terms Gi , represents set states
corresponds Gi s. intuition apply
W
lit+1 alGi
C
W
Vm i=1
t+1
( i=1 alGi ) (
i=1 li )
0
l
Gl l C
C 0 part C affect l. reason complete terms G know
li
l

al
Gi aGi . Thus, choice G includes conditions l
changes, assume precondition alGl .
compute action model l updating copy G l . Let li fluent literal,
set Glt = Gl .
1. Gl2 Glt Gl2 |= li , terms Glt include li . Thus,
Glt Glt li , alGl alGl li . Thus, add li conjunct Glt .
2. Otherwise, Gl2 Glt Gl2 |= li , terms Glt include li .
Thus, Glt Glt li , alGl alGl li . Thus, add li conjunct Glt .
3. Otherwise, know li li value fluent l changes l =
TRUE. Since assume value l changes single case preconditions
(i.e., conditional effects - either succeeds change, fails change),
li cannot part preconditions, i.e., every term G Glt replace li
li vice versa, precondition would still entail l action. Thus,
alGl alGl \{l } , Glt \ {li } result replacing li li TRUE.






6. related literal l proof above.

385

fiA MIR & C HANG

result replacements term Glt consistent (it consistent
original Gl ) satisfies 1 case |= alGl alGl . 2


W
li
t+1
cl =
Lemma B.2 Let C =
aG
clause formula Theorem 4.5, let G
i=1 li

W
{Gi | li = l}, literal l. Assume effect deterministic one case
cl equivalent
term precondition (if case hold, nothing changes). Then, either G
cl
term, C subsumed another clause entailed formula G
equivalent term.
Gl .

cl
P ROOF
Consider Gl Lemma B.1, let Gl1 complete fluent term G
l
l
l
Thus, G1 |= l. Let Gt term equivalent G according Lemma B.1.
Clause C equivalent alGl al
.... However, alGl already asserts change l l
Gl




1

result action a, al
asserts change different condition l l. Thus,
Gl
1

. get subsuming clause C 0 = C \ al
. way
1 case |= alGl al
Gl
Gl


1

1

remove C literals alGi Gi Gl .

cl . However, clause C
process left clause C Gl G
form Theorem 5.1 Gi missing. represent
theorem? must allow Gi missing.
2
Proof theorem continues Thus, representation C 0 (the new clause) takes space O(n2 )
(each propositional symbol encoded O(n) space, assuming constant encoding every
fluent p P).
However, number propositional symbols still large (there O(2 n ) fluent terms,
encoding still requires O(2n n) (all preconditions effects) new propositional symbols.
notice limit attention clauses C k literals l whose action
proposition alGl satisfies |= Gl l. k propositions C,
V
W
l
say {alGi l }ik0 , C ( ki=1 alGi l ) aGk+1
... im lit+1 , always subsumed
l


k+1
V
l
.

latter


sentence
always true, assume change
( ki=1 alGi l ) aGk+1
l


k+1

k fluents (aGk+1
asserts lk+1 remains same, alGi l asserts li changes
lk+1

one conditions satisfied Gli ).
V
l
(which state k effects)
Using clauses form ( ki=1 alGi l ) aGk+1
l
l



k+1

l

resolve away aGj l j > k every clause C original conjunction. Thus,
j
W
V
left clauses form C ( ki=1 alGi l ) im lit+1 . Now, since choice literals

l1 , ..., lk independent rest clause, every polarity
fluents, get clauses resolve (on combinations literals) (and
subsumed by)
k
_
^
lit+1
(6)
C ( alGi l )
i=1



386

ik

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

Thus, get conjunction clauses form (6), G li (i k) fluent term. So,
conjunction clauses Theorem 4.5 equivalent conjunction clauses
clause 2k literals. Thus, space required represent clause 2kn.
Finally, use fact every action dependent k fluents. Every proposition asserts no-change li equivalent conjunction literals stating none
possible k preconditions consistent affect li . example alli1 ...lk lu implies

alli1 ...lk alli1 ...lk1 lu .... Similarly, one elements conjunction implies

alli1 ...lk lu . 2

B.6 Proof Theorem 5.3: Equivalent Restricted Definition Action Axioms
P ROOF
Let 0 = P.(eff (a)). claim successful actionS
a, SLAF [a]()
0
[P 0 /P] . see this, consider model 0 . valuation fluents f P L0f define
transition relation R valuation fluents P 0 define state s0 hs0 , Ri 0 .
definition 0 , hs0 , Ri 0 exists hs, Ri eff (a) satisfied. Finally note eff (a) satisfied preconditions action met
s0 consistent effects action applied s. is, eff (a) satisfied
hs, a, s0 R. Together, observations Corollary 3.2 yield theorem. 2
B.7 Proof Theorem 5.4: AS-STRIPS-SLAF Correct
P ROOF
Let shorthand notation C() denote C() CnL ()[P 0 /P] .
definition, SLAF [ha, oi]() SLAF [o](SLAF [a]()). Theorem 5.3,
SLAF [a]() C( eff (a)). formula equivalent C( eff (a)) may generated
resolving
V fluents P (by following procedure proof Lemma 3.1). Suppose
= f P f fluent-factored form. may rewrite C( eff (a)) as:
0



SLAF [a]()










^

f P

^

f P

^

f P

^

f P



C(Prea,f ) C(Effa,f ) C(f )

(7)



C(Prea,f Effa,f )


C(f Prea,f )


C(f Effa,f )

equivalence holds resolvents generated resolving literals P C(
eff (a)) still generated formula. is, pair clauses possibly resolved together (where fluent P resolved out) eff (a) generate new
consequence C ( eff (a)) appear together one C () components (7).
387

fiA MIR & C HANG

every clause eff (a) contains one literal P, see possible consequences
generated.
note Effa,f may rewritten follows:
Effa,f



^

((al (af l)) l0 ) (l0 (al (af l)))

(8)

l{f,f }



^

(l (l0 al )) (l0 (al af ))

l{f,f }

straightforward verify equivalence rewritten formula original formula. Note
performing rewriting, may discard clauses form f af af , must
true every consistent model (given axioms described Section 5.2).
consider consequences generated component (7). may compute
consequences performing resolution. C(Pre a,f ) a[f ] a[f ] ,
may discard clauses inconsistent action models violate clause.
definition fluent-factored formulas, C(f ) Af . Next, remaining components
computed straightforwardly:
^
C(Effa,f )
(l0 al af )
l{f,f }

C(f Prea,f ) C(f ) C(Prea,f )

^

(a[l] expll )

l{f,f }

C(Prea,f Effa,f ) C(Prea,f ) C(Effa,f )

^

(l0 al a[l] )

l{f,f }

C(f Effa,f ) C(f ) C(Effa,f )

^

(l0 al expll )

l{f,f }

Finally, difficult see steps (a)-(c) procedure sets following formula (in
fluent-factored form):
^
^
SLAF [a]()
Af
(a[l] expll ) (l0 al (af a[l] expll )
f P

l{f,f }

Now, note SLAF [o](SLAF [a]()) SLAF [a]() o. Note term,
SLAF [a]() made fluent-factored performing unit resolution. exactly
steps 1.(d)-(e) do. 2
B.8 Proof Theorem 5.5: AS-STRIPS-SLAF Complexity
P ROOF
Consider size formula returned AS-STRIPS-SLAF. Overview: note
formula i-CNF, integer > 0, filtered formula one step
(i + 1)-CNF. Then, note every observation fluent f resets f -part belief state
formula 1-CNF (thus, = 1).
Details: first part, call procedure appends
one literal existing clauses formula, new clauses length k + 1
388

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

generated. Additionally, every fluent observed every k steps, transition belief
formula stays k-CNF (i.e., indefinitely compact). existing clauses may grow
length (1 literal per timestep) augmented steps 1.(a)-(c), appropriate fluent
observed steps 1.(d)-(e), clauses stop growing. Finally, easy see
steps 1.(a)-(e) performed polynomial time. 2
B.9 Proof Theorem 5.7: PRE-STRIPS-SLAF Correct
P ROOF
Consider semantics SLAF filtering STRIPS action known precondition. case action failure, world filtered transition belief state
world meet action precondition (and satisfies observation). Clearly, step 1
algorithm performs filtering conjoining belief formula negation action
precondition (converted logically equivalent disjunction fluent-factored formulas).
case action success, filtering performed first removing worlds
satisfy action precondition (so remaining worlds, action executable)
filtering remaining worlds using algorithm AS-STRIPS-SLAF. Moreover, Theorem 4.1
Corollary 4.3 follows filtering formula performed filtering
subformulas i,j separately. Furthermore, SLAF[ha, oi]() |= PRE-STRIPS-SLAF[ha, oi](),
PRE-STRIPS-SLAF[ha, oi]() SLAF[ha, oi]() conditions Corollary 4.3.
filtering subformula performed steps 2 3 algorithm.
Finally, note steps 3 4 serve simplify belief formula produce logically
equivalent formula. 2
B.10 Proof Theorem 5.8: PRE-STRIPS-SLAF Complexity
P ROOF
Note call AS-STRIPS-SLAF subformula takes time linear size
subformula, steps involving AS-STRIPS-SLAF performed linear time.
Thus total time complexity linear. Additionally, note every fluent observed every
k steps, every fluent-factored subformula i,j belief formula k-CNF,
theorem Amir
W (2005). action preconditions contain literals, disjunction
form j i,j contains disjuncts. Therefore, entire belief formula stays
k-CNF, indefinitely. 2

Appendix C. Experiments Outputs
experiments (Section 7) examine properties algorithms learning action models.
show learning tractable exact. Appendix section bring generating models
learned models detailed comparison reader. Recall algorithms
output representation set models possible given input. bring
one satisfying model learned formula.
experiments include following domains International Planning Competition
(IPC): Drivelog, Zenotravel, Blocksworld, Depots.
C.1 Driverlog Domain
Driverlog domain following generating PDDL:
(define (domain driverlog)

389

fiA MIR & C HANG

(:requirements :typing)
(:types
location locatable - object
driver truck obj - locatable )
(:predicates
(at ?obj - locatable ?loc - location)
(in ?obj1 - obj ?obj - truck)
(driving ?d - driver ?v - truck)
(path ?x ?y - location)
(empty ?v - truck) )
(:action LOAD-TRUCK
:parameters
(?obj - obj
?truck - truck
?loc - location)
:precondition
(and (at ?truck ?loc) (at ?obj ?loc))
:effect
(and (not (at ?obj ?loc)) (in ?obj ?truck)))
(:action UNLOAD-TRUCK
:parameters
(?obj - obj
?truck - truck
?loc - location)
:precondition
(and (at ?truck ?loc) (in ?obj ?truck))
:effect
(and (not (in ?obj ?truck)) (at ?obj ?loc)))
(:action BOARD-TRUCK
:parameters
(?driver - driver
?truck - truck
?loc - location)
:precondition
(and (at ?truck ?loc) (at ?driver ?loc) (empty ?truck))
:effect
(and (not (at ?driver ?loc)) (driving ?driver ?truck)
(not (empty ?truck))))
(:action DISEMBARK-TRUCK
:parameters
(?driver - driver
?truck - truck
?loc - location)
:precondition
(and (at ?truck ?loc) (driving ?driver ?truck))
:effect
(and (not (driving ?driver ?truck)) (at ?driver ?loc)
(empty ?truck)))
(:action DRIVE-TRUCK
:parameters
(?truck - truck
?loc-from - location
?loc-to location
?driver - driver)
:precondition
(and (at ?truck ?loc-from)
(driving ?driver ?truck)
(path ?loc-from ?loc-to))
:effect
(and (not (at ?truck ?loc-from)) (at ?truck ?loc-to)))
(:action WALK
:parameters
(?driver - driver
?loc-from - location
?loc-to - location)
:precondition
(and (at ?driver ?loc-from) (path ?loc-from ?loc-to))
:effect
(and (not (at ?driver ?loc-from)) (at ?driver ?loc-to))) )

One learned model (one possible satisfying model formula) random-sequence
input Driverlog domain following (brought together experimental parameters).
Driverlog domain:
* IPC3 problem 99
* 231 fluents
* 1000 randomly selected actions
* 10 fluents observed per step

390

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

* "schematized" learning
* 1:1 precondition heuristics
* Action distribution:
((BOARD-TRUCK . 52) (DRIVE-TRUCK . 86) (DISEMBARK-TRUCK . 52)
(WALK . 529) (UNLOAD-TRUCK . 139) (LOAD-TRUCK . 142))
converting CNF
clause count: 82338
variable count: 210
adding clauses
calling zchaff
parsing result
SLAF time: 2.469
Inference time: 8.406
Learned model:
(WALK NEEDS (AT ?DRIVER ?LOC-FROM))
(WALK NEEDS (NOT (AT ?DRIVER ?LOC-TO)))
(WALK CAUSES (AT ?DRIVER ?LOC-TO))
(WALK CAUSES (NOT (AT ?DRIVER ?LOC-FROM)))
(WALK KEEPS (PATH ?LOC-FROM ?LOC-FROM))
(WALK KEEPS (PATH ?LOC-TO ?LOC-TO))
(WALK KEEPS (PATH ?LOC-TO ?LOC-FROM))
(WALK KEEPS (PATH ?LOC-FROM ?LOC-TO))
(DRIVE-TRUCK NEEDS (NOT (AT ?TRUCK ?LOC-TO)))
(DRIVE-TRUCK NEEDS (AT ?TRUCK ?LOC-FROM))
(DRIVE-TRUCK CAUSES (AT ?TRUCK ?LOC-TO))
(DRIVE-TRUCK CAUSES (NOT (AT ?TRUCK ?LOC-FROM)))
(DRIVE-TRUCK KEEPS (AT ?DRIVER ?LOC-TO))
(DRIVE-TRUCK KEEPS (AT ?DRIVER ?LOC-FROM))
(DRIVE-TRUCK KEEPS (DRIVING ?DRIVER ?TRUCK))
(DRIVE-TRUCK KEEPS (PATH ?LOC-TO ?LOC-TO))
(DRIVE-TRUCK KEEPS (PATH ?LOC-FROM ?LOC-FROM))
(DRIVE-TRUCK KEEPS (PATH ?LOC-FROM ?LOC-TO))
(DRIVE-TRUCK KEEPS (PATH ?LOC-TO ?LOC-FROM))
(DRIVE-TRUCK KEEPS (EMPTY ?TRUCK))
(DISEMBARK-TRUCK NEEDS (NOT (AT ?DRIVER ?LOC)))
(DISEMBARK-TRUCK NEEDS (DRIVING ?DRIVER ?TRUCK))
(DISEMBARK-TRUCK NEEDS (NOT (EMPTY ?TRUCK)))
(DISEMBARK-TRUCK CAUSES (AT ?DRIVER ?LOC))
(DISEMBARK-TRUCK CAUSES (NOT (DRIVING ?DRIVER ?TRUCK)))
(DISEMBARK-TRUCK CAUSES (EMPTY ?TRUCK))
(DISEMBARK-TRUCK KEEPS (AT ?TRUCK ?LOC))
(DISEMBARK-TRUCK KEEPS (PATH ?LOC ?LOC))
(BOARD-TRUCK NEEDS (AT ?DRIVER ?LOC))
(BOARD-TRUCK NEEDS (NOT (DRIVING ?DRIVER ?TRUCK)))
(BOARD-TRUCK NEEDS (EMPTY ?TRUCK))
(BOARD-TRUCK CAUSES (NOT (AT ?DRIVER ?LOC)))
(BOARD-TRUCK CAUSES (DRIVING ?DRIVER ?TRUCK))
(BOARD-TRUCK CAUSES (NOT (EMPTY ?TRUCK)))
(BOARD-TRUCK KEEPS (AT ?TRUCK ?LOC))
(BOARD-TRUCK KEEPS (PATH ?LOC ?LOC))
(UNLOAD-TRUCK NEEDS (NOT (AT ?OBJ ?LOC)))
(UNLOAD-TRUCK NEEDS (IN ?OBJ ?TRUCK))
(UNLOAD-TRUCK CAUSES (AT ?OBJ ?LOC))

391

fiA MIR & C HANG

(UNLOAD-TRUCK CAUSES (NOT (IN ?OBJ ?TRUCK)))
(UNLOAD-TRUCK KEEPS (AT ?TRUCK ?LOC))
(UNLOAD-TRUCK KEEPS (PATH ?LOC ?LOC))
(UNLOAD-TRUCK KEEPS (EMPTY ?TRUCK))
(LOAD-TRUCK NEEDS (AT ?OBJ ?LOC))
(LOAD-TRUCK NEEDS (NOT (IN ?OBJ ?TRUCK)))
(LOAD-TRUCK CAUSES (NOT (AT ?OBJ ?LOC)))
(LOAD-TRUCK CAUSES (IN ?OBJ ?TRUCK))
(LOAD-TRUCK KEEPS (AT ?TRUCK ?LOC))
(LOAD-TRUCK KEEPS (PATH ?LOC ?LOC))
(LOAD-TRUCK KEEPS (EMPTY ?TRUCK))

C.2 Zeno-Travel Domain
Zeno-Travel domain following generating PDDL:
(define (domain zeno-travel)
(:requirements :typing)
(:types aircraft person city flevel - object)
(:predicates (at ?x - (either person aircraft) ?c - city)
(in ?p - person ?a - aircraft)
(fuel-level ?a - aircraft ?l - flevel)
(next ?l1 ?l2 - flevel))
(:action board
:parameters (?p - person ?a - aircraft ?c - city)
:precondition (and (at ?p ?c) (at ?a ?c))
:effect (and (not (at ?p ?c)) (in ?p ?a)))
(:action debark
:parameters (?p - person ?a - aircraft ?c - city)
:precondition (and (in ?p ?a) (at ?a ?c))
:effect (and (not (in ?p ?a)) (at ?p ?c)))
(:action fly
:parameters (?a - aircraft ?c1 ?c2 - city ?l1 ?l2 - flevel)
:precondition (and (at ?a ?c1) (fuel-level ?a ?l1) (next ?l2 ?l1))
:effect (and (not (at ?a ?c1)) (at ?a ?c2) (not (fuel-level ?a ?l1))
(fuel-level ?a ?l2)))
(:action zoom
:parameters (?a - aircraft ?c1 ?c2 - city ?l1 ?l2 ?l3 - flevel)
:precondition (and (at ?a ?c1) (fuel-level ?a ?l1) (next ?l2 ?l1)
(next ?l3 ?l2) )
:effect (and (not (at ?a ?c1)) (at ?a ?c2) (not (fuel-level ?a ?l1))
(fuel-level ?a ?l3) ))
(:action refuel
:parameters (?a - aircraft ?c - city ?l - flevel ?l1 - flevel)
:precondition (and (fuel-level ?a ?l) (next ?l ?l1) (at ?a ?c))
:effect (and (fuel-level ?a ?l1) (not (fuel-level ?a ?l)))))

One learned model (one possible satisfying model formula) random-sequence
input Zeno-Travel domain following (brought together experimental parameters).
Zenotravel domain:

392

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

*
*
*
*
*
*
*

IPC3 problem 9
91 fluents, 21000 possible unique actions
1000 actions learned action sequence
5 observed fluents per step
"schematized" learning
1:1 precondition heuristics
Action distribution: ((ZOOM . 27) (FLY . 216) (REFUEL . 264)
(BOARD . 249) (DEBARK . 244))

converting CNF
clause count: 71119
variable count: 138
adding clauses
calling zchaff
parsing result
SLAF time: 1.109
Inference time: 11.015
Learned model:
(REFUEL NEEDS (FUEL-LEVEL ?A ?L))
(REFUEL NEEDS (NOT (FUEL-LEVEL ?A ?L1)))
(REFUEL CAUSES (NOT (FUEL-LEVEL ?A ?L)))
(REFUEL CAUSES (FUEL-LEVEL ?A ?L1))
(REFUEL KEEPS (NEXT ?L ?L))
(REFUEL KEEPS (NEXT ?L ?L1))
(REFUEL KEEPS (NEXT ?L1 ?L))
(REFUEL KEEPS (NEXT ?L1 ?L1))
(ZOOM NEEDS (NOT (FUEL-LEVEL ?A ?L3)))
(ZOOM NEEDS (FUEL-LEVEL ?A ?L1))
(ZOOM CAUSES (FUEL-LEVEL ?A ?L3))
(ZOOM CAUSES (NOT (FUEL-LEVEL ?A ?L1)))
(ZOOM KEEPS (FUEL-LEVEL ?A ?L2))
(ZOOM KEEPS (NEXT ?L3 ?L3))
(ZOOM KEEPS (NEXT ?L3 ?L2))
(ZOOM KEEPS (NEXT ?L3 ?L1))
(ZOOM KEEPS (NEXT ?L2 ?L3))
(ZOOM KEEPS (NEXT ?L2 ?L2))
(ZOOM KEEPS (NEXT ?L2 ?L1))
(ZOOM KEEPS (NEXT ?L1 ?L3))
(ZOOM KEEPS (NEXT ?L1 ?L2))
(ZOOM KEEPS (NEXT ?L1 ?L1))
(FLY NEEDS (NOT (FUEL-LEVEL ?A ?L2)))
(FLY NEEDS (FUEL-LEVEL ?A ?L1))
(FLY CAUSES (FUEL-LEVEL ?A ?L2))
(FLY CAUSES (NOT (FUEL-LEVEL ?A ?L1)))
(FLY KEEPS (NEXT ?L2 ?L2))
(FLY KEEPS (NEXT ?L2 ?L1))
(FLY KEEPS (NEXT ?L1 ?L2))
(FLY KEEPS (NEXT ?L1 ?L1))
(DEBARK NEEDS (IN ?P ?A))
(DEBARK CAUSES (NOT (IN ?P ?A)))
(BOARD NEEDS (NOT (IN ?P ?A)))
(BOARD CAUSES (IN ?P ?A))

393

fiA MIR & C HANG

C.3 Blocks-World Domain
Blocksworld domain following generating PDDL:
(define (domain blocksworld)
(:requirements :strips)
(:predicates (clear ?x - object)
(on-table ?x - object)
(arm-empty)
(holding ?x - object)
(on ?x ?y - object))
(:action pickup
:parameters (?ob - object)
:precondition (and (clear ?ob) (on-table ?ob) (arm-empty))
:effect (and (holding ?ob) (not (clear ?ob)) (not (on-table ?ob))
(not (arm-empty))))
(:action putdown
:parameters (?ob - object)
:precondition (holding ?ob)
:effect (and (clear ?ob) (arm-empty) (on-table ?ob)
(not (holding ?ob))))
(:action stack
:parameters (?ob - object
?underob - object)
:precondition (and (clear ?underob) (holding ?ob))
:effect (and (arm-empty) (clear ?ob) (on ?ob ?underob)
(not (clear ?underob)) (not (holding ?ob))))
(:action unstack
:parameters (?ob - object
?underob - object)
:precondition (and (on ?ob ?underob) (clear ?ob) (arm-empty))
:effect (and (holding ?ob) (clear ?underob) (not (on ?ob ?underob))
(not (clear ?ob)) (not (arm-empty)))))

One learned model (one possible satisfying model formula) random-sequence
input Blocksworld domain following (brought together experimental parameters).
Blocksworld domain:
* 209 fluents
* 1000 randomly selected actions
* 10 fluents observed per step
* "schematized" learning
* 1:1 precondition heuristics
converting CNF
clause count: 235492
variable count: 187
adding clauses
calling zchaff
parsing result
SLAF time: 2.203
Inference time: 42.312

394

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

Learned model:
(UNSTACK NEEDS (NOT (CLEAR ?UNDEROB)))
(UNSTACK NEEDS (CLEAR ?OB))
(UNSTACK NEEDS (ARM-EMPTY))
(UNSTACK NEEDS (NOT (HOLDING ?OB)))
(UNSTACK NEEDS (ON ?OB ?UNDEROB))
(UNSTACK CAUSES (CLEAR ?UNDEROB))
(UNSTACK CAUSES (NOT (CLEAR ?OB)))
(UNSTACK CAUSES (NOT (ARM-EMPTY)))
(UNSTACK CAUSES (HOLDING ?OB))
(UNSTACK CAUSES (NOT (ON ?OB ?UNDEROB)))
(UNSTACK KEEPS (ON-TABLE ?UNDEROB))
(UNSTACK KEEPS (ON-TABLE ?OB))
(UNSTACK KEEPS (HOLDING ?UNDEROB))
(UNSTACK KEEPS (ON ?UNDEROB ?UNDEROB))
(UNSTACK KEEPS (ON ?OB ?OB))
(UNSTACK KEEPS (ON ?UNDEROB ?OB))
(STACK NEEDS (CLEAR ?UNDEROB))
(STACK NEEDS (NOT (CLEAR ?OB)))
(STACK NEEDS (NOT (ARM-EMPTY)))
(STACK NEEDS (HOLDING ?OB))
(STACK NEEDS (NOT (ON ?OB ?UNDEROB)))
(STACK CAUSES (NOT (CLEAR ?UNDEROB)))
(STACK CAUSES (CLEAR ?OB))
(STACK CAUSES (ARM-EMPTY))
(STACK CAUSES (NOT (HOLDING ?OB)))
(STACK CAUSES (ON ?OB ?UNDEROB))
(STACK KEEPS (ON-TABLE ?UNDEROB))
(STACK KEEPS (ON-TABLE ?OB))
(STACK KEEPS (HOLDING ?UNDEROB))
(STACK KEEPS (ON ?UNDEROB ?UNDEROB))
(STACK KEEPS (ON ?OB ?OB))
(STACK KEEPS (ON ?UNDEROB ?OB))
(PUTDOWN NEEDS (NOT (CLEAR ?OB)))
(PUTDOWN NEEDS (NOT (ON-TABLE ?OB)))
(PUTDOWN NEEDS (NOT (ARM-EMPTY)))
(PUTDOWN NEEDS (HOLDING ?OB))
(PUTDOWN CAUSES (CLEAR ?OB))
(PUTDOWN CAUSES (ON-TABLE ?OB))
(PUTDOWN CAUSES (ARM-EMPTY))
(PUTDOWN CAUSES (NOT (HOLDING ?OB)))
(PUTDOWN KEEPS (ON ?OB ?OB))
(PICKUP NEEDS (CLEAR ?OB))
(PICKUP NEEDS (ON-TABLE ?OB))
(PICKUP NEEDS (ARM-EMPTY))
(PICKUP NEEDS (NOT (HOLDING ?OB)))
(PICKUP CAUSES (NOT (CLEAR ?OB)))
(PICKUP CAUSES (NOT (ON-TABLE ?OB)))
(PICKUP CAUSES (NOT (ARM-EMPTY)))
(PICKUP CAUSES (HOLDING ?OB))
(PICKUP KEEPS (ON ?OB ?OB))

395

fiA MIR & C HANG

C.4 Depot Domain
Depot domain following generating PDDL:
(define (domain Depot)
(:requirements :typing)
(:types place locatable - object
depot distributor - place
truck hoist surface - locatable
pallet crate - surface)
(:predicates (at ?x - locatable ?y - place)
(on ?x - crate ?y - surface)
(in ?x - crate ?y - truck)
(lifting ?x - hoist ?y - crate)
(available ?x - hoist)
(clear ?x - surface))
(:action Drive
:parameters (?x - truck ?y - place ?z - place)
:precondition (and (at ?x ?y))
:effect (and (not (at ?x ?y)) (at ?x ?z)))
(:action Lift
:parameters (?x - hoist ?y - crate ?z - surface ?p - place)
:precondition (and (at ?x ?p) (available ?x) (at ?y ?p) (on ?y ?z)
(clear ?y))
:effect (and (not (at ?y ?p)) (lifting ?x ?y) (not (clear ?y))
(not (available ?x)) (clear ?z) (not (on ?y ?z))))
(:action Drop
:parameters (?x - hoist ?y - crate ?z - surface ?p - place)
:precondition (and (at ?x ?p) (at ?z ?p) (clear ?z) (lifting ?x ?y))
:effect (and (available ?x) (not (lifting ?x ?y)) (at ?y ?p)
(not (clear ?z)) (clear ?y) (on ?y ?z)))
(:action Load
:parameters (?x - hoist ?y - crate ?z - truck ?p - place)
:precondition (and (at ?x ?p) (at ?z ?p) (lifting ?x ?y))
:effect (and (not (lifting ?x ?y)) (in ?y ?z) (available ?x)))
(:action Unload
:parameters (?x - hoist ?y - crate ?z - truck ?p - place)
:precondition (and (at ?x ?p) (at ?z ?p) (available ?x) (in ?y ?z))
:effect (and (not (in ?y ?z)) (not (available ?x)) (lifting ?x ?y))) )

One learned model (one possible satisfying model formula) random-sequence
input Depot domain following (brought together experimental parameters).
Depots domain:
* IPC3 problem 5
* 250 fluents
* 1000 randomly selected actions
* 10 fluents observed per step
* "schematized" learning
* 1:1 precondition heuristics
converting CNF

396

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

clause count: 85359
variable count: 236
adding clauses
calling zchaff
parsing result
SLAF time: 2.797
Inference time: 8.062
Learned model:
(UNLOAD NEEDS (IN ?Y ?Z))
(UNLOAD NEEDS (NOT (LIFTING ?X ?Y)))
(UNLOAD NEEDS (AVAILABLE ?X))
(UNLOAD CAUSES (NOT (IN ?Y ?Z)))
(UNLOAD CAUSES (LIFTING ?X ?Y))
(UNLOAD CAUSES (NOT (AVAILABLE ?X)))
(UNLOAD KEEPS (AT ?Z ?P))
(UNLOAD KEEPS (AT ?Y ?P))
(UNLOAD KEEPS (AT ?X ?P))
(UNLOAD KEEPS (ON ?Y ?Y))
(UNLOAD KEEPS (CLEAR ?Y))
(LOAD NEEDS (NOT (IN ?Y ?Z)))
(LOAD NEEDS (LIFTING ?X ?Y))
(LOAD NEEDS (NOT (AVAILABLE ?X)))
(LOAD CAUSES (IN ?Y ?Z))
(LOAD CAUSES (NOT (LIFTING ?X ?Y)))
(LOAD CAUSES (AVAILABLE ?X))
(LOAD KEEPS (AT ?Z ?P))
(LOAD KEEPS (AT ?Y ?P))
(LOAD KEEPS (AT ?X ?P))
(LOAD KEEPS (ON ?Y ?Y))
(LOAD KEEPS (CLEAR ?Y))
(DROP NEEDS (NOT (AT ?Y ?P)))
(DROP NEEDS (NOT (ON ?Y ?Z)))
(DROP NEEDS (LIFTING ?X ?Y))
(DROP NEEDS (NOT (AVAILABLE ?X)))
(DROP NEEDS (CLEAR ?Z))
(DROP NEEDS (NOT (CLEAR ?Y)))
(DROP CAUSES (AT ?Y ?P))
(DROP CAUSES (ON ?Z ?Z))
(DROP CAUSES (NOT (ON ?Z ?Z)))
(DROP CAUSES (ON ?Z ?Y))
(DROP CAUSES (NOT (ON ?Z ?Y)))
(DROP CAUSES (ON ?Y ?Z))
(DROP CAUSES (NOT (LIFTING ?X ?Y)))
(DROP CAUSES (LIFTING ?X ?Z))
(DROP CAUSES (NOT (LIFTING ?X ?Z)))
(DROP CAUSES (AVAILABLE ?X))
(DROP CAUSES (NOT (CLEAR ?Z)))
(DROP CAUSES (CLEAR ?Y))
(DROP KEEPS (AT ?Z ?P))
(DROP KEEPS (AT ?X ?P))
(DROP KEEPS (ON ?Z ?Z))
(DROP KEEPS (ON ?Z ?Y))
(DROP KEEPS (ON ?Y ?Y))
(DROP KEEPS (LIFTING ?X ?Z))

397

fiA MIR & C HANG

(LIFT NEEDS (AT ?Y ?P))
(LIFT NEEDS (ON ?Y ?Z))
(LIFT NEEDS (NOT (LIFTING ?X ?Y)))
(LIFT NEEDS (AVAILABLE ?X))
(LIFT NEEDS (NOT (CLEAR ?Z)))
(LIFT NEEDS (CLEAR ?Y))
(LIFT CAUSES (NOT (AT ?Y ?P)))
(LIFT CAUSES (NOT (ON ?Y ?Z)))
(LIFT CAUSES (ON ?Z ?Z))
(LIFT CAUSES (NOT (ON ?Z ?Z)))
(LIFT CAUSES (ON ?Z ?Y))
(LIFT CAUSES (NOT (ON ?Z ?Y)))
(LIFT CAUSES (LIFTING ?X ?Y))
(LIFT CAUSES (LIFTING ?X ?Z))
(LIFT CAUSES (NOT (LIFTING ?X ?Z)))
(LIFT CAUSES (NOT (AVAILABLE ?X)))
(LIFT CAUSES (CLEAR ?Z))
(LIFT CAUSES (NOT (CLEAR ?Y)))
(LIFT KEEPS (AT ?Z ?P))
(LIFT KEEPS (AT ?X ?P))
(LIFT KEEPS (ON ?Y ?Y))
(LIFT KEEPS (ON ?Z ?Z))
(LIFT KEEPS (ON ?Z ?Y))
(LIFT KEEPS (LIFTING ?X ?Z))
(DRIVE NEEDS (AT ?X ?Y))
(DRIVE NEEDS (NOT (AT ?X ?Z)))
(DRIVE CAUSES (NOT (AT ?X ?Y)))
(DRIVE CAUSES (AT ?X ?Z))

References
Amir, E. (2005). Learning partially observable deterministic action models. Proc. Nineteenth
International Joint Conference Artificial Intelligence (IJCAI 05), pp. 14331439. International Joint Conferences Artificial Intelligence.
Amir, E., & Russell, S. (2003). Logical filtering. Proc. Eighteenth International Joint Conference
Artificial Intelligence (IJCAI 03), pp. 7582. Morgan Kaufmann.
Benson, S. (1995). Inductive learning reactive action models. Proceedings 12th International Conference Machine Learning (ICML-95).
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.
Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming first-order MDPs.
Proc. Seventeenth International Joint Conference Artificial Intelligence (IJCAI 01), pp.
690697. Morgan Kaufmann.
Boyen, X., Friedman, N., & Koller, D. (1999). Discovering hidden structure complex dynamic
systems. Proceedings 15th Conference Uncertainty Artificial IntelligenceUAI
1999, pp. 91100. Morgan Kaufmann. Available http://www.cs.stanford.edu/ xb/uai99/.
Boyen, X., & Koller, D. (1999). Approximate learning dynamic models. Kearns, M. S., Solla,
S. A., & Kohn, D. A. (Eds.), Advances Neural Information Processing Systems 11: Proceedings 1998 ConferenceNIPS 1998, pp. 396402. Cambridge: MIT Press. Available http://www.cs.stanford.edu/ xb/nips98/.
398

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

Calvanese, D., Giacomo, G. D., & Vardi, M. Y. (2002). Reasoning actions planning
LTL action theories. Principles Knowledge Representation Reasoning: Proc. Eighth
Intl Conference (KR 2002), pp. 593602. Morgan Kaufmann.
Chang, A., & Amir, E. (2006). Goal achievement partially known, partially observable domains.
Proceedings 16th Intl Conf. Automated Planning Scheduling (ICAPS06).
AAAI Press.
Chang, C.-L., & Lee, R. C.-T. (1973). Symbolic Logic Mechanical Theorem Proving. Academic
Press.
Clarke, E. M., Grumberg, O., & Peled, D. A. (1999). Model Checking. MIT Press.
Darwiche, A., & Marquis, P. (2002). knowledge compilation map. Journal Artificial Intelligence Research, 17, 229264.
Davis, M., & Putnam, H. (1960). computing procedure quantification theory. Journal
ACM, 7, 201215.
Dawsey, W., Minsker, B., & Amir, E. (2007). Real-time assessment drinking water systems using
Bayesian networks. World Environmental Water Resources Congress.
Dechter, R. (1999). Bucket elimination: unifying framework reasoning. Artificial Intelligence,
113(12), 4185.
del Val, A. (1999). new method consequence finding compilation restricted language. Proc. National Conference Artificial Intelligence (AAAI 99), pp. 259264.
AAAI Press/MIT Press.
Doherty, P., Lukaszewicz, W., & Szalas, A. (1997). Computing circumscription revisited: reduction algorithm. Journal Automated Reasoning, 18(3), 297336.
Eiter, T., & Gottlob, G. (1992). complexity propositional knowledge base revision, updates, counterfactuals. Artificial Intelligence, 57(2-3), 227270.
Even-Dar, E., Kakade, S. M., & Mansour, Y. (2005). Reinforcement learning POMDPs.
Proc. Nineteenth International Joint Conference Artificial Intelligence (IJCAI 05), pp.
660665. International Joint Conferences Artificial Intelligence.
Fagin, R., Ullman, J. D., & Vardi, M. Y. (1983). semantics updates databases.
Proceedings Second ACM SIGACT-SIGMOD Symposium Principles Database
Systems, pp. 352365, Atlanta, Georgia.
Fikes, R., Hart, P., & Nilsson, N. (1972). Learning executing generalized robot plans. Artificial
Intelligence, 3, 251288.
Fox, M., & Long, D. (2002). PDDL2.1: extension PDDL expressing temporal planning
domains. http://www.dur.ac.uk/d.p.long/IPC/pddl.html. Used AIPS02 competition.
Friedman, N., Murphy, K., & Russell, S. (1998). Learning structure dynamic probabilistic
networks. Proc. Fourteenth Conference Uncertainty Artificial Intelligence (UAI 98).
Morgan Kaufmann.
Gelfond, M., & Lifschitz, V. (1998). Action languages. Electronic Transactions Artificial Intelligence (http://www.etaij.org), 3, nr 16.
399

fiA MIR & C HANG

Ghahramani, Z. (2001). introduction Hidden Markov Models Bayesian networks. International Journal Pattern Recognition Artificial Intelligence, 15(1), 942.
Ghahramani, Z., & Jordan, M. I. (1997). Factorial hidden markov models. Machine Learning, 29,
245275.
Ghallab, M., Howe, A., Knoblock, C., McDermott, D., Ram, A., Veloso, M., Weld, D., & Wilkins,
D. (1998). PDDL Planning Domain Definition Language, version 1.2. Tech. rep. CVC
TR-98-003/DCS TR-1165, Yale center computational vision control.
Gil, Y. (1994). Learning experimentation: Incremental refinement incomplete planning domains. Proceedings 11th International Conference Machine Learning (ICML-94),
pp. 1013.
Ginsberg, M. L. (1987). Readings Nonmonotonic Reasoning, chap. 1, pp. 123. Morgan Kaufmann, Los Altos, CA.
Hajishirzi, H., & Amir, E. (2007). Stochastic filtering probabilistic action models. Proc. National Conference Artificial Intelligence (AAAI 07).
Hill, D. J., Minsker, B., & Amir, E. (2007). Real-time Bayesian anomaly detection environmental
sensor data. 32nd Congress International Association Hydraulic Engineering
Research (IAHR 2007).
Hlubocky, B., & Amir, E. (2004). Knowledge-gathering agents adventure games. AAAI-04
Workshop Challenges Game AI. AAAI Press.
Holmes, M. P., & Charles Lee Isbell, J. (2006). Looping suffix tree-based inference partially
observable hidden state. Proceedings 23rd International Conference Machine
Learning (ICML-06), pp. 409416. ACM Press.
Iwanuma, K., & Inoue, K. (2002). Minimal answer computation sol. Logics Artificial
Intelligence: Proceedings Eighth European Conference, Vol. 2424 LNAI, pp. 245
257. Springer-Verlag.
James, M., & Singh, S. (2004). Learning discovery predictive state representations dynamical systems reset. Proceedings 21st International Conference Machine
Learning (ICML-04), pp. 417424. ACM Press.
Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning acting partially
observable stochastic domains. Artificial Intelligence, 101, 99134.
Kearns, M., Mansour, Y., & Ng, A. Y. (2000). Approximate planning large POMDPs via reusable
trajectories. Proceedings 12th Conference Neural Information Processing Systems
(NIPS98), published 1999, pp. 10011007. MIT Press.
Kuffner., J. J., & LaValle, S. M. (2000). Rrt-connect: efficient approach single-query path
planning.. IEEE International Conference Robotics Automation (ICRA), pp. 995
1001.
Lee, R. C.-T. (1967). Completeness Theorem Computer Program Finding Theorems
Derivable Given Axioms. Ph.D. thesis, University California, Berkeley.
Lifschitz, V. (1990). semantics STRIPS. Allen, J. F., Hendler, J., & Tate, A. (Eds.),
Readings Planning, pp. 523530. Morgan Kaufmann, San Mateo, California.
400

fiL EARNING PARTIALLY BSERVABLE ETERMINISTIC ACTION ODELS

Littman, M. L. (1996). Algorithms sequential decision making. Ph.D. thesis, Department
Computer Science, Brown University. Technical report CS-96-09.
Littman, M. L., Sutton, R., & Singh, S. (2002). Predictive representations state. Proceedings
15th Conference Neural Information Processing Systems (NIPS01), published 2002.
MIT Press.
Marquis, P. (2000). Consequence finding algorithms. Gabbay, D., & Smets, P. (Eds.), Handbook Defeasible Reasoning Uncertainty Management Systems, Vol. 5: Algorithms
defeasible uncertain reasoning. Kluwer.
McCallum, R. A. (1995). Instance-based utile distinctions reinforcement learning hidden
state. Proceedings 12th International Conference Machine Learning (ICML-95).
Morgan Kaufmann.
McCarthy, J. (1986). Applications Circumscription Formalizing Common Sense Knowledge.
Artificial Intelligence, 28, 89116.
McCarthy, J., & Hayes, P. J. (1969). philosophical problems standpoint artificial intelligence. Meltzer, B., & Michie, D. (Eds.), Machine Intelligence 4, pp. 463502.
Edinburgh University Press.
McIlraith, S., & Amir, E. (2001). Theorem proving structured theories. Proc. Seventeenth
International Joint Conference Artificial Intelligence (IJCAI 01), pp. 624631. Morgan
Kaufmann.
Meuleau, N., Peshkin, L., Kim, K.-E., & Kaelbling, L. P. (1999). Learning finite-state controllers
partially observable environments. Proc. Fifteenth Conference Uncertainty Artificial
Intelligence (UAI 99). Morgan Kaufmann.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering
Efficient SAT Solver. Proceedings 38th Design Automation Conference (DAC01).
Murphy, K. (2002). Dynamic Bayesian Networks: Representation, Inference Learning. Ph.D.
thesis, University California Berkeley.
Nance, M., Vogel, A., & Amir, E. (2006). Reasoning partially observed actions. Proc. National Conference Artificial Intelligence (AAAI 06). AAAI Press.
Oates, T., & Cohen, P. R. (1996). Searching planning operators context-dependent
probabilistic effects. Proc. National Conference Artificial Intelligence (AAAI 96), pp.
863868. AAAI Press.
Pasula, H. M., Zettlemoyer, L. S., & Kaelbling, L. P. (2004). Learning probabilistic relational
planning rules. Proceedings 14th Intl Conf. Automated Planning Scheduling
(ICAPS04). AAAI Press.
Pednault, E. P. D. (1989). ADL: exploring middle ground STRIPS situation
calculus. Proc. First International Conference Principles Knowledge Representation
Reasoning (KR 89), pp. 324332.
Reiter, R. (2001). Knowledge Action: Logical Foundations Describing Implementing
Dynamical Systems. MIT Press.
401

fiA MIR & C HANG

Reiter, R. (1991). frame problem situation calculus: simple solution (sometimes)
completeness result goal regression. Lifschitz, V. (Ed.), Artificial Intelligence
Mathematical Theory Computation (Papers Honor John McCarthy), pp. 359380.
Academic Press.
Robert, C. P., Celeux, G., & Diebolt, J. (1993). Bayesian estimation hidden Markov chains:
stochastic implementation. Statist. Prob. Letters, 16, 7783.
Schmill, M. D., Oates, T., & Cohen, P. R. (2000). Learning planning operators real-world, partially observable environments. Proceedings 5th Intl Conf. AI Planning
Scheduling (AIPS00), pp. 246253. AAAI Press.
Shahaf, D., & Amir, E. (2006). Learning partially observable action schemas. Proc. National
Conference Artificial Intelligence (AAAI 06). AAAI Press.
Shahaf, D., & Amir, E. (2007). Logical circuit filtering. Proc. Twentieth International Joint Conference Artificial Intelligence (IJCAI 07), pp. 26112618. International Joint Conferences
Artificial Intelligence.
Shahaf, D., Chang, A., & Amir, E. (2006). Learning partially observable action models: Efficient
algorithms. Proc. National Conference Artificial Intelligence (AAAI 06). AAAI Press.
Simon, L., & del Val, A. (2001). Efficient consequence-finding. Proc. Seventeenth International
Joint Conference Artificial Intelligence (IJCAI 01), pp. 359365. Morgan Kaufmann.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: introduction. MIT Press.
Tang, D., Yinlei Yu, D. R., & Malik, S. (2004). Analysis search based algorithms satisfiability quantified boolean formulas arising circuit state space diameter problems.
Proceedings Seventh International Conference Theory Applications Satisfiability Testing (SAT2004).
Thielscher, M. (1998). Introduction fluent calculus. Electronic Transactions Artificial
Intelligence (http://www.etaij.org), 3, nr 14.
Thrun, S. (2003). Robotic mapping: survey. Exploring artificial intelligence new millennium, pp. 135. Morgan Kaufmann.
Wang, X. (1995). Learning observation practice: incremental approach planning operator acquisition. Proceedings 12th International Conference Machine Learning
(ICML-95), pp. 549557. Morgan Kaufmann.
Wu, K., Yang, Q., & Jiang, Y. (2007). Arms: automatic knowledge engineering tool learning
action models ai planning. Knowledge Engineering Review, 22(2), 135152.
Yang, Q., Wu, K., & Jiang, Y. (2005). Learning actions models plan examples incomplete
knowledge.. Biundo, S., Myers, K. L., & Rajan, K. (Eds.), ICAPS, pp. 241250. AAAI.

402


