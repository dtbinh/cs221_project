journal artificial intelligence

submitted published

latent relation mapping engine
experiments
peter turney

peter turney nrc cnrc gc ca

institute information technology
national council canada
ottawa ontario canada k r

abstract
many ai researchers cognitive scientists argued analogy core
cognition influential work computational modeling analogy making
structure mapping theory smt implementation structure mapping engine
sme limitation sme requirement complex hand coded representations
introduce latent relation mapping engine lrme combines ideas
sme latent relational analysis lra order remove requirement handcoded representations lrme builds analogical mappings lists words
large corpus raw text automatically discover semantic relations among words
evaluate lrme set twenty analogical mapping ten scientific
analogies ten common metaphors lrme achieves human level performance
twenty compare lrme variety alternative approaches
able reach level performance

introduction
faced try recall similar faced
past transfer knowledge past experience current
make analogy past situation current situation
use analogy transfer knowledge gentner minsky holyoak thagard
hofstadter hawkins blakeslee
survey computational modeling analogy making french cites
structure mapping theory smt gentner implementation structure
mapping engine sme falkenhainer forbus gentner influential
work modeling analogy making sme analogical mapping b
source target b source familiar known concrete
whereas target relatively unfamiliar unknown abstract analogical mapping
used transfer knowledge source target
gentner argues two kinds similarity attributional similarity
relational similarity distinction attributes relations may understood terms predicate logic attribute predicate one argument
large x meaning x large relation predicate two arguments
collides x meaning x collides
structure mapping engine prefers mappings relational similarity
mappings attributional similarity falkenhainer et al example sme
able build mapping representation solar system source
c

national council canada reprinted permission

fiturney

representation rutherford bohr model atom target sun mapped
nucleus planets mapped electrons mass mapped charge note
mapping emphasizes relational similarity sun nucleus different
terms attributes sun large nucleus small likewise
planets electrons little attributional similarity hand planets revolve
around sun electrons revolve around nucleus mass sun attracts
mass planets charge nucleus attracts charge electrons
gentner provides evidence children rely primarily attributional similarity
mapping gradually switching relational similarity mature uses
terms mere appearance refer mapping mostly attributional similarity analogy
refer mapping mostly relational similarity literal similarity refer
mixture attributional relational similarity since use analogical mappings solve
make predictions focus structure especially causal relations
look beyond surface attributes things gentner analogy
solar system rutherford bohr model atom illustrates importance
going beyond mere appearance underlying structures
figures lisp representations used sme input analogy
solar system atom falkenhainer et al chalmers french
hofstadter criticize smes requirement complex hand coded representations
argue hard work done human creates high level
hand coded representations rather sme
defentity sun type inanimate
defentity planet type inanimate
defdescription solar system
entities sun planet
expressions mass sun name mass sun
mass planet name mass planet
greater mass sun mass planet name mass
attracts sun planet name attracts form
revolve around planet sun name revolve
mass attracts form name
cause revolve name cause revolve
temperature sun name temp sun
temperature planet name temp planet
greater temp sun temp planet name temp
gravity mass sun mass planet name force gravity
cause force gravity attracts form name attracts

figure representation solar system sme falkenhainer et al
gentner forbus colleagues attempted avoid hand coding
recent work sme cogsketch system generate lisp representations
simple sketches forbus usher lovett lockwood wetzel gizmo system
generate lisp representations qualitative physics yan forbus
learning reader system generate lisp representations natural language text
forbus et al systems require lisp input
dedre gentner personal communication october



fithe latent relation mapping engine

defentity nucleus type inanimate
defentity electron type inanimate
defdescription rutherford atom
entities nucleus electron
expressions mass nucleus name mass n
mass electron name mass e
greater mass n mass e name mass
attracts nucleus electron name attracts form
revolve around electron nucleus name revolve
charge electron name q electron
charge nucleus name q nucleus
opposite sign q nucleus q electron name charge
cause charge attracts form name attracts

figure rutherford bohr model atom sme falkenhainer et al

however cogsketch user interface requires person draws sketch identify basic components sketch hand label terms knowledge
base derived opencyc forbus et al note opencyc contains
hand coded concepts added hand coded concepts opencyc
order support cogsketch gizmo system requires user hand code physical
model methods qualitative physics yan forbus learning reader
uses phrasal patterns derived researchcyc forbus
et al evident sme still requires substantial hand coded knowledge
work present effort avoid complex hand coded representations combine ideas sme falkenhainer et al latent
relational analysis lra turney call resulting latent relation mapping engine lrme represent semantic relation two terms
vector elements derived pattern frequencies large corpus
raw text semantic relations automatically derived corpus lrme
require hand coded representations relations needs list terms
source list terms target given two lists lrme uses corpus
build representations relations among terms constructs mapping
two lists
tables input output lrme analogy solar
system rutherford bohr model atom although human effort involved
constructing input lists considerably less effort sme requires input
contrast figures table
scientific analogies analogy solar system rutherfordbohr model atom may seem esoteric believe analogy making ubiquitous
daily lives potential practical application work task identifying
semantic roles gildea jurafsky since roles relations attributes
appropriate treat semantic role labeling analogical mapping
example judgement semantic frame contains semantic roles judge
evaluee reason statement frame contains roles speaker addressee message topic medium gildea jurafsky task identifying


fiturney

source
planet
attracts
revolves
sun
gravity
solar system
mass

target b
revolves
atom
attracts
electromagnetism
nucleus
charge
electron

table representation input lrme
source
solar system
sun
planet
mass
attracts
revolves
gravity

mapping








target b
atom
nucleus
electron
charge
attracts
revolves
electromagnetism

table representation output lrme
semantic roles automatically label sentences roles following examples gildea jurafsky
judge blames evaluee government reason failing enough
help
speaker talked topic proposal medium phone
training set labeled sentences testing set unlabeled sentences
may view task labeling testing sentences creating analogical
mappings training sentences sources testing sentences targets table shows blames government failing enough help might
mapped blame company polluting environment mapping
found transfer knowledge form semantic role labels source
target
source

blames
government
failing
help

mapping






target b

blame
company
polluting
environment

table semantic role labeling analogical mapping
section briefly discuss hypotheses behind design lrme
precisely define task performed lrme specific form analogical mapping


fithe latent relation mapping engine

section lrme builds latent relational analysis lra hence summarize lra
section discuss potential applications lrme section
evaluate lrme created twenty analogical mapping ten science analogy holyoak thagard ten common metaphor lakoff
johnson table one science analogy intended solution
given table validate intended solutions gave colleagues lists
terms table asked generate mappings lists section
presents experiment across twenty average agreement
intended solutions table
lrme outlined section along evaluation twenty
mapping lrme achieves accuracy difference
performance human average statistically significant
section examines variety alternative approaches analogy mapping task
best achieves accuracy requires hand coded partof speech tags performance significantly lrme human performance
section discuss questions raised preceding
sections related work described section future work limitations considered
section conclude section

guiding hypotheses
section list assumptions guided design lrme
present necessarily require assumptions might
helpful reader understand reasoning behind
analogies semantic relations analogies semantic relations
gentner example analogy solar system rutherford bohr model atom similarity semantic relations
among concepts involved understanding solar system semantic
relations among concepts involved rutherford bohr model atom
co occurrences semantic relations two terms interesting significant semantic relation tend co occur within relatively
small window e g five words relatively large corpus e g words
interesting semantic relation causes co occurrence co occurrence reliable
indicator interesting semantic relation firth
meanings semantic relations meaning relations among
words individual words individual words tend ambiguous polysemous
putting two words pair constrain possible meanings putting
words sentence multiple relations among words sentence
constrain possible meanings focus word pairs tuples instead
individual words word sense disambiguation less problematic perhaps word
sense apart relations words kilgarriff
pattern distributions semantic relations many many mapping semantic relations patterns two terms co occur
example relation causeeffect x may expressed x causes


fiturney

x due x x likewise pattern
x may expression causeeffect x sick bacteria
originentity x oranges spain however given x statistical distribution patterns x co occur reliable signature
semantic relations x turney
extent lrme works believe success lends support hypotheses

task
examine generate analogical mappings simplicity
restrict task generating bijective mappings mappings injective
one one instance two terms source map term
target surjective onto source terms cover target terms
target term left mapping assume entities
mapped given input formally input two sets terms
b
ha bi



since mappings bijective b must contain number terms




b b b bm



term ai bj may consist single word planet compound two words
solar system words may part speech nouns verbs adjectives adverbs
output bijective mapping b
b



ai b



b



consider accept batch multiple independent mapping
input generate mapping one output
ha b ha b han bn



b b mn bn



suppose terms arbitrary order
ha
mapping function b given determines unique ordering b b




fithe latent relation mapping engine

b hm



likewise ordering b b given defines unique mapping function since
possible orderings b possible mappings b task
search mappings best one section shows
relatively high degree consensus mappings best
let p b set bijective mappings b p stands permutation since mapping corresponds permutation
p b mm



b



p b



following experiments average usually around
feasible us exhaustively search p b
explore two basic kinds generating analogical mappings
attributional similarity relational similarity turney
attributional similarity two words sima b depends
degree correspondence properties b correspondence
greater attributional similarity relational similarity two
pairs words simr b c depends degree correspondence
relations b c correspondence greater relational
similarity example dog wolf relatively high degree attributional similarity
whereas dog bark cat meow relatively high degree relational similarity
attributional mapping seek mapping mappings maximizes
sum attributional similarities terms corresponding
terms b multiple mappings maximize sum break tie
randomly choosing one
arg max


x

sima ai ai



p b

relational mapping seek mapping mappings mr maximizes
sum relational similarities
mr arg max

x

x

simr ai aj ai aj



p b j

assume simr symmetrical example degree relational similarity
dog bark cat meow degree relational similarity
bark dog meow cat
simr b c simr b c



assume simr b b interesting example may constant
value b therefore designed less j


fiturney

let scorer scorea defined follows

scorer
scorea

x

x

simr ai aj ai aj

j

x

sima ai ai







mr may defined terms scorer scorea
mr arg max scorer



p b

arg max scorea



p b

mr best mapping according simr best mapping according sima
recall gentners terms discussed section mere appearance mostly attributional similarity analogy mostly relational similarity literal similarity mixture
attributional relational similarity take mr abstract model mapping analogy model mere appearance literal similarity
combine mr take care normalize scorer scorea
combine experiment combining section

latent relational analysis
lrme uses simplified form latent relational analysis lra turney
calculate relational similarity pairs words briefly describe past
work lra present lrme
lra takes input set word pairs generates output relational
similarity simr ai bi aj bj two pairs input
b b bn



simr



lra designed evaluate proportional analogies proportional analogies form
b c means b c example mason stone carpenter wood
means mason stone carpenter wood mason artisan works
stone carpenter artisan works wood
consider proportional analogies special case bijective analogical mapping
defined section b example b b equivalent

b b b b b
definition scorer following




fithe latent relation mapping engine

scorer simr simr b b



quality proportional analogy mason stone carpenter wood given
simr mason stone carpenter wood
proportional analogies may evaluated attributional similarity
definition scorea following
scorea sima sima sima b sima b



attributional similarity quality proportional analogy mason stone carpenter
wood given sima mason carpenter sima stone wood
lra handles proportional analogies main contribution lrme extend
lra beyond proportional analogies bijective analogies
turney describes ten potential applications lra recognizing proportional
analogies structure mapping theory modeling metaphor classifying semantic relations
word sense disambiguation information extraction question answering automatic thesaurus generation information retrieval identifying semantic roles two
applications evaluating proportional analogies classifying semantic relations experimentally evaluated state art
turney compares performance relational similarity attributional
similarity task solving multiple choice proportional analogy questions
sat college entrance test lra used measure relational similarity variety
lexicon corpus used measure attributional similarity
lra achieves accuracy sat questions significantly
different average human score hand best performance
attributional similarity attributional similarity better
random guessing good relational similarity consistent
gentners theory maturation human similarity judgments
turney applies lra task classifying semantic relations nounmodifier expressions noun modifier expression phrase laser printer
head noun printer preceded modifier laser task identify semantic
relation noun modifier case relation instrument
laser instrument used printer set hand labeled noun modifier pairs
five different classes semantic relations lra attains accuracy
turney employs variation lra solving four different language tests
achieving accuracy sat analogy questions accuracy toefl synonym
questions accuracy task distinguishing synonyms antonyms
accuracy task distinguishing words similar words associated
words similar associated core used
four tests tuning parameters particular test

applications lrme
since lrme extension lra every potential application lra potential
application lrme advantage lrme lra ability handle bijective


fiturney

analogies b section consider kinds
applications might benefit ability
section evaluate lrme science analogies common metaphors
supports claim two applications benefit ability handle larger sets
terms section saw identifying semantic roles gildea jurafsky
involves two terms believe lrme superior lra
semantic role labeling
semantic relation classification usually assumes relations binary
semantic relation connection two terms rosario hearst nastase
szpakowicz turney girju et al yuret observed binary relations may linked underlying n ary relations example nastase szpakowicz
defined taxonomy binary semantic relations table shows six binary relations nastase szpakowicz covered one ary relation
agent tool action affected theme agent uses tool perform action somebody
something affected action whole event summarized theme
nastase szpakowicz
relation
example
agent
student protest
purpose
concert hall
beneficiary
student discount
instrument
laser printer
object
metal separator
object property sunken ship

agent tool action affected theme
agent action
theme tool
affected action
tool agent
affected tool
action affected

table six binary semantic relations nastase szpakowicz
viewed different fragments one ary semantic relation

semeval task found easier manually tag datasets expanded
binary relations underlying n ary relations girju et al believe
expansion would facilitate automatic classification semantic relations
section suggest applications lra discussed section
might benefit able handle bijective analogies

mapping
evaluate analogical mapping created twenty mapping
given appendix twenty consist ten science analogy
examples analogy science chapter holyoak thagard ten
common metaphor derived lakoff johnson
tables appendix intended mappings twenty validate mappings invited colleagues institute information
technology participate experiment experiment hosted web server
deniz yuret personal communication february observation context
work building datasets semeval task girju et al



fithe latent relation mapping engine

accessible inside institute people participated anonymously web
browsers offices volunteers began experiment
went way end analysis use data participants
completed mapping
instructions participants appendix sequence
order terms within randomized separately participant
remove effects due order table shows agreement intended
mapping mappings generated participants across twenty
average agreement higher agreement figures many
linguistic annotation tasks agreement impressive given participants
minimal instructions training
type

science
analogies

common
metaphors

mapping





















source target
solar system atom
water flow heat transfer
waves sounds
combustion respiration
sound light
projectile planet
artificial selection natural selection
billiard balls gas molecules
computer mind
slot machine bacterial mutation
war argument
buying item accepting belief
grounds building reasons theory
impediments travel difficulties
money time
seeds ideas
machine mind
object idea
following understanding
seeing understanding

average

agreement













































table average agreement intended mappings mappings
participants see appendix details

column labeled gives number terms set source terms
mapping equal number terms set target terms
average third column table gives mnemonic summarizes
mapping e g solar system atom note mnemonic used input
mnemonic shown participants experiment
agreement figures table individual mapping averages
mappings appendix gives detailed view showing
agreement individual mapping mappings twenty contain
total individual mappings appendix shows every one


fiturney

mappings agreement higher every case majority
participants agreed intended mapping two cases agreement
exactly see table table appendix
select mapping chosen majority participants
get perfect score twenty precisely try mappings
select mapping maximizes sum number participants
agree individual mapping mappings score
twenty strong support intended mappings
given appendix
section applied genters categories mere appearance mostly attributional similarity analogy mostly relational similarity literal similarity mixture
attributional relational similarity mappings mr mr
best mapping according simr best mapping according sima twenty
mapping chosen analogy intended mappings
appendix meant relational mappings mr mappings maximize relational
similarity simr tried avoid mere appearance literal similarity
section use twenty mapping evaluate relational mapping
lrme section use evaluate several different attributional
mapping hypothesis lrme perform significantly better
attributional mapping twenty mapping
analogy mere appearance literal similarity
expect relational attributional mapping would perform approximately
equally well literal similarity expect mere appearance
would favour attributional relational test
latter two hypotheses primary interest analogy making
goal test hypothesis real practical effective measurable
difference output lrme output attributional mapping skeptic might claim relational similarity simr b c
reduced attributional similarity sima c sima b therefore relational mapping
complicated solution illusory slightly less skeptical claim
relational similarity versus attributional similarity valid distinction cognitive
psychology relational mapping capture distinction test
hypothesis refute skeptical claims created twenty analogical mapping
lrme handles significantly better
attributional mapping

latent relation mapping engine
latent relation mapping engine lrme seeks mapping mr maximizes
sum relational similarities
mr arg max

x

x

simr ai aj ai aj



p b j

search mr exhaustively evaluating possibilities ties broken randomly use simplified form lra turney calculate simr


fithe latent relation mapping engine


briefly idea lrme build pair pattern matrix x rows correspond
pairs terms columns correspond patterns example row xi might
correspond pair terms sun solar system column x j might correspond
pattern x centered patterns wild card match
single word value element xij x frequency pattern
x j x instantiated terms pair xi example
take pattern x centered instantiate x pair sun solar system
pattern sun centered solar system thus value element
xij frequency sun centered solar system corpus matrix
x smoothed truncated singular value decomposition svd golub van loan
relational similarity simr two pairs terms given cosine
angle two corresponding row vectors x
detail lrme takes input set mapping generates
output corresponding set mappings

ha b ha b han bn



b b mn bn



following experiments twenty mapping appendix processed
one batch n
first step make list r contains pairs terms input
mapping ha bi add r pairs ai aj ai aj
members j pairs bi bj bi bj members b j
b pairs pairs b
typical pair r would sun solar system allow duplicates r r list
pair types pair tokens twenty mapping r list pairs
pair r r make list r phrases corpus contain
pair r let ai aj terms pair r search corpus phrases
following form
words ai words aj words



ai aj r aj ai r phrases members pairs
orders ai aj aj ai search template used
turney
following experiments search corpus english words
gb plain text consisting web gathered web crawler retrieve phrases
need pairs orders want
calculate simr one order pairs less j however ensure
simr symmetrical need make matrix x symmetrical rows
matrix orders every pair
corpus collected charles clarke university waterloo provide copies
corpus request



fiturney

corpus use wumpus buttcher clarke efficient search engine
passage retrieval large corpora
pairs r total phrases corpus average
phrases per pair pair r sun solar system typical phrase
r would sun centered solar system illustrates
next make list c patterns phrases found pair
r r r ai aj found phrase r replace ai x
replace aj remaining words may left replaced
wild card symbol replace ai aj x replace
remaining words wild cards leave n remaining
words ai aj replaced generate n patterns add
patterns c add patterns c c list pattern types
pattern tokens duplicates c
example pair sun solar system found phrase sun centered solar
system illustrates replace ai aj x x centered
illustrates three remaining words generate eight patterns
x illustrates x centered x illustrates
patterns added c replace ai aj x yielding centered x
illustrates gives us another eight patterns centered x thus
phrase sun centered solar system illustrates generates total sixteen patterns
add c
revise r make list pairs correspond rows frequency
matrix f remove pairs r phrases found corpus
terms order let ai aj terms pair r remove
r r ai aj aj ai empty remove rows
would correspond zero vectors matrix f reduces r pairs
pairs let nr number pairs r
next revise c make list patterns correspond columns
frequency matrix f following experiments stage c contains millions
patterns many efficient processing standard desktop computer need
reduce c manageable size select patterns shared
pairs let c pattern c let r pair r phrase r
pattern generated identical c say r one
pairs generated c sort patterns c descending order number
pairs r generated pattern select top tnr patterns
sorted list following turney set parameter hence c reduced
top patterns tnr let nc number patterns
c nc tnr
rows r columns c defined build frequency matrix
f let ri th pair terms r e g let ri sun solar system let cj
j th pattern c e g let cj x centered instantiate x
pattern cj terms ri sun centered solar system element fij f
frequency instantiated pattern corpus
wumpus developed stefan buttcher available http www wumpus search org



fithe latent relation mapping engine

note need search corpus instantiated pattern
fij order frequency process creating pattern keep track
many phrases generated pattern pair get frequency fij
checking record patterns generated ri
next step transform matrix f raw frequencies form x
enhances similarity measurement turney used log entropy transformation
suggested landauer dumais kind tf idf term frequency
times inverse document frequency transformation gives weight elements
matrix statistically surprising however bullinaria levy recently
achieved good transformation called ppmic positive pointwise mutual
information cosine therefore lrme uses ppmic raw frequencies f used
calculate probabilities calculate pointwise mutual information
pmi element matrix element negative pmi set zero

fij
pij pnr pnc

j fij





pnc

j fij
pi pnr pnc



pnr
f
pncij
pnr





pj





j fij
j fij

pij
pi pj



pmiij log

pmiij pmiij
xij
otherwise




let ri th pair terms r e g let ri sun solar system let cj
j th pattern c e g let cj x centered pij estimated probability
pattern cj instantiated pair ri sun centered solar system pi
estimated probability ri pj estimated probability cj ri cj
statistically independent pi pj pij definition independence thus
pmiij zero since log interesting semantic relation
terms ri pattern cj captures aspect semantic relation
expect pij larger would ri cj indepedent hence
pij pi pj thus pmiij positive see hypothesis section
hand terms completely different domains may avoid case
pmiij negative ppmic designed give high value xij
pattern cj captures aspect semantic relation terms ri otherwise
xij value zero indicating pattern cj tells us nothing
semantic relation terms ri
experiments f density percentage nonzero elements
x density lower density x due elements negative pmi
transformed zero ppmic


fiturney

smooth x applying truncated singular value decomposition svd golub
van loan use svdlibc calculate svd x svdlibc designed
sparse low density matrices svd decomposes x product three matrices
uvt u v column orthonormal form e columns orthogonal
unit length ut u vt v diagonal matrix singular values
golub van loan x rank r rank r let k
k r diagonal matrix formed top k singular values let uk vk
matrices produced selecting corresponding columns u v matrix
uk k vkt matrix rank k best approximates original matrix x sense
minimizes approximation errors x uk k vkt minimizes kx xkf
matrices x rank k k kf denotes frobenius norm golub van
loan may think matrix uk k vkt smoothed compressed version
original matrix x following turney set parameter k
relational similarity simr two pairs r inner product two
corresponding rows uk k vkt rows normalized unit length
simplify calculations dropping vk deerwester dumais landauer furnas harshman
take matrix uk k normalize row unit length let w
resulting matrix let z wwt square matrix size nr nr matrix contains
cosines combinations two pairs r
mapping ha bi let pair terms let b b
pair terms b suppose ri rj b b ri rj
th j th pairs r simr b b zij zij element th
row j th column z b b r
b b b b empty set similarity zero finally mapping
output map mr maximizes sum relational similarities

mr arg max

x

x

simr ai aj ai aj



p b j

simplified form lra used calculate simr differs lra used turney
several ways lrme use synonyms generate alternate forms
pairs terms lrme morphological processing terms lrme uses
ppmic bullinaria levy process raw frequencies instead log entropy
following turney lrme uses slightly different search template lrme
sets number columns nc tnr instead constant section
evaluate impact two changes ppmic nc tested
changes mainly motivated desire increased efficiency
simplicity
experiments
implemented lrme perl making external calls wumpus searching corpus
svdlibc calculating svd used perl net telnet package interprocess
svdlibc work doug rohde available http tedlab mit edu dr svdlibc



fithe latent relation mapping engine

communication wumpus pdl perl data language package matrix manipulations e g calculating cosines list permutor package generate permutations
e loop p b
ran following experiments dual core amd opteron computer running
bit linux running time spent searching corpus phrases took
hours minutes wumpus fetch phrases remaining steps
took minutes svd took minutes running time could cut half
raid speed disk access
table shows performance lrme baseline configuration comparison
agreement volunteers intended mapping copied table
difference performance lrme human participants
statistically significant paired test confidence level

mapping




















average

source target
solar system atom
water flow heat transfer
waves sounds
combustion respiration
sound light
projectile planet
artificial selection natural selection
billiard balls gas molecules
computer mind
slot machine bacterial mutation
war argument
buying item accepting belief
grounds building reasons theory
impediments travel difficulties
money time
seeds ideas
machine mind
object idea
following understanding
seeing understanding

accuracy
lrme humans











































table lrme baseline configuration compared human performance
table column labeled humans average people whereas lrme
column one average comparing average several scores
individual score whether individual human may give
misleading impression individual person typically several
scores scores range average mapping seven
terms possible exactly one term mapped incorrectly
incorrect mappings must two incorrect mappings follows
nature bijections therefore score uncommon


fiturney

table looks another perspective column labeled lrme wrong
gives number incorrect mappings made lrme twenty
five columns labeled number people n wrong values n
may people made n incorrect mappings average mapping
participants perfect score n remaining participants
made two mistakes n table shows clearly table lrmes
performance significantly different individual human performance yet
another perspective see section

mapping




















average

lrme
wrong






















number people n wrong
n n n n n

































































































































table another way viewing lrme versus human performance
table examine sensitivity lrme parameter settings first row
shows accuracy baseline configuration table next eight rows
impact varying k dimensionality truncated singular value decomposition
eight rows effect varying column factor
number columns matrix nc given number rows nr
multiplied second last row shows effect eliminating singular
value decomposition lrme equivalent setting k number
rows matrix final row gives ppmic bullinaria levy
replaced log entropy turney lrme sensitive
manipulations none variations table perform significantly differently
baseline configuration paired test confidence level necessarily mean
manipulations effect rather suggests larger sample
would needed significant effect


fithe latent relation mapping engine

experiment
baseline configuration

varying k

varying

dropping svd
log entropy

k









































nc




















accuracy




















table exploring sensitivity lrme parameter settings modifications

attribute mapping approaches
section explore variety attribute mapping approaches twenty mapping
approaches seek mapping maximizes sum
attributional similarities
arg max


x

sima ai ai



p b

search exhaustively evaluating possibilities ties broken randomly use variety different calculate sima

following experiments test five lexicon attributional similarity measures
use wordnet hso hirst st onge jc jiang conrath lc leacock chodrow lin lin res resnik five implemented
perl package wordnet similarity builds wordnet querydata package core idea behind treat wordnet graph measure semantic
distance two terms length shortest path graph
similarity increases distance decreases
wordnet developed team princeton available http wordnet princeton edu
ted pedersens wordnet similarity package http www umn edu tpederse similarity html
jason rennies wordnet querydata package http people csail mit edu jrennie wordnet



fiturney

hso works nouns verbs adjectives adverbs jc lc lin res
work nouns verbs used wordnet similarity try possible parts speech
possible senses input word many adjectives true valuable
noun verb senses wordnet jc lc lin res still able
calculate similarity raw form word found wordnet
wordnet similarity searches morphological variations word
multiple similarity scores multiple parts speech multiple senses select
highest similarity score similarity score word wordnet
jc lc lin res could alternative noun verb form
adjective adverb set score zero
evaluate two corpus attributional similarity measures pmi ir turney
lsa landauer dumais core idea behind word
characterized company keeps firth similarity two terms
measured similarity statistical distributions corpus used corpus
section along wumpus implement pmi ir pointwise mutual information
information retrieval lsa latent semantic analysis used online
demonstration selected matrix comparison option general reading
st year college factors topic space term term comparison type pmi ir
lsa work parts speech
eighth similarity measure observation intended mappings
map terms part speech see appendix let pos partof speech tag assigned term use part speech tags define measure
attributional similarity simpos b follows

b
pos pos b

simpos b

otherwise
hand labeled terms mapping part speech tags santorini
automatic taggers assume words tagged embedded
sentence terms mapping sentences tags
ambiguous used knowledge intended mappings manually disambiguate
part speech tags terms thus guaranteeing corresponding terms
intended mapping tags
first seven attributional similarity measures created seven
similarity measures combining simpos b example let simhso b
hirst st onge similarity measure combine simpos b simhso b
simply adding
simhso pos b simhso b simpos b



values returned simpos b range whereas values returned
simhso b much smaller chose large values getting pos tags
match weight similarity measures manual pos tags
online demonstration lsa work team university colorado boulder
available http lsa colorado edu



fithe latent relation mapping engine

high weight simpos b give unfair advantage attributional mapping
relational mapping afford generous
experiments
table presents accuracy measures attributional similarity
best without pos labels hso best pos labels
lin pos accuracy lrme see table significantly higher
accuracy lin pos thus course significantly higher everything else
table paired test confidence level average human performance
see table significantly higher accuracy lin pos paired test
confidence level summary humans lrme perform significantly better
variations attributional mapping approaches tested

hso
jc
lc
lin
res
pmi ir
lsa
pos hand labeled
hso pos
jc pos
lc pos
lin pos
res pos
pmi ir pos
lsa pos

reference
hirst st onge
jiang conrath
leacock chodrow
lin
resnik
turney
landauer dumais
santorini
hirst st onge
jiang conrath
leacock chodrow
lin
resnik
turney
landauer dumais

accuracy
















table accuracy attribute mapping approaches wide variety measures
attributional similarity

discussion
section examine three questions suggested preceding
difference science analogy common metaphor
advantage combining relational attributional mapping approaches advantage relational mapping attributional
mapping
science analogies versus common metaphors
table suggests science analogies may difficult common metaphors
supported table shows agreement participants
intended mapping see section varies science metaphor


fiturney

science lower average performance greater variation
performance difference science metaphor
statistically significant paired test confidence level
participant






















average
standard deviation



























average accuracy
science metaphor

















































table comparison difficulty science versus metaphor participants numbers bold font scores
scores lrme
average science terms average metaphor
might contribute difficulty science however table
shows clear relation number terms
table level agreement believe people metaphor
easier science common metaphors entrenched
language whereas science analogies peripheral
table shows studied perform slightly worse science
metaphor difference statistically significant
paired test confidence level hypothesize attributional mapping approaches performing well enough sensitive subtle differences science
analogies common metaphors
incidentally tables give us another view performance lrme comparison human performance first row table shows performance lrme


fithe latent relation mapping engine

num terms






agreement






table average agreement among participants function number
terms


lrme
hso
jc
lc
lin
res
pmi ir
lsa
pos
hso pos
jc pos
lc pos
lin pos
res pos
pmi ir pos
lsa pos
average
standard deviation





















average accuracy
science metaphor





































table comparison difficulty science versus metaphor

science metaphor table marked bold font cases
human scores greater lrmes scores
cases science cases metaphor cases evidence lrmes performance
significantly different human performance lrme near middle range
performance human participants
hybrid relational attributional approaches
recall definitions scorer scorea given section


fiturney

scorer
scorea

x

x

simr ai aj ai aj

j

x

sima ai ai







combine scores simply adding multiplying scorer
scorea may quite different scales distributions values therefore
first normalize probabilities
scorer
mi p b scorer mi



scorea
mi p b scorea mi



probr p
proba p

probability estimates assume scorer scorea
necessary constant value may added scores ensure negative
combine scores adding multiplying probabilities


mr arg max probr proba



p b



mra arg max probr proba



p b

table shows accuracy lrme combined lin pos best attributional mapping table accuracy hso best
attributional mapping use manual pos tags accuracy
try adding multiplying probabilities lrme
accuracy combining lrme lin pos increases accuracy
improvement statistically significant paired test confidence level combining lrme hso decrease accuracy decrease significant
probabilities multiplied significant probabilities
added
summary experiments significant advantage combining lrme
attributional mapping however possible larger sample would
significant advantage combination methods explored addition
multiplication probabilities elementary sophisticated
weighted combination may perform better
coherent relations
hypothesize lrme benefits kind coherence among relations
hand attributional mapping approaches involve kind coherence


fithe latent relation mapping engine

components
relational attributional
lrme
lin pos
lrme
lin pos
lrme
hso
lrme
hso

combination
add probabilities
multiply probabilities
add probabilities
multiply probabilities

accuracy





table performance four different hybrids relational attributional mapping
approaches

suppose swap two terms mapping let original mapping
let mapping ai ai
attributional similarity impact swap score mapping
limited part score affected

scorea sima sima


x

sima ai ai



sima ai ai





scorea sima sima


x


hand relational similarity impact swap limited
way change part mapping affects whole score kind global
coherence relational similarity lacking attributional similarity
testing hypothesis lrme benefits coherence somewhat complicated
need design experiment coherence effect isolated
effects move terms outside accuracy calculation
let b one twenty mapping intended
mapping b let randomly selected subset size let b
subset b maps







b b





b

b








two ways might use lrme generate mapping b
reduced mapping internal coherence total coherence
internal coherence select ha b alone


fiturney







b b bm




arg max



x x

p b j

simr ai aj ai aj



case chosen relations internal ha b
total coherence select ha bi knowledge
must satisfy constraint b knowledge embedded
internal coherence





b b bm


p b p b b
x

x

arg max
simr ai aj ai aj






p b j

case chosen relations internal ha b
relations ha bi external ha b

suppose calculate accuracy two methods subproblem ha b first might seem advantage total coherence
must explore larger space possible mappings internal coherence since
p b larger p b additional terms explores
involved calculating accuracy however hypothesize total coherence
higher accuracy internal coherence additional external relations
help select correct mapping
test hypothesis set randomly generated ten reduced
mapping twenty e total size
average accuracy internal coherence whereas average accuracy
total coherence difference statistically significant paired test
confidence level
hand attributional mapping approaches cannot benefit total
coherence connection attributes ha b
attributes outside decompose scorea two independent parts


fithe latent relation mapping engine










p b p b b
x
arg max
sima ai ai








p b



arg max
p b


x

ai

sima ai ai



x
ai

sima ai ai





two parts optimized independently thus terms external
ha b influence part covers ha b
relational mapping cannot decomposed independent parts way
relations connect parts gives relational mapping approaches inherent
advantage attributional mapping approaches
confirm analysis compared internal total coherence lin pos
size average accuracy internal coherence
whereas average accuracy total coherence difference
statistically significant paired test confidence level reason
difference two mappings score break ties randomly
causes random variation accuracy
benefit coherence suggests make analogy mapping easier
lrme adding terms difficulty terms cannot randomly
chosen must fit logic analogy overlap existing terms
course important difference relational attributional mapping approaches believe important difference relations
reliable general attributes past experiences make
predictions future hofstadter gentner unfortunately hypothesis difficult evaluate experimentally hypothesis coherence

related work
french gives good survey computational approaches analogy making
perspective cognitive science emphasis well computational systems
model human performance rather well systems perform sample
systems survey add mentioned
french categorizes analogy making systems symbolic connectionist symbolicconnectionist hybrids gardenfors proposes another category representational
systems ai cognitive science calls conceptual spaces spatial geometric systems common information retrieval machine learning widdows
van rijsbergen influential example latent semantic analysis landauer
dumais first spatial approaches analogy making began appear around
time frenchs survey lrme takes spatial analogy making


fiturney

symbolic approaches
computational approaches analogy making date back analogy evans
argus reitman systems designed solve proportional analogies
analogies b see section analogy could solve proportional
analogies simple geometric figures argus could solve simple word analogies
systems used hand coded rules able solve limited range
designers anticipated coded rules
french cites structure mapping theory smt gentner structure
mapping engine sme falkenhainer et al prime examples symbolic
approaches
smt unquestionably influential work date modeling
analogy making applied wide range contexts ranging
child development folk physics smt explicitly shifts emphasis analogymaking structural similarity source target domains two
major principles underlie smt
relation matching principle good analogies determined mappings relations attributes originally identical predicates
mapped
systematicity principle mappings coherent systems relations
preferred mappings individual relations
structural intended produce domain independent mapping process
lrme follows principles lrme uses relational similarity attributional similarity involved see section coherent systems relations preferred
mappings individual relations see section however spatial statistical
corpus lrme quite different symbolic logical hand coded
sme
martin uses symbolic handle conventional metaphors gentner
bowdle wolff boronat argue novel metaphors processed analogies
conventional metaphors recalled memory without special processing however
line conventional novel metaphor unclear
dolan describes extract conventional metaphors
dictionary semantic parser used extract semantic relations longman
dictionary contemporary english ldoce symbolic finds metaphorical
relations words extracted relations
veale developed symbolic analogy making wordnet lexical resource spreading activation achieved score
set multiple choice lexical proportional analogy questions sat
college entrance test veale
lepage demonstrated symbolic proportional analogies
used morphology processing lepage denoual apply similar
machine translation


fithe latent relation mapping engine

connectionist approaches
connectionist approaches analogy making include acme holyoak thagard
lisa hummel holyoak symbolic approaches systems use handcoded knowledge representations search mappings takes connectionist nodes weights incrementally updated time
system reaches stable state
symbolic connectionist hybrid approaches
third family examined french hybrid approaches containing elements
symbolic connectionist approaches examples include copycat mitchell
tabletop french much work fluid analogies
group farg concerns symbolic connectionist hybrids hofstadter farg
spatial approaches
marx dagan buhmann shamir present coupled clustering
uses feature vector representation analogies collections text example
given documents buddhism christianity finds related terms school
mahayana zen buddhism tradition catholic protestant christianity
mason describes cormet system extracting conventional metaphors
text cormet clustering feature vectors represent selectional preferences
verbs given keywords source domain laboratory target domain finance
able discover mappings liquid income container institution
turney littman bigham shnayder present system solving lexical
proportional analogy questions sat college entrance test combines thirteen
different modules twelve modules use attributional similarity symbolic
relational similarity one module uses spatial feature vector
measuring relational similarity module worked much better
modules therefore studied detail turney littman
relation pair words represented vector elements pattern
frequencies similar lrme one important difference turney
littman used fixed hand coded set patterns whereas lrme automatically
generates variable number patterns given corpus patterns
experiments
turney introduced latent relational analysis lra examined
thoroughly turney lra achieves human level performance set
multiple choice proportional analogy questions sat college entrance exam lrme
uses simplified form lra similar simplification lra used turney
system processing analogies synonyms antonyms associations contribution
lrme go beyond proportional analogies larger systems analogical mappings
general theories analogy metaphor
many theories analogy making metaphor involve computation
suggest general principles concepts specific particular computational


fiturney

design lrme influenced several theories type gentner
hofstadter farg holyoak thagard hofstadter gentner

lakoff johnson provide extensive evidence metaphor ubiquitous
language thought believe system analogy making able
handle metaphorical language ten analogy derived
lakoff johnson agree claim metaphor merely
involve superficial relation couple words rather involves systematic set
mappings two domains thus analogy involve larger sets words
beyond proportional analogies
holyoak thagard argue analogy making central daily thought
especially finding creative solutions ten scientific analogies
derived examples analogy making scientific creativity

limitations future work
section mentioned ten applications lra section claimed
experiments section suggest lrme may perform better lra
ten applications due ability handle bijective analogies
focus future work testing hypothesis particular task semantic
role labeling discussed section seems good candidate application lrme
input lrme simpler input sme compare figures
section table still human effort involved creating input
lrme immune criticism chalmers french hofstadter
human generates input work computer makes
mappings although trivial matter right mapping
choices
future work would relax requirement ha bi must bijection
see section adding irrelevant words distractors synonyms mapping
forced decide terms include mapping terms
leave
would develop take proportional analogy
input e g sun planet nucleus electron automatically expand larger analogy
e g table would automatically search corpus terms
add analogy
next step would give computer topic source domain e g
solar system topic target domain e g atomic structure let work
rest might possible combining ideas lrme ideas
coupled clustering marx et al cormet mason
seems analogy making triggered people encounter
holyoak thagard defines target us immediately
start searching source analogical mapping enables us transfer knowledge
source target hopefully leading solution suggests
input ideal analogical mapping would simply statement


fithe latent relation mapping engine

e g structure atom ultimately computer might
well input would large corpus
considered perform exhaustive search set
possible mappings p b acceptable sets small
problematic larger future work necessary use
heuristic search instead exhaustive search
takes almost hours lrme process twenty mapping section
better hardware changes software time could significantly
reduced even greater speed could run continuously building large
database vector representations term pairs ready create mappings
soon user requests similar vision banko etzioni
lrme lra lsa landauer dumais uses truncated singular value
decomposition svd smooth matrix many proposed
smoothing matrices past work lra turney experimented
nonnegative matrix factorization nmf lee seung probabilistic latent semantic analysis plsa hofmann iterative scaling ando kernel
principal components analysis kpca scholkopf smola muller
interesting small matrices around none
seemed substantially better truncated svd none scaled matrix
sizes however believe svd unique
future work likely discover smoothing efficient effective
svd section significant benefit svd table
hints ppmic bullinaria levy important svd
lrme extracts knowledge many fragments text section noted
found average phrases per pair information
phrases combined vector represent semantic relation pair
quite different relation extraction example automatic content extraction
ace evaluation task ace identify label semantic relation single
sentence semantic role labeling involves labeling single sentence gildea jurafsky

contrast lrme ace analogous distinction cognitive
psychology semantic episodic memory episodic memory memory
specific event ones personal past whereas semantic memory memory basic facts
concepts unrelated specific event past lrme extracts relational information
independent specific sentence semantic memory ace concerned
extracting relation specific sentence episodic memory cognition episodic
memory semantic memory work together synergistically experience event
use semantic memory interpret event form episodic memory
semantic memory constructed past experiences accumulated
episodic memories suggests synergy combining lrme
semantic information extraction ace episodic information extraction

ace annual event began relation detection characterization rdc
introduced ace information see http www nist gov speech tests ace



fiturney

conclusion
analogy core cognition understand present analogy past
predict future analogy past present solve searching
analogous situations holyoak thagard daily language saturated
metaphor lakoff johnson metaphor analogy gentner et al
understand human language solve human work humans
computers must able make analogical mappings
best theory analogy making structure mapping theory gentner
structure mapping engine falkenhainer et al puts much burden
analogy making human users chalmers et al lrme attempt
shift burden onto computer remaining consistent general
principles smt
shown lrme able solve bijective analogical mapping
human level performance attributional mapping least tried
far able reach level supports smt claims relations
important attributes making analogical mappings
still much done lrme takes load human
user formulating input lrme easy incremental step
towards future computers make surprising useful analogies minimal
human assistance

acknowledgments
thanks colleagues institute information technology participating
experiment section thanks charles clarke egidio terra corpus
thanks stefan buttcher making wumpus available giving advice use
thanks doug rohde making svdlibc available thanks wordnet team
princeton university wordnet ted pedersen wordnet similarity perl package
jason rennie wordnet querydata perl package thanks lsa team
university colorado boulder use online demonstration lsa
thanks deniz yuret andre vellino dedre gentner vivi nastase yves lepage diarmuid
seaghdha roxana girju chris drummond howard johnson stan szpakowicz
anonymous reviewers jair helpful comments suggestions

appendix details mapping
appendix provide detailed information twenty mapping
figure shows instructions given participants experiment
section instructions displayed web browsers tables
twenty mapping first column gives number
e g mnemonic summarizes mapping e g solar system atom
second column gives source terms third column gives target terms
mappings shown tables intended mappings fourth column
shows percentage participants agreed intended mappings example


fithe latent relation mapping engine

systematic analogies metaphors
instructions
presented twenty analogical mapping ten scientific
analogies ten common metaphors typical look
horse
legs
hay
brain
dung



















may click drop menus see options available
task construct analogical mapping one one mapping
items left items right example
horse
legs
hay

car
wheels
gasoline





brain
dung

driver
exhaust




mapping expresses analogy horse car horses legs
cars wheels horse eats hay car consumes gasoline horses brain controls
movement horse cars driver controls movement car horse
generates dung waste product car generates exhaust waste product
duplicate items answers right hand side
duplicates missing items question marks get error message
submit answer
welcome use dictionary work would
helpful
instructions unclear please continue exercise
answers twenty used standard evaluating output
computer therefore proceed confident
understand task
figure instructions participants experiment section



fiturney

mapping

solar system
atom


water flow
heat transfer


waves
sounds


combustion
respiration


sound
light

source
solar system
sun
planet
mass
attracts
revolves
gravity
average agreement
water
flows
pressure
water tower
bucket
filling
emptying
hydrodynamics
average agreement
waves
shore
reflects
water
breakwater
rough
calm
crashing
average agreement
combustion
fire
fuel
burning
hot
intense
oxygen
carbon dioxide
average agreement
sound
low
high
echoes
loud
quiet
horn
average agreement










target
atom
nucleus
electron
charge
attracts
revolves
electromagnetism










heat
transfers
temperature
burner
kettle
heating
cooling
thermodynamics










sounds
wall
echoes
air
insulation
loud
quiet
vibrating










respiration
animal
food
breathing
living
vigorous
oxygen
carbon dioxide









light
red
violet
reflects
bright
dim
lens

agreement












































pos
nn
nn
nn
nn
vbz
vbz
nn
nn
vbz
nn
nn
nn
vbg
vbg
nn
nns
nn
vbz
nn
nn
jj
jj
vbg
nn
nn
nn
vbg
jj
jj
nn
nn
nn
jj
jj
vbz
jj
jj
nn

table science analogy derived chapter holyoak
thagard



fithe latent relation mapping engine

mapping

projectile
planet


artificial selection
natural selection


billiard balls
gas molecules


computer
mind


slot machine
bacterial mutation

source
projectile
trajectory
earth
parabolic
air
gravity
attracts
average agreement
breeds
selection
conformance
artificial
popularity
breeding
domesticated
average agreement
balls
billiards
speed
table
bouncing
moving
slow
fast
average agreement
computer
processing
erasing
write
read
memory
outputs
inputs
bug
average agreement
slot machines
reels
spinning
winning
losing
average agreement










target
planet
orbit
sun
elliptical
space
gravity
attracts









species
competition
adaptation
natural
fitness
mating
wild










molecules
gas
temperature
container
pressing
moving
cold
hot











mind
thinking
forgetting
memorize
remember
memory
muscles
senses
mistake







bacteria
genes
mutating
reproducing
dying

agreement










































pos
nn
nn
nn
jj
nn
nn
vbz
nns
nn
nn
jj
nn
vbg
jj
nns
nn
nn
nn
vbg
vbg
jj
jj
nn
vbg
vbg
vb
vb
nn
nns
nns
nn
nns
nns
vbg
vbg
vbg

table science analogy derived chapter holyoak
thagard



fiturney

mapping

war
argument


buying item
accepting belief


grounds building
reasons theory


impediments travel
difficulties


money
time

source
war
soldier
destroy
fighting
defeat
attacks
weapon
average agreement
buyer
merchandise
buying
selling
returning
valuable
worthless
average agreement
foundations
buildings
supporting
solid
weak
crack
average agreement
obstructions
destination
route
traveller
travelling
companion
arriving
average agreement
money
allocate
budget
effective
cheap
expensive
average agreement










target
argument
debater
refute
arguing
acceptance
criticizes
logic









believer
belief
accepting
advocating
rejecting
true
false








reasons
theories
confirming
rational
dubious
flaw









difficulties
goal
plan
person
solving
partner
succeeding








time
invest
schedule
efficient
quick
slow

agreement







































pos
nn
nn
vb
vbg
nn
vbz
nn
nn
nn
vbg
vbg
vbg
jj
jj
nns
nns
vbg
jj
jj
nn
nns
nn
nn
nn
vbg
nn
vbg
nn
vb
nn
jj
jj
jj

table common metaphor derived lakoff johnson



fithe latent relation mapping engine

mapping

seeds
ideas


machine
mind


object
idea


following
understanding


seeing
understanding

source
seeds
planted
fruitful
fruit
grow
wither
blossom
average agreement
machine
working
turned
turned
broken
power
repair
average agreement
object
hold
weigh
heavy
light
average agreement
follow
leader
path
follower
lost
wanders
twisted
straight
average agreement
seeing
light
illuminating
darkness
view
hidden
average agreement










target
ideas
inspired
productive
product
develop
fail
succeed









mind
thinking
awake
asleep
confused
intelligence
therapy







idea
understand
analyze
important
trivial










understand
speaker
argument
listener
misunderstood
digresses
complicated
simple








understanding
knowledge
explaining
confusion
interpretation
secret

agreement







































pos
nns
vbd
jj
nn
vb
vb
vb
nn
vbg
jj
jj
jj
nn
nn
nn
vb
vb
jj
jj
vb
nn
nn
nn
jj
vbz
jj
jj
vbg
nn
vbg
nn
nn
jj

table common metaphor derived lakoff johnson




fiturney

participants mapped gravity electromagnetism
final column gives part speech pos tags source target terms
used penn treebank tags santorini assigned tags manually
intended mappings tags chosen mapped terms tags
example sun maps nucleus sun nucleus tagged nn
pos tags used experiments section pos tags used lrme
shown participants experiment section

references
ando r k latent semantic space iterative scaling improves precision interdocument similarity measurement proceedings rd annual acm sigir
conference development information retrieval sigir pp

banko etzioni strategies lifelong knowledge extraction web
proceedings th international conference knowledge capture k cap
pp
bullinaria j levy j extracting semantic representations word cooccurrence statistics computational study behavior methods

buttcher clarke c efficiency vs effectiveness terabyte scale information retrieval proceedings th text retrieval conference trec
gaithersburg md
chalmers j french r hofstadter r high level perception representation analogy critique artificial intelligence methodology journal
experimental theoretical artificial intelligence
deerwester c dumais landauer k furnas g w harshman r
indexing latent semantic analysis journal american society
information science jasis
dolan w b metaphor emergent property machine readable dictionaries proceedings aaai spring symposium series representation
acquisition lexical knowledge polysemy ambiguity generativity pp
evans heuristic program solve geometric analogy proceedings
spring joint computer conference pp
falkenhainer b forbus k gentner structure mapping engine
examples artificial intelligence
firth j r synopsis linguistic theory studies linguistic
analysis pp blackwell oxford
forbus k usher j lovett lockwood k wetzel j cogsketch opendomain sketch understanding cognitive science education
proceedings fifth eurographics workshop sketch interfaces modeling annecy france


fithe latent relation mapping engine

forbus k riesbeck c birnbaum l livingston k sharma ureel l
prototype system learns reading simplified texts aaai spring symposium
machine reading stanford university california
french r subtlety sameness theory computer model analogymaking mit press cambridge
french r computational modeling analogy making trends cognitive
sciences
gardenfors p conceptual spaces geometry thought mit press
gentner structure mapping theoretical framework analogy cognitive
science
gentner language career similarity gelman byrnes j
eds perspectives thought language interrelations development pp
cambridge university press
gentner smart gentner goldin meadow eds
language mind advances study language thought pp
mit press
gentner bowdle b f wolff p boronat c metaphor analogy
gentner holyoak k j kokinov b n eds analogical mind perspectives cognitive science pp mit press cambridge
gildea jurafsky automatic labeling semantic roles computational
linguistics
girju r nakov p nastase v szpakowicz turney p yuret semeval task classification semantic relations nominals proceedings
fourth international workshop semantic evaluations semeval pp
prague czech republic
golub g h van loan c f matrix computations third edition johns
hopkins university press baltimore md
hawkins j blakeslee intelligence henry holt
hirst g st onge lexical chains representations context detection
correction malapropisms fellbaum c ed wordnet electronic
lexical database pp mit press
hofmann probabilistic latent semantic indexing proceedings nd
annual acm conference development information retrieval sigir pp berkeley california
hofstadter epilogue analogy core cognition gentner holyoak
k j kokinov b n eds analogical mind perspectives cognitive
science pp mit press
hofstadter farg fluid concepts creative analogies computer
fundamental mechanisms thought basic books york ny


fiturney

holyoak k thagard p analogical mapping constraint satisfaction cognitive
science
holyoak k thagard p mental leaps mit press
hummel j holyoak k distributed representations structure theory
analogical access mapping psychological review
jiang j j conrath w semantic similarity corpus statistics
lexical taxonomy proceedings international conference
computational linguistics rocling x pp tapei taiwan
kilgarriff dont believe word senses computers humanities

lakoff g johnson metaphors live university chicago press
landauer k dumais solution platos latent semantic analysis theory acquisition induction representation knowledge
psychological review
leacock c chodrow combining local context wordnet similarity
word sense identification fellbaum c ed wordnet electronic lexical
database mit press
lee seung h learning parts objects nonnegative matrix
factorization nature
lepage solving analogies words proceedings th
annual conference association computational linguistics pp
lepage denoual e purest ever example machine translation detailed
presentation assessment machine translation
lin information theoretic definition similarity proceedings th
international conference machine learning icml
martin j h computer understanding conventional metaphoric language cognitive science
marx z dagan buhmann j shamir e coupled clustering method
detecting structural correspondence journal machine learning

mason z cormet computational corpus conventional metaphor extraction system computational linguistics
minsky society mind simon schuster york ny
mitchell analogy making perception computer model mit press cambridge
nastase v szpakowicz exploring noun modifier semantic relations
fifth international workshop computational semantics iwcs pp
tilburg netherlands
reitman w r cognition thought information processing john
wiley sons york ny


fithe latent relation mapping engine

resnik p information content evaluate semantic similarity taxonomy
proceedings th international joint conference artificial intelligence
ijcai pp san mateo ca morgan kaufmann
rosario b hearst classifying semantic relations noun compounds
via domain specific lexical hierarchy proceedings conference
empirical methods natural language processing emnlp pp
santorini b part speech tagging guidelines penn treebank project tech
rep department computer information science university pennsylvania
rd revision nd printing
scholkopf b smola j muller k r kernel principal component analysis
proceedings international conference artificial neural networks icann pp berlin
turney p mining web synonyms pmi ir versus lsa toefl
proceedings twelfth european conference machine learning ecml
pp freiburg germany
turney p measuring semantic similarity latent relational analysis proceedings nineteenth international joint conference artificial intelligence
ijcai pp edinburgh scotland
turney p similarity semantic relations computational linguistics

turney p uniform analogies synonyms antonyms associations proceedings nd international conference computational
linguistics coling pp manchester uk
turney p littman l corpus learning analogies semantic
relations machine learning
turney p littman l bigham j shnayder v combining independent
modules solve multiple choice synonym analogy proceedings
international conference recent advances natural language processing
ranlp pp borovets bulgaria
van rijsbergen c j geometry information retrieval cambridge university
press cambridge uk
veale analogical thesaurus proceedings th innovative applications artificial intelligence conference iaai pp acapulco
mexico
veale wordnet sits sat knowledge lexical analogy
proceedings th european conference artificial intelligence ecai
pp valencia spain
widdows geometry meaning center study language
information stanford ca
yan j forbus k similarity qualitative simulation proceedings
th annual meeting cognitive science society stresa italy




