Journal Artificial Intelligence Research 51 (2014) 779804

Submitted 09/14; published 12/14

Research Note
BDD Ordering Heuristics Classical Planning
Peter Kissmann
Jorg Hoffmann

KISSMANN @ CS . UNI - SAARLAND . DE
HOFFMANN @ CS . UNI - SAARLAND . DE

Saarland University, Saarbrucken, Germany

Abstract
Symbolic search using binary decision diagrams (BDDs) often save large amounts memory due concise representation state sets. decisive factor methods success
chosen variable ordering. Generally speaking, plausible dependent variables
brought close together order reduce BDD sizes. planning, variable dependencies typically captured means causal graphs, preceding work taken basis
finding BDD variable orderings. Starting observation two concepts dependency actually quite different, introduce framework assessing strength variable
ordering heuristics sub-classes planning. turns that, even extremely simple planning
tasks, causal graph based variable orders may exponentially worse optimal.
Experimental results wide range variable ordering variants corroborate theoretical
findings. Furthermore, show dynamic reordering much effective reducing BDD
size, cost-effective due prohibitive runtime overhead. exhibit potential
middle-ground techniques, running dynamic reordering simple stopping criteria hold.

1. Introduction
Finding good variable orderings important task many areas Artificial Intelligence,
constraint satisfaction problems (CSPs), SAT, planning (for heuristic search approaches,
especially applying symbolic search). many cases, efficient ordering determined
evaluating graphical representation underlying problem. CSPs, example,
constraint graph used determine variable ordering backtracking-based approaches.
Typical approaches take minimum width (Freuder, 1982), maximum degree, maximum cardinality (Dechter & Meiri, 1989) nodes constraint graph account. alternative
approach considers bandwidth constraint graph given ordering, maximal distance ordering two nodes adjacent graph; idea find
ordering minimizes bandwidth (Zabih, 1990).
SAT, widely used approach determine variable order conflict-driven clause learning
(CDCL) variable state independent decaying sum (VSIDS) (Moskewicz, Madigan, Zhao, Zhang,
& Malik, 2001). based weights propositional variables, i.e., often
variable occurs clauses. Recently, Rintanen (2012) noted applying SAT solvers
planning tasks, different ordering might efficient, giving better coverage typical
benchmarks international planning competition (IPC). ordering takes structure
planning tasks account, trying support (sub)goals early possible.
planning, variable dependencies typically represented causal graph (e.g., Knoblock,
1994; Jonsson & Backstrom, 1995; Brafman & Domshlak, 2003; Helmert, 2006), capturing variable
dependencies terms co-occurences action descriptions. kind graph turned
c
2014
AI Access Foundation. rights reserved.

fiK ISSMANN & H OFFMANN

useful great variety purposes, including problem decomposition (Knoblock, 1994),
system design (Williams & Nayak, 1997), complexity analysis (e.g. Jonsson & Backstrom, 1995;
Domshlak & Dinitz, 2001; Brafman & Domshlak, 2003; Katz & Domshlak, 2008; Gimenez &
Jonsson, 2008; Chen & Gimenez, 2010), derivation heuristic functions (Helmert, 2004, 2006),
search topology analysis (Hoffmann, 2011b, 2011a). purposes here, causal graphs
relevant application derivation variable orderings. done BDDs,
return detail below, well merge-and-shrink heuristics (Helmert, Haslum, &
Hoffmann, 2007; Helmert, Haslum, Hoffmann, & Nissim, 2014). merge-and-shrink, complete
variable ordering corresponds (linear) merging strategy, order variables merged
global abstraction. recent extension non-linear merging strategies (Sievers, Wehrle,
& Helmert, 2014), order merges instead given tree. merge tree bears
similarity concept vtrees, used generalization variable orderings
sentential decision diagram (SDDs) (Darwiche, 2011). Fan, Muller, Holte (2014) shown
efficient merge trees determined means causal graph. so, use MinCuts causal graph, putting two resulting sets variables two different branches
merge tree recursively continue subgraphs.
paper, concerned symbolic search based binary decision diagrams (BDDs)
(Bryant, 1986) optimal planning. variable ordering refers order variables
queried within BDDs, key ingredient practical efficiency approach.
planning, much work invested finding good variable orderings, model
checking, symbolic search originated (McMillan, 1993), many different variable ordering
schemes proposed past (e.g., Malik, Wang, Brayton, & Sangiovanni-Vincentelli,
1988; Minato, Ishiura, & Yajima, 1990). Again, many based evaluation
graphical representation problem. Often, bringing dependent variables close together
results smaller BDDs. straightforwardly applied planning, defining variable
dependencies via causal graph. exactly Gamer, state-of-the-art symbolic search
planner, determines variable ordering (Kissmann & Edelkamp, 2011).
starting point investigation feeling discomfort double use word
dependency above. causal graphs, dependency means corresponding
variables appear least one common action, changing value one variable may require
changing variable well. BDDs, hand, represent Boolean functions .
many assignments subset P variables immediately determine truth value ,
independently value variables, variables P grouped closely
together. planning, typically represents layer states sharing distance initial
state (forward search) goal (backward search). concept dependence relates
determining whether state member layer. What, anything,
causal graph dependencies?
conclusive answer question, contribute number insights
suggesting two concepts dependence much common. consider
issue theoretical practical perspective. theoretical side, introduce
simple formal framework assessing strength variable ordering heuristics sub-classes
planning. Applying framework causal graph based variable orders, show may
exponentially worse optimal orderings, even extremely simple planning tasks.
practical side, experiment wide range variable ordering schemes, several
ones based causal graph, range techniques adapted model checking
780

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

literature. get idea good ordering schemes are, grand scale things,
use upper lower delimiter. latter, use random variable orderings.
surpisingly, ordering schemes better random; surprisingly, are.
Indeed, Fast Downwards level heuristic (Helmert, 2006) turns much worse
average random BDD variable ordering.
upper delimiter, employ dynamic reordering techniques minimize BDD size
online, construction process. Compared static up-front variable ordering schemes,
reordering much better basis taking decisions, much time-consuming.
thus expected BDD size results much better. extent happens
experiments remarkable, however: Static orderings hardly ever even tiny bit better, whereas
advantage dynamic reordering easily frequently goes three orders magnitude.
successfully employed least one domain non-deterministic planning
(Cimatti, Pistore, Roveri, & Traverso, 2003), dynamic reordering usually prohibitively slow
cost-effective. Still, prowess reducing BDD size, combined pessimistic outlook
static ordering schemes, suggests may better alternative. initial experiment
indicates could, indeed, case: simple adaptive stopping criteria, running
dynamic reordering certain point, obtain better results static
ordering schemes.
remainder paper organized follows. Section 2 gives necessary background
planning framework use BDDs. Section 3 introduces theoretical framework
investigates properties causal graph based ordering schemes range well-known
planning sub-classes. Section 4 presents experiments regarding quality causal graph
based ordering schemes, Section 5 presents experiments adaptive stopping criteria
dynamic reordering. Section 6 concludes paper brief discussion outlook.
research note extension authors previous short conference paper (Kissmann
& Hoffmann, 2013). present paper contains comprehensive details regarding technical
background variable orderings implemented, includes full proofs. experiments
adaptive stopping criteria dynamic reordering, Section 5, new.

2. Background
BDD-based planning, argued e.g. Edelkamp Helmert (1999), important
small encoding given planning task. use finite-domain variable representation
basis investigation. finite-domain representation (FDR) planning task tuple
= hV, A, I, Gi, V set state variables v V associated
finite domain D(v). finite set actions pair hpre , eff partial
assignments V pre precondition eff effect action a. initial state
complete assignment V . goal G partial assignment V . V(pa), partial
assignment pa, denote variables v V pa(v) defined.
action applicable state iff pre s. resulting successor state s0
holds s0 (v) = eff (v) v V(eff ) s0 (v) = s(v) v V \ V(eff ). plan
sequence actions whose successive application starting initial state results state sg
G sg . plan optimal plan shorter length exists.
Binary decision diagrams (BDDs) introduced Bryant (1986) represent Boolean functions
. BDD directed acyclic graph one root two terminal nodes, 0-sink
781

fiK ISSMANN & H OFFMANN

x1

x1

x3

x2

x2

x3

x3

0

1

x2

x3

x3

0

(a) Full OBDD.

1

(b) Reduced OBDD.

Figure 1: Example BDDs function = ((x1 x2 ) x3 ). Dashed arrows denote low edges;
solid ones high edges.
1-sink. internal node corresponds binary variable p two successors, one following
high edge taken p true one following low edge taken p false. assignment
variables sink reached corresponds value function represented .
common practice, use reduced ordered BDDs. ordered BDD (OBDD)
BDD ordering binary variables path fixed. reduced OBDD
applies two reduction rules result canonical representation: (i) remove node identical
successor along high low edge; (ii) merge nodes variable
successor along high edge successor along low edge. Figure 1 illustrates
example BDDs function = ((x1 x2 ) x3 ) ordering hx1 , x2 , x3 i. Figure 1a
full OBDD without reduction. considering nodes x3 , note
rightmost one removed due rule (i), three merged due rule (ii).
Applying rules preceding layers well, end reduced OBDD Figure 1b.
consider BDD-based planning terms symbolic search (McMillan, 1993) implemented Gamer (Kissmann & Edelkamp, 2011). finite-domain variables V FDR task
encoded replacing v V binary counter (v) using dlog2 |D(v)|e bits. task
representable n bits need 2n BDD variables two sets, one set x representing current
state variables, another set x0 representing successor state variables. action represented transition relation BDD, Ta (x, x0 ), captures changes due application
frame, i.e., variables change:
Ta (x, x0 ) = pre (x) eff (x0 ) frame(V \ V(eff ), x, x0 )
W
frame(V 0 , x, x0 ) = vV 0 v(x) v(x0 ) modeling
W frame. possible create monolithic transition relation actions, i.e., (x, x0 ) = aA Ta (x, x0 ). However, typically
feasible terms memory. Thus, store transition relations actions separately
(Burch, Clarke, & Long, 1991).
order calculate successors set states S, represented current state variables,
use image function
image(S) =

_

x.(S(x) Ta (x, x0 ))[x0 x].

aA

782

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

conjunction makes sure applicable actions considered, sets corresponding
successor state variables. existential quantification removes current state variables.
operator [x0 x] stands swapping current successor state variables,
end successor states represented current state variables, i.e., new
current states. Finally, disjunction ensures successors based actions calculated.
case backward search, pre-image calculating predecessors set given
successor variables looks similar, successor state variables quantified instead
current state variables.
Using two functions, symbolic breadth-first search straightforward: Starting initial
state (or set goal states), iterate image (or pre-image), goal (or initial state)
reached. Storing entire set reached states ensure completeness. search,
layer L states subset states identical distance initial state (forward search)
goal (backward search) represented BDD characteristic function.
Based given variable ordering, size BDD, i.e., number nodes needed
represent corresponding function, differ exponentially, finding good orderings
crucial practice. size influence runtime (e.g., time memory
requirements conjunction two BDDs polynomial product sizes two
BDDs), smaller size important terms memory terms runtime. BDD
packages typically contain dynamic reordering algorithms, reduce BDD sizes based
current situation. However, previous work argued (Kissmann & Edelkamp, 2011),
experiments reconfirm, runtime overhead dynamic reordering prohibitive
planning. alternative use static variable ordering schemes instead. define
schemes functions mapping planning task non-empty set () variable orderings, i.e., orderings planning tasks finite-domain variables V . use set () here,
opposed single ordering, variable ordering schemes consider contain ambiguity, i.e., impose constraints final variable ordering opposed fixing
unique complete ordering.
first BDD created, set possible orderings determined pre-processing
step, actual ordering hv1 , . . . , vn = () chosen arbitrarily (i.e., consider
step here). calculated ordering defined set multi-valued variables. Thus,
get final BDD binary variable order replace finite-domain variable vi binary
counter (vi ). means BDD treats counters inseparable fixed blocks. (Note
bits counters represented level planning tasks ,
impossible make informed choice separation block.) addition
blocks store current successor state variables interleaved fashion (Burch, Clarke,
Long, McMillan, & Dill, 1994).
layer L ordering planning tasks finite-domain variables, ordered BDD
unique. denote size, i.e., number nodes, BDDSize(o, L). BDDSize (L) :=
mino BDDSize(o, L) denote size BDD optimal variable ordering. Finding
optimal ordering NP-hard (Bryant, 1986).
state art ordering scheme symbolic planning based causal graph CG
planning task (Knoblock, 1994; Domshlak & Dinitz, 2001). CG directed graph
nodes V arc (v, v 0 ) iff v 6= v 0 exists action (v, v 0 ) V(eff )
V(pre ) V(eff ). words, arc v v 0 appear effect
action v appears precondition action v 0 effect.
783

fiK ISSMANN & H OFFMANN

Gamers scheme,
denoted ga , maps set orderings = hv1 , . . . , vn minimize
P
expression (vi ,vj )CG (i j)2 . idea variables vi , vj adjacent CG
dependent brought close together ordering minimizing distance
|i j|. bears similarity minimal bandwidth variable ordering CSPs (Zabih,
1990), though maximum distances minimized, minimize sum.
practice, Gamer approximates ga limited amount local search space orderings,
finding optimal solution NP-hard (Kissmann & Edelkamp, 2011). this, starts several
searches random ordering, swaps two variables checks sum decreased. did,
search continues new ordering, otherwise stick old one. end,
generated ordering smallest sum used. original hope connection
two notions dependency. supported fact new ordering
resulted improved coverage used benchmark set compared used before.
Apart ga , consider scheme cg , defined acyclic CG .
maps set topological orderings nodes CG . consider theoretical
interest since straightforward way trust causal graph completely, i.e., take
dependencies derived causal graph order BDD variables accordingly.

3. Whats Causal Graph: Theory
pointed introduction, doubtful whether concept dependency
causal graph real relation concept dependency relevant BDD size.
frame terms classification guarantees offered, rather, guarantees offered,
ga cg restricted classes planning tasks.
first introduce theoretical framework, outline results cg ga .
3.1 Classification Framework
classify ordering schemes, relative given scalable family planning tasks, follows:
Definition 1 (Classification Ordering Schemes). Let F = {n } infinite family FDR
planning tasks parameterized n, size n bounded polynomial n. Let
{forward, backward} search direction. variable ordering scheme is:
(i) perfect F n F, d-layers L n , (n ),
BDDSize(o, L) = BDDSize (L).
(ii) safe F exists polynomial p s.t. n F, d-layers L n ,
(n ), BDDSize(o, L) p(BDDSize (L)).
(iii) viable F exists polynomial p s.t. n F d-layers L n ,
exists (n ) BDDSize(o, L) p(BDDSize (L)).
words, perfect guarantees deliver optimal orderings, safe guarantees
polynomial overhead, viable always delivers least one good ordering runs
risk super-polynomial overhead. viable, actively deceives planner,
sense variable orderings suggested super-polynomially bad task layer.
Note interpretation viability generous that, least one good ordering
must delivered, ordering may differ different search directions layers,
784

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

x

x1

x2

x3

x4

g1

x5

(a) Chains

g2

g4

g3

g5

(b) Forks

G chain
x1

x2

x3

x4

x5

G

G fork

G dag

G

G ifork

g

(d) Relations (arrows mean )

(c) Inverted Forks

Figure 2: Causal graph special cases relation.
disambiguation (n ) left job determining ordering actually good
one. One could define notion strictly, results negative anyhow stick
optimistic version.
extend classification arbitrary sub-classes C FDR (whose sizes still bounded
polynomial) worst case families F contained C: C contains least one F
perfect, perfect C; C contains least one F safe,
safe C; C contains least one F viable, viable C.
interested variable orderings derived causal graph, natural consider
sub-classes FDR characterized causal graphs. set directed graphs G, FDR(G)
denote class FDR planning tasks whose causal graphs elements G. investigate
widely considered causal graph special cases, namely:
Chains (G chain ), find order x1 , . . . , xn variables
arcs xi xi+1 1 n 1 (cf. Figure 2a).
Forks (G fork ), one variable x, set variables gi , arc x
gi (cf. Figure 2b).
Inverted forks (G ifork ), set variables xi , one variable g, arc
xi g (cf. Figure 2c).
Directed acyclic graphs (DAGs, G dag ).
simple limiting cases, consider causal graphs without arcs (G ), well arbitrary
causal graphs (G ). Figure 2d illustrates relations cases considered.
Bad cases inherited hierarchy Figure 2d: G G 0 , ordering scheme
classification within FDR(G 0 ) least bad FDR(G), simply culprit
worst-case (not-perfect/not-safe/not-viable) family F FDR planning tasks FDR(G)
contained FDR(G 0 ) well.
3.2 Classification Results
start investigation empty causal graphs, i.e., causal graphs arcs:
785

fiK ISSMANN & H OFFMANN

00

01

00

01

10

10

11

11

(a) DTG variable x.

(b) DTG variable y.

Figure 3: DTGs two variables planning task used proof Theorem 1.
Theorem 1. search directions, ordering scheme safe FDR(G ). ga cg
perfect.
Proof. causal graph arcs, variables move independently, i.e., action
may single variable precondition, variable effect.
forward/backward layer distance contains exactly states sum individual
distances (from variables initial value/to variables goal value) equals d. variable v
task, number vertices (more precisely, copies binary counter (v)) needed thus
bounded number possible individual-distance sums variables preceding v. Hence
BDD size polynomially bounded regardless variable ordering.
see ga cg perfect, consider following simple example. design
FDR task n uses 2 variables x y, domain size 4, represented values
00, 01, 10, 11. forward search, initially x = 00 = 00 holds. x variable
action setting 01 currently 00, another setting 10 00, two setting
11 01 10, respectively. variable action setting 01 currently
00, another setting 01 10 another setting 10 11. Thus, values
x variable distances 0, 1, 1, 2, respectively, initial value x,
variable distances 0, 1, 2, 3, respectively, ys initial value. Figure 3 illustrates
domain transition graphs (DTGs) variables x y. similar task distances
goal values defined backward search.
variable represented two BDD variables, x0 , x1 y0 , y1 . keep order
within x variables fixed, two possible orderings: x vice versa.
distance 1 initial (or goal) state, get BDDs illustrated Figure 4: Ordering
x results slightly larger BDD. Thus, ga cg , correspond possible
orderings, perfect, concludes proof.
Even though schemes ga cg constrain set possible orderings way,
Theorem 1 seen good case connection causal graphs BDD orderings:
Empty causal graphs entail ordering safe. connection doesnt seem carry
trivial case, though: sub-classes considered, space BDD orderings
contains exponentially bad ones. Indeed, true set BDD orderings,
786

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

y0

x0

x1

x1

y0

y0

x0

x0

y1

y1

x1

x1

0

1

0

1

y1

(a) x y.

(b) x.

Figure 4: BDDs showing orderings perfect proof Theorem 1. Solid arrows
represent high edges, dashed ones low edges.
x1

x1

y1

x3

x2

x2

x3

x3

x3

y1

y1

y1

y2

y2

x3

y1

y2

y3

y3

0

x2

0

1

(a) Good variable ordering: hx1 , y1 , x2 , y2 , x3 , y3

1

(b) Bad variable ordering: hx1 , x2 , x3 , y1 , y2 , y3

Figure 5: BDDs different variable orderings Q(, ) n = 3: (x1 y1 ) (x2 y2 )
(x3 y3 ). Solid arrows denote high edges, dashed ones low edges.
subsets delivered ga cg . classification schemes bad
almost considered cases, little bit hope chain causal graphs.
negative results employ Boolean functions quadratic form. variables
{x1 , y1 , . . . , xn , yn }, take form (x1 oplow y1 )ophi . . . ophi (xn oplow yn ), either ophi
{, } oplow = , vice versa. denote functions Q(ophi , oplow ).
functions, ordering hx1 , y1 , . . . , xn , yn (i.e., bringing pairs xi yi together) yields
BDD whose size polynomial n, ordering hx1 , . . . , xn , y1 , . . . , yn (i.e., splitting
variables two blocks, one x one variables) yields BDD exponential
size. (Wegener, 2000, proves Q(, ) depicted Figure 5; similar arguments apply
quadratic forms.)

787

fiK ISSMANN & H OFFMANN

g

x1

x1

y1

y1

x2

g

x2

0

g

y2

y2

x3

x3

y3

y3

1

1

0

(a) g front.

g

(b) g within pair.

Figure 6: BDDs representing g Q(, ) different positions g variable. Solid arrows
represent high edges, dashed ones low edges.
Theorem 2. search directions, ga cg safe FDR(G ifork ).
W
Proof. prove claim backward search, consider function Q(, ) = ni=1 (xi yi ).
design FDR task n uses 2n + 1 Boolean variables, {g, x1 , y1 , . . . , xn , yn } including
additional variable g goal requires true. n actions achieving g,
requires pair (xi yi ) true precondition. Clearly, Wn FDR(G ifork ). backward
layer distance 1 goal characterized g ni=1 (xi yi ).
optimal ordering Q(, ) consists pairs (xi , yi ) (yi , xi ). Adding g variable,
optimal ordering places either front (as depicted Figure 6a) end. cases
require exactly one node representing g variable. Placing g variable anywhere else requires
many nodes representing g nodes (different 0-sink) reached edges passing
layer. case, two g nodes g placed two pairs,
three nodes placed two nodes constituting pair (see Figure 6b latter case).
ordering following ga (n ) places g middle x variables arbitrary
order around it. ordering following cg (n ) places g end x variables
arbitrary order it. cases, x variables may placed variables, resulting
exponential overhead concludes proof backward search.
forward search, consider function Q(, ), construct n ,
variables {g, x1 , y1 , . . . , xn , yn } domains {x1 , y1 , . . . , xn , yn } ternary:
unknown, true (>), false (). x variables initially unknown, set either
true false currently unknown. n actions achieving g, exactly above.
states initial state distance 2n + 1 x W
variables either true false
states exactly satisfy g Q(, ) = g ni=1 (xi = >) (yi = >). causal
788

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

d1

x1

dx1

dy1

y1

dy2

y2

dyn

yn

d2

x2

dx2

d3

dn

xn

dxn

dn+1

Figure 7: DTG variable z used proof Theorem 3. dashed edges correspond
preconditions changes value corresponding variable.
graph remains unchanged, set possible orderings following ga (n ) cg (n ) remains
backward search well, orders result exponential overhead
concludes proof forward search.
Note that, proof construction shows orders possible ga cg
super-polynomially bad, possible orders good. Hence, claimed prove ga
cg safe FDR(G ifork ), might case ga cg viable FDR(G ifork ).
leave open question.
Theorem 3. search directions, ga cg safe FDR(G fork ).
V
Proof. search directions, use function Q(, ) = ni=1 (xi yi ),
FDR task n Boolean variables {x1 , y1 , . . . , xn , yn } plus additional variable z domain
{d1 , dx1 , dy1 , d2 , dx2 , dy2 , . . . , dn , dxn , dyn , dn+1 }. actions that, 1 n,
z move di either dxi dyi , di+1 (see Figure 7). action
preconditioned dxi achieves xi , action preconditioned dyi achieves yi . Initially, z = d1
xi , yi false. goal requires z = dn+1 xi , yi true. forward search,
states initial state distance 3n exactly z = dn+1 Q(, ) true,
backward search states goal state distance 3n exactly z = d1 Q(, )
true.
ordering following ga (n ) places z middle x variables arbitrarily
around it; ordering following cg (n ) places z beginning x variables
arbitrarily it. Thus, constraint variables {x1 , y1 , . . . , xn , yn }, placing
789

fiK ISSMANN & H OFFMANN

x1

x2

y1

x3

y2

y3

g

Figure 8: Causal graph planning task used proof Theorem 4.
x variables variables ordering compatible schemes, results
exponential overhead.
Again, proof shows ga cg safe, makes statement regarding viability.
Note task proof construction unsolvable. easy modify task
solvable without breaking proof argument forward search direction. investigate whether true backward search direction well. practice, proving
unsolvability traditionally popular objective planning, state space exhaustion
one traditional purposes BDDs deemed good for.
DAG causal graphs, prove cases orderings admitted ga
cg
super-polynomially bad:
Theorem 4. search directions, ga cg viable FDR(G dag ).
Proof. backward search claim, use combination chain causal graph
inverted fork illustrated Figure 8. design FDR task n uses 2n + 1 Boolean
variables, {g, x1 , y1 , . . . , xn , yn }, including variable g goal requires true.
n actions achieving g, requires pair (xi yi ) true precondition (this
part task proof Theorem 2). add actions ensuring two
schemes x variables placed variables (or vice versa). One action empty
precondition sets x1 true effect, another one requires xn true precondition
sets y1 true effect, rest xi1 (or yi1 ) precondition set xi (or yi )
true effect. states goal distance 1 thus characterized g Q(, ).
order induced ga places g middle, either places x variables increasing
order g variables increasing order g, places variables decreasing
order g x variables decreasing order g. cg induces order starting
x variables increasing order, followed variables increasing order, followed g.
Thus, cases, x variables placed separately variables, resulting exponential
overhead proves claim backward search direction.
forward search use approach proof Theorem 2, namely extend
domain x variables {true (>), false (), unknown}. x variables
initialized value unknown. n actions setting g true, requiring pair (xi yi )
true. additional actions follows. Two require x1 unknown set true
false, respectively. Two require xn true y1 unknown set y1 true false,
respectively. Two require xn false y1 unknown set y1 true false, respectively.
manner four actions xi yi (2 n), requiring xi1 (yi1 )
true respectively false, requiring xi (yi ) unknown, setting xi (yi ) true respectively
false. Thus, states
W initial state distance 2n + 1 characterized function
g Q(, ) = g ni=1 (xi = >) (yi = >). variable orders induced ga cg
backward search, resulting exponential overhead, concluding proof.
790

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

x1

y1

y2

x2

y3

x3

Figure 9: Causal graph planning task used proof Theorem 5.
x1

x1

y1

y1

x3

x2

y2

y2

y2

y1

y1

x2

x2

x3

x3

y1

x3

y1

y2

y3

y3

0

1

0

(a) Optimal ordering

x3

y1

y1

y2

y2

y3

y3

y1

y2

1

(b) Exponential ordering

W
L
Figure 10: BDDs representing 3i=1 yi 3i=1 (xi yi ), used proof Theorem 5. Solid
arrows represent high edges, dashed ones low edges.
immediately get (recall cg defined acyclic causal graphs):
Corollary 1. ga viable FDR(G ).
close investigation somewhat positive result chain causal graphs:
Theorem 5. search directions, ga cg perfect FDR(G chain ). exists
ordering scheme viable FDR(G chain ).
Proof. first part claim inherited FDR(G ), i.e., corollary Theorem 1.
second part claim, existence non-viableW
ordering scheme, consider first
backward search direction, using function Q(, ) = ni=1 (xi yi ). design FDR
task n uses 2n Boolean variables, {x1 , y1 , . . . , xn , yn }. goal requires variables
false. action without precondition set x1 true, actions preconditions requiring
yi1 false setting xi true, actions preconditioned xi true setting yi false.
causal graph depicted Figure 9. Clearly, n FDR(G chain ).
states distance 1 goal ones except oneLyi false,
n

single
true
Ln
Wn yi xi true well. characterized formula i=1 yi Q(, ) =
i=1 yi i=1 (xi yi ). easy see exclusive part formula change
relevant properties BDDs quadratic form, i.e., still orderings polynomial
orderings exponential number nodes, e.g., placing x variables
791

fiK ISSMANN & H OFFMANN

safe?
G chain
trivially
safe
G


viable
G dag

safe
G fork


viable
G

safe
G ifork

Figure 11: Overview classification results. hold ga cg , search
direction.

variables (see Figure 10 illustration). ordering scheme including latter orderings
viable.
forward search direction case, construct planning task x variables
ternary (unknown, true (>), false ()), unknown initially. value x1 set
freely; yi set true false xi true, set true xi false; xi+1
set freely yi set
V either true false. 2n steps, reach exactly
states characterized Q(, ) = ni=1 (xi = >) (yi = >). BDD representing Q(, )
exponential size if, e.g., x variables placed variables, ordering scheme
including orderings viable.
Note that, planning task families {n } described, ga cg force
xi yi variable ordered pairs, resulting BDDs minimal size (see Figure 10a).
sense, two planning task families constitute truly positive result: Within them,
ordering information causal graph keeps us making exponentially bad mistakes.
positive message would much stronger ga cg safe families tasks
chain causal graphs. remains open question whether so.
Figure 11 gives overview results. evidence speaks rather clearly strong
connection causal graph dependencies dependencies relevant BDD size. Note
causal graph underlying Theorem 4 non-viability FDR(G dag ) simple
form combining chain inverted fork, Theorem 2 non-safety FDR(G ifork )
relies planning tasks fall known syntactically identified tractable class optimal
planning (Katz & Domshlak, 2010). Note safe already quite bad practice,
incurring exponential risk unless clever way choosing ordering within ()
(which, moment, have).

4. Whats Causal Graph: Practice
shown poor worst-case performance causal graph based variable ordering schemes
theory, practice might another matter. assess latter, implemented comprehensive
set causal graph based variable ordering schemes, comprising 12 schemes total, ran
comparison practical good/bad delimiters. bad delimiter, used random
orderings. good delimiter, used off-the-shelf dynamic reordering algorithm
Gamers BDD package CUDD, based sifting (Rudell, 1993).
words order regarding sifting works. variable greatest number
nodes current BDD chosen. first moved towards end ordering,
792

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

towards beginning ordering, iteratively swapping position next variable
corresponding direction. positions tried, variable moved position
BDD size smallest. done, next variable chosen, variables
processed. better comparability ordering schemes, restrict algorithm
keep variables representing (v) together.
previously indicated, dynamic reordering consumes much runtime cost-effective.
present experiments, interested BDD size, give dynamic reordering ample runtime. Section 5, identify simple adaptive criteria stopping dynamic
reordering automatically search, taking advantage size reduction capacity without
suffering much runtime consumption.
ran benchmarks 2011 International Planning Competition (IPC11), used
Gamer base implementation planners, running one core Intel Xeon
X5690 CPU 3.47 GHz. Unless otherwise stated, used IPC11 settings, namely timeout
30 minutes memory limit 6 GB.
4.1 Ordering Schemes
ran six schemes based directly causal graph:
Gamer Gamers original ordering scheme, approximates ga .
GamerPre Gamer causal graph extended arcs pairs precondition
variables. idea capture dependency forward search,
backward search, i.e., inverting actions.
WGamer Gamer arcs weighted number relevant actions, i.e., number
actions inducing corresponding arcs.
WGamerPre GamerPre weighted arcs.
CGLevel Fast Downwards (Helmert, 2006) level heuristic, approximates cg . orders
variables strongly connected components and, within components, considers
weighted causal graph orders variables smallest incoming weight first. Similar
WGamer, weights correspond number actions induce arc.
CGSons another approximation cg . always selects variable v whose parents already selected; least one whose parents already selected; arbitrary
variable v exists.
Additionally, used six ordering schemes adopted model checking literature,
based structure called abstract syntax tree (AST) (e.g., Maisonneuve, 2009).
directed graph containing root node overall task subtrees actions. subtree
consists nodes representing subformulas specified action (i.e., subformulas
actions precondition effect). variables task leaves AST. leaves
merged, i.e., one node variable task. Edges point node
representing function corresponding subtrees.
construct AST based PDDL input. Consider following example actions, similar Floortile domain. predicates at(r, t), denoting tile robot r
793

fiK ISSMANN & H OFFMANN



a2

a1







at(r1 , t1 )



painted (t2 )

at(r2 , t3 )

Figure 12: Example AST.
currently painted (t) denoting whether tile already painted. two actions
a1 = paint(r1 , t1 , t2 ) precondition (at(r1 , t1 ) painted (t2 )) effect (painted (t2 )) denoting robot r1 paint tile t2 currently t1 t2 painted. Similarly,
action a2 = paint(r2 , t3 , t2 ) precondition (at(r2 , t3 )painted (t2 )) effect (painted (t2 ))
denotes robot r2 paint tile t2 currently t3 t2 painted.
Figure 12 illustrates corresponding AST. root actions A, one subtree
two actions a1 a2 . actions preconditions effects encoded
retain one copy variable leaves (here relevant painted (t2 )).
Using first authors names reference, additional ordering schemes following.
Butler (Butler, Ross, Kapur, & Mercer, 1991) extension approach Fujita, Fujisawa,
Kawato (1988). latter proposed perform depth-first search (DFS) AST,
starting root node, order variables order reached
first time. Butler et al. extended setting several roots (if remove overall
root retain subtrees various actions arrive exactly setting).
approach starts DFS action containing highest number variables. Within
tree advances similar manner: always continues subtree contains
highest number variables among subtrees current node. retrieved ordering
order variables reached first time.
Chung1 (Chung, Hajj, & Patel, 1993) two-step approach. first step assigns values
nodes AST. Starting leaves, assigning value 0, assigns
inner node maximum values assigned successors plus 1. second step
performs DFS starting root, guided values nodes, visiting
successors highest value first. order variables reached first
time chosen variable ordering.
Chung2 (Chung et al., 1993) determines shortest distance pair variables,
calculated considering edges AST undirected. Additionally, total
distances, i.e., sum minimal distances variables, stored variables. variable smallest total distance chosen first. next one one closest
794

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

last variable inserted ordering. case tie distance preceding
variables taken account.
Maisonneuve (Maisonneuve, 2009) greedy approach starting empty sequence.
step temporarily extends current sequence variable yet sequence.
variable, weight determined, number variables extended
sequence appear action, summed actions. variable removed
sequence next one added. weights calculated variable
highest weight appended sequence, next iteration starts, calculating new
weights remaining variables. end, last sequence contains variables
thus corresponds variable ordering.
Malik (Malik et al., 1988) assigns level value (the maximal level predecessors plus 1)
node within AST. root assigned value 0. variables ordered
according level values, highest values coming first.
Minato (Minato et al., 1990) calculates weights nodes AST. weight root
node action set 1, successors node w/m w nodes weight
number successors node. One variables highest weight
chosen first nodes removed (along ingoing edges recursively
nodes remaining successors). reduced graph weights recalculated
procedure continues finally variables ordering.
4.2 Bad Delimiter
get bad delimiter ran 5000 random orderings, ordering corresponds
one run IPC11 benchmark tasks, using random variable ordering instance.
make feasible used time-out one minute (our backward search implementation
viable short time-out, use forward search here). comparison
data, settings (1 minute time-out, forward search) used twelve static
ordering schemes. Initially ran ordering schemes random orderings tasks;
200 random runs removed tasks benchmark set solved least
previous (random static ordering) runs, retaining 85 tasks. Figure 13 shows coverage,
i.e., number solved planning tasks, x axis, fraction random orderings
coverage axis. coverage data ordering schemes shown vertical lines.
Malik CGLevel lie middle Gaussian distribution, respectively.
words, Malik bad as, CGLevel even worse than, average random ordering.
Matters bleak ten ordering schemes, close together lie clearly
Gaussian distribution. Compared best-of random orders, however,
ordering schemes appear rather humble. Consider Table 1. particular, consider nr
+ , giving
number instances solved ordering scheme random order, consider n+r
,
giving number instances solved scheme solved random order.
+r
Table 1 shows, nr
+ strictly smaller n three ordering schemes ,
strictly larger (by single task) one schemes (namely Butler). average nr
+
2.92 n+r

9.08.

795

fiK ISSMANN & H OFFMANN

Percentage Random Orderings

16

CGLevel
Malik
Maisonneuve+WGamerPre
Minato+WGamer
CGSons
Gamer+GamerPre
Chung1+Chung2
Butler

14
12
10
8
6
4
2
0
20

30

40

50
Coverage

60

70

80

Type

Butler

CGLevel

CGSons

Chung1

Chung2

Gamer

GamerPre

Maisonneuve

Malik

Minato

WGamer

WGamerPre

Best Scheme

Figure 13: Coverage random orders vs. ordering schemes. Schemes ordered top-to-bottom
worst best coverage. X +Y means schemes, X , result coverage.

nr
+
n+r

n+r
+
nr


3
2
77
3

1
26
53
5

2
4
75
4

4
4
75
2

2
2
77
4

5
6
73
1

5
6
73
1

3
11
68
3

0
22
57
6

4
8
71
2

3
7
72
3

3
11
68
3

6
1
78
0

Table 1: Differences solved instances 85 IPC11 tasks (1 minute timeout); r means
solved random ordering, +r least one random ordering, solved corresponding ordering scheme, + solved corresponding ordering scheme.
4.3 Good Delimiter
performed bidirectional blind search, i.e., competitive setup general. Figure 14
contains one data point every pair (I, ) IPC11 benchmark instance ordering scheme
solved (a) Gamer using dynamic reordering starting arbitrary variable
order (the one returned Gamers grounding process), (b) Gamer using ordering scheme
(without dynamic reordering). time-out 6 hours (a), 30 minutes (b). x-value
data point size largest BDD constructed (a), y-value size
largest BDD constructed (b). allowed much higher time-out dynamic reordering
reordering runtime effective: question asking merely
two methods yields smaller BDDs. Figure 14 shows dynamic reordering universally
much better this, giving us sizes three orders magnitude smaller
schemes. total 1911 instances (solved ordering scheme dynamic reordering),
1431 cases BDD sizes smaller factor 10 using dynamic reordering,
796

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

Peak Size Ordering Schemes

108
107
106
105
104
104

105
106
Peak Size Dynamic Reordering

107

108

Dynamic
Reordering

WGamerPre

WGamer

Minato

Malik

Maisonneuve

GamerPre

Gamer

Chung2

Chung1

CGSons

CGLevel

Butler

Figure 14: BDD size dynamic reordering vs. ordering schemes.

Domain
Barman
4
4
4
4
8
8
7
4
4
4
5
4
9(5)
Elevators 19 19 19 19 19 19 19 19 19 19 19 19
19(17)
Floortile
8
8
7
8
8
8
8
7
7
8
8
8
7(6)
14(12)
NoMystery 14 14 14 14 14 13 14 14 15 14 14 14
Openstacks 20 18 20 20 20 20 20 19 19 19 20 20
20(20)
PARC-Printer
6
6
5
6
5
6
6
6
5
6
6
7
8(7)
PegSol 17 17 17 17 17 18 18 17 17 17 18 18
18(17)
Scanalyzer
8
7
9
9
8
9
9
9
9
9
9
7
9(9)
Sokoban 17 18 18 17 19 19 19 18 18 18 19 19
19(13)
Tidybot 16
7 14 15 15
9 12 14
9 15 12
8
16(8)
Transport
8
9
9
7
8
8
8
9
7
9
7
7
10(7)
9 11 11 11 11 11 11 10 10 11 11
12(11)
VisitAll 11
Woodworking 16 13 10 14 16 16 16 12
8 16 15 16
19(16)
Total (260) 164 149 157 161 168 164 167 159 147 164 163 158 180(148)

Table 2: Coverage IPC11 tasks. dynamic reordering, numbers parentheses represent coverage 30 minute timeout.
406 cases smaller factor 10 100, 20 cases smaller
factor 100.
Table 2 shows coverage different schemes IPC11 tasks. make
similar observation one minute, forward search results, namely CGLevel
Malik clearly behind others. last column shows coverage Gamer using
dynamic reordering, provides two numbers, first coverage 6 hours timeout, second
coverage timeout schemes, i.e., 30 minutes. becomes clear
applying dynamic reordering entire search time feasible practice limiting
runtime.
797

fi600
500
400
300
200
100
0

Total Runtime
Reordering Time
Transition Relation Creation

0

2

4

6
8
Reorderings

Time (s)

Time (s)

K ISSMANN & H OFFMANN

10

12

1400
1200
1000
800
600
400
200
0

Total Runtime
Reordering Time
Transition Relation Creation

0

(a) VisitAll, task 011

2

4

6
8 10
Reorderings

12

14

16

(b) PegSol, task 015

Figure 15: Total runtime time spent reordering limited number reordering steps two
example IPC11 tasks. reorderings vertical line performed transition
relation creation.

5. Limited Dynamic Reordering
Given much memory-efficient behavior dynamic reordering, possible approach
run dynamic reordering limited time only, hoping get ordering good enough
remainder search. Reordering automatically started number allocated
BDD nodes reaches certain threshold (by default, first threshold 4000 nodes),
dynamically adapted reordering (by default, next threshold set 2 times number
nodes reordering). simple way control dynamic reordering limit number
reordering steps, turn dynamic reordering desired number reorderings
performed.
different reordering limits, total runtime task often looks similar situation
depicted Figure 15a. reorderings takes long time solve task due
bad initial ordering. Also, first reorderings sometimes hurt, performed
beginning construction transition relation, enough information good
orderings available. However, many reorderings solving takes long time due
immense overhead reordering time, grows exponentially step.
important different behavioral pattern depicted Figure 15b: domains,
PegSol Sokoban, minimum curve beginning (without reordering),
total runtime increases afterward (mainly based increase reordering time).
explanation behavior might initial ordering already pretty good,
dynamic reordering cannot improve much overhead incurred vain. often
happens easier tasks domain, learning good setting based simpler tasks
seems impossible.
Attempting exploit observations design adaptive stopping criteria, geared finding
good point stopping dynamic reordering, given available observations (e.g., number
BDD nodes before/after reordering, reordering times, current total runtimes), experimented
following approaches.
First, noticed early reordering time increases step step small factor,
later factor increases. preliminary runs saw often area smallest
runtime coincides situation increase reordering time reaches threshold,
often 1.25 1.75 (see, e.g., Figure 16a compare runtime minimum
Figure 15a planning task). call factor criterion.
798

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

2.5

Factor
Percentage

Factor

2
1.5
1
0.5
0
0

2

4

6
8
10
12
Reorderings
(a) Factor time last reordering
previous one.

70
60
50
40
30
20
10
0

Percentage

0

2

4

6
8
10
12
Reorderings
(b) Percentage time last reordering
total runtime far.

Figure 16: Factor percentage criterion limited number reordering steps task 011
IPC11 VisitAll domain.
Second, another observation preliminary runs percentage time spent
last reordering step total current runtime often follows U-like curve, minimum
curve often lies close number reorderings total runtime minimum (see,
e.g., Figure 16b compare runtime minimum Figure 15a task). employ
percentage criterion, stops reordering (possibly local) minimum reached,
i.e., compare percentage current step previous step; current
one greater stop reordering.
Finally, simple combination criteria stop reordering soon one tells
us so.
evaluate adaptive stopping criteria, ran tasks IPC11 domains different limits number reorderings, ranging 0 20.1 Based runs calculated
results would achieve adaptive stopping criteria. See Table 3. best possible
coverage, i.e., number tasks solved least one setting limited number reorderings,
175, without reordering found 167 solutions. adaptive stopping criteria yield
coverage 158 171. Performance reasonable factor criterion, quite bad
percentage criterion combination criteria. Recall percentage criterion aims stopping reordering incurring prohibitive overhead. Indeed, criterion,
reordering often stopped earlier factor criterion. cases detrimental,
particularly Woodworking domain strategy happens fall dramatic local
peak total-runtime curve, resulting 9 problem instances longer solved.
As, several cases, dynamic reordering transition relation creation counterproductive, ran delayed reordering, dynamic reordering started BDDs
transition relation created. results Table 4. case without reordering
unchanged respect Table 3. best possible result slightly worse before,
coverage 174. adaptive stopping criteria, picture changes substantially: contrast
Table 3, percentage criterion excels, delivering coverage 1 short best possible.
Regarding factor criteria, overly small large factors bad best behavior (2 short
best possible) obtained middle.
1. cases highest number reorderings could observe clearly 20. Either planner ran
time memory, finished last reorderings could performed. cases used GamerPre
initial ordering, turned among best preliminary set experiments.

799

fiK ISSMANN & H OFFMANN

Domain
Barman
Elevators
Floortile
NoMystery
Openstacks
PARC-Printer
PegSol
Scanalyzer
Sokoban
Tidybot
Transport
VisitAll
Woodworking
Total


reord
7
19
8
14
20
6
18
9
19
12
8
11
16
167

best
possible
8
19
8
16
20
7
18
9
19
14
9
12
16
175

1.25
8
19
7
14
20
6
17
9
17
14
9
11
10
161

factor criterion
1.5 1.75 2.0
8
8
8
19
19
19
8
8
8
14
14
14
20
20
20
6
7
7
17
17
18
9
9
9
17
17
17
14
14
14
9
9
9
12
12
12
15
16
16
168 170 171

percentage
criterion
8
19
8
14
20
6
17
9
17
13
9
11
7
158

1.25
8
19
7
14
20
6
17
9
17
13
9
11
9
159

criteria
1.5 1.75
8
8
19
19
8
8
14
14
20
20
6
6
17
17
9
9
17
17
13
13
9
9
11
11
7
7
158 158

2.0
8
19
8
14
20
6
17
9
17
13
9
11
7
158

Table 3: Coverage results different stopping criteria. Immediate reordering.

Domain
Barman
Elevators
Floortile
NoMystery
Openstacks
PARC-Printer
PegSol
Scanalyzer
Sokoban
Tidybot
Transport
VisitAll
Woodworking
Total


reord
7
19
8
14
20
6
18
9
19
12
8
11
16
167

best
possible
8
19
8
16
20
7
18
9
19
13
9
12
16
174

1.25
8
19
7
16
20
6
17
9
19
13
9
12
10
165

factor criterion
1.5 1.75 2.0
8
8
7
19
19
19
8
8
8
16
14
14
20
20
20
7
7
6
17
17
17
9
9
9
19
19
19
13
13
13
9
9
9
12
12
12
15
16
16
172 171 169

percentage
criterion
8
19
8
16
20
7
17
9
19
13
9
12
16
173

1.25
8
19
7
16
20
6
17
9
19
13
9
12
10
165

criteria
1.5 1.75
8
8
19
19
8
8
16
16
20
20
7
7
17
17
9
9
19
19
13
13
9
9
12
12
15
16
172 173

2.0
8
19
8
16
20
7
17
9
19
13
9
12
16
173

Table 4: Coverage results different stopping criteria. Delayed reordering, i.e., reordering started
creation transition relation BDDs.
shed light observations, Figure 17 shows coverage function
different factor values, case immediate reordering (Figure 17a) delayed
reordering (Figure 17b). Figure 17a, see percentage criterion stops reordering
early. Without it, coverage resulting stopping reordering based solely factor criterion
get high 173. However, ascend coverage actually starts percentage
criterion stops reordering, thus cutting many solutions. Figure 17b, factor 1.6
curves identical, mainly increasing increasing factor. that, combination
criterion rises another little bit, factor criterion alone drops substantially. combined
criterion avoids drop because, point (here, factor roughly 2.0), percentage
criterion stops reordering least early factor criterion.
800

fi180
175
170
165
160
155
150

Factor

Coverage

Coverage

BDD RDERING H EURISTICS C LASSICAL P LANNING

0

0.5

1

1.5
2
Factor
(a) Immediate reordering.

2.5

3

180
175
170
165
160
155
150

Factor


0

0.5

1

1.5
2
Factor
(b) Delayed reordering.

2.5

3

Figure 17: Coverage function factor, factor criterion alone, combination
percentage criterion (denoted Both).

6. Conclusion
tempting equate variable dependencies BDD-based symbolic search
identified causal graphs, previous research done unquestioningly. Looking little
closely issue, shown causal graph based variable orderings exponentially bad
even severely restricted sub-classes planning. Empirically, Fast Downwards level heuristic
worse random, ordering schemes lag far behind off-the-shelf reordering.
One may wonder meaning theoretical results: could static ordering
scheme incur exponential overhead worst case? agree view principle,
expect happen planning tasks restricted tractable domainindependent optimal planning. remains seen extent classification framework
suitable characterize properties ordering schemes and/or planning fragments.
impression point static ordering schemes limited hopeless.
Prior actually building BDDs, appears impossible extract reliable information
form take. way forward, then, use dynamic reordering techniques
targeted manner. initial experiments direction meet immediate
breakthrough, certainly show promise, especially considering primitive nature
method stopping criteria employed. Promising future directions include flexible
on/off strategies dynamic reordering, machine learning deciding toggle switch,
planning-specific reordering techniques exploiting particular structure BDDs hand.

Acknowledgments
thank anonymous reviewers ICAPS 2013 short version previous version
article, whose comments helped tremendously improve paper.

References
Brafman, R., & Domshlak, C. (2003). Structure complexity planning unary operators.
Journal Artificial Intelligence Research, 18, 315349.
Bryant, R. E. (1986). Graph-based algorithms boolean function manipulation. IEEE Transactions Computers, 35(8), 677691.
801

fiK ISSMANN & H OFFMANN

Burch, J. R., Clarke, E. M., & Long, D. E. (1991). Symbolic model checking partitioned
transition relations. Halaas, A., & Denyer, P. B. (Eds.), Proceedings International
Conference Large Scale Integration (VLSI-91), Vol. A-1 IFIP Transactions, pp.
4958, Edinburgh, Scotland. North-Holland.
Burch, J. R., Clarke, E. M., Long, D. E., McMillan, K. L., & Dill, D. L. (1994). Symbolic model
checking sequential circuit verification. IEEE Transactions Computer-Aided Design
Integrated Circuits Systems, 13(4), 401424.
Butler, K. M., Ross, D. E., Kapur, R., & Mercer, M. R. (1991). Heuristics compute variable
orderings efficient manipulation ordered binary decision diagrams. Proceedings
28th Conference Design Automation (DAC-91), pp. 417420, San Francisco, CA,
USA. ACM.
Chen, H., & Gimenez, O. (2010). Causal graphs structurally restricted planning. Journal
Computer System Sciences, 76(7), 579592.
Chung, P.-Y., Hajj, I. N., & Patel, J. H. (1993). Efficient variable ordering heuristics shared
ROBDD. Proceedings 1993 IEEE International Symposium Circuits Systems
(ISCAS-93), pp. 16901693, Chicago, IL, USA. IEEE.
Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2003). Weak, strong, strong cyclic planning
via symbolic model checking. Artificial Intelligence, 147(12), 3584.
Darwiche, A. (2011). SDD: new canonical representation propositional knowledge bases.
Walsh, T. (Ed.), Proceedings 22nd International Joint Conference Artificial Intelligence (IJCAI11), pp. 819826. AAAI Press/IJCAI.
Dechter, R., & Meiri, I. (1989). Experimental evaluation preprocessing techniques constraint
satisfaction problems. Sridharan, N. S. (Ed.), Proceedings 11th International Joint
Conference Artificial Intelligence (IJCAI-89), pp. 271277, Detroit, MI. Morgan Kaufmann.
Domshlak, C., & Dinitz, Y. (2001). Multi-agent offline coordination: Structure complexity.
Cesta, A., & Borrajo, D. (Eds.), Recent Advances AI Planning. 6th European Conference
Planning (ECP-01), Lecture Notes Artificial Intelligence, pp. 3443, Toledo, Spain.
Springer-Verlag.
Edelkamp, S., & Helmert, M. (1999). Exhibiting knowledge planning problems minimize
state encoding length. Biundo, S., & Fox, M. (Eds.), Recent Advances AI Planning.
5th European Conference Planning (ECP99), Lecture Notes Artificial Intelligence, pp.
135147, Durham, UK. Springer-Verlag.
Fan, G., Muller, M., & Holte, R. (2014). Non-linear merging strategies merge-and-shrink based
variable interactions. Edelkamp, S., & Bartak, R. (Eds.), Proceedings 7th Annual
Symposium Combinatorial Search (SOCS14). AAAI Press.
Freuder, E. C. (1982). sufficient condition backtrack-free search. Journal Association
Computing Machinery, 29(1), 2432.
Fujita, M., Fujisawa, H., & Kawato, N. (1988). Evaluation improvements boolean comparison method based binary decision diagrams. Proceedings 1988 International
Conference Computer-Aided Design (ICCAD-98), pp. 25. IEEE Computer Society Press.
802

fiBDD RDERING H EURISTICS C LASSICAL P LANNING

Gimenez, O., & Jonsson, A. (2008). complexity planning problems simple causal
graphs. Journal Artificial Intelligence Research, 31, 319351.
Helmert, M. (2004). planning heuristic based causal graph analysis. Koenig, S., Zilberstein,
S., & Koehler, J. (Eds.), Proceedings 14th International Conference Automated
Planning Scheduling (ICAPS04), pp. 161170, Whistler, Canada. Morgan Kaufmann.
Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence Research, 26, 191246.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics optimal sequential planning. Boddy, M., Fox, M., & Thiebaux, S. (Eds.), Proceedings 17th
International Conference Automated Planning Scheduling (ICAPS07), pp. 176183,
Providence, Rhode Island, USA. Morgan Kaufmann.
Helmert, M., Haslum, P., Hoffmann, J., & Nissim, R. (2014). Merge & shrink abstraction: method
generating lower bounds factored state spaces. Journal Association Computing Machinery, 61(3).
Hoffmann, J. (2011a). Analyzing search topology without running search: connection
causal graphs h+ . Journal Artificial Intelligence Research, 41, 155229.
Hoffmann, J. (2011b). ignoring delete lists works, part II: Causal graphs. Bacchus, F.,
Domshlak, C., Edelkamp, S., & Helmert, M. (Eds.), Proceedings 21st International
Conference Automated Planning Scheduling (ICAPS11), pp. 98105. AAAI Press.
Jonsson, P., & Backstrom, C. (1995). Incremental planning. European Workshop Planning.
Katz, M., & Domshlak, C. (2008). New islands tractability cost-optimal planning. Journal
Artificial Intelligence Research, 32, 203288.
Katz, M., & Domshlak, C. (2010). Implicit abstraction heuristics. Journal Artificial Intelligence
Research, 39, 51126.
Kissmann, P., & Edelkamp, S. (2011). Improving cost-optimal domain-independent symbolic planning. Burgard, W., & Roth, D. (Eds.), Proceedings 25th National Conference
American Association Artificial Intelligence (AAAI-11), pp. 992997, San Francisco, CA,
USA. AAAI Press.
Kissmann, P., & Hoffmann, J. (2013). Whats BDD? causal graphs variable orders planning. Borrajo, D., Fratini, S., Kambhampati, S., & Oddi, A. (Eds.), Proceedings
23rd International Conference Automated Planning Scheduling (ICAPS13), pp.
327331, Rome, Italy. AAAI Press.
Knoblock, C. (1994). Automatically generating abstractions planning. Artificial Intelligence,
68(2), 243302.
Maisonneuve, V. (2009). Automatic heuristic-based generation MTBDD variable orderings
PRISM models. Internship report, Oxford University Computing Laboratory.
Malik, S., Wang, A., Brayton, R., & Sangiovanni-Vincentelli, A. (1988). Logic verification using
binary decision diagrams logic synthesis environment. Proceedings 1988 International Conference Computer-Aided Design (ICCAD-98), pp. 69. IEEE Computer
Society Press.
803

fiK ISSMANN & H OFFMANN

McMillan, K. L. (1993). Symbolic Model Checking. Kluwer Academic Publishers.
Minato, S., Ishiura, N., & Yajima, S. (1990). Shared binary decision diagram attributed edges
efficient boolean function manipulation. Proceedings 27th ACM/IEEE Design
Automation Conference (DAC-90), pp. 5257, Orlando, FL, USA. IEEE Computer Society
Press.
Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering
efficient SAT solver. Proceedings 38th Conference Design Automation (DAC01), Las Vegas, Nevada, USA. IEEE Computer Society.
Rintanen, J. (2012). Planning satisfiability: Heuristics. Artificial Intelligence, 193, 4586.
Rudell, R. (1993). Dynamic variable ordering ordered binary decision diagrams. Lightner,
M. R., & Jess, J. A. G. (Eds.), Proceedings 1993 IEEE/ACM International Conference
Computer-Aided Design (ICCAD-93), pp. 4247, Santa Clara, CA, USA. IEEE Computer
Society.
Sievers, S., Wehrle, M., & Helmert, M. (2014). Generalized label reduction merge-and-shrink
heuristics. Proceedings 28th AAAI Conference Artificial Intelligence (AAAI14),
Quebec City, Quebec, Canada. AAAI Press.
Wegener, I. (2000). Branching Programs Binary Decision Diagrams. SIAM.
Williams, B. C., & Nayak, P. P. (1997). reactive planner model-based executive. Pollack,
M. (Ed.), Proceedings 15th International Joint Conference Artificial Intelligence
(IJCAI-97), pp. 11781185, Nagoya, Japan. Morgan Kaufmann.
Zabih, R. (1990). applications graph bandwidth constraint satisfaction problems.
Proceedings 8th National Conference American Association Artificial Intelligence (AAAI-90), pp. 4651, Boston, MA. MIT Press.

804


