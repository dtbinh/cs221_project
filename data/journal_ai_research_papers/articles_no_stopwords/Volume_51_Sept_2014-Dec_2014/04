journal artificial intelligence

submitted published

note
bdd ordering heuristics classical
peter kissmann
jorg hoffmann

kissmann cs uni saarland de
hoffmann cs uni saarland de

saarland university saarbrucken germany

abstract
symbolic search binary decision diagrams bdds often save large amounts memory due concise representation state sets decisive factor methods success
chosen variable ordering generally speaking plausible dependent variables
brought close together order reduce bdd sizes variable dependencies typically captured means causal graphs preceding work taken basis
finding bdd variable orderings starting observation two concepts dependency actually quite different introduce framework assessing strength variable
ordering heuristics sub classes turns even extremely simple
tasks causal graph variable orders may exponentially worse optimal
experimental wide range variable ordering variants corroborate theoretical
findings furthermore dynamic reordering much effective reducing bdd
size cost effective due prohibitive runtime overhead exhibit potential
middle ground techniques running dynamic reordering simple stopping criteria hold

introduction
finding good variable orderings important task many areas artificial intelligence
constraint satisfaction csps sat heuristic search approaches
especially applying symbolic search many cases efficient ordering determined
evaluating graphical representation underlying csps example
constraint graph used determine variable ordering backtracking approaches
typical approaches take minimum width freuder maximum degree maximum cardinality dechter meiri nodes constraint graph account alternative
considers bandwidth constraint graph given ordering maximal distance ordering two nodes adjacent graph idea
ordering minimizes bandwidth zabih
sat widely used determine variable order conflict driven clause learning
cdcl variable state independent decaying sum vsids moskewicz madigan zhao zhang
malik weights propositional variables e often
variable occurs clauses recently rintanen noted applying sat solvers
tasks different ordering might efficient giving better coverage typical
benchmarks international competition ipc ordering takes structure
tasks account trying support sub goals early possible
variable dependencies typically represented causal graph e g knoblock
jonsson backstrom brafman domshlak helmert capturing variable
dependencies terms co occurences action descriptions kind graph turned
c

ai access foundation rights reserved

fik issmann h offmann

useful great variety purposes including decomposition knoblock
system design williams nayak complexity analysis e g jonsson backstrom
domshlak dinitz brafman domshlak katz domshlak gimenez
jonsson chen gimenez derivation heuristic functions helmert
search topology analysis hoffmann b purposes causal graphs
relevant application derivation variable orderings done bdds
return detail well merge shrink heuristics helmert haslum
hoffmann helmert haslum hoffmann nissim merge shrink complete
variable ordering corresponds linear merging strategy order variables merged
global abstraction recent extension non linear merging strategies sievers wehrle
helmert order merges instead given tree merge tree bears
similarity concept vtrees used generalization variable orderings
sentential decision diagram sdds darwiche fan muller holte shown
efficient merge trees determined means causal graph use mincuts causal graph putting two resulting sets variables two different branches
merge tree recursively continue subgraphs
concerned symbolic search binary decision diagrams bdds
bryant optimal variable ordering refers order variables
queried within bdds key ingredient practical efficiency
much work invested finding good variable orderings model
checking symbolic search originated mcmillan many different variable ordering
schemes proposed past e g malik wang brayton sangiovanni vincentelli
minato ishiura yajima many evaluation
graphical representation often bringing dependent variables close together
smaller bdds straightforwardly applied defining variable
dependencies via causal graph exactly gamer state art symbolic search
planner determines variable ordering kissmann edelkamp
starting point investigation feeling discomfort double use word
dependency causal graphs dependency means corresponding
variables appear least one common action changing value one variable may require
changing variable well bdds hand represent boolean functions
many assignments subset p variables immediately determine truth value
independently value variables variables p grouped closely
together typically represents layer states sharing distance initial
state forward search goal backward search concept dependence relates
determining whether state member layer anything
causal graph dependencies
conclusive answer question contribute number insights
suggesting two concepts dependence much common consider
issue theoretical practical perspective theoretical side introduce
simple formal framework assessing strength variable ordering heuristics sub classes
applying framework causal graph variable orders may
exponentially worse optimal orderings even extremely simple tasks
practical side experiment wide range variable ordering schemes several
ones causal graph range techniques adapted model checking


fibdd rdering h euristics c lassical p lanning

literature get idea good ordering schemes grand scale things
use upper lower delimiter latter use random variable orderings
surpisingly ordering schemes better random surprisingly
indeed fast downwards level heuristic helmert turns much worse
average random bdd variable ordering
upper delimiter employ dynamic reordering techniques minimize bdd size
online construction process compared static front variable ordering schemes
reordering much better basis taking decisions much time consuming
thus expected bdd size much better extent happens
experiments remarkable however static orderings hardly ever even tiny bit better whereas
advantage dynamic reordering easily frequently goes three orders magnitude
successfully employed least one domain non deterministic
cimatti pistore roveri traverso dynamic reordering usually prohibitively slow
cost effective still prowess reducing bdd size combined pessimistic outlook
static ordering schemes suggests may better alternative initial experiment
indicates could indeed case simple adaptive stopping criteria running
dynamic reordering certain point obtain better static
ordering schemes
remainder organized follows section gives necessary background
framework use bdds section introduces theoretical framework
investigates properties causal graph ordering schemes range well known
sub classes section presents experiments regarding quality causal graph
ordering schemes section presents experiments adaptive stopping criteria
dynamic reordering section concludes brief discussion outlook
note extension authors previous short conference kissmann
hoffmann present contains comprehensive details regarding technical
background variable orderings implemented includes full proofs experiments
adaptive stopping criteria dynamic reordering section

background
bdd argued e g edelkamp helmert important
small encoding given task use finite domain variable representation
basis investigation finite domain representation fdr task tuple
hv gi v set state variables v v associated
finite domain v finite set actions pair hpre eff partial
assignments v pre precondition eff effect action initial state
complete assignment v goal g partial assignment v v pa partial
assignment pa denote variables v v pa v defined
action applicable state iff pre resulting successor state
holds v eff v v v eff v v v v v eff plan
sequence actions whose successive application starting initial state state sg
g sg plan optimal plan shorter length exists
binary decision diagrams bdds introduced bryant represent boolean functions
bdd directed acyclic graph one root two terminal nodes sink


fik issmann h offmann

x

x

x

x

x

x

x





x

x

x



full obdd



b reduced obdd

figure example bdds function x x x dashed arrows denote low edges
solid ones high edges
sink internal node corresponds binary variable p two successors one following
high edge taken p true one following low edge taken p false assignment
variables sink reached corresponds value function represented
common practice use reduced ordered bdds ordered bdd obdd
bdd ordering binary variables path fixed reduced obdd
applies two reduction rules canonical representation remove node identical
successor along high low edge ii merge nodes variable
successor along high edge successor along low edge figure illustrates
example bdds function x x x ordering hx x x figure
full obdd without reduction considering nodes x note
rightmost one removed due rule three merged due rule ii
applying rules preceding layers well end reduced obdd figure b
consider bdd terms symbolic search mcmillan implemented gamer kissmann edelkamp finite domain variables v fdr task
encoded replacing v v binary counter v dlog v e bits task
representable n bits need n bdd variables two sets one set x representing current
state variables another set x representing successor state variables action represented transition relation bdd ta x x captures changes due application
frame e variables change
ta x x pre x eff x frame v v eff x x
w
frame v x x vv v x v x modeling
w frame possible create monolithic transition relation actions e x x aa ta x x however typically
feasible terms memory thus store transition relations actions separately
burch clarke long
order calculate successors set states represented current state variables
use image function
image



x x ta x x x x

aa



fibdd rdering h euristics c lassical p lanning

conjunction makes sure applicable actions considered sets corresponding
successor state variables existential quantification removes current state variables
operator x x stands swapping current successor state variables
end successor states represented current state variables e
current states finally disjunction ensures successors actions calculated
case backward search pre image calculating predecessors set given
successor variables looks similar successor state variables quantified instead
current state variables
two functions symbolic breadth first search straightforward starting initial
state set goal states iterate image pre image goal initial state
reached storing entire set reached states ensure completeness search
layer l states subset states identical distance initial state forward search
goal backward search represented bdd characteristic function
given variable ordering size bdd e number nodes needed
represent corresponding function differ exponentially finding good orderings
crucial practice size influence runtime e g time memory
requirements conjunction two bdds polynomial product sizes two
bdds smaller size important terms memory terms runtime bdd
packages typically contain dynamic reordering reduce bdd sizes
current situation however previous work argued kissmann edelkamp
experiments reconfirm runtime overhead dynamic reordering prohibitive
alternative use static variable ordering schemes instead define
schemes functions mapping task non empty set variable orderings e orderings tasks finite domain variables v use set
opposed single ordering variable ordering schemes consider contain ambiguity e impose constraints final variable ordering opposed fixing
unique complete ordering
first bdd created set possible orderings determined pre processing
step actual ordering hv vn chosen arbitrarily e consider
step calculated ordering defined set multi valued variables thus
get final bdd binary variable order replace finite domain variable vi binary
counter vi means bdd treats counters inseparable fixed blocks note
bits counters represented level tasks
impossible make informed choice separation block addition
blocks store current successor state variables interleaved fashion burch clarke
long mcmillan dill
layer l ordering tasks finite domain variables ordered bdd
unique denote size e number nodes bddsize l bddsize l
mino bddsize l denote size bdd optimal variable ordering finding
optimal ordering np hard bryant
state art ordering scheme symbolic causal graph cg
task knoblock domshlak dinitz cg directed graph
nodes v arc v v iff v v exists action v v v eff
v pre v eff words arc v v appear effect
action v appears precondition action v effect


fik issmann h offmann

gamers scheme
denoted ga maps set orderings hv vn minimize
p
expression vi vj cg j idea variables vi vj adjacent cg
dependent brought close together ordering minimizing distance
j bears similarity minimal bandwidth variable ordering csps zabih
though maximum distances minimized minimize sum
practice gamer approximates ga limited amount local search space orderings
finding optimal solution np hard kissmann edelkamp starts several
searches random ordering swaps two variables checks sum decreased
search continues ordering otherwise stick old one end
generated ordering smallest sum used original hope connection
two notions dependency supported fact ordering
resulted improved coverage used benchmark set compared used
apart ga consider scheme cg defined acyclic cg
maps set topological orderings nodes cg consider theoretical
interest since straightforward way trust causal graph completely e take
dependencies derived causal graph order bdd variables accordingly

whats causal graph theory
pointed introduction doubtful whether concept dependency
causal graph real relation concept dependency relevant bdd size
frame terms classification guarantees offered rather guarantees offered
ga cg restricted classes tasks
first introduce theoretical framework outline cg ga
classification framework
classify ordering schemes relative given scalable family tasks follows
definition classification ordering schemes let f n infinite family fdr
tasks parameterized n size n bounded polynomial n let
forward backward search direction variable ordering scheme
perfect f n f layers l n n
bddsize l bddsize l
ii safe f exists polynomial p n f layers l n
n bddsize l p bddsize l
iii viable f exists polynomial p n f layers l n
exists n bddsize l p bddsize l
words perfect guarantees deliver optimal orderings safe guarantees
polynomial overhead viable delivers least one good ordering runs
risk super polynomial overhead viable actively deceives planner
sense variable orderings suggested super polynomially bad task layer
note interpretation viability generous least one good ordering
must delivered ordering may differ different search directions layers


fibdd rdering h euristics c lassical p lanning

x

x

x

x

x

g

x

chains

g

g

g

g

b forks

g chain
x

x

x

x

x

g

g fork

g dag

g

g ifork

g

relations arrows mean

c inverted forks

figure causal graph special cases relation
disambiguation n left job determining ordering actually good
one one could define notion strictly negative anyhow stick
optimistic version
extend classification arbitrary sub classes c fdr whose sizes still bounded
polynomial worst case families f contained c c contains least one f
perfect perfect c c contains least one f safe
safe c c contains least one f viable viable c
interested variable orderings derived causal graph natural consider
sub classes fdr characterized causal graphs set directed graphs g fdr g
denote class fdr tasks whose causal graphs elements g investigate
widely considered causal graph special cases namely
chains g chain order x xn variables
arcs xi xi n cf figure
forks g fork one variable x set variables gi arc x
gi cf figure b
inverted forks g ifork set variables xi one variable g arc
xi g cf figure c
directed acyclic graphs dags g dag
simple limiting cases consider causal graphs without arcs g well arbitrary
causal graphs g figure illustrates relations cases considered
bad cases inherited hierarchy figure g g ordering scheme
classification within fdr g least bad fdr g simply culprit
worst case perfect safe viable family f fdr tasks fdr g
contained fdr g well
classification
start investigation empty causal graphs e causal graphs arcs


fik issmann h offmann

















dtg variable x

b dtg variable

figure dtgs two variables task used proof theorem
theorem search directions ordering scheme safe fdr g ga cg
perfect
proof causal graph arcs variables move independently e action
may single variable precondition variable effect
forward backward layer distance contains exactly states sum individual
distances variables initial value variables goal value equals variable v
task number vertices precisely copies binary counter v needed thus
bounded number possible individual distance sums variables preceding v hence
bdd size polynomially bounded regardless variable ordering
see ga cg perfect consider following simple example design
fdr task n uses variables x domain size represented values
forward search initially x holds x variable
action setting currently another setting two setting
respectively variable action setting currently
another setting another setting thus values
x variable distances respectively initial value x
variable distances respectively ys initial value figure illustrates
domain transition graphs dtgs variables x similar task distances
goal values defined backward search
variable represented two bdd variables x x keep order
within x variables fixed two possible orderings x vice versa
distance initial goal state get bdds illustrated figure ordering
x slightly larger bdd thus ga cg correspond possible
orderings perfect concludes proof
even though schemes ga cg constrain set possible orderings way
theorem seen good case connection causal graphs bdd orderings
empty causal graphs entail ordering safe connection doesnt seem carry
trivial case though sub classes considered space bdd orderings
contains exponentially bad ones indeed true set bdd orderings


fibdd rdering h euristics c lassical p lanning



x

x

x





x

x





x

x











x

b x

figure bdds showing orderings perfect proof theorem solid arrows
represent high edges dashed ones low edges
x

x



x

x

x

x

x

x











x











x





good variable ordering hx x x



b bad variable ordering hx x x

figure bdds different variable orderings q n x x
x solid arrows denote high edges dashed ones low edges
subsets delivered ga cg classification schemes bad
almost considered cases little bit hope chain causal graphs
negative employ boolean functions quadratic form variables
x xn yn take form x oplow ophi ophi xn oplow yn ophi
oplow vice versa denote functions q ophi oplow
functions ordering hx xn yn e bringing pairs xi yi together yields
bdd whose size polynomial n ordering hx xn yn e splitting
variables two blocks one x one variables yields bdd exponential
size wegener proves q depicted figure similar arguments apply
quadratic forms



fik issmann h offmann

g

x

x





x

g

x



g





x

x











g front

g

b g within pair

figure bdds representing g q different positions g variable solid arrows
represent high edges dashed ones low edges
theorem search directions ga cg safe fdr g ifork
w
proof prove claim backward search consider function q ni xi yi
design fdr task n uses n boolean variables g x xn yn including
additional variable g goal requires true n actions achieving g
requires pair xi yi true precondition clearly wn fdr g ifork backward
layer distance goal characterized g ni xi yi
optimal ordering q consists pairs xi yi yi xi adding g variable
optimal ordering places front depicted figure end cases
require exactly one node representing g variable placing g variable anywhere else requires
many nodes representing g nodes different sink reached edges passing
layer case two g nodes g placed two pairs
three nodes placed two nodes constituting pair see figure b latter case
ordering following ga n places g middle x variables arbitrary
order around ordering following cg n places g end x variables
arbitrary order cases x variables may placed variables resulting
exponential overhead concludes proof backward search
forward search consider function q construct n
variables g x xn yn domains x xn yn ternary
unknown true false x variables initially unknown set
true false currently unknown n actions achieving g exactly
states initial state distance n x w
variables true false
states exactly satisfy g q g ni xi yi causal


fibdd rdering h euristics c lassical p lanning



x

dx

dy



dy



dyn

yn



x

dx



dn

xn

dxn

dn

figure dtg variable z used proof theorem dashed edges correspond
preconditions changes value corresponding variable
graph remains unchanged set possible orderings following ga n cg n remains
backward search well orders exponential overhead
concludes proof forward search
note proof construction shows orders possible ga cg
super polynomially bad possible orders good hence claimed prove ga
cg safe fdr g ifork might case ga cg viable fdr g ifork
leave open question
theorem search directions ga cg safe fdr g fork
v
proof search directions use function q ni xi yi
fdr task n boolean variables x xn yn plus additional variable z domain
dx dy dx dy dn dxn dyn dn actions n
z move di dxi dyi di see figure action
preconditioned dxi achieves xi action preconditioned dyi achieves yi initially z
xi yi false goal requires z dn xi yi true forward search
states initial state distance n exactly z dn q true
backward search states goal state distance n exactly z q
true
ordering following ga n places z middle x variables arbitrarily
around ordering following cg n places z beginning x variables
arbitrarily thus constraint variables x xn yn placing


fik issmann h offmann

x

x



x





g

figure causal graph task used proof theorem
x variables variables ordering compatible schemes
exponential overhead
proof shows ga cg safe makes statement regarding viability
note task proof construction unsolvable easy modify task
solvable without breaking proof argument forward search direction investigate whether true backward search direction well practice proving
unsolvability traditionally popular objective state space exhaustion
one traditional purposes bdds deemed good
dag causal graphs prove cases orderings admitted ga
cg
super polynomially bad
theorem search directions ga cg viable fdr g dag
proof backward search claim use combination chain causal graph
inverted fork illustrated figure design fdr task n uses n boolean
variables g x xn yn including variable g goal requires true
n actions achieving g requires pair xi yi true precondition
part task proof theorem add actions ensuring two
schemes x variables placed variables vice versa one action empty
precondition sets x true effect another one requires xn true precondition
sets true effect rest xi yi precondition set xi yi
true effect states goal distance thus characterized g q
order induced ga places g middle places x variables increasing
order g variables increasing order g places variables decreasing
order g x variables decreasing order g cg induces order starting
x variables increasing order followed variables increasing order followed g
thus cases x variables placed separately variables resulting exponential
overhead proves claim backward search direction
forward search use proof theorem namely extend
domain x variables true false unknown x variables
initialized value unknown n actions setting g true requiring pair xi yi
true additional actions follows two require x unknown set true
false respectively two require xn true unknown set true false
respectively two require xn false unknown set true false respectively
manner four actions xi yi n requiring xi yi
true respectively false requiring xi yi unknown setting xi yi true respectively
false thus states
w initial state distance n characterized function
g q g ni xi yi variable orders induced ga cg
backward search resulting exponential overhead concluding proof


fibdd rdering h euristics c lassical p lanning

x





x



x

figure causal graph task used proof theorem
x

x





x

x











x

x

x

x



x















optimal ordering

x



















b exponential ordering

w
l
figure bdds representing yi xi yi used proof theorem solid
arrows represent high edges dashed ones low edges
immediately get recall cg defined acyclic causal graphs
corollary ga viable fdr g
close investigation somewhat positive chain causal graphs
theorem search directions ga cg perfect fdr g chain exists
ordering scheme viable fdr g chain
proof first part claim inherited fdr g e corollary theorem
second part claim existence non viablew
ordering scheme consider first
backward search direction function q ni xi yi design fdr
task n uses n boolean variables x xn yn goal requires variables
false action without precondition set x true actions preconditions requiring
yi false setting xi true actions preconditioned xi true setting yi false
causal graph depicted figure clearly n fdr g chain
states distance goal ones except onelyi false
n

single
true
ln
wn yi xi true well characterized formula yi q
yi xi yi easy see exclusive part formula change
relevant properties bdds quadratic form e still orderings polynomial
orderings exponential number nodes e g placing x variables


fik issmann h offmann

safe
g chain
trivially
safe
g


viable
g dag

safe
g fork


viable
g

safe
g ifork

figure overview classification hold ga cg search
direction

variables see figure illustration ordering scheme including latter orderings
viable
forward search direction case construct task x variables
ternary unknown true false unknown initially value x set
freely yi set true false xi true set true xi false xi
set freely yi set
v true false n steps reach exactly
states characterized q ni xi yi bdd representing q
exponential size e g x variables placed variables ordering scheme
including orderings viable
note task families n described ga cg force
xi yi variable ordered pairs resulting bdds minimal size see figure
sense two task families constitute truly positive within
ordering information causal graph keeps us making exponentially bad mistakes
positive message would much stronger ga cg safe families tasks
chain causal graphs remains open question whether
figure gives overview evidence speaks rather clearly strong
connection causal graph dependencies dependencies relevant bdd size note
causal graph underlying theorem non viability fdr g dag simple
form combining chain inverted fork theorem non safety fdr g ifork
relies tasks fall known syntactically identified tractable class optimal
katz domshlak note safe already quite bad practice
incurring exponential risk unless clever way choosing ordering within
moment

whats causal graph practice
shown poor worst case performance causal graph variable ordering schemes
theory practice might another matter assess latter implemented comprehensive
set causal graph variable ordering schemes comprising schemes total ran
comparison practical good bad delimiters bad delimiter used random
orderings good delimiter used shelf dynamic reordering
gamers bdd package cudd sifting rudell
words order regarding sifting works variable greatest number
nodes current bdd chosen first moved towards end ordering


fibdd rdering h euristics c lassical p lanning

towards beginning ordering iteratively swapping position next variable
corresponding direction positions tried variable moved position
bdd size smallest done next variable chosen variables
processed better comparability ordering schemes restrict
keep variables representing v together
previously indicated dynamic reordering consumes much runtime cost effective
present experiments interested bdd size give dynamic reordering ample runtime section identify simple adaptive criteria stopping dynamic
reordering automatically search taking advantage size reduction capacity without
suffering much runtime consumption
ran benchmarks international competition ipc used
gamer base implementation planners running one core intel xeon
x cpu ghz unless otherwise stated used ipc settings namely timeout
minutes memory limit gb
ordering schemes
ran six schemes directly causal graph
gamer gamers original ordering scheme approximates ga
gamerpre gamer causal graph extended arcs pairs precondition
variables idea capture dependency forward search
backward search e inverting actions
wgamer gamer arcs weighted number relevant actions e number
actions inducing corresponding arcs
wgamerpre gamerpre weighted arcs
cglevel fast downwards helmert level heuristic approximates cg orders
variables strongly connected components within components considers
weighted causal graph orders variables smallest incoming weight first similar
wgamer weights correspond number actions induce arc
cgsons another approximation cg selects variable v whose parents already selected least one whose parents already selected arbitrary
variable v exists
additionally used six ordering schemes adopted model checking literature
structure called abstract syntax tree ast e g maisonneuve
directed graph containing root node overall task subtrees actions subtree
consists nodes representing subformulas specified action e subformulas
actions precondition effect variables task leaves ast leaves
merged e one node variable task edges point node
representing function corresponding subtrees
construct ast pddl input consider following example actions similar floortile domain predicates r denoting tile robot r


fik issmann h offmann













r



painted

r

figure example ast
currently painted denoting whether tile already painted two actions
paint r precondition r painted effect painted denoting robot r paint tile currently painted similarly
action paint r precondition r painted effect painted
denotes robot r paint tile currently painted
figure illustrates corresponding ast root actions one subtree
two actions actions preconditions effects encoded
retain one copy variable leaves relevant painted
first authors names reference additional ordering schemes following
butler butler ross kapur mercer extension fujita fujisawa
kawato latter proposed perform depth first search dfs ast
starting root node order variables order reached
first time butler et al extended setting several roots remove overall
root retain subtrees actions arrive exactly setting
starts dfs action containing highest number variables within
tree advances similar manner continues subtree contains
highest number variables among subtrees current node retrieved ordering
order variables reached first time
chung chung hajj patel two step first step assigns values
nodes ast starting leaves assigning value assigns
inner node maximum values assigned successors plus second step
performs dfs starting root guided values nodes visiting
successors highest value first order variables reached first
time chosen variable ordering
chung chung et al determines shortest distance pair variables
calculated considering edges ast undirected additionally total
distances e sum minimal distances variables stored variables variable smallest total distance chosen first next one one closest


fibdd rdering h euristics c lassical p lanning

last variable inserted ordering case tie distance preceding
variables taken account
maisonneuve maisonneuve greedy starting empty sequence
step temporarily extends current sequence variable yet sequence
variable weight determined number variables extended
sequence appear action summed actions variable removed
sequence next one added weights calculated variable
highest weight appended sequence next iteration starts calculating
weights remaining variables end last sequence contains variables
thus corresponds variable ordering
malik malik et al assigns level value maximal level predecessors plus
node within ast root assigned value variables ordered
according level values highest values coming first
minato minato et al calculates weights nodes ast weight root
node action set successors node w w nodes weight
number successors node one variables highest weight
chosen first nodes removed along ingoing edges recursively
nodes remaining successors reduced graph weights recalculated
procedure continues finally variables ordering
bad delimiter
get bad delimiter ran random orderings ordering corresponds
one run ipc benchmark tasks random variable ordering instance
make feasible used time one minute backward search implementation
viable short time use forward search comparison
data settings minute time forward search used twelve static
ordering schemes initially ran ordering schemes random orderings tasks
random runs removed tasks benchmark set solved least
previous random static ordering runs retaining tasks figure shows coverage
e number solved tasks x axis fraction random orderings
coverage axis coverage data ordering schemes shown vertical lines
malik cglevel lie middle gaussian distribution respectively
words malik bad cglevel even worse average random ordering
matters bleak ten ordering schemes close together lie clearly
gaussian distribution compared best random orders however
ordering schemes appear rather humble consider table particular consider nr
giving
number instances solved ordering scheme random order consider n r

giving number instances solved scheme solved random order
r
table shows nr
strictly smaller n three ordering schemes
strictly larger single task one schemes namely butler average nr

n r





fik issmann h offmann

percentage random orderings



cglevel
malik
maisonneuve wgamerpre
minato wgamer
cgsons
gamer gamerpre
chung chung
butler
















coverage







type

butler

cglevel

cgsons

chung

chung

gamer

gamerpre

maisonneuve

malik

minato

wgamer

wgamerpre

best scheme

figure coverage random orders vs ordering schemes schemes ordered top bottom
worst best coverage x means schemes x coverage

nr

n r

n r

nr



































































table differences solved instances ipc tasks minute timeout r means
solved random ordering r least one random ordering solved corresponding ordering scheme solved corresponding ordering scheme
good delimiter
performed bidirectional blind search e competitive setup general figure
contains one data point every pair ipc benchmark instance ordering scheme
solved gamer dynamic reordering starting arbitrary variable
order one returned gamers grounding process b gamer ordering scheme
without dynamic reordering time hours minutes b x value
data point size largest bdd constructed value size
largest bdd constructed b allowed much higher time dynamic reordering
reordering runtime effective question asking merely
two methods yields smaller bdds figure shows dynamic reordering universally
much better giving us sizes three orders magnitude smaller
schemes total instances solved ordering scheme dynamic reordering
cases bdd sizes smaller factor dynamic reordering


fibdd rdering h euristics c lassical p lanning

peak size ordering schemes










peak size dynamic reordering





dynamic
reordering

wgamerpre

wgamer

minato

malik

maisonneuve

gamerpre

gamer

chung

chung

cgsons

cglevel

butler

figure bdd size dynamic reordering vs ordering schemes

domain
barman













elevators

floortile














nomystery
openstacks

parc printer













pegsol

scanalyzer













sokoban

tidybot





transport















visitall
woodworking


total

table coverage ipc tasks dynamic reordering numbers parentheses represent coverage minute timeout
cases smaller factor cases smaller
factor
table shows coverage different schemes ipc tasks make
similar observation one minute forward search namely cglevel
malik clearly behind others last column shows coverage gamer
dynamic reordering provides two numbers first coverage hours timeout second
coverage timeout schemes e minutes becomes clear
applying dynamic reordering entire search time feasible practice limiting
runtime










total runtime
reordering time
transition relation creation









reorderings

time

time

k issmann h offmann














total runtime
reordering time
transition relation creation



visitall task







reorderings







b pegsol task

figure total runtime time spent reordering limited number reordering steps two
example ipc tasks reorderings vertical line performed transition
relation creation

limited dynamic reordering
given much memory efficient behavior dynamic reordering possible
run dynamic reordering limited time hoping get ordering good enough
remainder search reordering automatically started number allocated
bdd nodes reaches certain threshold default first threshold nodes
dynamically adapted reordering default next threshold set times number
nodes reordering simple way control dynamic reordering limit number
reordering steps turn dynamic reordering desired number reorderings
performed
different reordering limits total runtime task often looks similar situation
depicted figure reorderings takes long time solve task due
bad initial ordering first reorderings sometimes hurt performed
beginning construction transition relation enough information good
orderings available however many reorderings solving takes long time due
immense overhead reordering time grows exponentially step
important different behavioral pattern depicted figure b domains
pegsol sokoban minimum curve beginning without reordering
total runtime increases afterward mainly increase reordering time
explanation behavior might initial ordering already pretty good
dynamic reordering cannot improve much overhead incurred vain often
happens easier tasks domain learning good setting simpler tasks
seems impossible
attempting exploit observations design adaptive stopping criteria geared finding
good point stopping dynamic reordering given available observations e g number
bdd nodes reordering reordering times current total runtimes experimented
following approaches
first noticed early reordering time increases step step small factor
later factor increases preliminary runs saw often area smallest
runtime coincides situation increase reordering time reaches threshold
often see e g figure compare runtime minimum
figure task call factor criterion


fibdd rdering h euristics c lassical p lanning



factor
percentage

factor
















reorderings
factor time last reordering
previous one










percentage











reorderings
b percentage time last reordering
total runtime far

figure factor percentage criterion limited number reordering steps task
ipc visitall domain
second another observation preliminary runs percentage time spent
last reordering step total current runtime often follows u curve minimum
curve often lies close number reorderings total runtime minimum see
e g figure b compare runtime minimum figure task employ
percentage criterion stops reordering possibly local minimum reached
e compare percentage current step previous step current
one greater stop reordering
finally simple combination criteria stop reordering soon one tells
us
evaluate adaptive stopping criteria ran tasks ipc domains different limits number reorderings ranging runs calculated
would achieve adaptive stopping criteria see table best possible
coverage e number tasks solved least one setting limited number reorderings
without reordering found solutions adaptive stopping criteria yield
coverage performance reasonable factor criterion quite bad
percentage criterion combination criteria recall percentage criterion aims stopping reordering incurring prohibitive overhead indeed criterion
reordering often stopped earlier factor criterion cases detrimental
particularly woodworking domain strategy happens fall dramatic local
peak total runtime curve resulting instances longer solved
several cases dynamic reordering transition relation creation counterproductive ran delayed reordering dynamic reordering started bdds
transition relation created table case without reordering
unchanged respect table best possible slightly worse
coverage adaptive stopping criteria picture changes substantially contrast
table percentage criterion excels delivering coverage short best possible
regarding factor criteria overly small large factors bad best behavior short
best possible obtained middle
cases highest number reorderings could observe clearly planner ran
time memory finished last reorderings could performed cases used gamerpre
initial ordering turned among best preliminary set experiments



fik issmann h offmann

domain
barman
elevators
floortile
nomystery
openstacks
parc printer
pegsol
scanalyzer
sokoban
tidybot
transport
visitall
woodworking
total


reord















best
possible































factor criterion










































percentage
criterion































criteria













































table coverage different stopping criteria immediate reordering

domain
barman
elevators
floortile
nomystery
openstacks
parc printer
pegsol
scanalyzer
sokoban
tidybot
transport
visitall
woodworking
total


reord















best
possible































factor criterion










































percentage
criterion































criteria













































table coverage different stopping criteria delayed reordering e reordering started
creation transition relation bdds
shed light observations figure shows coverage function
different factor values case immediate reordering figure delayed
reordering figure b figure see percentage criterion stops reordering
early without coverage resulting stopping reordering solely factor criterion
get high however ascend coverage actually starts percentage
criterion stops reordering thus cutting many solutions figure b factor
curves identical mainly increasing increasing factor combination
criterion rises another little bit factor criterion alone drops substantially combined
criterion avoids drop point factor roughly percentage
criterion stops reordering least early factor criterion










factor

coverage

coverage

bdd rdering h euristics c lassical p lanning









factor
immediate reordering













factor










factor
b delayed reordering





figure coverage function factor factor criterion alone combination
percentage criterion denoted

conclusion
tempting equate variable dependencies bdd symbolic search
identified causal graphs previous done unquestioningly looking little
closely issue shown causal graph variable orderings exponentially bad
even severely restricted sub classes empirically fast downwards level heuristic
worse random ordering schemes lag far behind shelf reordering
one may wonder meaning theoretical could static ordering
scheme incur exponential overhead worst case agree view principle
expect happen tasks restricted tractable domainindependent optimal remains seen extent classification framework
suitable characterize properties ordering schemes fragments
impression point static ordering schemes limited hopeless
prior actually building bdds appears impossible extract reliable information
form take way forward use dynamic reordering techniques
targeted manner initial experiments direction meet immediate
breakthrough certainly promise especially considering primitive nature
method stopping criteria employed promising future directions include flexible
strategies dynamic reordering machine learning deciding toggle switch
specific reordering techniques exploiting particular structure bdds hand

acknowledgments
thank anonymous reviewers icaps short version previous version
article whose comments helped tremendously improve

references
brafman r domshlak c structure complexity unary operators
journal artificial intelligence
bryant r e graph boolean function manipulation ieee transactions computers


fik issmann h offmann

burch j r clarke e long e symbolic model checking partitioned
transition relations halaas denyer p b eds proceedings international
conference large scale integration vlsi vol ifip transactions pp
edinburgh scotland north holland
burch j r clarke e long e mcmillan k l dill l symbolic model
checking sequential circuit verification ieee transactions computer aided design
integrated circuits systems
butler k ross e kapur r mercer r heuristics compute variable
orderings efficient manipulation ordered binary decision diagrams proceedings
th conference design automation dac pp san francisco ca
usa acm
chen h gimenez causal graphs structurally restricted journal
computer system sciences
chung p hajj n patel j h efficient variable ordering heuristics shared
robdd proceedings ieee international symposium circuits systems
iscas pp chicago il usa ieee
cimatti pistore roveri traverso p weak strong strong cyclic
via symbolic model checking artificial intelligence
darwiche sdd canonical representation propositional knowledge bases
walsh ed proceedings nd international joint conference artificial intelligence ijcai pp aaai press ijcai
dechter r meiri experimental evaluation preprocessing techniques constraint
satisfaction sridharan n ed proceedings th international joint
conference artificial intelligence ijcai pp detroit mi morgan kaufmann
domshlak c dinitz multi agent offline coordination structure complexity
cesta borrajo eds recent advances ai th european conference
ecp lecture notes artificial intelligence pp toledo spain
springer verlag
edelkamp helmert exhibiting knowledge minimize
state encoding length biundo fox eds recent advances ai
th european conference ecp lecture notes artificial intelligence pp
durham uk springer verlag
fan g muller holte r non linear merging strategies merge shrink
variable interactions edelkamp bartak r eds proceedings th annual
symposium combinatorial search socs aaai press
freuder e c sufficient condition backtrack free search journal association
computing machinery
fujita fujisawa h kawato n evaluation improvements boolean comparison method binary decision diagrams proceedings international
conference computer aided design iccad pp ieee computer society press


fibdd rdering h euristics c lassical p lanning

gimenez jonsson complexity simple causal
graphs journal artificial intelligence
helmert heuristic causal graph analysis koenig zilberstein
koehler j eds proceedings th international conference automated
scheduling icaps pp whistler canada morgan kaufmann
helmert fast downward system journal artificial intelligence
helmert haslum p hoffmann j flexible abstraction heuristics optimal sequential boddy fox thiebaux eds proceedings th
international conference automated scheduling icaps pp
providence rhode island usa morgan kaufmann
helmert haslum p hoffmann j nissim r merge shrink abstraction method
generating lower bounds factored state spaces journal association computing machinery
hoffmann j analyzing search topology without running search connection
causal graphs h journal artificial intelligence
hoffmann j b ignoring delete lists works part ii causal graphs bacchus f
domshlak c edelkamp helmert eds proceedings st international
conference automated scheduling icaps pp aaai press
jonsson p backstrom c incremental european workshop
katz domshlak c islands tractability cost optimal journal
artificial intelligence
katz domshlak c implicit abstraction heuristics journal artificial intelligence

kissmann p edelkamp improving cost optimal domain independent symbolic burgard w roth eds proceedings th national conference
american association artificial intelligence aaai pp san francisco ca
usa aaai press
kissmann p hoffmann j whats bdd causal graphs variable orders borrajo fratini kambhampati oddi eds proceedings
rd international conference automated scheduling icaps pp
rome italy aaai press
knoblock c automatically generating abstractions artificial intelligence

maisonneuve v automatic heuristic generation mtbdd variable orderings
prism internship report oxford university computing laboratory
malik wang brayton r sangiovanni vincentelli logic verification
binary decision diagrams logic synthesis environment proceedings international conference computer aided design iccad pp ieee computer
society press


fik issmann h offmann

mcmillan k l symbolic model checking kluwer academic publishers
minato ishiura n yajima shared binary decision diagram attributed edges
efficient boolean function manipulation proceedings th acm ieee design
automation conference dac pp orlando fl usa ieee computer society
press
moskewicz madigan c zhao zhang l malik chaff engineering
efficient sat solver proceedings th conference design automation dac las vegas nevada usa ieee computer society
rintanen j satisfiability heuristics artificial intelligence
rudell r dynamic variable ordering ordered binary decision diagrams lightner
r jess j g eds proceedings ieee acm international conference
computer aided design iccad pp santa clara ca usa ieee computer
society
sievers wehrle helmert generalized label reduction merge shrink
heuristics proceedings th aaai conference artificial intelligence aaai
quebec city quebec canada aaai press
wegener branching programs binary decision diagrams siam
williams b c nayak p p reactive planner model executive pollack
ed proceedings th international joint conference artificial intelligence
ijcai pp nagoya japan morgan kaufmann
zabih r applications graph bandwidth constraint satisfaction
proceedings th national conference american association artificial intelligence aaai pp boston mit press




